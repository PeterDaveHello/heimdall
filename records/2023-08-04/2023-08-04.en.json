[
  {
    "id": 36994214,
    "title": "Successful room temperature ambient-pressure magnetic levitation of LK-99",
    "originLink": "https://arxiv.org/abs/2308.01516",
    "originBody": "Skip to main content We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate > cond-mat > arXiv:2308.01516 Help | Advanced Search All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text Search Condensed Matter > Superconductivity [Submitted on 3 Aug 2023] Successful growth and room temperature ambient-pressure magnetic levitation of LK-99 Hao Wu, Li Yang, Bichen Xiao, Haixin Chang Recently, Sukbae Lee et al. reported inspiring experimental findings on the atmospheric superconductivity of a modified lead apatite crystal (LK-99) at room temperature (https://doi.org/10.6111/JKCGCT.2023.33.2.061, arXiv: 2307.12008, arXiv: 2307.12037). They claimed that the synthesized LK-99 materials exhibit the Meissner levitation phenomenon of superconductors and have a superconducting transition temperature (Tc) higher than 400 K. Here, for the first time, we successfully verify and synthesize the LK-99 crystals which can be magnetically levitated with larger levitated angle than Sukbae Lee's sample at room temperature. It is expected to realize the true potential of room temperature, non-contact superconducting magnetic levitation in near future. Subjects: Superconductivity (cond-mat.supr-con) Cite as: arXiv:2308.01516 [cond-mat.supr-con]   (or arXiv:2308.01516v1 [cond-mat.supr-con] for this version)  https://doi.org/10.48550/arXiv.2308.01516 Focus to learn more Submission history From: Haixin Chang [view email] [v1] Thu, 3 Aug 2023 03:13:51 UTC (598 KB) Download: PDF only Current browse context: cond-mat.supr-connew | recent | 2308 Change to browse by: cond-mat References & Citations NASA ADS Google Scholar Semantic Scholar Export BibTeX Citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Demos Related Papers About arXivLabs Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?) About Help Contact Subscribe Copyright Privacy Policy Web Accessibility Assistance arXiv Operational Status Get status notifications via email or slack",
    "commentLink": "https://news.ycombinator.com/item?id=36994214",
    "commentBody": "Successful room temperature ambient-pressure magnetic levitation of LK-99 | Hacker NewsHacker News new | comments | ask | show | jobs | submitloginSuccessful room temperature ambient-pressure magnetic levitation of LK-99 (arxiv.org) 1283 points by spekcular 8 hours ago| 628 comments jjallen One somewhat ironic fact of this story is that the rogue former employee perhaps deserves some credit for bringing this thing out into the world.They had been working on this for quite a long time themselves, rightfully so. But now the whole world is working on it and exploring other methods and combinations of materials I would assume (to improve upon the original design and avoid any patents).How long would they have kept this thing to themselves without the rogue employee bringing this thing to light?Perhaps that was part of the rogue former employee&#x27;s motivation in \"going rogue\": that this thing needs to see the light of day so it can start to benefit humanity. reply wcerfgba Exactly, the 99 stands for 1999, so potentially this material has existed for over 20 years and we could have started testing and replication on a much wider scale a decade ago. What benefit have we gained by disseminating this research so slowly? reply StackOverlord 1 What happened, for those who want to catch up:https:&#x2F;&#x2F;twitter.com&#x2F;8teAPi&#x2F;status&#x2F;1685294623449874432With the anti-hype hype that surrounds this discovery this was to be expected. Why would I disclose this kind of research to the public so that the whole world can benefit from it when I&#x27;m called a fraudster or a liar. Why would I risk my reputation – no matter how I spin my research – in a sacrificial circle jerk when I can work on it stealthily and hope to make some bucks ? reply n2d4 55 > What benefit have we gained by disseminating this research so slowly?It&#x27;s less visible, but at this scale there&#x27;s a high cost in everyone pausing their research to replicate LK-99. If it turns out to be real that&#x27;s worth, but if not it could&#x27;ve gone to better use. Think of what we could&#x27;ve done with the time we spent reproducing cold fusion.It&#x27;s survivorship bias; yes, you would love to see the significant discoveries happen sooner, but if they were rushed you&#x27;d also see a lot of trash that currently never leaves the draft stage. Just look at how many people complained that the LK-99 papers were incomplete and unprofessional!Also, LK-99 was discovered in 1999 but wasn&#x27;t known as a room-temperature superconductor then. There are too many things to research and not enough researchers, so it was put on hold for two decades. reply lucideer 8 > It&#x27;s less visible, but at this scale there&#x27;s a high cost in everyone pausing their research to replicate LK-99. If it turns out to be real that&#x27;s worth, but if not it could&#x27;ve gone to better use. Think of what we could&#x27;ve done with the time we spent reproducing cold fusion.This is a (I feel rudimentarily obvious) fallacy of finite time implying there is N researchers working on one thing that must be useful at any given time. The individuals reproducing cold fusion &#x2F; LK-99 &#x2F; whichever might not have been spending their energy &#x2F; time &#x2F; funding on anything more \"guaranteed productive\" (nor even on anything at all) otherwise.Knowledge motivates research. That motivating is not a classsically scarce resource, its multiplicative. reply Iulioh This reminds me of an Asimov novel (don&#x27;t remember the name)In this universe there are long life humans that don&#x27;t really collaborate with other humans (like a single person, not a group of quasi immortal humans) in the scientific field to have all the credit because who cares if you take 200 years for a discovery if the glory is all yours reply imdsm 54 https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;R._Daneel_Olivaw reply mousetree Maybe The Naked Sun or one of the books in that series? It’s been years since I read it but I remember there being some motif about people not interacting physically and living a long time. reply marmakoide It might be that the process to make LK99, produces a fraction of the Good Stuff, which went under the radar until recently. It would not have been the first time. If it is confirmed with the proper methodology ... right now it&#x27;s too early to build castles on LK99. reply ssl232 I don&#x27;t know if this is true or not, but I read something suggesting they produced it in 1999 as a side product of something else but didn&#x27;t start to examine its properties properly until a handful of years ago. reply agumonkey 31 One tiny thing, the compute power to research it in different ways maybe. In 99 the supercomputing&#x2F;datascience landscape was very different.Maybe not worth losing 20 years ... i don&#x27;t know reply beowulfey 35 Neither of them were doing research for the bulk of the time. We can only guess what brought them back to the project, but it may have restarted sometime around 2016. reply baq > The Croatian scientists say that current will flow effortlessly through their material, a mixture of lead carbonate and lead and silver oxides, at up to about 30 °C.[...]> Danijel Djurek, a physicist at A. Volta Applied Ceramics in Zagreb, Croatia, claims that he discovered his superconducting ceramic mixture in the late 1980s. But he was unable to pin down the structure and formula of the material, and his research was interrupted by years of war, following Croatia&#x27;s split from Yugoslavia.excerpts from http:&#x2F;&#x2F;www.rexresearch.com&#x2F;djurek&#x2F;djurek.htm reply jjallen I&#x27;d like to add that if this claim of having replicated the material with the reportedly poor description of how to do so is true then it really isn&#x27;t that hard to replicate. I am surprised they haven&#x27;t published a paper by now.And this suggests that they were conflicted for some reason about publishing, likely commercially so (as evidenced about the patent). Maybe they were trying to create a product with it that they could sell before others could replicate the material.So the rogue employee does absolutely deserve credit for bringing this thing into the world and humanity should not stigmatize them for doing so; perhaps we should do exactly the opposite. reply Iulioh >reportedly poor description of how to do soIsn&#x27;t it false?I have read that the description is pretty extensive, just the yelds are really bad because the production method is 1) hard and 2) inconsistent?So the description is good but hard to replicate reply CommanderData 34 They can still recover from this reputationally very easily assuming egos are not in the way.Accept it happened and make amends and make those things very public and move forward to making an official announcement together with the so called &#x27;rogue&#x27; author (in my opinion he did the world a favour). reply pcrh There&#x27;s apparently a patent published in 2020. It surprises me that it never gained attention.edit:KR20210062550A - Mehtod of manufacturing ceramic composite with low resistance including superconductors and the composite thereof -https:&#x2F;&#x2F;patents.google.com&#x2F;patent&#x2F;KR20210062550A&#x2F;en reply BaculumMeumEst people will claim all kinds of crazy, implausible shit in patents. you would go insane trying to draw conclusions from the set of applications sent to patent offices as a whole, it would be impossible to differentiate what is legitimately worth paying attention to. reply n2d4 43 Search on that site for \"room-temperature superconductor,\" and you&#x27;ll see why it never gained attention. reply fear91 45 Off-topic but I&#x27;d have expected someone to spell-check a patent title. Mehtod seems like a misspelling? reply londons_explore 40 Spelling doesn&#x27;t impact the legal weight of a patent, but can help prevent people searching for them.You&#x27;d think to put your deliberate typos in the word &#x27;supercobductor&#x27; though... reply imdsm 53 Imagine if human progress had taken a wrong turn in 2020 all becomes of a typo reply DoctorOetker 20 A funny theory, especially since this good samaritan only prematurely published after his connection to the research was severed. reply King-Aaron Have you got any back-story on that? I only saw that their team posted it to arxiv, hadn&#x27;t heard the other drama reply httpz 57 In the early 90s, Prof. Choi theorized a new way of creating a room temperature superconductor but it wasn&#x27;t really accepted by the mainstream. Supposedly, in 1999, two researchers in Choi&#x27;s lab, Lee and Kim (hence LK), created the first sample of LK-99. They weren&#x27;t able to reliably replicate nor were they able to fully explain the theory. In 2017, as a dying wish, Choi asked Lee and Kim to continue on with the LK-99 research but asked to not publish it until they understand the theory behind it. They founded a lab and collaborated with other scientists in the field and Kwon was one of them. 4 months ago, Kwon left the lab and two weeks ago Kwon leaked the paper. The paper Kwon leaked only listed Lee, Kim and Kwon as the authors and excluded other collaborators. Some suspect Kwon excluded the other collaborators because Nobel prize can only be awarded to three people at most. A few days after the leak, Lee & Kim hastily published a paper with four more authors but not Kwon.https:&#x2F;&#x2F;namu.wiki&#x2F;w&#x2F;LK-99&#x2F;%EC%A0%84%EA%B0%9C reply jjallen A former employee was the first to publish a paper with only three authors. I am surprised you haven&#x27;t heard about this.Then a few hours later a paper was published with six authors (without one of the original three authors), ostensibly by the core team that has been working on this.There should be much more detail on the Internet if you search for it. reply suby Notably, the missing author from the second paper is the rogue employee who published the first paper. The order of the first two authors is the same for both papers. reply acters earlier in the week, someone posted that the person who posted the paper early is someone who wanted to fund the project, but the researchers didn&#x27;t want to include him. So he took as much data as he could collect and posted it publicly with the addition of his name. He is not a researcher or scientist for the team. reply wetmore I also hadn&#x27;t heard about this for what it&#x27;s worth. reply cthalupa It&#x27;s one of the reasons people were thinking this might not be a fraud.Nobel prizes are capped to 3 people, and the speculation is that the rogue person published early to try and ensure they were one of the people that received it. No reason for infighting like that if you know it&#x27;s a hoax. reply oldgradstudent 9 > No reason for infighting like that if you know it&#x27;s a hoax.There was plenty of bitter infighting over credit during the 1989 cold fusion fiasco.Knowing it&#x27;s not a hoax does not near it is true.As always, only reproduction attempts matter. reply Iulioh I even wondered about that, is ever a thing?Like saying \"SORRY, FIRST\" to the nobel committee? reply belter See this: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36953050 reply King-Aaron Fascinating, thank you reply m463 Wait, how did co-discoverer a few days ago become rogue former employee today? reply anonylizard There&#x27;s 3 main parties to LK99.L&K, are two PHDs taught by their now dead former professor. Their research into LK-99 is inherited from their former professor but they lacked funding, hence it was a hobby project for a long time, and they needed funding to work on it full time.The Korean professor: A professor who started taking interest and sponsoring the project for the last few years. However, he likely didn&#x27;t participate directly in the research much.The American professor (Ethnically Korean): A professor who was brought in rather recently (Maybe last 1-2 years?), to help bring credibility to the team. He is probably the one with the expertise to perform measurement and ascertain that it is a superconductor.The Korean professor got kicked out from the team for unknown reasons. This was evidenced in the April paper published in Korea, which lacked the Korean professor&#x27;s name. Quantum center also removed him from the website.4 months later, he was back with a vengeance, and published the paper, with only him, and L&K on it (ie, the 3 man paper). The Korean professor possesses no sample, and also lacks the original data for LK-99.A day later, the american professor hastily rushed out another paper (The 6-man paper), with L&K, himself, and 3 irrelevant lab assistants.Since the earlier Korean paper in April got 0 attention and was treated like a typical troll paper. They probably assumed posting on arxiv was just good material for later legal battles, but they could otherwise continue happily researching and patenting their material. However, interest in LK-99 exploded like a nuke, because the first signal for credibility: That two professors were in a bitter battle over authorship, did not escape people&#x27;s eyes.2 days later, the Korean professor had a presentation at a Korean conference, but attendees were disappointed by his data and lack of samples (Prediction markets hit a low of 15% at this point).However, the American professor took control of media communications, and quickly dissociated with the Korean professor, yet he completely stood by the claims of LK-99. Now the American professor has talked to numerous Korean media and directly sent an exclusive video to NYT.Its interesting why L&K chose the American professor over the Korean one. Needless to say, if this works out, the interpersonal saga will end up in a Netflix documentary, and probably many court cases.I should also note that the nobel prize is likely a secondary concern for the group. They aren&#x27;t in a comfortable academic position where money is only a bonus. They were struggling PHDs for a long time. Nobel prize money is too little, and will come way too late to make a difference for their lives. L&K and the American professor are likely trying to maximize the value of their patents and know how to sell to investors, rather than to make public verification ASAP, which would be optimizing for a nobel prize. reply phtrivier For people who start the comic in the middle, can you provide the real names of the various superheroes mentionned here ? reply anonylizard The names are not helpful at all, because of Korean&#x27;s overlapping surnames. But here you go.L&K = Sukbae Lee, Ji-Hoon KimKorean professor: Young-Wan KwonAmerican professor: Hyun-Tak KimFormer (Long dead) professor: Tong-Seek Chair (Sample paper: https:&#x2F;&#x2F;link.springer.com&#x2F;article&#x2F;10.1007&#x2F;BF02697404) reply phtrivier 33 > The names are not helpful at all, because of Korean&#x27;s overlapping surnames.Well, you have to provide the full name. Bummer :DI assume the news would also be much shorter but slighly more confusing if we just called all \"Joe\"s \"Joe\" ?Whereas they would be much less ambiguous but slighly harder if we all had a uuid assigned at birth. (Or maybe a checksum of our DNA ?) reply dom96 28 > because of Korean&#x27;s overlapping surnamesThis is why you list the full name, rather than just the surnames. As you&#x27;ve listed them they are quite helpful. reply vlz This comment has the names and links to the papers: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36953050 reply Iulioh Wonder if the \"their former professor\" will recive meaningful credit reply anonylizard This is already in the 6 man paper, that&#x27;s how the internet deduced their story:\"ACKNOWLEDGEMENTS We acknowledge late Prof. Chair Tong-seek for initiating research of a 1-dimensional superconductor of over room temperature at atmospheric pressure. In particular, his enthusiasm on superconductor study impressed many researchers. \"If this works out, this will be by far the biggest invention from Korea ever. They will be remembered in every Korean textbook to the end of time. reply drcongo This is a fantastic rundown of some very confusing events, thank you. reply krisoft It is not a contradiction. One can be both.The alegation is that the person in question worked with them on the research, and they published it on arxiv without the permission of the others. Thus they can be a co-discoverer and also rogue former employee. reply jjallen Supposedly he worked there until four months ago. I am just repeating stuff I read on the Internet and I don&#x27;t know that we know all of the facts just yet FYI. reply highwaylights > that this thing needs to see the light of day so it can start to benefit humanity... by way of Back to the Future hoverboards. reply kome Young-Wan Kwon&#x27;s legacy will undoubtedly be that of the hero of LK99. There is a lingering thought that had this discovery been made in the US, it might have been hidden indefinitely by the military-industrial complex, never to see the light of day. reply ChuckMcM For those experiencing this type of \"black swan, but good\" event for the first time, it is helpful to recognize that the human tendency to believe that all future \"big events\" will be dystopian downers, is statistically unsound.For a while I&#x27;ve kept a list of the things that could be \"good\" swan events, but to be fair I didn&#x27;t have \"room temperature superconductor on that list\" :-)Other things that could happen:1) Fully decoding the cellular mechanism of cells allowing for the curing of any disease, repairing any genetic disorder.2) Commercially viable fusion energy. Will change a lot of things.3) An AI subsystem with some reasoning ability (yeah, could go either way)Etc. reply someplaceguy It would have been more convincing if you had given real past examples rather than speculative future ones :)Although I&#x27;m pretty sure there are plenty that many people can think of, so it doesn&#x27;t really detract much from your point. reply nindalf Auctions, sanitary towels, retirement, banking, disposable razor, sewing machine, canned food, interchangeable parts, antibiotics, solar cells, postage stamp, light bulb, pencil, air conditioning, insurance, dwarf wheat, spreadsheet, cold chain, double entry book-keeping, S-bend, infant formula, clocks, public key cryptography, passports, batteries, printing press, video games, GPS, contraceptive pill, shipping container, Haeber-Bosch process, concrete, iPhone.Shoutout to 50 things that made the modern economy, a great podcast&#x2F;book. reply smsm42 But other than that, what the Romans have ever done for us?! reply nindalf Apart from the aqueduct, sanitation, roads, irrigation, medicine, education, wine, public baths and public order - the Romans didn’t really do much at all. reply mnw21cam 3 And concrete. anovikov As i see it, Romans mainly gave us idea of \"rule-based society\" on which entire Western world stands. Even as Romans themselves made a joke out of it in their later history. But the idea was so transformative that even subsequent barbarian kings that ravaged Roman Empire after it&#x27;s downfall, did not seek to formally overthrow it - rather, they pretended (with varying levels of plausibility) to lawfully inherit and rule it, or parts of it. reply pyrale > As i see it, Romans mainly gave us idea of \"rule-based society\" on which entire Western world stands.Rule-based societies predate the Romans by a lot of time ; Romans weren&#x27;t even that good at it, considering how often violence was used as a political tool during the republic. reply nindalf You missed the reference about the Romans not doing much. Just pointing it out in case anyone reports the comment that says “oh shut up!”https:&#x2F;&#x2F;youtu.be&#x2F;Qc7HmhrgTuQ reply jacquesm 9 Spoilsport. totetsu Oh, shut up! reply blashyrk 44 > As i see it, Romans mainly gave us idea of \"rule-based society\"Wouldn&#x27;t the Code of Hammurabi have preceded that by quite a few centuries? reply nwiswell As I read this list, the rhythm to We Didn&#x27;t Start the Fire spontaneously started playing in my head.Sorry not sorry if I just subjected you to the same. reply mellosouls A minor observation - pretty much all of those describe a type where applicable, except for iPhone. \"Smartphone\" would have been consistent and more accurate. I don&#x27;t know if that&#x27;s a bias or proofreading issue.It&#x27;s an interesting and thought-provoking list though. reply voldacar 17 Passports were originally a temporary wartime measure. Not exactly something to celebrate reply Dylan16807 That&#x27;s just a list of good inventions.GPS, disposable razor, many of these are not impactful enough to be \"black swan but good\".And things like clocks and batteries were slowly refined over many, many years, so they don&#x27;t fit either. reply nindalf Respectfully, you don’t know what you’re talking about if you think GPS “isn’t impactful enough”.Don’t fall into the trap of reacting with “meh” to everything. Maybe you just don’t know? Maybe you don’t realise how much modern life depends on say, the Haeber-Bosch process or the shipping container? “Oh it’s just a metal box”, a person who doesn’t understand it might say. reply arketyp Is it a black swan though? I can imagine something like GPS was envisioned well before the first satellites were even launched into orbit. Note, I&#x27;m not disputing you. This got me thinking about the nature of invention and discovery. reply Rebelgecko GPS is a pretty cool case. It&#x27;s not the first navigation system out there, not even close. But the designers did something pretty forward-thinking and a bit risky: they made a big chart of all the different ways to implement GPS. A system where the ground based receivers has to talk back to the satellite. A system where every user needs their own atomic clock. A system where every user needs to communicate with a satellite. A system where every user needs to communicate with a separate ground station. Systems whose accuracy decreased at higher velocities. etc. The final solution was one that required more satellites, but allowed users to determine their own 4D position without needing any outside resources. The only downside was that it required portable atomic clocks, which didn&#x27;t exist yet.Not sure if that&#x27;s black swan territory or not, but IMO it was a great piece of forward-thinking that made GPS useful beyond just the original military applications. reply jacquesm 7 The most amazing thing to me about GPS is that it required compensation for relativistic effects to work. It is as far as I know the most direct impact relativity has on our every day life in a way that just sticking to Newton would have led to the project being abandoned or to the discovery of relativity if Einstein had not given it to us on a platter. krisoft > I can imagine something like GPS was envisioned well before the first satellites were even launched into orbit.I don’t know about that. Maybe it was. What I do know is that we have documented speculation about satelite based navigation the days right after the launch of Sputnik.American scientist figured out the orbit of Sputnik independently from the Russians by measuring the dopler shift of the radio transmission with their radios. Then knowing where their radio is located they used an iterative optimisation process to identify the orbital parameters of the satelite. Immediately there they were talking about how if the orbit of the satelite were known they could use the same process backwards to fix their location. That was 21 years before the launch of the first GPS satelite.Now, that is not exactly how GPS signals work, and with good reasons. But it is the first documented seed of the idea of satelite based navigation that I am aware of.Source: https:&#x2F;&#x2F;secwww.jhuapl.edu&#x2F;techdigest&#x2F;Content&#x2F;techdigest&#x2F;pdf&#x2F;... reply retrac No. You&#x27;re correct. GPS is the culmination of 50 years of work in radionavigation, and it wasn&#x27;t the first satellite navigation system either.As so often, the refinement of the technique makes it so widely available and effective that, without being revolutionary in principle, it becomes revolutionary in effect.Telecommunications is like that. A century ago a telex from Australia to England could make it from desk to desk in under an hour. The Internet is not revolutionary in that sense. And yet it is revolutionary anyway. reply zkr GPS was not a black swan event reply Dylan16807 > Respectfully, you don’t know what you’re talking about if you think GPS “isn’t impactful enough”.How informative of you.GPS does things better but we can do generally the same things without it.Don&#x27;t think about what would happen if we ripped out all GPS functionality overnight, think about what would happen if we had a decade to implement replacements.The loss of accuracy wouldn&#x27;t be that important.> the Haeber-Bosch procesThat one&#x27;s pretty great, it&#x27;s probably worth including.> or the shipping container? “Oh it’s just a metal box”, a person who doesn’t understand it might say.Hmm, focus on cargo ships and you can see a pretty rapid revolution, but in a wider lens maybe it was more of a broad evolution. I&#x27;m not sure.But my point was that the list was too long, not that it didn&#x27;t have any valid examples. reply ruszki 53 GPS changed my mind, how I think, and how I see the world. That’s not a small achievement. reply MrYellowP You make no sense. Observe:> And things like clocks and batteries were slowly refined over many, many years, so they don&#x27;t fit either.Everything started with a thought, or a discovery. What happens after is irrelevant. The event, that kicks off Dramatic Change(tm), is at the start.> That&#x27;s just a list of good inventions.No. It isn&#x27;t just a list of good inventions. Ignoring that it&#x27;s not all inventions, you seem to lack the understanding of the impact. For example:> AntibioticsA discovery. It literally changed how humanity moves forward. One of the whitest swan moments in human history.> public key cryptographyIt took until 1975 for someone to figure this out and it changed how we exchange information, legitimize ourselves and deal with our privacy.> contraceptive pillThe invention of the pill was an event that had massive impact on how Humanity moved forward.> printing pressThe invention of mass production of books lead to the first information explosion, dramatically changing humanity&#x27;s future.What you&#x27;re doing here is mixing your ignorance of the impactfullness of some of the things on the list, with your own personal idea of what&#x27;s \"great\", or however you want to call it.Even if I agree that not everything on that list is equally meaningfull in terms of impact, some of them are really fucking high up the ladder, just like room temperature superconductors. reply defrost Just for the record:> > public key cryptography> It took until 1975 for someone to figure this outSketched out in 1874 as a concept by Jevons, firmed up (sans implementation) in 1970, first implemented in 1973 (classified for nigh on 30 years by the UK Govt).First public example (of a different schema) was 1976.Other examples worked out in 1974, not published until 1978. etc.I have no great quibble here, 1975 is a good approximate ballpark figure but I wasn&#x27;t sure which scheme you had in mind as it&#x27;s almost the only year in the 1970s that nothing particularly significant happened in public key crypto.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Public-key_cryptography reply Dylan16807 > Everything started with a thought, or a discovery. What happens after is irrelevant. The event, that kicks off Dramatic Change(tm), is at the start.Clocks did not have an event that kicks off a dramatic change. We&#x27;ve had them for thousands of years. I don&#x27;t see how anyone could disagree with that.I could see disagreement about batteries, but even then I feel like they were quite marginal for quite a while. A slow buildup is not a \"black swan but good\". There needs to be quite a lot of suddenness to it all.And I didn&#x27;t even mention the ones in the rest of your post so I don&#x27;t want to argue those.If you talked about all those because I said \"list of good inventions\", let me clarify. It&#x27;s a list of \"good or better inventions\", mixing ones that qualify as &#x27;black swan but good\" with ones that don&#x27;t. reply huksley Also, air conditioner. It made huge difference to allow for intellectual work at the places which are otherwise too hot. reply SargeDebian It&#x27;s already in there. reply cezart This reads like a list of technologies from the game civilization :) reply nindalf I thought the same when I was listening to the podcast! Interchangeable parts especially! They’re so impactful, but they’re taken for granted outside of this podcast and Civ. reply anovikov Passports are not a good invention. They are a dystopian evil we grew to take for granted and even see as something that exists for our own benefit. Before WWI there were no passports and no need for them. Those were Good Old Days that are not coming back. It&#x27;s weird to see some people seeing some kind of benefit in them. reply throw__away7391 Travel is more free today compared to in the past, at least in for example Europe. You used to need traveling papers from your boss&#x2F;master&#x2F;lord granting you specific permission to travel, otherwise you could be arrested. People didn’t trust visitors in general outside of some specific circumstances. reply dataflow It&#x27;s not like we would have free roaming in the modern age if passports weren&#x27;t a thing. People would still face travel restrictions, they&#x27;d just be more nonstandard and unpredictable.Consider how the days before passports also lacked air travel available to the masses. Even cars has only just started to become commonplace. I don&#x27;t see how you could possibly have travel that is so cheap, quick, and accessible to such a large population without some way to control who is coming and leaving your country? Especially with how we&#x27;re quickly making different parts of the planet inhospitable, and given how rapidly populations have risen compared to a century ago. reply Cthulhu_ The passport is but one piece of the greater system that we have nowadays of international worldwide travel. I can get on a plane and travel pretty much anywhere in the world now, whereas before travel like that was reserved for explorers, missionaries or high ranking dignitaries.I don&#x27;t think the passport is an invention itself, so to speak. reply nindalf I got the list from 50 things that made the modern economy. Maybe you’d learn something by listening to the episode on passports - https:&#x2F;&#x2F;www.bbc.co.uk&#x2F;programmes&#x2F;p052spyb> Before WWI there were no passports and no need for them.This combination of ignorance and confidence isn’t a good look. reply inglor_cz \"Before WWI there were no passports and no need for them.\"Passports are much older than that, but in pre-WWI Europe, most countries didn&#x27;t require them for travel. (Russia and Turkey did.)Passports certainly do have a dystopian element to them, especially if they are demanded too frequently &#x2F; aggressively. But on their own, they aren&#x27;t particularly evil; they just identify you much like your face does. reply iraqmtpizza so how do you keep the illegals out reply pineaux The Gestapo popularized passports. Think about that for a while. reply nindalf 27 Hitler was a vegetarian. Think about that for a while. reply NegativeLatency Bicycle reply dclowd9901 I’ll add some more:Language, standards, the internet, agriculture, glass, sunscreen, resilient rice, sterilization, human flight, spontaneous development of sentient life in the universe…When you think about it all, you start to appreciate how miraculous things actually are. reply tzs Sanitation, medicine, education, wine, public order, irrigation, roads, fresh water system, and public health. reply MrYellowP Does language really count? It emerged as noises and refined over the years. It&#x27;s not something anyone invented, or even discovered. It simply came to be all by itself, until humanity reached a point where it could be formalized&#x2F;standardized (idk the proper term, I&#x27;m sure you get what I mean).Regardless ... people&#x27;s ignorance is showing. Too many never think about the fact that people just 200-100 years ago would have considered modern technology magic.Imagine showing off to one of these people:Omfg you&#x27;re speaking into a flat rectangle!Omfg it speaks back!Omfg it shows pictures!Omfg that box speaks!Omfg that box speaks and shows people!O M F G YOU GUYS FLY EVERY DAY???WHAT DO YOU MEAN, SYPHILIS ISN&#x27;T AN ISSUE ANYMORE??? AND THERE&#x27;S A PILL PREVENTING PREGNANCY ???????????It&#x27;s absolutely amazing. reply ETH_start Similar to language, money, which Nick Szabo—the person who first conceptualized a decentralized blockchain—speculates may have increased the carrying capacity of the environment ten fold and allowed humans to outcompete Neanderthals.https:&#x2F;&#x2F;www.fon.hum.uva.nl&#x2F;rob&#x2F;Courses&#x2F;InformationInSpeech&#x2F;C... reply jzymbaluk Penicillin has gotta be on that list. Just randomly happened to culture on a Petri dish left out on vacation, happened to be the worlds first antibiotic reply p-e-w I can&#x27;t imagine what it must have been like for people to hear about yet another \"miracle drug\" that cures most diseases – and then gradually realize that this one actually works. reply darkwater There is \"antibiotics\" already reply MrYellowP It wasn&#x27;t. \"Stuff that kills bacteria\" has been known for a long time, including times when nobody knew what bacteria were. Not every dirty wound was fatal, there&#x27;s mixes of plants, applied to wounds, that do a good job.Penicillin was the first highly effective AND mass producible antibiotic, though. reply Cthulhu_ While true, actually applying it in practice took a long time. Imagine the shock and horror when male doctors were told by midwives that washing hands and keeping things clean reduced infant mortality. reply jliptzin Antibiotics Electricity Internal combustion engine Flight Li-Ion batteries Radio communication reply q7xvh97o2pDhNrh And punctuation, too. reply jfoutz Printing press. broad access to clean water. transistor. reply XorNot Indoor plumbing in general - municipal sewer systems were a huge change (though not really new technology). reply King-Aaron I&#x27;ll grant you the aqueduct and the sanitation are two things that the Romans have done. reply avereveard Yes but apart from that what have capitalists ever done for us reply pineaux Capitalists dont make anything apart from making collectively owned goods and services privately owned.That is the whole game. reply avereveard they make available the capital for innovation, their investment in the most lucrative markets is propelling research to heights that state planned investment can only envy from the sidelines, and the availability of concentrated capital allows for production methods that are unavailable to distributed means of produciton, so much that the production output for bleeding edge technology is absolutely overwhelming even when distributed or stated owner proprietorship had a head start in research, see for example radar \"stealth\" technology originating in russia in the 60s. reply XorNot Well I&#x27;ve got bad news if you think capitalism built the sewer system... reply avereveard But you led with indoor plumbing. That is something that really only took of with an industrial base to produce the plumbing. reply XorNot Capitalism also didn&#x27;t build indoor plumbing though.Or let me put it a different way: do you think the USSR did not have an industrial base?And who do you think paid for the construction of the municipal sewer systems in American cities? Like in Chicago where the whole city was raised 4 ft to accomplish it[1].[1] https:&#x2F;&#x2F;gizmodo.com&#x2F;chicago-was-raised-more-than-4-feet-in-t... reply avereveard I can throw a dart on an italian map and the nearby houses will have indoor plumbing if there&#x27;s some resident. can you do the same in russia today?> And who do you think paidstate resources are always a fraction of the gdp trough whatever form of taxation. larger industrial base means proportional less burden on the society. that is why for example urss imploded, taxation was too high and spent too wastefully on military budget to be sustainable long term, while usa could spend that money on the defense budget, infrastructure, et etc, while still being sutainable from the economy, because the industrial base was so much larger. replybalaji1 insane agricultural productivity. storage and transportation of food. reply ncruces Haber–Bosch is already in there, and is a great part of it. reply actionfromafar That’s all oil. reply julianeon A good one would be \"productive AI.\" People forget, but a short while ago, AI was treated as something where being actually useful was perpetually 20 years away, and the real-world status of it was exemplified by a chatbot like Eliza. reply ben0x539 When AI was 20 years away, people seemed more optimistic about it than now when its inevitable transformative societal impact is seemingly right around the corner, are you sure this is the kind of example they were going for? reply bhaak This is mostly due to \"they&#x27;re taking our jobs!\".Which actually highlights a problem in our society that we have to work to be able to afford living instead of living to be able to work on something more meaningful than earning money. reply someplaceguy I think your point only demonstrates that useful AI was not something we could arrive at quickly like we thought we could, but rather over decades in a much more gradual process which slowly got people accustomed to its capabilities.Even then, when ChatGPT came out it was a pretty big deal, due to the surprisingly sudden jump in capabilities, at least from the point of view of someone who didn&#x27;t work in AI and didn&#x27;t closely watch its progress.According to Wikipedia, it was \"the fastest-growing consumer software application in history, gaining over 100 million users\" (in ~2 months). reply glompers Larry Page and Sergey Brin will be so upset when AIs unionize... reply Retric Yea, Eliza is a far worse chat bot than ChatGPT…More seriously AI has made lots of things better, it’s really the hype cycle that’s disappointing. More FPS in games just isn’t as exciting as self driving cars. But by the time you can buy a level 5 self driving car the technology will be pedestrian. reply lfnoise When COVID hit, my American Airlines flight got canceled and when I went online to ask about getting credit, I got connected to a bot. When I asked to be connected to a real person instead of a bot, the person came online and said: \"My name is Eliza. How can I help you today?\" At this point, I was very skeptical, but she was indeed a person. reply pjerem \"Sorry Eliza, can I speak to your manager ?\" \"Sure\" \"Oh, hello, I&#x27;m Hal. Eliza told me you want to get credit ? ! I&#x27;m afraid I can&#x27;t do that.\" reply sparrowInHand Open the purse, HAL reply chx An L5 self driving car is decades away. The needle hasn&#x27;t moved on that one.Nothing we have currently moves closer to that. Just doing more of the same of the current models will not get you there. reply xyproto If a city banned all manually driven cars and allowed only self driving cars, the number of car-related deaths would drop to almost nothing. Goods could also be transported more efficiently. The technology to achive this exists right now, L5 or not. The only thing stopping citites from doing this is the cost that inhabitants will have in connection with selling or switching our their car. And all the complaining. But lives would be saved, and the city would be safer and more efficient. reply pjerem Cities will not need to do that. In Europe they are gradually banning cars as a whole from city centers an you are right, it saves lives. And it also makes those cities more livable.When I say gradually, it&#x27;s an euphemism, it&#x27;s an _extremely_ slow process, but it&#x27;s the global tendency here. reply choeger They aren&#x27;t banning cars. They&#x27;re requiring special permits. That&#x27;s a difference. In effect, they&#x27;re banning cars for the masses and keep them for a small group (the wealthy, all sorts of delivery drivers, officials). reply ArnoVW 55 you&#x27;re both right.generally what&#x27;s happening is a combination of: * making pedestrian zones (i.e. banning) * deny access to certain types &#x2F; times (no vans, no old cars, etc.. i.e. also banning) * reducing roads (i.e. 2 > 1 lane, thus reducing attractivity) * raising driving prices (the congestion &#x2F; air quality certificates you mention) * reducing access to parking (remove places, make them more expensive, etc) .. all the while increasing alternatives (i.e. use those reduced lanes for bikes) reply Dylan16807 I&#x27;m not sure how relevant that argument is.You could have said the same thing 40 years ago. reply p1esk Don&#x27;t we have self-driving cars operating as taxicabs today in SF? reply fragmede Cruise is currently operating self-driving \"taxi\" service between the hours of 9pm and 5:30 am throughout the city to members of the general public who&#x27;ve waited on the wait-list. Waymo is too, in Phoenix, and supposedly SF too, but I don&#x27;t know anybody personally of the general public in SF that has ridden one. reply kortilla So yes, we have L5 driving. The cars don’t have drivers, regardless of some time restrictions. reply Dylan16807 Level 5 means it can do anything a human can.They&#x27;re level 4 with very severe location and weather limits. replyrockemsockem Rockets landing themselves back on Earth was looked at as really weird for quite a while. reply rvnx ? was just a design choice as it&#x27;s easier reply Cthulhu_ It wasn&#x27;t easy (else it would&#x27;ve been done earlier), but it was cheaper. reply rvnx I agree, you are right. We can find a compromise: an easy choice to make :) reply kzrdude Fall of the Berlin Wall should probably be on a list of black swan but good events. reply ant6n 40 That’s my first thought as well. reply shostack Watch the Connections series. reply riffraff For those who have not seen it: it&#x27;s old but it&#x27;s one of the best productions on the Evolution of science and technology ever made. reply abtinf Thousands of breakthroughs had to happen for you to be able to post your comment. reply ChuckMcM Fair point, I felt most people would have their own list. Powered flight, semiconductors, commercially competitive solar cells, antibiotics, sterile procedure. Etc. reply xorbax Democratization of the free internet, a more informed populace through free education, a generation of coders and computer adepts, robust journalism and investigation, a space that incentivizes knowledge rather than capital or status, society about the exchange of important ideas rather than flippant goods, ad infinitum reply havnagiggle Efficiency of food production reply RF_Savage Haber Process for manufacturing fertilizers. reply TheSpiceIsLife Nuclear weapons.There hasn’t been a full scale war between major powers since. reply rvnx 350K+ reported casualties just in a year sounds already muchhttps:&#x2F;&#x2F;www.reuters.com&#x2F;world&#x2F;europe&#x2F;ukraine-war-already-wit... reply ben_w Ukraine isn&#x27;t a major power, and the fact that they&#x27;ve been able to hold back Russia so effectively, with so few resources, is mainly an indicator of how weak Russia is these days. reply ayende To give some context, Battle of the Somme, lasted 4 months, total casualties: 1m+. reply rvnx This was before invention of Twitter, now with so many conflicts in the air, I&#x27;m sure we can beat that figure. reply Sugimot0 There&#x27;s been plenty of war, and it could well be the first step on a path to the end of life on earth. I imagine this belief stems from all the \"Hiroshima and Nagasaki were necessary&#x2F;good\" propaganda. reply blitzar > There hasn’t been a full scale war between major powers since.Yet all the major powers have launched multiple, lengthy full scale wars since. reply jchanimal As long as the people with the weapons act rationally. Which might be an anomaly. reply rurban The problem with game theory is that the actors do act rationally, and the most rational scenario is still the doomsday genocide: first strike, with a submarine counterstrike. reply Ekaros Entirely ruined by the reality that those having them are not bombed to ground by conventional weapons when they attack somewhere.So I would argue they are either neutral or massive negative. reply justin66 It&#x27;s all fun and games until someone loses an eye. reply urinotherapist Full scale war between Russia and Ukraine (with help of NATO) progressing right now with constant threats to use nuclear weapons or blow up a nuclear power station. reply konschubert Penicillin. Vaccines. reply paulddraper COVID 19 vaccine, plus better-than-feared virulence.Electric cars mainstream reply jaidhyani Smallpox eradication reply fhars That was not a black swan event, that was a concerted effort over two centuries. reply leoh The discovery of the vaccine itself reply bretpiatt 1) Subset breakthrough here potentially related to cancer, we&#x27;ll see how the peer review and evolution to becoming an available standard of care goes.City of Hope scientists develop targeted chemotherapy able to kill all solid tumors in preclinical researchhttps:&#x2F;&#x2F;www.eurekalert.org&#x2F;news-releases&#x2F;997141 reply isaacfung A few weeks ago, there was news that some Harvard MIT researchers had discovered a chemical cocktail that can reverse aging. https:&#x2F;&#x2F;news.yahoo.com&#x2F;harvard-mit-scientists-claim-chemical... reply iraqmtpizza is heart damage considered aging? asking for the 1 in 35. reply MostlyStable I&#x27;ve heard elsewhere that \"all solid tumors\" should really more accurately be conveyed as \"all solid tumors with a very specific mutation\". It is, apparently, a very common mutation, but also not universal, even among solid tumors.Apparently. I&#x27;m not an expect, but it&#x27;s what I have encountered elsewhere.Still great news! But not quite as revolutionary as the headline implies. reply JieJie I was interested in learning more, based on your comment. Here&#x27;s what I found out.City of Hope thinks they&#x27;ve found a chemotherapy that&#x27;s \"able to kill all solid tumors\",\"in more than 70 cancer cell lines\".[0]According to the National Cancer Institute[1], there are \"more than 100 kinds of cancer\". They&#x27;re listed here: [2] Some of those cancers are soft tissue, so they aren&#x27;t affected by this treatment.I didn&#x27;t know what a cancer \"line\" was, so I looked it up. \"Cancer cell lines are valuable in vitro model systems that are widely used in cancer research and drug discovery.\"[3] So, they&#x27;re not cancers in people, but cell cultures they can test drugs on.This probably doesn&#x27;t give you much more information than you already have, based on what you heard elsewhere, but I learned enough to figure maybe it would help someone else, too.Whether this&#x27;ll work in people, I guess we&#x27;ll find out when they start the Phase 1 clinical trial. If you, or someone you know think you might benefit from this, there is a link to sign up for Phase 1 trials.[0]It appears to have worked in pre-clinical trials, so they have tested this to make sure it doesn&#x27;t kill people outright, the same way it does cancer cells.[4][0]https:&#x2F;&#x2F;www.cityofhope.org&#x2F;city-hope-scientists-develop-targ...[1]https:&#x2F;&#x2F;www.cancer.gov&#x2F;about-cancer&#x2F;understanding&#x2F;what-is-ca...[2]https:&#x2F;&#x2F;www.cancer.gov&#x2F;types[3]https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC6721418&#x2F;[4]https:&#x2F;&#x2F;xkcd.com&#x2F;1217&#x2F; reply holtkam2 1. Cure for aging 2. AGI exists and ends up being somehow, unexpectedly easy to control 3. Russia &#x2F; China &#x2F; North Korea eventually become democraticSome of the “good” black swans at the top of my mind… reply Smoosh I&#x27;m unsure if we want people living forever. While disease, illness, and senility are terrible things, as soon as people can live forever we will have eternal dictatorships (or people trying for it) as well as other questions of perpetual inequality. \"Death renders all equal\". reply kaba0 12 Also, people’s mind simply worsen as they age, and I don’t mean senility only. We are not made for living too long, and the elderly are already the most commonly targeted group for populist propaganda by political parties. Reflexes worsen, the past will become rose-tinted, etc. reply ben_w Eternal youth != immortality; given accidental and deliberate injuries and deaths, the \"half life\" (feels wrong in this context) is about 1000 years.As for dictators: it&#x27;s not like guillotines stop working.What will keep dictators (if eternally young, or their offspring if not) in power forever is competent and obedient AI manning the police and army. reply gorbachev 54 The people going after \"eternal\" life right now are people with access to practically unlimited funding.They are immune to guillotines operated by peasants.The only thing they don&#x27;t have protection against is Government forces. With their armies of lobbyists, and other bought influence they have, they are also, largely, protected against those as well. reply shrx Source on the half life number? reply sethammons Similar, I recall hearing 2k years on some program. No source. The idea was that accidental deaths will happen. On mobile, but you could look up accidental death records to get the rate and then project out average lifespan.Still, that is averages. A cruel despot may never leave their palace fearing death and will always have security. They will have less opportunities for accidents. reply deely3 > we will have eternal dictatorshipsI can&#x27;t agree. We can have eternal dictatorship now. Nothing prevents it except other people, therefore people will prevent eternal dictatorship just as now (with various results).Anyway, Im ready to accept this risk. reply SanderNL We cannot have them though? The leaders die and the resulting fights over succession is what keeps us out of eternal territory.These maniacs didn’t have enough time to accrue enough mass to become power black holes, but give them a century or two to work with.. reply coderenegade Nah, the fact that even emperors die is a good thing. No dynasty lasts forever, because after the first few generations, assets get diluted, someone spends the money, descendants fight, etc. An aristocracy that lives forever would be very hard to remove because those factors would be greatly mitigated. reply bratbag Not just dictatorships.We already see the advantage age provides when building influence for US politics. reply highwaylights Also there’s a massive philosophical quandary in there too.If people could live for much longer then they’re likely disincentivised to procreate due to worries of overpopulation and then, in one way of thinking, you’re hypothetically depriving a line of offspring of lifetimes they’d otherwise have if you’d had what we consider a normal lifespan now.Yes I realise there are probably an infinite number of takes on this, I’m just pointing out one possible way of looking at it for the sake of saying not all technological advances have universally positive outcomes. reply gorbachev 52 I think a majority of the people who want to live \"forever\" are the types of megalomaniacs who want to populate the earth with their own kind of uber mench, and will actually have more children than an average person. reply raducu > you’re hypothetically depriving a line of offspring of lifetimes they’d otherwise have.I don&#x27;t want to open a can of worms, but... about 40 milion people are aborted each year... reply ajmurmann \"Science progresses one funeral at a time\" comes to mind as well. reply asadm Democracy is a diversion technique honestly. “Rulers” are always a few people&#x2F;corps and the fate of the people depends on them. reply borissk Honestly there&#x27;s a big difference in the way people live in North Korea and Switzerland. reply Cookingboy 24 I mean there is also a big difference in the way people live in India and Switzerland, and both are democratic countries. Your examples are the result of economic disparity, not political systems.But if you compare India to China, one democratic and one not, suddenly it&#x27;s not super clear which countries&#x27; citizens have \"better\" lives. reply kaba0 7 There are eons of differences between different democracies. Russia is also a democracy on paper, yet it is absolutely unfathomable for someone to “shot themselves in the back of the head and jump out the window” in, say, Switzerland, while many political opponents, journalists “committed suicide” that way in Russia. reply borkt One provides service to the outside world broadly in trade to fulfill its needs, the other provides limited service to the outside world and trades with a highly limited subset of the world to fulfill its needs reply chottocharaii Oh you. You nailed it. That&#x27;s the core difference. &#x2F;s reply suzzer99 The key is being able to throw the bums out every 4-8 years. This gives Democracy a self-correcting feature that doesn&#x27;t work with lifetime rulers. reply j16sdiz In most countries, that would be rotating between two or three leaders.Somewhat better than a lifetime ruler, but this is far from what Democracy are on the textbook. reply suzzer99 It&#x27;s still very very different than what&#x27;s happening in say Nicaragua right now, where the will of the majority of the people has no bearing. reply mnky9800n It also doesn&#x27;t work with corporate sponsorship of the elected. reply mgiampapa Interesting how the trajectory of the USA has changed since Citizen&#x27;s United was decided. When and how are we going to fix the rationalization that immortal and unaccountable entities aren&#x27;t people. AI legislation? I can dream of electric sheep. reply gorbachev 50 AI is controlled by the richest corporations.How do you think AI would legislate, if AI legislation would become reality? reply rnk I don&#x27;t think other democracies have allowed travesties like rich people funding elections (aka Citizen&#x27;s United). It&#x27;s possible the US will be able to stop it, but the insidious impact of that wealth feels like it is unending. reply suzzer99 But at some point the people get fed up with the same corporate message and do something crazy like elect Trump.I feel like there&#x27;s a limit to how much corporations can influence voters, the same way there&#x27;s a limit to how much moviegoers will keep paying to see the same corporate movie over and over. replyvincnetas i prefere rulers that care about general wellbeing of theyr populations. i know i might sound like a cattle or a sheep, but i prefere beying sheep that is treated well. this is provided that we really dont have a choice or say in things that happening around us. but this still needs to be shown. so far i feel like j can influence the path of my life quite a lot. reply jacquesm 10 I think every technology is double edged, from the humble hammer all the way to atomic energy, you can always apply tools for good and for bad. reply krisoft > Fully decoding the cellular mechanism of cells allowing for the curing of any disease, repairing any genetic disorder.Honestly that doesn’t seem likely to be a black swan event. Not because it is never going to happen, more because it won’t be an event but a slow progression.It is more likely that as we understand more and more we will be able to cure more and more. It is not like there is some silver bullet piece of research where sudenly we have “fully decoded the celular mechanism”. Plus even if we somehow suddenly and all at once atained all that knowledge (perhaps a flying saucer takes pitty on us and beams down a whole library documenting our cells) it would take a long time while we turn that knowledge into helpfull interventions. And even that progress would be multiple generations long.It is how becoming a black-belt martial artist is not an “event”. You don’t go from zero to that in one night. It is more of a progression where every day you are about as proficient as you were the previous one, but maybe a tiny bit better. Just applied on a whole species level. reply mrtksn > Commercially viable fusion energy. Will change a lot of thingsConsidering that we already have a fusion reactor in the skies, I think that the room temp room pressure superconductor is the next best thing. Fusion is good but at this stage, the natural one will just do. Think global network of solar cells interconnected with LK-99. reply ant6n 35 Yeah. Perhaps add in some cheap battery technology to the mix of solar power and superconductor, and energy production could become co2 neutral.The creation of a global electricity network perhaps also has some effect on global cooperation.Now we just need reduce the use of fossil fuels (cars, aviation, heating, industry). reply KRAKRISMOTT Not quite related to 2) but if the superconductors research pans out, portable high field desktop sized MRIs would be in the bag. Current portable MRIs are all low field (and to a certain extent, somewhat useless). reply jojobas So far this material (and pretty much all liquid nitrogen ones) can&#x27;t be used to create MRI sort of fields. There&#x27;s a reason they all stick with liquid helium. reply ralfd Why can’t liquid nitrogen SC used for creating MRI? reply cthalupa Superconductors also have points where they stop superconducting because of the strength of the magnetic field or amount of current. YBCO and similar have these points below the useful level for MRIs.There&#x27;s research around finding ways to use them but nothing that is currently viable. reply maccam94 Wait, Commonwealth Fusion Systems is already building 20T REBCO magnets, can&#x27;t those meet the requirements for MRIs? reply cthalupa You&#x27;re right - for whatever reason I had convinced myself YBCO had issues with both high current and high field. It&#x27;s just high current - anything outside of a single grain has low current density.Doing some more research to help make up for my spreading of incorrect info, I did stumble across this - https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC5472374&#x2F; - it seems like it&#x27;s a variety of factors that make most HST not really commercially viable for MRI machines at current.Mitsubishi has even made a small scale MRI machine with HTS - https:&#x2F;&#x2F;www.medicaldesignandoutsourcing.com&#x2F;worlds-first-3-t... - though I can&#x27;t find any newer details around it, despite the timeline provided in the article. replysparrowInHand 43 4) Mining of a complete mental model of the human mind from collected data. Allows for hacking and social engineering as never seen before. reply urinotherapist Commercially viable fusion can be achieved with commercially viable source of muons:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Muon-catalyzed_fusionhttps:&#x2F;&#x2F;link.springer.com&#x2F;article&#x2F;10.1007&#x2F;s00016-009-0006-9https:&#x2F;&#x2F;www.annualreviews.org&#x2F;doi&#x2F;pdf&#x2F;10.1146&#x2F;annurev.ns.39....http:&#x2F;&#x2F;large.stanford.edu&#x2F;courses&#x2F;2016&#x2F;ph241&#x2F;yoon1&#x2F;https:&#x2F;&#x2F;www.chemeurope.com&#x2F;en&#x2F;encyclopedia&#x2F;Muon-catalyzed_fu... reply ben_w Slightly harder than I remembered:> Even if muons were absolutely stable, each muon could catalyze, on average, only about 100 d-t fusions before sticking to an alpha particle, which is only about one-fifth the number of muon catalyzed d–t fusions needed for break-even, where as much thermal energy is generated as electrical energy is consumed to produce the muons in the first place, according to Jackson&#x27;s rough estimate reply urinotherapist > More recent measurements seem to point to more encouraging values for the α-sticking probability, finding the α-sticking probability to be about 0.5% (or perhaps even about 0.4% or 0.3%), which could mean as many as about 200 (or perhaps even about 250 or about 333) muon-catalyzed d-t fusions per muon.[29][30] Indeed, the team led by Steven E. Jones achieved 150 d-t fusions per muon (average) at the Los Alamos Meson Physics Facility.[31] Unfortunately, 200 (or 250 or even 333) muon-catalyzed d-t fusions per muon are still not quite enough even to reach \"break-even,\" where as much thermal energy is generated (or output) as the electrical energy that was used up (or input) to make the muon in the first place. This means, of course, that not nearly enough thermal energy is generated thereby to be able to convert the thermal energy released into more useful electrical energy, and to have any electrical energy left over to sell to the commercial electrical power \"grid.\" The conversion efficiency from thermal energy to electrical energy is only about 40% or so. Also, some not inconsiderable fraction of that electrical energy (hopefully not all of it) would have to be \"recycled\" (used up in deuteron particle accelerators, for example) to make more muons to keep the muon-catalyzed d-t nuclear fusion fires burning night and day.[32] The best recent estimated guess of the electrical \"energy cost\" per muon is about 6 GeV (billion electron Volts), using deuterons that are accelerated to have kinetic energies of about 800 MeV per nucleon, with accelerators that are (coincidentally) about 40% efficient at taking electrical energy from the Alternating Current (AC) mains (the plugs in the wall) and accelerating the deuterons using this electrical energy.Yep, it&#x27;s challenging. Maybe this rate can be improved by applying alternating voltage to reactor. Muons are charged particles, so they can be accelerated further. (Just idea) reply musebox35 It seems to me that technological developments and empirical scientific breakthroughs come in cycles, technology making it cheaper to experiment, science reducing cost of new technical developments. I would be happy to hear about pointers to any source discussing such a tech&#x2F;science cycle.I feel our generation (I am in my mid-forties) lived through enormous technological advancements but not as many scientific breakthroughs as the previous generation. So maybe it is not surprising that we are suddenly more likely to have breakthroughs in basic science.I hope there is a phase transition to science mode now, so we that have a chance to solve the hard pressing issues. reply sparrowInHand If you experience dystopian events, you cease to be, preventing information pass on. All instincts and warning signals, by there very nature are accurate, until they can not be any more.How do you build a warning system for a unsurvivable event, with not wittnesses? Eternal unease and anxiety, regardless of reality. reply hbogert If you have a list of potential black swans, they&#x27;re not black swans. reply icapybara 1) doesn&#x27;t make a whole lot of sense. A perfect understanding of something doesn&#x27;t mean you can fix anything wrong with it.3) has already happened. The AI chat bots aren&#x27;t very smart, but they&#x27;re clearly capable of some degree of basic reasoning. reply a_bonobo There&#x27;s a wonderful paper on 1) from a few years ago:https:&#x2F;&#x2F;journals.plos.org&#x2F;ploscompbiol&#x2F;article?id=10.1371&#x2F;jo...>Could a Neuroscientist Understand a Microprocessor?>We show that the [neuroscience experimental] approaches reveal interesting structure in the data but do not meaningfully describe the hierarchy of information processing in the microprocessor. This suggests current analytic approaches in neuroscience may fall short of producing meaningful understanding of neural systems, regardless of the amount of data. reply 0cf8612b2e1e Nothing in biology is as regular and systematic as a microprocessor. Scientists study biology using round-about approaches because there is nothing else available. reply zargon This fact only makes the problem even worse. reply bschne Which was inspired by this, \"Could a Biologist Fix a Radio?\"https:&#x2F;&#x2F;www.cell.com&#x2F;cancer-cell&#x2F;pdf&#x2F;S1535-6108(02)00133-2.p... reply mxkopy This is a silly argument. It presupposes that meaningful knowledge about neurons is structured similarly to knowledge about microprocessors, which does not have to be the case since neurons aren’t structured like microprocessors. reply irrational I interpret 3 as the chat bot requires no prompt from a human. Imagine the chat bot wakes you up in the middle of the night saying, \"Hey, sorry to disturb you, but I was thinking... wouldn&#x27;t eliminating all humans help to reverse the climate crisis more quickly? Just a thought.\" That is what I think of as number 3 (not actually wanting to kill off humans, but it is thinking on its own, without any prompts and then choosing to share what it has been thinking about with a human). reply LASR Don’t we already have this? If you prompt GPT to “care” about a human and then keep sending it observations, it does a pretty good job. reply irrational But there is still an initial prompt. I think number 3 is all about no initial prompt. The AI reaches out, not because it has been programmed or prompted to do so, but because it wants to do so. reply ChuckMcM The \"event\" I was trying to describe in #1 is that DNA and cellular mechanics are decoded to the point where one could do these things (repair, customization, Etc). I was not trying to specify all of the threshold requirements for reaching that point. Hopefully describing it that way makes more sense? reply xvector I&#x27;d go as to far as saying GPT-4 is capable of fairly complex reasoning, at least in my experience tossing complicated questions and situations at ChatGPT Plus. reply CSMastermind When I was tutoring people in college for their computer science classes I was struck with how some people could do reasonably well on programming assignments and then when presented with anything even slightly novel would be completely unable to reason their way to a solution.A classic tell of this is people handling out of bounds errors in loops by trying to randomly add or subtract 1 from their for-loop parameters.I realized that they didn&#x27;t have a mental model for what a loop did, they had simply memorized the syntax for a loop and were doing advanced pattern matching. Code repeats = write the for-loop syntax I&#x27;ve memorized. And then after seeing that fail with out of bounds exceptions, they learned a new rule: modify the loop parameters and see if that fixes the problem.When I think about how I write code, or I compare their approach to the other cohort of students I saw, it&#x27;s a different process. I see in my mind&#x27;s eye a type of &#x27;machine&#x27; that performs the actions that I want to take place. I simulate running that machine in my mind and tweak its design until it works the way I want it to. Only then do I think about syntax and try to translate what&#x27;s already happening in my mind into source code.I&#x27;ve seen people get shockingly far into software engineering careers using the pattern matching &#x2F; guess and check approach. I&#x27;ve wondered if a lot of the handwringing you see on programming forums about the &#x27;leetcode grind&#x27; is coming from people who do this pattern matching approach. To them it must seems like the only way to solve these problems is to simply train their internal pattern matching neural networks on huge amounts of examples.The code that I see GPT generate looks eerily similar to what I saw from those programmers. And that makes sense because I think that functionally they&#x27;re doing the same thing. Only GPT does it at a superhuman level.That seems to me to indicate that there&#x27;s something that at least some humans do with a mental model that our current LLMs lack. If someone figures out how to simulate those mental processes in a computer program I think we&#x27;ll see a huge inflection point and that&#x27;s what the original comment (as I read it) is referring to. reply q7xvh97o2pDhNrh > the handwringing you see on programming forums about the &#x27;leetcode grind&#x27;In fairness and compassion to that crowd, a lot of it comes from the fact that a modern interview for a coveted FAANG job often requires 1-2 LC Medium (or Hard) problems cranked out in 45-60 minutes. Depending on the company and the org, the overall interview loop may well be multiple such one-hour sprints.It&#x27;s quite a pressure-cooker of an interview setting. Given that, it&#x27;s understandable why many people converge on memorizing and brute-force pattern-matching as their interview strategy — if they can just memorize enough, the odds are actually pretty decent. (And the payoff is not bad, either.) reply ikt that&#x27;s me! i call myself a fake network engineer because there is simply too much info to retain, my brain just won&#x27;t retain things i&#x27;m not constantly doing, so i have a complete understanding of maybe 20% of things but outside of that comparing to other configs and pattern matching are my main ways of solving problems and to be fair for my job (fixing network faults) like 90% of faults i&#x27;ve seen before and can fix, for 10% i can&#x27;t i&#x27;m lucky that i have escalation pointsat the same time i do feel like pattern matching limits my growth, if i had a complete understanding of a majority of networking principals id be much higher up in my career reply bdsa If you compare yourself to colleagues at your level, particularly how _they_ would describe themselves, do you think they would be as self-aware?As long as it isn&#x27;t making you feel like a complete fraud, this level of introspection is a good thing imo.\"I know that I know nothing\" reply iraqmtpizza subtracting 1 from your loop variable and running again is common sense and the quickest way to narrow the problem. also, some people can still think while typing, still think while compiling and running.this is all assuming that someone is trying to be productive rather than stop and ponder the abstraction that is a loop and divine its nature in a rigorous wayif the students are having problems with loops, that&#x27;s not surprising considering that computer science doesn&#x27;t teach software development skills. like... at all. reply Vecr You mean that&#x27;s now how everyone else programs? Obviously you do fuzz testing and static analysis and possibly some sort of theorem prover verification so you don&#x27;t get too embarrassed. reply weard_beard I predict it’s a visual&#x2F;spatial form of what it already does with language. It won’t do it until it can see.There’s all kinds of other things it won’t do until it hears. And touches. Smell and taste might help too I guess!?As a byproduct it can also be taught truth is what it can verify with sensors. reply andrewmutz GPT4 is simultaneously smarter than and stupider than anyone you&#x27;ve ever met. reply someplaceguy I think that&#x27;s a hilarious and accurate way of describing it :-) reply leptons Not sure that AI chat bots are actually reasoning in any basic way, so much as they are filtering out noise and presenting an output that might satisfy the input, but it&#x27;s often quite wrong. It&#x27;s still more of a parlor trick than it is intelligence or reason. reply icapybara > Not sure that AI chat bots are actually reasoning in any basic way, so much as they are filtering out noise and presenting an output that might satisfy the inputNot sure if there is a difference, for sufficiently abstract interpretations of “satisfy the input” reply LASR There is no difference between simulated reasoning and reasoning. reply leptons Definition of Reasoning: \"the action of thinking about something in a logical, sensible way.\"LLMs don&#x27;t think, they extrapolate. They are a filter, not capable of thought or reason. You can&#x27;t reason with an LLM but plenty of people have tried and it fooled them well enough. reply p-e-w What you&#x27;re missing is the fact that in today&#x27;s world, where almost every aspect of life is subject to top-down control, any \"enabling\" technology above all else enables oppressors to oppress more effectively.If free-form gene editing were developed today, you would see the elites using it to make themselves immortal, while denying the same to everyone else. If fusion power suddenly became viable, you would see the richest people using it to make themselves even richer, while cementing their stranglehold on vital infrastructure. And it should be obvious to anyone who has been paying attention during the past 3 years that artificial intelligence is above all else an instrument of control, and even in its infancy, access to it is unevenly distributed along the same strata of power that already existed before.At this point, the only \"black swan, but good\" event that could happen is a cataclysmic reset of civilization that might somehow see a better phoenix rise from the ashes. Barring that, we&#x27;re full steam ahead to a techno-totalitarian nightmare future. reply SanderNL > in today&#x27;s world, where almost every aspect of life is subject to top-down controlA bit of history would do you wonders. Top-down control was the norm*. If it has changed, it’s less now.* For 95% of the peasant&#x2F;slave population reply p-e-w Top-down control was not the norm in the past. In fact, top-down control in the modern sense used to be impossible.Sure, there were lords who claimed large parts of the population as their property. But they often didn&#x27;t even have a complete list of the people they supposedly \"controlled\", nor did they have any insight or actual control over their private lives in the sense that modern nation-states do. Legal codes used to contain a few dozen criminal offenses in total – today, there are tens of thousands.Invasive, pervasive, centralized, highly organized, and sophisticated top-down control of individuals is an entirely new phenomenon that is only made possible by cutting-edge technology in the first place. If you imagine past societies as forerunners to modern police states, you have a very distorted picture of history. Many of them did not even have anything like police to begin with. reply SanderNL 19 I think that vastly underestimates the complete and total mental, religious and cultural control wielded by elites of the past and overestimates the impact and importance of superficial bureaucratic oversight indeed made possible by today&#x27;s technology.Whether we can build a large shed in our gardens is managed through a vast and intricate bureaucracy. A ridiculously precise and unwieldy apparatus is indeed watching our every move. I completely agree that is a new phenomenom, made possible by technology. I cannot just take down a tree without permission, even in my own yard. How weird is that. Yet does it matter?Do you have to work the fields just because your family failed to produce a consul in the past century or two? Are you destined for a life of abject slavery because you disagreed with the regional governor about some administrative issue? Peoples of the past may have lacked technology, but that doesn&#x27;t result in freedom. You don&#x27;t need penal codes if your every move is watched and judged by your peers. Each of them happy to turn you in for a small fee.More importantly, legal codes aren&#x27;t necessary if you drop the pretence and just wield power however you want, whenever you want. You don&#x27;t need detailed control of peasants&#x27; private hobbies if you got overpowering total dominion over the fate of an entire continent.I&#x27;m just saying that oppression is nothing new and I actually think we are at an all-time low in actual, life-dominating oppressive powers. In some cases I can make the case that&#x27;s actually not so great, because these days I&#x27;m increasingly more afraid of my fellow men than any \"government\" - which in my country is barely hanging on and always behind, but I don&#x27;t know about the US. reply Gooblebrai Would you mind sharing that list?Also, pedantic point, you keep referring to good and bad black swan events. I thought the definition of black swan didn&#x27;t make any assumption about whether the impact is positive or negative? Only that has a huge impact (I haven&#x27;t read Taleb&#x27;s book yet, correct me if I&#x27;m wrong) reply nosefurhairdo Green Revolution; most people have never heard of Norman Borlaug, despite being responsible for saving hundreds of millions of lives. reply ajmurmann The cool thing is that getting high-temp superconductors makes all the things you list more likely to happen. reply rvcdbn There is an anthropic line of reasoning over Everettian branch universes where you can actually expect these types of highly unlikely events to happen more often than chance alone would predict if they promote futures with more Born-rule weighted observer-moments. reply fouronnes3 What on earth does this mean? reply rvcdbn Please don&#x27;t take this as dismissive, but I really think ChatGPT does a better job at explaining this than I can do. Here&#x27;s what I got:https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;c1c779c7-3b5f-4ea7-a864-38561d...The response you posted seems to be referring to various concepts from theoretical physics and philosophy, specifically the ideas of the Everettian interpretation of quantum mechanics, anthropic reasoning, and the Born rule. Let&#x27;s break these down:Everettian interpretation of quantum mechanics: Also known as the Many-Worlds interpretation, it suggests that all possible alternate histories and futures are real, each representing an actual \"world\" or \"universe\". In layman&#x27;s terms, it&#x27;s the idea that there could be countless parallel universes where every possible outcome of an event happens.Anthropic reasoning: This is a philosophical consideration that observations of the universe must be compatible with the conscious and sapient life that observes it. In other words, our ability to exist and observe influences how we should interpret the universe.Born rule: In quantum mechanics, the Born rule is a statistical law that connects the mathematical formalism of quantum theory to experimental observations. It provides the probability that a measurement on a quantum system will yield a given result.The responder seems to suggest that in a universe with many possible futures (as the Everettian interpretation would suggest), we are more likely to observe \"black swan\" events that lead to more possible futures.The idea here is that if an event significantly increases the number of possible futures (like a breakthrough that extends human lifespan), then it effectively increases the number of \"observer-moments\". In other words, more possibilities for observers to exist and make observations. According to anthropic reasoning, this could make these events more likely to occur than pure chance would predict, because we&#x27;re only able to observe futures in which we exist.This line of reasoning is highly speculative and philosophical in nature, touching on deep and unresolved questions in physics and philosophy. It&#x27;s an interesting thought experiment, but it&#x27;s important to note that this isn&#x27;t widely accepted or proven in the scientific community as of my knowledge cutoff in September 2021. reply thecopy This sounds \"right\" but i have no idea what you mean. reply rvcdbn See my response to the other comment. I think I got this idea either from David Deutsch or Frank Tipler, I forget exactly which book. reply andbberger nonsense. reply rvcdbn I said \"there is a line of reasoning...\", I didn&#x27;t say I fully believe it. It definitely depends on a lot of pretty speculative ideas. I&#x27;m happy to discuss this further if you&#x27;d like to point out exactly which parts of the argument you object to.EDIT: I continue the conversation with ChatGPT to try to poke holes in the argument if you’re interested: https:&#x2F;&#x2F;chat.openai.com&#x2F;share&#x2F;19871222-9810-4a25-9604-8e690b... reply ChicagoDave 1. Anti-gravity2. Light year capable transport3. Inertia dampers4. Mass scale carbon capture technology5. Robots to prepare space for habitation6. World recognition to manage resources globally reply TeMPOraL I&#x27;m honestly not sure whether 1, 3 or 6 is most likely to be fundamentally impossible. reply urinotherapist Gravitational wells are spherical, so this unevenness can be utilized to lift up by pumping energy into higher energy state, at higher orbit. reply andbberger > 4. Mass scale carbon capture technologyone of these is not like the others. direct carbon capture works now with the slight caveat that we would have to build 10x our current power supply in fission plants to power them. coccolithophores are an appealing route in principle, but research into their lifecycle and use for sequestration would be a quotidian pursuit for thousands of labs around the world, given funding. reply lottin > 6. World recognition to manage resources globallyDo you mean communism? reply ChicagoDave - Protect the Amazon - Distribute food instead of wasting it - Build more trains, turn roads into park ways and bike paths - Recognize climate change globally before it kills us all reply kaliqt The earth&#x27;s climate changes naturally over the course of tens of thousands of years. The key for us is to minimally impact it and let it do what it wants.Now.... We may disagree on letting it go as it goes. Ice ages would overtake a ton of countries in glaciers entirely, so we may agree that that should be stopped? But........ Doing that would be directly trying to challenge the solar system and earth on their natural cycles. There would likely be massive unforeseen repercussions. reply rnk Think of the sea and pirate trawlers destroying the seabeds everywhere. We need to manage it. reply DrBenCarson If my understanding is correct, 2 is nearly solved if we have a room temp ambient superconductor reply Gud Fusion power engineering has gotten a lot further than most people think!But yeah I suspect the people who are most excited about this news are fusion power engineers!https:&#x2F;&#x2F;www.cambridge.org&#x2F;core&#x2F;journals&#x2F;journal-of-plasma-ph... reply rnk Please connect the dots for me. What does a room temp & atmosphere superconductor do for space travel? I am unaware of any obvious impact. reply radicalbyte Magnetic containment reactor designs become at least an order of magnitude easier if we have room temp&#x2F;pressure super conductors. reply pupperino Michael Levin [1] does brillant work on this \"cellular language\" space and the key point is that genetics is more like biological IaC, it only encodes proteins. Most of the actual control, anatomic and physiological homestasis happens at the higher level of bioelectricity - which works as a computational medium.[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=7FGM33sz25k reply croes To be fair all of your examples could go either way reply pjerem Can you ELI5 how is this possibly a black swan event ? reply UsedToDoNuclear Well conveniently, \"room temperature superconductor\" directly supports #2 reply zepn Interested to see your full list! reply FriedPickles I like the idea of this list. Some others: - Quantum supremacy - HIV vaccine - Synthetic life - Discovery of ET life - P vs NP solution reply p1mrx Bonus points if the ET life is broadcasting useful information. reply rnk I&#x27;d settle for explaining what all these UAPs are, what are they doing? reply dstroot Low cost carbon capture reply zack-m I like the idea of the list as well. Anyone know of resources that are on a similar theme? Only rethinkx “rethinking humanity” report comes to mind. reply jojobas Linux on desktop should be up there. &#x2F;s reply spaceman_2020 4) A cure for cancer reply donny2018 Unfortunately, \"cancer\" is not one thing. We have to find different cures for many specific cancers. reply andbberger > 1) Fully decoding the cellular mechanism of cells allowing for the curing of any disease, repairing any genetic disorder.no way, no how. there is every reason to believe that cells are irreducibly complex. we can understand parts in isolation, yes, but a full model of the cell (however that would look) is almost certainly beyond science and even if you had that good luck measuring the full state of a cell without destroying it reply ETH_start Excellent insight and perspective.>2) Commercially viable fusion energy. Will change a lot of things.How would that be any better than commercially viable fission breeder reactors (which seem far closer to reality than commercially viable fusion energy)? reply XorNot Mostly public perception (annoyingly): people are still going to have a go at being anti-nuclear about it, but building a fusion power reactor is going to have a lot more public cultural cachet to draw upon then fission. We&#x27;ve got a generation of science fiction who&#x27;s core message is \"fusion power solved all the problems\".Though there are genuine advantages: for as radioactive as the interior of a fusion reactor may get, if you cut power it&#x27;ll just sit there safely doing nothing. No decay heat, no potential isotopes to leak - maybe a puff of tritium gas - but that&#x27;s it. It is a technology that has a perfect control loop for safety because it can&#x27;t self-sustain at all. reply lowkey > Commercially viable fusion energy. Will change a lot of things.I would be curious if anyone with knowledge in the space could comment on whether or not LK-99 may get us closer to viable nuclear fusion?My understanding is that magnetic field containment systems are at least part of the technical hurdles required to make fusion feasible. reply antupis I would say that RNA vaccine and chatGPT are two that have happened during my adult life 05->. Iphone and some other innovations were more kinda incremental stuff. reply fnord77 All of these are fantasy.0. LK99 is so obviously a fraud. They&#x27;ve been dicking around with this substance for 24 years.1. some diseases will be possible to fix, like metabolic problems, but where structures are already formed in an adult organism this will be impossible. Like Autism. Go ahead, change every chromosome in every cell, the malformed brain structures will remain.2. Sure there will be ignition, but the facilities will be wildly too expensive for commercial power.3. will never happen with conventional computing hardware. Maybe if someone figures out how to grow actual neurons reply avereveard 0 write your proof then, rise to unending fame. reply Apocryphon If contemporary scientists cared about proving negatives, let alone assigning prestige to the task, then there wouldn’t be a replication crisis. reply avereveard ...the replication crisis is not in science reply Apocryphon When was the last time a Nobel was awarded for proving a negative? Who becomes rich and famous for being a killjoy?The entire premise of your retort was wrong. You should have challenged them to take their certainty to the prediction markets. reply335 more comments...",
    "originSummary": [
      "Researchers have synthesized LK-99 crystals capable of magnetic levitation at room temperature.",
      "Previous studies have shown that LK-99 materials exhibit the Meissner levitation phenomenon and have a higher superconducting transition temperature than originally believed.",
      "This research implies that non-contact, superconducting magnetic levitation at room temperature could become a reality soon."
    ],
    "commentSummary": [
      "The summary covers a range of topics, including the controversy surrounding a leaked paper on a room temperature superconductor and the banning of cars in city centers.",
      "It also includes discussions on the significance of inventions throughout history, potential cancer cures, future scientific breakthroughs, limitations and potential of AI chat bots, and advancements in physics, philosophy, and technology.",
      "The post offers a diverse and comprehensive exploration of various subjects relevant to technology and science."
    ],
    "points": 1284,
    "commentCount": 628,
    "retryCount": 0,
    "time": 1691111732
  },
  {
    "id": 36984282,
    "title": "Man spends entire career mastering crappy codebase",
    "originLink": "https://taylor.town/entire-career",
    "originBody": "taylor.town about now hire rss spam Man Spends Entire Career Mastering Crappy Codebase This week, software developer Arthur Westbook announced his early retirement at age 58. Westbrook spent 35 years in a codebase that allegedly powers some sort of medical software somewhere. During his tenure, he contributed hundreds of lines of code. Westbrook once touched legacy code without ending the company. Westbrook believes he grapsed over 4% of the entire codebase. A former colleague called it “the War & Peace of wingdings”. In the company, Westbrook was known as “one of the programmers on the team”. His manager noted, “Arthur had a knack for working hard without learning transferrable skills. He will be dearly missed. It’ll take two junior devs and a Keurig to replace him.” In honor of his decades of service, one of his coworkers will take him out for drinks “sometime next month”. Nobody on his team responded for comment. For his retirement, Westbrook plans to dabble in street performance and dumpster diving. He also plans to hone his culinary creation: Soylent mixed with Whole Foods Premium Adult Cat Salmon Mix.",
    "commentLink": "https://news.ycombinator.com/item?id=36984282",
    "commentBody": "Man spends entire career mastering crappy codebase | Hacker NewsHacker News new | comments | ask | show | jobs | submitloginMan spends entire career mastering crappy codebase (taylor.town) 805 points by surprisetalk 22 hours ago| 536 comments kypro I swear this guy exists at every company I&#x27;ve ever worked.He&#x27;s the guy you go to when you find some legacy code which you have no idea how the hell it works and end up getting a 2 hour history lesson into a decade of company politics and failed replatforming projects.They&#x27;re hard not to love. reply throwawaaarrgh \"... And the AIX machines were a real beast. We had 20 of those things, and each had its own 20 amp circuit. Had a tendency for the grounding to the steel case to fail. If you wanted to upgrade it you&#x27;d first need to grab a pair of thick leather gloves....\" reply baz00 You kids sitting there. All you do is change your EC2 instance size and restart it. Back in my day I had to go and install the RAM by hand. And you know 128Mb of RAM then took up a whole suitcase and weighed more than your laptopThe I fall asleep at my desk, periodically waking up shouting \"STOP-A!\" and hallucinating about being bitten by thick ethernet vampires.Going to make myself a coffin... reply arethuza \"I had to go and install the RAM by hand\"When the Sun 4&#x2F;330 I used to have needed a RAM upgrade someone flew up from London to Edinburgh with the RAM and installed it. Fortunately we were in the Grassmarket about 10 minutes from the Castle so he had plenty of things for him to do to keep him amused until his return flight.Edit: I checked and the max the 4&#x2F;330 could take was 96MB so I suspect the upgrade was an awesome 64MB. That machine cost more than most cars I have owned - even without allowing for inflation. reply SomeRndName11 1I worked in some ex-USSR government facility, and they had an old hp-9000 system, that needed ram upgrade. HP wanted some ridiculous thousands of $$ for like 16MiB of RAM. After some inspection it was discovered that the RAM is nothing more than 72pin SIMMs. We took some ram from nearby old 486 and it worked. reply baz00 Yeah crazy money. My father used to import RAM when it was really really expensive in the 1980s. He used to take it on planes from Taiwan as hand luggage handcuffed to himself because it was that valuable. reply 13of40 1When I was in Korea in the 90s you could get LG RAM for about half what it would cost in the US. I had a scheme to buy a bunch of it to sell when I came home, but in retrospect it would have been the nerdiest case of \"guy goes door to door trying to sell rapidly expiring meat\". reply smcameron 1I worked in a shop in the early 90s with a bunch of Suns, and we had hired this new sysadmin. One day we noticed that half the RAM was missing from a workstation, and few minutes later noticed half the RAM was missing from all the workstations. Turned out the new sysadmin was a cokehead and had stolen it. reply baz00 1Oh man that&#x27;s funny. Only because something similar happened to us. Hired new cleaners circa 2001. Got into the office one morning and all the PC cases were open. All the RAM and CPUs had been stolen. reply Trixter 1In the mid-90s, when CPU heatsinks didn&#x27;t need to be screwed in, thieves discovered that the new ZIF&#x2F;zero-insertion-force sockets also make good zero-removal-force sockets. reply K0balt 1This brings back memories. I got my start in parts wholesale selling 30pin SIMMs in static baggies out of my leather jacket in a Taco Bell LMFAO. It took some convincing to convince the management I wasn’t selling drugs, but the getup helped me to not be noticed by people that might otherwise know that I was carrying thousands of dollars in cash and chips daily.I would sit there and wait for RAM hungry customers that would call me on my 3 lb cellphone lol. Each one has to buy at least a $0.39 taco so I wouldn’t get kicked out by the manager. They had armed security, who I tipped 20 dollars a day. I hung fliers all over town with tear-off tabs.Then I went to COMDEX, it changed my life. Within 2 years I was in my early 20s and moving 2-3 million in hardware a year. It was a heady time.Then, the business dried up overnight with online sales.Fortunately I saw that coming and had moved into technical services and contracting, and sold the parts wholesale business to one of my competitors lol. The local wholesale distribution biz was dead within 8 months. reply baz00 1Hahaha hooky RAM dealer. Much respect though for being there at the start. I used to do something similar with pirated Amiga games but that was a limited market! reply FireBeyond 1I went to the closing sale of a local computer store that had been in business since XT days.Owner lamented finding 4MB sticks of RAM that had fallen behind the workstations that had cost hundreds of dollars back in the day, as he was selling (and this was a while ago) laptops with 1-2GB of memory). reply entropicgravity 1Continuing with the Monty Python vibe, the first code I wrote was in machine code (ie hex, not even assembler). Though I worked with a guy who wrote machine code on a magnetic drum and they used the delay of the rotation of the drum for their timing. The good ol&#x27; days. reply jolux 1Sorry, could you tell me what \"STOP-A\" means? reply baz00 1Stop-A is the key combo you hit on Sun workstations to drop into the ROM monitor. Usually when they are locked up solid with a crashed Xserver and need a reboot. reply pk-protect-ai 1into bootprom forth interpreter though. reply throwaway743 1\"Back in my day, we only got one compile a day with our punch cards. Now you can compile willy nilly without having to put in the forethought we did\" - ex coworker reply KineticLensman 1> Back in my day, we only got one compile a day with our punch cardsYou were lucky! In my computer class at school in 1979 we got one compile a week. Punched into cards which were taken to the local insurance company who actually had a computer. reply specialist 1My thumbs still have blisters from manually stuffing memory expansion boards with 1Mb of DIP RAM for our 80286 PCs. We were doing image capture and processing, long before it either usable or useful. reply sylario 1I did a real internship (as in it was for my diploma and lasted only a few months) in a medical facility operating Big Machines. I remember a guy soldering a new battery to some old DEC&#x2F;Digital hardware. reply foobarian I for one do not mind that part of computing getting abstracted away by the cloud, whatever its other failings. :-) reply bayindirh Working on the hardware directly is more than half of the fun. reply foobarian An old IBM tech told me that hard drives failed when power cycling equipment could be temporarily resuscitated by placing the drive on the floor, twisting it hard by hand, then as quickly as possible connecting it back into the machine and powering on. Apparently getting the platters to spin helped them get around a worn out motor that couldn&#x27;t make the initial spin-up. reply KMag 1I remember upgrading from a 4.3 GB HD to a 20 GB HD around 2001. I had the old hard drive sitting on my desk, and the new hard drive sitting in the case, both attached to the motherboard via IDE ribbon cables.Most of the way through backing up the 4.3 GB HD to the 20 GB HD, I heard a screech and the old hard drive twisted slightly on the desk... conservation of linear momentum. The drive was visible to the BIOS, but refused to spin up after that.I put the hard drive in a ziplock bag, put it in the freezer to give the parts slightly more clearance from thermal contraction, and slammed the hard drive nice and hard on the desktop to free the stiction. That revived the drive long enough to finish my copy.I did have backups of all of the really important information, but restoring from a stack of floppies is more tedious, slower, and less fun than percussive maintenance on a hard drive.Back when I had an internship working on MEMS gyros for GPS guided mortar rounds, we had to sometimes perform similar percussive maintenance if static electricity had caused the moving parts to contact the substrate. We took the gyro, and smacked it hard on the desk in an \"eyeballs out\" orientation to give it something like 10 to 100 Gs of acceleration in an attempt to un-stick the MEMS gyro. reply SomeRndName11 1Yeah, did same in 1999 or 2000, but we _did_ _not_ take the HDD from the freezer, just pulled the ribbon and power cable through the narrow slit between the door&#x27;s rubber gasket and the fridge&#x27;s body. reply tristor Yes, stiction is a real issue in old hard drives. In fact something that used to work well if you were cold booting an old server even in the mid 90s, with the expectations of an immediate migration, was giving the drives a good sharp slap to help break stiction so they could spin up. The only issue is it could cause a head crash. Another fun trick from back in the day was sticking hard drives in the freezer to cause the platters to shrink enough to dislodge the head and restore the air gap if you had a head crash so you could try to recover the data.As much as I love hardware, I much prefer our current solid state wonderland. reply justsomehnguy 1> to shrink enough to dislodge the head and restore the air gapHuh?What I heard is what a cold drive would be a bit more magnetically stable and IMMSMV that surely worked, because I never had a drive with a stuck heads but I did had drives what would just abort the read or return gibberish, but after an hour in the freezer they would read just fine, till they heat up again. That&#x27;s for the drives mfg after 2000, if that matters. reply tristor 1My understanding may be incorrect, after all the freezing the drives trick is mostly something that was shared among sysadmins like an old wive&#x27;s tale. Nonetheless, it does work (or did).The way I had always understood it was that if you had a head crash (which was caused by the head physically contacting the platter, overcoming the resistance of the air gap between the head and platter, usually due to physical impact) that the magnetism of the head would prevent it from lifting back up on its own, and that freezing the drive would cause the metal in the platter to contract away from the head, which was restricted in movement by its armature, thereby restoring the air gap and lifting the head away. If you started the drive spinning before it heated, the head would stay out of contact and you could successfully read data (some of it, for awhile).That said, my understanding may be incorrect. reply bayindirh I would believe them. I have heard a similar story. A data center had to go through a planned power cycle event.All systems were working when they shut down, but ~40% of the disks failed to spin up due to worn down motors.That&#x27;s a lot of disks. reply vbezhenar 1What’s a procedure to avoid it? Reboot machine once a week so disks fail not all at once? reply wrycoder Gotta know which way to twist it. reply throw0101b > Working on the hardware directly is more than half of the fun.It never really worked until you gave blood to the computing gods on a sharp edge of a metal case. reply Arrath 1I feel like the general improvement in fit & finish of cases and chassis is overlooked.I, for one, haven&#x27;t flayed open a knuckle on a random razor edge or burr on the inside of a case in like 15 years. reply awnion 1\"Hey, look, I have all five fingers! Three on one hand and two on the other!\" reply RajT88 1I have 6 stitches in my left hand from such an offering. reply bayindirh Looks to hands and fingers intentlyHmm, yes, true. reply philk10 1Every Friday I had to take a bunch of magnetic tapes to the bank so they could look after our backups ( which was a good excuse to pop into the pub next door to the bank...) Oh, and we never ever tested that the backups actually worked reply adolph 1\"They were afraid to turn off or reboot the DEC Vax for fear that if the disks stopped spinning they wouldn&#x27;t start again. I saw it once at the retirement ceremony and it didn&#x27;t look like a server but more like a set of industrial washer and driers. The users transferred files using the Kermit protocol and printed locally by a telnet client that could understand the special characters that redirected character output from the terminal to a lineprinter.\" reply WaitWaitWha 1I recognize the parody about me. ;)Do you know why I am giving you the two hour history?First, I recognize that I need human interaction, but do not really like people.Second, I am hoping that you will learn & understand instead of just memorize & regurgitate so in the future you can resolve it yourself instead of bothering me.Now, go away; I had my week&#x27;s fill of socializing.&#x2F;joking - or am I? reply InvertedRhodium 1For me, it&#x27;s usually trying to rapidly justify the existence of whatever Rube Goldberg machine I&#x27;m having to explain. There&#x27;s always reasons behind the madness, even if they&#x27;re not particularly good ones. reply lcnPylGDnU4H9OF 1> justify the existence of whatever Rube Goldberg machineI&#x27;m at least going to be waiting for questions to be asked.\"Why was it done this way?\"\"Circumstance combined with &#x27;path of least resistance&#x27;.\" reply Aeolun 1> Second, I am hoping that you will learn & understand instead of just memorize & regurgitate so in the future you can resolve it yourself instead of bothering me.Where does all this hope come from? I’m barely 15 years into my career and I’ve nearly given up… reply loa_in_ 1Hope is dangerous, for it&#x27;s itself very hard to resist. reply salawat I&#x27;ve started to attempt to gently grind that into juniors. After a certain point, hope is a vice you cannot afford. It is simply something you outgrow, if only because of the unceasing retirement from the mortal coil of those that can bail you out.Hope is for the young and inexperienced. Everytime I come to your rescue, you&#x27;d best pay attention. I have an expiration date. reply kstrauser 1Ha ha but really.I’m not trying to explain why you shouldn’t change it. I’m trying to help you understand what competing forces made it that way in the first place so you can decide if any of that’s still relevant. reply coffeebeqn I’ve seen a few of those. Some are worth their weight in gold. Most are set in their ways from the trauma of trying to make everything not fall apart for so long. Almost all have stagnated and are incapable of bringing in new ideas. Almost all are husks of human beings from putting up and personalizing so much of company dysfunction reply diegoperini 1> incapable of bringing in new ideasBut they are REALLY capable of detecting bad ideas. reply giraffe_lady 1They always say no, and are always correct. reply coffeebeqn 1I mean I’ve literally had people like this fight adding in a version control system. reply dkarl 1This reminds me, in a sad way, of a friend of mine who stayed on when a startup we worked at was acquired by a huge corporation. He has an amazing mind for technical detail, and at the startup, he planned and executed some hugely ambitious technical initiatives. But management at MegaCorp treat him as an obstructionist. They want to announce an initiative, launch it, declare it done, make up a big dollar figure for the \"savings,\" and gather a promotion. They don&#x27;t need the initiative to make sense or work in a technical sense. But he understands the immensely complicated legacy context, all the work required to accomplish anything, and all the things that will break if they leave out parts of the work, and he won&#x27;t keep his mouth shut. He would love the challenge of running a big ambitious project, but the only way to get anything big approved is to drastically underestimate the effort, so he&#x27;s stuck rearranging deck chairs until they inevitably eliminate the product and lay him off. reply bqmjjx0kac 1How can we be sure we can trust this \"git\" thing? Besides, CVS already does everything we need. reply SomeRndName11 1The CVS receipts are too long though. reply ycombobreaker 1A real life application of Odysseus&#x27;s Oar. I have mentored junior devs who have \"heard\" of SVN and also think CVS is just a pharmacy. It was a real gut-punch the first time. replym463 It&#x27;s hard to walk that line.There are really good or valid ideas that people try to implement in terrible ways.things like: for our app on windows, we just ship LIBRARY.DLL with it. We should do the same with linux. (ldd shows 50 inter-dependent libraries) reply ericmcer 1It doesn&#x27;t seem like a bad way to go. If the company is stable enough and you can cash in your engineers salary for 25 years and have crazy good job security.Seems better than being a 50 year old trying to wow a 28 year old interviewer with your skills on whatever hot new framework just came out. reply Gigachad If I’m still building webshit SaaS products at 50 then something has gone wrong. I should be either retired or some kind of high level manager. reply blantonl ...these OS&#x2F;2 machines were once interconnected by a networking technology called &#x27;token ring&#x27;.. no joke. It was basically an entire network where if one single node on the network misbehaved it would bring down the entire network - they didn&#x27;t self recover either! you had to reboot them all. I remember once when I misconfigured a token ring card on a PC and it brought down the mainframe! It shut down the bank for 30 minutes\" reply actionfromafar To be fair, in those days you could sink Ethernet (broadcast hubs, no switches!) with a faulty or malicious PC spamming the network, too.Didn’t have to reboot the others, though. reply tannhaeuser 1What do you mean hubs? Back in the day we manually pierced thick Ethernet coax to get access; of course you could ruin the whole segment running tens or hundreds of meters if you didn&#x27;t take care. reply arbitrage > in those days you could sink Ethernet with a faulty PCThat is still possible in the modern era. reply Doxin 1step one: disable spanning tree, because the LAN is so big it takes half an hour for a port to come up after plugging something instep two: plug a very cheap switch into the networkstep three: have someone move their desk around, and plug a spare cable into the switch at both endsstep four: spend a day doing a binary search by unplugging banks of switches to figure out where the heck all these packets are coming from. reply 13of40 1I used to work in a place where every office on the floor was connected to the same ethernet hub. We also tested a server product that became a DHCP server if you checked the wrong box, so periodically everything would stop working until the team lead came out of his den and went to yell at the new guy. reply dkarl It&#x27;s funny, startups turn over so fast that I&#x27;ve managed to become that guy while staying at a company less than two years. reply renegade-otter Hard to be anything else if the entire job is spinning up a yet another microservice and then spending most of your time debugging in production because shit keeps breaking all the time. reply norgie 1Oh good, we’re not the only ones. The rest of my time is spent saying I can’t help people fix problems with some old microservice my team “supports” reply jollyllama 1You&#x27;ll have that. I&#x27;ve always said those places should keep an anthropologist on staff. reply Waterluvian Maybe we&#x27;re thinking of two different archetypes, but I wonder if their \"hard not to love\" nature is part of the survivorship bias of why they&#x27;re still there. reply itronitron A former coworker of mine claims that he lasted over forty years in the company out of sheer stubbornness. He might still be there. reply bick_nyers 1They are worth their weight in gold, truly. I had the pleasure of interacting with one such man at my previous company weekly for an extended period of time while planning&#x2F;designing a rewrite. Listening, thinking, and questioning his stories and perspectives allowed me to formulate problems and architecture in a more first-principles, fundamental way and I believe that experience really helped me mature as a young engineer (as well as the project). reply racl101 1This is where another one of your Pied Piper boxes would go. Okay. Let me show you the next location where we would install one of your Pied Piper boxes. ... okay reply fnordpiglet They also tend to be brilliant engineers. It’s a heck of a lot easier to always be writing 1.0 of something. It’s a hellaciously difficult engineering task to improve a system that’s been improved upon for decades. These folks should be admired and respected, they’re by far the most crucial people at any company older than 30 years old. Instead we get condescending garbage like the linked article. reply tomatotomato37 I just wish hiring managers saw it the same way. It&#x27;s hard to explain how your last major project was a web enhancement that would have taken a couple days on a virgin codebase, because for you it involved a month of excavating through multiple strata of code dating nearly two decades old, spread across three codebases, two backend languages, a code generator which no one working there understands anymore, and a library who&#x27;s documentation now only exists on the wayback machine. reply urtie 1Or a library who&#x27;s code now only exists on the wayback machine... and of the modified version that you actually use only a single copy exists on an old machine that one of the devs in the company never bothered to hand in for recycling...Never mind that it&#x27;s part of a decade old contract stipulating a quarter century support...Greenfield is easy. :) reply fnordpiglet 1A secret I’ve learned is you only need one job, so you don’t need to take just any job or be hireable at every job. It might take longer, but finding a manager that “gets it” is very important. The most important thing is to find someone who recognizes further that a team is more than the sum of its parts, that each individual is unique and not a cog to be evaluated on a metric rubric and forced into compliance with some idealized engineer. They do exist - I was one for many many years. I’ve recently given up in disgust though and switched back to IC, but senior enough I can shape how managers manage engineers. Regardless, my advice is, if it’s helpful, find the right job with the right team and the right company. It’ll take longer, may pay less at first, but finding the right place that respects work at its value not at its marketability is key to any successful career. reply Kagerjay 1I wish people like this would architectural decision records so people inheriting it later wouldn&#x27;t be left in the dark by the decisions made in the systemBecause sometimes on the outside systems look confusingly written, but it could be a reflection of the scope of confusing business rules to begin with that they had to scope out reply KnobbleMcKnees They are hard not to love.They also hate each and every one of you. reply danesparza Or at the very least: incredibly suspicious of every one of you, and very unimpressed with the latest fad in software development. reply the_sleaze9 This has not been my experience at all reply sanderjd 1This is actually something I&#x27;ve identified as a major con of working at startups (there are a lot of pros too, and I&#x27;m at a startup right now that I love): It is impossible to have these people, because the company is just too young. And also I think this kind of person doesn&#x27;t usually join a startup for its first, like, decade. reply MilStdJunkie 1I am slowly turning into this person and I am not sure how I feel about that. reply m463 https:&#x2F;&#x2F;users.cs.utah.edu&#x2F;~elb&#x2F;folklore&#x2F;mel-annotated&#x2F;node1.... reply theteapot I think they&#x27;re called senior devs who&#x27;ve been there longer than you. reply foxyv 1I usually give the history lesson to forestall the endless series of \"Oh god, why do we do this?\" questions. reply onlypositive Damnit that&#x27;s me at the moment. I need a new job. reply scns Easy to love? reply CrazyStat \"Hard not to X\" is not the same as \"Easy to X\". It may be easy to do something but also easy not to do it. It would be easy for me to yell \"Elephant!\" right now, for example, but also easy not to do it. reply wwilim 1Just one? reply derealized 1> They&#x27;re hard not to love.I often search for a clearcut answer to a technical question and I&#x27;m met with a 2 hour history lesson into a decade of company politics and failed replatforming projects.Yeah, thanks for telling me why John from accounting was a dick 10 years ago and you had to code this module in a certain way. I really don&#x27;t care. I&#x27;m new to the codebase and I just want to know how it (the codebase) works.I&#x27;m currently in this situation and a colleage never gives straight answers to anything. It&#x27;s always some little rant about something and when it&#x27;s done, I still haven&#x27;t got my answer. reply cochne 1> I&#x27;m new to the codebase and I just want to know how it (the codebase) works.You should want to know _why_ it works that way too if you want to do any meaningful work with it. Context matters. I’ve seen many cases where the way something works seems dumb, only to learn later they had already tried the “smart” way but ran into some obscure problem which the “dumb” way solves. reply wonderwonder 1This is important. As soon as we come to the understanding that the coders that came before were not all idiots then we are forced to ask the \"why\". There is generally a decent reason why something is coded the way it is. Could be as simple as it was an emergency and meant to go back and fix it but never had the time or it could be a valid business edge case that absolutely had to be wedged in. There is almost always a why. Otherwise you tell everyone about a fix you made that 3x performance and you see their faces go gray as they explain you just shut down some archaic but mandatory process in Singapore. reply OOPMan 1The assumption that everyone that came before was an idiot is really frustrating...and yet I find myself doing it too.Generally speaking to that person helps, although sometimes they do turn out to actually be an idiot. reply jaywalk 1When I realize I&#x27;m writing some code that seems dumb&#x2F;overly complex on the surface, I leave a comment explaining why it was done that way. reply as1mov 1It probably depends on the person, but I personally enjoy such tales. Gives me more context about why a piece of code was written the way it is now. But then again, I also enjoy scrolling through the commit history of a repo like it&#x27;s an archaeological dig site, so I might be the weird one here ahaha. reply derealized 1It&#x27;s full of \"fix\" or \"fix typo\" or \"update blah.c\"... tiny commits straight to the master branch without CI.Anyway, I really don&#x27;t care about the past in this way. A simple \"accounting needs this for that\" is enough for me. No need to explain that Adam was getting divorced at the time, so he was grumpy, and, and, and... reply digging 1Easier said than done, but try telling them that. \"I appreciate you sharing context, but it&#x27;s too much to take in at once. It would work better for me to get a more clear-cut answer.\" reply belthesar 1Sometimes, the 2 hour story isn&#x27;t worth the time it&#x27;s told. Sometimes, the 2 hour story gives you the insight necessary to satisfy Chesterton&#x27;s Fence. It seems like in this instance, that&#x27;s not the case, but I&#x27;d definitely encourage you not to dismiss stories in general because you don&#x27;t think you need the history to achieve your goal. reply freetanga 1That attitude gives me “I don’t know how my code works, I copied it from the Internet and it does compile!” creeps. reply derealized 1Because I don&#x27;t want to hear about personal stories? How is that related? I do very much want to know how code works. It&#x27;s the very core of my argument. reply agentultra Man spends entire career convincing himself the reason he keeps job hopping is because everyone else is writing crappy code.Karl Hackerman shows up to each meeting complaining. He seems sour that he hasn’t been given the go ahead to rewrite the system in Rust. He knows a lot about bleeding edge frameworks and best practices and always seems annoyed that he can’t use them at work. He thinks it’s because everyone else has settled in to becoming wage slaves instead of striving to be the best programmers they can be. Everyone puts up with him because they know he’ll quit in six months anyway.Karl is 47 now. Hasn’t held a job for more than a couple of years. Has mostly been freelancing lately and trying to sell books on tech and frameworks nobody cares about anymore. reply JackMorgan 1I did not expect to wake up and be attacked like this. Not even a warning. Savage.Good thing I&#x27;m not in my 40s yet, still time to recover from my wayward path. reply appplication Yeah this is ruthless. On the other hand, I feel ok with my present course because the intermittent chance to use new shit is the only thing that keeps me interested anymore. That and the exorbitant pay, I guess. reply surprisetalk 1Author here!I love this so much. I&#x27;ve totally been this guy :) Learning how not to be an insufferable doucheb*g was a surprisingly hard challenge for meI&#x27;ve been writing a longer fiction piece about overzealous know-it-all engineers in the style of Confederacy of Dunces. Probably won&#x27;t be done for a while, &#x27;cause there&#x27;s a lot more of my soul in it haha reply agentultra 1Awesome! Enjoyed the post. Keep up the good work as long as it makes you happy. :) reply time0ut 1This was great.I felt this way earlier on, but quickly learned to get fulfillment in my day job purely from shipping and contemplate the mysteries of computer science largely on my own time. Sometimes they overlap, but good day jobs are often 80% boring in my experience. reply r-u-serious 1I lost it at \"best practice\". I once worked with this guy. He would use that term whenever he didn&#x27;t have any good argument, which was basically all of the time. He would have the strongest opinions, whenever it didn&#x27;t matter... reply hfhfhfhfhfhfhf 1FYI, Karl has been reincarnated as MyCurrentIntern reply hliyan 2For ten years, I worked on codebases written in C++ without using any third party libraries (no, not even STL -- we needed faster, thread safe versions of strings and maps which were not available at the time; Boost? What&#x27;s that?), its own custom messaging middleware built directly on sockets, its on distributed process management system built with unix syscalls (obviously). There was not a single line of HTML, Java etc. anywhere. It was a comfortable, high-paid life and I solved cutting edge problems (HFT, distributed, concurrent computing). In 2013, I forced myself to quit, start with a small company that paid me half the salary so that I could learn the web tech stack from the ground up. It was all to avoid this fate. I&#x27;d like to think I&#x27;ve succeeded. reply LudwigNagasena 2I don’t think anyone working with low-level C++ for HFT can face similar fate. Most of skills gained at such job seem very transferable. The article seems to be more about jobs where 95% of work consists in implementing CRUD in accordance with very specific business logic of the company.The only reason to change such job I can imagine is to sit out your non-compete package. But I am not in this industry so maybe I’m missing something. reply lordnacho It&#x27;s not that you won&#x27;t have the skills, it&#x27;s somehow demonstrating them.I also worked at an HFT C++ shop that used no STL. Every data structure has a weird name and API that you get used to. The whole architecture has its own idioms, and hasn&#x27;t needed much upgrading in terms of language features.Imagine you learn the grammar of English. You learn how to pluralise nouns, when to put an s at the end of a verb, how to to use commas, and so on. You then go to work at a place where they have a different word for coffee, drink, and order. Along with every other word. You end up learning where everything is and how to talk about it, and you&#x27;re productive.How do you apply for another job? Chances are you will be asked how to order a coffee and drink it.Very real issue btw, I still have friends there. reply nly 1I work at a HFT shop and put C++ code is modern (C++23, GCC 13) and uses stacks of third party libraries reply lordnacho Yeah I&#x27;m not entirely sold on the NIH story. Plenty of things written by other people will work just fine for HFT. reply bentcorner 1This kind of issue cuts both ways - how do you hire new people and get them productive quickly on a code base where they will almost certainly understand nothing?Getting rid of weird data structures that now have STL analogs then is a productive exercise - existing devs get to learn more STL and new devs have more familiar ground. You get to delete code too. reply omscs99 1Unrelated question: do hfts make you move out to east coast, or are there some in California? reply lordnacho Firms are mostly in the financial centers but maybe there&#x27;s a remote role here and there.There&#x27;s at least one in the bay area though. reply smabie 1HFT firms are primarily in Chicago &#x2F; NYC. reply bluGill Yeah, I find it amazing someone would transfer to standard web CRUD development from that. Sure you can have enough of all the custom stuff, but there are plenty of companies that will hire you for your current salary for non-web work. (you can probably guess how little I like web work) reply shrimp_emoji Same! The poster&#x27;s pivot reads like horror to me. Like they lost their mind and joined a cult where they worship Memnon with sermons of JavaScript.> It never sat well with me. Colocated systems saw latencies no mom-and-pop investor could ever dream to achieve. That is one of the reasons why the second company I joined was a non-profit that built systems to help track human rights violations, enforce labor rights, monitor democratic elections etc. Third job was in the food industry and the last one, in housing &#x2F; property management. So I&#x27;d like to think I&#x27;ve made sufficient amends.Ah, nevermind. Turns out they were worshipping Memnon with C++ and renounced that cult with web tech! :p reply DrBazza 2> so that I could learn the web tech stack from the ground up. It was all to avoid this fate. I&#x27;d like to think I&#x27;ve succeeded.I&#x27;m not sure if that&#x27;s intentional humour or not. reply hliyan There is a massive advantage in being able to see the web tech stack for what it is and wielding it without over-engineering or fanaticism, while your competitors are spending 2-3x on monstrosities that essentially does the same thing, but slower. reply bob1029 I was originally concerned about your parent comment regarding your new foray into web dev (that C++ path sounds amazing), but this comment has put my soul at ease.If you walk into web dev with aggressive principles and a willingness to be controversial, you can get a lot of shit done and it will feel great. Watching others struggle under the various JS framework circuses has almost an opulent&#x2F;aristocratic vibe in 2023. reply ticviking The day a professor made me implement a simple http server was the day I achieved code enlightenment.At that level of abstraction it’s all just strings reply tambourine_man That was the web, yeah. Absurdly simple. Now all new protocols are binary and require reading several academic papers instead of a single RFC. reply bob1029 > At that level of abstraction it’s all just stringsExactly... I worry about the masses learning of this and gaining literacy over the landed gentry.PHP&#x2F;CGI basically had it solved. I emulate PHP in .NET6 today using verbatim and interpolated string operations. reply a_subsystem 1Relevant: https:&#x2F;&#x2F;twitter.com&#x2F;serbantanasa&#x2F;status&#x2F;1582019078533046272 reply DrBazza Fair point. The web stack is the one thing I actively avoid doing anything significant with for exactly the reasons you&#x27;ve just described. reply sph 2Out of the frying pan, into the cow manure. reply pantulis I have a pretty similar story. I spent 7 years working as a subcontractor for a big telco with CORBA, pthreads and the ACE reactor library. First week, I halted a whole contact center service by adding a sleep call to the codebase (it was on UAT environment). Fast forward several years and I could effortlessly debug cores with thousands of threads, reason about semaphores, reentrancy and even tell the difference between the POA and the BOA Orbix adaptors. I began to become the mythical guy who knew what everything did not because I was technically good, it was because I understood the business and how it mapped to the different architecture elements.Then I felt like I could spend my whole career there and decided there was a whole world out there in the web, began to learn PHP in 2004 until the mythical \"blog in 5 minutes\" Rails demo appeared. I switched jobs in 2007 and I have never looked back. reply hliyan Interesting. I&#x27;ve used semaphores with pthreads (only once -- after that I realised plain old mutexes will do). Like your sleep call, I once brought an entire service to a grinding halt by adding a simple `fsync` call (to fix a recovery failure because once a sequenced message we thought we had written to disk before a crash had actually got lost in the buffer). Understanding things at that level makes any new tech fairly easy to grok. reply adolph 1> I understood the business and how it mapped to the different architecture elementsIf you have access to key systems, you can definitely reverse-Conway to understand how an organization really works.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Conway&#x27;s_lawAny organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization&#x27;s communication structure.— Melvin E. Conway reply pantulis 28 That&#x27;s so correct, this was Conway&#x27;s Law in action! reply bfrog C++ is such a damn chore. This is partly why, everyone always assumes they can do it better, they don&#x27;t trust any other code, so you end up with monoliths of NIMBY code and esoteric build setups. Code reviews are incredibly painful for the same sort of C++ reasons, everything can effect everything, the whole idea of encapsulation tends to fall apart when memory, time, ordering behavioral effects get relied on after some amount of time usage. Every change is a footgun to be found in production under just the right circumstances.Hard to be productive when you can&#x27;t trust the language, the tools, or other developers to be correct. reply rr808 2I did the same, I thought C++ was heading for obsolescence. Now a master of Java, Javascript and can write great full stack apps. Meanwhile HFT C++ jobs are paying double, I&#x27;m thinking of going back, even if the systems are boring. reply esMazer 1been working on java jobs and easy code bases since I graduated 10 years ago, nothing had been really challenging and I&#x27;m not complaining. Would be interested in a job that pays more even do you think working on C++ jobs is more challenging or just boring? reply bla3 Sounds like your old place had a good idea what&#x27;s good about c++. It&#x27;s not the STL and certainly not boost. reply intelVISA Legit, is that place hiring? Sounds like an ideal stack free from the tragedy of the commons. reply sumtechguy Those stacks can be full of &#x27;not invented here&#x27;. They are unique and have their own quirks. Quirks that you more than likely can not google for any sort of guidance as to what is going on. I wrote one of those stacks a few years ago. No std libs at all. Why? must fit in 32k and most of that space is needed to hold data. That means throwing a lot of those helper bits out or spend weeks figuring out how to bend the compiler to your will and not include everything. When it is easier just to roll your on CS version of whatever. But it sucks because you probably have odd edge cases. reply intelVISA Yeh it&#x27;s a rough but rewarding life; I spend most of my hours on problems that aren&#x27;t on Google, or any LLM, so I&#x27;m kinda used to it now. (Stockholm)Would love to know of more spaces which require this level of programming - usually I feel kinda underworked at most shops.Though, true enlightenment is combining the urge to NIH with some, light, sensible borrowing from those smarter than us :) very much a key skill unto itself. reply rthomas6 1Embedded programming is this 99% of the time. Abstracting hardware away is a silly notion. Docker? Cloud? Hard to do when your code only runs at all on one specific custom board. The protocol you wrote to talk to that one chip isn&#x27;t working? Time to break out the oscilloscope and look at the actual data going to the pins.Join us, the pay is worse and the work is harder, but also the prestige is lower. reply marssaxman 1I sometimes really miss embedded programming; it felt like real engineering in a way that higher-level software development often doesn&#x27;t. Alas, the shop I worked for could not keep me busy enough, the projects began to feel repetitive, and I got really bored; it&#x27;d be hard to go back. reply ukuina 1> Join us, the pay is worse and the work is harder, but also the prestige is lower.I tip my hat to you! reply sumtechguy 1The space I was in was IoT type items. Usually hub controllers. The thing is that is getting less and less as you can get a fairly robust thing now with a couple hundred meg of flash and ram for a very reasonable price. So those &#x27;must fit in 32k&#x27; items are few and far between these days. With that sort of space you may as well use the proper libs that are usually nicely documented and all the quirks have been seen by hundreds of other poor souls such as yourself. reply HPsquared Game engines have a lot of low-level C++... Often not the best working conditions though from what I hear. replygnfargbl 2I know it&#x27;s not all about the money, but over the course of your entire career, do you think that move was financially positive or negative?I&#x27;m very roughly estimating that you could probably have worked in the HFT job for around two-thirds the time you&#x27;re going to have spent working on generic web tech, and still been better off. reply hliyan Absolutely 100% positive. I was largely an individual contributor all that time, and only did some unstructured, untrained, unguided people & project management. Perhaps because it was such a niche, engineer-dominated environment. Several years after leaving that company, I quickly learned to effectively manage people and projects, architect systems using more mainstream&#x2F;open source tech and eventually reached exec level (but that&#x27;s a different story). reply gnfargbl Ah, that&#x27;s the missing punchline: you had ambitions to be something else other than an engineer, and you (quite correctly) recognised that you were never going to grow your wider skills at such a place.For someone who had wanted to stay an IC, I don&#x27;t think the move would have been quite as wise. Being in a niche, engineer-dominated environment, and being paid extremely well for it, is nirvana for many lifelong ICs. It certainly feels very different from the experience of Arthur from the linked article. reply markus_zhang That&#x27;s really some fields I&#x27;d love to get into -- less need to talk to people and more need to talk to the machine. What a dream! Alas I only scratched the surface of C++. reply coliveira I hope it worked for you, but I don&#x27;t see any big difference. Web technology will become dated faster than the old C++ codebase. If you learn some web tech stack today I expect that it will be obsolete in 5 to 10 years. What are you gonna do next? Move to another small company for half the salary to learn everything again and compete with 20 year olds? reply otabdeveloper4 > learn the web tech stack from the ground upOuch. Should have stayed in legacy C++. reply Aloha 2Was it something that ran in an embedded environment? reply hliyan 2High frequency algorithmic trading. Often ran on colocated hardware within the exchange &#x2F; trading system data centers. Started with stuff like Sun SPARC, Solaris and Oracle and we slowly made our way to Suse, Intel and... surprise, our own database optimised for fast writes. reply bboygravity 2Naive question: is this like creating fancy tech that is helping rich people to front-run the poor and middle-class?Because that&#x27;s what a lot of people think online. Maybe it&#x27;s more nuanced. I&#x27;m curious how someone from that carreer sees it? reply lordnacho The whole business model is misunderstood by your average internet commentator.When you have a market, you need someone to be there to provide liquidity. Imagine if you&#x27;re a farmer and you show up to the market with your wheat, but all the bakers have gone home that day. Or the baker shows up and there&#x27;s no farmer. The market maker stands around all day offering to buy and sell so that you don&#x27;t have to wait for the guy you&#x27;re really trading with. Of course this middle man wants to get paid for it, but your cost as an average Joe is next to nothing. This is trading in time.Now imagine you want to cook a meal and your ideal meat is beef, but actually you&#x27;re ok with pork, so long as the pork is cheap enough to make it worth it. How much cheaper should it be? Well your fellow who knows all the pork and beef people will be able to gauge where the balancing spread is, given the amount of interest. In fact he will from time to time do the trade when the spread is out of line. This is trading in space.So why all the fancy tech? After all market makers used to stand around in a pit in a colored jacket, and they didn&#x27;t have degrees. My first boss in the market was one of these guys.Well, things have gotten very tech heavy because as soon as prices are out of line, there is money to be made. Or rather, lost. As a market maker, you are constantly out there with your prices, offering to buy or sell at a very small spread. If some news happens that affects prices in a big way, you can be sure that you will buy when it&#x27;s going down and sell when it&#x27;s going up. In order to both have tight prices and avoid this \"adverse selection\", you really want to be able to react as quickly as you can when your system decides that something&#x27;s up. reply brnt Ah, the ol&#x27; liquidity spiel. One wonders how markets were even possible before HFT... reply Spinnaker_ Markets were possible. But what about the current offering of ETFs and similar products? Despite all the fancy talk, many HFT firms are just market makers for the products that enable average joes to invest well and cheaply.You don&#x27;t have to be that old to remember how terrible the experience used to be, and how easily even sophisticated individuals were ripped off at every point of the process. reply matheusmoreira > You don&#x27;t have to be that old to remember how terrible the experience used to beI guess I&#x27;m not old enough. What was the system like? How did sophisticated traders get ripped off? reply shrimp_emoji Was that like Gomez Addams with the paper ticker coming out of that glass domed contraption, calling his guy to buy Consolidated Lint? reply lordnacho I explained that. It doesn&#x27;t matter whether it&#x27;s a computer doing it or a guy in a jacket, but once one guy gets a computer all the market makers need it. reply actionfromafar So take away the computers. Or more realistically, batch run all orders once an hour. reply ycombobreaker 1Retail consumers aren&#x27;t exactly disadvantaged by the gradual narrowing of spreads, so what are you trying to fix? The latency arms-race is exclusively professionals fighting each other.Getting back on topic, being a software developer for an HFT shop can be a lot of fun: serious technical challenges and a rapid feedback loop in a role where you may be the revenue stream rather than just another cost center. But posters highlighting NIH syndrome are spot on: you risk pigeonholing yourself. reply JustLurking2022 You could easily solve all of this without HFTs - you might introduce a few seconds of latency but virtually no real investors care about that level of latency and it would save them billions per year. reply lordnacho Would save money for the market makers too. Assuming someone couldn&#x27;t get an advantage, and that&#x27;s the rub. reply snowwrestler 1Yes you could, but the point is that HFTs don&#x27;t create any new problems that need solving. They don&#x27;t make anything worse.> and it would save them billions per year.This is not true. reply w4termelon 1\"Your average internet commentator\" is ignorant by choice. No argument or description will convince them. reply nly 1You&#x27;re describing market makers, not all HFT participants. reply lordnacho True but trying to keep it simple. reply hliyan Unfortunately, yes. It never sat well with me. Colocated systems saw latencies no mom-and-pop investor could ever dream to achieve. That is one of the reasons why the second company I joined was a non-profit that built systems to help track human rights violations, enforce labor rights, monitor democratic elections etc. Third job was in the food industry and the last one, in housing &#x2F; property management. So I&#x27;d like to think I&#x27;ve made sufficient amends. reply ReactiveJelly 1I wonder why mom and pop are investing in individual stocks at all. Buying the index has been a passable \"get rich slow\" scheme for me. reply rocqua Generally, it&#x27;s not about front-running normal people. Instead its racing other HFTs. Either a race to capture arbitrage opportunities, or to update your orders on one market based on trades made in another market.The aim of the game is to collect a small spread on a lot of transactions.The scary thing for an HFT like that is being &#x27;run over&#x27; by a big party selling or buying a lot over a day. If a pension fund is dumping 10٪ of their holdings of shell, it&#x27;s hard to collect a spread because you need to find buyers for every stock you buy from them. Meanwhile the price is dropping as they sell off.Hence you occasionally see &#x27;front running&#x27; with price improvement. Instead of buying from the market at 1.02 a HFT gets to sell to you at 1.01, yielding you a better price. This is a good deal for the HFT, because a normal person isn&#x27;t going to run the HFT over. And it&#x27;s a good deal for the normal person because they get a better price. reply semi-extrinsic No, the poor and middle-class are not day trading stocks in any sort of meaningful volume.It is to help the super-rich who own hedge funds to frontrun the rich upper-middle-class people with significant disposable income. reply snowwrestler 1No, it&#x27;s a zero sum game. HFT firms fight to be the first to pick up a penny, but they can&#x27;t force anyone to drop more pennies. They don&#x27;t cause prices to go up more than they would have otherwise, or extract more value from the poor and middle class. reply eamonnsullivan 2Bloomberg? Comdb? If not, sounds very similar, anyway. Been there, done that! reply commandlinefan 1> in C++ without using any third party libraries (no, not even STLAs God intended it! reply deadletters 1That first place sounds awesome reply bowsamic 2What about it would you like to avoid? I don&#x27;t understand the fears that people have in this thread. To me this sounds like the Platonic ideal of a programming job.EDIT: I&#x27;ll reply to my replier here because &#x2F;u&#x2F;Dang rate limited me (again), though I must commend him for letting me have one more comment than usual before he pushes the button ;)> I would say the ending -- the part where you are unemployed and unable to support yourself in your old age because you invested decades of your brainpower into a highly specialised, non-transferrable skill.I would contend that such a person, unless very reckless with finances or extremely underpaid, should have enough money saved up to make what is mentioned there very unlikely. That said, I know some high-income earners struggle to not blow their entire bank account each month reply hliyan 2I would say the ending -- the part where you are unemployed and unable to support yourself in your old age because you invested decades of your brainpower into a highly specialised, non-transferrable skill. reply sidlls 1Most of my early programming work was with C and C++ (after I left academia, where it was mostly Fortran). I am, simply put, a better programmer for it, objectively so when compared to my peers who&#x27;ve never touched it, at basically every place I&#x27;ve worked at since (including a FAANG-level company, currently, where I&#x27;m mostly writing in go and python). At least, that&#x27;s the feedback I get from them.I think it&#x27;s fair to say this skill difference is largely from that work in the C family, where I learned a number of different paradigms for design and development in that world, with all its footguns and low-level \"gotchas\". It has always been easier for me to parse and understand others&#x27; code, identify subtle bugs, to use debugging tools, and to identify some optimizations by examining the code that others might spend days using profilers to find.Some of that would come with engineering experience in general, regardless of languages used, but not all of it, but I picked these skills up faster and earlier in my career, thanks to that early work. Skill with C++ is definitely transferrable, in at least some cases. reply michaelteter 2I should think that years of specialized C++ work in hft environments would have come with impressively high pay… in which case one could retire early and self study anything for fun, not hope to find a job for financial reasons. reply hliyan 2Ideally, yes! Unfortunately, there is such a thing as being young and not knowing your own worth &#x2F; not knowing how to negotiate &#x2F; not having a manager who looks out for your career growth. reply michaelteter 1Understood.In that case, if web development is your interest, then you have many possible paths.The primary choices are full stack, backend, or frontend.Obviously full stack is most flexible because you can theoretically do it all. But keeping up with so many technologies simultaneously is really tiring.Take a look at Phoenix framework. It is a fantastic way to get started, and it will grow with you into just about any future project need. Plus Elixir is an excellent language built on top of the incredibly powerful Erlang ecosystem. reply kjksf Being good at C++ is very much a transferable skill.I&#x27;m sure he could learn STL (standard C++ library) in a fraction of time it would take someone else to become proficient in C++ in general. reply sumtechguy It is a transferable skill. But not one many people want to pay for except in very niche areas these days. So if you are out of a job expect to grind for awhile trying to find someone to hire for C++. Unless you have network connections then you might be ok. Being good at C++ only goes so far, you have to have skills in techs people are willing to pay for. Not many companies are willing to wait while you skill up in their stack unless you are willing to work jr but they will not hire you anyway because &#x27;you will jump ship&#x27;. Its not great. reply maaarghk 2The web stack might give you more transferable skills but how did you calculate the trade off vs the 50% pay cut? Was the salary not actually very high and at a low ceiling compared to web work - i.e. you expect your salary to soon exceed what you made working in HFT? Or was there a serious risk of layoffs happening far in advance of your retirement? If the goal is to support yourself after retirement, are you saying in certain circumstances halving your salary 10 years into a tech career ultimately optimises your entire-career-earnings? reply hliyan It wasn&#x27;t such a purely material calculation. Less stress, more time to spend with family and friends, learning more things and doing something that you know actually adds value to the world -- those things matter. reply mustafa_pasi Shouldn&#x27;t you have ample savings, a private pension and social security? reply FrustratedMonky ? In the US? Maybe not. I&#x27;d bet a lot of hot shot young programmers think it will be gravy for ever.Start saving now. reply Double_a_92 That&#x27;s mostly the guys fault and not the jobs fault.Even in a bad code base you can start making things better, apply modern techniques and learn new things.Also most of the skill you gain there is transferrable. E.g. just because you have to work with some legacy PHP project, it doesn&#x27;t mean that you would suck at creating modern applications in JS. It would just take a couple of weeks to get use to it. reply lelanthran > Even in a bad code base you can start making things better, apply modern techniques and learn new thingsAll th bad codebase I&#x27;ve seen were a result of fossils who are still with the company gatekeeping anyone from fixing their code.A few years ago, I had one architect stubbornly refuse to use source control, rejected all PRs that didn&#x27;t use his homegrown buggy C++ libs for strings, refused to let anyone do the http server bits unless they used his C++ server and so on.If there isn&#x27;t a gatekeeper, you wouldn&#x27;t have the bad codebase in the first place. reply yonaguska I&#x27;ve got to disagree. not every contributor is making the code base better. I&#x27;m in a situation where we are such a small team that there really is no gatekeeper, and we only require one approve per pr...and I&#x27;ve come back from vacation to some monstrosities that I have to look at with no time to fix. After a pairing session with a a fellow developer, where I took the extra effort to refactor something along the way, probably an addition 15 minutes of effort...she quipped- no wonder it takes you so long to finish your stories sometimes. I mean, that&#x27;s not why- I&#x27;m ADHD, so my lack of productivity sometimes is invariably due to a day where I forgot my meds or didn&#x27;t get a full nights rest. reply 0x445442 Making things better and applying modern techniques don’t map to a feature story. In the environments being discussed you’ll have to wait for a cadre of architects and program managers to convince the C levels to commit to a multi year, millions of dollar effort to have any hope of improving a code base. reply Double_a_92 You don&#x27;t have to rewrite everything, to start fixing things. reply sumtechguy &#x27;So your story ran over again help me understand where we can improve your work flow&#x27;. reply 0x445442 Must be nice to live in your world of being treated as a professional. reply chrisweekly > \"just because you have to work with some legacy PHP project, it doesn&#x27;t mean that you would suck at creating modern applications in JS\"I disagree; working on a legacy PHP project isn&#x27;t just opportunity cost (failing to sharpen your knife), it&#x27;s actively harmful (leaving the knife in salt water, accelerating the rust). reply Barrin92 that part is a complete fiction. People who have a lot of experience in the embedded world or performant but esoteric codebases are highly thought after. Even if the literal job isn&#x27;t transferable, the skills for sure are.My mother was a COBOL developer and didn&#x27;t work for 20 years because she stayed home. She recently returned to her old bank she worked for because they are dragging people out of retirement as they can&#x27;t find anyone else. She earns more than I do now.People are crazy to give a job like that up for generic web dev work. reply Etheryte 2Are you aware that rate limiting is not something a moderator goes around doing to a single person, but instead a server managing its own workload? reply morelisp Hacker News has per-user configurable posting rate limits. Moderators use them. reply stefan_ 2And now you are jumping from one \"stack\" to another, none the wiser, your knowledge hopelessly outdated just a year in. The principles you learned in HFT? Those apply all the same. reply armitron 2So you left a job that paid 2x and exposed you to hard problems that require reliable solutions for a job inside the horror clusterfuck that&#x27;s the modern web where nothing really \"works\" and there&#x27;s no real engineering to speak of besides monkeys throwing crap in a shared pile and shovelling it out the door ASAP.Good for you I guess? reply intelVISA Most people I know, inc. myself, would call this a \"bruh moment\".I can&#x27;t fathom willingly entering the web mines if you&#x27;ve already sunk in the hours to master high perf native code, OSdev, dist systems etc. People usually enter web to avoid having to learn such things.To discard that knowledge and instead compete with an endless stream of fresh grads, boot camp grinders and LLMs for less money? A madness if I&#x27;ve seen one. reply sys_prog 1Fun fact: I&#x27;m actually a bootcamp grad in web dev doing the opposite. I agree. reply shadowgovt 1Speaking as someone who does both:Web tech is more immediately rewarding. With C++ (and especially with modern web dev agile processes), you can spend a week building enough framework and infrastructure crap to stand up the barest inkling of a demo of the solution you plan to implement, only to have the whole thing pivot out from under you and become wasted work.More complicated languages and frameworks that manage memory and do UI and everything for you let you get to a prototype much faster, so you can see whether it&#x27;ll work or whether you want to toss out the idea much sooner. reply gorjusborg The arrogance you are showing is disgusting.Even if the decision he made was a bad one, you don&#x27;t know anything about why it made sense for him at the time.People aren&#x27;t algorithms running in complete isolation and silence. They live in nuanced circumstances you can&#x27;t possibly understand by his short history in a comment.I hope you can find understanding and peace in the future. reply brnt HFT is still CRUD, CRUD for the extremely wealthy.If you want interesting, go to HPC large scale simulation. reply seanthemon Tell me you know nothing about web dev without telling me you know nothing about web dev reply ncann It&#x27;s hyperbolic but it&#x27;s a common sentiment that I tend to agree with. The web dev world changes too fast and too often, many stacks involve absurd complexity for dubious performance and maintainability and other metrics. reply recursive I&#x27;ve been doing web dev for 20+ years. Which part is wrong?It&#x27;s not hard to find feature support or implementation differences between browsers. But these days, that&#x27;s not really the problem. I can go read the ES language specification, and generally find user agents&#x2F;node&#x2F;deno&#x2F;bun have compliant implementations.The problem is brittle \"ecosystem\" stuff. How are the create-react-apps going? How is module bundling going amidst the UMD&#x2F;CJS&#x2F;ESM war? reply sfn42 Damn so it&#x27;s not just me having that impression. Guess I better steer towards other things.. reply zabzonk 2> so that I could learn the web tech stack from the ground up. It was all to avoid this fatesame fate> I&#x27;d like to think I&#x27;ve succeeded.possibly not reply throwawaaarrgh Don&#x27;t live to work, work to live. I bet Arthur partied his ass off back in the day, stumbled into work without sleep, napped during retros and refinement. He might be the least useful dev but he&#x27;s a king at Burning Man. Now with his flush 401k, he can finally retire to make little wooden figurines to sell at the farmers market, where he really just wants to regale people with stories of the biggest fish he ever caught, or his dream of opening up a ramen food cart if his in-laws will go in on it with him. Arthur&#x27;s lived a life - just not at work. reply dxuh Hard to do if most of your life is work. I find it very hard to find space for an actual life after subtracting a full-time job, exercise, personal hygiene, nutrition, etc. from my waking hours. It&#x27;s essentially ~2h a day + the weekend, which often also consists of getting stuff done you didn&#x27;t manage during the week.I hate the thought of my life starting in retirement. Especially if I might be 67 by then, which is the legal retirement age, where I live. reply surprisetalk https:&#x2F;&#x2F;taylor.town&#x2F;10-minutes reply jjice > Especially if I might be 67 by then, which is the legal retirement age, where I live.When you say \"legal retirement age\", what do you mean? Is this to receive some sort of retirement benefit like Social Security in the US? Or is it something else? reply dxuh 1The retirement system is completely broken over here. As an employee you have to pay into it. I pay > 500€&#x2F;mo, which a big part of my pay check and one of my largest expenses. My employer has to pay the same amount on top. You might or might not consider this essentially an additional cost for me as well. It is intended to be the primary pension plan for most people, though by the time I will go into retirement, the whole system will be unviable financially and I might get nothing. If I do get something, I get it starting after completing my 67th year of life. Of course I&#x27;d rather invest that money privately. If I choose to go into retirement early, I will have to pay hefty life-long penalties - 0.3% per month that I retire early. Obviously a couple of percent over 20 years of retirement or so can hurt quite a bit.It might sound silly, but it&#x27;s one of the main reasons I want to leave this country. reply imtringued 1It sounds silly because Germany is a good place to retire in, not a good place to be young and work. reply mrpound 1That, plus you&#x27;ll pay penalties (10%) if you draw on a retirement account like an IRA&#x2F;401k before retirement age. reply iExploder 1mate you think retirement age is 67, thats very cute of you. just wait for 20 years and see how many times this milestone will change with the way the world population is going :) reply lolsal 1I think this was a contrived example, but I really appreciated all the little details here! They struck close to home and felt very validating, even if accidental :) reply saiya-jin Yes that would be great and I do hope for mr A the reality is some variant of this.More often than not though, its not so rosy. Arthur would be overweight, riddled with medical issues, solitary guy with unhealthy attachment to XYZ (anime, gaming etc).But if he had kid(s) and raised them well, well as a parent too I do have tons of respect for him for that alone, rest are details when looking back. reply DoingIsLearning There are talented people everywhere, the probability of somehow being ground breaking and world impactful is ridiculously small. Anyone pegging their self-worth on that goal is setting themselves up for a lot of mental health struggles.My levels of ambition and relentlessness absolutely shifted after having kids, I used to be absolutely furious about being the best. Now I am very much \"fuck you pay me\" and my priority is having as much free time as possible for family and friends. I for one would be fine with Mr. Westbrook&#x27;s career although thankfully I haven&#x27;t had as crappy colleagues as him throughout my career.There are people of all types who will want different things, no point in judging. As the great thinker Alicia Keys once said: &#x27;you do you boo!&#x27; reply bayindirh > I used to be absolutely furious about being the best.I found out that just being better than yourself takes you a long long way.I have never competed, but just did my thing. Then found out that I&#x27;ve already know more and ahead of many people I&#x27;m inspired by.Yet, this was not my aim, and still is not. I&#x27;m just one of the so-called dark developers. I just do my thing, try to do it better every time, and don&#x27;t care about hall of fame of anything casual or serious. reply hiAndrewQuinn I recently put a little modal on my phone that just says \"Compete against yourself\" every 30 minutes, and I&#x27;m finding it remarkably helpful at focusing my efforts back to what I want to see in the world.I like the mindset of trying to be just a little better than you were, every day. It feels... correctly scaled, somehow. reply enlyth You willingly turned on a notification every 30 minutes that tells you to compete against yourself? I cannot tell if this is parody or just Peak HN reply kayodelycaon 1I&#x27;d go with Peak HN.Everyone has their quirks. I&#x27;ve got my computer speaking the time every 15 minutes and everyone I know would be driven absolutely insane by that. It helps me keep track of time.Some people put a postit on their mirror or laptop screen. reply bayindirh 1This is a comic I love (titled: Weird): https:&#x2F;&#x2F;viruscomix.com&#x2F;page500.htmlI store a copy in my \"life changing comics\" folder. reply clementime 1This is a great comic. Understanding and appreciating other people&#x27;s differences goes a long way. So much harm comes from being fearful or judgemental of people who are different.Now I&#x27;m curious - what else is in your \"life changing comics\" folder? reply lemper 1Baki the Grappler. reply hiAndrewQuinn 1oh hell yeah you&#x27;re my kind of guy. reply kayodelycaon 1Ooooo... a peanut butter banana bacon sandwich sounds awesome. reply HankB99 1I&#x27;ve done a PBBJ (peanut butter bacon jelly) but never a PBBB. Might need to try it. reply toomuchtodo 1Highly recommend. reply pmlamotte 1The time notification reminds me of a screenless \"watch\" 10 years ago. It would buzz every 5 minutes as a supposed aid in perceiving the passage of time for various tasks.https:&#x2F;&#x2F;www.theverge.com&#x2F;2014&#x2F;1&#x2F;30&#x2F;5361210&#x2F;skrekkogle-durr-t... reply TZubiri 1Mine is currently on a 15 minute loop as well, but it just plays prerecorded numbers from 15 to 0 telling me how many minutes left in my 15 minute time block reply abnry 1Yes, 30 minutes is a shockingly long time. I&#x27;d say 5 minutes makes a lot more sense. reply cableshaft 1Those are rookie numbers. You need to get that down to 5 seconds. reply cm2012 1Amateur. I have a neon sign that strobes every millisecond in front of my office chair. reply tarxvf 1How embarassing for you.I have a GPS disciplined rubidium clock with a 100MHz output hooked up directly to my sinuses. The slow sensation of waves washing ashore keeps me awake long enough to interact with the rest of you when I am taking my daily luxury 3ms break to read HN. Further, I have a script that, when my break time is over, automatically terminates any conn- replypmontra 1That is coincidentally similar to a pomodoro sprint: 25 minutes of work (compete with yourself) and 5 of something else. reply boringg Great for the upside of growth - how do you change it for when you start to age and skills erode a little bit. That would be deeply frustrating. Need to change the model at that point! What to though? reply swader999 The AI helps a bit, I&#x27;m feeling a bit recharged with it, like I have a few more extra years of capable contributing in me. Easier to get stuff done, not getting worn out with technical minutia as much.Move more into to people skills and relationships. It could be management, marketing, sales, HR, recruiting, mentoring, training. There&#x27;s a plethora of side functions. Or take a lower paying less demanding role. Do harder technical work that isn&#x27;t time constrained like open source or personal projects. reply smackeyacky Your skills don&#x27;t age like your physical body does. reply oaktowner 1That is true, but the rapid change in the tech industry makes \"skills\" mean something different than it would in, say, woodworking.Once you learn woodwoorking, you&#x27;re going to be good at it (until you lose strength, flexibility in your fingers, etc).In our industry, to &#x27;stay at the same place,&#x27; you continually have to learn new technologies, new concepts, etc. reply smackeyacky Computer programming isnt like woodworking though, its all in the mind reply KETHERCORTEX 1You are saying it like skills aren&#x27;t contained in that physical body. reply smackeyacky You can program using a blow stick if you have to. Its a mental ability not a physical one. Unless you get dementia you could do it forever reply Aeolun 1My existing skills don’t, but learning new ones sure takes more effort. reply bregma 1It&#x27;s not the effort of learning, it&#x27;s the effort of tolerating all the know-it-all newbies that increases. reply toastedwedge What does it mean in this context to compete against yourself? Anything at immediately at hand or on the todo list? Or is it just a reminder to get something done you thought of doing but normally wouldn&#x27;t otherwise? reply kayodelycaon 1I like it phrased this way: \"There is nothing noble in being superior to your fellow man; true nobility is being superior to your former self.\" reply carlivar I&#x27;ve become very fond of the phrase \"comparison is the thief of joy\" lately. This seems like a version of that. Keep your scope local only. reply bayindirh It means \"It doesn&#x27;t matter what other people do, are doing, or have achieved\". In other words, do not compare yourself to others.Do what you&#x27;re doing, a little better this time, then GOTO 10. reply bandyaboot 1If you find yourself becoming desensitized to the notifications on your phone, I suggest training a parrot to stand on your shoulder to liven it up. Great for parties too. reply hsavit1 1i suggest a new push notification on your phone that says \"be funnier\" - all the top comedians do it reply derealized > I found out that just being better than yourself takes you a long long way.That resonates with me.There is a saying where I&#x27;m from that says \"most people are just kicking dirt\" that basically means people are doing the bare minimum or don&#x27;t care at all, and if you just do your thing and really care about your stuff, you&#x27;re already ahead of the majority.Being anxious all the time, I use that saying in the opposite way though: just relax and do your thing... you don&#x27;t need to worry about not having a job, all those other people are barely doing anything and you can&#x27;t be the best at everytime. Just do your thing are relax. reply ryneandal 1> I found out that just being better than yourself takes you a long long way.I usually hold vast disdain for the \"self-help\" genre of books, but after a recommendation from someone whose opinion I value greatly, I read Atomic Habits by James Clear. I&#x27;ve never found myself agreeing with and finding revelations from such seemingly mundane and obvious statements. Sometimes seeing a statement or opinion you take for granted can make you cognizant of that point.I&#x27;ve since tried to adopt such \"agile\" methodologies in personal improvement. Clear says 1% improvement each day always sounds attainable, and such iterative improvements add up. reply majjam Would you mind expanding on what you mean by ‘dark developer’? I could guess from context but Id appreciate your definition if you dont mind. reply plaugg 90% sure it&#x27;s \"dark matter developers\" as in \"they never write blogs, they don&#x27;t go to user groups, they don&#x27;t tweet or facebook, and you don&#x27;t often see them at large conferences.\" - https:&#x2F;&#x2F;www.hanselman.com&#x2F;blog&#x2F;dark-matter-developers-the-un... reply bayindirh 1Yeah, that&#x27;s true. I have a blog, and share the code & docs I write for myself, but my blog is not about programming, and the docs are more like cheat sheets for general public.Well, the code is just GPLv3 licensed small tools which I develop according to my own needs. Nothing impressive.I don&#x27;t use Twitter, Facebook and Reddit anymore. I just converse here, and with a Discord server I really like. reply sanderjd 1I&#x27;m in a constant state of pendulum swing with this. (Not with the goal of being \"ground breaking\" or \"world impactful\", but just doing \"great\" work within the range of my own self-perceived capabilities.)When I first had children, my pendulum swung way over to disinterest in seeking anything in my work beyond financial support for my family and time to spend with them (while still supporting and not breaking trust with my professional colleagues).But my kids are growing and becoming more independent all the time, and I&#x27;m currently in a phase where my mental cycles and energy are on an upward trajectory over time, and now I&#x27;m back to being excited to use those cycles to do impactful work. But critically, I think, with significantly more wisdom about how to strike a healthy and happy balance for me and my family. I mean, I&#x27;m not naive, I don&#x27;t think it will be easy to strike a good balance, I think it require be constant work and effort at it. But as I&#x27;ve emerged from the baby-brained haze, I have renewed clarity that neither focusing my energy entirely on family or entirely on work is the right path for me. reply sam0x17 1> the probability of somehow being ground breaking and world impactful is ridiculously small.See I have the opposite take. There are so many damn facets of modern life&#x2F;society, and new avenues&#x2F;facets&#x2F;domains coming out every year, that it is actually pretty easy to find some niche where something hasn&#x27;t been done yet that is world-shattering for some specific community or niche.World-shattering for everyone is pretty overrated. reply taude Agree with you. I don&#x27;t understand the point of this article other than some sort of tongue and cheek snobbery. Hope it maybe made the OP feel better about themselves. reply surprisetalk Author here!For context, I recently wrote a tongue-in-cheek guide on how to coast in large companies.[0] https:&#x2F;&#x2F;taylor.town&#x2F;corporate-camouflageThat got me thinking about what happens when people, especially engineers, coast too much, or fail to plan out their careers.I know plenty of smart people that are enchanted by comfort, then chain themselves to companies that take advantage of them.If you&#x27;ve developed transferrable skills, this parable probably isn&#x27;t for you :)I personally think it&#x27;s okay to be ambitious, and it&#x27;s also okay to chill. reply nus07 I will not call it snobbery but a difference in generational culture. I am assuming you are below the age of 45 and came into the industry where jobs were aplenty , super low interest rates and the industry was rapidly innovating and risk taking is encouraged . For a lot of folks from the Office Space days of 80s and 90s that wasn’t necessarily the case . Tech jobs were limited and you probably had to post or submit a paper version of your resume. I would encourage you to take a look at JavaScript code from 2003 or a Java codebase from then and see how dreary and different the tech industry was back then . As for transferable skills there is a reason IT workers were stereotyped as autistic nerds before the brash,well rounded, rock climbing risk takers came in. Culture, risk, opportunities and interest rates had to do a lot .Edit- I was probably like Arthur Westbrook when I was working on a visa and had a family to support . As soon as I got my greencard my appetite for risk taking increased and showing my transferable skills increased . Situational context . reply sramsay Honestly, I just thought it was hilarious -- a sort of parodic counterpoint to the Story of Mel. reply HenryBemis I thought I was reading at The Onion!! reply nazgulsenpai You say tongue-in-cheek while, almost verbatim, summarizing my day-to-day strategy at $megacorp! Seriously great stuff. reply meesles This level of reaction tells me more about you than the author. Referring to it as &#x27;snobbery&#x27; shows that you interpret satire as a personal attack on someone, probably yourself. I clicked to their home page and immediately figured out that they dabble in tech and like to joke around.This is as much a tip for myself as for you: take a deep breath before reacting. reply Mashimo I think it was just a joke :) reply josephg > There are talented people everywhere, the probability of somehow being ground breaking and world impactful is ridiculously small.No there aren’t. For every Jonathan Blow, Salvatore Sanfilippo (redis) or Mike Pall (LuaJIT) there are probably thousands of run of the mill developers working at feature factories. You don’t build amazing software by being lucky. Your boss at GenericCo will never go out of their way to ask you to build that thing you’ve always been dreaming of making.You choose to work on software you find interesting. Or, for any of 1000 totally valid reasons, you choose to be small.If you think you’re all that, don’t blame your company for “not getting the opportunity”. Please. You already have all the tools you need to code. Make something cool! reply DoingIsLearning > No there aren’t.You underestimate the odds of talent in a population of 8 billion humans.> If you think you’re all that, don’t blame your company for “not getting the opportunity”. Please. You already have all the tools you need to code. Make something cool!There are neurosurgery robots operating with my code running in the background for several years now. I am now working on ophthalmic surgery software for sub-retinal operations. I would think that is actually kind of pretty \"cool!\".However, I still know full well that I am a cog in a big machine. I still know full well that my impact is not world shattering. And I still very much think \"fuck you pay me!\".My self worth is pinned by family and friends. Work is fun but it&#x27;s a side quest. If you think differently that is ok, and so am I. reply zimpenfish 1Stephen Jay Gould in \"The Panda&#x27;s Thumb\": \"I am, somehow, less interested in the weight and convolutions of Einstein’s brain than in the near certainty that people of equal talent have lived and died in cotton fields and sweatshops\"(whilst double-checking my memory of where that came from, I found the obligatory LinkedIn post using it as an advert for consultancy services: https:&#x2F;&#x2F;www.linkedin.com&#x2F;pulse&#x2F;einstein-cotton-fields-sweats...) reply josephg 1> There are neurosurgery robots operating with my code running in the background for several years now. I am now working on ophthalmic surgery software for sub-retinal operations. I would think that is actually kind of pretty \"cool!\".That’s super cool dude! Surgery robots are pretty world shattering for the people whose lives are saved by them. Contributing to that sounds like something well worth feeling proud of too. reply djbusby Surgery bots are cool. My software just keeps track of drugs reply notbeuller 1As someone that has relied on such devices to survive cancer - thank you. reply djbusby 1You must think I&#x27;m cooler than I really am. I don&#x27;t even do any devices. Just boring ass inventory control. reply DoingIsLearning There are a lot more drug infusions than there are surgeries so you win! reply constantly I don’t even know where to begin with this comment. It’s a gross mischaracterization of what was being said for starters. reply deely3 Its not a mischaracterization, its a projection: if you don&#x27;t do something that parent commenter believes is important then you are not important.Moral : before starting new job always ask parent commenter are this new job is important for him? reply josephg 1That’s not an accurate summary of my beliefs. Maybe this would be clearer:If you want to be interesting, choose to do something interesting. Luck is rarely the limiting factor in your creative output. reply deely3 Thanks for explanation.> If you want to be interesting, choose to do something interesting.Interesting for who? For you or for someone else? reply timacles 1Yea this is as classic fallacy.This famous talk outlines it: https:&#x2F;&#x2F;www.cs.virginia.edu&#x2F;~robins&#x2F;YouAndYourResearch.html but theres a huge amount of factors that go into becoming one of those guys.Its not just talent, or desire, or luck.Its: - Talent - obviously have to be really good to even do anything in the first place - Vision - Need to have a goal of some sort to accomplish something - Decision making - The goal needs to actually be something the world finds useful. - Drive - Be able to take constant set backs and negative feedback and believe in yourself to an almost delusional level. - Consistency - This means doing and thinking about your \"thing\" for a REALLY REALLY long time. Like weekends and holidays and ignore family and etc...The talk above goes into it pretty in depth, but theres no mystery about it. You need ALL those things and no less. People who achieve at this level aren&#x27;t accidents. They are simply not only talented in their fields, but also in areas of being able to consume volumes of information and handle failures. They&#x27;re the ones getting up at 6AM every day working and thinking about their \"problem\" and going to bed dreaming about it, for years.You can be a 10x developer, but you also need to be 10x in several other areas to actually accomplish valuable things. Theres a grand canyon of difference between them and everyone else. reply nightski Redis will bit rot. LuaJIT will bit rot. Jonathan Blow did make some fantastic games, but even then it&#x27;s in a sea of games that are pretty great. Everyone is pretty small in the long run. reply MattPalmer1086 The truth is almost certainly between those extremes. People who never put themselves in a place where they can do something amazing are obviously much less likely to do so.Equally, there are many, many talented people out there who never achieve recognition for what they do or were capable of. reply nervousvarun You may not want to hear this (I certainly didn&#x27;t when I felt similarly)...but perspective does change with age&#x2F;personal life...with all due respect do you have kids? A partner? Any major commitments outside work? That&#x27;s an enormous part of OP&#x27;s statement.People don&#x27;t stop being talented&#x2F;smart when they have kids&#x2F;families&#x2F;personal lives...but they will have less time and their perspectives do change.It&#x27;s a balance&#x2F;spectrum where most of us end up somewhere in between two cliches: do what you love and you never work a day in your life on one end & work to live not live to work on the other. reply digging 1Your response is completely out of line with what you were responding to. reply hgomersall Engineering is one of a few special disciplines where peoples&#x27; hobbies align easily with ability to earn money at most levels of professional performance; being mediocre is still a recipe for a generally acceptable standard of life. Compare it to things like sports or acting or music. It&#x27;s possible to make a living at the lower echelons (read: everything below elite level), but it&#x27;s hard work or mundane and often not well compensated. reply ecshafer 1While I love programming and computer science that is one of the reasons I chose programming over other fields. I figure if you want to be a journalist you’re basically broke unless you’re one of the top few that are also making money writing books or doing podcasts. If you’re a historian you are basically not doing well unless you are one of the top and get a tenure track professor position. If you are a programmer, and aren’t even that good, you have a comfortable life in the us. The bottom 20% of software jobs are still in like the top 75% pay range. reply a_c Have kids really bring things into perspective. Every moment with them is unique. reply weregiraffe Every moment without them is also unique. reply bflesch Having kids is such a traumatic, life-changing event. I mean this in the most positive way. I can see why so many people see this as the before&#x2F;after watershed moment of their lives and ambitions. However, it&#x27;s understandable that not everyone needs to have kids to come to this realization. reply lovecg For me it was the profound perspective shift from being a leaf node of a tree so to speak to becoming just one link in a long chain. It tends to relax the do-or-die drive quite a bit. reply ambicapter 1Maybe the do-or-die drive is relaxed because you (or your body) realizes that you&#x27;ve fulfilled your biological purpose and passed on your genes? reply Cthulhu_ It also makes it feel all the more exploitative that young developers are encouraged to work long hours and put their everything into their job. And that women are de-incentivized to have children by the market, if not capitalist society at large - don&#x27;t do it, it&#x27;ll cost you your career! We only give you two weeks of leave after you gave birth. You can&#x27;t afford child care, or all your wages would be spent on it! etc. reply OoooooooO That&#x27;s a US only problem though. reply Mashimo You don&#x27;t think it&#x27;s an issue in Japan or south-east Asia? reply Aeolun 1It’s not, really. Japan is absurdly good if the only thing you want to do is have children, and don’t care too much about how or where they’re schooled.1 year of leave per child, inability to get fired while on leave, free childcare.The only negative is that all those make advancement options for working age women 25-35 whom are expected to have kids ’soon’ nonexistent. reply Mashimo Oh sorry, I was talking about the \"young developers are encouraged to work long hours part\" not the after birth care. reply mensetmanusman 1Japan has the highest fertility rate in Asia now. SK is doomed economically over the next 50 years. reply frenchman99 1In France, women get 10 weeks & men get 4 weeks paid leave. reply kpw94 1This is surprisingly low for a country known for its long vacation! Especially the men.Here FAANG it ranges from 18 to 24 weeks for women, 12 to 18 weeks for \"non birthing parent\" (men, or adopting parents).There&#x27;s State-by-state paid family leaves laws, which makes it usually around 12 weeks (men or women). reply oytis You cannot fully appreciate your moments without kids until you have kids though. reply kerkeslager Why do people feel they can make sweeping assertions about other people&#x27;s experiences like this? You don&#x27;t know anything about the lives of the billions of childless people out there. Many of us have livestyles that wouldn&#x27;t be possible if we had children, and our \"moments without kids\" are totally, incomparably different from your moments without kids.The smugness of people with kids is just annoying. reply Aeolun 1> The smugness of people with kids is just annoying.The ability of people without kids to have a firm belief on how they’d feel with or without them is also astonishing.I doubt people with kids are smug about it. It’s just been life changing for them, and to some extend they must regret that other people will never get to experience that, especially if they were initially hesitant too.Anyway, fully agree it makes you appreciate your time more. I enjoy adjusting the flow of time to school age again, even if it’s not my own. reply kerkeslager > The ability of people without kids to have a firm belief on how they’d feel with or without them is also astonishing.First he tells me how I feel, now you&#x27;re telling me what I believe?I don&#x27;t know how I&#x27;d feel if I had kids. What I do know is that I \"fully appreciate my moments without kids\".If a non-parent told you that you can&#x27;t truly enjoy your free time because you have kids, wouldn&#x27;t that be a bit rude? reply matsemann 1People with kids have also been people without kids at some point in their life. So I&#x27;d guess they know both perspectives.I didn&#x27;t read their comment as smugness. reply oytis 1Maybe I should be smugger about myself having kids, but it was really meant as nothing else as a lightheaded remark. From my own perspective of course - there is clearly my (nick)name over it. reply kerkeslager Sure, and if it was just your comment it wouldn&#x27;t annoy me. But these sorts of comments about non-parents from parents are constant. I totally parents that they enjoy having kids--why is it so implausible to parents that I can equally enjoy not having kids? reply a_c 1I can relate. Sometimes they are pure abomination. reply oytis 1Lighthearted. I meant to write \"lighthearted\". Anyway. reply digging 1They know two perspectives. Both from their own point of view. reply dotnet00 1This is stated as if the only way for someone to experience kids is to have their own.I didn&#x27;t need to have my own kids to appreciate the peace of not having them (although at some point I do still intend to have kids, just not soon). I just had to frequently babysit my niece and nephew.Nowadays I visit them only for a few days every few weeks and even then it&#x27;s blatantly obvious that kids would mean a sharp drop in my ability to have as many different projects and hobbies as I do right now, for at least 5-10 years. Makes me really appreicate my moments without kids, as much as I also appreciate being able to see my niece and nephew grow and develop into their own selves. reply a_c 1To me I enjoy every moments with my children. Not only enjoyment, I couldn&#x27;t have imagined how much I&#x27;m learning from them and I&#x27;m experiencing life so much fuller now. For one example, empathy, all the books about how to be empathetic can&#x27;t make me a bit more empathetic. My children do. Another example being learning to listen, it is humbling to have your children asking you to listen them more. Ok, one last example is gaining inner peace of people not \"understand\" you. It happens in work place a lot that sometimes seemingly good idea goes unheard. There are lots of things I can share with my young. It is okay if they don&#x27;t understand now. And I&#x27;m learning from them too so what I think I know might not matter 10 years down the road. Live the momentThe rational side of me tell me it is all my selfish gene in action. And I&#x27;m loving it. reply lolsal 1It seems tragic to me that you had to procreate to appreciate your time on earth. I am grateful and thankful for every moment. Life is full of wonder to me without the burden of children. reply ryneandal 1It appears you&#x27;re grossly misinterpreting his statement. When you have children, you treasure alone time _that much more_. That&#x27;s his meaning.It isn&#x27;t some desperate plea like you&#x27;re implying. reply mensetmanusman 1Appreciation has a range of values. Having kids for many people is like going from black and white to color TV. reply suslik 1Maybe - but I don&#x27;t have to. I&#x27;m happy enough as it is to not have children. I don&#x27;t need to loose a leg to enjoy going for a run either. reply digging 1Yes I can. That&#x27;s why I don&#x27;t have kids. reply tacitusarc Everything is unique, but some are more unique than others. reply falcor84 Some dichotomies are more dichotomous than others. reply throwaway14356 it is all the same to me reply duxup Maintenance doesn&#x27;t get enough respect &#x2F; glory too. \"Arthur\" should be highly thought of.Folks writing new code in the wonderfully free world without a ton of odd dependencies and corner cases ... IMO often aren&#x27;t doing as much \"work\". reply lolsal Writing new code with no existing constraints or requirements isn’t some masterful feat of engineering, usually.Working in an existing code base, on a team with multiple features going in, gathering requirements from stakeholders and negotiating deliverables on a timeline while refactoring is happening, libraries being upgraded and CVEs being fixed - navigating all of that while being a useful, compassionate team member - that’s priceless on a team. reply lusus_naturae You&#x27;re just going to off load your lost potential and lack of ambition on to your kids, and so on and so forth. It&#x27;s the main reason why people have them. reply SanderNL You&#x27;re being negged into oblivion, but you have a point.There is \"I&#x27;m OK with my pedestrian job but I still try to do my best and actually like the people there\" and \"my job sucks all joy out of my life and provides me with nothing of value except money\".I have kids, but I somehow skipped the \"I want to be the best\"-phase and went straight to \"I&#x27;ll make do with whatever you give me\" so nothing really changed. I actually work a bit harder now so my kids can see work is good - also to pay for their fancy shit.Even stupid jobs can be sources of relative joy if you let them. Don&#x27;t put up with abuse of any kind, though. reply wiz21c The opposite is no good. I had 1 or 2 opportunities which a lot of people of my age were looking at with envy. I was not super gifted but they came out of passion: by working on the things I loved relentlessy, I ended up being noticed. I was good because I worked a lot. It was not hard work since it was stuff I enjoyed a lot to do, but I spent countless hours on it (about 25-30 hours a week in addition to my studies or day time job).Problem with the kids is that when I tell them about that, they feel they don&#x27;t have enough passion to succeed. So you see, eventhough I was on the right side of success for a while, it scares the hell out of them... reply vdqtp3 1> they don&#x27;t have enough passion to succeedThen they should find something they are passionate enough about to succeed. reply baz00 I mostly had my kids because I was drunk. reply generic92034 1Boredom is another common reason. ;) reply Aeolun 1Well, if nothing else, it certainly solves that problem. reply mlinhares 1So true, I wish I had this perspective before having kids as well, I was so focused on the rat race and on \"being the best\", to the point of being hospitalized with intestinal problems. Now I have a great job, that gives me joy but the two things i care the most in life are my two little devils. reply i_am_a_peasant 1I also went from dreaming of being the best at 1 thing to \"fuck you pay me\" in a hilariously short time.10 years of being underpaid and yet being the most productive guy at work will do that to you. reply sspiff I largely agree. My goals have shifted from having an impact moving the technology world forward to not being frustrated and depressed from work and getting enjoyment and satisfaction from personal small projects with no deadlines.Since having kids, most of these have shifted from a few months in time to a few years, but they are unambitious, poorly defined and unimportant so who cares if they take a little longer?My main goal at work is not getting annoyed or frustrated and getting paid well for my time. reply lo_zamoyski 1It was once said that the national anthem of Hell is \"My Way\", and that the motto over the main gate reads \"Do what thou wilt\".Pride, radical individualism, self-promotion. These are extremely common today, especially in the US (just compare an American resume with a European CV). Both the US and Europe have their problems, but this particular obsession tends to be more conspicuous in the US. Paradoxically, it doesn&#x27;t bear the desired fruit because it misunderstands the nature of personal excellence.This isn&#x27;t a vote for collectivism or mediocrity. Only dead fish float downstream. It&#x27;s a vote for the notion that the riches of society are the result of countless incremental contributions up and down the hierarchy of value for the sake of the common good. But lib",
    "originSummary": [
      "Software developer Arthur Westbrook is retiring after a 35-year career working with a codebase for medical software.",
      "Westbrook is highly regarded for his expertise in working with legacy code and has made significant contributions to the codebase.",
      "His retirement will require the hiring of two junior developers to fill his role, highlighting the impact he has had on the project.",
      "In recognition of his service, a coworker plans to treat Westbrook to drinks.",
      "During retirement, Westbrook plans to pursue street performance, dumpster diving, and culinary experimentation."
    ],
    "commentSummary": [
      "Hacker News forum discussions cover a wide range of topics including working with outdated technologies, transitioning to new jobs, high-frequency trading, work-life balance, retirement, skill development, talent in software development, the impact of having children, and finding fulfillment in one's job.",
      "The conversations on the forum provide diverse experiences, perspectives, and insights into societal pressures related to the tech industry.",
      "The discussions on Hacker News offer valuable insights and perspectives for software engineers and individuals interested in the tech industry."
    ],
    "points": 805,
    "commentCount": 536,
    "retryCount": 0,
    "time": 1691062111
  },
  {
    "id": 36988262,
    "title": "Hackers manage to unlock Tesla software-locked features",
    "originLink": "https://electrek.co/2023/08/03/hackers-manage-unlock-tesla-software-locked-features/",
    "originBody": "Skip to main content Go to the Electrek home page Switch site Toggle social menu Toggle dark mode Toggle search form Exclusives Autos Alt. Transport Autonomy Energy Tesla Shop TESLA Hackers manage to unlock Tesla software-locked features worth up to $15,000 Fred Lambert  | Aug 3 2023 - 8:44 am PT 72 Comments A group of hackers have exposed an exploit that can unlock Tesla’s software-locked features worth up to $15,000. Free heated seats and Full Self-Driving package, anyone? Software-locked features that need to be activated by the owner paying or subscribing to a service are becoming increasingly popular in the auto industry. Tesla has been on board that trend very early since it produced virtually all its vehicles with the same hardware and owners can unlock features later through software updates. This includes features like heated seats, acceleration boost, and even Tesla’s Full Self-Driving package, which costs $15,000. It creates a market for people trying to get around the software lock. A group of security researchers (aka hackers) at TU Berlin announced that they managed to exploit a weakness in the onboard computer to unlock these features: Tesla has been known for their advanced and well-integrated car computers, from serving mundane entertainment purposes to fully autonomous driving capabilities. More recently, Tesla has started using this well-established platform to enable in-car purchases, not only for additional connectivity features but even for analog features like faster acceleration or rear heated seats. As a result, hacking the embedded car computer could allow users to unlock these features without paying. They plan to unveil the result of their exploit in a presentation called “Jailbreaking an Electric Vehicle in 2023 or What It Means to Hotwire Tesla’s x86-Based Seat Heater” next week. The hack requires physical access to the car, and it involves a “voltage fault injection attack” on the AMD-based infotainment system: For this, we are using a known voltage fault injection attack against the AMD Secure Processor (ASP), serving as the root of trust for the system. First, we present how we used low-cost, off-the-self hardware to mount the glitching attack to subvert the ASP’s early boot code. We then show how we reverse-engineered the boot flow to gain a root shell on their recovery and production Linux distribution. The group of hackers claims that their “Tesla Jailbreak” is “unpatchable” and allows to run “arbitrary software on the infotainment.” They add: Second, it will enable us to extract an otherwise vehicle-unique hardware-bound RSA key used to authenticate and authorize a car in Tesla’s internal service network. Top comment by Dr. Chaos Liked by 35 people I can see having users pay for advanced software like FSD (if it actually works), but paying to turn on hardware that already exists in the car is a couple of steps too far. It's as if the car owner doesn't own his own car. Lame. View all comments Ultimately, the hackers believe that they can unlock virtually all software-locked features inside Tesla vehicles even Full Self-Driving – though they believe that it would require some more reverse-engineering. Electrek’s Take Generally, these exploits are shared with Tesla, and it helps the automaker secure its systems. In this case, the hackers said that despite the exploit, they believe Tesla’s security is better than other automakers. We have seen Tesla put a lot more emphasis on cyber security over the last few years. We highlighted the effort in our report: The Big Tesla Hack: A hacker gained control over the entire fleet, but fortunately he’s a good guy. Add Electrek to your Google News feed.   FTC: We use income earning auto affiliate links. More. Stay up to date with the latest content by subscribing to Electrek on Google News. You’re reading Electrek— experts who break news about Tesla, electric vehicles, and green energy, day after day. Be sure to check out our homepage for all the latest news, and follow Electrek on Twitter, Facebook, and LinkedIn to stay in the loop. Don’t know where to start? Check out our YouTube channel for the latest reviews. Featured from Electrek slide 1 to 2 of 4 Tesla and Rivian are heading to court over ‘stolen trade secret’ claims Fred Lambert Aug 2 2023 Watch a Rimac Nevera take on a Bugatti Chiron SuperSport and Tesla Plaid in a wild drag race Peter Johnson Aug 2 2023 The first Tesla (and first EV) to drive around the world is doing it again now Jameson Dow Aug 2 2023 Subaru shifts focus to EVs with plans for eight electric models by 2028 Peter Johnson Aug 2 2023 Subscribe to Electrek on YouTube for exclusive videos and subscribe to the podcast. Comments EXPAND COMMENTS Guides Tesla Tesla is a transportation and energy company. It… Author Fred Lambert @FredericLambert Fred is the Editor in Chief and Main Writer at Electrek. You can send tips on Twitter (DMs open) or via email: fred@9to5mac.com Through Zalkon.com, you can check out Fred’s portfolio and get monthly green stock investment ideas. Fred Lambert's Favorite Gear Zalkon Green Stock Ideas Get interesting investment ideas by Fred Lambert ChargePoint Home charger ChargePoint Home WiFi Enabled Electric Vehicle (EV) Charger",
    "commentLink": "https://news.ycombinator.com/item?id=36988262",
    "commentBody": "Hackers manage to unlock Tesla software-locked features | Hacker NewsHacker News new | comments | ask | show | jobs | submitloginHackers manage to unlock Tesla software-locked features (electrek.co) 768 points by 1970-01-01 17 hours ago| 691 comments vessenes 1Pretty sophisticated attack vector: low voltage attack on AMD secure execution environment during boot. I wonder how many tries you need to get whatever bits you need in the right place. Also, I imagine you only need to cut 12V wires to do this, but I admire the willingness to get in there direct on these systems. I&#x27;d be a little nervous to make those cuts personally.Buried in the article is the claim that this will let them pull the RSA private key the car owns out for other uses -- while this is likely to remain a very niche attack vector, that&#x27;s got to be really bad news for someone in vehicle security at Tesla. On the other hand, post jailbreak you could anonymize your location on Tesla&#x27;s servers, which would be nice. reply ddalex 1> you could anonymize your location on Tesla&#x27;s serversI already anonymise my location on Tesla&#x27;s servers by simply not owning a Tesla reply coolspot 1Your car is filmed and recognized by other teslas. reply jcuenod 1That&#x27;s why I also rotate license plates and repaint my car twice a year. reply culi 1you&#x27;re joking, but there&#x27;s a whole genre of \"adversarial fashion\"[0][1] dedicated to making clothing that spams these sort of public data recognition services. Hoodies with license plates, face masks with weird facial features, etc. Often optimized against actual neural networks too[0] https:&#x2F;&#x2F;adversarialfashion.com&#x2F;[1] https:&#x2F;&#x2F;www.capable.design&#x2F; reply syx 1That’s really cool, I wonder effective these designs really are! This reminds me of a font that came out 10 years ago ZXX [1] that was presumably designed to hide from OCRs.[1] https:&#x2F;&#x2F;www.businessinsider.com&#x2F;zxx-fonts-that-google-cant-r... reply rapnie This is really cool. Though the Capable Design site with its animations is a bit adversarial to me browsing it. reply pests Gait detection renders any of this obsolute sadly. reply kibwen If you&#x27;re willing to go to the lengths of adversarial fashion, you&#x27;re probably also willing to walk around with a stone in your shoe, or in high heels. reply bbarnett Pfft. Stilts, 10 footers, that&#x27;s the key. reply xattt A third pant leg sown on one side with a rock on the bottom will (probably) throw off some algos. reply blackrobot This is a good idea! https:&#x2F;&#x2F;youtu.be&#x2F;BNhriA2xq9E reply berniedurfee Something something silly walks reply squarefoot You beat me to it:)Context: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=eCLp7zodUiI reply rasz 28 gait analysis is up there with bite marks(https:&#x2F;&#x2F;www.theguardian.com&#x2F;us-news&#x2F;2022&#x2F;apr&#x2F;28&#x2F;forensics-bi... )&#x2F;jeans wear marks(https:&#x2F;&#x2F;www.pnas.org&#x2F;doi&#x2F;10.1073&#x2F;pnas.1917222117) and other FBI post hoc ergo propter hoc fraud.If it worked this would be a solved case https:&#x2F;&#x2F;www.fbi.gov&#x2F;contact-us&#x2F;field-offices&#x2F;washingtondc&#x2F;ne... reply paradox460 Put different insoles in your shoe every day reply gonzo41 And cost at scale renders gait detection detection and most face detection at scale useless. The sexy movie detection methods all suck.Go with what works. Just id people via their phones with a dirtbox. reply downWidOutaFite Luckily my gait is not in an adtech company&#x27;s database and sold to the government, like my face probably is. reply bbarnett How do you know?ID phone Bluetooth on passing, or even facial rec, then it gets tied to gait, and it&#x27;s forever tied. reply steve_adams_86 This made me realize that recent openAI tech is able to cut through misleading or confusing images, even finding the potentially inferred humour or absurdity layered in the images. I wonder how we’ll find a way to trick that kind of technology as well. reply jliptzin I wonder how effective that is considering storage costs are very cheap and an AI can easily filter out images that are either “car” or “not car” reply JohnBooty 1This is awesome, and thanks for posting this. I had no idea. reply knodi123 1That&#x27;s why my license plate is shaped like 3 different light bulbs, and is hidden in a grid of light bulb shaped objects. reply zoky 1Oh hey, I just did your license plate as a CAPTCHA! reply seanmcdirmid This is actually a common practice. Thieves will jack someone’s plates (prefer that they don’t notice) after stealing a car. It is pretty effective, since most people don’t realize their plates have been swapped until they have been pulled over for vehicle theft, so the cops aren’t even looking for the right plate for a few days, and by then they’ve already swapped again.Better put an apple tag in your car just in case. reply rasz 31 You use license plates? pleb!Why Steve Jobs Never Had License Plates on His Car https:&#x2F;&#x2F;abcnews.go.com&#x2F;Technology&#x2F;steve-jobs-car-apple-ceo-l... reply zapdrive 1I also change my facial hair style 4 times a year. Will start getting plastic surgery twice a year starting next year. reply jancsika 1That&#x27;s why I wear an rpi connected to four lcd&#x27;s on my face that display randomly chosen beard tiles.It&#x27;s also why I started Our Lady of the Anonymity Pool where we gather for music and fellowship, and to recharge and distribute beard screens to our congregants and visitors. reply alinaval 1Phillip K Dick imagined a \"scramble suit\" that did just that in a Scanner Darkly, continuously randomizing the users facial features. reply brenainn The film has a good representation of it: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=2aS4xhTaIPc reply Jerrrry This is currently possible in real time on consumer mobile hardware, looks neat reply wongarsu 1Against face recognition you could use CV dazzle makeup [1] to look less like a face. However I wouldn&#x27;t recommend using that approach for your vehicle1 https:&#x2F;&#x2F;dangerousminds.net&#x2F;comments&#x2F;foil_facebooks_facial_re... reply vondur 1I wonder how the face painting antics of Death Metal bands would hold up to face recognition software? reply Accacin 1Sorry for being pedantic, but it&#x27;s usually Black Metal bands that wear the face paint that you&#x27;re thinking of :) reply fho 1I think that&#x27;s actually quite common on new car models. The dazzle paint job makes it harder for the press to see the shape.E.g.: https:&#x2F;&#x2F;www.bmw.com&#x2F;en&#x2F;automotive-life&#x2F;prototype-cars.html reply rascul 1I vaguely recall reading (probably in the book All Corvettes Are Red) that the C5 Corvette was driven around with Camaro body panels to fool the media. reply zapdrive 1I don&#x27;t want my car \"harder to see\" going at 100 miles down the highway. reply myself248 1Oh no, it&#x27;s super easy to see, just harder to tell if it&#x27;s a coupe or a sedan or whatever. New lines in the body panels get drowned out by the pattern, etc. reply ukd1 1I always wondered if this still worked with a IR&#x2F;UV camera too...? replymcbuilder 1I just inked an adversarial CV tattoo onto my face, worked great until that image leaked into the training data. reply zapdrive 1Should have tattooed a QR code that auto downloads a malware that bricks A100s. reply 867-5309 1sounds like a slippery slope to voluntary hip surgery for gait correction reply silisili 1Not sure if it&#x27;s changed now, but just wearing flip flops used to defeat gait recognition... reply cool_dude85 1I always wondered if this could be beat by putting a pebble in your shoe or something. reply fleshdaddy It’s been a long time since I read it but I think that’s exactly how it was beat in Cory Doctorow’s novel Little Brother. replyholri That is why I ride a bicycle. reply closewith 1That can&#x27;t be legal? Not in the EU, anyway. reply ballenf 1Are you saying dash cams are illegal broadly there? reply anamexis 1In Germany, dash cams specifically are a bit of a gray area, but for example CCTV of any public areas is generally illegal.https:&#x2F;&#x2F;europe.autonews.com&#x2F;automakers&#x2F;tesla-warns-its-camer... reply someplaceguy 1I think EU countries are supposed to be using the same legal privacy framework, although the exact way the laws are phrased and interpreted might differ from country to country.I believe in Spain, generally speaking, it is legal to record your interactions with someone when you are in public.But I think many people are not aware that this is legal, including some police officers, because privacy laws are perceived to be quite strict.Similarly, I think dashcams are actually legal, even though most police probably think they are not.I think these recordings can even be used in court cases, and in fact in many cases it&#x27;s probably the reason why they are legal, otherwise it would be hard to see a legitimate purpose that would override the privacy drawbacks.However, there are restrictions. Indiscriminate recording (i.e. CCTV) of public areas is illegal, as in Germany. This is also true for the entrances of personal homes: you are only allowed to have CCTV outside if it&#x27;s pointing directly at your door, not the street in general (and you must post a sign).An obvious restriction is that I think you are not allowed to publish a recording without either anonymizing the people in them or getting their permission.An interesting restriction that comes to mind is that a few years ago, there was a court case of a man who was caught filming children on a school playground while positioned outside the school, which at the time it was presumed to be for sexual purposes, I think because of the way he was doing the recording (big lenses, I think?) and because he didn&#x27;t have a legitimate motive for doing that (like being the parent of one of the children, or filming a documentary, etc).He was sentenced and received a large fine, but I think the legal reasoning was that children on a school playground are expected to have a legal right to privacy, even though it&#x27;s a public school. So the judge considered it the legal equivalent of filming someone in their private home from outside.I&#x27;m very happy for cases like these where common sense prevails over legal &#x2F; ideological dogma (even though I&#x27;m also aware of the dangers it can pose when laws aren&#x27;t interpreted to the letter). reply someplaceguy > you are only allowed to have CCTV outside if it&#x27;s pointing directly at your door, not the street in general (and you must post a sign).I forgot to mention that I highly disagree with this restriction.It&#x27;s really, really bad for home and personal security: pointing the CCTV at your door does absolutely nothing when a robber &#x2F; kidnapper enters your house while wearing a ski mask.However, pointing the camera outside could much more easily record their identity in the days previous to the crime while they were staking the house (even if they only get caught after the crime), as obviously it&#x27;s not very feasible to stake a house wearing a ski mask.Or at least, it would deter them much more heavily and possibly prevent a not-insignificant proportion of kidnapping cases, since most of them seem to occur in people&#x27;s own homes, which seems to be the easiest choice.I am similarly an extremely big critic of self-defense laws in European countries, which basically leave you completely defenseless in your own home even if you or your family are being kidnapped, due to the huge asymmetric advantage that an attacker has over you.Or at the very least, you risk going to jail for many years if anything goes wrong. reply gnatolf A vast majority of kidnappings are done by family members. It&#x27;s a movie thing that a ski mask vigilante enters your home to kidnap you. I&#x27;m almost 100% positive there&#x27;s virtually no risk of being kidnapped at home by ski-mask wearing criminals that staked your house previously.Or, if you are in that specific, very small target group for e.g. ransom etc, you probably should&#x27;ve been investing in home security beyond a front door camera anyways. reply someplaceguy > Or, if you are in that specific, very small target group for e.g. ransom etc,I am, as are many thousands of other people, in different fields. Although some of my personal circumstances contribute to my risk being especially high, even within these fields.> you probably should&#x27;ve been investing in home security beyond a front door camera anyways.I have, to an extent that has been called unreasonable by multiple \"normal\" people, and these people are not even aware of 90% of the security measures I&#x27;ve taken, including the best ones. Fortunately, my closest family has always been highly supportive in this endeavor.And these measures are not even half of the recommendations I&#x27;ve been given by security professionals who have scrutinized my life with a fine-toothed comb. Some of these recommendations I&#x27;ve chosen not to take due to not being too adapted to my personal circumstances and lifestyle, but others were amazingly good, far beyond what I expected.That said, the camera issue, gun restrictions, and strict self-defense laws in Europe are huge limitations that all contribute to vastly decreased personal security for me and my family. And I&#x27;ve been advised by experts in this area, so it&#x27;s not like I&#x27;m setting an unreasonably high standard. I&#x27;m also generally anti-guns, but alas, in some cases their benefits outweigh their disadvantages (otherwise police wouldn&#x27;t carry them) and I think gun laws in Europe don&#x27;t contemplate this type of situation very well.It&#x27;s also a fallacy to think that there is any single set of measures that will protect you. It&#x27;s not like you can just hire a bodyguard and suddenly you are safe, in fact this can make things even worse in some circumstances.Physical security can be as much about being careful, having plans in place, keeping a low profile and adding security layers &#x2F; friction &#x2F; risk &#x2F; deterrents as other forms of security such as infosec. In fact, infosec is also a part of physical security nowadays, as well as other similar measures.But of course, you can&#x27;t just add every possible security measure, either due to cost or friction &#x2F; unpleasantness. As an example, almost nobody would like to literally live in a bunker, if you know what I mean.Also, don&#x27;t forget to consider that even when you have great home security, it can be very, very easy to bypass it. Even very famous celebrities with great security teams have been kidnapped in modern times, although many of these cases are unknown to the general public. You&#x27;d probably be surprised! And that&#x27;s only the cases that have been made public, most of them are probably not even made public.Furthermore, your closest family members may not be able to be as vigilant as you, for many different reasons. And it&#x27;s not even possible to be 100% vigilant all the time, it&#x27;s extremely easy to get complacent over the years or make mistakes that decrease your security.To add to all that, attackers have a huge asymmetric advantage during an attack, as they have the surprise element. reply hutzlibu \"gun restrictions, and strict self-defense laws in Europe are huge limitations that all contribute to vastly decreased personal security for me and my family\"Even in germany it is quite easy to legally own a gun. All you have to do is be a member of a Schützenverein (\"shooting club\") for some time.What is indeed very hard, is get permission to carry a gun with you.But your main point seems to have been about home security and having a gun in your home is very possible. Unless you live somewhere with tighter gun laws than germany?(Also most abductions for ransom happen outside, easier to snatch someone from the road, than come into his home)\"To add to all that, attackers have a huge asymmetric advantage during an attack, as they have the surprise element.\"But you can also surprise them with security, they were not aware of and after that initial attack advantage, time is on your side. (Emergency call and panic room).\"It&#x27;s not like you can just hire a bodyguard and suddenly you are safe, in fact this can make things even worse in some circumstances.\"Yeah, because a common bodyguard mainly creates visibility. And the best defense is to not let the attacker know you exist as a target. But there are security guards, that are not visible to the bystander.And all in all I have to say, that you do sound quite paranoid. And I cannot think of too many professions, where that paranoia in europe is warranted and where you do not have professional security assigned to you, or where you do in fact get permission to carry a weapon. If the walls you build around you are too tight, you eventually just build your own prison. reply someplaceguy 15 > But your main point seems to have been about home security and having a gun in your home is very possible. Unless you live somewhere with tighter gun laws than germany?No, you are completely right, I had forgotten about that possibility!Indeed, my main worry with gun laws in Europe is about home security, where the advantages can outweigh the benefits if you have a high risk profile, not about carrying them in public which I think could lead to other problems.The hunting gun is much better than nothing, that&#x27;s for sure!> (Also most abductions for ransom happen outside, easier to snatch someone from the road, than come into his home)From my experience (i.e. the many cases I&#x27;m familiar with, not that I&#x27;ve been a victim), this is not true, although I&#x27;m also familiar with cases like you describe.But perhaps I&#x27;m simply not familiar with the cases that you know about, or about general statistics. I&#x27;m more familiar about cases similar to my risk profile.> But you can also surprise them with security, they were not aware of and after that initial attack advantage, time is on your side. (Emergency call and panic room).There are scenarios of home invasion for kidnapping purposes that I&#x27;m familiar with, which have really happened in Europe not too long ago, and which are impossible to defend against without extreme measures or very significant lifestyle changes, even taking into the account what you just mentioned (which I&#x27;m obviously familiar with) but I really don&#x27;t feel comfortable sharing more information.> Yeah, because a common bodyguard mainly creates visibility.Indeed, but even ignoring that (and the cost which is usually not a problem in these circumstances) there can also be quite a few more drawbacks that you didn&#x27;t mention, but again, I don&#x27;t really want to get into it.> And the best defense is to not let the attacker know you exist as a target.Not always possible, but completely agreed in-so-far as you can achieve that as much as possible!I consider this to be one of the most important goals, assuming you are not a famous person already.But even then, over the years there have been literally dozens of people who have become familiar with the riskiest part of my situation due to things that are completely outside my control, like different types of legislation which actually force me to disclose the most critical parts of my personal information to dozens of strangers for different (although usually similar) reasons.Several databases also contain this critical information.These strangers I mentioned are unlikely to lead to problems themselves, but information can travel easily or be leaked, and it&#x27;s still an increase in risk.> And all in all I have to say, that you do sound quite paranoid.Yes, I&#x27;m 100% aware of that :) Don&#x27;t think I haven&#x27;t been told this by many people who are not entirely familiar with my situation.That said, all of the people who have been aware of the details of my situation have shared exactly the same worries as me, and this includes people who have motivation to tell me the harsh truth rather than simply humoring me.But of course, I try to share all of my details with as few people as possible, for obvious reasons.In these kind of high-risk stakes, I make sure to really seek honest feedback rather than confirming my biases, because I just want to get the most useful information to make the best decisions I can, accepting that I can be very ignorant about things which I knew almost nothing about (like physical&#x2F;personal security). The professionals who have assessed my situation have been really clear about all the stupid, unrealistic worries that I had, as well as all the things that I should be really worried about. They have also provided me with a numerical estimate of my personal risk (hopefully much less biased than my perceptions), along with justifications.Yeah, I know I may be unreasonably paranoid, but on the other hand, are you really paranoid if they are really out to get you? lol!> And I cannot think of too many professions, where that paranoia in europe is warranted and where you do not have professional security assigned to you, or where you do in fact get permission to carry a weapon.Indeed, but there are many drawbacks to the solutions you are proposing and not many benefits in my particular situation, although I admit my situation is unusual. But really, I am already sharing more than I am comfortable with.> If the walls you build around you are too tight, you eventually just build your own prison.Indeed! That&#x27;s why you need a good balance and accept some risk, because it&#x27;s simply not possible to completely avoid it. But since I could afford to, I couldn&#x27;t help to take the most reasonable and highest low hanging fruit steps I could take to protect my family, under the circumstances.Imagine not caring very much and then something really bad happens to your child or spouse, how would you feel?This actually touches on something I was told by the security professionals I mentioned: some (although very few) of the security measures we&#x27;ve decided to take don&#x27;t actually provide a meaningful amount of security, but even a tiny incremental improvement disproportionately contributed to us becoming more worry-free &#x2F; experiencing greater piece of mind and being happier (but of course, this only works if it doesn&#x27;t continuously affect your quality of life).And the other thing to mention is that some things are simply outside our control, so there&#x27;s nothing you can do about that and there&#x27;s no point in obsessing over it, it&#x27;s just something you have to accept. I think we have been extremely good in this area.So I am happy to report that after the initial effort was finished (which lasted a few months), we have been able to live with a lot less worries and almost no decrease in quality of life for quite a few years already :) singpolyma3 CCTV&#x27;s only purpose for home security is for possible intruder to see it and decide to not intrude. If they come in and you get them in vidi then what? Who will you show it to? Police? What are they going to do? reply someplaceguy > CCTV&#x27;s only purpose for home security is for possible intruder to see it and decide to not intrude. If they come in and you get them in vidi then what?If your CCTV can only film inside your house, it will not be able to record the identity of a sophisticated attacker.> If they come in and you get them in vidi then what? Who will you show it to? Police? What are they going to do?If you are able to record their identity (this is much more likely if you can film outside your house, within an area they would use to stake it), then there are several advantages:1. Even if you are kidnapped or your house is robbed, it is more likely that the attacker&#x27;s identity will be recognized, either during this attack, before another attack or even after they are caught in another attack, which would help to increase their sentences.The chance this will help stop the current attack is minor, although not impossible if law enforcement acts in an expertly fashion (huge \"if\", I know).2. For the same reasons above, it is also a huge deterrent, as it greatly increases the risk of the attack (for the attackers, of course), so it also helps to prevent you from being attacked.3. Furthermore, it shows that you have taken security measures and therefore will increase the chance that the attackers will choose an easier target rather than you. reply chemmail Not to worry, chinese made cams broadcast everything for everyone on the internet to see. Nothing closed circuit about that! reply closewith 1Dash cams are much more tightly regulated in the EU than elsewhere (you become a Data Processor and have all the responsibilities that comes with that).Private ANPR in public spaces is unlawful in I think every EU state? reply liber8 1Coming from an American perspective (where, when you are in public, you have basically no expectation of privacy), this seems insane.Does this mean that if I&#x27;m filming a vlog at Brandenburg Gate (which inevitably includes video of other people in the background enjoying the area), I&#x27;m in violation of privacy laws?Does that mean if I take a video selfie of me and my family members (which, again, includes images of others in the background, and which is automatically uploaded to icloud) I&#x27;m a data processor and am in violation of privacy laws?I assume there is some line here, but I can&#x27;t think of the logic separating a person&#x27;s dashcam from my examples? reply avar 1The European perspective is broadly to have the \"freedom from\", whereas the American one is the \"freedom to\".You&#x27;ve got the freedom to aquire an arsenal, I don&#x27;t, but I prefer the freedom from other people gunning down my kids, which by extension limits the narrow personal freedoms of myself and others.Likewise, the American perspective is to draw a hard line on \"in public\", the European one is more nuanced.Yes, you can film your vlog without fear, but a random pedestrian in Berlin also has the freedom from being associated with your public vlog.Therefore you have a responsibility to either get their permission to broadcast it, or to anonymize them.A useful way to think about it is to shift your view from \"can I do X?\" to \"will I bother anyone else by doing X?\". reply caf A useful way to think about it is to shift your view from \"can I do X?\" to \"will I bother anyone else by doing X?\".I don&#x27;t think that&#x27;s particularly useful, because the answer to the second is trivially Yes, regardless of the value of X. reply avar 51 Are you suggesting that someone could shut down all human activity on the European continent by declaring that everything bothers them? reply ux-app >the answer to the second is trivially Yes, regardless of the value of Xthen don&#x27;t do it? reply hutzlibu There are still many people bothered by the fact, that I as a men have long hair.I am sorry to dissapoint you and those people, but for now I keep my hair.You cannot please everyone and I think it is a path into madness to even try it. There are maaany things people feel bothered about … reply filoleg Your response to \"by that metric, essentially almost everything is disallowed\" is \"well yeah, just don&#x27;t do it\". I don&#x27;t think that stance would sit well with most. reply codedokode 1> Does this mean that if I&#x27;m filming a vlog at Brandenburg Gate (which inevitably includes video of other people in the background enjoying the area),I don&#x27;t know about the law in Germany but I think it is very impolite in any country. You should ask people&#x27;s permission before putting them online. On Japanese TV they blur out faces of people passing by for example when filming an interview in the street. reply klausa 1Broadly speaking the line is: someone in the background, appearing briefly: fine.Taking photos of specific people in public without their consent: not fine. reply closewith 1As other have pointed out, the rules on photography vary from country to country within the bloc. However, the rules governing data protection and the processing of personal data (including photos) come from the GDPR, and very basically say that any processing of personal data requires a valid legal basis.There is an exception for personal use - the household exemption - but as soon as you cross the line into commercial operations or certain activities such as publishing, creating databases, etc, you lose the benefit of that exception.That doesn&#x27;t mean you can&#x27;t continue, just that you now need a legal basis and need to follow the rules (inform data subjects, allow the right to be forgotten, etc).So in general, dashcams are fine (unless a local law prohibits them) as you have a legitimate interest in recording your driving in case of an accident. Creating a facial recognition or ANPR database with the same footage would be unlawful, however. reply ukd1 1Why is A[LN]PR unlawful for private citizens to perform on their own footage? (e.g. using https:&#x2F;&#x2F;www.openalpr.com) reply closewith 1It&#x27;s unlawful as it means you lose the household exemption, and so need a legal basis for the processing. You also need to inform others of the data collection in advance, the purpose for which the data is collected, and the contact details of the data controller.Private ANPR-equipped vehicles are rare (and outright illegal in some EU states), but when you see them they&#x27;ll have large decals with the above information on all sides.Facial recognition is considered biometric data, which is special category data under the GDPR and forbidden to process except in very strict circumstances. Apart from law enforcement&#x2F;government, it is more or less impossible to lawfully process biometric data with informed consent from the data subject. The household exemption does not apply. reply monksy 1There are differences between private photographs and commerical products.Vlog&#x2F;youtube would be considered to be potentially commerical .. so you would probably be responsible fore GDPR and likeness recording. (The onious is on you to blur)Video selfie&#x2F;photograph personal&#x2F;non shared use - you&#x27;re free do thishttps:&#x2F;&#x2F;allaboutberlin.com&#x2F;guides&#x2F;photography-laws-germanyI am not a lawyer, nor is this legal advice. reply littlestymaar 1> Does this mean that if I&#x27;m filing a vlog at Brandenburg Gate (which inevitably includes video of other people in the background enjoying the area), I&#x27;m in violation of privacy laws?No (at least not in France, which also has pretty stringent privacy policy so I think it&#x27;s still a relevant answer) you can film people or cars in public streets but you cannot do any kind of data processing on the things you film (you can&#x27;t keep a database with the license plates you have on your personal videos for instance).In short the line is: pictures and films by themselves are OK [1], but doing anything with the personal info you get from those video is forbidden.[1]: (under conditions, you must not cause harm in the process: for instance no “happy slapping” videos) reply Ylpertnodi 1Fucking hell, here we go again: \"Dash cams are much more tightly regulated in some parts of the EU than elsewhere.\"It depends on the eu country of which there are several...including an ex-eu country.How it comes accross: One of the things i hate about America is that in new york all the californian building restrictions and zoning are killing free speech. reply mahathu Preach it brother reply closewith 1With respect, the GDPR is a Regulation and this applies uniformly across the bloc. Enforcement varies, obviously.TBH your comment comes off as very condescending and ill-informed. reply Knee_Pain GDPR is to be implemented independently in each country. There is room for interpretation, it&#x27;s not a granitic ruleset from above reply closewith No, that&#x27;s not correct.When talking about the EU, there are two types of laws (well, three if you include treaties), Directives and Regulations.Directives are common goals which much be transposed into law by each country and there is indeed differences in implementation. An example of a directive is Directive 2012&#x2F;27&#x2F;EU on energy efficiency. It set goals on energy efficiency (and minimum targets), but each country implemented it&#x27;s own legislation to transpose the Directive into law, and those implementations varied wildly.However, EU Regulations are a different kettle of fish. Regulations are EU legal acts which are immediately enforceable as national law in all EU states. GDPR is a Regulation and so applies uniformly across the bloc.Regulations are designed to harmonise legislation across the entire bloc. Obviously there are differences in enforcement, but the ultimate arbiter is the CJEU and decisions are binding in all EU states. replyholri In Austria there are illegal. reply bigbillheck 1I don&#x27;t think they&#x27;re all that concerned about the law. reply bonestamp2 1Which part? Lots of German cars use cameras to recognize cars for various safety and convenience features. reply ModernMech 1I drive a firetruck, so I&#x27;m invisible to Teslas. reply gumby 1This is a plausible attack vector, parallel to the profiles Facebook, Linkedin et al maintain for people who don&#x27;t have accounts. reply painted-now 1That&#x27;s why I only hang out in the metaverse and don&#x27;t leave my home anymore. Umm, ... reply steelframe 1That&#x27;s why I cycle everywhere. With my phone switched off and stowed in a Faraday bag. reply EMCymatics 1Yeah, how much do you trust Musk and company? reply cozzyd 1fortunately I only own a bike...though maybe this makes me ineligible for some Illinois class action lawsuit... reply thefounder 1Just like on social media&#x2F;chat apps reply brador 1>Your car is filmed and recognized by other teslas. - coolspotIs this true? reply xavdid 1next [–]- filmed: definitely - recorded: not sure (probably not long term) - recognized: unlikely reply mtlmtlmtlmtl 1Recorded, definitely based on the fact that Tesla employees were sharing various \"funny\" clips from these cams among themselves.https:&#x2F;&#x2F;www.reuters.com&#x2F;technology&#x2F;tesla-workers-shared-sens... reply nonrandomstring 1Teslas, Roombas and Rings...https:&#x2F;&#x2F;cybershow.uk&#x2F;episodes.php?id=12 reply WeylandYutani I thought the Chinese were being paranoid about Tesla but really anything from the US can be used to spy on your military bases. reply Too Recorded, yes. Tesla uses the fleet to collect video data for training their algorithms. This has been shared in multiple presentations from Tesla. reply bonestamp2 1Tesla owners can use the cameras as \"dashcams\" and save the recordings. Here&#x27;s an example from r&#x2F;dashcam: https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;Dashcam&#x2F;comments&#x2F;15ezdjd&#x2F;tesla_dash... reply chaps What kind of car do you have? Your car almost definitely shares its gps location to the manufacturer and downstream data brokers. reply ddalex I have a Volvo, and it&#x27;s not connected to any freaking thing, so if it&#x27;s sends the location, that would be magic. reply zootboy Lol, not my 2005 Toyota. It doesn&#x27;t even have anti-lock brakes, much less a GPS phone-home system. reply chaps Hah, fair enough! reply moffkalast 1Ah, but where&#x27;s the challenge in that? reply 93po 1Cool reply mgiampapa 1Just like we used to have cable box guys willing to sell you an unlocked box for premium channels, we are eventually going to have feature unlock guys that you go do and for a small fee perform some slightly more technical hack to enable features that are already there. reply technothrasher 1This market already exists for things like enabling Navigation on VW&#x2F;Audi cars. People were offering to enable the hidden Android Auto support on my Porsche Macan for $600, which I almost went for until I found the scripts and instructions to do it myself. reply robterrell 1This is how I got CarPlay on the used BMW I bought. Gave some guy in Thailand my VIN and $60, he sent me firmware to install, and now I drive around with working CarPlay and the vague notion that I&#x27;ve maybe been p0wned in ways I don&#x27;t fully understand. reply knodi123 1When your car idles, it&#x27;s contributing to his Folding@Home account rank reply jjkaczor 1Heh... or mining coins... or these days, factoring LLM&#x27;s... reply tmpX7dMeXU Simpler times. reply TedDoesntTalk 1More likely it’s mining crypto. reply nobleach 1Wait, CarPlay is a \"premium\" feature on a BMW? reply greenthrow On older models. Current models come with it. reply filoleg Current ones instead charge you a recurring subscription for seat heating, right? reply mgiampapa 1I did the same on a Mazda CX5 a few years back, but it was a software only hack to get root first. I suspect the actual physical hardware modification line is the one that most users are going to be unwilling to cross unless they are in the \"Download a Car\" crowd. reply littlestymaar 1> I suspect the actual physical hardware modification line is the one that most users are going to be unwilling to cross unless they are in the \"Download a Car\" crowd.Idk, hardware modification of the first Playstation that allowed to play ripped games became mainstream very quickly in my country (France) and you could even go to some shops that sold Playstations to get it done. It only stopped when it was made openly illegal.“I paid for this shit, I do what I want with it” is a very powerful sentiment (and a legitimate one actually: corporation adding “Digital Right Management” system to deprive people from their property right is dystopian as hell). reply hunter2_ By the time I got around to booting \"backup\" discs in that system, it could be done just with a dongle (like a GameShark type thing, maybe? Can&#x27;t remember) although unlike a soldered-in mod chip, it required booting with any genuine game and quickly swapping to any copy of another game, using a spring to defeat the lid sensor thus avoiding a subsequent check for a genuine disc.Not quite as convenient, but lack of invasive mod was the tradeoff. reply acer589 Okay, but in that PlayStation example you DIDN&#x27;T pay for the games, but still decided to &#x27;do what you want&#x27;. How is that legitimate but attempting to prevent it not? reply filoleg Because you also prevent legitimate uses of such \"feature\", such as playing games you purchased legitimately from other regions, as that \"feature\" also allows to defeat region-locking. As for why not just buy those same game versions released in your region, some games were just never released in some regions. Another common use is running legitimate homebrew software.So logically, it isn&#x27;t modding&#x2F;unlocking the console itself that&#x27;s illegitimate. But it can be used for certain illegitimate actions, yes (along with legitimate ones). reply littlestymaar This, or you want to have a backup of your disk because your younger brother isn&#x27;t especially gentle, or you want to have a second copy of your game so that you can have one at Dad&#x27;s home and one at Mom&#x27;s.And these use-cases aren&#x27;t only legitimate, in France they are even legal and in exchange we pay a tax whenever we buy a media storage device (Taxe sur la copie privée). reply WarOnPrivacy > hardware modification of the first Playstation that allowed to play ripped games became mainstream very quicklyI remember this. Chip on chip iirc. The period is stored in my memory because it was also when DVD media first broke the $1&#x2F;disc barrier. It wasn&#x27;t very good media at $1 per but exciting times nonetheless. reply harshalizee 1Doesn&#x27;t the Mazda CX-5s all ship with Android Auto and Apple Carplay by default? reply mgiampapa 2016 Didn&#x27;t, I also enabled the built in navigation while I was at it. reply jxf 1Hidden as in it&#x27;s not available normally, or hidden as in it&#x27;s a paid feature? reply avree 1It was built, and then disabled, as Porsche wasn&#x27;t comfortable with Google&#x27;s policies around data collection from Android Auto. You can pretty easily figure out how to turn it back on. reply BonoboIO 1$600 is not cheap. What model year do you have? Does Porsche not provide an update or possibility to upgrade. reply fragmede 1If you&#x27;re in the market for a recent Porsche, which go for let&#x27;s say ~$100k, $600 is cheap to you. Cheaper than the time you&#x27;d spend on doing it yourself really, but doing it yourself is half the fun. reply mrguyorama 1If $600 is something you have to think about, you should never own a Porsche.If you can&#x27;t afford to maintain an expensive car, you can&#x27;t afford to purchase an expensive car. reply WarOnPrivacy > If you can&#x27;t afford to maintain an expensive car, you can&#x27;t afford to purchase an expensive car.Depends on how you acquire it. I can get a couple BMW&#x27;s for cheap to free but I&#x27;ve heard too many repair stories around the campfile to blind dive into that particular rabbit hole. reply bri3d 1This has already been the case on European navigation systems (Audi and VW MMI&#x2F;MIB) for many years now.VW Audi Group developed an entire infrastructure called SWaP (Software as a Product) and FEC (Feature Enable Codes) many years ago, and ever since, there has been a cottage industry in bypassing the system to enable features like CarPlay, Navigation, and Performance Monitor which are usually locked by software trim levels. reply hunter2_ It&#x27;s always awesome seeing your comments about VW stuff. I&#x27;ve been using VCDS over 10 years now with nothing but various trims of Golfs for even longer than that. Luckily my Mk7 R came with all the FECs I&#x27;d ever want, stock! The secret menu doesn&#x27;t show anything interesting in the diff between supported and installed.Do you think there will ever be ECU&#x2F;TCU tunes maintained as open source projects? Maybe not quite as user-friendly as the Cobb ecosystem and the like, but good enough to make $600+ tunes a thing of the past for DIY types who are into mucking about but want the peace of mind that comes with using maps that enough other people are already using? Not that tuners shouldn&#x27;t be paid for their work, but I feel like they could focus on the custom tune segment and be ok. My current understanding is that free software exists (I haven&#x27;t actually played with any myself yet, but I&#x27;ve heard of TunerPro, WinOLS, etc. and I see you maintain VW_Flash, very cool) but then the user needs to know how to create a custom tune from scratch, no free and widely used \"off the shelf\" &#x2F; \"staged\" files floating around for common cars (the main value proposition of APR, EQT, IE, UM, etc.), correct? reply no_wizard 1The only hack on cable style TV I remember is you could buy modified satellite authentication cards for DirectTV for a time - usually on eBay or similar sites - and they worked. No idea how long, I had an uncle that had one though, got all the premium channels etc.I doubt any of this works anymore though reply bonestamp2 1I remember being out for a beer run with a friend during these days. On the way there he pulls into a parking lot and stops in front of a nail salon. He said, \"Come on\" and I followed him into the nail salon. There were about 10 women in there, not a guy in sight... he goes up to the desk and pushes a button that looks like a doorbell.One of the ladies doing the nails says, \"He no work here no more, check dry cleaner across the street.\" We get back in the car and I&#x27;m like, \"What was that all about?\". \"My DirecTV card got disabled and that&#x27;s where I get it reprogrammed\".We go across the street to the Dry Cleaners. There are three ladies in the lobby watching TV, and a guy behind the counter. He asks the man, \"Is Ken here?\" The man says, \"I&#x27;ll check\" as he walks into the back. Now, the man was coming from the back when we came in, so I assume he already knows if Ken is there or not, but Ken probably only comes out if he recognizes my friend.Sure enough, Ken comes right out all smiles and they have a quick chat. My friend hands over his card and Ken says, \"we had to get new equipment, it&#x27;s now $100, ATM next door\".Ken disappears for about 10 minutes and comes back. My friend gives him cash and away we went. About 4 months later, he had to get it reprogrammed again. reply Biganon Why did you take the car to cross the road? reply bonestamp2 It&#x27;s a big busy road with a median in the middle. There were no crosswalks nearby, and we had to go back that direction anyway. Why do you ask? reply kortilla This is America reply toKillTheChick To get to the other side... reply tmpX7dMeXU That guy’s name? Jimmy McGill. reply bonestamp2 No, it&#x27;s all good man. ;) reply nobleach 1I worked for a cable company in the mid-90s. The amount of boxes that disappeared (and couldn&#x27;t be located) was insane. The folks that procured them also used a \"bullet blocker\" (basically a resistor) to avoid the box being disabled.In the satellite realm, DishNetwork was always the easier service to hack. The FTA scene was completely overrun with folks buying 3rd party tuners. Once Dish switched to an encrypted signal, a few vendors (nFusion if I recall) even could rotate keys in a matter of hours to decrypt Dish&#x27;s new encryption schemes. I doubt any of that works these days simply because there&#x27;s no reason to push too hard for content that is likely available via easier means. reply jandrese I read an article about the early DirecTV hacking days and the cat and mouse game the hackers played with the company. DirecT cards were smart cards that ran programs for the decryption path. The hackers kept just duplicating whatever DirecTV sent down to keep them workign, mystery bits and all. Then one day a final update came out and those weird bits turned out to be a specially designed program that bricked all of the hacked cards. I&#x27;m sure that was a temporary setback for the hackers but it was a great story. reply kortilla Didn’t this happen recently with a usb to serial port vendor or something like that? Vendor released a new driver that bricked all of the knockoff ones… reply yjftsjthsd-h Yes, FTDI did that - https:&#x2F;&#x2F;www.zdnet.com&#x2F;article&#x2F;ftdi-admits-to-bricking-innoce... reply fragmede 1If you want a rabbit hole, start with Christopher Tarnovsky at Defcon https:&#x2F;&#x2F;www.wired.com&#x2F;2008&#x2F;05&#x2F;tarnovsky&#x2F; reply darkclouds 1The dragon cam.https:&#x2F;&#x2F;www.kustompcs.co.uk&#x2F;components&#x2F;interface-cards&#x2F;tv-tu... reply rebolek 1Let me tell you what&#x27;s wrong with this:Nothing. reply progman32 I unlocked a whole extra gallon on my i3&#x27;s fuel tank (just about doubling its capacity) just by poking it with a computer, there&#x27;s definitely people around willing to pay for this service. reply berniedurfee And gray market chips you could swap into your US Robotics Sportster modem for dual standard 56k baud compatibility! reply bonestamp2 1Be careful though, some automakers are tracking software mods and voiding warranties. Example: https:&#x2F;&#x2F;www.motorbiscuit.com&#x2F;beware-dodge-challenger-mods-do... reply Faaak I don&#x27;t think how that could work with the Magnuson–Moss Warranty Act ? reply bonestamp2 Good point. There is an exception in that act that allows the warrantor to waive coverage if the damage was caused by the consumer, so I guess Dodge can do it because the software mod in that case is causing the vehicle to perform outside of its design envelope. The warranty only covers manufacturer defects, and forcing the vehicle to do something it&#x27;s not intended to do is not a defect.So, I guess these Tesla hacks should be fine so long as they&#x27;re only enabling things that the vehicle has been designed to do. reply rconti One advantage of having blown through the warranty on my Tesla already!On the other hand, I don&#x27;t think my car has any unlocked features I want. I mean, I didn&#x27;t pay for FSD &#x2F; Autopilot but I&#x27;m not sure I&#x27;d use either. reply mrguyorama 1Internal employee controls have gotten way more sophisticated, and cared about since it&#x27;s one of the things you need to do for business focused information security. reply Prickle 1This is true, but if I remember correctly, Apple has a very similar issue with user locked devices.Employees have opened their own \"stores\", where they remove activation locks, or unlock iphones remotely for a small fee. reply sleepybrett 1I had a friend that made a tidy sum in college by selling replacement chips for high end cars that overrode some governors built into the firmware. reply awad 1Mod chips for consoles and mod chips for cars don&#x27;t seem too dissimilar reply striking 1> I wonder how many tries you need to get whatever bits you need in the right place.For the Xbox 360, the \"Reset Glitch Hack\" (which worked similarly) would just try over and over again until it got it right. A computer is happy to try tens or hundreds of times on your behalf. reply jsheard 1However the next Xbox added active countermeasures against glitching attacks which force a reboot if the clocks, temperatures or voltages go outside of reasonable bounds, and that&#x27;s never been defeated. Glitching attacks can be very powerful, but they have a limited shelf life if the hardware manufacturer cares to prevent them.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=U7VwtOrwceo reply striking 1Definitely. Not arguing that this can&#x27;t be fixed, but rather outlining how a similar successful attack was made more reproducible. reply judge2020 1Anonymizing your location - until you put in route and your car asks for traffic information from teslas servers. reply d4l3k 1If the map can&#x27;t talk to Tesla it&#x27;ll use Google maps directly. I usually don&#x27;t allow connections to Tesla on my rooted Model 3 reply adamgamble 1I also would like to subscribe to your newsletter. reply d4l3k 1I&#x27;ve got a blog if you&#x27;re interested haha https:&#x2F;&#x2F;fn.lc&#x2F;post&#x2F;I&#x27;ve been hacking on my car and creating my own self driving modelsCode is at https:&#x2F;&#x2F;github.com&#x2F;d4l3k&#x2F;torchdrive reply seanthemon 1Very cool, am going to eat this up. FYI some of your images won&#x27;t load for me, shoots me a 502 here https:&#x2F;&#x2F;fn.lc&#x2F;post&#x2F;diy-self-driving&#x2F; reply d4l3k 1Not sure why they aren&#x27;t loading, seem to be fine nowThey&#x27;re also at https:&#x2F;&#x2F;github.com&#x2F;d4l3k&#x2F;fn.lc&#x2F;tree&#x2F;master&#x2F;static%2Fdiy-self... reply acer589 Is that legal? reply kortilla Is getting married at 15 in Georgia? reply malwrar 1How does this work with their charging network? Are you still able to use their chargers, or are you stuck with home charging & third parties? reply d4l3k 1Supercharger auth is between the car and the charger and doesn&#x27;t require an internet connection. I get billed the normal way via my Tesla account since the VIN is registered reply wholinator2 1Oh no, don&#x27;t give them ideas. It&#x27;ll become the HP instant ink of car charging reply zoover2020 1Hoe did you root yours? Did you lose out on any functionality? reply d4l3k 1There&#x27;s some functionality loss but it&#x27;s mostly been mitigated. I have a custom app I wrote since I can&#x27;t use the stock app.The one feature I miss is that there&#x27;s no voice commands since that requires Tesla&#x27;s servers but at the same time I also haven&#x27;t been bothered enough to plug in a custom backend reply lrem 1waitSo the company that goes \"we don&#x27;t need physical buttons since we have voice commands\" also goes \"you don&#x27;t need those in underground parkings\"?! reply majikandy It’s ok, the voice commands are barely understood anyway. At least in the UK they aren’t. Gets it drastically wrong and messes up your navigation destination, because you asked it to open the glovebox “navigating to Columbia” reply judge2020 Are there api keys for google maps in the car? Or does it emulate some client like a browser or android phone? reply bushbaba 1Isn’t this a huge risk to AMD’s confidential compute offering. It’s a major security flaw. reply kccqzy 1I have reviewed the threat model carefully before. AMD never claims that their confidential compute offering is immune to attacks involving physical access. I assume what you mean by confidential compute is technology like AMD SEV SNP? Those are very different in that they allow you to run a trusted virtual machine on an untrusted hypervisor. This attack is completely different; it&#x27;s akin to breaking Secure Boot on a PC. reply bastardoperator 1Definitely sophisticated, but something console hackers have been doing for quite some time now including the boot flow. I&#x27;m wondering if a Tesla vehicle&#x2F;computer is more sophisticated than say a PS5? reply closewith 1Can you not turn off vehicle tracking? reply speedgoose 1Since a few weeks you get a classic consent screen for various categories of tracking. At least in Norway. You can turn everything off but I think some data is still sent to your phone through the Tesla servers. And I assume it’s not end 2 end encrypted. reply klysm 1I don’t understand how you can defend against low voltage attacks like this. reply jsheard 1The Xbox 360 was broken by voltage glitching, and Microsoft successfully prevented it from happening again with the Xbox One: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=U7VwtOrwceoIn short, there&#x27;s now a hardware watchdog which reboots the system if anything weird happens to the clocks&#x2F;temps&#x2F;voltages, and they carefully structured their boot ROM (the only code they can&#x27;t patch later) to ensure that even if you somehow manage to sneak one glitch past the watchdog, no single branch condition being inverted will lead to a compromised state. reply 14 That is really cool. I personally installed the reset glitch hack on several Xbox 360. Immediately thought about that when seeing this article on the Tesla reply weebull 1Make sure all security critical state is initialised to known values at reset, then have very tight tolerances on your power watchdog to initiate reset.However, that doesn&#x27;t make for a stable system when powered from batteries. reply brewtide 1Semi related question I suppose. Do the Teslas simply use GPS for their location information? If so, couldn&#x27;t one spoof the GPS using a hackRF or similar? reply comboy 1I have no idea about Tesla specifically but normally you&#x27;d also you cell and wifi information (in their case probably also information from other teslas around) and additionally you have accelerometer and the whole \"self-driving\" computer to estimate where the car is and where it&#x27;s going. It&#x27;s also a known attack vector and likely covered because GPS signal is really weak so it&#x27;s easy for somebody outside the car to try to make a mess. reply ballenf 1Targeted by the FCC seems worse than violating a Tesla clickwrap agreement. reply myself248 1Only an idiot would let their GPS spoofer onto the air. You unplug the antenna cables from the receiver and pipe the spoof signal in there. reply dhx This is the same attack (and same people who developed) faulTPM[1] that was previously discussed[2]. This article is the same people demonstrating that attack against Tesla vehicles. The paper[1] and previous discussion[2] address the underlying problems with AMD&#x27;s Secure Processor (AMD-SP) that is embedded in their CPU SoCs and previously and more commonly known as Platform Security Processor (AMD-PSP).Unlike a web browser where W3C AntiFraudCG folk propose that websites would blacklist all impacted AMD-SP hardware and create massive amounts of e-waste[3], Tesla likely can&#x27;t do much about this attack because Tesla (not users) would be responsible for a very expensive change of vehicle hardware.If it&#x27;s not an easy-to-execute attack like faulTPM, there are more complex (but becoming more mainstream and cheaper) IC reverse engineering methods like polishing the die down to take photos of each metal layer and regenerating VHDL, FIB editing an operational IC to bypass tamper detection methods, etc[4].A security architect of the Xbox One presented a talk[5] a few years ago which provides some good background too. Largely the Xbox One has managed to avoid piracy because they made it economically not worth anyone&#x27;s time to attack due to competitive pricing models versus high cost of attack. Similar to use of Denuvo for a month or two after release of a PC game, attackers aren&#x27;t going to bother if their work amounts to nothing a month later.Hacking a Tesla to enable additional features is worth a lot of money, so the economics are quite different. It&#x27;s also different economics for printer cartridges, \"pay to enable more features or performance\" network equipment, etc. The cost of IC reverse engineering &#x2F; FIB editing attacks (or other future attack methods) will keep reducing. IC tamper detection features will get more complex. Perhaps attackers will even get an advantage once they can readily reverse engineer 3nm ICs and defenders can&#x27;t do much other than implementing ever more complex and obfuscated IC tamper detection features and VHDL logic (kind of like a Denuvo situation in hardware).[1] https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2304.14717[2] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35787195[3] https:&#x2F;&#x2F;github.com&#x2F;antifraudcg&#x2F;proposals&#x2F;issues&#x2F;19[4] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=6390Zqca3Mg[5] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=U7VwtOrwceo reply FirmwareBurner 1>that&#x27;s got to be really bad news for someone in vehicle security at Tesla.It says in the article: \"Generally, these exploits are shared with Tesla, and it helps the automaker secure its systems.\"So it&#x27;s only a matter of time till Tesla patches it. reply denysvitali 1Although this seems unpatchable without an HW upgrade reply capableweb 1More relevant quotes from the article:> The group of hackers claims that their “Tesla Jailbreak” is “unpatchable” and allows to run “arbitrary software on the infotainment.”And the full quote of what you put:> Electrek’s Take> Generally, these exploits are shared with Tesla, and it helps the automaker secure its systems.> In this case, the hackers said that despite the exploit, they believe Tesla’s security is better than other automakers.Doesn&#x27;t seem like the security researchers actually shared the exploit with Tesla, at least as far as I understand. reply kelnos 1The information in this article alone is likely enough for some Tesla engineers to sit down and figure out the exploit themselves.And if this research group wants to enable regular people to \"jailbreak\" their cars, they have to publish their full methodology anyway. reply vorticalbox 1That&#x27;s likely because it&#x27;s a hardware issue, nothing really for tesla to do. reply bumby 1Apologize for my ignorance, but isn&#x27;t it up to Tesla to define what hardware they want to integrate? Or is there no design alternative? reply avrionov 1What they meant is that it is not possible to fix it without replacing the hardware. reply bumby 1I see. But replacing the hardware would still be very much in the purview of \"Tesla&#x27;s problem\" if you think they are a car manufacturer. reply filoleg Yes, but it is unpatchable for any currently existing cars on the road, I believe that&#x27;s the point they were trying to articulate (though not super well).And yeah, you are correct, Tesla can close up that exploit in their newer hardware revisions. reply pitched 1Changing hardware would mean a recall and this doesn’t seem to warrant it. reply Knee_Pain 1But how much time until the hardware is changed? And all the current models? reply neuralzen They will share the details at Blackhat next week reply samstave 1On the black-hat-flip-side ; This is exactly what a Black Hat would want to say - preventing from Tesla stating that they \"aint got shit\" from the hackers...So hackers can claim they called tesla, and tesla can ignore it and we no wiser reply sirsinsalot 1There&#x27;s a lot of missing the point in these threads about software locks.Building a car in a uniform way for economy of scale savings, fine.Having a software unlock for hardware you already have (but didn&#x27;t pay for in the price). Fine.Using software to rent-seek on one time costs like heated seats. Not fine. Less fine too if the seat subscription can&#x27;t carry to secondary market. This can he used to cripple secondary markets: sorry, the BMW account you have isn&#x27;t linked to this VIN. Heated seats and android auto are disabled.Let&#x27;s stop the third. reply sdfignaionio 1>Having a software unlock for hardware you already have (but didn&#x27;t pay for in the price). Fine.Tolerable, perhaps, but pretty far from fine. It&#x27;s pretty shocking to me that people in our society build things and then deliberately break them so they can make more money. Is this really the best system we can come up with?We have built a society where what is plainly crazy is rational. reply someplaceguy > Tolerable, perhaps, but pretty far from fine. It&#x27;s pretty shocking to me that people in our society build things and then deliberately break them so they can make more money. Is this really the best system we can come up with?It&#x27;s not as bad as it looks. If you think about it, it&#x27;s basically a form of wealth redistribution.Rich people will pay the premium, which subsidizes the cost of the car for others. In other words, poorer customers will get a cheaper car.It&#x27;s a pretty good deal for those who are less wealthy and don&#x27;t really need the extra functionality.Also, these poorer customers can always upgrade later if want to (because circumstances change and they want the functionality or because they get richer and can afford more luxury). This is not always possible with hardware-based customization, or even if it is, it would be more expensive.The alternative would be to only install the extra hardware in the cars of the wealthier customers, but presumably this would make the car more expensive for everyone (both the poor and the rich owners), due to the added costs of hardware-based customization. So everyone would lose.And even if the latter is not true, a similar car manufacturer could just offer you a better deal by selling you a similar, cheaper car without installing the hardware, which means that the manufacturer&#x2F;brand that does the shenanigans would lose customers. Competition is pretty awesome like that. reply jjulius >Rich people will pay the premium, which subsidizes the cost of the car for others. In other words, poorer customers will get a cheaper car.This sorta thing is usually done because retooling an assembly line so the car can have different features can be incredibly costly. It&#x27;s often the case that all cars are built with the same features and the cost of this hardware is also included the price of the cheaper car with the features disabled. The \"rich people\" just pay a premium to have &#x27;off&#x27; switched to &#x27;on&#x27;. reply someplaceguy Still, there are only 2 options:1. This scenario makes the car cheaper for the poorer customers, so they benefit from it. Or at least, it doesn&#x27;t increase the price, so they get the added benefits of being able to upgrade their car more easily and cheaply than going to back to the shop to install the extra hardware.2. Or, this situation makes the car more expensive for the poorer customers, but since they are much more price sensitive, it is very likely that they will choose to go to a competitor who actually sells them a similar car without the additional hardware (therefore cheaper), or without subscriptions.Unless of course, there was a monopoly or cartel, but I don&#x27;t think we are in that situation.The fact that these companies are going in this direction, indicates that they are able to profit more in this situation, which indicates that they are providing more value (again, unless their customers didn&#x27;t have a reasonable choice). It&#x27;s not proof, but it&#x27;s evidence that there are advantages.That said, it&#x27;s not as simple as I&#x27;ve just put, because sometimes it can be easy to trick people into making a worse choice for themselves in the long term, e.g. due to marketing, or buying things with credit or as subscriptions instead of one-time payments, for example.... which can definitely apply in this case! reply jjulius >1. This scenario makes the car cheaper for the poorer customers, so they benefit from it.Pardon my ignorance, but if the cost of the hardware is already baked into the cost of the cheapest options, which means they are paying for all of the hardware they have in their cars, including the hardware they can&#x27;t use, how do they benefit? Cost, in that situation, is determined simply by the need to assemble efficiently. I can&#x27;t see how the consumer benefits in that scenario by paying for something they can&#x27;t use.Responding to your edit:>Or at least, it doesn&#x27;t increase the price, so they get the added benefits of being able to upgrade their car more easily and cheaply than going to back to the shop to install the extra hardware.Again, pardon my ignorance, but it feels disingenuous to call it \"an upgrade\" if the car already has the equipment, especially to be charged more to use what you&#x27;ve already paid for.Am I crazy? reply LeafItAlone > Pardon my ignorance, but if the cost of the hardware is already baked into the cost of the cheapest options, which means they are paying for all of the hardware they have in their cars, including the hardware they can&#x27;t use, how do they benefit?The idea is that the “cheaper” models are getting the hardware at a discount. Very simply: are getting $30,000 of hardware for $25,000 because features aren’t active. Others are willing to pay $35,000 for the same hardware with the features active. Obviously this example is over simplification of pricing and value, but that’s the general idea. reply someplaceguy It may actually be even better than that.If the manufacturer hadn&#x27;t done this, they would have to produce at least 2 versions of the car: one without any extra hardware, and one with all the extra hardware.It may turn out that doing separate versions of the car could cost $5,000 more per car over its entire lifetime, including production (extra design, assembly lines, etc) and support, rather than simply making one version of the car.So if the car company hadn&#x27;t done this, the car might have cost $30,000 anyway without the extra features, and $35,000 with the extra features, so the poorer customers would lose while the rich customers would pay the same.This works more or less the same if these costs are comparable or higher than the costs of the extra hardware. And I suspect they are higher, as it seems highly likely that the price for these premium features in cars are a lot higher than the actual costs of the hardware itself.Sure, the company could still engage in the same wealth redistribution &#x2F; subsidization &#x2F; price differentiation in the 2-car scenario (and they likely already do), but everyone could still lose anyway because the total costs of all the cars could still be higher in total. reply someplaceguy I don&#x27;t think I understand your question.The customer can be receiving extra hardware and still be paying a cheaper price due to the assembly line efficiencies you mentioned, as well as the support costs of having just one new car model every year instead of 10 slightly different car models every year.In other words, the additional hardware costs might be lower than the other cost reductions due to the increased efficiency.Furthermore, even if the customer is paying exactly the same as before for the car (but now they are getting additional hardware which they can&#x27;t use), it would be cheaper and much easier for these customers to upgrade their car if they so choose.This would also mean higher profits for the car manufacturers, which allows them to reduce the initial purchase price of the cars to compete more effectively in the market.And if it turns out that the car is more expensive due to having to buy the additional hardware, since these customers are price-sensitive they can just go to a competitor who would sell them a car without the additional hardware, therefore cheaper.EDIT:> Again, pardon my ignorance, but it feels disingenuous to call it \"an upgrade\" if the car already has the equipment, especially to be charged more to use what you&#x27;ve already paid for.Perhaps that&#x27;s because you&#x27;re only considering the cost of the hardware and not all the other costs of producing and supporting all the different car models for every combination of hardware features each customer would choose?I mean, yeah, sure, car companies could just sell a car with all the hardware features enabled and charge all customers the same, but then the price of the cars would be higher for those who don&#x27;t need all those features, as the company wouldn&#x27;t be able to charge higher prices for premium customers to subsidize the cars for the \"poorer\" customers. replyhot_gril 1> It&#x27;s pretty shocking to me that people in our society build things and then deliberately break them so they can make more money. Is this really the best system we can come up with?All part of cost tradeoffs. Previously, they&#x27;d build the car with the ability to support all those add-ons even if the customer isn&#x27;t getting them. Turns out it&#x27;s cheaper not to do that. reply circuit10 I wish the solution was to just give everyone those features. Maybe it can’t work like that but this feels very wasteful reply jimmyk2 I assume it’s all to game the starting MSRP.Like the barebones Tesla 3 that existed on paper but was basically impossible to order. OE’s know most people will spring for that creature comforts. reply circuit10 That reminds me of this video: https:&#x2F;&#x2F;youtu.be&#x2F;cLGcGnGJvL0 where they say how one of the reasons laptops are getting harder to upgrade is probably so they can make you buy an expensive configuration and still advertise a low starting price reply hot_gril Laptops have real physical limitations involved, similar to smartphones don&#x27;t have RAM slots, so I don&#x27;t buy the video. But silly as it is, at least you can \"download\" heated seats later if you change your mind. reply sdfignaionio Perhaps it is reasonable to solder parts to the motherboard. It&#x27;s less reasonable to charge a massive markup on storage and memory. The margins on those upgrades are well over 100%. reply hot_gril Yeah, even if the soldering isn&#x27;t intentional for non-upgreadability, they certainly took advantage of it in the pricing. And with the heated seats, the margin is infinite. replyfemto Being a tradeoff it works both ways. Customers get broken add-ons for free if it&#x27;s cheaper to not pursue the customers that fix them. reply hot_gril Yeah, same with how I watch YouTube ad-free for free. reply wingworks Kinda what the chip Intel (and others chip makers?) have been doing for years. Make the best next gen chip, then strip out parts to slow it down and sell cheaper ones. Not 1:1 the same, but pretty similar. reply harry8 >Having a software unlock for hardware you already have (but didn&#x27;t pay for in the price). Fine.Ok as long as &#x2F;any&#x2F; end run around that garbage made by the car&#x27;s &#x2F;owner&#x2F; is specifically: legal, legitimate and not-warranty voiding.Because you know the step from there to not being able to repair the things you own without paying more to allow you to do so is nonexistent. reply ravenstine The third is exactly why the second is NOT fine. The second naturally leads to the third.Until legislation is passed, you will only pry my dumbcar from my cold dead hands. reply Panzer04 The solution to these problems? Don&#x27;t be a customer of said abusive company.If they don&#x27;t present value for money at a given price point (including these sorts of shenanigans), don&#x27;t buy it. So long as you know about these issues up front I don&#x27;t think it&#x27;s that problematic (even if it feels a bit wasteful in a holistic sense) reply satao Individual solutions are never going to fix collective problems. reply filoleg Collective solutions to collective problems are often just individual solutions applied at scale by many unrelated individuals (on their own). reply hot_gril 1What&#x27;s the difference between the second and the third? reply dr_orpheus 1Second is \"I pay $50 once to unlock heated seats in my car forever. This car now has heated seats and anyone that I sell it to also gets heated seats\"Third is \"I pay $5&#x2F;month for heated seats for the entire time I own the car. Anyone that I sell the car to would also have to pay $5&#x2F;month for heated seats.\"Edit: The other version of the third option (your BMW account is not tied to this vin) is something like \"I pay $50 once for heated seats in my car. If I sell it to someone, they also have to pay $50 to unlock the heated seats\" reply hot_gril 1Third seems slightly better, cause at least the secondary buyer clearly knows it&#x27;s $5&#x2F;mo instead of having to make sure the one-time payment sticks. reply eganist In fairness, the second method should probably be implemented with an e-fuse. That way once it&#x27;s paid, there&#x27;s no taking it away. reply hot_gril Yeah, otherwise I don&#x27;t trust it. reply lajamerr 1Probably the same sentiment between DLC vs Expansions in gaming.But fundamentally no difference because you are getting a discounted price in exchange for the soft locked feature. So 2 and 3 are the same imo. reply hot_gril 1I&#x27;m not asking what&#x27;s the conceptual difference, I just don&#x27;t get what the two options are. Is #2 one-time purchase and #3 subscription? reply liendolucas 1> Software-locked features that need to be activated by the owner paying or subscribing to a service are becoming increasingly popular in the auto industry.Sorry, WHAT? People should absolutely boycott companies that try to squeeze bucks in this miserable way. reply ryathal 1You better be ok with building your own car then, because every major player is adding subscriptions for various features. Remote start and remote lock&#x2F;unlock are the most common, along with satellite radio. reply liendolucas 1The way I see it is that you&#x27;re supposed to own the car and every feature you paid for it. reply stjo 1I could give companies a pass for features that require continuous maintenance from them, like remote unlock (properly secured servers). But there was a car company that tried to sell you your own seat warmers, which definitely crosses my barrier. reply woah The seats get warm by running Javascript single page apps which need to be served from the servers, and frequently updated by the company&#x27;s front end developers to use newer frameworks that make them get even hotter reply ulamel 1big tech is trying to erase this concept from the consumer mind. Assuming someone tried to do everything legally (not pirating) when was the last time anyone \"owned\" anything. Music, Movies, TV shows, Software, you don&#x27;t own any of it you are simply paying for server space. reply liendolucas 1You couldn&#x27;t have stated that more clearly. Is a disgrace. We&#x27;re basically headed to rent features of all kinds. It&#x27;s terrible. reply tmpX7dMeXU It’s a point repeated practically infinite times daily on this website and any other tech community. It’s not a revelation deserving of accolades. It’s the nerd equivalent of “lower taxes!” at a political rally. This entire back and forth where all participants are clearly on the same side and are clearly regurgitating all the talking points of their shared ideology isn’t a conversation, it’s people patting eachother on the back. reply wpietri Amazingly, this corporate desire goes back more than a hundred years. Edison cylinders had a \"shrink-wrap\" license trying to control what people did with the recordings they bought: https:&#x2F;&#x2F;www.flickr.com&#x2F;photos&#x2F;59414209@N00&#x2F;5072909557&#x2F;That was later outlawed with the \"first-sale doctrine\": https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;First-sale_doctrineI would say that it seems like it&#x27;s time for some new legislation that supports consumer freedom. But given the state of American politics, I can only hope that Europe will do some pioneering work on this. reply userbinator Not just big tech; there&#x27;s a reason why \"you will own nothing and be happy\" is a thing. reply LeafItAlone Which would you rather have:Option A: A vehicle that lacks the hardware for heated seats, heated steering wheel, and driver assist that costs $25,000 to produce and that you pay $25,000 for. If you want these items next year, you have to buy a new vehicle.Option B: A vehicle that includes the hardware for heated seats, heated steering wheel, and driver assist that costs $27,000 to produce. You can pay $25,000 now and those features aren’t enabled. But next year you can enable them for a nominal fee. Or you can pay $30,000 now and there are enabled for life. Or $27,000 now and a $500&#x2F;year subscription fee that you can later cancel.If not having two separate designs and production lines means less cost to make that a reality, that seems like a reasonable trade off to me. reply nottorp 59 So ... you mean those bmws with the subscription for heated seats were sold for less than the previous models? reply jaclaz But you know how this will end up with you paying 30,000 upfront AND the yearly 500. reply lstodd No you don&#x27;t have to buy a new vehicle, just aftermarket seats and the wheel for a thousand bucks or so.edit: https:&#x2F;&#x2F;youtu.be&#x2F;phHZ2HOkn8s?t=14 reply afavour Sure, that’s the way I see it too. Isn’t the way the car manufacturers see it, though. And I’m not able to build my own car. So… reply grishka Features that need servers — which all remote ones do — have a running cost, so it&#x27;s fine for them to be a subscription. However, paying to use the hardware you already have installed on your car, like heated seats or smart headlights, is absolutely not fine. reply hot_gril 1Or having an older car. Personally this concept doesn&#x27;t bother me; I&#x27;d just not pay for the features. Many old cars have features locked behind buying the physical button to activate them. Hackers find their ways around that, and now it&#x27;s becoming harder to hack. Fine, whatever. But I just don&#x27;t trust the crappy software they increasingly put into new cars, so I&#x27;m riding out my old one for now. reply forgetfreeman 1I am very ok with building my own car if it comes to that. It&#x27;s the cretins willing to actually go along with bullshit like this that are the problem. reply abraae People who are unable to build their own car are not all cretins. reply forgetfreeman Agreed. People who willingly purchase a vehicle that includes subscription fee for features built into the car absolutely are cretins however. reply eganist if everyone is doing it, it&#x27;s time for the law to step in. reply nichos What could possibility go wrong? reply eganist > What could possibility go wrong?Do tell. I&#x27;m always keen on hearing why people prefer no regulation in the automotive space. reply pkaye 1BMW has plans for locking features behind subscriptions like seat heaters, heated steering wheels, recording from your car&#x27;s camera, etc.https:&#x2F;&#x2F;www.theverge.com&#x2F;2022&#x2F;7&#x2F;12&#x2F;23204950&#x2F;bmw-subscription... reply hot_gril 1My friend bought a new BMW, and the seat heater subscription is already a thing on it. reply oatmeal1 1People overreact to this. If this didn&#x27;t exist, they would just manufacture cars the old way where multiple version of the same car are produced at high and low prices. I have seen no evidence provided this actually increases the total price of a high feature car. This might actually lower the average price paid because of the economies of scale achieved by making fewer different versions of the same car. Resale value can increase as well, since the person buying your car can get the features they want, even if you didn&#x27;t originally purchase those features. reply afavour It strikes me as a far more fundamental shift: up until now I buy something and I own it. In the future I will effectively be renting part of my car. Instead of a one time payment I’m now I’m now required to make monthly payments until the day I stop using my car. That’s a massive difference.Unless it’s something that requires the car manufacturer to also spend money on an ongoing basis (e.g. a cell data connection or something) it strikes me as absolutely immoral that these companies are going to band together and force this arrangement upon us. reply liendolucas I&#x27;m not overreacting to this. I&#x27;m absolutely tired to learn that subscriptions are being pushed everywhere. Having to pay for something that is already in a vehicle is insulting to me. Car manufacturers should sell cars, not subscriptions of ANY kind. What&#x27;s going to be tomorrow? Will I have to subscribe to a service to actually let my speakers emit sound despite that I have payed for them? Ridiculous today, a business tomorrow. reply tmpX7dMeXU Any country with even half decent consumer protection would stop your imagined slippery slope scenario. You bought the speakers, as speakers? Then they need to operate like speakers, unless it was clear ahead of time that more is needed.Software locking like this is bad for environmental &#x2F; waste reasons. All of this complaining about there being a disconnect between what you willingly paid for and what the physical hardware components in the product you receive can technically do, is just a nerd’s argument. I agree with it. Subscriptions suck when there’s no ongoing cost to the seller. But I’m not going to pretend that this is some moral crusade, or be as emotionally invested as you quite obviously are. reply wpietri You have pretty strong opinions for somebody who has admittedly seen no evidence either way.Personally, I think it&#x27;s a terrible idea in that it further changes the relationship between buyers and sellers toward a relationship of long-term exploitation. It takes the notion of enshittification [1] and extends it into the realm of physical goods.[1] https:&#x2F;&#x2F;kottke.org&#x2F;23&#x2F;01&#x2F;the-enshittification-lifecycle-of-o... reply circuit10 In an ideal world we could just give everyone those features if they didn’t cost any extra to add instead of creating an artificial pricing structure to get more money out of people. Maybe it can’t work that way but making people’s lives worse just to punish them for paying less in order to incentivise them to pay more, rather than as compensation to the company for doing more work, seems wrong reply caf Doesn&#x27;t the same sort of apply to eg. Microsoft should give you access to all of their existing software titles when you buy an xbox? It&#x27;s not like you paying for Flight Sim now compensates them for doing more work. reply lambersley 1This isn&#x27;t new. Automakers following software companies&#x27; subscription modelhttps:&#x2F;&#x2F;www.foxnews.com&#x2F;tech&#x2F;automakers-bmw-gm-mercedes-char... reply Tangurena2 Every car manufacturer is planning to do this. Not enough people protested when this category of features first came out. reply 427 more comments...",
    "originSummary": [
      "Hackers have discovered an exploit that can unlock software-locked features in Tesla vehicles, such as heated seats and the Full Self-Driving package.",
      "The hack requires physical access to the car and involves a voltage fault injection attack on the infotainment system.",
      "The hackers claim their \"Tesla Jailbreak\" is unpatchable and allows for running arbitrary software on the infotainment system, potentially unlocking all software-locked features."
    ],
    "commentSummary": [
      "The conversation covers the hacking of software-locked features in Tesla vehicles, highlighting potential security vulnerabilities.",
      "It explores privacy laws regarding dash cams and CCTV, emphasizing the need for responsible and legal use of surveillance technology.",
      "The discussion underscores the importance of home security and the advantages and disadvantages of security cameras."
    ],
    "points": 768,
    "commentCount": 691,
    "retryCount": 0,
    "time": 1691081044
  },
  {
    "id": 36986769,
    "title": "Elixir for cynical curmudgeons",
    "originLink": "https://wiki.alopex.li/ElixirForCynicalCurmudgeons",
    "originBody": "Login / Get an account viewedithistorydiscuss ElixirForCynicalCurmudgeons Introduction Elixir The sales pitch I hate sales pitches The epiphany maniacal laughter Introduction This is an attempt to wrap my head around using the Phoenix web framework for a small project. However, it got too long so I broke it into two parts. This is part 1 and just talks about the Elixir language, part 2 is PhoenixForCynicalCurmudgeons but that is still WIP. However, I realized that I have a number of attitude issues that make Phoenix hard to start getting into, so I’m going to attempt to write about it in a way that makes sense to me. My issues are: I don’t actually know Erlang too well in practice I don’t actually know web programming too well in practice I don’t actually like web programming much I’ve spent the last 10 years being the go-to person to fix every random technical thing that could screw up, and am thus something of a pessimist and a control freak The world is burning down around us and none of us can do anything about it So, if you share some of these issues, maybe this doc will be useful to you. This will not teach you Elixir or Phoenix, but it may help you figure out how to think about them. This is a supplement to the official docs, not a replacement, so it won’t try to cover the things that those docs explain well. Disclaimer: As far as I know this is correct, but there’s probably details I’m missing or misinterpreting. Don’t take this as gospel. I am not an expert, I am merely a determined idiot. Last updated in August 2023. It uses Elixir 1.14, Erlang/OTP 25 and Phoenix 1.7.7. Elixir Really what I want to get a handle on is the web framework Phoenix. But Phoenix is written in the Elixir programming language, so to tackle Phoenix, we must tackle Elixir. The sales pitch I’m not going to spend too long singing the praises of The Erlang/OTP Platform, I assume if you’re here then you already know enough to be interested. Long story short, it gives you multiprocessing via communicating independent processes, makes almost all state immutable so these independent processes can only talk with each other via messages, and gives you bunches of tools for handling the failure and restarting of processes, as well as inspecting and changing code at runtime. It runs on a VM called BEAM, because for various reasons the conventional Unix process model can’t actually give the same level of robustness and introspection that you can get with a sandboxed virtual machine. Erlang itself is a wild programming language made in the late 80’s that started with Prolog with a sprinkling of Lisp here and there and turned it into a language like nothing else on this earth. Elixir is a much newer and more comfy-looking programming language that started in 2012 and also compiles to the BEAM VM, offering good compatibility with Erlang code. I love Erlang but have never really used it In Anger; the biggest thing I’ve written with it is a card game. I have dipped in and out of it many times over the years, but most of the time I just don’t have a lot of use cases where it’s obviously the best choice over something else. It has always seemed like the ideal tool for non-trivial web applications, but I never really had a need to write that. But I recently had an idea I want to try to write for an actual web service that’s not a static generated site or a tiny mono-purpose API, so I figured I’d take a good stab at using Erlang or Elixir for it. Elixir at first blush looks like they just took Erlang and re-skinned it to look like Ruby. However, Elixir offers some modest but meaningful functional upgrades over Erlang: Nested modules. Erlang has a flat module namespace, you can make a module named foo but you can’t put a module named bar into it and get foo/bar or foo.bar. This is Fine but not ideal, you generally end up faking the nesting and making a module named foo_bar anyway. Erlang doesn’t care, but it also doesn’t help you. Better strings. Erlang strings are by default a linked list of characters, which probably made a lot more sense for a telecoms infrastructure language in the late 1980’s than it does for a web language in the 2020’s. This still actually works half decently because a lot of I/O can be done with lists of substrings rather than creating/modifying existing strings, but it’s still not ideal. But Erlang also has bit-strings which are immutable arrays of arbitrary bytes, and you can stuff ASCII or UTF-8 data into those and use them as strings too. In Elixir the defaults are flipped: strings are immutable arrays by default, and if you need to talk to Erlang code that expects the linked-list type of string you can create them. It still keeps the scatter-list-y I/O model though, so constructing a new string out of a bunch of pieces with a format function or such won’t allocate a new buffer and copy the strings into it, it will just produce a list of packed string fragments. Elixir strings also assume UTF-8 by default; Erlang bit-strings assume no particular encoding. Nicer structure syntax. Erlang is sort of weird ’cause for the longest time structs were not first-class objects, they were just tuples with macros for creating and accessing them. Erlang is a very dynamic language that tends to say that abstraction is done by functions and interfaces, and if you need to rummage around in the guts of your data structures then you should. However, its creators really didn’t want to add hashtables everywhere as a general-purpose structure the way that Python and Ruby do, so they just sat and mulled on the problem. They did eventually add real structures/records, which are much nicer wrappers around tuples, but they’re still a little tacked-on. Elixir’s maps are basically the same as Erlang’s structures (records, whatever), but more convenient. Bigger stdlib. Erlang’s stdlib is pretty nice, Elixir’s adds to it. ’Nuff said. Better macros. Erlang has actually fairly powerful macros but they are, frankly, a cleaned up C preprocessor. You can define constants, include files, do some basic ifdef stuff, shit like that. You can get significantly fancier, but it’s pretty clear that you’re usually not intended to; the reference docs barely tell you anything about it. I hate sales pitches However, there’s also a bunch of cognitive bumps for me to overcome when trying to learn Elixir: All the syntactic sugar. Elixir looks like Ruby, which is quite loosey-goosey and malleable, and Elixir is even more malleable. There’s a lot of bits in the first half of the tutorial that say “you can also write it like this…” and gives you some uncertain thing with less punctuation involved At first glance, it feels like it tries excessively hard to make things pretty rather than good, and the way Phoenix writes code makes that worse. It’s easy to feel like it’s all just sugar rather than content. Bigger language, period. Erlang is very appealingly simple; there’s a small number of constructs that then fit together pretty well. Sometimes it’s a little clunky, but if you look at some Erlang code then there’s not much fanciness outside of how message and processes interact; it generally just does what it says it does. Elixir has a lot more going on at many different levels; why do we need that? Big complicated project structure. You can make an Elixir project that’s just a single script or a directory with a small collection of files, but the docs prefer to plunge you into its build tool mix, designing an OTP application, how GenServer works, etc. It’s all significantly more complicated to pick up and get going with mix than with cargo, zig or other tools I’m more familiar with. Some of it like OTP and GenServer are already familiar from Erlang, but in that case what does Elixir add over just using Erlang again? Tries fairly hard to look hip. The presentation for both Elixir and Phoenix is quite shiny, it has lots of very friendly introductions that tell you how great it is, all the features it has, and how it’s totally worth all this extra complexity to get into it and do everything with its awesome new paradigm. This makes me automatically distrust it. It’s honestly not that bad, and in my more forgiving moments I have a hard time looking at the Elixir website and docs and realistically saying that I could do better, but I still end up feeling like there’s still a certain amount of hype to machete your way through before you get to the content. See the “cynical curmudgeon” part; the harder something tries to convince me of anything, the more I expect it to suck. If someone just takes Erlang, slaps on a friendly Ruby-ish syntax and a few modest upgrades and touts it as the Next Big Thing, do I really trust anything they have to say? So I’ve looked at Elixir before but this has kinda tended to turn me off, even with Elixir’s benefits. I can get all those benefits in Erlang, it just takes a little more work. Why should I bother learning a new language with ten million special syntax frills, all sorts of domain-specific tooling, a new stdlib, etc? There’s nothing fundamentally wrong with that stuff, but most of the time it’s really not my jam. I much prefer starting off with a small, simple system and then incrementally adding bits in a controlled fashion… especially when I want to make a reliable, robust, complex system with an unfamiliar tool in an unfamiliar problem domain. If I’m going to use something big and complicated then it needs to make it worth it – Rust crosses this threshold for me, for example, because it does things other languages literally cannot. Meanwhile, Elixir starts off feeling like it wants to hold your hand a lot. Erlang is a pretty small, conservative language where, despite its 1980’s warts, you write what you mean and that’s what you get. In contrast, it’s easy to get the impression that Elixir is trying to be Magical and thus actually just hiding all the real work. Yes, this is kinda bitchy, but I’m not here to rant. I’ve looked at Elixir reasonably seriously several times before, and every time it left a bad taste in my mouth and I went “whatever, I’ll just use Erlang instead”. So in writing this I wanted to look at why I felt that way. This is the root of my curmudgeoniness: Magic is never worth it. 99% of the time, Magic breaks. And when it does, and someone inevitably asks me to help fix it, I do it by getting out the machete and chopping out all the happy shiny convenient shit until you can see what is actually going on. And when you dig through the Magic and try to figure out what the hell is actually going on, most of the time it’s either stupid and broken by design, or it’s not very magical at all and you’re just like “why didn’t you just say this in the first place?” This has happened to me again and again in all sorts of places; here’s a list of real examples from work I’ve run into in the last couple years alone: A distributed service does Magical Autodiscovery to find other nodes on the network without needing a central index? It just scans for UDP ports that are willing to talk to it, starting with a Well-Known Port Number and trying each in sequence until it thinks it’s found everything. A proprietary monitoring GUI for that service which Magically lets you inspect it remotely? It just uses an existing open-source program that collects that information and ships it to you over websocket. A website Magically presents a live-updating display without needing a Full Front-End Javascript Framework? It’s just an iframe that is refreshed every five seconds. A communication protocol you want to implement that provides a set of RPC messages you need to receive and respond to and it all Magically clicks together? Nope, turns out there’s a lot of undocumented assumptions about what messages are sent when and in what order, and you have to poke at the client and massage your server’s output until you manage to figure out what it actually expects. Over and over again, it turns out that there is no such thing as Magic, and anyone who says otherwise is skimming over details that will bite you in the ass later on. This is fine for many purposes, because 90% of programs are small hacks and one-off tools and so “later” very seldom actually happens. But in those cases, why are you using a big, complicated language like Elixir in the first place, especially when there’s already the more minimal Erlang sitting right there waiting to be picked up? It’s a pretty tough sell. The epiphany But I still felt like Elixir deserved a good hard go, so I shrugged off my prejudice and started digging. I read the tutorials for Elixir and Phoenix, trusted that the people who were sensible enough to build a web system atop Erlang are sensible enough to know what they’re doing, and tried to put the pieces together. When gradually, bit by bit, I realized what was going on and everything made much more sense. Here’s the trick about Elixir: Elixir is actually a Lisp. Elixir is actually a Lisp. It doesn’t have the parenthesis, but it does have most of the things things that make Common Lisp very flexible, very powerful, very dynamic, and very metaprogramming-heavy. I don’t actually enjoy Common Lisp itself very much ’cause it comes with a lot of baggage and doesn’t have most of the things that have been developed since 2000 or so to make programming less painful, but Elixir does. Elixir also has all of Erlang’s goodness still present: true immutability, pervasive pattern matching, extensive symbolic programming, optional/gradual typing, etc. It doesn’t do this alone of course; as I said, Erlang has a fair dollop of Lisp in its genetics already. BEAM is already probably 75% of a Lisp runtime in terms of how easy it is to introspect, modify, dig into and poke around with, but Erlang doesn’t do a whole lot to take advantage of that directly until you start actually getting deep into the guts of the runtime libraries, which is not the easiest thing to do. Elixir on the other hand takes advantage of all that introspective power right from the start and runs with it, and runs with it hard. It’s relatively hard to find Erlang programs and stuff written about Erlang that really takes you through all the various tools and how to put them together into something awesome; there’s a very solid handful of books and docs and such, but apart from that people don’t seem to talk about Erlang very much, or if they do it’s the same “Intro to OTP” content every single time. Meanwhile the Phoenix web framework appears to be a pretty good and honestly quite interesting example of how to write Elixir programs and libraries in the large, so you can dig into something Real and Complex and see how it can all be put together. I bitched about all of Elixir’s syntactic sugar and how much special-case nonsense it appears to do. For example, here’s a basic hello world in Elixir: defmodule Hello do def greet() do IO.puts(\"Hello world!\") end end Hello.greet() So far so good. defmodule defines a module, and it consists of function/method definitions starting with def ... do ... end, nothing particularly surprising. Now, here’s a snippet from the default Phoenix project template for my wiki test project, Otter: defmodule OtterWeb.Router do use OtterWeb, :router pipeline :browser do plug :accepts, [\"html\"] plug :fetch_session plug :fetch_live_flash plug :put_root_layout, html: {OtterWeb.Layouts, :root} plug :protect_from_forgery plug :put_secure_browser_headers end pipeline :api do plug :accepts, [\"json\"] end scope \"/\", OtterWeb do pipe_through :browser get \"/\", PageController, :home end scope \"/api\", OtterWeb do pipe_through :api end if Application.compile_env(:otter, :dev_routes) do import Phoenix.LiveDashboard.Router scope \"/dev\" do pipe_through :browser live_dashboard \"/dashboard\", metrics: OtterWeb.Telemetry forward \"/mailbox\", Plug.Swoosh.MailboxPreview end end end What the hell is going on here? use is fairly normal, it’s just a module import that calls a callback to initialize stuff in that module. (It isn’t, but that’s what you think at first.) But this module has scope blocks and pipeline blocks, they’re right under the top-level defmodule, they contain a bunch of weird plug or pipe_through statements… this isn’t Elixir, it’s some weird special-purpose domain-specific language that Elixir just… happens to have built into it somehow? Why does Elixir let a library write all this special custom syntax? Is this just part of the language somehow because Phoenix is its flagship software? Hang on, there’s an if expression at the end of the module that looks like it’s run at compile time… can you even do that? The language tutorial never heckin’ does that! Buckle up, we’re in for a trip. ’Cause here’s the trick: Elixir actually has only one syntax for calling a function or a macro: foo(arg1, arg2, arg3). That’s all. Every function or macro call will turn into that format, and that’s the format the documentation will show you too. So let’s see how the various layers of syntactic sugar work with that basis… First, because Elixir likes Ruby (and for pretty good reasons), you can generally ditch the parens around a function call and just write it as foo arg1, arg2, arg3. Ok, fine, that’s fairly sensible. Now if you have a function that takes a variable number of keyword arguments, you just make the last function arg an assoc list, a list of key-value pairs where the key is an atom. (Resist the curmudgeonly urge to get all “hashtables and arrays are better” here, these linked lists are generally short with good memory locality, it’s Fine.) So if you want a function with a variable numbers of params you can define it as foo(arg1, params) and call it as foo arg1, [{:arg2, something}, {:arg3, something_else}]. (:foo is what Lisp calls a symbol, Erlang/Elixir calls an atom, and most of the rest of the world calls an interned string. They are immutable, uniquely identified by name and only by name, and compile down to integers.) Since assoc lists are pretty common, there’s a piece of syntactic sugar for them that looks more dictionary-like: [key1: val1, key2: val2] is equivalent to [{:key1, val1}, {:key2, val2}]. Moving the colon makes my brain fritz a little bit but the result looks nice. So you can call a function and give it an assoc list as an argument just with foo arg1, [arg2: something, arg3: something_else]. That’s nice, but really as long as our assoc list is the last thing being passed to the function we don’t need the outer brackets of the list either, so sure, just make it so you can call foo arg1, arg2: something, arg3: something_else. Are you yet thinking “oh no… they wouldn’t”? I have news for you: oh yes they would. This only works in some places and I still haven’t figured out quite all the rules, but do, followed by a newline, followed by end, is in fact sugar for an assoc list. So if you write: foo thing do 10 end then it is equivalent to actually calling foo thing, do: 10. Or rather, foo(thing, [{:do, 10}]). And what do you know, if foo is not a function but a macro, then the syntax is exactly the same but the contents of the assoc list it gets passed is not the evaluated expression between the do and end, it’s a syntax tree. Made, naturally, of lists and tuples and atoms. So going back to our weird Phoenix module with all the new block types? All those blocks that are written in the format of magical_keyword value do ... end? All macros. scope is a macro. pipeline is a macro. So defmodule can contain any kind of macro call? …wait, that means… if is a macro. def is a macro. defmodule is a macro. It’s all macros. It’s ALL MACROS! ALL THE WAY DOWN! AAAAAAAAAA AHAHAHAHAHHAHAAAA! maniacal laughter This is not done naively though, oh no! Elixir takes other things from Lisp-y origins as well. Wonderful things! For example, a string is written \"foo\". Sensible enough. Making an old-style Erlang list-y string is ~c\"foo\", sure. Making a regex is ~r/foo/, ok, so the ~ is general syntax for “string-ish thing”, the way that \\x in a string in most languages is general syntax for “some special character”. Not quite! Elixir calls it a “sigil”, but you can define your own sigils just by writing a function that takes a string and does something with it and returns some data, and bam, it works. Common Lisp calls these “reader macros”. They’re rather a pain in the ass though, Elixir’s version is a much nicer shortcut for most of the things that you would actually want to use them for. So the Elixir creators haven’t just stolen macros and homoiconic syntax from Lisp, they’ve rummaged deeper into “what made Lisp awesome” and pulled out other bits too. And also stolen liberally from other languages! There’s an equivalent to Rust’s dbg!() macro that prints an expression’s code and its result, then goes further and optionally breaks into the interactive debugger, pry, which appears more juiced up than Erlang’s debugger. They’ve stolen |> expression-pipeline syntax from the Haskell/ML world. They’ve taken a lot of the interactive documentation functions that make Python so easy to poke around in from the REPL. You know, all the good shit. Also note that while we have like 4 layers of syntactic sugar between foo([{:do, 3}]) and foo do 3 end, they are truly layers. Each one fits neatly inside the previous one with no overlapping edge cases or hazardous interactions. They’re not separate features that you have to jig-saw together in some intricate manner where everything explodes if you overlook something. It’s always just a function/macro call that takes an assoc list as its last parameter. (There actually is one sharp edge, do\\n ...\\n end vs do: ...\\n, but don’t harsh my groove.) Oh, then there’s use. You know how I said “use is fairly normal, it’s just a module import that calls a callback to initialize stuff”, and then noted that the truth was more complicated and moved on? The truth is way more interesting: use Thing, option: something imports the module Thing like require does, then calls Thing.__using__(option: something). The trick is that the __using__() function usually isn’t called for its side effects, though that might happen occasionally. In fact, if you read the docs more carefully it never says that __using__() is a function at all, just “a callback”. Quite often, __using__() is in fact a macro. A macro that will generate and return some code, which is then spliced into your module where you wrote the use statement. So you can write a Thing.__using__() macro such that use Thing actually expands into require Thing1; require Thing2; def some_cool_method() ...; use SomeOtherThing. use doesn’t import a module’s definitions into your module’s namespace, it gives that module permission to generate arbitrary code in your module’s namespace. So be very aware when reading or writing Elixir code: whenever you see use invoked, it’s actually some kind of turbo-macro that is probably defining a bunch of exciting new things for you! There’s probably more, but I haven’t found it yet. I’m having too much fun to dig for many more details. Because, I’ll say it, Elixir is a better Lisp than Common Lisp or Scheme. Writing either of those comes with a lot of problems you have to solve to get started compared to, say, Clojure or Fennel: libs, package manager, FFI, build system, how to distribute applications, etc. No Lisp I know of has had the kind of robustness and multiprocessing power that BEAM can give you (unless it was already written for BEAM ). Erlang’s pattern-matching is top-tier, and Elixir inherits all of that. Erlang has a bunch of libs and tools for monitoring and poking around inside a running application, and Elixir uses them and adds more. And so on. And that’s the thing about Elixir’s version of magic: none of it is actually hidden. They don’t try to pretend it’s magic, they tell you exactly how it works in the first half of the tutorial! It just, you know, takes a bit of work to actually absorb what they’re telling you and figure out how it all interacts. Most of the structures that form the guts of the runtime are made out of lists and tuples and atoms, which feels weird to a Rust person who is used to structs and types which are not interchangeable and never public unless you know for sure they’re supposed to be. Erlang and Elixir are just like, go ahead, poke around, make changes, break shit! Because unlike Common Lisp with its state baked in manually to an image, everything can be automatically restored to a clean slate when you tell it to starting from a declarative project specification. Elixir hides nothing behind “magic”. It wants you to poke around in its magical bits. Yeah you’ll break shit, here, have the tools you need to make sure that shit doesn’t break in production. Just use them! It’s been a long time since a programming language made me this happy. computerprogrammingwriting powered by gitit Site Front page All pages Categories Random page Recent activity Upload a file Help This page Raw page source Printable version Delete this page",
    "commentLink": "https://news.ycombinator.com/item?id=36986769",
    "commentBody": "Elixir for cynical curmudgeons | Hacker NewsHacker News new | comments | ask | show | jobs | submitloginElixir for cynical curmudgeons (alopex.li) 416 points by todsacerdoti 19 hours ago| 210 comments freedomben 1What a terrific write up! I highly recommend the read.I too had an ephiphany when I realized Elixir was actually a Lisp. The language went from mildly interesting to \"holy crap I think this could be my favorite language.\" Add on some wildly productive and pragmatic frameworks like Phoenix, Nerves, and increasingly Nx, and you&#x27;ve got a hell of a toolkit.My biggest criticism of Elixir has been the difficulty of writing quick scripts, but that story has improved greatly over the last couple of years. I still turn to Ruby for scripts (especially since it&#x27;s often present on systems and so easy to install), but this is a good reminder that it&#x27;s time to try Elixir again for that. In some ways it may be better, such as dealing with dependencies. For exmaple I try hard to avoid using any non-standard libs with Ruby scripts so I can just use the system ruby, and don&#x27;t have to ship a Gemfile and&#x2F;or install any gems, or mess with chruby&#x2F;asdf. With Elixir that story looks even better since the deps can be part of the script itself. reply capableweb 1> I too had an ephiphany when I realized Elixir was actually a Lisp.Is it actually? Last time I looked at Elixir (granted, that was a while ago), the syntax for writing macros was different than the syntax for writing ordinary code, so it fails even at a simple thing like that, it doesn&#x27;t seem to support homogeneous meta-programming at all.But again, I feel like I might be wrong here and I&#x27;m happy to be proven wrong. reply sodapopcan 1Ya, it&#x27;s not actually a lisp. I can&#x27;t find the source but José has stated part of the idea was to give you lisp-like metaprogramming with a non-lisp syntax (sorry, José, if I have mis-quoted).Even the regular syntax is sort of lispish, though, if you remove the syntactic sugar. It&#x27;s all macros and datastructres. defmodule Foo do def bar do \"baz\" end endis really: defmodule Foo, do: (def bar, do: \"baz\")...which is lispish if you squint the right way. reply zambal 1A bit pedantic I guess, but that still uses some syntactic sugar (optional brackets and keyword syntax). Removing all syntactic sugar would look like this: defmodule(Foo, [{:do, def(:bar, [{:do, \"baz\"}])}])Even aliases (like Foo) are also a kind of syntactic sugar for a specific type of atom (Foo is actually the atom :\"Elixir.Foo\") reply sodapopcan 1Ha, ya I meant remove the `do` sugar. reply foldr 1That’s just syntax sugar. Even the original Lisp was supposed to have sugar on top of S-expressions, although that never really happened.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;M-expression reply jjtheblunt 1I think Mathematica has had a slight variant since 1988 (i&#x27;ve been using it since then, but never M-expressions, but they look awfully similar). reply anamexis 1It&#x27;s listed under the \"Implementations\" section of that wiki article. reply pmarreck You can write macros (as well as functions, actually) that accept AST and emit transformed AST back. It has quote and unquote. Turns out that it doesn&#x27;t need homoiconicity to accomplish Lisp-level macro capability, which means it has all the power of a Lisp but with actual syntax (which is, like it or not, more appealing to many people) in a language with deep pattern-matching and completely immutable data guarantees. reply bmitc 1What is the actual failure? The macros are written with and by processing the built-in data structures. reply jrochkind1 1> For exmaple I try hard to avoid using any non-standard libs with Ruby scripts so I can just use the system ruby, and don&#x27;t have to ship a Gemfile and&#x2F;or install any gemsThe ruby \"story\" for Gemfile dependencies for single-file scripts have gotten a BIT better since possibly last time you looked at it.It will of course necessarily involve installing gems still though. Ideally for your use case, I feel like you&#x27;d want to install them to a local (not system-default) location ... which is ordinarily possible with bundler, but oddly the maintainers seem to think it&#x27;s an anti-use-case for inline bundler? https:&#x2F;&#x2F;github.com&#x2F;rubygems&#x2F;bundler&#x2F;issues&#x2F;7131. I dunno.Anyway, I put this here not to convince you, your decision is reasonable, but just other info for other readers. reply malkosta Problem with writing scripts in Erlang VM is the slow startup time...it isn&#x27;t suited for that. Although I love it for pretty much everything else besides scripts and executables. reply ghayes Also it’s not the best for creating OS processes and&#x2F;or interacting with stdio. reply vfclists It needs a Babashka equivalent. reply pmarreck Yeah, this miffs me too (a half second startup time, locally), which has got me even looking at languages like Idris that can compile down to C and then thus to an instant-start app. reply toast0 You can definitely get startup mich faster than half a second if you tweak the start script and maybe start only one scheduler, etc.I don&#x27;t think it will be great without heroics, but a little work and I think you can get it down toMy biggest criticism of Elixir has been the difficulty of writing quick scriptsCurious what you find to be the biggest pain point(s) here. Is it runtime containment? Library access? Etc. reply monsieurbanana 1Is the size of the erlang vm one such point? I think I remember reading it&#x27;s about 500mb, and you won&#x27;t find it installed by default in many systems. reply square_usual 1Startup time is another. For example: $ elixir test.exs hello, world! $ hyperfine \"elixir test.exs\" Benchmark 1: elixir test.exs Time (mean ± σ): 471.1 ms ± 2.6 ms [User: 187.4 ms, System: 83.1 ms] Range (min … max): 467.1 ms … 475.6 ms 10 runsCompared to: $ ruby test.rb hello, world! $ hyperfine \"ruby test.rb\" Benchmark 1: ruby test.rb Time (mean ± σ): 36.3 ms ± 2.6 ms [User: 26.0 ms, System: 8.4 ms] Range (min … max): 34.5 ms … 53.6 ms 53 runsIn practice, I&#x27;ve been able to get the ruby startup time to as low as 6ms - this is what I use for scripts running as keyboard macros, for example. I cannot practically use elixir for that. reply hosh 1Huh, interesting. I bet for keyboard macros, it would work better by invoking a call to something that is already running to reduce startup time. Kinda like the emacs server.BEAM should still be able to compile new code on the fly, for one-off scripts reply square_usual 1> keyboard macros [...] would work better by invoking a call to something that is already running to reduce startup timeMaybe, but that comes with two disadvantages:- I would have to re-architect my scripts to work like that, and run a server with uncertain memory costs perpetually; and - I would have to use something with faster start time to run the call on my keyboard macros, e.g. bash, which would mean writing bash instead of elixir&#x2F;ruby and&#x2F;or being clever. reply barkerja 1Using escript, I am able to almost halve the startup time. But it&#x27;s still ~4x slower than ruby. hyperfine \".&#x2F;derp\" Benchmark 1: .&#x2F;derp Time (mean ± σ): 241.0 ms ± 7.4 ms [User: 146.9 ms, System: 170.8 ms] Range (min … max): 235.1 ms … 261.7 ms 11 runs reply nelsonic Not even close. A Nerves (iOT) package with Linux Kernel and Erlang&#x2F;OTP VM and our App code comes in at 21Mb. See: https:&#x2F;&#x2F;nerves-project.org&#x2F; reply bongobingo1 1Most of my phoenix apps sit under or around 100mb resident, and they load a fair bout more than a script probably would. reply sergiotapia 1Here&#x27;s a great repo showcasing how to use it more like a quick scripting language. https:&#x2F;&#x2F;github.com&#x2F;wojtekmach&#x2F;mix_install_examples reply mcguire 1\"This is the root of my curmudgeoniness: Magic is never worth it. 99% of the time, Magic breaks. And when it does, and someone inevitably asks me to help fix it, I do it by getting out the machete and chopping out all the happy shiny convenient shit until you can see what is actually going on. And when you dig through the Magic and try to figure out what the hell is actually going on, most of the time it’s either stupid and broken by design, or it’s not very magical at all and you’re just like “why didn’t you just say this in the first place?”\"Over and over again, it turns out that there is no such thing as Magic, and anyone who says otherwise is skimming over details that will bite you in the ass later on. This is fine for many purposes, because 90% of programs are small hacks and one-off tools and so “later” very seldom actually happens.\"Oh, yeah. This. So much this. A dump-truck load of this.Even better when everybody is using different Magic, or the guy who set up this Magic left two years ago and everything has been done my cargo-cult since. reply Dowwie 1Things I like about Elixir:- concurrency is intuitive!- Elixir is a two-for-one language. You can reach into Erlang std library as easily as you can that of Elixir. So, depending on your work, you get a chance to discover a wide range of goodies that come for \"free\". Examples include gen_tcp, gb_tree, etc.- You can remote into a running virtual machine in production, pod or whatever, and have access to a repl that let&#x27;s you inspect state, manage \"processes\", and manually invoke commands to troubleshoot issues. The observer, and tui counterpart, are quite useful too.- everyone in the community writing libraries uses the standard approach to emitting telemetry, saving time and effort for users to take what is available- fast compile times- hardest working BDFL (although this presents risks, too), who also has a pleasant, respectful disposition- the community is respectfulThings I don&#x27;t like:- dynamic language leads to pattern matching or type mismatch errors at runtime that could have been caught at compile time- Elixir Phoenix doesn&#x27;t have a large community, nor much up to date reference material, or literature. If you&#x27;re not experienced with Front-end dev, it&#x27;s easier to onboard with a modern SPA framework like React.- supply of Elixir talent exceeds demand, although this isn&#x27;t unique to Elixir (e.g Rust)- slowly growing ecosystem, relatively speaking reply OkayPhysicist 1What the documentation for Elixir and its big libraries (Ecto and Phoenix) lack in quantity of documentation, they exceedingly make up for in quality of documentation. Who needs a bunch of garbage blog posts about how to do xyz, when the official docs painstakingly lay out not only what you need to know, but also present it in a readable and discoverable way? reply lolinder I generally agree, but to play devil&#x27;s advocate: some people learn better by example, and having thousands of (admittedly low quality) blog posts out there makes it more likely that someone will have done something very similar to what you&#x27;re trying to do. reply jpbastyr 1If you&#x27;re a fan of the ecosystem, but not of dynamic types, there are statically typed languages on BEAM, eg Gleam (https:&#x2F;&#x2F;gleam.run&#x2F;) reply nithinbekal > type mismatch errors at runtime that could have been caught at compile timeIt&#x27;s still early, but there are plans to introduce a type system for Elixir:https:&#x2F;&#x2F;elixir-lang.org&#x2F;blog&#x2F;2023&#x2F;06&#x2F;22&#x2F;type-system-updates-... reply melvinroest 1The changing code in production with a REPL reminds me of Pharo. Though, with Pharo you get a whole IDE :DI also feel that Pharo has too small if a community. The ESUG conference is coming up soon though. It’s good to see they’re coming togetherWhy is concurrency intuitive? reply Dowwie 1There&#x27;s no function color. The concurrency patterns are well defined, documented and discussed. You don&#x27;t need to sit in a chat room asking for help from a benevolent core team of maintainers.Granted, I did learn the hard way about introducing cycles but the error messaging lead me to the root of the problem quickly. reply beeburrt 1> supply of Elixir talent exceeds demand, although this isn&#x27;t unique to Elixir (e.g Rust)Is this true? reply sarchertech 1At my current company we’ve many times had to hire and train people who had no elixir experience. If anything I’d say the demand for experienced people exceeds supply. reply di4na As a counter point, nearly all the good senior engineer with experience in elixir i know have all accepted non elixir jobs in the past few years and are still in them.Every time they go on the market for an elixir one, they cannot find good jobs and the few good one reject them.As I regularly point out, i have hired whole elixir teams in 2 months multiple time in the past. If you cannot find us, the problem is that your hiring process and work practices are pushing us out. Not that we do not exist. reply esclerofilo Talent and experience are not the same thing, and I would say experience is a lot more correlated to demand of talent than to supply of it. More demand means more opportunities to get experience. reply Dowwie 1No, I am lying. The most jobs out there are for elixir engineers and managers are struggling to fill vacancies. reply RadiozRadioz 1Why be so unnecessarily subversive? reply bmitc 1Elixir, other than the language itself, has wonderful developer tooling that&#x27;s all written and configured in the language itself. It makes me feel really comfortable because it&#x27;s all right there. You don&#x27;t need external scripting languages. For some programming, you don&#x27;t even need external libraries sometimes. It all feels very OS like, not to mention the OS-like nature of the BEAM.If you&#x27;re on the fence on Erlang or Elixir, watch The Soul of Erlang and Elixir by Sasa Juric: https:&#x2F;&#x2F;youtu.be&#x2F;JvBT4XBdoUEIf it doesn&#x27;t make you excited about a language, I don&#x27;t know what will. It is an astounding feat that the Erlang team at Ericsson were so ahead of the curve and remain so today. reply macintux 1I absolutely love Erlang. It’s a succinct, powerful, amazingly well-thought-out system design with a VM that is very complementary.I just can’t get past all the extra verbosity of Elixir, but this writeup gives me hope that someday I will. reply bmitc Erlang does have that nuts and bolts simplicity going for it, for sure. If it allowed rebinding on variable names and had pipelines, it would be very attractive to me. Elixir comes with a Ruby-esque syntax which I don&#x27;t personally prefer, but I have gotten used to it. The built-in formatter helps out greatly there.I just go all in on Elixir module design just like I would in an ML dialect. So structs, module types, custom types, typespecs, docs, Credo turned up to 11, run Dialyzer, etc. So I embrace some of the verbosity. Some don&#x27;t prefer the style, but those are all features already there, and for me, it helps bridge the gap for Elixir being dynamically typed. Although there are developments coming to give it a static type system. reply bhaney 1> `if` is a macro.> `def` is a macro.> `defmodule` is a macro.> It’s all macros. It’s ALL MACROS! ALL THE WAY DOWN! AAAAAAAAAA AHAHAHAHAHHAHAAAA!Also see the definition for `defmacro`, the macro for defining macros, which is defined using... defmacrohttps:&#x2F;&#x2F;github.com&#x2F;elixir-lang&#x2F;elixir&#x2F;blob&#x2F;v1.15&#x2F;lib&#x2F;elixir&#x2F;... reply aeturnum 1Always glad to see another person finding their way to Elixir!IMO the biggest tripping point for people (including, clearly, this author) is the freedom. They said that the \"Big complicated project structure\" was a stumbling point - but there is no structure! You can actually do it any way you want. But there are conventions. Mix suggests that you lay our your project in a certain way (and most Elixir projects are laid out that way) - but you are not required to by the language.Nearly everything in the language is a convention (including the test &#x2F; dev &#x2F; prod run modes). This applies to Erlang as well. It has standard approaches, but you don&#x27;t &#x2F;have&#x2F; to follow them. I frequently get confused about the way libraries tend to approach something (do you have to do it this way? Is there a requirement?) and the answer is generally \"no, but the community tends to think this is the best way to do it and so people generally do it this way.\"A great example of everything being a convention: structures aren&#x27;t a language feature. They&#x27;re maps with special keys and Elixir library support. The upside and downside to this is that you could actually do almost anything with them - if you have the time and the skill to implement the system. MANY things are like this when you get into it. reply jnsaff2 1If you want to get a mindbending experience of the articles \"it&#x27;s macros all the way down\" then here is one for you in glorious 3 minutes and 39 seconds: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=x5W3CmZJMLs reply tommica 1That&#x27;s pretty cool! reply whalesalad 1The a-ha moment when you grok \"Elixir is actually a Lisp\" is very exciting indeed. It&#x27;s a beautiful language that fits all of its elements together so nicely. reply davidw 1That&#x27;s a pretty good write up.There&#x27;s a fine line between making things easier and more readable and having less boilerplate code, and pouring a bit too much magic and macros into things.I&#x27;m always curious to see what people do with Elixir. The BEAM environment offers a lot in terms of a platform, but if you&#x27;re just using it to serve web dynamic web pages, Rails is going to be a better pick in some circumstances because of the huge number of libraries, people who know it, documentation, hosting and the rest of the ecosystem. reply sodapopcan 1> Rails is going to be a better pick in some circumstances because of the huge number of libraries.This isn&#x27;t really as big a problem as many people think. I&#x27;ve been out of Rails for a while now but haven&#x27;t really felt the pain of missing anything with Phoenix. I&#x27;ve noticed there aren&#x27;t often Elixir wrappers around third party APIs, but those are really not a big deal to create a small version on your own with only what you need. I always used to wrap the wrappers anyway! As far as UI stuff goes, there are actually a lot of really nice vanilla JS libs out there which play really nicely with LiveView&#x27;s JS hooks.I would be interested to hear what people have been sorely missing, though.EDIT: Said \"are\" when I meant \"aren&#x27;t\" reply davidw 1Oh, I don&#x27;t think the library thing and ecosystem is really an obstacle for using Elixir so much as it makes Rails a &#x27;safe bet&#x27;.If I&#x27;m putting on my business hat, I need a reason to use Elixir instead of Rails and that probably has something to do with a better concurrency story, but I&#x27;m always curious to hear what other people are getting out of it.My previous experience with BEAM was using Erlang in a semi-embedded environment and it was fantastic for that. Solid, dependable, deterministic, great response times... all of that. But while we did have a web interface to the system, it wasn&#x27;t a web site. reply bcrosby95 1For us its the simplified production environment. We use BEAM&#x27;s clustering capability to forgo things like redis and&#x2F;or a message queue. It probably doesn&#x27;t matter for every company, but it helps for us where we have zero full time ops people. reply davidw 1That&#x27;s a pretty good reason. Some people might react \"well, you&#x27;re going to need those things broken out anyway as you scale\" or something to that effect, but it can be really nice to just not need them until you have scaled further. There are plenty of smaller applications where you just don&#x27;t want or need all the extras and the longer you can keep it simpler, the better off you are. reply sodapopcan 1Ya, this is one big bonus in my eyes. I have certainly hear the argument several times that \"installing redis is really easy\" and it is! But it&#x27;s another moving part that often isn&#x27;t necessary with BEAM.In a current project I&#x27;m also able to use OTP to create a single microservice for my monolith that runs on its own node and the two can communicate with run-of-the-mill message passing without the need for an HTTP API. reply OkayPhysicist 1The BEAM&#x27;s multi-node scaling works really well. The argument that you&#x27;ll need to break things out if you get big enough doesn&#x27;t really hold water. reply davidw 1BEAM isn&#x27;t magic scaling sauce, and you&#x27;re going to run into trouble if you get big enough. But that&#x27;s a \"good problem to have\". And it&#x27;s probably &#x27;enough&#x27; for many businesses as-is. reply OkayPhysicist 1It&#x27;s not magic, but neither are any of the alternatives. There needs to be a compelling \"my constellation of services written in a variety of languages, communicating via a half-baked homebrew collection of API calls beats a constellation of distributed Erlang applications communicating via message passing over the BEAM\" to claim that Erlang has scaling issues relative to the alternative.The reality is that asynchronous, parallel, distributed computing is hard, Erlang makes it easier. Not easy, but easier. reply hosh 1And even if you need to break things out, you can build different variants of distributions that can all still work together. reply toast0 1> Some people might react \"well, you&#x27;re going to need those things broken out anyway as you scale\" or something to that effect, but it can be really nice to just not need them until you have scaled further.Dist messaging and mnesia scale pretty far. Although it must be noted that they were original built around rock solid networking (two nodes in one chasis), so if your networking is flakey, you have to handle that; my recommendation is to make your network not flakey, but that&#x27;s easier to say than it is to do. reply davidw 1I would pair BEAM with Postgres, not Mnesia as that&#x27;s going to limit you in a lot of ways. Unless you reaaaaaally know what you&#x27;re doing. reply toast0 Well, I like to think I know what I&#x27;m doing. And I&#x27;ve participated in some big Mnesia operations.That said, redis is in memory key-value, and Mnesia does in memory key-value too. If you&#x27;re using Postgres&#x27;s relational stuff or data bigger than memory, that&#x27;s a different thing. Mnesia has some relational facilities, but I dunno if anybody uses them much; mnesia can use disc_only_copies, but that&#x27;s not a good time. Of course, memory only gets you pretty big tables these days; I ran some mnesia nodes with 768GB, but a couple TB isn&#x27;t too hard to put together these days. reply hmmokidk 1And if you forgo those things you can easily test them. reply arrowsmith 1My reason to use Phoenix instead of Rails: development speed. I&#x27;m just so blazingly productive in Phoenix that nothing else compares, including Rails. Every time I&#x27;m forced to develop in another framework I now get agonisingly frustrated by how long it takes to get anything done. reply arrowsmith 1Your experience matches mine. And ChatGPT has been a game-changer - if there isn&#x27;t an Elixir library for some third-party API, GPT is very good at generating some wrapper functions in Elixir using the API docs. reply cschmatzler 1Phoenix is obviously “the big thing” and no other language&#x2F;framework combination has something as good as LiveView. Rails cannot compete there. Other than that, building Livebook apps for our customer success team has been really great and easy.There’s quite a big push for ML in Elixir right now, and then there’s also Nerves for embedded programming, which I’ve never dabbled in but it looks nice. reply OkayPhysicist 1LiveView is definitely Elixir&#x27;s killer app. It&#x27;s what takes Phoenix from \"a really good web framework\" to \"the singular best web framework\", in my experience. Ecto is also a best-in-class data-layer adapter (ORM seems wrong and reductive). reply sethammons 53 I&#x27;m primarily a Go developer who loathes ORMs. I have to admit that Ecto is pretty great. reply slekker 1Do you have any write up about Livebooks for your CS team? Sounds like an interesting use case! reply metaltyphoon > no other language&#x2F;framework combination has something as good as LiveViewYou just have to look. Blazor does what LiveView do and on upcoming. NET 8 it will leapfrog it. reply porker People have been saying this about Blazor for years, and it&#x27;s never reached that point.Where can I see what .NET 8 will bring to Blazor to change this? reply cultofmetatron 1ecto is also just an amazing db wrapper in general. you basically write sql in elixir which means you can optimize the crap out of your queries and its easy to steop down to actual sql where needed via fragments. reply hosh 1And you can still use composable queries if you still want to (equivalent to Rail’s named scopes). reply pdimitar 1The transparent parallelism makes it an amazing fit for pretty much anything and everything that doesn&#x27;t require minimum system resources and microsecond-level of response times.1. Web apps work awesomely because they tolerate sudden bursts of load much, much better than Rails. Rails deployments regularly fall over on bursty workloads unless complex load-balancing setups have been put in front of them.2. Which brings me to: operations &#x2F; infra story is much simpler, and it is thus cheaper and easier to maintain Elixir apps, even when they span multiple nodes (because Erlang&#x27;s builtin mechanism to do mesh networking &#x2F; distribution works well enough for 99% of the projects out there).3. Complex service trees f.ex. scrapers that also present their data in a visual CMS backoffice UI and background tasks infrastructure -- all of that can live on literally the same node, share the same code repo and be very easy to manage and maintain as a result.4. Oh, that also reminds me: almost anything and everything you would need Redis for, you can have it natively with Erlang&#x2F;Elixir.5. Corollary to point 3: long-lived daemons that are not even web apps &#x2F; APIs work really well under Elixir due to the supervision tree guarantees of Erlang&#x27;s underlying OTP framework. If you configure it well (the defaults are not always optimal) you can have your invisible mesh of services survive extended outages of the 3rd party APIs it depends on.6. In the last years, LiveView and Livebooks are amazing additions that help severely reduce the need of JS and provide an alternative to Jupyter Notebooks, respectively. Though it has to be said that LiveView works best when the latencies to the backend aren&#x27;t too big, say, 200ms or less. Beyond one certain human perception threshold it starts to feel sluggish however.I could go on and on and give plenty of examples from my career. I&#x27;ve replaced a lot of shell scripts and PHP &#x2F; Python &#x2F; JS services with Elixir, and each migration was a crushing success in every way. We&#x27;re talking 15+ such projects. Only 1-2 of them got back to their original language simply because the companies &#x2F; teams were too risk-averse and didn&#x27;t want to hire Elixir devs (or train their current people). But the network effects are always a chicken-and-egg problem; if people never want to bet something on the tech then it obviously is never going to be appealing to them.There are many who made the plunge though and are happy with the results. reply davidw 1> If you configure it well (the defaults are not always optimal) you can have your invisible mesh of services survive extended outages of the 3rd party APIs it depends on.This is something that annoyed me a bit with OTP. The basic strategies aren&#x27;t really enough for that, so you need something like https:&#x2F;&#x2F;github.com&#x2F;jlouis&#x2F;fuseI wrote something like that myself, but it hasn&#x27;t seen a ton of use: https:&#x2F;&#x2F;github.com&#x2F;davidw&#x2F;hardcore reply megaboy101 1Where I previously worked we used Elixir as the backend for a early-stage social app.We only really encountered the lack-of-libraries issue a single time (we needed a Neo4j driver that supported their hosting platform).But aside from that, Elixir was a great choice and served us well. When our app went semi-viral all we needed to do was increase our instance size in AWS, never really needed to worry about horizontal scaling thankfully.Our app also needed a lot of realtime messaging and updates, which was genuinely a breeze with Phoenix. I don’t think I could ever to back to trying to finagle a websocket API in Python. reply hosh 1If anything, scaling Elixir apps favors vertical scaling. Horizontal scaling starts hitting the limits of dist erlang (since, unless you restrict the topolog, every node connects with every other node).It makes for an interesting time when deploying to Kubernetes. But we figured out how to increase the number of cores per erl node during peak daily traffic.I’m working for a Nodejs shop now. For all its use of async stuff, it simply does not scale as well as Elixir (not to mention the deep dysfunctions in the Nodejs ecosystem). reply dsiegel2275 1If I recall the things I&#x27;ve read on this in the past, the horizontal scaling limitations of distributed Erlang are encountered around like 500 to 1,000 nodes? Which I have to imagine means the large, large majority of shops using Elixir and scaling horizontally will be just fine, as they are typically in the size of 2 - 10, or maybe 20 nodes. reply hosh 33 There is a reason stuff like Partisan were conceived - https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1802.02652If you do a lot of cross node talk with say, the Phoenix channels, then lowering the total number of nodes helps (n*(n-1) for a full mesh). And since the BEAM scheduler will try to use up all available cores by default, past a certain threshold of nodes, it makes more sense to use smaller numbers of nodes with more cores per node. When you also have say, an observaility agent taking up 1000 mcore, doubling the instance size makes a difference. In the last shop, we would idle at 4-cores, jump to 16-cores instance sizes for the morning rush, and go back to 8-cores for the late afternoon traffic. I had tried to horizontally scale it with 4-cores machines, but saw a lot more instability and performance issues.This is one of the advantages with using Elixir or Erlang. You simply don’t get this kind of operational characteristics with Ruby, Python, or Nodejs. reply hosh 1Having done both Rails and Elixir, Elixir is vastly easier to scale. Not just because it can use up all the available cores, but also because a REPL in a production environment makes troubleshooting and identifying bottlenecks easier. When I scaled Rails, it was a struggle, and the epiphany I had when I had to modify how Sidekick worked was that Elixir and Erlang had built-in primitives to do what is major refactor of Sidekick to get Sidekick to do what I want.One of the things I had success with in a non-web applications is writing Kubernetes Operators in Elixir. Though I also want to experiment with the embedded Prolog-in-Elixir for those. reply chubot 1I&#x27;m also looking at Elixir and Phoenix (coming from Python&#x2F;C++), and it looks cool. Doing realtime features with Python requires something like Tornado &#x2F; asyncio, which isn&#x27;t ideal IMO.I&#x27;m all for the immutable &#x2F; message-passing architecture in the large, but I wish that you could just write Python-style code within processes. The VM copies all data structures at process boundaries anyway.I think that language would be very popular!I wrote Lisp 20 years ago, before Python, but now it feels a little annoying to \"invert\" all my code, for what seems like no benefite.g. from https:&#x2F;&#x2F;learnxinyminutes.com&#x2F;docs&#x2F;elixir&#x2F; defmodule Recursion do def sum_list([head | tail], acc) do sum_list(tail, acc + head) end def sum_list([], acc) do acc end endI would rather just write def sum_list(L): result = 0 for item in L: result += item return resultBut then also have the Erlang VM to schedule processes and pass immutable messages.There is obviously a builtin in Python that does this, and I&#x27;m sure there is a better way to do this in Elixir. But I think the general principle does hold. reply pythonaut_16 1Have you seen Elixir list comprehensions? iex> for nl = 1..3 # equivalent to [1,2,3] iex> Enum.reduce(l, fn item, acc -> acc + item end) # or iex> Enum.reduce(l, &(&1+&2) # or the built in iex> Enum.sum(l) # all return: 6https:&#x2F;&#x2F;elixir-lang.org&#x2F;getting-started&#x2F;comprehensions.html https:&#x2F;&#x2F;hexdocs.pm&#x2F;elixir&#x2F;1.12&#x2F;Enum.html#reduce&#x2F;2 https:&#x2F;&#x2F;hexdocs.pm&#x2F;elixir&#x2F;1.12&#x2F;Enum.html#sum&#x2F;1None of which take away from your point though: it&#x27;s definitely a different mental model than you use for Python&#x2F;Go&#x2F;Javascript. reply chubot Yes though Python has list comprehensions too :)I should have picked a different example -- the idea I was trying to get across was that mutability within a loop is useful.Here’s a similar question I asked with Python vs. OCaml and Lisp. Short-circuiting loops seems to cause the code to become fairly ugly in functional languageshttps:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;ProgrammingLanguages&#x2F;comments&#x2F;puao1... reply jclem 1You can reduce with list comprehensions in Elixir, but it&#x27;s uncommon to see: sum_list = fn list -> for itemsum + item) end sum_list.([1,2,3])Other comments are correct that `Enum.reduce&#x2F;2` is probably better: Enum.reduce(list, &(&1 + &2))Obviously you don&#x27;t have the flexibility &#x2F; mutability you refer to in other comments with either of these, but you can always put more in your accumulator: get_sum_and_update_count = fn list, map -> for item{sum + item, Map.update(map, item, 1, &(&1 + 1))}) end(A contrived function that returns a list sum and an updated map with the count of the values found in the list) reply bcrosby95 1Built ins aside, I find most uses of recursion to be better served by Enum.reduce. reply chubot 1Yeah I knew someone was going to say that (see last sentence), but a for loop is more powerful and general than reduce().Mutability within the loop is useful, and it can be controlled by processes and message passing. reply bcrosby95 1I assumed you meant something like Enum.sum that completely trivializes the code. In comparison, generic, higher level functions are pretty fundamental to FP. reply throwawaymaths 1the problem with a for loop is that it is inexplicit about what from the outer scope can be mutated. Which isn&#x27;t a problem, for small functions but I have definitely seen monster for loops in professionally written django code with ~500 lines of code in the function.Besides being in that magical sweet spot (executes imperatively but reads declaratively), a reduce forces you to declare ahead of time what things can be carried over and mutated between each iteration.> it can be controlled by processes and message passing.DO NOT DO THIS YOU WILL REGRET THIS SIMCITY MEME reply sodapopcan 1I&#x27;m not sure \"powerful\" is the right word here, it&#x27;s more a matter of \"what certain people are used to\". If you want a counter or whatever, you can use a tuple to give yourself multiple accumulators. You could argue it&#x27;s uglier, but I wouldn&#x27;t necessarily agree. It&#x27;s something that is easy to get used to if you remove the \"but I&#x27;d rather just do it this way\" mindset. reply ttymck Is Enum.reduce not sufficient? Even better, Enum.sum?https:&#x2F;&#x2F;hexdocs.pm&#x2F;elixir&#x2F;1.12&#x2F;Enum.html#reduce&#x2F;3 reply mfitton 1You might want to look into Ray. It&#x27;s a Python library lets you deploy actors (classes) and tasks (functions) and abstracts away the management of resources, message passing, lets you define automatic repairs, etc. that is entailed with deploying an arbitrary amount of intercommunicating processes in Python.Admittedly, I haven&#x27;t worked with Erlang or Elixir, so their solution to this might be much more usable. Ray is aimed primarily at ML use-cases, though it is quite general. reply dgb23 1> the harder something tries to convince me of anything, the more I expect it to suck.That&#x27;s me vs web development in general and especially in the JS ecosystem. Other, similar red-flags: hand holding, \"best practices\", \"anti-patterns\" and other voodoo and cargo culting.The most suspicious one is prettiness:- custom DSL syntax without data representation- cosmetic wrappers that are just thin layers without substance- \"everything is an X\" for the sake of faux consistency reply throwawaymaths 1- cosmetic wrappers that are just thin layers without substanceIf you&#x27;ve ever tried to write keyword lists in erlang.... The keyword list cosmetic wrapper is fucking amazing, not only because it makes it easy to read, but it makes it easier to debug and easier to one-glance see \"this is a keyword list\". reply 59nadir 1> - custom DSL syntax without data representationThis is an interesting comment in a post about Elixir because the Elixir ecosystem is actually full of things that should just be data but are instead macros being used in modules. Phoenix in particular is an especially egregious example of a library that is badly made in almost every regard> - cosmetic wrappers that are just thin layers without substanceThis one is also funny because Elixir itself is little more than a fairly small set of convenience libraries, a syntax and a very good tool for project management (`mix`) on top of Erlang. You can skip the syntax and the convenience libraries for the most part and actually just use Erlang in a `mix` project and get the best of both worlds. The convenience libraries usually are bad makeup on top of Erlang in many cases and you&#x27;d be better served just learning the Erlang way anyway. reply jeremyjh 1Phoenix is popular partly because people like its API and its convenience macros. It won out over Jose&#x27;s own framework, Dynamo which he scrapped in favor of becoming a core contributor to Phoenix. Its easy to make yourself sound wise by complaining about macros, but this largely boils down to personal preferences, and a lot of people have different ones from you.For most of the people who actually use Phoenix, the DSL makes intuitive sense and so there isn&#x27;t much learning curve, and it is such an important library to applications that use it that its worth taking the time to really learn it, whereas it might not be the case for other libraries that are macro heavy. Most libraries don&#x27;t go that route though. reply arrowsmith 1> Phoenix in particular is an especially egregious example of a library that is badly made in almost every regardCan you elaborate on this? Why do you think this? reply 59nadir 1The interface to almost everything either contains or is based on a macro. This persists even in cases where you can clearly see there needed to be no macros at all.The non-standard (won&#x27;t work with anything else) and basically superfluous websocket protocol has bad fundamentals and has been marred by bad JavaScript code being needed for it. On top of that it&#x27;s pretty bloated.The actual channel processes could&#x27;ve simply followed a standard Erlang interface but someone (...) felt they needed to put their fingerprint on it, I guess, so it kind of doesn&#x27;t. And yes, again everything surrounding channels is a bunch of macros until you at least get to write and use normal functions in the actual channel module.They&#x27;ve had a long history of arbitrarily deciding to hide settings&#x2F;configuration from dependencies they use and having no actual argument for doing so when asked to expose them.If the part about macros being overused wasn&#x27;t bad enough Phoenix also promotes this type of thinking by overusing them even in generated code, so people can follow the bad example. reply josevalim 1> The interface to almost everything either contains or is based on a macro.This is not true. The endpoint and router are macro based, but once it is routed, it is all functions. Your controller actions are functions, calling the view&#x2F;template is a function, your channel is functions, the model&#x2F;context layer are functions.When it comes to behaviors, we do our best to follow Erlang&#x2F;OTP conventions, but deviate where it makes sense. For example, channel has “join” instead of “init” because you can refuse a join but you can’t refuse an init. They have different return types and augmenting init could be confusing if later you were to write a plain GenServer.It is easy to look from outside and say “someone wanted to put their fingerprints on it” but actual discussions were had in pretty much all of these topics. I suggest asking around. If you asked for something and we had no actual arguments, then please point me to such occurrences. I will be eager to clarify (and as a rule we generally do). reply theonething Any answers to Jose&#x27;s reply?If not, your criticisms seem to hold no water. reply giraffe_lady 1I know erlang better than I know elixir but I still prefer to use elixir when I have the choice.It may be \"little more than\" convenience, but especially consistency decisions like always data-first functions plus the pipe macro is already a monumental ergonomic leap over erlang. I love erlang but, like php, it is a language where I have to look up the argument order and config options of every function every time I use it. reply throwawaymaths 1Yep. The only problem with elixir macros is that people look at the macros that are in core++ (exunit, plug, phoenix, ecto) and decide it&#x27;s a good idea to dsl-up everything.The biggest offenders IMO are commanded, Tesla, absinthe, exmachina and now most recently ash. Then there&#x27;s tons of tiny libraries that litter hex.pm with macro-heavy nonsense.At least the core++ libraries make macros whose syntax&#x2F;keywords matches something outside elixirland that you&#x27;d have to know anyways (e.g. &#x27;get&#x27; from plug, all of SQL from ecto), but the big offenders list are making up clever names for things, which adds mental overhead to literally everything you do, building crazy complicated compilation pathways (especially for overeagerly lazy stuff) or writing function names from whole cloth that make refactoring or searching your codebase a nightmare (or more than one). E.g. if you&#x27;re working in a domain where non-proud camel case is the convention, don&#x27;t automatically snake-case it. reply sodapopcan 1I personally don&#x27;t have any problem with heavy macro-use in libraries, I feel like that is where they shine. So long as the documentation is good, I don&#x27;t really care how the library itself is implemented. I would much rather have the cleaner API in many cases. I know it can be taken too far, though. Some funky stuff can happen in Phoenix&#x27;s router, though a lot of it is actually to reduce cyclic compile-time dependencies as the router is a place where these necessarily happen.Macros in business code, however, are pure evil. I feel like anyone who spent any time in Rails over the past decade has learned that lesson. reply throwawaymaths 1Yep. I wish `pipeline`, `scope` and `resources` in Phoenix router and also all the `use MyApp.Web, :x`, would just die in a fire.Thank goodness they got rid of views though I still am annoyed that the default path resolution on templated content isn&#x27;t explicit.The crazy thing is that the most amazing part of phoenix, liveview, is almost no macros. reply sodapopcan 1I never use `resources` though have no beef with `pipeline` or `scope`, though I haven&#x27;t thought too much about it. It is a little weird getting used to which modules are getting auto-qualified and which aren&#x27;t, but I&#x27;m long passed that. And that is actually what is \"fixing\" the cyclical dependency issue.What&#x27;s wrong with the `use MyApp.Web, :x`? You can easily get rid of it as it&#x27;s just generated boilerplate. It&#x27;s a nice little pattern to allow all the different things to share the view helpers. If you&#x27;d like to be extra explicit, though, just delete the file and include everything manually.I&#x27;m indifferent on views because I never really used them, haha. reply halostatue 1I personally would prefer something like: defmodule MyApp.Web.Router do use MyApp.Router endover defmodule MyApp.Web.Router do use MyApp, :router endbut that’s a preference. reply sodapopcan You can do that if you want. Just remove `def router` from `MyAppWeb` move its contents over to a custom module: defmodule MyAppWeb.Router do defmacro __using__(_) do quote do use Phoenix.Router, helpers: false import Plug.Conn import Phoenix.Controller import Phoenix.LiveView.Router end end endBut why the dislike for passing a second argument to `use`? It keeps everything together pretty nicely. reply halostatue Mostly because we’re using an umbrella at the place of work, and we absolutely don’t want those boundaries crossed. reply sodapopcan Oh! Well I don&#x27;t know your setup but you could always add a top level `PhoenixHelpers` namespace (or a better name) that holds these generic types of things that can be shared between apps. Though again I really don&#x27;t know your set up. Like maybe you have an app whose router doesn&#x27;t need `Phoenix.Controller` so then this wouldn&#x27;t make sense. replyarrowsmith 1> I wish `pipeline`, `scope` and `resources` in Phoenix router and also all the `use MyApp.Web, :x`, would just die in a fire.How would you prefer it worked&#x2F;looked?> I still am annoyed that the default path resolution on templated content isn&#x27;t explicit.What do you mean by this? In the new 1.7 approach to views, you explicitly set the path in each view using `embed_templates` (if you&#x27;re not defining your HEex directly within the view module itself.) What part isn&#x27;t explicit? reply throwawaymaths 1> What do you mean by this? In the new 1.7 approach to views, you explicitly set the pathFor example, if you wrote a liveview called FooView in &#x2F;path&#x2F;to&#x2F;my_liveview, a default render() will look for &#x2F;path&#x2F;to&#x2F;my_liveview&#x2F;foo_view.html.heex(Also note auto-snakecasing)Btw, this is still a different semantic if you do the deadview equivalent, which will try to do a path resolution in &#x2F;templates.I guess these are minor complaints but I would much prefer they use the same default strategy and, say, pass the path in `use Phoenix.Liveview` reply arrowsmith 1> This is still a different semantic if you do the deadview equivalent, which will try to do a path resolution in &#x2F;templates.Not true in 1.7 - views* don&#x27;t have any kind of \"default\" template resolution; you have to explicitly state the template path with `embed_templates`. That is if you&#x27;re not just defining your HEEx directly within the view module itself, as I already mentioned.*By \"views\" I mean the new style that uses `use MyAppWeb, :html`, not the old style you describe which is now (in 1.7+) only available as the external dependency `phoenix_view`. The new style of module is still called a \"view\" by the docs: https:&#x2F;&#x2F;hexdocs.pm&#x2F;phoenix&#x2F;request_lifecycle.html#from-endpo... reply jrochkind1 1> So long as the documentation is good, I don&#x27;t really care how the library itself is implemented.I don&#x27;t have experience in Elixir, but in my general experience what you say is fine until you need to debug something going wrong (or something you don&#x27;t understand and _think_ is going wrong) in a library, which always happens eventually, no? Or until you want to PR a feature, etc. reply sodapopcan 1Those are fair points. In terms of PRing, though, I do think that people are a little too \"afraid\" of macros. It sometimes feels like people won&#x27;t learn them out of of principle which is a shame as they aren&#x27;t that complicated. Though anyone trying to navigate nested macros definitely has my sympathy.No matter how slice it, however, macros are a massive part of what makes Elixir Elixir. A large portion of the language&#x27;s \"keywords\" are just macros and they reduce a lot of the boilerplate Erlang forces you to write. reply throwawaymaths 1EEx does macros well. Note that EEx.function_from_x makes you declare the name of the function it instantiates, so it&#x27;s searchable.GenServer is kind of a \"bad example\" of a macro. It creates a totally hidden function. Though I guess to be fair 99.9% of the time you really shouldn&#x27;t be writing genservers in elixir. reply dqv >It creates a totally hidden function.Are you talking about child_spec&#x2F;1? `use GenServer` honestly provides some pretty good QoL enhancements over `@behaviour GenServer`. I don&#x27;t know when or if there was a change to recommending `use GenServer`, but I was pleasantly surprised when I started using it. Especially because I&#x27;m not writing new GenServers all the time, having guard rails is nice to avoid being slowed down by remembering all the boilerplate: init&#x2F;1, handle_x&#x2F;y, child_spec&#x2F;1It&#x27;s even nice enough to give additional information about why its crashing so you don&#x27;t get confused why e.g. the handle_call function is working. I make this mistake almost every time I write a new GenServer: def handle_call(:ping, state) do {:reply, :pong, state} endBefore, you would just get this meaningless gen_server stacktrace that basically just says \"it crashed lol\". Now you get the additional hint of \"hey you didn&#x27;t define handle_call&#x2F;3\" when it crashes. reply throwawaymaths Last I checked you need to do init&#x2F;1 by hand. Honestly being more transparent about creating child_spec like `GenServer.create_default_child_spec` would be great. The rest of use GenServer is pretty good, IMO (this is why I wrote &#x27;kind of a bad&#x27; macro). I normally hate default implementation of functions but defaulting with an error saying \"you forgot this\" is reasonable.Edit: just checked, it warns if you don&#x27;t... I have compiler warnings as error on all my personal projects so that&#x27;s why I thought you had to do it manually reply AlchemistCamp 1> 99.9% of the time you really shouldn&#x27;t be writing genservers in elixirWoah! Why is that?I&#x27;ve written at least one GenServer in nearly all the Elixir projects I&#x27;ve worked on. They seem like one of the base building-blocks to me. Also, if you squint a bit, you&#x27;ll see that many libraries you&#x27;re working with are essentially exposing a GenServer interface, with a few extra features. reply throwawaymaths I&#x27;ve never written a genserver in any professional project I&#x27;ve worked on.... Well, except maybe for a trivial 5 line wrapper enables a global ets.> Also, if you squint a bit, you&#x27;ll see that many libraries you&#x27;re working with are essentially exposing a GenServer interface, with a few extra features.I never said you shouldn&#x27;t be using GenServers. I said you shouldn&#x27;t write GenServers. reply jolux > I&#x27;ve never written a genserver in any professional project I&#x27;ve worked onWow, that&#x27;s quite surprising! We use GenServers quite extensively at work. The most interesting usage is probably this application, which uses GenServers to model the state of real-world hardware (in this case, transit stop countdown clocks): https:&#x2F;&#x2F;github.com&#x2F;mbta&#x2F;realtime_signs&#x2F;blob&#x2F;main&#x2F;lib&#x2F;signs&#x2F;s...Curious what you use instead of GenServers. Plain processes? Agents? Something else? GenServers are probably overused but I still reach for them when I need a concurrent bundle of state with a specific interface and behavior.I think we&#x27;re generally trying to write more GenStages than GenServers at the MBTA these days, but that&#x27;s mainly because we&#x27;re moving towards being event-driven. GenServers still have their place. reply throwawaymaths I use other people&#x27;s GenServers. Never agents. Tasks for concurrency (but almost never those either, just Oban). Ets for stateful datastore.Pedantically I guess gen_statem isn&#x27;t a genServer, but I&#x27;m generally referring to the pattern, which gen_statem is.Mostly webdev, so, that stuff is all taken care of for me.MBTA is modeling reactive systems that exist in the real world, so yeah, that&#x27;s a place where i would be surprised if you didn&#x27;t use genservers, though I suppose you could just use a database-backed state machine. Surprised you use GenServers instead of gen_statem (though you might have been, as I was, less than pedantic) reply jolux Ah I see. Yeah, Phoenix definitely gives you a lot out of the box. I think for webdev it&#x27;s probably enough. This is a pretty straightforward Phoenix app for example, only uses a couple GenServers: https:&#x2F;&#x2F;github.com&#x2F;mbta&#x2F;arrowThe question of when to introduce databases is a really interesting one and also one I&#x27;m still coming to terms with a few years into writing Elixir full-time. Many of our apps don&#x27;t use them at all, but I think at least a few could benefit from more structure and durability in their datastores. reply AlchemistCamp Are you actively trying not to use GenServers in your application code or is it just that you have a set of 3rd party dependencies that remove the need? reply throwawaymaths Yes reply sodapopcan There&#x27;s no reason not to write GenServers if you need them. Just don&#x27;t use them as a class replacement :) But if you need to model some simple runtime state or concurrency, that&#x27;s what they&#x27;re there for. reply throwawaymaths use Tasks for simple concurrency, Jose has built an awesome module for us. reply sodapopcan Oh I agree! I have a couple of gen servers acting as very simple message queues—the kind that don&#x27;t matter if they are nuked during a deploy. reply pests The only thing I can think of is when developers overuse genserver not realizing it&#x27;s involving another process and then serializing your requests (behind a queue even) into its mailbox. That may be desirable for some but in-process handling can sometimes be the better choice. reply sodapopcan > Also, if you squint a bit, you&#x27;ll see that many libraries you&#x27;re working with are essentially exposing a GenServer interface, with a few extra features.Like LiveViews :) reply throwawaymaths 1Your intuition as a nom-elixir user is absolutely correct. However it&#x27;s worth saying that as a working dev, there&#x27;s almost never a problem in the core++ libraries.Edit: lol looking at the log in elixir slack, and one of the most recent posts is exactly trying to debug something too magical in one of the aformentioned non-core++ libries!! reply freedomben 1Yep this is definitely a problem, but fortunately the culture&#x2F;community around Elixir generally tends to frown on unnecessary macros. I heard the saying, \"if it can be a normal function, it should be\" many times, which pleases me.Overall though this isn&#x27;t something I&#x27;ve generally run into too much with Elixir. reply 59nadir 1> Yep this is definitely a problem, but fortunately the culture&#x2F;community around Elixir generally tends to frown on unnecessary macros. I heard the saying, \"if it can be a normal function, it should be\" many times, which pleases me.While Elixir people usually say this, they don&#x27;t at all follow it in practice because of the terrible example set by all the libraries. Phoenix is especially egregious and I can&#x27;t believe the grandparent didn&#x27;t bring it up.Looking at Clojure&#x27;s solution that is (as far as I can see) very popular it makes me annoyed at the relaxed attitude towards macros in Elixir and how bad it actually is:Elixir and `Plug.Router`: defmodule MyRouter do use Plug.Router plug :match plug :dispatch get \"&#x2F;hello\" do send_resp(conn, 200, \"world\") end forward \"&#x2F;users\", to: UsersRouter match _ do send_resp(conn, 404, \"oops\") end endClojure and `reitit` (https:&#x2F;&#x2F;github.com&#x2F;metosin&#x2F;reitit): (def router (r&#x2F;routes [[\"&#x2F;hello\" {:get (fn [r] {:status 200 :body \"world\"})}] [\"&#x2F;users\" {:name :users :router users-router}] [\"*\" {:get (fn [r] {:status 404 :body \"oops\"})}]]))basically everything in the Elixir case is a macro and non-standard syntax whereas literally of the components of the Clojure case are just standard data types, and yet it manages to be more readable. reply dragonwriter 1> basically everything in the Elixir case is a macro and non-standard syntax whereas literally of the components of the Clojure case are just standard data types, and yet it manages to be more readable.“Readable” is mostly a matter of “fits the grooves already worn in my brain”; to me, the Elixir there nonstandard-macro-based-syntax-and-all, is vastly more readable than the Clojure. reply 59nadir 1> “Readable” is mostly a matter of “fits the grooves already worn in my brain”; to me, the Elixir there nonstandard-macro-based-syntax-and-all, is vastly more readable than the Clojure.I&#x27;ll admit to being able to read Lisp syntax without choking on the parens, but I don&#x27;t even use Clojure (or any other dialect that uses special syntax for the different collection types) and I think it&#x27;s way more readable and malleable (you can literally do whatever you want that makes sense to this data and it&#x27;ll work, meaning you&#x27;re free to write whatever middleware you want that takes and produces the expected data).I&#x27;ve used Elixir since 2015 so I have no problem actually reading the syntax at all; I just think it&#x27;s factually much worse than the Clojure example because it&#x27;s basically just a bunch of macros you can&#x27;t do much with and lots of implicit behaviors.This also applies to Elixir&#x27;s greater position in the BEAM ecosystem. I think the idea was that Elixir was going to be a boon to Erlang and other languages in there over time but I think it&#x27;s demonstrably pretty useless as a BEAM citizen except for some of the patches they&#x27;ve submitted; most big Elixir libraries can&#x27;t even be used outside of Elixir because they&#x27;re full of macros and don&#x27;t even provide interfaces with just functions. reply josevalim 1> I think the idea was that Elixir was going to be a boon to Erlang and other languages in there over time but I think it&#x27;s demonstrably pretty useless as a BEAM citizen except for some of the patches they&#x27;ve submittedNot sure whose idea it was but I would say this is a very inaccurate take. Of course, we have taken much more from Erlang than given (that&#x27;s expected from hosted languages), but I personally sit on more than 100 PRs to Erlang&#x2F;OTP. I made binary matching several times faster by using SIMD. I improved the compiler performance (including Erlang programs) by (conservatively) 10-20%. I contributed compiler optimizations to reduce memory allocation. There is a now faster sets implementation which I contributed. Erlang&#x2F;OTP 26 ships with faster map lookups for atom keys based on a pull request I submitted. The new logger system in Erlang takes ideas from Elixir logger. The utf-8 string handling in Erlang is based wholesale on Elixir’s (and extended for lists). And this is in no way a comprehensive listing [1].And this is not counting everyone else in the Elixir community who contributed and those who are now actively working on Erlang tooling and were on-boarded to the ecosystem via Elixir. The Erlang ecosystem now has a package manager [2], used extensively by both languages, rebar3 and Mix, all implemented and powered by Elixir.And then there are efforts like the Erlang Ecosystem Foundation, which is made of developers and sponsored by companies working with both languages, and it delivers important projects around observability, documentation, and more. For example, you can find several Erlang projects now using ExDoc for documentation, such as Recon [3].That’s my take. What are your demonstrations that we are pretty useless for the BEAM ecosystem?1: https:&#x2F;&#x2F;github.com&#x2F;erlang&#x2F;otp&#x2F;pulls?q=is%3Apr+author%3Ajosev... 2: https:&#x2F;&#x2F;hex.pm&#x2F; 3: https:&#x2F;&#x2F;hexdocs.pm&#x2F;recon reply di4na Hell i could add more. The current best json lib in erlang is a literal (called out for it in its readme) copy of the Jason elixir one in erlang.My hyperloglog erlang lib is one of the most advanced in any language (behind what Omar Ertl does for Java) and i come wholesale from elixir.I have my own code, as an elixir person, in OTP, for the formatting of float to string. The maybe construct was only possible because elixir with showed the way.I could probably keep going. reply troupo 1Elixir was the kick that Erlang needed for a long time. reply josevalim 1Honestly, I don&#x27;t care if we were a kick or not :) but saying we are \"demonstrably pretty useless\" is completely unfair and bordering on being a bad faith argument. reply theonething > bad faith argumentIt is. That they have not replied to any of your responses shows they don&#x27;t have much argument.I mean using \"factually\" in this subjective opinion is just ridiculous.> I just think it&#x27;s factually much worse than the Clojure example reply kazinator > most big Elixir libraries can&#x27;t even be used outside of Elixir because they&#x27;re full of macros and don&#x27;t even provide interfaces with just functions.I was just reading the documentation, where it says \"remember that macros are not your API\", and smirking. If you write macros and things depend on them, such that if you change the macros, things will break, macros are your API. Syntax is API. reply hosh 1Sure. But there were improvements to the ecosystem. Telemetry is a great example, though they ended up porting it to Erlang so that both Erlang and Elixir projects can use it. reply no_wizard 1`conn` is a magic argument isn&#x27;t it? Like an implicit argument to this block of code?That is one thing that really bugs me, is I can&#x27;t automatically see where the arguments are coming from. I realize it makes code a little more verbose, but a requirement around explicitly showing the dependencies used is much more useful when you&#x27;re refactoring, for instance, or scaling code.not a hard requirement by any means, sure, and it definitely doesn&#x27;t mean something won&#x27;t scale as it were, however I am constantly frustrated by languages that allow for implicit scoped dependencies &#x2F; arguments. reply halostatue 1Yes, it’s a bit of a magic argument, but it’s the only unhygienic variable introduced with a Plug dispatch:https:&#x2F;&#x2F;github.com&#x2F;elixir-plug&#x2F;plug&#x2F;blob&#x2F;main&#x2F;lib&#x2F;plug&#x2F;route...Everything else is explicitly passed, AFAICT. reply arrowsmith 1Maybe it&#x27;s just down to familiarity, but I find the Phoenix example more readable than the Clojure one. To each their own I guess. reply throwawaymaths 1Actually I think plug is mostly fine since it only brings in one macro (plug) that isn&#x27;t an http verb, or http common concept (forward e.g.).My huge beef with plug is that it creates an implicit conn variable in all of the plug bodies.But yeah, phoenix is a combination of good choices and some real stinkers, and I did mention it.Edit: I forgot about match. match \"isn&#x27;t great\". reply dqv 1>My huge beef with plug is that it creates an implicit conn variable in all of the plug bodies.What do you mean? That only happens if you use Plug.Router; otherwise, you have to define a call function that takes the conn as the first argument. You can even go as far as explicitly calling the init functions for each Plug manually. It&#x27;s init(opts), call(conn, opts) all the way down. reply throwawaymaths yes sorry, I meant Plug.Router macro bodies. The rest of plug is fine. reply hosh 1Not to mention that the macros should be invoking regular functions, making it easy to skip macros if you so choose.When I pivoted from Ruby to Elixir, I was expecting to do a lot more metaprogramming, but I found that regular functions with pattern matching already does a lot that I want for many cases. reply throwawaymaths 1Mark my prediction: as the big \"non-core++\" libraries get bigger and trashier with their macros, and more used by the community, hex.pm will become littered with even more trashy macro libraries, and people will stop saying \"don&#x27;t use macros\". reply josevalim Eh, there is also plenty of indication this may not happen. :)- Many of the non-core++ libraries are considered done- Many popular and upcoming projects have zero macros: Decimal, Jason, Telemetry, Mint, Finch, Req, etc- All machine learning projects have either zero macros (Axon, EXLA, Bumblebee) or the macro layer is built on top of the functional API (Nx and Explorer)- Phoenix LiveView, which is the most recent project from the Phoenix team, is very minimal on the use of macros- Most of the Phoenix sub-projects have zero-macros: phoenix_pubsub, phoenix_html, phoenix_ecto, esbuild&#x2F;tailwind, etcI mentioned this in another comment but in my opinion Phoenix is low on the use macros. They are present in the endpoint+router but then you are working with functions. I speculate the reason why they stand out is because they are the entry-point of your code. But even then the socket API in the endpoint is being replaced by a functional API thanks to contributions from Mat Trudel and the new verified routes are way less magic than the previous route helpers. reply cschmatzler 1I’m pretty sure that the libraries you consider core++ such as ExUnit and Ecto are considered feature complete and won’t get any bigger. reply throwawaymaths 1Correct, but remember core++ seeded atrocities like ExUnit.CaseTemplate.Anyways my prediction is about Non-core++ libs, which I listed in gp. reply josevalim 1I was never fully pleased with ExUnit.CaseTemplate. If you have suggestions I am all ears. :) reply throwawaymaths just yeet it and have people do it manually. To be honest, it&#x27;s not fatal for the ecosystem. It will just be slightly less enjoyable over time. reply johnisgood 1I&#x27;m sleep deprived. Would not it rather be \"start\" saying \"don&#x27;t use macros\", given that macros are \"bad\"? reply halostatue 1I haven’t used commanded, exmachina, or ash:- Tesla has a mode which can be used completely without macros, and I am increasingly encouraging that it be the only way that it is used. So does the author (as of 2020): https:&#x2F;&#x2F;github.com&#x2F;elixir-tesla&#x2F;tesla&#x2F;issues&#x2F;367#issuecommen...There is also `req` mentioned in a recent post as an alternative (it looks good, but I am still playing with it to see if it is a suitable replacement for Tesla in all cases).- Absinthe is something of a compiler itself, because it has to strictly define things the way that is specified in the GraphQL spec. You can now import an SDL file, but you still need to hook resolvers and middleware into it. Honestly, I don’t think that the schema definitions in JS&#x2F;TS are much better for GraphQL in terms of readability.Being heavily macro-based means that there are sharp edges that are harder to work around when you want to add your own macros for code reuse purposes. That said, aside from the schema definition, Absinthe is entirely usable without macros. Within the schema definition, Absinthe isn’t making anything up, it’s using the same basic definitions that the GraphQL spec do, adapted for Elixir syntax.Exmachina didn’t interest me because I don’t think much of factory_bot (which used to be called factory_girl), as I saw it abused far more than used well (IMO, it’s impossible to use correctly). Ash…looks like an interesting experiment, but I don’t know that there’s a lot of pick-up with it compared to Phoenix. And I have yet to find a use for CQRS&#x2F;ES, so there’s no reason for me to play with commanded. I certainly wouldn’t consider any of these three to be \"major\" players in Elixir. Tesla and Absinthe? Yes. reply throwawaymaths Yes, sorry didn&#x27;t mean to claim all of the libs do all of the sins: absinthe definitely didn&#x27;t make up words.The circular compiler dependencies of absinthe really ticked me off. Was on a project where one small change elsewhere would mysteriously trigger absinthe recompilation which would trigger even more recompilation. Might or might not been fixed in one of the newer compile-slim elixir releases reply bmitc 1As someone who loves Elixir and knows it, this is one thing that really makes it hard to learn Phoenix for me personally. I have struggled learning Phoenix because it is so heavy with macro upon macro that it feels like learning another language. reply throwawaymaths 1I have some bad news for you: elixir ecosystem is consultancy-driven ecosystem. While at least better than bigtech-driven ecosystem (cough cough), the changes you seek are less likely to happen because1. They make it easier for consultancies to templatize what they do, which:- keeps their employees tied to the hard earned knowledge- keeps their clients tied to their servicesAt least though you know that those patterns are (usually) common and battle tested (or, at least, will be battle tested - cough cough ash), and unlike a bigtech \"their problems are likely to be your problems\". reply josevalim 1> - keeps their clients tied to their servicesI have heard this claim so many times but it is easy to prove it wrong given how much we focus on documentation and understandability around Elixir and main libs. I have had clients asking me questions and I would answer it by improving the docs or writing a guide, committing it to the repo, and then asking the client for feedback. Half of the Ecto guides were written like this.It is not about keeping clients at all. It is about having a great on-boarding (and beyond) experience. reply bmitc I second the notion that the Elixir documentation is generally great, especially the libraries and ecosystem bits. It is clear it is taken seriously and cared about. The level of pro-activeness of the Elixir core team is definitely something that&#x27;s noticed and personally draws me to the language. reply nkjnlknlk 1is the claim Ash is not battle tested? reply troupo 1> now most recently ashI&#x27;ve been using Ash in a side project and it&#x27;s slowly growing on me. You have to twist your brain a bit to grok it (and I haven&#x27;t, not fully).Pros:- a lot of things happen where you want them to happen.I found that writing stuff with Ecto involves more boilerplate than with Ash because you have to write your queries, and your changelogs, and your API accesses, and wire them together, but what if you want a separate API.... With Ash it&#x27;s a single resource with a few macros.- quite a few escape hatches into regular ElixirYou don&#x27;t want magic behind actions? There are several ways to hook into what&#x27;s happening, or even write everything manually. And to the calling code... it will still look the same- Despite all the macros the errors are usually quite good and pinpoint the problemsCons:- too few people who truly understand Ash- documentation is often too terse and concise. But you can&#x27;t really blame the author who is doing a lot- errors are not always good :)I do agree with you on overreliance on macros in parts of the ecosystem reply throwawaymaths I am working at a company that uses ash and have a data science side project that doesn&#x27;t.The data science project did a sql query that I couldn&#x27;t figure how to optimize in SQL and I turned it into simple elixir code. Queries that took minutes now took seconds.Now, I know that ash can do both but I don&#x27;t know how I would diagnose that problem or test alternatives in ash, because it hides way too fucking much of the underlying code. reply troupo I guess you&#x27;d do it the same way: look at logs, write an optimized query manually :)But I do get what you mean. reply weatherlight 1Elixir is probably my favorite dynamic language and a lot of that has to do with the community that sprung up around it. I wish it were more popular. reply hosh 1I don’t wish it to be super popular.I heard the argument before that JS (and Nodejs) is popular (top 3), so you should go into it.I’m now in a nodejs shop. Turns out, the way Erlang and Elixir is designed serves as a filtering function for hiring. People who just wants to code without putting a lot of thought into it, don’t go into Elixir and land in JS instead. (All the current coworkers I have wants to make things better but we are saddled with code that has been … oddly written)At the last Elixir shop I was at, I was part of a small crew that was more experienced as a whole than other shops I have been at. And I liked it. reply no_wizard 1Popularity is a multiple faceted issue w&#x2F;r&#x2F;t quality of engineers in any given language.One caveat to any of it is the easier a language is to grok and the more use cases it has, the more likely it will attract all types of developers and there will always be more \"bottom end\" developers than \"top end\" developers, as is patterned out in any large distribution.That said, here&#x27;s some facets to consider about this- Its not likely its the language (or to be charitable, not just the language) at play here. As noted above, the more popular something is, the more likely you end up with a wider varieties of folks at very different backgrounds &#x2F; skill levels etc. Python and PHP have similar issues.- The more popular the language is, is often correlated to its use cases. For example, JavaScript is hugely popular in a wide swath of problem domains, from the server, to the web (its de facto monopoly right now) to desktop apps to even now mobile (Ionic, NativeScript etc). This leads to the top developers in the language often going to very lucrative positions that one would also presumably have to be working alongside or as part of to be working with them- Its harder in a bigger pool to work with the top N % of developers in any given language or (better yet, any given environment &#x2F; problem space deploying that language as part of its core technological backbone). The big \"sea\" in the middle is what you&#x27;re most likely to be apart ofI think smaller communities benefit from organic interest, people who are enthusiastic to use the technology and therefore often the perceived quality of those developers is higher (and often it does correlate, see: the history of Clojure)I don&#x27;t think a language in and of itself is to blame, except in that maybe, because some languages like Python and JavaScript are so easy to pickup as opposed to say, Java, Kotlin, C# or Rust, that they attract more developers in general. That said, I think its the laws of distribution at work, and not really the driven by the language per se. reply throwanem 1Seems struggling at the moment. Archive link: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230803145324&#x2F;https:&#x2F;&#x2F;wiki.alop... reply satvikpendem 1Elixir is cool, I used to use it for web app backends before adopting TypeScript and Rust. The reason I adopted them was the same reason I stopped using Elixir after a while: type safety. It was getting increasingly hard to be productive in Elixir in a large application due to runtime type errors that are caught in statically typed languages. reply johnisgood 1Strange, I cannot recall the last time I ran into one and I write a lot of Erlang. Both Erlang and Elixir share the \"Let It Fail\" philosophy, additionally it is also highly encouraged to use pattern matching, guards, and error-handling techniques to deal with potential type-related issues and errors.On the other hand, I get it all the time with Python, for example. reply cpursley 1I&#x27;ve found that pattern matching in the function head and guards get you most of the way there. reply satvikpendem 1Yes however I get that in TS and Rust while also having stronger type guarantees. I don&#x27;t think pattern matching is an alternative to static types, it&#x27;s a supplement. reply johnisgood 1Well, I suppose to each their own. I use languages with and without static typing. I love Ada the most though, because the way you define types is very different from the most widespread way. In Ada, you define the range.Examples: type Day is (Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday); subtype Business_Day is Day range Monday .. Friday; subtype Weekend_Day is Day range Saturday .. Sunday; subtype Dice_Throw is Integer range 1 .. 6; type Arr_Type is array (Integer range ) of Character; type Color is (White, Red, Yellow, Green, Blue, Brown, Black); type Column is range 1 .. 72; type Table is array(1 .. 10) of Integer; type Device_Register is range 0 .. 2**5 - 1 with Size => 5; type Commands is (Off, On); type Commands2 is new Integer with Static_Predicate => Commands in 2 | 4; reply weatherlight 1Rust, sure. Love me some Rust.Typescript&#x27;s type system isn&#x27;t sound and you can still get runtime errors. (Type systems should be bomb-proof or just get out of the way.) reply hmmokidk 1How tested were your applications? reply plainOldText 1The syntactic sugar for the list of tuples (aka the Keyword list), such as: [one: 1, two: 2] instead of [{:one, 1}, {:two, 2}] and the other ... do: macros drove me crazy when I first learned Elixir. But as soon as I familiarized myself with it and a few other gotchas, Elixir managed to become my favorite and main language. reply ljm 1I&#x27;m really enjoying getting to grips with Elixir, but I&#x27;m still really in two minds about Ecto having a macro-based SQL ORM.Like any ORM, the abstraction leaks, but it really throws you off course when you&#x27;re trying to map the host syntax to raw SQL. from(t as SomeTable, where: x.z == ^y, join: x on assoc(t, :y))Like, it&#x27;s macro enough to make SQL feel more first-class...but not enough to actually make it first class, so you&#x27;ve gotta learn Ecto&#x27;s quirks.It&#x27;s also chainable so it&#x27;s a macro over a query builder that eventually resolves to SQL at runtime. reply simmanian 1If I volunteer at a nonprofit and I&#x27;m trying to run a team of volunteers who would... 1) probably not stick around for long 2) need to be trained from scratch 3) not have a solid development backgroundWould Phoenix be a good choice, given that you can do so much with it without needing to learn many other tools, or would it be better to start with something like Supabase + a javascript front end framework and hope we&#x27;ll never have to deal with monsters like kubernetes? reply impulser_ 1I would probably go with Javascript and Supabase, this would require you to only really worry about the frontend. Javascript is also probably easier to train people because of how many resources there are out there about training people to write Javascript. Supabase is also has a great free tier which will help your nonprofit. Hell, you might even want to try to contact them and they might give you a better tier for free they are really friendly there.Elixir is great, and developers love it but training new people without a solid development background might be hard. reply biorach 1phoenix does not sound like a good fit reply stilwelldotdev 1I&#x27;ve landed on SvelteKit and classless CSS for most of my hobby projects.I am interested in Elixir though, especially Phoenix, but found it to be difficult to manage and get started with in Windows.Still looking for the easy way into learning to work with web sockets as a 41 year old man with very little spare time. reply CollinEMac 1I&#x27;m using Phoenix for my side project on a Windows machine. It hasn&#x27;t been too problematic for me. Maybe something changed since you&#x27;ve tried it. reply OkayPhysicist 1There used to be a couple pain points when working with Phoenix on Windows. The bcrypt library wouldn&#x27;t build, something needed to be run in Administrator mode to establish their symlink workaround, and PostgreSQL is a little more irritable on Windows. SASS (some node dependency in the Javascript asset managing stuff) also flat out didn&#x27;t work on windows, but there was a drop-in replacement.I know the SASS issue was solved (as a side effect of eliminating the node dependency), and I believe the bcrypt issue was, too. reply victorbjorklund 1What is \"classless CSS\"? Just using style attributes? reply tommica 1Probably just a css file that styles the html elements only without using any classes reply toldyouso2022 1Use virtuabox and make a vm with ubuntu, install elixir and connect via ssh. This is what I did when I wanted to try it out but only had win8 reply _joel 1WSL2 should get you going? reply freedomben 1That&#x27;s what I would suggest as well. WSL2 and use asdf[1] to manage the erlang&#x2F;elixir versions.You could also use containers pretty easily as well with docker or podman for windows and the official Elixir images[2].[1]: https:&#x2F;&#x2F;github.com&#x2F;asdf-vm&#x2F;asdf[2]: https:&#x2F;&#x2F;hub.docker.com&#x2F;_&#x2F;elixir reply coolros 1That was a good read, well done. I&#x27;ve been using Elixir for about a year now and I just smile when I&#x27;m coding. I&#x27;m still a little unsure about it&#x27;s place and where it&#x27;ll go, but I have loved exploring and learning BEAM with a little nicer syntax. Jose is great and watching the introduction of a type system is interesting too reply golemotron 1Disappointed. I thought it was going to describe a way for cynical curmudgeons to get out of their rut. reply rekoros I usually just blindly upvote anything with Erlang&#x2F;Elixir in the title, but this one I read in its entirety over some PhoExcellent writeup! reply pmarreck It looks like it got HackerNews&#x27;d. The stack seems to be Happstack, a Haskell lib.Perhaps if it was served by Phoenix... &#x2F;obvious comment is obvious reply hu3 You&#x27;re correct.It says at the bottom: powered by https:&#x2F;&#x2F;github.com&#x2F;jgm&#x2F;gititReadme states that: \"Gitit is a wiki program written in Haskell. It uses Happstack for the web server and pandoc for markup processing.\" reply CyberDildonics 1Elixir seems to benchmark as half the speed of python, which would put it about 100x to 200x slower than C++. That&#x27;s a lot of speed to give up for the silver bullet promise of immutable data structures (which I&#x27;ve never understood the appeal of in the first place).https:&#x2F;&#x2F;elixirforum.com&#x2F;t&#x2F;elixir-vs-python-performance-bench... reply elcritch 1It&#x27;s unclear why the techempower gives low performance for elixir &#x2F; phoenix. But from what I&#x27;ve heard is that in real world applications the performance tends to scale much better than Python or Ruby. reply BaculumMeumEst 1it&#x27;s because the people who contribute to techempower benchmarks are zealots who believe that it&#x27;s far more useful and important to show their One True Language in the Best Possible Light than to give you a useful benchmark. take a look at the source code for some of them and see for yourself. reply CyberDildonics 1The link is about execution speed, I think if you start talking about &#x27;scale&#x27; that&#x27;s a diversion, since that isn&#x27;t about the language and is more about the architecture of the program. reply di4na These benchmarks have been thoroughly studied by the elixir community (even myself) and are... Trash.They compare things that have nothing to do with production, use non realistic code for most language and keep refusing PR to fix it for elixir.The community simply decided to stop trying to engage and let that code die. reply BaculumMeumEst 1elixir seems cool and i love its tooling but the more i use datomic, the less i want to spend my time dealing with SQL and its baggage unless i absolutely have to. reply whalesalad 1what would prevent you from using datomic with elixir? https:&#x2F;&#x2F;github.com&#x2F;edubkendo&#x2F;datomexthere are other datalog-y tools as well, ie https:&#x2F;&#x2F;github.com&#x2F;naomijub&#x2F;translixir reply BaculumMeumEst 1i lost my enthusiasm for building a jenga tower of niche community libraries reply whalesalad 1that is literally clojure development reply BaculumMeumEst 1you can get pretty far with cognitect&#x27;s libraries and java interop replyLispSporks22 1prev [–] Lisp user here. I couldn&#x27;t see what he was talking about re: \"Elixir is a Lisp\" and the \"why\" was pretty hand-wavy, but the author does seem pretty stoked about whatever he&#x2F;she saw so good for them. reply cmcaine It&#x27;s got good macros and the implementation of both regular code and macros operate on the same core datastructures.It has the interactive features for inspecting and modifying a running system that Lisps often have.It has reflection APIsIts ints are big like Lispetc.Seems pretty Lispy to me. reply weatherlight 1prev [–] hygienic macros doe not make a lisp, but.... it get you very close to the spirit of the thing, i think that&#x27;s why the author was excited,( and it&#x27;s a good reason to be.) reply",
    "originSummary": [
      "The author shares their initial skepticism of the Elixir language and their lack of experience with web programming.",
      "After reading tutorials and understanding its similarities to Lisp and integration with Erlang, the author becomes interested in Elixir.",
      "The Phoenix web framework is praised as an example of how to write complex Elixir programs, despite the author's initial confusion with syntactic sugar and macros. Additionally, the author highlights the robustness, multiprocessing power, transparency, and the use of lists, tuples, and atoms in Erlang and Elixir."
    ],
    "commentSummary": [
      "The discussions revolve around various aspects of the Elixir programming language and its frameworks, including syntax, concurrency capabilities, and simplified production environment.",
      "Participants express admiration for Elixir's syntax and its usefulness for writing quick scripts, comparing it to other languages like Ruby and Python.",
      "Maco usage in Elixir is also explored, with different opinions on their effectiveness and necessity. Other topics include the readability and usability of Elixir and Clojure, challenges of using Elixir on Windows, and the significance of static typing in different programming languages."
    ],
    "points": 416,
    "commentCount": 210,
    "retryCount": 0,
    "time": 1691074287
  },
  {
    "id": 36989798,
    "title": "AWS to begin charging for public IPv4 addresses",
    "originLink": "https://aws.amazon.com/blogs/aws/new-aws-public-ipv4-address-charge-public-ip-insights/",
    "originBody": "Skip to Main Content Click here to return to Amazon Web Services homepage Contact Us Support  My Account  Sign In Create an AWS Account Products Solutions Pricing Documentation Learn Partner Network AWS Marketplace Customer Enablement Events Explore More AWS Blog Home Topics  Edition  AWS News Blog New – AWS Public IPv4 Address Charge + Public IP Insights by Jeff Barr | on 28 JUL 2023 | in Amazon EC2, Announcements, Launch, News | Permalink | Comments |  Share We are introducing a new charge for public IPv4 addresses. Effective February 1, 2024 there will be a charge of $0.005 per IP per hour for all public IPv4 addresses, whether attached to a service or not (there is already a charge for public IPv4 addresses you allocate in your account but don’t attach to an EC2 instance). Public IPv4 Charge As you may know, IPv4 addresses are an increasingly scarce resource and the cost to acquire a single public IPv4 address has risen more than 300% over the past 5 years. This change reflects our own costs and is also intended to encourage you to be a bit more frugal with your use of public IPv4 addresses and to think about accelerating your adoption of IPv6 as a modernization and conservation measure. This change applies to all AWS services including Amazon Elastic Compute Cloud (Amazon EC2), Amazon Relational Database Service (RDS) database instances, Amazon Elastic Kubernetes Service (EKS) nodes, and other AWS services that can have a public IPv4 address allocated and attached, in all AWS regions (commercial, AWS China, and GovCloud). Here’s a summary in tabular form: Public IP Address Type Current Price/Hour (USD) New Price/Hour (USD) (Effective February 1, 2024) In-use Public IPv4 address (including Amazon provided public IPv4 and Elastic IP) assigned to resources in your VPC, Amazon Global Accelerator, and AWS Site-to-site VPN tunnel No charge $0.005 Additional (secondary) Elastic IP Address on a running EC2 instance $0.005 $0.005 Idle Elastic IP Address in account $0.005 $0.005 The AWS Free Tier for EC2 will include 750 hours of public IPv4 address usage per month for the first 12 months, effective February 1, 2024. You will not be charged for IP addresses that you own and bring to AWS using Amazon BYOIP. Starting today, your AWS Cost and Usage Reports automatically include public IPv4 address usage. When this price change goes in to effect next year you will also be able to use AWS Cost Explorer to see and better understand your usage. As I noted earlier in this post, I would like to encourage you to consider accelerating your adoption of IPv6. A new blog post shows you how to use Elastic Load Balancers and NAT Gateways for ingress and egress traffic, while avoiding the use of a public IPv4 address for each instance that you launch. Here are some resources to show you how you can use IPv6 with widely used services such as EC2, Amazon Virtual Private Cloud (Amazon VPC), Amazon Elastic Kubernetes Service (EKS), Elastic Load Balancing, and Amazon Relational Database Service (RDS): Dual Stack and IPv6-only Amazon VPC Reference Architectures (pdf) Dual-stack IPv6 architectures for AWS and hybrid networks – Part 1 Dual-stack IPv6 architectures for AWS and hybrid networks – Part 2 IPv6 on AWS AWS Services that Support IPv6 Earlier this year we enhanced EC2 Instance Connect and gave it the ability to connect to your instances using private IPv4 addresses. As a result, you no longer need to use public IPv4 addresses for administrative purposes (generally using SSH or RDP). Public IP Insights In order to make it easier for you to monitor, analyze, and audit your use of public IPv4 addresses, today we are launching Public IP Insights, a new feature of Amazon VPC IP Address Manager that is available to you at no cost. In addition to helping you to make efficient use of public IPv4 addresses, Public IP Insights will give you a better understanding of your security profile. You can see the breakdown of public IP types and EIP usage, with multiple filtering options: You can also see, sort, filter, and learn more about each of the public IPv4 addresses that you are using: Using IPv4 Addresses Efficiently By using the new IP Insights tool and following the guidance that I shared above, you should be ready to update your application to minimize the effect of the new charge. You may also want to consider using AWS Direct Connect to set up a dedicated network connection to AWS. Finally, be sure to read our new blog post, Identify and Optimize Public IPv4 Address Usage on AWS, for more information on how to make the best use of public IPv4 addresses. — Jeff; Jeff Barr Jeff Barr is Chief Evangelist for AWS. He started this blog in 2004 and has been writing posts just about non-stop ever since. Comments AWS Podcast Subscribe for weekly AWS news and interviews Learn more  AWS Partner Network Find an APN member to support your cloud business needs Learn more  AWS Training & Certifications Free digital courses to help you develop your skills Learn more  Resources Getting Started What's New Top Posts Official AWS Podcast Case Studies Follow  Twitter  Facebook  LinkedIn  Twitch  RSS Feed  Email Updates AWS Events Discover the latest AWS events in your region Learn more  Learn About AWS What Is AWS? What Is Cloud Computing? AWS Inclusion, Diversity & Equity What Is DevOps? What Is a Container? What Is a Data Lake? AWS Cloud Security What's New Blogs Press Releases Resources for AWS Getting Started Training and Certification AWS Solutions Library Architecture Center Product and Technical FAQs Analyst Reports AWS Partners Developers on AWS Developer Center SDKs & Tools .NET on AWS Python on AWS Java on AWS PHP on AWS JavaScript on AWS Help Contact Us Get Expert Help File a Support Ticket AWS re:Post Knowledge Center AWS Support Overview Legal AWS Careers Create an AWS Account Amazon is an Equal Opportunity Employer: Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation / Age. Language عربي Bahasa Indonesia Deutsch English Español Français Italiano Português Tiếng Việt Türkçe Ρусский ไทย 日本語 한국어 中文 (简体) 中文 (繁體) Privacy | Site Terms | Cookie Preferences | © 2023, Amazon Web Services, Inc. or its affiliates. All rights reserved.",
    "commentLink": "https://news.ycombinator.com/item?id=36989798",
    "commentBody": "AWS to begin charging for public IPv4 addresses | Hacker NewsHacker News new | comments | ask | show | jobs | submitloginAWS to begin charging for public IPv4 addresses (amazon.com) 368 points by realshadow 15 hours ago| 295 comments amluto 1> A new blog post shows you how to use Elastic Load Balancers and NAT Gateways for ingress and egress traffic, while avoiding the use of a public IPv4 address for each instance that you launch.It would be nice if this came with reasonably priced NAT gateways. The current pricing is outrageous. reply brickteacup Not to mention the absurd fact that accessing (IPv4) AWS APIs from a private subnet requires paying for either a NAT gateway or an interface endpoint (we got bitten by sending a ton of Kinesis traffic through a NAT gateway once) reply profmonocle This is one thing Google Cloud does well - traffic to Google services bypasses NAT gateway, even over IPv4.I was curious how they do this, so I set up a service on Google Cloud Run that just echo&#x27;d the user&#x27;s public IP address. When curl&#x27;d over IPv4, it said I was coming from a unique local (i.e. private) IPv6 address. The private IPv4 address of my server was embedded in the address, along with some other random-looking bits that probably identified my VPC somehow. So they must have been doing some sort of stateless IPv4 to IPv6 translation behind the scenes.It was a clever solution that takes advantage of the fact that all of Google&#x27;s API endpoints are dual-stack, even though (at the time) they didn&#x27;t support IPv6 on customer VMs. The problem AWS currently has is not all of their internal endpoints are dual-stack, so even using IPv6 can&#x27;t save you from cloud NAT costs when accessing AWS services. reply formercoder Our network is completely software defined, so we just fake it to the VM and make it look like it&#x27;s talking right to the service, and do all the routing via magic. reply asmor Honestly, I really like that the AWS implementation is not magic. AWS is the only one of the big 3 cloud providers where I can reasonably assume I get what it says on the lid, and that it works with the pieces it advertises working with (whereas other cloud providers tend to be more nebulous in their documentation).GCP especially takes a lot more trial and error building systems that compose a bunch of different primitives. That the API is awful doesn&#x27;t help either. reply victor106 This is very cool.Have quite a bit of experience with AWS and Azure, and only recently learning about GCP, it’s very clear that Google nailed Some of GCP’s core cloud engineering concepts and got them exactly right.Although unfortunately they will never reach the size of AWS or (maybe Azure? It’s hard to tell Azure’s market size as they don’t disclose it.) reply rescbr The problem AWS has is the design of VPC internals.As the first hyperscaler, they gotta pay the legacy tax. reply saurik AWS didn&#x27;t start with \"VPC\", and people who still had access to the much-easier-to-conceptualize EC2 Classic only got forced off recently; Amazon VPC wasn&#x27;t actually launched publicly until after Google Cloud. reply pyeri Another dead simple solution would be if AWS would provide us a simple subdomain (such as myapp.xxxx.aws-hosting.com), no need to meddle with IPs at all in that case. Google Cloud already does this with xyz.appspot.com subdomains, same with Github Pages as they provide you xyz.github.io subdomain for your app. reply acdha Yeah, the endpoints bother me. I get charging for IPv4 space but they shouldn’t charge you for calling their APIs, especially since it’s one ENI per endpoint so I have a few VPCs which have half the allocated addresses used by endpoints (the old trade off between multi AZ reliability and the cost of allocating redundancy). reply belter NAT Instances are still a thing. - https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;vpc&#x2F;latest&#x2F;userguide&#x2F;vpc-nat-com... reply aednichols 1NAT is pretty computationally intensive, this is why e.g. ISPs & mobile carriers are pushing IPv6 over CGNAT. reply amluto AWS NAT gateway is $0.045 per hour plus $0.045 per GB. The hourly fee seems mostly okay - for largish users, one or two per region is fine.$0.045 per GB is nuts. That’s $20.25&#x2F;hour or $14580&#x2F;mo for 1 Gbps. One can buy a cheap gadget using very little power that can NAT 1 Gbps at line rate for maybe $200 (being generous). One can buy a perfectly nice low power server that can NAT 10Gbps line rate for $1k with some compute to spare. One can operate one of these systems, complete with a rack and far more power than needed, plus the Internet connection, for a lot less money than $14580&#x2F;mo. (Never mind that your $14580 doesn’t actually cover the egress fee on AWS.)A company with a couple full time employees could easily operate quite a few of these out of any normal datacenter, charge AWS-like fees, and make a killing, without breaking a sweat. But they wouldn’t get many clients because most datacenter customers already have a NAT-capable router and don’t need this service to begin with.In other words, the OpEx associated with a service like this, including the sysadmin time, is simply not in the ballpark of what AWS charges. reply kelnos Is that $0.045&#x2F;GB for all data transferred through it, or just egress to the public internet? If it&#x27;s the latter, that&#x27;s half the price of normal EC2 instance egress to the public internet.If it&#x27;s the former... oh sweet jesus, what? Probably way cheaper to just run an a1.large or something with Linux on it, plus a very short shell script to set up NAT. That&#x27;s assuming well more than half of the traffic going through it is ingress from the internet. If it&#x27;s 50&#x2F;50 ingress and egress, then it&#x27;s basically the same pricing as NAT gateway. reply Nathan2055 No, it’s so much worse than that. Look closely at https:&#x2F;&#x2F;aws.amazon.com&#x2F;vpc&#x2F;pricing&#x2F; and note this line:> You also incur standard AWS data transfer charges for all data transferred via the NAT gateway.Yes, the $0.045&#x2F;GB “data processing” charge is in addition to the usual $0.09&#x2F;GB egress charge. You are paying an effective $0.135&#x2F;GB for all of your egress, in addition to the $0.045&#x2F;hr just to keep the NAT gateway running.And yes, your ingress and even internal-to-AWS traffic is also billed at the $0.045&#x2F;GB rate. (An example given on the aforementioned page is traffic from an EC2 instance to a same-region S3 bucket, which they note doesn’t generate an egress charge but does generate a NAT processing charge.) As far as I can tell, the only traffic which isn’t billed is traffic routed with internal VPC private IP addresses, which don’t hit the NAT gateway and thus aren’t counted.There are highly paid AWS consultants who shave literal millions of dollars off of many company’s AWS bills by just setting it up a cheap EC2 box to handle their NAT instead of using the built-in solution. Doing that instantly wipes out the ingress charges and effectively halves the egress charges, and it’s probably a lower hourly cost than they’re already paying: an a1.large is $0.051&#x2F;hr on-demand but that immediately drops to just $0.032&#x2F;hr with a 1 year no upfront reserved plan. If you’re willing to pay upfront and&#x2F;or sign a longer contract, you can get it as low as $0.019&#x2F;hr. reply ttt3ts Bit confused. Couldn&#x27;t you just run a Linux VM to do your NAT and only pay normal egress? reply endgame Yes. And AWS do (sorta) offer a NAT AMI (amazon machine image) if you want to do more management yourself and not get extorted for bandwidth.https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;vpc&#x2F;latest&#x2F;userguide&#x2F;VPC_NAT_Ins...I say sorta because it&#x27;s built on an old version of Amazon Linux and is headed towards EOL with no replacement except \"go build your own\" as you suggest.https:&#x2F;&#x2F;www.lastweekinaws.com&#x2F;blog&#x2F;an-alternat-future-we-now...AlterNAT uses managed NAT Gateways as a fallback when the NAT Instance is out of service, but again you will have to make your own NAT AMI.This is not to excuse AWS&#x27; frankly absurd NATGW pricing, but to point out other ways around it. reply dwilkie You don’t actually need to use the AMI. Here’s an example of a NAT instance we build from scratch:https:&#x2F;&#x2F;github.com&#x2F;somleng&#x2F;somleng-project&#x2F;blob&#x2F;main&#x2F;infrast... reply ttt3ts Thanks! That is exactly what I wanted to know. reply endgame Another thing: EC2 instances (VMs) have a \"Source&#x2F;Destination IP check\" which makes them ignore any packets not intended for them. If you want an instance to do NAT, you need to turn this off. reply jon_richards Weird, I was just looking into this yesterday and found https:&#x2F;&#x2F;fck-nat.dev&#x2F; reply deadmutex > just run a Linux VM+ Run extra for failover, HA etc + manage security + Monitor performance + ... reply ttt3ts You would have to run that in your own data center which is what original poster was comparing to. reply otterley You also have to do it in AWS if you don&#x27;t want to use the NAT Gateway service and still desire reliability over and above the MTBF for an EC2 instance or AZ, or ever want to do anything requiring a reboot. replyNoZebra120vClip 1For example, rather than simply routing IP packets and then forgetting them, you need to statefully inspect every TCP segment and every supposedly connectionless UDP conversation, you need to maintain state for every live conversation, and you need to mitigate DOS with all those resources.At that point, you might as well be running a Layer 7 Firewall or an Intrusion Protection System. reply Bluecobra > At that point, you might as well be running a Layer 7 Firewall or an Intrusion Protection System.If you go down this path consider using Transit Gateway so you can route multiple VPC traffic to a central security VPC in a region. I’ve done this a Palo Alto VM and it seems to work well. reply tptacek 1UDP is connectionless precisely so you can build novel stateful protocols on it. There’s no promise in UDP that you’ll be able to statelessly monitor it. reply colmmacc UDP is actually more expensive to NAT than TCP is. The reason is UDP fragmentation, which is my vote for the worst, and least forgivable, design error of TCP&#x2F;IP.Instead of putting the fragmentation in L4 (like QUIC now does) and including a UDP header on every fragmented packet in a datagram, UDP only includes the header on the first packet. With fragmentation happening; firewalls, NATs, and end-hosts have to buffer and coalesce IP packets based on IP IDs, before the destination can be identified. It&#x27;s a real nuisance. A lot of CGNAT \"stateless\" implementations can&#x27;t handle this and you get very hard to debug issues when there are fragmentation and MTU mismatches. reply pclmulqdq This is probably more accurately called IP fragmentation (since that is the layer where the fragmentation happens), and a lot of companies make it optional to support in networking gear. I&#x27;m surprised that you are using it or seeing it, because it is essentially obsolete today.It has a legitimate purpose in old-timey systems which have bespoke MTUs on each link, but now the usual thing is to use 1500 bytes for WAN traffic, which is the generic Ethernet MTU, and reserve larger sizes for intra-datacenter communications. reply colmmacc There&#x27;s a number of UDP protocols that have large enough payloads to fragment. DNSSEC and EDNS0 in particular made it much more common, though the EDNS0 flag day in 2020 partially undid some of the damage by getting folks to ratchet down their EDNS0 buffer sizes.1500 is absolutely not a pervasively usable WAN MTU, you&#x27;re going to need pMTUd if you&#x27;re sending 1500 byte packets broadly. Plenty of WAN links won&#x27;t tolerate it. If you don&#x27;t want to deal with fragmentation at all ... 500 is the minimum guaranteed MTU, but in practice it&#x27;s exceptionally rare to see anything below about 1200 require fragmentation. But you can always only control what you send, not what others are sending you. reply tptacek One thing I&#x27;ve learned since joining Fly.io in 2020 is to laugh when people point to the 1500 MTU. You absolutely can&#x27;t count on that: IPv6 cuts into it, and so does every additional layer of encapsulation on your path. reply pclmulqdq Yeah, you have to account for the headers in the 1500 byte MTU, which I suppose can be substantial if you have several VLAN tags, IPSec, IPv6, and a bunch of IP options. Presumably most of that encapsulation happens inside a datacenter, though, where you can use jumbo frames. reply dgemm Even well-behaved unfragmented UDP should be more expensive to NAT because it doesn&#x27;t have an end-of-stream \"FIN\" marker, meaning stateful middleboxes need to retain state for longer because they can only time out. reply tedunangst But TCP fragments in the same way? reply colmmacc TCP does not use IP fragmentation, and the IP packets are marked \"Don&#x27;t fragment\". TCP performs its own fragmentation and every packet gets a TCP header in its leading section. A NAT, Firewall, or end-host can L4 route the TCP packet as-is and does not need to correlate with other packets.Edited to extend: this is why TCP has a \"Maximum Segment Size\", and why Path MTU Discovery information has to be passed into the TCP state machine. It is TCP that takes responsibility for carving up the data into the packets, not IP.One of the goals of UDP was to avoid needing this kind of state, which is why the IP layer handles fragmentation for it instead. This is allowed on a hop-by-hop basis, unless the DF bit is set; so when a \"too big\" packet gets to a node with a smaller MTU, it can just split it and send on the fragments. No PMTUD needed.The design could have been for the fragmenting node to also add a UDP header as part of that process, but was not. It would have been a simple change at the time. It&#x27;s had a lot of consequences since and is responsible for a decent amount of complexity in hardware and software packet pipelines. reply wbl It could not have copied the UDP header. Otherwise you wouldn&#x27;t be able to put any new protocol on IP without teaching it to every router. reply tedunangst It&#x27;s been a while since I&#x27;ve thought about this; thanks for the refresher. reply debugnik Which is why game networking libraries put a lot of emphasis on NAT traversal, forcing NATs to recognise the \"connection\". And why game console manufacturers tell users to just forward all incoming traffic unmanaged by the NAT to the console. reply meragrin_ > ISPs & mobile carriers are pushing IPv6 over CGNATLOL. Not Metronet. They are doubling down on CGNAT. They&#x27;ve acquired ISPs with IPv6 and killed it in favor of CGNAT. reply xxpor 1It&#x27;s not really computationally expensive, it&#x27;s memory expensive. You need per connection state. reply blibble 1it already has stateful firewallso that&#x27;s: source ip, dest ip, protocol, source port, dest port, connection state (say 16 bytes total)doing NAT too is what, 3 more bytes per connection (8 bits for an offset into an IP table and 16 bits for the translated port) reply dijit 1NAT and Stateful firewalling are commonly bundled together (especially on home systems) but I would not go so far as to say “NAT has a stateful firewall”-I hear such takes all the time and its really frustrating; usually in threads regarding IPv6, incidentally it is usually programmers who think they understand everything about networks because they know how tcp operates. reply blibble > but I would not go so far as to say “NAT has a stateful firewall”-> I hear such takes all the time and its really frustratingmaybe you&#x27;d be less frustrated if you understood what people were saying, because I didn&#x27;t say thatAWS already do 1:1 NAT and there&#x27;s additionally a stateful firewall, which necessitates connection state trackingadding the extra few bytes to do port translation shouldn&#x27;t vastly increase the memory required> incidentally it is usually programmers who think they understand everything about networks because they know how tcp operates.from someone who has written a commercial packet filter: in terms of complexity, TCP blows the preceding layers of the stack out of the water reply p1mrx 1Generally an ISP does not have a stateful firewall prior to deploying CGNAT. reply Spivak 1This is missing the point mostly, my own sites have supported ipv6 for a going on a decade because it was fun to get it working. But that&#x27;s a very different thing than supporting only IPv6. reply p1mrx 1It&#x27;s best for an ISP to deploy IPv6 and CGNATv4 in parallel, so the NAT only needs to handle traffic for services that don&#x27;t support IPv6 (e.g. news.ycombinator.com) reply whalesalad 1$40&#x2F;mo is outrageous? We spend thousands a month on AWS and drive most traffic thru a single NAT gateway. It&#x27;s rock solid and it \"just works\" without any fuss. Totally worth it. reply cdchn 1There is where people usually start chiming in about how they can run a VPS at Whatever Hosting and Waffles Inc. for $4&#x2F;mo. reply whalesalad 1yep, and they should. aws has never really been suited to the hobbyist. does it work for that? of course. is it most cost effective? absolutely not. is it cost effective for people who need the resources? yes. reply otabdeveloper4 1> is it cost effective for people who need the resources? yes.There is no possible use case in no possible universe where AWS is cost effective.Renting the same compute resources wholesale will cost you 20 times less. (Not a typo.) reply dmattia I run a number of personal projects on AWS entirely on their serverless offerings and pay $0 outside of domain registration as I&#x27;m well within their free tiers. That seems pretty cost effective. reply pclmulqdq Yes, if you can abuse the free tiers, you can essentially run a small SaaS company for free. Once you scale past that point, you are on the hook for a (probably much too large) bill, when you could still be using the same $5 VPS. reply AlchemistCamp 1Yes, and for bandwidth, AWS is closer to 100x overpriced. reply hughw You must be talking about renting resources that run 100% of the time. AWS rents us gpu instances by the second. We have to run sporadic jobs throughout the day that take 50 seconds to two hours. Depending on customer activity we might need to run 10 or more at once, or we might lie idle for an hour. The elastic economics are unbeatable. reply hodgesrm > Renting the same compute resources wholesale will cost you 20 times less. (Not a typo.)You mean like S3 object storage? That costs less outside AWS because you are usually getting less. That&#x27;s if you can get it at all. reply hathchip S3 is not a compute resource. reply theamk so I have an HTTP endpoint which gets maybe 10 hits per day, and does some lightweight computations and records small amount of data.Right now, this is done on AWS, with lambda + S3, and costs under $0.02&#x2F;month.Can you point me to something more cost effective that that? Don&#x27;t forget I also need backup for data, automatic failover in case of machine failure or crash, amd no maintenance (like OS upgrades) for 5+ years. reply bx376 Stateless applications are far cheaper than stateful applications to host on AWS. Computing is cheap, object storage is where AWS make unreasonable profit and lock you in their platform. reply bx376 See https:&#x2F;&#x2F;world.hey.com&#x2F;dhh&#x2F;we-stand-to-save-7m-over-five-year... reply theamk That does not answer my question though... I am not spending $600,000 on hardware!I have no doubt that there are plenty of cases when local hardware is cheaper, but gp said \"There is no possible use case in no possible universe where AWS is cost effective.\"... and I claim there are many use cases where AWS is cheaper. reply Thaxll Do you have the expertise and confidance to run at the same lvl as AWS does for cheaper? reply MildRant Renting the same compute resources might cost you less but you are on the hook for maintenance and administration which can cost you more in the long run. reply finikytou 1sure they became a multi billion dollar business by not being cost effective reply dijit 1They became a multi-billion dollar business by:A) Promising scale (and delivering to a certain extent)B) being significantly more convenient than contemporary solutionsC) becoming trendyD) hoodwinking CxO’s into the belief that not owning your data is better for you, actually. (CapEx vs OpEx)E) unfathomable amounts of DevRel.Nobody has ever claimed AWS was cost effective, they have said that “it’s worth the cost” though. reply Aperocky > cost effective> it’s worth the costSounds about the same. reply dijit I guess you could read it that way.The issue tends to be that people do not actually stay on top of their spend- they claim to need less headcount but then spend more than a few salaries worth on their cloud spend.They claim they do not need headcount but then spend the same headcount in infra people anyway, or finops people in the best case.people have lost touch with how much compute actually costs, because its little by little and claims to scale to zero or you only pay what you want. - yet every installation I’ve ever seen has had a base cost higher than the largest colo installation cost we would have needed times 2.Its not cost effective, because its on average 11x more expensive than a fully managed colocation installation. - your packets dont care that you spent 11x more on half the performance. reply otabdeveloper4 No, the second line is when somebody else is paying the bill.AWS is a boutique retail reseller for compute. It&#x27;s okay for very tiny projects, or for vanity purposes. replySpivak 1Yes it is which is why Lightsail exists. The whole mantra of the cloud is only pay for what you need and scale down to zero. reply cj 1Plus $0.045 per gigabyte of data that passes through it.AWS has notoriously high egress fees. reply dilyevsky 1It&#x27;s not just egress in case of NAT - they charge you 4.5c per processed GB which means in both directions. This trips a lot of people up. reply CSSer 1I ran into a SaaS company recently that had a guide for how to setup a white-label domain using route 53 and Cloudfront for one of their services. The SaaS company charges for service bandwidth usage, and they host their infrastructure on AWS, so if you opt to follow their guide they get a fat margin bump in the form of avoiding an egress charge and you get to be double-charged for bandwidth. You&#x27;ve gotta love it. reply cebert How are the avoiding egress costs? I am not completely following. reply dilyevsky Egress to cloudfront is free on aws reply grrdotcloud Imagine a cloud transfer utility that made that easily possible? replyandrewguenther $40&#x2F;month just to run it, but then $0.045 per GB data rates. The data rates are what is outrageous. NAT Gateways comprise a non-trivial portion of many customer&#x27;s bills for this reason. reply l5870uoo9y 8 Exactly, it is $32 just to have it turned on 24&#x2F;7 and then you pay additionally. Looked into it as it is the only(?) way to get dedicated IP for Lambda which is a common use case, which also explains why it is so costly. They lure you in free tier and then charge for all the necessities. reply Dylan16807 1Most users are below 10Mbps average, so yes $480 per year is a huge price for a fraction of a percent share of a router (plus redundancy). reply ishanjain28 1Okay and those users can easily use a much cheaper NAT instance instead of managed NAT Gateways. reply wpietri It&#x27;s worth it if you spend thousands a month. I run assorted personal projects in AWS and pay $80&#x2F;month. Another $40&#x2F;month looks like a lot to me.But I think the point is more that it&#x27;s outrageous compared to the marginal costs. reply electroly 1The expensive part of NAT Gateway is the $0.045&#x2F;GB. reply mgaunard 1Leasing an IPv4 is 0.40 per month. The 39.60 on top is just their margin. reply dilyevsky Amazon owns millions of IPv4s which they purchased for probably less than $5 a pop. So it completely pays for itself after less than a year then it’s just free cash flow reply ishanjain28 1Where? reply est31 1Exchange prices are still in that region, at least for some RIRs: https:&#x2F;&#x2F;www.ipxo.com&#x2F;market-stats&#x2F; reply paulddraper 1For a lot of traffic $40 is not outrageous.For a little traffic $40 is outrageous. reply thayne For a lot of traffic, the $40 is nothing compared to the per GB price. reply kelnos How much does the NAT gateway cost? Quick search didn&#x27;t turn up anything (and I don&#x27;t care about this enough to spend more than a few seconds on it). You can turn a regular EC2 instance running Linux into a NAT box by giving it two network interfaces (hell, you can even do it with a single interface) and a few shell commands; I wonder if that&#x27;s cheaper, even including the price of the public IPv4.Edit: I see from another post that NAT gateway costs $0.045&#x2F;hr + $0.045&#x2F;GB of transfer. That seems... not terrible? An a1.large on EC2 is $0.051&#x2F;hr + $0.09&#x2F;GB transfer to the internet (which I assume this type of box would be doing a lot of). reply storyinmemo The 0.045&#x2F;GB of NAT transfer cost is in addition to the $0.09&#x2F;GB egress costs. reply pnpnp 1I completely agree. It’s odd they would announce charging for dedicated IPv4 while not having a free shared egress solution (unless I’m misunderstanding).I would expect them to reduce NAT pricing in the long run, but who knows. reply SteveNuts 1I&#x27;m shocked this isn&#x27;t a feature of a VPC out of the box (shared internet bound traffic). You should only need a NAT gateway if you want the traffic to come out of a single set of external IPs that you control.Almost all of my use cases I could easily ride out to the internet through a shared pipe (apt updates and such) and don&#x27;t care whatsoever what IP that exits the AWS network from, since I&#x27;m not applying firewall rules or anything. reply patmcc 1>>> and don&#x27;t care whatsoever what IP that exits the AWS network fromYou&#x27;ll start to care pretty quickly if it&#x27;s the same IP as a bad actor that&#x27;s blocked everywhere. reply ishanjain28 1So for this, Run your apps in public subnets that are attached to IGW. reply zeroimpl Which then requires each app to have a public IP, priced at $44&#x2F;year starting soon reply ransackdev 1I think that as a business and given the fact they are now charging for a previously free service (public IPs), offering a now paid service as free would nullify the reasons for doing what they are doing. They don&#x27;t owe anyone anything for free. reply Ensorceled > They don&#x27;t owe anyone anything for free.I always love this comments. We pay them literally hundreds of thousands a year. reply inopinatus 1That doesn&#x27;t follow, because the reason is that IP addresses are scarce. reply Hexcles We use https:&#x2F;&#x2F;github.com&#x2F;1debit&#x2F;alternat in our EKS cluster to save the AWS tax (surcharge for NAT on top of the egress fee) reply Galanwe You don&#x27;t have to use AWS&#x27; appliance (the NAT GW) to do NAT. You can NAT your traffic yourself from a t2.micro Linux.AWS used to maintain a AMI to do just that, nowadays you have to do it yourself, but it&#x27;s honestly not much more than adding 2&#x2F;3 iptables rules.I find this trade-off to be exactly the reason why AWS is so good even for small startups. You can bootstrap something quickly, though it will be a tad expensive.And if you need to down your costs later on, you start chasing the quickwins like maintaining your own NAT gateway. The same could apply for all managed services.Maintaining your own OpenVPN VS AWS VPN. Maintaining your own Postgres VS RDS. etc reply benjaminwootton The sweet point should be that the total cost of using the managed services should be less than doing so yourself when you account for manpower.If we have ended up at a place where it’s cheaper to run them yourself on an EC2 box then something has gone awry. reply Galanwe \"Cheaper\" is not the only dimension to consider. Using managed services is also faster, more reliable, and scale better. You cannot just get that for free. reply hnav 1You can stand up your own on top of a t3.micro or something if you don&#x27;t care too much about HA (e.g. you just wanna be able to hit the internet when SSHed into your instances). reply multifasciatus Just run an Aviatrix gateway instead, same functionality, lower price reply nodesocket 100% agree, they need to offer steep reserved instance pricing for NAT gateways. To deploy 3 NAT gateways (HA one in each availability zone) is $99&#x2F;mo just for the instances. reply secondcoming 1Last time we used GCP&#x27;s NAT gateway it was constantly dropping SYN packets. We had to revert to using External IPs on machines that talked to the wider internet. reply alberth 1This was expected, and rent seeking.AWS over the last decade has spent $ billions buying up ASN blocks.I&#x27;ve never been one to use the word \"rent seeking\", but owning IPs is the ultimate rent seeking cloud business. Domain names can change registries but if you own the underlining IP being used (and there&#x27;s a depleting supply of them) - it&#x27;s a great business to charge rents on.https:&#x2F;&#x2F;www.techradar.com&#x2F;news&#x2F;amazon-has-hoarded-billions-o... reply eqvinox > spent $ billions buying up ASN blocks.You can&#x27;t buy&#x2F;sell&#x2F;trade \"ASN blocks\". The only people handling \"ASN blocks\" are the 5 RIRs (APNIC, RIPE NCC, ARIN, AfriNIC and LACNIC) and IANA.> owning IPs is the ultimate rent seeking cloud businessIt also seems that your use of \"rent seeking\" doesn&#x27;t match established use. It normally refers to people extracting money for things far beyond their actual value. The IPv4 market is working pretty well on a supply vs. demand price feedback loop, i.e. the prices are in fact just reflecting the scarcity of IPv4 addresses. The term \"rent seeking\" does not fit that situation. reply sgjohnson 47 > You can&#x27;t buy&#x2F;sell&#x2F;trade \"ASN blocks\". The only people handling \"ASN blocks\" are the 5 RIRs (APNIC, RIPE NCC, ARIN, AfriNIC and LACNIC) and IANA.You absolutely can sell ASNs or ASN blocks, just like you can sell IPs.Want to sell an ASN? Ask the buyer for money. When the money is in your account&#x2F;escrow, transfer the ASN to them. Get money. Sale complete.But that’s besides the point, this has got nothing to do with ASNs. reply efitz Looking at it a different way, IPv4 addresses are scarce so it makes more economic sense to have fewer, central owners that can maximize usage, rather than millions of individuals owners, many or most of which would not necessarily be using them at any given time.Putting a price on IP address usage again is a mechanism to prevent squatting&#x2F;hoarding a scarce resource.But if you don’t want to “rent” IP addresses from anyone, you can still find blocks for sale. Last time I checked (last year) class C blocks were going for $15k-$20k. reply mike_d > makes more economic sense to have fewer, central owners that can maximize usageWhat you have described is effectively a China-style ICP license[1]. Unless you are willing to give a big name cloud provider $x per month, you shouldn&#x27;t be able to put a service on the internet?1. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;ICP_license reply ripdog Only on legacy IP. We&#x27;re trying to kill it.A bit of pain will be necessary to finally get modern IP across the line of mainstream usage. reply efitz BTW AWS specifically allows you to bring your own IP addresses.https:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;AWSEC2&#x2F;latest&#x2F;UserGuide&#x2F;ec2-byoi... reply sgjohnson 45 I have a &#x2F;24 of v4 just so I don’t have to run NAT at home. My Apple Watch has a real, globally unique IP address.Is this valuable use of IPv4 space? I think yes. reply madsbuch 1Most applications will be able to move to v6 eventually. Hopefully moves like this will push that development. reply voytec It&#x27;s ISPs who are the main problem, not applications. reply madsbuch Not software applications, applications of network usage (though I see why it would be reasonable to misunderstand) reply dunno7456 Both reply andrewstuart2 1Even already, I think you can get away with doing almost everything v6 with a much smaller number of ipv4s for legacy traffic. I say that but still largely use v4 for everything, so maybe I&#x27;m not one to talk. reply pantalaimon Unless you need to pull anything from GitHub… reply GoblinSlayer That&#x27;s the idea, you route github through a legacy route and use normal route for everything else. reply kccqzy Then direct your anger at Microsoft, not Amazon. reply doublerabbit Why not both?Both are dominating the internet-cyberspace and both are screwing it over for everyone else. reply duped Why do you need a public IPv4 address to pull from GitHub? reply ripdog GitHub has no modern IP support, so a system without a legacy IP is unable to pull anything from GitHub. replyTheDudeMan I guess you feel that AWS should pay for the IPs and then give them to you for free. Makes sense. reply teddyh IP addresses are supposed to be free! The RIRs are in the business of handing out addresses to whoever applies for them if the applicant can show that they have a reasonable use for the addresses. But as the IPv4 addresses eventually run out, AWS will then buy addresses directly from whoever has them. This is allowed, but a bit dubious, since if someone aren’t using their addresses, it would make more sense to return them to the RIR to be reassigned. But if AWS owns all the addresses, and nobody can get any more, it makes sense for AWS to start charging for the addresses. It would also make sense for AWS to halt and delay any IPv6 adoption, so we should watch for that. reply chii > IP addresses are supposed to be free!just like the air is supposed to be free!In reality, nothing can be free. The cost was initially not being paid for, because initially there&#x27;s just quite a bit of addresses, and there wouldnt have been any quarrels.I maintain that the world is being polluted because things aren&#x27;t free. Imagine if every cubic inch of air, water and land is owned. You would not be allowed to pollute! You&#x27;d pay for your use of it! reply Sebguer You&#x27;ve read The Moon is a Harsh Mistress too many times, and taken away the wrong lessons. reply mike_d Had AWS not gone around offering to beat any offered price for IPs things might be a lot more reasonable right now. You can&#x27;t complain that you had to pay a ton for a scare resource when you were the ones throwing gasoline on the scarcity problem.They even did backroom deals to steal large blocks of IP space, most notably from the HAM radio community. reply yieldcrv Most of the internet is rent seekingVPNs just resell internet under a “more private than the next” unverifiable claim, and hope they get enough sycophants believing itMost of YC this year resells access to ChatGPTIts the game reply vbezhenar I doubt many people care about private aspect of the VPN. They usually want to access services which are inaccessible from their primary IP.I&#x27;d say that VPN is a way for Internet to work around artificial obstacles. reply wpietri That&#x27;s not rent seeking: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Rent-seeking reply yieldcrv I see, I understand the distinction then, so why would would owning and reselling IP addresses be rent seeking then, if my examples also are not reply StopHammoTime Because for better or worse, those services are transforming the output. Arguably in not a very valuable way but they are transforming it nonetheless. Whether or not you find that transformation useful doesn’t change the fact it is happening. IPs are IPs no matter what way you are cutting it. There is no other universal way to address internet resources yet (as adoption is still slow on ipv6), so this is rent-seeking in the same way a toll road on public roadway that has existed for 20 years is rent-seeking.Edit: furthermore, in both of your examples you can just go to another provider or not use those services. If you are locked in to AWS, you HAVE to pay this price. replywongarsu 1This finally puts real pressure on software and services to work on IPv6 only. I wouldn&#x27;t be surprised if within 1-2 release cycles lots of distributions suddenly update just fine with just IPv6, package mangers can download packages over IPv6, lots of APIs gain solid and well-tested IPv6 support, etc. reply candiddevmike 1Businesses and organizations are holding IPv6 back, not consumers. No one I talk to is prioritizing IPv6 migrations or spending money to upgrade gear that will support it. Maybe some net new stuff might get it, but for most businesses IPv4 is and will be the default, simply because they can&#x27;t be bothered to do something different. reply jiggawatts It’s worse than that: new software and hardware is being developed or rolled out right now that is incapable of working on an IPv6 network. Not just unable to use it, but actively incompatible — failing to run if other devices use IPv6!This was an issue with Azure’s PostgreSQL service, which would fail if you deployed other unrelated IPv6 services in the same virtual network.We need a guild of software engineering so that the people responsible for this can be summarily ejected from it. reply endgame > We need a guild of software engineeringThe threat of professional exclusion is one of the big levers provided by such a guild. Given the way tech companies behave, why do you believe that this lever will be left in the hands of good people, and not taken over (like the rest of the internet)? reply candiddevmike I think there are more developers opposed to the recent web attestation shenanigans than those for it (even those who might be coerced into being for it by their employer). A majority guild vote could stop everyone working on it and keep the web open. reply endgame Yes, and if you can hold and retain power over the guild then the power of professional exclusion exceeds the coercive power of any one employer. But when your threat model includes adversaries who are willing to subvert the entire open internet to get their way, how do you harden your guild against this attack? reply LeafItAlone Who accredits someone to join this guild? Who holds the keys? reply aoetalks > new software and hardware is being developed or rolled out right now that is incapable of working on an IPv6 networkI would be shocked if this were true for hardware. Even for software, every major OS in the last 10 years as supported IPv6, and prefers it over IPv4I’m sure there’s horror stories, but I doubt it’s systemic. reply jiggawatts > prefers it over IPv4That&#x27;s the problem. If the OS starts using IPv6 preferentially but the software on top can&#x27;t handle it, then you get a crash.E.g.: if you turn on IPv6 for DNS and it starts returning AAAA records instead of A records, then a lot of applications fall flat on their face.Usually the type written in C and insisting on maintaining compatibility with whatever Berkley did in the 1970s. reply bauruine Some enterprise software I guess? I have native IPv6 since 2010 and can&#x27;t remember a single software that crashed because of it. reply 0cf8612b2e1e 1Serious question, is there any enterprise gear made today which does not support IPv6? I have assumed that the natural hardware upgrade cycles made it so 99% of all active equipment could support the technology, even if it was not configured to do so. reply patrakov It is not about the gear, it&#x27;s about security people that force you to disable IPv6. \"You do not have a valid technical or business reason to use it. And, as electricians say, a VISIBLE circuit break provides the best assurance that this circuit will not kill you. Lack of IPv6, as opposed to just firewalling it, is the equivalent of the visible circuit break. I would also enable a whitelist of permitted ethertypes on all switches, and not include IPv6 there.\"And let me quote from CIS SUSE Linux Enterprise 15 Benchmark v1.1.1 page 191: \"3.1.1 Disable IPv6 (Automated). Profile Applicability: Level 2 - Server, Level 2 - Workstation.\" reply champtar Having an Allowlist of ethertype (ARP&#x2F;IPv4&#x2F;IPv6) is an extremely good idea IMO, as Windows and Linux are extremely permissive in what they accept on L2: https:&#x2F;&#x2F;blog.champtar.fr&#x2F;VLAN0_LLC_SNAP&#x2F; reply candiddevmike 1That door alarm thing that has a Windows XP workstation VM the facilities team touches once a month probably doesn&#x27;t support IPv6.Repeat that scenario across multiple BUs and multiple locations and no leader wants to commit to doing that kind of due diligence. What&#x27;s wrong with our current IP? reply GoblinSlayer Windows XP supports IPv6. reply jandrese Man in the middle certificate re-signing deep packet inspection firewalls are notorious for not supporting IPv6. Most everything else has switched, but many network admins fear IPv6 and don&#x27;t want to have to learn something new. reply squeaky-clean \"Made today\"? Probably not. \"Still in operation today\"? Definitely.My company makes what is essentially an enterprise IoT device. I&#x27;d guesstimate 10% of networks with our hardware in them have no ipv6 support at all. And these are businesses that are on the more tech savvy side (I would assume, since they&#x27;re ordering our stuff). reply Aeolun Hmm, I use IPv4 mostly because nobody in their right mind can remember a IPv6 address… reply chungy I must be in my wrong mind then. :)Just because it&#x27;s a 128-bit number doesn&#x27;t mean it should be difficult to remember, the standard notation goes a long way toward that. 2001:db8::cafe:f00d and fc00:bad:beef::1 aren&#x27;t what I&#x27;d call the epitome of \"can&#x27;t remember\"Mind that real-world global addresses often have four groups of almost-random at the beginning, but it&#x27;s usually not terrible to commit to memory. reply lucb1e Have you tried? I knew my v6 block (and static addresses within that, which is like two: router and server) back when I used v6 ten years ago, same as I know my v4 address, without really actively learning eitherFor sure this is a self-hoster thing, where you have pets not cattle, but so is memorizing your v4 address(es) reply ghosty141 There is nothing wrong with ipv4 in the LAN, for public things in the internet DNS is and should be used anyways making ipv6 there a non issue. reply sgjohnson 40 > There is nothing wrong with ipv4 in the LANAsides from potential address conflicts, should your work VPN space overlap with your LAN subnet, for example. reply post-it Who&#x27;s out there remembering IPv4 addresses? reply brickteacup If only there were some sort of a system for translating human readable names to network addresses... reply waithuh damn, imagine if the buddies of the company that owns all of these IPs operated that system. The entire internet would be in their control. Wild dream. reply ricardo81 Not I. Any commonly accessed IP tends to be named in my SSH config. reply capableweb Plenty of people own ipv4 addresses (I mean, all of them are owned, but most by companies) and have been using the same addresses for a very long time, you start to remember some of them by heart after that :) reply gaudystead &#x2F;me slowly raises hand reply skrause Is is really so hard to remember the addresses fd::1, fd::2 etc. for your local network? reply tenebrisalietum Use DNS? reply dheera IP addresses should never have had letters and double colons in them.What&#x27;s Google&#x27;s IPv4 DNS? 8.8.8.8.What SHOULD Google&#x27;s IPv6 DNS be? 8.8.8.8.8.8.What SHOULD Google&#x27;s IPv8 DNS be? 8.8.8.8.8.8.8.8.What IS Google&#x27;s IPv6 DNS? 2001::some::shit::I::::can&#x27;t::remember&#x2F;&#x2F;::h0ff::affblahThis is why I&#x27;m still stuck on IPv4. I&#x27;m a walking DNS server for all the instances I own, I can hammer out IPs when DNS fails me and that&#x27;s a very useful feature, especially when idiot Wi-Fi hotspots try to DNS poison you when you&#x27;re trying to SSH into something and the poisoned IPs stay cached even after you&#x27;ve accepted the stupid TOS. reply red_trumpet If it is the use of colons instead of dots that prevents you from learning the adresses, then I&#x27;m not sure you can be helped.But that discussion aside, if you adopt the IPv4 naming scheme to the 128-bit IPv6 adresses, Google&#x27;s DNS would be 8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.8.I would never be confident that I put in the right number of 8&#x27;s in that case. And I have a feeling that you being overwhelmed has more to do with the total increase of possibilities, than with hexadecimal notation.I guess it shows that IPv6 was designed for computers, not humans. Because we need a vast number if IP adressses. And that is fine for me. reply rvnx It would be 1.2.3.4.5.6.7.8.9.10.11.12.13.14.15.16 reply dheera > If it is the use of colons instead of dotsColons are inherently more frightening than dots, especially double colons, which seems like some badly written C++ class escaped from gaol. Dots feel friendly and cute, I would pet an IPv4 address.> then I&#x27;m not sure you can be helpedSure, and the rest of the planet hasn&#x27;t adopted IPv6 either. It&#x27;s a horrible UX. reply red_trumpet If I&#x27;m allowed to argue using unrelated topics and feelings, here you go ;)> Colons are inherently more frightening than dotsI highly disagree. In traditional text usage, dots end a sentence. They are terminal. A symbol of stasis. Like death. Contrary to that, a colon always refers to something that comes after: it transcends itself, and wakes my curiosity. It is a symbol of growth and learning. replymiyuru > I&#x27;m a walking DNS server for all the instances I ownIn that case you don&#x27;t need to remember the google&#x27;s DNS address or any DNS servers address for that matter. reply GoblinSlayer It would be 8::8 reply kccqzy 1Apple has been demanding apps support IPv6 only for years now. They reject your app if it fails under NAT64. The end user side is mostly a solved problem. reply ketralnis 1For iOS maybe. Most of those applications are also using Apple&#x27;s networking libraries and are effectively required to be on Apple&#x27;s infinite software update treadmill to continue to be listed, keeping them young and hip in perpetuity. This is the upside to that treadmill, things are up to date or just stop working.But I don&#x27;t think that&#x27;s representative. \"Or just stop working\" isn&#x27;t a valid alternative to the rest of the world. Outside of mobile ecosystems and maybe web development most things aren&#x27;t on these 6 to 12 month update cycles. It would be absolutely unreasonable to tell a hospital that every piece of hardware and software and MRI machine in their building has to be upgraded every 2 years or it&#x27;s positively geriatric and do you even `pacman -Syyu` bro?Theres a whole world of things that haven&#x27;t been, and may never be, transitioned. Useful things like utility control computers and even peoples&#x27; 10 year old, still perfectly functional and supported desktops. Heck, my \"end user\" newly-installed fibre ISP doesn&#x27;t support IPv6! And their previous DSL installation to the same address did! So much for \"solved problem\" :( reply kccqzy 1A hospital&#x27;s MRI machine doesn&#x27;t need an internet connection. IPv4 only intranets are fine and we are never going to get rid of them.But anything that connects to the internet needs to be updated regularly, if only for security and vulnerability reasons. If you have a 10-year-old functional and supported desktop, it most likely supports being IPv6 only just fine. The typical 10-year-old desktop came from the factory with Windows 8 and could be upgraded to Windows 10 (since it&#x27;s supported). It even gets relatively new features such as IPv6 RDNSS allowing DHCP-less deployments. reply p_l Windows networking became v6-first in Vista, over a decade ago. reply bandrami > A hospital&#x27;s MRI machine doesn&#x27;t need an internet connectionThat&#x27;s one of the more disheartening searches on censys, unfortunately reply wiredfool For a while, google was blocking linode&#x27;s ipv6 block in Frankfurt.NBD, except that elastic hosts their client deb repos on google infra, so apt-get update was failing from it.The solution was to single stack the server, or manually install the clients having downloaded from elsewhere. reply Macha 1As a business... $40&#x2F;year&#x2F;server is nothing.As a individual&#x2F;hobbyist, it&#x27;s a much bigger disincentive.For students and the like, it might actually be prohibitive.The problem is it&#x27;s really the first group that needs to drive the remaining IPv6 adoption by replacing their middleware boxes etc. and they&#x27;re the group who are unlikely to care at this price. reply NoZebra120vClip 1TIL that my Chromebook connects to the Internet with a 6to4 address rather than the real &#x2F;64 that my ISP assigns. reply p1mrx 1This seems unlikely, as 6to4 was deprecated in 2015: https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;rfc7526 reply NoZebra120vClip 1I couldn&#x27;t believe it either, but using Chome on ChromeOS 114, updated yesterday, all the public sites report that I am connecting from 2002::&#x2F;16 reply p1mrx 1Interesting. It&#x27;s only possible to terminate 2002::&#x2F;16 using a public IPv4 address, so if you&#x27;re behind a NAT router, then the router itself must be running 6to4. reply NoZebra120vClip Aha! Thanks for the hint: I recently had to reconfigure my router from factory settings. The IPv6 configuration, sure enough, was kicked into 6to4 mode. I set it to \"Auto Config\" and now I&#x27;ve got end-to-end IPv6 connectivity with, look Ma, no NAT!Thank you, p1mrx! replysph Yearly reminder that HN is still IPv4-only reply wmf 1Previously: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36910855 https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36910994 https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36942424 reply metadat 1Thanks! Macro-expanded:AWS: IPv4 addresses cost too much, so you’re going to payhttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36942424 (3 days ago, 186 comments)AWS Begins Charging for Public IPv4 Addresseshttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36910994 (6 days ago, 36 comments)AWS Public IPv4 Address Charge and Public IP Insightshttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36910855 (6 days ago, 9 comments) reply MayeulC You make it sounds like that expansion was performed automatically. Is that something HN&#x27;s reply box supports? reply decasia 1So I have a tiny personal website hosted on ec2. Right now the DNS points to the server&#x27;s public IPv4 address. But I don&#x27;t really want to pay $40+&#x2F;year for an IPv4 for my personal project.Does anyone have experience switching a small personal site to IPv6 only in 2023?I&#x27;m guessing the vast majority of my (North American&#x2F;European-based) friends and visitors can probably connect just fine to an IPv6 address. I wish I knew what percentage it is.I guess I could add an AAAA record and check what percentage of traffic actually uses it. reply capableweb 1According to Google (https:&#x2F;&#x2F;www.google.com&#x2F;intl&#x2F;en&#x2F;ipv6&#x2F;statistics.html), 60% of word-wide users wouldn&#x27;t be able to visit your website.In the US, it would be about ~50% of users, while in Europe it&#x27;s ranging from 30% (France) to 98% (Spain) who wouldn&#x27;t be able to visit the website.But yeah, I&#x27;d do what you say in the bottom of your comment. Add AAAA records and then see how many people uses ipv6 compared to ipv4 and then decide. reply KAMSPioneer I understand that Movistar, the largest Spanish ISP, is currently deploying IPv6 in beta at the moment. I expect that will trickle down to the various resellers of Movistar&#x27;s network shortly after. Hopefully that will get that 98% down in the near future. :( reply LeafItAlone I think there’s a difference between “don’t” and “can’t”.It’s not clear to me on that page how it describes “can’t”, other than ambiguous (to me) graph labels.Is there more info elsewhere that describes the “can’t”? reply GoblinSlayer 37 Chrome connects to google through ip6, if it succeeds, then ip6 is available, thus they gather statistics. reply decasia 1Sigh, so basically it&#x27;s impossible to switch without shredding an already tiny audience. I&#x27;m sure it won&#x27;t be a nice UX either to have a \"can&#x27;t connect to this IP\" error in someone&#x27;s browser.IPv6 has been around for so long now, I&#x27;m disappointed it doesn&#x27;t have a little bit higher adoption. reply GoblinSlayer 31 It&#x27;s a chicken and egg problem: as long as sites are available through ip4, ISPs have no incentive to provide ip6, and since ISPs often don&#x27;t provide ip6, sites can&#x27;t go ip6-only. One possible solution would be to provide both and throttle ip4 traffic, then better speed can provide incentive to upgrade to ip6. reply smileybarry And if all else fails, you can put something like Cloudflare in front of it to handle IPv4 traffic. reply doublerabbit Which than you&#x27;re back to paying $40+&#x2F;year to ensure you don&#x27;t get wiped from their \"free\" tier when they feel like it.Nothing is free forever. reply godzillabrennus They have had a free tier since they launched over a decade ago. I think they’ve found a way to monetize that traffic or at least the data they collect on the sites they proxy because it’s survived so long. reply asynchronous True, it is a temporary solution though to how long Cloudflare offers it. reply abdullahkhalids Might be a good idea to make a hidden request from your homepage to an ipv6 only resource. Then log how many of your visitors actually fail. reply mr_toad So if a domain only has a AAAA record, and for whatever reason a user can’t use IPv6, what sort of error message would the user see? reply strbean Found https:&#x2F;&#x2F;test-ipv6.com and:https:&#x2F;&#x2F;ipv6.ams2.test-ipv6.com&#x2F;ip&#x2F;?callback=?&testdomain=te...I get the following from Chrome:> This site can’t be reached> Check if there is a typo in ipv6.ams2.test-ipv6.com.>DNS_PROBE_FINISHED_NXDOMAIN reply miyuru >>DNS_PROBE_FINISHED_NXDOMAINThis is because your OS is not querying AAAA records. I am gonna guess that your using macos.The most common error would be a \"connection time out\". reply pravus The client shouldn&#x27;t even attempt to get an AAAA record unless they have an IPv6 stack available. In that case, their client should try to look up an A record and get an NXDOMAIN error which the browser usually shows as \"IP address could not be found\". If the client does attempt IPv6, you&#x27;ll get a stack error when trying to connect to the remote host because the kernel will reject the address family and you&#x27;ll get something like \"network is unreachable\". Some clients will also degrade from AAAA to A on error so you&#x27;ll get the NXDOMAIN error as above. reply MayeulC I wrote this a few years ago, but I feel like putting a dedicated IPv4 like 66.66.66.66 in the A record would inform the web browser or other software that the website is only reachable via IPv6, and a more informative error message could be displayed.This would require a proper RFC of course, with support from IANA and web browsers. reply avereveard 1How about removing the public IP and receiving connection from cloudfront? Or have it hosted in apprunner. Then you cname your domain to the services&#x27; domain, and skip the cost. reply decasia Yep I think that&#x27;s plan B, thanks. reply red_trumpet That&#x27;s a high price tag! On my Hetzner instance I pay 0.5€ per month and IPv4 adress, so 6€ per year. reply sgjohnson 37 > Does anyone have experience switching a small personal site to IPv6 only in 2023?Trivial. Just put Cloudflare in front of it. reply pfych Throwing the VPC behind cloudfront is probably the best course of action, if your site is static I&#x27;d recommend looking into S3 + Cloudfront for hosting it. It&#x27;s basically free, and great if your site is mostly static. I run a few scheduled jobs on Lambda to pull some data for my site and it comes out at basically $0 every month. reply ThatPlayer Cloudflare&#x27;s gateway supports IPv6 and will serve over IPv4 if you want to use that. reply Saris Why not switch to a different provider? AWS is really pricey for what you get reply wuming2 For a small personal website I suggest to look at alwaysdata.com. In France so ipv6 support is a given. reply toomim Switch to linode. reply decasia So I used to use DigitalOcean for around the same intro price point, but after a while I realized that I could pay $22&#x2F;year for a t4g.nano ec2 instance instead of $72 for the cheap DigitalOcean VPS. I guess in the end, the $22&#x2F;year was too good to be true and the DO&#x2F;Linode pricing effectively bundles in the price of the IPv4 address. reply cferry 1The only barrier for me to go IPv6-only is those VPS that are provided with a single &#x2F;128 IPv6, and I do not know of a service that would offer IPv6 tunneling other than HE, that requires an IPv4 endpoint. The day I get a full &#x2F;48 or &#x2F;64 with my VPSes, I&#x27;m ready to drop IPv4. reply xuki 36 Vultr&#x2F;Linode offer a full &#x2F;64. Linode even offers &#x2F;56 with justification. reply mgbmtl Does your VPS assign you multiple ipv4 addresses? Otherwise seems like feature parity.I use ipv6 everywhere, but I get annoyed when some features are missing.For example, OVH won&#x27;t let me transfer an IPv6 prefix like they do for IPv4. I thought I could just migrate my VMs to another box, but one of them had lots of clients with their own DNS&#x2F;domains, so it was a huge pain to update. reply MayeulC OVH gives me a single &#x2F;128. Spam whitelists are at &#x2F;64 grsnularity, so I cannot use IPv6 e-mail. this is not parity!I asked their support about this a year ago. They said they were discussing increasing the prefix size internally.That kind of makes me want to move to Hertzner or another competitor. reply kccqzy Amazon gives you more than a single &#x2F;128. So your complaint is irrelevant if you actually use AWS. reply londons_explore 1As long as IPv6 remains free, and there is some kind of ipv4 accessible proxy for web stuff for free, I&#x27;m happy. reply blibble 1the ipv6 support is sporadic and not in all regionshttps:&#x2F;&#x2F;docs.aws.amazon.com&#x2F;vpc&#x2F;latest&#x2F;userguide&#x2F;aws-ipv6-su...why are these large hosting companies so incompetent? reply Beached 1because they don&#x27;t have to be. when you own 20% of the entire Internet, you can just do whatever you want, very few can compete reply psanford 1aws is many things but &#x27;incompetent&#x27; is not one of them. reply blibble 1explain that page any other way reply est31 1AWS has spent billions (with a b) on ipv4 addresses: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36991477This investment wasn&#x27;t just of a strategic nature: they have enough market power to hold back the move towards ipv6. reply blibble how does reducing your competitiveness in the ipv4 market (what they&#x27;ve done today) hurt ipv6?it will have the exact opposite effect replyArchOversight 1> ipv4 accessible proxy for web stuff for freeNot within AWS. reply londons_explore 52 Cloudflare does the trick tho reply mnutt 1I don&#x27;t see where the latter is the case? For that I believe regular NAT gateway bandwidth charges apply? reply ChrisArchitect [dupe]The other large threads on this a week ago (when this link was also posted) weren&#x27;t good enough?https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36910994https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36942424 reply dang We changed the url from https:&#x2F;&#x2F;www.infoq.com&#x2F;news&#x2F;2023&#x2F;08&#x2F;aws-ec2-public-ipv4&#x2F;, which points to this. reply grobbyy 1This is a hidden price hike. It would be more reasonable if there was a corresponding decrease in server costs. reply ketralnis 1I don&#x27;t think either of those is true?It&#x27;s not hidden, they put it right up on their blog https:&#x2F;&#x2F;aws.amazon.com&#x2F;blogs&#x2F;aws&#x2F;new-aws-public-ipv4-address... the opening line of which is \"We are introducing a new charge for public IPv4 addresses\" and when it starts and what the cost is. I assume like every other AWS charge it&#x27;s broken out in great detail on their billing statements and even have APIs to query costs. Usually they send an email with these changes too so if they haven&#x27;t I assume they will. It&#x27;s a regular old price hike but it&#x27;s not a hidden one.Secondly since \"the cost to acquire a single public IPv4 address has risen more than 300% over the past 5 years\", there&#x27;s no accompanying decrease in server costs that would be \"reasonable\" to account for this. Charging for the IP itself makes total sense since that&#x27;s the cost they&#x27;re accounting for. If it were packed into the instance costs, then instances without a public IP would be paying for it too. This incentivises you to do exactly what they want you to do: use fewer public IPs where you don&#x27;t need them. This is way more reasonable than an across-the-board instance cost bump which would be a hidden price hike. This is a bridge toll that covers the cost of the bridge by its users instead of raising taxes on everyone.I guess you&#x27;re wanting to pay the same and just distribute the cost between the IP and the instance differently? And hey me too, I love not being charged more. But they want to account for their costs without eating into their margin and this is how they&#x27;re going about it. You don&#x27;t have to like it; I sure don&#x27;t. You can wish AWS would just keep eating the cost for you; me too! But I don&#x27;t think \"hidden\" or \"unreasonable\" is accurate. reply grobbyy My back charged me a new fee advertised on new fine print in a web page somewhere I never saw. I changed banks. You can hide things in plain sight. No one has visited every page on Amazon.com.There has been a decrease in server costs. Prices of computers continue to fall. AWS hosting has become (relatively) more expensive over time. reply whalesalad 1IPv4 is a finite resource. This is a forcing function to ensure that people who actually need IPv4 addresses are using them. Gotta pay to play.I guarantee there are a ton of unused IP&#x27;s just sitting on accounts doing absolutely nothing. reply mark242 1Addresses were already being charged if they weren&#x27;t attached to an interface. Increase that charge if you&#x27;re looking to churn unused IP addresses. reply jeremyjh 1That would not catch every public IP address that is actually unused, because it can be attached to an interface and yet not be needed or actually used by any client. But I don&#x27;t agree with GP that this is an important reason for the price increase. They are increasing prices simply because costs have increased. reply mark242 1Anything that an IP address can be attached to is already accumulating a charge, just by existing and running. EC2, NAT gateway, ELB, etc. What&#x27;s \"actually unused\" then? Minimum amount of traffic? I don&#x27;t think it&#x27;s in Amazon&#x27;s purview to make those judgement calls. reply jeremyjh 1What I meant by unused is that there might not be a client that ever connects to that IP address, so the public IP address itself might not be used even if its attached to a resource.> I don&#x27;t think it&#x27;s in Amazon&#x27;s purview to make those judgement calls.I already said I don&#x27;t agree with GP that this is a motive for Amazon. replymarcus0x62 1Their costs for delivering one service are increasing so they should lower their prices on another? reply ribosometronome 1If they&#x27;re separating out functionality from that service and charging for it, sure. Customers who don&#x27;t pay extra are getting less service than they used to for the same money they used to pay. reply ketralnis 1> Customers who don&#x27;t pay extra are getting less service than they used to for the same money they used to paySure, yeah. That&#x27;s how price increases work. Nobody&#x27;s arguing that it&#x27;s not a price increase. But if your delivered pizza&#x27;s costs are fuel+ingredients and the price of fuel goes up, well, the whole price goes up or you have to give on the amount of pizza. The price of the ingredients didn&#x27;t go down, so yeah you&#x27;re just going to have to pay more or get less pizza. Sorry.You can quibble on the pizzeria&#x27;s margin I guess: AWS could just eat the increased price themselves, and probably have been until now. But apparently they don&#x27;t want to so they&#x27;re raising the price to compensate in frankly the most reasonable way possible. AWS has insane pricing for many of its services, especially bandwidth, but this isn&#x27;t one of them. reply barryrandall 1The move may seem unreasonable, but it seems more unreasonable to expect anything different from the oligarchy. reply brickteacup > but it seems more unreasonable to expect anything different from the oligarchyoh my god when the demand for a scarce resource outstrips supply, prices go up. this is high school microecon, not some conspiracy by tHe oLiGaRcHy reply mythz Always more expensive on AWS: $0.005&#x2F;hr =~ $3.60&#x2F;moWe pay $0.55&#x2F;mo (€0.50) on Hetzner. reply netcraft 1I personally dont think 45$ per year is going to change habits that much, especially for larger customers who have a lot of public IPs. reply kiririn 1Hobby customers can buy an entire VPS, complete with IPv4 to tunnel through, for 1&#x2F;4 that reply Operyl 1Hobby customers aren&#x27;t using AWS, by and large. And it&#x27;s only a matter of time before we see more and more costs for IPv4 down in these tiers as well. reply pnpnp 1Totally disagree! :)My monthly costs are minuscule with a reserved with a t4g instance, Lambda, S3 and Cloudfront as my primary usage.Honestly, it beats out the “budget” VPS providers I was previously using, and is a heck of a lot more powerful&#x2F;reliable. reply Operyl 1I knew I’d get the counter points here on HN, but I’d argue we’re probably the exception here. AWS can be really cheap, but it is easy for things to go wrong. Bandwidth, commonly unmetered at places like OVH or Hetzner, can cost a fortune at AWS if you get attacked. And while AWS will refund you once or twice, after that you’re either left scared or on the hook eventually. reply pnpnp 1Absolutely! It just happens to be a good fit for me :)I use very little bandwidth and processing with the vast majority of my projects. In the even that I do need heavy lifting for a couple hours, it still tends to be a pretty minimal cost.Now for sustained heavy loads&#x2F;bandwidth… I definitely would look elsewhere for hobby projects.Edit: and I agree with your point about attacks. I have pretty aggressive monitoring set up around billing. reply voytec 1> Hobby customers aren&#x27;t using AWSAWS has the easy to use Lightsail[1] VPS offer with cheapest product at $3.5&#x2F;mo but they&#x27;ll likely increase these prices as well, since there&#x27;s an IPv4 address included.[1] https:&#x2F;&#x2F;aws.amazon.com&#x2F;lightsail&#x2F;pricing&#x2F; reply rusl1 1I&#x27;ve got a 2GB ram 2 CPU for the same price on IONOS reply preommr 1Counterpoint: My hobby projects all use AWS because that&#x27;s what I am familiar with, and they have the cheapest prices. I also reuse a lot of resources like a database to further save costs. reply Aeolun AWS have many things, but they most definitely do not have the cheapest prices. Unless you are pricing in convenience. reply znpy 1Hobby provider most often are already charging for ipv4 addresses. reply lokar 1Already a lot of discussion about this at my job. It’s a lot of $ at scale. We will put a bunch of work in to avoid the fee. reply mrweasel 1Some companies have been allocating a bunch of pointless IPv4 addresses and I think that&#x27;s why AWS is doing this. A friend of mine have reduced the number of IPv4 addresses his employer uses by 80% (100+ IPs) in less than a week. That&#x27;s a huge saving, but those IPs should never have been allocated to begin with. reply rblatz 1At $45 a year per IP address you’d have to spend less than a man hour per address to even conceivably approach break even.And I normally would be worried if my company was focusing on break even initiatives instead of higher impact ones. reply toast0 1Depends how many IPs you&#x27;re using. If you&#x27;re using 10, who cares; if you&#x27;re using 100, I dunno. If it&#x27;s 1,000 or more, that&#x27;s real money you probably shouldn&#x27;t be pissing away. (OTOH, a lot of cloud spend is pissing away money, so what&#x27;s another $45k&#x2F;year) reply lokar 1And at 100,000+ it’s worth real engineering reply wongarsu 1But if you have 100 backend servers that mostly communicate on the internal network&#x2F;VPC and need their IPv4 mostly for updates, it seems easy to justify standing up a proxy and reconfiguring your template. At least if your engineers aren&#x27;t in Silicon Valley and thus don&#x27;t cost you $400&#x2F;h. reply Beached 1you don&#x27;t have to break even on implementation. you will get billed every single year, so if you can have two dudes solve this in 3 months, you can break even in 3 years and every year after that you saved money reply rblatz In most companies that would worry me. That there isn’t anything more impactful to work on than a project that breaks even in 3 years likely is over staffed and I’m likely on the chopping block when things turn south. reply foobarian 1Huh, speaking of lots of public IPs, most of MIT&#x27;s old class A is now owned by Amazon :-(NetRange: 18.32.0.0 - 18.255.255.255 reply Analemma_ 1Why :-( ? There&#x27;s no way MIT was using more than a tiny fraction of that &#x2F;8; now it&#x27;s actually being put to real use, and MIT probably got some money out of it. Everybody wins. reply amluto MIT was using it. Not efficiently, but MIT sold addresses that were in use at the time due to what appeared to be IT ineptitude.It was also shortsighted. It was a massive resource, MIT presumably sold it for under $200M (I assume far under), and now AWS plans to rent the addresses at a rate that will be around $600M per year if they manage to rent them all. reply wmf 1The market is working :-) reply 27 more comments...",
    "originSummary": [
      "Starting from February 1, 2024, AWS will implement a charge of $0.005 per IP address per hour for public IPv4 addresses across all AWS services.",
      "This change is motivated by the growing shortage of IPv4 addresses and is intended to promote the adoption of IPv6.",
      "AWS is also introducing Public IP Insights, a free feature that enables users to monitor and analyze their usage of public IPv4 addresses.",
      "For the first 12 months from February 1, 2024, the AWS Free Tier for EC2 will include 750 hours of public IPv4 address usage per month."
    ],
    "commentSummary": [
      "AWS has implemented charges for public IPv4 addresses, leading to dissatisfaction among users.",
      "Users have praised Google Cloud's solution and suggested alternatives such as using NAT instances or Linux VMs.",
      "Frustration exists regarding the costs and design of the VPC internals in AWS, as well as concerns about the price increase of Elastic IP addresses."
    ],
    "points": 368,
    "commentCount": 295,
    "retryCount": 0,
    "time": 1691087510
  },
  {
    "id": 36985197,
    "title": "IBM and NASA Open Source Largest Geospatial AI Foundation Model on Hugging Face",
    "originLink": "https://newsroom.ibm.com/2023-08-03-IBM-and-NASA-Open-Source-Largest-Geospatial-AI-Foundation-Model-on-Hugging-Face",
    "originBody": "IBM  Newsroom Press Releases Blog Latest News Media Contacts Media Center Leadership Global Newsrooms About Subscribe IBM and NASA Open Source Largest Geospatial AI Foundation Model on Hugging Face Effort aims to widen access to NASA earth science data for geospatial intelligence and accelerate climate-related discoveries Aug 3, 2023 YORKTOWN HEIGHTS, N.Y., Aug. 3, 2023 /PRNewswire/ -- IBM (NYSE: IBM) and open-source AI platform Hugging Face today announced that IBM's watsonx.ai geospatial foundation model – built from NASA's satellite data – will now be openly available on Hugging Face. It will be the largest geospatial foundation model on Hugging Face and the first-ever open-source AI foundation model built in collaboration with NASA. Access to the latest data remains a significant challenge in climate science where environmental conditions change almost daily. And, despite growing amounts of data — estimates from NASA suggest that by 2024, scientists will have 250,000 terabytes of data from new missions — scientists and researchers still face obstacles in analyzing these large datasets. As part of a Space Act Agreement with NASA, IBM set out earlier this year to build an AI foundation model for geospatial data. And now, by making a geospatial foundation model available via Hugging Face — a recognized leader in open-source and a well-known repository for all transformer models — efforts can advance to democratize access and application of AI to generate new innovations in climate and Earth science. \"The essential role of open-source technologies to accelerate critical areas of discovery such as climate change has never been clearer,\" said Sriram Raghavan, Vice President, IBM Research AI. \"By combining IBM's foundation model efforts aimed at creating flexible, reusable AI systems with NASA's repository of Earth-satellite data, and making it available on the leading open-source AI platform, Hugging Face, we can leverage the power of collaboration to implement faster and more impactful solutions that will improve our planet.\" \"AI remains a science-driven field, and science can only progress through information sharing and collaboration,\" said Jeff Boudier, head of product and growth at Hugging Face. \"This is why open-source AI and the open release of models and datasets are so fundamental to the continued progress of AI, and making sure the technology will benefit as many people as possible.\"  \"We believe that foundation models have the potential to change the way observational data is analyzed and help us to better understand our planet,\" said Kevin Murphy, Chief Science Data Officer, NASA. \"And by open sourcing such models and making them available to the world, we hope to multiply their impact.\" The model – trained jointly by IBM and NASA on Harmonized Landsat Sentinel-2 satellite data (HLS) over one year across the continental United States and fine-tuned on labeled data for flood and burn scar mapping — has demonstrated to date a 15 percent improvement over state-of-the-art techniques using half as much labeled data. With additional fine tuning, the base model can be redeployed for tasks like tracking deforestation, predicting crop yields, or detecting and monitoring greenhouse gasses. IBM and NASA researchers are also working with Clark University to adapt the model for applications such as time-series segmentation and similarity research. The news follows IBM's announcement earlier this year to collaborate with NASA to build an AI model that could speed up the analysis of satellite images and boost scientific discovery. It's also part of NASA's decade-long Open-Source Science Initiative to build a more accessible, inclusive, and collaborative scientific community. NASA, along with the White House and other federal agencies, has declared 2023 a Year of Open Science to celebrate the benefits and successes created through the open sharing of data, information, and knowledge. The model leverages IBM foundation model technology and is part of IBM's larger effort to create and train AI models that can be used for different tasks and apply information from one situation to another. In July, IBM announced the availability of watsonx, an AI and data platform that allows enterprises to scale and accelerate impact of the most advanced AI with trusted data. A commercial version of the geospatial model, which is part of IBM watsonx, will be available through the IBM Environmental Intelligence Suite (EIS) later this year. For more information about this collaboration, visit the IBM Research Blog Statements regarding IBM's future direction and intent are subject to change or withdrawal without notice, and represent goals and objectives only. About IBM IBM is a leading provider of global hybrid cloud and AI, and consulting expertise. We help clients in more than 175 countries capitalize on insights from their data, streamline business processes, reduce costs, and gain the competitive edge in their industries. More than 4,000 government and corporate entities in critical infrastructure areas such as financial services, telecommunications and healthcare rely on IBM's hybrid cloud platform and Red Hat OpenShift to affect their digital transformations quickly, efficiently, and securely. IBM's breakthrough innovations in AI, quantum computing, industry-specific cloud solutions and consulting deliver open and flexible options to our clients. All of this is backed by IBM's legendary commitment to trust, transparency, responsibility, inclusivity, and service. Visit www.ibm.com for more information. Contacts: Sarah Benchaita IBM Research sarah.benchaita@ibm.com Bethany Hill McCarthy IBM Research Bethany@ibm.com   SOURCE IBM Subscribe to email Release Categories AI More Articles Wintershall Dea Works with IBM to Ramp Up AI Initiatives Across its Organization Technology Workforce Playbook for the U.S. NABP Collaborates With IBM to Build New Digital Platform to Protect the Drug Supply Chain Subscribe to email Additional Assets Top products & platforms Industries Artificial intelligence Blockchain Business operations Cloud computing Data & Analytics Hybrid cloud IT infrastructure Security Supply chain Financing What is Hybrid Cloud? What is Artificial intelligence? What is Cloud Computing? What is Kubernetes? What are Containers? What is DevOps? What is Machine Learning? IBM Consulting Communities Developer education Support - Download fixes, updates & drivers IBM Research Partner with us - Partner Plus Training - Courses Upcoming events & webinars Annual report Career opportunities Corporate social responsibility Diversity & inclusion Industry analyst reports Investor relations News & announcements Thought leadership Security, privacy & trust About IBM LinkedIn Twitter Instagram Subscription Center United States — English Contact IBM Privacy Terms of use Accessibility",
    "commentLink": "https://news.ycombinator.com/item?id=36985197",
    "commentBody": "IBM and NASA Open Source Largest Geospatial AI Foundation Model on Hugging Face | Hacker NewsHacker News new | comments | ask | show | jobs | submitloginIBM and NASA Open Source Largest Geospatial AI Foundation Model on Hugging Face (ibm.com) 293 points by drkommy 21 hours ago| 76 comments philosophygeek 1I wish the press release had a bit more detail about what this model actually does and whether it&#x27;s actually useful for the suggested use cases.However, make no mistake: this is for the scientific community and will not help geospatial data to be commercialized. No one cares about your geospatial crop model or that you can identify energy infrastructure or that there&#x27;s some activity around that copper mine. Well, at least no one cares that will actually pay you.(FWIW, I cofounded a geospatial analytics company)Satellite data is extremely idiosyncratic. It&#x27;s coarse (~10m at best), infrequent (every few days at best), and oh you have to deal with the fact that the planet is covered in 50% clouds at any moment. Satellite data works best on things that don&#x27;t move, that are fairly large, and change infrequently. If you find a use case that satisfies those conditions and want to make money, then you need to find a problem that terrestrial sensors haven&#x27;t solved. And if you find that problem, the cost of building, training, and running your model (plus the cost of the data!) has to be less than the marginal value of your model. Good luck finding those use cases.The US Government is special. We don&#x27;t know what&#x27;s going on in North Korea or Ukraine or the South China Sea so we buy high resolution imagery over those areas (30cm) at great cost. Large ag companies and oil companies know what&#x27;s going on within their own facilities; and price gives them information about the rest of the supply chain.In other words, this might be an interesting announcement for scientists, but it won&#x27;t change the geospatial market at all. reply dharmab 1PlanetScope is 3.7m and captures the full land area of the earth daily (minus cloud cover, of course): https:&#x2F;&#x2F;www.planet.com&#x2F;products&#x2F;planet-imagery&#x2F;Disclaimer: I work for Planet.I also disagree with the assertion \"no one will actually pay you.\" Read pages 26-28 of the quarterly report for more information. reply fnands I work for a customer of Planet and can confirm, we pay Planet a lot of money each year. reply fnands I&#x27;m an ML engineer working for a geospatial company and I can assure you, we are looking into this.> Satellite data is extremely idiosyncratic. It&#x27;s coarse (~10m at best) 10m is the best free imagery, in the commercial domain it goes down to 30cm.> Well, at least no one cares that will actually pay you. There are plenty of things people will pay you for. But you gotta find those niches.> In other words, this might be an interesting announcement for scientists, but it won&#x27;t change the geospatial market at all.Maybe, we&#x27;ll definitely check if it can be fine-tuned on higher res data. We do sometimes use Sentinel-2 (not a lot though), but can help with those cases. reply bookofjoe 1>Satellite data is extremely idiosyncratic. It&#x27;s coarse (~10m at best)>The best commercially available spatial resolution for optical imagery is 25 cm, which means that one pixel represents a 25-by-25-cm area on the ground—roughly the size of your laptop.https:&#x2F;&#x2F;spectrum.ieee.org&#x2F;commercial-satellite-imagery reply RosanaAnaDana 1I regularly use up to 3cm aerial imagery.There are many very nice commercial products available. reply DennisP Are there any products available for casual users, just paying for a few images? reply woeirua 1I think it is very important for people to understand that terrestrial sensors are orders of magnitude cheaper for most applications, and are typically far more accurate too. There&#x27;s a reason why most remote sensing companies go out of business fairly quickly. reply pmarreck You have a sibling comment from PlanetScope that claims ~30-50% profit margin, depending on the quarter. reply blincoln 1> Satellite data is extremely idiosyncratic. It&#x27;s coarse (~10m at best), infrequent (every few days at best), and oh you have to deal with the fact that the planet is covered in 50% clouds at any moment.Are the coarseness and cloud aspects going to become less of a factor now that there are commercial high-resolution synthetic aperture radar imagery providers? I&#x27;m just a hobbyist, but the imagery I&#x27;ve seen is sharp, and it even caught the NRO&#x27;s attention.[1][1] https:&#x2F;&#x2F;spacenews.com&#x2F;national-reconnaissance-office-signs-a... reply RosanaAnaDana 1Like... no?InfSar (InSar, SAR, whatever we&#x27;re calling it these days) isn&#x27;t a drop in replacement for anything. Its really neither here nor there when it comes to the utility of other dataset. Infsar is amazing, dgmw, but its stands on its own and has its own advantages&#x2F; disadvantages.The ocs point stands. Satellite data is tough because there is a shit ton of atmosphere between you and the target. That issue doesn&#x27;t go away with infsar and especially not if it isnt coincidentally collected with higher resolution spectral data. I&#x27;ve been in the industry for around 15 years. Things have gotten better, but really, its important to understand the context and limitations of specific platforms. Afaik, there is no panacea. reply nico 1Super interesting. Hadn’t heard of SAR before. Quickly reading about it, it seems like it works like lidar, what’s the difference between the two techniques? Is SAR like “lidar for space”? reply changoplatanero 1I think one difference is that with SAR the sensor needs to be moving. reply mrbgty 1what happened with your company? reply justinwp 1he ran into the ground without a vision and excess spending on bar tabs and the startup life reply gulyams 1If I&#x27;m correct and philosophygeek is Mark Johnson, he cofounded Descartes Labs. It was a pretty cool company with some quite impressive technology. He (they) did a lot.I&#x27;m not far from bashing the VC scene and the adjacent startup culture, but your overly cynical comment was too much even for me. More intellectual humility and less cheap soundbites would benefit society a lot.If you&#x27;re interested, he wrote about it: https:&#x2F;&#x2F;philosophygeek.medium.com&#x2F;meditations-a-requiem-for-... reply RosanaAnaDana 1Descarte labs folded?Oh man. I had no idea! These guys were some of my prime competition for years.The true cost of venture capitol revealed. reply throwaway20222 1Did you work there and know this as a fact? reply numair 1https:&#x2F;&#x2F;philosophygeek.medium.com&#x2F;meditations-a-requiem-for-... reply capableweb Here are a bunch of demos of different use cases:- https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;ibm-nasa-geospatial&#x2F;Prithvi-10... - This demo showcases how the model was finetuned to detect water at a higher resolution than it was trained on (i.e. 10m versus 30m) using Sentinel 2 imagery from on the sen1floods11 dataset- https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;ibm-nasa-geospatial&#x2F;Prithvi-10... - This demo showcases how the model was finetuned to classify crop and other land use categories using multi temporal data.- https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;ibm-nasa-geospatial&#x2F;Prithvi-10... - This demo showcases the image reconstracting over three timestamps, with the user providing a set of three HLS images and the model randomly masking out some proportion of the images and then reconstructing them based on the not masked portion of the images- https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;ibm-nasa-geospatial&#x2F;Prithvi-10... - This demo showcases how the model was finetuned to detect burn scarsMore&#x2F;same but different source information:- From NASA - https:&#x2F;&#x2F;www.earthdata.nasa.gov&#x2F;news&#x2F;impact-ibm-hls-foundatio...- From IBM - https:&#x2F;&#x2F;research.ibm.com&#x2F;blog&#x2F;nasa-hugging-face-ibm- From huggingface - https:&#x2F;&#x2F;huggingface.co&#x2F;ibm-nasa-geospatial reply taf2 1Wondering a use case for a model like these would be navigation without GPS? reply RosanaAnaDana 1Not at 10m brah. reply oefrha I suggest changing the link to https:&#x2F;&#x2F;huggingface.co&#x2F;ibm-nasa-geospatial. The currently linked press release is an insufferable corporate PR word salad. reply Kiro As someone who is not a Hugging Face user your link is much less clear than the submitted link. Really esoteric UI. What am I even looking at? What are Spaces? reply oefrha 1I’m not familiar with HuggingFace at all (not in the AI space) but I clicked on the demos and models on that page and was able to learn what this is all about. On the other hand, I read the press release in full and left with no idea what the model is supposed to be. reply mcwm 1Is this any more useful: https:&#x2F;&#x2F;research.ibm.com&#x2F;blog&#x2F;nasa-hugging-face-ibm reply lolinder 1In addition to what Kiro said (Hugging Face&#x27;s organization UI is hard to parse), the text on this Organizational Card is written in exactly the same word-salad style, just with even less information.I prefer the full press release, especially since it already has the link to Hugging Face for those who want it. reply qwertox 1The core information:> The model – trained jointly by IBM and NASA on Harmonized Landsat Sentinel-2 satellite data (HLS) over one year across the continental United States and fine-tuned on labeled data for flood and burn scar mapping — has demonstrated to date a 15 percent improvement over state-of-the-art techniques using half as much labeled data. With additional fine tuning, the base model can be redeployed for tasks like tracking deforestation, predicting crop yields, or detecting and monitoring greenhouse gasses. IBM and NASA researchers are also working with Clark University to adapt the model for applications such as time-series segmentation and similarity research. reply ritwikgupta 1This simply is not true! NASA and IBM need to do further literature review and rely less on press releases.There are larger foundation models for geospatial imagery available. Our pre-training method, Scale-MAE [0], has 323M parameters, makes encoders robust to changes in satellite imagery resolution, and is therefore trained on satellite imagery of all resolutions. Work out of SI Analytics [1] presents a 2.4B parameter transformers for satellite imagery.[0] https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2212.14532[1] https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2304.05215 reply RosanaAnaDana 1If the models aren&#x27;t available in a repo for download do they actually exist? reply jafo1989 1I&#x27;m interested. Are your models open sourced like the IBM model, and are they easily accessible on HuggingFace? reply ritwikgupta 1They are open sourced (code and weights) [0], but not accessible on HuggingFace.[0] https:&#x2F;&#x2F;ai-climate.berkeley.edu&#x2F;scale-mae-website&#x2F; reply jafo1989 1You might want to think about adding them to HuggingFace, and making them HuggingFace API compliant to lower the barrier to entry.The IBM offering is appealing not because it is \"first\" or the \"best\", but because it is accessible. A lot of institutions &#x2F; enterprises (including my own) are able to leverage transformer models because HF has done so much to lower the barrier to entry with their hub, documentation (model cards) and API.How else would I have found your models but for an IBM press release? reply korypostma 1I work for USGS EROS Data Center and this is basically our life. Taking remote sensing data and generating various models to determine all sorts of things. Yes, I agree with much of what people are saying. This means very little to the public except when it matters. Some of the projects I work on determine famine early warning systems across the globe so that governments can make sure they have enough food for their populations. Others depend upon the health of crops. How people are using the land (land cover). How much cheatgrass and other things are there that affects rangelands (it cuts the tongues of cows for instance). We use super computers (Cray HPCs with GPUs) and deep learning (PyTorch&#x2F;Keras&#x2F;TF). But, given all of the above, I&#x27;m not sure how this would help me to do my job. reply garyfirestorm 1The demo misidentifies West Bengal, India flood to a location in Pakistan. Either the title is incorrect or the model is simply wrong. The demo should have been proof read before publishing :&#x2F;https:&#x2F;&#x2F;youtu.be&#x2F;9bU9eJxFwWc?t=28 reply mletonsa 1Well, it also says Indus which is in Pakistan. But, good catch, weird mistake! reply nharada 1This is cool -- I built something very close to this and I think it&#x27;s really useful for researchers to have access to pre-trained models. Training something like this isn&#x27;t that challenging given the relatively limited scale (100M parameters), but most grad students working in GIS won&#x27;t have the resources or time to do it.I think partnering with Huggingface was a good move, because it means the interface is easy to use. This difficulty in actually using pre-trained research models was one of the design goals of Moonshine[1] and I have no doubt that if it was IBM alone it wouldn&#x27;t be nearly as easy to use.Will be excited to hear if this works for people! Always cool to see your idea validated even if nobody really uses your tool :)[1] https:&#x2F;&#x2F;github.com&#x2F;moonshinelabs-ai&#x2F;moonshine reply bfeynman 1this is just PR newswire hype, calling it foundation model is a stretch. People have been training nets on satellite imagery for a long time, I don&#x27;t even see anything here that would need a foundation model, most of them are vanilla CNNs that work relatively well, the problem has mainly been the data pipeline of different gsds and nadir of images which makes layering difficult. reply H12 This may be a silly question as I&#x27;m quite inexperienced w&#x2F; ML and a lot of the words in this article don&#x27;t mean anything to me yet:But, could this \"model\" be used for something like monitoring land use in a city? The specific example I&#x27;m thinking of is getting a percentage breakdown of what land devoted to paved surfaces (parking&#x2F;roads), to vacant undeveloped lots, and to built structures. It would also be interesting to see how those percentages have changed over time. reply defrost If I skimmed the linked source and https:&#x2F;&#x2F;hls.gsfc.nasa.gov&#x2F;algorithms&#x2F; correctly the models are trained on 10m x 10m ( ~ 30 ft x 30 ft ) cells.That may not be fine enough resolution in the source data to resolve parking lots Vs undeveloped areas to the degree you require.The alternatives are to use the nature of the models (trained to lock in on multispectral signatures) on finer source data - which may limit your options about the globe, ORto use urban data from city land agencies which have maps from low level air photo surveys with resolution down to 10 cm (+&#x2F;-) and GIS land boundaries which are often classified via metadata.Air photos are not multispectral (usually) so you won&#x27;t have access to IR bands etc.You can get coarse city growth figures globally from sat data going back to TERRA (launched 1999 IIRC) and fine grained air photo data from well off cities going back to (say) the mid 80s (and longer for wet negatives). reply krisoft The thing you are asking for does not sound hard if you have multispectral satelite data of your target area.The typical trick is to look for areas which absorb visible red while reflect near infrared to identify vegetation. If all you have is rgb imagery then you can use machine learning techniques to develop a classification system.It does not look like this model means a breakthrough in your application area. Definietly not out of the box, maybe with more work you can refine it to do the classification you are looking for.Do you have access to satelite images of areas where you would be interested in these percentages? reply krisoft > Do you have access to satelite images of areas where you would be interested in these percentages?Answering my own question: it seems one can access the right type of data from the Sentinel satelites relatively freely. reply capableweb I think that&#x27;d make a lot of sense to use it for. One of the demos (https:&#x2F;&#x2F;huggingface.co&#x2F;spaces&#x2F;ibm-nasa-geospatial&#x2F;Prithvi-10...) showcases a fine-tuned version of the model that detects crop type and land usage, so hard to imagine it couldn&#x27;t be done for more types that are more city-oriented. reply netrus 1If you are just interested in the percentage share (not a map of labeled data), all you need is random sampling. Classifying a couple of hundred coordinates is sufficient, takes at most some hours (more likelyWith additional fine tuning, the base model can be redeployed for tasks like tracking deforestation, predicting crop yields, or detecting and monitoring greenhouse gasses. IBM and NASA researchers are also working with Clark University to adapt the model for applications such as time-series segmentation and similarity research. reply mistrial9 the emphasis here is obviously on market-facing customer accounts. Basic LANDSAT NASA data is open to anyone, including big companies. So is this not simply an IBM Watson 2.0, including vague and bombastic impressiveness claims?Floods and fires are bad news, but how does this product actually get used to make things any different ? reply Frost1x 1Land use classification is one of the features advertised. While some may be capable of putting together a classification system on their own, not everyone can (especially reliably). Land use often directly effects things like flooding and fires. Such classification can be used in conjunction with other models to compare say current vs proposed changes in attempts to reduce things like flooding and fires spreading. You might be talking more about mass flooding and less about, poor water overflow management and things like that in which case sure, some things are largely inactionable for humans currently. There are cases where we can have some tangible effects at least on the scales we do create and manage infrastructure though. reply fidotron prev [–] “Model” is a dangerously overloaded word in 2023, possibly worse than Object in 1996.When I worked on ML inference I would tease the researchers with the question “what is a model?” in the hope they would say something that constrained it in any way, but no, a model can be anything at all and is whatever you want it to be.As such this press release is perfect nonsense, which is kind of appropriate for a Watson offshoot. If there is something interesting here it doesn’t succeed in telling you what it is. reply Chabsff If you think of a model as a function approximator with an error that can only be characterized empirically, it&#x27;s not a bad term at all to describe the class of algorithms ANNs belong to.It&#x27;s a real shame that the term is being abused so badly, because it&#x27;s really appropriate in a lot of these cases. Or rather, it would be if people used it mindfully. reply nerdponx 1It&#x27;s a better term than \"algorithm\" or \"learner\" or \"AI\".It very literally is a model of the relationships within the training data.Moreover, statisticians and other varieties of people doing data analysis have been using the term \"model\" to mean something along these lines for many decades already.If anything, it&#x27;s nice to see more people calling these things \"models\". reply romusha So what&#x27;s the better word? reply fidotron What it actually is: https:&#x2F;&#x2F;huggingface.co&#x2F;ibm-nasa-geospatial&#x2F;Prithvi-100M“Prithvi is a first-of-its-kind temporal Vision transformer”That is enormously more specific and interesting, and the word model is absent. reply sxg This entirely depends on context. Replacing “model” with “temporal Vision transformer” in the title would ensure only people “in the know” understand what this even is, which severely limits the reach this post obtains. The point in posting this article is to broadly inform people that this temporal Vision transformer exists. In order to do that, you have to use words the broader audience understands even if the terms aren’t perfectly accurate.In contrast, if you’re publishing this in a machine learning journal, then sure—you should definitely call it a temporal Vision transformer. reply Hizonner 1So it&#x27;s some coils of wire wound around a common high permeability core?Or some kind of weird robot-car hybrid?I guess since it&#x27;s a \"Vision\" transformer, it&#x27;s probably actually some kind of hallucinogenic plant. reply nerdponx 1\"Transformer\" is a particular type of neural network architecture, and neural networks are a class of models. The term \"model\" in this sense has been standard in statistics and data analysis for a very long time. reply oh_sigh 1Transformer is overly specific. Most people won&#x27;t care about the actual architecture and would just treat it as a black box. reply brigadier132 prev [–] dangerous how? reply",
    "originSummary": [
      "IBM and Hugging Face have collaborated to release IBM's geospatial foundation model, based on NASA's satellite data, on the Hugging Face platform.",
      "This is the largest geospatial foundation model on Hugging Face and the first open-source AI foundation model developed with NASA.",
      "The goal is to make AI more accessible in climate and Earth science and advance critical areas like climate change.",
      "The model has demonstrated promising results in analyzing satellite data for tasks such as tracking deforestation and predicting crop yields.",
      "A commercial version of the model will be released through IBM's Environmental Intelligence Suite in the future."
    ],
    "commentSummary": [
      "IBM and NASA have collaborated to release a large geospatial AI model called Prithvi on Hugging Face's platform.",
      "Prithvi is designed for the scientific community and focuses on analyzing satellite images to classify land usage, track deforestation, predict crop yields, and monitor greenhouse gases.",
      "Critics have expressed concerns about the lack of detailed information regarding the capabilities of the model in the press release."
    ],
    "points": 293,
    "commentCount": 76,
    "retryCount": 0,
    "time": 1691067136
  },
  {
    "id": 36989845,
    "title": "FCC fines robocaller a record $300M after blocking billions of their scam calls",
    "originLink": "https://techcrunch.com/2023/08/03/fcc-fines-robocaller-a-record-300m-after-blocking-billions-of-their-scam-calls/",
    "originBody": "Login Join TechCrunch+ Search TechCrunch+ Startups Venture Security AI Crypto Apps Events More (opens in a new window) (opens in a new window) (opens in a new window) (opens in a new window) (opens in a new window) Link Copied Government & Policy FCC fines robocaller a record $300M after blocking billions of their scam calls Devin Coldewey@techcrunch / 11:23 AM CDT•August 3, 2023 Comment Image Credits: Bryce Durbin / TechCrunch The FCC’s robocaller penalties are growing as the agency tracks down and terminates their operations — this time resulting in a record $300 million forfeiture. But whether and when that money will be paid is, as always, something of an open question. The robocaller in this case was known by a variety of names and had been scamming people since 2018, as the FCC announcement explains: This enterprise operated a complex scheme designed to facilitate the sale of vehicle service contracts under the false and misleading claim of selling auto warranties. Two of the central players of the operation, Roy M. Cox and Aaron Michael Jones, were under lifetime bans against making telemarketing calls following lawsuits by the Federal Trade Commission and State of Texas. The multi-national enterprise did business as Sumco Panama, Virtual Telecom, Davis Telecom, Geist Telecom, Fugle Telecom, Tech Direct, Mobi Telecom, and Posting Express. The long-running scheme used the promise of selling auto warranties to collect personal information from people. As if the fake warranty wasn’t enough, the calls also exhibited the standard robocall characteristics of failing to identify the caller, failing to respect call consent laws (like the Do Not Call list), failing to provide a call-back number and spoofing the area code. Chances are you received at least one of these calls — the companies placed at least five billion of them. FCC Chairwoman Jessica Rosenworcel got a few herself, she mentioned in her accompanying remarks. “Armed with the facts [the FCC] gave phone companies permission to cut off this traffic before going one step further and directing them to block it outright. We got results. Following our action, the number of auto warranty calls fell by 99 percent,” she wrote. This effective and quick (at least, quick once they identified the culprits) action is due to various improvements to the FCC robocall enforcement mechanisms over the years. They’ve also established agreements with nearly all the Attorneys General in the U.S. so that they can coordinate with local law enforcement. But one thing they are still lacking is the ability to effectively hammer these malicious actors with proper fines. The FCC is limited to investigating, taking counter-actions (like asking phone companies to stop carrying certain callers), and documenting the extent of the alleged criminal activity. But their recommendation of a $300 million fine must be evaluated and prosecuted by the Justice Department. “What happens next?” writes Rosenworcel. “Under the law we will refer this Forfeiture Order to the Department of Justice to collect payment.  I hope, however, that Congress will consider giving the FCC authority to go to court and collect these fines ourselves.” Justice, like most federal agencies, is swamped; it may be a long time before anyone attempts to collect, and by the time they do, the robocallers will likely have covered their tracks or sequestered their earnings in forfeiture-proof vehicles. A few years ago I wrote about how these fines often end up largely unpaid or drastically reduced due to loopholes and a lack of resources on the enforcers’ side. Florida is a popular refuge for scammers due, among other things, to laws that shield certain property from being seized. Today’s operation is described as being “transnational,” which is not elaborated upon but strongly suggests even greater difficulties in tracking down and squeezing the money out of those responsible. Though it may play out like a game of whack-a-mole, if the FCC were not doing their part it’s likely our phones would be blowing up non-stop. “We know the scam artists behind these calls are relentless,” said Rosenworcel, “but we are coming for them, and won’t stop until we get this junk off the line.” More TechCrunch Researchers jailbreak a Tesla to get free in-car feature upgrades What if room temperature superconductors were real? As AI porn generators get better, the stakes get higher What if room temperature superconductors were real? Please login to comment Login / Create Account TechCrunch Disrupt Sept 19-21 San Francisco, CA Register Now Sign up for Newsletters See all newsletters (opens in a new window) Daily Week in Review Startups Weekly Event Updates Advertising Updates TechCrunch+ Announcements TechCrunch+ Events TechCrunch+ Roundup Email Subscribe (opens in a new window) (opens in a new window) (opens in a new window) (opens in a new window) (opens in a new window) Copy Tags FCC robocalls Government & Policy FCC fines robocaller a record $300M after blocking billions of their scam calls Devin Coldewey 11:23 AM CDT•August 3, 2023 The FCC’s robocaller penalties are growing as the agency tracks down and terminates their operations — this time resulting in a record $300 million forfeiture. But whether and when that money... Fundraising 3 reasons to maintain a follow-on allocation Champ Suthipongchai 5:00 AM CDT•August 4, 2023 A venture fund maintaining some allocation for follow-on investments is not unheard of. But should VCs do this? Apps Discord cuts 4% staff as part of company reorganization Ivan Mehta 1:28 AM CDT•August 4, 2023 Chat app Discord has let go of nearly 40 employees (4% of its workforce) as part of company’s restructuring efforts, according to multiple reports. Several Discord former employees posted on ... Featured Article Fisker reveals all-electric Alaska pickup, 3 other EV prototypes Fisker, the automotive startup-turned publicly traded company founded by famed automotive designe... Abigail Bassett 7:21 PM CDT•August 3, 2023 AI GoStudent adds another $95M to its war chest to go after VR and AI-enhanced tutoring Mike Butcher 5:00 PM CDT•August 3, 2023 GoStudent — the late-stage tutor marketplace that has raised $686.3 million so far — has now raised another $95 million in what it calls a strategic fundraise from Deutsche Bank and other inv... AI AI.com flips from ChatGPT to Elon Musk’s X.ai Devin Coldewey 4:47 PM CDT•August 3, 2023 There was a bit of a hubbub in February as it emerged that OpenAI had seemingly purchased AI.com in order to redirect it to the ChatGPT web interface. But now erstwhile backer, Twitter haver and X ... Hardware Apple services growth continues to counter iPhone sales slide in Q3 Brian Heater 4:25 PM CDT•August 3, 2023 Apple’s Q3 earnings presented a mixed bag for the company, as iPhone revenue continued to slide. The handset brought in $39.67 billion for the quarter, down from $40.66 this time last year. The dro... Transportation Nikola finally gets enough shareholder support to issue more shares Kirsten Korosec 4:16 PM CDT•August 3, 2023 After three attempts and a change in Delaware law, EV truck maker Nikola was able to get enough shareholders to vote on a proposal that will allow it to issue more shares. Nikola said Thursday it r... Market Analysis Coinbase Q2 earnings exceed estimates, signaling potential market recovery Jacquelyn Melinek 4:05 PM CDT•August 3, 2023 Coinbase reported its second quarter earnings Thursday after the bell, beating market estimates with $707.9 million in total revenues. Transportation BMW is pumping more cash into EVs ‘than originally planned’ Harri Weber 3:35 PM CDT•August 3, 2023 As far as sales go, BMW still lags well behind Tesla on the electric-vehicles front, but the German automaker is arguably making strides. BMW told investors Thursday that EVs made up 12.6% of the f... TechCrunch Disrupt 2023 Credo AI, GitLab, Numbers Station will put the AI in SaaS at TechCrunch Disrupt 2023 Lauren Simonds 2:43 PM CDT•August 3, 2023 The global hype surrounding the potential benefits of AI has captured the attention of the business world and beyond, so it’s no surprise that new and existing SaaS startups are integrating it into... Transportation Rivian elects former Waymo CEO John Krafcik to board Kirsten Korosec 2:42 PM CDT•August 3, 2023 John Krafcik, who led autonomous vehicles company Waymo for five years, has joined Rivian’s board of directors, according to a regulatory filing. EV maker Rivian increased the size of its boa... Startups EventMobi acquires a16z-backed virtual events platform Run The World Kyle Wiggers 2:29 PM CDT•August 3, 2023 EventMobi, an event management software provider based in Toronto, Canada, today announced that it’s agreed to acquire Run The World, an Andreessen Horowitz (a16z)-backed platform for online ... Crypto Monthly NFT sales fell for fifth consecutive month to $495M in July Jacquelyn Melinek 2:00 PM CDT•August 3, 2023 Welcome back to Chain Reaction. The NFT space isn’t doing too well right now. It seems like there’s a new project being launched every week, but there’s less and less money being spent in the... Media & Entertainment The San Francisco Giants will wear big Cruise ads through 2025 Brian Heater 1:50 PM CDT•August 3, 2023 One of the fringe benefits of owning a professional sports team is the ability to sell ads on just about everything. Stadiums have been at it for some time, of course. Who can forgot when the Stapl... Apps Privacy-focused Brave Search launches its own image and video search Sarah Perez 1:21 PM CDT•August 3, 2023 Privacy-focused search engine and browser maker Brave is taking another step away from its reliance on other search providers with today’s news that it has now launched its own image and vide... Transportation Moonware’s AI lets airfield ground crews ditch the walkies Aria Alamalhodaei 12:42 PM CDT•August 3, 2023 The fact that any flight departs on time is a minor miracle, one that requires the precise synchronization of thousands of data points and an equally large workforce on the ground. Much of this the... Apps Google is making it easier to find and remove personal info, explicit images from Search Aisha Malik 12:00 PM CDT•August 3, 2023 Google is introducing a few new Search updates that are designed to help users stay in control of their personal information, privacy and online safety. The company announced today that it’s ... Transportation The first Tesla ‘range inflation’ lawsuit has been filed Kirsten Korosec 11:59 AM CDT•August 3, 2023 Several Tesla owners have filed a lawsuit against the U.S. automaker over allegations of consumer fraud a week after a Reuters investigation found the company had exaggerated the range estimates of... Social TikTok competitor Triller files to go public Amanda Silberling 11:04 AM CDT•August 3, 2023 Triller has long teased its ambitions to go public, and now, the short-form video platform seems to on its way to an IPO. Triller filed an S-1 on Wednesday, seeking to directly list on the New York... About TechCrunch Staff Contact Us Advertise Crunchboard Jobs Site Map Legal Terms of Service Privacy Policy TechCrunch+ Terms Privacy Dashboard Code of Conduct About Our Ads Trending Tech Topics Tech Layoffs ChatGPT Threads FAQ Facebook (opens in a new window) Twitter (opens in a new window) YouTube (opens in a new window) Instagram (opens in a new window) LinkedIn (opens in a new window) Mastodon (opens in a new window) © 2023 Yahoo.All rights reserved.Powered by WordPress VIP (opens in a new window) .",
    "commentLink": "https://news.ycombinator.com/item?id=36989845",
    "commentBody": "FCC fines robocaller a record $300M after blocking billions of their scam calls | Hacker NewsHacker News new | comments | ask | show | jobs | submitloginFCC fines robocaller a record $300M after blocking billions of their scam calls (techcrunch.com) 291 points by rntn 15 hours ago| 181 comments phkahler 1This kind of thing is why a lot of people dropped their land line. Sure it was made largely redundant with mobile, but it also became primarily a nuisance.Facebook and others keep that in mind as you relentlessly monetize without offering value to people. reply MiddleEndian 1>Facebook and others keep that in mind as you relentlessly monetize without offering value to people.Pretty much all of my communication on Facebook Messenger is with my friends, and the rest is with some groups I&#x27;m in to find local events, which I could leave hassle-free at any time with the click of a button. No communication with spammers or businesses, with the exception of someone with an obviously hacked account once every few years.With the rare exception, my incoming calls on my phone are either my doorbell (which I answer if I&#x27;m expecting someone), or spammers (who I don&#x27;t answer).So I would say Facebook keeps this in mind much better than the phone company. reply rightbyte 1> my doorbell (which I answer if I&#x27;m expecting someone)My would you not answer if you don&#x27;t expect someone? Pranks? Sellers? I have never experienced any door knockers that are obnoxious, except one seller once. Mostly it is friends, neighbours or missionaries who are unannounced. reply wccrawford 1Even before I had door cameras, I would just not answer the door if I wasn&#x27;t expecting someone. Everyone I know would know enough to call or text before coming over, and anyone in an emergency would keep knocking.I&#x27;ve had plenty of obnoxious salespeople and other solicitors, especially religious ones. They even have the nerve to claim that they aren&#x27;t soliciting because they&#x27;re not selling anything for money. And none of them have the good sense to accept that they&#x27;re bothering someone that is obviously not happy that their door was knocked on.Unless I&#x27;m already in a really bad mood, I generally start off nice, but I turn serious as soon as they refuse to take the first &#x27;no&#x27;. Except for the ones I argue with for a while to waste their time and energy. reply monetus 1Not the OP, but, I once fought off a robbery with a fencing hammer, that started that way. Maybe look for balaclavas before you open the door. reply WarOnPrivacy Who doesn&#x27;t look for balaclavas before they open the door? reply brookst Not always in the mood for a snack. reply debo_ \"Honey, I&#x27;m home\" reply Spinnaker_ 1Depends on the neighbourhood. I moved recently and now a salesman or charity is a 3-4x a week occurrence for me. I also get a bunch of teens selling various goods that I&#x27;m 90% sure are stolen, in order to raise money for their education. reply cwkoss 1Door to door solicitation is obnoxious even if the people are polite, IMO. reply rightbyte 1Sure, but not in the same league compared to sellers calling over the phone in my experience.I guess it comes down to the effective wanna answer the door to not wanna answer the door ratio. I don&#x27;t want to miss someone I&#x27;d like to meet to avoid the 1&#x2F;X chance of a seller. As sibling comment noted that ratio probably depends on local circumstances. reply lazide Someone in person is a lot harder to ignore if they get pushy. reply jfghi As is website to website solicitation reply CameronNemo 1Does solicitation include political lobbying? reply cwkoss I&#x27;d be willing to make a carve out for the candidates themselves or entirely uncompensated volunteers.Campaign staff are not welcome. reply baseballdork 1Yes reply CameronNemo Solicitation is the act of offering, or attempting to purchase, goods and&#x2F;or services.Can you explain how talking to my neighbors about important social issues falls under that criteria? reply lazide A neighbor talking to their neighbors about actual important political issues isn’t typically what people don’t like.People they don’t know trying to convince them they should care about a political issue they don’t care about or they are terrible and bad people is what people don’t like. It’s usually the second one, even if someone thinks it’s the first one. reply CameronNemo So you only want to talk to neighbors you already know? Isn&#x27;t that a bit insular?I think if you want to live in a community, you have to be open to having conversations with your coinhabitants about polemic issues. Anything less is unkind.Regardless, persistent lobbying from a stranger is no more solicitation than softer lobbying from a friend. reply JumpCrisscross In practice, this is rarely a problem. The civically inactive tend to congregate; communities with a strong civic sense, on the other hand, understand why organization is important. (TL; DR If you get mad about neighbors, including those you don&#x27;t know, trying to talk to you about issues, you&#x27;re the root cause of what you might complain about your community.) reply lazide Nice try. I’d say this manipulative BS is the real root cause.People in battleground areas often have buses of activists brought in from neighboring states to do door to door canvassing. Among other things.Thanks for calling everyone who wants to be able to cast their vote without active harassment from people with no stake in their community or reputation to worry about first ‘the root of the problem’ though. reply JumpCrisscross > People in battleground areas often have buses of activists brought in from neighboring states to do door to door canvassingThese aren&#x27;t neighbors. We&#x27;re talking about neighbors.> everyone who wants to be able to cast their vote without active harassment from people with no stake in their communityYour neighbors have a stake in your community. It&#x27;s almost part and parcel with the definition. Refusing to engage with them because you assume to know better obviously impacts the community&#x27;s strength, cohesiveness and civic integrity. reply lazide People recognize their neighbors. reply CameronNemo If by battleground areas you mean swing states, then the national popular vote could reduce that cross-state migration and canvassing that we see so much of.Still, does someone in Georgia not have a stake in whether Florida lines their roads with radioactive agricultural waste? In our industrialized, globalized economy stakes reach much farther than a neighborhood or city level. reply lazide Claiming that any discussion of that sort is ‘friendly neighborhood discussion’ is the height of disingenuous bullshit. Which is my point. reply JumpCrisscross > Claiming that any discussion of that sort is ‘friendly neighborhood discussion’Bit of a straw man to quote something nobody in this thread said.Nobody said civic duty is champagne and French fries. Just that rejecting it has a cost, and the people who cause that cost have a tendency to congregate. That, in turn, frees up resources for the communities who bother organizing. reply lazide Someone literally equated folks from other states as having similar stakes as actual neighbors. This isn’t strawmanning.And you’re the one that keeps beating ‘civic duty’ when I’m pointing out the disingenuous and manipulative nature of a lot of the current political strategies - including fake grass roots ‘neighbors’.Which people have a right to ignore, despite your statements otherwise.Personally, I’d argue they have an actual civic duty to ignore or even ostracize folks doing that, as that kind of manipulative lying is what poisons actual civic discussion. replyshadowgovt No, because if you&#x27;re going to try and start that conversation I&#x27;m not going to answer the door. ;) reply CameronNemo You sound like a pleasant person to be around. &#x2F;s replyMiddleEndian If I&#x27;m not expecting someone to ring my doorbell (or call me on the phone, which is certainly rarer), my phone is on silent. So I simply wouldn&#x27;t notice unless I happen to be looking at my phone.I have my other communication (mostly FB Messenger, but also Discord and SMS&#x2F;MMS) set up to work on my computer, so I rarely look at my phone at home.Also I live in a condo, nobody can really \"knock on my door\" unless it&#x27;s someone who lives in my building, in which case I&#x27;ll answer. reply karaterobot I don&#x27;t answer the door unless the caller knocks more than once. If it&#x27;s only one knock, I assume it&#x27;s someone dropping off a package or asking for money, which accounts for about 95% of cases. If I do answer the door, I&#x27;m almost never glad I did, though. My neighbors have my number, and generally text me before coming over.My thought is that you knocking on my door does not oblige me to stop what I&#x27;m doing and answer it, any more than someone saying, \"sir, do you have a minute for...\" while I&#x27;m walking down the street obliges me to stop and hear their sales pitch, or seeing an unknown caller on the phone means I ought to pick it up. reply Waterluvian 1It’s my time. I will regularly just not answer the door even if they’re looking right at me through the bay window. reply joejerryronnie Friends and neighbors are the primary people I don’t answer the door for. reply smcg 1This could deteriorate at any point. Facebook owes you nothing. reply MiddleEndian Sure, I don&#x27;t think Facebook is benevolent. I hear Whatsapp (also owned by Facebook) has plenty of spam, and I don&#x27;t use that, much to the dismay of some of my non-American friends.The phone companies also owe me nothing, and they provide a worse experience and will likely continue to do so unless forced by the FCC (which seems to be getting better lately).I do use SMS&#x2F;MMS but forwarded to my web browser so I don&#x27;t have to look at my phone.At the moment, Messenger is better for both text and voice&#x2F;video calls. If that changes, my friends and I will adapt. reply CWuestefeld 1Although even today I still have a \"house phone\", I haven&#x27;t used a POTS land line in 15 years or more - I switched to VoIP long ago because of related nuisances.The straw that broke the camel&#x27;s back was that somebody had their fax machine to send something to a (wrong) number every night at 2am. The phone company said they had no way to just block that number for us, but that for abusive calls we could talk to the police. The police said they couldn&#x27;t do anything because although it was an extreme nuisance, it didn&#x27;t fit the legal definition of abusive. Since we were going to have to change our number because of this anyway, we decided to just move to a platform with which we really could manage blacklists and such.A prior experience had a debt collection agency calling us a couple of times a week, asking for some guy we never heard of. Each time we&#x27;d tell them that this was a wrong number, but they&#x27;d just call back a couple days later anyway. I tried using logic: the person they were looking for apparently had a Florida address, while the number they were calling at was a NJ number (back when you could pretty definitively link phone numbers to geography). The guy calling us agreed that it didn&#x27;t make sense, but that didn&#x27;t matter. I finally told them that the guy was deceased, and oddly, they seemed to buy that.Anyway, my experience suggests that the demise of land lines has been not just because of the nuisance itself, but also because the technology and regulatory situation didn&#x27;t allow people any effective way to deal with it.Makes me wonder what that will eventually mean to email, SMS, etc., if anything.EDIT: my current solution for spam calls on our VoIP line is three-pronged.1) Known abusers are blacklisted, never to be heard from again. I don&#x27;t really use this, though, because they&#x27;re probably just spoofing the number anyway.2) Everybody on my contact list can freely ring our phone, no problem.2) Otherwise, the call is intercepted by a voice response system. It just tells them that if they want to talk to us, to push \"2\". Bots never do that, so we&#x27;re very nearly 100% free of spam calls. reply LeafItAlone Fwiw, the three-pronged approach is supported by household phones now. So if you went back to POTS, you could have the same features. Not that you should, but the tools are better now. reply baby I block all calls by default on my cellphone as well. If you want to reach me but you don&#x27;t have my whatsapp&#x2F;facebook&#x2F;etc. then you probably shouldn&#x27;t reach me anyway. reply vkou 1I get mobile robocalls, too. reply EamonnMR 1Most of them get a \"scam likely\" flag these days though. reply jiveturkey 1sure, now. but at the time it was one of the drivers for cutting the land line reply miked85 Mobile doesn&#x27;t help very much - I ended up just silencing calls not from contacts, which I get at least 5 or 6 a day reply jeffbee I haven&#x27;t ever got a robocall on my landline and I get a half a dozen a day on my mobile. reply mikeyouse 1Note, Roy Cox was previously sanctioned and fined for the exact same behavior - his $1M settlement was suspended due to \"inability to pay\".https:&#x2F;&#x2F;www.ftc.gov&#x2F;news-events&#x2F;news&#x2F;press-releases&#x2F;2013&#x2F;02&#x2F;... reply jabroni_salad 1Nintendo can garnish a dude&#x27;s wages to the tune of $10M for the rest of his life for IP violations but we can&#x27;t put the screws on a phone scammer that steals from our grandmothers? Sheesh. reply edgyquant 1So take every cent from him and jail him if he makes no cents. Inability to pay is bs reply NotYourLawyer 1We don’t really do debtor’s prison anymore… reply qingcharles Tell that to the thousands of people locked up for inability to pay their child support. They don&#x27;t imprison you for the debt, they imprison you because the court gave you a direct order and you could not fulfill that order, thus you committed contempt. reply dymk That&#x27;s fine, but we do prisons for criminals, and the guy is a fraudster reply unsignedint 1Implementing a challenge system could be a potential solution. In this system, each outgoing call would require the caller to pay a dime as a deposit. If the recipient marks the call as legitimate after the conversation, either through the app or website, the caller would receive the dime back.To ensure customer convenience, inbound business numbers could have the option to opt out of the challenge deposit requirement, allowing customers to call in without any deposit.While requiring all outgoing calls to be charged might be more effective, it might not be a popular direction, especially in the United States. Thus, the challenge system with a deposit and the optional opt-out for inbound business numbers appears to be a more balanced and acceptable approach, considering both the need for legitimacy verification and user satisfaction. reply coder543 1The recipient of the call would have zero incentive to mark any call as legitimate, so this system would not work due to sheer apathy. All calls would automatically be considered illegitimate.Unless you&#x27;re proposing to also fine people 10 cents for every call that they receive that they don&#x27;t mark as legitimate or illegitimate? That&#x27;s not going to be popular either. reply unsignedint 1Under the challenge system, your friend pays a dime for the call, providing an incentive for you to return that money unless you want to be inconsiderate.For other callers, like businesses, if the recipient does not mark the call as legitimate, they have the option to discontinue offering calls to that customer in the future or absorb the associated cost.To strike a balance, the cost for the challenge should be small enough for typical calling cases, allowing users to accept the occasional expense if necessary. However, as the calling volume becomes excessive, the cost should increase significantly, serving as a deterrent against excessive or spammy calling behavior. This way, the system encourages genuine calls while discouraging misuse of the service. reply coder543 1> Under the challenge system, your friend pays a dime for the call, providing an incentive for you to return that money unless you want to be inconsiderate.At most, this \"consideration\" would extend to a handful of people. In reality, no, most people would not care to mark calls as legitimate, even from friends.> For other callers, like businesses, if the recipient does not mark the call as legitimate, they have the option to discontinue offering calls to that customer in the future or absorb the associated cost.Yes, it would just be part of the cost of doing business. It would be a tax on all phone calls. No one would mark these calls as legit.> This way, the system encourages genuine calls while discouraging misuse of the service.Again, the incentives aren&#x27;t aligned. It would not work.If you had proposed the opposite, your idea would have a much greater chance of working, but you didn&#x27;t. If more than a handful of people mark a particular number as having called them illegitimately, then yes, fine that number a large sum of money. That would work. People are incentivized to complain when they receive spam calls and texts. People are not incentivized to confirm that normal calls are normal.Imagine applying this idea to credit card fraud instead of phone calls, so you had to mark every single credit card transaction as legitimate, or else the business gets charged an extra 10 cents. The customer faces no consequences for \"forgetting\" to mark the charges as legitimate. The people who empathize enough with the business to do that for every single charge would just be faced with a major hassle, and the credit card companies would have a null signal where most \"illegitimate\" (by default) charges are actually legitimate. People can already contest illegitimate credit card charges, and that system works much better than a default-illegitimate system. reply unsignedint 1Personally, I will never call you again if I don&#x27;t get that dime back. However, it is also possible to design the system in a way that it actually comes with some disadvantages if calls are not marked in a reasonable timeframe. For instance, all the incoming call from that number is blocked if it is not marked within three days.I&#x27;m just providing a broad idea, and I&#x27;m pretty sure there are different types of details that can make it more workable. reply unsignedint 1Also, if anything like this were to be implemented, it would probably be through some sort of SaaS where payment is consolidated, perhaps as a phone bill, etc., instead of charging a credit card for each transaction. reply madsbuch 1While that would be a solution, it appears to be a solved problem. Neither my Portugese, nor my Danish number receives any robocalls. Frinds with US numbers get a lot of robocalls, though. reply submeta 1I got a lot of calls here in Germany from people with indian accent, pretending to work for Microsoft. At some point I wouldn’t pick up the phone if I did not know the caller. reply lightbendover 1Size of market. reply madsbuch 1The European union holds more than 100m more people than the US. reply itake 1Aren&#x27;t most retired people&#x27;s money locked up in gov pension and social programs as opposed to the USA where you&#x27;re expected to mostly self-fund retirement with 401k, IRA, and savings?So older US people have more control of their retirement funds than Europeans? reply madsbuch I don&#x27;t know how this related to robocall, but I like the question!I can only answer for Denmark, but there we have a thing called \"ratepension\" which I think is similar to a 401k. Retirement age in Denmark is 73 and the public pensions do only cover the bare minimums – you also need at private pension. reply itake In the US, the robocalls typically target seniors that aren&#x27;t able to identify the scam.In the US, we have 3 \"pillars\" of retirement income that we are told to keep roughly the same size: Gov plans (Social Security), personal savings, employer sponsor plans (401k).I had always assumed in Europe, most people expected the gov to fund most of their retirement (70%?). Whereas the expectation in the US is social security only covers ~33% (although for many people its 100%). reply madsbuch At least for Denmark, the expectation are more or less the same as for the US. reply lightbendover I don’t see how that’s the only dimension to look at when identifying addressable markets. Actually I don’t even see how it’s any dimension at all since you just can’t target “Europe” as a whole with a single solution that doesn’t have dozens of bespoke per-country exceptions. France is just about as different from Germany as any North American country. reply madsbuch EU has harmonised the mobile network market meaning that you can basically call cross borders as if it was a single market.Anyhow, I don&#x27;t know of any single country in the EU that has issues with robocalls. reply supertrope 1Who speak different languages. It also costs much more per minute to call EU cellphones. reply arp242 1I never got any in the UK either. Are you saying that 67 million people is too small of a market? Even the 10 and 6 million of Portugal and Denmark seems plenty large enough to make these type of things viable. reply lightbendover 1> Are you saying that 67 million people is too small of a market?Yes. If I&#x27;m a scammer, I&#x27;m going to target the most profitable single market that I understand. Building an international capability on top of that is a fairly large leap. reply madsbuch 1I can ensure you that both Portugal and Denmark has plenty og spam and scams. Also in local languages. Just not robocalls. reply arp242 1You can apply that reasoning to every product or service. Do you actually have any knowledge on this? reply lightbendover Having worked on GTM strategies for nearly a dozen new technology products at an international company and seen countless more, I have more than reason to believe that targeting the entire world at once is almost never done. You do your market research and make the best decision you can, scamming is no different. Scamming’s addressable market is dictated by many factors other than population: mean income by cohort, regularity climate, normal liquidity situations, bank policies, etc.. reply arp242 Of course American scammers wouldn&#x27;t be regularly targetting Europe; European scammers would be targetting Europe. reply lozenge 1They&#x27;re not robocalls, but since my mobile number was ported to O2 I have received multiple calls a week of scammers wanting to access my account to order phones. reply rootusrootus 1Random chance. Some people in the US get no calls, either. Some people in Europe get a barrage of calls every day. reply madsbuch 1I have never heard about anybody in Europe getting robocalls. It was a completely foreign concept for me before I hear about Americans getting them. reply rootusrootus 1Well, given that there are people in this very discussion from Europe discussing the robocalls they get, I&#x27;d guess you are seeing only what you want to see. Can&#x27;t help you with that. reply madsbuch 1Interesting! Can you lead me to those comments? reply Mountain_Skies Sibling comment of the root reply this is on. Everyone else can see it and it was posted before you made this comment so no idea why you can&#x27;t see it but everyone else can. reply madsbuch > I got a lot of calls here in Germany from people with indian accent, pretending to work for Microsoft. At some point I wouldn’t pick up the phone if I did not know the caller.The person is clearly not talking about robocalls, but a spam&#x2F;scam caller. replyc0nsumer 1Like STIR&#x2F;SHAKEN to provide affirmation that the calling number is legit?https:&#x2F;&#x2F;ribboncommunications.com&#x2F;company&#x2F;media-center&#x2F;blog&#x2F;o... reply unsignedint 1STIR&#x2F;SHAKEN is a mechanism that validates the origination of calls but doesn&#x27;t verify the legitimacy of the call, which can only be determined by the recipient. While it is a good starting point to protect against spoofing, what we truly need is an end-to-end deterrent to prevent these annoying calls altogether. I believe that imposing a potential financial burden on the caller could be the only effective solution to counter these calls. reply j-bos 1This would be a cool idea for an email filter. reply Rebelgecko 1There was a proposal for this in the 90s called Hashcash. Senders would have to brute force some random data to append onto email headers until they found some such that the first n bits of the hashed header were 0s. Sending emails would be computationally expensive, but not to a point that it would impact non-bulk users.The proof-of-work email use case never took really took off, but if you&#x27;re acquainted with cryptocurrencies some parts of the implementation might sound familiar :) reply JumpCrisscross > each outgoing call would require the caller to pay a dime as a depositThis means the single mom whose account is overdrawn, with only a debit card, can&#x27;t call their bank to have the overdraft fee waived. For lack of ten cents. reply Dylan16807 Oh come on. It would be nonsense to go all the way to the bank account every phone call. It would not work that way.Also you could waive the first several calls per day per number. reply unsignedint Or it could be handled more like a postpaid phone bill. reply JumpCrisscross > it could be handled more like a postpaid phone billThere is still a strong predatory incentive for people with limited choices. Who wants to guess, for example, what cheque-cashing establishments will do? Or asshat landlords? reply unsignedint That&#x27;s why I suggested (also in another thread) that the amount charged should be modest. I&#x27;m merely suggesting the concept and not the specifics. Perhaps businesses should be subjected to different types of regulations on how they can charge their clients under such a system, just like businesses are excluded from the National Do-Not-Call Registry. replyal_be_back the telco industry failed terribly to innovate around the phone-line and the mobile-line.phone line: hoisted for internet services, then customers dumped it mobile line: being hoisted for internet services, customers will soon dump them toobiggest issue: privacy & security - it&#x27;s a spammers, scammers paradise.fines won&#x27;t fix the underlying issues (telco) reply TechBro8615 1I haven&#x27;t answered the phone in years. All calls from unknown numbers go straight to silent, and anyone in my contacts knows not to call me anyway. What kind of real person uses the phone nowadays? It&#x27;s literally scams, customer support, billing departments, credit collection agencies, and generally people you don&#x27;t talk to as long as you can avoid it. Normal people use FaceTime, WhatsApp, Messenger, Zoom, etc.There&#x27;s basically zero upside to phone calls, and frankly nor is there much for SMS either. I would suggest that phone companies completely deprecate their telecom networks and go all-in on internet, but then the spam would migrate to the apps (it&#x27;s already begun with whatsapp), so I don&#x27;t want to give them any ideas. reply jaclaz 5 >Normal people use FaceTime, WhatsApp, Messenger, Zoom, etc.I must be abnormal. reply Amasuriel This seems like either a regional and&#x2F;or phase of life difference. As a homeowner in Canada for example, I often have need to find contractors for home items for example, like I just replaced a few windows.Most of those businesses do not operate primarily (or at all) over email or sms so leaving phone messages and receiving calls from unknown numbers is normal. Investment firms also generally need occasional contact etc.So I guess all I’m saying (as someone who would rather use text whenever possible) is that there is still many legitimate use cases for receiving phone calls. reply ericksoa This. 99&#x2F;100 calls I get are someone trying to sell me something worthless. reply beebeepka 1This reads like sarcasm to me.I barely use my phone, yet calls is 99% of what I do. I get less than 5 unsolicited calls per year. Don&#x27;t use any of the things your imaginary \"normal people\" use. What a weird thought process. I guess the world does revolve around you reply TechBro8615 What do you mean calls is 99% of what you do? For work? Doesn&#x27;t that just prove my point? You&#x27;re not using the phone system for personal calls. You must work somewhere doing outbound calls for some reason or receiving them for another. And yes, I would include sales in this classification. reply vel0city I have a lot of somewhat tech illiterate family which I communicate with regulaly who pretty much only care to SMS and regular phone calls. Before Signal dropped SMS support I had managed to get a number of them on Signal, but dropping SMS really confused most of them so they dropped it.I also participate in a lot of local groups where the least common denominator is usually phone&#x2F;SMS for quick comms.I refuse to use Meta products outside a privacy container on my computer so no Facebook Messenger&#x2F;WhatsApp on my phone. reply ryandrake I&#x27;m with you. My Phone app is probably the least-used app on my phone, because pretty much all inbound calls are unwanted. I occasionally need to make an outbound call so my Phone app usage is not quite zero. reply beebeepka Holy mother of presumptions!How the hell am I proving your point when I say I use my personal (don&#x27;t have any other) phone for nothing but calls and the occasional SMS? reply babyshake 1I don&#x27;t even try to stop the scams anymore for the most part. I just assume that anything incoming is a scam until I am able to verify it. It is kind of crazy making, but maybe not as crazy making as trying to stop the flood. reply larperdoodle 1My phone hasn&#x27;t rung with a scam call since I enabled Google assistant call screening. Unknown callers have to explain why they&#x27;re calling reply rmason 1Someone has figured out how to break it. I have it enabled yet I still receive one call a week from a Chinese speaking robo caller. Everyone I know gets these calls, some daily on their cell phones. Must be a very profitable product they&#x27;re selling to afford making 600 calls to reach one person who understands Mandarin. reply VintageCool 1Those calls threaten their Mandarin-speaking target that US Immigration services are going to kick them out of the country. But the scammers (who might be dressed up as immigration lawyers) will take care of the problem in exchange for a bunch of money. reply esalman 1Isn&#x27;t this feature only available in Pixel phones? reply jimmySixDOF 1Curious if this has worked where a valid caller with a valid reason made it through the screen and how you could catch false positives. Sounds like a great idea if it works so that&#x27;s why I am asking. reply larperdoodle 1I think if they say anything, it rings and shows a transcript of what they said. At least, that&#x27;s what happened the few times I&#x27;ve received a legitimate call from an unknown number (think calls like a contractor or a doctor&#x27;s office). reply xur17 1At least so far there don&#x27;t seem to be any false positives, but it does seem like something that could easily be botted. reply Bloating 1Been using this for what seems like years. Initially Google Asst screening would throw some legit callers off base, but I haven&#x27;t had a false-positive or scam calls for years. Google Asst also manages the call when put on-hold. Would be more fun if it could emulate Its Lenny reply 2OEH8eoCRo0 1What&#x27;s in it for Google? reply esalman 1They can sell more Pixel phones. reply jjoonathan 1Yeah. I ragequit Android when they went back on photo storage promises but wowza I did not think that Apple would be so bad at handling spam. Unless they get their act together I am ragequitting the Apple ecosystem back to Android for my next phone. reply esalman For me spam is at the bottom of the list of things Apple can&#x27;t handle. reply ajhurliman 1Isn’t that more of a carrier thing? reply jjoonathan The phone changed but the carrier and phone number didn&#x27;t. Pixel&#x27;s robocall screening was evidently like that meme with the soldier blocking the arrows. reply fluidcruft 1It decreases user availability to non-Google advertising vectors. I would also assume that if Google can figure out who&#x27;s trying to sell what to you, they can use that to better funnel ads your way on their own platform. reply kramerger 1It&#x27;s part of Googles strategy for adding human-level AI to Google Assistant and Android.See the restaurant reservation demo from Google IO 2018. reply sudobash1 1People buying their phone? reply 2OEH8eoCRo0 1Oh. Is that also why they continue to remove features that I use? reply thatfunkymunki 1The answer to this question is probably also yes, regardless of how orthogonal it is to the previous question. reply plagiarist 1Knowing every inbound call made to that number and collecting ML training data. reply stronglikedan 1Tmobile and others have some ot-in feature that prevent most of the scam calls from getting to your phone. I went from a couple a day to a couple a week after turning it on. reply supertrope 1Previously the FCC has collected $0. The most they ever collected was a few thousand. They have to ask another agency to enforce these and by then Shady Telecom LLC has been shutdown by the owners without any forwarding address. reply devindotcom 1they&#x27;ve collected considerably more than that, but you&#x27;re right that it&#x27;s not likely to be anywhere near $300M. but it&#x27;s up to justice to collect, something the fcc wants to change (as Rosenworcel says ITA). reply psychlops Nothing like giving an independent agency the ability to investigate, fine and enforce payment collection when they want. What could go wrong? reply supertrope There’s still a court case. This is just so they can file it themselves. reply Google234 11 second of jail for every second of American time wasted reply coding123 1That doesn&#x27;t even account for the scams, life savings lost, ruined relationships. reply myself248 Surgeries failed because the doctor didn&#x27;t get enough sleep because they forgot to put their phone on silent... (I refuse to blame the victim here.)While it would be hard to definitively trace any specific death, statistically these spammers are also mass murderers. reply sgustard 1\"Two of the central players ... were under lifetime bans against making telemarketing calls\"Wait, why isn&#x27;t every human under such a ban? reply jhallenworld To allow political ads I would guess. reply pnpnp 1If I had to guess, capitalism? reply csa 1> Wait, why isn&#x27;t every human under such a ban?Because it would kill cold sales calls, which I think have a ton more value than you probably think they do (when ethically done).For reference for a business I previously owned:- Per 100 cold calls based on leads we qualified…- We actually spoke to about 30 people…- Of which about 10 were actually interested…- Of which about 3 became customers.- Customers paid on a monthly basis for an average of well over two years for our service.For loosely qualified cold calls, this was a pretty big success, imho.Yes, we mildly bothered 70 people (unanswered call), and we bothered 20 more with an unwanted sales pitch (usually less than one minute), but we had good conversations with 10 of them. Whether they became a customer or not, I think that we at least helped them understand clearly what their options were in our product market. reply mrguyorama 1You have provided a great example of how worthless cold calling is to society.Ten percent of your interactions were even close to being considered not a nuisance (more like 3 percent were actually not a nuisance, someone listing to an advertisement willingly is still being interrupted and annoyed)Fuck that man, come on. If you are bothering 100 people to POSSIBLY help a couple people possibly find a service that might help them, you are spam. reply Alupis 1Cold Calls aren&#x27;t the problem though. Getting one random call a month or whatever never was an issue in the past.The issue is getting 10 completely silent calls per day, sometimes with an additional \"your car warranty is expired\" call. That&#x27;s the issue everyone has a problem with - it&#x27;s made answering your phone nearly useless. reply csa 1> You have provided a great example of how worthless cold calling is to society.I think you are missing the big picture.Assuming that we waste 1 minute of time for 90 people, and everything else is productive, it’s:- 90 minutes of aggregate inefficiency…- to benefit 7 folks who have a much better understanding of the market for their current and future needs…- and 3 people who are scaling their business for years via delegating something they are not good at to folks who are.I don’t know about you, but I’ve had many many dud 90-minute encounters (much less one minute encounters) that were all worth it for the one encounter that moved the needle. This could be sales leads, training, dates, finding new restaurants… there are many domains for which this is true.Frankly, I think that this is a fairly efficient ratio compared to most value-seeking activities in the world.Edit: Note that the close rate was close to 40% live (versus 10% calls) with a non-significant n, so I think the medium itself was one source of inefficiency. The product was clearly needed by our leads, but trust-building was tougher over the phone. reply ryandrake From your point of view, it&#x27;s great--there&#x27;s no downside. A little \"Aggregate inefficiency\" as you put it.From the point of view of the victims (or leads, as you might describe them), 70% deftly avoided you and 20% were annoyed that you intruded on their lives, albeit briefly. Or put another way, for every new customer you got, you actively annoyed ~7 of them, and confirmed the problem of unsolicited phone calls for a further ~23 of them. reply lp0_on_fire 1> Assuming that we waste 1 minute of time for 90 people, and everything else is productiveMost people aren&#x27;t interested in being tricked into opening their wallet, sorry. If I want your services, I&#x27;ll seek them out. You&#x27;re not entitled to even a second of my time. reply csa > Most people aren&#x27;t interested in being tricked into opening their wallet, sorry.I’m very curious about why “sales” automatically equates to “trickery” for you.Ethical, high quality sales is the efficient matching of goods and&#x2F;or services with folks who want them.These types of sales exist and are not as uncommon as some HNers seem to think that they are.> If I want your services, I&#x27;ll seek them out.You seem to assume that most people are good at finding services they need. In general, I have found this not to be the case both for me and many of my customers (at least not initially).For me personally, I spend a shit ton of time on discovery, and I still find that random ads and sales pitches introduce me to things that I was not aware of.FWIW, my service was a tech service, and my market was decidedly not tech savvy. One of the challenges of the sales process was getting them to understand and believe that we weren’t trying to bamboozle them (as many competitors were). We couldn’t sell them with technical explanations of why we were good or why some other option was not as good — we had to use non-technical explanations and an onboarding process that minimized the friction.Ultimately, the proof of the pudding was in the eating, so we retained customers for much longer than industry average, with most of our churn being due to businesses being sold, closing, or moving beyond what we offered (at which point we referred them to an ethical provider that was appropriate for their newfound needs).> You&#x27;re not entitled to even a second of my time.Honestly, I think you’re living a lesser life (especially professionally) if you are not willing to defer seconds, minutes, or even hours to speculative engagements.It doesn’t take long to qualify a sales call for fit — the good sales people will know how to what itches they are good at scratching and whether you might have those itches. reply constantly Fingers crossed the FTC finds and fines you. If it’s big enough maybe you’ll have some empathy for your victims, or at least the calculus will change in society’s favor. reply csa > Fingers crossed the FTC finds and fines you.What exactly would they fine me for?I’m not robo-calling, I’m cold calling. Furthermore, all of my leads are internally generated and qualified B2B leads.There is nothing illegal about this.https:&#x2F;&#x2F;blog.close.com&#x2F;is-cold-calling-legal&#x2F;You seem to have a big bone to pick for a domain you don’t understand very well. reply myself248 If the law is so far divorced from what everyday people see as a scourge, then perhaps it is the law that has a poor understanding of reality. Just because bothering people is legal doesn&#x27;t mean it&#x27;s ethical. reply csa > what everyday people see as a scourgeI think you might be projecting a wee bit too much.I guess you missed the following quote in the article I linked to (emphasis mine):“Only 2% of cold calls convert. But 69% of buyers are willing to take a cold call, and 57% of C-level buyers want sales reps to contact them first.”Most savvy business people are willing to take speculative engagements (within reason) — it’s just +ev to do so.Let me be charitable and say that I think that a lot of tech sales is low quality (e.g., trying to force fit when there isn’t much&#x2F;any) or downright scams (e.g., the alleged yelp “protection money” gambit), so I can understand that a tech-oriented community may be a bit jaded. That said, low quality sales interactions are not the norm in large swathes of the economy — it’s just as much or more of a waste of time for the sales person as it is for the potential buyer. reply Dylan16807 1. I don&#x27;t trust the biased source of that number.2. I want to know exactly how they asked the question, and how \"contact them first\" was interpreted by the people being surveyed.3. Were your cold calls going directly to C-level buyers?4. If 69% of buyers are willing to take a cold call, why do you think only 30% of people answered the phone, of which only a third were willing to listen to a pitch? reply csa 1. Fair enough. Do you think it’s far from directionally correct?2. Very good question. I go back to, do you think it’s far from directionally correct? I think it’s close.3. Small business owners ($1-10 million annual revenue).4. Great question. First, many of these folks do like I do and send non-contacts to voicemail (they’re busy). Second, I clearly stated who I was, what my company did, and the specific problem of theirs that I wanted to solve. I’m guessing that a healthy chunk of that delta was just folks for whom my offering was not a hair on fire problem, so they didn’t call back (few people answered directly, most were call backs). There was probably a small percentage of wrong number, closed&#x2F;closing business, etc.Note that I was selling a technical service to a mostly non-technical crowd, so they really had no desire to do research. Most of the folks really seemed to appreciate talking to someone who could answer their questions in a way they could understand (e.g., saying something “loads slowly” rather than “is bloatware”). My goal was always to do a few things: 1) help them understand what they needed and tell them the verbiage they needed to use to ask for it, 2) to determine if we offered what they needed, and 3) if we were not a good fit, let them know what I thought were good fits. I also tried to give some free advice on easy wins like how to get good GBP reviews (with a cheat sheet if they wanted it).I got a not small number of referrals from folks who didn’t sign up with us but referred their acquaintances to us due to the positive, but not closed, sales experience they had with me&#x2F;us. reply cwkoss 1Annoying 90 people to make a marginal profit from 3 seems bad for society, and I would fully support a ban. reply csa > Annoying 90 people to make a marginal profit from 3 seems bad for society, and I would fully support a ban.I mean, that’s easy to say in a glib way on a site like HN, but are factoring in the full consequences of the knock-on effects of a high-friction economy?Oh, ads are annoying? Ok, everything that is ad supported ceases to exist. Little or no TV, no social media (ok, this sort of seems like a win), no newspapers, no magazines, no radio, much smaller movie scene (since they can’t advertise), etc.I’m all for having healthy boundaries and being able to set healthy boundaries, but your solution seems like overkill.Fwiw, I set my phone on do not disturb for numbers not in my address book. That’s an easy way to not be bothered if that’s your jam (I just check messages if&#x2F;when I want to). reply joseda-hg It makes sense that you feel a more positive about it than the average person, but you should be aware that the other 90% that are \"annoyed\" also have an opinion with which you will never interactI wouldn&#x27;t place cold calling on the same level as regular ads, ostensibly I care for whatever I get from the place showing the ads, which might or might not be the case on cold calling (I get that you said that you only called relevant people, but based on the general sentiment, I think we can reasonably say that you&#x27;re an outlier, and even then ~10% cared enough to answer)As someone that receives plenty of calls from numbers not on their contact list, it feels wrong that I have to actively distrust, instead of dealing with the problem from the source , some countries (Like Germany) do ban cold calling, which seems the sane option to me, but I personally don&#x27;t think America cares enough about privacy to even consider it reply Dylan16807 > Little or no TV, no social media (ok, this sort of seems like a win), no newspapers, no magazines, no radio, much smaller movie scene (since they can’t advertise), etc.I&#x27;m sure cable fees (much of which go to broadcast stations) could pay for plenty of TV.And social media could survive fine if it had to charge enough to cover servers.Newspapers would be in more trouble but they&#x27;re already in deep trouble.Radio I&#x27;m not sure. reply cwkoss I would also happily tax advertisements extremely aggressively to the point that most advertisements cease to exist. replyi5heu 1Fun fact:Cold calling private individuals is illegal in Germany. reply Alupis 1There&#x27;s very little point in having un-enforceable laws. reply myself248 The content I would like to put in this comment is vastly, egregiously, horrifyingly inappropriate according to HN&#x27;s policy.So instead I will just say that I dislike you very much and I hope you have an awful, poopy day.You, and those like you, are the reason we can&#x27;t have nice things. reply csa > So instead I will just say that I dislike you very much and I hope you have an awful, poopy day.> You, and those like you, are the reason we can&#x27;t have nice things.Cheers.I love you, too.I will be sure to remember your kind words when my customers thank me for doing such a good job (which is typical and often). reply hanniabu 1America, where you can inconvenience an entire nation as long as there&#x27;s money to be made reply bediger4000 1You hit the nail on the head. The US could have stopped robocalls years ago, by enforcing accurate caller ID and maybe policing who got to hook up to the SS7 network, and aggressively enforcing whatever laws could be used against the scammers.But instead, the phone companies probably decided they could make extra cash off the robocallers, not realizing they were killing the golden goose. I&#x27;m also 100% certain that both phone companies and members of Congress received bribes i mean sizeable campaign contributions and cushy think tank jobs over this.So maybe 50-100 people made money, and absolutely ruined a working communication system. I hope it was worth inconveniencing the entire US population to make a little money, you shameless wieners. reply azinman2 1Better than inconvenience due to inefficiencies and stupidity with no money to be made reply nonameiguess 1The problem with this point of view that all businesses seem to have is you&#x27;re not the only ones doing this. Those same 90 people you&#x27;re providing negative value and nuisance to are getting it from hundreds of businesses a day, gradually driving the signal to noise ratio of all communications channels down to zero. It&#x27;s entirely possible one of the hundreds of real estate investment companies calling me every day trying to buy one of my houses was going to make a terrific offer that would have provided me with value. But I&#x27;ll never know, because if I answered the phone and actually talked to them, I&#x27;d have to answer all of these calls, and doing that would leave me with no time to do anything at all except answer phone calls and listen to sales pitches all day every day. reply csa > Those same 90 people you&#x27;re providing negative value and nuisance to are getting it from hundreds of businesses a day, gradually driving the signal to noise ratio of all communications channels down to zeroIt’s more likely that they find a good match with about 2% of them, and those 2% help grow their business.I really get the sense that the people complaining the most about cold calling (different than robo-calling) are folks who:- have little or no business experience- have never had a good sales experience- work in tech where the default sales experience sucksSuccessful business people know what their hair-on-fire problems are, and they are willing to take on speculative engagements that may help them solve those problems. This is not rocket science. reply midjji FCC the regulator agency charged with regulating telecom companies once again fails to regulate telecom companies. Despite a trivial and permanent remedy beeing available, e.g. fine the telecom companies in significant excess of what they made from providing the robocalling companies with the services required to make the robocalls, they instead place a ineffectual and unenforceable fine on a couple of soon to be chapter 11 LLC. Yay for telecom lobbying.... reply wombat-man 1Would love to see some jail time too. What a nuisance. reply tasty_freeze I&#x27;ve noticed an influx of robocalls that get through my pixel 4 spam call filter. Recently when I get these, unless I&#x27;m in a hurry, I play nice with the robot and they connect me to a real person. Either I&#x27;ll waste their time by acting sincere but stupid, or I&#x27;ll tell them a sob story, eg, sorry, I don&#x27;t need your home insurance because I got fired from my job, so my wife divorced me, and now I&#x27;m homeless and living out of my car.What I&#x27;m really hoping for is a real-time AI app that can (a) understand what they are saying and generate plausible time wasting responses. reply datashaman > What I&#x27;m really hoping for is a real-time AI app that can (a) understand what they are saying and generate plausible time wasting responses....until one day the AI is convinced it&#x27;s a good deal and buys you a comprehensive insurance package. :) reply TylerE Fine for stuff like this should be: You get audited, and pay 150% of what you earned from the illegal activity. Not \"cost of doing business\".Can&#x27;t pay it? C-Suite goes to prison. reply rootusrootus 1It&#x27;s a start. Next time fine the carrier. reply m463 From what I understand, these huge fines are never collected. reply plagiarist 1It&#x27;s insane that this is not a solved problem. Here&#x27;s a thought: if I could collect $100 from my carrier for each spam call they put through, this problem would be solved overnight. reply ipython 1You can collect $$ for spam calls already in the United States, with laws on the books today- see the [TCPA](https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Telephone_Consumer_Protection_...). Problem is that you have to track down the individual&#x2F;company that&#x27;s doing it. That&#x27;s become dramatically more difficult over the past 15 years. reply viraptor 1Time for my usual comment. No, it&#x27;s not difficult. Every Telco knows where the call comes from and where it&#x27;s routed to. Sure, the end-user doesn&#x27;t necessarily know the origin, but there&#x27;s regulation that would trivially solve this. \"For each spam report, you&#x27;re responsible unless you point out where you got the call from\" if enforced would sort out the problem almost immediately.Telco can&#x27;t say how the call happened? Fine them. Telco can&#x27;t sort out their spammy customer? Fine them. \"Oh, but international calls!\" - they can drop the spammy international peer - the US is large enough that nobody serious would risk getting disconnected. reply jcrawfordor First, telcos are not permitted to refuse calls from other telcos unless they receive permission from the FCC. This is what it means to be a \"common carrier,\" an old regulatory regime intended to prevent larger telcos using carriage as a negotiating tool over small telcos. The internet has this problem to a degree, which has lead to years of conflict over \"net neutrality.\" Part of the new regulatory regime intended to address spam calls is that the FCC now regularly grants such permission when they determine that a particular telco is failing to uphold its obligations.Second, telcos do not necessarily know the origin of calls. Virtually all spam&#x2F;scam calls originate from the internet via a VoIP gateway. There are numerous VoIP gateways, they often obtain their traffic from yet other VoIP gateways, and they often introduce traffic into the US PSTN through a foreign telco. At each of these steps, the origin of the call is usually lost. Telephone circuits are always established in the \"forward\" direction and there is no need for reverse routing information, so historically it was never provided. At the extreme, some calls are introduced into the TDM telephone system by boxes with multiple SIM cards that relay calls from IP to a cellular carrier (this is not very common in the US because cellular carriers aggressively monitor for it, but it&#x27;s very common in for example Africa---where this method is often used to carry legitimate traffic at a cost savings!). All of this means that tracing the origin of calls can be surprisingly complex, which is why USTelecom (an industry association) funds a consortium to perform tracing for the FCC.The underlying reason is simple: nothing in the telephone system requires calls to identify their origin. There are two (and in many cases more) different concepts of \"originating number\" on a telephone call, CID and ANI, and neither are required or even expected to correspond to the origin point of the call. The purpose of STIR&#x2F;SHAKEN is to introduce such a requirement for the first time, standardizing a header (in the case of VoIP) or SS7 message (in the case of TDM) that declares the carrier with which a call originated. This will vastly simplify tracing and blocking of calls from problematic carriers, which is the motivation behind the mandatory rollout that is currently in progress. One of the broader goals of the STIR&#x2F;SHAKEN program is to introduce a degree of liability at all points in the process, as every carrier is responsible for ensuring appropriate attestations on calls they hand off to customers. This seems to be having a positive impact, although as with most spam mitigation efforts, it does have the downside of making it more expensive and complex to get access to the telephone network, mostly to the financial advantage of Twilio. reply viraptor > telcos are not permitted to refuse calls from other telcos unless they receive permission from the FCCYes, that&#x27;s exactly the part that could&#x27;ve been changed long time ago to solve this problem. That&#x27;s what I&#x27;m describing.> telcos do not necessarily know the origin of calls. Virtually all spam&#x2F;scam calls originate from the internet via a VoIP gatewayThey know the next hop though. Knowing the ultimate origin doesn&#x27;t matter. You can iterate until a) you find the origin, or b) you find someone who doesn&#x27;t keep records - in either case, they&#x27;re the problem to deal with. It doesn&#x27;t matter that someone uses a VoIP gateway - now it should be the gateway operator&#x27;s problem to point out the origin or pay up.I worked at a VoIP provider. We had full records already available for billing purposes. This is why I&#x27;m so angry about this every time it comes up, all this technical talk is true and completely irrelevant. Let FCC fine the first entity in chain which cannot say \"we got it from X\", or \"we got it internationally, here&#x27;s the fine payment from our side, they&#x27;ve been warned&#x2F;disconnected\".The shaken&#x2F;stir provided a small tool which avoids addressing the actual issue. It&#x27;s a fun tool which would make the above slightly easier - but doesn&#x27;t actually enable it. reply ipython 1Well, it’s not quite that simple- especially for an end user. I don’t have the ability to trace it- and even if I did most of the scam calls I get these days are from overseas voip providers. So I have to invest a lot of time to get to a U.S. based business that benefits from the calls. Even then, the tcpa may not allow you to collect (some state laws do)It is difficult enough that there is a full on coalition dedicated to this (the trace back working group that’s mentioned by the fcc in this order) reply viraptor You don&#x27;t have to trace it yourself. The simple solution is: a online portal, you report a spam call to your number with time and origin as you see it, your telco is required to act on that, FCC or someone else gets to audit and assign fines. From there it would be each telco&#x27;s responsibility to do the same from their end.Trivial for the user, and likely apps would be created to automate it. As I mentioned, international VoIP providers are not an issue if you make it a local telco problem: whether they forward the cost of the fines, drop the peer, or pay the fine themselves. Any serious telco abroad will solve the outbound spam to the US rather than get dropped. reply newaccount74 1Change the law so that telcos are on the hook for fines if they can&#x27;t identify who the call came from.Just like you have to pay a speeding ticket if you lend your car to someone and don&#x27;t tell the police who was driving. reply say_it_as_it_is 1Roy M. Cox and Aaron Michael Jones. They don&#x27;t even have wikipedia entries. reply coding123 1This is the way to do this. If more of these scam calls & texts are found to be coming through certain pipes, fine those parties, jail those parties so that there is an incentive to stop it. I don&#x27;t know why its taking them this long to figure this out. reply jiveturkey 1couldn’t disagree more. this is pointless and useless. jail time is required, not an uncollectable fine from the perps. a more palatable solution would be fining telcos (because it’s collectible and damaging) for allowing it. we’ll then see good blocking measures in place. reply lightbendover 1Not even sure why telecoms are allowed to allow spoofing. Should be absolutely illegal both in their own network and they should be disallowed from peering with networks where it is allowed.Actually, I do know: it&#x27;s profitable to them and they lobby a lot. reply shadowgovt Telcos actually don&#x27;t have that much leeway in whether they can allow this stuff on the network. That&#x27;s part and parcel of the whole \"common carrier\" thing that some people wish would be required of internet service providers; as a common carrier, they can&#x27;t block legitimate, legal use of the service until some authority tells them it&#x27;s not legitimate or legal, and that&#x27;s a (due) process.So not to go to bat for Ma Bell and her li&#x27;l babies here, but fining the telcos for following the law would be counter-productive and unfair. reply jiveturkey i understand that but that rule is actually imposed by the same agency (FCC) imposing the fine. AIUI. so that is changeable. correct though, under the current rules this is not possible reply crawsome 1At the scale they are wasting people&#x27;s time, they should be jailed for life. Plenty of lifetime&#x27;s worth of wasted time.We should also retire auth-less POTS. reply shadowgovt prev [–] A hack someone introduced me to that I cannot recommend enough if you still, for some God-unfortunate reason, have a landline:Record the audio for the \"We&#x27;re sorry, this number has been disconnected\" message from Verizon or whoever. Keep it on your phone. If you get a lot of telemarketers, queue it up before you answer an unknown number. Hit &#x27;em with it if it sounds like a robocall.Robocalls still cost time even if they&#x27;re functionally free money-wise, so a lot of systems will key on that message and will yank your number off their call list. reply green-salt parent [–] A friend of mine recorded that to the beginning of their voicemail greeting, and apparently its worked. reply",
    "originSummary": [
      "The FCC has imposed a record-breaking fine of $300 million on a robocaller for engaging in a scam scheme since 2018.",
      "The robocaller used different names and pretended to be a company selling auto warranties to collect personal information.",
      "While the FCC's efforts, including partnerships with state law enforcement, have significantly reduced auto warranty calls by 99%, it is unclear if and when the fine will be paid due to the FCC's limited authority in collecting fines effectively."
    ],
    "commentSummary": [
      "The article focuses on the issue of robocalls and unwanted phone calls, which are seen as a significant annoyance and inconvenience.",
      "Various potential solutions are discussed, including stricter regulations, fines for telcos, and identifying the origin of calls.",
      "There is frustration with Apple's handling of spam, leading some to consider switching to Android, which is believed to have more effective robocall screening."
    ],
    "points": 291,
    "commentCount": 181,
    "retryCount": 0,
    "time": 1691087711
  },
  {
    "id": 36984171,
    "title": "Network protocols for anyone who knows a programming language",
    "originLink": "https://www.destroyallsoftware.com/compendium/network-protocols?share_key=97d3ba4c24d21147",
    "originBody": "DESTROY ALL SOFTWARE 20 MINUTE READ The network stack does several seemingly-impossible things. It does reliable transmission over our unreliable networks, usually without any detectable hiccups. It adapts smoothly to network congestion. It provides addressing to billions of active nodes. It routes packets around damaged network infrastructure, reassembling them in the correct order on the other side even if they arrived out of order. It accommodates esoteric analog hardware needs, like balancing the charge on the two ends of an Ethernet cable. This all works so well that users never hear of it, and even most programmers don't know how it works. Network routing In the old days of analog telephones, making a phone call meant a continuous electrical connection from your phone to your friend's. It was as if a wire were run directly from you to them. There was no such wire, of course – the connection was made through complex switching systems – but it was electrically equivalent to a single wire. There are too many Internet nodes for it to work in this way. We can't provide a direct, uninterruptible path from each machine to each other machine it wants to talk to. Instead, data is bucket-brigaded – handed off from one router to the next, in a chain, each one bringing it closer to its destination. Each router between my laptop and google.com is connected to a number of other routers, maintaining a crude routing table showing which routers are closer to which parts of the Internet. When a packet arrives destined for google.com, a quick lookup in the routing table tells the router where the packet should go next to bring it closer to Google. The packets are small, so each router in the chain ties up the next router for only a tiny fraction of a second. Routing breaks down into two sub-problems. First, addressing: what is the data's destination? This is handled by IP, the Internet Protocol, whence IP addresses. IPv4, still the most common version of IP, provides only 32 bits of address space. It's now fully allocated, so adding a node to the public Internet requires reusing an existing IP address. IPv6 allows 2128 addresses (about 1038), but only has about 20% adoption as of 2017. Now that we have addresses, we need to know how to route a packet through the Internet toward its destination. Routing happens fast, so there's no time to query remote databases for routing information. As an example, Cisco ASR 9922 routers have a maximum capacity of 160 terabits per second. Assuming full 1,500 byte packets (12,000 bits), that's 13,333,333,333 packets per second in a single 19 inch rack! To route quickly, routers maintain routing tables indicating the paths to various groups of IP addresses. When a new packet arrives, the router looks it up in the table, telling it which peer is closest to the destination. It sends the packet to that peer and moves on to the next. BGP's job is to communicate this routing table information between different routers, ensuring up-to-date route tables. IP and BGP together don't make a useful Internet, unfortunately, because they provide no way to transfer data reliably. If a router becomes overloaded and drops a packet, we need a way to detect the loss and request retransmission. Packet switching If the Internet works by routers handing data to each other down the line, what happens when the data is large? What if we request the 88.5 MB video of The Birth & Death of JavaScript? We could try to design a network where the 88.5 MB document is sent from the web server to the first router, then to the second, and so on. Unfortunately, that network wouldn't work at Internet scale, or even at intranet scale. First, computers are finite machines with finite amounts of storage. If a given router has only 88.4 MB of buffer memory available, it simply can't store the 88.5 MB video file. The data will be dropped on the floor and, worse, I'll get no indication. If a router is so busy that it's dropping data, it can't take the time to tell me about dropped data. Second, computers are unreliable. Sometimes, routing nodes fail. Sometimes, ships' anchors accidentally damage underwater fiber-optic cables, taking out large portions of the Internet. For these reasons and more, we don't send 88.5 MB messages across the Internet. Instead, we break them down into packets, usually in the neighborhood of 1,400 bytes each. Our video file will be broken into 63,214 or so separate packets for transmission. Out-of-order packets Measuring an actual transfer of The Birth & Death of JavaScript with the packet capture tool Wireshark, I see a total of 61,807 packets received, each 1,432 bytes. Multiplying those two, we get 88.5 megabytes, which is the size of the video. (This doesn't include the overhead added by various protocols; if it did, we'd see a slightly higher number.) The transfer was done over HTTP, a protocol layered over TCP, the Transmission Control Protocol. It only took 14 seconds, so the packets arrived at an average rate of about 4,400 per second, or about 250 microseconds per packet. In 14 seconds, my machine received all 61,807 of those packets, possibly out-of-order, reassembling them into the full file as they came in. TCP packet reassembly is done using the simplest imaginable mechanism: a counter. Each packet is assigned a sequence number when it's sent. On the receiving side, the packets are put in order by sequence number. Once they're all in order, with no gaps, we know the whole file is present. (Actual TCP sequence numbers tend not to be integers simply increasing by 1 each time, but that detail isn't important here.) How do we know when the file is finished, though? TCP doesn't say anything about that; it's the job of higher-level protocols. For example, HTTP responses contain a \"Content-Length\" header specifying the response length in bytes. The client reads the Content-Length, then keeps reading TCP packets, assembling them back into their original order, until it has all of the bytes specified by Content-Length. This is one reason that HTTP headers (and most other protocols' headers) come before the response payload: otherwise, we wouldn't know the payload's size. When we say \"the client\" here, we're really talking about the entire receiving computer. TCP reassembly happens inside the kernel, so applications like web browsers and curl and wget don't have to manually reassemble TCP packets. But the kernel doesn't handle HTTP, so applications do have to understand the Content-Length header and know how many bytes to read. With sequence numbers and packet reordering, we can transmit large sequences of bytes even if the packets arrive out-of-order. But what if a packet is lost in transit, leaving a hole in the HTTP response? Transmission windows and slow start I did a normal download of The Birth & Death of JavaScript with Wireshark turned on. Scrolling through the capture, I see packet after packet being received successfully. For example, a packet with sequence number 563,321 arrived. Like all TCP packets, it had a \"next sequence number\", which is the number used for the following packet. This packet's \"next sequence number\" was 564,753. The next packet did, in fact, have sequence number 564,753, so everything was good. This happens thousands of times per second once the connection gets up to speed. Occasionally, my computer sends a message to the server saying, for example, \"I've received all packets up to and including packet number 564,753.\" That's an ACK, for acknowledgement: my computer acknowledges receipt of the server's packets. On a new connection, the Linux kernel sends an ACK after every ten packets. This is controlled by the TCP_INIT_CWND constant, which we can see defined in the Linux kernel's source code. (The CWND in TCP_INIT_CWND stands for congestion window: the amount of data allowed in flight at once. If the network becomes congested – overloaded – then the window size will be reduced, slowing packet transmission.) Ten packets is about 14 KB, so we're limited to 14 KB of data in flight at a time. This is part of TCP slow start: connections begin with small congestion windows. If no packets are lost, the receiver will continually increase the congestion window, allowing more packets in flight at once. Eventually, a packet will be lost, so the receive window will be decreased, slowing transmission. By automatically adjusting the congestion window, as well as some other parameters, the sender and receiver keep data moving as quickly as the network will allow, but no quicker. This happens on both sides of the connection: each side ACKs the other side's messages, and each side maintains its own congestion window. Asymmetric windows allow the protocol to take full advantage of network connections with asymmetric upstream and downstream bandwidth, like most residential and mobile Internet connections. Reliable transmission Computers are unreliable; networks made of computers are extra unreliable. On a large-scale network like the Internet, failure is a normal part of operation and must be accommodated. In a packet network, this means retransmission: if the client receives packets number 1 and 3, but doesn't receive 2, then it needs to ask the server to re-send the missing packet. When receiving thousands of packets per second, as in our 88.5 MB video download, mistakes are almost guaranteed. To demonstrate that, let's return to my Wireshark capture of the download. For thousands of packets, everything goes normally. Each packet specifies a \"next sequence number\", followed by another packet with that number. Suddenly, something goes wrong. The 6,269th packet has a \"next sequence number\" of 7,208,745, but that packet never comes. Instead, a packet with sequence number 7,211,609 arrives. This is an out-of-order packet: something is missing. We can't tell exactly what went wrong here. Maybe one of the intermediate routers on the Internet was overloaded. Maybe my local router was overloaded. Maybe someone turned a microwave on, introducing electromagnetic interference and slowing my wireless connection. In any case, the packet was lost and the only indication is the unexpected packet. TCP has no special \"I lost a packet!\" message. Instead, ACKs are cleverly reused to indicate loss. Any out-of-order packet causes the receiver to re-ACK the last \"good\" packet – the last one in the correct order. In effect, the receiver is saying \"I received packet 5, which I'm ACKing. I also received something after that, but I know it wasn't packet 6 because it didn't match the next sequence number in packet 5.\" If two packets simply got switched in transit, this will result in a single extra ACK and everything will continue normally after the out-of-order packet is received. But if the packet was truly lost, unexpected packets will continue to arrive and the receiver will continue to send duplicate ACKs of the last good packet. This can result in hundreds of duplicate ACKs. When the sender sees three duplicate ACKs in a row, it assumes that the following packet was lost and retransmits it. This is called TCP fast retransmit because it's faster than the older, timeout-based approach. It's interesting to note that the protocol itself doesn't have any explicit way to say \"please retransmit this immediately!\" Instead, multiple ACKs arising naturally from the protocol serve as the trigger. (An interesting thought experiment: what happens if some of the duplicate ACKs are lost, never reaching the sender?) Retransmission is common even in networks working normally. In a capture of our 88.5 MB video download, I saw this: The congestion window quickly increases to about a megabyte due to continuing successful transmission. A few thousand packets show up in order; everything is normal. One packet comes out of order. Data continues pouring in at megabytes per second, but the packet is still missing. My machine sends dozens of duplicate ACKs of the last known-good packet, but the kernel also stores the pending out-of-order packets for later reassembly. The server receives the duplicate ACKs and resends the missing packet. My client ACKs both the previously-missing packet and the later ones that were already received due to out-of-order transmission. This is done by simply ACKing the most recent packet, which implicitly ACKs all earlier ones as well. The transfer continues, but with a reduced congestion window due to the lost packet. This is normal; it's happened in every capture of the full download that I've done. TCP is so successful at its job that we don't even think of networks as being unreliable in our daily use, even though they fail routinely under normal conditions. Physical networking All of this network data has to be transferred over physical media like copper, fiber optics, and wireless radio. Of the physical layer protocols, Ethernet is the most well known. Its popularity in the early days of the Internet led us to design other protocols to accommodate its limitations. First, let's get the physical details out of the way. Ethernet is most closely associated with RJ45 connectors, which look like bigger eight-pin versions of older four-pin phone jacks. It's also associated with cat5 (or cat5e, or cat6, or cat7) cable, which contains eight total wires twisted into four pairs. Other media exist, but these are the ones we're most likely to encounter at home: eight wires wrapped in a sheath connected to an eight-pin jack. Ethernet is a physical layer protocol: it describes how the bits turn into electrical signals in a cable. It's also a link layer protocol: it describes the direct connection of one node to another. However, it's purely point-to-point and says nothing about how data is routed on a network. There's no concept of a connection in the sense of a TCP connection, or of reassignable addresses in the sense of an IP address. As a protocol, ethernet has two primary jobs. First, each device needs to notice that it's connected to something, and some parameters like connection speed need to be negotiated. Second, once link is established, Ethernet needs to carry data. Like the higher-level protocols TCP and IP, Ethernet data is broken into packets. The core of a packet is a frame, which has a 1,500 byte payload, plus another 22 bytes for header information like source and destination MAC address, payload length, and checksum. These fields are familiar: programmers often deal with addresses and lengths and checksums, and we can imagine why they're necessary. The frame is then wrapped in yet another layer of headers to form the full packet. These headers are... weird. They start to bump up against the underlying reality of analog electrical systems, so they look like nothing we would ever put in a software protocol. A full Ethernet packet contains: The preamble, which is 56 bits (7 bytes) of alternating 1s and 0s. The devices use this to synchronize their clocks, sort of like when people count off \"1-2-3-GO!\" Computers can't count past 1, so they synchronize by saying \"10101010101010101010101010101010101010101010101010101010\". An 8-bit (1 byte) start frame delimiter, which is the number 171 (10101011 in binary). This marks the end of the preamble. Notice that it's \"10\" repeated again, until the end where there's a \"11\". The frame itself, which contains the source and destination addresses, the payload, etc., as described above. An interpacket gap of 96 bits (12 bytes) where the line is left idle. Presumably, this is to let the devices rest because they are tired. Putting this all together: what we want is to transmit our 1,500 bytes of data. We add 22 bytes to create a frame, which indicates the source, destination, size, and checksum. We add another 20 bytes of extra data accommodating the hardware's needs, creating a full Ethernet packet. You might think this is the bottom of the stack. It's not, but things do get weirder because the analog world pokes through even more. Networking meets the real world Digital systems don't exist; everything is analog. Suppose we have a 5-volt CMOS system. (CMOS is a type of digital system; don't worry about it if you're not familiar.) This means that a fully-on signal will be 5 volts, and a fully-off signal will be 0. But nothing is ever fully on or fully off; the physical world doesn't work like that. In reality, our 5-volt CMOS system will consider anything above 1.67 volts to be a 1, and anything below 1.67 to be 0. (1.67 is 1/3 of 5. Let's not worry about why the threshold is 1/3. If you want to dig, there's a wikipedia article, of course! Also, Ethernet isn't CMOS or even related to CMOS, but CMOS and its 1/3 cutoff make for a simple illustration.) Our Ethernet packets have to go over a physical wire, which means changing the voltage across the wire. Ethernet is a 5-volt system, so we naively expect each 1 bit in the Ethernet protocol to be 5 volts and each 0 bit to be 0 volts. But there are two wrinkles: first, the voltage range is -2.5 V to +2.5 V. Second, and more strangely, each set of 8 bits gets expanded into 10 bits before hitting the wire. There are 256 possible 8-bit values and 1024 possible 10-bit values, so imagine this as a table mapping them. Each 8-bit byte can be mapped to any of four different 10-bit patterns, each of which will be turned back into the same 8-bit byte on the receiving end. For example, the 10-bit value 00.0000.0000 might map to the 8-bit value 0000.0000. But maybe the 10-bit value 10.1010.1010 also maps to 0000.0000. When an Ethernet device sees either 00.0000.0000 or 10.1010.1010, they'll be understood as the byte 0 (binary 0000.0000). (Warning: there are going to be some electronics words now.) This exists to serve an extremely analog need: balancing the voltage in the devices. Suppose this 8-bit-to-10-bit encoding doesn't exist, and we send some data that happens to be all 1s. Ethernet's voltage range is -2.5 to +2.5 volts, so we're holding the Ethernet cable's voltage at +2.5 V, continually pulling electrons from the other side. Why do we care about one side pulling more electrons than the other? Because the analog world is a mess and it will cause all kinds of undesirable effects. To take one: it can charge the capacitors used in low-pass filters, creating an offset in the signal level itself, eventually causing bit errors. Those errors would take time to accumulate, but we don't want our network devices to suddenly corrupt data after two years of uptime simply because we happened to send more binary 1s than 0s. (Electronics words end here.) By using an 8b/10b encoding, Ethernet can balance the number of 0s and 1s sent over the wire, even if we send data that's mostly 1s or mostly 0s. The hardware tracks the ratio of 0s to 1s, mapping outgoing 8-bit bytes to different options from the 10-bit table to achieve electrical balance. (Newer Ethernet standards, like 10 GB Ethernet, use different and more complex encoding systems.) We'll stop here, because we're already beyond the scope of what can be considered programming, but there are many more protocol issues to accommodate the physical layer. In many cases, the solutions to hardware problems lie in the software itself, as in the case of the 8b/10b coding used to correct DC offset. This is perhaps a bit disconcerting to us as programmers: we like to pretend that our software lives in a perfect Platonic world, devoid of the vulgar imperfections of physicality. In reality, everything is analog, and accommodating that complexity is everyone's job, including the software's. The interconnected network stack Internet protocols are best thought of as a stack of layers. Ethernet provides physical data transfer and link between two point-to-point devices. IP provides a layer of addressing, allowing routers and large-scale networks to exist, but it's connectionless. Packets are fired into the ether, with no indication of whether they arrived or not. TCP adds a layer of reliable transmission by using sequence numbers, acknowledgement, and retransmission. Finally, application-level protocols like HTTP are layered on top of TCP. At this level, we already have addressing and the illusion of reliable transmission and persistent connections. IP and TCP save application developers from constantly reimplementing packet retransmission and addressing and so on. The independence of these layers is important. For example, when packets were lost during my 88.5 MB video transfer, the Internet's backbone routers didn't know; only my machine and the web server knew. Dozens of duplicate ACKs from my computer were all dutifully routed over the same routing infrastructure that lost the original packet. It's possible that the router responsible for dropping the lost packet was also the router carrying its replacement milliseconds later. This is an important point for understanding the Internet: the routing infrastructure doesn't know about TCP; it only routes. (There are exceptions to this, as always, but it's generally true.) Layers of the protocol stack operate independently, but they weren't designed independently. Higher-level protocols tend to be built on lower-level ones: HTTP is built on TCP is built on IP is built on Ethernet. Design decisions in lower levels often influence decisions in higher levels, even decades later. Ethernet is old and concerns the physical layer, so its needs set the base parameters. An Ethernet payload is at most 1,500 bytes. The IP packet needs to fit within an Ethernet frame. IP has a minimum header size of 20 bytes, so the maximum payload of an IP packet is 1,500 - 20 = 1,480 bytes. Likewise, the TCP packet needs to fit within the IP packet. TCP also has a minimum header size of 20 bytes, leaving a maximum TCP payload of 1,480 - 20 = 1,460 bytes. In practice, other headers and protocols can cause further reductions. 1,400 is a conservative TCP payload size. The 1,400 byte limit influences modern protocols' designs. For example, HTTP requests are generally small. If we fit them into one packet instead of two, we reduce the probability of losing part of the request, with a correspondingly reduced likelihood of TCP retransmissions. To squeeze every byte out of small requests, HTTP/2 specifies compression for headers, which are usually small. Without context from TCP, IP, and Ethernet, this seems silly: why add compression to a protocol's headers to save only a few bytes? Because, as the HTTP/2 spec says in the introduction to section 2, compression allows \"many requests to be compressed into one packet\". HTTP/2 does header compression to meet the constraints of TCP, which come from constraints in IP, which come from constraints in Ethernet, which was developed in the 1970s, introduced commercially in 1980, and standardized in 1983. One final question: why is the Ethernet payload size set at 1,500 bytes? There's no deep reason; it's just a nice trade-off point. There are 42 bytes of non-payload data needed for each frame. If the payload maximum were only 100 bytes, only 70% (100/142) of time would be spent sending payload. A payload of 1,500 bytes means about 97% (1500/1542) of time is spent sending payload, which is a nice level of efficiency. Pushing the packet size higher would require larger buffers in the devices, which we can't justify simply to get another percent or two of efficiency. In short: HTTP/2 has header compression because of the RAM limitations of networking devices in the late 1970s. This article is part of The Programmer's Compendium. Previous article: Software Structure. This URL can be posted anywhere you like, including in public. You can get access to the full Programmer's Compendium by subscribing to Destroy All Software. CONTENT Screencasts Execute Program Programmer's Compendium Conference Talks ACCOUNT Sign In Sign Up COMPANY Blog Contact Privacy Policy FAQ EULA",
    "commentLink": "https://news.ycombinator.com/item?id=36984171",
    "commentBody": "Network protocols for anyone who knows a programming language | Hacker NewsHacker News new | comments | ask | show | jobs | submitloginNetwork protocols for anyone who knows a programming language (destroyallsoftware.com) 266 points by yla92 22 hours ago| 36 comments monk1 > An interpacket gap of 96 bits (12 bytes) where the line is left idle. Presumably, this is to let the devices rest because they are tired.This one left me laughing hard. reply jmbwell It’s funny cos it’s kinda true?While the preamble allows the devices to sync their clocks, the gap allows them to reset.The assumption is that there will be some drift between the clocks over the course of a transmission. A period of electrical silence makes it clearer when the last packet ends and when the next preamble begins.I think of it like shouting in a canyon. Shout Hello and it’s intelligible, but shout a whole sentence, and it’s hard to make out among the echoes and wind and birds. With some time between words for noise to settle down, signal to noise ratio improves and everyone can resync with each word.It’s not a big deal, and the gaps are smaller as line speeds increase. 10Base-T has big fat millisecond gaps, while 400G Ethernet has gaps that seem impossibly small. reply convolvatron 1I suspect it has (had) to do more with the fact that ethernet used to be a multi-access protocol and you were giving someone else a chance to talk. in general having read this its not clear how much of this is legacy and how much is modern. certainly there doesn&#x27;t need to be a rest on a dedicated channel, and most other protocols leave the clock synched between peers (i.e. with 4b5b idle tokens) reply jmbwell 1Yeah the article skips past the multiple access (hub) era for sure, and I haven’t thought about it in many years myself (!).I don’t know for sure how directly the IPG was related to multiple access. Early Ethernet would wait for silence, a la carrier sense multiple access, but it also used a collision detection and backoff mechanism. When someone tried to transmit, if someone else was talking, both would detect the collision and each would wait a semi-random period of time and try again, repeating with incrementally larger delays until a collision wasn’t detected and the frame could be transmitted.When there were only hubs, or when everything was on one coaxial cable, collisions happened all the time. The more nodes on a segment, the more collisions would impede traffic. You’d design a network with gateways and routers and expensive little store-and-forward switches at what we’d now call the core, to partition everything into smallish segments and try to keep the collision domains small.Cheap switching at what we’d now call the access level fixed all this by making all links effectively point to point.Ethernet standards from 10G onward don’t even bother with multiple access (point to point only, meaning switched), but they still retain the inter-packet gap. In some places it’s referred to as a “guard interval.” So I do think it’s mostly to provide opportunities for resyncing.Much of this applies in the RF domain as well. Before MIMO, Wi-Fi was directly analogous to an Ethernet hub… CSMA, one collision domain, incremental back off. Some access points still let you specify the guard interval manually. MIMO and things like beam-forming help reduce the collision domains by breaking the RF into cells and allowing something pretty close to a point to point link between the node and the AP. RF is its own dark art, but in terms of signaling, the problems and their solutions are much the same.So you’re correct that the guard interval or IPG would create a bit of silence for someone else to jump into. Everyone would probably have to resolve the collision in that case, but Ethernet accommodates that scenario as well. reply pests In the Gemini spacecraft this was almost true. The ram they used would overheat if accessed too frequently so the assembly coders had to be sure to add no ops or find other things to do while the ram cooled down. reply aequitas 1Thinking of the router in Warriors of the Net[0] and it makes perfect sense, he could use a rest once in a while.[0] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=PBWhzz_Gn10 reply tambourine_man 1Gary Bernhardt is just so good, I wish I would dedicate more time to read and watch his content.Alas, I&#x27;m a lazy #$%@& reply s_dev 1He&#x27;s basically a hardcore version of Julia Evans who also does great learning content for techies. reply tambourine_man 1She&#x27;s also fantastic. Their sense of humor is great and it makes digesting deep content a lot easier.But Julia&#x27;s concision in her Zines is what sets her apart, to me. So much great content in 3 or 4 panels. Incredible, it must be really hard and take a long time to achieve.Gary is more of a prose guy, to me. reply sesm You can find a more detailed (yet accessible) description of TCP congestion avoidance and slow start in this excellent and free book: https:&#x2F;&#x2F;hpbn.co&#x2F;building-blocks-of-tcp&#x2F;#congestion-avoidance...Edit: also, it has an entire section about HTTP&#x2F;2 https:&#x2F;&#x2F;hpbn.co&#x2F;http2&#x2F; reply lordnacho 1Cool, I didn&#x27;t know that final wrinkle about the 8b&#x2F;10b encoding. Physical layer stuff is not so common these days. reply ipython 1TCP sequence numbers count bytes not packets, which is why they don&#x27;t increment by 1 for each packet (unless the previous packet only included one byte of payload).Agreed with other commenters, this is a great article- thanks for posting! reply id0ntw4ntit 1> There are too many Internet nodes for it to work in this way. We can&#x27;t provide a direct, uninterruptible path from each machine to each other machine it wants to talk to.Is this true? Isn&#x27;t a direct, uninterruptible path from each machine to the other a requirement for communication? The path must proceed through complex switching systems, like in the analog days, yes.What is meant by the statement that it is no longer electrically equivalent to a single wire? reply roelschroeven 1In old telephone systems, each telephone had a dedicated wire to the central, and centrals had a number of dedicated wires between, each one of which could be used for one conversation at a time. Setting up a call involved physically switching your line to one of the wires to the next central, and from there to the next, until the last central where there was a physical connection made to the line the person you were calling (unless if at some place no free wires were available; then you got a busy signal). Once all the switches were put in the correct position, there was practically speaking one uninterrupted wire between the two phones. If you were to put a voltage spike on your line, that could be measured at the other end. At the end of the call the switches were put in another position, and there was no electrical connection between those phones anymore.In a packet-switched network, there is no direct electrical connection between two arbitrary nodes; there is only an electrical connection between your device and the first router, and between any router and the next one.Of course nowadays telephone lines don&#x27;t work with physical dedicated wires anymore either. It&#x27;s all digitized and multiplexed now. reply alfons_foobar 1I think this refers to circuit switching (in the old telephone networks, when you called someone, the connection had to be physically established at the \"intersections\" by the phone network operators) vs. packet switching (where the underlying network is not changed, instead the data packet is forwarded from one \"intersection\" to the next and reaches its destination eventually). reply HL33tibCe7 1> This is handled by IP, the Internet Protocol, whence IP addresses.This is grammatically nonsense. Correct would be “whence IP addresses come”. Or, “from where IP addresses come”, if you want to write like somebody normalOne of my biggest pet peeves is when someone uses obscure words like “whence” in an effort to flex their knowledge - and it’s even worse when they actually use it wrong. Almost made me stop reading the article. Although I’m glad I didn’t, because the rest of the article is great. reply gary_bernhardt 1That sentence&#x27;s grammar is intentional. (I wrote the sentence.)English is not a programming language. I&#x27;m sure that we can both name revered authors who have used far \"worse\" grammar consistently throughout their careers, whereas the word choice that has so ruffled you here involves a single word.As to \"flexing knowledge\": I had some fun in a couple sentences in that article. I aim to be at least slightly more than a machine that extrudes gray paste of unit density. Fabricating an ulterior motivate and attributing it to me is offensive. reply davidrupp 1Flex on, lad. Flex. On. Long may you flex. reply plazma box? reply saghm 1Do you react similarly when watching \"wat\" due to the misspelling, or \"The Birth and Death of JavaScript\" due to pronouncing the \"J\" like a \"y\"? Part of the charm of his content is the lighthearted, silly nature of it, and throwing in an antiquated sounding word seems to me like just another instance of not making technical content have to be overly dry and serious. reply starttoaster 1Even if it was grammatically incorrect, you understood what they meant, right? With such a vast field of knowledge as tech, should one strive to become a masterful writer on top of their technical studies? Maybe just being able to get an intelligible point across to the masses is good enough.Not necessarily focusing my comment at you, either. I&#x27;ve seen this sentiment around a lot, and my reaction each time is \"what am I, a software engineer or the one monkey that managed to type the complete works of William Shakespeare on a typewriter?\" reply icedchai 1I think it&#x27;s a simple typo... \"hence IP addresses\" makes more sense. reply capableweb 1I guess sometimes it takes a bit of knowledge about the author to read through their reading without cringing. In this case, I think it&#x27;s on purpose, to give the author&#x27;s (fictional) tone to the text. If you try watching one of the later talks, you&#x27;ll see what style the text is trying to emulate. reply depressedpanda 1I&#x27;m just happy they didn&#x27;t write \"from whence\". I know it&#x27;s accepted usage, but it just irks me when I see it as \"from\" is entirely redundant. reply mjdowney 1Concise better, silly reply z5h Great read. This made me curious about “the story” of the creation of the internet. ChatGPT suggested some books: 1. Where Wizards Stay Up Late: The Origins Of The Internet 2. The Innovators: How a Group of Hackers, Geniuses, and Geeks Created the Digital Revolution 3. Inventing the InternetAny comments on the above? Or other suggestions? reply pjmorris 1I read &#x27;Where Wizards Stay Up Late&#x27;, thoroughly enjoyed it, and would recommend.I can&#x27;t speak to the others. reply wofo I liked \"The Dream Machine\", which also tells how computers came to exist reply beeburrt 1The Backbonehttps:&#x2F;&#x2F;technicshistory.com&#x2F;the-backbone&#x2F;There&#x27;s also The Switch by the same person:https:&#x2F;&#x2F;technicshistory.com&#x2F;the-switch&#x2F; reply ipython 1Not related to the \"creation\" of the Internet, but Clifford Stoll&#x27;s The Cuckoo&#x27;s Egg is a great read and I would highly recommend it. I also second \"Where Wizards Stay Up Late\". reply whartung 1I looked at those titles and wondered if ChatGPT just made them up. reply tiahura 1While not Internet-centric, hopefully you’ve read Hackers by Steven Levy. reply z5h 1No. (Shame). But I did just download “UNIX: A History and a Memoir”. reply yayitswei 1Good study guide for that one interview question, \"what happens when I type google.com into the browser and press enter\". reply glonq 1\"The great firewall of china blocks me and I lose 10 social credit points\" reply jbirer 1prev [–] Bookmarked. reply",
    "originSummary": [
      "The passage covers various topics related to networking, including the network stack, network routing, packet switching, TCP, and HTTP.",
      "It explains concepts such as TCP slow start, packet loss and retransmission, Ethernet as a physical layer protocol, and the layered structure of internet protocols.",
      "The influence of payload size on modern protocols like HTTP/2 is discussed, and the choice of 1,500 bytes as the Ethernet payload size is described as a trade-off for efficiency."
    ],
    "commentSummary": [
      "The discussion on Hacker News revolves around network protocols and interpacket gaps in data transmission.",
      "It includes information on the history of Ethernet, multiple access protocols, and the role of IP addresses in communication.",
      "Recommended books on the origins of the internet are mentioned in the conversation."
    ],
    "points": 266,
    "commentCount": 36,
    "retryCount": 0,
    "time": 1691061252
  },
  {
    "id": 36991293,
    "title": "Color-Diffusion: using diffusion models to colorize black and white images",
    "originLink": "https://github.com/ErwannMillon/Color-diffusion",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up ErwannMillon / Color-diffusion Public Notifications Fork 7 Star 313 Code Issues Pull requests Actions Projects Security Insights ErwannMillon/Color-diffusion main 6 branches 0 tags Go to file Code Latest commit ErwannMillon Update README.md 8acee88 Git stats 20 commits Files Type Name Latest commit message Commit time configs/default update config input_images Initial commit visualization update inference gifs .gitignore cleaning and refactoring README.md Update README.md app.py update app.py dataset.py update visualization code denoising.py cleaning and refactoring diffusion.py cleaning and refactoring download_dataset.sh cleaning and refactoring dynamic_threshold.py big clean inference.py cleaning and refactoring model.py update visualization code requirements.txt cleaning and teting train.py cleanup, visualization utils.py update visualization code visualization.py update inference gifs README.md Color Diffusion Using diffusion models to colorize black and white images. Overview This project is a simple example of how we can use diffusion models to colorize black and white images. This implementation uses the LAB color space, a 3 channel alternative to the RGB color space. The \"L\" (Lightness) channel in this space is equivalent to a greyscale image: it represents the luminous intensity of each pixel. The two other channels are used to represent the color of each pixel. To train the model, we first load color images and convert them to LAB. Then, we add noise only to the color channels, keeping the L channel constant. The model gets this channel \"for free\" because it doesn't need to learn how to predict the greyscale image: it is always known at train and test time. Forward Diffusion Process Note that we actually don't need to go through all of the steps of the diffusion process to get to timestep t. Our forward diffusion process is non-Markovian, but the entire diffusion process is shown for illustrative purposes The model is a UNet that takes a 3 channel LAB input (the ground-truth greyscale channel concatenated with noised AB channels) and outputs a 2 channel prediction of the color noise. Forward diffusion and denoising at train time In addition to receiving the greyscale channel as input, the UNet is also conditioned on features extracted from the greyscale channel. Intermediate feature maps from an encoder (implemented as the first half of a UNet) are concatenated with the features of the main denoising UNet throughout the downsampling stage of the forward pass. Future Work / Ideas This was just a quick proof of concept to satisfy my curiosity and get a feel for training diffusion models from scratch, so the results are very basic. There are many ways this project could be improved, such as: Using pretrained face recognition networks like ArcFace or FaceNet as feature extractors to get the conditioning features Implementing cross attention on the embeddings Pretraining the greyscale feature extractor as the encoder stage of a greyscale autoencoder References A lot of code for the dataset and LAB color operations was adapted from moein-sharitania's colorization project, which used Conditional GANs https://github.com/moein-shariatnia/Deep-Learning I implemented optional dynamic thresholding as in Assembly AI's Minimagen project (the Assembly AI blog posts are excellent for getting a deep understanding of the maths and concepts behind diffusion models) https://www.assemblyai.com/blog/minimagen-build-your-own-imagen-text-to-image-model/ The UNet architecture was adapted from denoising-diffusion-pytorch https://github.com/lucidrains/denoising-diffusion-pytorch Usage Run bash download_dataset.sh to download the CelebA dataset and extract it Use inference.py for command line colorization. python inference.py --image-path--checkpoint--outputOr run python app.py for a simple gradio web UI About A diffusion model to colorize black and white images Resources Readme Activity Stars 313 stars Watchers 3 watching Forks 7 forks Report repository Releases No releases published Packages No packages published Languages Python 99.5% Shell 0.5% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=36991293",
    "commentBody": "Color-Diffusion: using diffusion models to colorize black and white images | Hacker NewsHacker News new | comments | ask | show | jobs | submitloginColor-Diffusion: using diffusion models to colorize black and white images (github.com/erwannmillon) 253 points by dvrp 13 hours ago| 120 comments erwannmillon Btw, I did this in pixel space for simplicity, cool animations, and compute costs. Would be really interesting to do this as an LDM (though of course you can&#x27;t really do the LAB color space thing, unless you maybe train an AE specifically for that color space. )I was really interested in how color was represented in latent space and ran some experiments with VQGAN clip. You can actually do a (not great) colorization of an image by encoding it w&#x2F; VQGAN, and using a prompt like \"a colorful image of a woman\".Would be fun to experiment with if anyone wants to try, would love to see any results if someone wants to build reply carbocation > I did this in pixel space for simplicity, cool animations, and compute costsA slight nitpick, wouldn&#x27;t doing diffusion in the latent space be cheaper? reply erwannmillon Depends, given the low res, the 3x64x64 pixel space image is smaller than the latents you would get from encoding a higher-res image with models like VQGAN or the stablediff VAE at their native resolutions.It&#x27;s easier to get a sense of what&#x27;s going wrong with a pixel space model though. With latent space, there&#x27;s always the question of how color is represented in latent space &#x2F; how entangled it is with other structure &#x2F; semantics.Starting in pixel space removed a lot of variables from the equation, but latent diffusion is the obvious next step reply ShamelessC Not necessarily if you don’t already have a pretrained autoencoder. reply xigency Question, how long did it take to train this model and what hardware did you use? reply erwannmillon Took a lot of failed experiments, the model would keep converging to greyscale &#x2F; sepia images. Think one of the ways I fixed was by adding an greyscale encoder to the arch. Used its output embedding as additional conditioning. Can&#x27;t remember if I only added it to the Unet input or injected it during various stages of the unet down pass. reply erwannmillon Think the final training run was only a couple hours on a Colab V100 reply data-ottawa 1Off topic: this has an absolutely 90’s sci-fi movie effect watching the gifs, it’s funny how the tech just wound up looking like that. reply erwannmillon 1hahaha it reminded me of some \"zoom and enhance\" stuff when I was making the animations reply barrkel It reminded me of the days of antenna pass-through VCR players, where you had to tune into your VCR&#x27;s broadcast signal when you couldn&#x27;t use SCART. reply Cthulhu_ I never knew that was a thing, today I learned. I was spoiled with our first VCR having SCART already :p. And an IR remote! We could put the antenna cable into the VCR then use the remote to change channels (all three) instead of having to walk up to the TV. (this was late 80&#x27;s, maybe early 90&#x27;s; I wonder if we were late with things like that) reply nerdponx Looks like something you&#x27;d see in an X Files episode. reply asciimov I’m not a fan of b&w colorization. Often the colors are wrong, either outright color errors (like choices for clothing or cars) or often not taking in to account lighting conditions (late in day shadows but midday brightness).Then there is the issue of B&W movies. Using this kind of tech might not give pleasing results as the colors used for sets and outfits were chosen to work well for film contrast and not for story accuracy. That “blue” dress might really be green. (Please, just leave B&W movies the way they are.) reply imoverclocked I think keeping the art as it was produced is important but there is also a good history of modifying art to produce new art too. In the digital age, we aren’t losing the original art so it seems even stranger to be against modification of the “original.”However, just applying a simple filter (or single transform without effort) definitely feels derivative to me. reply SiempreViernes Additionally, colorisations very commonly present themselves as showing a \"more true\" version of how things looked and not as creative art projects. reply solumunus I don’t see why it matters if the blue dress was really green. The result is either an enhanced experience or not, if it is then minor inaccuracies don’t seem relevant. reply Cthulhu_ If there&#x27;s a source that a blue dress was green, then that could be taken into consideration for recoloring, but as you said, it&#x27;s to enhance the experience, not to be 100% accurate. reply qiqitori Maybe you&#x27;re used to looking at B&W stuff and effortlessly figuring out what the scene is depicting, but for me at least it&#x27;s very hard. Adding a little color makes it much easier. In that regard, it doesn&#x27;t matter to me if the colors are wrong.(Perhaps it just takes some getting used to. Back when I read a black and white comic for the first time (as a child), I had a hard time figuring out things at first but got used to it at some point.) reply brianpan I think the point being made is that movies were made for the B&W end result, not just shooting color with B&W film.For instance, fake blood in B&W was often produced with black liquid. Colorizing it correctly just doesn&#x27;t make sense. Or a green or blue dress can be chosen because of the way it looks on film, not because it&#x27;s supposed to BE a green or blue dress. reply jojobas It&#x27;s not as if B&W movies or pictures are taken away, it&#x27;s just a fun exercise for NN to play with. reply hedora Due to the magic of the DMCA’s anti-circumvention clauses, the B&W movie can be taken away.The last time I checked, “the source is public domain” is not a valid defense against the pro-DRM parts of that law. reply Cthulhu_ Would a B&W film republished in color cause the original film to have its copyright extended? reply jojobas So, source is public domain somebody \"owns copyright\" on colorizing it, and you can no longer access the B&W source due to DMCA?That&#x27;s pretty perverse, got any links for a primer? reply grncdr Not specific to colorization, but didn’t something like this happen with the Star Wars trilogy? Lucas made a re-release with a few edits (that were not universally liked) and it’s now impossible to purchase a new copy of the original version (or something like that, I only remember hearing about it). reply jojobas 23 Well Star Wars wasn&#x27;t public domain, and I can&#x27;t see why the copyright holders would be forced to keep selling old versions.But fair point, non-public-domain B&W could be withdrawn from distribution. replyzamadatix I think colorization with some effort put in can be pretty decent. E.g. I prefer the 2007 colorization of It&#x27;s a Wonderful Life to the original. It&#x27;s never perfect but I don&#x27;t think that&#x27;s a prerequisite to being better. Some will always disagree though.About every completely automated colorized video tends to be pretty bad though. Particularly the YouTube \"8k colorized interpolated\" kind of low effort channels where they just let them pump out without caring if it&#x27;s actually any good. reply blululu Yeah it&#x27;s cool tech but I really don&#x27;t appreciate how it is just straight up deceitful and spreading misinformation. A lot of hues are underdetermined and the result is more or less arbitrary in a historical context. If one were to research and fine-tune the model such that ambiguous shades are historically accurate I would be less annoyed by the sense that these images are just spreading misinformation. Compare this with Sergey Prokudin-Gorsky&#x27;s photos of the Russian Empire or autochromes of Paris in 1910 which are actual windows into a lost world.*for works of fiction these issues vanish, but for any historical or documentary photographs&#x2F;films, I really hate that I am being lied to. reply ChrisArchitect Author&#x27;s writeup on this from May: https:&#x2F;&#x2F;medium.com&#x2F;@erwannmillon&#x2F;color-diffusion-colorizing-... reply buildbot 1Does it work on arbitrary image sizes?One of the nice features of the somewhat old Deoldify colorizer is support for any resolution. It actually does better than photoshops colorization: https:&#x2F;&#x2F;blog.maxg.io&#x2F;colorizing-infrared-images-with-photosh...Edit - technically, I suppose, the way Deoldify works is by rendering the color at a low resolution and then applying the filter to a higher resolution using OpenCV. I think the same sub-sampling approach could work here... reply erwannmillon Technically yes, the encoder and unet are convolutional and support arbitrary input sizes, but the model was trained at 64x64px bc of compute limitations. You could probably resume the training from a 64x64 resolution checkpoint and train at a higher resolution.But like most diffusion models, they don&#x27;t generalize very well to resolutions outside of their training dataset reply snvzz 1All the examples are portraits of people.I have to wonder whether it works well with anything else. reply erwannmillon 1trained on celebA, so no, but you could for sure train this on a more varied dataset reply Eisenstein 1Would it be as simple as feeding it a bunch of decolorized images along with the originals? reply erwannmillon 1basically the training works as follows: Take a color image in RGB. Convert it to LAB. This is an alternative color space where the first channel is a greyscale image, and two channels that represent the color information.In a traditional pixel-space (non latent) diffusion model, you noise all the RGB channels and train a Unet to predict the noise at a given timestep.When colorizing an image, the Unet always \"knows\" the black and white image (i.e the L channel).This implementation only adds noise to the color channels, while keeping the L channel constant.So to train the model, you need a dataset of colored images. They would be converted to LAB, and the color channels would be noised.You can&#x27;t train on decolorized images, because the neural network needs to learn how to predict color with a black and white image as context. Without color info, the model can&#x27;t learn. reply bemusedthrow75 1But since you do not have access to colour originals of historical photos in almost every instance, you cannot possibly train the network to have any instinct for the colour sensitivity of the medium, can you?An extreme example:https:&#x2F;&#x2F;www.cabinetmagazine.org&#x2F;issues&#x2F;51&#x2F;archibald.phphttps:&#x2F;&#x2F;www.messynessychic.com&#x2F;2016&#x2F;05&#x2F;05&#x2F;max-factors-clown-...Colourising old TV footage can only result in a misrepresentation, because the underlying colour is false to have any kind of usable representation on the medium itself.And this caricatured example underpins the problem with colourisation: contemporary bias is unavoidable, and can be misleading. Can you take a black and white photo of an African-American woman in the 1930s and accurately colour her skin?You cannot. reply dragonwriter 1> Can you take a black and white photo of an African-American woman in the 1930s and accurately colour her skin?AI colorization will, in general, be plausible, not accurate. reply erwannmillon 1Yeah, the model is racist for sure. That&#x27;s a limitation of the dataset though (celeb A is not known for its diversity, but it was easy for me to work with, I trained this model on Colab)And plausibility is a feauture, not a bug.There are always many plausibily correct colorizations of an image, which you want the model to be able to capture in order to be versatile.Many colorization models introduce additional losses (such as discriminator losses) that avoid constraining the model to a single \"correct answer\" when the solution space is actually considerably larger. reply morelisp 1In other words, bullshit. reply dragonwriter 1No more so than any other colorization method that isn’t dependent on out-of-band info about the particular image (and even that is just more constrained informed guesswork.)That&#x27;s what happens when you are filling in missing info that isn&#x27;t in your source.EDIT: Of course, color photography can be “bullshit” rather than accurate in relation to the actual colors of things in the image; as is the case with the red, blue, and green (actual colors of the physical items) uniforms in Star Trek: The Original Series. But, also fairly frequently, lots of not-intentionally-distortive reproductions of skin tones (often most politically sensitive in the US with racially non-White subjects, where there are also plenty of examples of deliberate manipulation.) reply morelisp 1Showing color X on TVs by actually making the thing color Y in the studio, well, filming, not bullshit. It&#x27;s an intentional choice playing out as intended. It is meant to communicate a particular thing and does so. reply dragonwriter 1That particular thing was not intentional, and is the reason why the (same color in person, different material) command wrap uniform that is supposed to be color-matched to the made-as-green uniforms isn’t on screen.But, yes, in general inaccurate color reproduction can be intentionally manipulated with planning to intentionally create appearances in photos that do not exist in reality. reply snvzz 1The original color information just isn&#x27;t there.So bullshit is the best you&#x27;re going to get. reply morelisp 1Well, you could also not put more bullshit in the world by not doing the thing. reply wruza Why are you so negative about it? Pretty sure many people would find it impressive to colorize old photos to look at them as if these were taken in color.Should artists not put their bs in the world? Writers? Musicians? Most of it is made up but plausible to make you feel something subjective. reply roywiggins People have been colorizing photos as long as there have been photos. reply jackpeterfletch 1shrug people like looking at colorised photos because it helps root the image within the setting of the real world they occupy.For some it’s more evocative, irregardless of the absolute accuracy.Having a professional do it for that picture of your great grandad is expensive.Having a colourisation subreddit do it is probably worse for accuracy.I think there is a place for this bullshit. reply atorodius 1This is true, but if you have some reference images, you can probably adapt some of the recent diffusion adaptation work such as DreamBooth, to tell the model „hey this period looked like this“, and finetune it.https:&#x2F;&#x2F;dreambooth.github.io&#x2F; reply coldtea 1>You can&#x27;t train on decolorized images, because the neural network needs to learn how to predict color with a black and white image as context. Without color info, the model can&#x27;t learn.I think the parent means with delocorized images used to test the success and guide the training (since they can be readily compared with the colored image they resulted from which would be the perfect result).Not to use decolorized images alone to train for coloring (which doesn&#x27;t even make sense). reply omoikane 1Is there a reason for using LAB as opposed to YCbCr? My understanding is that YCbCr is another model that separates luma (Y) from chroma (Cb and Cr), but JPEG uses YCbCr natively, so I wonder if there would be any advantage in using that instead of LAB? reply TylerE 1The Y in YCbCr is linear, and is just a grayscale image. The L channel in lab is non-linear (as are A and B), and is a complex transfer function designed to mimic the response of the human eye.A YCbCr colorspace is directly mapped from RGB, and thus is limited to that gamut.LAB can encode colors brighter than diffuse white (ala #ffffff), like an outdoor scene in direct sunlight.Sorta HDR (LAB) vs non-HDR (YCbCr).This image (https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;thumb&#x2F;f&#x2F;f3&#x2F;Ex...) is a good demo, left side was processed in LAB, right in YCbCr). Even reduced back down to a jpeg, the left side is obviously more lifelike, since the highlights and tones were preserved until much later in processing pipeline. reply aendruk The description included with that image conflicts with your account:> An example of color enhancement using LAB colorspace in Photoshop (CIELAB D50). Left side is enhanced, right side is not. Enhancement is \"overdone\" to show the effect better.And per the original upload the “enhancement” demonstrated is linear compression of the a* and b* channels—https:&#x2F;&#x2F;upload.wikimedia.org&#x2F;wikipedia&#x2F;commons&#x2F;archive&#x2F;f&#x2F;f3&#x2F;...—the effect a divergence from the likeness of life at least as I’ve experienced it. reply atorodius 1You can take arbitrary images and convert them to grayscale for training, and do conditional diffusion reply bemusedthrow75 1But convert them to grayscale how?Black and white film doesn&#x27;t have one single colour sensitivity. Play around with something like DxO FilmPack sometime (it has excellent measurement-based representations of black and white film stocks).It&#x27;s a much more complex problem than it might seem on the surface. reply atorodius 1fair, but can’t you just randomize the grayscale generation for training? reply atorodius 1yes, so infinite training data. but the challenge will be scaling to large resolutions and getting global consistency reply jrockway 1Is that challenging? Humans have awful color resolution perception, so even if you have a huge black-and-white image, people would think it looks right with even with very low-resolution color information. Or, if the AI hallucinates a lot of high frequency color noise, it wouldn&#x27;t be noticable.Wikipedia has a great example image here: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Chroma_subsampling. Most people would say all of them looked fine at 1:1 resolution. reply atorodius 1I meant more from a comoute standpoint, the models are expensive to run full res reply jrockway 1I see what you mean. I think that you can happily scale the B&W image down, run the model, and then scale the chroma information back up.Something I was thinking about after writing the comment is that the model is probably trained on chroma-subsampled images. Digital cameras do it with the bayer filter, and video cameras add 4:2:0 subsampling or similar subsampling as they compress the image. So the AI is probably biased towards \"look like this photo was taken with a digital camera\" versus \"actually reconstruct the colors of the image\". What effect this actually has, I don&#x27;t know! reply atorodius 1good point, I hadn’t realized that you only need to predict chroma! That actully greatly simplifies thingsre. chroma subsampling in training data: this is actually a big problem and a good generative model will absolutely learn to predict chroma subsampled values (or JPEG artifacts even!). you can get around it by applying random downscaling with antialiasing during training. reply drapado 1I guess you can always use a two-stage process. First colorize, then upscale reply atorodius 1yeah, you can use SOTA super res, but that tends to be generative too (even diffusion based on its own, or more commonly based on GANs). it can be a challenge to synthesize the right high res details.but that’s basically the stable diffusion paper (diffusion in latent space plus GAN superres) reply erwannmillon Yeah, if you have a high res image, you can get color info at super low-res and then regenerate the colors at high res with another model. (though this isn&#x27;t an efficient approach at all)https:&#x2F;&#x2F;github.com&#x2F;TencentARC&#x2F;T2I-Adapteri&#x27;ve also seen a controlnet do this. replyquickthrower2 That is so 2023 and so 1993 at the same time! reply iamflimflam1 I wonder if this can be used for color correction in videos. reply aziaziazi 1How much would it cost to colorize a movie with a fork of this? reply NBJack 1I think the bigger question is would it be stable enough. Many SD like models struggle with consistency across multiple images (i.e. frames) even when content doesn&#x27;t change much. Would he a cool problem to see tackled. reply erwannmillon temporal coherence is def an issue with these types of models, though I haven&#x27;t tested it out with ColorDiffusion. Assuming you&#x27;re not doing anything autoregressive (from frame to frame) to do temporal coherence, you can also parallelize the colorization of each frame, which would affect cost.Tbh most cost effective would be a conditional GAN though reply lajamerr Change up the model. That allows it to see previous frames and 1-2 future frames.Then train the model on movies that are color and then turn them black and white.That way you can train temporal coherence. reply leetharris 1Quick math:24 frames per second * 60 seconds per minute * 90 minute movie length = 129600 framesIf you could get cost to a penny per frame, about $13k? But I&#x27;d bet you could easily get it an order of magnitude less in terms of cost. So $1500 or so?And that&#x27;s assuming you do 100% of frames and don&#x27;t have any clever tricks there. reply caturopath 1I&#x27;m willing to bet that if you just treated each frame as an image, it would result in some weird stuff when you played them as a movie.> penny per frameWhere did this come from? reply leetharris 1I do lots of large scale ML work, this was just sort of a random educated \"order of magnitude\" guess. reply syntaxing Seems like a pretty reasonable estimate, if it cost about $2 a hour to rent a decent GPU, that’s 18s per penny which sounds pretty doable to run one frame. reply erwannmillon Think inference time was on the order of 4-5seconds per image on a v100, which you can rent for like .80 cents an hour, though you can get way better gpus like a100s for ~1.1 usd&#x2F;h now. But ofc this is at 64px res in pixel space.If you wanted to do this at high res, you would definitely use a latent diffusion model. The autoencoder is almost free to run, and reduces the dimensionality of high res images significantly, which makes it a lot cheaper to run the autoregressive diffusion model for multiple steps. replyrealusername Is there anything that exists right now with diffusion models to improve poor VHS coloring? The coloring does exist so I would not want to replace a red shirt by a blue shirt for example but it&#x27;s just not very accurate. reply jurassic 1This is a cool party trick, but I don&#x27;t see a need for this in any real applications. Black and white is its own art form, and a lot of really great black and white images would look like absolute garbage if you could convert them to color. This is because the things that make a great black and white image (dramatic contrasts, emphasis on shape&#x2F;geometry, texture, etc) can lose a lot of their impact when you introduce color. Our aesthetic tolerance for contrast seems significantly reduced in color because our expectations for the image are more anchored in how things look in the real world. And colors which can be very pleasing in some images are just distracting in others.So all this is to say.... I don&#x27;t think there would be commercial demand to, say, \"upgrade\" classic movies with color. Those films were shot by cinematographers who were steeped in the black & white medium and made lighting and compositional choices that take greatest advantage of those creative limitations. reply simonw I&#x27;ve run colorization like this against historic photographs and it had a very real impact on me - I found myself able to imagine life when the photo or video was taken much more easily when it was no longer in black and white.Here&#x27;s an example I really enjoyed, of a snowball fight in 1896: https:&#x2F;&#x2F;twitter.com&#x2F;JoaquimCampa&#x2F;status&#x2F;1311391615425093634 reply dylan604 The issue I have is that the examples appear to be color images that were converted to black and white. In other words, they are modern images with plenty of images acquired in color for training. Converting an archival shot from early 20th century is totally different. Totally lowers credibility in my eyes reply pythonguython 1Counterexample: They Shall Not Grow Old, a WW1 documentary film with mostly colorized footage with recreated audio. The film was commercially successful and I found it to be a great watch. reply 112233 I really really want something like this to actually reduce noise in images. Current raw photo denoising often is little more than a tuned up gaussian blur. Making it guess color based on larger context and external info would be step up.Eztra happy if it would be possibe to tune denoising, using photos from the same series. Multiframe NLMeans right now is slow and mostly theoretical. reply ragnarok451 Have you used Topaz Labs? That denoising is pretty good, definitely more advanced than a tuned-up gaussian. reply dragonwriter 1> I don&#x27;t think there would be commercial demand to, say, \"upgrade\" classic movies with color.There was, and maybe there will be again once we get far enough from the consumer burnout from the absolute deluge of that in, mostly, the 1980s-1990s.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;List_of_black-and-white_film... reply bemusedthrow75 > I don&#x27;t think there would be commercial demand to, say, \"upgrade\" classic movies with color.Alas there has been serious money in this in the past (VHS and as I understand it US cable TV).I would not assume that we have more taste now than we did then. (The state of cinema suggests the opposite to me at least.) reply MrVandemar Some of the old Doctor Who stories that were filmed in colour they only have black and white copies of. The colourisations have been ... very good, better than I would have thought, but not perfect. Could be an a good application. reply yieldcrv > but I don&#x27;t see a need for this in any real applicationswhen your mom asks you to make a black and white image in colordigital retouchers do this kind of work all day for decades reply bemusedthrow75 1prev [–] Colourising old photographs is the banal apotheosis application of diffusion AI.It&#x27;s the pinnacle of the whole thing: \"imagine it for me in a way that conforms to my contemporary expectations\".If you&#x27;re going to colourise images, have the decency to do it by hand. If possible on a print with brushes.Edit: didn&#x27;t think this would be popular. Maybe it&#x27;s the historical photography nerd in me, but colourising images without effort and thought is like smashing vintage glass windows for the fun of it: cultural vandalism. reply dragonwriter 1> But since you do not have access to colour originals of historical photos in almost every instance, you cannot possibly train the network to have any instinct for the colour sensitivity of the medium, can you?Plenty of people say that about colorization period, which, while I disagree, seems more sensible than your position to me, which just seems to be fetishizing suffering. reply crazygringo 1If you&#x27;re going to write code, have the decency to do it on punch cards. If possible by hand punching, rather than using a keypunch machine. reply bemusedthrow75 1This isn&#x27;t the point I am making.The point I am making is that colourisation is subjective art, and that alone.Colourisation cannot fail to enforce contemporary biases based on poor understanding of the materials. It will darken or lighten skin inappropriately, and mislead in any number of ways.Doing it by hand (in photoshop or on a print) acknowledges the inherent bias that is involved in colourisation.Automating it is banal at best and dangerous at worst; colourised images risk distorting history. reply crazygringo 1> Colourisation cannot fail to enforce contemporary biases based on poor understanding of the materials. It will darken or lighten skin inappropriately, and mislead in any number of ways.If anything, an AI trained on a large and diverse dataset is probably going to wind up being much more accurate with regards to skin color than a human colorist would be in most cases.The problem here isn&#x27;t whether colorization is done by man or machine; it&#x27;s just ensuring that colorized photos are identified as such. Which they usually are -- that&#x27;s not a new problem to be solved. reply bemusedthrow75 1No it&#x27;s not, not really.A diverse data set of black and white images doesn&#x27;t have any kind of knowledge of the colour sensitivity of the medium in that moment.What film was it? How was it processed? Is it a scan of a negative or a print? What was the colour of the lighting? Was a particular colour tint filter used on the lens? Was the subject wearing makeup optimised for black and white photography?The black and white image, standing alone, cannot tell you this, I think. Sure, it might get a bit better at, say, identifying a 1950s TV show. But what is the \"correct\" accurate colour representation of that scene, when televisual makeup was wildly unnatural in colour? reply crazygringo 1But do people have any of that knowledge either? Most of the time, I don&#x27;t think so -- they colorize stuff in a way that just \"looks right\" or \"looks natural\" or \"looks nice\" to their eye, that&#x27;s all.And the dataset an AI is going to train on should be using original color photos that are then converted to B&W across a wide variety of color curves. So it should be fairly robust to all sorts of film types. So again, I repeat that it&#x27;s probably going to wind up being more accurate with regard to skin tone than a human (with their aesthetic biases) usually would. reply bemusedthrow75 1> But do people have any of that knowledge either? Most of the time, I don&#x27;t think so -- they colorize stuff in a way that just \"looks right\" or \"looks natural\" or \"looks nice\" to their eye, that&#x27;s all.No, indeed. Which is why doing it by hand is more respectful of the notion that it is subjective.Automatic colourisation is and will be viewed differently, as more \"scientific\", when it&#x27;s still absolutely beholden to the same biases and maybe misconceptions that we can&#x27;t unpick because they come from poor training data.Finally: \"original colour photos\" are also a problem. Not only for the part of the history where they don&#x27;t exist. But also for the part of history (until the early 1960s) when the colour rendition of those photos was false or incomplete. You can get a little closer to understanding what that colour looked like, but it&#x27;s important to understand that colour emulsions vary in the way they work: it&#x27;s not black and white film with extra colour sensitivity.So at best you will be colourising the black and white film to look like the colour film, which is not reality. And there are well-understood problems with correct representation of skin tones with colour film until the mid-eighties.I can see your point; I just think there&#x27;s a bigger picture here (pun not intended) that you&#x27;re not seeing. reply crazygringo 1> Automatic colourisation is and will be viewed differently, as more \"scientific\"Then the solution is to correct that misperception, not deny ourselves a useful tool.> I can see your point; I just think there&#x27;s a bigger picture here (pun not intended) that you&#x27;re not seeing.My overarching point is that this is a tool like any other. And the idea that \"doing it by hand is more respectful of the notion that it is subjective\" I will push back on 100%.There is nothing disrespectful about colorizing a photo, automatically or by hand. But it should always be clearly communicated that it is subjective not objective, whether human or machine.Again, if someone believes the colorization is somehow \"real\" or \"scientific\" because a computer did it, then correct their misbelief. Don&#x27;t stop using the tool. That&#x27;s the bigger picture here. replycoldtea 1>Automating it is banal at best and dangerous at worst; colourised images risk distorting historyWell, faces still have a certain tint, the sky is mostly blue, the grass green, water is blue, mud pools are brown, the ground too, a lot of historical fabrics are certain inherent colors, known flowers have known colors, brownstones have red&#x2F;brown color. A lot of it, is just not that subjective.Besides different color film stock (or camera sensor \"color science\") can already result in dozens of widely different colorings of the same exactly scene. reply bemusedthrow75 1> Well, faces still have a certain tintDo they? A certain tint?You cannot accurately colourise skin from photographic film without an _enormous_ amount of knowledge of the taking and processing of the film, and of the lighting and subject.An AI can&#x27;t do it any better than a painter. You can&#x27;t take a scan of a print or a negative and get skin tones right.Think about how weird the skin tones are from scans of wet-plate photography plates compared to the same process used in antiquity with the aim of producing a carbon print. reply coldtea 1>Do they? A certain tint?Yes. There&#x27;s just not a single one across all faces - but I wasn&#x27;t meaning that.What I mean is, we know the kind of tints a face will have. A face is not suddenly going to be blue or green or poppy red. And by how light a black and white face appears, we can tell quite well if it&#x27;s a darker one (oilish to brown) or lighter (pinkish towards more pale).If we get it wrong within a range it&#x27;s no big deal. Color film stocks would also vary it widely.Hell, even actual people who met the person we colourise in real life will remember (or even experience in real time) their face&#x27;s hue somewhat differently each. reply bemusedthrow75 1But how brown? How pink? How light? How dark?This is an enormously important issue.Black and white films of different technologies and manufacturers and eras actually lighten or darken skin tones. Really very significantly.And it&#x27;s not going to be obvious from the final positive, unless there&#x27;s _extensive_ data with those images about how the photography was done. And there never is.Editing because I can no longer reply: the question of whether a skin tone is a dark one or a light one has had severe real life impacts on people whose lives are now only represented in photographs. You can&#x27;t write this off as micromanagement; it&#x27;s about the ethics of representation. reply coldtea 1>But how brown? How pink? How light? How dark? This is an enormously important issueIs it?If 2 colour film stocks took the same image of them, it would show their hue a little (or a lot) different.Even if two different people actually met the same person, they will probably describe their face as slightly different tones from memory. (And let&#x27;s not even get into different types of color-blindness they could have had).Hell, a person&#x27;s hue will even look different to the same person looking at them, in real time, depending on the changes in lighting and the shade at the scene as they talk (e.g. sun behind clouds vs directly sun vs shade vs bulbs).It&#x27;s not really \"enormously important\" to micromanage the (non-existent) exact right brown or right pink. replydragonwriter 1> Doing it by hand (in photoshop or on a print) acknowledges the inherent bias that is involved in colourisation.No, doing it by hand doesn&#x27;t acknowledge that your interpretation is a fallible interpretation shaped by bias, just like translating a written work (e.g., the Bible, for a noted example where this has been done often without any such acknowledgement being conveyed) by human effort doesn’t do that.Acknowledging bias in translation of either kind is an entirely separate action, orthogonal to the method of the translation itself. reply erwannmillon Fair enough. Honestly this was just a fun side project. I actually coded this up last october when I was doing a deep dive to learn about diffusion models, and saw that no one had ever applied them to colorization. This was just a fun opportunity to build a project that no one had done before reply geon 1How can it affect the lightness channel when it is locked? reply erwannmillon So we&#x27;re using a color space that has two channels dedicated entirely to color, which is the only thing the model needs to learn.The model doesn&#x27;t need to touch the lightness channel at all, only predict the noised added to the color channels at train time.At inference time, we start with a real lightness channel (b&#x2F;w image), and initialize the color channels to random noise. The model iteratively denoises the color channels while keeping the lightness channel locked. reply bemusedthrow75 1The point is that the source black and white image is not truthful about skin colour. The film locks in a level of lightness but that lightness may be very wrong (depending on the red and blue sensitivity of the film, the colour of the light, the time of day, the print, whether a filter was being sued).So if you colourise an image of someone who appears to be a light-skinned 1930s African-American with colours that appear to conform to our contemporary understanding of light-skinned Black people of our era, you might be getting it right, of course.But you might be getting it quite, quite wrong, in a way that matters. reply PartiallyTyped > Automating it is banal at best and dangerous at worst; colourised images risk distorting history.There&#x27;s a lot of irony in acknowledging this but not acknowledging that each and everyone of us has their own biases inherent to our perception and experiences.Like the blue and white dress; we all perceive things differently even on identical images, monitors, screens, etc. reply bemusedthrow75 My post you are replying to contains the sentence \"Doing it by hand (in photoshop or on a print) acknowledges the inherent bias that is involved in colourisation\". reply PartiallyTyped That&#x27;s the point; you acknowledge the inherent bias in constructing, but not the bias in observing. replygeon 1How was anything destroyed? the original grayscale is still there. reply bemusedthrow75 1Colourised images absolutely replace mono images in image searches, unfortunately; I&#x27;ve seen this again and again. It gets more difficult to find originals.But also you have to consider that bias is being introduced in the colour rendition. That causes damage.For example, you could see a photograph of an African American woman in the 20s or 30s, and your AI would say, this is an African American woman and colour her skin in some way.But a lighter-skinned-looking African American woman in a pre&#x2F;early-post-war photo is a challenge. She may have had darker skin -- been unable to \"pass\" -- and the film simply didn&#x27;t get that across because of its colour sensitivity.Or she may actually have been light-skinned and able to \"pass\" (or wearing makeup that helped).Automatically colouring that image introduces risks to the reading of history; you can read that woman&#x27;s entire life completely wrong.It&#x27;s also common with photos of men from that era who worked outdoors. Many of them will come across much darker-skinned in photos than they actually would have appeared in real life, because not-readily-visible sun damage can look odd in mono. But if you colourise all those sun-baked people the same way, what happens to those of mixed heritage among them? (A thing that is already rather \"airbrushed out\" of history.)Without knowing about the lighting, the material, the processing and the source of the positive (is it a negative scan? was it a good one? or is it a scan of a print?) you cannot make accurate impressions of skin tone.And given the power and importance of photography in the history of the USA in particular -- photography coincides with and actually helps define the modern unified US self-image -- this is not something to blaze through without care.This is a far less tricky problem in more homogeneous societies, obviously. But even then, there is this perception from photographs that British women in the 1920s were all deathly pale; colourisation preserves that illusion that actually comes in part from photographic style. reply pkoiralap 1Making music without actually knowing anything about it is the banal apotheosis application of Generative AI. - Music nerd in meCreating art without actually knowing anything about it is the banal apotheosis application of Diffusion AI. - Artist in meUsing ChatGPT to write essays that are better than anyone could have ever written is the banal apotheosis application of LLMs - Teacher in meIt is already here. Better use, appreciate, and try to understand how it works rather than complaining about it doing a better job. In this instance, for example, the model can be made to generate multiple outputs or even better, generate output based on precise user input. reply erwannmillon I work at krea.ai. We are for sure making art extremely accessible, but we consider it enhancing creativity rather than replacing.I fully agree that being able to generate an aesthetically pleasing image with an AI that has been optimized to do exactly that is a banal application of creativity.I do think that AI has incredible potential to make (and become art).The best AI artists don&#x27;t just throw art into midjourney, they experiment, create their own secret sauce.Training models has become an art form in and of itself: ai artists curate incredible datasets and devise recipes for training stunning models. Their workflows span multiple companies &#x2F; tools &#x2F; models.AI just means that the goalposts for creativity are shifting. Boring people will use AI to make boring art, artists will find completely unexpected ways to use the tools we build to create art forms we&#x27;ve never imagined before. reply bemusedthrow75 1I&#x27;m actually concerned it is doing a worse job, in important ethical ways, than a hand colourist. But I&#x27;ve explained elsewhere.Colourisation cannot be done accurately from a black and white image without context that is almost always lacking. Hand colouring is less dishonest. reply coldtea 1When did colorizing images become an \"art\"?What if the \"effort\" way is less accurate? reply bemusedthrow75 1The effort is obviously going to be less accurate.But it reflects the fact that an accurate colourisation of a black and white image without access to every possible detail about the scene and processing from the photographer&#x27;s perspective is impossible.Black and white film is substantially more complex and varied than people understand. Its sensitivities are complex and vary from processing run to processing run, and people at the time knew of the weaknesses of black and white and often used false colour to get an acceptable rendition.Colourisation is a form of expression, not a form of recovery. reply coldtea 1>But it reflects the fact that an accurate colourisation of a black and white image without access to every possible detail about the scene and processing from the photographer&#x27;s perspective is impossible.Accurate colourisation is impossible even in a color photograph. There is no \"canonical\" film stock that accurately represents all actual real-life colors.The expectation from colourisation is not an accurate representation of the original colors, but a good application of color based on our knowledge (whether from historical facts a human colorist knows or from training with similar objects and materials a NN did) that matches a realistic representation of the scene.If a human colourist draws a dress and doesn&#x27;t know the color of it, nor have they any historical information about what the person depicted wore that day, they&#x27;re going to take a guess. That&#x27;s kind of what the NN will do as well. reply vorpalhex 1There is a community of people who carefully recolor historical photos by hand. It&#x27;s really beautiful time consuming work and often they invest heavily to get the colors to be correct. reply erwannmillon 1touché, nevertheless, colors go brrrrrrrr reply bemusedthrow75 1Don&#x27;t get me wrong. It&#x27;s impressive technology. I&#x27;m amazed at what it can do.Also horrified. reply mrkeen 1Nice, I&#x27;ll have to try smashing vintage glass windows. Thanks for the tip! reply vorpalhex 1prev [–] I think a lot of it depends on what you are doing and why.Yes, recolors can be inaccurate but they can make historical moments feel more alive and connected. At the same time one can imagine the issues of a recolor that is inaccurate and that is troubling with historical photographs.At the same time I have a bunch of old family photos I&#x27;d love to recolorize. Maybe the colors won&#x27;t be quite right but that&#x27;s an OK failure mode for family photos!I&#x27;d love to see a version where you can drop just a spot or two of the correct color and let the AI fill it out. My grandmother had stark red hair but most algorithms will color her as a blond. It&#x27;d be nice to fix that, using one of the color photos we do have. reply erwannmillon 1parent [–] You can do this with spatial palette t2i or controlnet. Give a super lores spatial palette as conditioning like this: https:&#x2F;&#x2F;camo.githubusercontent.com&#x2F;8e488996fd309165fb065b0cd...https:&#x2F;&#x2F;github.com&#x2F;TencentARC&#x2F;T2I-Adapter reply",
    "originSummary": [
      "The project utilizes diffusion models to add color to black and white images, employing the LAB color space and a UNet model to predict color noise.",
      "It serves as a proof of concept, showcasing the potential for improvement by incorporating pretrained face recognition networks and implementing cross attention.",
      "The project provides instructions for usage, including downloading the dataset and executing the colorization process, while acknowledging the code and resources used from other repositories."
    ],
    "commentSummary": [
      "Diffusion models and neural networks are being used for colorizing black and white images.",
      "The debate revolves around the credibility and historical accuracy of colorization.",
      "Some view colorization as a form of art and creative expression, while others worry about its potential to distort history.",
      "The introduction of AI in colorization raises concerns about automation and the subjective nature of color perception."
    ],
    "points": 253,
    "commentCount": 120,
    "retryCount": 0,
    "time": 1691094290
  },
  {
    "id": 36987920,
    "title": "Show HN: Hydra 1.0 – open-source column-oriented Postgres",
    "originLink": "https://hydra-so.notion.site/Hydra-1-0-beta-318504444825401e8ce21796dcadd589",
    "originBody": "hi hn, hydra ceo here<p>hydra is an open source, column-oriented postgres. you can set up remarkably fast aggregates on your project in minutes to query billions of rows instantly.<p>postgres is great, but aggregates can take minutes to hours to return results on large data sets. long-running analytical queries hog database resources and degrade performance. use hydra to run much faster analytics on postgres without making code changes. data is automatically loaded into columnar format and compressed. connect to hydra with your preferred postgres client (psql, dbeaver, etc).<p>following 4 months of development on hydra v0.3.0-alpha, our team is proud to share our first major version release. hydra 1.0 is under active development, but ready for use and feedback. we’re aiming to release 1.0 into general availability (ga) soon.<p>for testing, try the hydra free tier to create a column-oriented postgres instance on the cloud. <a href=\"https:&#x2F;&#x2F;dashboard.hydra.so&#x2F;signup\">https:&#x2F;&#x2F;dashboard.hydra.so&#x2F;signup</a>",
    "commentLink": "https://news.ycombinator.com/item?id=36987920",
    "commentBody": "Show HN: Hydra 1.0 – open-source column-oriented Postgres | Hacker NewsHacker News new | comments | ask | show | jobs | submitloginShow HN: Hydra 1.0 – open-source column-oriented Postgres (hydra-so.notion.site) 247 points by coatue 17 hours ago| 66 comments hi hn, hydra ceo herehydra is an open source, column-oriented postgres. you can set up remarkably fast aggregates on your project in minutes to query billions of rows instantly.postgres is great, but aggregates can take minutes to hours to return results on large data sets. long-running analytical queries hog database resources and degrade performance. use hydra to run much faster analytics on postgres without making code changes. data is automatically loaded into columnar format and compressed. connect to hydra with your preferred postgres client (psql, dbeaver, etc).following 4 months of development on hydra v0.3.0-alpha, our team is proud to share our first major version release. hydra 1.0 is under active development, but ready for use and feedback. we’re aiming to release 1.0 into general availability (ga) soon.for testing, try the hydra free tier to create a column-oriented postgres instance on the cloud. https:&#x2F;&#x2F;dashboard.hydra.so&#x2F;signup qeternity 1Ok so this is a Citus fork.Where can I read about what the differences &#x2F; trade offs are? I don’t see anything in the docs. reply pella 1Congratulations!Can we expect support for gist, gin, spgist, and brin indexes sometime in the near future?Based on the source code, it appears that they are not supported:https:&#x2F;&#x2F;github.com&#x2F;hydradatabase&#x2F;hydra&#x2F;blob&#x2F;96056312e7c0f413...\"... Columnar supports `btree` and `hash `indexes (and the constraints requiring them) but does not support `gist`, `gin`, `spgist` and `brin` indexes.\" reply nerdponx 1Do different kinds of indexes work better for columnar storage? Or is it the same principles for both? reply hodgesrm 1Difference principles of indexing, as least based on my experience with ClickHouse.* Column-based stores have really fast scans due to compression and vectorization, so you&#x27;ll generally always read down the column. The way to speed it up is to have \"skip indexes\" that allow you to skip blocks, e.g., don&#x27;t even bother to read&#x2F;decompress them.* Commonly used indexes need to be very sparse, so they fit in memory even when tables run to hundreds of billions of rows.* Finally highly compressed columns can be used as indexes to filter data rapidly. ClickHouse calls this PREWHERE processing.Edit: clarify skip indexes reply pella 1We need a spatial index for spatial (columnar) data!- https:&#x2F;&#x2F;www.crunchydata.com&#x2F;blog&#x2F;the-many-spatial-indexes-of...- http:&#x2F;&#x2F;postgis.net&#x2F;workshops&#x2F;postgis-intro&#x2F;indexing.html- Spatial indexes for OSM in PostGIS (PDF) : https:&#x2F;&#x2F;pretalx.com&#x2F;media&#x2F;sotm2019&#x2F;submissions&#x2F;CAD93S&#x2F;resour... reply mlenhard 1Congrats on the launch!For those who have not experimented with columnar based databases, I would highly recommend toying around with them.The performance improvements can be substantial. Obviously there are drawbacks involved with integrating a new database into your infrastructure, so it is exciting to see columnar format introduced to Postgres. Removes the hurdle of learning, deploying and monitoring another database. reply ryanb_wise 1Talked to OP last night and played around with it this morning. This is something I&#x27;ve wanted to see added to postgres for a long time, and couldn&#x27;t have been done by a nicer and more accommodating founder. Very excited. reply therealwardo 1how does Hydra compare to Citus? https:&#x2F;&#x2F;www.citusdata.com reply jerrysievert 1generally faster across the board, a lot of work was done to expand and speed it up, plus updates, deletes, and vacuuming.https:&#x2F;&#x2F;benchmark.clickhouse.com&#x2F;#eyJzeXN0ZW0iOnsiQXRoZW5hIC... reply rubiquity 1Since benchmarks can be misleading I want to point out that the differences between Hydra and the \"tuned\"[0] PostgreSQL (which are some very basic settings) are a lot less convincing, with plain old PG coming ahead on quite a few: https:&#x2F;&#x2F;tinyurl.com&#x2F;eju9tht2I also noticed quite a bit of parity between Hydra and Citus on data set size. Is Hydra a fork of Citus columnar storage?0 - https:&#x2F;&#x2F;github.com&#x2F;ClickHouse&#x2F;ClickBench&#x2F;blob&#x2F;main&#x2F;postgresq... reply arp242 1> plain old PG coming ahead on quite a fewI found that is common among these types of databases (e.g. Citus, Timescale, etc.) which perform well under very specific conditions, and worse for many (most?) other things, sometimes significantly worse.That said, Hydra does take up ~17.5G for that benchmark and \"PostgreSQL tuned\" about 120G, the insert time is ~9 times faster, and \"cold run\" is quite a bit faster too. It&#x27;s only \"hot run\" that shows a fairly small difference. I think it&#x27;s fair to say Hydra \"wins\" that benchmark.> Is Hydra a fork of Citus columnar storage?Yes: \"Hydra Columnar is a fork from Citus Columnar c. April, 2022\". reply riku_iki 1> Hydra does take up ~17.5G for that benchmark and \"PostgreSQL tuned\" about 120Gyou can run pg on compressed filesystem reply arp242 1I&#x27;m sure you can, but AFAIK neither uses compression in that benchmark so it&#x27;s a fair comparison. Even if filesystem compression would reduce that to 17.5G (doubtable), it won&#x27;t be free in terms of CPU cycles, and no matter what it&#x27;s still ~120G to load in memory, bytes to scan&#x2F;update, etc. reply riku_iki 1my bet is that hydra uses compression inside already, otherwise it is hard to explain where difference comes from.> it won&#x27;t be free in terms of CPU cyclesit can reduce IO traffic significantly, and it can be very positive trade off depending on circumstances. reply arp242 1I had assumed that PostgreSQL is so much larger because it creates heaps of indexes (which is probably also why inserts are so much slower for it), but I don&#x27;t really have a good way to confirm that quickly. reply riku_iki 1one can choose to not create \"heaps of indexes\". reply arp242 1At which point your performance will drop like a brick for these types of queries – I&#x27;m pretty sure these indexes weren&#x27;t added for the craic. reply riku_iki 1it depends on your query obviously.In general, I did very deep benchmarking of pg, clickhouse and duckdb, and I sure didn&#x27;t make stupid mistakes like this: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36990831My dataset has 50B rows and 2tb of data, and I think columnar dbs are very overhiped and I chose pg because:- pg performance is acceptable, maybe 2-5x times slower than clickhouse and duckdb on some queries if pg is configured correctly and run on compressed storage- clickhouse and duckdb start falling apart very fast because they specialized on very narrow type of queries: https:&#x2F;&#x2F;github.com&#x2F;ClickHouse&#x2F;ClickHouse&#x2F;issues&#x2F;47520 https:&#x2F;&#x2F;github.com&#x2F;ClickHouse&#x2F;ClickHouse&#x2F;issues&#x2F;47521 https:&#x2F;&#x2F;github.com&#x2F;duckdb&#x2F;duckdb&#x2F;discussions&#x2F;6696 reply arp242 \"2-5x times slower\" can mean the difference from 2 seconds to 4 to 10 seconds. Two seconds is still (barely) acceptable for interactive usage, ten seconds: not so much. You&#x27;re also going to need less beefy servers, or fewer servers.I also \"just\" use PostgreSQL for all of this by the way, but the limitations are pretty obvious. You&#x27;re much more limited in what you can query with good performance, unless you start creating tons of queries or pre-computed data and such, which have their own trade-offs. Columnar DBs are \"overhyped\" in the sense that everything in programming seems to be, but they do exist for good reasons (the reason I don&#x27;t use it are because they also come with their own set of downsides, as well as just plain laziness). reply zX41ZdbW 1ClickHouse can do large GROUP BY queries, not limited by memory: https:&#x2F;&#x2F;clickhouse.com&#x2F;docs&#x2F;en&#x2F;sql-reference&#x2F;statements&#x2F;sele... reply riku_iki 1as explained in https:&#x2F;&#x2F;github.com&#x2F;ClickHouse&#x2F;ClickHouse&#x2F;issues&#x2F;47521#issuec... it can&#x27;t, that parameters only applies on pre aggregation phase but not aggregation.Feature request is not implemented yet: https:&#x2F;&#x2F;github.com&#x2F;ClickHouse&#x2F;ClickHouse&#x2F;issues&#x2F;40588 reply benn0 Do you have happen to have any documentation about your benchmarking? I&#x27;m also considering these options at the moment (currently using pg+timescaledb) and interested in what you found. reply riku_iki I don&#x27;t have documentation.I just created large tables, and tried to join, group by, sort them in pg, clickhouse, duckdb, looked what failed or being slow, and tried to resolve it.I am happy to answer specific questions, but I didn&#x27;t use timescaledb. reply riku_iki 1> 0 - https:&#x2F;&#x2F;github.com&#x2F;ClickHouse&#x2F;ClickBench&#x2F;blob&#x2F;main&#x2F;postgresq...that postgres config is very underpowered, it has only 8 workers per gather while machine has 192 vcpus. reply re-thc Submit a PR? reply adr1an 1Right when I was thinking URL shorteners were out of fashion... &#x2F;S reply biugbkifcjk 1It&#x27;s just there to make it easier for mobile users to click it.. reply setr 1I don’t see why the GitHub link is any harder to click than the tiny url link in that post.I’m pretty sure the only reason url shorteners exist with purpose is because of Twitter limits (and software that doesn’t visually hide egregiously long urls), but continues to be used outside of those places due to cargo culting replyhgimenez 1Always awesome to see folks moving Postgres forward. Congrats on the launch! reply edublancas 1Congrats on the 1.0 milestone!A few months ago, we worked with the team to bring Hydra to Jupyter, you can check out the tutorial here: https:&#x2F;&#x2F;docs.hydra.so&#x2F;analyze&#x2F;jupyterJupySQL&#x27;s GitHub: https:&#x2F;&#x2F;github.com&#x2F;ploomber&#x2F;jupysql reply coatue 1Nice and thanks @edublancas, that was a useful tutorial and it&#x27;s nice to be able to query hydra with SQL via Jupyter. fan of your project reply KingOfCoders How does it compare to Timescaledb? Performance? Features? (TSDB is my current Postgres data lake setup) reply techwizrd 1This looks really impressive, and I&#x27;m excited to see how it performs on our data!P.S., I think the name conflicts with Hydra, the configuration management library: https:&#x2F;&#x2F;hydra.cc&#x2F; reply entuno 1And also the password bruteforcing tool by THC. reply notpushkin 1Also with the OIDC server by Ory [1] and a certain defunct Russian darknet marketplace [2].[1]: https:&#x2F;&#x2F;www.ory.sh&#x2F;hydra&#x2F;[2]: Not today, tovarisch mayor. reply chrisjc 1Very out of touch with Postgres, but is there a native column oriented table type option in Postgres so that you choose either row-based or columnar in the CREATE TABLE DDL? reply btown 1I don&#x27;t believe Postgres has this natively, but an alternative to OP is Citus, a Postgres extension which allows this kind of syntax.https:&#x2F;&#x2F;www.citusdata.com&#x2F;blog&#x2F;2021&#x2F;03&#x2F;06&#x2F;citus-10-columnar-...EDIT: per another comment, OP is a fork of Citus Columnar! reply dikei For a Postgres extension, there&#x27;s a strangely lack of documentation on how to add Hydra to an existing PG installation. reply joshgray 1Congrats to the entire Hydra team on the launch! We (Artemis - https:&#x2F;&#x2F;www.artemisdata.io&#x2F;) are stoked to be build with you as a partner to help data teams analyze data even faster! reply zhendlin 1awesome project - and we tested Zing Data ( http:&#x2F;&#x2F;www.zingdata.com ) with Hydra to make really fast analytical queries on postgres scale to analytics users on mobile and so far have seen great results. reply florianherrengt 1Can you add the extension to an existing database? reply ahmedfromtunis That&#x27;s also my question. Couldn&#x27;t find anything for it in the docs provided.Also, how to migrate data from an existing database? (Is it the usual pg_dump&#x2F;psql combo?) reply mch82 Is hydra compatible with the PostGIS extension? reply say_it_as_it_is 1Hydra Columnar is a fork from Citus Columnar c. April, 2022. reply thih9 1Citus: https:&#x2F;&#x2F;github.com&#x2F;citusdata&#x2F;citusBTW, Citus license is GNU Affero General Public License (github lists “conditions: same license”) and hydra is Apache. How is that possible if the latter is a fork? There’s probably something about these licenses I’m not aware of and I’m curious. reply jerrysievert 1hydra columnar inherits its license from citus: https:&#x2F;&#x2F;github.com&#x2F;hydradatabase&#x2F;hydra&#x2F;blob&#x2F;main&#x2F;columnar&#x2F;LI...but, hydra itself is more than just the columnar extension. reply thih9 1Thanks for explaining. This is confusing to me as a github user, i.e. if I saw a license in the project’s description, I wouldn’t expect another license in a subdirectory.Github now has UI for repos with multiple licenses: https:&#x2F;&#x2F;github.blog&#x2F;changelog&#x2F;2022-05-26-easily-discover-and... , that would have been clearer for me. reply mitchpatin 1super impressive performance improvements!do most of your customers replicate their postgres database to Hydra for analytics jobs, or what&#x27;s the typical set up? reply burcs 1This is really cool, just played around with it a bit but excited to do a deeper dive later. Nice work guys! reply coatue 1Thanks! feel free to DM me in the hydra discord (or email) anytime reply s-mon 1This looks wild! Been looking for a good event based logs DB and didn’t want to go full clickhouse. This will do! reply quadrature 1How are updates handled, is it doing a merge on read ? reply wuputah First we added a bitmask to mark rows as deleted - these rows are filtered out on read. Then updates are implemented as deletions + inserts. We have also added vacuum functions to remove&#x2F;rewrite stripes that have >20% of deleted rows in order to reclaim space and optimize those stripes. reply zrizavi17 1Such a game changer and useful alternative to legacy databases! reply mdaniel 1I wanted to say thank you for using actual Open Source licenses. It&#x27;s gotten to where I treat any recent \"Launch HN\" or \"Show HN\" containing \"open source\" in the title as \"well, I wonder which crazy license this project is using\" reply dang 1Can you point me to examples of Launch HNs using funky licenses? Show HNs are free-form but Launch HNs are curated by us, and I&#x27;d like to know what red flags to watch for.(As this is offtopic for the current Show HN, it might be better for to email hn@ycombinator.com if you, or anyone, would be willing to share that way.) reply mdaniel 1I sent email to avoid being a distraction, but I did want to follow up publicly and say that I apologize for lumping Launch HN into the same bucket as Show HN. For the most part the Launch ones are really Open Source and I apologize for the over generalization :-( reply afeiszli Really cool! reply carlod 1Congrats guys! reply ushakov 1Are you funded? reply coatue 1Check out the \"about us\" section on the page for more details! \"We are excited to share that Hydra raised a $3.1M seed round to drive development of columnar Postgres. We remain committed to sharing our upcoming releases to open source.\" reply wrowan33 1Congrats on the success! reply pajep 1can I ask if you guys take contributors? reply wuputah of course :) drop by our Discord if there&#x27;s something you&#x27;d like to contribute and want to chat about it beforehand, need help&#x2F;have questions getting started, etc. https:&#x2F;&#x2F;hydra.so&#x2F;discord reply Iwan-Zotow 1prev [–] > to query billions of rows instantlyRows? Rows?!? What&#x27;s the point to have columnar DB to query rows? reply ithkuil 1parent [–] Columnar DBs often allow you to have tables consisting of multiple columns where values in a column are correlated with values in the other columns. All such correlated values belonging to different columns are commonly called a \"row\" despite not being stored contiguously.Generally what you do is to scan a column and evaluate a predicate in each value you encounter during the scan (possibly in parallel). For each value of that column that matches the predicate you then keep track of the \"position\" of the value in the column (a common technique is sparse set data structure such as for example a roaring bitmap). Then you scan through another column and select values for the saved \"positions\".As you can see, it&#x27;s not a stretch to view values from different columns that belong to the same \"position\" as belonging to the same \"row\" and the \"position\" to be the \"row index\" or \"row id\" reply",
    "originSummary": [
      "Hydra is an open-source, column-oriented version of Postgres designed to handle large datasets and enable fast aggregation of data.",
      "Analytical queries on Postgres can be time-consuming and resource-intensive, but Hydra eliminates these issues.",
      "The latest version, Hydra 1.0, is available for users to try out and provide feedback, with a full release planned in the near future. A free tier on the cloud allows users to explore Hydra's capabilities."
    ],
    "commentSummary": [
      "Hydra 1.0 is an open-source, column-oriented version of Postgres designed for faster aggregates and queries on large datasets.",
      "It automatically loads data into a columnar format, supports compression, and is compatible with popular Postgres clients.",
      "The project is planning to release version 1.0 soon and offers a free tier for users to try it out.",
      "Comparisons between Hydra and other columnar storage options like Citus have sparked discussions on performance and benefits.",
      "The passage also introduces the concept of tables with multiple columns and suggests using a sparse set data structure for evaluating predicates and tracking matching values in columns."
    ],
    "points": 247,
    "commentCount": 66,
    "retryCount": 0,
    "time": 1691079547
  }
]
