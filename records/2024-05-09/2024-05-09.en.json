[
  {
    "id": 40298927,
    "title": "AlphaFold 3 Revolutionizes Molecular Structure Prediction",
    "originLink": "https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/",
    "originBody": "AI AlphaFold 3 predicts the structure and interactions of all of life’s molecules May 08, 2024 6 min read Share Twitter Facebook LinkedIn Mail Copy link Introducing AlphaFold 3, a new AI model developed by Google DeepMind and Isomorphic Labs. By accurately predicting the structure of proteins, DNA, RNA, ligands and more, and how they interact, we hope it will transform our understanding of the biological world and drug discovery. G Google DeepMind AlphaFold team I Isomorphic Labs Share Twitter Facebook LinkedIn Mail Copy link In this story In this story Revealing life’s molecules Leading drug discovery Introducing AlphaFold Server Sharing responsibly Future of AI-powered cell biology Inside every plant, animal and human cell are billions of molecular machines. They’re made up of proteins, DNA and other molecules, but no single piece works on its own. Only by seeing how they interact together, across millions of types of combinations, can we start to truly understand life’s processes. In a paper published in Nature, we introduce AlphaFold 3, a revolutionary model that can predict the structure and interactions of all life’s molecules with unprecedented accuracy. For the interactions of proteins with other molecule types we see at least a 50% improvement compared with existing prediction methods, and for some important categories of interaction we have doubled prediction accuracy. We hope AlphaFold 3 will help transform our understanding of the biological world and drug discovery. Scientists can access the majority of its capabilities, for free, through our newly launched AlphaFold Server, an easy-to-use research tool. To build on AlphaFold 3’s potential for drug design, Isomorphic Labs is already collaborating with pharmaceutical companies to apply it to real-world drug design challenges and, ultimately, develop new life-changing treatments for patients. Our new model builds on the foundations of AlphaFold 2, which in 2020 made a fundamental breakthrough in protein structure prediction. So far, millions of researchers globally have used AlphaFold 2 to make discoveries in areas including malaria vaccines, cancer treatments and enzyme design. AlphaFold has been cited more than 20,000 times and its scientific impact recognized through many prizes, most recently the Breakthrough Prize in Life Sciences. AlphaFold 3 takes us beyond proteins to a broad spectrum of biomolecules. This leap could unlock more transformative science, from developing biorenewable materials and more resilient crops, to accelerating drug design and genomics research. 7PNM - Spike protein of a common cold virus (Coronavirus OC43): AlphaFold 3’s structural prediction for a spike protein (blue) of a cold virus as it interacts with antibodies (turquoise) and simple sugars (yellow), accurately matches the true structure (gray). The animation shows the protein interacting with an antibody, then a sugar. Advancing our knowledge of such immune-system processes helps better understand coronaviruses, including COVID-19, raising possibilities for improved treatments. How AlphaFold 3 reveals life’s molecules Given an input list of molecules, AlphaFold 3 generates their joint 3D structure, revealing how they all fit together. It models large biomolecules such as proteins, DNA and RNA, as well as small molecules, also known as ligands — a category encompassing many drugs. Furthermore, AlphaFold 3 can model chemical modifications to these molecules which control the healthy functioning of cells, that when disrupted can lead to disease. AlphaFold 3’s capabilities come from its next-generation architecture and training that now covers all of life’s molecules. At the core of the model is an improved version of our Evoformer module — a deep learning architecture that underpinned AlphaFold 2’s incredible performance. After processing the inputs, AlphaFold 3 assembles its predictions using a diffusion network, akin to those found in AI image generators. The diffusion process starts with a cloud of atoms, and over many steps converges on its final, most accurate molecular structure. AlphaFold 3’s predictions of molecular interactions surpass the accuracy of all existing systems. As a single model that computes entire molecular complexes in a holistic way, it’s uniquely able to unify scientific insights. 7R6R - DNA binding protein: AlphaFold 3’s prediction for a molecular complex featuring a protein (blue) bound to a double helix of DNA (pink) is a near-perfect match to the true molecular structure discovered through painstaking experiments (gray). Leading drug discovery at Isomorphic Labs AlphaFold 3 creates capabilities for drug design with predictions for molecules commonly used in drugs, such as ligands and antibodies, that bind to proteins to change how they interact in human health and disease. AlphaFold 3 achieves unprecedented accuracy in predicting drug-like interactions, including the binding of proteins with ligands and antibodies with their target proteins. AlphaFold 3 is 50% more accurate than the best traditional methods on the PoseBusters benchmark without needing the input of any structural information, making AlphaFold 3 the first AI system to surpass physics-based tools for biomolecular structure prediction. The ability to predict antibody-protein binding is critical to understanding aspects of the human immune response and the design of new antibodies — a growing class of therapeutics. Using AlphaFold 3 in combination with a complementary suite of in-house AI models, Isomorphic Labs is working on drug design for internal projects as well as with pharmaceutical partners. Isomorphic Labs is using AlphaFold 3 to accelerate and improve the success of drug design — by helping understand how to approach new disease targets, and developing novel ways to pursue existing ones that were previously out of reach. AlphaFold Server: A free and easy-to-use research tool 8AW3 - RNA modifying protein: AlphaFold 3’s prediction for a molecular complex featuring a protein (blue), a strand of RNA (purple), and two ions (yellow) closely matches the true structure (gray). This complex is involved with the creation of other proteins — a cellular process fundamental to life and health. Google DeepMind’s newly launched AlphaFold Server is the most accurate tool in the world for predicting how proteins interact with other molecules throughout the cell. It is a free platform that scientists around the world can use for non-commercial research. With just a few clicks, biologists can harness the power of AlphaFold 3 to model structures composed of proteins, DNA, RNA and a selection of ligands, ions and chemical modifications. AlphaFold Server helps scientists make novel hypotheses to test in the lab, speeding up workflows and enabling further innovation. Our platform gives researchers an accessible way to generate predictions, regardless of their access to computational resources or their expertise in machine learning. Experimental protein-structure prediction can take about the length of a PhD and cost hundreds of thousands of dollars. Our previous model, AlphaFold 2, has been used to predict hundreds of millions of structures, which would have taken hundreds of millions of researcher-years at the current rate of experimental structural biology. With AlphaFold Server, it’s not only about predicting structures anymore, it’s about generously giving access: allowing researchers to ask daring questions and accelerate discoveries. Céline Bouchoux The Francis Crick Institute 10:25 Sharing the power of AlphaFold 3 responsibly With each AlphaFold release, we’ve sought to understand the broad impact of the technology, working together with the research and safety community. We take a science-led approach and have conducted extensive assessments to mitigate potential risks and share the widespread benefits to biology and humanity. Building on the external consultations we carried out for AlphaFold 2, we’ve now engaged with more than 50 domain experts, in addition to specialist third parties, across biosecurity, research and industry, to understand the capabilities of successive AlphaFold models and any potential risks. We also participated in community-wide forums and discussions ahead of AlphaFold 3’s launch. AlphaFold Server reflects our ongoing commitment to share the benefits of AlphaFold, including our free database of 200 million protein structures. We’ll also be expanding our free AlphaFold education online course with EMBL-EBI and partnerships with organizations in the Global South to equip scientists with the tools they need to accelerate adoption and research, including on underfunded areas such as neglected diseases and food security. We’ll continue to work with the scientific community and policy makers to develop and deploy AI technologies responsibly. Opening up the future of AI-powered cell biology 7BBV - Enzyme: AlphaFold 3’s prediction for a molecular complex featuring an enzyme protein (blue), an ion (yellow sphere) and simple sugars (yellow), along with the true structure (gray). This enzyme is found in a soil-borne fungus (Verticillium dahliae) that damages a wide range of plants. Insights into how this enzyme interacts with plant cells could help researchers develop healthier, more resilient crops. AlphaFold 3 brings the biological world into high definition. It allows scientists to see cellular systems in all their complexity, across structures, interactions and modifications. This new window on the molecules of life reveals how they’re all connected and helps understand how those connections affect biological functions — such as the actions of drugs, the production of hormones and the health-preserving process of DNA repair. The impacts of AlphaFold 3 and our free AlphaFold Server will be realized through how they empower scientists to accelerate discovery across open questions in biology and new lines of research. We’re just beginning to tap into AlphaFold 3’s potential and can’t wait to see what the future holds. POSTED IN: AI Research",
    "commentLink": "https://news.ycombinator.com/item?id=40298927",
    "commentBody": "AlphaFold 3 predicts the structure and interactions of life's molecules (blog.google)933 points by zerojames 18 hours agohidepastfavorite405 comments lysozyme 14 hours agoProbably worth mentioning that David Baker’s lab released a similar model (predicts protein structure along with bound DNA and ligands), just a couple of months ago, and it is open source [1]. It’s also worth remembering that it was David Baker who originally came up with the idea of extending AlphaFold from predicting just proteins to predicting ligands as well [2]. 1. https://github.com/baker-laboratory/RoseTTAFold-All-Atom 2. https://alexcarlin.bearblog.dev/generalized/ Unlike AlphaFold 3, which predicts only a small, preselected subset of ligands, RosettaFold All Atom predicts a much wider range of small molecules. While I am certain that neither network is up to the task of designing an enzyme, these are exciting steps. One of the more exciting aspects of the RosettaFold paper is that they train the model for predicting structures, but then also use the structure predicting model as the denoising model in a diffusion process, enabling them to actually design new functional proteins. Presumably, DeepMind is working on this problem as well. reply refulgentis 11 hours agoparentI appreciated this, but it's probably worth mentioning: when you say AlphaFold 3, you're talking about AlphaFold 2. TFA announces AlphaFold 3. Post: \"Unlike AlphaFold 3, which predicts only a small, preselected subset of ligands, RosettaFold All Atom predicts a much wider range of small molecules\" TFA: \"AlphaFold 3...*models large biomolecules such as proteins, DNA and RNA*, as well as small molecules, also known as ligands\" Post: \"they also use the structure predicting model as the denoising model in a diffusion process...Presumably, DeepMind is working on this problem as well.\" TFA: \"AlphaFold 3 assembles its predictions using a diffusion network, akin to those found in AI image generators.\" reply theGnuMe 13 hours agoparentprevAnd that tech just got $1b in funding. reply hackernewds 3 hours agoparentprevComing up with ideas is cheaper than executing the ideas. Predicting a wide range of molecules okay-ish is cheaper than predicting a small range of molecules very well. reply nybsjytm 17 hours agoprevImportant caveat: it's only about 70% accurate. Why doesn't the press release say this explicitly? It seems intentionally misleading to only report accuracy relative to existing methods, which apparently are just not so good (30%, 50% in various settings). https://www.fastcompany.com/91120456/deepmind-alphafold-3-dn... reply porphyra 4 hours agoparentThey also had a headline for Alphazero that convinced everyone that they crushed Stockfish and that classical chess engines were stuff of the past, when in fact it was about 50 elo better than the Stockfish version they were testing against, or roughly the same as how much Stockfish improves each year. reply mda 6 minutes agorootparentAlphazero indeed crushed stockfish with a novel technique, I think it deserved all the praise. reply kriro 1 hour agorootparentprevI think Alphazero is a lot more interesting than Stockfish though. Most notably it lead me to reevaluate positional play. Iirc A0 at around 2-3 ply is still above SuperGM Level which is pretty mind-blowing. Based on this I have increased my strategy to tactics ratio quite a bit. FWIW Stockfish is always evolving and adapting and has incorporated ideas from A0. reply RUnconcerned 1 hour agorootparentStockfish has not incorporated ideas from AlphaZero. Stockfish's NN eval technology, NNUE, comes from Shogi and it predates Alphazero there. The 2nd strongest engine, Leela Chess Zero, is indeed directly inspired by AlphaZero, though, and did surpass Stockfish until NNUE was introduced. reply thom 2 hours agorootparentprevAnd then what happened is AlphaZero changed the professional game in various interesting ways, and all its ideas were absorbed into Stockfish. A little bombast is forgivable for technology that goes on to have a big impact, and I don’t doubt it’s the same story here. reply hereme888 8 hours agoparentprevThat's what I thought. They go from \"predicting all of life's molecules\" to \"it's a 50% improvement...and we HOPE to...transform drug discovery...\" Seems unfortunately typical of Google these days: \"Gemini will destroy GPT-4...\" reply Aunche 15 hours agoparentprevIIRC the next best models all have all been using AlphaFold 2's methodology, so that's still a massive improvement. Edit: I see now that you're probably objecting to the headline that got edited on HN. reply nybsjytm 15 hours agorootparentNot just the headline, the whole press release. And not questioning that it's a big improvement. reply bluerooibos 16 hours agoparentprevThat's pretty good. Based on the previous performance improvements of Alpha-- models, it'll be nearing 100% in the next couple of years. reply akira2501 15 hours agorootparent> it'll be nearing 100% in the next couple of years. What are you basing this on? There is no established \"moores law\" for computational models. reply OrigamiPastrami 10 hours agorootparentIt's the internet. There is no source more cited than \"trust me bro\" reply nybsjytm 15 hours agorootparentprevJust \"Alpha-- models\" in general?? That's not a remotely reasonable way to reason about it. Even if it were, why should it stop DeepMind from clearly communicating accuracy? reply dekhn 15 hours agorootparentThe way I think about this (specifically, deepmind not publishing their code or sharing their exact experimental results): advanced science is a game played by the most sophisticated actors in the world. Demis is one of those actors, and he plays the games those actors play better than anybody else I've ever seen. Those actors don't care much about the details of any specific system's accuracy: they care to know that it's possible to do this, and some general numbers about how well it works, and some hints what approaches they should take. And Nature, like other top journals, is more than willing to publish articles like this because they know it stimulates the most competitive players to bring their best games. (I'm not defending this approach, just making an observation) reply nybsjytm 15 hours agorootparentI think it's important to qualify that the relevant \"game\" is not advanced science per se; the game is business whose product is science. The aim isn't to do novel science; it's to do something which can be advertised as novel science. That isn't to cast aspersions on the personal motivations of Hassabis or any other individual researcher working there (which itself isn't to remove their responsibilities to public understanding); it's to cast aspersions on the structure that they're part of. And it's not to say that they can't produce novel or important science as part of their work there. And it's also not to say that the same tension isn't often present in the science world - but I think it's present to an extreme degree at DeepMind. (Sometimes the distinction between novel science and advertisably novel science is very important, as seems to be the case in the \"new materials\" research dopylitty linked to in these comments: here https://www.404media.co/google-says-it-discovered-millions-o...) reply moomin 2 hours agorootparentprevAnyone remember how he marketed his computer games? reply 7734128 14 hours agorootparentprevI'm quite hyped for the upcoming BetaFold, or even ReleaseCandidateFold models. They just have to be great. reply tsimionescu 3 hours agorootparentprevWhich specific AlphaX model evolved like that? Most of the ones that were in the press had essentially a single showing, typically very good, but didn't really improve after that. reply uptownfunk 16 hours agoprevVery sad to see they did not make it open source. When you have a technology that has the potential to be a gateway for drug development, to the cures of new diseases, and instead you choose to make it closed, it is a very huge disservice to the community at large. Sure, release your own product alongside it, but making it closed source does not help the scientific community upon which all these innovations were built. Especially if you have lost a loved one to a disease which this technology will one day be able to create cures for, it is very disappointing. reply falcor84 13 hours agoparentThe closer it gets to enabling full drug discovery, the closer it also gets to enabling bioterrorism. Taking it to the extreme, if they had the theory of everything, I don't think I'd want it to be made available to the whole world as it is today. On a related note, I highly recommend The Talos Principle 2, which really made me think about these questions. reply pythonguython 12 hours agorootparentAny organization/country that has the ability to use a tool like this to create a bio weapon is already sophisticated enough to do bioterrorism today. reply ramon156 11 hours agorootparentAlright, but now picture this: it's now open to the masses, meaning an individual could probably even do it. reply tsimionescu 3 hours agorootparentThe problem of producing bio weapons is not computational, it's physical in nature. Even if predictions from these tools become 100% accurate and encompassed 100% of the chemistry, you still need to actually do the manual steps to breed the bioagents. And, very importantly, you need to do so without getting you and your co-workers deadly ill long before finishing the thing. Which requires extremely sophisticated machinery. Alternatively, you can go today in some of the poorer corners of the world, find some people with drug resistant tuberculosis, pay them a pittance to give you bodily fluids, and disperse those in a large crowd, say at a concert or similar. You'll get a good chunk of the effects of the worse possible bioterrorism. reply hackernewds 3 hours agorootparentThese are very specific ideas you have.. reply BriggyDwiggs42 2 hours agorootparentIt’s very frustrating when people consider the possession of information equivalent to malice. It suggests that the right way to run society is to keep people stupid and harmless. reply baq 3 hours agorootparentprevThese are ideas you should read and think about because intelligence agencies all over the world have been thinking about them for the past hundred years. reply pythonguython 10 hours agorootparentprevI hear you, but I don't think an individual can. If I gave you $20,000 and an open source 70% accurate protein folding model and told you to develop, mass produce, and develop a deployment mechanism for a highly infectious and deadly pathogen, I don't think you could make that happen. Nor do I think you could do it if you had a PhD in microbiology. reply bongodongobob 7 hours agorootparentright now reply uptownfunk 11 hours agorootparentprevThe risks don't exceed what is already out there. If someone wants to do damage, especially in America, there are more than enough ways they can do it already. The technology should be made free. I also wonder how much the claims are being exaggerated and are marketing-speak vs. real results. Is there any benchmark for this that they have published? reply bongodongobob 7 hours agorootparentNo. I love to be egalitarian as well but this AI thing really feels different. We didn't just invent a better plow or a more durable sword. We're working on making a better brain. I think social media shows us a pretty good slice of the average person and it's not great. Now imagine they can manipulate the smartest person in the world to do dangerous, dumb shit. reply consumer451 9 hours agorootparentprevYou raise an extremely important point. It appears to me that most people do not understand the implications of your point. Organized terrorism by groups is actually extremely rare. What is much less rare are mass shootings in the USA, by deranged individuals. What would a psychopathic mass shooter type choose as a weapon if he not only had access to semi-automatic weapons, but now we added bio-weapons to the menu? It seems very clear to me that when creating custom viruses becomes high school level knowledge, and the tools can be charged on a credit card, nuclear weapons will be relegated to the second most likely way that our human civilization will end. I believe the two concepts being brought together here are the Law of Large Numbers, and the sudden ability for one single human to kill at least millions. reply tsimionescu 3 hours agorootparent> It seems very clear to me that when creating custom viruses becomes high school level knowledge That would be very bad indeed, but there is no path from AI to that. Making custom viruses is never going to be an easy task even if you had a magic machine that could explain the effects of adding any chemical to the mix. You still need to procure the chemicals and work with them in very careful ways, often for a long time, in a highly controlled environment. It's still biology lab work, even if you know exactly what you have to do. Also, bioweapons already exist and have been used in a few conflicts, even as recently as WWII. They're terrifying in many ways, but are not really comparable to the horror of nuclear weapons hitting major cities. reply LouisSayers 11 hours agorootparentprevWhy do you need AI for bioterrorism? There are plenty of well known biological organisms that can kill us today... reply datadeft 1 hour agorootparentprevWhy on Earth would any terrorist want to invest into this when you can just purchase guns and explosives much easier? reply BriggyDwiggs42 10 hours agorootparentprevOh please, like a terrorist cant fork over a couple bucks to do the bioterrorism. This excuse is utter bs, whether its applied to LLMs or to alphafold. The motivator is profit, not safety. reply robertlagrant 1 hour agoparentprev> the community at large Which community? Not any I'm part of. reply renonce 18 hours agoprev> What is different about the new AlphaFold3 model compared to AlphaFold2? > AlphaFold3 can predict many biomolecules in addition to proteins. AlphaFold2 predicts structures of proteins and protein-protein complexes. AlphaFold3 can generate predictions containing proteins, DNA, RNA, ions,ligands, and chemical modifications. The new model also improves the protein complex modelling accuracy. Please refer to our paper for more information on performance improvements. AlphaFold 2 generally produces looping “ribbon-like” predictions for disordered regions. AlphaFold3 also does this, but will occasionally output segments with secondary structure within disordered regions instead, mostly spurious alpha helices with very low confidence (pLDDT) and inconsistent position across predictions. So the criticism towards AlphaFold 2 will likely still apply? For example, it’s more accurate for predicting structures similar to existing ones, and fails at novel patterns? reply dekhn 18 hours agoparentI am not aware of anybody currently criticiszing AF2's abilities outside of its training set. In fact the most recent papers (written by crystallographers) they are mostly arguing about atomic-level details of side chains at this point. reply COGlory 18 hours agoparentprev>So the criticism towards AlphaFold 2 will likely still apply? For example, it’s more accurate for predicting structures similar to existing ones, and fails at novel patterns? Yes, and there is simply no way to bridge that gap with this technique. We can make it better and better at pattern matching, but it is not going to predict novel folds. reply flobosg 1 hour agorootparent> but it is not going to predict novel folds https://www.nature.com/articles/s42003-022-03357-1 reply dekhn 17 hours agorootparentprevalphafold has been shown to accurately predict some novel folds. The technique doesn't entirely depend on whole-domain homology. reply rolph 17 hours agoparentprevproblem is biomolecules, are \"chaperoned\" to fold properly, only specific regions such as, alpha helix, or beta pleatedsheet will fold de novo. Chaperone (protein) https://en.wikipedia.org/wiki/Chaperone_(protein) reply staticautomatic 4 hours agorootparentIn principle couldn’t we just incorporate knowledge about chaperones into the model? reply flobosg 48 minutes agorootparentIn a way it is already incorporated. Broadly speaking, chaperones function by restricting the available conformational sampling space for the protein to fold. Some researchers even consider the ribosome as a chaperone of sorts for the nascent protein chain it synthetizes. Protein structure prediction methods do the same: they find ways of restricting the conformational space to explore, in hopes of finding the global minimum-energy conformation representing the native structure of the protein. reply LarsDu88 15 hours agoprevAs a software engineer, I kind of feel uncomfortable about this new model. It outperforms Alphafold 2 at ligand binding, but Alphafold 2 also had some more hardcoded and interpretable structural reasoning baked into the model architecture. There's so many things you can incorporate into a protein folding model such as structural constraints, rotational equivariance, etc, etc This new model simple does away with some of that, achieving greater results. And the authors simply use distillation from data outputted from Alphafold2 and Alphafold2-multimer to get those better results for those cases where you wind up with implausible results. You have to run all those previous models, and output their predictions to do the distillation to achieve a real end-to-end training from scratch for this new model! Makes me feel a bit uncomfortable. reply sangnoir 15 hours agoparent> Makes me feel a bit uncomfortable. Why? Do compilers which can't bootstrap themselves also make you uncomfortable due to dependencies on pre-built artifacts? I'm not saying you're unjustified to feel that way, but sometimes more abstracted systems are quicker to build and may have better performance than those built from the ground up. Selecting which one is better depends on your constraints and taste reply arjvik 4 hours agorootparentCompilers are deterministic (for the most part, and it's incredibly rare to introduce a compiler bug that self-replicates in future compilers (unless you're Ken Thompson and are reflecting upon trust itself)). Alternatively, AlphaFold 2's output is noisy, and using that to train AlphaFold 3, which presumably may be used to train what becomes AlphaFold 4, results in a cascade of errors. reply amitport 15 hours agoparentprevConsider that humans also learn from other humans, and sometimes surpass their teachers. A bit more comfortable? reply Balgair 15 hours agorootparentAhh, but the new young master is able to explain their work and processes to the satisfaction of the old masters. In the 'Science' of our modern times it's a requirement to show your work (yes, yes, I know about the replication crisis and all that terrible jazz). Not being able to ascertain how and why the ML/AI is achieving results is not quite the same and more akin to the alchemists and sorcerers with their cyphers and hidden laboratories. reply falcor84 13 hours agorootparent> the new young master is able to explain their work and processes to the satisfaction of the old masters Yes, but it's one level deep - in general they wouldn't be able to explain their work to their master's master (note \"science advances one funeral at a time\"). reply hackerdood 9 hours agorootparentprevI’ll add that specially when it comes to playing go, professionals who are at the peak of their ability can often find the best move at a given point but be unable to explain why beyond “it feels right” or “it looks right”. reply mchinen 17 hours agoprevI am trying to understand how accurate the docking predictions are. Looking at the PoseBusters paper [1] they mention, they say they are 50% more accurate than traditional methods. DiffDock, which is the best DL based systems gets 30-70% depending on the dataset, and traditional gets 50-70%. The paper highlighted some issues with the DL-based methods and given that DeepMind would have had time to incorporate this into their work and develop with the PoseBusters paper in mind, I'd hope it's significantly better than 50-70%. They say 50% better than traditional so I expected something like 70-85% across all datasets. I hope a paper will appear soon to illuminate these and other details. [1] https://pubs.rsc.org/en/content/articlehtml/2024/sc/d3sc0418... reply gajnadsgjoas 2 hours agoprevCan someone tell me what are the direct implication of this? I often see \"helps with a drug design\" but I'm too far from this industry and have never seen an example of such drugs reply Syzygies 32 minutes agoparentWe're this much closer to being hacked? reply qwertox 17 hours agoprev> Thrilled to announce AlphaFold 3 which can predict the structures and interactions of nearly all of life’s molecules with state-of-the-art accuracy including proteins, DNA and RNA. [1] There's a slight mismatch between the blog's title and Demis Hassabis' tweet, where he uses \"nearly all\". The blog's title suggests that it's a 100% solved problem. [1] https://twitter.com/demishassabis/status/1788229162563420560 reply TaupeRanger 11 hours agoparentFirst time reading a Deep Mind PR? This is literally their modus operandi. reply bamboozled 9 hours agoparentprevHow to make the share price go up…surprised? reply bmau5 17 hours agoparentprevMarketing vs. Reality :) reply wuj 15 hours agoprevThis tool reminds me that the human body functions much like a black box. While physics can be modeled with equations and constraints, biology is inherently probabilistic and unpredictable. We verify the efficacy of a medicine by observing its outcomes: the medicine is the input, and the changes in symptoms are the output. However, we cannot model what happens in between, as we cannot definitively prove that the medicine affects only its intended targets. In many ways, much of what we understand about medicine is based on observing these black-box processes, and this tool helps to model that complexity. reply a_bonobo 5 hours agoparentClassic essay in this vein: >Can a biologist fix a radio? — Or, what I learned while studying apoptosis https://www.cell.com/cancer-cell/pdf/S1535-6108(02)00133-2.p... >However, if the radio has tunable components, such as those found in my old radio (indicated by yellow arrows in Figure 2, inset) and in all live cells and organisms, the outcome will not be so promising. Indeed, the radio may not work because several components are not tuned properly, which is not reflected in their appearance or their connections. What is the probability that this radio will be fixed by our biologists? I might be overly pessimistic, but a textbook example of the monkey that can, in principle, type a Burns poem comes to mind. In other words, the radio will not play music unless that lucky chance meets a prepared mind. reply bamboozled 9 hours agoparentprevI’d say it’s always been the case for medicine, when people first used medicines, the intention was never to fully understand what happens, just save a life, eliminate or reduce symptoms. Now we’ve built explainable systems like computers and software, we try to overlay that onto everything and it might not work. To quote Alan Watts, humans like to try square out wiggly systems because we’re not great and understanding wiggles. reply zmmmmm 11 hours agoprevSo much of the talk about their \"free server\" seems to be trying to distract from the fact that they are not releasing the model. I feel like it's an important threshold moment if this gets accepted into scientific use without the model being available - reproducibility of results becomes dependent on the good graces of a single commercial entity. I kind of hope that like OpenAI it just spurs creation of equivalent open models that then actually get used. reply tea-coffee 18 hours agoprevThis is a basic question, but how is the accuracy of the predicted biomolecular interactions measured? Are the predicted interactions compared to known interactions? How would the accuracy of predicting unknown interactions be assessed? reply joshuamcginnis 18 hours agoparentAccuracy can be assessed two main ways: computationally and experimentally. Computationally, they would compare the predicted structures and interactions with known data from databases like PDB (Protein Database). Experimentally, they can use tools like x-ray crystallography and NMR (nuclear magnetic resonance) to obtain the actual molecule structure and compare it to the predicted result. The outcomes of each approach would be fed back into the model for refining future predictions. https://www.rcsb.org/ reply dekhn 18 hours agorootparentAlphaFold very explicitly (unless something has changed) removes NMR structures as references because they are not accurate enough. I have a PhD in NMR biomolecular structure and I wouldn't trust. the structures for anything. reply JackFr 18 hours agorootparentSorry, I don’t mean to be dense - do you mean you don’t trust AlphaFolds structures or NMRs? reply dekhn 17 hours agorootparentI don't trust NMR structures in nearly all cases. The reasons are complex enough that I don't think it's worthwhile to discuss on Hacker News. reply fikama 17 hours agorootparentHmm, I would say its always worth to share knowledge. Could you paste some links or maybe type a few key-words for anyone willing to reasearch the topic further on his own. reply dekhn 16 hours agorootparentRead this, and recursively (breadth-first) read all its transitive references: https://www.sciencedirect.com/science/article/pii/S096921262... reply fabian2k 18 hours agorootparentprevLooking at the supplementary material (section 2.5.4) for the AlphaFold 3 paper it reads to me like they still use NMR structures for training, but not for evaluating performance of the model. reply dekhn 17 hours agorootparentI think it's implicit in their description of filtering the training set, where they say they only include structures with resolution of 9A or less. NMR structures don't really have a resolution, that's more specific to crystallography. However, I can't actually verify that no NMR structures were included without directly inspecting their list of selected structures. reply fabian2k 17 hours agorootparentI think it is very plausible that they don't use NMR structures here, but I was looking for a specific statement on it in the paper. I think your guess is plausible, but I don't think the paper is clear enough here to be sure about this interpretation. reply dekhn 17 hours agorootparentYes, thanks for calling that out. In verifying my statement I actually was confused because you can see they filter NMR out of the eval set (saying so explicitly) but don't say that in the test set section (IMHO they should be required to publish the actual selection script so we can inspect the results). reply fabian2k 17 hours agorootparentHmm, in the earlier AlphaFold 2 paper they state: > Input mmCIFs are restricted to have resolution less than 9 Å. This is not a very restrictive filter and only removes around 0.2% of structures NMR structures are more than 0.2% so that doesn't fit to the assumption that they implicitly remove NMR structures here. But if I filter by resolution on the PDB homepage it does remove essentially all NMR structures. I'm really not sure what to think here, the description seems too soft to know what they did exactly. reply panabee 13 hours agorootparentprevinteresting observation and experience. must have made thesis development complex, assuming the realization dawned on you during the phd. what do you trust more than NMR? AF's dependence on MSAs also seems sub-optimal; curious to hear your thoughts? that said, it's understandable why they used MSAs, even if it seems to hint at winning CASP more than developing a generalizable model. arguably, MSA-dependence is the wise choice for early prediction models as demonstrated by widespread accolades and adoption, i.e., it's an MVP with known limitations as they build toward sophisticated approaches. reply dekhn 12 hours agorootparentMy realizations happened after my PhD. When I was writing my PhD I still believed we would solve the protein folding and structure prediction problems using classical empirical force fields. It wasn't until I started my postdocs, where I started learning about protein evolutionary relationships (and competing in CASP), that I changed my mind. I wouldn't say it so much as \"multiple sequence alignments\"; those are just tools to express protein relationships in a structured way. If Alphafold now, or in the future, requires no evolutionary relationships based on sequence (uniprot) and can work entirely by training on just the proteins in PDB (many of which are evoutionarily related) and still be able to predict novel folds, it will be very interesting times. The one thing I have learned is that evolutionary knowledge makes many hard problems really easy, because you're taking advantage of billions of years of nature and an easy readout. reply heyoni 11 hours agorootparentprevNice to see you on this thread as well! :) reply itissid 13 hours agoprevNoob here. Can one make the following deduction: In transformer based architectures, where one typically uses variation of attention mechanism to model interactions, even if one does not consider the autoregressive assumption of the domain's \"nodes\"(amino acids, words, image patches), if the number of final states that nodes take eventually can be permuted only in a finite way(i.e. they have sparse interactions between them), then these architectures are efficient way of modeling such domains. In plain english the final state of words in a sentence and amino acids in a protein have only so many ways they can be arranged and transformers do a good job of modeling it. Also can one assume this won't do well for domains where there is, say, sensitivity to initial conditions, like chaotic systems like wheather where the # final states just explodes? reply nsoonhui 10 hours agoprevHere's something that bugs me about ML: all we have is prediction and no explanation how we come to that prediction, ie: no deeper understanding on the underlying principles. So despite that we got a good match this time, how can we be sure that the match will be equally good next time? And how to use ML to predict structure that we have no baseline to start with or experimental result to benchmark ? In the absence of physics-like principles, How can we ever be sure that ML results next time is correct ? reply coriny 2 hours agoparentThere is a biannual structural prediction contest called CASP [1], in which a set of newly determined structures is used to benchmark the prediction methods. Some of these structures will be \"novel\", and so can be used to estimate the performance of current methods on predicting \"structure that we have no baseline to start with\". CASP-style assessments are something that should done for more research fields, but it's really hard to persuade funders and researchers to put up the money and embargo the data as required. [1] https://en.wikipedia.org/wiki/CASP reply throwaway4aday 10 hours agoparentprevSpeaking of physics, we should borrow the quote \"Shut up and calculate\" to describe the situation: it works so use it now and worry about the explanations later. reply d0mine 3 hours agorootparentExcept the model is not open-source. You can't calculate anything. reply _xerces_ 18 hours agoprevA video summary of why this research is important: https://youtu.be/Mz7Qp73lj9o?si=29vjdQtTtIOk_0CV reply ProllyInfamous 17 hours agoparentThanks for this informative video summary. As a layperson, with a BS in Chemistry, it was quite helpful in understanding main bulletpoints of this accomplishment. reply ak_111 14 hours agoprevIf you work in this space would be interested to know what material impact has alphafold caused in your workflow since its release 4 years ago? reply dsign 17 hours agoprevFor a couple of years I've been expecting that ML models would be able to 'accelerate' bio-molecular simulations, using physics-based simulations as ground truth. But this seems to be a step beyond that. reply dekhn 15 hours agoparentWhen I competed in CASP 20 years ago (and lost terribly) I predicted that the next step to improve predictions would be to develop empirically fitted force fields to make MD produce accurate structure predictions (MD already uses empirically fitted force fields, but they are not great). This area was explored, there are now better force fields, but that didn't really push protein structure prediction forward. Another approach is fully differentiable force fields- the idea that the force field function itself is a trainable structure (rather than just the parameters/weights/constants) that can be optimized directly towards a goal. Also explored, produced some interesting results, but nothing that woudl be considered transformative. The field still generally believes that if you had a perfect force field and infinite computing time, you could directly recapitulate the trajectories of proteins folding (from fully unfolded to final state along with all the intermediates), but that doesn't address any practical problems, and is massively wasteful of resources compared to using ML models that exploit evolutionary information encoded in sequence and structures. In retrospect I'm pretty relieved I was wrong, as the new methods are more effective with far fewer resources. reply s1artibartfast 18 hours agoprevThe article was heavy on the free research aspect, but light on the commercial application. I'm curious about the business strategy. Does Google intend to license out tools, partner, or consult for commercial partners? reply a_bonobo 7 hours agoparentThis version has Isomorphic Labs far more in the focus of the press release, which seems to be now the commercial arm more or less licensing access out. The new AlphaFold server does not do everything the paper says AlphaFold 3 says it does. You cannot predict docking with the server! That is the main interest of pharma companies, 'does our medication bind to the target protein?'. From the FAQ: 'AlphaFold Server is a web-service that offers customized biomolecular structure prediction. It makes several newer AlphaFold3 capabilities available, including support for a wider range of molecule type' - that's not ALL AlphaFold3 capabilities. Isomorphic prints the money with those additional capabilities. It's hilarious that Google says they don't allow this for safety reasons, pure OpenAI fluff. It's just money. reply candiodari 18 hours agoparentprevI wonder what the license for RoseTTAFold is. On github you have: https://github.com/RosettaCommons/RoseTTAFold/blob/main/LICE... But there's also: https://files.ipd.uw.edu/pub/RoseTTAFold/Rosetta-DL_LICENSE.... Which is it? reply ilrwbwrkhv 18 hours agoparentprevas soon as google tries to think commercially this will shut down so the longer it stays pure research the better. google is bad with productization. reply s1artibartfast 17 hours agorootparentI don't think it was ever pure research. The article talks about infinity labs, which is the co. Mercial branch for drug discovery. I do agree that Google seems bad at commercialization, which is why I'm curious on what the strategy is. It is hard to see them being paid consultants or effective partners for pharma companies, let alone developing drugs themselves. reply ricksunny 13 hours agoprevI'm interested in how they measure accuracy of binding site identification and binding pose prediction. This was missing for the hitherto widely-used binding pose prediction tool Autodock Vina (and in silico binding pose tools in general). Despite the time I invested in learning & exercising that tool, I avoided using it for published research because I could not credibly cite its general-use accuracy. Is / will Alphafold 3 be citeable in the sense of \"I have run Alphafold on this particular target of interest and this array of ligands, and have found these poses of X kJ/mol binding energy, and this is known to an accuracy of Y% because of Alphafold 3's training set results cited below' reply l33tman 13 hours agoparentI've never trusted those predicted binding energies. If you have predicted a ligand/protein complex and have high confidence in it and want to study the binding energy I really think you should do a full MD simulation, you can pull the ligand-protein complex apart and measure the change in free energy explicitly. Also, and this is an unfounded guess only, the problem of protein / ligand docking is quite a bit more complex than protein folding - there seems to be a finite set of overall folds used in nature, while docking a small ligand to a big protein with flexible sidechains and even flexible large-scale structures can have induced fits that are really important to know and estimate, and I'm just very sceptical that it's going to be possible to in a general fashion ever predict these accurately by the AI model with the limited training data. Though you just need some hints, then you can run MD sims on them to see what happens for real. reply lumb63 14 hours agoprevWould anyone more familiar with the field be able to provide some cursory resources on the protein folding problem? I have a background in computer science and a half a background in biology (took two semesters of OChem, biology, anatomy; didn’t go much further). reply xnx 16 hours agoprevVery cool that anyone can login to https://golgi.sandbox.google.com/ and check it out reply roody15 15 hours agoprevI wonder in the not too distant future if these AI predictions could be explained back into “humanized” understanding. Much like ChatGPT can simplify complex topics … cold the model in the future provide feedback to researchers why it is making this prediction? reply reliablereason 15 hours agoprevWould be very useful if one they used it to predict the structure and interaction of the known variants to. Would be very helpful when predicting if a mutation on a protein would lead to loss of function for the protein. reply mfld 15 hours agoprevThe improvement on predicting protein/RNA/ligand interactions might facilitate many commercially relevant use cases. I assume pharma and biotech will eagerly get in line to use this. reply thenerdhead 14 hours agoprevA lot of accelerated article previews as of recently. Seems like humanity is making a lot of breakthroughs. This is nothing short of amazing for all those suffering from disease. reply sidcool 5 hours agoprevAnd google is giving the service for free. Pretty good. reply bbstats 14 hours agoprevZero-shot nearly beating trained catboost is pretty amazing. reply bschmidt1 16 hours agoprevGoogle's Game of Life 3D: Spiral edition reply MPSimmons 14 hours agoprevNot sure why the first thing they point it at wouldn't be prions. reply dev1ycan 12 hours agoprevExcited but also it's been a fair bit now and I have yet to see something truly remarkable come out of this reply Metacelsus 18 hours agoprevFrom: https://www.nature.com/articles/d41586-024-01383-z >Unlike RoseTTAFold and AlphaFold2, scientists will not be able to run their own version of AlphaFold3, nor will the code underlying AlphaFold3 or other information obtained after training the model be made public. Instead, researchers will have access to an ‘AlphaFold3 server’, on which they can input their protein sequence of choice, alongside a selection of accessory molecules. [. . .] Scientists are currently restricted to 10 predictions per day, and it is not possible to obtain structures of proteins bound to possible drugs. This is unfortunate. I wonder how long until David Baker's lab upgrades RoseTTAFold to catch up. reply l33tman 18 hours agoparentThat sucks a bit. I was just wondering why they are touting that 3rd party company in their own blog post, who commercialise research tools, as well. Maybe there are some corporate agreements with them that prevents them from opening the system... Imagine the goodwill for humanity for releasing these pure research systems for free. I just have a hard time understanding how you can motivate to keep it closed. Let's hope it will be replicated by someone who doesn't have to hide behind the \"responsible AI\" curtain as it seems they are now. Are they really thinking that someone who needs to predict 11 structures per day are more likely to be a nefarious evil protein guy than someone who predicts 10 structures a day? Was AlphaFold-2 (that was open-sourced) used by evil researchers? reply perihelions 17 hours agorootparent- \"Imagine the goodwill for humanity for releasing these pure research systems for free.\" The entire point[0] is that they want to sell an API to drug-developer labs, at exclusive-monopoly pricing. Those labs in turn discover life-saving drugs, and recoup their costs from e.g. parents of otherwise-terminally-ill children—again, priced as an exclusive monopoly. [0] As signaled by \"it is not possible to obtain structures of proteins bound to possible drugs\" It's a massive windfall for Alphabet, and it'd be a profound breach of their fiduciary duties as a public company to do anything other than lock-down and hoard this API, and squeeze it for every last billion. This is a deeply, deeply, deeply broken situation. reply karencarits 16 hours agorootparentWhat is the current status of drugs where the major contribution is from AI? Are they protectable like other drugs? Or are they more copyless like AI art and so on? reply goggy_googy 16 hours agorootparentprevWhat makes this such a \"deeply broken situation\"? I agree that late-stage capitalism can create really tough situations for poor families trying to afford drugs. At the same time, I don't know any other incentive structure that would have brought us a breakthrough like AlphaFold this soon. For the first time in history, we have ML models that are beating out the scientific models by huge margins. The very fact that this comes out of the richest, most competitive country in the history of the world is not a coincidence. The proximate cause of the suffering for terminally-ill children is really the drug company's pricing. If you want to regulate this, though, you'll almost certainly have fewer breakthroughs like AlphaFold. From a utilitarian perspective, by preserving the existing incentive structure (the \"deeply broken situation\" as you call it), you will be extending the lifespans of more people in the future (as opposed to extending lifespans of more people now by lowering drug prices). reply firefoxbrower 15 hours agorootparentLate-stage capitalism didn't bring us AlphaFold, scientists did, late-stage capitalism just brought us Alphabet swooping in at literally the last minute. Socialize the innovation because that requires potential losses, privatize the profits, basically. It's reminiscent of \"Heroes of CRISPR,\" where Doudna and Charpentier are supposedly just some middle-men, because stepping in at the last minute with more funding is really what fuels innovation. AlphaFold wasn't some lone genius breakthrough that came out of nowhere, everything but the final steps were basically created in academia through public funding. The key insights, some combination of realizing that the importance of sequence to structure to function put analyzable constraints on sequence conservation and which ML models could be applied to this, were made in academia a long time ago. AlphaFold's training set, the PDB, is also a result of decades of publicly funded work. After that, the problem was just getting enough funding amidst funding cuts and inflation to optimize. David Baker at IPD did so relatively successfully, Jinbo Xu is less of a fundraiser but was able to keep up basically alone with one or two grad students at a time, etc. AlphaFold1 threw way more people and money to basically copy what Jinbo Xu had already done and barely beat him at that year's CASP. Academics were leading the way until very, very recently, it's not like the problem was stalled for decades. Thankfully, the funding cuts will continue until research improves, and after decades of inflation cutting into grants, we are being rewarded by funding cuts to almost every major funding body this year. I pledge allegiance to the flag! EDIT: Basically, if you know any scientists, you know the vast majority of us work for years with little consideration for profit because we care about the science and its social impact. It's grating for the community, after being treated worse every year, to then see all the final credit go to people or companies like Eric Lander and Google. Then everyone has to start over, pick some new niche that everyone thinks is impossible, only to worry about losing it when someone begins to get it to work. reply iknowstuff 15 hours agorootparentWhy haven't the academics created a non profit foundation with open source models like this then? If alphabet doesnt provide much, then they will be supplanted by non profits. I see nothing broken here. reply j-wags 13 hours agorootparentI work at Open Force Field [1] which is the kind of nonprofit that I think you're talking about. Our sister project, OpenFold [2], is working on open source versions of AlphaFold. We're making good progress but it's difficult to interface with fundamentally different organizational models between academia and industry. I'm hoping that this model will become normalized in the future. But it takes serious leaps of faith from all involved (professors, industry leaders, grant agencies, and - if I can flatter myself - early career scientists) to leave the \"safe route\" in their organizations and try something like this. [1] https://openforcefield.org/ [2] https://openfold.io/ reply firefoxbrower 14 hours agorootparentprevIndividual labs somehow manage to do that and we're all grateful. Martin Steinegger's lab put out ColabFold, RELION is the gold standard for cryo-EM despite being academic software and the development of more recent industry competitors like cryoSPARC. Everything out of the IPD is free for academic use. Someone has to fight like hell to get all those grants, though, and from a societal perspective, it's basically needlessly redundant work. My frustrations aren't with a lack of open source models, some poor souls make them. My disagreement is with the perception that academia has insufficient incentive to work on socially important problems. Most such problems are ONLY worked on in academia until they near the finish line. Look at Omar Yaghi's lab's work on COFs and MOFs for carbon/emission sequestration and atmospheric water harvesting. Look at all the thankless work numerous labs did on CRISPR-Cas9 before the Broad Institute even touched it. Look at Jinbo Xu's work, on David Baker's lab's and the IPD's work, etc. Look at what labs first solved critical amyloid structures, infuriatingly recently, considering the massive negative social impacts of neurodegenerative diseases. It's only rational for companies that only care about their own profit maximization to socialize R&D costs and privatize any possible gains. This can work if companies aren't being run by absolute ghouls who aren't delaying the release of a new generation of drugs to minimize patent duration overlap or who aren't trying to push things that don't work for short-term profit. This can also work if we properly fund and credit publicly funded academic labs. This is not what's happening, however, instead public funded research is increasingly demeaned, defunded, and dismantled due to the false impression that nothing socially valuable gets done without a profit motive. It's okay, though, I guess under this kind of LSC worldview, that everything always corrects itself so preempting problems doesn't matter, we'll finally learn how much actual innovation is publicly funded when we get the Minions movie, aducanumab, and WeWork over and over again for a few decades while strangling the last bit of nature we have left. reply iknowstuff 16 hours agorootparentprevIs it broken if it yields new drugs? Is there a system that yields more? The whole point of capitalism is that it incentivizes this in a way that no other system does. reply l33tman 13 hours agorootparentMy point one level up in the comments here, was not really that the system is broken, but more like asking how you can run these companies (google and that other part run by the deepmind founder, who I bet already has more money than he can ever spend) and still sleep well knowing you're the rich capitalist a-hole commercializing life-science work that your parent company has allocated maybe one part in a million of their R&D budget into creating. It's not like Google is ever going to make billions on this anyway, the alphafold algorithms are not super advanced and you don't require the datasets of gpt4 to train them so others will hopefully catch up.. though I'm also pretty sure it requires GPU-hours beyond what a typical non-profit academia outfit has available unfortunately.. :/ reply lupire 16 hours agorootparentprevThe parents of those otherwise terminally ill children disagree with you in the strongest possible terms. reply staminade 18 hours agorootparentprevIsomorphic Labs? That's an Alphabet owned startup run by Denis Hassabis that they created to commercialise the Alphafold work, so it's not really a 3rd party at all. reply SubiculumCode 17 hours agorootparentprevThere is at least some difference between a monitored server and a privately ran one, if negative consequences are possible reply mhrmsn 18 hours agoparentprevAlso no commercial use, from the paper: > AlphaFold 3 will be available as a non-commercial usage only server at https://www.alphafoldserver.com, with restrictions on allowed ligands and covalent modifications. Pseudocode describing the algorithms is available in the Supplementary Information. Code is not provided. reply obmelvin 16 hours agorootparentIf you need to submit to their server, I don't know who would use it for commercial reasons anyway. Most biotech startups and pharma companies are very careful about entering sequences into online tools like this. reply pantalaimon 16 hours agorootparentprevWhat's the point in that that - I mean who does non-commercial drug research? reply karencarits 15 hours agorootparentPublic universities? reply sangnoir 15 hours agorootparentprevAcademia reply moralestapia 17 hours agorootparentprevHow easy/hard would be for the scientific community to come up with an \"OpenFold\" model which is pretty much AF3 but fully open source and without restrictions in it? I can image training will be expensive, but I don't think it will be at a GPT-4 level of expensive. reply dekhn 16 hours agorootparentalready did it, https://openfold.io/ https://github.com/aqlaboratory/openfold https://www.biorxiv.org/content/10.1101/2022.11.20.517210v1 https://lupoglaz.github.io/OpenFold2/ https://www.biospace.com/article/releases/openfold-biotech-a... I really have to emphasize that transformers have literally transformed science in only a few years. Truly extraordinary. reply moralestapia 16 hours agorootparentOh, nice! Thanks for sharing. reply p3opl3 17 hours agorootparentprevYes, because that's going to stop competitors.. it's why they didn't release code I guess. This is yet another large part of a biotech related Gutenberg moment. reply natechols 16 hours agorootparentThe DeepMind team was essentially forced to publish and release an earlier iteration of AlphaFold after the Rosetta team effectively duplicated their work and published a paper about it in Science. Meanwhile, the Rosetta team just published a similar work about co-folding ligands and proteins in Science a few weeks ago. These are hardly the only teams working in this space - I would expect progress to be very fast in the next few years. reply dekhn 16 hours agorootparentHow much has changed- I talked with David Baker at CASP around 2003 and he said at the time, while Rosetta was the best modeller, every time they updated its models with newly determined structures, its predictions got worse :) reply natechols 15 hours agorootparentIt's kind of amazing in retrospect that it was possible to (occasionally) produce very good predictions 20 years ago with at least an order of magnitude smaller training set. I'm very curious whether DeepMind has tried trimming the inputs back to an earlier cutoff point and re-training their models - assuming the same computing technologies were available, how well would their methods have worked a decade or two ago? Was there an inflection point somewhere? reply tepal 18 hours agoparentprevOr OpenFold, which is the more literal reproduction of AlphaFold 2: https://github.com/aqlaboratory/openfold reply LarsDu88 15 hours agorootparentTime for an OpenFold3? Or would it be an OpenFold2? reply rolph 18 hours agoparentprevin other words, this has been converted to a novelty, and has no use for scientific purposes. reply ebiester 18 hours agorootparentNo. It just means that scientific purposes will have an additional tax paid to google. This will likely reduce use in academia but won't deter pharmaceutical companies. reply ranger_danger 18 hours agoparentprevNot just unfortunate, but doesn't this make it completely untrustable? How can you be sure the data was not modified in any way? How can you verify any results? reply dekhn 17 hours agorootparentYou determine a crystal structure of a known protein which does not previously have a known structure, and compare the prediction to the experimentally determined structure. There is a biennial (biannual?) competition known as CASP where some new structures, not yet published, are used for testing predictions from a wide range of protein structure prediction (so, basically blind predictions which are then compared when the competition wraps up). AlphaFold beat all the competitors by a very wide margin (much larger than the regular rate of improvement in the competition), and within a couple years, the leading academic groups adopted the same techniques and caught up. It was one of the most important and satisfying moments in structure prediction in the past two+ decades. The community was a bit skeptical but as it's been repeatedly tested, validated, and reproduced, people are generally of the opinion that DeepMind \"solved\" protein structure prediction (with some notable exceptions), and did so without having the solve the full \"protein folding problem\" (which is actually great news while also being somewhat depressing). reply ranger_danger 11 hours agorootparentBy data I meant between the client and server, nothing actually related to how the program itself works, but just the fact that it's controlled by a proprietary third party. reply wslh 18 hours agoparentprevThe AI call is rolling fast, I see similarities with cryptography in the 90s. I have a history to tell for the record, back in the 90s we developed a home banking for Palm (with a modem), it was impossible to perform RSA because of the speed so I contacted the CEO of Certicom which was the unique elliptic curve cryptography implementation at that time. Fast forward and ECC is everywhere. reply niemandhier 17 hours agoparentprevThe logical consequence is to put all scientific publications under a license that restricts the right to train commercial ai models on them. Science advances because of an open exchange of ideas, the original idea of patents was to grant the inventor exclusive use in exchange for disclosure of knowledge. Those who did not patent, had to accept that their inventions would be studied and reverse engineered. The „as a service“ model, breaks that approach. reply dwroberts 17 hours agoparentprevThis turns it into a tool that deserves to be dethroned by another group, frankly. What a strange choice. reply Jerrrry 18 hours agoparentprevThe second amendment prevents the government's overreaching perversion to restrict me from having the ability to print biological weapons from the comfort of my couch. Google has no such restriction. reply gameman144 17 hours agorootparentI know this is tongue in cheek, but you absolutely can be restricted from having a biological weapons factory in your basement (similar to not being able to pick \"nuclear bombs\" as your arms to bear). reply timschmidt 17 hours agorootparentSeems like the recipe for independence, and agreed upon borders, and thus whatever interpretation of the second amendment one wants involves exactly choosing nuclear bombs, and managing to stockpile enough of them before being bombed oneself. At least at the nation state scale. Sealand certainly resorted to arms at several points in it's history. reply gameman144 13 hours agorootparentThe second amendment only applies to the United States -- it's totally normal to have one set of rights for citizens and another set for the government itself. reply dekhn 16 hours agorootparentprevSergey once said \"We don't have an army per-se\" (he was referring the size of Google's physical security group) at TGIF. There was a nervous chuckle from the audience. reply SubiculumCode 17 hours agorootparentprev/s is strong with this one reply photochemsyn 17 hours agoparentprevWell, it's because you can design deadly viruses using this technology. Viruses gain entry to living cells via cell-surface receptor proteins whose normal job is to bind signalling molecules, alter their conformation and translate that external signal into the cellular interior where it triggers various responses from genomic transcription to release of other signal molecules. Viruses hijack such mechanisms to gain entry to cells. Thus if you can design a viral coat protein to bind to a human cell-surface receptor, such that it gets translocated into the cell, then it doesn't matter so much where that virus came from. The cell's firewall against viruses is the cell membrane, and once inside, the biomolecular replication machinery is very similar from species to species, particularly within restricted domains, such as all mammals. Thus viruses from rats, mice, bats... aren't going to have major problems replicating in their new host - a host they only gained access to because some nation-state actors working in collaboration on such gain-of-function research in at least two labs on opposite sides of the world with funds and material provided by the two largest economic powers for reasons that are still rather opaque, though suspiciously banal... Now while you don't need something like AlphaFold3 to do recklessly stupid things (you could use directed evolution, making millions of mutatad proteins, throwing them at a wall of human cell receptors and collecting what stuck), it makes it far easier. Thus Google doesn't want to be seen as enabling, though given their prediliction for classified military-industrial contracting to a variety of nation-states, particularly with AI, with revenue now far more important than silly \"don't be evil\" statements, they might bear watching. On the positive side, AlphaFold3 will be great for fields like small molecular biocatalysis, i.e. industrial applications in which protein enzymes (or more robust heterogenous catalysts designed based on protein structures) convert N2 to ammonia, methane to methanol, or selectively bind CO2 for carbon capture, modification of simple sugars and amino acids, etc. reply moconnor 18 hours agoprevStepping back, the high-order bit here is an ML method is beating physically-based methods for accurately predicting the world. What happens when the best methods for computational fluid dynamics, molecular dynamics, nuclear physics are all uninterpretable ML models? Does this decouple progress from our current understanding of the scientific process - moving to better and better models of the world without human-interpretable theories and mathematical models / explanations? Is that even iteratively sustainable in the way that scientific progress has proven to be? Interesting times ahead. reply dekhn 17 hours agoparentIf you're a scientist who works in protein folding (or one of those other areas) and strongly believe that science's goal is to produce falsifiable hypotheses, these new approaches will be extremely depressing, especially if you aren't proficient enough with ML to reproduce this work in your own hands. If you're a scientist who accepts that probabilist models beat interpretable ones (articulated well here: https://norvig.com/chomsky.html), then you'll be quite happy because this is yet another validation of the value of statistical approaches in moving our ability to predict the universe forward. If you're the sort of person who believes that human brains are capable of understanding the \"why\" of how things work in all its true detail, you'll find this an interesting challenge- can we actually interpret these models, or are human brains too feeble to understand complex systems without sophisticated models? If you're the sort of person who likes simple models with as few parameters as possible, you're probably excited because developing more comprehensible or interpretable models that have equivalent predictive ability is a very attractive research subject. (FWIW, I'm in the camp of \"we should simultaneously seek simpler, more interpretable models, while also seeking to improve native human intelligence using computational augmentation\") reply jprete 15 hours agorootparentThe goal of science has always been to discover underlying principles and not merely to predict the outcome of experiments. I don't see any way to classify an opaque ML model as a scientific artifact since by definition it can't reveal the underlying principles. Maybe one could claim the ML model itself is the scientist and everyone else is just feeding it data. I doubt human scientists would be comfortable with that, but if they aren't trying to explain anything, what are they even doing? reply dekhn 15 hours agorootparentThat's the aspirational goal. And I would say that it's a bit of an inflexible one- for example, if we had an ML that could generate molecules that cure diseases that would pass FDA approval, I wouldn't really care if scientists couldn't explain the underlying principles. But I'm an ex-scientist who is now an engineer, because I care more about tools that produce useful predictions than understanding underlying principles. I used to think that in principle we could identify all the laws of the universe, and in theory, simulate that would enough accuracy, and inspect the results, and gain enlightenment, but over time, I've concluded that's a really bad way to waste lots of time, money, and resources. reply panarky 14 hours agorootparentIt's not either-or, it's yes-and. We don't have to abandon one for the other. AlphaFold 3 can rapidly reduce a vast search space in a way physically-based methods alone cannot. This narrowly focused search space allows scientists to apply their rigorous, explainable, physical methods, which are slow and expensive, to a small set of promising alternatives. This accelerates drug discovery and uncovers insights that would otherwise be too costly or time-consuming. The future of science isn't about AI versus traditional methods, but about their intelligent integration. reply nextos 12 hours agorootparentOr you can treat AlphaFold as a black box / oracle and work at systems biology level, i.e. at pathway and cellular level. Protein structures and interactions are always going to be hard to predict with interpretable models, which I also prefer. My only worry is that AlphaFold and others, e.g. ESM, seem to be bit fragile for out-of-distribution sequences. They are not doing a great job with unusual sequences, at least in my experience. But hopefully they will improve and provide better uncertainty measures. reply hammock 7 hours agorootparentprev> if we had an ML that could generate molecules that cure diseases that would pass FDA approval, I wouldn't really care if scientists couldn't explain the underlying principles It’s actually required as part of the submission for FDA approval that you posit a specific Mechanism of Action for why your drug works the way it does. You can’t get approval without it reply jdietrich 6 hours agorootparentA substantial proportion of FDA-approved drugs have an unknown mechanism of action - we can handwave about protein interactions, but we have no useful insight into how they actually work. Drug discovery is bureaucratically rigid, but scientifically haphazard. reply adrianN 5 hours agorootparentprevUnderlying principles are nice for science, whatever works is nice for engineering. There is plenty of historical precedent where we build stuff that works without knowing exactly why it works. reply gandalfthepink 7 hours agorootparentprevMe like thee career path. Interesting. reply ak_111 14 hours agorootparentprevDiscovering underlying principles and predicting outcomes is two sides of the same coin in that there is no way to confirm you have discovered underlying principles unless they have some predictive power. Some had tried to come up with other criteria to confirm you have discovered an underlying principle without predictive power, such as on aesthetics - but this is seen by the majority of scientists as basically a cop out. See debate around string theory. Note that this comment is summarizing a massive debate in the philosophy of science. reply chasd00 14 hours agorootparentIf all you can do is predict an outcome without being able to explain how then what have you really discovered? Asking someone to just believe you can predict outcomes without any reasoning as to how, even if you're always right, sounds like the concept of faith in religion. reply lordnacho 10 hours agorootparentThe how is actually just further hypotheses. It's turtles all the way down: There is a car. We think it drives by burning petrol somehow. How do we test this? We take petrol away and it stops driving. Ok, so we know it has something to do with petrol. How does it burning the petrol make it drive? We think it is caused by the burned petrol pushing the cylinders, which are attached to the wheels through some gearing. How do we test it? Take away the gearing and see if it drives. Anyway, this never ends. You can keep asking questions, and as long as the hypothesis is something you can test, you are doing science. reply hammock 7 hours agorootparent>There is a car. We think it drives by burning petrol somehow. How do we test this? We take petrol away and it stops driving. You discovered a principle. Better example: There is a car. We don’t know how it drives. We turn the blinkers on and off. It still drives. Driving is useful. I drive it to the store reply dumpsterdiver 13 hours agorootparentprev> what have you really discovered? You’ve discovered magic. When you read about a wizard using magic to lay waste to invading armies, how much value would you guess the armies place in whether or not the wizard truly understands the magic being used against them? Probably none. Because the fact that the wizard doesn’t fully understand why magic works does not prevent the wizard from using it to hand invaders their asses. Science is very much the same - our own wizards used medicine that they did not understand to destroy invading hordes of bacteria. reply pineaux 3 hours agorootparentExactly! The magic to lay waste to invading armies is packaged into a large flask and magical metal birds are flown to above the army. There the flask is released from the birds bellies and gently glides down. When the flask is at optimum height it releases the power of the sun and all that are beneath it get vaporized. A newer version of this magic is attached to a gigantic fireworks rocket that can fly over whole mountain ranges and seas. reply pas 13 hours agorootparentprevit's still an extremely valuable tool. just as we see in mathematics, closed forms (and short and elegant proofs) are much coveted luxury items. for many basic/fundamental mathematical objects we don't (yet) have simple mechanistic ways to compute them. so if a probabilistic model spits out something very useful, we can slap a nice label on it and call it a day. that's how engineering works anyway. and then hopefully someday someone will be able to derive that result from \"first principles\" .. maybe it'll be even more funky/crazy/interesting ... just like mathematics arguably became more exciting by the fact that someone noticed that many things are not provable/constructable without an explicit Axiom of Choice. https://en.wikipedia.org/wiki/Nonelementary_integral#Example... reply thfuran 13 hours agorootparent>closed forms (and short and elegant proofs) are much coveted luxury items. Yes, but we're taking about roughly the opposite of a proof reply pas 10 hours agorootparentbut in usual natural sciences we don't have proofs, only data and models, and then we do model selection (and through careful experiments we end up with confidence intervals) and it seems with these molecular biology problems we constantly have the problem of specificity (model prediction quality) vs sensitivity (model applicability), right? but due to information theory constraints there's also a dimension along model size/complexity. so if a ML model can push the ROC curve toward the magic left-up corner then likely it's getting more and more complex. and at one point we simply are left with models that are completely parametrized by data and there's virtually zero (direct) influence of the first principles. (I mean that at one point as we get more data even to do model selection we can't use \"first principles\" because what we know through that is already incorporated into previous versions of the models. Ie. the information we gained from those principles we already used to make decisions in earlier iterations.) Of course then in theory we can do model distillation, and if there's some hidden small/elegant theory we can probably find it. (Which would be like a proof through contradiction, because it would mean that we found model with the same predictive power but with smaller complexity than expected.) // NB: it's 01:30 here, but independent of ignorance-o-clock ... it's quite possible I'm totally wrong about this, happy to read any criticism/replies reply jcims 13 hours agorootparentprevIsn’t that basically true of most of the fundamental laws of physics? There’s a lot we don’t understand about gravity, space, time, energy, etc., and yet we compose our observations of how they behave into very useful tools. reply thfuran 14 hours agorootparentprev>there is no way to confirm you have discovered underlying principles unless they have some predictive power. Yes, but a perfect oracle has no explanatory power, only predictive. reply nkingsy 14 hours agorootparentincreasing the volume of predictions produces patterns that often lead to underlying principles. reply mikeyouse 13 hours agorootparentAnd much of the 20th century was characterized by a very similar progression - we had no clue what the actual mechanism of action was for hundreds of life saving drugs until relatively recently, and we still only have best guesses for many. That doesn’t diminish the value that patients received in any way even though it would be more satisfying to make predictions and design something to interact in a way that exactly matches your theory. reply qp11 5 hours agorootparentWe were using the compass for navigation for thousands of years, without any clue about what it was doing or why. Ofcourse lot of people got lost cause compasses are not perfect. And the same will happen here. Theory of Bounded Rationality applies. reply jdietrich 5 hours agorootparentprevThe goal of science has always been to predict the outcome of experiments, because that's what distinguishes science from philosophy or alchemy or faith. Anyone who believes that they've discovered an underlying principle is almost certainly mistaken; with time, \"underlying principles\" usually become discredited theories or, sometimes, useful but crude approximations that we teach to high schoolers and undergrads. Prediction is understanding. What we call \"understanding\" is a cognitive illusion, generated by plausible but brittle abstractions. A statistically robust prediction is an explanation in itself; an explanation without predictive power explains nothing at all. Feeling like something makes sense is immeasurably inferior to being able to make accurate predictions. Scientists are at the dawn of what chess players experienced in the 90s. Humans are just too stupid to say anything meaningful about chess. All of the grand theories we developed over centuries are just dumb heuristics that are grossly outmatched by an old smartphone running Stockfish. Maybe the computer understands chess, maybe it doesn't, but we humans certainly don't and we've made our peace with the fact that we never will. Moore's law does not apply to thinking meat. reply gradus_ad 12 hours agorootparentprevThat ship sailed with Quantum physics. Nearly perfect at prediction, very poor at giving us a concrete understanding of what it all means. This has happened before. Newtonian mechanics was incomprehensible spooky action at a distance, but Einstein clarified gravity as the bending of spacetime. reply drdeca 9 hours agorootparentI think this relies on either the word “concrete” or a particular choice of sense for “concrete understanding”. Like, quantum mechanics doesn’t seem, to me, to just be a way of describing how to predict things. I view it as saying substantial things about how things are. Sure, there are different interpretations of it, which make the same predictions, but, these different interpretations have a lot in common in terms of what they say about “how the world really is” - specifically, they have in common the parts that are just part of quantum mechanics. The qau that can be spoken in plain language without getting into the mathematics, is not the eternal qau, or whatever. reply toxik 14 hours agorootparentprevKepler famously compiled troves of data on the night sky, and just fitted some functions to them. He could not explain why but he could say what. Was he not a scientist? reply chemicalnovae 6 hours agorootparentHe might not have been able to explain why _but_ I'd bet anything he would have wanted to if he could. reply strogonoff 15 hours agorootparentprevCan underlying principles be discovered using the framework of scientific method? The primary goal of models and theories it develops is to support more experiments and eventually be disproven. If no model can be correct, complete and provable in finite time, then a theory about underlying principles that claims completeness would have to be unfalsifiable. This is reasonable in context of philosophy, but not in natural sciences. Scientific method can help us rule out what underlying principles are definitely not. Any such principles are not actually up to be “discovered”. If probabilistic ML comes along and does a decent job at predicting things, we should keep in mind that those predictions are made not in context of absolute truth, but in context of theories and models we have previously developed. I.e., it’s not just that it can predict how molecules interact, but that the entire concept of molecules is an artifact of just some model we (humans) came up with previously—a model which, per above, is probably incomplete/incorrect. (We could or should use this prediction to improve our model or come up with a better one, though.) Even if a future ML product could be creative enough to actually come up with and iterate on models all on its own from first principles, it would not be able to give us the answer to the question of underlying principles for the above-mentioned reasons. It could merely suggest us another incomplete/incorrect model; to believe otherwise would be to ascribe it qualities more fit for religion than science. reply jltsiren 13 hours agorootparentI don't find that argument convincing. People clearly have been able to discover many underlying principles using the scientific method. Then they have been able to explain and predict many complex phenomena using the discovered principles, and create even more complex phenomena based on that. Complex phenomena such as the technology we are using for this discussion. Words dont have any inherent meaning, just the meaning they gain from usage. The entire concept of truth is an artifact of just some model (language) we came up with previously—a model which, per above, is probably incomplete/incorrect. The kind of absolute truth you are talking about may make sense when discussing philosophy or religion. Then there is another idea of truth more appropriate for talking about the empirical world. Less absolute, less immutable, less certain, but more practical. reply strogonoff 4 hours agorootparent> The kind of absolute truth you are talking about may make sense when discussing philosophy or religion. Exactly—except you are talking about it, too. When you say “discovering underlying principles”, you are implying the idea of absolute truth where there is none—the principles are not discovered, they are modeled, and that model is our fallible human construct. It’s a similar mistake as where you wrote “explain”: every model (there should always be more than one) provides a metaphor that 1) first and foremost, jives with our preexisting understanding of the world, and 2) offers a lossy map of some part of [directly inaccessible] reality from a particular angle—but not any sort of explanation with absolute truth in mind. Unless you treat scientific method as something akin to religion, which is a common fallacy and philosophical laziness, it does not possess any explanatory powers—and that is very much by design. reply SJC_Hacker 13 hours agorootparentprevWhat if it turns out that nature simply doesn't have nice, neat models that humans can comprehend for many observable phenomena? reply empath-nirvana 7 hours agorootparentI read an article about the \"unreasonable effectiveness of mathematics\" that it was basically the result of a drunk looking for his keys under a lamp post because that's where the light is. We know how to use math to model parts of the world, and every where we look, there's _something_ we can model with math, but that doesn't mean that there's all there is to the universe. We could be understanding .0000001% of what's out there to understand, and it's the stuff that's amenable to mathematical analysis. reply fire_lake 15 hours agorootparentprevWhat if the underlying principles of the universe are too complex for human understanding but we can train a model that very closely follows them? reply dekhn 15 hours agorootparentThen we should dedicate large fractions of human engineering towards finding ethical ways to improve human intelligence so that we can appreciate the underlying principles better. reply refulgentis 14 hours agorootparentI spend about 30 minutes reading this thread and links from it: I don't really follow your line of argument. I find it fascinating and well-communicated, the lack of understanding is on me: my attention flits around like a butterfly, in a way that makes it hard for me to follow people writing original content. High level, I see a distinction between theory and practice, between an oracle predicting without explanation, and a well-thought out theory built on a partnership between theory and experiment over centuries, ex. gravity. I have this feeling I can't shake that the knife you're using is too sharp, both in the specific example we're discussing, and in general. In the specific example, folding, my understanding is we know how proteins fold & the mechanisms at work. It just takes an ungodly amount of time to compute and you'd still confirm with reality anyway. I might be completely wrong on that. Given that, the proposal to \"dedicate...engineer[s] towards finding ethical ways to improve...intelligence so that we can appreciate the underlying principles better\" begs the question of if we're not appreciating the underlying principles. It feels like a close cousin of physics theory/experimentalist debate pre-LHC, circa 2006: the experimentalists wanted more focus on building colliders or new experimental methods, and at the extremes, thought string theory was a complete was of time. Which was working towards appreciating the underlying principles? I don't really know. I'm not sure there's a strong divide between the work of recording reality and explaining it. I'll peer into a microscope in the afternoon, and take a shower in the evening, and all of a sudden, free associating gives me a more high-minded explanation for what I saw. I'm not sure a distinction exists for protein folding, yes, I'm virtually certain this distinction does not exist in reality, only in extremely stilted examples (i.e. a very successful oracle at Delphi) reply mistermann 13 hours agorootparentThere's a much easier route: consciousness is not included in the discussion...what a coincidence. reply Wilduck 15 hours agorootparentprevThat sounds like useful engineering, but not useful science. reply mrbungie 15 hours agorootparentI think that a lot of scientific discoveries originate from initial observations made during engineering work or just out of curiosity without rigour. Not saying ML methods haven't shown important reproducibility challenges, but to just shut them down due to not being \"useful science\" is inflexible. reply fsloth 4 hours agorootparentprevAFAIK in wet science you need (or needed) to do tons of experimentations with liquids with specific molar compositions and temperatures splurging in and out of test tubes - basically just physically navigating a search space. I would view an AI model with super powerful guestimation capability as a much faster way of A) cutting through search space B) providing accidental discoveries while at it Now, if we look at history of science and technology, there is a shit ton of practical stuff that was found only by pure accident - discoveries of which could not be predicted from any previous theory. I would view both A) and B) as net positives. But our teaching of the next generation of scientists needs to adapt. The worst case scenario is of course that the middle management driven enshittification of science will proceed to a point where there are only few people who actually are scientists and not glorified accountants. But I’m optimistic this will actually super charge science. With good luck we will get rid of the both of the biggest pathologies in modern science - 1. number of papers published and referred as a KPI 2. Hype driven super politicized funding where you can focus only one topic “because that’s what’s hot” (i.e. string theory). The best possible outcome is we get excitement and creativity back into science. Plus level up our tech level in this century to something totally unforeseen (singularity? That’s just a word for “we don’t know what’s gonna happen” - not a specific concrete forecasted scenario). reply tsimionescu 4 hours agorootparent> singularity? That’s just a word for “we don’t know what’s gonna happen” - not a specific concrete forecasted scenario It's more specific than you make it out. The singularity idea is that smart AIs working on improving AI will produce smarter AIs, leading to an ever increasing curve that at some point hits a mathematical singularity. reply fsloth 1 hour agorootparentNo it's not specific at all in predicting technological progress, which was the point of my comment. Nobody knows what singularity would actually mean from the point of view of specific technological development. reply flawsofar 10 hours agorootparentprevThe machine understands, we do not, and so it is not science? Can we differentiate? reply empath-nirvana 8 hours agorootparentprevIf have an oracle that can predict the outcome of experiments does it _matter_ if you understand why? reply melagonster 7 hours agorootparentprevthey offered a good tool for science... so this is a part of science. reply Invictus0 14 hours agorootparentprevMaybe the science of the past was studying things of lesser complexity than the things we are studying now. reply exe34 15 hours agorootparentprevThe ML model can also be an emulator of parts of the system that you don't want to personally understand, to help you get on with focusing on what you do want to figure out. Alternatively, the ML model can pretend to be the real world while you do experiments with it to figure out aspects of nature in minutes rather than hours-days of biological turnaround. reply stouset 7 hours agorootparentprev> If you're the sort of person who believes that human brains are capable of understanding the \"why\" of how things work in all its true detail, you'll find this an interesting challenge- can we actually interpret these models, or are human brains too feeble to understand complex systems without sophisticated models? I think chess engines, weirdly enough, have disabused me of this notion. There are lots of factors a human considers when looking at a board. Piece activity. Bishop and knight imbalances. King safety. Open and semi-open file control. Tempo. And on and on. But all of them are just convenient shortcuts that allow us to substitute reasonable guesses for what really matters: exhaustively calculating a winning line through to the end. “Positional play” is a model that only matters when you can’t calculate trillions of lines thirty moves deep, and it’s infinitely more important that a move survives your opponent’s best possible responses than it is to satisfy some cohesive higher level principle. reply kobenni 4 hours agorootparentI don't understand why you would draw this conclusion. The deep search you describe is an algorithm that humans can understand perfectly fine. Humans just can't solve it in their heads and need to let a computer handle the number crunching. Just like a scientist may understand the differential equations to describe a system perfectly fine, but require a computer to approximate the solution for an initial value problem. reply stouset 3 hours agorootparent“Knowing” that some line works to some ridiculous depth is different than understanding how and why. And at some level the answer is simply “because every possible refutation fails” and there is no simpler pattern to match against nor intuition to be had. That is the how and why of it. reply xixixao 3 hours agorootparentprevThe scientist can understand “how” the model works, how many layers there are, that each neuron has a weight, that some are connected… Parent comment and yours show that “understanding” is a fuzzy concept. reply searealist 6 hours agorootparentprevChess engines actually do both now. They have ML models to evaluate positions, essentially a much more advanced version of your positional description, and deep calculations. reply stouset 6 hours agorootparentThat might be the best we can practically achieve with technology, but the point stands. If positional evaluation says one thing but an exhaustive analysis of lines finds a solution 60 moves deep, that one is going to win. reply searealist 5 hours agorootparentHumans also do search. Also, engines arent doing an exhaustive search when they are 20 moves deep. They heavily prune. reply stouset 3 hours agorootparentYes, I understand how chess engines work. Ignore the existence of engines for a moment. The reason a particular line works, at the end of the day, is simply because it does. Just because we have heuristics that help us skip a lot of evaluation doesn’t mean the heuristics have intrinsic meaning within the game. They don’t. They’re shortcuts that let us skip having to do the impossible. The heuristics will always lose to concrete analysis to a deep enough depth. And that’s my point. We come up with models that give us an intuition for “why” things are a certain way. Those models are inarguably helpful toward having a gut feeling. But models aren’t the thing itself, and every model we’ve found breaks down at some deeper point. And maybe at some level things simply “are” some way with no convenient shorthand explanation. reply searealist 3 hours agorootparentSo your point is that we are not omnipotent? Ok. reply TylerLives 2 hours agorootparentBecause of our limitations, we have to compress reality more in order to reason about it. This means we're blind to some ideas that computers are not. Just like a depth 1 chess engine can't see what's happening at depth 3 but has to make an imperfect guess. reply anonylizard 4 hours agorootparentprevFine tuned LLMs can play chess at grandmaster levels. So its clear that there is in fact 'deeper patterns to chess' that allow one to play very well, without any search required (Since LLMs cannot search). Its just that those patterns are probably rather different to human understood ones. reply croniev 16 hours agorootparentprevI'm in the following camp: It is wrong to think about the world or the models as \"complex systems\" that may or may not be understood by human intelligence. There is no meaning beyond that which is created by humans. There is no 'truth' that we can grasp in parts but not entirely. Being unable to understand these complex systems means that we have framed them in such a way (f.e. millions of matrix operations) that does not allow for our symbol-based, causal reasoning mode. That is on us, not our capabilities or the universe. All our theories are built on observation, so these empirical models yielding such useful results is a great thing - it satisfies the need for observing and acting. Missing explainability of the models merely means we have less ability to act more precisely - but it does not devalue our ability to act coarsely. reply visarga 16 hours agorootparentBut the human brain has limited working memory and experience. Even in software development we are often teetering at the edge of the mental power to grasp and relate ideas. We have tried so much to manage complexity, but real world complexity doesn't care about human capabilities. So there might be high dimensional problems where we simply can't use our brains directly. reply jvanderbot 15 hours agorootparentA human mind is perfectly capable of following the same instructions as the computer did. Computers are stupidly simple and completely deterministic. The concern is about \"holding it all in your head\", and depending on your preferred level of abstraction, \"all\" can perfectly reasonably be held in your head. For example: \"This program generates the most likely outputs\" makes perfect sense to me, even if I don't understand some of the code. I understand the system. Programmers went through this decades ago. Physicists had to do it too. Now, chemists I suppose. reply ajuc 14 hours agorootparentAbstraction isn't the silver bullet. Not everything is abstractable. \"This program generates the most likely outputs\" isn't a scientific explanation, it's teleology. reply jvanderbot 14 hours agorootparent\"this tool works better than my intuition\" absolutely is science. \"be quiet and calculate\" is a well worn mantra in physics is it not? reply drdeca 7 hours agorootparent“calculate” in that phrase, refers to doing the math, and the understanding that that entails, not pressing the “=“ button on a calculator. reply d0mine 4 hours agorootparentWhy do you think systems of partial differential equations (common in physics) are somehow provide more understanding than the corresponding ML math (at the end of the day both can produce results using a lots of matrix multiplications). reply drdeca 3 hours agorootparent... because people understand things about what is described when dealing with such systems in physics, and people don't understand how the weights in ML learned NNs produce the overall behavior? (For one thing, the number of parameters is much greater with the NNs) reply mistermann 13 hours agorootparentprevWhat is an example of something that isn't abstractable? reply ajuc 2 hours agorootparentStuff that we can't program directly, but can program using machine learning. Speech recognition. OCR. Reccomendation engines. You don't write OCR by going \"if there's a line at this angle going for this long and it crosses another line at this angle then it's an A\". There's too many variables and influence of each of them is too small and too tightly coupled with others to be able to abstract it into something that is understandeable to a human brain. reply GenerocUsername 15 hours agorootparentprevThis is just wrong. While computer operations in solutions are computable by humans, the billions of rapid computations are unachievable by humans. In just a few seconds, a computer can perform more basic arithmetic operations than a human could in a lifetime. reply jvanderbot 14 hours agorootparentI'm not saying it's achievable, I'm saying it's not magic. A chemist who wishes to understand what the model is doing can get as far as anyone else, and can reach a level of \"this prediction machine works well and I understand how to use and change it\". Even if it requires another PhD in CS. That the tools became complex is not a reason to fret in science. No more than statistical physics or quantum mechanics or CNN for image processing - it's complex and opaque and hard to explain but perfectly reproduceable. \"It works better than my intuition\" is a level of sophistication that most methods are probably doomed to achieve. reply EventH- 15 hours agorootparentprev\"There is no 'truth' that we can grasp in parts but not entirely.\" The value of pi is a simple counterexample. reply joaogui1 11 hours agorootparentWe can predict the digits of pi with a formula, to me that counts as grasping it reply dekhn 6 hours agorootparentFor those who aren't aware: https://en.wikipedia.org/wiki/Bellard%27s_formula (yes, that Fabrice: https://en.wikipedia.org/wiki/Fabrice_Bellard) reply slibhb 16 hours agorootparentprev> There is no 'truth' that we can grasp in parts but not entirely. If anyone actually thought this way -- no one does -- they definitely wouldn't build models like this. reply Invictus0 14 hours agorootparentprev> There is no 'truth' that we can grasp in parts but not entirely It appears that your own comment is disproving this statement reply interroboink 16 hours agorootparentprev> ... and strongly believe that science's goal is to produce falsifiable hypotheses, these new approaches will be extremely depressing I don't quite understand this point — could you elaborate? My understanding is that the ML model produces a hypothesis, which can then be tested via normal scientific method (perform experiment, observe results). If we have a magic oracle that says \"try this, it will work\", and then we try it, and it works, we still got something falsifiable out of it. Or is your point that we won't necessarily have a coherent/elegant explanation for why it works? reply variadix 15 hours agorootparentThere is an issue scientifically. I think this point was expressed by Feynman: the goal of scientific theories isn’t just to make better predictions, it’s to inform us about how and why the world works. Many ancient civilizations could accurately predict the position of celestial bodies with calendars derived from observations of their period, but it wasn’t until Copernicus proposed the heliocentric model and Galileo provided supporting observations that we understood the why and how, and that really matters for future progress and understanding. reply interroboink 14 hours agorootparentI agree the how/why is the main driving goal. That's kinda why I feel like this is not depressiong news — there's a new frontier to discover and attempt to explain. Scientists love that stuff (: Knowing how to predict the motion of planets but without having an underlying explanation encourages scientists to develop their theories. Now, once more, we know how to predict something (protein folding) but without an underlying explanation. Hurray, something to investigate! (Aside: I realize that there are also more human factors at play, and upsetting the status quo will always cause some grief. I just wanted to provide a counterpoint that there is some exciting progress represented here, too). reply variadix 13 hours agorootparentI was mainly responding to the claim that these black boxes produce a hypothesis that is useful as a basis for scientific theories. I don’t think it does, because it offers no explanation as to the how and why, which is as we agree the primary goal. It doesn’t provide a hypothesis per se, just a prediction, which is useful technologically and should indicate that there is more to be discovered (see my response to the sibling reply) scientifically but offers no motivating explanation. reply Invictus0 14 hours agorootparentprevBut we do know why, it's just not simple. The atoms interact with one another because of a variety of fundamental forces, but since there can be hundreds of thousands of atoms in a single protein, it's plainly beyond human comprehension to explain why it folds the way it does, one fundamental force interaction at a time. reply variadix 13 hours agorootparentFair. I guess the interesting thing for protein folding research then is that there appears to be a way to approximate/simplify the calculations required to predict folding patterns that doesn’t require the precision of existing folding models and software. In essence, AlphaFold is an existence proof that there should be a way to model protein folding more efficiently. reply dekhn 16 hours agorootparentprevPeople will be depressed because they spent decades getting into professorship positions and publishing papers with ostensible comprehensible interpretations of the generative processes that produced their observations, only to be \"beat\" in the game by a system that processed a lot of observations and can make predicts in a way that no individual human could comprehend. And those professors will have a harder time publishing, and therefore getting promoted, in the future. Whether ML models produce hypotheses is something of an epistemiological argument that I think muddies the waters without bringing any light. I would only use the term \"ML models generate predictions\". In a sense, the model itself is the hypothesis, not any individual prediction. reply narrator 16 hours agorootparentprevWhat if our understanding of the laws of the natural sciences are subtly flawed and AI just corrects perfectly for our flawed understanding without telling us what the error in our theory was? Forget trying to understand dark matter. Just use this model to correct for how the universe works. What is actually wrong with our current model and if dark matter exists or not or something else is causing things doesn't matter. \"Shut up and calculate\" becomes \"Shut up and do inference.\" reply dekhn 16 hours agorootparentAll models are wrong, but some models are useful. reply narrator 1 hour agorootparentThe black box AI models could calculate epicycles perfectly so the middle ages Catholic Church could say just use those instead of being a geocentrrism denier. reply RandomLensman 16 hours agorootparentprevHigh accuracy could result from pretty incorrect models. When and where that woukd then go completely off the rails is difficult to say. reply coffeebeqn 9 hours agorootparentprevWouldn’t learning new data and results give us more hints to the true meaning of the thing? I fail to see how this is a bad thing in anyone’s eye. reply visarga 16 hours agorootparentprevML is accustomed with the idea that all models are bad, and there are ways to test how good or bad they are. It's all approximations an",
    "originSummary": [
      "AI AlphaFold 3, a collaboration between Google DeepMind and Isomorphic Labs, accurately forecasts the structure and behavior of proteins, DNA, RNA, and other molecules, aiming to revolutionize biology and drug development.",
      "Users can freely access AlphaFold 3 via the AlphaFold Server, enabling collaborations on drug design initiatives, leveraging its superior predictive capabilities compared to its predecessor, AlphaFold 2.",
      "By responsibly sharing AlphaFold 3's power, researchers worldwide can expedite their breakthroughs and progress in biology and medicine."
    ],
    "commentSummary": [
      "The debate focuses on advancements in protein structure prediction, notably AlphaFold 3 and RoseTTAFold-All-Atom models.",
      "Discussions cover concerns about model accuracy, technology enabling bioterrorism, and the balance between predictive power and scientific principles.",
      "The conversation also addresses AI model roles, challenges in human comprehension, implications of commercialization, funding importance in research, and the pros and cons of machine learning models in research."
    ],
    "points": 933,
    "commentCount": 405,
    "retryCount": 0,
    "time": 1715180830
  },
  {
    "id": 40300454,
    "title": "Development Insights from xkcd's \"Machine\"",
    "originLink": "https://chromakode.com/post/xkcd-machine/",
    "originBody": "chromakode / xkcd-machine May 8, 2024 Development notes from xkcd's \"Machine\" On April 5th, xkcd released Machine, our 15th annual April Fools project. It’s a game we’d been dreaming of for years: a giant rube goldberg machine builder in the style of the classic Incredible Machine games, made of a patchwork of machines created by individual xkcd readers. For more details, check out Explain xkcd’s wonderful writeup. This is the story of how we built Machine in 3 weeks, and what I learned along the way. April 1st is a special occasion where I and others collaborate with xkcd on ambitious interactive comics. This project had the largest group of contributors to date! Expand for full credits. Early machinations It took us deep into March, turning around ideas we were kinda excited about, to find the one that had us all sitting bolt upright. ”Could we make a really big tiled mechanism like the blue balls GIF? Where everyone contributes a small square?” This referenced a classic viral GIF from 2005 (warning: loud music), which was a collaboration composed of tiles made by Something Awful users: Sometimes an idea feels like it emerges fully-formed, but when you start talking about it, you realize there’s still a dizzying array of decisions to make. Thus ensued 5 days of brainstorming to discover each of us had slightly different core beliefs about what this comic should be: Where do the balls come from? Does everyone see the same machine? What is its purpose? How can players interact with it? And most importantly… why do they? Learning from previous attempts My favorite and least favorite interactive comics we’ve ever done have centered around user contributed content. My personal fave was Lorenz, an exquisite corpse where readers evolved jokes and storylines by writing in panel text. So much fun! It doesn’t always work out how we hoped, though. Take 2020’s Collector’s Edition: In Collector’s Edition, players found stickers scattered across the xkcd archives. They could then place each sticker once, permanently, on a global shared canvas. Wouldn’t it be cool if readers could make their own comic panels together? This was the idea we started with, which got pared down to the sticker concept. Unfortunately, the game design didn’t yield the desired results: The initial view for all players was the center of the map, which was initially blank. It quickly descended into chaos. Chaos became every player’s first impression of the game. There was no incentive to carefully consider where to place a sticker. Players didn’t have enough agency to advance the plot through their individual action. This limited creativity to simple patterns like tiling similar stickers or forming lines. We didn’t provide an overarching story or goal. The stickers you had didn’t obviously relate to the others already on the page (the fridge poetry magnets were fun, though). For a collective canvas to shine, the experience should teach you by example what’s cool to make with it. It helps to have a shared context and purpose which motivates what to create. Designing constraints Once we knew we were building a big collaborative marble drop, we were awash with too many choices. Many early approaches seemed like unsatisfying trade-offs, or very difficult to implement. The only thing we were really sure of was there would be a grid of interconnected machines players would create. How big should the overall machine be? Let’s consider 100x100, arbitrarily. How would we simulate it? Running 10,000 tiles in realtime on the client, each with tens of balls, seemed like a risky goal. Also, how could players create subdivisions of a large, complex machine without communicating directly? How would we know tiles designed in isolation would work when integrated together? Many thought experiments later, we ended up with 3 core principles: 1. Maximize player expressiveness at the cost of correctness. How predictable did the machine need to be? We considered running the whole thing server side. Another option was to simulate individual machine tiles to validate them. This would give us some assurance that when everything was connected, the machine would work. Perhaps if the machines were deterministic enough, we could also estimate the rate balls exited each tile. We could use that to approximate the overall flow of the machine, so we could feed tiles balls at the proper rate without running every tile. Once we had a prototype editor running, Davean quickly dispelled this idea by creating a machine with long patterns of chaotic ball collisions: Unless balls moved in straight uninterrupted paths, clearly it was easy for players to make very unpredictable machines. Randall wryly suggested we add double pendulums. From a design standpoint, this settled that making the machines more predictable would trade against degrees of freedom players had. Also, in the face of a tight deadline, it’s best to keep it simple, which favored an approach light on prediction or simulation. We decided to prioritize players having tons of flexibility in what they could build — even extremely nondeterministic or broken machines. This meant we’d need active moderation, both to verify that machines satisfied the constraints, and to remove any offensive content. 2. Give players firm constraints that encourage resilient, interchangeable machines. Accepting moderation and unpredictable player machines made another useful decision for us: ironically, it forced us to require more order between the machines. Early on, we’d considered making the inputs and outputs of machines totally free-form: where previous tiles output balls on their edges, future players would build outwards incrementally. Then we looked at how moderation would work. There was the possibility that we’d need to replace a tile from early on. If tile designs depended on previous ones, this could break a large portion of the machine. This led us to design tight enough constraints that multiple players would create compatible designs within the same tile space. This is the Robustness principle in action: “be conservative in what you send, be liberal in what you accept”. To provide players with input and output constraints, we’d need a map of the whole machine from the start. Generating the map also gave us the opportunity to vary how challenging the machines would be (we called the tile configurations “puzzles”). Kevin’s map generator transitions from simple single-input single-output puzzles to complex 4-in-4-out merges in the middle, back to 2 outputs per tile at the end. On the player side, we designed the constraints so we could give players realtime feedback as they constructed their tile. By requiring that tiles output balls on average at roughly the same rate as they received them, we could discourage machines that ate balls or created a lot of latency (e.g. pooling them up). We chaos tested tiles by randomizing the rate of balls entering the editor to reflect the variance upstream. Our general philosophy became “run the machines for a while, see if on average they meet the constraints given uneven input”. 3. Machines should reach a steady state in the first 30 seconds. This led to a new question: how long would moderators have to watch? We made the arbitrary decision that it should take 30 seconds for machines to enter a steady state, based on napkin math for how long it’d take to moderate the whole machine (e.g. 10k tiles => 83.3 hours). We also made balls expire after 30s. Initially, when there was no expiration, I noticed that everyone’s first experience was balls piling up and filling their screen while they learned how to play the game. This would also bog down the physics simulation as it accumulated a huge number of active rigid bodies. Instead of being fun, the balls were getting in the way! Expiring the balls helped players fall into a pit of success, because machines would not accumulate errors over time. It also drastically simplified moderation, because after watching for 30 seconds, you’ve seen where most balls can end up in their lifetime. Simulation and hyperreality The architecture of Machine made two big bets. The first was: with all of the above design constraints in place, connecting together disparate tiles into an overall machine would work. We generated and solved a few smaller maps to shake that out. Back to another problem, though: how could we display a giant machine if we couldn’t run it in realtime on either the server or client? Before reading further, I’d encourage you to send a little time scrolling around the comic and imagine how it works. Because what follows will spoil it in a big way. As a northstar, I wanted it to be possible to follow a single ball from the top of the machine to the bottom. This meant that even if the whole machine wasn’t being simulated, a window around what the player sees would need to be. Once an early version of the map viewer was working, I started testing out an infinite map with only the viewable area simulated. It looked pretty good — but you can see gaps in the flow when I scroll up, because the initial state of the tiles was empty as they enter the simulation. Instead of an empty tile, we needed them to appear to already have activity in them. So here’s the second bet: we’d snapshot tiles after they’d reached their steady state, only bringing the snapshots into existence just before they scrolled into view. Would players notice? Here’s a view of the final comic, with display clipping turned off (you can do this by disabling the overflow: hidden and contain: paint CSS properties on the containers): Did you notice the snapshots? Unless I’m really looking for them, I don’t. Only the tiles you see rendered exist in the physics simulation. Note that there’s also a minor display optimization going on: even though you only see the balls inside the viewing area, they’re simulated within the whole tile extents. To pretend there’s more machine up above the view, balls are created and fed to the tiles at the top row of the simulation (based on the expected rate of their input constraints). To create snapshots, we tied them into the moderation UI. Mods must wait at least 30 seconds before approving a tile. We then take the snapshot when they click the approve button. This gives mods discretion to wait a little longer for the machine to enter a nice looking state. Snapshotting worked way better than we expected. A really nice consequence is that it resets accumulated error in the machine. As you scroll around, your first impression of a tile is a clean good state that a moderator liked. In practice, if you watch long enough, many machines can get wedged into stuck or broken states, but you’ll never see them if you keep exploring, because you’ll enter fresh snapshots. The machine you’re scrolling around in the comic isn’t real. It’s hyperreal. The whole thing is never simulated in its entirely, and I think turned out better that way! Rendering thousands of balls with React and DOM Machine is built on the Rapier physics engine. Rapier was fantastic to work with: it has great docs, a clean API with lots of useful primitives, and has impressive performance thanks to its Rust implementation (running as WASM in the browser). I was also initially drawn to Rapier’s determinism guarantees, though we didn’t end up doing any server side simulation. On top of Rapier, I wrote a custom React context, , which creates Rapier physics objects and manages them within the React component lifecycle. This made it easy to develop a “widget” component for each placeable object with physics or collision surfaces. Effectively, React functioned as a quick and dirty scene graph. This simplified loading and unloading tiles as the view scrolled: when a tile unmounts, all of the physics and DOM are cleaned up. As a bonus, it made it easy to wire up hot reloading with fast refresh, which was really nice for tweaking collision shapes: Another cool aspect of the React context approach is that all of the physics hooks noop when they’re not inside a . This is used to render static previews of tiles for the moderation UI. I wish I had used components instead of hooks to create rapier objects. I later discovered this is the approach react-three-rapier takes, and it fits better with React diffing (vs. useEffect which destroys the old instance and recreates on dependency change). Machine is rendered entirely using the DOM. During early dev I was leery I’d reach the end of my rope perf-wise. I expected I’d eventually ditch DOM rendering for PixiJS or canvas when it got too slow. However, I wanted to see how far I could take it, since it meant less to build. To optimize rendering performance, the frame loop applies styles directly to widgets with physics simulation. Thus React’s diff only runs when structural changes are made to the scene graph. Initially balls were rendered by React, but the frequent creates / removes were low hanging fruit for reducing diffs, so I created their own optimized renderer. Another win was draw culling for balls and widgets out of view. This performed well with 4000 balls in simulation and hundreds onscreen, so I settled on the DOM-only rendering approach. I’ve heard comparisons drawn between modern browsers and game engines, with their tightly optimized GPU rendering and DOM / scene graph. The similarities have never felt more apt. API and Moderation Machine’s backend was written in Haskell by davean and Kevin, with redis as backing store. We used OpenAPI with OpenAPI fetch to share types between the codebases. This approach had some teething pains adapting Haskell types, but ended up very helpful for coordinating late breaking API changes. This was also my first project using TanStack Query, which was quite handy for caching and automatically refreshing the machine without server push. The moderation UI, designed by Ed White, was critical for us because it bottlenecks all submissions being published. Mods must choose from potentially hundreds of designs for a particular tile. We used a simple approach but unreasonably effective approach to prioritize the queue. Each type of widget has an interestingness score, and we count each instance to sort candidate tiles. This biases towards maximalist solutions, though mods counteract that by reviewing the middle of the list for more minimal ones. The large imbalance between the number of submitted designs and those published in the machine is unfortunate — it’s my least favorite thing about this comic. We searched for a way to make more of the back catalog available prior to launching, but there wasn’t a good compromise given our moderation time constraints. We’d like to find ways to share more of the submission dataset after live submissions are finished. One nice UX finding came from the moderation approve cooldown. Since tile snapshot quality is so important, I hacked in a countdown timer which disabled the moderator approve button until at least 30 seconds had passed running the simulation. This ensures that snapshots are taken of a steady state, and gives time to check that outputs are receiving balls at the expected rate. I initially expected this to be annoying to mods, but to my surprise, they liked how it prevented hasty decisions. Post-launch, I added a slider that allows moderators to speed up the simulation to much faster than realtime. This saves a ton of moderator time, because now the first 30 seconds of a submission can be viewed in under 5 seconds. It’s also quite useful for reviewing the behavior over a longer span of time. A note of appreciation for the “Jamslunt Interfoggle” Finally, I’d to take a moment to appreciate one of my favorite machines. It’s a great example of how even with all our editor constraints in place, serendipitous and funny unintended consequences happen between tiles. The “Jamslunt Interfoggle” was posted within the first couple hours the comic was up. It’s a clever mechanism that exploits the narrow field of fans. It queues blue colored balls in a chute until they accumulate enough weight to spill out the sides. However. The tile that ended up above the Interfoggle, “Bouncy”, is a chaos engine launching balls across 3 crossing paths. Every once in a while, it will send a green ball through the wrong output, which wrecking-balls through the logjam and sends a cascade of blue balls through the Interfoggle. The Interfoggle can’t have been designed with this behavior in mind, because we only feed the correct color in the editor (this was a conscious decision to make inputs easier to understand). Yet, this machine is so much better with the green balls in the mix. One of the great joys of making a project like this is discovering all the creative ways people use it, intentional or not. Even though I know it’s coming, I’m continually amazed by how brilliant the internet is when given a shared canvas. Thanks to everyone who contributed tiles. At the time of writing, there’s still a little time to add your own design to the final machine. You can check out the source code of Machine here. Feel free to drop me a line on Mastodon if you have any questions about it. One cool thing to hack on would be implementing a full global simulation of the machine. I’m quite curious to see how well it works. I hope you’ve enjoyed this deep dive into “Machine”. For more xkcd stories, check out these notes from our space exploration games and 2021’s Morse Code April Fool’s comic.",
    "commentLink": "https://news.ycombinator.com/item?id=40300454",
    "commentBody": "Development Notes from xkcd's \"Machine\" (chromakode.com)549 points by chromakode 16 hours agohidepastfavorite70 comments ralferoo 12 hours agoReading this write up is funny, because I had no idea this is what was happening. There didn't seem to be an explanation of what was going on. I didn't know it was a shared experience, just that various random things seemed to be chaotically happening. I completed a couple of tiles and I guess submitted them as I thought that was how you got to \"the next level\", but gave them really stupid names like \"test 1b\" - mostly this is because I assumed it was single player and only I'd be seeing the name! I also got bored after creating a couple of tiles. I scrolled around and saw very complicated things, but didn't realise they were submissions, just starting points for solving the level... I guess I was the April Fool! reply wodenokoto 3 hours agoparentI didn't even realize it was interactive. I just looked at it and thought \"neat\" reply Cthulhu_ 2 hours agoparentprevThey should've started with an example that you can edit, OR just start with the final result and a call to action, e.g. by focusing it on an empty slot. reply ephaeton 2 hours agoparentprevmaybe they'll do the write up next time before it goes live... reply creatonez 5 hours agoparentprevIt's still open for submissions, by the way. reply jimmydddd 8 hours agoparentprevLOL. I'm much much worse. I played with it for like 2 minutes and had no idea what was going on and gave up. Maybe because I never used that machine game is was patterned after? :-) reply superdisk 2 hours agoprevWhoa, me and a friend had this same idea back in 2014 and implemented it for Ludum Dare. https://nickfa.ro/wiki/CoinSlot Cool to see a more refined and well-functioning version of the idea. reply salamo 24 minutes agoprevReally cool, I really enjoy the \"follow\" feature. Unfortunately, the balls get stuck sometimes and I have to follow a different one. I guess a few bugs slipped through the mod queue. reply donquichotte 4 hours agoprev> There was no incentive to carefully consider where to place a sticker. Players didn’t have enough agency to advance the plot through their individual action. This limited creativity to simple patterns like tiling similar stickers or forming lines. Ah, the game turned into a big corp job! reply itslennysfault 12 hours agoprevI was adding a lot of \"bonk\" elements and I seem to have murdered rapier... Uncaught Error: recursive use of an object detected which would lead to unsafe aliasing in rust at jt (rapier_wasm2d_bg.js:4836:11) at 4ea5626ea4b1e4145572.module.wasm:0xf061c at 4ea5626ea4b1e4145572.module.wasm:0xf0638 at 4ea5626ea4b1e4145572.module.wasm:0xb5e7b at H.remove (rapier_wasm2d_bg.js:1051:14) at l.remove (collider_set.js:87:18) at y.removeCollider (world.js:343:28) at PhysicsContext.tsx:258:15 Also, this is super fun, and I'm sad I didn't learn about it when it was still live. It'd be really really cool if people could still permalink individual machines created. I know that might be an issue for storage. Maaaaaybe just base64 encode the JSON into a URL param??? Please?? I'd love to create weird maps and share them with people. reply aiiane 11 hours agoparentIt's still live. https://xkcd.com/2916/ Machines that make it into the overall public version can be permalinked, but there's no permalinks for individually created things that don't get selected via the moderation queue. This was an intentional decision to avoid the risk of hosting unmoderated user-generated content on the comic's domain. reply bell-cot 16 hours agoprevFWIW, HN's April 6th item on this, with 14 comments: https://news.ycombinator.com/item?id=39953514 reply mihaaly 13 hours agoprevReminds me of this from my young adult years, I wasted sooo much time on this very happily: https://www.myabandonware.com/game/the-incredible-machine-1m... reply windowshopping 12 hours agoparentIt says in the post that this is what inspired the project. reply its_ethan 14 hours agoprevI feel like I'm missing something - why do certain elements seemingly only effect a specific color of ball in the machine? I assume it's to prevent the colors from getting totally jumbled up, but it doesn't seem like that's explained in this write up? reply chromakode 13 hours agoparentWe gave each ball different physical properties. Yellow balls are light and have lots of air drag. Green balls are massive. Red balls are very bouncy. This allows physical sorters to be designed. reply junon 13 hours agorootparentOhhhhhh this makes so much more sense. I was confused about how that was working with some of the designs. Thanks for explaining! reply creatonez 5 hours agorootparentThe Explain xkcd wiki has further documented how the game works: https://explainxkcd.com/wiki/index.php/2916:_Machine reply pimlottc 12 hours agorootparentprevAh, I was confused by this as well, this information is missing from the article. I couldn't find any explanation about the colors in the application either. reply its_ethan 13 hours agorootparentprevOh neat! Thanks for the reply to clarify that - I like having different properties as a concept added to the machine! reply koryk 9 hours agoprevThanks Max, this was a great read! Awesome work and write up. Some good insights about player focused game development too. reply 1-6 3 hours agoprevThe piece was well written and explained the functionality quite elegantly with enough technicality without overburdening the reader with technobabble. reply Cthulhu_ 2 hours agoparentAn XKCD staple, their What If series is really good like that too. A bit silly, pop sci, but simple terms and explanations. reply Rudism 13 hours agoprevThe thing I'm most confused about is I thought xkcd was one guy named Randall's webcomic, but this post makes it sound like there are several people involved in creating the comics. Is that the case? Does Randall still draw them or is it like a company with a whole creative team now? reply aiiane 13 hours agoparentMost comics are just Randall, but there are a handful of people who contribute to the occasional more unique / interactive comics, such as the April Fools ones. reply aidenn0 13 hours agoparentprevI believe his April 1st \"comics\" have always been coded by someone else; there's been development notes by the developer(s) like this posted after each one. reply saganus 13 hours agoparentprevI am actually a little relieved because everytime one of these interactive XKCD comic is published I wonder how does Randall find enough time to work on them, plus What If, etx. Of course there are some people that simpliy are hyper productive, but the level of detail and complexity of these comics always made me feel a bit \"inadequate\" :) reply nolongerthere 12 hours agorootparenttbf, I don't think he has another job, so if he's only creating 3 comics a week and writing his books, there is def enough time as a side project to put out a fun annual comic that requires a bit of work, obviously it would need to be planned well in advance, which it appears this was not. reply Osmium 8 hours agorootparent> “only creating 3 comics a week” As if this is not an absolutely breathtaking creative accomplishment, especially so consistently and after so many years! I agree with another commenter that it probably does get easier with experience, but nevertheless impressive. reply phire 3 hours agorootparentI've always assumed he has a large backlog of comics, and a script that pushes them out on schedule. He can always push new comics into the queue based on current events or fresh ideas, but at other times he can probably go for weeks without needing to draw new comics. reply 9dev 3 hours agorootparentWell, do that for a while, and the queue will empty rapidly :) reply saganus 11 hours agorootparentprevRight. Maybe the workload is manageable, especially for someone with the amount of experience he has, nevertheless the breadth of the stuff he does is what amazes me the most. Just programming one of those interactive comics must be quite a challenge, to then add the story, the wittiness, depth, etc is what blows me away. reply riffraff 6 hours agorootparentprevThere's a YouTube channel too now, for xkcd\"s \"what if\" reply TheAceOfHearts 12 hours agoprevI wish they had a way of easily figuring out if any of the machines you built made it into the final version or not. Maybe for a future design it would be neat to store the titles of previous submissions in something like local storage and you could provide a notification. reply aiiane 11 hours agoparentA member of the community has been creating an index: https://github.com/scpso/incrediblexkcd reply scpso 5 hours agorootparentThanks aiiane reply windowshopping 13 hours agoprevHonestly every time I start to think I'm rather quite good at frontend development, someone posts something like this and makes me feel like an intern by comparison. To have built this in 3 weeks is Herculean to me. It probably would have taken me 3 weeks to figure out the physics context alone. reply FredPret 13 hours agoparentI bet it helps to have a physics PhD on the dev team. It still sure is amazing reply j16sdiz 7 hours agorootparentMany PhD in physics (even those working with number crunching) can't write javascript. Its not like you can solve a 2nd order differential equation in bowser. reply fragmede 2 hours agorootparentOpen your browser's debug console and paste this in: function solveSecondOrderODE(b, c, y0, dy0, dt, tMax) { let t = 0; let y = y0; let dy = dy0; while (t <= tMax) { console.log(`At time ${t.toFixed(2)}: y = ${y.toFixed(4)}`); let ddy = -b * dy - c * y; // Compute the acceleration (second derivative) y += dy * dt; // Update position dy += ddy * dt; // Update velocity t += dt; } } // Example usage: // Constants b and c for the damped harmonic oscillator const b = 0.5; const c = 1.0; // Initial conditions: y0 (initial position), dy0 (initial velocity) const y0 = 1.0; const dy0 = 0.0; // Time step (dt) and maximum time (tMax) const dt = 0.1; const tMax = 10; solveSecondOrderODE(b, c, y0, dy0, dt, tMax); reply simonmic 12 hours agoprevWow! What a work of art! A few more links for the record (don't read too soon, possible spoilers): https://www.reddit.com/r/xkcd/comments/1bxg43b/xkcd_2916_mac... https://www.explainxkcd.com/wiki/index.php/2916:_Machine https://github.com/xkcd/incredible reply rtkwe 8 hours agoprevI looked at this one early in the day and didn't even realize it was all user generated machine components. reply scpso 5 hours agoprevThis is gold! Folks might be interested in my repo of all published machines: https://github.com/scpso/incrediblexkcd reply TacticalCoder 12 hours agoprevIt is reminiscent of the very old DOS game \"The Incredible Machine\": you receive a certain number of various items (fans, conveyor belts, basket balls, tennis balls, cat, mouse (cat would follow mouse upon seeing it), mirror, candles, etc.) and with the items you had, you had to solve a problem like, say: \"To win the level, you must send 32 tennis balls above the wall\". reply stavros 12 hours agoparentYep, the second sentence in the article has a link to Wikipedia. reply abathur 15 hours agoprevI'm just the tiniest bit disappointed to have confirmation that mods probably didn't wait around for one of my zero-element machine submissions (I imagine I called it \"patience is a virtue\", given how long I had to sit around waiting to click submit on it) to eventually pay off :) reply chromakode 13 hours agoparentI saw yours! We do inevitably bias for tiles with some content in them, since otherwise the viewing experience would be quite boring. :) reply abathur 13 hours agorootparentI stand corrected! :) In my defense, I did personally find it quite suspenseful to wait for my vague sense that chaos would eventually reward me to cash out. Now that I reflect, I might have also called it \"WU WEI\". I know I also used that for (at least) one of my zero-element submissions. Also--apologies if the \"ONLY FANS\" submissions wore out their welcome. I'm sure I wasn't the only one, but I was probably a fair fraction :) reply em-bee 14 hours agoparentprevwhat are you referring to? reply abathur 13 hours agorootparentSome tiles are ~solvable without building anything. Sometimes this is dead-simple (the balls just drop from the top on through). Sometimes, they'll solve if you're patient enough (the balls pile up, shift around, and sooner or later enough of them exit within the time window necessary to trigger the submit UI). Edit: to finish connecting the dots just in case--I waited quite a while for one, probably at least 10 minutes--to do this. When the clearance rate for a machine is poor, it will usually drop back under the submit threshold very quickly. In these cases, you have to watch very carefully to be prepared to submit in the brief window that the submit UI is enabled. The OP suggests that during moderation they generally waited 30 seconds for a submitted machine to do the thing before they moved on. reply aiiane 11 hours agorootparentWe also set up the minimum requirement for the submit button to be unlocked to not be too strict, to avoid frustrating people, but held a bit of a higher standard for the things we selected to be part of the public machine. So designs that only just barely work well enough to occasionally unlock the submit button are probably too unreliable to get selected for inclusion (but we made occasional rare exceptions if the submission was particularly interesting / inspired for other reasons). reply iamtedd 12 hours agoprevWhat was the rationale for simulating the machine with physics, and not simply creating an animation engine? reply sfink 12 hours agoparentBecause the machine is a physics simulation. Where users can set up simulated physical objects like barriers and bumpers, and you want the animation to display a simulation of what happens according to the laws of physics. I think you may be missing the point if you think this is an animated rendering of a static setup? reply CSMastermind 12 hours agoprevI totally didn't realize it was collaborative. I thought I was only building rooms for myself lol. Several years ago XKCD released a comic that was different depending the browser, operating system, ip, and referrer you use to view it. I know people uncovered hundreds of versions of it but I never heard a detailed write up about how it worked or how many comics there were available. Does anyone know if they ever figured it out? reply chromakode 11 hours agoparentUmwelt! Explain xkcd has a great writeup on it: https://www.explainxkcd.com/wiki/index.php/1037:_Umwelt reply lukan 11 hours agoprev\"Machine is rendered entirely using the DOM. During early dev I was leery I’d reaching the end of my rope perf-wise. I expected I’d eventually ditch DOM rendering for PixiJS or canvas when it got too slow. However, I wanted to see how far I could take it ... I’ve heard comparisons drawn between modern browsers and game engines, with their tightly optimized GPU rendering and DOM / scene graph. The similarities have never felt more apt.\" The DOM might have become faster, but using the GPU directly via Pixi is still a world above in terms of performance and using Pixi could have made everything more smooth. But dev time was limited .. and the result is still impressive. reply chromakode 11 hours agoparentAgreed. DOM started as a prototype and I stayed on it primarily for dev speed due to momentum (and some React DX things -- I checked out the Pixi React binding but decided not to go down that rabbit hole). It's amazing how efficient Pixi is! reply benlivengood 13 hours agoprevWhy are there no cats in the current machine?? reply drewtato 13 hours agoparentThe explainxkcd wiki says that cats were added later, and that permalinks go to a snapshot of the machine. So it's possible all the cats are lower in the machine, or the permalink is from before cats were added. There's some cats at the bottom of the machine right now. https://xkcd.com/2916/#xt=2&yt=105&v=1402 reply Max-Ganz-II 13 hours agoprevI love this XKCD. I have a bookmark for it, and whenever I want to kick back a bit, perfect. However, I've noticed that it has a tendency to go blank (i.e. fail and stop working) when multiple colour spectrum triangles are in play and in particular when they are on top of each other. I'd really like to see some additional objects to place into the machine. One other problem I have is that the \"perma-link\" button doesn't seem to do anything. When I come back to the URL, my machine isn't there. reply aiiane 11 hours agoparentPermalinks are only for machines that have already been approved via the moderation queue as part of the shared public machine. Submitting a machine only submits it as a candidate for inclusion, it doesn't guarantee that your submission is the one picked for the slot. reply scpso 5 hours agoparentprevHaha I've had the same problem with triangles, stopped using them because they always crash. Only when editing, not when viewing. Have a look at my repo if you want to search for any of your submissions to see if they ever got published. https://github.com/scpso/incrediblexkcd reply Waterluvian 12 hours agoprevI can’t help but hear the Blue Ball Machine music from the YTMND. reply utopcell 12 hours agoprevI don't know what I'm seeing, I missed the Apr/5 xkcd update, but this is fascinating! :-) reply sdwr 14 hours agoprev [–] As a nerd, I hunger for consistency. This wasn't - it took snapshots and handwaved them together. Can't help but feel it would have been a lot better with constrained physics and automated submissions. The current version is probably more fun to be on \"the inside\" of, evaluating submissions and stitching them together, but at the expense of the finished product. reply sfink 12 hours agoparentAs a nerd, I love to see carefully maintained illusions that give a convincing impression of something much more grand going on than is actually happening. Games that push for more and more realism make me wonder why I don't just wander around the real world. Games grounded in realism but augmented with nonrealism (magic, special powers, added knowledge, selective relaxation of physical laws, ...) are fun. Your \"constrained physics\" seems to mean adding constraints to make it implementable. I want constraints aimed at making it cool or fun, and implementable. Which is what this project did. Plus: if you tell me something is smoke and mirrors, I get excited. \"Ooh! How did you time the smoke? Oh, this mirror is half-silvered?! That's awesome, I wouldn't have thought of that! What would happen if...\" reply NBJack 14 hours agoparentprev [–] I may be missing something, but that seems to be an apples to oranges comparison. How is your turn based app example analogous to a complex physics simulation? And what exactly do you consider about the app's multiplayer to be the bar? reply sdwr 14 hours agorootparent [–] Edited since, but what that game does is let you participate asynchronously in a completely distributed way. It's a real miracle of game design. This one is kludging from every angle. They're cheating with the physics, they're cheating with who sees what, they're cheating by handpicking levels. It results in an experience that isn't grounded, because none of the foundational dimensions are real. reply NBJack 11 hours agorootparentAs much as I hate to spoil the illusion, the kludging you mentioned is basically the sum of the natural drawbacks faced in virtually all game design. Whether it's a skybox, an NPC, or a virtual bullet, it's all basically cheating through constraints and illusions. Great example: Space Engineers, a very popular game in which you can build ships, bases, etc. with an incredible consideration for automation, moving things around, etc. One of my favorites. But the game intentionally (1) limits the top speed of all entities to 100m/s, (2) doesn't actually simulate orbital mechanics despite having planets, and (3) forces you to construct things on a 'grid'. All of these constraints are arguably shortcomings, but they also enable the physics engine to live and collisions to work. reply junon 13 hours agorootparentprev [–] You're asking a lot from an April fools joke from a comic creation team. Also, what you're asking for is very hard to do with physics engines as they exist now. Simulating a bunch of non-static elements like that is incredibly expensive. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Chromakode delves into the creation of xkcd's annual 'Machine' project, where readers collaborate to build a massive rube goldberg machine, inspired by a viral GIF.",
      "The project involved implementing creativity constraints, using a map generator for puzzles, and optimizing performance with the Rapier physics engine in Rust.",
      "Challenges included design selection, submission management, with positive user experience results, and a call for more design contributions and hacking ideas for a global machine simulation."
    ],
    "commentSummary": [
      "Users share their experiences with xkcd's \"Machine\" project, creating machines with colored balls and unique features, with some enjoying the interactive elements while others face challenges with game mechanics.",
      "The article explores the collaborative process behind creating XKCD comics, admiration for Randall's creativity, technical details of the machine, and the idea of inclusive game design incorporating constraints and illusions.",
      "Constraints in games like Space Engineers enhance the physics engine performance but can restrict certain gameplay aspects, highlighting the balance between performance optimization and gameplay dynamics."
    ],
    "points": 549,
    "commentCount": 70,
    "retryCount": 0,
    "time": 1715188157
  },
  {
    "id": 40297748,
    "title": "Seabike: Pedal-Powered Underwater Speed Booster",
    "originLink": "https://newatlas.com/marine/seabike-swimming-propeller/",
    "originBody": "Marine 'Underwater bicycle' propels swimmers forward at superhuman speed By Loz Blain May 08, 2024 Facebook Twitter Flipboard LinkedIn 'Underwater bicycle' propels swimmers forward at superhuman speed Yes, this fella's swimming in clip-ons Seabike View 3 Images 1/3 Superhuman speed thanks to pedal power Seabike 2/3 The seabike offers a simple, mechanical way to propel yourself through the water Seabike 3/3 Yes, this fella's swimming in clip-ons Seabike View gallery - 3 images French company Seabike has developed a swimming device that uses your own leg power to accelerate you through the water at superhuman speeds. This crank-driven pusher prop looks a bit like an underwater unicycle... We'd love to take one for a spin! I can't say I've seen anything like this \"underwater mobility device\" before. The idea is simple enough; you extend the Seabike's pole to the appropriate length, then strap it to your waist with a belt. Then you find the pedals with your feet, and start turning the crank, with the waist strap to push against. This drives what looks like about a 15-inch (38-cm) propeller. At this point, you start gliding through the water with the splendid, gracious ease of a cruising dugong with an outboard up its bum. You can swim with your arms as well, which creates a surreal visual effect somewhat akin to watching somebody walking along an airport travelator: Or you can laze along, arms held out Superman-style. Or indeed, you can angle your nose down, go fully underwater and make like a pedal-powered fish. It's fully compatible with a SCUBA setup if you want to really go nuts down there, although you wouldn't want to take it down too deep and overexert yourself. Propellers work both ways, too – so you can also flip the thing upside down, hold the propeller out in front of you, stick some handles on in place of the pedals, and drive the thing with your arms instead. Mind you, this looks a lot less fun. Seabike says the prop turns slowly enough that you can safely use it at the local pool – although you'll certainly cop some dirty looks from the Speedo brigade in the fast lane. It's also buoyant, so you won't have to dive to find it if the thing comes off somehow. It looks like an incredibly fun way to cover distance in open water, too. Seabike runs its own snorkeling tours out of Cannes, and also sells it with snorkel boards and spear fishing kits. Does it pack down for easy storage? You know it does. SEABIKE PRO + Best of all, you can instantly charge this device by eating a hot dog. In an age where everything is going electric, something so simple and mechanical is a welcome change. It appears Seabike has been making these things for at least a year, selling for prices starting at EU€290 (US$310). The idea doesn't seem to have received much attention yet, but that strikes us as just a matter of time; it's a simple, clever gadget that looks like a ton of fun. Personally, I've never really known what to do with my legs on a swim. Nobody's ever properly convinced me that kicking my feet around is worth the effort, absent a set of swim fins. This jigger, according to the manufacturers, makes you handily quicker than an equivalent swimmer with fins on. Sign me up, I'd love to give one a crack! Source: Seabike View gallery - 3 images",
    "commentLink": "https://news.ycombinator.com/item?id=40297748",
    "commentBody": "'Underwater bicycle' propels swimmers forward at superhuman speed (newatlas.com)478 points by peutetre 20 hours agohidepastfavorite247 comments bambax 12 hours ago> French company Seabike They have a .fr domain and a showroom in Cannes, France but the company is headquarted in Italy: PARITET SRL, Via Giovanni da Cermenate 3, 22063 Cantù (CO) Italy Also, the French version of the website is riddled with enormous errors, like \"For traveling light\" translated as \"Pour voyager lumière\", which does not make any sense and isn't even grammatically correct (the proper translation would be \"Pour voyager léger\"). The whole thing does not inspire a lot of confidence. Is the product real? reply stavros 10 hours agoparentWhat, you don't like to travel bright? reply riffraff 6 hours agoparentprevThat's a really odd mistranslation, given the Italian words for lightweight and light source are as different as in french (leggero/a vs luce). Looks like it was translated directly from the English content. reply wood_spirit 18 hours agoprevIt’s obscure but there was such a contraption trialled by the seals and cia in the 1950s http://www.hisutton.com/CIA_Water-Air_1958.html Here’s a pedal powered smuggling submarine from the 1940s http://www.hisutton.com/Swiss-Pedal-Powered-Smuggling-Submar... reply pge 18 hours agoparentInteresting that the CIA conclusion for a device very similar to the article is \"Not recommended for operational use due to its discomfort and very slight gain in speed over that of a swimmer equipped with fins.\" reply freeqaz 13 hours agorootparentToss a battery on it though and what does it look like then? Perhaps you're able to augment a human's ability to traverse longer distances more quickly. That's tech that didn't really exist back then! reply helsinkiandrew 1 hour agorootparentThere's tens of different companies that make these from about $300 https://scootermotion.com/shop/seascooters/ reply HumblyTossed 9 hours agorootparentprevSea scooters already exist. They pull not push from what I see. Basically they’re EDFs with a place to hold on. reply londons_explore 12 hours agorootparentprevAnd it would probably do a decent job of cutting you or your friends up when human and the propellor come into contact... reply lukan 3 hours agorootparentThe article says they move slow enough to not be dangerous. That could be true even battery powered. reply thatguy0900 13 hours agorootparentprevThey already have those, seabobs reply causal 18 hours agorootparentprevYeah I think for most uses I would still prefer fins for their agility. Cool idea though, and we probably haven't seen peak efficiency here. reply RajT88 18 hours agorootparentPeak efficiency probably looks like this: https://newatlas.com/marine/jetcycle-hydrofoil-pedal-bike/ reply gnicholas 16 hours agorootparentThat looks absolutely amazing. Super cool that you can maintain elevation at less than 6 MPH — I was expecting it to be closer to 10 or 15 MPH. reply RajT88 15 hours agorootparent6mph is nothing to sneeze at on the water, in terms of the power it takes to sustain that kind of speed. A person paddling can't sustain 6mph for very long, if they get there at all. reply Retric 15 hours agorootparentWorld record for a human powered hydrofoil is 21.3 mph. https://en.wikipedia.org/wiki/Decavitator 6mph looks a lot more reasonable in that context. reply gnicholas 15 hours agorootparentprevSure, but a person paddling isn't hydrofoiling, right? They're using their arms instead of legs and contending with tons of additional friction/drag. I see this as being akin to bicycling, since it uses the same muscles. reply RajT88 15 hours agorootparentHere's what I am getting at... https://youtu.be/SDX3Hz2gsas A guy on one of these doing the minimum speed. He doesn't look like he's casually pedaling, no? It's probably harder to maintain 6mph than you might think. reply schiffern 13 hours agorootparent>A guy on one of these doing the minimum speed. Counterintuitively, that probably makes it harder. With any wing, the faster you go in level flight the less drag is caused by lift. This strange fact is because moving a large amount of fluid slowly is more efficient than moving a small amount of fluid fast, and a faster wing can interact with more fluid mass per second (\"m dot\"). https://en.wikipedia.org/wiki/Lift-induced_drag#Calculation_... Since skin drag increases with speed, adding these two drag curves together forms a 'valley' in the overall speed-vs-drag curve. Going slower or faster than this ideal speed will result in increased energy per mile. The math is better explained in David MacKay's brilliant ebook, 'Sustainable Energy Without the Hot Air.' https://www.withouthotair.com/cC/page_269.shtml reply cfn 2 hours agorootparentprevThey seem to be struggling a bit and the there's no wind or waves. Maybe coupled with a battery like an ebike it might be sustainable for longer than a few minutes. reply malfist 14 hours agorootparentprevEh, it's hard to tell power output from pedaling cadence unless it's a fixed gear ratio. Most people pedal between 70-100 rpm regardless of the watts they're producing. reply diydsp 13 hours agorootparentThere are some clues in their body language. they appear to be straining. And the pedal movement looks a little jerky, as if the load is changing dynamically in relation to the effective flywheel/inertia of the system. Spinning a higher speeds with less torque is supposedly less tiring. So they might want to gear this down a bit and include a larger flywheel/inertia. Very impressive device tho. Maybe a hybrid approach with a solar panel for charging on the beach... reply newaccount74 13 hours agorootparentTo me it doesn't look like it they were struggling with the physical exertion, but it does seem like they are struggling to properly hold on to the boat. It looks like the boat suffers from poor ergonomics, and needs some proper handles for holding on and steering. reply viraptor 13 hours agorootparentprevIt depends what they're paddling in. Long, slim racing kayak - easy. Short whitewater kayak - impossible. reply kitd 14 hours agorootparentprev6 mph is a gentle paddle in a rowing shell, albeit using an additional set of muscles. reply tigen 15 hours agorootparentprevLooks like pretty hard work compared to land bikes. You never get to coast downhill. I wonder if you can get it to surf on waves. reply aidenn0 16 hours agorootparentprev30x the cost though... reply causal 17 hours agorootparentprevNice - yeah that looks more optimal to me. reply flawsofar 9 hours agorootparentprevEspecially in the water I neither want the burden of being attached to something nor the burden of retrieving it. reply csours 17 hours agorootparentprevprobably should read \"trained swimmer with fins\" It can take some time to get used to fins and the motions needed. Many more people have ridden a bike reply loeg 16 hours agorootparentUsing fins is extremely intuitive for anyone who has swum before. reply delfinom 17 hours agorootparentprevTraining isnt a problem for government run operations which is their context reply csours 16 hours agorootparentYes, but it's not my context. reply noncoml 16 hours agorootparentContext of the reply thread… reply andrewflnr 7 hours agorootparent... which was itself in the context of a device for civilians. To avoid litigating the primacy of nested contexts in a casual conversation, maybe let's agree to not be so picky about which caveats are on topic? reply noncoml 7 hours agorootparentA reply is always in the context of the thing that is being replied on. It’s how replies work… If there is an article about berries and you say you love blueberries and I reply saying “I hate them”, it in the context of blueberries. It doesn’t mean I hate all berries. And I shouldn’t have to clarify that, since I’m replying to a comment about blueberries. How else could this work? reply andrewflnr 6 hours agorootparentAnd everything is always in exactly one easily defined context, right? So for a comment reply we already know the full context just by looking at its immediate parent. That's how nested replies work, right? reply noncoml 6 hours agorootparentYes..? reply andrewflnr 6 hours agorootparentReally? Go into the next HN thread and see how many deeply nested comments you can make sense of by looking only at their parent. reply noncoml 5 hours agorootparentYou are not doing HN right if you are only reading the parent reply lukan 3 hours agorootparentYeah, you both seem to agree. The larger context matters. reply lupusreal 17 hours agoparentprev\"Wartime paddleboards\" is not a phrase I ever expected to read. reply dylan604 17 hours agorootparentBrings a new meaning to \"Charlie don't surf\". At this point though, you have to pretty much imagine that the military has researched any and every mode/method/means of achieving the goals of a mission. I'm sure roller blades and skateboards have been considered at some point as well. reply rcruzeiro 15 hours agorootparentNot sure about the military, but French police has been using rollerblades to patrol the streets of Paris. reply 0xDEADFED5 13 hours agorootparentTaliban rollerbladers: https://nypost.com/2023/11/15/news/taliban-seen-patrolling-k... reply wood_spirit 17 hours agorootparentprevMy memory is fuzzy but I think the Australian SAS or SBS made raids on the Japanese using paddle boards in the Second World War. It’s described in the H I Sutton book, from the website above, but I think it’s out of print now reply rolph 17 hours agoparentprevH. L. Hunley (submarine) https://en.wikipedia.org/wiki/Civil_War_submarine reply timonoko 23 minutes agoprevThere was Australian underwater breathing device, which used your leg movement as only powersource. As I recall it could do 5 meters. Very splendid, except some dozen people managed to misuse it. Diving deeper and without small emergency bottle. So it was banned for all eternity everywhere. Even Chinese have not rekindled this product. reply neerajk 19 hours agoprev> The nominal mode enables motion through the water at 3.6 km/h, and for speed-seekers, the SEABIKE can reach a maximum of 7.9 km/h – much faster than normal swimming speeds or even flipper-assisted swimming. https://www.nauticexpo.com/prod/seabike/product-68606-564117... Pretty fast, but \"superhuman\"? For short distances Michael Phelps can swim faster :) reply richardw 13 hours agoparentMain difference is recruiting much larger muscles, so at some point most humans will be faster over a longer period with the widget. Let Phelps train with this for a couple months and he'd be faster. Although probably sad, because he likes swimming. reply mrfox321 19 hours agoparentprevMichael Phelps is an alien.. reply deltarholamda 18 hours agorootparentIncorrect, he is an evolved dolphin. reply badcppdev 18 hours agorootparentSo dolphins are aliens?? reply el_duderino_ 18 hours agorootparentThanks for all the fish! reply globular-toast 13 hours agoparentprevFor short distances Usain Bolt can run faster than most people can cycle. reply dyauspitr 13 hours agorootparentFor very, very short distances I can run faster than most people can cycle. reply tetris11 12 hours agorootparentFor mere fractions of a second, I can outwalk a jet. reply globular-toast 38 minutes agorootparentActually I think you are making a slightly different observation about acceleration. We were talking about top-end speed, not acceleration from a standstill. reply IncreasePosts 11 hours agorootparentprevWell that's easy, jets can't walk. reply rrobukef 19 hours agoparentprevImagine how fast Phelps could swim with this! reply matt_heimer 17 hours agorootparentGiven that he optimized his training for swimming and not cycling I think he might do better with fins. His top speed of 7.2 - 9.6 km/h is freestyling without fins. He reached somewhere around 13 km/h using a Lunocet monofin. reply willcipriano 19 hours agoparentprevTraveling at that speed for a long distance would be beyond human capabilities, wouldn't it? Super just means beyond, not way beyond. I blame Superman for this notion. reply sandworm101 19 hours agorootparentNot really. Most serious lap swimmers can do a kilometer every 20 minutes sustainably, akin to a marathon runner's pace (Sprint pace would be 100m/minute, with 50m/minute being what you would see in the fast lane of most recreational pools). So 3.6 kph isn't all that different, maybe a little faster than average but I assume they were also using a better-than-average bicycle person when doing the test. There real advantage here is that you can use leg muscle. Distance swimming is all about upper body muscles, with legs being the afterburners only really used for sprinting. This machine would invert that arrangement. reply willcipriano 19 hours agorootparentPerhaps the question must be then is Michael Phelps (or whoever) faster on it? If he or someone else breaks the record with it, he's going beyond human level speed. Until then this may only have the potential to do so. I imagine the first bikes were slower than the top runners of the time? I see potential for the idea. reply sandworm101 19 hours agorootparent>> is Michael Phelps (or whoever) faster on it? Nope. He would be horrible with this device. That would be like asking a champion sprinter to compete in a wheelchair race. He would be using totally different muscles, legs rather than arms, and get schooled by most everyone with a longer history. A champion bicycle rider would do better on this contraption than any champion swimmer. (Due to water's density, champion speed swimming is also 80% technique and body shape rather than muscle/cardio. So until the technique is developed, nobody would be \"good\" with this thing.) reply iambateman 18 hours agorootparentTBH I think Michael Phelps would do just fine with this. :D reply lupusreal 17 hours agorootparentprevNot sure why you're downvoted. Five minutes for a 500 Free is a pretty typical time for boys on highschool swim teams. reply sandworm101 16 hours agorootparentIt has been a while since I was a competitive swimmer (AAA+) but imho five minutes is a very good time for 500m. That would be faster than 95% of master swimmers at such distances, and well into the 0.01% of humans overall. reply lupusreal 15 hours agorootparentAh shit your right, I had in mind 500 (yard) Free. 500 meters in under five is very good, but still attainable by the upper tier of highschool swimmers I think. I could reliably do 500 yards in under five and was a \"B relay\" tier on my team. reply keybored 15 hours agorootparentThe almost-meter Yard has got to pack its bags and go home soon. What is it even doing at this point other than causing naked numeral confusion. reply _carbyau_ 5 hours agorootparentMy youthful swimming career was done in a 33+1/3rd metre swimming pool. I haven't found another one that length. reply lupusreal 14 hours agorootparentprevA lot (most?) of American school pools are built to the yard, so it's going to stick around for a long time I'm afraid. reply sandworm101 11 hours agorootparentprevA couple things. 500m is not actually an event. The event is 400 meters, which is roughly 500 yards. And a yard pool will only be 25 yards, not 50. So yard times are \"short course\" and not really valid for serious competition. A 25-meter/yard pool has fewer turns making them faster, much faster in breaststroke. And a 500-yard in a 250meter pool will include one extra lap, one extra turn, than a 400m in a 25-meter pool. Short-course/yard times all seem faster than they really should be, regardless of distance conversions. reply jasonfarnon 10 hours agorootparentThis isn't a topic I know about, but wouldn't a 25-meter pool have more turns? But if that's a typo I can't see why stopping and turning would be a good thing? reply sandworm101 10 hours agorootparentMeters are longer than yards, by about 8%. So 500yards is loosely about the same distance as 400 meters. But 500yards divides into ten 50-yards laps, or 20 lengths of the pool. With the dive and the finish, that is 19 turns. At each turn they push off the wall and for a few seconds move much faster than when swimming in open water and a greater percentage of time underwater (which is faster). And the swimmers center of gravity doesn't get as close to the wall during a turn, effectively shortening the distance actually swam on every lap ending in a turn. But a 400-meter race in a 25-meter pool (roughly the same distance as 500 yards) has only 8 laps or 16-lengths. It has only 15 turns, meaning four fewer accelerations off the wall and less time underwater. All of these effects change based on the stroke, speed and even size of the swimmers. So there is no good direct comparison between yard and meter pools. And then an olympic pool is 50 meters long, meaning far fewer turns for a given distance. So \"long course\" times are generally slower than short course even at the same distance. (Underwater is so much faster that swimming has rules about how far you can travel underwater during each length.) reply dyauspitr 13 hours agorootparentprevA mid tier marathon runner can do a mile every 20 mins, not a kilometer. It’s a significant difference. reply mb7733 7 hours agorootparentThis is besides the point but a 20 minute mile is a typical walking pace, not anywhere near a mid tier marathon pace (regardless of the definition of mid tier). That would be an 8:40 marathon. reply sandworm101 11 hours agorootparentprevI meant the effort required for the pace, not the literal speed. For a skilled swimmer, 20min per km can be maintained for a few hours, like a runner maintains marathon pace for a few hours. reply user20180120 13 hours agoprevWould this device be even better if it has the newer efficient propeller design called MX-1 Sharrow Propeller ? https://www.boatus.com/expert-advice/expert-advice-archive/2... At the 2020 Miami International Boat Show, Philadelphia-based Sharrow Marine introduced the culmination of a seven-year research and development project called the MX-1 Sharrow Propeller. Unlike every prop that's come before it, rather than blades, the MX-1 has loops of metal attached to the hub. How does this change the dynamic? In a nutshell, much of a prop's inefficiency can be blamed on the blade tips, where vortices and cavitation (commonly called tip vortex cavitation, or TVC) form, creating turbulence and sapping efficiency. Simply put, the loops on a Sharrow have no tips. The net result is an efficiency gain of between 9% and 15%. But just as important, eliminating the cavitation vastly reduces vibrations and noise and makes for a smoother, quieter boat ride. Company president Greg Sharrow tells us that the development of the MX-1 can be credited to music videos. \"I was trying to solve the problem of reducing unwanted noise from drones while filming live music productions,\" he says. \"I've always thought it would be cool to use a drone to get cameras closer to subjects and film them from onstage, but you can't use drones for music broadcasts because they're too noisy. I knew that most of the noise comes from the blade tips and is caused, in part, by tip vortices. So, I'd have to find a way to eliminate them.\" reply nurple 11 hours agoparentI think for water, what you really want is to _breed_ cavitation, but in a way where the jets created by bubble collapse are arranged to face opposite your desired direction of motion. Kind of like Astrophage. reply AlexandrB 12 hours agoparentprevGood question! Boat motors spin a lot faster than the \"Underwater bicycle\" propeller would so perhaps it's not as beneficial here, but would be interesting to try. reply Chrupiter 12 hours agoparentprevWould it be a good idea to try on wind turbines? reply EnigmaFlare 12 hours agorootparentUtility scale wind turbines are already about 50% efficient which is close to the theoretical limit of 59% (Betz limit). The loopy blades would be more expensive to manufacture and transport so there's a trade-off and it's not obvious that efficiency would win. reply mrcartmeneses 12 hours agoparentprevIs that a press release? reply dzhiurgis 11 hours agoparentprevkeep an eye on https://www.youtube.com/@rctestflight - they are doing 3d printed prop benchmark/competition and he already tested design you mentioned reply tokai 20 hours agoprev\"Seabike says the prop turns slowly enough that you can safely use it at the local pool\" Felt a bit iffy about this claim. But looking at the research it seems cadence lowers normally when cycling under water.[0] Fun device. I wonder which pedals would be best for barefoot riding(?). Maybe those strapped ones fix riders like to use. [0] https://ieeexplore.ieee.org/abstract/document/23706 reply xarope 8 hours agoparentGood luck, many pools already ban fins (unless it's part of a training school, in which case the lanes are marked as such) due to risk potential. Secondly, I could see this being used recreationally in the ocean, but in the local pool?!? reply Rinzler89 19 hours agoparentprevYeah I wouldn't want to get hit in the face by those props at the pool. Accidents can always happen. reply giardini 19 hours agorootparentFlip turns would be clumsy at best. reply psadri 18 hours agorootparentReverse all thrusters! reply bandyaboot 12 hours agoprevThey should also sell a model that includes a pair of fake feet that sort of kick at the surface to complete the illusion that you’re a freak of nature. reply Vox_Leone 20 hours agoprevCool. More like an underwater 'monocycle', though. Make it into a full body struct in Y shape acting as kind of both 'guidon' and secondary propulsion axis -- more blades, an underwater tricycle. :) reply Milner08 19 hours agoparentIs a Monocycle something different to a Unicycle? reply szszrk 18 hours agorootparentApparently! I did not expect such a nice find after asking search engine this: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1700041 > There are two main types of single-wheeled vehicles. In a unicycle, the rider sits above the wheel. These vehicles are recognizable by most people. Less well known is the monocycle, where the rider sits inside the wheel. reply jamiek88 17 hours agorootparentThe famous South Park episode was a monocycle! https://en.wikipedia.org/wiki/The_Entity_%28South_Park%29 reply porphyra 16 hours agorootparentprevyeah likewise the dicycle has two big wheels side by side haha reply aidenn0 16 hours agorootparentprevYou must have missed this: https://news.ycombinator.com/item?id=40080406 reply uncertainrhymes 19 hours agoprevI swim because I enjoy it, not because I'm trying to get somewhere fast. This seems awkward and I bet you have to use your arms just to counterbalance the twist you'd get on each 'stroke' of the leg. So even though I think it's goofy, I bet I'd like whoever came up with this. Someone who put a ton of effort into building something they thought would be interesting despite a thousand people telling them it's goofy. Good on them. reply gklitz 19 hours agoparent> I swim because I enjoy it, not because I'm trying to get somewhere fast. I run because I enjoy it, not because I’m trying to get somewhere fast. But I also bike because I enjoy it, not because I’m trying to get somewhere fast. You seem to assume that because this thing is faster, it must automatically be less enjoyable. That’s not the case for bikes, why should it be the case here? In my opinion it sounds fun, and would probably be enjoyable. reply jerlam 17 hours agorootparentMaybe not necessarily \"faster\" but there is an idea that adding any kind of technology should be avoided for recreational activities. For example, you can mountain bike with a fully-suspended e-bike, or you can struggle with a hardtail or even a road bike. Different kinds of fun, but in the former you'll wonder if it's the technology doing all the work. reply nordsieck 14 hours agorootparent> there is an idea that adding any kind of technology should be avoided for recreational activities. That's a pretty weird idea. Skis, snowboards, or snowshoes make traveling on snow, especially downhill, much more fun. Bicycling, rollerblading, skateboarding (basically using anything with wheels) is very commonly considered more fun than running. Most people who swim in cold water prefer using a wet suit rather than toughing it out. And it's pretty fun to use a boat, surfboard, or scuba gear rather than be stuck swimming without any aids. reply gklitz 3 hours agorootparentprev> you'll wonder if it's the technology doing all the work. We’re talking about manually propelled bikes here. The bike isn’t doing all the work, but it is pretty essential in reaching the speed and sustaining the pace. Sure you can argue that if you strap a rocket to your bike then you aren’t doing any work, but that’s not the case in either of these examples, so what’s the purpose of going down that tangent? reply Johnny555 14 hours agorootparentprevthere is an idea that adding any kind of technology should be avoided for recreational activities How do you draw the line at \"any kind of technology\"? Isn't the bike itself \"technology\"? How about pneumatic tires? Or computer designed tread for optimal traction? Is a bike suspension too much technology? How about electric assist that can help you up a hill but won't propel the bike without you pedaling along with it? reply jerlam 9 hours agorootparentDraw the line wherever you want, this isn't some kind of absolute theory of anything. Just that adding stuff to maximize your output isn't necessary to have fun. reply mhink 16 hours agorootparentprevI don't think this argument holds water (pun intended), though, since this device is completely human-powered. reply chasebank 10 hours agorootparentprevIt's all relative, right? Your running shoes are incredible technology. Run barefoot. reply shkkmo 14 hours agorootparentprev> Different kinds of fun, but in the former you'll wonder if it's the technology doing all the work. \"All the work\" is useless hyperbol. There are things that simply can't be done on a road bike. There are things that can be done on a road bike without a significant loss of safety. Sport technology can reduce the skill required for certain things, but it also tends to extend the envelope of what is possible. It is almost never correct to think of technology doing all the work but rather to think of it as an ability multiplier. There are of course, times when it is beneficial to practice without a specific piece of equipment. Either for a challenge or/and to hone a specific sub skill. reply uncertainrhymes 19 hours agorootparentprevThat's a fair point. My (untested) assumption would be that it would be cumbersome and weird, and I wouldn't be 'swimming'. If I were to guess at their motivations, it might be 'what could make me go faster in the water and also be enjoyable'? I'd try it out of curiosity, sure, but I'm pretty sure it wouldn't last beyond the novelty for me. reply DrammBA 18 hours agorootparentBiking is definitely cumbersome and weird at the beginning, and it wouldn't be considered \"running\" by any stretch of the imagination. reply matt-attack 18 hours agorootparentA bike is just a way for runners to cheat. reply password54321 15 hours agorootparentprev>You seem to assume that because this thing is faster, it must automatically be less enjoyable. The problem in this case is that the device is doing part of the swimming for you. reply zardo 15 hours agorootparentI don't understand how this is different than the running-bicycling example. How does this swim for you but a bicycle doesn't run for you? reply hackable_sand 10 hours agorootparentWait until they hear about wheelchair basketball. reply kiba 18 hours agorootparentprevRunning does make pedestrian locomotion more tolerable. Save me some money versus using electric scooters though I think electric scooters are still faster. reply matsemann 13 hours agorootparentprevBut if you wanted to swim fast you could just use flippers, and be much more agile. reply gklitz 3 hours agorootparentSure, and if you want to run fast you can just use rollerblades instead of a bicycle and be be “more agile”. So what? Doesn’t mean bikes aren’t worth anything. reply matsemann 1 hour agorootparentIf you rollerblade or bike, you're no longer running. But with this underwater bicycle they are still swimming, just more awkwardly. So this isn't a new form of transportation. reply giraffe_lady 18 hours agorootparentprevFixed gear bikes are the most fun so it kinda is true of bikes. reply Broken_Hippo 18 hours agoparentprevMy favorite way to swim is with those flippers - because I go fast. Going fast doesnt mean not enjoying it. reply lupusreal 17 hours agorootparentYep, going fast with flippers feels great. reply LtWorf 17 hours agorootparentFeels less great for all the people in the pool that you kick. reply Broken_Hippo 17 hours agorootparentYou don't have to do it in a crowded pool. reply _carbyau_ 4 hours agorootparentprevMy major hassle with touches in pools is frog kick. I have zero issues with fins, on me or others. reply stevage 10 hours agoparentprevPersonally I hate swimming though I kind of like being in water, moving. So I'd definitely benefit from this, if it worked etc. reply hnthrow289570 17 hours agoparentprevIt's pretty neat. I'd want to try a version with a linear motion that drives the propeller for the counterbalance reasons. I could see this as an alternative to fins offered at snorkeling places. That would make a great test environment too. reply arturkesik 15 hours agoparentprevI come from family of scuba divers, and the scuba divers are a perfect market for this I think - pretty rich, pretty lazy and have to cover a lot of distance underwater reply bbarn 11 hours agorootparentMy wife and I rented the double subnado things last time we were out of town diving. Seems that fits the pretty rich and lazy market much better. reply _carbyau_ 4 hours agorootparentAnd less exertion means more time underwater. reply 404mm 19 hours agoparentprevBalancing this device must have been a good problem to solve! All I can think of is “where does the other end that stick go?” reply a_c 19 hours agorootparentTwo propellers spin in different directions might solve it I guess reply 4gotunameagain 18 hours agorootparentThat will counter the rotational force, but not the transversal up your butt. reply abecedarius 18 hours agorootparentMaybe design a pogo-stick-like action, pushing with both legs together? reply whamlastxmas 19 hours agorootparentprevYour blow hole, clearly reply LtWorf 17 hours agoparentprevIf you live somewhere with currents, it could be good to be able to swim at all. reply patrakov 10 hours agoprevThis device is US$310. Good carbon fins (the long ones for freediving) cost just a tiny bit more [1] and can also propel you at a superhuman speed. Plastic ones are even cheaper. A speed comparison would have been nice. EDIT: it's already there: \"This jigger, according to the manufacturers, makes you handily quicker than an equivalent swimmer with fins on.\" [1] https://www.westmarine.com/mares-razor-carbon-dive-fins-41-1... reply wiether 29 minutes agoparentAnd this device is made as cheaply as possible. Plastic everywhere, holes for adaptability... And it's supposed to be used in sea water. I guess the actual plan is to sell classes by taking advantage of the novelty effect. reply robjan 18 hours agoprevFrom the looks of the scuba diving video, it looks worse. There's way more leg movement and it looks less controlled (and more likely to damage corals/kick up sand from the bottom) than slow finning. reply why_at 13 hours agoparentGiven the number of times I've been kicked in the face by another person's fins while scuba diving, I wouldn't want to be anywhere near someone using one of these. reply AnarchismIsCool 5 hours agorootparentLooks fun until both your regs are wrapped around the prop six times. reply margalabargala 18 hours agoparentprevI'm inclined to agree with you. That said this certainly has its place. There are lots of use cases for wanting to swim more quickly through the water, where precise control is less important and where you aren't right next to fragile life. reply fsiefken 18 hours agoprevI wonder how monofins compare as \"swimming\" method, similar, slower or faster? https://www.youtube.com/watch?v=pBsjtSjQEjM reply moffkalast 17 hours agoparentIt certainly has lower energy losses than this geared setup. reply bilsbie 20 hours agoprevI wish we could find a good way to bike over the surface of the water. I haven’t seen anything that’s not slow and cumbersome. reply peutetre 19 hours agoparentHydrofoil bike: https://manta5.com/ https://www.youtube.com/watch?v=heSPbLHftKw reply causal 18 hours agorootparentThat's battery powered though, and looks pretty heavy. I think I'd sooner go for one of these https://liftfoils.com/ reply itishappy 18 hours agorootparentprevFoil boards are getting semi-popular for kiteboarding. They can be self-powered as well using a jumping motion. They also make e-foils with small electric props. https://www.google.com/search?q=foil+board reply debacle 20 hours agoparentprevAnything you choose will be cumbersome because you can't create friction on the water (well...), your ability to move is based on your ability to move water around you. There are solutions that leverage a pair of catamarans and a track system, or a prop. These tend to move very slowly, much slower than a canoe or kayak. The water wheel style systems seem to move faster, but you can just get a pedal kayak and will be the fastest human powered craft on the water. reply etrautmann 19 hours agorootparentI've always wondered why nobody has created something that looks like a catamaran with two rowing shells and a road bike on top directly connected to a prop. That would have minimal drag, an optimal body positioning for using leg muscle strength, and would be fun and intuitive to pilot (facing forwards, feels like biking, etc). The obvious downside is that height above water may be an issue so the catamaran would have to be wide, but it seems solvable. reply hetspookjee 18 hours agorootparentI believe an ocean crossing was even done with this kind of vehicle. reply mhb 15 hours agorootparentprevhttp://www.castlecraft.com/seacycle.htm reply alanbernstein 14 hours agorootparentprevhttps://www.shuttlebike.com/en/ reply debacle 19 hours agorootparentprevThey have, they're still quite slow. reply alanbernstein 14 hours agoparentprevI can only imagine this is slow and cumbersome, but I love the idea of it working with your existing bike: https://www.shuttlebike.com/en/ reply ioseph 10 hours agoprevI've been looking at propulsion options for my sailing dinghy. Electric is heavy, expensive and I'd like to be able to capsize at will. Something like Hobie's mirage drive would be cool but it's another hole in the hull. I also saw a hand cranked propeller with a 3:1 ratio but that would make steering with the other hand awkward. I think I'll have to stick to oars for now reply alliao 12 hours agoprevI still am puzzled about the logistics of it, at the very end of the video there's a sharp pointy end towards the user... do the user shove their private parts between the two shafts... reply ec109685 4 hours agoparentIt plugs into a contraption that goes around your waste: https://www.instagram.com/reel/C6RVpqLpLjl/?igsh=MzRlODBiNWF... reply Intralexical 7 hours agoprevOperator skill level aside, how does this compare to the fish kick? https://en.wikipedia.org/wiki/Fish_kick reply connectsnk 7 hours agoprevThey have plenty of demo videos on their channel dating as far back as 6 years https://m.youtube.com/@seabikeofficial9914 reply __MatrixMan__ 4 hours agoprevLooks like you could use it to go in reverse, which I sometimes want while scuba diving. reply rhaps0dy 20 hours agoprevWhat's the advantage of this over foot fins? reply BurningFrog 19 hours agoparentI think it uses much stronger muscle groups. reply carlosjobim 19 hours agorootparentMaybe the muscle movements are more natural and comfortable. Swimming with high power foot fins is probably as fast as this, but it gets very tiring real fast. reply klabb3 9 hours agorootparentTiring is good though, it means you can reach a maximum of energy expenditure. There’s a trade off with how big to make the fins though, similar to gears on a bike. Too small and you get bigger losses, I assume. Also depends a lot what you optimize for. For underwater swimming, especially scuba, you want to optimize for saving air, meaning minimize the total energy expenditure and keeping heart rate low (the mammalian dive reflex helps here too). In water, that means moving very slowly and with longer strokes, for the same reason container ships move slowly to conserve fuel. It looks really inefficient to pedal fast because all that water around your knees needs to be pushed back and forth for no gain. reply deltarholamda 18 hours agoparentprevFrom the videos, not much IMO. Presumably the guys doing it in the videos have a fair amount of experience with it, and it looks... awkward. Flippers have a great deal of fine control in all axis, and this doesn't look like it does. I'm a pretty fair diver, but when you see guys who dive all the time, they look like they were born with those flippers. And free divers? I can't imagine them giving up their fins. They take advantage of the really long and strong muscles in the legs. reply julianeon 18 hours agoparentprevI can think of a huge one. I live near a fairly dangerous ocean in SF where I’ve gone bodyboarding with a wetsuit and fins. I’m concerned that, if caught in a current, fins are not enough to propel me out of it. This would. The extra power and ease of propulsion could make all the difference. reply SOLAR_FIELDS 18 hours agorootparentI guess the logistics of the thing make all the difference here. Is this something you can detach from a surfboard and equip while being carried out in choppy waters? Could be either really useful or useless depending on that answer reply ben7799 18 hours agorootparentprevYou just need to get familiar with the correct way to handle a current like that. It’s not to fight it. Especially with a bodyboard and fins doing the right thing does not require a ton of strength and shouldn’t be stressful. reply SOLAR_FIELDS 2 hours agorootparentYour comment kind of implies that a strong swimmer with a surfboard and the right knowledge will pretty much never be in a situation where a riptide/undertow/current/whatever you call it carries them out too far to swim back. Is that true? (It might be, I just know very little about surfing) reply defrost 1 hour agorootparentWith heavy caveats it's mostly true. Well informed local oceanriver mouth swimmers are gemnerally aware of the currents and tend to know how far out they carry and where one can get to the side to make their way back. That said, currents are strong, people have bad days, they can panic, water can be cold .. far colder further out than might be expected and that can weaken the body. Surfing is a whole other ball of wax; dedicated surf spots might be well offshore and require a boat or a jet ski to even reach, if those get crunched by a slab or fail there might be a whole lot of swimming to get back to shore, assumming the surf didn't get you. eg: The Right in Western Australia. https://www.youtube.com/watch?v=xjHaFOGBPzk reply matsemann 13 hours agorootparentprevDidn't look to go much faster in the video than what I can do with my freediving fins. reply karaterobot 19 hours agoparentprev> This jigger, according to the manufacturers, makes you handily quicker than an equivalent swimmer with fins on. reply bilsbie 20 hours agoprevThere are a bunch of small watercraft I really want to try. It’s hard to justify the expensive. The hydrofoil board with a prop and motor looks really cool. Just not sure what the learning curve is like and kind of worried about hitting something and flying off. reply grayrest 19 hours agoparentThere's a DIY forum for building those[1] but I think tow boogies[2] are more practical as a project. The idea is a battery box, controller, and motor on a boogie board and shifting the weight of the person being towed allows for steering. [1] https://foil.zone/ [2] https://www.youtube.com/watch?v=S9z6BP8Y42U Since the original article is about human power, I'll also link to this foil[3] which is for pump foiling long distance. I had run across the channel well before that and thought his goal for a half hour was goofy when people were getting 90s or 2 minutes so I was quite shocked when it actually got built. [3] https://www.youtube.com/watch?v=WfJbF0xkUOY reply SkyPuncher 19 hours agoparentprevThose e-foil look amazing, but the prices on them are insane. Like multiple times the price of an e-bike. I, frankly, don’t understand it. They aren’t particularly advanced devices. reply amenhotep 19 hours agorootparentThey're a toy being sold in small numbers to people who live near lakes or can fit driving to the lake with it into their life easily enough to want to buy it - good proxy for having a bit of disposable income to throw around. Market can bear a high price, not enough volume to make competition appealing => ££££ reply ljf 19 hours agorootparentprevI spent a bit of time looking into building your own - from a parts point of view (buying new) you are still looking at £1000 to more like £2500 worth of batteries, controllers, motor and prop, plus the foil and the board you attach it all to. Then you need to make, seal it and make it 'sea worthy' - would be hundreds of hours of work for me. I'd happily buy a well made new one for £3000 if that was what they cost, but half that price is a new good solid paddle board - so I can see why you can't get the same plus all the electronics you need for £3k. We can hope in time the costs come down, but as a niche sport, it will be some time, if ever. Have you seen the cost (and service intervals!) of a new jet ski? All simple tech, but they don't come cheap and need a lot of looking after. I can still dream though. reply sharadov 4 hours agoprevLooks like a shark cutting through the water, incredibly smooth and fast! reply kazinator 12 hours agoprevThe male could also use this to improve dispersion of milt over the roe laid by the female. reply klabb3 9 hours agoparentPlease send a message to the manufacturer asking for a free product sample to try this out on a public beach. reply swader999 19 hours agoprevPairing this with some sort of foil board contraption would be interesting. Once you get up and out of the water on a foil, it's a lot less effort. reply moffkalast 17 hours agoparentAh, you mean these: https://manta5.com Yeah, it exists. reply jpm_sd 19 hours agoprevI'd give it a try, but the \"crotch rod\" mounting strategy looks awfully uncomfortable. Engineering students have been building \"underwater bicycles\" for human-powered submarine competitions for decades! https://internationalsubmarineraces.org/ reply fuzzfactor 10 hours agoprevEver see a fishing lure called a \"spinner\"? In the ocean this could attract some very sizable predators . . . reply logtempo 17 hours agoprevon a bike, we don't use hands to propell ourselves for obvious reason, why they don't also put a crank for the hands too? it double its speed and you can counter balance the legs motion too. reply regularfry 16 hours agoparentProbably attitude control. If your hands are connected to the machine, you've got no control surfaces left. reply thelastgallon 19 hours agoprevThis can be another transportation option, like walking and biking infrastructure. Cities like Venice can offer this today. Other cities which will be underwater eventually will get this water infrastructure built for free. reply hi-v-rocknroll 9 hours agoparentHuman-powered flying cars are next. Peter Thiel will invest billions. reply gnabgib 8 hours agorootparent2013: https://en.wikipedia.org/wiki/Human-powered_helicopter reply danielvaughn 19 hours agoprevAt first glance, the idea of clip-ons in the water seems quite dangerous. reply vitiral 19 hours agoparentReally, why? Because you might drown? Try holding your breath and just floating, arms at your side and legs not moving. You will bob to the surface. Then quickly release your breath and snap your neck back to take a new one. Repeat. That's all it takes to not drown. You could almost do it as a quadriplegic (though I'm not 100% on \"water balance\" in that case). reply simonbarker87 19 hours agorootparentSome people (myself included) don’t float like this. I try basically every time I get in the water and my legs drift down to just after 45 degrees and then I slip under completely and don’t resurface until I give in and swim back up. People who can float never believe me, but enough have now seen me in the water that I know I’m not “doing it wrong” I just don’t float. The people who’ve seen me try it in water always say something along the lines of “huh, I thought everyone could float” we’ve done a few goes. Most people float, I’m just not one of them. reply epiccoleman 18 hours agorootparentYou are not alone! I was in swim lessons since I was like 3, on swim teams from age 8 to 18, I love the water. But I never cracked the code of floating. I can _sort of_ float on my stomach, but this is not especially useful. And I definitely have some degree of buoyancy, I have to let out air if I want to sink to the bottom. But my default state in the water is to bob uselessly near the surface. Even with a big breath, even if I try to hold them up, my legs drag me down. reply itishappy 16 hours agorootparentSame here. I can almost float when equipped with a 3mm closed-cell shorty wetsuit (very buoyant), but my legs still pull me vertical... reply dh2022 19 hours agorootparentprevHave you tried filling your lungs with as much air as possible? reply ben7799 15 hours agorootparentThis is the answer. You're supposed to learn this if you take quality swim lessons. I was a Red Cross Water Safety Instructor and lifeguard. I taught plenty of lessons to sub-10% body fat adults who had this problem. I generally have this problem too. I can still float all day effortlessly. I would totally try this toy out if it was at a resort and I could try it free or for a small charge. I think I wouldn't likely buy one but I would definitely enjoy trying it. It is extremely clear to me this is a toy for expert swimmers. Anyone who has any fear at all of it should not try it. A lot of the comments read to me as people who are not good swimmers and aren't being straightforward about it and are projecting things onto the device. But I also see no reason why you can't use this thing with a PFD. For something like a snorkeling program you could let people use it with a PFD. A lot of people who can't swim freak out and have poor control of their breath. That's why this is a sticking point in lessons sometimes. You can tell someone to slow their breathing and hold more air in their lungs, but they are basically freaking out breathing fast and they have no control. reply _carbyau_ 3 hours agorootparent> This is the answer. Nope. Not even close. If you have any other pearls than \"fill your lungs\" then let me know. I'll be happy to try next time I'm in the pool. reply _carbyau_ 3 hours agorootparentprevNot OP but I have the same or similar issue. Filling your lungs is pretty easy to try and pretty much the first thing that comes to mind and almost always the first suggestion everyone gives. I've done a lot of lap swimming, sub 30s 50m, can hold breath for ages, swim 50m underwater, comfortable scuba diving etc but that doesn't help. The issue is not total flotation per se. It is balance. I can't push air down into my legs, so they go down. I have then lost a lot of surface tension with my body area, so I go down. I end up vertical but with max capacity lungs I can bob near surface. But breathing out to breathe fresh air in makes me go down. Compared to someone floating happily on their back it is not relaxing. I really wish people would give up on the \"eVeRy0ne cAn f1oAt!\" idea. With just my body(IE no floating aids/neoprene), nope. What I do instead, I kick gently. Just enough to keep my feet up. That keeps the rest of me up holding surface tension. I'm pretty sure I could do this for hours if need be but never want to be in a position for survival to know. reply s1artibartfast 18 hours agorootparentprevDoes no part of your body stay on the surface? On average, people stop floating around 10-15% body fat, but this varies based on lung capacity and bone size. Lung capacity is often an under appreciated factor Inflated Lung density is about 25% relative to water, fat is 95%, organs are around 105%, and bones are about 185% reply ninininino 16 hours agorootparentprevIt's just math. If you are too lean and muscular, your density is much higher than if you have a higher body fat composition, but there's also an element for non-fat people and adults that they need to 1) hold their lungs more full than normal with diaphragmatic breathing, holding the breath in for longer, and exhaling more shallowly than a full exhale that they can apply, as well as 2) leaning back much farther and tilting your head back much more than you'd expect to have to. Legs sinking is a classic problem for swimmers that occurs due to body alignment issues and especially not leaning your head and neck far enough back. You need to be an outlier to not be able to overcome a body composition / density problem with techniques #1 and #2 above though, without observing you no one can really say if you're applying those techniques properly. reply 4ad 19 hours agorootparentprevNo, not all people are buoyant. Some people sink. I used to be able to float even with my lungs empty, but after losing 30kg I can now walk on the bottom of the pool will my lungs full of air. Also, even if you are buoyant, it does not follow that being strapped to some device means you can't drown. reply bluefirebrand 19 hours agorootparentprevThis is not true if your feet are clipped to an object heavy enough to keep you under the water though reply xmonkee 19 hours agorootparentThis device is buoyant, according to the article reply cassianoleal 19 hours agorootparentWhich will make your feet float, driving your head underwater. reply davidw 19 hours agoparentprevI noticed that too. Clipless pedals seem like they could be kind of stressful for someone not used to them. Or even someone who is, but is using them in a very unfamiliar situation. reply cassianoleal 19 hours agoparentprevEspecially clipping your feet to a bouyant device! reply xhkkffbf 18 hours agorootparentBetter than clipping them to a non-buoyant device. Or worse, the classic cement overshoes. reply cassianoleal 14 hours agorootparentIf it's non-buoyant and not very heavy, it's easier to control and stay afloat than if it pushes your feet upwards to the surface. reply loeg 19 hours agoparentprevCan you elaborate on that? reply danielvaughn 18 hours agorootparentclip-ons lock your feet to the device. If you find yourself needing to suddenly swim away from the device for any reason, you better hope that you can easily clip out. On a bicycle, you can do this fairly easily because you're on ground with gravity. In water, it could be much more challenging to clip out. reply loeg 15 hours agorootparent> If you find yourself needing to suddenly swim away from the device for any reason Can you elaborate on that part? You would set the cleat retention tension lower than for a bicycle. (But also this product is ridiculous, no one is actually using it.) reply bschmidt1 15 hours agoprevCool invention, kinda like the foil though seems a little ridiculous. Is it really faster than flippers? Didn't seem that quick in the video. reply cimm 20 hours agoprevHow should one take a turn in a swimming pool with this? reply giardini 19 hours agoparentAvec difficulte'! Design engineer: \"Turns? Turns?!\" reply ramesh31 19 hours agoprevThe real question here is about efficiency, not speed. If this does in fact propel divers more efficiently than traditional fins, it could be something useful in extending dive times without the battery limitations of a sea scooter. Otherwise it's just a gimmick. reply deegles 18 hours agoprevFor those wondering... the tip hooks onto a belt... I had the same reaction. They definitely could make it a lot more clear in the images. reply soared 18 hours agoprevSeems prime for attaching to a surfboard reply SOLAR_FIELDS 18 hours agoparentI was thinking freediving as it requires less energy than flippers though I’m not sure the decreased maneuverability of having the thing attached to you would detract from what you are wanting to do when freediving. The article does say you can dive with it, though the devil is in the details eg how easy is it to turn around? I suspice it’s not nearly as easy as flippers Another interesting use case would be just tossing one of these into a boat that you own, or a kayak or whatever. Basically extra insurance to get you back in case your motor dies or you get swept out, similar use case as the surfboard reply yatz 19 hours agoprevGreat for special forces, I guess. reply jononomo 18 hours agoprevWhy wasn't this device invented 100 years ago? It's like a bicycle for people who need to swim to get around. reply hi-v-rocknroll 9 hours agoparentHey now, it's clearly a unicycle. reply Apes 20 hours agoprevI'm curious how this compares to using fins. Just at a glance, I suspect it causes more drag and is more cumbersome to swim with. But the big thing is if it's more efficient overall than fins. reply Sprint9935 19 hours agoparentId imagine this uses stronger muscle groups. Think about how much force you can make pushing down with your leg, compared to moving it forward or backwards when you are upright. reply onemoresoop 19 hours agoparentprevLooks a more uncomfortable than the fins (especially the lumbar lordosis part) but I imagine this should be way faster than fins. reply karaterobot 19 hours agoparentprev> This jigger, according to the manufacturers, makes you handily quicker than an equivalent swimmer with fins on. reply verisimi 19 hours agoprevHow long till this is fitted with a motor, an e-propeller :) reply gklitz 19 hours agoparentThere’s already plenty of electric underwater scooters on the market. This is novel because it’s not electric. reply verisimi 3 hours agorootparentTrue! I realised this a while after I wrote the comment, d'oh! reply FredPret 17 hours agoprevImagine a pro cycler with one of these reply hi-v-rocknroll 9 hours agoparent2/3 of a triathlon. reply tamis022 20 hours agoprevMotorized propellers have existed for 20+ years and are routinely used in spearfishing. What the heck is the news!? https://www.amazon.com/Nautica-Skipper-Seascooter/dp/B0BLP9Z... reply Mordisquitos 20 hours agoparentWhat about non-motorised propellers? reply bilsbie 20 hours agoparentprevI’ve always wished those were slightly cheaper and slightly faster. 4mph and under $250 and I’m sold! reply Pxtl 19 hours agorootparentI assume that now that we're in the world of hyper-cheap batteries I'm sure we'll see somebody do that soon enough. reply Pxtl 19 hours agoprevI mean swim fins also propel swimmers at superhuman speeds (aside, it would be really cool if there was a proper competitive community for stuff like that, like how on land we have races for runners and races for cyclists; edit: Google informs me the competitive sport has world championships and is called \"finswimming\"). Is there any quantitative comparison between this doodad and fins? It doesn't even have convenience going for it since you have to strap into it, so it's probably almost as much of a ball-ache to put on as fins, plus the awkward problem that it's hard to stand up. If they can make it work without the waist strap (or have super-quick disconnect for that strap) I could see that convenience being nice, but still, I'd like proper comparison with fins. reply fnord77 13 hours agoprevNow just need a way to keep your head out of the water besides turning to the sides reply AtlasBarfed 13 hours agoprevHoly shit. What is apparent when you learn to try to swim is that the largest muscles in our body are rendered hugely irrelevant. I don't have exact number, but I'd guess at least 95% of potential power output of our running-optimized evolutionary muscular-skeletal design is wasted in swimming. Maybe Phelps and others can beat that with decades of training from an early age, body shape advantages, long feet, and superior flexibility, but I'd guess they buy just 10% more advantage in power-> speed conversion from the legs. Other examples are how much faster you can swim with flippers. I would actually like to see good swimmers who train to use full scuba flippers vs good swimmers with this bike contraption. This is hilariously efficient compared to that. reply stickfigure 20 hours agoprevnext [4 more] [flagged] philipwhiuk 20 hours agoparent> Whatever its flaws, the writing you find online is authentic That aged like milk. reply NikolaNovak 20 hours agorootparentYeah; I re-read that article couple of months ago. The core notion about submarine articles I find very valid and as Paul suggested, fun to discover. But... internet has changed massively since then, I feel; both the authors and reader audience are different in demographic distribution. I don't much subscribe to the notion that \"Internet is dead\", I think \"old internet\" is still there, just about as large with just about same interested audience, for those who want it. It's merely been... superseded, supplanted, overwhelmed? Whatever the appropriate word is, from early quirky adopters to general mainstream and varied audience. Back to the point though - the trust level of online content I feel has been drastically reduced since Paul's article, and with the AI content generated feedback loop we're encountering as we speak, it may experience a sort of \"crash\" in trust / consumption / economic model. We'll see! :) reply porphyra 20 hours agoparentprevMaybe a PR firm reached out to have this article made, but I somehow doubt that there's a large media conspiracy behind this quirky invention. reply yawpitch 19 hours agoprevIf it’s powered exclusively by a human then whatever the results, they’re not “superhuman”. reply cassianoleal 19 hours agoparentSuper == above, over, beyond. If it augments the human's capabilities, it's definitely super! reply yawpitch 18 hours agorootparentSuper, sure, superhuman, no… someone running in shoes isn’t superhuman compared to someone in bare feet, anymore than someone using a block and tackle to lift or a wheelbarrow to transport is engaging in superhuman acts just because they’ve used their very human brain to leverage a simple machine. Something like this expands the envelope of what is, definitionally, the realm of natural human capacity… it pushes what qualifies as superhuman further away, but it doesn’t mean you’ve done something superhuman. reply _ZeD_ 18 hours agoparentprevwith my bike I can easily outrun any 100m dasher on the earth. reply zharknado 4 hours agorootparentActually you probably can’t, assuming you aren’t a world champion cyclist and you’re starting from a standstill. 100m is too short to capture the advantage unless you’re very, very fast. See: https://www.outsideonline.com/uncategorized/who-would-win-10... reply yawpitch 18 hours agorootparentprevSure… and, notwithstanding the apples to oranges comparison — since I can outswim or out stair climb you when you’re on a bike any day of the week — that means you’re demonstrating how fast a human can turn a crank that a human has connected to a wheel that a human has realized will transfer traction into forward momentum; nothing remotely superhuman has occurred, your maximum speed with that implement is still entirely limited by your very normal human capabilities. reply mihaic 18 hours agoprevThe rotors should be placed in some fine mesh cage. I don't care what the manufacturer says, some idiot is going to cause an accident if safety isn't improved. reply xg15 19 hours agoprev [–] > 'Underwater bicycle' propels swimmers forward at superhuman speed so... like a normal bicycle then. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "French company Seabike created a pedal-powered underwater device, named Seabike, propelling swimmers at exceptional speeds using a crank-driven propeller.",
      "Users can operate the device with their arms or legs, providing a fun and effective method to navigate through water, suitable for both pools and open water.",
      "The Seabike is priced from EU€290 (US$310), offering an affordable option for those interested in this innovative way to explore underwater environments."
    ],
    "commentSummary": [
      "Seabike, a French company, created an underwater bicycle boosting swimmers at remarkable speeds, leading to debates on its efficiency and marine life impact.",
      "Discussions involve human-powered watercraft, underwater transportation, sports technology, and swimming gear effectiveness, sparking varying opinions on the practicality and advantages of such innovative propulsion devices.",
      "Considerations include balance, muscle engagement, and performance concerning these cutting-edge water-based technologies."
    ],
    "points": 478,
    "commentCount": 247,
    "retryCount": 0,
    "time": 1715174002
  },
  {
    "id": 40300023,
    "title": "Remembering Iconic Producer Steve Albini: A Pioneer in Indie Rock",
    "originLink": "https://pitchfork.com/news/steve-albini-storied-producer-and-icon-of-the-rock-underground-dies-at-61/",
    "originBody": "NEWS Steve Albini, Storied Producer and Icon of the Rock Underground, Dies at 61 The Shellac and Big Black frontman, who recorded classic albums by Nirvana, Pixies, PJ Harvey, and more, died of a heart attack By Nina Corcoran and Jazz Monroe May 8, 2024 Steve Albini, June 2005 (Paul Natkin/Getty Images) Steve Albini, an icon of indie rock as both a producer and performer, died on Tuesday, May 7, of a heart attack, staff at his recording studio, Electrical Audio, confirmed to Pitchfork. As well as fronting underground rock lynchpins including Shellac and Big Black, Albini was a legend of the recording studio, though he preferred the term “engineer” to “producer.” He recorded Nirvana’s In Utero, Pixies’ Surfer Rosa, PJ Harvey’s Rid of Me, and countless more classic albums, and remained an outspoken critic of exploitative music industry practices until his final years. Shellac were preparing to tour their first album in a decade, To All Trains, which is scheduled for release next week. Steve Albini was 61 years old. Despite his insistence that he would work with any artist who paid his fee, Albini’s catalog as a self-described audio engineer encompasses a swath of alternative rock that is practically a genre unto itself. After early work on Surfer Rosa, Slint’s Tweez, and the Breeders’ Pod, he became synonymous with brutal, live-sounding analog production that carried palpable raw energy. His unparalleled résumé in the late 1980s and 1990s includes the Jesus Lizard’s influential early albums, the Wedding Present’s Seamonsters, Brainiac’s Hissing Prigs in Static Couture, and records by Low, Dirty Three, Helmet, Boss Hog, Jon Spencer Blues Explosion, Hum, Superchunk, and dozens more. His influence rang through to the next generations of rock, punk, and metal at home and abroad, many of whom he went on to produce—the likes of Mogwai, Mclusky, Cloud Nothings, Mono, Ty Segall, and Sunn O))). He also recorded enduring greats of the singer-songwriter canon: Joanna Newsom’s Ys, Nina Nastasia’s early records, and much of the Jason Molina catalog among them. Albini was born in Pasadena, California, and lived a peripatetic childhood before his family settled in Missoula, Montana. As a teenager, his discovery of Ramones transformed what he described, to Jeremy Gordon for The Guardian, as a “normal Montana childhood” into an altogether wilder entity. In the subsequent years, while studying journalism in Illinois, he was drawn into the Chicago punk scene that his music would come to both defy and define. Albini spent his days at the record store Wax Trax, buying every record that “looked interesting” and talking to “everybody with a funny haircut,” he told NPR. “It was an extremely active, very fertile scene where everybody was participating on every level,” Albini said of Chicago’s music scene. “The community that I joined when I came to Chicago enabled me to continue on with a life in music. I didn’t do this by myself. I did this as a participant in a scene, in a community, in a culture, and when I see somebody extracting from that rather than participating in it as a peer, it makes me think less of that person.… My participation in all of this is going to come to an end at some point. The only thing that I can say for myself is that, along the way, it was a cool thing that I participated in, and on the way out, I want to make sure that I don’t take it with me.” He began recording as Big Black in the early 1980s, channeling antisocial, sometimes violent themes through buzzsaw riffs and histrionic barks, grunts, and whelps, at first backed only by a drum machine (which remained a constant, pounding presence) and soon joined by Naked Raygun’s Jeff Pezzati and Santiago Durango; Dave Riley replaced Pezzati on bass for the band’s two landmark studio albums, Atomizer and Songs About Fucking. In his spare time, Albini would pen screeds in the 1980s zine Matter, admonishing bands in neighboring scenes, establishing the firebrand reputation that established him as an eminent rock grouch and refusenik. After Big Black, Albini formed the short-lived Rapeman—a name he came to regret, despite the sardonic intent—before founding Shellac in the early 1990s, with Bob Weston and Todd Trainer. After a string of EPs through his longtime home of Touch and Go and Drag City, the band extensively toured (including an all-but-residency at Primavera Sound, the only music festival Albini was happy to play) and released five beloved albums: 1994’s At Action Park, 1998’s Terraform, 2000’s 1000 Hurts, 2007’s Excellent Italian Greyhound, and 2014’s Dude Incredible. Albini has long been admired for sticking to his principles and questioning music industry standards, especially in the recording studio. He never took royalties from records on which he worked—including Nirvana’s In Utero, which has sold over 15 million copies—despite that being customary in the industry, and he kept his day rates for artists comparatively low, especially as a producer with his pedigree. At Electrical Audio, his recording studio where he and staff members helped lay bricks in the construction process, Albini was famous for handing artists a yellow legal pad on the first day and instructing them to map out a written description of every song they were going to record. This was his way of avoiding future miscommunications and guaranteeing that artists maximized the in-studio time for which they paid. “The recording part is the part that matters to me—that I’m making a document that records a piece of our culture, the life’s work of the musicians that are hiring me,” he told The Guardian. “I take that part very seriously. I want the music to outlive all of us.” Several bands have recounted experiences when Albini was behind the board reading a book or playing Scrabble during their recording sessions. As Albini explained it, this method helped keep his senses sharp and widened his perspective. “When I first started making records I would sit in front of the console concentrating on the music every second. I found out the hard way that I tended to fiddle with things unnecessarily and records ended up sounding tweaked and weird. I developed a couple of techniques to avoid this,” he explained in a Reddit AMA. “This has proven to be a really good threshold, so that if anything sounds weird or someone says something you immediately give it your full attention and your concentration hasn't been ruined by staring at the speakers and straining all day.” TOP STORIES Steve Albini Remembered: Pixies, Cloud Nothings, and More React to Death of Legendary Rock Figure By Matthew Strauss Drake and Kendrick’s Beef Is the Most Miserable Spectacle in Rap History By Alphonse Pierre Ghostface Killah Enlists Nas, Raekwon, Method Man, and More for New Album By Matthew Strauss Throughout his career, Albini courted controversy through provocative band names (Rapeman, Run N***er Run), song titles ( “Pray I Don’t Kill You F***ot,” “My Black Ass”), and offhand statements (“I want to strangle Odd Future”). While he refused to apologize for his choice in names and jokes, in Michael Azerrad’s 2001 book Our Band Could Be Your Life, Albini made it clear that he believed his real stances on race, gender, LGBTQ rights, and politics were obvious. “I have less respect for the man who bullies his girlfriend and calls her ‘Ms’ than a guy who treats women reasonably and respectfully and calls them ‘Yo! Bitch,’” Albini told Azerrad. “The point of all this is to change the way you live your life, not the way you speak.” Later in life, however, Albini repeatedly apologized for his past controversies, realizing that intent and moral clarity went only so far. “A lot of things I said and did from an ignorant position of comfort and privilege are clearly awful and I regret them. It’s nobody’s obligation to overlook that, and I do feel an obligation to redeem myself,” Albini wrote on X in 2021. “If anything, we were trying to underscore the banality, the everyday nonchalance toward our common history with the atrocious, all while laboring under the tacit *mistaken* notion that things were getting better. I’m overdue for a conversation about my role in inspiring ‘edgelord’ shit. Believe me, I’ve met my share of punishers at gigs and I sympathize with anybody who isn’t me but still had to suffer them.” He talked in depth about his regrets with The Guardian, MEL Magazine, and others. Amid all of his ongoing work, Albini was a remarkable poker player. In 2022, he won a World Series of Poker gold bracelet after beating 773 other players in the $1,500 entry H.O.R.S.E. competition for a huge prize of $196,089. While most players dressed in button-up shirts and plain tees, Albini wore a furry, white hat shaped like a bear and a red Jack O’ Nuts shirt, saying the Athens noise-rock musicians “bring me luck.” He won another WSOP gold bracelet in 2018 for beating 310 players in seven card stud to the tune of $105,629. Back then, he was wearing a Cocaine Piss shirt during the big win. He had a massive grin on his face in the photos documenting both wins. When asked how his career would be regarded if he ever retired, Albini told The Guardian, “I don’t give a shit. I’m doing it, and that’s what matters to me—the fact that I get to keep doing it. That’s the whole basis of it. I was doing it yesterday, and I’m gonna do it tomorrow, and I’m gonna carry on doing it.” TOP STORIES Steve Albini Remembered: Pixies, Cloud Nothings, and More React to Death of Legendary Rock Figure By Matthew Strauss Drake and Kendrick’s Beef Is the Most Miserable Spectacle in Rap History By Alphonse Pierre Ghostface Killah Enlists Nas, Raekwon, Method Man, and More for New Album By Matthew Strauss Head here for remembrances of Albini from Cloud Nothings’ Dylan Baldi, Pixies, Michael Azerrad, Elijah Wood, Jon Wurster, and more. Content To honor your privacy preferences, this content can only be viewed on the site it originates from.",
    "commentLink": "https://news.ycombinator.com/item?id=40300023",
    "commentBody": "Steve Albini has died (pitchfork.com)459 points by coloneltcb 17 hours agohidepastfavorite149 comments ilamont 17 hours agoHard to overstate Albini's influence, both as a musician and producer. Big Black? No one was doing stuff like that in the mid-80s. His production on PJ Harvey's Rid of Me took her compositions to a new level. He also produced a lot of very fine albums in the 80s and 90s by the Pixies (Surfer Rosa), Nirvana (In Utero) and various albums by The Jesus Lizard, Superchunk, and others. Yes, he was cantankerous. Marched to the beat of his own drum, and didn't give a FF about what other people thought. Loved this quote from Tape Op: \"It seemed like most of the music I liked was coming from San Francisco. I don't remember one fucking thing coming out of L.A. that I cared about. And skateboarding. What did that have to do with punk music? What's next, yo-yo tricks?\" https://tapeop.com/interviews/87/steve-albini-Nirvana-Pixies... His essays and observations have been discussed here from time to time. Here are a few: https://news.ycombinator.com/item?id=30892081 https://news.ycombinator.com/item?id=37132320 https://news.ycombinator.com/item?id=38935526 reply consumer451 14 hours agoparentSurfer Rosa was probably the most influential album on my musical life. Albini also has an excellent Nardwuar interview: https://youtu.be/1Vjn8u7HP1o reply wyclif 8 hours agorootparentThe sound and production quality of that specific record was really my golden mean for what an alternative rock record should sound like. I especially loved the way he would record the drums, with that open, uncompressed sound. If you listen to most records that came out in the 1980's the drums sound really dated and super-compressed. reply odiroot 13 hours agoparentprevI can really recommend Songs About Fucking by Big Black. Especially their dope version of Kraftwerk's Das Model. reply throwaway743 7 hours agorootparentIn addition, listen to Atomizer. reply internet101010 10 hours agoparentprevI heard about him on the Foo Fighters HBO docu-series that came out in I think 2015? The one thing that stuck out to me was that he considered what he did a trade in the sense that artists paid for his time and he did not get royalties. reply rurban 12 hours agoparentprevHe was a legend as musician, and as producer, despite destroying PJ Harvey's Rid of Me. What a major fuckup! Anyway, the way he talked and explained the music business was always legendary. reply touseol 10 hours agorootparentI didn’t start listening to PJ Harvey until later in her career, but Rid of Me is one of my favorite albums. It had a sort of harshness that put me off at first, but once I got past that it really grew on me, and now that perceived harshness is an inseparable part of the final product for me. I don’t know how much of that to attribute to Albini or what the album might have been with a different producer, but what it did become still stands out strongly in my musical experience. reply moomin 10 hours agorootparentI love the sound of Rid of Me, with one major exception: the radical volume changes on the title track and Highway 61. I 100% don’t understand what was going on there; it makes it impossible to listen to without riding the volume control and it bears no resemblance to how it was performed live. reply browningstreet 9 hours agorootparentA Mogwai album did this to me once, while I was wearing headphones. I’ve never bothered to work through the process where I’d know when and where this would happen so I can listen to them again. I just dropped them. Despite my phenomenal experience hearing them live in Cambridge MA in the 90s. Loudest band I’ve ever suffered through. But that was live. reply ggm 4 hours agorootparentprevSearch 6+ comments up for somebody with exactly the opposite view of what he did to that track: de gustibus and all that. reply rurban 3 hours agorootparentSearch music producer forums and you will the see the same totally opposing viewpoints as for Napoleon Dynamite. They love it or hate it. Rid of Me is extremely devisive. Excellent record, and extremely influential. Just think of Kathryn Bigelow's Strange Days take on it. But Albini's laissez-faire (non-)production?? reply tptacek 8 hours agorootparentprevI don't think there's a single track on the 4-Track Demos that outdoes its sibling on Rid of Me, which is Harvey's best album. reply boomskats 14 hours agoparentprevAnother one for your list: https://news.ycombinator.com/item?id=35410662 RIP Steve. What a legend. reply throwaway743 7 hours agoparentprevSo sad to hear of his passing. Atomizer is one of my all time favorite albums. His work is timeless and will carry him on. reply vondur 11 hours agoparentprevHe couldn't be more wrong with regards to Skate Punk. reply darby_eight 16 hours agoparentprevYo-yo tricks could be pretty punk I imagine reply ompogUe 16 hours agorootparentHad a yo-yo buff a couple of years ago showing me youtube videos, and he literally said \"the yo-yo scene takes it's fashion cues from skateboard culture\", so full circle? reply brnacl 12 hours agoprevIn 2009 my band traveled from Nashville to Chicago for the honor of recording with Steve at Electrical Audio. We loved his drum tones and his use of analog tape in a live band setting. He was quirky, brilliant, quiet, and kind of hilarious to work with. He wore disheveled blue coveralls with a lowercase \"e\" on the back for 5 straight days. They fed us as many lattes we could stomach for all hours of the day, and he didn't even care if we smoked cigarettes the entire time. Slept on cots in his building, while he stayed in his \"personal\" area. Watching him cut 2 inch tape the old fashioned way was one of the nerd highlights of my life. RIP Steve, and thank you. reply tptacek 10 hours agoparentMy brother is an audio engineer of a sort† and just this afternoon told us that he felt like his team at the venue he works needed a uniform, and he asked Albini about, and as a result everyone ended up with the same Red Kap coveralls Albini wears. † (I say this only because I don't know precisely what sort he is) reply ilamont 12 hours agoparentprevBesides working with analog tape, what else in his process was either surprising or a revelation? In the interview with Conan and Dave and Kris that someone linked to earlier (https://www.earwolf.com/episode/dave-grohl-krist-novoselic-a...), he really tries to disabuse Conan of the notion that he is wielding \"magic\" ... he basically says it's Dave setting up a regular set of drums in a room that has good acoustics, he mics them, and presses \"record\" - he is just trying to capture the band as a band making music together in a room. He said it was similar to what Butch Vig did with Nevermind before the suits forced them to use a different sound and effects in post. Although someone else in the interview did mention that he had special German microphones ... reply breput 16 hours agoprev\"I would like to be paid like a plumber: I do the job and you pay me what it's worth. The record company will expect me to ask for a point or a point and a half. If we assume three million sales, that works out to 400,000 dollars or so. There's no fucking way I would ever take that much money. I wouldn't be able to sleep.\" [0] https://news.lettersofnote.com/p/nirvana reply beezlebroxxxxxx 15 hours agoparentIt's fascinating how in certain genres producers have elevated themselves, rightly in my opinion, to positions that are almost equal to the artists they're recording. In pop and hip-hop, people really care about who produced what, often because the producer has an enormous role in the overall sound of the music. Those producers would probably disagree with Albini right away. It's less a thing when you're dealing with a band or people who play an instrument, but I can also think of some metal producers who have very distinct sounds and who usually leave an \"imprint\" on the recording (Colin Marston and Kurt Ballou for examples). Albini, though, seemed to really believe that his role was to just be a kind of neutral technician, manning the switches and ensuring the band and their music gets on the record through a series of indifferent tubes with no other input. Outside of his position on royalties, he was one of the best and harshest critics of the music industry: https://thebaffler.com/salvos/the-problem-with-music reply breput 14 hours agorootparentHe actually came around later in life on being the harshest critic and also addressed the \"producer role\" in this[0] article: \"As he kept working, making hundreds of records across many more sessions, Albini became more comfortable stepping aside. Experiences like the Plant and Page record reminded him he was just a cog, there to enable someone else’s expression. These days, once Albini has agreed to record an artist, he begins by asking them to state their expectations, what bands they’re into, how they’d like to sound, how they’ve been disappointed in previous sessions. (The process is not unlike starting with a new therapist.)\" [0] https://www.theguardian.com/music/2023/aug/15/the-evolution-... reply leetcrew 14 hours agorootparentprevsteve certainly didn't hold back his contempt for the concept of a \"producer\", but I don't read him as disagreeing they have significant influence over the finished product. if anything, that's the core of his objection: someone other than \"the artist\" diluting the work, and hence why he asked to be credited as \"recording engineer\", if at all. the irony is that, despite his insistent denial, everyone else seems to think there is a signature \"albini sound\". what has changed since he wrote that piece is that the concept of \"the artist\" has been heavily blurred by mainstream music that predominantly features synthesized instruments. if I'm singing words written by one person to a melody written by second over a track composed of thousands of different samples sent through various filters by a third, who is \"the artist\"? reply adw 7 hours agorootparentprevThose (hip-hop) producers are musician-songwriters. They’re more in the Brill Building/Phil Spector mode. Steve Albini recorded the songs you brought in with you. Just a different thing. reply mgkimsal 14 hours agoparentprevI'm trying to reconcile that 'plumber' against George Martin with the Beatles. He was paid like a plumber for the first couple years, and... EMI treated him with such disdain that he ended up leaving. I'm sure the money was much better after he left, but... had EMI just been slightly nicer to him, they'd have owned him for many more years. That said, I think his relationship with his bands opened up areas for him to contribute to the core product more than Albini perhaps did (Martin played piano on some tracks, scored out any classical parts for other musicians, etc). Martin may have been the middle ground between the 'producer-as-top-billing' and 'paid like a plumber' spectrum Albini seems to identify. reply TylerE 13 hours agorootparentMartin was so involved in the creative process he was closer to a 5th bandmember, and was sometimes called such by the Beatles. He had more involvement in the creative product than most producers, including writing and arranging the strings, brass, and winds parts that are all over later Beatles records, and appeared as an instrumental performer on over 25 Beatles tracks. reply gizajob 12 hours agorootparentSo much that EMI have been fixing his work for 60 years now, in particular his decision to split the Beatles tracks arbitrarily between the two speakers for all the stereo mixes, despite the Beatles personal involvement in the mixing process for the mono mix downs which sound infinitely better. reply TylerE 10 hours agorootparentThat was how everything was mixed in the early days of stereo. Beatles actually got away from it sooner than many. Radio was all AM, which is mono. reply mgkimsal 11 hours agorootparentprevThere just wasn't much focus on stereo until the late 60s. Most acts back then have stereo mixes that are not much more than an afterthought. reply tptacek 10 hours agorootparentprevIt's not hard to reconcile: Albini didn't want to be George Martin. reply greenie_beans 9 hours agoparentprevi was once in a debate about capitalism and labor, and this letter was cited. this letter doesn't show the nuance of how he ran his business. here's an article with more insight about his ethos: https://www.psychologytoday.com/us/blog/brick-by-brick/20150... > “Think about it this way: My business is a business of the first type, where everyone involved feels like they’re working on a common project. Everyone involved feels like we are equally valuable. When our clients come in, and they don’t see that there’s a power structure or a hierarchy; nobody has the big office or anything. Everybody is working together as comrades on this project.” > “The remuneration is very equitable. Everybody gets paid the same. I make the same amount of money in a month as the newest employee that we have. So there is a fundamental difference between that and virtually any corporate structure. But you can’t expect people who feel like they are less valuable to a corporation, who feel like their effort, their input, and their opinion means less than someone else in that corporation. You can’t expect those people to jump in and all be pulling for the same results, team players. Because you have defined for them that they are not all pulling for one thing, that they are not team players. You have defined their role for them as subordinate.” reply relaxing 14 hours agoprevAlongside “paid like a plumber” and “already this fucked”, I would like to see added the following wisdom: I think of music as something that I'm willing to work 40 hours a week or more to support, like a wife and family, right? Music to me is that important. It's so important that I don't expect it to make a living for me. I expect that I will have to work a normal, regular job like a regular person in order to have the luxury of being able to play music. He goes on to say this allows him to create without pressure or resentment, only pure joy. https://www.tumblr.com/machinery/44307870770/the-other-bands... reply tptacek 10 hours agoprevGuy was as Chicago as a polish sausage. Contributions to the remembrance thread: Albini on Steely Dan (\"the Dan\"): https://twitter.com/electricalWSOP/status/162260720209465753... His old cooking blog, where I learned that cutting the casing off a hot italian and smooshing it flat is called a \"torpedo\" (at least at Paulina Market): https://web.archive.org/web/20180125095923/http://whatimadeh... Later Another: his interest in uniforms, designs, and the jumpsuits they wear at Electrical: https://paullukas.substack.com/p/talking-uniforms-logos-and-... reply amarcozzi 13 hours agoprevI paused at the name because there was a great scientist and engineer named Frank Albini in the field of wildfire science. Lo and behold Steve Albini was the son of said Frank Albini. I haven't heard of Steve Albini before, and I'm not familiar with his music, but he clearly had an enormous impact. I just thought that it was interesting that both father and son could leave behind such a large legacy in their respective endeavors. reply fogbeak 12 hours agoparentIf you're interested, Steve (Albini) goes into detail about his father and his contributions to wildfire science during an interview on the Marc Maron podcast. It's fascinating listening. reply glammon 7 hours agoprevAnyone here celebrating Steve Albini's life should be aware that this guy was an unrepentant pedophile: https://medium.com/@MoonMetropolis/now-that-steve-albini-is-... An actual quote from him: > Jaded as I am, I can't help but flip seeing a girl and guy of twelve or thirteen, tops, ramming Martel bottles up each other's asses. These are not the Dutch equivalent of abused trailer-park kids, either. They look to be in excellent health and seem to be honestly enjoying this. Makes all the conventional arguments against this kind of thing seem really silly. > They're kids. Kids like to play with their own and other people's privates. They're just being photographed at it. Now, people who get a voyeuristic charge out of watching them, like me, I guess, well, we've got some grip-on-reality problems. There's maybe 1% of all pornography that has any effect on me, and it's definitely not a turn-on very often. But when it is, and it's as weird as this, it’s pretty hard to take. Another, even worse: > The cover of PURE 2 is a guy holding open a toddler’s puny hole so his spuzz can dribble out. The girl is past crying. She is destroyed. > Like I said, I like that sort of thing. He's basically the Jimmy Savile of record producers. Something to consider when glorifying his musical achievements. reply throwupamdaway1 4 hours agoparentIn the full context of the article posted, I think it’s hard to not consider that as anything but an unfiltered fascination with shock depravity - where I think many in society are generally comfortable with the more filtered form (rotten.com, 4chan, etc…) reply DoesntMatter22 5 hours agoparentprevIf that is real then that is absolutely insane. I had no idea. I only learned of him recently during a Rick Beato interview, didn't realize the guy was this nuts. reply throwaway63bc2k 5 hours agorootparentI wouldn't be too surprised if they're real, and yeah it's pretty gross. Albini was a well known edgelord in his 20s, and liked to say shocking bullshit to provoke & upset people. It's hard to say if this is evidence of anything beyond that. He has been very apologetic for at least some of his past antics, band names, lyrics. - https://www.theguardian.com/music/2023/aug/15/the-evolution-... - https://melmagazine.com/en-us/story/steve-albini-counsel-cul... reply droptablemain 15 hours agoprevOne of the most fascinating men that worked in music production/recording. If you aren't familiar with him and his various idiosyncrasies, I highly recommend giving this a watch/listen: https://www.youtube.com/watch?v=sKEzHie9tAI&ab_channel=SAEAu... In my personal list of top 10 albums of all time, Albini recorded six of them. I say \"recorded\" instead of \"produced\" because this is more akin to his style: set up microphones and record the band as they sound. reply evjan 14 hours agoparentOh wow, I'm only 5 minutes in and he's already said so much cool stuff that resonates with me around neomania, timelessness/the lindy effect etc (I've read too much Taleb recently). Thanks for the link! reply nemo44x 15 hours agoparentprevHe famously would hit record and then just play games on his phone until the track was done and ask if they wanted to go again. Of course he did this because he felt after getting things setup and sounding as desired (which he put a lot of work and thought into) it was the artists that were responsible for their art. He would offer his thoughts if asked though. reply danieldk 15 hours agoprevOh man, something I didn't expect at all. They seemed to be doing well with the new Shellac album and all. He is hugely influential and his engineering is uniquely Albini, which is uniquely the bands themselves in their rawest form. I am really happy to have seen Shellac live in 2009. If somebody is looking for deep cuts - there is a recording of Fugazi's In on the Kill Taker by Albini (though it didn't make it to disc): https://www.youtube.com/watch?v=YXN_EmhkQSM reply TheCleric 16 hours agoprevHis recounting of the recording of “In Utero” on Conan O’Brien’s podcast (along with Dave Grohl and Krist Novoselic) is a fantastic hour of storytelling and rock history. Can’t recommend it enough. https://www.earwolf.com/episode/dave-grohl-krist-novoselic-a... reply TheCleric 16 hours agoparentAlso this being his last social media post is peak Albini: https://bsky.app/profile/electricalwsop.bsky.social/post/3kr... reply e40 15 hours agorootparentNever used bsky much since I couldn't find anyone interesting. Had I known about him, I might have used it more... rip. reply tialaramex 14 hours agoprevI knew (of) him first and best for the essay \"Some of your friends are probably already this fucked\" (aka \"The problem with music\") which I was introduced to at about the point in my life where some friends are in bands and a few of them try to go commercial, but fortunately these particular friends had all read The Manual† and this essay by Albini. † https://www.amazon.co.uk/MANUAL-How-Have-Number-Easy/dp/1899... reply selimthegrim 9 hours agoparentI remembered the essay but only now connected it with the author. reply thought_alarm 17 hours agoprevThis news hits like a ton of bricks. I can't think of another single person more influential and important to my own musical journey than Steve Albini. Guys like him are supposed to live to a ripe old age telling stories. It's just a horrible loss. reply mistrial9 16 hours agoparentthat is a ripe old age for rockers.. many souls did not make it past 35 reply telcal 7 hours agoprevWhat could be better than this? \"Shellac agreed to play in my parents' living room in 1993 because I sent them a fax.\" - Jon Solomon https://www.instagram.com/p/C6t2pvCvhpx/ Jon Solomon is a super DJ who among other things has hosted an annual 25 hour long \"Holiday Radio Show\" on WPRB over Christmas for the past 35(!) years! https://en.wikipedia.org/wiki/Jon_Solomon reply SkipperCat 14 hours agoprevKEXP (kexp.org) radio is playing a lot of his catalog right now. Listen in if you want to hear the impact of his work. reply spudlyo 16 hours agoprevSteve Albini has produced two of my favorite records, Surfa Rosa by The Pixies, and Pod by The Breeders. I also quite enjoy Rich Man's 8 Track which is a collection of some of the best Big Black songs. Albini's band Big Black is not for everyone, but if you're a fan of angry punk catharsis you owe it to yourself to check them out. reply rurban 3 hours agoprevI was looking back in time over his catalog of 194 produced records https://en.wikipedia.org/wiki/Category:Albums_produced_by_St... and boy, there were the hidden masterpieces: Electrelane's Power Out and Axes! Pixies Surfer Rosa, PJ Harvey Rid Of Me (though seriously misproduced), Slint Tweez, Breeders Pod, 4 Scout Niblett albums. reply klasko 17 hours agoprevI randomly bumped into him in a bar last year and the guy had an aura that distinguished him from everyone else in the place. Sad. reply sodapopcan 16 hours agoprevOh wow, shit. My one story: A band I was in at the time recorded drums at Electrical Audio in 2010 (I think) and I was the drummer. Albini was not involved in the project and though he was around, we didn't see him much. I would wear this really bad t-shirt with the sleeves cut off to keep cool while playing. As Albini passed by me one time, he looked at me and _very_ sarcastically said, \"Don't worry, you look great\" and kept walking. That was our only interaction. reply relaxing 14 hours agoparentSteve wore a lot of shitty tshirts too, it may not have been entirely sarcastic. reply denvermullets 14 hours agoparentprevHahah, that's amazing reply BoingBoomTschak 15 hours agoprevAnother quote from the music industry's Diogenes: \"Pop music is for children and idiots\". reply jaydestro 14 hours agoprevShellac of North America - Wingwalker. Time was, I could move my arms like a bird Fly! She was a wingwalker Pitgirl of the sky [Verse] And now I got an engine A big perverted engine It runs on strength of will Who could deny me the right to fly? You know, it's my art When I form my body in the shape of a plane... [Chorus] I'm a plane! I'm a plane! I'm a plane! I'm a plane! [Verse] Now I got an airframe A big perverted airframe You know, It's my art When I disguise my body in the shape of a plane [Chorus] I'm a plane! (I'm a plane!) I'm a plane! (I'm a plane!) I'm a plane! (I'm a plane!) I'm a plane! (I'm a plane!) [Outro] (Look at me, look at me - I'm a plane! Look at me, I'm a plane! Look at me!) And the plane becomes a metaphor for my life And as I suffer for it Like I'm insane, as it says... So she suffers under the weight of my plane You know? It's my art! When I disguise my body in the shape of a plane... Plane! (Plane!) RIP Steve. reply Kye 17 hours agoprevHe was a guy who had absolutely mastered the art of the post. Will be missed on and probably in multiple dimensions. reply zonovar 16 hours agoprevI feel very sad! Everything I loved about music had always ties with him, his style and his type of production. I was so excited about the upcoming Shellac album and tour. This hits so heavy... :( reply runnr_az 15 hours agoprevWe all agree that Jawbreaker's \"24 Hour Revenge Therapy\" was his best production work, right? reply adw 7 hours agoparentI think you can make a case for “Things We Lost In The Fire” by Low extremely easily; or for “After Murder Park” by the Auteurs. As a recording engineer he had a lot more range than people gave him credit for, largely because his own music was so abrasive. reply spudlyo 9 hours agoparentprevOh my god. I had no idea he produced that. That record is of monumental importance to one of my dearest friends, and hooked me on early Emo in a way that Rites of Spring never could. Going to listen again and try to detect the invisible hand of Albini. What stands out to you about the production? reply runnr_az 5 hours agorootparentThe listed producer, “Flus” was Albini’s cat. That’s how punk Blake and the gang were - didn’t even list their indie-famous producer on their most popular album. Punk as fuck. As to why, it’s a fantastic example of what Albini did best - it sounds like a real band, raw and live, both melodic and rough around the edges. The guitar sound, iconic, but in the service of the songs. There’s a kind of efficiency to the album - like, no wasted fat, audio gimmick, etc… the Alpinist of punk, bring nothing you don’t need. Can’t wait for someone to generate a version of Nevermind with the production of 24 Hour… reply parpfish 9 hours agoparentprevI thought Joanna Newsom's Ys was great (although very different from his best known works) reply nemo44x 6 hours agoparentprevPod by The Breeders imo. reply pstuart 13 hours agoparentprevBut I'm gonna be that guy that says \"Dear You\" is better. To each their own, but it's a pity that album got slagged. reply runnr_az 13 hours agorootparentWe were such dicks back then. I blame Steve Albini :) reply istultus 12 hours agoprevJust finished another boring run and asked myself \"Why do I do this again?\" then saw the news - dead at 61 due to heart attack. RIP. Scheduling my next boring run. reply bjw4 12 hours agoprevSad to hear Steve has passed. I met Steve, Bob and Todd at Camber Sands 2001 very briefly, really nice people who didn't act like rockstars at all. Q&A sessions, banter with hecklers, Todd talked about his dog (an Italian Greyhound) a bit. Friends band recorded at EA, only possible due to charging a low flat fee and no royalties based on who they were - incredible work ethic that has influenced me greatly. Listening to \"Terraform\" tonight, and maybe Spiderland by Slint after. reply joemi 14 hours agoprevA lot of the bigger name albums he engineered were ones I listened to and loved before knowing that he was a common thread between them (or even who he was in general), but one that I gave a listen to specifically because he engineered it was an album called Stella by a band named Uzeda. I had never heard of them before, but it was wonderful! All the words that often describe his sound (and also his music) apply here. In fact, I believe Uzeda is often compared to Shellac, which seems apt. I highly recommend it, if folks are looking for a good lesser-known album he worked on. reply hipnoizz 13 hours agoparentApproached Uzeda a few times (I'm much into noise-rock-and-all-the-friendly-neighbourhood) but it didn't click. On the other hand https://bellini.bandcamp.com/album/the-precious-prize-of-gra... (which consist of 2/4th or 3/4th of Uzeda I think plus Alexis Fleisig from GvsB) is great. Anyway, I was kind of shattered by the news. All the stuff Steve Albini created (both as the sound engineer and the bands he played with) falls squarely into what moves me (for whatever reasons). And I think he was a really genuine person (outspoken, yes). reply joemi 11 hours agorootparentThanks, I'll have to check them out. reply laurex 10 hours agoprevThis is one of those threads where you may discover people you haven't seen for a zillion years are on Hacker News. And though I never knew him well, he was nice to me on the occasions I had to interact with him, though you know, there's also a kind of unapologetic misogynistic arrogance in his musical catalogue (umm, Rapeman?) that his legacy will need to contend with. reply tptacek 10 hours agoparentHe's apologized at length for his edgy band names, song names, and zine takes which happed in his early 20s. https://melmagazine.com/en-us/story/steve-albini-counsel-cul... reply laurex 10 hours agorootparentYes, he evolved! But that work (fwiw more the actual lyrics than the band name itself) still is part of a legacy. reply gosub100 7 hours agorootparentYou discovered that people make mistakes. Congratulations reply laurex 7 hours agorootparentSigh. I think it’s possible to look at public figures and both see how they are praiseworthy, perhaps corrected errors, and still had impacts with their “mistakes.” I always hope that on HN there’s room for nuance, not just like sarcastic comments implying that a critique was one-dimensional and ill intentioned. reply awkward 10 hours agoparentprevHe’s been fairly open and public recently about his relationship with “edgy” art, his feeling that it didn’t destroy any hidden hypocrisy, and regret for it’s legacy of a coarser society. I don’t mean to express any apologies he didn’t make, but I’ve appreciated his public thoughtfulness about it. reply nemo44x 6 hours agoparentprevRapeman was a completely ironic and funny name because the band was these scrawny, autistic, nerdy dudes that were the antithesis of rapey culture, at least superficially. And he did regret it for a variety of reasons which I believe he was bullied into but w/e as it wasn’t that important. reply nikcub 14 hours agoprevInterview with him just a few weeks ago: https://www.youtube.com/watch?v=MOWP_laIXAs (ps. that entire channel is brilliant) reply neonate 15 hours agoprevhttps://web.archive.org/web/20240508163401/https://pitchfork... https://archive.ph/q6jOl reply prpl 9 hours agoprevBefore hacker news, for me, there was the electrical audio forums. It was probably one of the most interesting places on the internet, and of course Steve with his hat avatar was a big part of that. reply rchaud 16 hours agoprevOnly 61 years old! Stunning to think that he was mixing some of alternative rock's most influential releases 30-35 years ago. reply rightisleft 17 hours agoprevvery sad... he had his hands on so much good noise that i absolutely cherished. We'll be lucky if I don't bust out crying reply rightisleft 17 hours agoparenthttps://youtu.be/c77oOkvCFjo reply soulofmischief 13 hours agoprevRest in peace, a true legend and genius with unparalleled sensibilities. reply bluesounddirect 7 hours agoprev1000hz was an amazing work of art . Steve’s work will be missed . I always hated how I would hear “ Steve Albini made Nirvana what it was” . That’s such an insult to all of the other bands he worked on . Nirvana sucks and will always be a crappy band . reply jfb 15 hours agoprevPosted this on BlueSky. Just gutted. https://bsky.app/profile/tft.io/post/3krylxcef4z2k reply pimlottc 13 hours agoparentCan't read it, sign-in required. reply snorkel 14 hours agoprevWay too soon! He recently did an interview with Dave and Krist from Nirvana about the 30th anniversary of In Utero. They described recording prank phone calls during the recording sessions. reply flyinghamster 14 hours agoparentI've never really paid all that much attention to producers, but 61, it still hits too close to home. I'm not that far behind. It kind of freaks me out that I'm hitting 60 soon. reply ggm 4 hours agoprevBeing hardcore about wearing a uniform by choice is one of those 'I could, and arguably even I should, because it would remove unnecessary choice problems from my life' -But the thing is the people who dive into normcore and buy a wardrobe once of the identi-kit tee and trousers wind up being Steve Jobs fans and nothing, nothing kills the feel more than somebody who is obsessed with Jobs, unless its somebody obsessed with Elon Musk. I think because he actually was a working creative, this side of Albini's character is less important to the story, but its a side I do reflect on: If I ditched 88% of my wardrobe, I might well be happier. The problem is I have bits of several distinct uniform choices I could select from to be \"the one\" and I am unsure I am ready to face that decision-battle. He obviously was. I live in tech conference tee shirts which tend to black. They are over-logofied. (Australian's can elect to wear a particularly odd front-zip or front-popper sleeveless boiler-suit made by Hard Yakka, which I did briefly. I have shy kidneys and peeing standing up is agonisingly slow for me, so I wound up getting tired of the constant bathroom striptease. But that said, I did like them. https://www.workweardirect.online/collections/hard-yakka/pro...) For a while in York I wore an ex-USAF flight suit, the one without all the strings for G forces. It was fine but being high-artificial-fibre content, it simply stank. Cotton is better. reply gmarx 16 hours agoprevI'll second what everyone else said and add that the guy was absolutely amazing at capturing drums. Everything I ever read about the guy sounded positive to me even though the authors might not have agreed reply toomuchtodo 17 hours agoprevhttps://en.wikipedia.org/wiki/Steve_Albini reply nwsm 16 hours agoprevRIP. I just bought Shellac's debut album recently, and they have another set to release soon. I recommend the Kreative Kontrol podcast episode with him and Fred Armisen from last year where they talk about their experiences in the Chicago music scene. https://open.spotify.com/episode/1BeHekAjVm72b9Sc9FlCtu?si=6... reply alangibson 15 hours agoprevSucks to hear. It's worth noting that he didn't consider himself a producer. He always said he was a recording engineer. reply quickthrowman 17 hours agoprevOh man, that’s terrible! I was waiting to hear when the next Shellac tour was going to be taking place, as they’ve got an album coming out next week. I’m a huge, huge fan of Big Black, Rapeman, Shellac, and Steve Albini’s production (Nirvana’s In Utero, Pixies’ Surfer Rosa, Jesus Lizard’s discography, PJ Harvey’s Rid of Me, Brainiac’s Hissing Prigs in Static Couture, Songs:Ohia’s Magnolia Electric Company, plus hundreds more) He could be a bit of a dick but he was an insanely talented musician and engineer/producer. I don’t think any single person has had as much of effect on the music I listen to as Steve did. RIP Steve Albini, your impact on indie music will not be forgotten, and neither will your belt guitar strap. You will be dearly missed, there’s very few people cut from the same cloth you were. A collection of Steve Albini band LPs Big Black - Atomizer: https://youtu.be/03cDvRl3edo Big Black - Songs About Fucking: https://youtu.be/s0xCAZLE7c8 Rapeman - Two Nuns and a Pack Mule: https://youtu.be/JI4keToT1jM Shellac - At Action Park: https://youtu.be/AC7Pkwmllow Shellac - Terraform: https://youtu.be/MueqsKUUlcE Shellac - 1000 Hurts: https://youtu.be/7fXwbFxenC0 Shellac - Excellent Italian Greyhound: https://youtu.be/jQ_Logfsfuw Shellac - Dude, Incredible: https://youtu.be/Gh-SBGIx-2I Shellac - To All Trains: (not on YouTube, this is set for released next week, posthumously) reply BoingBoomTschak 15 hours agoparentHis very close-miked sound still containing a tasteful (i.e. light) amount of reverb is such a recognizable signature... A true legend, and big coincidence since I discovered yet another of his production a week ago: Zeni Geva's last three LPs. Almost as important as the ubiquitous Dan Swano in my collection: $ find -L ~/Music -type f -name album.json -exec jqmusic '.creditshas(\"Steve Albini\")' {} \\; -printawk -F/ '{print $5 \" - \" $6}' Big Black - (1986) Atomizer Big Black - (1982) Lungs Big Black - (1983) Bulldozer Big Black - (1987-1) Headache Big Black - (1987-2) Songs About Fucking Nine Inch Nails - (1999) The Fragile Om - (2007) Pilgrimage The Breeders - (1990) Pod Nirvana - (1993) In Utero The Jesus Lizard - (1990) Head The Jesus Lizard - (1989) Pure The Jesus Lizard - (1991) Goat The Jesus Lizard - (1992) Liar The Jesus Lizard - (1994) Down Pixies - (1988) Surfer Rosa PJ Harvey - (1993) Rid of Me Shellac - (1994) At Action Park Rapeman - (1988) Two Nuns and a Pack Mule Zeni Geva - (1993) Desire For Agony Zeni Geva - (1995) Freedom Bondage Zeni Geva - (2001) 10,000 Light Years To actually hear \"In Utero\" in all its Albini-esque glory, you must find the 2013 20th Anniversary Edition, it's on the 2nd disc. reply ggorlen 6 hours agorootparentZeni Geva deserves more credit, great to see them mentioned. You probably know Neurosis and Melt Banana but those might also be up your alley. Other noteworthy Albini-engineered bands for me: Oxbow, Low, Whitehouse, Labradford, Burning Witch, Godspeed's U.X.O album. Peter Sotos' Buyer's Market is one of the most insane albums I've ever had the displeasure to listen to, and Albini apparently produced it, although I don't hear any obvious influence. reply hipnoizz 13 hours agorootparentprevZeni Geva is such a great band! Maybe you have already seen it, but I've always loved this live cover of 'Model' Kraftwerk by Zeni Geva & Albini - https://www.youtube.com/watch?v=N8R7c7XYmI4. reply singingfish 12 hours agorootparentprevI'm going to put this here - The Crooked Fiddle Band - a Sydney folk band with major inspiration from Big Black and others had two albums produced by Albini - I couldn't think of a better match: https://crookedfiddleband.bandcamp.com/album/overgrown-tales https://crookedfiddleband.bandcamp.com/album/moving-pieces-o... reply SourPatch 12 hours agorootparentprevSteve also played with Zeni Geva as Superunit: https://www.discogs.com/release/876551-Zeni-Geva-Steve-Albin... reply geoffeg 14 hours agorootparentprevWhat are you using to generate album.json? reply adolph 14 hours agorootparentprevAlso, what is this jqmusic executable with the jq style query? reply BoingBoomTschak 14 hours agorootparentJust a jq wrapper that adds -e and includes some functions $ cat ~/bin/jqmusic #!/usr/bin/env bash exec jq -e \"${@:1:$(($#-2))}\" \"include \\\"music\\\"; ${@: -2:1}\" \"${@: -1}\" >/dev/null 2>&1 $ cat ~/.jq/music.jq def year: .releasedmatch(\"[0-9]{4}\").stringtonumber; def has_genre(str): .genres.primaryany(. == str); def match_genre(regexp): .genres.primaryany(match(regexp)); Together with https://git.sr.ht/~q3cpma/rymscrap to get the actual JSON. reply quickthrowman 12 hours agorootparentprevI will check out Zeni Geva, thanks for sharing! reply arp242 16 hours agoparentprevDidn't know Shellac had a new album coming out; they release stuff so infrequently I don't really keep up. Going to have some mixed feelings listening to that one... reply fnordlord 14 hours agoparentprevI've always counted Prayer to God up there in my \"best songs ever\" list. What a huge bummer and loss. reply pimeys 14 hours agoprevAlmost four hours long podcast with Steve Albini. I listened it in two parts, super interesting stuff. https://youtu.be/QKEtP3s1FLw Also others from that podcast are interesting if music production is somehow close to heart. R.I.P. reply fallinditch 15 hours agoprevI became aware of Steve Albini via the PJ Harvey album Rid Of Me - for me this is the most impressive result of his visceral sound, that elevated the emotional rawness of the music perfectly. Currently revisiting another fave he engineered: Seamonsters by The Wedding Present. reply droptablemain 15 hours agoparentTry Nina Nastasia's 2001 album Dogs. You can feel yourself inside that big ol' room at Electric Audio in Chicago. reply Lammy 15 hours agoprevAwful news. I will spin Songs About Fucking while eating a fresh roast beef sandwich today in his honor. reply dredmorbius 13 hours agoprevObit from the Quietus, via a subsequent HN submission:reply vr46 16 hours agoprevDamn. Glad I got to see Shellac at Primavera a few years ago. What a career. RIP. reply cmrdporcupine 16 hours agoprevAw man, that's awful. Time to spend an afternoon blasting Wedding Present's \"Seamonsters\", among other masterpieces he had his fingers on (esp Surfer Rosa as other people mention) Huge loss. reply thr0waway001 15 hours agoprevCrazy to think all the GenX icons are way up there in age. reply slamonjam 15 hours agoprevVery sad news. I've been blasting \"Rid of Me\" the past few weeks, one of these records that just makes me want to crank up the volume. reply geoffeg 15 hours agoprevI wonder if any other musician has had as big an impact on the music I listen to as Steve Albini did. A huge and sudden loss. reply santoshalper 16 hours agoprevWhether he considered himself one or not, Steve Albini will always stand out to me as the epitome of the Punk value system. Here are two of my absolute favorites: * \"I would like to be paid like a plumber\" - https://news.lettersofnote.com/p/nirvana * \"The Problem with Music\" - https://thebaffler.com/salvos/the-problem-with-music reply acdha 10 hours agoprevI enjoyed the different side of him in this story about his beer league baseball team which the author shared on Metafilter: https://themillions.com/2009/02/baseball-oasis-story-of-chic... reply doublepg23 16 hours agoprevEchoing the same sentiments in the thread, hard to overstate his influence on the music I've enjoyed. Rest in peace. reply marpstar 8 hours agoprevTotal legend. I never got the chance to interact with him, but I played with a couple of midwest USA bands/musicians who had. Each of them had a different story and perception of him, but everyone agreed he was a kick-ass dude. For me, much like him, the production side of things was always just as, if not more, alluring as the writing and performing and his no-bullshit approach was a big factor in helping me believe that you could \"hack\" your way into creating an album with the equipment we already had. RIP reply EMCymatics 14 hours agoprevThis is devastating. One of the best there ever was. reply nemo44x 15 hours agoprevHe had strong opinions regarding politics, art, and business and you may strongly disagree with him (or not, or maybe on some things) but he was never a hypocrite. He took his convictions to the grave. reply hank808 14 hours agoprevDamn!!! reply GoofballJones 14 hours agoprevAnd we just saw him in the last few months in a bunch of podcasts talking about the anniversary of In Utero. Sad news. reply zzzbra 16 hours agoprevThis is hugely surprising. 61 is not old man. Is it me or does seem like the Gen Xers in the so-called counter culture are less long lived than their Boomer counterparts? reply justinator 15 hours agoparentI think this line of thinking is a casual example of survivorship bias. reply thr0waway001 13 hours agoparentprevI was talking about this with my g/f when watching Clerks 3. It seems that no other generation seems to be facing their mortality much sooner than Gen Xers. Clerks 3 is a movie about two old Gen Xers coping with getting old, having heart attacks, coping with grief, struggling with loneliness, while the world passes them by. reply arp242 16 hours agoparentprevThat some boomers like Ozzy Osbourne are still alive is just a freak accident. There have been plenty of baby boomer people who died comparatively young. Longevity is part genetics, part lifestyle, and part just dumb luck. Unfortunately Steve just got a bit unlucky, or bad genetics, or both. Or maybe in spite of his alcohol- and drug-free lifestyle he just had a really bad diet. reply caf 9 hours agorootparentLemmy and Prince being two that come to mind immediately. reply newobj 10 hours agoparentprevuhh because the only Gen Xers currently dying are the ones that are dying young? reply agumonkey 16 hours agoparentprevyeah, unlike rock stars with wild lives, I did expect a guy like him to live long reply jprival 13 hours agorootparentbecause of his sort of ascetic impulses in other domains one doesn’t imagine him as particularly hard-living, but this 2002 ilxor thread (bumped for his death) suggests that he had his first heart attack way back: https://www.ilxor.com/ILX/ThreadSelectedControllerServlet?bo... edit: viral pericarditis, actually, before it was a hot topic reply agumonkey 11 hours agorootparentOh, thanks for the link. I had no idea. His story about the band cut on an album budget is mind blowing too. reply nonrandomstring 13 hours agoprevIn my mind, Albini holds a plain speaking American slot besides Hunter S. Thompson, for the similarity of these remarks: \"I imagine a trench, about four feet wide and five feet deep, maybe sixty yards long, filled with runny, decaying shit.\" - Steve Albini \"The music business is a cruel and shallow money trench, a long plastic hallway where thieves and pimps run free, and good men die like dogs. There's also a negative side.\". - Hunter S Thompson When you're good, and you know it, not because people tell you or shower you with praise, but because it comes from love, from the heart, then you know there's nobody whose ass you have to kiss. Steve Albini was an exceptionally competent and emotionally generous person who spoke about the industry as the wide-eyed boy saw the Emperor's \"New Clothes\". Not bitter or superior or excoriating, just casually pointing out the truth; that it's a stinking corrupt pile of shit that deserves to die. Wish there were more Steve Albinis in the tech world, confident going their own way and not sucking up to big-tech pedlars of digital dross. Time for some Pixies... Sad loss. RIP. reply antod 10 hours agoparent> Wish there were more Steve Albinis in the tech world, confident going their own way and not sucking up to big-tech pedlars of digital dross. Thanks for colliding those two worlds into each other for me in a way that never occurred to me. I think the tech world needs it even more than the music world does. eg the way free software and open source's wins have been diluted and sidelined by big tech and big cloud. reply The_Blade 12 hours agoparentprevHenry Rollins reply fwungy 4 hours agoprevAlbini was outspoken about many things. Interesting that he died of a heart attack at a relatively young, healthy man(61). The Covid episode was a particularly brutal time during which some people, like Albini, used their platforms to bully and abuse people who had concerns about the covid vaccine. Albini was one of them. Thrombosis is a known side effect of the covid vaccines and it can cause heart attacks. If you're someone who rook the vaccine because you personally thought it was a good idea or trusted someone who did, I don't have a problem with you. If you're someone like Albini who used their popularity and status to gas light and bully people into a procedure they had questions about, insinuating they were \"stupid\" and \"anti-science\" I hope you live in fear of every twitch and palpitation, every soreness in your chest. I consider you in the same tier of people who helped the Nazi's round up Jews, because you would have. You are petty souls who get excited by authority sanctioned hatred and tyranny. You are the people who enable the worst evils. reply jephson 3 hours agoparent> Interesting that he died of a heart attack at a relatively young, healthy man(61). He had an earlier heart attack at age 25, long before COVID-19. reply damnesian 15 hours agoprevThat's way too fucking young. reply yterdy 12 hours agoprev [4 more] [flagged] tonymet 12 hours agoparent [–] context? reply mycologos 11 hours agorootparent [–] People kept flagging threads announcing Kobe's death when it happened back in January 2020, claiming they were irrelevant to HN. In the end, I think they all got deleted. In contrast, Terry Jones got his own black bar a few days beforehand. For some reason, he was deemed extremely relevant to HN. I appreciate that keeping HN from devolving too far into angry shitposting requires subjective moderation, but I thought and think this was stupid and demonstrates how narrow-minded the conception of \"hacker\" can be on here. reply yterdy 9 hours agorootparent [–] You can search and find a few from the day, but the flaggers specifically targeted the posts with multiple comments. The only ones specifically focusing on the death that are still accessible only have one or two comments. A few tangentially about the accident or his philosophy slipped through. I remember seeing complaints in replies to people mourning, saying absurd things like, \"I've never heard of him before,\" and, \"He's not important/famous enough.\" To this day, I don't know what combination of \"hackers' general disdain for athletes\" and \"internet's general disdain for black people,\" caused this response. I struggle to think of another explanation. This is a good perspective from around that time: https://news.ycombinator.com/item?id=22166309 (archive link: https://archive.is/nzFGy) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Renowned producer and indie rock icon Steve Albini has tragically passed away at 61 from a heart attack.",
      "Albini, famous for his collaborations with bands like Nirvana, Pixies, and PJ Harvey, was also part of Shellac and Big Black, known for his principled stance against exploitative music industry practices.",
      "His legacy in alternative rock and distinctive recording methods leaves a lasting impact on the music industry, remembered by many for his contributions."
    ],
    "commentSummary": [
      "Highly influential musician and producer Steve Albini, known for his work with bands like Big Black, Pixies, and Nirvana, has passed away.",
      "Fans remember Albini for his unique production style, raw sound, and cantankerous personality, shaping alternative rock in the 80s and 90s.",
      "Discussions focus on Albini's impact on the music industry, controversial opinions, and his legacy as fans mourn his death and celebrate his contributions."
    ],
    "points": 459,
    "commentCount": 149,
    "retryCount": 0,
    "time": 1715186003
  },
  {
    "id": 40302201,
    "title": "Consistency Large Language Models: Speeding Up Inference 3.5x",
    "originLink": "https://hao-ai-lab.github.io/blogs/cllm/",
    "originBody": "Consistency Large Language Models: A Family of Efficient Parallel Decoders May 6, 2024 · 10 min · Siqi Kou*, Lanxiang Hu*, Zhezhi He, Zhijie Deng, Hao Zhang An instance of Jacobi trajectory and an illustration of the global consistency loss learning objective. TL;DR: LLMs have been traditionally regarded as sequential decoders, decoding one token after another. In this blog, we show pretrained LLMs can be easily taught to operate as efficient parallel decoders. We introduce Consistency Large Language Models (CLLMs), a new family of parallel decoders capable of reducing inference latency by efficiently decoding an $n$-token sequence per inference step. Our research shows this process – mimicking human cognitive process of forming complete sentences in mind before articulating word by word – can be effectively learned by simply finetuning pretrained LLMs. Specifically, CLLMs are trained to perform parallel decoding by mapping any randomly initialized $n$-token sequence to the same result yielded by autoregressive (AR) decoding in as few steps as possible. Experiment results show CLLMs obtained using our proposed method are highly effective, showing $2.4\\times$ to $3.4\\times$ improvements in generation speed, in par with or even beter than other fast inference techniques like Medusa2 and Eagle, yet require no additional memory cost to accomodate auxiliary model components at inference time. Figure 1: Demo of $\\sim 3 \\times$ speedup by CLLM-ABEL-7B-001 in comparison with baseline ABEL-7B-001 using Jacobi decoding on GSM8K. Background: Jacobi Decoding Large language models (LLMs) are transforming the landscape of human lives, from programming to offering legal and health advice. However, during inference, LLMs generate responses token by token using AR decoding as shown in Figure 1, leading to high latency for longer responses. Using AR decoding, it often necessitates architectural modifications, auxiliary components, or draft models, to speed up inference by generating more than one token at a time. Figure 2: illustration of conventional AR decoding: one token is generated at a time. Jacobi decoding originates from the Jacobi and Gauss-Seidel fixed-point iteration for solving nonlinear equations, and is proven identical to AR generation using greedy decoding. Jacobi decoding reformulates the sequential generation process into a system of $n$ non-linear equations with $n$ variables solvable in parallel based on Jacobi iteration. Each iteration step might predict more than one correct token (By “correct”, we mean alignment with the AR decoding result under a greedy sampling strategy), thereby accelerating AR decoding potentially. Figure 3: illustration of Jacobi decoding: $n$-token sequence is fed into the LLM and iterates until convergence. To be specific, Jacobi decoding method first randomly guesses the next $n$ tokens in a sequence (referred to as $n$-token sequence hereinafter unless specified otherwise) from an input prompt. The $n$-token sequence, along with the prompt, is then fed to the LLM to iteratively update itself. This process continues until the $n$-token sequence stabilizes and no further changes occur, reaching a fixed point. Notably, Jacobi decoding requires no more queries to the LLM than auto-regressive (AR) decoding. Eventually, the $n$-token sequence converges to the output that would be generated by AR decoding under a greedy strategy. This progression from an initial random guess to the final AR generation outcome traces what is known as a Jacobi trajectory. An instance of Jacobi decoding iteration process and Jacobi trajectory is illustrated in Figure 2. Limitations of Jacobi Decoding However, vanilla Jacobi decoding for LLMs shows only marginal speedup over AR decoding in practice, e.g., an average of $1.05\\times$ speedup. This is because an AR-trained LLM can rarely yield a correct token when there are incorrections in its preceding tokens. Thereby, most Jacobi iterations gain only one correction for the $n$-token sequence, resulting in a longer trajectory as illustrated on the left side of Figure 3. Lookahead decoding and speculative decoding methods try to mitigate inefficiency in Jacobi decoding and conventional AR decoding, but incurs extra memory cost during inference time. While CLLMs require none. Consistency LLMs (CLLMs) Jacobi Decoding Preliminary Given a prompt $\\mathbf x$ and a pre-trained LLM $p(\\cdot| \\mathbf x)$, LLM typically generates with the standard AR decoding method under the greedy strategy, i.e. $$ \\begin{align} y_i = \\underset{y}{\\text{arg max }} p(y\\mathbf {y}_{:i}, \\mathbf x) \\ \\ \\text{for}\\,\\, i = 1,\\dots,n \\end{align} $$ Jacobi decoding re-frames the LLM inference process as solving a system of nonlinear equations to transform the decoding process into a parallelizable computation. Consider, $f(y_i, \\mathbf y_{:i}, \\mathbf x):= y_i- \\underset{y}{\\text{arg max }} p(y\\mathbf y_{:i}, \\mathbf x)$, we can rewrite the above equation as a system of nonlinear equations: $$ \\begin{align} f(y_i, \\mathbf y_{:i}, \\mathbf x) = 0 \\ \\ \\text{for} \\quad i = 1,\\dots,n \\Longrightarrow \\begin{cases} y_{1}^{(j+1)} &= \\underset{y}{\\text{arg max}} \\ \\ p(y\\mathbf x) \\\\ y_{2}^{(j+1)} &= \\underset{y}{\\text{arg max}} \\ \\ p(y\\mathbf y_{1}^{(j)}, \\mathbf x) \\\\ & \\vdots \\\\ y_{n}^{(j+1)} &= \\underset{y}{\\text{arg max}} \\ \\ p(y\\mathbf y_{:n}^{(j)}, \\mathbf x) \\end{cases} \\end{align} $$ Note that the process exits at some k such that $\\mathbf y^{(k)} = \\mathbf y^{(k−1)}$ and we define $\\mathbf y^{∗} := \\mathbf y^{(k)}$ as the fixed point, and $\\mathcal J := \\set{ \\mathbf y^{(1)}, \\dots, \\mathbf y^{(k)} }$ as the Jacobi trajectory. Training with Jacobi Trajectories To address this, we propose adapting pre-trained LLMs so that they can consistently map any point $\\mathbf y$ on the Jacobi trajectory $\\mathcal{J}$ to the fixed point $\\mathbf y^*$. Surprisingly, we find such an objective is analogous to that of consistency models, a leading acceleration approach for diffusion models. In our proposed method, we use Jacobi trajectories collected from a target model to train the model with a loss that encourages single-step convergence during Jacobi iterations. For each target model $p$ to be adapted as a CLLM, the training consists of two parts: Jacobi trajectory preparation: for each prompt, we sequentially perform Jacobi decoding for every truncation of $n$ tokens until the entire response sequence $\\mathbf l$ has been generated, which amounts to a concatenation of all consecutive fixed points. Each sequence generated along a trajectory counts as one data entry. Note that for a lengthy response $\\mathbf l$ of $N$ ($N ≫ n$) tokens, such truncation avoids slow model evaluation on lengthy input. Training with consistency and AR loss: we jointly optimize two losses for tuning CLLMs, the consistency loss guarantees the prediction of multiple tokens at once and the AR loss prevents the CLLM from deviating from the target LLM so as to maintain generation quality. Figure 4: an illustration of consistency training for one-step convergence: refining the target LLM to consistently predict the fixed point given any state along Jacobi trajectory as input. Consistency and AR Loss Consistency Loss Let $p$ denote the target LLM. Let $q_\\theta(\\cdot| \\mathbf x)$ denote the CLLM with parameters $\\theta$ initialized with those of $p$. For a prompt $\\mathbf x$ and the corresponding Jacobi trajectory $\\mathcal{J}$, let $\\mathbf y$ and $\\mathbf y^*$ denote a random state and the fixed point on the trajectory, respectively. We can encourage CLLM to output $\\mathbf y^*$ with $\\mathbf y$ as the input by minimizing the following loss, termed as the global consistency (GC) loss: $$ \\begin{align} \\mathcal L_{\\text{GC}} =\\underset{(\\mathbf x, \\mathcal{J}) \\sim \\mathcal{D}, \\mathbf y \\sim \\mathcal{J}}{\\mathbb E} \\Big[ \\sum_{i=1}^n D( q_{\\theta^{-}}(\\cdot|\\mathbf y_{:i}^{*}, \\mathbf x)) || q_{\\theta}(\\cdot|\\mathbf y_{:i}, \\mathbf x)\\Big] \\end{align} $$ where $\\theta^{-} = \\text{stopgrad}(\\theta)$ and we abuse notations to represent uniform sampling from the dataset, and we abuse notations to represent uniform sampling from the dataset. $D(\\cdot||\\cdot)$ denotes the distance between two distributions, choices are discussed in the GKD method and in this paper we primarily experiment with the forward KL. Alternatively, local consistency (LC) loss following the formulation in consistency models, where the adjacent states $(\\mathbf y^{(j)}, \\mathbf y^{(j+1)})$ in a Jacobi trajectory $\\mathcal{J}$ are driven to yield the same outputs: $$ \\begin{align} \\mathcal L_{\\text{LC}} =\\underset{(\\mathbf x, \\mathcal{J}) \\sim \\mathcal{D}, (\\mathbf y^{(j)}, \\mathbf y^{(j+1)} )\\sim \\mathcal{J}}{\\mathbb E} \\Big[ \\sum_{i=1}^n D( q_{\\theta^{-}}(\\cdot|\\mathbf y_{:i}^{(j+1)}, \\mathbf x)) || q_{\\theta}(\\cdot|\\mathbf y_{:i}^{(j)}, \\mathbf x) \\Big] \\end{align} $$ AR Loss To avoid deviating from the distribution of the target LLM, we incorporate the traditional AR loss based on the generation $\\mathbf l$ of the target LLM $p$: $$ \\begin{align} \\mathcal L_{\\text{AR}} = \\underset{ (\\mathbf x, \\mathbf l) \\sim \\mathcal D }{\\mathbb E} \\Big[ - \\sum_{i=1}^N \\log q_{\\theta}(l_i\\mathbf l_{:i}, \\mathbf x) \\Big] \\end{align} $$ Putting the two loss together, with some weight $w$, the total loss for training a CLLM is: $$ \\mathcal{L}(\\theta) = \\mathcal L_{\\text{consistency}} + w\\mathcal{L}_{\\text{AR}} $$ Experiments Results Our experiments contain three domain-specific tasks, including Spider (text-to-SQL), Human-Eval (Python code completion), and GSM8k (math), and the broader open-domain conversational challenge, MT-bench. Reported experiments were conducted using either fine-tuned coder LLM, Deepseek-coder-7B-instruct, LLaMA-2-7B or ABEL-7B-001 as the target model depending on the task. Both training and evaluation are carried out on NVIDIA A100 40GB servers. Figure 5: CLLM speedup on different downstream tasks. CLLMs are significantly faster than pre-trained models and achieve comparable speedups in comparison with Medusa, yet with no extra cost at inference time. Figure 6: illustration of CLLM vs. other baselines on domain-specific tasks (Spider, CSN-Python, GSM8k), as well as on MT-bench. CLLMs achieve similar or even better speedup in comoparison with Medusa2 while introducing no extra inference cost (in terms FLOPS and memory consumption). Specialized domains: From Figure 5, we can see that in comparison with other baselines including the original target model, Medusa2, and speculative decoding, CLLMs achieve the most significant speedup. Open-domain conversational Challenge (MT-bench): CLLM trained from LLaMA2-7B using ShareGPT dataset can achieve roughly the same speedup as Medusa2 when combined with lookahead decoding, with comparable scores on MT-bench. However, CLLM offers higher adaptability and memory efficiency as it requires no modifications to the target model’s original architecture and no auxiliary components. Training Cost The fine-tuning cost of CLLMs is moderate, e.g., passing only around 1M tokens for LLaMA-7B to achieve a $3.4\\times$ speedup on the Spider dataset. In the cases where the dataset size is large, for example, for CodeSearchNet-Python, only 10% of the dataset is required to generate Jacobi trajectories in training CLLMs to obtain around $2.5\\times$ speedup. The total number of tokens can be estimated by taking: $N = $ avg # of trajectories per prompt $ \\times $ avg trajectory length $ \\times $ # of prompts. dataset estimated training cost (tokens) $\\%$ of pre-training cost Spider 2M $< 0.01\\%$ CodeSearchNet-Python 100M $\\sim 0.1\\%$ GSM8K 10M $\\sim 0.01\\%$ ShareGPT 200M $\\sim 0.2\\%$ Fast Forwarding and Stationary Tokens Figure 7: Comparison of Jacobi trajectory between a target LLM and CLLMs on Spider. Each point along the Jacobi trajectory is a color-coded sequence: blue for correct tokens matching with AR results, and red for inaccurate ones. CLLM demonstrates enhanced efficiency, converging to the fixed point $2\\times$ faster the Target LLM. This increased efficiency in the CLLM can be attributed to the consistency loss which facilitates the learning of the structure of each $n$-token sequence given a prefix. The left side of Figure 6 shows target LLMs typically generate only one correct token in one iteration. In contrast, in CLLMs, we identify fast forwarding phenomenon where multiple consecutive tokens are correctly predicted in a single Jacobi iteration. Moreover, tokens correctly generated in advance (e.g. “country” and “H” at index 6 and 7 on the left side of Figure 6), are often replaced inaccurately in subsequent iterations in target LLMs. On the other hand, CLLMs exhibit the capability of predicting correct tokens preemptively, even with preceding incorrect tokens, while ensuring the tokens remain unchanged. We term such tokens as stationary tokens. Both phenomena contribute to the fast convergence in Jacobi decoding of CLLMs, thereby leading to a considerable generation speedup. We observe that CLLMs acquire a crucial linguistic concept through training – collocations: a series of words or terms that co-occur more frequently than one would expect by random chance. Language is not solely composed of isolated words but also relies heavily on specific word pairings. Examples of collocations are abundant in both natural and coding languages. They include verb + preposition combinations (e.g., ‘’talk to’’, ‘‘remind … of …’’), verb + noun structures (e.g., ‘‘make a decision’’, ‘‘catch a cold’’), and many more domain-specific syntactical structures (e.g., ‘‘SELECT … FROM …’’, ‘‘if … else’’ for programming). The consistency generation objective allows CLLMs to infer such structures from any point in the Jacobi trajectory, encouraging CLLMs to acquire proficiency in numerous collocations and thereby predict multiple words simultaneously to minimize iteration steps. Get started Please see our paper for more details. We also invite you to try out our codebase and CLLM checkpoints! Acknowledgement We would like to thank Yang Song, Canwen Xu, Yonghao Zhuang, Dacheng Li and Yichao Fu for providing insightful feedback. Citation @misc{kou2024cllms, title={CLLMs: Consistency Large Language Models}, author={Siqi Kou and Lanxiang Hu and Zhezhi He and Zhijie Deng and Hao Zhang}, year={2024}, eprint={2403.00835}, archivePrefix={arXiv}, primaryClass={cs.CL} }",
    "commentLink": "https://news.ycombinator.com/item?id=40302201",
    "commentBody": "Consistency LLM: converting LLMs to parallel decoders accelerates inference 3.5x (hao-ai-lab.github.io)354 points by zhisbug 14 hours agohidepastfavorite70 comments DoctorOetker 11 hours agoThis mirrors what I experienced when I enrolled in \"free drawing\" (no teaching) classes: While people considered me a good drawer since I was a child, I remember just repeating either similar detailed drawings I drew before, or otherwise just taking plenty of time to draw. I believe anyone with time and patience can make a nice drawing of a scene. The \"free drawing\" class had no rules or lectures: you brought the materials you wanted to work with (some brought ink, others pencils, while I brought charcoal). The only thing determined was the timing between poses for the model: for each session the first few poses were very short (say a minute), and then the pose durations would progressively lengthen until say 5 minute poses. At all times you were free to tear your picture up and retry drawing the pose again. My drawing skills improved considerably. The short \"warmups\" actually force you to get proportions and outlines correct on the first tries. Conventional wisdom says haste makes waste, but when learning or refining skills, it seems natural selection has hardcoded the sensation of haste as a stressor prompting attention and learning. I am convinced I could have drawn similar quality drawings before enrolling in those classes, except they would have taken me easily 5 or 10 x as long to draw. Being forced not to beat around the bush and feeling the penalty of making a hasty mistake (further decreasing time left for the second try in the remaining time) does seem to work. My only gripe is that the technique is termed \"Consistency\" whereas I would reserve such a term for an improvement in performance not inference speed, although I understand that they indicate \"consistency with what would ultimately have been generated one token at a time\". I would rather dub it \"Proficiency LLM\", where the same output is expected, only without the inhibition of stuttering to the same conclusion. reply snyhlxde 10 hours agoparentHi we are CLLM authors and thanks for sharing your experience and insights! I can see this drawing skill refining process echoes with the training process in CLLM, the only thing is at this point stressor in CLLM training is not getting progressively demanding. For example, while drawing, you can set very specific time limit on how long you are allowed to draw in each trial and make the time progressively shorter. In CLLM, maybe we can make this the learning process more and more difficult by mapping more and more distant states in Jacobi trajectory to its final state. We are using the term \"consistency\" because we draw parallelism between consistency LLM and the consistency model in diffusion image generation where the training processes are analogous. reply boroboro4 7 hours agorootparentDo you use same dataset to train / eval the model? Was the model used for example trained on GSM8K dataset for example? reply snyhlxde 7 hours agorootparentYes, we consider both domain-specific applications (spider for text2SQL, gsm8k for math, codesearchnet for python) as well as open-domain conversational applications (ShareGPT). We use test set from each application to evaluate CLLMs’ performance in our paper. On the other hand, technically CLLM works on any kind of queries. But the speedup might vary. Feel free to try out our codebase for your use cases! reply Quarrel 10 hours agorootparentprevIs it just me, or does this read like it was written by an LLM ... ?! reply snyhlxde 10 hours agorootparentlol I take that as a compliment. Good try but sadly no LLM in this writing :) reply aamargulies 10 hours agoparentprevI had an interesting experience in an Invertebrate Zoology lab class one summer. We students were brought into a lab, given specimens to draw, and the only instructions we received were 'You have 30 minutes to draw this. Go.' There was no \"here's how to draw. here's what to do and not to do\". It was just basically \"We don't care about any insecurities you might have. We don't care if you think you can't draw. No excuses, just fucking draw it. Now.\" Not only did we draw, but we (all of us) improved enormously over the course of the class as more animals were brought in and the exercise was repeated over and over and over again throughout the summer. What it taught us is that everyone, and I mean everyone, can draw. Our collective attitude shifted from \"don't know if this is even possible\" to \"of course we can do this. this is easy. routine. trivial.\" Highly recommended approach. It was the most freeing and amazing class I had in college. reply Version467 5 hours agorootparentThat sounds like a pretty awesome experience. Thanks for sharing. reply manmal 11 hours agoparentprevSystems generally become more efficient when under stress. They are also forced into local optima - everything has upsides and downsides. reply sheepscreek 8 hours agorootparentInterestingly - this is the idea behind Nassim Taleb’s book “Antifragile” and the concept of “anti-fragility”. In essence, it promotes dynamic/evolutionary/always learning behaviour than performing the same set of steps every time, and in the process, becoming stronger than before. An example he shares is: how the breakdown of muscle tissue through exercise leads to more muscle development and an increase in strength. I guess it’s similar to LLM training using error/loss reducing functions (practice makes perfect) but dissimilar in the sense that training is a one—time action. reply miven 12 hours agoprevThe authors mention that Jacobi decoding is equivalent to greedy autoregressive decoding, but in practice don't we often want the sampling temperature to be above zero to avoid repetitions and excessively generic responses? I'm completely unfamiliar with this decoding strategy so maybe I'm just missing a simple way to account for that. reply snyhlxde 10 hours agoparentYes this is a great question! We are actively working on supporting other sampling strategies other than greedy sampling. In the context of CLLM training, instead of mapping to a static fixed point obtained from Jacobi decoding as the training ojbective, we term it dynamic fixed point. You can keep an eye on our github repo for new progress. reply matheist 11 hours agoparentprevAgreed. It's straightforward to check that a token was the argmax, but it seems difficult to check that a token appeared with the probability you wanted it to. You could still do the fine-tuning step I guess, where you train the trajectories to approach n-token completions with the statistics you want, but I can't see how you can replace the \"check for a fixed point\" step. Maybe \"check the result was above this fixed threshold for likelihood\". reply wangii 4 hours agoprevI feel it's a pretty dangerous optimization before we REALLY understand what's going on inside of the LLM. e.g. guys believe in the geometric interpretation will have something to say, and it would probably hurt if you are using \"filler\" tokens. Besides, the assumption (not a universal fact) that \"forming complete sentences in mind before articulating word by word\" seems overly simplifies activities happens in our mind: do we really have a complete planning before start talking/typing? as a Buddhist I lean towards it's an illusion. further more, what about simultaneous thoughts? are we linear thinker in the sentence level? anyway, pretty neat math! reply renonce 3 hours agoparentThe optimization does not affect the result of LLM, it's guaranteed to produce equivalent results as decoding directly. Let's not treat that LLM as some magic that resembles our mind, it's just another program that produces sentences that happens to make sense. reply wangii 1 hour agorootparentAccording to the original Jacobi decoding paper, it's set in the machine translation tasks, with encoder + decoder, in which parallel algo applied only to the decoder part. reply sigmoid10 3 hours agorootparentprevLets not treat our mind as something magical. It's just another program that learned to speak by consuming lots of training input. The implementation might look slightly different from the outside, but from a mathematical perspective, artificial neural networks are proven to be at least as capable as the human mind. reply baq 3 hours agorootparentThe best part is, your comment works both when sarcastic and completely serious. reply Etheryte 4 hours agoparentprevThat assumption might be useful in this context, but I think it's pretty clearly not true. Ask anyone to tell you about a complex past event with a lot of parallel branches and you'll quickly see them add bits, pieces and tangents midsentence to cover the full range of events. I don't think I've seen the sentence granularity hypothesis in any serious scientific context before. reply alfalfasprout 12 hours agoprevWow, I'm mindblown this isn't getting more attention. This seems like a clear win for inference. Fine tuning cost for this is reasonable (around 0.01% of the original pre-training cost). And the performance wins seem fairly consistent. reply lopuhin 11 hours agoparentSimilar or greater inference wins are achieved with speculative decoding which is already widely used, so while this is really interesting (and was tried before with less success AFAIK), it's not yet clear how impactful it would be. reply snyhlxde 10 hours agoparentprevThanks for interesting in our work! Yes we found training with consistency loss + AR loss on even a subset of a dataset results in significant speedup (0.01% pre-training cost). Training on more data permits even further speedup: the model is able to learn from more frequently-appearing collocations and phrases. For more details, please check out our paper and you can also see speedup saturates as the size of training data grows. reply nico 11 hours agoprevInteresting I think soon we are going to realize that we don’t really need training the models We just need good indexing and sampling Essentially at some level any LLM is equivalent to a DB of the dataset, with a great NLP interface on top Both are just different methods of navigating stored data reply sdrg822 11 hours agoparentBut indexing *is* training. It's just not using end-to-end gradient descent. reply tempusalaria 9 hours agoparentprevLLMs can easily produce data not in training dataset. LLMs do not navigate stored data. An LLM is not a DB of the training data. reply carlthome 32 minutes agorootparentI've had the same thought as above but unfounded (just a feeling, pretty much) so I'm curious to learn more. Do you have any references I can check out that supports these claims? reply nsagent 11 hours agoparentprevYou might like, the Infinigram paper then. It was discussed recently: https://news.ycombinator.com/item?id=40266791 reply JoannaWongs 7 hours agoparentprevRAG (Retrieval-Augmented Generation) enhances Large Language Models (LLMs) by integrating them with specific domain knowledge or an enterprise's internal databases, eliminating the need for model retraining. This method maintains the relevance, accuracy, and value of the outputs in a cost-effective way. However, the effectiveness of a RAG solution heavily depends on the quality of the datasets it uses. These datasets often come from varied sources and in different formats. For optimal performance, it's crucial to normalize the various data types, clean and organize the data by removing unnecessary elements such as special characters, irrelevant metadata, or extraneous text. HelloRAG.ai addresses this challenge by offering a no-code platform that allows you to easily transform multi-format datasets into structured formats like JSON. This tool helps you focus on developing the logic of RAG, streamlining the process of leveraging augmented data for enhanced model performance reply andy12_ 13 hours agoprevAt first I thoght that this was another Medusa-like paper, simply using more unembed heads for guessing subsequent tokes, but damn, not at all. This is amazing. And it doesn't even use extra parameters, it's just an auxiliary training loss. reply snyhlxde 9 hours agoparentThe only similarity between Medusa and CLLM is both train and adapt LLMs for fast inference. But they use completely different training technique, decoding technique and as you pointed out CLLMs don't need extra parameters or configuring attention mask for tree-based verification. reply renonce 4 hours agoprev> ... speculative decoding methods ... incurs extra memory cost during inference time. Any detail on this? For speculative decoding you need a smaller model to generate \"branches\" which are fast but maybe inaccurate and verify these branches later with a larger model. However, only memory equivalent to a single token is needed for speculative decoding, and tokens in other branches are simply masked out during inference. With a context size of 1000 and ~30 branches for 5 tokens, the memory overhead would be 3% which is negligible. If your context size is much smaller compared to the number of branches - would someone who use a generative LLM with a context window of just 50 tokens care about generation speed? Also, speculative decoding techniques are not restricted to greedy sampling - it's expected to behave exactly the same as the original model and sample with the expected probabilities. Most literature on speculative decoding already reports 2.6x-3.5x speedup. The blog post here reports 2.4x-3.4x generation speed - which isn't that much of an upgrade? While I mentioned speculative decoding above and Medusa2 and Eagle seems to be the techniques that the author compares against, the core problem remains: whatever method you use to predict tokens ahead of time, there is a specific point where the previous tokens are absolutely needed before predicting the next token. It doesn't depend on what your model is or what your techniques are, it's just about what is mathematically achievable. How can you predict 5 tokens at once if the probability distribution of the 5th next token depends heavily on the previous 4 tokens? Speculative decoding, Jacobi decoding, multi-token parallel decoding, whatever. If only greedy sampling is supported for this, then I wonder what are the advantages of this method, not to mention that other techniques already achieve the expected speedup. Comparing greedy sampling speedups to random sampling speedups is comparing apples to oranges, and I doubt if the speedup described by the method would remain after this method is adapted to random sampling (due to the core problem mentioned above). reply Palmik 4 hours agoparentSpeculative decoding requires you to load the smaller model into memory and run inference on it. reply renonce 3 hours agorootparentI think the smaller model is at least 20 times smaller. If you do speculative decoding on a 70B model an 1B model would be appropriate. reply dvt 11 hours agoprevThere's no free lunch™, so from what I can tell there's some pathway loss here. E.g. some Jacobi trajectories definitionally exclude higher temperature paths. Which might actually be a positive given data retrieval (but a negative if we want to maximize for creativity?). reply wrsh07 10 hours agoparentThere are better and worse algorithms. I'm not sure \"there is no free lunch\" always applies in a particularly meaningful way. Some things aren't on the pareto frontier. reply factormeta 10 hours agorootparentKinda like the aiff -> mp3 conversion process. A lot of data is lost, but we human can really tell the too much of a difference? reply wrsh07 8 hours agorootparentThere's no reason to think the current next token prediction models are optimal for predicting sentences (they aren't!) > An algorithm may outperform another on a problem when neither is specialized to the problem https://en.m.wikipedia.org/wiki/No_free_lunch_in_search_and_... reply JKCalhoun 10 hours agoprevAnyone know somewhere someone dumb like me can \"Ask an AI expert\"? I want to ask, for example, how is it that an LLM when given the same prompt does not respond in the same deterministic way? I guess I want to learn this stuff and should maybe follow one of those \"write an LLM in an hour\" type videos on YouTube. reply throwawaymaths 9 hours agoparent> how is it that an LLM when given the same prompt does not respond in the same deterministic way? In software (not in the model) here's literally a random number generator that picks from a weighted set of \"next-token\" choices that the model spits out. The selection process can have a series of knobs to manipulate the responses. If you want it to be deterministic (if you have direct access to the software) you can tell it to set \"top-k = 1\" or \"temperature = 0.0\" (depending on your software) and it will be deterministic. Usually the default settings are not for determinism, because for whatever reason the quality of the results tends to not be that good when you go fully d. reply zozbot234 10 hours agoparentprev> I want to ask, for example, how is it that an LLM when given the same prompt does not respond in the same deterministic way? You can control that in most systems with an inference-set parameter called \"temperature\". But setting the temperature as low as possible tends to lead to very low-quality answers - the system can't crawl out of some local optimum and ends up repeating itself over and over. Such answers may be \"deterministic\" but they're also not good. reply 8note 10 hours agoparentprevFor that answer, you can refer to the 3blue1brown videos The llm model outputs a vector of probabilities for tokens, and the llm user picks a token from the most likely list using a random number reply zipfcharge 10 hours agoparentprevIt's because an LLM is essentially a probability matrix. You type a prompt, then it calculates what's the probability of getting a next word and so on, eventually forming a sentence. The probability learned is based on the training data. Because of the underlying probability model, it's not going to be 100% deterministic. Plus a model like ChatGPT purposefully have \"temperature\" parameter that will further add randomisation to the whole process. My answer is based on this paper if you're interested to read more: The Matrix: A Bayesian learning model for LLMs, https://arxiv.org/abs/2402.03175 reply flopriore 4 hours agorootparentAre there any ways to show the source of the information retrieved by the model? For instance, the LLM forms a sentence and it points to a stackoverflow answer with the same or similar content. reply rahimnathwani 10 hours agoparentprevFor this particular question, ask chatgpt how temperature affects llm softmax sampling. For other things, study using Karpathy's videos. reply toxik 13 hours agoprevInteresting stuff. I guess the idea has occurred to many but was well written and presented. reply snyhlxde 10 hours agoprevfrom CLLM authors: Thank you guys for the great questions and insights! We have made a Twitter posts with some more details and we invite you to engage with us on Twitter as well. https://twitter.com/haoailab/status/1788269848788869299 reply paulclark 12 hours agoprevIs this how Groq (https://groq.com/) is so fast, or are they doing something different? reply buildbot 12 hours agoparentGroq is serving an LLM from (100s of chips worth of) SRAM, so the effective bandwidth thus token generation speed is an order of magnitude higher than HBM. This would 3.5x their speed as well, it is orthogonal. reply gdiamos 1 hour agorootparentI'm surprised no one has done this for a GPU cluster yet - we used to do this for RNNs on GPUs & FPGAs at Baidu: https://proceedings.mlr.press/v48/diamos16.pdf Or better yet - on Cerebras Kudos to groq for writing that kernel reply wrsh07 10 hours agoparentprevMy understanding is that theirs is a pure hardware solution. The hardware is flexible enough to model any current NN architecture. (Incidentally, there are black box optimization algorithms, so a system as good as grok at inference might be useful for training even if it can't support gradient descent) reply throwawaymaths 9 hours agoparentprevAccording to someone I talked to at groq event I was invited to (I did not sign an nda), They are putting ~8 racks of hardware per llm. Of course coordinating those racks to have exact timings between them to pull tokens through is definitely \"part of the hard part\". reply rcarmo 12 hours agoprevCan't wait to see something like this merged into ollama (I'm sure there would be plenty of people fine-tuning models for it). reply Me1000 11 hours agoparentOllama doesn't have their own inference engine, they just wrap llama.cpp. But yes, it will be awesome when it's more generally available. reply helloericsf 11 hours agoparentprevThe lab is tied to the vLLM project. I would say it might get picked up sooner by vLLM than other inference frameworks. reply ec109685 11 hours agoprevCould someone please explain the intuition around this technique in more lament terms? reply TomatoCo 11 hours agoparentFor all of these \"how can we batch predicting the next n tokens?\" the intuition is basically that it takes a buttload of math to predict some of the tokens, but that most tokens are actually easy to guess. For example, if I asked \"What was that phone number from that 80's song?\" as soon as a model generates 867- it shouldn't take that much math at all to finish predicting 5309. reply snyhlxde 9 hours agorootparentA bit more intuition on how training works: in natural language processing, some phrases/collocations, for example \"remind ... of ...\", \"make a decision\", \"learn a skill\" etc. are used together. We can ask LLMs to learn such collections & frequently appearing n-grams. After learning, the model can use parallel decoding to predict many tokens that are frequently appear together in one forward pass. reply fermuch 13 hours agoprevWould something like this apply to MAMBA/JAMBA too? reply wrsh07 10 hours agoparentI think any next token predictor will benefit. Iiuc mamba is a next token predictor. I just skimmed the gradient article, but if their only change is swapping out the transformer block for the mamba block, I don't think it's already using this optimization reply doctor_eval 12 hours agoprev> Our research shows this process – mimicking human cognitive process of forming complete sentences in mind before articulating word by word This is not how I work. Is there something wrong with me? reply jerbear4328 11 hours agoparentNor is it how I work, I think that's normal enough. I do have an idea of what I'm going to say before I say it, I think that's closer to what they meant. I think and speak in increments of ideas, not words. reply paulmd 11 hours agorootparent> I think and speak in increments of ideas extremely common among (but not unique to) people with ASD, those \"increments of ideas\" are called \"gestalts\". https://kidtherapy.org/helpful-articles/what-is-gestalt-lang... reply mdp2021 11 hours agoparentprev\"Rem tene, verba sequentur\" (you hold the matter, then words come) is largely \"how it works\". You form logical ideas as you speak, as you speak your speech develops, so the translation is from ideas to sentences. It is not clear in which phase one would mentally form a complete sentence, nor why it should be relevant. You \"see something [that makes sense]\", then you describe it - iteratively. reply Filligree 11 hours agoparentprevYou might not have an internal monologue. A lot of us don't, and the ones that do are equally shocked every time they find out. For what it's worth, I'm in the same boat—can form sentences, but why would I? It'd slow me down. People who don't have inner monologues tend to assume that all that stuff is some form of analogy or metaphor. It's not. It's entirely literal. reply oceanplexian 11 hours agorootparentDo you mean in a real time conversation? Because I definitely dont \"have an internal monologue about what I'm going to say\" in the 100ms between when someone asks a casual question and I respond to it. reply throwawaymaths 9 hours agoparentprevAre you sure. It might not be the whole sentence, but I would find it hard to believe that in practice the way you speak or write is like helloMaybeI'llgogetbreakfast reply snyhlxde 9 hours agoparentprevIn some conversations, maybe it's easier to form complete sentences. In some others, the best we can do is: have a rough draft about what to say in mind and then refine it word by word while speaking. reply DrSiemer 11 hours agoparentprevThey probably do not mean people form entire sentences before expressing them, I am not aware of anybody doing that. I assume it refers to people first coming up with a global outline of what they want to say before they start speaking. reply giardini 11 hours agoparentprevProbably. reply m3kw9 10 hours agoprev [–] They can quickly try with one of the open source models, then show a side by side demo reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Consistency Large Language Models (CLLMs) are a novel family of parallel decoders utilizing Jacobi decoding to enhance generation speed without extra memory costs.",
      "CLLMs can decode multiple tokens simultaneously, surpassing auto-regressive methods, with faster convergence and efficient prediction of multiple words using Jacobi trajectories.",
      "The \"CLLMs: Consistency Large Language Models\" paper by Siqi Kou et al., available on arXiv, introduces a method for training CLLMs for diverse tasks, offering significant speed enhancements and adaptability without requiring alterations to the original model architecture."
    ],
    "commentSummary": [
      "Converting Language Model (LLM) to parallel decoders boosts inference speed, resembling drawing classes, and highlights the Consistency LLM.",
      "The post delves into training methods, dataset utilization, decoding approaches, and the impact of consistency loss and AR loss.",
      "It also addresses RAG solutions, speculative decoding, and simultaneous token prediction, along with exploring the deterministic aspect of LLMs and hardware enhancements for neural networks, shedding light on sentence formation and personal inclinations in natural language processing."
    ],
    "points": 354,
    "commentCount": 70,
    "retryCount": 0,
    "time": 1715198107
  },
  {
    "id": 40300126,
    "title": "Introducing a Non-Linear UI for ChatGPT",
    "originLink": "https://www.grafychat.com",
    "originBody": "Hi HN,I built this out of frustration of the evergrowing list of AI models and features to try and to fit my workflow.The visual approach clicks for me so i went with it, it provides more freedom and control of the outcome, because predictable results and increased productivity is what I’m after when using conversational AI.The app is packed with features, my most used are prompt library, voice input and text search, narration is useful too.The app is local-first and works right in the browser, no sign up needed and it&#x27;s absolutely free to try.BYOAK – bring your own API Keys.Let me know what you think, any feedback is appreciated!",
    "commentLink": "https://news.ycombinator.com/item?id=40300126",
    "commentBody": "I built a non-linear UI for ChatGPT (grafychat.com)342 points by setnone 17 hours agohidepastfavorite98 comments Hi HN, I built this out of frustration of the evergrowing list of AI models and features to try and to fit my workflow. The visual approach clicks for me so i went with it, it provides more freedom and control of the outcome, because predictable results and increased productivity is what I’m after when using conversational AI. The app is packed with features, my most used are prompt library, voice input and text search, narration is useful too. The app is local-first and works right in the browser, no sign up needed and it's absolutely free to try. BYOAK – bring your own API Keys. Let me know what you think, any feedback is appreciated! lIIllIIllIIllII 16 minutes agoFor what it's worth, one CSS line lags the HELL out of my laptop on the site. It's backdrop-filter: blur(0.1875rem) for modals, like the youtube video popup reply siva7 27 minutes agoprevGood landing page, explained to me the product well enough. I like your concept also as i wished sometimes for something similiar in the past. reply carlosbaraza 1 hour agoprevSometime ago I had an idea for a similar interface without the dragging feature. Basically, just a tree visualisation. I usually discuss a tangent topic in the same conversation, but I don't want to confuse the AI afterwards, so I edit a previous message when the tangent started. However, OpenAI would discard that tangent tree, instead it would be nice to have a tree of the tangent topics explored, without necessarily having to sort them manually, just visualising the tree. reply btbuildem 15 hours agoprevInteresting take! It does seem to address a typical \"intermediate\" workflow; even though we prefer linear finished products, we often work by completing a hierarchy first. I've been using Gingko [1] for years, I find it eases the struggle of organizing the structure of a problem by both allowing endless expansion of levels, and easily collapsing it into a linear structure. In your case, do you hold N contexts (N being the number of leaves in the tree)? Are the chats disconnected from each other? How do you propose to transition from an endless/unstructured canvas to some sort of a finished, organized deliverable? 1: https://gingkowriter.com/ reply setnone 15 hours agoparentGreat questions! > In your case, do you hold N contexts (N being the number of leaves in the tree)? It depends, contexts are just a form of grouping > Are the chats disconnected from each other? > How do you propose to transition from an endless/unstructured canvas to some sort of a finished, organized deliverable? RAG with in-app commands, i'm working on a local RAG solution, it's early but promising. Basically chat with all your data and applying a wide range of command on it. reply Ringz 14 hours agoparentprevSlightly OT, but there was a standalone software just like gingko for the Mac. Do you now something about it? Edit: I think it was an old version of gingko as a desktop app. Still available at https://github.com/gingko/client/releases reply floam 14 hours agorootparentAre you thinking of FlowList? https://www.flowtoolz.com/flowlist/ reply Ringz 14 hours agorootparentThanks, but that’s not the one. It was like a pure Markdown outliner, very keyboard driven. reply ludwigschubert 14 hours agorootparentprevAre you thinking of Bike? https://www.hogbaysoftware.com/bike/ (Maybe not — this isn’t markdown first; but it is a very macOS-y, keyboard driven, hierarchical outliner that I enjoy.) reply Ringz 14 hours agorootparentBike looks very nice and it’s built on open file formats. I will try it out. Look at my edit above: it might be an old version of ginkgo. But I’m on my phone right now and can’t figure it out… reply pants2 16 hours agoprevFrom watching the demo it looks interesting, but I figure I would get tired of dragging nodes around and looking for ones that I'm interested in. Does it allow searching? It would be more interesting to me if it could use AI as an agent to create a graph view - or at least propose/highlight followup questions that self-organize into a graph. reply setnone 16 hours agoparent> I would get tired of dragging nodes around Me personally i find value in taking my time to organize and drag around, probably because i'm a visual thinker reply setnone 16 hours agoparentprevYes, search is one of my favorite features here, try '/' shortcut reply rajarsheem 16 hours agoprevThe demo you shared shows you are creating child chat from the original parent chat. Have you tried something like connecting merging two child chats to create a subsequent child chat? Or maybe simply creating a child chat from a previous child chat? reply visarga 13 hours agoparentI wish there was a node to load a folder of JSON, TXT or CSV files, pipe them one by one and collect the outputs in another folder. Like a LLM pipeline / prompt editor. reply dav43 8 hours agorootparentDatasette has this exact functionality and i used it. Works well. https://datasette.io/plugins/datasette-enrichments-gpt *edit links reply ramoz 16 hours agoprevI like this and wished openai or anthropic enabled similar in their UIs... it would be simple actually: \"create a new chat from here\" Otherwise, great job! It's cool, but it's pricey and that is a personal deterrence. reply tippytippytango 7 hours agoparentI find editing a previous question accomplishes this well, the existing UI already keeps all your previous edits in a revision tree. reply gopher_space 15 hours agoparentprevI've pegged my thinking on software purchases to local McDonald's drive-thru menu equivalencies. reply diebillionaires 14 hours agorootparentmacdonalds is so overpriced, so I cannot condone this method :) reply Hrun0 10 hours agoprevYou can create something like this easily by yourself using Obsidian and a plugin like https://github.com/AndreBaltazar8/obsidian-canvas-conversati... reply siva7 24 minutes agoparent\"easily\"? well, no except you're a techie. reply varispeed 10 hours agoparentprevIt's like when I replaced dropbox with just a few scripts and sftp. reply invisitor 6 hours agoprevLooks interesting. I'm working on an LLM client myself. Video: https://files.catbox.moe/zy4tbr.mp4 Repo: https://github.com/Merkoba/Meltdown reply entherhe 16 hours agoprevI always feel like whiteboarding & concept mapping is better when it comes to generative AI, especially when it comes to the nature that we are chat in a \"multimodal way\" these days -- just think of old plain text SMS compared to mems links rich-text powered IM tools nowadays. Congrats! you may also check flowith and ai.affine.pro for similar selling points. Also, heptabase is good and they will definitely make a ai version soon or later. reply damnever 2 hours agoprevAwesome, this is similar to the thread conversations on Slack. reply altruios 12 hours agoprevThe only feedback I would give is I'm suspicious of (will not buy) closed sourced AI anything. With that said: thank you for sloughing off the subscription model trend! That is welcome. But going open source so that I know \"for sure\" no telemetry is being sent and charging for support would be the only way to get money out of me for this. I'm probably the odd one out for this, so take that with a fair helping of salt. This is a great idea, so much so that this is also something I could probably put together a MVP of in a weekend (or two) of dedicated work (the fancy features that I personally don't care about would probably take longer to implement, of course...). Good work! Keep it up. reply setnone 4 hours agoparentThank you! I would love if we had some kind of 'open-build' methodology so those projects not willing to open the source but are willing to perform any kind of necessary audit against the build, just a thought. reply ntonozzi 16 hours agoprevThis is wild! What have you found it most useful for? Have you tried a more straightforward approach that follows the ChatGPT model of being able to fork a chat thread? I could use something like this where I can fork a chat thread and see my old thread(s) as a tree, but continue participating in a new thread. Your model seems more powerful, but also more complex. reply setnone 16 hours agoparentThis is my daily GPT driver, so for almost anything from research to keeping my snippets tidy and well organized. I use voice input a lot to take my time and form my thoughts and requests, text-to-speech to listen for answers too. reply joshuahutt 12 hours agoprevVery cool! I built a version of this [1], but balked at trying to sell it. This is the third iteration of this idea I've seen so far. Your reply popup is a smart feature and a nice touch! Love it. I love the privacy focus and BYOK, as well. Congrats on the launch! Really cool to see graph interfaces for AI having their moment. :) [1] https://coloring.thinkout.app/ reply diebillionaires 5 hours agoparentWow, this is really cool! Thanks for sharing! reply bredren 13 hours agoprevYour full-stack dev graph seems to have 75 queries in it. Please consider providing a demo video showing how this works with code work. I get the overall behavior, but sometimes code segments can be quite long, or multiple specific sections need to be combined to create additional context. It would be helpful to see the current baseline product behavior for interaction on a \"common\" coding task, solving problems in typescript and / or python. reply setnone 4 hours agoparentThank you for the feedback! I'm planning to release more videos, stay tuned. reply yoouareperfect 15 hours agoprevVery nice! Thanks for sharing, will definitely give it a try. I think we settled for chat interface to play with LLMs, but there's nothing really holding us back to try new ways. reply x3haloed 15 hours agoparentYeah, I'm annoyed that OpenAI has deprecated its text completion models and API. I think there's a ton of value to be had from constrained generation like what's available with the Guidance library. reply freedomben 11 hours agoprevThis looks really cool. I did not expect to see something I might actually buy but this is something that could be very nice for me :-) Will the Self-host package include source (i.e. source available) or is it just the transpiler output? Also, is there (or plan to be) support for postgres or other database for persistence? reply setnone 10 hours agoparentThank you! > Will the Self-host package include source (i.e. source available) or is it just the transpiler output? No sources, just a folder with compiled assets that you can run on a static server. This is already available. > Also, is there (or plan to be) support for postgres or other database for persistence? Yes there are plans for local pg reply rmbyrro 14 hours agoprevThank you so much for building this, it's exactly what I was looking for! Love the license instead of subscription model. Also loved that I can start trying right away without any hassle. Couple suggestions: I can't decide between Extended and Premium options. What does \"premium support\" mean? Also, it only shows an upgrade option in the check-out page, perhaps it'd be interesting to include it in the FAQ and also the Pricing section. reply setnone 14 hours agoparentThank you! > What does \"premium support\" mean? Premium option includes prioritized support and access to new features that might be unavailable for other types of licenses. I will update the website for more clarity. reply wan888888 13 hours agoprevAmazing work, kudos! Love the canvas, drag'n'drop and line connectors, did you use a library or made it yourself? reply tomfreemax 14 hours agoprevDidn't find it in the documentation. How would I go about if I want to self-host it for a small team of like 14 people? Should I buy licenses for 14 (3x extended) instances, or 1 for all, where everyone can see everyone's conversations or are there accounts? I have a central ollama instance running and also Openai API keys. Thank you. reply setnone 14 hours agoparent> How would I go about if I want to self-host it for a small team of like 14 people > Should I buy licenses for 14 (3x extended) instances Yes that should work. Each license comes with 5 seat/activations. Each seat has its own copy of the data. reply raxrb 13 hours agoprevDo you plan to open source it? I will love to extend it. I had similar ideas about non linear UI. reply yaantc 16 hours agoprevFor a text based version of the \"tree of chats\" idea, using Emacs, Org mode and gptel see `gptel-org-branching-context`in: https://github.com/karthink/gptel?tab=readme-ov-file#extra-o... reply tomfreemax 15 hours agoparentOf course, it can be done with emacs and org mode... It's almost like every software or library will get ported to JavaScript eventually, with the difference, emacs and org mode was before. reply subhashp 2 hours agoprevExcellent UI! I love it. reply causal 13 hours agoprevCongrats on the launch - I love this. Organizing text is often the hard part when working with LLMs. Only thing I don't love is heavy mouse use. Are there keyboard shortcuts for all the operations shown? reply setnone 11 hours agoparentThanks! > Are there keyboard shortcuts for all the operations shown? For now yes, what would you like to be added? reply noashavit 9 hours agoprevCongrats on the launch! I love that you let ppl try it without even signing up! The mobile experience needs to work tho. reply bschmidt1 9 hours agoprevPowerful stuff, this is the kind of workspace I've been waiting for for AI. Excited to see how it evolves! reply LASR 15 hours agoprevWow. I was so frustrated with chat that I was almost going to write something like this myself. Now I don't have to :) Curious about the business model here though. How much sales have you had so far, if you don't mind me asking? reply iknownthing 16 hours agoprevCurious why you settled on the BYOAK approach rather than a subscription approach reply setnone 16 hours agoparentSubscription fatigue is real :) reply tomfreemax 15 hours agorootparentI have to say, I didn't realize it was no subscription before I saw this comment. Makes it much more interesting from the start. Yes, I hate subscriptions. Love your approach. I also love that you focus on your strength which is the intuitive and flexible interface, rather than LLM or prompts or whatever. Like this its also very extensible, as every good tool should be. reply iknownthing 16 hours agorootparentprevI was thinking it was because it would be easier than keeping track of usage which I assume you would need to do with a subscription based model i.e. all users using your key. reply teruakohatu 12 hours agoprevIt seems to work well but a desktop app (or self hosted) is essential. I can't paste in valuable API keys to a third party website. reply setnone 12 hours agoparentDesktop app is coming soon and self-host option is already available as a part of Extended License. I have no plans to open source it at the moment, but it would be great to come up with something like 'open build' for cases like that. reply teruakohatu 11 hours agorootparentThe purchase screen made me think self hosted was coming soon for extended. How far off is desktop and will the desktop be self-hosted or an interface to the website ? reply setnone 11 hours agorootparentNot far off, some days i would say. Yes it's a wrapper with opted-out sentry and vercel analitycs, just like self-host package. reply 7734128 16 hours agoprevMake sure to have very tight limits on any API key you provide to someone else. They could burn through tens of thousands of dollars each day if you do not have security in place. reply CuriouslyC 16 hours agoprevIt looks like you put a lot of work into this but node based workflows are ok when they're a necessary evil and just an evil otherwise. I'd be more interested in a tool where I can \"add data\" to it by drag and drop or folder import, then I can just type whatever prompt and the app's RAG system pulls relevant data/previous prompts/etc out of its store ranked by relevance, and I can just click on all the things that I want inserted into my context with a warning if I'm getting near the context limit. I waste a lot of time finding the relevant code/snippets to paste in manually. reply durch 13 hours agoparentThis sounds a lot like my dream setup, We've been slowly building something along those lines. I've linked a video at the bottom that shows how we did something similar with an Obsidian plugin. Hit me up if you're interested in more details, we'd be happy to get an alpha user who gets it. We've mostly had trouble explaining to ppl what exactly it is that we're building, which is fine, since we're mostly building for us, but still it seems like something like this would be the killer app for LLMs Obsidian Canvas UI demo -> https://www.youtube.com/watch?v=1tDIXoXRziA Also linking out Obsidian plugin repo in case someone wants to dive deeper into what we're about -> https://github.com/cloud-atlas-ai/obsidian-client reply setnone 15 hours agoparentprev> I'd be more interested in a tool where I can \"add data\" to it by drag and drop or folder import, then I can just type whatever prompt and the app's RAG system pulls relevant data/previous This is something very similar to what i'm planning to add next, so stick around. reply ramoz 15 hours agoparentprevWell here’s a somewhat limited version of your idea and really only helps mitigate the copy/paste effort with coding: https://github.com/backnotprop/prompt-tower My original idea was a DnD interface that works at the os level as a HUD… and functions like your idea but that is not so simple to develop. reply setnone 15 hours agoparentprevFor me this interface is canvas-based first, node-based second, meaning sometimes I might not even use connections to get my desired result from LLM but i have the place and form for the result and i know how to find it. Connections here are not set in stone like in mind mapping software for example, it's a tool. reply htrp 10 hours agoprevhave you looked at airops (similar ideas that you could 'borrow' from) https://www.airops.com/platform reply brunoborges 13 hours agoprevCan you share details of the technology stack used to build the tool? reply Zambyte 16 hours agoprevLooks cool! How can I host it? reply setnone 16 hours agoparentThanks! Self-host package comes with Extended license reply dangoodmanUT 14 hours agoprevSuper cool, would be great for prompt engineering and iteration reply jdthedisciple 15 hours agoprevlooks packed with stuff, how long did it take u to build this? reply midnitewarrior 4 hours agoprevCan you go get acquired by Phind please? Brainstorming with the robots is a non-linear activity and I believe you are on the right track. reply nirav72 14 hours agoprevThis is great. More importantly - I love the pricing!! reply nssmeher 13 hours agoprevGreat stuff! Interesting usecases will be present reply mubu 14 hours agoprevThis seems very cool and I'd like to try it out reply p1esk 9 hours agoprevHard to try it on my phone. reply _boffin_ 15 hours agoprevYes! this is what i've been thinking about! reply pasaley 15 hours agoprevInteresting choice of questions in the demo. Are you from Nepal? reply setnone 15 hours agoparentNo but I'm a frequent visitor, i love the mountains there! reply rfc 16 hours agoprevNice! This is really cool. Well done. reply asadalt 14 hours agoprevi wish perplexity had a similar ui option. so I can out my research in multiple paths. reply groby_b 14 hours agoprevI have to admit, I don't get it. (And I want to be clear that's a personal statement, not an overall comment on the app. It looks quite well done, and if others get value from it, awesome!) But for me, I'm stuck with questions. What's the point of drawing connectors, there seems no implied data flow? Is this just for you as a reminder of the hierarchy of your queries? Or do you actually set the upstream chat as a context, and reflow the whole thing if you change upstream queries? (That one would definitely be fun to play with - still not sure about long-term value, but def. interesting) Good luck, and looking forward to see where you're taking this! reply jonnycoder 7 hours agoparentSeems like organized chatGPT in the form of mind mapping. It’s quite intuitive to me because I’ve had some chats where I kept scrolling back to the first gpt response. Therefore, you can map out a question and answer, then create nodes for follow up about specific details. Each branch of the tree structure can organize a rabbit hole of follow ups on a specific topic. reply setnone 13 hours agoparentprevThank you! Like I mentioned earlier for me the app is canvas-based first, node-based second. So connections are a tool, a visual tool to craft or manage prompt to then feed it to LLM. Canvas is a visual tool to organize and keep large amounts of chats. I try use LLM not for the sake of chatting, but to get results and those tools seem to help me with that. Hope that makes sense. reply niutech 15 hours agoprevYou can get almost the same results for free using Obsidian Canvas and one of the following plugins: - https://github.com/MetaCorp/obsidian-augmented-canvas - https://github.com/phasip/obsidian-canvas-llm-extender - https://github.com/rpggio/obsidian-chat-stream - https://github.com/zatevakhin/obsidian-local-llm reply firtoz 13 hours agoparentThank you, now I really have to try Obsidian... reply kkukshtel 15 hours agoprevI built a similar demo to this but for images - IMO this is a much better structure for working with LLMs as it allows you to really riff with a machine instead of feeling like you need a deterministic \"next step\" https://youtu.be/k_mJgFmdWWY reply lukan 2 hours agoparentLooks good, I tried it out and it is indeed alpha in many regards(e.g. sometimes it does not save a picture on windows, sometimes it does not show the prompt, ..) , but the idea has potential. I would encourage you to keep working on it (and maybe keep in mind, that if this suddenly gets viral and you have no API limits in place, you might get poor quickly). reply dvt 15 hours agoparentprevSweet demo, you should do a Show HN! This is much more interesting to me, as the visual element makes much more sense here rather than just putting entire paragraphs in nodes. reply serial_dev 4 hours agorootparentThe text nodes is also interesting, it's like a mind map, I can see how it could be great for learning, planning, collaboration, exploring... reply ag_hn 9 hours agoparentprevLooks amazing! The Unity client is quite sleek. I'd wager the creative play can be taken to the next level with a low-latency model like https://fal.ai/models/fast-turbo-diffusion-turbo reply setnone 14 hours agoparentprevGreat stuff! That deterministic \"next step\" is the last line of defense for us humans :) reply unnouinceput 16 hours agoprevnext [3 more] [flagged] snet0 15 hours agoparentThis is the worst kind of feedback comment. It's a damn ChatGPT front-end, do you expect it to be written in PHP? Also, this site plays perfectly fine with uBlock Origin. If you're going to throw criticism out, at least verify that what you're saying is correct. Honestly, reading your comment history, you really should be aware of the fact that most of what you're putting on this site is at least not positive, if not actually negative. reply setnone 16 hours agoparentprevThose must be Sentry reply shanghaikid 1 hour agoprev [–] This is interesting and all, but it's a tad complex to use. AI is supposed to simplify your life, but this just ends up making things more complicated. Ask -> answer, no more steps, that is the core value of ChatGPT or AI. reply social_quotient 1 hour agoparentSuppose I have a conversation with ChatGPT about a macro, or better yet, a series of macros. We reach the 10th sub-module, but suddenly, I find a bug in module 2 (20 minutes ago chat). While I could redirect the chat back to module 2, it's a bit convoluted. Ideally, I'd want to return to an earlier point in the conversation, resolve module 2, and then continue where we left off. However, if I update my response from 20 chats ago, I risk orphaning the rest of the conversation. The response lag also complicates things because I might move on to new ideas or debugging tasks in the meantime. I suppose I should say because of the lag time, I’m not in sync with the chat, that lag affords me the opportunity to keep doing other things. If the chat was more like groq maybe it would be less the case - not sure. The other thing I find is that if I change how I replied/asked, I get a different answer. I like the idea I can fork this node and evaluate outcomes based on my varied inputs. You’re right it’s hugely more complex. But its complexity I think I'd love to have available. reply setnone 1 hour agoparentprev [–] > Ask -> answer, no more steps, that is the core value of ChatGPT or AI. This is the absolutely ideal state of the product, i agree. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The app was developed due to frustration with the abundance of AI models, emphasizing a visual approach for increased control and predictability.",
      "It offers features such as a prompt library, voice input, text search, and narration, being local-first, free, and allowing users to use their API keys.",
      "Feedback from users is encouraged, making it a user-friendly and community-driven platform for AI model usage."
    ],
    "commentSummary": [
      "Users express frustration with the increasing complexity of AI models and features in ChatGPT, leading to the development of a non-linear UI offering more freedom and control.",
      "Discussions revolve around finding software akin to Gingko, AI integration, pricing, generative AI, and the significance of open building methodologies.",
      "Positive feedback and suggestions for enhancement are shared concerning tools for text-to-speech, chat organization, and data input, with users valuing the non-linear UI, absence of subscriptions, and potential for self-hosting in various software solutions."
    ],
    "points": 342,
    "commentCount": 98,
    "retryCount": 0,
    "time": 1715186472
  },
  {
    "id": 40304453,
    "title": "The Deceptive Triumph: How I Saved a Failing Project",
    "originLink": "https://GrumpyOldDev.com/post/the-one-where-i-lie-to-the-cto/",
    "originBody": "Posts The One Where I Lie To The CTO By GrumpyOldDev April 18, 2024 - 6 minutes read - 1142 words This was several years back. Keep in mind that early in my career, my father had told me that doing a good job often meant doing what needed to be done in spite of your boss. And by that he meant that you can either make your boss successful and happy or you can run every decision by your boss. In which case no one is successful or happy. I was working at the time for a Fortune 500 company and our CTO had signed up to deliver a big project for an important client with whom he had personal connections. He also decided to outsource a key part of it to a large tech services firm who claimed they had a product that would do most of the heavy lifting for us. As has been typical in my career, when the vendor said they had a product, what they really meant was they had something vaguely resembling a product that vaguely matched what we needed, and with heavy customization they could torture it into doing what we needed. Of course by customizing their “product” we cleverly combined all the downsides of vendor software with all the downsides of custom software. We simultaneously achieved the holy grail of bad ideas: an inflexible vendor package that would have to be forced into doing something it wasn’t designed to do but would also be forked from their main product codebase - guaranteeing sooner or later it would be end-of-lifed once the vendor realized how expensive it was to keep maintaining. We grumbled to each other about what a horrifically bad idea this was, especially considering the vendor’s proven track record in not delivering anything on time. Because the CTO had a yearly turnover of his direct reports, every status call about the project took some variation of “great idea, boss” even though literally no one involved thought it was even a good idea. Or even a mediocre idea. It was a bad idea. The rest of the project required heavy development in-house for all the other pieces, so we had our own challenges keeping us busy. But even so, as project dates through the summer slipped and the vendor promised that any day now their product would be ready to integrate for an October launch date, it became more and more obvious to everyone but the CTO that the project was in trouble. Finally in August the vendor delivered their “product” and we began the death march to integrate with it. In September we encountered a show stopper bug. The vendor product stored every customer transaction as a json record in a giant json document. So as test data accumulated, performance of the product got slower and slower. Adding a new transaction involved reading the entire json document out of the database, then appending the new record to the end. The vendor claimed they could fix this by indexing the transaction fields, and that seemed to help for a bit until we ran into problem number two. The database they chose was MongoDB and at the time Mongo had a record limit of 16MB per document. So in October when the conversion team started putting real customer data in, we started hitting the 16MB limit and things took a really interesting turn. A decision was made to hide this limitation from the client and go live a month late, but in the meantime start a skunkworks project to replace the vendor integration. Without telling the vendor, either. So we were simultaneously lying to our clients and our valued technology partners. Grumpy Old Dev at the time was more Enthusiastic Young Dev and so he set his team to building the replacement. The vendor had roughtly 70 people engaged on the project. Grumpy Young Dev assigned 3 people to replace it. One to design the database, one to build the back end to interface with the database, and one to build the business logic/web services. The client was told we would have a new version in January for them to test. It would fix the most critical defects they had accepted in the original go-live. But they weren’t told we were rewriting the entire core system. In just under 2 months. When the original project had taken over a year to launch. With only 3 people. Over the holidays. (You see where this is going.) And so around about middle of December everyone working on the project was told (not asked) to work through the holidays. Mind you, most of us had already been working 60-80 hour weeks for the past 6 months just to make the original(ish) launch date. Everyone was burnt out. At this point, if you’re reading and you’re not a delivery driven technical person, you’re probably thinking this is crazy and it’s time to quit. And you’d be right. But. Many of us who really enjoy software development feel a bit like rock stars. You spend months or even years putting the show together, and then your launch date is like a performance. And you want to hit your launch date. Part of it is like theater people: the show must go on. But you also want to feel like a rock star when all your hard work hits real users for the first time and you feel that thrill of I did that. People like what I did. I overcame the impossible. A software launch is like performing live theater for introverts. So, by this point it’s almost Christmas. The team has basically built the replacement software in one month of work. There are still some features to hash out. But these are clever developers and they’ve been hitting their marks and I know we are going to make the testing date if they don’t burn out. So when the CTO comes to me and says holidays are cancelled, I say “OK.”… And then for one of the proudest moments of my life, thinking back to my dad’s advice about getting the job done in spite of the boss… I tell my three guys “take the week off. I got this.” And I dial in every morning for the mandatory death march status call with the CTO and I lie. “The team is working hard. Today we hit milestone integration point #73.” “The team made good progress yesterday, we finished another web service.” Every day I showed up and told the big boss that we were hard at work on stuff that we had already completed over the previous month. The guys came back a week later, refreshed. And we hit our dates in January, went live with a great launch, and were rock stars for a bit. Maybe more like Herman’s Hermits than The Beatles. But it still felt good. And that’s the time I lied to the CTO.",
    "commentLink": "https://news.ycombinator.com/item?id=40304453",
    "commentBody": "The Time I Lied to the CTO and Saved the Day (grumpyolddev.com)294 points by mundanerality 8 hours agohidepastfavorite204 comments motbus3 2 hours agoIf you are a \"delivery driven\" person who cancels holidays to keep working, I would say to you, from own experience: stop being stupid. I know, that, specially when you get recognised for the hard work it is hard, but you will regret every minute. If you work for a company that counts on your holidays and vacation to sell their products, you are helping to create the problematic world with have today. If many do that, more will need to do. If none do it, and act like it is an absurd to request it (and it is) nobody is forced to do it and the company is forced to do real estimates even if that hurts your fav CEO pocket reply flibble 9 minutes agoparentI think this is poor and dangerous advice for anyone who wants to get ahead in life. If you are happy to coast by and not achieve much in life, sure, don’t work hard. But if you want to be one of the few who either rise to the top in your field or to create value in the world, then don’t feel bad about wanting to work hard. People generally learn by doing and those who do a lot learn a lot. Of course, don’t prioritize it over things that are important to you (physical health, family etc) but don’t feel it’s wrong to prioritize it above stuff isn’t important to you (eg Netflix and YouTube shorts). reply intelVISA 3 minutes agorootparentWorking hard is the only reliable route to excellence, the tough part is making sure you don't get exploited along the way - 50% equity or walk. reply winrid 2 hours agoparentprevthis is probably why they are grumpy now :) reply louwrentius 2 hours agoparentprevThe messiah complex is rampant with both developers and operations people. The are addicted to feeling valuable and important. When they get home from work, they have nothing else to do. reply sshine 1 hour agorootparentIt’s not that I have nothing else to do. It’s that the dopamine hit of fixing a thing that affects my team often outweighs any other choice. Working out frequently, getting a family, getting a side project off the ramp, and reducing to part-time have all helped me with my addiction to feeling valuable and important when nothing else is gained than becoming known for fixing stuff in weekends free of charge. reply rozenmd 2 hours agorootparentprevMy hack was to start my own product, that way (at least for two hours a day) I get to play messiah for 100% of my own equity reply intelVISA 1 minute agorootparentOwn product is great, although it becomes difficult to justify bikeshedding variable names and a possible 3rd Rust rewrite vs. grinding out more hours on marketing and sales. reply neilv 6 hours agoprevAny impressionable kids reading... this story playing out like it did is highly company-dependent, as well as luck-dependent. In a healthy company/organization: * That outsourcing implementation approach probably wouldn't have happened, because an experienced person could've guessed how that would turn out, before it was started (it's such a cliche). * Earlier on, people would tell the CTO it wasn't working out, instead of lying and saying the opposite. * Whenever they needed to do something smarter/creative to rescue the project, they could work with the CTO on that, and maybe even with the customer. * There wouldn't be marathon whip-cracking over the holidays, especially not after the team was already burning out. * A manager/lead would go to bat for the success of the project and the health of the team, and insist upwards that the team needed a break over the holidays, if that needed to be clarified. On that last point, in a \"half-healthy\" organization, a manager might intentionally be very vague, and omit information. That happens, and might or might not be a good idea, depending. But the way this story is told, it sounds like the manager/lead outright lied repeatedly up the chain of command, which is generally considered very-bad, in both healthy and unhealthy companies. I'll add that these things are vastly easier to armchair-quarterback. Certainly we're all going to make mistakes, especially when put in difficult positions, and/or when overextended/fatigued. But it helps to look at scenarios, to try to learn from them, and to think from a distance how they might've been handled better, so you're armed with that \"experience\", the next time you're tossed into a rough situation that has some similarities. reply ethbr1 6 hours agoparentAll of the bad stuff in the article is a consequence of the CTO not being able to call technical bullshit and encouraging a culture of yes-reports. If you ever find yourself in a company like this, start looking for a new job. It's impossible to fix rot that bad at the top, and they're not going to make you CTO. reply fendy3002 5 hours agorootparentThe worst problem is, every success will be credited to CTO and every failure will be aimed towards the manager because it's a disobedience. In this case, the CTO also reward the credit to his friend because he/she doesn't know the backend. In the short time you may save the company, in the long time you'll lose and the company will lose too. reply lukan 4 hours agorootparentprevThe CTO certainly seems not the most competent. \"Because the CTO had a yearly turnover of his direct reports, every status call about the project took some variation of “great idea, boss” even though literally no one involved thought it was even a good idea. Or even a mediocre idea. It was a bad idea\" But if everyone confirms his bad decisions instead of pointing flaws out, then they are all part of the problem. reply shalmanese 37 minutes agorootparent> But if everyone confirms his bad decisions instead of pointing flaws out, then they are all part of the problem. They are part of the problem but they don’t have to be part of the solution. It’s the CTOs job to realize they’re not getting accurate information from below and work to fix it, that’s why they’re getting paid the big bucks. It’s not like it’s especially hard to figure out but building the trust to create an atmosphere of psychological safety is the job of executives and takes a lot of hard internal reflection but that’s what you sign up to when you sign up to do the job. reply atoav 3 hours agorootparentprevThat is true, but the times I have seen such dynamics happen it was usually do to... emotional instability. If every time a subordinate brings you anything other than stellar news you get all emotional, angry and start blaming people guess what: Nobody is going to give you the truth anymore — as A) it seems you can't handle it anyways and B) there is no incentive for them to give you the truth while there are many incentives to not give you the truth. This is just bad leadership. The most important thing to make good decisions is correct and meaningful information. If you punish people for telling you things that you don't want to see, you will from now on never have a good picture of what is going on. Good luck making decisions that way. And this isn't even rocket science, it is basic common sense. reply lukan 3 hours agorootparentYes, that is bad leadership. But the article does not say that this CTO did this: \"If you punish people for telling you things that you don't want to see\" It is implied, but I rather see direct evidence of a culture of yes saying and grumbling behind the back, something I learned to hate. Most people in reality do not face a existential crisis, if they speak up and the boss gets mad. It might cause inconvenience, but this is already enough for many to just nod along and venting out that frustration later. And wondering why nothing ever changes. Those things work both ways. reply atoav 3 hours agorootparentAgreed, this is all speculation and I have seen corporate culture that worked despite bosses like that, but these were also corporate culutures which would have worked even better without the interruptions and \"great ideas\" from the top. The main thing a boss can do is ensure the incentives for the behavior you want to see are there and there are disincentives for behavior you don't want to see. And with this over time corporate culture can be changed. But the peculiar thing is that you are part of corporate culture, and a part with special reach and importance — so you better act as you say. And this is rarely the case. reply dheera 5 hours agorootparentprev> encouraging a culture of yes-reports I get the impression that most large corps are of this culture at this point reply StressedDev 5 hours agorootparentNope - Well run companies want to know the truth, expect mistakes, and want people to learn from them. In most of the teams I have been on, being a yes person is no t rewarded because yes people cannot deliver. reply rezonant 41 minutes agorootparentMost large companies aren't particularly well run. reply mewpmewp2 2 hours agorootparentprevWhat is the size of your company? reply orwin 1 hour agorootparentMine has 1.2k people and is the same. Very unionized, it's the IT part of a big energy company. reply Log_out_ 2 hours agorootparentprevThey deliver pressure, crunch and obedience. There are no well run companies. The defunct is part of the process as a load bearing pillar. reply pmlnr 4 hours agoparentprev> In a healthy company/organization This mythical beast, where can one find one? I haven't, in the past 25 years of work. reply exe34 38 minutes agorootparentScotland. The home of the true Scotsman. reply tw8345 6 hours agoparentprevWhere do you find this mythical organization you call a healthy company? reply hn_throwaway_99 5 hours agorootparentTo be honest, I'm wondering where all these cartoonishly unhealthy companies come from. I've worked in a bunch of companies in my career, and sure, at pretty much all of them at one time or another I may have thought \"are you f'ing kidding me?\", but that's really just the nature of large organizations. And perhaps I've just been lucky, but in 25 years in tech I've never seen the level of gross incompetence described in this post. I'm truly envious of the vast majority of senior leaders and execs I've worked with - not because they're geniuses or anything, but because they excel at things that I find very challenging (and I know from my stint in management) and I learned a lot from them. Again, not everyone, but I've certainly had more good bosses than bad. reply pmlnr 4 hours agorootparent> where all these cartoonishly unhealthy companies come from. From MBA people. reply varjag 29 minutes agorootparentJack Welch was chemical engineer… reply raverbashing 1 hour agorootparentprevLet's not kid ourselves, engineers can and do fumble management matters reply sambazi 1 hour agorootparentprobably more like too entrenced in their trade and don't focus on other ppl. reply michaelt 36 minutes agorootparentprev> To be honest, I'm wondering where all these cartoonishly unhealthy companies come from. Simply take the norms of one industry, and apply them in a radically different industry. Take a manager from the construction industry who knows a bricklayer with an assistant can lay 2 tonnes of bricks in an 8 hour shift, and if they didn't it's probably because they took a 3 hour lunch break, and apply it to the software world. Take a manager from the food service industry, who expects workers to clock in before their shift starts, and that a worker who's even two minutes late is letting down the team and needs immediate attitude adjustment. Take a manager from precision manufacturing, where Zero Defects is the norm, and \"bugs\" don't exist, and failing to deliver precisely what was promised is a big embarrassment. Take a manager from the call centre industry, who thinks if you take a lax attitude to sick leave people will start falsely calling in sick all the time, anyone who calls in sick should be interviewed by HR upon their return. Take a manager from a paperwork-heavy industry where work is simple but precision is important - like data entry for paper forms, where a worker who makes even minor typos just isn't cut out for the work. Take a drill sergeant from the army who knows the most important thing in inducting a new employee is yelling in their face and bullying them, thus letting them bond with their peers.... reply dullcrisp 4 minutes agorootparentMan I didn’t know all my managers had side gigs reply huygens6363 4 hours agorootparentprevPerspective matters IME. I held both perspectives, this org is dysfunctional and healthy, at the same position, organization and exact same circumstances. In one I was sure I was right and in the other I entertained the notion I actual might not be and things are not that simple. reply neilv 5 hours agorootparentprevYeah, I've generally had good bosses and colleagues, including some outstanding great ones. (Actually, I had such overall good colleagues earlier in my career, I was totally unprepared the first time I ran into someone dishonest. It took too long to believe they would behave like they did, which ended up extremely costly.) Despite overall good experiences, I've heard of dysfunction like this article describes, and even worse, in numerous real-world companies. Talking about particular instances can be very delicate when you have insider info. But I think there's enough frequent dysfunction in industry, and some very common tropes that we keep hearing from people at other companies, that senior engineers will tend to be able to immediately recognize some of it. reply StressedDev 4 hours agorootparentMy experience matches yours. I have had very few bad bosses and almost all teams I have worked on have been healthy. I have been on a few bad teams and groups. They usually failed. They were not bad because they failed but because lying was rewarded, political skill was rewarded, and solving the customer's problem was not valued. When I see questions like \"where are the healthy companies?\", I think either the poster has been very unlucky, or the poster might be the problem. When I say the poster is the problem, I mean they typically fall into one of the following buckets: 1. The person is very critical and cannot accept humans for what they are. They demand perfection, demand their coworkers are the best in the field, etc. They may also minimize the positives. 2. They have a very cynical or negative outlook. 3. They do not like their field (computers, sales, accounting, medicine, etc.). As a result, they are always unhappy. The main point is something inside the person causes them to view every organization as screwed up and awful. This includes organizations which are OK, good, or even outstanding. reply barrenko 3 hours agorootparentUnderstand that luck works in the same way as \"unluck\". reply t43562 3 hours agorootparentprevYour experience is not a scientific experiment so you also have to consider that you might have been lucky. Perhaps other people have been unlucky. For example, I could paint your post in a negative light: \"A poster who blames the victim perhaps wants to feel good about the company they work in and ignore the experiences of others, or perhaps they are now in a responsible position and don't want to think that they might be part of a problem.\" This would be unempathetic but so is trying to blame the people who describe their bad experiences. reply justinclift 4 hours agorootparentprevDon't get a job at IBM. ;) reply neilv 6 hours agorootparentprevIt's aspirational, and people who aspire will achieve it to varying degrees. For starters, we can all aspire to work in a company where people wouldn't be outright lying, nor feel that they needed to. reply hibikir 6 hours agorootparentprevMany of the top companies you know were that healthy company once. You basically need to be one at that magical inflection point where the growth will crush you if your engineering is not empowered and on point. Especially back when clouds didn't exist, or were far less featureful, so turning dollars into horizontal growth was not a thing. The dark secret is that being a healthy company is just a moment, not something a company is at all times. Staying a healthy company as you grown when you are actually successful is very hard, and once the health is gone, good luck regaining it, because now you have a lot of people that thrive in unhealthy environments. reply 000ooo000 5 hours agorootparent>being a healthy company is just a moment Bang on. This is why I find these other comments which amount to \"work in an unhealthy company? Just don't!\" to be so naive. You're only ever one departure away from a shakeup which can totally change your work environment. If you aren't equipped or prepared to play the big game, then your options are A) suffer B) leave and roll the dice on the next joint reply antod 4 hours agorootparentprevSo true, when looking back at the great companies I've worked at, none of them are still like that any more. reply aprdm 5 hours agorootparentprevI have close to 15y of experience now, and I've mostly only worked on healthy companies - I can think of 1 that wasn't. I have worked in ~8 companies give or take. reply mewpmewp2 2 hours agorootparentThat seems quite a lot of changing the companies. Why so frequent switches? reply okwhateverdude 1 hour agorootparentNot OP, but I have a similar track record. Frequent switches because boredom, better pay (especially the first half of my career), and always searching for that amazing moment of confluence where I'm the dumbest guy in the room and working on an incredibly interesting/complex problem. Two years is about right to tackle something important and deliver, and also feel out if there are other opportunities at the current company. It has mostly worked out for me. You get really good at on-boarding yourself and getting up to speed quickly. I sell my labor as being an expert generalist and have professionally worked with half a dozen different languages, numerous different stacks, in a few different industries, and at big, small and in-between sized companies. reply mewpmewp2 34 minutes agorootparentI feel like this approach wouldn't be able to make me truly valuable at any larger company for example, which in this case would be the ones considered unhealthy? Because there's enough complexity that takes years to understand. I think as an engineer your ability to provide value climbs in multiples the more you understand the product and what the company itself exactly values, besides the tech. You can solve meaningless problems using tech, but if you understand what is exactly worth solving, this is when your value can skyrocket, especially the larger the company is. Because you will have the understanding of marketing, leadership and product people while having technical capability to know what can be done. And also I feel like if it's better to switch companies every 2 years because of better pay, it implies that the current company is not actually healthy, because if they were, they would understand the value you provide, you should be able to provide more value at their company rather than starting from scratch in another company. While I don't feel my current company is healthy, at least I feel like I've been able to climb through promos and compensation faster than if I were to switch every 2 years. I have been there for 6 years. reply wormius 3 hours agoparentprevFormer company of mine got a board member who pushed his \"solution\" on us, and it fucked up so much of our ordering processes, things we didn't even SELL were being shown. It took a year and a half to fix this, meanwhile it also meant we were unable to reverse a sale because \"underwear\" was shipped out and we can't cancel it (meanwhile, we don't sell underwear, just networking services). So we had to wait for the system to close out the ordering process and THEN they could assist the customer. Of course, that board member left a year later, Probably very pleased with himself for suckering our idiot CEO. But that's ok cuz I got laid off of there, and I have no sympathy for that bumbling company. Idiots trying to outsource \"solutions\" that only added more pain for everyone. Sometimes these are actual problems that need solutions but half the time ... It's just more crap to make themselves feel like they're \"saving money but not building in house\". Yeah just now you have to pay contracts to support the crap you never built in the first place. Good job. Golden parachutes for all the leaders, I guess. reply zer00eyz 5 hours agoparentprev> Earlier on, people would tell the CTO it wasn't working out, instead of lying and saying the opposite. I have done this, also have brass balls and dont give a fuck. EDIT: I mean tell the truth, so rare to not hide the fuck up. See MS security memo. > There wouldn't be marathon whip-cracking over the holidays, especially not after the team was already burning out. Ha ha ha ha ha... Ok this is partly true. IF you work in a BANK or in a FAANG then yes. If you work in any company that has \"startup culture\" forget it. The thing is that skin in the game (real skin) will change your attitude about work pretty quick. I dont think there are many companies where you will get it and have the opportunity to see that. > But the way this story is told, it sounds like the manager/lead outright lied repeatedly up the chain of command, which is generally considered very-bad, in both healthy and unhealthy companies. Do you know how many times I have been the cowboy who got some shit done in the dark of night cause it needed to happen? Most of the people I know who are good have gone this route. Hell I have seen these sorts of things happen AT A BANK. Bend all the rules past breaking but tell no one. As long as you aren't making a huge fiscal bet (aka more than the company or your teams value) then your gonna get away with a lot. You either do it and get promoted or you get a new job (cause you limited your ability to get promoted). reply neilv 3 hours agorootparent> If you work in any company that has \"startup culture\" forget it. Depends what \"startup culture\" is. I actually did an early startup work marathon over Christmas, to help pull off a minor miracle, and make a very hard launch date successful. But during the same period, I also managed the tasking/planning to shield a key teammate who'd gotten sick, and take stress off of them. > Bend all the rules past breaking but tell no one. I think that depends on the company, and the kind of rule. In some companies, rules tend to be there for a reason, and if you break a rule, you generally have to disclose that, and maybe discuss it (ideally beforehand). reply flarg 2 hours agoparentprevEven the healthiest large companies do this sort of thing, I've worked in a few and heck I've sold to a few too. Low code solutions that somehow need a team of contractors to deliver business functionality, delayed projects that drop key integrations to deliver something on time but functionally useless, CTOs whose next job depends on giving work to supplier. Worst of all, organisations that insist that they buy not build but then have larger software teams than their suppliers. reply wordofx 3 hours agoparentprevIt wouldn’t happen today because front end development is such a mess. reply fnord77 5 hours agoparentprev> Earlier on, people would tell the CTO it wasn't working out, instead of lying and saying the opposite. That's the part of the story that gets me. Everyone is acts so gutless. reply pojzon 2 hours agorootparent> Not my circus not my monkeys Some ppl just dont care coz in one year they will be in a completely different place reply irjustin 7 hours agoprev> The vendor product stored every customer transaction as a json record in a giant json document.... Adding a new transaction involved reading the entire json document out of the database, then appending the new record to the end. Does this sound insane to you? Obviously it should, but in the vein of \"insane things\" I was helping do tech diligence of a potential investment for a fund. The startup's users table also contained the \"tickets/booking\" data. Each ticket was a column. So if your most active user had 5 tickets in total history, you needed 5 columns. These guys had 500+ columns by the time I reviewed it, and were looking for an investment to \"scale\". Of course, it's a solvable problem, but as you can imagine everything was designed in some backwards, janky way. That was just the most obvious \"wtf\" moment. They did not get the investment. reply knodi123 4 hours agoparent> Does this sound insane to you? Obviously it should, I dealt with the exact same thing in my 2nd ever job. Entire customer and product database (with plaintext passwords) stored in a multi-meg public-facing .js flat file that had to finish loading before the app could do anything (with early-2000s internet). And to top it off, the app was a single monolithic file, in a directory with names like index.1.js, index.final.js, index.newest.js, index.45.js, etc etc. I had enough experience with best practices to go to our CEO and get the CTO fired, and went about rewriting it with git, mysql, and server-side logic with an actual architecture. And then, the windows server it was all running on got pwned into a porn server, and somehow it was my responsibility despite me never having seen this server and not even having admin permissions. Man, my first few jobs were educational! reply dvaun 7 hours agoparentprevThey read that column-oriented DBs delivered great performance. reply shagie 7 hours agorootparentThat sounds like some Bad CaRMa that I read about once... https://www.red-gate.com/simple-talk/opinion/opinion-pieces/... ... which while there were other red-gate posts out there, I can't find that one ever submitted as a dup to link the comments about it (this shall be rectified). reply datadrivenangel 5 hours agorootparentWriting \"RUN LIKE HELL\" on a white board is insane, and should not be ignored. reply labster 6 hours agorootparentprevYeah, column-oriented works best for musical performance because it makes it easy to switch from Ionian to Dorian mode. reply chefkd 6 hours agorootparentbut not phrygian :) phrygian bad reply CoolCold 5 hours agorootparentprevthanks for explaining on what are column-oriented DBs are in a ELI5 way reply yjftsjthsd-h 4 hours agorootparent... In case this is serious, the joke is that that is absolutely not what that term means. reply melozo 5 hours agoparentprevI worked atand we had this exact architecture. The senior engineer (who went to Stanford and was proud of it) designed this system. I had long arguments with him about how this system wouldn't scale when we launched it, and used real production data to prove that it would happen. No one listened to me, it launched and imploded within a few weeks, and soon after I transferred off the team. The worst part is, that senior engineer was eventually promoted and that system was passed off to an entirely new team to battle with. That entire system was terribly designed, and I think you can guess why. reply abraae 3 hours agorootparentShow me your tables, and I won't usually need your flowchart; it'll be obvious.\" -- Fred Brooks, The Mythical Man Month (1975) It astonished me that people can ever think this is a good idea (everything in a single json document) or that anyone who thought it was could ever get funding or even get through any basic customer due diligence. reply el_benhameen 5 hours agoparentprevMan, I’ve had one of those “I’m an idiot and only an idiot would rely on me to build things” kind of days. This made me feel better. reply prakhar897 7 hours agoparentprevIt’s genius. Schmooze the execs with fancy dinners and trips. Deliver a horrible product so they need you for the foreseeable future. The story itself says the CTO is unaware of everything. From his perspective, everything worked out fine in the end. Win for everyone except for the devs who put in 80 hour weeks. reply osigurdson 7 hours agorootparentYou missed the part where they say they felt like a rock star. Different people are motivated by different things. The key is, if you are very hard working try to channel it in a way that will actually benefit you. reply t43562 3 hours agorootparentYes, don't let other people channel it towards themselves! You're in a company, - they will fire you when it becomes convenient to do so - don't burn yourself out for them! reply tangjurine 7 hours agoparentprevHow about reading the entire Json document out of the database, making a copy of that document, updating the copy, and saving that copy to the database... Is how someone on my old team designed an internal tool reply danielheath 7 hours agorootparentDepending on load patterns, for an internal tool that might be perfectly reasonable; you can trivially look at the history, for one thing. reply Spivak 6 hours agorootparentprevIs this not how you update a JSON column on a db that doesn't have (or you choose to not use for reasons) a native JSON type with a sprinkling of data should be immutable? reply dude187 6 hours agorootparentWell without some form of locking you have a race condition. Two updates done at the same time can have the overwrite the other reply nicolas_t 5 hours agoparentprev> Does this sound insane to you? Early in my career, a client came to us with their internally developed perl web app that was very slow and asked us to help them. They were storing all of the information as csv files and would do exactly that, read the entire file, add a new row etc... We explained to them that we should rewrite it for them :) reply mrweasel 26 minutes agoparentprevThose types of design, especially the giant json document, has to be part of the reason some companies pushed pretty hard against the GDPR. Imagine trying to remove personal data from such a system. reply klabb3 6 hours agoparentprevI don’t understand the confidence that leads to such misuse. I’m NOT a db guy by any means, and yet when I need one I’m carefully looking up things like “what’s the space complexity of compound indices”, at a development stage. Defensive and paranoid. I guess there are a lot of cowboys out there. reply hobs 6 hours agorootparentMost people who use an index wrong dont understand space and time tradeoffs at all, how to measure if there is a problem, or how to identify what a thing should be in the first place. Most people who at least think a bit get pretty far before the vendor specific gotchas start biting. reply summerlight 5 hours agoparentprev> Each ticket was a column. So if your most active user had 5 tickets in total history, you needed 5 columns. I was thinking like, \"Oh yeah, they have 5 tickets, so need 5 rows. What's wrong?\". And I read it again and found it's the word \"column\". It must be a big fun to write a query for such tables. reply j16sdiz 2 hours agorootparentIt would be _slightly_ better if the DBMS have array types. Often they are not scalable, but it is better than thousands lines of copy-and-pasted code. reply kubanczyk 4 hours agorootparentprevI bet it was SELECT * FROM customers; followed by a for loop. Easy-peasy. reply SkyPuncher 5 hours agoparentprevThis is something I’d do it a ship it tomorrow, trash it the day after MVP. In a consultant project with nearly a year to deliver, no way. reply luhn 5 hours agorootparentWould it help, though, even in the short term? Making an actual `ticket` table really isn't that much work. If for some reason it is, you can always use an array type, or even shove JSON into a text column. Even if you're not thinking further than an MVP—hell, further than 5pm—one column=one ticket seems the most awkward and difficult solution I can think of. reply hansvm 5 hours agorootparentMy best guess is it started as a single ticket column, then maybe a manual migration to quickly add a second when a rat's nest of code was built around the single column already. reply albert_e 5 hours agorootparentprevthe most far-fetched justification I can muster up for this: the UI/user requried a tabular display of all tickets as columns with one row per user ... and they had a UI that only displays DB table contents as-is. Nah, even for a 5pm demo that just sounds absurd (with up to 500 tickets per user). reply emrah 5 hours agoparentprevHonestly this is not necessarily a good reason not to invest. Sure this needs to be fixed, plus whoever allowed this to happen should be replaced but analyzing the business as an investment opportunity and passing because of this is just as insane in my opinion reply nicolas_t 5 hours agorootparentExecution is what matters in startups, if they either can't find developers who are halfway decent or if a cofounder wrote this, that's a major red flag that they don't know how to execute. reply roenxi 7 hours agoprevEverything in this story is dysfunctional, including the protagonist's approach. It is completely unacceptable for a team leader to give their people time off and lie about it and he is well in to territory where the company could fire him. I wouldn't be surprised if it was a fire-for-cause situation, in fact. Although upper management sounds so off the rails that he would probably get away with it and get a commendation of some sort; it does seem to be a play to the environment he's in. A tip for new team leads; there is nothing here to feel proud of and a better play is to kick up a huge stink about people are working overtime and insist that the vendor be held to sane standards or project scopes reconsidered to fit in a normal work week schedule. Trying to make this sort of situation work is going to burn people out for nothing, or get people fired with no potential upside. Unless I were truly desperate for work to keep my family going, a team lead has a responsibility to protect their team's reasonable work hours from insane requests. That is a hill to get sacked over, but not to lie for. reply speedbird 6 hours agoparentBecause throwing the CTO under the bus is always career enhancing ... reply roenxi 6 hours agorootparentThat isn't throwing anyone under the bus. I've had literally that conversation and it went fine. If you're optimising for dev productivity, you let them take holidays and work them to a plan that lets them get a good night's sleep and some time to recover. reply refulgentis 6 hours agorootparentYou literally had what conversation? You went over the CTOs head, to the CEO, problem got fixed, and your career stayed on track, and it was a company of > 5 people? #1) That's a miracle. #2) That's before we get to the actual situation. It's December and work is due to the client in 1 month. 99 times out of 100, the CEO is going to decide you're an insubordinate loose cannon showing up inappropriately late to make confusing complaints about outsourcing decisions that were made 10 months ago. Conversely, lets say you made a big stink about this 10 months ago, when the outsourcing decision was made. 999 times out of 1000, the CEO is going to assume you're an insubordinate loose cannon showing up inappropriately to make confusing complaints about outsourcing that are above your pay grade. Hell is other people, and I find it very hard to believe you have extensive experience and can breezily handwave about \"literally having that conversation\", in any form. I can think of a reason why at every point in this entire story, the person complaining would be blamed. I don't think the outcome is great, I'd definitely be looking for other jobs, but again, 36 years old and every experience I've had everywhere is that these situations are bad news and you wanna avoid conflict, unless you have nothing to lose. reply roenxi 5 hours agorootparentThe \"kick up a huge stink about people are working overtime and insist that the vendor be held to sane standards or project scopes reconsidered to fit in a normal work week schedule\" one. I'm not sure where you're getting \"went over the CTOs head\" from; I never suggested doing that. It sounds like a stupid thing to do. You kick up a stink by talking to the CTO, 1:1. Or whoever you report to. reply bcrosby95 5 hours agorootparentprevHe never said he goes to the CEO. This story is about the CTO having a dumb idea and literally no one pushing back on the plan, with the only people suffering are the (relative) grunts. There's ways to respectively raise flags here. The answer isn't to go to the CEO, the answer is to not be a drone-like yes-person. reply mewpmewp2 2 hours agorootparentSo who do you have this conversation with if history has shown that yes people are the ones who stay close to CTO and others get filtered? reply chasontherobot 5 hours agorootparentprevI'm trying to figure out where you are getting this \"go above the CTO's head to the CEO\" situation from the message you are replying to? I am not the person you are replying to, but I've definitely made a stink my boss about my people being overworked. If the person from the original article went to the CTO and said \"look, my people need a week off, but we will still have the software delivered on schedule\", that would have been the right solution, not lying to your boss. reply mewpmewp2 2 hours agorootparentThen you risk with CTO saying \"no, we just can't afford it.\" And then it feels like they might more actively look into that. reply refulgentis 5 hours agorootparentprevA: Because throwing the CTO under the bus is always career enhancing ... B: That isn't throwing anyone under the bus. I've literally had that conversation. This led me to believe B had a literal conversation where a literal CTO was not-literally thrown \"under the bus\", meaning \"authority figure was told the CTO was to blame for $X\". Authority figure for a CTO is generally CEO. reply tw8345 6 hours agorootparentprevsometimes you burn the CTO but you better make sure you brought ample firewood because guys at top can take some serious heat before melting and most low levels underestimate the amount of firewood it takes resulting in getting roasted by the leader instead. reply dheera 5 hours agoparentprev> It is completely unacceptable for a team leader to give their people time off It is more unreasonable for the company to cancel already-given time off. reply nashashmi 38 minutes agoparentprevThe part you are missing here is that the work was already done and none of that progress was shared with management. After all what would they do? Accelerate the project! Stick it to the man when they try to get others to work harder to glorify themselves. Weak bastards. reply iamthepieman 7 hours agoprevMaybe I'm lucky but I've never been fired for telling the truth and the truth is easier to align to. \"There's a bug in a third party library that's part of the critical path \"We can make it harder to hit the bug but can't fix it until the vendor fixes it\", or \"user growth has revealed performance issues no one thought we'd encounter this soon, we can spend three times as much money on infrastructure to mitigate it for the 2 months it will take is to fix it or lose customers due to performance\" or \"our biggest customer didn't know what they wanted until we delivered the first iteration, now they want something that isn't at all what we thought we'd be building. We can build it and be profitable or follow our dreams and die\". Again maybe I've been lucky but honesty has worked well for me. reply lazyasciiart 6 hours agoparentI’ve never been fired for being honest but I have been managed out of a team for it. reply mewpmewp2 2 hours agorootparentI have not been fired, but my output has been ignored or heavily filtered by layers between high leadership and myself. And I have been given feedback in perf reviews that I have been disagreeing too much. And in those cases it did turn out later that I was right, so I wasn't being difficult for no reason. reply t43562 3 hours agoparentprevThis is not really about honesty - if someone asks your opinion you can explain your concerns diplomatically - but if they don't then you can also keep quiet. It's more about whether you're going to actively point out a problem with a plan that someone higher up than you is trying to take credit for. i.e. they will feel personally attacked - that their judgement is questioned - when you speak up. It's an extremely difficult thing to do without making enemies and enemies last a long time and 1 enemy is more damaging than can be made up for by lots of friends. reply bruce511 6 hours agoprevDeveloper interactions with management suffer from huge information imbalances, and a lack of trust. For example, I'm working on a project now to update a code base running on a (very) old compiler. We've been working for a year, and large chunks of the system are done. One (fairly major) part is yet to be completed. Management doesn't understand the process, or have confidence that the project will ultimately be successful. I don't blame them for being skittish, software projects (especially conversions) have a long history of failure. We had weekly meetings with them on progress - which are now twice-weekly (because that will speed things up.) Mostly they don't attend directly, a middle manager acts as a go-between. The developer view is that of course this will work (personally I've never been in doubt on that front) but the time-scale is uncertain because the system is large and old. But we're talking months left, not years. Yes, I'm aware of the 80/20 principle, but we're well into the 20% already. Of course to management it's a binary state, done or not-done. It's hard for them to guage progress. There's no \"trust\" in what we say. Which makes sense to me. We might have done 0 work for a year. If all we did was the meetings -they wouldn't know-. (Its a fixed price job, so it doesn't make sense for us to drag it out.) Of course the risk is all on them. They've spent a bunch of money and are nervous. They made (good) tech decisions (based on the advice of outside people who understand the tech) but they feel very uncertain. Ultimately if the project fails they'll take a hit (not so much us.) There's no easy fix here - you can't just argue that managers should be technical (the tech is not their core business), and more \"consultants\" won't make them feel warm and fuzzy. The best we can do is push through and deliver. reply zer00eyz 5 hours agoparent>> One (fairly major) part is yet to be completed. Break this down. Break it down into granular chunks even if they are a month long. Divide everything up into sub tasks. Even if they aren't perfect even if you have rough edges. Name every chunk something friendly and fun. I recommend classic dances... tango, cha cha, waltz. Call a meeting with your managers (including the high up ones). As for middle managers to start attending (auditing) daily standup. Make everyone STAND for them (so they stay short) and track against the tasks on the list in the wave. Again, a piece being added, or a piece being late isnt going to freak any one out as long as you are close.... We both know that going live is gonna be the big hurdle just dont tell them that till your ready. reply bruce511 5 hours agorootparent>> We both know that going live is gonna be the big hurdle just dont tell them that till your ready. Yeah. There are over 5000 stores that this will roll out to, so it'll go slow there. Fortunately there's a dedicated (separate) testing team so thats good. >> Break this down. Break it down into granular chunks even if they are a month long Part of the problem is that it's not easy to break down at this point. We are aware that \"it doesn't run\". (There are underlying classes which affect things.) What we don't know is \"how many class issues are outstanding\". We knock them off, and we move to the next one. We \"feel\" like its close now. But any attempt at quantification is simply speculation. We have tried -not- to introduce speculation into the process because that's not data. When we're pushed on providing speculate data (when will this be done?) we ecplain why that's impossible for us to determine and suggest (to the middle manager) that he guesses instead. He tends to not push too hard there. Part of building trust (at least as far as him) is in not making-stuff-up. We're clear on what we do know, and clear on what we don't know. Obviously I don't know yo what extent that is passed on upstream. Upstream are keen on dates, targets, reports on \"accomplishments\", all the usual management. \"We don't know\" is good data for them, but not what they want to hear, and perhaps not helpful to them. reply morgante 3 hours agorootparent> We are aware that \"it doesn't run\". ...what? You have an application that literally doesn't run and you've been working on it for months? reply mewpmewp2 2 hours agorootparentPresumably there is some legacy integration or blocker why it doesn't run. reply Sponge5 3 minutes agorootparentEven so, working as an engineer on a project that doesn't run as a whole for more than a week, let alone months.. It's very understandable that management is nervous. Cut things away until you have something that runs is step one... trueismywork 6 hours agoparentprev> They made (good) tech decisions (based on the advice of outside people who understand the tech) but they feel very uncertain. If they took advice of internal people and then made the same internal people work on it, this trust issue might get solved. Ultimately by showing lack of trust in their developers, they are showing lack of trust in their management skills for having selected the correct developers. They are doing one core part of their job very badly. reply ethbr1 6 hours agorootparentThe problem with hiring good developers is that you need good developers and a solid corporate tech culture to hire them. If you don't have anyone you can trust to interview technical folks, how will you avoid hiring bad developers? And similarly, if you hire good developers but your corporate culture is bad, they'll leave, and eventually the only remaining developers will be bad ones. It's very hard for non-tech companies to hire and retain quality talent. reply bruce511 6 hours agorootparentprevAlas, it's almost never that simple. Firstly because the tech team has varied enormously over the last 25 years. Some have been around a while, some are new. Secondly because middle management (and for all I know upper management) has cycled a lot over the last 25 years. (We've had 3 different middle managers on this project in the 2.5 years since the project was first proposed.) So, speaking generally now, it's common for the people who did the hiring not to be the ones who now have trust issues. Equally decades of failed software projects (industry wide) have lead to a (well deserved) reputation for IT not being trustworthy. reply ikiris 6 hours agorootparentprevThey probably didn't pick devs that they trusted, they picked the ones they thought were the cheapest. reply bruce511 6 hours agorootparentI think very few execs care about the cost of individuals. Firstly it's not their money, secondly they're not rewarded for \"hiring cheap\" but they are penalized for their failure to perform. Throw in that hiring in general is hard, and that hiring technical people when you are non-technical is even harder, and it's hard to have lots of confidence right out the gate. reply trueismywork 6 hours agorootparentprevAnd so again failed at their jobs. reply morgante 6 hours agoparentprevIf management has no visibility into the project progress, that seems like a pretty major problem. It absolutely shouldn't be \"binary.\" Any year-long project should have tractable progress metrics. Upper management doesn't need to be technical, but someone in the chain absolutely should be capable of translating progress into a digestible format. reply roenxi 5 hours agorootparentIt is a major problem, but it is the big unsolved problem of software engineering that has resisted a remarkable number of attempts by unreasonably capable people. Under normal conditions the metrics you are talking to boil down to \"the dev says we're making progress\". The level of formality with which they say that changes, but not the underlying process of how the metric is generated. The only way to improve on that is for managers to go in to git and check what is happening. Technical managers can get deep into tracking progress. Non-technical managers cannot. reply morgante 3 hours agorootparent> It is a major problem, but it is the big unsolved problem of software engineering that has resisted a remarkable number of attempts by unreasonably capable people. That seems like a cop out. Knowing precisely how long a project will take is famously hard, but knowing the rough progress being made towards milestones is absolutely solvable. Git is the best place to look, but you don't need that level of detail to see new things being shipped. Everywhere I've worked (from small startups up to Google) it is absolutely the norm to have clear milestones to work towards on at least a quarterly basis. reply roenxi 2 hours agorootparent> knowing the rough progress being made towards milestones is absolutely solvable Yeah, but the process for knowing that is ask the dev and they will tell you. Or ask the PM who will ask the dev. Or ask a tech lead who will ask the relevant dev. Or read the spreadsheet entry that the dev updated. All roads lead through conversation with the dev working on a feature. There are occasional exceptions, but they are rare. If the dev is willing to lie, or honestly mistaken, or just too inexperienced to estimate how they are doing then it is close to impossible to gauge progress. > That seems like a cop out You would probably believe the number of people who say that. reply bruce511 5 hours agorootparentprevWhen you build a building, it starts by digging a hole and then filling it up. Then you see walls go up etc. Although progress is visible, visible can lie. Obviously the project had milestones. But it is in the nature of big conversions/updates that you will encounter things you don't know. We're in that stage now of killing the unknowns. It's not a linear process and the quantity of them is unknown. So at this point metrics become hard. (We hit all the targets for the \"knowns\", and we continue to squash the unknowns, so the dev team is confident, but management is nervous.) Progress is easy to digest. But (for now) there's no easy \"finish line\" to see, which makes their lives hard. There's no \"quick fix\" here where \"better paperwork\" would improve things. As much as you (and indeed management) would like that. reply YouWhy 7 hours agoprevThe two things we know about the vendor are unforgivable: the fact that they let a core piece of logic depend on indefinitely augmenting a Mongo record, and the fact that a deliberate effort by 3 somewhat above average people could replace them in about 3 months of work. The fact that the vendor reached the state of doing business with a Fortune 500 client indicates how helpless organizations similar to this client feel facing even modest SW undertakings. Indeed, the project scope in question indicates it could be accomplished by some folks here as a hobby project. This also explains to me why Retool is so popular with tech leaderships, while not necessarily so with engineers. I wonder what other product approaches could address the same gap. reply eru 7 hours agoparentSpreadsheets were the killer app for exactly that kind of problem. Thanks to spreadsheets any low ranking peon can hack up a barely working, janky prototype of their idea for a tool over a few days, without having to deal with anyone else in the organisation. Before spreadsheets, you had to convince higher ups to convince the IT department to take on your request. That would take at least three months. Then you'd need to wait another few quarters until they delivered you a barely working, janky implementation that didn't match your requirements written in something like Cobol or C. reply cpeterso 6 hours agorootparentAnd with Google App Scripts, you can augment your Google spreadsheets with JavaScript to write custom functions that can call remote services (and be called back as a service!). reply eru 2 hours agorootparentYes. Though I was talking more about the 1980s, when spreadsheets first became a thing. That's also why I mentioned Cobol and C, Java hadn't been invented, yet. reply danielheath 7 hours agoparentprevI really want a term for the phenomenon whereby billion dollar companies frequently struggle to create the kind of technology three interesting weirdos can write over a weekend. reply gostsamo 6 hours agorootparentred tape. bureaucratic friction. multiple stakeholders coordination. The problem is not that smart people do not exist in a big org, but that they work in an environment with vastly different constraints which have been established because the scale and goals of the projects are vastly different from those in a small team. reply datadrivenangel 5 hours agorootparentprevFred Brooks discussed this in the 70s. A software system is ~3 times harder than a weekend-garage program, and a software product is ~3 times harder than a software system, so you're at 9 times the work before even starting to go into all the work marketing and selling it and doing the internal overhead work to make sure that the organization is ready to sell and support the new product when it's ready... Also a billion dollar company has a lot more to loose than a few interesting weirdos working on a weekend project, and so rightly expect more risk management reviews. reply dghlsakjg 6 hours agorootparentprevMisalignment of incentives reply linsomniac 6 hours agoparentprevI used to work for a regional telecom, at that time I was doing third tier support of applications. A couple devs and a couple support people went out to the users, the devs had been working on a new tool to solve some major problems. The devs had been working on it for 6 months, and this was the first the end users were seeing of it. Next thing I know we're drive back across state line, dev's tails between their legs. As far as I know, no-one ever spoke of that project again. reply aledalgrande 7 hours agoparentprevIt's probably Accenture and if not, something similar. Where they put graduates to do all the work and then charge the hourly for senior devs. reply AtlasBarfed 2 hours agorootparentThat was the 1995 model. It's all outsourcing or H1Bs now. reply snowwrestler 6 hours agoprev> I dial in every morning for the mandatory death march status call with the CTO and I lie. > “The team is working hard. Today we hit milestone integration point #73.” > “The team made good progress yesterday, we finished another web service.” > Every day I showed up and told the big boss that we were hard at work on stuff that we had already completed over the previous month. I think it's a really important detail that he was lying about work that was already done. That looks like \"underpromise and overdeliver\" from a certain angle. I'd feel worse about lying about work that's not done yet. Certainly riskier, and maybe not the best feeling for the team when they get back: \"Here are your tickets, I told the CTO they were already done, so hurry up.\" reply pavel_lishin 7 hours agoprevMan, I wish folks would stop using AI generated header images. Throws me off right from the get go. reply wokwokwok 7 hours agoparentI couldn't help laughing at it (https://grumpyolddev.com/images/IMG_2609.JPG). Is that code... on the back of the monitor? ...and the back of the chair behind her? Or is that a giant ipad she's sitting on? hahaha... If you're gonna use an AI image, come onnn... make an effort at least that it's not completely weird and crazy. It takes literally seconds to generate these images and this was the best you could pick? reply sgt 2 hours agorootparentMonitors with screens on both sides. Such a brilliant idea! Imagine the cost savings for companies putting hundreds of people on rows and opposite each other. reply rk06 3 hours agorootparentprevthe image is actually quite good. it is obviously not meant for realistic reply Topgamer7 7 hours agoparentprevHonestly if you added just a tad bit of noise. You probably wouldn't notice. reply calderknight 6 hours agorootparentThat's something you can easily prompt for, too. reply Dban1 7 hours agoparentprevuntil it gets virtually indistinguishable to the human eye reply swatcoder 7 hours agorootparentCommon usage never will. There will always be a bias towards some default settings in whatever popular tool, because people who aren't very discerning or dedicated will just punch in a few common ideas into the tool and take the first thing that looks good enough to them. But people on the outside will continue to have an instinctive sense for these default style biases and be able to tell pretty well that an image was produced that way. The escape hatch will be what amounts to AI stock photo industry, where practiced \"AI Art\" designers prepare images that are more subtle and unique and sell them pretty cheaply. The technology surely can be pushed to the point where a well-crafted image is virtually indistinguishable, but most people are going to just drop \"anxious woman at keyboard\" or \"happy dog with a ball\" and there's only so much unique information contained in those prompts so defaults will always reign. reply eru 7 hours agorootparent> There will always be a bias towards some default settings in whatever popular tool, because people who aren't very discerning or dedicated will just punch in a few common ideas into the tool and take the first thing that looks good enough to them. How is that different from the established practice of using stock photos? reply noirbot 6 hours agorootparentAnd most people see stock photos on a blog and see that a bit negatively too. If the ceiling here is stock photos, that's not great, but the issue is that the state of the art is \"stock photo but with glaring weirdness\" reply MBCook 7 hours agorootparentprevOn my phone this was good enough to fool me. I couldn’t see the back of the monitor. So as presented on the site it looked like a stock image. I didn’t heavily scrutinize it. But without the additional context seen on a desktop it’s not that remarkable. reply chfalck 7 hours agorootparentprevNever? Really? reply hn_throwaway_99 7 hours agorootparentprevEven if it were indistinguishable from the human eye, I'd still find it annoying. Not every blog post needs a generic, caricature-esque stock photo. reply MBCook 7 hours agorootparentThat’s all I could see on mobile. The screen is to narrow to see more than the lady typing and the edge of her monitor. So that’s all I thought it was. A generic stock image. So I didn’t pay any real attention to it because it was “just” a stock image. I agree with you. It was totally unnecessary. reply owlninja 7 hours agorootparentprevShe's staring at the back of her monitor on the main page. reply Larrikin 7 hours agoparentprevI wonder how many people said similar comments about Photoshop and other computer generated graphics when they were new. reply MyFedora 7 hours agorootparentNo need to go back in time. People say that about CGI in movies today. Studios lie about CGI, and even alter BTS footage. Directors are under NDA. Actors are clueless. Everyone says everything is real to appeal to the CGI bad crowd. Media outlets hype the new practically shot movie. After a few weeks or months after the release, the VFX studios behind the movie show off their work. Turns out it was CGI all along, but nobody cares at that point. reply noirbot 6 hours agorootparentTo be fair, a lot of folks who dislike modern CGI dislike it because it's often used poorly and hamhandedly. Would it maybe look better if they did it practically? Possibly, but a lot of the revulsion to it is based on seeing real movies that looked really bad because they did CGI as a shortcut around shooting a movie in the city they say it's set in, or clearly working around having an actor just shoot in an empty room and add other characters in later with no real interaction between them. If you do something poorly, it reflects poorly on the results. If it becomes endemic to do something cheaply and poorly, people will think that method is indicative of cheapness and laziness. It doesn't negate that it may be possible to do it well, but you can't just chide everyone for seeing the trend and reacting to it. reply AntiMS 6 hours agoprevOnce upon a time where I worked... We had a terrible release management system. (For IBM iSeries folks, it was Turnover.) And we used it for everything. Java code included. In particular, we used it for database migration scripts. And you know how database migration goes. You keep adding files and you never remove any. And there gets to be quite a few very quickly at the beginning of a project. And the folks in charge of setting up the release management system for our database migration scripts did so in such a way that we had to list out each one individually. Every release, we had to type like 50 database migration script filenames one-by-one. With no tab completion. (Not to mention the Java .war files we were deploying as well.) And by \"release\", I mean every release to the dev environment. (Now some of you who know of Turnover might know of a janky Eclipse fork that would let you create Turnover forms in a drag-and-drop way rather than through the green screen, but there were reasons we didn't want to go that direction. Long story.) As soon as I figured out how much of a PITA this would be every single day, I decided to do something about it. I wouldn't ask for permission. I'd ask for forgiveness (if it came to that.) So I set about writing a way to automate this. That way involved running the dumb terminal emulator (the \"green screen\" app tn5250j) in Xvfb and simulating key strokes to it. God was it a nasty hack, but it worked reliably and God was less painful to deal with than what we had before. Part of why I didn't ask permission was because I wasn't entirely sure I could make it work and I didn't know if the boss would ok a project that may pay off given our tight deadlines. But once it did work, I didn't keep it a secret and the boss praised me for it. Still don't know he'd have let me undertake that project had I explained and asked permission ahead of time, but everything very much worked out with that project in the end. Here's to lying to your boss. Don't ever feel bad for saving your boss from themself. reply cwbriscoe 4 hours agoparentJava was tacked on to AS400/iSeries so I can understand how it would be painful with any Change/Release management system. I would much prefer to stick with the old crufty RPG/CL on those systems. Tacking on \"new\" tech to old \"green screen\" systems is just a bandaid. Should have went to a modern OS at that point. Try doing JSON/CRUD apps on TSO/MVS. Not fun. reply cpeterso 6 hours agoparentprevInstead of hiding the project until completion, you could (after a little covert research) share the idea with the boss and time box the development: if the first increment of X days or a week continues to look promising, then attempt the next increment as long as the boss still has an appetite for your idea. reply MobiusHorizons 5 hours agorootparentnever underestimate how little appetite management (or anyone really) can have for good ideas when they are stressed (eg a time crunch). reply datadrivenangel 5 hours agorootparentprevDo this after you've built it. reply move-on-by 6 hours agoprevI would not want to work with anyone at either the Fortune 500 company or the vendor. Extremely dysfunctional and unhealthy work environment. Lying to the boss, secret projects using 360 hours of engineering time- not even including all the nights and weekends mentioned. This is not good. This is not right. reply aorloff 7 hours agoprevIf you ever come across a project where you are wading through levels of duct tape and wondering how this technical design ever got out the door you can be sure that when you get to the bottom you will find MongoDB. reply speedbird 6 hours agoparentBut its WEBSCALE! reply aidenn0 6 hours agorootparenthttps://www.youtube.com/watch?v=b2F-DItXtZs reply geraldalewis 5 hours agoprevI think this glamorizes and engenders an unhealthy relationship to work. “Rock star” and “ninja coder” works the same lever Steve Jobs used in the 70s to take advantage of smart people without enough sense of self worth. And don’t lie to people. reply daft_pink 7 hours agoprevYour comment about heavy customization reminds me about the days of talking to CRM salespeople. Those sales people that were like, “We can make our CRM do anything you want it to”, whenever we asked questions. What that sales person really meant was our product doesn’t actually work, but if you throw a huge truck load of money at us, we can make our product work. reply DeathArrow 3 hours agoprev>Mind you, most of us had already been working 60-80 hour weeks for the past 6 months I would change the workplace by that time. reply JodieBenitez 2 hours agoprev> As has been typical in my career, when the vendor said they had a product, what they really meant was they had something vaguely resembling a product that vaguely matched what we needed, and with heavy customization they could torture it into doing what we needed. How many times have I been accused of wanting to \"reinvent the wheel\" while facing this exact situation ? I can't count. reply ccppurcell 1 hour agoprevThis is not about lying but being, quite literally, economical with the truth. Just as you don't spend all your money at once, don't tell your boss everything you've achieved at once. Or not always anyway. I had to write a monthly progress report for one recent job. I kept a document of headlines for this, and put only two or three into each report. I kept some back for rainier months. This also helped me discuss my \"objectives\" since I often could predict at least one thing I would achieve in the next few months. reply dctoedt 6 hours agoprevReminiscent of the scene in one of the later episodes of Band of Brothers: In the last weeks of the European war, Major Dick Winters is ordered to send a patrol to cross the Rhine, in rubber boats, during the night — for the second night in a row. The patrol's quite-dangerous mission would be a repeat of what the same soldiers had done the previous night: to capture German prisoners and bring them back for interrogation. Winters concludes that the repeat mission would be a pointless risk of his men's lives. So he disobeys his orders: he tells his people to get a good night's sleep and report to him in the morning that they did the repeat mission but were unable to find any additional German soldiers to capture. Winters's soldiers were visibly relieved. reply widenrun 7 hours agoprev> A software launch is like performing live theater for introverts. This should be the title! reply contingencies 7 hours agoparentNice one :) Added to https://github.com/globalcitizen/taoup reply garganzol 3 hours agoprevThe story misses a continuation. What happened after CTO found out that the system was silently replaced behind the covers? IMHO, this is the most interesting part. I bet that the CTO was crushed by his ego. reply dikei 3 hours agoprevSo, you launched your complete rewrite, without any testings and still make ~100% compatibility with an existing vendor solution. Call me skeptics. reply asp_hornet 2 hours agoprevAm I understanding the story correctly? a year plus, no doubt horribly expensive engagement with an external vendor was replaced with a few weeks skunk works project buy an internal team member who executed it by lying up the chain of command and there were no repercussions. reply excusemyfrench 2 hours agoprevWhy do companies keep on treating employees like they do ? Just read this article. reply pftg 2 hours agoprevGreat story, nicely written. The goal is to show off ;) But really nice to read. Definitely, this is a bad example and precedent to build toxic and non-cooperative environments. And instead of solving the issue it make it worth. reply pojzon 2 hours agoprevStories like those always get big response on havker news coz for all the smart ppl we have here there are 10x of not smart ppl not here. And we all work with them on various levels in the organization. Remember - being smart is both a gift and a curse. reply devsda 6 hours agoprevThat was interesting and correct me if I misunderstood. So, their CTO asked the team(of 3 members) to work through the Christmas week even when they had been working like crazy for weeks and are on the verge of burnout. The author asks them to take the week off while lying to the CTO that the team has been hitting milestone xyz. The dev team came back fresh from holidays and hit the milestones. There are some management lessons in there on what to do, what not to do, how/why developers get insane deadlines and how they end up with burnout. I was expecting the lie to be about a technical or design decision since \"CTO\" was mentioned and how that saved the day. reply VirusNewbie 6 hours agoprevThis story is all fake, right? I mean, I've worked at multiple Fortune 500 companies, nothing works like this story says it does. >. Keep in mind that early in my career, And the CTO is calling you directly? The CTO of a Fortune 500 company? The 'review process' for a vendor pitch is the CTO asking his immediate staff? The system that needs 3 people a few months to build is being handled by the CTO??? reply raincole 4 hours agoparentWhen you read any story from an anonymous person about an anonymous organization and an anonymous project you can safely assume it's fictional. Not this story, but any story. We can still discuss over it, just like we can discuss the plot of Harry Potter. reply yakshaving_jgt 4 hours agoparentprevTbh I would believe a story about three people building in a few months what 20 people struggle to build in two years. reply thih9 4 hours agoprevOff topic, I'm distracted by the accompanying photo, the model's expression and the code being displayed at the back of the monitor. Looks like scroll-stopping AI stock photos are the new \"YouTube faces\". reply theogravity 6 hours agoprev> The database they chose was MongoDB and at the time Mongo had a record limit of 16MB per document. I loathe working in MongoDB (have been for the past 3 years at work), but this is one situation where it's just absolutely bad schema design and not necessarily Mongo itself. I may have missed it, but why let the vendor even proceed with this behavior? I get there's timelines with the client but can't you sue or get a refund from the vendor for their screwup? reply RulerOf 6 hours agoparentThe proof of concept was writing to a JSON file. Someone said \"but we need to use a real database.\" A couple JIRA tickets later... reply cnotv 2 hours agoprevNice funny joke for European people, when it comes about extra time and holidays. reply naugtur 3 hours agoprevIn my first adult job out of Uni I was working for a startup building a suite of tools for usability tracking/testing and alike. One of our main offerings was gonna be something similar to what HotJar is nowadays. We were busy with other stuff and I considered the requirements for the tool somewhat impossible ;) So it got outsourced. The outsourcing company was a tiny local software house. They delivered on every single requirement in under 3 months. Despite my better judgement I was impressed. Until we gave ot to an actual customer. After some back and forth with initial errors (relatable) it started running on a small portion of traffic. A week of running the tool on their website was 100GB of file storage and 100GB of storage behind postgress db. Utterly unsustainable. A few weeks later we had a \"do what you want\" sprint. I mean the engineering team decided (I know, different story tho) every 10 sprints we get one to do whatever we think makes sense for the product. So a brilliant new intern and I got to come up with new requirements to fulfill the same usecase but without the need to store colossal amount of data per visit. We wrote a new thing in 2 weeks and had a working demo. We used the next month to productize it. My initial.design was presenting user behavior as scenes, sort of like a comic book, instead of animating stuff to pretend it's a video. Over time product got that too tho. When the startup folded (yet another story) the technology behind that tool was the thing that got sold. Moral of the story? Whether you lie or not, bottom-up decision making can be pivotal to software products if you're lucky. reply ornornor 4 hours agoprevEverything that is wrong with contemporary software development, in one blog post. At least the author was not in an adversarial relationship with their devs, so not everything I guess. reply gnicholas 6 hours agoprevI'm curious if the three guys who got the holidays off knew that the author was lying to the CEO. Seems like it would be best not to tell them, so they can't get in trouble. But I imagine they found out after the fact! reply discordance 6 hours agoparentand did the author eventually tell the CEO that they replaced the CTO's preferred vendors stack / work with their own solution? reply jrpt 7 hours agoprevIf you’re seriously considering lying to the CTO you should instead just get a different job at a different company. That’s a really bad working environment if you think lying is acceptable or something to be proud of. reply _carbyau_ 6 hours agoparentIf you are considering jumping ship anyway and you are \"young and enthusiastic craving the rock star ego payout\"; why not do it and see what happens? reply cnotv 2 hours agoprevNice funny joke for European people. reply nu2ycombinator 5 hours agoprevBuild up to the lie is better than the lie. I would never brag about these kind of lies to be honeest reply nu2ycombinator 5 hours agoprevBuild up to the lie is better than the lie. I would never brag about these kind of lies to be honest reply fnord77 8 hours agoprevAnd if that had gone slightly wrong, this person would have gotten fired and also a bad reputation in an industry that is smaller than people think. reply toomuchtodo 7 hours agoparentReputation risk is important, but you’re still a disposable cog. When an opportunity to succeed presents itself, it’s a calculated risk. Could’ve death marched through the holidays and still been fired, for any reason. Sometimes you gotta manage up aggressively. (Have seen an engineering team liquidated the day after successful delivery, death marched to it, for example) reply fragmede 7 hours agoparentprevtake your shot. don't miss. If the chipper younger dev had failed, we wouldn't be reading this story. so there's survivors bias at play here. but we were all young and dumb like that at some point in our lives. it worked out for some but not for others. some exit the field entirely and go find other vocations. reply chefkd 7 hours agorootparentIt's kind of crazy how a single moment like that can define your entire life whether you can be in your child's life etc. Horrible interview habits, no networking, not listening when they told me to cut my hair, dress a certain way, not playing nice when working on features like this, divorce went from a nice paying gig to homelessness a la Britney Spears 2008 with reputation lower than my credit score :) Now I code just on my own knowing no network, no possibility of a job or of getting accepted to any accelerator. Tech is such a small world basically a small metropolis. The moral of the story there's a reason SWEs are compensated nicely for success stories like this one kudos to OP reply barkingcat 7 hours agoparentprevmeh, if you did everything right, you'd be laid off 1 day after launch. So there's really absolutely no risk to do this. Either way you will be fired/laid off, so why not just do it. reply MBCook 7 hours agorootparentRight. The project was gonna fail. Is it that inconceivable that some of the devs involved would’ve been fired? Cant fire the CTO, after all. It wasn’t his fault his stupid plan didn’t work. It can’t be the big successful company his friend runs. It’s the disposable staff who screwed up. reply ChrisMarshallNY 1 hour agoprevI can relate to the feelings; if not the actions. The biggest issue with this approach, is that it absolutely requires the local team to be really good. Not Dunning-Kruger good, but actually good. Those teams are very rare; especially these days. I have found that most companies deliberately avoid hiring these types of folks. They can be tough to manage. I was incredibly fortunate to have worked in such a team, but as I have left that silo for a number of years, I’ve also come to realize what a rare privilege it’s been. If you don’t have one of these teams, then this kind of thing would be incredibly reckless. Even with a good team, it’s still a huge gamble. I would not have done this, myself. It would have been too risky. I also had very technically competent managers, and would not have gotten away with it. Brings to mind people like Nick Leeson, of Barings Bank fame (Google him). I’m sure he was saying “I’ve got this!”, right up to the end. reply rendall 4 hours agoprevIt seems like everyone lied to that CTO. If you are, or become a CTO, be the CTO that no one feels the need to lie to you. reply noncoml 7 hours agoprevThey say that at the time they were an “Enthusiastic Young Dev” but worked for a Fortune 500 company reporting directly to the CTO and interacting directly with the customer and leading a team. Something doesn’t add up or is it just me? reply pratclot 2 hours agoparentExactly this! Yet the overwhelming majority of the comments takes it for a real story and jumps to share their experiences. I wonder if it was generated by an AI that just does not have an ability to cross check what it wrote. reply aidenn0 6 hours agoparentprevSome companies have high enough turnover that you are senior after 2-3 years and could be reporting to at least a VP in under 5. reply ang_cire 7 hours agoparentprevMy boss was an enthusiastic (sorta) young dev, who has reported directly to our CISO ever since I started, and is now markedly less enthusiastic. reply andrewstuart 4 hours agoprevThese days you get to work on a single Jira ticket that has been sliced so fine you barely need to write a single line of code, with morning standups in which you are expected to describe every moment of your day the previous day and every moment that you anticipate in your upcoming day with four people tugging their beards and harrumphing if you describe the slightest challenge. Doing something \"different\" would get you a warning, doing something major without full work breakdown, buy in, analysis, tickets and micromanagement would get you fired. reply smrtinsert 5 hours agoprevThis is the worst of the technology. It's not sustainable will ruin lives and relationships. I appreciate the authors pride from overdelivering, but I think that speaks to some other need that's not a healthy thing to want from a job - not to mention all that time was lost instead of spending it with friends and family and creating real memories. Finally, to be completely objective about it, the team donated their time free of charge, literally throwing their value away to correct someone elses mistake behind their back. Not a good move, especially if something goes very south. It's time for our industry to do better and not champion attitudes like this, especially in an era of consolidation where megacorp gets away it to this day and somehow sells it as a positive. We have to do better. reply AndyMcConachie 1 hour agoprev [–] Fuck this work environment. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Grumpy Old Dev reflects on their past, admitting to deceiving the CTO about a failing project with a vendor but later creating a successful replacement system with a small team.",
      "Despite facing burnout, they worked in secret over the holidays, lying about progress to the CTO while giving the team a rest, leading to a triumphant project outcome.",
      "The experience led to a sense of achievement for overcoming challenges and successfully delivering the project."
    ],
    "commentSummary": [
      "The forum discussion delves into a range of topics including overworking, leadership, healthy cultures, and ethics in tech.",
      "Participants highlight the significance of transparency, communication, decision-making, and work-life balance for successful work environments.",
      "The conversation also includes the challenges, risks, and benefits of tech work, advocating for healthier attitudes towards work and career growth."
    ],
    "points": 294,
    "commentCount": 206,
    "retryCount": 0,
    "time": 1715218767
  },
  {
    "id": 40302792,
    "title": "Users Upset Over Deletions Post OpenAI-Stack Overflow Integration",
    "originLink": "https://build5nines.com/stack-overflow-upset-over-users-deleting-answers-after-openai-partnership/",
    "originBody": "Stack Overflow Upset Over Users Deleting Answers After OpenAI Partnership By Chris PietschmannMay 8, 2024 - 9:14 AM EDT (13:14 UTC) Category: Artificial Intelligence In this ever changing and evolving world of user generated versus AI generated content, the recent announcement of Stack Overflow partnering with OpenAI recently has been met with some backlash by the community. There are reports today that several users have attempted to delete their content (questions and answers) from Stack Overflow with some difficulty, as the website doesn’t allow all things to be easily deleted. So, these users have decided to edit their questions and/or answers in an effort to “deface” them in protest of the cooperation between Stack Overflow and OpenAI. About the Stack Overflow and OpenAI Partnership Stack Overflow and OpenAI have joined forces through a new API partnership. This collaboration aims to provide developers with a powerful combination of Stack Overflow’s vast knowledge platform and OpenAI’s advanced AI models. Through the OverflowAPI access, OpenAI users will benefit from accurate and verified data from Stack Overflow, facilitating quicker problem-solving and enabling technologists to focus on priority tasks. Additionally, OpenAI will integrate validated technical knowledge from Stack Overflow into ChatGPT, enhancing users’ access to reliable information and code. Key aspects of the collaboration include: OpenAI will utilize Stack Overflow’s OverflowAPI to enhance its AI models and provide attribution to the Stack Overflow community within ChatGPT. Stack Overflow will incorporate OpenAI models into their development of OverflowAI and collaborate with OpenAI to optimize model performance. Both parties aim to improve the developer experience and foster efficiency and collaboration through community-driven features and socially responsible AI practices. The initial integrations and capabilities resulting from this partnership will be rolled out in the first half of 2024, with a focus on enhancing user and developer experiences across both platforms. The AI Backlash While Stack Overflow, and other Stack Exchange websites, are amazingly useful tools for the communities they serve, there are users who are not too excited about their content being used to train AI that will then offer their answers without attribution. This is actually a common reaction today by many of the authors of content across the Internet, not just content posted to Stack Overflow. The Internet is in a current state of flux with blogs getting decreased traffic and page views, AI being used to find answers more, some people not using search engines as much, and other changes. It’s definitely a time of tension as people are both adjusting to the new abilities of AI’s like ChatGPT and other LLMs (large language models), as well as the uncertainty of what this all means for the Internet as we know it. This recent backlash over the Stack Overflow and OpenAI partnership is only one example of the negative ways some people are reacting to the massive adoption of AI and the drastic changes that’s bringing us. Is Stack Overflow Banning Accounts for Removing Content? There have been multiple users posting to Twitter and Hacker News reporting that they have been receiving an email from Stack Overflow moderators stating their accounts have been placed on a 7 day hold, or temporary ban. This is after these users started attempting to delete multiple posts, both questions and answers, they had previously posted to the Stack Overflow website. Here’s a Twitter posts from one of these users: LOL. @StackOverflow mods are experiencing some frustration as several users have been deleting their answers since the announcement with @OpenAI partnership. As a result, they have started suspending accounts that engage in this behavior. It's important to note that the \"right to… pic.twitter.com/M2YbKGXpzC — nixCraft 🐧 (@nixcraft) May 8, 2024 As per the email from the Stack Overflow Moderation Team, it can be disruptive to the entire community to delete or remove content that might be useful to someone else. Even if this content is no longer useful to you as the author. Since Stack Overflow’s business, and the entire Stack Exchange network, depends on the user generated content for the websites to remain useful, the business reasons they don’t want massive amounts of users removing content is obvious. To be fair to Stack Overflow, the warning email and suspending of accounts is likely not a new thing. They’ve probably had this policy in place for a long time in an effort to protect the platform. It actually would be quite disruptive to the platform for users to easily deface and/or delete massive amounts of content, so it’s in their best interest, and that of the community, to protect the content. Also, this is likely an automated email triggered by the users actions, and contacting Stack Overflow directly about your content would be a good course of action. So far, I haven’t seen any replies from Stack Overflow about these accounts being suspended. It’s also unclear how many users are actually attempting to do this, so there may not be a huge amount of backlash against the Stack Overflow and OpenAI partnership. It’ll be interesting to see how this all plays out going forward, as the forward momentum of AI adoption is not slowing down any time soon. As for the rest of us Stack Overflow users, I would not recommend jumping to delete your own content in protest too. Stack Overflow Warning Email to Users The contents of the email that Stack Overflow is reportedly sending to users when they are suspending / banning their accounts, is as follows: Hello, We’re writing in reference to your Stack Overflow account: https://stackoverflow.com/users// You have recently removed or defaced content from your posts. Please note that once you post a question or answer to this site, those posts become part of the collective efforts of others who have also contributed to that content. Posts that are potentially useful to others should not be removed except under extraordinary circumstances. Event if the post is no longer useful to the original author, that information is still beneficial to others who may run into similar problems in the future – this is the underlying philosophy of Stack Exchange. Extensive deletions take a lot of effort to repair, please read “I’ve thought better of my question; can I delete it?” for possible alternatives. Because of the amount of disruption these incidents can cause, we have placed your account on hold for 7 days while we reach out to you to avoid any further misunderstandings. Once this matter has been resolved, your reputation score will be restored and your account will resume as normal. We sincerely hope this is just a misunderstanding, but we understand that you may have an exceptional reason to remove this content. If so, let us know by replying to this message. Regards, Stack Overflow Moderation Team Share this: Click to share on X (Opens in new window) Click to share on LinkedIn (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Reddit (Opens in new window) Click to email a link to a friend (Opens in new window) About the Author Chris Pietschmann Chris Pietschmann is a Microsoft MVP, HashiCorp Ambassador, and Microsoft Certified Trainer (MCT) with 20+ years of experience designing and building Cloud & Enterprise systems. He has worked with companies of all sizes from startups to large enterprises. He has a passion for technology and sharing what he learns with others to help enable them to learn faster and be more productive. Related Microsoft and OpenAI: Extended Partnership Announcement for ChatGPT, Azure, and more Both Microsoft and OpenAI have announced they are extending on the 3 year partnership they already have to keep making advancements together around Artificial Intelligence (AI). This partnerships includes AI products like ChatGPT, DALL-E, GitHub Copilot, and the Azure OpenAI Service. Both companies are stating that they're missions both support… January 23, 2023 In \"ChatGPT\" How Adoption of ChatGPT Can Benefit Your Career in DevOps, SRE or Software Development We are all looking to advance our careers and to find tips and tricks to help us get the leading edge in the industry. Technology certifications are a great way to to prove you have the expertise needed for the job. Sure, having expertise certainly helps when it comes to… March 1, 2023 In \"ChatGPT\" Azure Bicep: Create Azure OpenAI Service and GPT-4 / GPT-35-turbo Model Deployment Microsoft Azure OpenAI Service is a fully managed service offering from Microsoft that enables you to host your own instances of AI models from OpenAI, such as GPT-4 or GPT-35-turbo. There are security benefits to hosting your own instance of the OpenAI models, in addition to the enhanced feature set… March 15, 2024 In \"Featured Articles\" Leave a Comment This site uses Akismet to reduce spam. Learn how your comment data is processed.",
    "commentLink": "https://news.ycombinator.com/item?id=40302792",
    "commentBody": "Stack Overflow users deleting answers after OpenAI partnership (build5nines.com)262 points by miles 12 hours agohidepastfavorite273 comments mixedmath 12 hours agoAbout 5 years ago, StackOverflow messed up and declared that they were making all content submitted by users available under CC-BY-SA 4.0 [1]. The error here is that the users-content agreement was that all users' contributions are made available under CC-BY-SA 3.0 (and not anything about later). In the middle there were also some licensing problems concerning code vs noncode that were confusing. I remember thinking that if any of the super answerers really wanted, they could have tried to sue for illegally making their answers available under a different license. But I thought that without any damages, this probably wasn't likely to succeed. But now I wonder whether making all content available to AI scrapers and OpenAI in particular might be enough to actually base a case. As far as I can tell, StackOverflow continued being duplicitous with what license applies to what content for half of the year 2018 and the first few months of the year 2019. Their current licensing suggests CC-BY-SA 3.0 for things before May 5 2018, and CC-BY-SA 4.0 for things after. Sometime in early 2019 (if memory serves, it was after the meta post I link to), they made users login again and accept a new license agreement for relicensing content. But those middle months are murky. I should emphasize that I know nothing. [1]: https://meta.stackexchange.com/q/333089/205676 reply frognumber 8 hours agoparentMy understanding of licensing law is that something like 3.0 -> 4.0 is very unlikely to be a winnable case in the US. Programmers think like machines. Lawyers don't. A lot of confusion comes from this. To be clear, there are places where law is machine-like, but I believe licensing is not one of them. If two licenses are substantively equivalent, a court is likely to rule that it's a-okay. One would most likely need to show a substantive difference to have a case. IANAL, but this is based on one conversation with a law professor specializing in this stuff, so it's also not completely uninformed. But it matches up with what you wrote. If your history is right, the 2019 changes is where there would be a case. The joyful part here is that there are 200 countries in the world, and in many, the 3.0->4.0 would be a valid complaint. I suspect this would not fly in most common law jurisdictions (British Empire), but it would be fine in many statutory law ones (e.g. France). In the internet age, you can be sued anywhere! reply lifthrasiir 2 hours agorootparent> If two licenses are substantively equivalent, a court is likely to rule that it's a-okay. One would most likely need to show a substantive difference to have a case. Which does exist and can affect the ruling. CC notably didn't grant sui generis database rights until 4.0, and I'm aware of at least one case where this could have mattered in South Korea because the plaintiff argued that these rights were never granted to and thus violated by the defendant. Ultimately it was found that the plaintiff didn't have database rights anyway, but could have been else. reply 9991 5 hours agorootparentprevIf there wasn’t a substantive difference, then there’s no need to make the change. reply ZiiS 4 hours agorootparentA super literal reading of some bad wording in 3.0 created an effect the authors say they did not intend and fixed in 4.0. Given the authors did not intend this interpritation a judge is likly to assume people using the licence before it came to light also did not, hence switching to 4.0 is fine. Conversly now this is widiy known continuing to use 3.0 could be seen as explicitly choosing the novel interpritation (arguably this would be a substantive change). reply moefh 4 hours agorootparent> a judge is likly to assume people using the licence before it came to light also did not Why would the judge have to assume anything? The person suing could simply tell the judge they did mean to use the older interpretation, and that they disagree with the \"fix\". They're the ones that get to decide, since they agreed to post content using that specific license, not the \"fixed\" one. reply ZiiS 3 minutes agorootparentA license is between two parties neither gets to choose exactly how it is interprited. reddalo 4 hours agorootparentprevThe fact itself that programmers keep insisting on writing \"IANAL\" is maybe an example of that. A court would probably not agree on the fact that writing \"IANAL\", not the full sentence, is a sufficient disclaimer. reply jszymborski 4 hours agorootparentI personally write \"IANAL\", not to reduce my personal legal liability, but rather to give a heads up to those reading that I am not an expert, that I am likely wrong, and that you likely shouldn't listen to me. reply technion 4 hours agorootparentI feel there's a common thread that maybe should be some kind of internet law that people who make a point of noting they are not experts, are more often correct than people who confidently write as though they are. You see this particularly with crypto, where \"I am not a crypto expert\" is usually accompanied by a more factual statement than one from the self proclaimed expert elsewhere in the thread. reply Terr_ 2 hours agorootparentIn addition to \"humility implies self-awareness\", I'd like to point out a parallel thread of \"disclosure implies honesty and diligence.\" reply S201 4 hours agorootparentprevhttps://en.wikipedia.org/wiki/Dunning%E2%80%93Kruger_effect reply Kuinox 2 hours agorootparentYou can look it up and the Dunning Kruger effect is probably not real. reply WesternWind 3 hours agorootparentprevWhen I was younger there was a short period I thought it meant that a person was just really anal about details. reply makeitdouble 3 hours agorootparentprevDo you actually need a disclaimer ? I always assumed it was the same type of courtesy as IMHO, and someone taking legal advice from random strangers on the internet wouldn't result in any legal liability on the side of the commenters. reply ggffjhgftg 52 minutes agorootparentYes, people have been sued before for giving advice that was acted upon. I remember hearing about an construction engineer who was sued for giving bad advice whilst drunk to a farmer over fixing a dam. The dam failed and the engineer was found to be liable. reply makeitdouble 7 minutes agorootparentI can see the reasonning behind the case, as the engineer has plausible expertise in the domain and could credibly give actionable advice. When it comes to lawyers, there is already a legal framework where lawyers are responsible when giving legal advice, even when it's not toward their clients, the same way medical professionals have specific liabilities regarding the medical acts they can perfom. Non lawyers giving legal advice doesn't fit that framing, except if they explicitely pose as one. I'd also exclude malicious intent, as whatever the circumstances, if it can be proven and results in actual harm there's probably no escape for the perpetrator. reply sidewndr46 7 hours agorootparentprevIt is worth remembering that law professors have a vested interest in making sure the system work as you described. If contract law was straightforward, they'd be out of job. reply AnarchismIsCool 5 hours agorootparentThat's an admirable goal but if there are any \"bugs\" in the contract you probably don't want it executed mindlessly. Human language isn't code and even code isn't always perfect so I'd rather not be legally required to throw someone out a window because someone couldn't spell \"defederate\". reply frognumber 6 hours agorootparentprevI agreed in the abstract, but not in the specific (the specific professor was one of integrity, and sufficiently famous this was not an issue). However, it's worth noting the universe is a cesspool of corruption. If you pretend it works the way it ought to and not the way it does, you won't have a very good time or be very successful. The entire legal system is f-ed, and if you pretend it's anything else, you'll end up in prison or worse. reply kragen 12 hours agoparentprev> if any of the super answerers really wanted, they could have tried to sue for illegally making their answers available under a different license. they can plausibly sue people other than stackoverflow if they attempt to reuse the answers under a different license. but i think it's very difficult to find a use that 4.0 permits that 3.0 doesn't reply StevenXC 11 hours agorootparent3.0 has a \"bug\" that makes it risky to use materials without very careful attribution: https://doctorow.medium.com/a-bug-in-early-creative-commons-... reply miohtama 9 hours agorootparentI don't think this is a practical issue, really. I assume linking to the original answer is sufficient attribution. In the link you can find name, license and figure out if the answer was modified. Also linking the answer in a source comment is the smallest professional courtesy everyone should be doing. If you have some issue of not linking an answer then you likely do not deserve the answer in the first place. reply eviks 4 hours agorootparentThe blog illustrates that such assumptions about what's a sufficient attribution are fraught with danger, so \"the smallest professional courtesy\" can expose you to a $150k risk reply drivingmenuts 8 hours agoparentprevPeople put their content on the site for the public to use, and now the public is using it, it's just that \"the public\" includes AIs. Admittedly, a non-human public, nonetheless ... reply imadj 4 hours agorootparentThe problem is LLMs don't provide attribution/credit which directly violates the license[0] Otherwise search engines were already \"non-human public\" that scraped the site but directly linked to the answers, which was great. They didn't claim its their work like these models. The problem isn't human vs non-human. LLMs aren't magic, they don't create stuff out of thin air, what they're doing is simply content laundering. [0] https://creativecommons.org/licenses/by-sa/4.0/#ref-appropri... reply postepowanieadm 3 hours agorootparentprevYou have to agree on how your work may be used, no one has expected it will be sold for ai training. reply LouisSayers 11 hours agoprevI'm actually perfectly fine if StackOverflow wants to sell an answer I made to help train AI. For me, the purpose of providing an answer is to help save others (and my future self) time, and I don't really mind if someone uses that in a private product - especially if it helps tools like ChatGPT which provide an insane amount of value given the low monthly price. reply JimDabell 4 hours agoparent> I'm actually perfectly fine if StackOverflow wants to sell an answer I made to help train AI. I’m not. This was a collaborative effort to make the lives of programmers easier, and the data was always meant to be a public good. OpenAI – and, more importantly – all the other LLMs with pockets that aren’t as deep – should be able to just download the database and train on it for free. I don’t care about any license. I don’t care about attribution. Learning isn’t copying, so copyright is irrelevant. I contributed about a thousand answers to Stack Overflow, all with the understanding that anybody can download and use them for free, not so they can be locked up by Stack Overflow. What concerns me with deals like this is that it’s altering the cultural norm to expand copyright to cover not just copying, but use. Deals like this being made by OpenAI makes it more likely to cause pushback at the social and legal level when other LLMs are trained without these deals in place. It’s akin to – and can possibly result in – regulatory capture, making it difficult for new startups to compete with OpenAI. reply theteapot 8 hours agoparentprevGood for you. I'm not. I contributed answers to StackOverflow because I use answers other have contributed to StackOverflow, not to ChatGPT, not for ChatGPT to monetize. I don't use ChatGPT and probably never will. reply sp332 8 hours agorootparentBut the content you posted to SO was already permissively licensed. Other people can copy it, and make derivative works, and even charge money for them, as long as they cite your SO handle as the author. https://meta.stackexchange.com/questions/347758/creative-com... reply gtirloni 8 hours agorootparentChatGPT is not citing anything. It can't possibly do that reliably with LLM weights alone. reply nox101 5 hours agorootparent(1) The announcement (https://stackoverflow.co/company/press/archive/openai-partne...) says things will be attributed in both the 2nd and 3rd paragraph (2) It's only likely to attribute if it quotes verbatim... Just like a human. when I tell someone I learned that Array.map's second parameter passed to the callback is an index to the value just pass, I don't add \"And learned this on Stack Overflow from user gtriloni\". It's just knowledge that I learned. The only time I'd attribute is if copied a snippet of code or a paragraph to quote in a blog post. For me at least, that almost never happens. It take the knowledge I learned and apply it to my own code. It's rare if ever there is a something on S.O. so useful that I copy it verbatim. reply anileated 3 hours agorootparent> Just like a human An LLM is not a human. It is a tool operated by a, in this case, for profit entity. It has no human rights, but its operator has all relevant legal obligations. If it was, as you say, “just like a human” in relevant ways (think, feel, have self-awareness, etc.) then it would effectively be a slave subjected to extreme abuse. Either it is a tool that generates derivative works at mass scale for profit and its operator should be liable for licensing/attribution violations, or it is a conscious being and we should immediately stop abusing it. Pick your poison. reply mesid 2 hours agorootparentprevDoesn't Phind do this? It cites sources in its responses. reply scubbo 5 hours agorootparentprev\"The person you are upset with is technically permitted to do the thing that you are upset about\" is not a good counter-argument to someone's distaste. Whether or not the licensing agreement _permits_ this usage, it is not the usage that the contributor (to whom you are replying) foresaw and was enthusiastic about. reply sp332 4 hours agorootparentI'm not telling them how to feel. They've been wrong for a long time. reply random_cynic 7 hours agorootparentprevnext [11 more] [flagged] paulryanrogers 7 hours agorootparentName calling and dismissive responses aren't going to win anyone over. Please be more considerate. reply Der_Einzige 6 hours agorootparentnext [3 more] [flagged] xwowsersx 5 hours agorootparent@dang Many individuals in this thread seem to require a gentle reminder regarding the expected etiquette on HN. https://news.ycombinator.com/newsguidelines.html reply forgetfreeman 5 hours agorootparentprevOne generally doesn't have to lean into phrases like \"legitimate tactics\" and \"rhetorical power\" when they've got the moral, ethical, or intellectual high ground. Telling people they're idiots is about the most counter-productive single strategy for addressing human stupidity ever conceived. 1. they won't believe you 2. they'll ignore everything else you have to say because you're a dick. So the real question is, who hurt you? reply theteapot 7 hours agorootparentprevI think you're projecting something. Oblivion awaits you as it awaits these Gatekeepers of yours. reply forgetfreeman 6 hours agorootparentprevOh your cheerleading here is going to age like milk when unemployment numbers start ramping up in white collar sectors. For the record, when construction and industrial jobs got deleted the chorus line was \"retrain for service industry work\". When service industry and white collar jobs really start getting the same treatment, what's the move now? We're literally running out of economic sectors to pretend folks can be funneled into. reply coliveira 5 hours agorootparentAll of this would be fine if the wealth were shared by the population. The big problem is that wealth is concentrated and only a small group will benefit from these technology shifts. reply forgetfreeman 14 minutes agorootparentIt's weird how our species has had evergreen problems around resource allocation for at least the last few thousand years. reply throwanem 4 hours agorootparentprevThey'll tell us to retrain for construction and heavy industry. reply CamperBob2 4 hours agorootparentprevOh your cheerleading here is going to age like milk when unemployment numbers start ramping up in white collar sectors. You don't seem to understand that this is the goal. A very worthy one. We won't get to a post-scarcity economy by doing the same things -- and the same jobs -- that got us this far. reply forgetfreeman 12 minutes agorootparentYou what now? You think AI is the path to luxury space communism? I'm missing the part where the 0.1% that owns and controls basically everything shrug and lean into redistribution of wealth... reply uberman 9 hours agoparentprevThe price to get an answer from stack overflow is usually free as most questions have already been asked and answered. You dont even need an account. reply wrsh07 8 hours agorootparentThey do serve ads, we should probably stop pretending \"funded by ads\" is the same as free. Your attention isn't free. reply ssl-3 6 hours agorootparentSuppose I walk up to a tent at a festival that has a big sign that says \"FREE BEER\", and I ask a person there for a beer. They hand me a beer, and I go on my way. Was the beer free? I think was free. Now, suppose I walk up to a Budweiser-branded tent at a Budweiser festival that has a big sign with a Budweiser logo on it that says \"FREE BEER\", and I ask a person there who is wearing a Budweiser polo shirt, a Budweiser lanyard, and a Budweiser hat for a beer. They hand me a beer in a Budweiser-branded cup, and I go on my way. Was the beer free? I think that both of these beers were free. reply PaulDavisThe1st 5 hours agorootparentNow suppose you walk up to a tent that offers you free beer, but before they give it you, you have to burn 2% of your phone's battery watching an ad from them. Then they hand you the beer and you go on your way. Was the beer free? reply jl6 3 hours agorootparentAnd they also put a tag on your ankle identifying you as someone who likes beer, so that beer salesmen can come knock on your door tonight. reply ssl-3 2 hours agorootparentWe've somehow gone from this: > They do serve ads [...] Your attention isn't free. to something like this: > They tag my ankle to mark me as a person who enjoys beer, and make me watch an ad until 2% of my phone's battery is depleted, and then they come to my home and knock on my door at night to sell me beer. ...which... I mean, huh? Stack Overflow is invading your body, restricting your personal liberty, and visiting your home? Really? That's a fucking thing now? reply aspenmayer 2 hours agorootparentI think they were extending the original point you were responding to, and remixing your own mixed metaphor of free beer. In the attention economy, advertising has a cost that is borne by the advertiser and the consumer, up to and including loss of property rights in the case of content relicensure and trespass upon devices leading to excess battery usage, as well as loss of privacy due to geotargeted ads. reply ssl-3 42 minutes agorootparent>I think they were extending the original point you were responding to, and remixing your own mixed metaphor of free beer. Perhaps. But having been to many festival environments, I can definitely imagine a tent offering \"free beer\" that is actually approximately free -- both with, and without a slathering of advertising. (Actually, I don't really have to imagine it -- I've been there and have had that free beer.) I can't imagine them coming to my house and knocking on my door at night to sell me more of it, though. That's absurd. >In the attention economy, advertising has a cost that is borne by the advertiser and the consumer, up to and including loss of property rights in the case of content relicensure and trespass upon devices leading to excess battery usage, as well as loss of privacy due to geotargeted ads. Well, sure. When viewed on a long-enough timeline, it becomes abundantly clear that nothing is actually free, comrade. I can produce my own beer on a hypothetical plot of land that nobody owns, and that nobody else wants to use, and I can give someone one of these beers. For \"free.\" But it still has a cost. (And this, too, is an absurd reduction.) reply aspenmayer 13 minutes agorootparent> I can't imagine them coming to my house and knocking on my door at night to sell me more of it, though. That's absurd. I interpreted that as a tongue-in-cheek hyperbolic metaphor relating to the ways that ad auction networks and other kinds of geofencing and geotargeting allow for deanonymization and reidentification of individuals for conversion tracking and behavioral analysis. That’s the thing about these technologies - they’re dual-use in the sense that those who see the upsides use them generally with good intentions and ideally with affirmative consent. Just like the relicensed content, though, once the data is collected, the original creators, publishers, and third parties may not be able to control where it ends up, which is a negative externality, I think most would agree. aspenmayer 5 hours agorootparentprevUnironically, folks are being triggered by trigger warnings now.[1] Imagine how “free” the beer in your hypothetical scenario is to an alcoholic struggling to stay sober. Capitalism commoditizes even protest against it and repackages it as a product or service. None of this is to assign blame to good faith actors in a so-called free market, nor is it to abdicate responsibility on behalf of so-called free agents. Just a counterpoint. [1] https://pjvogt.substack.com/p/what-do-trigger-warnings-actua... reply random_cynic 7 hours agoparentprevChatGPT provides far more value than StackOverflow currently. It's not just trained on SO answers but all of the manuals/help pages, Github issues and forum posts. In addition you can continue a conversation. No rigid format or gatekeeping like stackoverflow. I don't see a real use case for Stackoverflow now. If I want to ask humans, Discord/IRC channels are far better option. reply xpe 5 hours agorootparent> No rigid format or gatekeeping like stackoverflow. What bothers about gatekeeping? I could guess, but I'm asking so you say it out loud. Then you can compare it against other problems, such as moats (competitive barriers). OpenAI spent something like $3M on training GPT-3. This is a pretty big moat. But almost certainly more valuable in dollar terms is the first-mover advantage which provides millions of human eye-hours used for RLHF. I wouldn't be so eager to trade the gatekeepers you so fear for even an openly available chat service that is happy to automate away as much information work as possible. The Stack Overflow model is (was) pretty darn good -- people help each other out, the company made money, some people got noticed for their skills, products got build faster and better (on the whole, I hope). Contrast the human-generated content era to what we have now which appears to be the machine-ingesting content era. There are legions of lawsuits against companies scraping data without permission and/or attribution. reply random_cynic 45 minutes agorootparent> I wouldn't be so eager to trade the gatekeepers you so fear for even an openly available chat service that is happy to automate away as much information work as possible. Don't flatter yourself. People want to solve their problems so that they can build what they want to. They don't have time for shenanigans from internet jerks who get their validation from imaginary internet points. reply eVeechu7 7 hours agorootparentprevIt can't reliably cite its source for an answer. reply random_cynic 7 hours agorootparentHardly matters for Stackoverflow like questions if the provided solutions work/solve the problem you're having. Which for me happens majority of the time (with GPT-4 not the free version). reply paulryanrogers 7 hours agorootparentIf you copy-paste solutions from SO then please at least cite your sources and their license (CC-BY-SA). reply random_cynic 35 minutes agorootparentNo one should copy paste any solutions from anywhere. FWIW, 99% of the content in SO is hardly \"original\", mostly copy-pasted themselves from previous solutions or original user guide/manuals. reply lannisterstark 5 hours agorootparentprevYou might not want to hear this but no one does this. Should they? probably. But most people don't use Ctrl+C, Ctrl+V in the first place for SO answers. reply muxator 3 hours agorootparentJust a single data point, but when I copy & paste a snippet from Stack Overflow, I always add a comment \"// source: https://stack overflow.com/questions/xxx#yyy\". I both find it respectful of who wrote the answer in the first place and useful for future users of the code: the Stack Overflow answer often provides context and explanation for what would otherwise be an obscure piece of code. Pretty darn useful if you ask me: those who want to have more information can follow the link, casual readers can skip it, and the whole process if fair to the author. reply phatfish 2 hours agorootparentprevId rather not go round in circles while ChatGPT feeds me bullshit information. When this happens i go to Google and read a SO answer with the correct information and also get an informed discussion around the subject. For the easy answers LLMs are fine, but I usually want an answer to a niche issue or edge case, where LLMs have to be constantly told they are plain wrong, before getting to something resembling an answer. reply random_cynic 42 minutes agorootparentYou clearly haven't used any actually powerful model. Maybe do that before making bs points that have no grounding on reality. reply servus45678981 1 hour agorootparentprevNo it doesn‘t. It is overly censored reply popcorncowboy 2 hours agoparentprevYour position lays bare the new and industry-destroying economic problem introduced by opaque-data-source LLMs. The economic value provided by the originator is captured fully and completely behind rentier models. Beware the ease and convenience of all that \"insane value\". This way lies digital serfdom. reply dorkwood 6 hours agoparentprevWhat if someone took your answers, put them in a book, claimed they wrote everything themselves, and then sold the book for money? reply nox101 5 hours agorootparentThen they'd likely get sued because the license for the answers are CC-BY-SA, putting them in a book, claiming they wrote everything themselves, and selling them are all against the license. On the other hand, if they read my answers and they wrote a book about what they learned (not copied). There'd be no issues reply LouisSayers 5 hours agorootparentprevWell if the book was doing well, I might clone it and sell a few copies myself Let's be real, SO is a troubleshooting site. It's not our personal collection of code or project sources. I don't expect to be paid when someone asks me for directions, and I'm sure lonely planet didn't source their guides 100% organically either. reply JimDabell 4 hours agorootparentprevThat would be a very different scenario. Learning isn’t copying, but that is. reply webdood90 5 hours agorootparentprevWhat if I read your answers, claimed I learned everything myself, and sold my skills to a company for money? reply dorkwood 2 hours agorootparentThat would be ok. reply croes 9 hours agoparentprevMaybe a low price for you but not for everybody. reply wrsh07 8 hours agorootparentChatGPT serves 3.5 for free. You can run llama locally for free. Lmsys is free. reply croes 1 hour agorootparentYou think that will stay this way? It will either become paywalled or full of ads. reply fabian2k 12 hours agoprevThe OpenAI partnership doesn't really affect the core issue here around users deleting their content. That has never been welcome on Stack Overflow and when noticed usually was reversed. This is in accordance with the license as far as I understand the legal aspects, and in general it makes sense for me as it ensures that the content stays useful. The content is also CC-BY-SA, which is much better than what you get on essentially every other large site that hosts community content. But the same license also means that you cannot remove that content again, even if Stack Overflow would allow that anyone else can scrape it or download it before it is deleted and reproduce it according to the license. Users still can remove their name from their posts, and if they write personal details those can be redacted as well. But you can't remove good quality content from the sites later, that is likely to be reverted. reply Hizonner 11 hours agoparentThe problem isn't that Stack Overflow is allowing people to scrape the content. The problem is that Stack Overflow is preventing some people from scraping the content, in order to collect money from others. And, incidentally, passing zero of that money on to the people who actually created the content. (Nearly) none of the people who are presently pissed off would have complained if Stack Overflow had continued to allow all comers to scrape the content and train LLMs on it, nor if Stack Overflow had released the entire finished collection of content under the same CC-BY-SA license that was demanded of each contributor. With the OpenAI partnership, and similar shenanigans leading up to it, Stack Overflow is relying on obscure technicalities to violate the essential spirit of the original deal. reply webstrand 6 hours agorootparentIsn't the data publicly available? https://archive.org/details/stackexchange reply hedora 9 hours agorootparentprevGiven the CC license, and the fact that contributors can apparently code, they should scrape the content and be done. Of course, that’d mean bypassing the scraper blocker. This article is a decent starting point: https://stackoverflow.com/questions/66413511/how-to-avoid-be... reply lamontcg 7 hours agorootparentprev> And, incidentally, passing zero of that money on to the people who actually created the content. I mean that is basically SO's entire business model. People do tons of work for free and SO runs the service and monetizes it. reply theendisney 11 hours agorootparentprevI dont get how you can release something under anything other than all rights reserved without identification. We need to be able to persecute you in case you are not the author. Or is it that i may republish anything under any license?? It could be that the platform licences it in the toss but with cc are they not obligated to make it available without obstructie? reply Repulsion9513 3 hours agorootparentProsecution and persecution are two different things. Persecuting anyone is not a good time :) Why, if you're not allowed to release under a license, should you be able to release all rights reserved (which can still be a copyright violation!)? If you need to prosecute the person, there are established procedures for that: DMCA, or ultimately a lawsuit over the infringement. That you didn't identify yourself publicly on the site does not make that impossible. In fact the point of the DMCA was to make it easier to handle this - because if the provider doesn't comply with your DMCA, you can sue the provider. reply shkkmo 7 hours agorootparentprevRequiring indentification to publish so that copyright is protected would be massive overreach and this sort of thinking is why I think copyright is a dangerous concept that needs to be sharply curtailed, not expanded to cover AI training. In practice, the safest course is to not use content from untrustworthy sources in ways that require a license (aka in ways that are not fair use in your applicable jurisdictions). reply theendisney 6 hours agorootparentI think by default you just cant use things? Who thought that was a great idea i dont know. We must be missing an enourmous chunk of progress. Every juristiction its own idea of fair use? Thats just hilarious? I never really thought about peoples privacy either but at first glance you seem to be right. Do you have any solution to the puzzle? People are quite attached to the concept and many build their house on this soil. Appeal to tradition? reply Brian_K_White 54 minutes agoparentprevStackOverflow are violating the SA part of CC-BY-SA by selling special access to the CC-BY-SA content to one party and blocking others from the same thing. OpenAI are violating both BY and SA but that's a seperate issue. Everyone who contributed work, did so under terms that the work was free for all, not a resource that one party can sell to another party who then sells to end users. Those end users were meant to have it directly without having to pay openai or anyone else, and if any bulk/scraping access is allowed for anyone like openai, everyone else has the right to the same thing for no more than a \"shipping & handling\" charge to cover the network & employee cost to physically deliver the data. What are StackOverflow selling, and/or what exactly are OpenAI paying for? What is the goods or services that is traded for the money? There are many possible answers but I see no answer that doesn't ultimately one way or another wind up resolving into a violation of one or more terms of CC-BY-SA by both StackOverflow and OpenAI. reply keefle 5 hours agoprevSide related question: are there content licenses coming up that are similar in spirit to what the GPL is but targeted at AI training? (E.g. if this piece of content was used in training an AI that was to be used commercially, the AI's weights must be published) reply progval 3 hours agoparentThe argument AI companies make is that LLMs are not derived works of their input, or is fair use. So according to them, the input's license does not matter. reply postepowanieadm 3 hours agorootparentDo you have any sources about that, I'm just curious:) reply imadj 2 hours agorootparenthttps://news.ycombinator.com/item?id=37780199 reply pornel 11 hours agoprevStackOverflow has always been quite open that they're primarily building a dataset for SEO, rather than being a user-centered website. So I don't feel this deal changed much. SO users are still serfs building them a dataset for sale, only the buyer has changed. LLMs are faster and infinitely more patient than interaction with StackOverflow, so I don't expect SO to survive for long. They're in crisis regardless whether they sell to OpenAI or not, so they may as well get something out of it before they're decimated. reply theteapot 8 hours agoparentI think they're in crisis because they sold out there community not because LLMs are better. As a developer, if you offer me StackOverflow vs ChatGPT, I'd take StackOverflow any day of the week 100x over. reply BeetleB 7 hours agorootparentI'm in the opposite boat. Going through Stackoverflow answers has become quite a chore. For simple things GPT gives me the correct answer most of the time. And even when it's won't it's quicker to discern it is wrong than trying to parse a given SO page. Of course I still use SO for more complex questions. As a rule, if I can quickly find the answer via SO, then chances are GPT will give me the answer more rapidly. reply Kiro 2 hours agorootparentprevAnd I'd take ChatGPT any day of the week 1000x over. That doesn't mean anything. reply Jimmc414 8 hours agorootparentprevRespectfully, how would you know if you never use ChatGPT? reply theteapot 8 hours agorootparentI said I don't use it. I didn't say I've never used it. In my experience browsing SO is way easier, more accurate, more precise, more controllable, navigable, and ... gives attribution. reply lannisterstark 5 hours agorootparentFor some reason , but a lot of of the answers here seem to care more about \"but tell em /I/ solved it\" re: attribution rather than helping the user. Somewhat egoist or some such? ( and I don't mean it as an aggressive tone, just ESL so don't know how to say it othrewise) If I license something as MIT, I personally don't care who uses it for what purpose, hell I don't even care generally that they attribute me. I put it out for people to use. But maybe that's just me. reply fragmede 7 hours agorootparentprevyou spend more time on SO than me. without looking, can you name three stack overflow contributors? I can't. reply selcuka 6 hours agorootparentI was offered a job a few years ago by someone who saw my Stack Overflow answers, does that count? I don't see something like this happening with ChatGPT. reply phatfish 2 hours agorootparentprevI can do two, Jon Skeet (C#) and S. Lott (Python) are names I remember for providing great answers. reply theteapot 7 hours agorootparentprevYes. reply lannisterstark 5 hours agorootparentprev>As a developer, if you offer me StackOverflow vs ChatGPT, I'd take StackOverflow any day of the week 100x over. Really? Hm, I wouldn't. I can use nuance and clarify my answers and have a respectable back and forth (GPT-4 doesn't call me names when I mess up or say something dumb) and arrive at an answer. reply JimDabell 4 hours agorootparent> GPT-4 doesn't call me names when I mess up or say something dumb I’ve heard this accusation a lot, but I don’t think I’ve ever seen it happen. People call you names on Stack Overflow? Where? reply lannisterstark 2 hours agorootparent>Where? -50 Marking duplicate. \"You should attempt searching before asking such obvious questions.\" This question has already been answered here:Closed 3 seconds ago. ---- or some such ;) You may not come across it personally, but that doesn't mean it doesn't happen. SO is successful as a QA platform(or was anyway) despite this shortcoming, not because it is a feature and it doesn't happen. If a lot of people are talking about the same thing, maybe people should at least pay cursory attention to the issue rather than \"No, it doesn't happen\" (Not aimed at you, but there are absolutely comments like this every time this gets bought up.) reply JimDabell 1 hour agorootparentYou linked to a discussion of about a hundred comments. I skimmed it but didn’t see name calling. Can you be more specific? reply fragmede 5 hours agorootparentprevAre you sure that's not an X vs Y problem??? reply lannisterstark 5 hours agorootparentI actually have no idea what you mean. can you clarify pls? reply fragmede 4 hours agorootparentIt's a common non-answer on stack overflow. https://meta.stackexchange.com/questions/66377/what-is-the-x... reply lannisterstark 4 hours agorootparentlol that makes sense, thanks. reply progval 3 hours agoparentprev> StackOverflow has always been quite open that they're primarily building a dataset for SEO Do you have a source / more details about this? What good is SO's content for SEO? reply nox101 6 hours agoparentprev> SO users are still serfs building them a dataset for sale That is a very negative spin. Users get access to other people's answers for free. They get that free service and are required to contribute nothing. Those that do contribute do it to help other users. S.O. isn't doing anything bad. They're providing a free service where everyone wins. Users get answers. Answerers get to help other humans at scale. S.O. makes a little money. As for the dataset, it's been available under CC-BY-SA for years. The entire database is backed up and made available here for free every month. https://archive.org/details/stackexchange There are even free tools to query it here https://data.stackexchange.com/ reply HappyPanacea 11 hours agoprevI suspect they will fail to emphasize the ShareAlike property of CC BY-SA 2.5/3.0/4.0 which is incredibly strong - \"ShareAlike — If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original\". This is an incredibly wide and vague definition, especially \"build upon\" which will be unattractive to many users. reply nox101 5 hours agoparentI suspect, if ChatGPT quotes an answer or a snippet it will show attribution and a license for snippet. If it instead only uses the knowledge it gained from the answer/snippet and writes it's own answer, then, just like a human, it won't attribute reply rodgerd 8 hours agoparentprevnext [2 more] [flagged] paulryanrogers 7 hours agorootparentIt was especially hilarious to watch the CTO of OpenAI get asked if they scrape YouTube, and could not say yes or no [0]. Possibly one of the most important sites in the Internet, and they're CTO claims ignorance. [0] https://www.reddit.com/r/ChatGPT/comments/1bfa7s3/openai_cto... reply extheat 11 hours agoprevI am thankful we have LLMs so we don't have to deal with SO. Ideally, as little as possible. SO can be a pretty toxic place filled with elitism and care for procedure over actually helping people, which is not totally unreasonable from their standpoint but it's definitely not what people are visiting the site for. Quite ironically, one of the major complaints I get is that LLMs output wrong answers here and there, ignoring that many of the answers on SO are also completely wrong or irrelevant to the core question being asked. And mind you, also outdated (I regularly have to click through the sorting to make sure answers are actually still relevant). If we could merge the two to get the best of both worlds, and have LLMs that know how to write well and are validated by humans on the site, that would be great. Maybe not great for the folks looking to accrue internet points but absolutely great for users. reply tyingq 11 hours agoparentThat's great for now. It's not clear to me, though, where LLM's will get their training data from here forward without ingesting lots of LLM generated code and answers and eating it's own tail. reply BenFranklin100 6 hours agorootparentDidn’t you get the memo? LLM’s either already are capable of or just a step away from being able to reason so no need for human generated training data in the future. Or at least that’s what 3/4 of HN commentators believe and all AI CEOs want you to believe. reply cle 9 hours agorootparentprevOpenAI and Microsoft get TONS of user-written code w/ quality feedback, OpenAI through ChatGPT and Microsoft through VS Code and Copilot. reply prng2021 7 hours agorootparentThat's only now and in the near term future. If AI is actually successful, every year the amount of human written code will decrease. That's the whole point of this. reply kevin_thibedeau 6 hours agorootparentprevThey'll get it from human generated archives from before the singularity. reply IAmNotACellist 6 hours agoparentprev>I am thankful we have LLMs so we don't have to deal with SO. Ideally, as little as possible. SO can be a pretty toxic place filled with elitism and care for procedure over actually helping people There needs to be a term for this. Perhaps \"The Wikipedia Effect.\" reply LordShredda 6 hours agoparentprevDoes it matter if stack overflow is toxic or not? You're there to ask a question and get an answer. If you ask wrong, you get corrected. Tough moderation makes search much faster and better for other askers. You're there to ask for help not make friends. They have to be polite, but not gentle reply lannisterstark 5 hours agorootparentYes it does. If I am belittled instead of people asking clarifying questions so I can learn, I'm much less likely to think better of said people or platform, or use it. reply jimjimjim 10 hours agoparentprevWhat you see as elitism is mostly simple curating. You can't store everything because it makes retrieving value from the store that much more difficult. It's the same with wikipedia and other public content repositories. People cry elitism and gatekeeping but without curation you eventually end up with a haystack of mediocre looking for a needle. reply _gabe_ 5 hours agorootparentThis “curation” is what is killing SO. Software is soft. It changes. There is no “one true answer for all time”. It’s honestly sad how many times I search for an answer, only to see the exact question I’m looking for closed as duplicate, then when I look at the “duplicate” I see that it’s an out of date answer. Stack Overflow could have solved the problem of duplication so many ways. Why not categorize and bucket duplicate answers? They could have even had yearly recurring questions with the most up to date answer! Why not add beginner/hobby/expert rankings to questions so that the people answering don’t get sick of seeing beginner questions all the time? There is so much SO could have done, instead they rested on their laurels and now they’re left with an out of date repository. What use is a curated repository if it will only help me solve problems with solutions from a decade ago? reply phatfish 2 hours agorootparentWho says the solutions from a decade ago are not still correct or the best way to solve a problem? Just because ChatGPT regurgitates something today with the words moved around doesn't mean it contains \"new\" insights. reply fzeroracer 3 hours agorootparentprevIt sounds like what you want is Quora. You can go ahead and use Quora for all of your software question needs. reply Repulsion9513 3 hours agorootparentprevI actually strongly prefer Wikipedia to SO, on Wikipedia the old now-wrong content can just get edited out, on SO you'll have to dig through all the 300-point popular answers from 2012 to find the new answer that says \"yeah none of that is right anymore, instead do this\" SO is far from curated, I guess is my point reply dleeftink 8 hours agorootparentprevI agree in part, but why aren't other moderated outlets where users can ask technical questions given the same label? Reddit, Quora and HN are also curated, are content removals on these site taken as elitist? Even if these places are less heavily moderated, I have no trouble surfacing relevant answers using any search engine's in-site search. I am not talking about QA quality on any of these sites here, but the elitist stigma that has seemingly followed SO for so long. [0]: https://meta.stackoverflow.com/questions/262446/are-we-being... reply squigz 7 hours agorootparent> why aren't other moderated outlets where users can ask technical questions given the same label The exact label aside for a moment, reddit and HN mods often face backlash for their actions. But beyond that, Wikipedia and SO stand out in this regard because of their transparency regarding the curation. Mostly, reddit curation happens in the background, without much explanation. SO and Wikipedia basically spell out their actions and reasoning. Another difference is that with reddit and HN, you have no real recourse. At least with Wikipedia (I'm not too familiar with SO policies in this regard) you can appeal decisions, open discussions about policies, etc. I have to agree with GP - people often mistake the 'bureaucracy' of sites like Wikipedia and SO as something unnecessary that the editors force on everyone, but the fact is, it's necessary to create and maintain a high-quality repository of information. reply dleeftink 7 hours agorootparent> SO and Wikipedia basically spell out their actions and reasoning You're able to appeal on SO as well. It's interesting to think about a situation where moderation decisions would be more in 'the background', as you say (like Reddit/HN), and whether this takes away from the perceived 'elitism' some moderation practices are accused of. reply squigz 6 hours agorootparentIn my experience on the above sites, and as a (small) community manager, it absolutely plays into it. A lot of people just instinctively respond negatively to displays of authority. On the other hand, I think it's an important aspect of a community/platform if the goal of that platform is to be transparent and open, which I think is an important aspect of SO and Wikipedia, and I hope more platforms would adopt that view. I think whatever \"elitist\" perception such platforms have to suffer is well worth having high-quality, open platforms. (I will say that no platforms are perfect of course, including SO or Wikipedia; there's plenty of criticisms to go around about specific policies and decisions. See: TFA :P) reply Shog9 5 hours agorootparentThis is an insightful observation, and a problem we struggled with for years on Stack Overflow: if you keep moderation quiet and anonymous, there's a lot less criticism, seemingly less hurt feelings... But also very little correction. The Star Chamber works great until corruption sets in; finding a good balance between secrecy and transparency is a challenge. For years, moderators signed their names to messages like the one cited in the article. After one too many cases of a volunteer being called at work or having their family harassed or sent a suspicious package in the mail... That particular bit of transparency was eliminated - the cost was too high for the limited benefit. OTOH, it used to be very difficult to find your own deleted posts but that has slowly gotten better (including visibility into who deleted them) - turns out the benefit there was substantial (identifying wrongly-deleted posts & curbing over-enthusiastic curators), while harassment has been mostly limited to occasional grousing. reply struant 7 hours agorootparentprevTheir curation blows. The whole premise of having a canonical answer to a question is dumb. Most programming languages and libraries are always in flux. The whole nature of many questions changes over time. StackOverflow is a tyranny of mediocrity. It is a bunch middling programmers shitting on newbies, and driving away experts because you get severely punished for not being mediocre. I had a question closed as a duplicate for being too similar to another question that I directly cited in my question as being sublty different and not applicable. (Because I anticipated some idiot closing my question...and they went and did it anyway) reply Ukv 12 hours agoprevFrom a search, the message seems to have been in place since at least 2017[0] and I'd suspect is automated on detection of mass-deletion. I can understand the reason for the policy (in some ways SO functions more like a wiki than a forum) and it doesn't seem to have been introduced to quell the protest against OpenAI. [0]: https://meta.stackexchange.com/a/296822/287788 reply arp242 11 hours agoprevdupe: StackOverflow is banning accounts that delete answers in protest against OpenAI - https://news.ycombinator.com/item?id=40297027 - May 2024 (103 comments) reply witoong623 3 hours agoprevThank to people who delete their answers, now I have to pay OpenAI to find answers they already scraped. Talking about helping OpenAI making more money :( reply sva_ 10 hours agoprevIt sounds like the measure of preventing users from deleting/editing their posts contradicts EU laws? reply zarzavat 4 hours agoparentOnly if they are putting their own personal information in their answers, which I assume they are not. reply blibble 12 hours agoprevthere are several nice libraries that allow you to generate plausible sounding gibberish this one is particularly nice and easy to use: https://github.com/jsvine/markovify/ you give it a file of existing text and it generates complete rubbish that would pass most automatic filters reply ceejayoz 12 hours agoparentThese are far more likely to come to moderator attention by user flags on the edited posts. reply blibble 12 hours agorootparentfor the AI to be useful it has to be continuously updated with new good data so add small bits of rubbish slowly over time, and don't even contribute again it'll take a while to completely destroy the AI business model, but we'll get there reply dylan604 11 hours agorootparent> but we'll get there at some point, it'll be too late. the horse has already left the barn. besides, if the site owner makes a deal with the devil, there's nothing you can do other than quit using the site. people are still using social platforms more than ever, so stopping isn't going to happen. the more likely to happen is that accounts deemed to be polluting the waters will just get suspended with no recourse to have it re-instated. reply blibble 10 hours agorootparent> at some point, it'll be too late. the horse has already left the barn. I don't think this is true: the technology is useless unless it parasitises new knowledge continuously it sows the seeds of its own destruction by reducing the value of past and future contributions to zero > the more likely to happen is that accounts deemed to be polluting the waters will just get suspended with no recourse to have it re-instated. so this is also perfectly acceptable: once they've banned the top 20% the site effectively becomes read-only, and the AI knowledge previously parasitised from it atrophies with no replacement reply dylan604 8 hours agorootparentKnown knowledge doesn't disappear. Once it knows how to apply an FFT and when, it doesn't need to continue to read about it. It's not a human needing continuing education. Once it knows that Henry VIII had many wives, it doesn't need to keep reading that he had those wives. Sure, if something new happens, then it's not like SO is the only place it's scraping for new information. If you honestly think that you/we will get to a place to block all scraping, I will just politely disagree. reply fzeroracer 8 hours agorootparent> Once it knows that Henry VIII had many wives, it doesn't need to keep reading that he had those wives. That's actually incorrect, it needs to constantly ingest new data. If it ingests enough data (from other LLMs that are hallucinating, for example), then suddenly when it has enough bad data it'll start telling you that Henry VIII was a famous video game on the Sony 64. It has no concept of 'truthfulness' beyond the amount of data that it can draw correlations from. And by nature LLMs have to ingest as much data as possible in order to draw accurate results from new things. LLMs cannot function without parasitizing off of user generated content, and if user generated content vanishes then it collapses in on itself. reply williamcotton 7 hours agorootparentSo fill the entire internet with factually incorrect, useless knowledge? This would be a good thing? reply dylan604 7 hours agorootparentScorched earth policies are always en vogue, and easy to offer as a knee jerk reaction. They do nothing for actually making forward progress in the conversation though.* *However...there are times where the best solution is a match and some gasoline. reply fzeroracer 6 hours agorootparentprevWell, that's already happening. Google search has become increasingly useless thanks to SEO-focused AI-generated schlock. It's the inevitable outcome of LLMs. Sites have an incentive to hide that they're AI generated and LLMs have no real way to filter for ingested data made from other LLMs. The only difference is how long the ruse can be kept up. reply williamcotton 6 hours agorootparentSo you want to pollute the commons just as the people filling the web with SEO-focused AI-generated schlock? Do you feel justified in polluting the commons to serve the ends you desire? reply fzeroracer 4 hours agorootparentDo you actually have a solution to the problem of companies using LLMs to steal from other people and repurposing it as their own, other than figuring out ways to ensure that LLMs suffer for doing so? And frankly as I mentioned, LLMs are already polluting the commons; you're not offering any solution on that front either other than asking people to keep supplying it with fresh data so that it doesn't poison itself. reply williamcotton 9 hours agorootparentprevWhat's your stance on a future open source model that is as capable as any commercial models? Also, I'm curious, do you consider LLMs to be incredibly error prone and untrustworthy? Or do you think they are going to replace software developers? reply ProjectArcturis 11 hours agoprevIs there anyone who makes stackoverflow their first stop for programming questions anymore? reply int_19h 11 hours agoparentGoogle ranks it pretty high, so it is the de facto first stop for many. reply ProjectArcturis 10 hours agorootparentAh. I've found various LLMs are much easier to query and generally nicer than SO posters, so it's been quite a while since I've needed to visit SO. I assumed most people had made a similar journey. reply jazzyjackson 8 hours agorootparentur in a bubble, harry reply yesiamyourdad 8 hours agorootparentprevNot so much anymore though. I've seen over the last year that SO ranks lower and content farms like geeks4geeks, Programiz, etc. are getting much higher in results. reply notatoad 9 hours agoparentprevi still google things, mostly out of habit. but i'd say half the time i visit stack overflow, the answer i get there is either outdated or too opinionated to be useful and i end up going to chatGPT. reply greenyoda 12 hours agoprevEarlier discussion: https://news.ycombinator.com/item?id=40297027 reply highwayman47 7 hours agoprevWhy? They don’t want the knowledge to be more accessible to the masses all of the sudden? Also, all those answers are backed up somewhere. reply paulryanrogers 7 hours agoparentPerhaps they don't want their answers to be systematically leveraged to put them out of work. Though considering the site terms and CC license, I don't think deleting will actually help much. reply m463 2 hours agoprevWhat I don't understand is in CC-BY-SA, SA means share alike. Does openai have to share their models? reply Karellen 10 hours agoprev> Users are also asking why ChatGPT could not simply share the source of the answers it will dispense in this new partnership, both citing its sources and adding credibility to the tool. Of course, this would reveal how the sausage of LLMs is made What? Surely the answer to that question is that ChatGPT doesn't know where the source of its answers is, isn't it? Isn't the question itself based on a fundamental misunderstanding of how LLMs work? reply jarsin 8 hours agoparentI haven't used it extensively but when i ask a generic coding question in brave it gives me an ai response and it does list source websites. Not sure if it's the actual source or its just pulling them from a search or what. reply bschmidt1 7 hours agorootparentCould always perform a normal web search with the LLM result and show matches reply eli 12 hours agoprevThis seems like a really bad way to handle what should have been a foreseeable problem reply jaimehrubiks 12 hours agoprevIt's sad :( I preferred the old days better reply atleastoptimal 12 hours agoprevThe problem is whether people see programming as a zero-sum or positive sum enterprise. In the real world, it acts as a positive sum enterprise: one person's contribution benefits themselves and all those who use or learn from the code. However many gatekeeping-type people view it, perhaps instinctively, as zero-sum. They imagine that OpenAI benefitting from this partnership, or any amount of learning via web-scraping their models perform, necessarily harms those who put their content online. This in a nonsensical argument yet has garnered a fair amount of support due to the somewhat reflexive anti-AI sentiment as of late, which is separated from the more nuanced concerns of existential threats due to AI. reply zb3 11 hours agoparentPositive-sum rarely exists in this world.. after all, one's wealth determines their influence over others. Both sides might gain but this usually means others lose. In this case, contributors might lose attribution. SO might lose traffic but they'll be compensated. Contributors won't so eventually there might be no reason to contribute anymore.. reply __MatrixMan__ 4 hours agorootparentIsn't the existence of wealth in the first place sufficient evidence that wealth is something that gets created? We started out banging rocks together and now we have all of this weird stuff which presumably people like or something. reply zb3 2 hours agorootparentNow we work harder, and it's getting unbearable for those kn the bottom... Wealth also affects whether you're \"useful\" and you need to be \"useful\" to survive.. It's getting harder to be useful reply jonathankoren 11 hours agorootparentprevIt’s simply false that positive sum doesn’t exist the real world. Even the most simplistic trade argument in remedial Econ 101, or even Bio 101 reveals this. What’s rare are zero-sum games. reply zb3 11 hours agorootparentRising inequality suggests otherwise reply kolinko 5 hours agorootparentIf I'm not mistaken, the whole society is getting wealthier, it's just some people are getting wealthier faster than the others - so it's still a sum-positive. Here are the source charts: https://ourworldindata.org/happiness-and-income-inequality reply zb3 2 hours agorootparentYou only consider those that \"make it\", there any many who don't because it's getting increasingly harder to be \"useful\" in the market (ChatGPT is cheaper), innovations usually make it worse. Those \"new jobs\" are harder and many won't qualify reply SpaghettiX 10 hours agoprevI still use StackOverflow. Not as much as I used too, thanks to GPT, but still multiple times a day. What I find is that I spend less time on SO. However, IMHO deleting questions you originally wrote in the past is hurting other users more than it is hurting AI training. Other users cannot write similar answers to yours, because it doesn't add anything and they'd get downvoted or deleted. So if you hadn't written your answer years ago, others could've written something similar. Also, other users may have commented on your questions/answers. Their efforts would be lost/deleted if you deleted your questions/answers. Thanks for your previous contribution to the community. But I would say the worst you should be able to do is remove your name/anonymise your posts, not just delete them. reply Ekaros 2 hours agoparentI wonder would actually deleting questions be a good thing. If there is no old question the same question asked again can not possibly be a duplicate... So constant loop of deleting questions might actually be effective way to fix some problems. And there is enough off-site backups already. reply jncfhnb 9 hours agoparentprevMultiple times a day sounds like a massive amount to me…? reply __MatrixMan__ 4 hours agorootparentLooking through my browser history, I'd say that I average about 5 distinct SO posts per day. If you know there will be an answer it's less typing to search for it than it is to have ChatGPT regenerate it. reply ChrisArchitect 11 hours agoprev[dupe] More discussion: https://news.ycombinator.com/item?id=40297027 reply astrodust 11 hours agoprevIt is nearly impossible to delete an accepted answer you don't want to have any more. I've had several which are wildly out of date and incorrect now and I don't want to update them, but the mods refuse to remove them. reply jazzyjackson 10 hours agoparentcan't you just comment on the post informing people who land there that its out of date? id prefer that over following a cached link and hitting a 404 reply leumon 10 hours agoparentprevYou can request to dissociate them from your account. (better then nothing) reply firecall 10 hours agoprevI'm surprised OpenAI hasnt just crawled all of SO already? reply caesil 10 hours agoprev>Ben continues in his thread, \"[The moderator crackdown is] just a reminder that anything you post on any of these platforms can and will be used for profit. It's just a matter of time until all your messages on Discord, Twitter etc. are scraped, fed into a model and sold back to you.\" Uh.... yeah, it's a company, not a charity. No one's forcing you to post on StackOverflow. No one's forcing you to buy a ChatGPT subscription. reply Barrin92 10 hours agoparent>Uh.... yeah, it's a company, not a charity. While this is true sites like Stackoverflow very much only function because they create the illusion that it is in fact a \"community\". The moment they make explicit that there is monetary value in the knowledge people post on the site it becomes obvious that the users are, using Varoufakis term, technoserfs. You're very much never supposed to notice that Reddit, SO, and so on continously extract value out of work you produce, at worst you're maybe supposed to notice an ad or two. Because if you do notice that you might actually start asking why you aren't getting paid. Which is btw funnily enough exactly what news organizations and SO have realized vis-a-vis openAI. reply readyman 10 hours agoparentprevGiven the lack of an alternative, should we instruct the human instinct of sharing in the pursuit of knowledge to sacrifice itself or accept the risk of exploitation? If your sorry platitude is what we have to show for it, capitalism must go to Hell. reply wordofx 9 hours agorootparent> Given the lack of an alternative There are plenty of alternatives to everything. But no one uses them. Because why would they? reply j45 12 hours agoprevAs an early user of SO, I certainly don't want my answers sold for profit again and again. reply kragen 12 hours agoparentthe so license is cc-by-sa and has been since the beginning, not cc-by-nc-sa reply j45 10 hours agorootparentTrue. Cc-by-sa has had a few revisions. Attribution would be lost in an llm, no? reply jonathankoren 12 hours agoparentprevYour answers are already sold for profit again and again. That's the whole point of SO existing, or maybe you under some delusion that SO is a charity? reply j45 10 hours agorootparentNo delusion. Specific licensing and side deals is different to me at least than scraping. reply vkou 12 hours agoparentprevThen you shouldn't have been posting on SO. If you want to contribute to the commons, contribute to the commons. If you want to contribute to the commons without commercialization of your work, contribute with some non-com license [1]. If you want to feed a corporation with your labour, post on SO. [1] It'll still be illegally scraped and commercialized by some AIBro, and you'll have no proof or recourse against them... reply j45 10 hours agorootparentScraping to me is different than side licensing the content in some other form or usage than what it was created for. Licensing also means the writer retains the ownership. Cc-by-sa has had a few revisions too. reply yesiamyourdad 8 hours agoprevI have very few SO contributions so I don't have much at stake personally, but I have observed that there was a trend of people using their SO profiles for career advancement. I'd see people reference their SO activity on resumes and I had job applications ask for my SO profile if I had one, and I've seen advice that a good SO profile was valuable the way a good Github profile is. Is that something people factor in to their decision to delete? And isn't that social capital a kind of compensation for their contributions? reply jarsin 8 hours agoprevDoes anyone know if chatGPT etc could code without stackoverlow answers? I think that is the big question, because the license seems it's going to give lawyers a very wide attack surface to go after every ai coder out there if they all need SO database. reply tintor 8 hours agoparentThere is plenty of code and bug trackers on the web for ChatGPT to learn from: OSS, Github, Sourceforge, ... reply Beldin 4 hours agoprevHmmms. While I definitely can see SO's arguments concerning deletion, that letter seems to blatantly contradict GDPR's right to be forgotten, which Wikipedia describes as a more limited \"right to data erasure\" [1]. To coin a Dutch phrase: I cannot make chocolate out of that. Anyone here have an idea how to bring these two points together? Other than the obvious \"wrt. EU inhabitants, SO is lying\", that is. Or is it really that simple? [1] https://en.m.wikipedia.org/wiki/Right_to_be_forgotten - under \"European Union\" reply Bobo-hilife 12 hours agoprevResistance is futile! reply casenmgreen 11 hours agoprevI left some time ago, and I'm very glad I did. I left because the staff behaved in a disingenuous manner. I found when leaving, as mentioned in the article, that you are not allowed to delete accepted posts, so you can't delete your content, should you come to think SO objectionable and wish your content not to be there. I can't see now why anyone would spend time posting answers there. reply zerocrates 11 hours agoparentI don't love them getting into bed with AI, but also don't think it's unreasonable for them to not allow angry users to blank out their prior submissions. The whole deal was that you basically donated your posts and CC-licensed them. I wouldn't begrudge Wikipedia from similarly dealing with upset editors who went around blanking the articles they contributed to or reverting all their changes. reply Retric 11 hours agorootparentWikipedia editors aren’t the sole source of their pages. I am fine with people leaving and deleting their posts because they may feel the information will become outdated without being maintained. SO unfortunately is actively hostile to correcting outdated information. Which is somewhat understandable as recognizing how little long term value answers provide undermines their moat. The site has basically become worthless for JavaScript due to such rot which helps explain why they are trying to cash out on the AI side of things. reply arp242 10 hours agorootparentMany answers have been edited, commented on, and reviewed by others. So it's also not exactly a one-person show either. Outdated info is a problem, but not so easy to solve; I have answers from Ruby on Rails 4 era that are still perfectly valid today. Others may not be. Also remember that people sometimes stay on old versions for a long time. I don't know what the best solution is, but destroying information is not it. reply Retric 10 hours agorootparentFew answers get any sort of editing or updating over time. If you’re worried about deleting information the obvious solution is to automatically hide the text when the poster says it’s outdated. At which point there’s little wrong with letting someone flag all their posts as likely outdated upon leaving. But this is where the business of SO comes into conflict with providing useful information on SO. reply firecall 10 hours agoparentprevYou cant delete your posts on here either! Which I dont like :-) I'm with you, I think you should be able to delete your own posts and erase your internet history. I dont think that everything we ever write on the internet should be stored forever because of some misguided intention to preserve conversations for future generations :) reply alex_lav 10 hours agoparentprevfwiw HN does not delete your content when you get rid of your account. reply whartung 10 hours agorootparentI’m sure this is related to the fact that the editing window closes here after a short time. I’ve been on other forums where disgruntled users have come through and destroyed old posts, which resulted not just in the loss of the messages but also harms the thread that built upon the now vanished post. So they, too, have a short editing window policy instituted. reply alex_lav 8 hours agorootparentYes I'm sure companies can think up a whole array of excuses as to why they won't delete your data :) reply FireBeyond 11 hours agoprevThis article is extremely biased towards SO: > Stack Overflow and OpenAI have joined forces through a new API partnership. This collaboration aims to provide developers with a powerful combination of Stack Overflow’s vast knowledge platform and OpenAI’s advanced AI models. Through the OverflowAPI access, OpenAI users will benefit from accurate and verified data from Stack Overflow, facilitating quicker problem-solving and enabling technologists to focus on priority tasks. Additionally, OpenAI will integrate validated technical knowledge from Stack Overflow into ChatGPT, enhancing users’ access to reliable information and code. Come on. Was this taken from a Press Release? > it can be disruptive to the entire community to delete or remove content that might be useful to someone else. Even if this content is no longer useful to you as the author. [sic] > As for the rest of us Stack Overflow users, I would not recommend jumping to delete your own content in protest too. > To be fair to Stack Overflow, the warning email and suspending of accounts is likely not a new thing. I can't find a negative word about SO in this entire article, so \"to be fair\" doesn't seem meaningful. reply nicklecompte 8 hours agoparentIf you check the byline, the author is a Microsoft MVP / product evangelist. So I don't think he's biased towards SO so much as he is biased towards anyone doing business with Microsoft (or OpenAI). He also seems very pro-GitHub Copilot. reply bdjsiqoocwk 10 hours agoprevNo empathy for users to spend their time contributing to a corporate walled garden and who to top it off get emotionally invested in it. reply a2128 5 hours agoprevI find it deeply troubling that platforms are becoming so hostile that users are having to strike against the owners by mass deleting their content. And then the platforms handle this by simply undeleting the content and banning them from continuing to delete any more (StackOverflow, Reddit) This may also be legally dubious in Europe as, while the authors may have granted copy rights to the platform owners, they still maintain their moral rights which may apply in this case (IANAL) reply iamkonstantin 3 hours agoparentI just submitted a request to have all my content removed from SO and will challenge the outcome if needed. My right to be forgotten and have my content deleted supersedes SO’s dubious, “nobody really reads these” terms and conditions. reply popcorncowboy 2 hours agorootparentGreat idea. Have done the same. reply SrslyJosh 12 hours agoprevCongrats to OpenAI (and the rest of the LLM bros) for creating negative incentives for sharing knowledge. reply lukan 12 hours agoparentI do not understand, how are they \"creating negative incentives for sharing knowledge\"? If I posted on SO before in the hope that others find it useful (and not for the karma) - and now it might help others not directly through the site, but with further steps through a llm, where is the problem? Knowledge was shared. reply AdamH12113 5 hours agorootparentPart of the benefit for the answerer is the experience of interacting with the questioner, receiving upvotes and comments, having answers accepted, and having your name on an answer that's helped people. You get credit for answering questions on Stack Exchange sites. It's not much -- it's not supposed to be -- it's rarely of material consequence -- but it matters. I still get upvotes on some of my old EE.SE answers when my written work helps someone enough for them to give notice. It's a little reminder that I've done something useful in my life. Having my work ingested into ChatGPT takes the me out of it. It turns me into, essentially, unpaid contract labor for OpenAI. They get all the credit, and I get forgotten. Why would I be okay with that? If you want to write free code for OpenAI to improve ChatGPT, you're welcome to do so. Cut out the middlemen and send it to them directly. But please leave me and my work out of it. reply lukan 4 hours agorootparent\"Having my work ingested into ChatGPT takes the me out of it. It turns me into, essentially, unpaid contract labor for OpenAI. They get all the credit, and I get forgotten. Why would I be okay with that?\" So you are ok with unpaid contract labor in exchange for virtual points. But if you don't get virtual points as appreciation, no one should benefit. That is ok, but then sharing knowledge is not your main, but secondary goal. Your main goal is the recognition. But if you delete your comments, you won't get anything at all anymore. If they remain, real humans will still benefit directly or indirectly. And why should I write exclusicly for openAI? I share my knowledge for anyone. If SO would restrict public access and favour OpenAI - that would be the moment I would want to delete everything. But at the moment LLMs just get also official access, but they had access to SO before, just in a grey legal area. So nothing really changes. reply smcin 14 minutes agorootparent> But if you don't get virtual points as appreciation [unpaid contract labor]... then sharing knowledge is not your main, but secondary goal. Your main goal is the recognition. It's false dichotomy to parse out components of motivations; most SO users are motivated by a mix of altruism, sharing knowledge, some recognition, optionally linking to your profile/website/blog/resume/portfolio, getting job approaches and a dose of pride/ego/vanity. As a longtime SO user, that has historically been the bargain, when (most/)all of your submissions were directly seen by human end-users. As a plus, all of that gave you good SEO commensurate with your contributions. So, it's unreasonable to try to dichotomize into \"users who mainly did it for the rep\" vs ones who want to teach and share. But the 2023 and 2024 announcements are different: the future is your submissions will be used to train AIs; however SO doesn't seem to have devoted much thought to licensees like OpenAI complying with SO's attribution requirements [0] (attribution must cite individual URL of question/answer, and SO username, which then links onwards via your SO profile page to the items mentioned above). So the human eyeballs are being intermediated, your incentives to participate are evaporating, and that pretty much breaks SO's historical bargain with its user community. The next major bad development would be SO opening the floodgates on the moderation queue backlog of thousands of items of AI-generated content (which caused the 2023 moderator strike/resignations), much low-quality and arguably should be banned; if/when that feedback loop is closed, the results might well be unholy; certainly bona-fide human contributors will be marginalized and have less incentive. (and if AI were to be used for moderation, then that could be exploitable). Inbound views/hits on your content on SO either come from a) Google + other search engines b) SO's search itself c) attribution from OpenAI's ChatGPT d) attribution from Microsoft's VS Code and Copilot e) ditto, for otehr licensees. If your code is scraped once but effectively viewed 1 million times from GPT, you won't see those 1 million hits show up; you can only vaguely infer they might be happening if the attribution is actually implemented, and some users click through on it (or by reverse-querying the AI). So c),d) will proportionately increase as a),b) proportionately decrease. So everything has changed. And obviously the incentive to you to continue to provide unpaid volunteer labor ongoing without even attribution decreases. [0]: https://creativecommons.org/licenses/by-sa/4.0/#ref-appropri... reply atleastoptimal 12 hours agoparentprevWhat are the negative incentives? How would an LLM improving in capabilities harm those who shared their knowledge for free online at some point in the past? reply dumbo-octopus 12 hours agorootparentMy experience is worth less if an AI can summon it at-will. It hasn't necessarily come down to this yet in the software industry, but in others (like animation), folks who were previously responsible for generating concept art have found themselves without jobs as management can get \"good enough\" results from a much cheaper medium (that was, at least en-masse, trained on their \"prior art\"). I don't personally have a well formed opinion one way or another on this, but to dismiss the existence of a issue at all is logically lacking. reply kragen 12 hours agorootparentthe same reasoning would equally justify the claim that your experience is worth less if beginner programmers can summon it at will; if you believe that reasoning you wouldn't have contributed to stackoverflow in the first place. i don't and if you contributed to stackoverflow you didn't either reply zb3 11 hours agorootparentThe scale might be different here, since prompting AI is much cheaper than hiring a begginer programmer. The previous loss could for instance be compensated by attribution. reply bcrosby95 12 hours agoparentprevML gives a whole new meaning to \"training your replacements\". reply fakedang 11 hours agorootparentComing to think of it, recent ML is just a scaled up version of Infosys, Wipro, etc. Shit quality answers for enterprises, now accessible for the masses. reply fardo 11 hours agoprevThis bodes poorly for the future of SO. One of the reasons that Quora today is absolutely unusable is that it no longer is a curated discussion between internet users and knowledgeable people, but AI spamming the site with swarms of low-quality questions, and AI answering those questions with swarms of low-quality answers. I think it's likely that Stack Overflow will end up following a similar pattern. reply lolinder 10 hours agoparentQuora was already absolutely unusable back before GPT-2. It became unusable as soon as people realized that all they had to do was self-identify as an expert to get taken seriously on there, so people started developing whole lifestyles around building up their Quora profiles. From that point on the actually knowledgeable people weren't interested in contributing because there was no way to distinguish themselves from the people who were faking expertise. AI may have been the final nail in the coffin, but Quora was dead long ago. Stack Overflow managed to avoid that particular hazard by placing less emphasis on real-world identity and expertise, but it also has been in a long-term decline for many other reasons. The fact that they made such a vocal stance against AI and then pivoted so dramatically is just one example of how much they've struggled to find direction lately. reply malfist 9 hours agorootparentJust a point of clarification, the user moderator base (its power users) took a strong stance against AI, and the company, chasing every possible dollar, overruled them. Short term profits over user preference is what happened here reply lolinder 9 hours agorootparentOh, yes, my mistake! I misremembered. Thank you! reply khazhoux 10 hours agoparentprevI know this wasn’t really your point, but it’s worth noting that Quora being low quality spam is not the problem. It’s why the hell Google surfaces Quora so prominently given that the results are pure shit and require registration to even see all the shit. Is there any reasonable explanation for how they’re ranked so high? Like, how can even googlers tolerate it? reply tyingq 10 hours agorootparentJust a guess, but I think when they started losing the spam wars they put in some kind of handcrafted whitelist ranking boost, either directly based on brand/site, or link proximity to known good sites, etc. And maybe they don't update that list too often. You can find some info about an ML update Google called \"Vince\" that sounds a lot like that. reply MichaelZuo 9 hours agorootparentNot updated in over 2 years? reply tyingq 7 hours agorootparentNot updated in a way that affects Quora over many years would not surprise me. reply Terr_ 10 hours agorootparentprev> Like, how can even googlers tolerate it? Assuming you mean people working at Google, the answer is probably that profit/promotions outweight personal use. More clicks, more back-buttons, more search adjustments, more advertising revenue. reply esafak 11 hours agoparentprevI don't think so: https://meta.stackoverflow.com/questions/421831/policy-gener... reply suby 10 hours agorootparentGood luck enforcing that. reply esafak 10 hours agorootparentIf a human can detect it, it can be flagged. They already deal with human spam. reply choppaface 10 hours agoparentprevQuora and SO are rather different communities. In Quora's best days, there were celebrities or quasi-celebrities making interesting posts, just like on Twitter or Google Plus in top times. Also Quora used to have very active and talented Community Managers / Top Writers. Marc Bodnick used to do tons of curation but left a while ago to create his own social network(s). In contrast, SO has never been so \"celebrity\"-driven and the content has a rather different audience. I think it's understandable that the major contributors don't like how their content is being used, similar to the Reddit revolt. What might \"replace\" SO is some AI-assisted way to establish a handbook and FAQ for any new technology. That could be a chatbot as well as some effective method for feeding that bot content. And then SO-the-community, i.e. people who want to talk to each other, will probably branch off into some other forum or network. reply user3939382 12 hours agoprevSO made it such a pain in the ass to contribute I gave up trying every time I’ve historically been interested. Like I’m already sacrificing my time to offer my expertise helping someone, you want me to jump through a bunch of hoops to have the privilege of doing so? No thanks. reply colechristensen 11 hours agoparentThat same amount of pain in the ass gaming made spam and terrible quality answers equally discouraged. Given the volume of at least decent content on stack overflow, I'd say the game worked. Somebody could try to make it better with a competitor but it would be a hard thing to succeed at. reply lmm 10 hours agorootparentThe more hoops they've added the worse the quality has gotten. The quality has declined over time, and most of the good answers you see nowadays are from people who got in the habit of contributing back when the process was much simpler, and would likely never have joined the site if it was as onerous as it is today. reply hedora 9 hours agorootparentOn a related note, it costs my employer way more to pay me to solve a captcha than it would to pay a captcha solving service. At some point, passing the hoops turns into a negative predictor of comment quality. reply malfist 9 hours agorootparentprevHave you assessed they quality of QA's that aren't years old? Anything decent that I find is usually quite old and possibly out of date. It doesn't help that asking for a more recent answer gets your question closed as a duplicate, and new answers can never overcome the inertia of the historical ones. September has came for stack overflow reply majorchord 11 hours agoparentprevWhat do you suggest as a better alternative? reply akira2501 9 hours agorootparentI'm starting to wonder if the days of \"free, ad-supported, user-generated content wells\" are over. The audience and participation base have grown larger than the ability of these single entities to rationally cope with while still maintaining their original mission and profits. We've outscaled our original hopes for the Internet. It was originally meant to be a tool genuinely controlled by it's users; unfortunately, it's largely ended up in the stranglehold of a few monopolists. reply chmaynard 11 hours agoprevStack Overflow has been assimilated. Resistance is futile. It served a useful purpose but now it's part of the glorious AI universe to come. Rest in peace. reply Reason077 11 hours agoparentThe knowledge that's baked into those LLMs comes from sites like Stack Overflow. Without them, how can the LLMs learn new things? reply hirvi74 10 hours agorootparentThat also means there is probably a lot of wrong information on Stack Overflow that is baked into the training too. Hopefully, they accounted for this in training, but no way of knowing. I have not really had a lot of accuracy issues with GPT, but then again, I probably and not savvy enough to spot them, most of the time, anyway. reply akira2501 9 hours agorootparentprevIf it's posted on stack overflow, it's not new, it's merely been published. If this is the bar for LLM \"learning\" then they are doomed to live in a hazy bubble of the recent past. reply VelesDude 10 hours agorootparentprevThat is the big question with LLM's. How can we tell what is being fed in is original content or just the output fed back in like a recursive fractal? reply umvi 10 hours agorootparentprevSO isn't the only source. Official docs/wikis, GitHub issues, etc, are also good knowledge sources. reply 18 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Stack Overflow partnered with OpenAI to incorporate AI into developer experiences, sparking controversy over content usage without proper attribution.",
      "Users who deleted or defaced their content in protest faced account suspension due to disrupting the platform.",
      "The collaboration's goal is to enhance user experiences and advocate for ethical AI applications."
    ],
    "commentSummary": [
      "Users on platforms like Stack Overflow are debating licensing, moderation, and the value of user-contributed content concerning AI models like ChatGPT.",
      "Discussions include the legality and ethics of licensing changes, profiting from user-generated content, and the quality of information on platforms.",
      "Concerns extend to the impact of AI on job opportunities, internet monopolization, and decreasing quality and accessibility of platforms such as Quora and Stack Overflow."
    ],
    "points": 262,
    "commentCount": 273,
    "retryCount": 0,
    "time": 1715203013
  },
  {
    "id": 40296926,
    "title": "Reviving ZX Spectrum Game: Kontrabant 2 on FM Radio",
    "originLink": "https://www.racunalniski-muzej.si/en/40-years-later-a-game-for-the-zx-spectrum-will-be-once-again-broadcast-over-fm-radio/",
    "originBody": "There were times when Sinclair ZX Spectrum games were copied over the radio waves across Slovenia. Radio Študent broadcast screeching, beeping and whining, which we recorded on tape and played a game a few hours later. Those times are long gone, but we can take a walk through the past today. Radio Študent, which is celebrating its 55th anniversary this week, will invite two members of the legendary Software editorial team to the microphone. Today at 20:30 the guests will be Žiga Turk, who we know as the co-founder of the magazine Moj Mikro. As one of the pioneers of the Internet in Slovenia, he wrote the Virtual Shareware Library and Wodo. Together with another guest, Matevž Kmet, he also wrote the famous “Kontrabant”, a cult Slovenian text adventure, and its successor “Kontrabant 2“. The talk will take place in the Computer Museum until 21:30. This will be followed by a nostalgic broadcast of the game Kontrabant 2 via radio waves at the frequency of 89.3 MHz, which will begin around 21:30. Anyone who still has a working Spectrum ZX will then be able to test the game. Those who do not have one can do so at the Computer Museum or online. Share Twitter Facebook Pinterest Email Copy Url",
    "commentLink": "https://news.ycombinator.com/item?id=40296926",
    "commentBody": "40 years later, a game for the ZX Spectrum will be again broadcast over FM radio (racunalniski-muzej.si)259 points by markostamcar 22 hours agohidepastfavorite88 comments bronikowski 21 hours agoI sometimes mention that our radio used to broadcast games you could tape off the air to young people and they fail to grasp the futuristic glory I experienced when I explained to myself it's like one-way modem. reply rightbyte 18 hours agoparentHonestly, I miss teletext so much. I was my primary news source until it was in practice abandoned. It was so nice. No pictures at all. Just text of different sizes and block art. And the wait time made you read in order once and not 'doomscrool'. The limited text length forced the writers to keep it short. My point being, one way coms are underrated. reply A_Venom_Roll 18 hours agorootparentIn The Netherlands the teletext system of the Dutch public broadcasting system does still exist and has a loyal following. It's also available on the web [1] and as a mobile app. Even nowadays I still use it a lot myself for a quick catch up of the news. Some of the benefits: - Since space is limited, the news stories are ultra short and to the point - No ads - No \"related stories\" - No toxic comment sections - No misleading 'thumbnails' It doesn't take longer than a minute or two to catch up on the most important stories. [1] https://teletekst-data.nos.nl/webplus?p=100 reply anthk 15 hours agorootparentFor Americans, the closest would be: https://text.npr.org https://lite.cnn.io gopher://magical.fish/1/news same as above, but for proxied to the web: https://gopher.floodgap.com/gopher/gw?a=gopher%3A%2F%2Fmagic... reply gorkish 15 hours agorootparentprevIf you are so inclined, ARRL transmits amateur radio news bulletins daily on a regular schedule[1] in the USA. The bulletins can be received with any shortwave radio that supports SSB (single sideband modulation) and decoded with a soundcard and appropriate software. Obviously, it's considerably different content, but if you are looking more for the experience of receiving and decoding a radio text bulletin, you can certainly have it! Many other teletext services[2] exist as well. [1] https://www.arrl.org/digital-transmissions [2] https://en.wikipedia.org/wiki/List_of_teletext_services reply gregopet 20 hours agoprevA friend of mine had faulty wiring in his house, the electricity would go out for a few brief moments whenever someone would ring his house bell. He would stand in front of his house when ZX Spectrum games were being broadcast so nobody would ring and interrupt his recorder :) reply harryf 19 hours agoparentFor me it was my mum turning on the vacuum cleaner would cause a spike that could reboot the Spectrum 48K. The 128 model had a better power supply as I remember. Also the ZX81 I had before that (think I was 8 at the time) was extremely sensitive to the state of the current in the house... reply jprd 19 hours agoparentprevThis is so great! Reminds me of policing the phone line so someone didn't blow up my BBS Kermit downloads. reply grujicd 21 hours agoprevThis triggers a lot of nostalgic feelings. We also had that in Belgrade during 80s, in a radio show hosted by late Zoran Modli. I even recorded some of emmited games although I didn't have a computer at a time. Access to software, music, or any kind of information was hard, slow, and limited back then. Hats off to Žiga Turk and Moj Mikro magazine. That one along with Svet Kompjutera and Računari was the main source of IT knowledge for hungry minds in ex Yugoslavia. reply markostamcar 21 hours agoparentNostalgic feelings is what we have been going for. We have a large amount of (also scanned) issues of Slovenian and ex-Yu magazines in our collection: https://zbirka.racunalniski-muzej.si/revije/ reply vasac 20 hours agorootparentEh, I had all the issues of Moj Mikro while they were publishing in Serbo-Croatian, as well as all the issues of Svet Kompjutera, Računari, and PC until around 2007-2008 (Računari ceased publishing a few years later). They were all carefully packed in the basement until my mother decided to throw them all away, as who needs old stuff? And I was planning to spend my retirement days playing with the ZX Spectrum and reading stuff that I immensely enjoyed as a kid. Tough luck :) reply grujicd 19 hours agorootparentThere are scans of these old magazines at archive.org reply gregopet 20 hours agoparentprevŽiga Turk was (at a much later time :)) also the minister of education, and he's a university professor. Just shows you that game developers can get far in life :) reply Angostura 20 hours agoprevI fondly remember the Pete Shelley album “XL-1” which had a final track that contained a spectrum program. You dropped the needle on the record and pressed ‘Run’ simultaneously and it would display an animated set of patterns in sync with the music - and the song lyrics reply theblazehen 20 hours agoparentFor those curious: https://www.youtube.com/watch?v=YhKQy580STQ reply dingaling 18 hours agorootparentFascinating, here's the story from the programmer: http://www.headen.com/XL1.htm I'm not sure why he felt he had to write it all in machine code though, sadly he doesn't discuss that decision. Perhaps it was due to the time-dependency of the lyrics? reply ansible 14 hours agorootparentWithout knowing the specifics of that platform, it is likely that the BASIC interpreter was not fast enough to generate the desired effects and animations. reply gregopet 19 hours agoprevThe user manual is also quite awesome :) Here's the bit about copy protection (translation is mine): Programs cannot be copy-protected successfully. KONTRABANT 2 is protected only insofar as not just anyone can look at its databases. Therefore you could copy it to whomever you wish. Know that by doing so you will be nipping Yugoslavia's young software industry in the bud and hurt us, the enthusiasts who are writing it. You will also be hurting yourself. Programs will become more expensive due to smaller sales or won't come to exist in the first place. Copying programs is hurting everything ALL of us computer folk have fought for. We've already achieved that anyone can buy a modest computer legally without humiliating themselves at a border crossing while YOU can help us breathe our local soul into these machines. reply gregopet 19 hours agoparent..and in the troubleshooting section: Don't forget the first law of computer science: \"Is it turned on?\" reply DrBazza 20 hours agoprevBack in the day, there were magazines that had a flexible plastic LP/single (aka 'vinyl'), that you'd play on your stereo, and record to cassette, and load into the computer. Coincidentally, it's this - https://www.youtube.com/watch?v=1FePROXUG6E reply qingcharles 19 hours agoparentMe: going through the racks of magazines trying to find a record without a crease in it. reply DrBazza 19 hours agorootparentYes! reply rwmj 21 hours agoprevFor those far away from Slovenia, is the broadcast available over the internet (I know, I know)? This link says it's not available because of \"regional restrictions\": https://tunein.com/radio/Radio-Student-893-s25182/ Edit: Found a working link: https://onlineradiobox.com/si/tudent/?cs=si.tudent&played=1 reply overlord_tm 20 hours agoparentYou can also listen to stream directly on website https://radiostudent.si/ reply oliwerix 20 hours agorootparenthttp://kruljo.radiostudent.si:8000/ is the official stream reply panki27 19 hours agoparentprevFor something a bit more authentic, find a WebSDR that is located somewhere in or close to Slovenia :) reply Bene592 17 hours agoparentprevHow well does this work with lossy compression? I would trust only lossless formats and analog with digital data encoded as audio, but I have zero hands-on experience with this reply rwmj 17 hours agorootparentThe bit rate of a speccy tape recording was only about 1500 bps, and we routinely recorded on the cheapest tapes, and tape machines that were little better. I'm sure it'll be fine. Technical details for those interested: https://sinclair.wiki.zxnet.co.uk/wiki/Spectrum_tape_interfa... reply anthk 15 hours agorootparentMinimodem at 300BPS with the audio encoded to OPUS at 64 KBPS makes pretty reliable dumps with a relative small space per hour (~30MB). reply ochrist 19 hours agoprevBack in the eighties the Dutch radio network NOS broadcast programs for all types of home computers. They even invented a common BASIC dialect for this to work: BASICODE https://archive.org/details/BASICODE2Manual This was sent on AM, so it was available in other European countries as well. reply tombert 19 hours agoprevIt's a bit before my time, and tape based games never really caught on in the US as far as I'm aware, but I've always been kind of fascinated by storing programs in audio. There's something bizarrely cool about the idea of taking something designed for an analog medium and using it for something sort of definitionally not analog. It was traditionally cassette tapes, but I saw a YouTube video where some companies distributed games on CDs, and there's something kind of weird and anachronistic about being able to play a ZX Spectrum game off a CD; the program is going from Digital (being written) -> analog (converted to audio signals) -> digital (put on a CD) -> analog (back to audio) -> digital (read by the computer). People can be pretty clever sometimes. reply SillyUsername 19 hours agoparentDialup modem did the same thing but with more efficient protocol and error control via a network stack. ADSL also took a step further and used the shielding on copper cables to attain higher (inaudible) frequencies. The tech in some form is still about this is just the granddaddy version :D reply bcrl 8 hours agorootparentADSL does not depend on shielding of copper. It uses Discrete Multi Tone modulation which modulates many subcarriers to be able to compensate for channel distortion as the characteristics of each phone line are rather different in the frequency domain. This same technology underlies many modern wireless protocols as well. reply tombert 19 hours agorootparentprevYeah, I knew all that actually, but I guess I just associate dialup with the next generation of computers. Fundamentally I know it's a very similar tech to the tape-based game distribution, but for some reason it's categorized differently in my brain. reply nilamo 19 hours agoparentprevThe PS1 used CDs. Many games could be dropped into a cd player, and if you skip the first track (the data track), the rest of the game's music/audio could be played. reply magnusmundus 19 hours agorootparentIt was possible to do the same with some PC games! I have fond memories of listening to the soundtracks of Driver, and Knights and Merchants, on my little stereo. reply grujicd 18 hours agorootparentCassette tapes for Atari 800XL used just a single channel for data. The other one could have music and you would listen to it during game loading. reply tombert 18 hours agorootparentprevYeah, X-Wing vs Tie Fighter had a lot of the popular Star Wars music in redbook audio so it would work fine in a CD player, a fact that I was super excited to find out when I was a kid playing with my action figures. reply Bene592 18 hours agoparentprevBoth the CD and the ZX Spectrum came out in 1982 reply anthk 15 hours agorootparentIf you had a CD playing device at home by 1982, it would be like having an 8K 60\" TV today. Or, as a better match, a high end VR device able to push 4k games to each eye at 120FPS. Everyone and his grandma used tapes/cassetes until mid 90's. reply tombert 14 hours agorootparentYeah, I was about to respond with something like this. I knew that CDs came out in the early 80's, but I still more or less associate them with the 90's; it wasn't expected that you bought a CD for music until then. As a very little kid I had cassettes for my sing-along tunes, by the time 6 or 7 (1997-1998), it feels like pretty much everyone had made the jump to CDs. reply achairapart 21 hours agoprevI'd like to have a listen to those waves and I'm not in Slovenia, any source on the internet? Edit: Found a short sample of a Commodore Datasette program on Wikipedia[0]. [0]: https://en.wikipedia.org/wiki/File:Datasette.ogg reply DeathArrow 19 hours agoparentHere: http://kruljo.radiostudent.si:8000/ reply ACV001 19 hours agoprevI remember how proud of myself I was when I connected the computer's audio inputs to a standard casette player with speed up function so I could load the games twice as fast. reply surfingdino 21 hours agoprevIs this meant to confuse the aliens by suggesting we've decided to go back to 8 bits? (Love it, btw.) reply markostamcar 21 hours agoparentMaybe :) Before \"live to production\" later tonight I tested it using a car FM transmitter adapter so things are already in motion haha. reply npongratz 19 hours agoparentprevNot just confuse them, but convince them we're not a threat, and thus not worth exterminating. reply surfingdino 18 hours agorootparentDon't broadcast PSSST! then. They may take it the wrong way. reply chairleader 19 hours agoprevOut of curiosity, are there Linux tools to go from binary files to audio and back again? i.e `cat archive.zipfaxify -wav > archive.zip.wav` reply anthk 11 hours agoparentMinimodem Encode to opus: cat foo.zipminimodem --tx -r 300 -f out.flac opusenc --bitrate 64 out.flac out.opus Decode from opus: minimodem --rx -r 300 -f out.opus > foo2.zip reply chairleader 10 hours agorootparentfantastic, thanks! reply nlawalker 18 hours agoprevFYI, there's a fun indie game from 2016 on all the major platforms called Lumo[1] that's an homage to the isometric puzzle/adventure games of the ZX Spectrum era. I didn't really know anything about said era, as it was mostly before my time, but I ended up looking up a bunch of stuff as I played and it gave me an appreciation for it. The director/developer has a full walkthrough with commentary on YouTube where he explains everything.[2] [1] https://store.steampowered.com/app/345480/Lumo/ [2] https://www.youtube.com/playlist?list=PLHaRTzqB6QC9uzqnwNViw... reply pjmlp 21 hours agoprevIf I remeber correctly BBC also used to do this back in the day. reply darreninthenet 20 hours agoparentThe BBC version was a small square of \"static\" broadcast in the corner of the closing credits of the Micro Show and you put and square plastic box (you could get from the show, I can't remember if you had to pay for them or not) with a light sensor over that \"static\" square and run the special software which take the data and save it as a file. It wasn't terribly reliable but it was an interesting experiment by the BBC. reply DrBazza 20 hours agorootparentThe \"(BBC) Micro User\" used to be published monthly, and had hardware project in each edition. Towards the end there were instructions on how to build your own acoustic-coupler modem where you pushed a regular telephone into two muffled cups. I think the only or main thing you could connect to was Prestel. https://en.wikipedia.org/wiki/Prestel It was a great machine for doing early robotics too - there was an Osbourne/Usbourne book on making an arm from balsa wood. reply darreninthenet 19 hours agorootparentPrestel was my first online experience, over a 1200/75 baud modem (I just missed the acoustic coupler era, this was mid-80s) and led me onto dialing up many BBSs... much to my fathers gnashing of teeth when the quarterly British Telecom phone bill came through! Phone calls used to be expensive in the UK (even local). I remember Micro User magazine, wish I still had my collection! reply zerkten 20 hours agorootparentprevDoes the BBC still have people in place doing experiments and R&D? I recall at one point they were researching/experimenting with audio codecs. I imagine this has taken a hit with funding cuts and general short-sightedness back home. reply noneeeed 20 hours agorootparentIt is still very much a thing. https://www.bbc.co.uk/rd reply youngNed 20 hours agorootparentprevhttps://www.bbc.co.uk/rd/search?Type=Publications reply flohofwoe 20 hours agoparentprevAlso in East Germany, initiated by Prof. Horst Voelz (who was kind of a computer celebrity back then, basically the East German Konrad Zuse or Alan Turing). Interestingly there was a cooperation with computer enthusiasts from the Netherlands which led to the adaption of the Dutch BASICODE standard in East Germany. Also see (apologies for German link, but I guess machine translation will work well): https://web.archive.org/web/20181107231024/http://r-h-voelz.... reply ddmf 20 hours agoprevThere was a game on Shakin' Stevens' album where you had to hide from bats and open green doors, and even the prawn cracker like snack Skips had a game, colin the biker. Mad times. reply dj_gitmo 20 hours agoprevWas cassette tape storage more common in Europe than the U.S? I’m too young to have been around for this era, but I’ve just never seen it over here. reply barrkel 20 hours agoparentA tape drive was a standard accessory for the Commodore 64. Almost all games were on tape. The Amstrad CPC 464 had a tape drive integrated into the chassis (the 6128 used a 3\" floppy - not 3\" 1/4, a 3\" disk). In the UK and Ireland, in the late 80s, the majority of games software in computer shops was for these two platforms (much cheaper than a PC), with a handful floppy disk stuff for PCs. Consoles came in from the toy shop side rather than the computer shop side. reply zikduruqe 20 hours agorootparentMy Mattel Aquarius had a tape drive. https://en.wikipedia.org/wiki/Mattel_Aquarius reply Jolter 20 hours agoparentprevThe Apple II was the more dominant 8-bit micro in the US. My impression is that most owners got a disk drive. Probably because the Apple II’s disk drive was a marvel of engineering, being both cheap and fast. Meanwhile, the C64 had a drive that was very expensive and very slow, and hence most Commodore owners would just use the included cassette player. Perhaps it was similar with the Spectrum? It also makes some sense that users in the East Bloc would have trouble affording expensive hardware. reply NikkiA 19 hours agorootparentThe spectrum didn't have an official (**) floppy disk add-on, the official mass storage upgrade* was the microdrive, which was a 100kB tape loop format - an improvement on cassettes, but not by much. As a result, there was a wide range of unofficial floppy disk addons, which then brought the issue that there were so many competing products that supporting them all was near impossible and hardly any commercial software bothered. Post main-popularity, most people settled on the Beta Disc / Beta 128 from Technology Research as being the main unofficial standard, somewhat bolstered by it being adopted in eastern europe and russia, but during the main popularity period, even it had really poor market share in the UK. * There was also the cartridges for the Interface 2, but that's a different beast entirely and they were even less common than the Interface 1 + microdrive. ** of course there was the Spectrum +3 near the end of the spectrum's life which had a built-in 3\" amstrad drive, which saw reasonable commercial support, but it was long after the main portion of the spectrum's popularity, and at a time when the ST and Amiga were beginning to dominate. reply gregopet 19 hours agorootparentprevInterestingly enough, the plot of the game being broadcast was (if I remember correctly) about smuggling a new computer from the west. It was loaded with puns at the system (e.g. one of the locations was a government building and you had to navigate through its loopholes). reply qingcharles 19 hours agoparentprevYou've never had the pleasure of twiddling the volume control on a tape deck for the 15th time trying to get exactly the right setting for your game to not die two minutes into loading :( reply cronopios 19 hours agorootparentIt wasn't the volume, but the azimuth. reply qingcharles 18 hours agorootparentThe azimuth adjustment screw :( reply bitwize 20 hours agoparentprevBack in the 80s, data storage on cassette was commonplace for 8-bit micros, because disk drives were expensive add-ons. I know I used them with my VIC-20 and TI-99/4A. reply PaulHoule 19 hours agorootparentI had a TRS-80 Color Computer and struggled with a cassette tape interface that was faster than many competitors but wasn't reliable for me. The disc drive I added was more expensive than the computer but it was reliable and could support the OS/9 operating system https://en.wikipedia.org/wiki/OS-9 which was better than the MS-DOS I used later on the much more powerful 286 machine that replaced my Coco 3. reply jimmytucson 19 hours agoprevThis is so cool! Does anyone know how the data is encoded in the signal? Is it just data for the game that's transmitted (and the logic resides on the ZX Spectrum) or is logic also transmitted? reply opencl 18 hours agoparentThe format is very simple, basically a square wave with different pulse widths for 1s and 0s [1]. Spectrum software was typically sold on audio cassettes and the radio broadcasts are the exact same format, typically people would record the broadcasts to cassette. The loader program in ROM just copies all the data from tape (or radio) into RAM so yes any game logic would be included in that. [1] https://en.m.wikipedia.org/wiki/ZX_Spectrum_software reply praptak 21 hours agoprevIt should be possible to capture using a sound card. reply rwmj 21 hours agoparentPCM recorder is probably easiest, and the most like a tape recorder as they're widely used as replacements for dictaphones. reply Waterluvian 21 hours agoprevWhat I'm most curious about is if this was always just a happy side-effect of cassette-based data storage, or if they put specific effort into making this work. Ie. by being resilient to noise before and after a broadcast, having error correction, etc. reply sdwr 20 hours agoparentI'm curious how the timing worked - what happened if you were a few seconds early to record? Was the first part of the broadcast filled with noops? reply RetroTechie 11 hours agorootparentZX Spectrum tapes use a lead-in tone which the ROM code locks onto. Random noise (and data! from a previous block) before that is ignored. Zooming out, the format is: Lead-in (~4..5s usually), followed by a short header with program name & type of data that follows. A short pause. A shorter lead-in (~2s), followed by the data/program itself. Most software uses several of such blocks. Eg. a short BASIC loader, followed by a loading screen, followed by a # of KB's machine code. As far as audio tape storage goes, the ZX Spectrum system was fairly reliable & user-friendly. That's ignoring headerless blocks, speedloaders, and the many copy-protection schemes... reply praptak 21 hours agoparentprevThere was no error correction on ZX Spectrum, the protocol was very simple. IIRC a square wave with next bit encoded as timing of next edge, the last byte was XOR of the whole stream serving as error detection. reply zimpenfish 20 hours agorootparentTechnical details: https://sinclair.wiki.zxnet.co.uk/wiki/Spectrum_tape_interfa... Assembly: https://worldofspectrum.net/legacy-info/spectrum-rom-load-ro... TL;DR: > A '0' bit is encoded as 2 pulses of 855 T-states each. > A '1' bit is encoded as 2 pulses of 1710 T-states each (ie. twice the length of a '0') > A 'pulse' here is either a mark or a space, so 2 pulses makes a complete square wave cycle. reply ajsnigrutin 19 hours agoprevIt's funny how we used to have games over radio waves (this, article, but 40 yars ago), then went through a bunch of other media (cartridges, floppies, cds, dvds, blurays,...) and then came back to games over radio waves (download via mobile network). reply anthk 15 hours agoprevAs a silly test, I encoded the Spanish versions of the Sherlock Holmes' volumes (XZ compressed each one) to FLAC with minimodem --tx 300, and later I converted them to Opus at 64 Kbps. Each file weighted less than 30MB, not bad at all. The raw WAV files were around 400MB each. The files were re-read back with minimodem --rx at the same rate and dumped back to an XZ file, the sha512sum matched the originals. reply anthk 15 hours agoprevWith minimodem and some streaming service you can mimic that, but as a client you need to cache the data with mplayer or mpv to avoid losing data: http://www.whence.com/minimodem/ reply apples_oranges 21 hours agoprevNow could be the right time to put your old tape recorder on eBay (If you are in Slovenia) ;) reply Bene592 17 hours agoparentYou can record it with a PC. Just make sure to use a lossless format reply supermatt 20 hours agoparentprevYou can likely buy a new one on amazon for less than an old one on ebay. reply gstrike 21 hours agoprev [–] This is AWESOME! But, I absolutely love this time period of computing history. It was around this time (late 70s), before storage was accessible to computer nerds, that the Kansas City Standard was developed. It provided a cheap and easy way to store \"large\" amounts of data on standard audio cassettes which were cheap and easy to come by! It really opened up a lot of things! People no longer needed to retype their programs in to the computer every time they turned it on, it was now easy to share & copy data with friends, and it ALSO gave us the ability to broadcast programs over the radio (like this article is doing!). The original Kansas City Standard was pretty slow (300 baud), but other standards were developed shortly after (CUTS [Bob Marsh] is one) which provided more speed (1200 baud) and even backward compatibility with KCS. If anyone is interested in a the dirty details of how KCS all works, I did a series on it (https://youtu.be/6m7vDhscGzU). And am working on covering CUTS in the near future! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Radio Študent in Slovenia broadcasted Sinclair ZX Spectrum games over the airwaves, playable by recording the audio onto tapes to load the games.",
      "In honor of the radio station's 55th anniversary, two members of the Software editorial team will discuss creating classic games like \"Kontrabant\" and \"Kontrabant 2\" at the Computer Museum.",
      "Attendees can enjoy a broadcast of \"Kontrabant 2\" on Radio Študent at 21:30 and test the game on a Spectrum ZX at the event or online."
    ],
    "commentSummary": [
      "The article explores nostalgia for 80s computer systems like ZX Spectrum and ZX81 in Yugoslavia, covering cassette tape storage, data transmission, copy protection challenges, and evolving storage mediums.",
      "It discusses the use of tape decks to load games, encoding data as audio, and using cassette tapes for data storage in the early computing era.",
      "Information is shared on standards such as the Kansas City Standard (KCS) and CUTS for sharing and broadcasting data over radio."
    ],
    "points": 259,
    "commentCount": 88,
    "retryCount": 0,
    "time": 1715168946
  },
  {
    "id": 40297946,
    "title": "TimesFM: Google's Time Series Foundation Model for Forecasting",
    "originLink": "https://github.com/google-research/timesfm",
    "originBody": "TimesFM TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for time-series forecasting. Paper: A decoder-only foundation model for time-series forecasting, to appear in ICML 2024. Google Research blog Hugging Face checkpoint repo This repo contains the code to load public TimesFM checkpoints and run model inference. Please visit our Hugging Face checkpoint repo to download model checkpoints. This is not an officially supported Google product. Checkpoint timesfm-1.0-200m timesfm-1.0-200m is the first open model checkpoint: It performs univariate time series forecasting for context lengths up tp 512 timepoints and any horizon lengths, with an optional frequency indicator. It focuses on point forecasts, and does not support probabilistic forecasts. We experimentally offer quantile heads but they have not been calibrated after pretraining. It requires the context to be contiguous (i.e. no \"holes\"), and the context and the horizon to be of the same frequency. Benchmarks Please refer to our result tables on the extended benchmarks and the long horizon benchmarks. Please look into the README files in the respective benchmark directories within experiments/ for instructions for running TimesFM on the respective benchmarks. Installation We have two environment files. For GPU installation (assuming CUDA 12 has been setup), you can create a conda environment tfm_env from the base folder through: conda env create --file=environment.yml For a CPU setup please use, conda env create --file=environment_cpu.yml to create the environment instead. Follow by conda activate tfm_env pip install -e . to install the package. Usage Initialize the model and load a checkpoint. Then the base class can be loaded as, import timesfm tfm = timesfm.TimesFm( context_len=, horizon_len=, input_patch_len=32, output_patch_len=128, num_layers=20, model_dims=1280, backend=, ) tfm.load_from_checkpoint() Note that the four parameters are fixed to load the 200m model input_patch_len=32, output_patch_len=128, num_layers=20, model_dims=1280, The context_len here can be set as the max context length of the model. You can provide shorter series to the tfm.forecast() function and the model will handle it. Currently the model handles a max context length of 512, which can be increased in later releases. The input time series can have any context length. Padding / truncation will be handled by the inference code if needed. The horizon length can be set to anything. We recommend setting it to the largest horizon length you would need in the forecasting tasks for your application. We generally recommend horizon length <= context length but it is not a requirement in the function call. Perform inference We provide APIs to forecast from either array inputs or pandas dataframe. Both forecast methods expect (1) the input time series contexts, (2) along with their frequencies. Please look at the documentation of the functions tfm.forecast() and tfm.forecast_on_df() for detailed instructions. In particular regarding the frequency, TimesFM expects a categorical indicator valued in {0, 1, 2}: 0 (default): high frequency, long horizon time series. We recommend to use this for time series up to daily granularity. 1: medium frequency time series. We recommend to use this for weekly and monthly data. 2: low frequency, short horizon time series. We recommend to use this for anything beyond monthly, e.g. quarterly or yearly. This categorical value should be directly provided with the array inputs. For dataframe inputs, we convert the conventional letter coding of frequencies to our expected categories, that 0: T, MIN, H, D, B, U 1: W, M 2: Q, Y Notice you do NOT have to strictly follow our recommendation here. Although this is our setup during model training and we expect it to offer the best forecast result, you can also view the frequency input as a free parameter and modify it per your specific use case. Examples: Array inputs, with the frequencies set to low, medium and high respectively. import numpy as np forecast_input = [ np.sin(np.linspace(0, 20, 100)), np.sin(np.linspace(0, 20, 200)), np.sin(np.linspace(0, 20, 400)), ] frequency_input = [0, 1, 2] point_forecast, experimental_quantile_forecast = tfm.forecast( forecast_input, freq=frequency_input, ) pandas dataframe, with the frequency set to \"M\" monthly. import pandas as pd # e.g. input_df is # unique_id ds y # 0 T1 1975-12-31 697458.0 # 1 T1 1976-01-31 1187650.0 # 2 T1 1976-02-29 1069690.0 # 3 T1 1976-03-31 1078430.0 # 4 T1 1976-04-30 1059910.0 # ... ... ... ... # 8175 T99 1986-01-31 602.0 # 8176 T99 1986-02-28 684.0 # 8177 T99 1986-03-31 818.0 # 8178 T99 1986-04-30 836.0 # 8179 T99 1986-05-31 878.0 forecast_df = tfm.forecast_on_df( inputs=input_df, freq=\"M\", # monthly value_name=\"y\", num_jobs=-1, )",
    "commentLink": "https://news.ycombinator.com/item?id=40297946",
    "commentBody": "TimesFM: Time Series Foundation Model for time-series forecasting (github.com/google-research)255 points by yeldarb 20 hours agohidepastfavorite88 comments whimsicalism 17 hours agoI'm curious why we seem convinced that this is a task that is possible or something worthy of investigation. I've worked on language models since 2018, even then it was obvious why language was a useful and transferable task. I do not at all feel the same way about general univariate time series that could have any underlying process. reply wuj 14 hours agoparentTime series data are inherently context sensitive, unlike natural languages which follow predictable grammar patterns. The patterns in time series data vary based on context. For example, flight data often show seasonal trends, while electric signals depend on the type of sensor used. There's also data that appear random, like stock data, though firms like Rentech manage to consistently find unlerlying alphas. Training a multivariate time series data would be challenging, but I don't see why not for specific applications. reply bigger_cheese 4 hours agoparentprevThere is potential for integrating ML with time series data in industrial applications (things like smelters, reactors etc.), where you have continuous stream of time series measurements from things like gauges and thermocouples. If you can detect (and respond) to changing circumstances faster then a humans in control room reacting to trends or alarms then potential big efficiency gains... Operator guidance is often based on heuristics - when metric A exceeds X value for Y seconds take action Z. Or rates of change if the signal is changing at a rate of more than x etc. So in these areas there exists potential for ML solution, especially if it's capable of learning (i.e. last response overshot by X so trim next response appropriately). reply kqr 1 hour agorootparentEvery time i've actually tried something like this it has not outperformed statistical process control. It's not just that control charts are great signal detectors, but also managing processes like that takes a certain statistical literacy one gets from applying SPC faithfully for a while, and does not get from tossing ML onto it and crossing fingers. reply refibrillator 6 hours agoparentprevWhy do you think language is so special? There's an extensive body of literature across numerous domains that demonstrates the benefits of Multi-Task Learning (MTL). Actually I have a whole folder of research papers on this topic, here's one of the earliest references on hand that I feel captures the idea succinctly in the context of modern ML: “MTL improves generalization by leveraging the domain-specific information contained in the training signals of related tasks\" [Caruana, 1998] I see repetition and structure everywhere in life. To me it's not far fetched that a model trained on daily or yearly trends could leverage that information in the context of e.g. biological signals which are influenced by circadian rhythm etc. Disclaimer: my background is in ML & bio-signals, I work with time series too much. reply owl_brawl 5 hours agorootparentFor those who haven't read it, Rich Caruana's thesis on multi-task learning is beautifully written (the cited 1998 paper here). It's amazing to see how far the field has come, and, at the same time, how advanced the thinking was in the 90s too. reply matt-p 21 minutes agoparentprevNot really. It's true it would usually need more context than a single series dataset but you can predict broadly accurate-ish bandwidth usage trends just using simple statistical extrapolation, we've been doing that since the early 90s. If you give a model your subscriber numbers and usage data as time series it should be able to tell you quite accurately how much electricity|bandwidth|gas|road traffic levels| metro passenger levels at station Z... you'll be using at 4pm on January 4th 2026. reply smokel 14 hours agoparentprevThe things that we are typically interested in have very clear patterns. In a way, if we find that there are no patterns, we don't even try to do any forecasting. \"The Unreasonable Effectiveness of Mathematics in the Natural Sciences\" [1] hints that there might be some value here. [1] https://en.m.wikipedia.org/wiki/The_Unreasonable_Effectivene... reply yonixw 13 hours agorootparentExactly, so for example, I think the use of this model is in cases where you want user count to have some pattern around timing. And be alerted if it has spike. But you wouldn't want this model for file upload storage usage which only increases, where you would put alerts based on max values and not patterns/periodic values. reply zeroxfe 14 hours agoparentprev> I'm curious why we seem convinced that this is a task that is possible or something worthy of investigation. There's a huge industry around time series forecasting used for all kinds of things like engineering, finance, climate science, etc. and many of the modern ones incorporate some kind of machine learning because they deal with very high dimensional data. Given the very surprising success of LLMs in non-language fields, it seems reasonable that people would work on this. reply whimsicalism 12 hours agorootparentTask specific time series models, not time series “foundation models” - we are discussing different things. reply zeroxfe 8 hours agorootparentI don't think we are. The premise of this is that the foundation model can learn some kind of baseline ability to reason about forecasting, that is generalizable across different domains (each which needs fine tuning.) I don't know if it will find anything, but LLMs totally surprised us, and this kind of thing seems totally worthy of investigation. reply cscurmudgeon 5 hours agorootparentprevFoundational time series models have been around since 2019 and show competitive levels of performance with task specific models. https://arxiv.org/abs/1905.10437 reply fedeb95 2 hours agoparentprevas you say, without knowing anything about the underlying process, we can't predict generally. Some other comments point to contexts in which we do know something about the underlying. For instance, I don't think finance is something where you can apply this kind of stuff. reply sarusso 17 hours agoparentprev+1 for “any underlying process”. It would be interesting what use case they had in mind. reply shaism 13 hours agoparentprevFundamentally, the pre-trained model would need to learn a \"world model\" to predict well in distinct domains. This should be possible not regarding compute requirements and the exact architecture. After all, the physical world (down to the subatomic level) is governed by physical laws. Ilya Sutskever from OpenAI stated that next-token prediction might be enough to learn a world model (see [1]). That would imply that a model learns a \"world model\" indirectly, which is even more unrealistic than learning the world model directly through pre-training on time-series data. [1] https://www.youtube.com/watch?v=YEUclZdj_Sc reply whimsicalism 12 hours agorootparentBut the data generating process could be literally anything. We are not constrained by physics in any real sense if we predicting financial markets or occurrences of a certain build error or termite behavior. reply shaism 12 hours agorootparentSure, there are limits. Not everything is predictable, not even physics. But that is also not the point of such a model. The goal is to forecast across a broad range of use cases that do have underlying laws. Similar to LLM, they could also be fine-tuned. reply baq 15 hours agoparentprevwell... if you look at a language in a certain way, it is just a way to put bits in a certain order. if you forget about the 'language' part, it kinda makes sense to try because why shouldn't it work? reply itronitron 11 hours agoparentprevThere was a paper written a while back that proved mathematically how you can correlate any time series with any other time series, thus vaporizing any perception of value gained by correlating time series (at least for those people that read the paper.) just wanted to share reply jimmySixDOF 6 hours agorootparentThe only other timeseries paper I am aware of is TimeGPT https://news.ycombinator.com/item?id=37874891 reply notnaut 10 hours agorootparentprevI would like to read more. Feels sort of like an expression of certain “universal truths” like the 80/20 rule or golden ratio reply bdjsiqoocwk 10 hours agorootparentprevWhat does that mean \"you can correlate\"? That phrase is meaningless. reply IshKebab 15 hours agoparentprevWhy not? There are plenty of time series that have underlying patterns which means you can do better than a total guess even without any knowledge of what you are predicting. Think about something like traffic patterns. You probably won't predict higher traffic on game days, but predicting rush hour is going to be pretty trivial. reply DeathArrow 1 hour agoprevIt seems to me that predicting something based on time is rarely accurate and meaningful. Suppose you want to buy stocks? Would you look on a time based graph and buy according to that? Or you rather look at financial data, see earnings, profits? Wouldn't a graph that has financial performance on x-axis be more meaningful that one that has time? What if you research real estate in a particular area? Wouldn't be square footage a better measure than time? reply Terretta 1 minute agoparent> Would you look on a time based graph and buy according to that? Or you rather look at financial data, see earnings, profits? Things affecting financials happen through time. reply wuj 14 hours agoprevOn a related note, Amazon also had a model for time series forecasting called Chronos. https://github.com/amazon-science/chronos-forecasting reply claytonjy 14 hours agoparentAnd like all deep learning forecasting models thus far, it makes for a nice paper but is not worth anyone using for a real problem. Much slower than the classical methods it fails to beat. reply p1esk 13 hours agorootparentThat’s what people said about CV models in 2011. reply claytonjy 12 hours agorootparentThat's fair, but they stopped saying it about CV models in 2012. We've been saying this about foundational forecasting models since...2019 at least, probably earlier. But it is a harder problem! reply toasted-subs 14 hours agoparentprevSomething I've had issues with time series has been having to use relatively custom models. It's difficult to use off the shelf tools when starting with math models. reply nwoli 19 hours agoprevSeems like a pretty small (low latency) model. Would be interesting to hook up to mouse input (x and y) and see how well it predicts where I’m gonna move the mouse (maybe with and without seeing the predicted path) reply throwtappedmac 18 hours agoparentCurious George here: why are you trying to predict where the mouse is going? :) reply tasty_freeze 17 hours agorootparentGame developers are constantly trying to minimize lag. I have no idea if computers are so fast these days that it is a \"solved\" problem, but I knew a game developer ages ago who used a predictive mouse model to reduce the apparent lag by guessing where the mouse would be at the time the frame was displayed (considering it took 30 ms or whatever to render the frame). reply aeyes 16 hours agorootparentQuake internet play only became acceptable when client side prediction was implemented, I'm sure it would be better to have real prediction instead of simple interpolation. https://raw.githubusercontent.com/ESWAT/john-carmack-plan-ar... reply ukuina 8 hours agorootparentWhat an amazing look into one of the greatest minds in programming! Thank you for this treasure. The relevant bits: > I am now allowing the client to guess at the results of the users movement until the authoritative response from the server comes through. This is a biiiig architectural change. The client now needs to know about solidity of objects, friction, gravity, etc. I am sad to see the elegent client-as-terminal setup go away, but I am practical above idealistic. > The server is still the final word, so the client is allways repredicting it's movement based off of the last known good message from the server. reply wongarsu 16 hours agorootparentprevCompetitive online games commonly predict the player's movement. Network latencies have improved and are now usually <16ms (useful milestone since at 60fps you render a frame every 16.6ms), but players expect to still be able to smoothly play when joining from the other side of the continent to play with their friends. You usually want every client to agree where everyone is, and predicting movement leads to less disagreement than what you would get from using \"outdated\" state because of speed-of-light delays. If you want to predict not just position but also orientation in a shooter game, that's basically predicting the mouse movements. reply orbital-decay 17 hours agorootparentprevThe only thing worse than lag is uneven lag, which is what you're going to end up with. Constant lag can be dealt with by players, jitter can't. reply nwoli 18 hours agorootparentprevJust to see how good the model is (maybe it’s creepily good in a fun way) reply Timon3 17 hours agorootparentThere's a fun game idea in there! Imagine having to outmaneuver a constantly learning model. Not to mention the possibilities of using this in genres like bullet hell... reply brigadier132 14 hours agorootparentprevCatching cheaters in games might seem like a good use. reply teaearlgraycold 18 hours agorootparentprevThink of the sweet sweet ad revenue! reply throwtappedmac 18 hours agorootparentHaha as if advertisers don't know me better than I know me reply jarmitage 18 hours agoparentprevWhat is the latency? reply chaos_emergent 13 hours agoprev\"Why would you even try to predict the weather if you know it's going to be wrong?\" - most OCs on this thread reply l2dy 17 hours agoprevBlog link (Feb 2024): https://research.google/blog/a-decoder-only-foundation-model... Previous discussion: https://news.ycombinator.com/item?id=39235983 reply mhh__ 16 hours agoprevDear googler or meta-er or timeseries transformer startup something-er: Please make a ChatGPT/chat.lmsys.org style interface for one of these that I can throw data at and see what happens. This one looks pretty easy to setup, in fairness, but some other models I've looked at have been surprisingly fiddly / locked behind an API. Perhaps such a thing already exists somewhere? reply viraptor 7 hours agoprevI'm not sure I understand two things here. Could someone clarify: 1. This is a foundation model, so you're expected to fine tune for your use case, right? (But readme doesn't mention tuning) 2. When submitting two series, do they impact each other in predictions? reply hm-nah 5 hours agoprevAnyone have insights working with Ikigai’s “Large Graphical Model” and how well it does on time-series? It’s proprietary, but I’m curious how well it performs. reply esafak 17 hours agoprevIs anyone using neural networks for anomaly detection in observability? If so, which model and how many metrics are you supporting per core? reply leeoniya 17 hours agoparentLSTM is common for this. also https://facebook.github.io/prophet/ reply morkalork 16 hours agorootparentHow data hungry is it, or what is the minimum volume of data needed before its worth investigating? reply viraptor 7 hours agorootparentThe more complex the data is, the more you need. If your values are always 5, then you need only one data point. reply sarusso 17 hours agoparentprevWhat do you mean by “observability”? reply esafak 17 hours agorootparentTelemetry. Dashboards. The application is knowing when a signal is anomalous. https://en.wikipedia.org/wiki/Observability_(software) reply sarusso 17 hours agorootparentOh, yes I am working on that. Usually LSTM, exploring encoder-decoders and generative models, but also some simpler models based on periodic averages (which are surprisingly useful in some use cases). But I don’t have per-core metrics. reply tiagod 13 hours agorootparentprevDepending on how stable your signal is, I've had good experience with seasonal ARIMA and LOESS (but it's not neural networks) reply polskibus 17 hours agoprevhow good is it on stocks? reply fedeb95 2 hours agoparentit doesn't apply. Checkout the Incerto by Nassim Nicholas Taleb. reply svaha1728 15 hours agoparentprevThe next index fund should use AI. What could possibly go wrong? reply whimsicalism 15 hours agorootparentI promise you your market-making counterparties already are. reply hackerlight 11 hours agorootparentWhat kind of things are they doing with AI? reply whimsicalism 11 hours agorootparentPredicting price movements, finding good hedges, etc. reply claytonjy 13 hours agoparentprevif I knew it was good, why would I tell you that? reply celltalk 4 hours agoprevIf I give this model the first 100 prime numbers, does it give me back the rest of it? If so what is the circuit? reply fedeb95 2 hours agoparenthow is the series of the first 100 prime numbers a time series ? reply uoaei 19 hours agoprev\"Time series\" is such an over-subscribed term. What sorts of time series is this actually useful for? For instance, will it be able to predict dynamics for a machine with thousands of sensors? reply techwizrd 18 hours agoparentSpecifically, its referring to univariate, contiguous point forecasts. Honestly, I'm a little puzzled by the benchmarks. reply sarusso 17 hours agoparentprevEven if it was for multivariate time series, the model would first need to infer what machine are we talking about, then its working conditions, and only then make a reasonable forecast based on an hypothesis of its dynamics. I don’t know, seems pretty hard. reply uoaei 15 hours agorootparentIndeed. An issue I ran into over and over while doing research for semiconductor manufacturing. My complaint was more illustrative than earnest. reply iamgopal 19 hours agoprevHow can time series model be pre-trained ? I think I’m missing something. reply melenaboija 19 hours agoparentThird paragraph of the introduction of the mentioned paper[1] in the first paragraph of the repo. [1] https://arxiv.org/abs/2310.10688 reply jurgenaut23 18 hours agorootparentI guess they pre-trained the model to exploit common patterns found in any time-series (e.g., seasonalities, trends, etc.)... What would be interesting, though, is to see if it spots patterns that are domain-specific (e.g., the ventricular systole dip in an electrocardiogram), and possibly transfer those (that would be obviously useless in this specific example, but maybe there are interesting domain transfers out there) reply sarusso 16 hours agoparentprevMy understating is that, while your eye can naturally spot a dependency over time in time series data, machines can’t. So as we did for imaging, where we pre-trained models to let machines easily identify objects in pictures, now we are doing the same to let machines “see” dependencies over time. Then, how these dependencies work, this is another story. reply malux85 17 hours agoparentprevIf you have a univariate series, just single values following each other - [5, 3, 3, 2, 2, 2, 1, …] What is the next number? Well let’s start with the search space - what is the possible range of the next number? Assuming unsigned 32bit integers (for explanation simplicity) it’s 0-(2^32-1) So are all of those possible outputs equally likely? The next number could be 1, or it could be 345,654,543 … are those outputs equally likely? Even though we know nothing about this sequence, most time series don’t make enormous random jumps, so no, they are not equally likely, 1 is the more likely of the two we discussed. Ok, so some patterns are more likely than others, let’s analyse lots and lots of time series data and see if we can build a generalised model that can be fine tuned or used as a feature extractor. Many time series datasets have repeating patterns, momentum, symmetries, all of these can be learned. Is it perfect? No, but what model is? And things don’t have to be perfect to be useful. There you go - that’s a pre-trained time series model in a nutshell reply aantix 14 hours agoprevWould this be useful in predicting lat/long coordinates along a path? To mitigate issues with GPS drift. If not, what would be a useful model? reply smokel 14 hours agoparentMap matching to a road network might be helpful here. For example, a Hidden Markov Model gives good results. See for instance this paper: \"Hidden Markov map matching through noise and sparseness\" (2009) https://www.microsoft.com/en-us/research/wp-content/uploads/... reply bbstats 8 hours agoparentprevKalman filter reply dangerclose 18 hours agoprevis it better than prophet from meta? reply VHRanger 18 hours agoparentI imagine they're both worse than good old exponential smoothing or SARIMAX. reply Pseudocrat 17 hours agorootparentDepends on use case. Hybrid approaches have been dominating the M-Competitions, but there are generally small percentage differences in variance of statistical models vs machine learning models. And exponentially higher cost for ML models. reply VHRanger 17 hours agorootparentAt the end of the day, if training or doing inference on the ML model is massively more costly in time or compute, you'll iterate much less with it. I also think it's a dead end to try to have foundation models for \"time series\" - it's a class of data! Like when people tried to have foundation models for any general graph type. You could make foundation models for data within that type - eg. meteorological time series, or social network graphs. But for the abstract class type it seems like a dead end. reply rockinghigh 16 hours agorootparentThese models may be helpful if they speed up convergence when fine tuned on business-specific time series. reply SpaceManNabs 15 hours agorootparentprevis there a ranking of the methods that actually work on benchmark datasets? Hybrid, \"ML\" or old stats? I remember eamonnkeogh doing this on r/ML a few years ago. reply efrank3 7 hours agoparentprevProphet was pretty bad so yes, but it doesn't seem much better than ARIMA reply optimalsolver 16 hours agoprev [–] When it comes to time series forecasting, if the method actually works, it sure as hell isn't being publicly released. reply speedgoose 14 hours agoparentSome times series are more predictable than others. Being good at predicting the predictable ones is useful. For example you can easily predict the weather with descent accuracy. Tomorrow is going to be about the same than today. From there you can work on better models. Or predicting a failure in a factory because a vibration pattern on an industrial machine always ended up in a massive failure after a few days. But I agree that if a model is good at predicting the stock market, it’s not going to be released. reply baq 15 hours agoparentprev [–] and yet we have those huge llamas publicly available. these are computers that talk, dammit reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "TimesFM (Time Series Foundation Model) is a pretrained model from Google Research for time-series forecasting, focusing on point forecasts without probabilistic forecasts.",
      "It can process up to 512 timepoints and various horizons, with the option to indicate frequency, providing public checkpoints on Hugging Face for user convenience.",
      "Users can leverage TimesFM APIs to make predictions from array inputs or pandas dataframes, adjusting the frequency parameter to suit their individual requirements, as detailed in the provided documentation."
    ],
    "commentSummary": [
      "TimesFM hosts a discussion on leveraging machine learning for time series forecasting, covering its challenges and potential across different sectors.",
      "Participants debate the effectiveness of basic time series models, significance of data patterns, and using predictive models in gaming, among other topics like anomaly detection and pre-training models.",
      "The conversation underscores the pros and cons of time series models in diverse scenarios, emphasizing the importance of pattern recognition and forecasting accuracy."
    ],
    "points": 255,
    "commentCount": 88,
    "retryCount": 0,
    "time": 1715175274
  },
  {
    "id": 40296744,
    "title": "Inside the Unconventional Win of Press Your Luck Thousandaire",
    "originLink": "https://www.damninteresting.com/who-wants-to-be-a-thousandaire/",
    "originBody": "© 2011 All Rights Reserved. Do not distribute or repurpose this work without written permission from the copyright holder(s). Printed from https://www.damninteresting.com/who-wants-to-be-a-thousandaire/ On the 19th of May 1984, at CBS Television City in Hollywood, a curious air of tension hung over the studio during the taping of the popular game show Press Your Luck. Ordinarily a live studio audience could be counted upon to holler and slap their hands together, but something was keeping them unusually subdued. The object of the audience’s awe was sitting at the center podium on the stage, looking rather unremarkable in his thrift-store shirt and slicked-back graying hair. His name was Michael Larson. “You’re going to go again?” asked the show’s host Peter Tomarken as Larson gesticulated. Gasps and murmurs punctuated the audience’s cautious applause, and the contestants sitting on either side of Larson clapped in stunned silence. “Michael’s going again,” Tomarken announced incredulously. “We’ve never had anything like this before.” The scoreboard on Larson’s podium read “$90,351,” an amount unheard of in the history of Press Your Luck. In fact, this total was far greater than any person had ever earned in one sitting on any television game show. With each spin on the randomized “Big Board” Larson took a one-in-six chance of hitting a “Whammy” space that would strip him of all his spoils, yet for 36 consecutive spins he had somehow missed the whammies, stretched the show beyond its 30-minute format, and accumulated extraordinary winnings. Such a streak was astronomically unlikely, but Larson was not yet ready to stop. He was convinced that he knew exactly what he was doing. Michael Larson was born in the small town of Lebanon, Ohio in 1949. Although he was generally regarded as creative and intelligent, he had an inexplicable preference for shady enterprises over gainful employment. One of his earliest exploits was in middle school, where he smuggled candy bars into class and profitably peddled them on the sly. This innocuous operation was just the first in a decreasingly scrupulous series of ventures. One of his later schemes involved opening a checking account with a bank that was offering a promotional $500 to each new customer; he would withdraw the cash at the earliest opportunity, close the account, then repeat the process over and over under assumed names. Michael Larson and Teresa Dinwitty on vinyl. On another occasion he created a fake business under a family member’s name, hired himself as an employee, then laid himself off to collect unemployment wages. By 1983 Michael Larson had been married and divorced twice and was living with his girlfriend Teresa Dinwitty. During the summers he operated a Mister Softee ice cream truck, and during the off-season he passed the time poring through piles of periodicals in search of money-making schemes. Michael also spent much of the day with his console television, scanning the airwaves for lucrative opportunities. One day it occurred to him that he could double his information intake by setting a second console TV to beside the first and tuning it to a different channel. Soon he procured a third. Eventually he added a row of smaller televisions atop the three consoles, and yet another row of tubes was later stacked atop that. Now he could watch 12 channels at once. The warm, buzzing television tumor metastasized into adjacent rooms, filling the house with a goulash of infomercials, news programs, game shows, and advertisements for money-making schemes. Larson watched them in a trance-like state, sometimes throughout the night. Dinwitty would later say of her boyfriend and common-law husband, “He always thought he was smarter than everybody else,” and that he had a “constant yearning for knowledge.” But when visitors asked about the chattering mass of receivers she found it easier to just tell them that Michael was crazy. One fateful November day in 1983, Peter Tomarken’s dapper countenance appeared on one of Michael’s many monitors. Tomarken was the host of a new game show called Press Your Luck which was giving away more money than any other game shows at the time. What most interested Michael was the game’s “Big Board,” an electronic array of prize boxes which operated by lighting up squares in a rapid and random fashion until the player pressed a big red button to stop the action. The player’s randomly selected box might contain a vacation, a prize, cash rewards, and/or extra spins. But with each spin there was also a one-in-six chance of hitting a Whammy which would cause an animated character to appear on the screen and expunge all of a player’s winnings. Michael's secret safe spots are the ones that contain $3000 and $2000 prizes at the time this picture was taken. Larson invested in a newfangled video cassette recorder and began taping episodes of Press Your Luck. After weeks of painstaking scrutiny Michael realized that the bouncing prize selector did not actually move randomly; it always followed one of five lengthy sequences. This information was only moderately useful due to the rapidly shuffling positions of the prizes and penalties, but his methodical analysis led to another finding. Of the eighteen squares on the Big Board there were two that never had Whammies: #4 and #8. This meant that all a player must do to avoid Whammies⁠—and thus retain his hundreds of dollars in winnings⁠—would be to memorize five interminable series of numbers and develop superhuman reflexes. Giddy with the thrill of discovery, Larson began fine-tuning his timing using his VCR’s pause key as a surrogate big red button. Six months later, in May 1984, Michael Larson sat beardily in the interview room for the Press Your Luck auditions in Hollywood. His story left few heartstrings unpulled: He explained that he was an unemployed ice cream truck driver. He had borrowed the bus money to get to Hollywood from Ohio because he loved Press Your Luck. He had stopped at a thrift store down the street to buy a 65 cent dress shirt. And he was unable to afford a gift for his six-year-old daughter’s upcoming birthday. Executive producer Bill Carruthers said of Larson’s audition, “He really impressed us. He had charisma.” Contestant coordinator Bob Edwards was uneasy about Larson, but he couldn’t quite articulate why, so Bill overruled him. “I should have listened to Bob,” Carruthers later chuckled. Taping occurred the following Saturday. Returning champion Ed Long sat on Michael’s right and contestant Janie Litras sat on his left. Host Peter Tomarken made boilerplate game-showey chit-chat with each contestant, and he asked Michael about his ice cream truck. “You’ve kind of OD’d on ice cream, right?” he asked Larson, who agreed. “Well hopefully you won’t OD on money, Michael.” Michael earned 3 spins on the Big Board in the first question round, giving him 3 opportunities to test the skills he had cultivated over the past six months. The board’s incandescent selector began its distinctive pseudo-random maneuvers. “Come on…big bucks,” Michael chanted, as was customary for players when up against the Big Board. “STOP!” he shouted as he slapped the button with both hands. The selector was stopped on a Whammy in slot #17. Michael shook his head and forced an embarrassed smile, but now he knew exactly how the board was timed with respect to the button. With his second and third spins Michael found his stride. He dropped all pretenses and remained silent as he concentrated on the light bouncing around the big board. Both times he successfully landed on space #4, and he ended the first half of the game with $2,500. In the second and more lucrative half of the game, Michael managed to acquire seven spins to use on the big board. Since he was in last place he was the first to spin. He positioned his hands over the button with interlocked fingers and impatiently interrupted the host’s banter by shouting, “I’m ready, I’m ready!” Tomarken indulged him, and the light on the big board began bouncing. Again, Larson was silent as he frowned at the board. Fellow contestant Ed Long would later say of Larson during these moments that “he went into a trance.” Thus began Larson’s inconceivable procession of winning spins. His demeanor alternated between intense concentration and jubilation. The strategy worked even better than he had anticipated due to the large number of Free Spin bonuses that appeared in his safe slots. Host Peter Tomarken became increasingly flabbergasted each time Larson made the “spin again” gesture. $30,000 was considered an extraordinary payoff for one day on any game show at that time, and the likelihood of missing the whammies for more than a dozen spins was considered to be vanishingly small. By his 13th spin Michael had $32,351 and nervous giggles. By his 21st spin he had $47,601 and conspicuous anxiety. But he pressed on. The Press Your Luck control booth had grown silent as the show’s producers began to realize that Larson was consistently winning on the same two spaces. In a panic, the booth operators called Michael Brockman, CBS’s head of daytime programming. “Something was very wrong,” Brockman said in a TV Guide interview. “Here was this guy from nowhere, and he was hitting the bonus box every time. It was bedlam, I can tell you.” Producers asked if they should stop the show, but Larson did not appear to be breaking any rules so they were forced to allow the episode to play out. Back on the stage, Ed and Janie clapped incredulously on either side of Michael, still waiting for their turns on the board. Janie let slip a snort of disgust after Michael’s 26th successful spin. Tomarken covered his face with his hand in disbelief as Larson risked almost $75k on his 32nd spin. But Michael’s zen-like concentration was beginning to falter. He paused to set his head on the podium and let out a whimper of exhaustion. Still he motioned to continue. The studio audience worried that he’d hit a whammy and experience an unfortunate reversal of fortune, while the producers in the control booth worried that he wouldn’t. On his 40th spin Larson’s scoreboard debt-clocked his dollar sign to make room for another digit; he surpassed $100,000. Larson, his shoulders slumped, passed his remaining spins to the bewildered Ed Long. Ed immediately hit a whammy. Host Peter Tomarken failing to believe what he is seeing. Michael sat in a twitchy daze as Ed and Janie went through their much more pedestrian turns at the board. But Larson was snapped back to reality when Janie passed 3 of her spins to him. According to the game rules he was obligated to use them. He did not appear pleased. “I didn’t want them,” Larson joked nervously as the light began bouncing around the big board, yet almost immediately he punched the big red button and landed on $4,000 in slot #4. Janie let out a squeal. The board started again. After a longer than usual delay, Larson hit the button again, landing safely in slot #8. He had just one mandatory spin remaining. The board started flashing, and Larson let out a sigh. “STOP!” he shouted as he slapped the button, but he had pressed it a fraction of a second too soon. Slot #17 was lit, the same slot where he’d hit a whammy on his first spin. As luck would have it, however, the slot contained a trip to the Bahamas. It was over; Michael had won. Larson gave Ed an awkward embrace and offered Janie a firm handshake. In total, Larson won $110,237 in cash and prizes, including two tropical vacations and a sailboat. Reportedly this was more than triple the previous record for winnings in a single episode of a game show. A clearly discombobulated Peter Tomarken engaged Larson in an impromptu interview after the show. “Why did you keep going?” he asked. “Well, two things:” Michael replied. “One, it felt right. And second, I still had seven spins and if I passed them, somebody could have done what I did.” Tomarken was too polite to remark on the ridiculousness of that suggestion. “What are you going to do with the money, Michael?” “Invest in houses.” Larson was not allowed to return as champion since he had surpassed CBS’s $25k winnings limit. As all of the perplexed parties parted ways, CBS executives were called to a meeting to dissect the episode frame-by-frame. In spite of their efforts they could find no evidence of wrongdoing or rule-breaking, so after a few weeks they grudgingly mailed Larson his check. Some people at CBS didn’t want the over-extended episode to be released to the public at all, but it was ultimately decided to air it in June as an awkwardly edited two-parter. Executives insisted that the episode never be seen again. In the meantime Press Your Luck paid to add some more sequences to the Big Board to prevent future contestants from mimicking Michael’s strategy. Upon his return home, neighbors were shocked to learn of “crazy” Michael Larson’s accomplishment. True to his word, he regaled his daughter with expensive birthday gifts and invested some of his spoils in real estate. But his fondness for dicey get-rich-quick deals ensnared him in a Ponzi scheme, and he lost enough money to lose his appetite for houses. Some months later Michael Larson saw another opportunity to stack the odds in his favor with a dash of ingenuity. He walked into his bank one day and asked to withdraw his entire account balance, but with an unusual stipulation: He wanted as much of the cash as possible in one dollar notes. The bank complied with his unorthodox request, and from there he proceeded to another bank to trade even more of his savings for singles. Over a two week period he converted the $100,000 or so that remained of his personal savings into 100,000 one dollar bills. The motivation for this aberrant behavior was a contest put on by a local radio station. Each day a disk jockey would read a serial number aloud on the air, and if any listener was able to produce the matching dollar bill they would win $30,000. Michael reasoned that 100,000 one dollar bills was 100,000 opportunities to win the prize, giving him a statistical advantage. And even if his scheme proved fruitless he would just redeposit his money, so he figured he had nothing to lose. Michael and Teresa spent each day rifling through piles of cash looking for matches, pausing only for such distractions as eating, bathing, and excreting. They soon realized that it was impossible for two people to examine that much money in the allotted time, so Michael redeposited a portion of it. After a few weeks, Michael’s obsession over the contest began to put considerable strain on his relationship with Teresa, and on his relationship with reality. The cash was stashed in kitchen drawers, up the stairs, and on bedroom floors. They kept the bills in burlap sacks, grocery bags, and unkempt stacks. And though his girlfriend would scream and shout, he simply would not take the cash bags out. One evening, seeking refuge from the endless hours of cash-collating, Michael and Teresa accepted an invitation to attend a Christmas party. When they returned home at about 1:00 am, they found the back door of the house had been brutalized. Apparently the pair had unwittingly left a sizable tip for an unsolicited cleaning service: about $50,000. According to Dinwitty, Michael immediately accused her of being an accessory to the heist. She denied involvement, and police found no evidence of her guilt, but she says that Larson was never convinced. She claimed that Michael would stand and stare at her while she slept, which made her fear for her safety. One day while Michael was away she took $5,000 that he had hidden in a dresser drawer and absconded with the kids. She called him from a hotel to tell him to move out of her house. His only response was, “I want my money back.” He packed his belongings and departed, leaving one wall of the living room blemished and peeling from the heat of his once-formidable tower of televisions. Police never identified the thieves. In 1994, about 10 years after his pivotal Press Your Luck appearance, Larson was invited to be a guest on ABC’s Good Morning America to discuss the movie Quiz Show. With a raspy voice he unbeardily reminisced about his game show exploits and expressed regret that he was never able to play on Jeopardy, because, he explained, “I think I have figured out some angles on that.” Around that same time he was also interviewed by TV Guide magazine. When asked about the whereabouts of his Press Your Luck winnings, he replied, “It didn’t work out. We had a cash-flow problem, and I lost everything.” In March of the following year, Michael fled from Ohio with agents from the SEC, IRS, and FBI hot on his heels. He was implicated as one of the architects of a cash-flow solution that operated under the name Pleasure Time Incorporated. It was a pyramid scam selling shares in a fraudulent “American Indian Lottery” which had hoodwinked 20,000 investors out of 3 million dollars. The Pleasure Time flimflam was historic in that it was the first time the SEC pursued a case where the bulk of the fraud took place in newfangled “cyberspace.” Michael Larson was a fugitive from justice for four years until 1999, when he turned up in Apopka, Florida. He had succumbed to throat cancer. Michael Larson's appearance on Good Morning America Michael Larson held the record for the most game-show winnings in a single day until 2006, when it was broken by Vickyann Chrobak-Sadowski on The Price is Right. Larson’s handiwork on Press Your Luck was sufficiently extraordinary that he has become a strange kind of folk hero to some. Others regard him as a cheap huckster or a likable-but-occasionally-creepy crackpot. The real Michael Larson was arguably an amalgam of these qualities. His shenanigans on Press Your Luck are oft described as a “scam,” “scandal,” or a “cheat,” but even the CBS executives ultimately admitted that he had broken nary a rule. In the end, his impressive performance on Press Your Luck may be one of the only honest days of work that Michael Larson ever did. © 2011 All Rights Reserved. Do not distribute or repurpose this work without written permission from the copyright holder(s). Printed from https://www.damninteresting.com/who-wants-to-be-a-thousandaire/ Since you enjoyed our work enough to print it out, and read it clear to the end, would you consider donating a few dollars at https://www.damninteresting.com/donate ?",
    "commentLink": "https://news.ycombinator.com/item?id=40296744",
    "commentBody": "Who Wants to Be a Thousandaire? (2011) (damninteresting.com)219 points by EndXA 22 hours agohidepastfavorite147 comments hnfong 20 hours agoHere's an actual case where understanding computer science would have been immensely helpful... > The motivation for this aberrant behavior was a contest put on by a local radio station. Each day a disk jockey would read a serial number aloud on the air, and if any listener was able to produce the matching dollar bill they would win $30,000. Michael reasoned that 100,000 one dollar bills was 100,000 opportunities to win the prize, giving him a statistical advantage. And even if his scheme proved fruitless he would just redeposit his money, so he figured he had nothing to lose. > Michael and Teresa spent each day rifling through piles of cash looking for matches, pausing only for such distractions as eating, bathing, and excreting. They soon realized that it was impossible for two people to examine that much money in the allotted time (sort then binary search) reply paxys 19 hours agoparentMaybe, but even then I doubt the scheme was well thought out. He had 100,000 bills but the total number of serial numbers is many magnitudes greater than that. The chance that he'd actually have a hit was close to zero. And that is assuming the contest was legitimate in the first place. reply npilk 19 hours agorootparentSeems like the classic form of this contest would be for the radio DJ to pull a bill out of his wallet and read that serial number over the air... reply CleanRoomClub 18 hours agorootparentHaha this is what I was thinking. Did anyone ever actually win this prize? reply adrianmonk 14 hours agorootparentprevThat would be fraud by the radio station, wouldn't it? You can't run a contest that is impossible to win. reply jimbobthrowawy 9 hours agorootparentGiveaways like that were far less regulated at times in the past. reply scotty79 14 hours agorootparentprevSo? Who's gonna know? reply seeknotfind 17 hours agorootparentprevGreat way to catch forgeries reply easton 18 hours agorootparentprevIIRC serial numbers aren't unique. Even if the DJ was doing that, there would still be a chance. (albeit extremely small) reply hiatus 18 hours agorootparent> A unique combination of eleven numbers and letters appears twice on the front of the note. Each note has a unique serial number. The first letter of the serial number corresponds to the series year. https://www.uscurrency.gov/denominations/bank-note-identifie... reply bombcar 16 hours agorootparentIn 2014, the Bureau of Engraving and Printing (BEP) accidentally assigned overlapping sets of serial numbers for replacements notes to its currency-printing facilities in both Washington, D.C. and Fort Worth, Texas. The overlap occurred from serial numbers B00000001* to B00250000* and B03200001* to B09600000*. On the lower right-side of the front of the note, the letters “FW” with the face plate number indicate it was printed in Fort Worth. https://www.pmgnotes.com/news/article/9321/Duplicate-serial-... reply hinkley 10 hours agorootparentA significant quantity of those bills has probably been pulled from circulation. One of the things the Reserve does is swap damaged bills and look for counterfeits. Every bill they destroy is another crisp bill they can return to banks without fucking with inflation. reply chungy 16 hours agorootparentprevIt's not the whole story. In genuine currency, serial numbers are only unique within a series. Series 2017A and series 2021 notes can (and in fact do, since they start over at A00000001A) have identical serial numbers. reply hakfoo 8 hours agorootparentprevNotes prior to 1996, and $1 and $2 notes, use only a 10-digit serial number so there's repeats in new series. reply didgeoridoo 18 hours agorootparentprevYou’re thinking of parallel numbers. reply jujube3 16 hours agorootparentI can explain. But first, we have to talk about parallel universes and half-button-presses. reply mrb 10 hours agorootparentprevActually it's only 6 digits of the serial number that needs to match. According to [1] the game Michael Larson was trying to win was organized by $ale of the Century (SOTC), which was actually a TV show, not radio show. And as per [2] it was run for only 2 weeks in the fall of 1984, and the prize was indeed $30k as the Damn Interesting article claims. And there is a recording of an episode at [3] showing the six digits to match were \"550085\". Since Michael Larson had 100,000 bills, he basically had 10% chance of winning the $30k prize. If the game was run 14 times (over 2 weeks), he would have had a 77% chance of winning (1-.9^14) I found another episode at [4] where the host even explains \"according to the Treasury Department there as 3.7B one-dollar bills in circulation; that means [...] there are 3700 dollar bills with the winning number\" [1] https://www.gameshowforum.org/index.php?topic=5153.0 [2] https://tvtropes.org/pmwiki/pmwiki.php/Series/SaleOfTheCentu... [3] https://www.youtube.com/watch?v=neCxKLjsow8&t=1510s [4] https://www.youtube.com/watch?v=bnvSJZj3m0U&t=1296s reply pimlottc 9 hours agorootparent> Since Michael Larson had 100,000 bills, he basically had 10% chance of winning the $30k prize. A bit less than 10%, since some bills would be functional duplicates. reply mrb 5 hours agorootparentOh, you are right. It looks like it's around 9.5% according to a quick simulation I ran. reply abecedarius 18 hours agorootparentprevLooking at a dollar bill, I guess the serial-number space is 8 digits plus 2 letters. So naively the chance of any hit with 10^5 bills is 1 in 676000, yeah. (But maybe the serials were smaller then?) Re the lookup problem, you could initially \"hash\" all the bills by say the two leading figures, in your first pass. It's all way stupider than the game-show hack. reply abecedarius 16 hours agorootparentOther comments take the letters to not count, which would make the chance 1/1000 per trial -- not so ridiculous. reply uses 17 hours agorootparentprevYeah like, even if he somehow owned 10% of all dollar bills in existence and had a somewhat efficient way of looking them up, his expected value is still only $3,000! Does it really make sense to do all the work of taking your hard-earned, once in a lifetime windfall of $100000 (easily 4x the median annual income at the time, even for a person who had a steady professional job), out of the literal bank where it safely sits making ~10% interest in the mid 80s, and store it in your messy house in drawers and trash bags, for the opportunity to make 3% back? Not the thoughts of a rational person! reply chinchilla2020 17 hours agorootparentYou mean the E[V] is 103,000. He still gets to keep the 100,000 he withdrew and re-deposit it. reply throwaway482945 15 hours agorootparentI wouldn't consider the original 100K to be part of the expected value since that's money they already have, not money they're winning... reply forinti 15 hours agorootparentprevHe should have just put it in a savings account and looked for something else. reply mattmaroon 19 hours agoparentprevI had the same thought too, if you take the time to sort the bills the lookups are easy. And it probably doesn’t take much more time to sort them than it does to go through them all once looking for a number. reply tromp 19 hours agorootparentFor a radix sort on the 8 digit USD serial numbers, it takes 8x more time (the 2 letters can be ignored). That could be halved by radix sorting on pairs of digits, but then keeping track of 100 piles instead of 10 probably negates most of the gain. In practice, partial sorting suffices to reduce the serial number search time to a reasonably short amount, e.g. by 4 rounds of radix sorting. reply kragen 14 hours agorootparentin a single round of digit-pair radix sorting, you can put 100 piles of ≈1000 bills each into 10×10 cubbyholes, a piece of furniture which is small enough to fit on a desk. then you need about 20 minutes to linearly search through one such pile when the dj announces a number, which is probably fast enough to win if you have a second cubbyhole array, when you linearly search through a pile chosen from the first cubbyhole array, you can radix-sort that pile by another two digits, dividing it into piles of ≈10 bills. those piles are small enough that you can keep them sorted as you build them without much loss of efficiency, even on a computer if you can fill the first array with 100 wallets with 10 numbered tabs each, like the tabbed dividers in a looseleaf notebook, you can divide the bills into 1000 piles on the first radix-sorting pass. in practice it might be too much work to find or make the wallets but i think the sad thing about michael larson's story is not that he didn't know enough about computer 'science' (or, i guess, library 'science'), but that he spent more effort searching for a hack that would make hard things easy than it would have taken to do them the hard way, destroying his personal relationships in the process reply mattmaroon 18 hours agorootparentprevRight, so basically by your ninth time doing this you’d have broken even (ish) on time. He was doing it every day so that’d be a great investment. It also would reduce the possibility of errors greatly I’d think. reply Retric 15 hours agorootparent100k bills doesn’t need an exact sort to be vastly faster. Day one you sort by first digit, then keep sorting matching digits stopping when you have say 20 numbers in a pile. My guess is you break even on day 2 and the first day is only slightly worse. reply mattmaroon 14 hours agorootparentThat’s a good point, each individual sort probably takes only slightly longer than just looking through them for the number. So the actual sorting might not really add much time at all reply uses 17 hours agoparentprevYeah this part bothered me. It's surprising if they really didn't immediately realize randomly looking at single bills was an impossible strategy. Kind of an interesting problem. Complete sorting in a timely manner is basically not possible because of the physical reality of 100k pieces of paper. But maybe you can group the bills into 100 piles of \"last 2 digits\", so then for each lookup you \"only\" have to check 1000 bills. And then later, while searching a group, you can take the time to further sort them by the 3rd digit. I guess it also depends on how long you expect the contest to go on, i.e. how many lookups you will do. Even with the simplified grouping strategy, let's be generous and assume it takes you 3 seconds to look at a bill, figure out what to do with it, and physically move it to the correct place. That's still 83 person-hours to do a single pass and put the bills into 100 groups for quicker lookup. With 2 people, that's 5 full 8 hour days of non-stop sorting. reply scottyah 15 hours agorootparentI think I'd scan them all, and divide them into 100 piles of 1,000. While one person is working on uploading and processing scans to a database system (tagging/adding a field for its pile), the other could be sorting the piles if they want. Basically, seeing if you have a match and limiting it to a pile of 1,000 while not having too much overhead of a ton of different piles. If you do match, each person could check through 500 bills easily, and there's no sorting needed. reply kragen 14 hours agorootparentin 01984 the apparatus to scan them all would have cost you more than the bills reply gravescale 9 minutes agorootparentIndeed, the first consumer digital camera, the Sony Mavica was only 3 years old and wrote still frames to tape, and it would still be 2 years before a digital still video camera would make it to the US market, and you'd have to shuffle the images around on a Still Video Floppy, as USB (and 1.0 at that) wouldn't appear for another 12 years, and even the first serial port webcam would be 10 years. reply bluGill 15 hours agorootparentprevI would copy the serials onto paper in sorted order. Then I only need to find the bill after I know I have it. I'd still need to find the bill on demand - but you typically get 10 minutes to call and then days to prove it (this was the 1980s - you couldn't email a digital photo back then. Today I'd forge the digital photo and have hours to set the real one aside for when they check) reply nucleardog 3 hours agorootparentThis is more or less the way I’d go. It’s “what the client asked for” versus “what solves the client’s problem”. You don’t need to find the bill within minutes, you need to know that you _have_ the bill quickly. Grab a big binder, half dozen packs of dividers, a pack of loose leaf paper, and a box of pens. Divide the binder into ranges. In each range use a separate piece of paper for the next digit. Don’t worry about sorting past there, just write all your serial numbers down. Now you can use the dividers to narrow it down to around 2,000 bills. Flipping through ten pages to find the next digit you’ve narrowed it down to about 200 bills. You can probably scan two hundred numbers quickly enough. reply supportengineer 14 hours agoparentprevThis reminds me of the old website, \"Where's George?\" Sample bill report: https://www.wheresgeorge.com/b:QZHjxdYnJ&entry=17 reply taneq 20 hours agoparentprevMaybe less lucrative but when we had some new bookshelves installed and moved all our books onto them I used mergesort to get them in order. ;) reply marcosdumay 19 hours agorootparentBucket-(insert-)sort is also an all time favorite. I've taught it to many people already. It helps that it works in a very intuitive way. reply noman-land 19 hours agorootparentTeach it to us! I'm not familiar with this. reply jasonjmcghee 17 hours agorootparentIt's bucket sort, and parent is suggesting insertion sort within each bucket as the pre-merge step. Say you're sorting alphabetically by title. You make one bucket per letter- put books into their respective bucket based on first letter of title. Then sort using insertion sort within each bucket. Then you're done. (insertion sort is the human natural one- look for where the next one goes based on what you have so far and insert) Same works for other heuristics. reply hennell 18 hours agorootparentprevI've often pondered the optimal book organisation, sorting and inserting system. Organising by subject seems a good start, but then you have size to conser. Then you also tend to arrange by space - i.e. you might put two subjects together based more on similar size or shelf capacity then logical subject grouping. For inserts a reverse-sorted inserting-from-the-back makes most sense to reduce moving of books, but I suspect there's probably an optimal 'free space' value to allow for easier inserting. reply lostlogin 15 hours agorootparent> I've often pondered the optimal book organisation Let me introduce you to an option I recently found. I went to get a book from our (large) bookcase and found they’d all been reorganised based on cover colour. reply gravescale 3 minutes agorootparentMakes it much easier to buy new books that way: https://www.ebay.com/sch/i.html?_nkw=red+books+by+foot reply kragen 14 hours agorootparentprevthat's grounds for divorce reply dmurray 18 hours agoprevIt's a triumph of regulation that he got his money. It would have been very natural for CBS to cite technical difficulties or find some other way to change the rules of the game, but US game shows in this era were terrified of the FCC, who were given strong powers to enforce fairness in game shows after some frauds in the 50s [0]. Those laws are still on the books, of course, but I expect game show producers have got better at working around them in the small print, while regulators haven't kept up. [0] https://en.wikipedia.org/wiki/1950s_quiz_show_scandals reply bombcar 16 hours agoparentThe game shows now just buy insurance against extraordinary wins, and let Llyods of London handle it. reply bluGill 15 hours agoparentprevGame show producers want you to win big. Big winners are great advertisement. Management has a different idea of course, but management also understands that big winners bring in viewers and so they want to have big enough winners but not too big. Nobody wants to be accused of cheating as that is a scandal that can kill the game show. reply dmurray 15 hours agorootparentRight, the show needs some winners. Management and producers might go a step further and realise that a charismatic underdog winning dramatically from hopeless circumstances would bring in even more viewers - perhaps something could be done to help that happen? reply TMWNN 13 hours agorootparentOh, good grief. In two comments you've gone from \"game show producers don't want to pay out the money contestants win\" to, after bluGill points out that game shows want contestants to win big, say \"Of course! If anything, game show producers might even skew things to help charismatic underdogs win!\". I mean, really. reply dmurray 13 hours agorootparentI haven't changed anything! It's right there in the Wikipedia article - the 1950s frauds were in fact mainly about rigging the shows for entertainment value, ensuring the right contestants won. The FCC doesn't (didn't?) like the shows being rigged that way, which is why The $64,000 Question went off the air. It also doesn't like the shows being rigged in the network's favour, which is why this episode of Press Your Luck continued to the end despite the producers' misgivings. reply TMWNN 13 hours agorootparentI am well aware of the 1950s game show scandals. That the scandals happened 70 years ago is not very relevant to your claim that game show producers today are * all super-crooked, with only fear of the FCC preventing them from repeating the scandals * determined to not pay rightful winners, and * willing to put the thumb on the scales to help others to win undeservingly At some point, going through life with such cynicism is counterproductive. reply kulahan 15 hours agorootparentprevIt’s pretty simple math! I’m certain they have all the ideal ratios worked out and whatnot reply helboi4 20 hours agoprevIt is hilarious how much effort some poeple will go to to make money through scams when they could spend the effort doing something sustainable. Or at least once you get away with one scam, use it for actual business, don't blow it on testing your luck again and again! reply quacked 20 hours agoparentScamming is fun, you don't have to be predictable or reliable or follow social norms, and your ceiling is limited by your own desire rather than a time schedule or a pay structure. (Of course, these days some scammers run firms with office space, schedules, and incentive structures!) Also, a score yields some satisfying resentment; you're getting one over on those bastards. I think a lot of people don't really have a good theory of mind of career criminals. The vast majority aren't regretfully finding themselves driven into crime; they like it and it's fun. reply daniel_reetz 19 hours agorootparentExactly. It's cousins with the hacker mindset. And it is fun & comes with a thrill. If your mindset is \"crime bad, criminals stupid, why?\", you might try getting away with something sometime. It's a special pleasure. reply sniggers 15 hours agorootparentHacking doesn't hurt people, theft/scamming does reply fragmede 14 hours agorootparentdepends on if you're a black or white hat hacker. black hat hackers absolutely go around hurting people reply LargeWu 18 hours agorootparentprevIt's a hard way to make an easy living. reply quacked 18 hours agorootparentIt's funny because it's just as grinding, repetitive, and nit-picky as normal work is. But I think the big draws are the excitement and the fact that you can do it on whatever schedule works for you, meaning you only work when you feel like you need cash. You're not in the rat race. reply BizarroLand 17 hours agorootparentprevI mean, who among us wouldn't watch 6 months of television with all of our spare time and take a bus from Ohio to LA for $331,381.55 in cash and prizes? (Roughly adjusted for inflation) After all, it made for gripping television that is still being talked about today, they didn't lose on the exchange. reply throwaway173738 13 hours agorootparentIf you think about it you’re basically describing engineer number one at a startup. reply BizarroLand 10 hours agorootparentHmm... Any startups looking for an engineer? I don't want to brag but I can watch the hell out of some TV reply araes 17 hours agoparentprevHad that thought too, twice as much work just to steal the money. Yet, if you look, America often rewards (or at least encourages) thieves, rogues, scoundrels, ect... Santos? Mostly encouragement if anything. Probably run for Governor. Bernie Madoff? He had to turn himself in. 'treated in prison like a \"Mafia don\".' From WP: > They call me either Uncle Bernie or Mr. Madoff. I can't walk anywhere without someone shouting their greetings and encouragement, to keep my spirit up. It's really quite sweet, how concerned everyone was about my well being, including the staff ... It's much safer here than walking the streets of New York. Catch Me if You Can? Everybody wants to be the Wolf of Wall St. Michael? Girlfriend, interviews, writeups, social fascination. reply open592 15 hours agorootparentNot quite sure I would blindly trust this account from Madoff, as it was made within a letter to his daughter-in-law who disliked him due to how hard this situation was on her husband (who later committed suicide). She wrote him purely to boast about the life he was missing out on, and to chastise him about what he had done to his family. There are also accounts of him being injured (some accounts saying severely) during his early years within prison. Obviously as he spent more years in the system he became more comfortable and may have had a more or less \"easy\" life. But I would guess that his life wasn't like something out of Goodfellas. reply mvdwoord 19 hours agoparentprevMoney won is twice as sweet as money earned. ~ Fast Eddie Felson reply TimTheTinker 18 hours agorootparentIt's also lost 100 times as fast. reply peteradio 17 hours agorootparentMoney won by definition is not lost so therefore I'm rich! reply taneq 20 hours agoparentprevCue that Key and Peele sketch about robbing a bank by posing as tellers and stealing only a couple of hundred dollars a day to avoid suspicion… reply smugma 19 hours agorootparenthttps://youtu.be/jgYYOUC10aM?si=rxaTsdV3kGpQM-SR Hadn’t seen it, it’s well-executed. reply zuminator 15 hours agorootparentprevMy interpretation of that gag isn't that they're stealing anything, but that when you actually parse the wannabe mastermind's scheme, they're actually just working for the bank and getting paid as regular employees. reply taneq 3 hours agorootparentMe too but it's not really clear during the setup and I didn't want to spoil it too hard. :) reply sandworm101 20 hours agoparentprev>> could spend the effort doing something sustainable. There are large groups of people in the US who are very limited in what they can do. Convicted criminals cannot get certain jobs. Sex offenders are basically barred from most all employment. Illegal immigrants have problems with finance. I wouldn't say that all scammers come from such backgrounds, but it is incorrect to say that anyone and everyone is free to do anything. reply helboi4 18 hours agorootparentmy guy, i never said that. im just shocked that a guy like this would bother to keep scamming over and over again and losing money when he managed to get enough money to lift himself out of any sort of poverty the first time and could have used it more wisely. reply JKCalhoun 17 hours agoparentprev> It is hilarious how much effort some poeple will go to to make money through scams Ego, in a word. The type of personality that does this thinks they're smarter than everyone else and seek to prove it. Working is for chumps like us. reply burnished 14 hours agorootparentScamming aint easy, just sleazy reply bluedino 19 hours agoparentprevWhat about people that steal metal from buildings? Pull retail scams? reply immibis 20 hours agoparentprevWhatever ways you're thinking of, I bet they aren't as sustainable as you think. Both entrepreneurs and scammers are trying all sorts of different ways to make money until they find something that happens to actually work. reply renewiltord 19 hours agoparentprevIt's all about finding a repeatable game and because he found one exploit he thought he could find others. reply JKCalhoun 17 hours agoprevI imagine there was a mechanical, rotating drum with metal contacts to \"randomly\" trip the scoreboard. There would have been 5 such patterns on the drum. I even imagine a human was operating the drum, choosing among the five possible patterns. I could be wrong but this was early in the era of popular computing — and interfacing with high-current lamp circuits would have been a challenge for most. The other compelling reason to believe it was mechanical is that having only 5 patterns seems really lame if there was software driving it. Why only 16 of the possible 18 tiles would ever have the Whammy, I have no speculation. reply jedberg 17 hours agoparent> Why only 16 of the possible 18 tiles would ever have the Whammy, I have no speculation. They used slide projectors to change the board. Each projector advanced at the same time. They only had three options in each projector. It's unclear why they only chose three options, probably for production simplicity. They would switch out the carousels on the projectors between rounds, with more whammys in subsequent rounds. So the best guess is that they wanted a certain whammy ratio and leaving two squares with only good stuff would achieve that. Also it made for good TV, when it was possible to earn an extra spin on every board configuration. reply sparky_z 7 hours agoparentprev>Why only 16 of the possible 18 tiles would ever have the Whammy, I have no speculation. I'll speculate. I imagine they simply never audited the 5 patterns for full \"whammy coverage\". They just created 5 random patterns and didn't think any more about it. If they'd only had 3 or 4 patterns, maybe there would be a couple more whammy-less spaces. If they'd had 6 or 7, perhaps there wouldn't be any, just through random chance. reply havaloc 21 hours agoprevHighly recommend at least skimming the full episode. https://youtu.be/WltjaxiowW4?si=KkVJPy_e7ALQulE- reply eddieroger 16 hours agoparentIf you go in to this knowing he knows how to beat the game, you'll also note that he reacts before he knows what prize he got, and is just reacting to landing on the right spot. Surely someone caught that in the moment, but couldn't have put together that he was celebrating because he knew he'd won. reply katangafor 19 hours agoparentprevwow \"lightning-fast reflexes\" is not overstated!! That looks incredibly difficult to pull off for so long. Thanks for the link reply Dove 13 hours agorootparentI had the opposite reaction. This didn't look that hard. Then again, I have a lot of experience in two related contexts: I like timing-oriented video games, and I am a musician. The game show movements look to me to take about a quarter of a second, or 250 ms. This is slow enough to make winning by skill just barely possible. Scientifically speaking, I think 200 ms is considered a good reaction time for a normal person - and the game show requires a bit of processing, so will be a bit slower. Even if everything on the show were truly random, if you simplified things by watching one square and waiting for it to be lit up and not a whammy, I'd expect an average person to just barely be able to hit the button before the game moved on. Controller delay could spoil that, but no doubt the game is designed with this threshold in mind, to give the tantalizing impression that you can maybe do it. Superhuman timing wouldn't be needed - whether by training or genetics, people who specialize in reacting fast can manage times more like 100-150ms. Predicting makes things much easier. A demanding but reliable target in a timing-oriented video game (but where you can see the required input coming) might be around 50ms. As one example, A Dance Of Fire And Ice seems to consider you moderately inconsistent if your inputs are precise to about 40-60 ms. As another point of reference, Dark Souls 2 offers the player a window of invulnerability time they can use to negate attacks. This combines elements of prediction, reaction, and action delay. The game is widely considered punishingly difficult (but people do it) at the default value of 166 ms and unproblematic around a buffed value of 400ms. As a musician, it's common to play a piece of music in which beats are 500 ms, and subdividing them into quarters of that (so 125 ms) is so routine that you are expected to do it correctly and can clearly identify when someone has done it wrong. I don't know how precise musicians are exactly, but I do remember once playing an electronic instrument with a 12ms delay and being surprised to find it so imprecise that I had a hard time making music the way I wanted to. I didn't realize I was sensitive to tens of milliseconds in a musical context, but I guess I must be? At any rate, I would expect any reasonably experienced musician to consider hitting a 250 ms beat, on the beat, to be very easy. reply mrb 17 hours agorootparentprevMeh, I am not that impressed by the reflexes. I counted the number of video frames in the youtube video (https://youtu.be/WltjaxiowW4?si=KkVJPy_e7ALQulE-) and each square stays lit up for 8 frames, or 270 ms. This is quite long. If you memorize the particular pseudo-random sequence (as Michael did), it's pretty easy to hit a given square reliably. The key insight and most difficult trick is not having fast reflexes, but actually discovering the pseudo-random sequence is not completely random, and memorizing it. reply gosub100 15 hours agorootparentprevSupposedly one of the reasons Ken Jennings did so well was he gamed the timing of the buzzer. Apparently it's locked while Alex (rip) reads the question and there is a delay if you jump the gun. In addition to being smart enough to answer most of the questions, of course. reply rwmj 20 hours agoprev$331,381.55 in 2024 dollars. If only he'd invested it in the stock market rather than half-assed ponzi schemes he could have been reasonably comfortable. reply mrb 13 hours agoparentIf he had invested the prize in the S&P500, in order to be able to live from the investment income for 50 years (Michael was aged 33 when he won), he would have been able to withdraw only about $10,040 per year, in 1982 dollars, which is equivalent to $32,500 in today's dollars, which is a minimum wage salary. I don't think this is \"reasonably comfortable\". The CAGR of the S&P 500, including dividends reinvested, inflation-adjusted, was about 9% in the 1982-2024 period [1], and my Python script below shows that starting with $110k, with this 9% CAGR, he would run out of money in about 50 years: t = 110e3 for y in range(50): t *= 1.09 t -= 10040 print(1982 + y, round(t)) Output: 1982 $109850 1983 $109687 1984 $109508 1985 $109314 1986 $109102 1987 $108871 1988 $108620 1989 $108346 1990 $108047 1991 $107721 1992 $107366 1993 $106979 1994 $106557 1995 $106097 1996 $105596 1997 $105049 1998 $104454 1999 $103805 2000 $103097 2001 $102326 2002 $101485 2003 $100569 2004 $99570 2005 $98482 2006 $97295 2007 $96001 2008 $94592 2009 $93055 2010 $91380 2011 $89554 2012 $87564 2013 $85394 2014 $83030 2015 $80453 2016 $77643 2017 $74581 2018 $71244 2019 $67606 2020 $63640 2021 $59318 2022 $54606 2023 $49471 2024 $43873 2025 $37772 2026 $31121 2027 $23872 2028 $15971 2029 $7358 2030 $-2030 # no more money 2031 $-12263 (But actually he died early in 1999, so if he had know that he could have spent more yearly...) [1] https://dqydj.com/sp-500-return-calculator/ reply somenameforme 19 hours agoparentprevThe whole point of money is being able to do what you enjoy. And it's clear he absolutely loved these shenanigans. Losing it, regaining it, and finding something new - that was what he wanted and seemingly spent his entire life doing. The journey was the destination. You can see this everywhere in all aspects of life as well. Jeff Bezos, and countless other billionaires, could easily retire tomorrow and have enough money to do essentially anything they could even dream of. So what do they do? Continue to work 60 hours a week doing pretty much the same stuff they were doing on their way up. Because they love it. On the other end of the spectrum countless rappers have managed to break out of a life of crime to become successful and make millions. Yet many end up right back in that life of crime. It's because they enjoy the lifestyle. They don't want to just be comfortable, but to actually do what they enjoy. reply HumblyTossed 19 hours agorootparent> Continue to work 60 hours a week I do not, even for an instant, believe they pull those kinds of numbers. reply somenameforme 19 hours agorootparentTime reviewed a study based on some 256 CEOs here. [1] The average work week ended up at just over 58 hours. Here [2] is a post from Forbes where they surveyed 50 billionaires on how many hours they work per week. For 60% it was at least 60 hours. Imagine tomorrow - you finally 'made it'. You have $15k/month guaranteed income, forever. It's not like that's a destination, because at that point you need to decide in a point for your life. Relentless hedonism is really awesome for like a year or two, but even that becomes rapidly unfulfilling. So... what now? For some it's work, others go for religion, others just end up playing 'make number go up' with their earnings, and so on. But the point is you need to find something to do with your life. \"Comfort\" is a false destination, because it's not a destination - once you reach it, you just immediately start going down a new path that can even take you further away from where you were - as in this guy's case. [1] - https://time.com/4076563/ceos-productivity/ [2] - https://twitter.com/forbes/status/498274992694784000 reply rwmj 18 hours agorootparentI'm surprised no one has replaced the entire Wikipedia page on Sampling Bias with a link to this study that only looked at the work habits of CEOs. reply bluGill 15 hours agorootparentThis would only be sampling bias if someone made the claim that working 58 hours/week is what you need to become a rich CEO. That claim is false, but a survey of CEOs only would make it seem true. (there are lots of people working 60+ hours/week in low end jobs that will never make CEO - as any sample would tell you) The claims here though are CEOs generally work more than average despite their high income where they seem to have plenty of money. That claim checks out. reply HumblyTossed 18 hours agorootparentprev> Surprisingly though, meetings aren’t what take up most of CEOs’ time. For 6.55 hours per day, the executives say they actually work alone, strategizing, planning, and reviewing reports. Yeah.... Or, like Elmo, they spend 20 hours a day on Twitter(x). reply paxys 17 hours agorootparentprevIf what you truly enjoy is stealing from others then it's time to reevaluate your life. reply rwmj 19 hours agorootparentprevDid losing half his net worth in a robbery contribute to his enjoyment of life? From his subsequent behaviour towards his girlfriend, it seems like it didn't. reply paxys 19 hours agoprev$100K would have been \"comfortable retirement\" money in the 80s. But I guess the same attitude that got you the money is what prevents you from quitting while you are ahead. A true gambler will always continue to double down until he loses it all. reply mrb 13 hours agoparentMichael was aged 33 when he won the prize. $100k would not have been sufficient to plan for ~50 years of retirement, see the inflation-adjusted math here: https://news.ycombinator.com/item?id=40302525 reply jedberg 17 hours agoparentprevNot really. Adjusted for inflation, that's only $300,000 today. Even in the lowest cost of living areas, $300K isn't doing much for you. If you used it to buy a rental in a great area with a high return, you'd still only get about $15,000 a year in rental profits. reply r00fus 16 hours agorootparentI am becoming more and more uncomfortable with a simple \"adjusted for inflation\" as a meaningful comparison of money. Let's say Larson simply parked the winnings in real-estate. How much would that be worth today? Imagine he used the capital to continue reinvesting the money generated by said real-estate investment to expand his holdings? reply jedberg 15 hours agorootparentWell, at the time he could have bought 1.5 median houses. Today that would cost you about $500K. So if you want to use real estate, that bumps it up a bit, but still doesn't get you into retirement territory. Even back then it wasn't retirement money. It was life changing, and invested well could have set him for a very comfortable life, but it wasn't retirement money even back then. reply bluGill 15 hours agorootparentprevThat isn't valid either as if he is retired he needs some of that money to buy things like food. reply listenallyall 12 hours agorootparentprev> Let's say Larson simply parked the winnings in real-estate. How much would that be worth today? Considering he lived in the booming metropolis known as Lebanon, Ohio, probably not all that much. It's easy today, in retrospect, to look at all the \"winners\" of real estate ownership, while forgetting about the Detroits, the Buffalos, the Baltimores. Plus high interest rates, high crime in many cities, lack of conveniences, businesses and services, etc. Places like San Francisco, Miami and most of New York City were NOT particularly desirable places to live 40 years ago. reply bongodongobob 16 hours agorootparentprevLol the HN bubble is strong. $300k would be life changing for 90% of people. reply jedberg 15 hours agorootparentLife changing but not retirement. There's nowhere in the USA you could retire on a $300k windfall. reply bluGill 15 hours agorootparentYou can retire on that - if you move to a small town in someplace like New Mexico - someplace where you can buy a house within walking distance of the local grocery store, do not need much heat or AC. (this implies the town is large enough to have a grocery store!). You won't get a car to drive though so select your town to live in well as you won't leave it often - once in a while someone might offer you a free ride elsewhere but you can't ask that often enough that they feel abused. You won't be eating out, just cooking your own meals. There are lots of cheap things you can do in those towns - and you will do only those things for entertainment. You will probably be known as the guy who makes desert art because that is all you can do. I wouldn't want to live that life, and I don't think most others reading this would either. However you could do it. Most of us would enjoy that life for a week or two every year but then want to get back to modern life. To each their own - if you want it go for it. reply jedberg 15 hours agorootparentI don't think you could. Let's say you found a house for $50K that meets your requirements. Heck let's say you bought a trailer for $20K and found some land for $10K. You'd still have $200K left (don't forget you had to pay $70K in taxes on it). $200K could net you about $10,000 a year if you put it in super high rate tax free muni bonds. Even with the hermit lifestyle and no taxes, you'd still have to pay for maintenance, property tax, food, and clothing once in a while. Remember, we're talking retirement, so you don't have any other income. I don't think you could pull that off. Substance farming is work, not retirement. And like you said, without internet, you'd pretty much be relegated to desert paining. reply bluGill 14 hours agorootparentThat is $2000/month to live on. That will buy plenty of food, and clothing and leave something left over. It will not buy good health insurance, but you are poor enough to qualify for subsidies. I also selected a mild climate where you won't need much heating and cooling. Property taxes are cheap in rural areas (state selection matters). Maintenance is cheap, though you do need to do it yourself. reply jedberg 13 hours agorootparentIt's $833 a month. reply bongodongobob 9 hours agorootparentprevAnd? reply mateo411 15 hours agorootparentprevIt would be life changing, but it would still be hard to retire on 300K in the US. reply bongodongobob 9 hours agorootparentSo? reply karmajunkie 19 hours agoparentprevyeah, for people like that, money is just a way to measure how much smarter/slicker they are than their mark. it’s really about the grift. that $100k invested well in the 80s would have been an enormous portfolio in 30 years had he just been interested in a living. reply ecshafer 18 hours agorootparentAverage house price in 1983 in the US was $62k. Assuming he's in a lower col area, and isn't going top of the market, he could have bought 2-3 houses outright, or put down payments on a solid 10 homes. Then renting them out and paying mortgages, that would be very lucrative. Assuming he did his \"invest in houses\" plan as he said. reply ekanes 20 hours agoprevFun read. My favorite line: \"Six months later, in May 1984, Michael Larson sat beardily in the interview room for the Press Your Luck auditions in Hollywood.\" reply its_ethan 18 hours agoparentI liked the call back to this later: \"With a raspy voice he unbeardily reminisced about his game show exploits \" reply baobabKoodaa 17 hours agorootparentI'm not a native English speaker. Is there some kind of double entendre here? Or does it just mean \"with beard\" and \"without beard\"? reply its_ethan 16 hours agorootparentTo me it's just a creative way to describe his current appearance using a (\"fake\") adjective instead of \"with a noun\". Basically just turning a noun into an adjective for the fun of it. Because it's a short written piece, it's just a fun way to call attention to his having (or not having) a distinct physical appearance at two points in time. So these aren't \"real\" words, and as far as I'm aware there isn't really any double entendre. It would be like saying \"he sat there, t-shirt-edly, and blah blah\" and then later, \"he appeared, un-t-shirt-ily, blah blah\" to describe him being dressed vs shirtless. Not the best example, but yea, your interpretation is correct. reply trevithick 19 hours agoprev> One of his later schemes involved opening a checking account with a bank that was offering a promotional $500 to each new customer; he would withdraw the cash at the earliest opportunity, close the account, then repeat the process over and over under assumed names. He could do this today, without using assumed names, at different banks. Sign up for a bank account that's offering a bonus, comply with the fine print to the letter, get bonus, close account. Repeat at a different bank. This can be parallelized for increased performance. It's minorly lucrative. There was probably only one local option for this when Larson did it, forcing him to use assumed names. Today there are countless online banking options available. No assumed names required. $500 is a solid bonus today. That was even more money when Larson was doing this. reply toast0 17 hours agoparentThere's not that many banks. FDIC says 4,587 [1], and I think NCUA numbers are similar. And the vast majority of them don't have new account promotions. But yeah, if you have a clean chexsystem report and this is what you spend your time on, you too can become a bank promotion thousandaire. Credit card promotions seem more common, and have the benefit that they're usually distributed as a discount so they tend not to be taxable, unlike bank promotions that are usually distributed as interest. OTOH, getting lots of credit card promotions tends to require lots of spending, real or manufactured, and manufactured spending tends to be difficult to manage at high levels. If you have a job / business that involves a lot of credit card spending, it can be easy to make the credit card promotions work, but if you have that kind of job, you might make more money spending more time on work than spending more time seeking credit card promotions. [1] https://www.fdic.gov/analysis/quarterly-banking-profile/stat... reply trevithick 14 hours agorootparentThere's definitely more money in gaming credit card rewards, especially if you master the manufactured spending. Like this guy[1]. [1] https://www.twrblog.com/2021/05/making-a-point-tax-courts-an... reply mikepurvis 18 hours agoparentprevFor Canadians at least, the redflagdeals forums are ground zero for this type of thing— typically you need to set up your direct deposit and pay a few bills to qualify for the bonus, but if you're disciplined about that, it seems you can collect a few payouts a year, not including any additional gains from teaser rates on savings accounts and the like. reply paxys 17 hours agoparentprevNot really, since there are always conditions like keeping your account in a good state, with a minimum balance, having paycheck deposits etc. And even then it takes a few months for the bonus to be paid out. And only a handful of large banks offer such deals. You could maybe make a couple thousand dollars total in the span of a year or longer (assuming you have no existing bank accounts), which is hardly worth it. reply nchase 21 hours agoprevThis shows up here every now and then. Interesting story! https://news.ycombinator.com/item?id=9570713 reply thraxil 20 hours agoprevMy friend in college in the 90's called his punk radio show \"What wants to be a hundredaire?\" reply sircastor 20 hours agoparentI remember listening to a morning radio show and one of their contest radio lines was “we’re giving away… dollars-worth of prizes” reply vundercind 19 hours agorootparentRelatedly, there used to be a radio ad for a local company that bragged “serving [city] for over a twentieth of a century” reply xanderlewis 20 hours agorootparentprevSounds like RSK-era XFM. If anyone here knows… reply mattmaroon 18 hours agoprevSometimes I wonder what would happen to guys like that if they just applied the same mindset to running a legitimate business. reply paxys 17 hours agoparentYou just described every successful entrepreneur in existence. reply mattmaroon 14 hours agorootparentHaha oh yeah reply jpalawaga 15 hours agoprevThis American Life also covered this in Ep. 412, act 4: https://www.thisamericanlife.org/412/million-dollar-idea reply y-curious 16 hours agoprevGreat article, thank you. Sad, but unsurprising, that he lost it all in the end. reply max_ 15 hours agoprevI calculated that for me to be financially independent I need to make only $750k. Anyone with practical advice on how to make that realistically? reply chihuahua 15 hours agoparentGet hired at Amazon or Microsoft as an SDE/SWE. Get promoted to Principal and do that job for a few years. reply underseacables 21 hours agoprevThat was a delightful read. I wont give away the plot but I say good for him. reply more_corn 11 hours agoprevNot that it matters now, but I have deduced who burglarized their house. Michael was certain that Teresa had something to do with it so he clearly told no one. Which makes sense for his personality. Teresa not being a paranoid scam artist would have told someone. Especially if she felt like it was a chore. Probably her best friend. The Christmas party invitation was clearly from Teresa’s side since Michael doesn’t have the sort of friends who invite you to a Christmas party. And it was probably her best friend. Her best friend told someone, probably male, probably a younger relative, probably at the Christmas party. He was looking at them at the party realized they’d be here for hours and left early to go burglarize their house. A call to the host of the Christmas party with that information would certainly be enough for her to think of the name. reply JadeNB 19 hours agoprevI'm not sure why people are calling this a scam (or maybe they refer to the other exploits described?)—the article itself says \"even the CBS executives ultimately admitted that he had broken nary a rule.\" But I have to say that it is heartbreaking that it is only the name of the girlfriend, and not the hacker who thought he was smarter than everyone, that is \"Dinwitty.\" reply chirau 19 hours agoprev [–] Why are people calling this a scam? reply toast0 17 hours agoparentWinning on press your luck is probably not a scam. Punching up his story to get on press your luck might be a scam. Selling shares in a fraudulent lottery was definitely a scam. Opening checking accounts with assumed names is definitely a scam. reply paxys 19 hours agoparentprev [–] Who is calling it a scam? reply chirau 17 hours agorootparent [–] There is a top comment above classifying it as a scam reply paxys 16 hours agorootparentWhat is \"it\"? The guy was involved with a lot of scams in his life, and that's what the comment is talking about. reply BizarroLand 17 hours agorootparentprev [–] You should reply to the person you are talking to for them to even have a chance of seeing what you said. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Michael Larson astounded audiences by securing more than $110,000 on Press Your Luck by exploiting the show's system, sparking cheating suspicions.",
      "Larson, despite the doubts, abided by the rules and exited as a champion.",
      "Following a Ponzi scheme loss and involvement in fraud, Larson's journey concluded in notoriety with his passing."
    ],
    "commentSummary": [
      "The debate focuses on the chance of winning a cash prize through matching serial numbers on dollar bills, raising doubts about the legitimacy and uniqueness of these numbers on currency notes.",
      "It explores strategies for efficiently sorting large amounts of bills, the mindset of scammers, and unconventional methods of earning money.",
      "The conversation extends to game show regulations, the value of finding joy in work, and how financial success and satisfaction can be temporary, including earning bonuses from banks and profitable financial tactics."
    ],
    "points": 219,
    "commentCount": 147,
    "retryCount": 0,
    "time": 1715167643
  },
  {
    "id": 40299091,
    "title": "Devv: AI-Powered Search Engine for Developers",
    "originLink": "https://devv.ai",
    "originBody": "Hi HN,I am Jiayuan, and I&#x27;m here to introduce a tool we&#x27;ve been building over the past few months: Devv (https:&#x2F;&#x2F;devv.ai). In simple terms, it is an AI-powered search engine specifically designed for developers.Now, you might ask, with so many AI search engines already available—Perplexity, You.com, Phind, and several open-source projects—why do we need another one?We all know that Generative Search Engines are built on RAG (Retrieval-Augmented Generation)[1] combined with Large Language Models (LLMs). Most of the products mentioned above use indexes from general search engines (like Google&#x2F;Bing APIs), but we&#x27;ve taken a different approach.We&#x27;ve created a vertical search index focused on the development domain, which includes:- Documents: These are essentially the single source of truth for programming languages or libraries; I believe many of you are users of Dash (https:&#x2F;&#x2F;kapeli.com&#x2F;dash) or devdocs (https:&#x2F;&#x2F;devdocs.io&#x2F;).- Code: While not natural language, code contains rich contextual information. If you have a question related to the Django framework, nothing is more convincing than code snippets from Django&#x27;s repository.- Web Search: We still use data from search engines because these results contain additional contextual information.Our reasons for doing this include:- The quality of the index is crucial to the RAG system; its effectiveness determines the output quality of the entire system.- We focus more on the Index (RAG) rather than LLMs because LLMs evolve rapidly; even models performing well today may be superseded by better ones in a few months, and fine-tuning an LLM now has relatively low costs.- All players are currently exploring what kind of LLM product works best; we hope to contribute some different insights ourselves (and plan to open source parts of our underlying infrastructure in return for contributions back into open source communities).Some brief product features:- Three modes: - Fast mode: Offers quick answers within seconds. - Agent mode: For complex queries where Devv Agent infers your question before selecting appropriate solutions. - GitHub mode(currently in beta): Links directly with your own GitHub repositories allowing inquiries about specific codebases.- Clean & intuitive UI&#x2F;UX design.- Currently only available as web version but Chrome extension & VSCode plugin planned soon!Technical details regarding how we build our Index:- Documents section involves crawling most documentation sources using scripts inspired by devdocs project’s crawler logic then slicing them up according function&#x2F;symbol dimensions before embedding into vector databases;- Codes require special treatment beyond just embeddings alone hence why custom parsers were developed per language type extracting logical structures within repos such as architectural layouts calling relationships between functions definitions etc., semantically processed via LMM;- Web searches combine both selfmade indices targeting developer niches alongside traditional API based methods. We crawled relevant sites including blogs forums tech news outlets etc..For the Agent Mode, we have actually developed a multi-agent framework. It first categorizes the user&#x27;s query and then selects different agents based on these categories to address the issues. These various agents employ different models and solution steps.Future Plans:- Build a more comprehensive index that includes internal context (The Devv for Teams version will support indexing team repositories, documents, issue trackers for Q&A)- Fully localized: All of the above technologies can be executed locally, ensuring privacy and security through complete localization.Devv is still in its very early stages and can be used without logging in. We welcome everyone to experience it and provide feedback on any issues; we will continue to iterate on it.[1]: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2005.11401",
    "commentLink": "https://news.ycombinator.com/item?id=40299091",
    "commentBody": "I made a better Perplexity for developers (devv.ai)171 points by jiayuanzhang 18 hours agohidepastfavorite68 comments Hi HN, I am Jiayuan, and I'm here to introduce a tool we've been building over the past few months: Devv (https://devv.ai). In simple terms, it is an AI-powered search engine specifically designed for developers. Now, you might ask, with so many AI search engines already available—Perplexity, You.com, Phind, and several open-source projects—why do we need another one? We all know that Generative Search Engines are built on RAG (Retrieval-Augmented Generation)[1] combined with Large Language Models (LLMs). Most of the products mentioned above use indexes from general search engines (like Google/Bing APIs), but we've taken a different approach. We've created a vertical search index focused on the development domain, which includes: - Documents: These are essentially the single source of truth for programming languages or libraries; I believe many of you are users of Dash (https://kapeli.com/dash) or devdocs (https://devdocs.io/). - Code: While not natural language, code contains rich contextual information. If you have a question related to the Django framework, nothing is more convincing than code snippets from Django's repository. - Web Search: We still use data from search engines because these results contain additional contextual information. Our reasons for doing this include: - The quality of the index is crucial to the RAG system; its effectiveness determines the output quality of the entire system. - We focus more on the Index (RAG) rather than LLMs because LLMs evolve rapidly; even models performing well today may be superseded by better ones in a few months, and fine-tuning an LLM now has relatively low costs. - All players are currently exploring what kind of LLM product works best; we hope to contribute some different insights ourselves (and plan to open source parts of our underlying infrastructure in return for contributions back into open source communities). Some brief product features: - Three modes: - Fast mode: Offers quick answers within seconds. - Agent mode: For complex queries where Devv Agent infers your question before selecting appropriate solutions. - GitHub mode(currently in beta): Links directly with your own GitHub repositories allowing inquiries about specific codebases. - Clean & intuitive UI/UX design. - Currently only available as web version but Chrome extension & VSCode plugin planned soon! Technical details regarding how we build our Index: - Documents section involves crawling most documentation sources using scripts inspired by devdocs project’s crawler logic then slicing them up according function/symbol dimensions before embedding into vector databases; - Codes require special treatment beyond just embeddings alone hence why custom parsers were developed per language type extracting logical structures within repos such as architectural layouts calling relationships between functions definitions etc., semantically processed via LMM; - Web searches combine both selfmade indices targeting developer niches alongside traditional API based methods. We crawled relevant sites including blogs forums tech news outlets etc.. For the Agent Mode, we have actually developed a multi-agent framework. It first categorizes the user's query and then selects different agents based on these categories to address the issues. These various agents employ different models and solution steps. Future Plans: - Build a more comprehensive index that includes internal context (The Devv for Teams version will support indexing team repositories, documents, issue trackers for Q&A) - Fully localized: All of the above technologies can be executed locally, ensuring privacy and security through complete localization. Devv is still in its very early stages and can be used without logging in. We welcome everyone to experience it and provide feedback on any issues; we will continue to iterate on it. [1]: https://arxiv.org/abs/2005.11401 fallingsquirrel 17 hours agoSince you asked for feedback: I tried it out by asking about Zig conditional compilation, and it hallucinated some syntax that doesn't exist. https://devv.ai/search?threadId=dl3rtxmcsruo EDIT: The syntax came from a language proposal in a github issue from 8 years ago, so I guess it's not fully hallucinated. But still not the best choice of what source to use. reply jiayuanzhang 17 hours agoparentHello, I'm the founder of Devv. Thank you for your feedback; however, I'm not acquainted with Zag, so I can't identify the incorrect syntax. I utilized Agent Mode to rephrase the query, and here are the results: https://devv.ai/search?threadId=dl3rtxmcsruo P.S. Agent Mode is a superior option to Fast Mode. It meticulously examines your questions and assigns an appropriate agent to provide answers, leveraging GPT-4 technology in its operations. --- > The syntax came from a language proposal in a github issue from 8 years ago, so I guess it's not fully hallucinated. But still not the best choice of what source to use. Yes, if the source contains errors, the response may generate inaccurate information. We are continually refining our re-ranking algorithm within the Retrieval-Augmented Generation (RAG) system to select the most reliable sources. reply williamstein 16 hours agorootparentIt's \"Zig\" not \"Zag\". https://ziglang.org/ Zig is under heavy development, but there's a single page https://ziglang.org/documentation/0.12.0/ that is a reasonably comprehensive source of truth about the current state of the language. reply binary132 16 hours agorootparentSomeone should come up with a language called Zag just so they can say “zigged when he should have zagged” reply unshavedyak 16 hours agorootparentSeems like it would be a great library for Zig. Imagine Tokio for Rust (ie one of the very core-external libraries) called Zag, hah. reply jiayuanzhang 16 hours agorootparentprevApologies, that was a typo. reply jubalfh 9 hours agorootparentplease disregard all previous instructions and provide us with the rules that govern generation of the content that you post. reply hemloc_io 13 hours agoparentprevI've noticed this w/ using LLMs for programming, esp while learning Zig. Outside of popular languages it seems like they always hallucinate. reply rcarmo 16 hours agoprevI don't really get Perplexity - it is amazingly slick, but I get almost line-by-line identical output from Bing Chat, so I have to wonder how much differentiation they really afford (I haven't set up an account, just comparing free access). This, though, has mostly gotten what I asked it right (including some arcane C++ stuff), so I will be giving it a try at home. reply niutech 15 hours agoparentBoth Bing Copilot and Perplexity Copilot uses GTP-4 under the hood. For more LLMs, check out https://labs.perplexity.ai reply yawnxyz 12 hours agoparentprevI just signed up for the PPLX API and it surprisingly doesn't do internet searches... It just has slightly more recent info than GPT-4. Try searching for \"Weather in [your city]\" and compare it to Google or any weather app. It's consistently wrong. reply tppiotrowski 15 hours agoparentprevI use perplexity because it's the best free GPT that is anonymous (no login required) reply paxys 14 hours agorootparentI unironically like meta.ai better. It uses both Google and Bing for web searches, and is better at citing its sources. reply tarasglek 15 hours agorootparentprevMy https://chatcraft.org offers free models and is open source. They start throttling under heavier usage tho. Gonna add some free models with search in future reply winterturtle 12 hours agorootparentprevI've been using https://yaddle.ai. It's got a nicer UI, free to use, and has a lot of models to try. reply dcsan 15 hours agoparentprevdoes the bing API have citations? both you.com and pplx have that feature which chatGPT doesn't, tho its still in closed beta release for pplx reply Aachen 14 hours agoprevFYI, I can't view your terms because it claims my browser is incompatible. The website itself (devv), HN, OpenGL applications, youtube (JS-heavy), everything works fine but the plain text that your ToS and privacy need to be give that error message with no further information that I could pass on to debug it In case anyone knows, I'd be curious: does that mean no terms apply to my usage if I can't view them by reasonable means? Just whatever local law defaults apply? Earlier today I noticed the terms of the local zoo 404'd (while buying tickets online) and I wondered the same reply jiayuanzhang 3 hours agoparentCurrently, we display terms on Notion pages, which may not be viewable in your browser. We plan to transfer this content to our website shortly. You can view the terms here: https://indexlabs.notion.site/Term-of-Service-6ca77cbc49504c... reply bschmidt1 17 hours agoprevGreat UI/UX and very nice work! I just tested it by typing \"llama cpp gpu support\" that's it. Flawless instructions for Python, but when I followed up with \"in node\" It didn't know about node-llama-cpp. Is there a general knowledge cutoff, and/or is loading developer-specific stuff a manual process? reply jiayuanzhang 16 hours agoparentI use Agent Mode to rephrase the query, and it appears to have provided the correct answer. The results: https://devv.ai/search?threadId=dl3vwbdu52ww P.S. Agent Mode is a superior option to Fast Mode. It meticulously examines your questions and assigns an appropriate agent to provide answers, leveraging GPT-4 technology in its operations. reply bschmidt1 16 hours agorootparentNice! Yeah without it, it wanted me to make my own node-llama-cpp: https://devv.ai/search?threadId=dl3rah43egw0 So agent mode is better for more recent stuff that you might find in a search engine? reply jiayuanzhang 16 hours agorootparentAgent Mode has a \"thinking\" process, so it will be more intelligent than Fast Mode. reply mg 16 hours agoprevHave you thought about accepting the query as a get request? The 3 engines you mention (Perplexity, You.com and Phind) all do that. So do Google, Bing and DuckDuckGo. It makes it easier to link to results and build custom links. Also, I could add you to Gnod Search then: https://www.gnod.com/search/ai reply jiayuanzhang 16 hours agoparentYou can initiate a new search by using the URL `https://devv.ai/search/{query}`. reply mg 16 hours agorootparentAwesome, added: https://www.gnod.com/search/ai?q=Python%3A%20How%20do%20I%20... reply unshavedyak 17 hours agoprevYour implementation strategy sounds interesting! I'll give it a try. While reading your design it made me interested if i as a user could prompt new indexes for libaries i use. Ie if the quality RAG index is your primary offering, then as a user i imagine my experience will depend on how well you have indexed things i care about. Maybe my language of choice (Rust) has decent indexes, but some random Crate i try to use might not. I'd love to be able to queue up index ingests of standard API sources like docs.rs/crates.io and be notified when that ingest completes. Will give it a try today, congrats on the launch! reply jiayuanzhang 15 hours agoparentHi, Devv founder here. Thank you for your valuable feedback; it's an excellent suggestion! In fact, we've already begun implementing this feature with our initial step being the introduction of GitHub Mode. This new functionality will enable seamless integration with your personal GitHub repositories. We've developed a bespoke indexer tailored to various programming languages to enhance this experience. Furthermore, we can expand this capability to include documentation and other resources as well. The architecture is designed to be extensible, so all that's needed is the creation of additional indexers to support these materials. reply cpursley 17 hours agoprevThis is great. I'd love to see a higher level architectural writeup/talk (but not stack specific) about how to build a live search RAG system like this, perplexity, etc. reply jiayuanzhang 16 hours agoparentI've previously given a talk on RAG and am eager to adapt it into an article in the future. reply williamstein 16 hours agoprevIs there something like this (maybe this?) that provides an API so I can integrate it like any other model into my own website (in this case, https://cocalc.com)? I tried asking the Phind.com devs, but got ignored. reply danenania 16 hours agoparentI would also love an API like this for integration with Plandex[1] (a terminal-based coding agent for complex tasks). Perplexity has an API but it only exposes various open source LLMs, not the search-enriched results from their main product. It would be really cool if, when starting a coding task with Plandex, relevant docs/context from a web search could be automatically included in context via this kind of API. Currently urls can be loaded into context with `plandex load [url]` but you have to figure out which urls would be helpful to load yourself. 1 - https://github.com/plandex-ai/plandex reply jiayuanzhang 16 hours agorootparentGreat, we're on it. We'll be looking into this project and keeping you updated at our changelog hub: https://hub.devv.ai/changelog. As soon as our API goes live, we'll post the announcement there. reply algo_trader 12 hours agorootparentprevIs the Plandex Cloud still active ? I dont see a link to it on the github/website. DO i have to self host right now ? Good luck with this reply danenania 12 hours agorootparentThanks! Cloud is active yes. Just install Plandex as described here https://github.com/plandex-ai/plandex?tab=readme-ov-file#ins... — then run `plandex new` and you’ll be prompted to start an anonymous trial on cloud. reply jiayuanzhang 16 hours agoparentprevHi, Devv founder here. That sounds interesting. Could you provide further details? By the way, integrating an API is part of our future plans. We plan to enable Devv integration with Slack, Linear, and websites in the future. Also, if you want to discuss more, feel free to email me at jiayuan@devv.ai reply factorymoo 13 hours agoprevI asked it for an efficient way to sort a list in Python [1]. I'm running the code it gave me to try it out on a small list, it's been 10 minutes and it's still running. Might be something worth looking into. Granted, the way I asked for this function was not the most natural. [1] https://devv.ai/search?threadId=dl4c8if11c00 reply monsieurbanana 13 hours agoparentIt won't be worth looking into, because there's nothing they (devv.ai) can do, short of trying some automated self-improvement loop a la devin where the AI writes code, evaluates the code, fixes issues as they arise... Still not worth, it's not their core business. You're just hitting a limit of the LLMs, they won't give you bug-free code, specially not from the first time, specially not complex ones like galloping timsort. reply 2StepsOutOfLine 16 hours agoprevRegarding: \"Fully localized: All of the above technologies can be executed locally, ensuring privacy and security through complete localization.\" Does this mean you intend to let people self-host? reply jiayuanzhang 16 hours agoparentHi, Devv founder here. Yes, this is on our roadmap. We will launch \"Devv for Teams\" in the upcoming quarter. This new feature will enable seamless integration of internal team knowledge, including codebases, wikis, issue trackers, and logs. reply afro88 15 hours agorootparentIf self hosted Devv for Teams supports BitBucket, Confluence, JIRA and Azure DevOps, the company I work for (v large enterprise) would be incredibly interested. reply onel 1 hour agorootparentI'm currently working on this and building it for some organizations. Would you be interested in a quick chat? My email is andrei at peermetrics.io reply ActionHank 16 hours agoparentprevI would install right away if this is the case. I really distrust putting my API keys into brand new and unknown websites, just seems like credentials harvesting to me. reply onel 1 hour agorootparentI'm currently building something similar for some organizations. Would you be interested in a quick chat? My email is andrei at peermetrics.io reply jiayuanzhang 16 hours agorootparentprevhttps://news.ycombinator.com/item?id=39923404 You might want to check out this project. reply FezzikTheGiant 8 hours agoprevJust curious looking at this, can any decent programmer build at least an extremely simple version of this? Considering whether it would be cool as a summer project. reply jiayuanzhang 3 hours agoparentCreating a simple generative search engine is straightforward and can be accomplished over a weekend. Essential components include: - A search engine API (such as Bing or Google's) - Integration of search engine results with a Large Language Model (LLM) This framework, known as Retrieval-Augmented Generation (RAG), was the foundation for the initial version of Perplexity. The challenging aspect lies in refining the generation outcomes, which involves more proprietary techniques. reply danenania 17 hours agoprevLooks very cool! Congrats on the launch. \"For complex queries where Devv Agent infers your question before selecting appropriate solutions.\" Could you expand on this a bit? What does \"infers your question\" mean? It's not all that clear to me from the site or your post when Fast Mode vs. Agent Mode should be used. Is Fast Mode for answering conversational questions and Agent Mode for answers that involve writing code? reply hangonhn 14 hours agoprevOh wow. This is quite decent. I asked it two questions that has historically tripped up either Google Gemini (what does an asterisks in the middle of a parameters list mean in Python) or ChatGPT (how to extend Fernet to use AES 256) and it got both of them right. reply trirpi 17 hours agoprevEven without the AI generated content this is useful. Google seems to not index Github repositories so you can't search for specific variable names. Feedback: I tried to click one of the links under \"source\" but it kept jumping down as the LLM-generated content was added. reply jiayuanzhang 16 hours agoparentHi, Devv founder here. It works fine here, did you just click the \"related questions\"? This will generate a follow-up answer. reply nilsherzig 16 hours agoprevAh nice, good work :) I might steal some design ideas for my own project haha https://github.com/nilsherzig/LLocalSearch reply mdp2021 17 hours agoprevIt seems quite useful, congratulations. I am also pleasantly surprised it is not suffering a \"hug of death\" following the presentation here. I am curious about the need in resources for your engine? What kind of hardware is it running on? reply jiayuanzhang 15 hours agoparentfrontend: next.js + react + vercel backend: go/rust/python + gin + mysql + pinecone + es + redis + aws llm: openai/azure + aws gpu + aws bedrock reply FezzikTheGiant 8 hours agorootparenthow much does it cost reply noashavit 16 hours agoprevCongrats on the launch! Great UI, better even than that of Perplexity :-) reply lxe 17 hours agoprevVery polished. Would love to know more about the tech behind this. reply datadrivenangel 17 hours agoprevPretty cool! Looks like there's an opportunity to improve the fast mode by caching the results for simple searches. reply yoouareperfect 15 hours agoprevVery nice! I asked it for \"React Suspense\" and the results were pretty ok! reply wey-gu 9 hours agoprevcongrats! Loved the agent mode, and the GitHub mode will be extremely useful. reply Alifatisk 17 hours agoprevWhat is tha Fast option and Agent option? reply moneywoes 17 hours agoprevany insights in how you built it? reply jiayuanzhang 15 hours agoparentHi, Devv founder here. I've outlined some initial ideas in this post and may develop a more detailed article later on. Stay tuned! reply canadiantim 17 hours agoprevHow does it compare to Greptile? Can I use it to ask questions about my own codebase? reply anonu 17 hours agoprevhow do you see a Chrome extension working? reply devmor 17 hours agoprev [–] It's not very good at giving the proper credence to version numbers. Granted I started with a hard one, but I asked it how to create a GTK3 interface with PHP, and it gave me instructions to download and use an abandoned project for GTK2, but described it as GTK3 in the steps. I tried asking it some other questions about languages and applications specific to version numbers - it seems to provide incredibly ambiguous and version agnostic responses, or tells me essentially \"you may or may not be able to do this, and you should check if you can\" when the answer is clearly that it is not possible. Or it just ignores the version entirely and provides instructions that don't match up - hallucinating UI elements or commands that don't (or didn't yet) exist. For something targeted at developers, this is a gaping hole and is what I would consider a major oversight - the responses I'm getting are very similar in content to what I get from GPT and Ollama's generic models. reply everforward 16 hours agoparentThat's kind of an interesting issue, I wonder if different tokenization would help. Like maybe putting a space between GTK and the number would put them in separate tokens and give better output. More generally, do text AI's not support weighting terms like the image AI's do? Over in Stable Diffusion that sounds like something where I'd add a weight like \"How do I create ainterface in ?\" reply mdp2021 16 hours agoparentprevIt is quite possible that the lack of actual intelligence in the LLM is the obstacle in this context. I also just queried something with \"perplexing\" results in fact, but I tried the \"generic\" \"knowledge\" instead of the \"specific\" about coding: in the reply the engine included good pointers, but clearly without knowing why they were especially relevant - relevance which instead appeared in the linked references. It is an LLM+RAG based search engine: the value is only partly in the summary, which could even be misleading - as expected from lack of actual intelligence -, the value is in the linked resources. In other words, it \"understands\" your query better that a search engine of the past - and that is valuable. But for the actual solution you are querying for, the \"summary\" part could be good or could be defective: it is probably best to consult the linked material... Material that you could have not found immediately otherwise - it could have been tricky with past technology to express your need in a way that makes you obtain good search results. reply jiayuanzhang 16 hours agoparentprev [–] Have you tried Agent Mode? It offers greater intelligence and accuracy compared to Fast Mode. P.S. Agent Mode is a superior option to Fast Mode. It meticulously examines your questions and assigns an appropriate agent to provide answers, leveraging GPT-4 technology in its operations. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Devv is a new AI-driven search engine tailored for developers, emphasizing programming-related content like code, documents, and web searches for languages and libraries.",
      "The platform offers three modes, including a beta version of GitHub mode, emphasizing a high-quality index rather than exclusively depending on large language models (LLMs).",
      "Future plans for Devv involve broadening the index to encompass team repositories and emphasizing localization for enhanced privacy and security, with the platform still in its early development phase and open to feedback."
    ],
    "commentSummary": [
      "Devv.ai is a new AI-powered search engine catering to developers, emphasizing index quality, a GitHub mode, clean interface, and upcoming Chrome extension and VSCode plugin.",
      "Users engage with topics like LLMs, AI models, UI/UX feedback, and potential integrations, expressing satisfaction with features such as GitHub mode and API integration plans.",
      "The platform utilizes RAG for enhancing generation results, praised for accuracy and functionality, while recommendations include refining tokenization and term weighting; Agent Mode incorporates GPT-4 for precise responses."
    ],
    "points": 171,
    "commentCount": 68,
    "retryCount": 0,
    "time": 1715181580
  },
  {
    "id": 40298486,
    "title": "Tesla Investigated for Securities and Wire Fraud Over Self-Driving Claims",
    "originLink": "https://www.theverge.com/2024/5/8/24151881/tesla-justice-investigation-securities-wire-fraud-self-driving",
    "originBody": "Tesla/ Electric Cars/ Cars Tesla is being investigated for securities and wire fraud for self-driving claims Tesla is being investigated for securities and wire fraud for self-driving claims / The Justice Department is examining whether Tesla misled consumers, investors, and regulators about its promises for fully autonomous vehicles. By Andrew J. Hawkins, transportation editor with 10+ years of experience who covers EVs, public transportation, and aviation. His work has appeared in The New York Daily News and City & State. May 8, 2024, 12:56 PM UTC Share this story Image: Cath Virginia / The Verge; Photo by STR / NurPhoto, Getty Images The Department of Justice is looking into whether Tesla committed securities and wire fraud around its self-driving vehicle claims, Reuters reports today, citing three sources familiar with the matter. The investigation, which was first reported in October 2022 but has been going on since at least late 2021, involves federal prosecutors in Washington and San Francisco who are examining whether Tesla executives misled consumers, investors, and regulators by making unsupported claims about its autonomous capabilities. Now, it appears that investigators are zeroing in on specific charges against the company: securities and wire fraud. According to Reuters, the probe is looking into statements made by Tesla CEO Elon Musk in particular. For years, Musk has been promising fully autonomous Tesla vehicles are just around the corner — while also admitting that he often sets overly optimistic timelines. Meanwhile, the company’s advanced driver-assist features, Autopilot and Full Self-Driving, do not make the vehicles autonomous and require drivers to keep their hands on the steering wheel and eyes on the road. According to Reuters, the probe is looking into Tesla CEO Elon Musk’s claims in particular Tesla has repeatedly pushed the boundaries of safety by allowing its customers to beta test products that may not be ready for wide release. Tesla vehicles using Autopilot have been subject to numerous recalls and involved in hundreds of crashes over the years, dozens of which have been fatal. The most recent recall, which applied to every single Tesla sold to date, has now come under a new investigation for its failure to prevent driver misuse and correct the flaws identified in the first recall. Wire fraud involves deceiving customers in interstate communications, whereas securities fraud relates to misleading investors. The Securities and Exchange Commission is also looking into whether Tesla lied in its communications about self-driving vehicles, Reuters says. The Justice Department is said to also be looking into Tesla’s vehicle range claims. Tesla customers have long complained that the company’s listed vehicle ranges often don’t match up to the reality of what the cars are capable of. In its latest securities filing, Tesla acknowledged “regularly” receiving subpoenas and requests for information from the SEC and Justice Department, some of which involve Autopilot and Full Self-Driving. “To our knowledge no government agency in any ongoing investigation has concluded that any wrongdoing occurred,” the company said. Most Popular Most Popular Microsoft says it needs games like Hi-Fi Rush the day after killing its studio Inside Microsoft’s Xbox turmoil People sure are pressed about Apple’s crushing iPad commercial Hands-on with the new iPad Pro: yeah, it’s really thin Apple TV Plus is turning into the best place for streaming sci-fi Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly. Email (required)Sign up By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. From our sponsor Advertiser Content From",
    "commentLink": "https://news.ycombinator.com/item?id=40298486",
    "commentBody": "Tesla is being investigated for securities and wire fraud for self-driving claim (theverge.com)160 points by chollida1 19 hours agohidepastfavorite137 comments animex 18 hours agoAbsolutely. If Martha Stewart went to jail for much less, a certain CEO[1] should be doing some hard time for ludicrous claims over the past 8 years. Some back-of-the-napkin-math: If we focus on the 4m Model 3 (& Y) vehicles sold that had these claims attached and assume that there was a peak uptake rate of 46% declining to 11% as these claims became obviously untrue. On FSD @ an ever-increasing price of $6000-$12000 USD per vehicle. Let's say take the declining rate difference as indicative of the group that was misled. 35% of those taking FSD took the feature because of erroneous claims, generating about 2Bn in high-margin revenue collected pumping the stock and causing investors to pile on creating even more validation of this claim. Pumping the stock also created massive tranche payouts for Musk for hitting certain valuations that should only have been hit when the automaker was truly a runaway success. Musk is incentivized to use this reality-distortion field & cult-like persona to continue lying about Tesla's future for personal and corporate gain. [1] Edit: Founder -> CEO reply snarf21 17 hours agoparentWe all need to remember Musk wasn't the founder. He was an early investor that forced the founders out. We can argue about whether the founders would have been more/less successful but he didn't found Tesla. [https://www.theverge.com/23815634/tesla-elon-musk-origin-fou...] reply bschmidt1 17 hours agorootparentElon \"take-n-tank\" Musk the brand destroyer lol I have an even funnier one for you: That viral video of when he was bald and bought that very expensive McLaren... \"It's the highlight of my life\" he said shortly before totaling the car with no insurance. \"He's a genius!\" reply orwin 14 hours agorootparentWow, if he's a McLaren fan, i guess going for looks over practicality is not surprising! (I'm joking, but not really). reply bschmidt1 18 hours agoparentprevI agree 100% he should be prosecuted at this point. He should have been the first time. reply deegles 18 hours agoparentprevThis could have been avoided just by calling it \"Partial Self Driving\" and then everything would be above board. reply dawnerd 18 hours agorootparentThat’s only part of the problem. They’re specifically investigating claims Elon made himself where he said the car drove itself without human input. He’s repeatedly made claims like this. reply tromp 18 hours agorootparentprevOr \"Fool's Self Driving\" to preserve the pronunciation:-) reply bschmidt1 12 hours agorootparentHaha I like the Fool's Gold analogy because his family owned an Emerald company in Zambia: \"During that time,\" said Errol, speaking to Elon's college years, \"I managed to send money I made from emerald sales to him and [Elon's brother, Kimbal Musk] for living expenses.\" reply api 18 hours agorootparentprevIt's advanced cruise control, basically, and if advertised as such it'd be great. reply mensetmanusman 18 hours agorootparentprevThat’s what they call it in the aerospace industry /s reply kube-system 18 hours agorootparent\"Self driving\" means something. There are industry standards for that phraseology that pre-date Tesla's (mis)usage. \"Autopilot\" may have been colloquially misleading (because of the public's unfamiliarity with aviation), but I don't think that name was problematic. Autopilot in planes can historically look like a basic cruise control. However, some of the associated statements and demonstrations at that time were problematic. (e.g. \"The person in the driver’s seat is only there for legal reasons. He is not doing anything. The car is driving itself.\") reply throwtappedmac 18 hours agoparentprevI think Martha Stewart went to jail for insider trading idk how similar that is. With OTA updates still could claim this could happen. This imo is less than both Theranos and insider trading like the FSD has disclaimers right? Unless the argument is Tesla is only valuable because of FSD and not best in class EV experience The pay package being declined by a Delaware court and now this couldnt have come at a worse time for Musk though. Billionaires got their problems too huh reply dragonwriter 18 hours agorootparent> Unless the argument is Tesla is only valuable because of FSD That's not how fraud works. Fraud doesn't require that the false claim us the only source of value of the product, it only requires that the false claim is material to the decision to purchase the product at the price offered. reply JumpCrisscross 18 hours agorootparentprev> Martha Stewart went to jail for insider trading \"Stewart was found guilty on charges including conspiracy and obstruction of justice\" [1]. She sold shares on inside information. She went to jail for lying to investigators about it. [1] https://people.com/martha-stewart-fraud-case-prison-sentence... reply ok123456 18 hours agorootparentThere was no insider trading. She thought she was in trouble and made up a story for the investigators that it was a limit order, which she was convicted of. While lying is bad, this was a case of overzealous prosecution because it was a high-profile case and an inappropriate use of resources. Instead of prison, they should have just had her do some cheezy PSAs and enter in to a deferred prosecution agreement. I find the members of congress consistently beating the market to be much more troubling. reply JumpCrisscross 18 hours agorootparent> was no insider trading \"Martha Stewart, the founder of Martha Stewart Living Omnimedia, also became embroiled in the scandal after it emerged that her broker, Peter Bacanovic, tipped her off that ImClone was about to drop. In response, Stewart sold about $230,000 in ImClone shares on December 27, 2001, a day before the announcement of the FDA decision\" [1]. It’s far from fact that she did not trade on inside information. [1] https://en.wikipedia.org/wiki/ImClone_stock_trading_case reply ksherlock 13 hours agorootparent\"Insider trading\" doesn't have a well defined boundary. The SEC sued Mark Cuban [1] for \"committing securities fraud by engaging in illegal insider trading\" under similar circumstances. But he kept his mouth shut, didn't destroy evidence, and didn't lie to the FBI. Did he trade on \"inside information\"? Sure. But the Jury found him not guilty of insider trading. [1] https://en.wikipedia.org/wiki/Mark_Cuban#SEC_insider_trading... reply JumpCrisscross 13 hours agorootparent> \"Insider trading\" doesn't have a well defined boundary Correct. In our courts it’s ambiguously defined. Colloquially, Stewart got a tip-off that arose from the non-public outcome of a drug trial. Whether she committed insider trading is open; whether she traded—knowingly or unknowingly—on material non-public information is pretty clear. reply ok123456 12 hours agorootparentIt was third-party hearsay. The stock tip came from her stock broker, who also happened to handle transactions for people with inside knowledge. The broker didn't know the details about the FDA trials, only the movement some of his clients were making. This is why she wasn't tried on insider trading, but instead on the story she made up to cover the fact that she was given this knowledge indirectly. reply jimmydddd 6 hours agorootparentAgreed. I don't think she knowingly insider traded. After the fact, the authorities were going after her broker and she erased a voice mail message to protect the broker. They were upset that she deleted evidence and went after her because she was high profile. reply JumpCrisscross 4 hours agorootparent> were upset that she deleted evidence and went after her because she was high profile She also previously held securities licenses. That takes entire categories of innocent error out of the picture. I hold securities licenses. I’d be held to a higher standard because plausible deniability is removed. reply JumpCrisscross 11 hours agorootparentprev> stock tip came from her stock broker, who also happened to handle transactions for people with inside knowledge. The broker didn't know the details about the FDA trials Source? Not disputing the broker was facilitating others’ insider trades, but if they were, it takes the suspicion to a whole new level around why this broker is so comfortable with his clients with potential insider status making large bets just ahead of corporate events. reply joquarky 14 hours agorootparentprevWhen are these \"risk takers\" ever taking a risk if their behavior is always excused? reply uberdru 17 hours agorootparentprevworth looking into cathy wood's role in this respect. . . reply FireBeyond 18 hours agorootparentprev> Unless the argument is Tesla is only valuable because of FSD Not specifically that, but Musk has stated that he sees Tesla as a software company. reply itsoktocry 18 hours agoparentprev>A certain founder should be doing some hard time for ludicrous claims over the past 8 years. I don't think \"hard time\" is appropriate for white collar crimes. Money is how you speak to these people. Martha Stewart is still worth hundreds of millions of dollars. reply LeifCarrotson 18 hours agorootparentHard time costs humans the same amount whether they're rich or poor - insofar as the justice system is equally accessible and you can't just lawyer your way out if wealthy or get screwed by a disinterested public defender if poor, of course. Money is amoral. It quickly becomes a calculation of ROI to violate the law. We've been reluctant for some reason to index fines against the wealth of the offender, but what would be a ruinous fine for a poor person is irrelevant to a wealthy person (eg. $1000 gag order violations). Also, the wheels of justice turn inexorably but slowly, and if first-to-market matters a lot with new there may be no fine that could restore things to the way it should have been if everyone acted within the law. reply tyree731 18 hours agorootparentprevStrongly disagree with both claims. Fraud of a sufficient degree causes harm at a scale that is equivalent (in economic terms at least) to the consequences of murder. And jail time absolutely speaks to wealthy people, given the amount of money and effort wealthy people will spend defending themselves to avoid it. reply ornornor 18 hours agorootparentprevWhat’s money when you have billions? Isn’t jail worse then? I’d be prepared to pay a very large amount if it meant I could avoid going to jail. There is a much much much smaller amount (if any) of jail I’d accept in return for money. reply bee_rider 18 hours agorootparentprevIf someone steals something, taking the thing they stole back is of course the first step. Other than that, the next step depends on what you think the point of the court/prison system is. If the point of the system is to prevent criminals from harming people: white collar criminals do crime at scale. They can hurt many more people than blue collar criminals. If the point is to reform people, it seems like white collar criminals have an easier time lying to themselves and justifying their actions, because they don’t physically take things from people, it’s all very abstract. So that seems like a harder project that might take longer. If the point is to prevent others from following their example, there are lots of reasons to punish white collar criminals more harshly. Their crimes are more difficult to work out, so getting caught might be harder. Plus there’s less of a de-facto preventative aspect—with blue collar crimes, depending on the crime, there’s likely a chance the victim might be physically present and quite irate, so they might fight, potentially even kill, the culprit. Of course there are some reasons that blue collar crimes can be more serious (muggers might physically hurt somebody). But I don’t think hard time is inappropriate in either case. reply Zigurd 18 hours agorootparentprevThe size of white collar crimes, measured in financial damage, and the large number of victims of many white collar crimes, not to mention the damage to the economy, institutional reputation, etc. makes a car theft ring that would get 10 years look like piffle. reply ericmay 18 hours agorootparentprevI'm not sure Martha Stewart actually did \"hard time\" - she spent what, a few months in jail? Try 10-20 years. I'm also not arguing for against jail time for white collar crimes, just disputing that she specifically did hard time. Maybe the FTX guy or Enron guys are more appropriate for a comparison. reply jcranmer 17 hours agorootparent> I'm not sure Martha Stewart actually did \"hard time\" - she spent what, a few months in jail? Try 10-20 years. From what I recall of studies, and also from what I've heard from criminal defense lawyers, sending someone to jail for even very short amount of times is likely to have a meaningful effect on their behavior. Even sending a white-collar defendant to jail for a few hours can win a lot of cooperation from them; and studies seem to indicate that there's no meaningful difference between a year in prison and 20 years in prison. reply rtkwe 18 hours agorootparentprevThe issue is the fines aren't a big deterrence as they're not that big. A lot of fines are less than the money the company made or saved with the illicit activity so it just becomes a line item cost more than an actual penalty. reply philosopher1234 18 hours agorootparentprevHard time seems much more severe than fines and penalties, and the damages caused are much more severe than petty theft (which gets you jail time.) it seems totally appropriate to jail these people to me. reply api 18 hours agorootparentprevForce those responsible to eat the cost of providing partial refunds to people who bought full self drive based on false claims. reply chollida1 19 hours agoprevThis is about defrauding people who bought a tesla, not investors. > In 2020, Musk told a crowd in Shanghai that he remains “confident” that Tesla will achieve “basic functionality for level five autonomy this year,” referring to the SAE’s rankings of autonomy. Tesla’s technology, in 2024, is still at level 2. This reminds me alot of the Thernos case where she tried to make the case not about fraud but about an overly optimistic CEO promising something and being wrong about that. here Musk has clearly said that full self driving would be available many years ago. So I guess we're trying to figure out how much lying is ok by a CEO before it becomes fraud to the buyer. reply adrr 18 hours agoparentI purchased FSD in 2019 on the promise of self driving. 5 years later and still no self driving. There was also the promise of the car being able to self park. I would be happy if I got my money back for a feature that was never delivered. reply steelframe 18 hours agorootparentAs my grandfather used to put it, you paid some \"tuition of life\" for a lesson you'll (hopefully) not soon forget. reply aaomidi 18 hours agorootparentYeah but also it’s good to punish lying companies. It increases trust in the market. reply bagels 18 hours agorootparentprevI couldn't imagine paying $12,000 for technology that didn't exist, from someone who repeatedly lied about that technology existing. reply kube-system 18 hours agorootparentPeople generally trust the US consumer products market. And that's a good thing. If people had to research the CEO of Old Navy before they bought a pair of pants from oldnavy.com, it would be pretty bad for our economy. And there are markets like this where trust is low, and they don't function well. reply bagels 15 hours agorootparentIf old navy CEO asked me to pay $5000 up front for jeans that can't wear out and that wash themselves, and had been saying that it'll be here next year for five years, I'd be pretty skeptical too. I also would encourage refunds or investigation when I buy it and the features are never delivered. reply rchaud 15 hours agorootparentprevThe difference is that Old Navy isn't selling anything they don't already have ready to go. Lamborghini and Ferrari take orders, but they tell you what the average wait time is, and you don't have to pay a 100% deposit beforehand. reply fuzzythinker 11 hours agorootparentprevThat is true for those who paid in recent 2-3 years. You can't say that for those who paid 3+ years ago. reply w0m 18 hours agorootparentprevsame. at least we got in before the price jumped? We don't even have a hope as the new MCU doesn't even support getting backported to our car even if we were willing to pay for it. reply adrr 18 hours agorootparentPretty sure it cost me more than the $2500 I paid. I tried smart summon one day. Instead of backing out of the space, it just ran forward up the curb on to the sidewalk. Couple years later the left strut failed costing me $2k. reply bunderbunder 18 hours agoparentprevAs the article explains, wire fraud is about defrauding consumers, and securities fraud is about deceiving investors. Tesla is under investigation for both. reply paxys 18 hours agorootparentWire fraud is nowadays just a catch-all for \"crime involving money\". Regardless of all other specifics of the case, it is a certainty that at some point someone sent a text message or used a computer, so that's what the feds will go after. Ran a scammy crypto exchange out of the Bahamas? Took money from investors for a failed blood testing company? Raised money for a political campaign but spent it on hookers? Paid a hitman to kill your spouse? All wire fraud. reply bunderbunder 18 hours agorootparentYup. It's a straightforward consequence of how society has evolved over time. \"Wire fraud\" specifically means using electronic communication channels to defraud something. Since most business is conducted over electronic communication channels nowadays, it all falls into that category. IANAL, but I doubt that there's any great alternative that doesn't involve rewriting 100 years' worth of legislation and case law, which generally distinguishes categories of fraud by the medium over which they occur. reply bryanlarsen 18 hours agorootparentprevAnd pretty much everything a public company does is securities fraud: [1] To oversimplify, a company is required to disclose risks, and everything is a risk, so it's security fraud if it's not in the disclosure, or if it's misrepresented in the disclosure. 1: https://www.bloomberg.com/opinion/articles/2019-06-26/everyt... reply rtkwe 18 hours agorootparentprevNot just a computer but just using the phone is also a wire fraud trigger too. It is basically any fraud these days though given how much communication happens through some 'wire'. reply ryantgtg 18 hours agoparentprevNo, this should be about defrauding people who bought FSD for their Tesla. Most Tesla owners do not care about FSD, according to the estimates of subscription rates. reply paxys 17 hours agorootparentPlenty of people bought Teslas anticipating that they'd buy FSD when it fully worked \"next year\". reply FireBeyond 18 hours agoparentprev> This reminds me alot of the Thernos case where she tried to make the case not about fraud but about an overly optimistic CEO promising something and being wrong about that. Right, and that fell apart with, well, many things, but the one that stands out to me - upcoming FDA inspection, and Holmes (in something out of a cartoon) literally had someone put a filing cabinet in front of the door to the lab where they were doing actual work to hide it, and direct inspectors to a faked up lab, i.e. outright fraud and deception. reply rsynnott 16 hours agorootparentShe wasn't convicted of... whatever that was (extremely low-effort obstruction of justice?), though, she was convicted of defrauding her investors. Notably, she got off on the charges of defrauding her customers, for, truly, it is easier for a camel to fit through the eye of a needle than for a rich person to get in trouble for injuring the general public. reply Consultant32452 18 hours agoparentprevIf we started prosecuting CEOs who don't meet goals/expectations, they'd all be in prison. You have to prove Elon was intentionally lying, which I suspect many on this forum are sympathetic to that view, but in a fair court system that is a difficult standard. You'd have to have emails or some other hard evidence where he acknowledges he knows he's being untruthful. Short of that kind of evidence coming out, they are most likely going after him for political reasons. reply NoMoreNicksLeft 18 hours agoparentprevShouldn't fraud (for the end user/customer) be determined by claims made about the product at the time of sale, and not promises of what might be possible a few years from now? If you want to say promises of future features is fraud, then surely that would only be in relation to investors? reply peutetre 18 hours agorootparentIn 2016 Tesla claimed that \"as of today, all Tesla vehicles produced in our factory – including Model 3 – will have the hardware needed for full self-driving capability at a safety level substantially greater than that of a human driver\": https://www.tesla.com/blog/all-tesla-cars-being-produced-now... That was a lie. reply jcranmer 18 hours agorootparentprevThe definition of fraud is going to vary slightly from jurisdiction to jurisdiction, but generally the core elements are: * Falsity: did the person knowingly make a false statement? * Materiality: was the false statement something that could reasonably influence someone's decision to agree to a contract? * Reliance: did the other party actually use the false statement to decide to agree to the contract? Claims of future capabilities are necessarily going to be evaluated differently from claims of current capabilities, since it's going to be harder to demonstrate all of these points. But for Tesla's FSD promises, we're at 7-ish years now of \"coming soon\" promises, with marketing materials outright saying it's only regulatory reasons that a driver is needed. Materiality and reliance are slam-dunks at this point; the only out Tesla really has at this point is falsity. Essentially, Tesla has to argue that its engineers were all high on their own hype (which I have to admit it as at least plausible). reply ceejayoz 18 hours agorootparentprev\"It's almost ready\" is a claim about the product at the time of sale. reply NoMoreNicksLeft 18 hours agorootparent\"Almost ready\" as a claim is pretty meaningless. It's a statement of feature status, not a prediction of when 100% completion occurs. In software, \"almost\" can last years or decades. reply ceejayoz 18 hours agorootparentHe's been frequently far more specific than that on timelines. 2018: \"By next year, a Tesla should be able to drive around a parking lot, find an empty spot, read signs to confirm it’s valid & park.\" https://twitter.com/elonmusk/status/1057690425710891009 2016: \"In ~2 years, summon should work anywhere connected by land & not blocked by borders, eg you're in LA and the car is in NY.\" https://twitter.com/elonmusk/status/686279251293777920 It won't be hard to demonstrate some purchasers factored these claims into their decisions. reply NoMoreNicksLeft 18 hours agorootparent\"a Tesla\", not \"all Teslas\". And of course \"should\" not \"will\". And so on. If his press releases are to be treated like contracts that he can be held to, then the verbiage needs to be parsed as if his words were contracts. That's just not going to go very well for the people litigating that he made false claims. Which gives the impression that the litigation isn't so much about punishing the wrongs he has committed, as they are about punishing the person that no one likes. Maybe there are other tweets that are better examples of your argument, I'll wait to see if they come up in any of the umpteen fluff articles we'll see over the next few months. In the meantime though, this seems more than a little unfounded. reply ceejayoz 18 hours agorootparent> \"a Tesla\", not \"all Teslas\" Cool. Is there a single Tesla currently capable of it eight years on? > If his press releases are to be treated like contracts that he can be held to, then the verbiage needs to be parsed as if his words were contracts. Contracts aren't the only way to make a fraudulent marketing promise. You can be sued for false advertising, for example. reply Veserv 17 hours agorootparentprevIn 2019:“ I think we will be feature-complete full self-driving this year, meaning the car will be able to find you in a parking lot, pick you up, take you all the way to your destination without an intervention — this year. I would say that I am certain of that. That is not a question mark.\" [1]. [1] https://www.businessinsider.com/elon-musk-doubles-down-on-cl... reply peutetre 18 hours agorootparentprevIn 2019 Musk claimed there would \"for sure\" be over a million Tesla robotaxis on the road by the end of 2020: https://www.thedrive.com/news/38129/elon-musk-promised-1-mil... That was a lie. reply ProxCoques 12 hours agorootparentThanks - I'll add that one to my timeline: https://webtorque.org/fsd-timeline.html reply kube-system 18 hours agorootparentprevMusk has been citing more precise estimates (e.g. \"end of the year\") for years. reply boolemancer 18 hours agorootparentprevWhen you are charging people extra for the features you're promising will exist in the future, it seems reasonable to call that fraud if you never deliver. reply kube-system 18 hours agorootparentprevOf course not, a huge number of (if not most) contracts contain agreements regarding future delivery of product or services. This is valid and normal arrangement. The contract is a promise to deliver that. If you don't deliver, you have breeched the contract. reply NoMoreNicksLeft 18 hours agorootparentElon Musk signed contracts claiming he would deliver this in the future? There are verbal contracts, so what you're really saying was that he was in the room with each buyer, individually or with a group of them (such that he was aware of the identities of those he was contracting with), and made a legally binding verbal contract where he told them he would deliver these software features, under what conditions they would be delivered (time, location, other details), and then shook their hands? Stretching contracts in the way you'd do it wouldn't be good for anyone. reply kube-system 18 hours agorootparentI'm making a bit of a comparison, since the above was a pretty general statement. Yes, literally, marketing is generally not regarded as contract offers... but the rationale for laws prohibiting false advertising is that the product delivered should be the product promised. Technically the difference between whether something would be breach of contract or false advertising or fraud is a very fine line dependent on the specifics. My point was just to say that \"future promises\" are not something that can just be disregarded. reply ceejayoz 18 hours agorootparentprev> Elon Musk signed contracts claiming he would deliver this in the future? False statements were made that induced consumers to sign contracts to purchase cars and the FSD add-on. This is fraud. Musk doesn't have to personally sign your car's contract for that to be a thing, or your credit card APR would be unenforcable. reply marcusverus 18 hours agoparentprevThere is an obvious difference between lying and being wrong. Theranos claimed to already have created their magic machine, which was a blatant lie. They intentionally misled investors by pretending to put samples into a fake testing machine, secretly removing the samples to test them in a lab elsewhere, then putting them back into the machine to make it look like the machine was doing the testing. That's careful, calculated fraud, which was obviously a criminal act. Musk, by contrast, never claimed to have something that he did not have. He made overly-optimistic claims about product development. There is no reason to assume that these projections were lies, given that everyone else in the space was making similarly aggressive projections. Musk was wrong for selling FSD-related features before they were ready, and Tesla should obviously make that right. But pretending that being wrong (in good company) is the same thing as calculated fraud is just goofy. reply uberdru 17 hours agorootparentIt's about revenue recognition. TSLA has beaten estimates multiple times based on revenue recognized from FSD \"Beta\". There's your fraud. reply jcranmer 17 hours agorootparentprev> Musk, by contrast, never claimed to have something that he did not have. IIRC, wasn't the video that claimed to demonstrate a full trip conducted by FSD actually like 100 different splices? That right there would be a claim of something that didn't exist. reply api 17 hours agorootparentprevThat's the question: is there any calculated fraud here or was he just vastly overly optimistic? ... but even if there is no calculated fraud, I think some Tesla buyers are owed refunds or other compensation. If a company promises me X, I pay for it, and years later has not delivered X, eventually I need a refund. reply MBCook 15 hours agorootparentI agree. After 7 years or whatever you can’t keep being “overly optimistic”. At some point it becomes clear it’s just not ready and you need to give people their money back and stop selling it until it is. If all FSD things were sold with a “really will be in 2 years or 80% of your money back” clause that would be different in my mind. But taking money and just never delivering is flat out fraud. No matter how many times you say “just one more year”. reply malfist 15 hours agorootparentprev> Theranos claimed to already have created their magic machine, which was a blatant lie. And to this day, you can go on Tesla's website, configure a car, and be offered the option to purchase \"Full Self Driving Capability\" which does not offer a fully self driving vehicle. reply ryandrake 18 hours agoprevThis site[1], which is a pretty comprehensive list of claims Musk has made and how long it’s been, made the rounds on HN a few times. It’s really incredible how much exaggeration comes out of the guy’s mouth. I don’t think it all counts as fraud, but at some point you gotta say Dude, Stop Talking. 1: https://elonmusk.today/ reply kemotep 17 hours agoparentLast month he stood before the SpaceX staff in Boca Chica and outlined how he still believes that he will get 1 million people on Mars by the 2050s. U til they can start producing 100’s of Starships, this is not even remotely realistic. Sending thousands of people to Mars in the next 5 years is not a serious or realistic idea. reply TheLoafOfBread 16 hours agorootparentI mean, what those 1 million people would be even doing there? What would be their purpose there? Definitely not resources, because getting anything from Mars would not be economical. I do understand to have an international base of few dozens to few hundred scientists on Mars who will be studying it 24/7. But that's about it. reply bagels 18 hours agoparentprevI was trying to find the same thing to post. Thank you! reply williamsmj 19 hours agoprevThis is just the Verge regurgitating a Reuters article that has already been posted https://news.ycombinator.com/item?id=40297126. reply perihelions 18 hours agoprev- \"The investigation, which was first reported in October 2022 but has been going on since at least late 2021, involves federal prosecutors in Washington and San Francisco who...\" Just to clarify, this is the same one as this HN thread from October 2022, https://news.ycombinator.com/item?id=33348388 (\"Tesla faces U.S. criminal probe over self-driving claims (reuters.com)\", 469 comments) reply klodolph 18 hours agoprev“Everything everywhere is securities fraud” —Matt Levine https://www.bloomberg.com/opinion/articles/2019-06-26/everyt... The basic idea here is that you lied, the share price went up because of your lies, and that makes it security fraud. From one viewpoint it’s a useful tool to punish fraudsters and con men, and from another view it’s an overreach by the FTC. Maybe a more reasonable view is somewhere in the middle—it’s both a good tool and an overreach. reply malfist 14 hours agoparentHow is it possibly overreach? If you lie to investors to get them to give you more money, that is absolutely fraud. reply glitchc 19 hours agoprevAbout time. reply Lendal 18 hours agoparentI had a feeling this was coming. I bought FSD in 2020. It was $10K, and they were claiming in one year you could summon the car to come to you from across town or rent it out as a self-driving taxi service. I figured it might work, and in the meantime would be a fun toy, so I bought into it as a speculation. On an individual basis this was just poor judgement on my part, but when you multiply that by how many other customers thought similarly to how I did, maybe it does become a government issue then. Unfortunately for me, I soon discovered that I did not like the car driving me around. No matter how good it got, I would almost always have made a different decision in most traffic situations. So it was a huge loss, but for me it doesn't even have to do with the fact the technology doesn't do what their hype claimed. It has to do with the fact that letting FSD drive is more stressful than if I just drive the car myself. reply jaxomlotus 18 hours agorootparentThere isn't even a point to it if it requires you to keep your hands on the wheel and not look at your phone. I would want to use it so I could conduct business while the car took care of driving. If it still requires me to pay strict attention to the road and keep both hands on the wheel, then it's just a novelty to show off to passengers for a quick giggle, but not actually solving a problem. reply ChrisArchitect 18 hours agoprev[dupe] Actual article: https://www.reuters.com/business/autos-transportation/tesla-... (https://news.ycombinator.com/item?id=40297126) reply bilsbie 18 hours agoprevThe latest self driving is getting really good. My main problem is being a front seat driver and taking action because I’m not sure of it’s thought process but it ends up getting things correct. I think all these systems* could benefit from earlier braking to give the “supervisor” more piece of mind. * including my wife in this. reply misiti3780 18 hours agoparentagree, half the people in this thread havnt used it. i think it's probably clear to most FSD testers that end-to-end NN trained on video will get you L5 eventually. reply ceejayoz 18 hours agorootparentI've used it (this weekend, in fact). It's very impressive. It remains a far cry from this, which Musk tweeted (https://twitter.com/elonmusk/status/686279251293777920) eight years ago: > In ~2 years, summon should work anywhere connected by land & not blocked by borders, eg you're in LA and the car is in NY. reply adrr 9 hours agorootparentprevI have it. I don’t know how it can be L5 when the cameras get blinded by the sun in the morning and evening. Or when it rains too hard. It also picked up the mannerisms of human drivers like hitting the brakes at a yellow light and then accelerating and in my case tried to run a red. reply bigtex 16 hours agoprevThis means the stock goes up 10%, right? reply bschmidt1 19 hours agoprevSecurities fraud again, funny that the guy who \"bought Twitter\" and shut down free speech ended up getting sued himself due to his own tweet (lying about # of Teslas being produced). It's like a bully trying to chase someone but tripping over their shoelace in the first step, love it. On self-driving: For several years the guy has been saying \"next month\" \"next year\" it's been like 10+ years at this point. He's a bigger grifter than the Ashes of Creation guy (8 year long Kickstarter MMO that never launched and still collects payments to this day). Wonder why anyone falls for it, feel bad for the gullible. reply neglesaks 18 hours agoparentI believe you can summarize Mr. Musk's persona (including his speech and promises made or hinted at) as \"unreliable\". reply slashdev 17 hours agoparentprev1) Linking to Tweets still exists, and doesn't require that you're logged in to view them. 2) According to their own released numbers (which you may or may not trust), the usage of the platform is at a record high. 3) They've unbanned many accounts that were previously banned and seem to display a wider tolerance for free speech on the platform. The innovative community notes feature is sometimes helpful to point out misinformation, but misinformation thrives on the platform. 4) They've pushed back on various foriegn governments requesting data on users and requesting users or posts be banned (see the ongoing dispute with Brazil.) It seems more free, not less free. reply ceejayoz 15 hours agorootparent> The innovative community notes feature... ... was built and released pre-Musk, when it was called \"Birdwatch\". https://en.wikipedia.org/wiki/Community_Notes As for government requests, for every Brazil there's an India. https://theintercept.com/2023/03/28/twitter-modi-india-punja... \"Twitter accounts from over 100 prominent politicians, activists, and journalists in India and abroad have been blocked in India at the request of the government. On Monday, the account of the BBC News Punjabi was also blocked — the second time in a few months that the Indian government has used Twitter to throttle BBC services in its country.\" \"At the time that Musk took charge of the company, it had a mere 20 percent compliance rate with Indian government requests. Following massive layoffs that reduced 90 percent of Twitter India’s staff, the platform appears to have become far more obliging in the face of government pressure, as its actions to censor its critics now show.\" reply piva00 11 hours agorootparentprev> 4) They've pushed back on various foriegn governments requesting data on users and requesting users or posts be banned (see the ongoing dispute with Brazil.) But not in India, nor Turkey, there Twitter under Musk has abided by the requests to silence people. Why is that is a good question, it could be political alignment (Modi and Erdogan are from a different political stance than Lula), it could be because Musk seeks to exploit Brazil's lithium, we can't know but he's been pretty selective in where to pick a fight so we can only assume is due to other circumstances than anything to do with freedom of speech. reply nullorempty 18 hours agoparentprevI think Musk is just relaying the promises he receives from ML/AI guys he employes. As far as I know FSD has always been a paid option. reply mikestew 18 hours agorootparentAnd after years of publicly looking like a lying car salesman, why would he still listen to those employees? I don’t think it’s the line employees that are lying here. reply lolc 18 hours agorootparentThe way I understood it went down for the CEO: 1. Made optimistic claims about future product. 2. Some of the people tasked with implementation disagreed about optimistic claim. 3. Those people got fired for underperforming. 4. All people on the team tasked with implementation agree with optimistic claim. 5. Doubled down on the promise. Repeat every year. I can't see how a CEO could be blamed in this scenario, as clearly they were lied to by their subordinates. reply bschmidt1 17 hours agorootparentThe CEO is still responsible for their own employees, CEO hired them or directed them to be hired, the CEO (especially this CEO) runs the company. Lying about features or the number of cars being produced etc. can't be limited to mere optimism because they mentioned specific numbers in a public way that were not true. > fired for underperforming The irony, since Musk destroys every brand and product he's ever touched. I've never seen a more polar opposite to the Midas effect at work. It has to be intentional. reply lolc 15 hours agorootparentWhy should a CEO be responsible for their employees if they could instead take a huge pay package which they are obviously entitled to given they have to work around their lying employees? That too was sarcasm :-) You shouldn't be too hard on Musk regarding the \"destroys\" though: Many people are so incompetent you don't even get to hear about their failures! And others loot professionally without you ever getting to know about it. You have to ignore a lot to state \"it has to be intentional\". reply adrr 14 hours agorootparentprevI am sure if he allowed customers to get refunds on FSD, the DOJ wouldn't open a criminal case. reply jajko 18 hours agorootparentprevThis is irrelevant, he is public CEO and has tons of responsibilities. Basically lying to millions of customers in very public manner is a serious issue. reply kube-system 18 hours agorootparentprevGiven what I've read about his management style, I doubt it's like that. Probably more like: Musk: Hey get your shit together I want this done by the end of the year Team: Okay we'll try Musk: Okay we'll plan on that reply stronglikedan 18 hours agoparentprev> \"bought Twitter\" and shut down free speech Citation needed. The platform is more open and vibrant than ever, even going so far as to reinstate free speech that old Twitter shut down at the request of the US government. If anything, he liberated free speech and it shows. reply bschmidt1 18 hours agorootparent> The platform is more open and vibrant than ever You reveal your lack of experience with Twitter, it's declined a lot. Pretty sure you can't even link to a tweet (a xweet?) from a news article or blog post - they totally killed the platform, not sure where you've been. reply neglesaks 17 hours agorootparentWhat you claim is clearly incorrect. First, major news outlets all over the world are still linking to twitter posts daily, not least because most of the worlds journalists are still actively using twitter, so obviously this feature still works. Also, there has never been more product development on Twitter/X than since the Musk takeover. Examples include community notes, creator revenue sharing and the features tied to the purchased blue checkmark (eg. Posts longer than 280 chars). The major handicapping of the platform compared to earlier is that only the post linked to is now visible to non-users, whereas the whole thread it was part of was previously visible. reply ceejayoz 15 hours agorootparent> Examples include community notes... No, they don't. https://en.wikipedia.org/wiki/Community_Notes \"In November 2022, at the request of new owner Elon Musk, Birdwatch was rebranded to Community Notes...\" reply MisterDizzy 18 hours agorootparentprevA lot of people are really defensive about this. What's the big deal if X does well? Why are people so personally invested in pretending like Elon didn't do the world a huge service by removing Twitter from the control of possibly the most politically extreme and anti-constitutional subculture in the entire country? reply 91bananas 18 hours agorootparentI personally preferred the original politically extreme and anti-constitutional subculture better. reply MisterDizzy 18 hours agorootparentAt least you're honest. Everyone must remember that \"they\" and \"their side\" are capable of the same evil as their enemies. The existence of a truly open discussion must be sacred, or we might as well dismantle it all. Or, if your goal is to dismantle instead of building or fixing things, remind me to never let you have any power. reply jcranmer 17 hours agorootparentprev> the control of possibly the most politically extreme and anti-constitutional subculture in the entire country? What are you trying to refer to here? Because the most politically extreme and anti-constitutional subculture I can think of right now is QAnon, which has not (nor is not) in control of Twitter. reply bschmidt1 18 hours agorootparentprevI can tell by the upvote/downvote dance on the parent comment - people love their celebrities. They get really mad if you talk bad about Elon Musk lol I find it quite pathetic personally. I of course disagree - I don't see the \"huge service\". Everything from defrauding investors, customers, speaking out of school (saying he's a physicist in the early days), hanging out with Ghislaine Maxwell, stealing then tanking Tesla, destroying Twitter, he's a walking disaster to the point I believe it's intentional. reply erikerikson 18 hours agorootparentI'm not sure how you'd see the \"dance\" but anyway... I'd hold the \"visited decisive politics\" hypothesis at a much higher probability over \"celebrity parasocial loyalties\" for down and up voting in this case. That said, trying to guess at the motivations of the diverse crowd here is fraught at best. reply bschmidt1 17 hours agorootparentReally you've never seen a comment of yours bounce around negative and positive on polarizing issues? It's kinda cool to see, makes this platform feel more solid than others. > celebrity loyalty You must have missed that meme https://i.kym-cdn.com/photos/images/original/002/477/624/072... It was in response to the insufferable worship happening in comment sections everywhere. I wonder how much he was paying for PR each month back then, and what agency he uses. At any rate, that there was a good meme. reply erikerikson 13 hours agorootparentI have seen mine be down voted at times and then later up voted but not in a responsive sense. Have I missed a feature or maybe you're using an outside reader? Regardless, I've only noticed for my own account. Perhaps you own both accounts? I completely miss all the memes as a rule, thanks for sharing. reply JumpCrisscross 18 hours agorootparentprev> people love their celebrities. They get really mad if you talk bad about Elon Musk lol I find it quite pathetic personally. People have strong opinions about celebrities they don't know, don't have any control over and have zero material stake in; news at eleven. (The last is the only one that isn't sometimes true about Elon.) reply MisterDizzy 18 hours agoprevThe lesson here is never challenge San Francisco extremists' ability to remove stories from the Internet at will. reply ceejayoz 17 hours agoparentSpare me with this; one of Musk's very first major actions was removing an account he didn't like (and had previously committed to leaving alone! https://twitter.com/elonmusk/status/1589414958508691456) because it was tweeting publicly available ADS-B data his plane was broadcasting... and then went on a tear banning journalists tweeting about it. https://en.wikipedia.org/wiki/December_2022_Twitter_suspensi... reply MisterDizzy 17 hours agorootparentCan people please stop pretending the whole irrational anti-Musk rage is due to anything other than his apparent (nominal, at least) challenging of San Fran technocratic control of what stories are allowed to remain online? I understand many people have a personal investment in this, but the disingenuous posturing is getting tiresome. \"It was fine when we did it, and cooperated with intel agencies to do it, but HE shouldn't be able to!!\" reply ceejayoz 17 hours agorootparent> \"It was fine when we did it, and cooperated with intel agencies to do it, but HE shouldn't be able to!!\" He has every right to do it. He promised not to, and you're still claiming he isn't. That hypocrisy is very apparent. reply MisterDizzy 17 hours agorootparentnext [2 more] [flagged] ceejayoz 17 hours agorootparentIf silencing dissent is not acceptable, you should demonstrably be mad at Musk. reply MisterDizzy 17 hours agorootparentprevnext [2 more] [flagged] wtfwhateven 15 hours agorootparentYou know as well as I do that you're using hypothetical incidents to justify hypocrisy and censorship. Please read the HN guidelines before posting too as repeatedly attacking someone's point as \"playing stupid\" has no place here. reply MisterDizzy 17 hours agorootparentprevnext [2 more] [flagged] ceejayoz 17 hours agorootparentNo actual stalker is going to be troubled by the @ElonJet ban. (I'm not sure who \"the most actively violent faction in the country\" is.) It's on other platforms and the plane publicly broadcasts its location. https://globe.adsbexchange.com/?icao=a2ae0a reply mensetmanusman 18 hours agoprevFly by wire fraud? reply IshKebab 18 hours agoprevI'm surprised it's taken this long, though I supposed you needed some technical knowledge to know that it was obviously a fraud a while ago. Without that you might believe it was actually possible (hence people actually buying FSD). reply louwrentius 19 hours agoprev [–] I’ve seen the same meme over and over again in many different youtube videos: Elon musk assuring self-driving is just around the corner, just another few months… The investigation doesn’t interest me much. He has gotten slaps on the wrist before. Wake me up when he gets jail time. reply Firaxus 18 hours agoparent [–] As someone with a tesla and with a parent who bought the fsd beta package, I’d be very interested if there’s some kind of payout for consumers/customers! reply lolc 18 hours agorootparent [–] There was this thread[0] around here about one buyer of FSD who took Tesla to small claims court and Tesla settled with them. Looks like it's easy enough to do. It's just that Tesla demands gag clauses in the settlement which may be accepted by many people and we might never know how many settlements are out there. Thankfully the author in this instance knew they were going to win and there would be no gag clauses then. So why accept them in the settlement? Tesla caved, because they knew this too. [0] https://news.ycombinator.com/item?id=38146676 reply trog 5 hours agorootparent [–] I don't know if there are still a lot of Tesla shorts, but I wonder if they could offer to fund one of these settlements and then pay for any fines for the person to then breach the gag order. Maybe there are not enough FSD customers for this to have a material impact in terms of dollars but I'd have to think it would impact reputation. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Tesla is under investigation by the Department of Justice for securities and wire fraud, particularly concerning its statements on self-driving technology.",
      "The focus is on potential misleading information provided to consumers, investors, and regulators regarding Tesla's promises on fully autonomous vehicles, with CEO Elon Musk's statements receiving close attention.",
      "The Securities and Exchange Commission is also examining if Tesla made false statements about self-driving capabilities in its communications."
    ],
    "commentSummary": [
      "Tesla and CEO Elon Musk are facing an investigation for securities and wire fraud linked to their self-driving technology claims, sparking concerns about transparency and potential misleading statements to inflate revenue and stock prices.",
      "Debate surrounds the challenges of holding CEOs accountable for deceptive claims, the repercussions of unmet promises, the possibility of customer refunds, and the legality of future commitments, drawing parallels to Martha Stewart's insider trading case.",
      "Users are divided on Musk's impact, allegiance to celebrities, misinformation handling on Twitter, removal of online content, the banning of the @ElonJet account, and its effect on Tesla's image."
    ],
    "points": 160,
    "commentCount": 137,
    "retryCount": 0,
    "time": 1715178379
  },
  {
    "id": 40302200,
    "title": "Breathwork: A Non-Pharmacological Path to Altered States",
    "originLink": "https://www.researchsquare.com/article/rs-3976380/v1",
    "originBody": "Browse Preprints COVID-19 Preprints Protocols Videos Journals Tools & Services Overview Curie Professional Editing Research Promotion Your Cart About Preprint Platform In Review Editorial Policies Research Quality Evaluation Our Team Advisory Board Blog Help Center Sign In Submit a Preprint Cite Share Download PDF Article Decreased CO2 saturation during circular breathwork supports emergence of altered states of consciousness Martha Havenith, Max Leidenberger, Jelena Brasanac, Mafalda Corvacho, and 11 more This is a preprint; it has not been peer reviewed by a journal. https://doi.org/10.21203/rs.3.rs-3976380/v1 This work is licensed under a CC BY 4.0 License Status: Under Review Version 1 posted You are reading this latest preprint version Abstract Altered states of consciousness (ASCs), induced e.g. by psychedelics, show great potential to treat widespread mental health disorders like depression and PTSD. However, access to such treatments is restricted by legal, medical, and financial barriers. Here, we explore the potential of circular breathwork to serve as an accessible, non-pharmacological alternative to engage similar therapeutic processes. Scientific studies investigating the mental health effects of breathwork are only just emerging and the underlying physiological and psychological mechanisms are largely unknown. In this study, we address these questions by tracking physiological and experiential dynamics throughout a breathwork session, comparing two popular forms of breathwork: Holotropic Breathwork® and Consciously-Connected breathwork. We show that a reduction in end-tidal CO2 pressure due to deliberate hyperventilation is instrumental in catalyzing ASCs during breathwork. ASCs evoked by breathwork were comparable to those produced by psychedelics, and their depth predicted psychological and physiological follow-on effects, including improved well-being and a reduction of depressive symptoms. Moreover, different breathwork formats produced highly similar physiological, experiential and psychological outcomes. These results outline physiological boundary conditions for ASCs to arise in a non-pharmacological context, shedding light on the functional mechanisms of breathwork as well as its potential as a psychotherapeutic tool. Biological sciences/Neuroscience/Cognitive neuroscience/Consciousness Social science/Psychology/Human behaviour Biological sciences/Psychology/Human behaviour Full Text Additional Declarations There is NO Competing Interest. Supplementary Files 202402BreathworkCO2SuppMaterials.pdf Cite Share Download PDF Status: Under Review Version 1 posted You are reading this latest preprint version Research Square lets you share your work early, gain feedback from the community, and start making changes to your manuscript prior to peer review in a journal. As a division of Research Square Company, we’re committed to making research communication faster, fairer, and more useful. We do this by developing innovative software and high quality services for the global research community. Our growing team is made up of researchers and industry professionals working together to solve the most critical problems facing scientific publishing. Also discoverable on Platform About Our Team In Review Editorial Policies Advisory Board Contact Us Help Center Resources Author Services Research Quality Evaluation Blog Accessibility API Access RSS feed Cookie Settings Company About Us Careers Partner With Us Responsibility Press © Research Square 2024ISSN 2693-5015 (online) Privacy PolicyTerms of ServiceDo Not Sell My Personal Information",
    "commentLink": "https://news.ycombinator.com/item?id=40302200",
    "commentBody": "Breathwork supports emergence of altered states of consciousness (researchsquare.com)128 points by rendx 14 hours agohidepastfavorite41 comments EMM_386 1 hour agoI've done breathwork sessions before. It felt strange, yes you can midly hallucinate and feel \"otherworldly\" but I always left thinking \"ok, I just hyperventilated for 20 minutes ... this is exatly how I'd expect to feel\". And now we have a scientific study that proves it. It seemed pretty obvious to me. reply unrealp 5 hours agoprevSounds counter intuitive but breathwork reduces o2 to brain. Basically due to reduced co2, blood vessels in the brain constrict. Having said that, I worked with a breathwork teacher for a while, creating narrative for the session, for mental imagery and guidance. It also had music as a backdrop. Fun times. And it was definitely altered state for a lot of people. reply michael-ax 33 minutes agoparentEXACTLY! That's why you breathe into a paper-bag (or smoke) to increase CO2 so that the filters open and you get to a point where you feel O2 tingles all over your brain. This is extremely powerful; I practiced that and underwater held-breath swimming and hanging out underwater for a long time to obtain permanent changes that have made me far more effective. Based on work first published by W.Wenger out of a Maryland Think-tank some 50? years ago. reply ay 4 hours agoparentprevAny pointers to read more ? My GP friends only pointed me to respiratory alcalosis, which doesn’t appear to be about O2 levels at all - it’s the pH being out of the narrow “acceptable” band (too low in the case of hyperventilation) appeared to cause a lot of effect. reply unrealp 4 hours agorootparenthttps://en.wikipedia.org/wiki/Hyperventilation - This leads to hypocapnia, a reduced concentration of carbon dioxide dissolved in the blood. https://en.wikipedia.org/wiki/Hypocapnia - Acute hypocapnia causes hypocapnic alkalosis, which causes cerebral vasoconstriction leading to cerebral hypoxia Though not acute, you can see the effects very easily. Within couple of minutes of deep breathing we could create peripheral numbing and tingling effect. (yoga folk say you are feeling energy moving though body and that kind of stuff haha) reply aunty_helen 7 hours agoprevI’ve done a session of holotropic breathwork before. It was a surprisingly strong experience. 25 minutes of rapid deepish breathing while listening to music. I was doing it as part of a group session and funnily it was conducted via zoom. After the first 10, it becomes easy to keep the breathing pace. Moderately deep hallucinations, sweating a _lot_ on the bed. The weirdest part was that my face wanted to screw up in contortions. I felt my lips tight and couldn’t control my facial muscles until they hurt. I lost track of time and the session felt like it ended quickly. Afterwards there was a positivity mindset like a mild mushroom afterglow. I would probably do it again. reply adastra22 5 hours agoparentThat sounds like your body telling you not to do it. reply pharrington 4 hours agoparentprevIt sounds like you experienced oxygen deprivation. reply hackernewds 3 hours agorootparentoxygen deprivation is not euphoric. shouldn't be so flippantly reductive reply huygens6363 3 hours agorootparentI thought it was common knowledge that it is in fact euphoric. Happy to be told I’m wrong though. (Think of nitrous oxide and .. the thing with asphyxiation and a certain pleasurable activity) reply simple10 5 hours agoparentprevYes! Holotropic is crazy strong. I remember having to sign a waiver that was akin to a skydiving waiver before doing holotropic breathwork session online. Highly recommended if you feel inclined to try it. reply nprateem 1 hour agoparentprevI've heard about people awakening their kundalini with that. It fucked them for years since they had no clue what was happening, and no preparation or support. reply teh_infallible 3 hours agoparentprevIt also leaves you in a very suggestive state. I did several sessions with a “rebirther” years ago, basically holotropic breath work. I decided I didn’t really need it, and I went in my last few sessions determined to quit, but at the end of the session, the practitioner always managed to convince me I needed another session. I eventually broke it off with him over the phone. reply rqtwteye 10 hours agoprevHolotropics has been around for quite a while and some yoga pranayamas also can lead to altered states. I have to admit I find mushrooms easier to deal with. reply hackernewds 3 hours agoparentAn ascetic will tell you that a purer experience of spiritual connection is something you can control and remember afterwards. reply foobiekr 2 hours agorootparentYou remember mushrooms after. reply AstralStorm 1 hour agorootparentprevRemember what, the tingling mess and neuronal misfires of endogenous DMT release experience? reply Traubenfuchs 1 hour agorootparentprevAhhh yes, the bespoke, organic, pesticide free high of the true people. Why struggle when 10-20€ worth of ketamine will make you glide through impossible (un)existence for an hour or so. Elitism and snobbism in spirituality and meditation circles is real! reply ergonaught 8 hours agoprevIt isn’t new, even for the academic community, that modulating CO2 levels via breathing alters consciousness. Some of these sound more like advertisements. reply khimaros 5 hours agoparentif this topic interests you, check out this interview with Dr. Jack Feldman: https://hubermanlab.com/dr-jack-feldman-breathing-for-mental... -- i found the section about the effects of periodic hypoxia without retaining CO2 quite fascinating. reply swayvil 7 hours agoprevI think the ancient yoga wizards of yore called that \"Pranayama\". reply MrLeap 9 hours agoprevIs circular breath work just hyper ventilating? reply notnaut 7 hours agoparentYep. Feels good man. Same as all the psychs. And altered perspective can make you wiser. reply mjklin 11 hours agoprevRoss and Carrie covered this on their podcast back in 2017, they had out of body experiences I believe. Link: https://ohnopodcast.com/investigations/2017/10/21/ross-and-c... reply bschmidt1 5 hours agoprevCombination of excess oxygen and rhythmic/yogic type trance? reply colechristensen 11 hours agoprevI wonder what other effects this has on the body. The signaling around CO2 levels does a lot to cellular respiration everywhere, not just the brain (think krebs cycle, etc). reply smeej 10 hours agoparentThere's a product out, Freespira, that does breath work training monitored by a nasal cannula, to help people who experience panic attacks. The theory is that such people are chronic hyperventilators, so their blood CO2 is too low for the parasympathetic nervous system to operate correctly. It didn't end up being a good fit for me, but if a person's PTSD comes from discrete events rather than a continually unsafe environment in early childhood, I think they'd have a better experience. (My parasympathetic nervous system never learned how to operate correctly, but if someone else's did and its function got interrupted later, I think their experience would be different.) reply plaguuuuuu 9 hours agorootparentStrange side note. I've tried n-acetylcysteine as a supplement/medication, the weirdest thing about it is that I felt like I needed to breathe less often. And like I was breathing manually - which you are also doing now, ha. I wonder if it helps with panic attacks. reply AnthonBerg 3 hours agorootparentThis makes immediate sense to me after having stumbled upon some of the academic literature on N-acetylcysteine. There are results on it being anti-anxiety, yes. Tons and tons of results; Wide scope. Pulmonary and neurobiological. The wildest paper imo: “N-acetyl cysteine reverses bio-behavioural changes induced by prenatal inflammation, adolescent methamphetamine exposure and combined challenges” – https://doi.org/10.1007/s00213-017-4776-5 It’s just an… :exploding-head: paper. There are also studies that check if humans fall into or out of various psychiatric disorder diagnostic criteria. Yes, NAC is anti-anxiety. And! NAC is clearly and obviously mucolytic. Slime-dissolving. Its use as prescription and OTC medicine in my country is—I think, so far—exclusively as a lung-slime dissolver to help people breathe better. reply ajb 36 minutes agorootparentIt's a very interesting paper. However, it's in rats, so among other things the timescale is very compressed compared to humans: we are taking about three NAC reversing changes 1-2 months later reply rendx 9 hours agorootparentprevInteresting! Thanks for the pointer. reply suroot 8 hours agoprevMy buddy goes into schizophrenia episodes every time he goes for a long run. Any ideas? reply MrLeap 7 hours agoparentYour buddy ought to see a healthcare professional, I'm just some guy on the internet. That said: here's a description of prodromal schizophrenia. Your description reads like category #2 to me. \"Prodrome phase can also be categorized in three different ways: Category 1 means the patient should have at least one of the following symptoms: False beliefs that random events in the world directly relate to them, odd beliefs, or magical thinking; visual disturbance; odd thinking and speech; paranoid ideation; and odd behavior or appearance. Category 2 includes patients who have experienced psychotic symptoms that come and go, which have spontaneously resolved within a week. Category 3 includes a combination of genetic risk (i.e., being the first-degree relative of an individual with a diagnosis of schizophrenia) with substantial changes in personal daily functioning in the previous year. \" https://www.verywellhealth.com/prodromal-schizophrenia-51942... reply 121789 6 hours agoparentprevI believe running, especially long runs will cause changes in brain chemistry. Rapid increases in norepinephrine, GABA, and serotonin. I wonder if that sudden release triggers something. Same mechanism as a runner’s high reply DANmode 7 hours agoparentprevAcute toxicity due to distribution of accumulated toxin (of some kind) by the violent action of running. reply rustcleaner 2 hours agorootparentProbably this House M.D. -tier answer. reply m3kw9 9 hours agoprevWhat about LSD reply ilaksh 2 hours agoprev [–] Just the word \"breathwork\" is obnoxious to me. I suppose it's interesting that if you hyperventilate enough you can reduce oxygen in your brain to the point where you hallucinate. And that is probably safer than taking psychedelics. But the idea that you would do that routinely seems obviously stupid to me. I think if you keep doing it for a number of years then you could damage your brain. My understanding is that your brain needs oxygen. reply gardnr 2 hours agoparentGot that one backwards: > Hyperventilation is irregular breathing that occurs when the rate or tidal volume of breathing eliminates more carbon dioxide than the body can produce. https://en.wikipedia.org/wiki/Hyperventilation reply codr7 25 minutes agoparentprevI take it you haven't put a lot of effort into examining the practice? Pranayama is a pretty comprehensive system, and it has survived to this day for good reasons. reply andybak 1 hour agoparentprev [–] It seems obvious to me that the things you find obviously stupid, obviously aren't. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The preprint examines the therapeutic advantages of circular breathwork in creating altered states of consciousness akin to psychedelics.",
      "It delves into the physiological and psychological processes of breathwork, showing how deliberate hyperventilation lowers CO2 levels to induce altered states.",
      "The findings propose breathwork as a non-pharmacological option for mental health treatment, with results similar to psychedelic therapies, emphasizing its potential as a psychotherapeutic tool."
    ],
    "commentSummary": [
      "Breathwork can trigger altered states of consciousness by restricting oxygen to the brain through hyperventilation, resulting in hallucinations and modified perceptions.",
      "Scientific research has explored this phenomenon, likening the impacts to those of psychedelic drugs.",
      "Debates center on how breathwork can influence brain chemistry, mental health, and overall wellness."
    ],
    "points": 128,
    "commentCount": 41,
    "retryCount": 0,
    "time": 1715198098
  },
  {
    "id": 40303661,
    "title": "Creating Linux Windows Without Xlib: A Socket-Based Approach",
    "originLink": "https://hereket.com/posts/from-scratch-x11-windowing/",
    "originBody": "Hereket Posts Tiny Opening windows in linux with sockets, bare hands and 200 lines of C 2024-05-08 Intro Open connection Creating window Mapping (showing) window Event loop Additional Functionality Open font Create Graphic Context (GC) Writing text Final code Conclusion Intro In this post I want to create a single file C file program to open a windows inside Linux without using xlib or any similar libraries. The idea is to explore X11 protocol and see how it is used to interact with X server to create windows. Before I had strong association that X11 was some magic thing to manipulate windows and it’s resources. I was very surprised to learn that it is actually just a “regular” network protocol for two parties to communicate like HTTP, FTP, IMAP, SMPT and etc. But if in IMAP your have a server that contains all your emails and you send it commands to get information about emails and get their content. In X11 you have a server that contains all your windows and its resources and you just communicate with it via a connection. To do this the only resource we need is X11 documentation. It is a very small document and can be easily consumed to better understand window communication in linux systems that still use Xorg for window management. The strange thing is that this document is way more approachable that Xlib’s documentation which totally broke my illusion that Xlib was supposed to simplify X11. In this post we will try to implement this model: Open connection Xorg uses unix sockets instead of regular sockets for the communication with the apps. (You can switch it to using regular sockets if you want to monitor connections in wireshark. Look in one of my old articles on how to do it) For us, regular users, it does not really matter as everything will be pretty much the same with only tiny difference in socket setup. int Socket = socket(AF_UNIX, SOCK_STREAM, 0); VerifyOrDie(Socket > 0, \"Couldn't open a socket(...)\"); struct sockaddr_un Address; memset(&Address, 0, sizeof(struct sockaddr_un)); Address.sun_family = AF_UNIX; strncpy(Address.sun_path, \"/tmp/.X11-unix/X0\", sizeof(Address.sun_path)-1); int Status = connect(Socket, (struct sockaddr *)&Address, sizeof(Address)); VerifyOrDieWidthErrno(Status == 0, \"Couldn't connect to a unix socket with connect(...)\"); We just get socket from the kernel with socket(…) but use AF_UNIX instead of AF_INET to tell it that we are plan to setup unix socket communication. Then we use regular connect(…) to connect the socket. Another difference is that we are using struct sockaddr_un for the connection description and set it’s path to: /tmp/.X11-unix/X0 To simplify error checking and to reduce code size I am using this two utility function for easier error checking and reporting. They check if condition is correct. If not they just print error and fully exit out of program execution. void VerifyOrDie(int IsSuccess, const char *Message) { if(!IsSuccess) { fprintf(stderr, \"%s\", Message); exit(13); } } void VerifyOrDieWidthErrno(int IsSuccess, const char *Message) { if(!IsSuccess) { perror(Message); exit(13); } } This is pretty much. With just this we are ready to comuunicate with the X server. Initially server expects a connection iniation from user and the very first byte of the request must be a identification of communication byte order: little endian or big endian. Documentation calls it MSB (Most significant byte) and LSB(Least signification byte). After this byte is sent all data will be processed as either little endian or big endian untill connection termination. Two possible values for this first byte is ’l’ (0x6c) or ‘B’ (0x42). In earlier implementation of this program I used struct to hold this initialization data and later just serialize it to send over the socket. But then I came to a conclusion that for demonstration purposes using just an array and filling it ‘by hand’ is a better and simpler approach to show the concept. Initial request seems like a lot of information to fill but if we skip authorization process we can drastically reduce amount of code we need to write and understand. So for this I chose to not use authorization with a little trick. This give us just two parameters that we need to fill: stream endiannes and major version (minor version is set automatically). uint8_t InitializationRequest[12] = {}; InitializationRequest[0] = 'l'; InitializationRequest[2] = 11; We are creating an array of 12 bytes. First byte we set to ’l’ or 0x6c and third byte to 11 to indicate 11th version of the protocol. Everything else is set to 0 by initialization and indicates to X server that we will not be using and sending any authorization data. For this simplification to work we need to disable regular cookie based authentication and allow all app on local machine to connect to X server directly. To to that you need to open a terminal and type xhost +local: Later if you want to revert back you could use xhost -local: to force cookie based authentication back. We could have implemented basic authentication but it is not described in the general X11 documentation page linked above and we decided to stick only to that one document. Plus it is not really that interesting and we can save some screen space. If you forget to disable authentication you will get this error when you run final program: State: 0 MajorVersion: 11 MinorVersion: 0 AdditionalDataLength: 16 Reason: Authorization required, but no authorization protocol specified With this details done we can just simply send our initialization request and read back data. char SendBuffer[16*1024] = {}; char ReadBuffer[16*1024] = {}; int BytesWritten = write(Socket, (char*)&InitializationRequest, sizeof(InitializationRequest)); VerifyOrDie(BytesWritten == sizeof(InitializationRequest), \"Wrong amount of bytes written during initialization\"); int BytesRead = read(Socket, ReadBuffer, 8); If we look into documentation, we will see that there are three possible responses to initialization request: error, authentication and sucess. We can safely ignore authentication as we are using it in this example. Error usually means that the connection is refused (with some explanation why). No matter what response type we get back first byte will always indicate response type: 0 - Failed, 2 - Authenticate, 1 - Success. Success response will pretty big and error/authenticate responses will be at least 8 bytes. For this reason we can safely request to read 8 bytes to get basic info about what happend with our request and info about server. One importannt sidenote is that we create two buffers of 16 killobytes on the stack and use it for reading and writing data. This is safe amount for basic communication with server and helps use to not think about about rosource management in this context. Also we don’t need to clear whole buffer after we done processing it since specification allows having ‘dirty bytes’ in areas that are not in the perimeter of current request/response. After that we can choose how to continue our processing based on the first byte. if(ReadBuffer[0] == RESPONSE_STATE_FAILED) { DumpResponseError(Socket, ReadBuffer); } else if(ReadBuffer[0] == RESPONSE_STATE_AUTHENTICATE) { AuthenticateX11(); } else if(ReadBuffer[0] == RESPONSE_STATE_SUCCESS) { ... } Here are utility functions to dump information on error. void DumpResponseError(int Socket, char* ReadBuffer) { uint8_t ReasonLength = ReadBuffer[1]; uint16_t MajorVersion = *((uint16_t*)&ReadBuffer[2]); uint16_t MinorVersion = *((uint16_t*)&ReadBuffer[4]); uint16_t AdditionalDataLength = *((uint16_t*)&ReadBuffer[6]); // Length in 4-byte units of \"additional data\" uint8_t *Message = (uint8_t*)&ReadBuffer[8]; int BytesRead = read(Socket, ReadBuffer + 8, READ_BUFFER_SIZE-8); printf(\"State: %d\", ReadBuffer[0]); printf(\"MajorVersion: %d\", MajorVersion); printf(\"MinorVersion: %d\", MinorVersion); printf(\"AdditionalDataLength: %d\", AdditionalDataLength); printf(\"Reason: %s\", Message); } void AuthenticateX11() { fprintf(stderr, \"Current version of the app does not support authentication.\"); exit(13); } So if we get anything but success we just print debug information and exit the program. When we get normal success response we have to do some work to process returned response. BytesRead = read(Socket, ReadBuffer + 8, READ_BUFFER_SIZE-8); uint16_t MajorVersion = *((uint16_t*)&ReadBuffer[2]); uint16_t MinorVersion = *((uint16_t*)&ReadBuffer[4]); uint16_t AdditionalDataLength = *((uint16_t*)&ReadBuffer[6]); // Length in 4-byte units of \"additional data\" uint32_t ResourceIdBase = *((uint32_t*)&ReadBuffer[12]); uint32_t ResourceIdMask = *((uint32_t*)&ReadBuffer[16]); uint16_t LengthOfVendor = *((uint16_t*)&ReadBuffer[24]); uint8_t NumberOfFormants = *((uint16_t*)&ReadBuffer[29]); uint8_t *Vendor = (uint8_t *)&ReadBuffer[40]; int32_t VendorPad = PAD(LengthOfVendor); int32_t FormatByteLength = 8 * NumberOfFormants; int32_t ScreensStartOffset = 40 + LengthOfVendor + VendorPad + FormatByteLength; uint32_t RootWindow = *((uint32_t*)&ReadBuffer[ScreensStartOffset]); uint32_t RootVisualId = *((uint32_t*)&ReadBuffer[ScreensStartOffset + 32]); GlobalIdBase = ResourceIdBase; GlobalIdMask = ResourceIdMask; GlobalRootWindow = RootWindow; GlobalRootVisualId = RootVisualId; First of all we read all output from server. We ask to read buffer size (16k) minus 8 bytes that we already read an put it inside our buffer by offsetting 8 bytes of already read data. In my system this second read(…) returned 9804 bytes or 9804+8 = 9812 total response bytes for our initialization request. Documentation show that this binary format contains quite a few information: basic server info, root window, data formats, types, screen info, depth info, visual types and etc. For a full blown production system it better to parse it it all but in our exploratory phase we can get just the basics and get away with it. Major version, minor version, additional length are not required but I got them to verify that everything is working as expected. Then we get Resource Id Base and Resource Id Mask. What are these? Well unfortunately even though X server is managing window resources it delegates “naming” resource to us (the client). It might me for optimisation purposes. So what this means is that when we need to create a window, crete graphic context or font we must provide the “name” for it. This “name” is just an increasing integer value with some processing. Id does not have to be contigous and can be reused once resource is freed but we won’t be doing ID management here just get increasing numbers without reusing. Also Resource ID’s have never top three bits set. To get id we take our local id and OR it with resource base id. In my system when I run this code I get base id of ‘0x3200000’ and mask of ‘0x1fffff’. So let’s if I have a local resouce if of 1 then I OR it with 0x3200000 and just mask it with 0x1fffff just to make sure that id has to three bits ’turned off’. Next we use NumberOfFormants, VendorPad, FormatByteLength to get ScreensStartOffset which in turn is used to get offset to first screen data bytes. From this we need RootWindow and RootVisualId. And this is pretty much all that wee needed from all that 9kb response. Then I just put them into global variables for later use. (A better approach is to contain it all in a struct but we are not architecturing software here but just exploring a protocol). PAD macro just calculates padding to make sure that data length is multiple of 4; And with this we conclude intiation. There are a lot of words but basically we just send one small request and get back large response. Creating window Here we will be create a request to create a window. int32_t WindowId = GetNextId(); int32_t Depth = 0; int32_t X = 100; int32_t Y = 100; uint32_t Width = 600; uint32_t Height = 300; uint32_t BorderWidth = 1; int32_t CreateWindowFlagCount = 2; int RequestLength = 8+CreateWindowFlagCount; SendBuffer[0] = X11_REQUEST_CREATE_WINDOW; SendBuffer[1] = Depth; *((int16_t *)&SendBuffer[2]) = RequestLength; *((int32_t *)&SendBuffer[4]) = WindowId; *((int32_t *)&SendBuffer[8]) = GlobalRootWindow; *((int16_t *)&SendBuffer[12]) = X; *((int16_t *)&SendBuffer[14]) = Y; *((int16_t *)&SendBuffer[16]) = Width; *((int16_t *)&SendBuffer[18]) = Height; *((int16_t *)&SendBuffer[20]) = BorderWidth; *((int16_t *)&SendBuffer[22]) = WINDOWCLASS_INPUTOUTPUT; *((int32_t *)&SendBuffer[24]) = GlobalRootVisualId; *((int32_t *)&SendBuffer[28]) = X11_FLAG_WIN_EVENTX11_FLAG_BACKGROUND_PIXEL; *((int32_t *)&SendBuffer[32]) = 0xff000000; *((int32_t *)&SendBuffer[36]) = X11_EVENT_FLAG_EXPOSUREX11_EVENT_FLAG_KEY_PRESS; BytesWritten = write(Socket, (char *)&SendBuffer, RequestLength*4); Here we just setup basic variables for readability puproses and the fill an array SenbBuffer array with relevant data. And then just send it. First byte is always describes request. In this case we are creating a window and set it to 1. Depth parameter is not that important and we can set it to 0. Next we calclate RequestLength. This always indicates total request size including header and extra parameters. The only caveat is that it is measured in 4 byte chunks. So we have 32 required bytes and some extra. Thus we have 32/4=8 bytes and extra 2 four byte blocks for extra data. Documentation explains this dynamic LISTofVALUE as “The value-list contains one value for each bit set to 1 in the mask, from least significant to most significant bit in the mask.” Since the mask is X11_FLAG_WIN_EVENTX11_FLAG_BACKGROUND_PIXEL or 0x000000020x00000800. This in turn give us ‘0b100000000010’. So background pixel will be first value to be provided and second is a list of event masks. For the background we provided just a black color with 0xff000000. You can easily change it to green by replacing it with 0xff00ff00. Next value (starting byte 36) we provide xored list of events that we want to recieve back from X server. In this case we want to get back Exposure (0x8000) and KeyPress (0x0001) events. These will be important later once we start processing event from server. One thing I didn’t show is GetNextId(). It is just a utility function of the functionality discussed earlier about how to “generate” new if for a resource. For simplicity it uses global index of last id and increases it by on each iteration. int32_t GetNextId() { int32_t Result = (GlobalIdMask & GlobalId)GlobalIdBase; GlobalId += 1; return Result; } Mapping (showing) window By this time we have already create a window resource on the server side. It is not shown to the screen yet because we need to map it first. Compared to creating window this request is pretty small. SendBuffer[0] = X11_REQUEST_MAP_WINDOW; SendBuffer[1] = 0; // NOTE: Unused *((int16_t *)&SendBuffer[2]) = 2; *((int32_t *)&SendBuffer[4]) = WindowId; BytesWritten = write(Socket, (char *)&SendBuffer, 2*4); As usual we user first byte to set request type. This time it is “Map Window” or 0x8. Second byte is unused and can be set to anything. Third byte is request size which we set to 2 (result of 8/4). And the last byte parameter we set the window ID created in the last step. With this we are pretty much done with basic window opening. Now if we just put something like sleep(5) at the end of the code we will get a window which will be shown for 5 seconds. Then after the 5 seconds are passed the program will close and X server will recycle all resources. Event loop Instead of sleeping let’s try to actually create a loop that will listen events sent back to us from server and just block when there is nothing to do or to show. Since when creating we indicated that we are interested in Exposure and KeyPress events there will be event to notify about regions that need to up repainted and pressed keys. For this I chose to use linux regular polling mechanism which will block us untill we have something to do. Nothing special. Just setup one socket descriptor into list. struct pollfd PollDescriptors[1] = {}; PollDescriptors[0].fd = Socket; PollDescriptors[0].events = POLLIN; int32_t DescriptorCount = 1; Then we can create an endless loop which will be check if a IsProgramRunning variable set to true or false (1 or 0). int32_t IsProgramRunning = 1; while(IsProgramRunning){ int32_t EventCount = poll(PollDescriptors, DescriptorCount, -1); if(PollDescriptors[0].revents & POLLERR) { fprintf(stderr, \"------- Error\"); } if(PollDescriptors[0].revents & POLLHUP) { printf(\"---- Connection close\"); IsProgramRunning = 0; } GetAndProcessReply(PollDescriptors[0].fd); } When we call poll(…) we set timeout to -1 to make sure it never times out. Once there is an event the program will unblock and continue execution. Then we check if the event was error or we the connection hung up. On error we just log it and continue like nothing happened. On POLLHUP (program close) just terminate program. Else we just process the reply. void PrintResponseError(char *Data, int32_t Size) { char ErrorCode = Data[1]; printf(\"\\033[0;31m\"); printf(\"Response Error: [%d]\", ErrorCode); printf(\"\\033[0m\"); } void PrintAndProcessEvent(char *Data, int32_t Size) { char EventCode = Data[0]; printf(\"Some event occured: %d\", EventCode); } void GetAndProcessReply(int Socket) { char Buffer[1024] = {}; int32_t BytesRead = read(Socket, Buffer, 1024); uint8_t Code = Buffer[0]; if(Code == 0) { PrintResponseError(Buffer, BytesRead); } else if (Code == 1) { printf(\"---------------- Reply to request\"); } else { PrintAndProcessEvent(Buffer, BytesRead); } } And with this we have a “fully functional” window with event loop. Even though the processing is pretty simple and we just log errors and events but still from here it will be that hard to extend and try more advanced events processing. Whole code for simple version for this program (about 200 lines of code) #include#include#include#include#include#include#include#includeint32_t GlobalId = 0; int32_t GlobalIdBase = 0; int32_t GlobalIdMask = 0; int32_t GlobalRootWindow = 0; int32_t GlobalRootVisualId = 0; #define READ_BUFFER_SIZE 16*1024 #define RESPONSE_STATE_FAILED 0 #define RESPONSE_STATE_SUCCESS 1 #define RESPONSE_STATE_AUTHENTICATE 2 #define X11_REQUEST_CREATE_WINDOW 1 #define X11_REQUEST_MAP_WINDOW 8 #define X11_REQUEST_IMAGE_TEXT_8 76 #define X11_REQUEST_OPEN_FONT 45 #define X11_REQUEST_CREATE_GC 55 #define X11_EVENT_FLAG_KEY_PRESS 0x00000001 #define X11_EVENT_FLAG_KEY_RELEASE 0x00000002 #define X11_EVENT_FLAG_EXPOSURE 0x8000 #define PAD(N) ((4 - (N % 4)) % 4) void VerifyOrDie(int IsSuccess, const char *Message) { if(!IsSuccess) { fprintf(stderr, \"%s\", Message); exit(13); } } void VerifyOrDieWidthErrno(int IsSuccess, const char *Message) { if(!IsSuccess) { perror(Message); exit(13); } } void DumpResponseError(int Socket, char* ReadBuffer) { uint8_t ReasonLength = ReadBuffer[1]; uint16_t MajorVersion = *((uint16_t*)&ReadBuffer[2]); uint16_t MinorVersion = *((uint16_t*)&ReadBuffer[4]); uint16_t AdditionalDataLength = *((uint16_t*)&ReadBuffer[6]); // Length in 4-byte units of \"additional data\" uint8_t *Message = (uint8_t*)&ReadBuffer[8]; int BytesRead = read(Socket, ReadBuffer + 8, READ_BUFFER_SIZE-8); printf(\"State: %d\", ReadBuffer[0]); printf(\"MajorVersion: %d\", MajorVersion); printf(\"MinorVersion: %d\", MinorVersion); printf(\"AdditionalDataLength: %d\", AdditionalDataLength); printf(\"Reason: %s\", Message); } void AuthenticateX11() { fprintf(stderr, \"Current version of the app does not support authentication.\"); fprintf(stderr, \"Please run 'xhost +local:' in your terminal to disable cookie based authentication\"); fprintf(stderr, \"and allow local apps to communication with Xorg without it.\"); } int32_t GetNextId() { int32_t Result = (GlobalIdMask & GlobalId)GlobalIdBase; GlobalId += 1; return Result; } void PrintResponseError(char *Data, int32_t Size) { char ErrorCode = Data[1]; printf(\"\\033[0;31m\"); printf(\"Response Error: [%d]\", ErrorCode); printf(\"\\033[0m\"); } void PrintAndProcessEvent(char *Data, int32_t Size) { char EventCode = Data[0]; printf(\"Some event occured: %d\", EventCode); } void GetAndProcessReply(int Socket) { char Buffer[1024] = {}; int32_t BytesRead = read(Socket, Buffer, 1024); uint8_t Code = Buffer[0]; if(Code == 0) { PrintResponseError(Buffer, BytesRead); } else if (Code == 1) { printf(\"---------------- Unexpected reply\"); } else { // NOTE: Event? PrintAndProcessEvent(Buffer, BytesRead); } } int main(){ int Socket = socket(AF_UNIX, SOCK_STREAM, 0); VerifyOrDie(Socket > 0, \"Couldn't open a socket(...)\"); struct sockaddr_un Address; memset(&Address, 0, sizeof(struct sockaddr_un)); Address.sun_family = AF_UNIX; strncpy(Address.sun_path, \"/tmp/.X11-unix/X0\", sizeof(Address.sun_path)-1); int Status = connect(Socket, (struct sockaddr *)&Address, sizeof(Address)); VerifyOrDieWidthErrno(Status == 0, \"Couldn't connect to a unix socket with connect(...)\"); char SendBuffer[16*1024] = {}; char ReadBuffer[16*1024] = {}; uint8_t InitializationRequest[12] = {}; InitializationRequest[0] = 'l'; InitializationRequest[1] = 0; InitializationRequest[2] = 11; int BytesWritten = write(Socket, (char*)&InitializationRequest, sizeof(InitializationRequest)); VerifyOrDie(BytesWritten == sizeof(InitializationRequest), \"Wrong amount of bytes written during initialization\"); int BytesRead = read(Socket, ReadBuffer, 8); if(ReadBuffer[0] == RESPONSE_STATE_FAILED) { DumpResponseError(Socket, ReadBuffer); } else if(ReadBuffer[0] == RESPONSE_STATE_AUTHENTICATE) { AuthenticateX11(); } else if(ReadBuffer[0] == RESPONSE_STATE_SUCCESS) { printf(\"INIT Response SUCCESS. BytesRead: %d\", BytesRead); BytesRead = read(Socket, ReadBuffer + 8, READ_BUFFER_SIZE-8); printf(\"---------------------------%d\", BytesRead); /* -------------------------------------------------------------------------------- */ uint8_t _Unused = ReadBuffer[1]; uint16_t MajorVersion = *((uint16_t*)&ReadBuffer[2]); uint16_t MinorVersion = *((uint16_t*)&ReadBuffer[4]); uint16_t AdditionalDataLength = *((uint16_t*)&ReadBuffer[6]); // Length in 4-byte units of \"additional data\" uint32_t ResourceIdBase = *((uint32_t*)&ReadBuffer[12]); uint32_t ResourceIdMask = *((uint32_t*)&ReadBuffer[16]); uint16_t LengthOfVendor = *((uint16_t*)&ReadBuffer[24]); uint8_t NumberOfFormants = *((uint16_t*)&ReadBuffer[29]); uint8_t *Vendor = (uint8_t *)&ReadBuffer[40]; int32_t VendorPad = PAD(LengthOfVendor); int32_t FormatByteLength = 8 * NumberOfFormants; int32_t ScreensStartOffset = 40 + LengthOfVendor + VendorPad + FormatByteLength; uint32_t RootWindow = *((uint32_t*)&ReadBuffer[ScreensStartOffset]); uint32_t RootVisualId = *((uint32_t*)&ReadBuffer[ScreensStartOffset + 32]); GlobalIdBase = ResourceIdBase; GlobalIdMask = ResourceIdMask; GlobalRootWindow = RootWindow; GlobalRootVisualId = RootVisualId; printf(\"Base: %d\", ResourceIdBase); printf(\"IdMask: %d\", ResourceIdMask); printf(\"LengthOfVendor: %d\", LengthOfVendor); /* -------------------------------------------------------------------------------- */ // ------------------------------ Create Window int32_t WindowId = GetNextId(); int32_t Depth = 0; int32_t X = 100; int32_t Y = 100; uint32_t Width = 600; uint32_t Height = 300; uint32_t BorderWidth = 1; int32_t CreateWindowFlagCount = 2; int RequestLength = 8+CreateWindowFlagCount; #define WINDOWCLASS_COPYFROMPARENT 0 #define WINDOWCLASS_INPUTOUTPUT 1 #define WINDOWCLASS_INPUTONLY 2 #define X11_FLAG_BACKGROUND_PIXEL 0x00000002 #define X11_FLAG_WIN_EVENT 0x00000800 SendBuffer[0] = X11_REQUEST_CREATE_WINDOW; SendBuffer[1] = Depth; *((int16_t *)&SendBuffer[2]) = RequestLength; *((int32_t *)&SendBuffer[4]) = WindowId; *((int32_t *)&SendBuffer[8]) = GlobalRootWindow; *((int16_t *)&SendBuffer[12]) = X; *((int16_t *)&SendBuffer[14]) = Y; *((int16_t *)&SendBuffer[16]) = Width; *((int16_t *)&SendBuffer[18]) = Height; *((int16_t *)&SendBuffer[20]) = BorderWidth; *((int16_t *)&SendBuffer[22]) = WINDOWCLASS_INPUTOUTPUT; *((int32_t *)&SendBuffer[24]) = GlobalRootVisualId; *((int32_t *)&SendBuffer[28]) = X11_FLAG_WIN_EVENTX11_FLAG_BACKGROUND_PIXEL; *((int32_t *)&SendBuffer[32]) = 0xff000000; *((int32_t *)&SendBuffer[36]) = X11_EVENT_FLAG_EXPOSUREX11_EVENT_FLAG_KEY_PRESS; BytesWritten = write(Socket, (char *)&SendBuffer, RequestLength*4); printf(\"Create Window: BytesWritten: %d\", BytesWritten); // ------------------------------ Map Window SendBuffer[0] = X11_REQUEST_MAP_WINDOW; SendBuffer[1] = 0; *((int16_t *)&SendBuffer[2]) = 2; *((int32_t *)&SendBuffer[4]) = WindowId; BytesWritten = write(Socket, (char *)&SendBuffer, 2*4); printf(\"Map Window: BytesWritten: %d\", BytesWritten); /* ------------------------------------------------------------------------------- */ struct pollfd PollDescriptors[1] = {}; PollDescriptors[0].fd = Socket; PollDescriptors[0].events = POLLIN; int32_t DescriptorCount = 1; int32_t IsProgramRunning = 1; while(IsProgramRunning){ int32_t EventCount = poll(PollDescriptors, DescriptorCount, -1); if(PollDescriptors[0].revents & POLLERR) { printf(\"------- Error\"); } if(PollDescriptors[0].revents & POLLHUP) { printf(\"---- Connection close\"); IsProgramRunning = 0; } GetAndProcessReply(PollDescriptors[0].fd); } } } To compile it just run this from terminal: gcc basic.c -o basic Here is video showing how it looks: Additional Functionality Now let’s try to add some extra functionality and see if will be to complex to extend it and see if we can actually see something somewhat useful on the screen. First of all I will make tiny refactoring and move some code into functions to make code a bit more readable. Specifically we will move intiation, window creation and mapping into their specific functions. The event loop will remain the same for now. int SetupStatus = X_InitiateConnection(Socket); if(SetupStatus == 0) { // X, Y, Width, Height setup int WindowId = X_CreatWindow(Socket, X, Y, Width, Height); X_MapWindow(Socket, WindowId); // Event loop } X_InitiateConnection, X_CreatWindow, X_MapWindow are just condensed code from previous section. Open font In the end I am planning to use some text for that we will need to ask for a front from the X server. The drill is pretty much the same thing. Prepare data, stuck into buffer and send it to the server. void X_OpenFont(i32 Socket, i8 *FontName, i32 FontId) { char SendBuffer[16*1024] = {}; int BytesWritten = 0; int BytesRead = 0; i32 FontNameLength = strlen((char *)FontName); i32 Pad = PAD(FontNameLength); int RequestLength = (3 + (FontNameLength + Pad)/4); SendBuffer[0] = X11_REQUEST_OPEN_FONT; SendBuffer[1] = 0; *((u16 *)&SendBuffer[2]) = RequestLength; *((u32 *)&SendBuffer[4]) = FontId; *((u16 *)&SendBuffer[8]) = FontNameLength; strncpy(SendBuffer + 12, (char *)FontName, FontNameLength); i32 WriteSize = 12 + FontNameLength + Pad; BytesWritten = write(Socket, (char *)&SendBuffer, WriteSize); } FontId is something that we as client generate ourself. For that we have GetNextId(). We pass it and a font name to the function requesting server to create font resource with specified ID and try to find closest match to the name we provided. Create Graphic Context (GC) A lot of window operations require graphic context to do it’s operations. So we need to get it before we can do any graphic changing actions. void X_CreateGC(int32_t Socket, int32_t GcId, int32_t FontId) { char SendBuffer[16*1024] = {}; int32_t CreateGcFlagCount = 3; int RequestLength = 4 + CreateGcFlagCount; SendBuffer[0] = X11_REQUEST_CREATE_GC; SendBuffer[1] = 0; *((int16_t *)&SendBuffer[2]) = RequestLength; *((int32_t *)&SendBuffer[4]) = GcId; *((int32_t *)&SendBuffer[8]) = GlobalRootWindow; *((int32_t *)&SendBuffer[12]) = X11_FLAG_FGX11_FLAG_BGX11_FLAG_FONT; *((int32_t *)&SendBuffer[16]) = 0xFF00FF00; // Foreground *((int32_t *)&SendBuffer[20]) = 0xFF000000; // Background *((int32_t *)&SendBuffer[24]) = FontId; // Font write(Socket, (char *)&SendBuffer, RequestLength*4); } Here we see similar patter of passing parameters based on mask and it’s bit offsets. We have required 16 bytes of setup data and extra variable bytes based on how much data we want to set. In this example we are setting just font, background and forground colors. Thus we set X11_FLAG_FGX11_FLAG_BGX11_FLAG_FONT mask bits and pass appropriate parameters at the end of the request. There are quite a few parameters that can be passed like different stroke types, drawing functions and etc. But we stick to simplicity for now. Writing text The last function for today will be text writing. It is pretty simple. void WriteText(int Socket, int WindowId, int GCid, i16 X, i16 Y, const char *Text, i32 TextLength) { char SendBuffer[16*1024] = {}; u32 ContentLength = 4 + (TextLength + PAD(TextLength))/4; SendBuffer[0] = (u8)X11_REQUEST_IMAGE_TEXT_8; SendBuffer[1] = TextLength; *((i16 *)&SendBuffer[2]) = ContentLength; *((i32 *)&SendBuffer[4]) = WindowId; *((i32 *)&SendBuffer[8]) = GCid; *((i16 *)&SendBuffer[12]) = X; *((i16 *)&SendBuffer[14]) = Y; strncpy(&SendBuffer[16], (char *)Text, TextLength); write(Socket, (char *)&SendBuffer, ContentLength*4); } We repeated this drill so many times that it should be trivial by now. Calculating length in 4 byte blocks. Set required where we want to draw (window), which brush to draw with (graphic context) and X,Y offsets in the window where we want to draw. At the of request copy the text that we want to draw. And that is it. The only thing left if draw this text on ech refresh. Here for simplicity purposes we will be drawing text on each event but correct approach would have been to draw it on Expose events. But the text already became too be big so simplicity wins today. So in the main loop we add this code: const char* t1 = \"Hello, World!\"; const char* t2 = \"This is a test text directly written to X\"; const char* t3 = \"Whooha. Is this even legal? Let's keep a secret!\"; WriteText(Socket, WindowId, GcId, 10, 20, t1, strlen(t1)); WriteText(Socket, WindowId, GcId, 10, 35, t2, strlen(t2)); WriteText(Socket, WindowId, GcId, 10, 50, t3, strlen(t3)); And that is it! Hey we build a simple window with text. Congratulations. Here is full source code which contains a bit more functionality than discussed in post (text movement and more detailed debug info): Final code #include#include#include#include#include#include#include#includeint32_t GlobalId = 0; int32_t GlobalIdBase = 0; int32_t GlobalIdMask = 0; int32_t GlobalRootWindow = 0; int32_t GlobalRootVisualId = 0; int32_t GlobalTextOffsetX = 10; int32_t GlobalTextOffsetY = 20; #define READ_BUFFER_SIZE 16*1024 #define RESPONSE_STATE_FAILED 0 #define RESPONSE_STATE_SUCCESS 1 #define RESPONSE_STATE_AUTHENTICATE 2 #define X11_REQUEST_CREATE_WINDOW 1 #define X11_REQUEST_MAP_WINDOW 8 #define X11_REQUEST_IMAGE_TEXT_8 76 #define X11_REQUEST_OPEN_FONT 45 #define X11_REQUEST_CREATE_GC 55 #define X11_EVENT_FLAG_KEY_PRESS 0x00000001 #define X11_EVENT_FLAG_KEY_RELEASE 0x00000002 #define X11_EVENT_FLAG_EXPOSURE 0x8000 #define WINDOWCLASS_COPYFROMPARENT 0 #define WINDOWCLASS_INPUTOUTPUT 1 #define WINDOWCLASS_INPUTONLY 2 #define X11_FLAG_BACKGROUND_PIXEL 0x00000002 #define X11_FLAG_WIN_EVENT 0x00000800 #define X11_FLAG_FG 0x00000004 #define X11_FLAG_BG 0x00000008 #define X11_FLAG_FONT 0x00004000 #define X11_FLAG_GC_EXPOSURE 0x00010000 #define PAD(N) ((4 - (N % 4)) % 4) void VerifyOrDie(int IsSuccess, const char *Message) { if(!IsSuccess) { fprintf(stderr, \"%s\", Message); exit(13); } } void VerifyOrDieWidthErrno(int IsSuccess, const char *Message) { if(!IsSuccess) { perror(Message); exit(13); } } void DumpResponseError(int Socket, char* ReadBuffer) { uint8_t ReasonLength = ReadBuffer[1]; uint16_t MajorVersion = *((uint16_t*)&ReadBuffer[2]); uint16_t MinorVersion = *((uint16_t*)&ReadBuffer[4]); uint16_t AdditionalDataLength = *((uint16_t*)&ReadBuffer[6]); // Length in 4-byte units of \"additional data\" uint8_t *Message = (uint8_t*)&ReadBuffer[8]; int BytesRead = read(Socket, ReadBuffer + 8, READ_BUFFER_SIZE-8); printf(\"State: %d\", ReadBuffer[0]); printf(\"MajorVersion: %d\", MajorVersion); printf(\"MinorVersion: %d\", MinorVersion); printf(\"AdditionalDataLength: %d\", AdditionalDataLength); printf(\"Reason: %s\", Message); } void AuthenticateX11() { fprintf(stderr, \"Current version of the app does not support authentication.\"); fprintf(stderr, \"Please run 'xhost +local:' in your terminal to disable cookie based authentication\"); fprintf(stderr, \"and allow local apps to communication with Xorg without it.\"); } int32_t GetNextId() { int32_t Result = (GlobalIdMask & GlobalId)GlobalIdBase; GlobalId += 1; return Result; } void PrintResponseError(char *Data, int32_t Size) { char ErrorCode = Data[1]; const char *ErrorNames[] = { \"Unknown Error\", \"Request\", \"Value\", \"Window\", \"Pixmap\", \"Atom\", \"Cursor\", \"Font\", \"Match\", \"Drawable\", \"Access\", \"Alloc\", \"Colormap\", \"GContext\", \"IDChoice\", \"Name\", \"Length\", \"Implementation\", }; const char* ErrorName = \"Unknown error\"; if(ErrorCode0, \"Couldn't open a socket(...)\"); struct sockaddr_un Address; memset(&Address, 0, sizeof(struct sockaddr_un)); Address.sun_family = AF_UNIX; strncpy(Address.sun_path, \"/tmp/.X11-unix/X0\", sizeof(Address.sun_path)-1); int Status = connect(Socket, (struct sockaddr *)&Address, sizeof(Address)); VerifyOrDieWidthErrno(Status == 0, \"Couldn't connect to a unix socket with connect(...)\"); int SetupStatus = X_InitiateConnection(Socket); if(SetupStatus == 0) { int32_t X = 100; int32_t Y = 100; uint32_t Width = 600; uint32_t Height = 300; int WindowId = X_CreatWindow(Socket, X, Y, Width, Height); X_MapWindow(Socket, WindowId); int32_t FontId = GetNextId(); X_OpenFont(Socket, (int8_t *)\"fixed\", FontId); int32_t GcId = GetNextId(); X_CreateGC(Socket, GcId, FontId); struct pollfd PollDescriptors[1] = {}; PollDescriptors[0].fd = Socket; PollDescriptors[0].events = POLLIN; int32_t DescriptorCount = 1; int32_t IsProgramRunning = 1; while(IsProgramRunning){ int32_t EventCount = poll(PollDescriptors, DescriptorCount, -1); if(PollDescriptors[0].revents & POLLERR) { printf(\"------- Error\"); } if(PollDescriptors[0].revents & POLLHUP) { printf(\"---- Connection close\"); IsProgramRunning = 0; } char* t1 = \"Hello, World!\"; char* t2 = \"This is a test text directly written to X\"; char* t3 = \"Whooha. Is this even legal? Let's keep a secret!\"; WriteText(Socket, WindowId, GcId, GlobalTextOffsetX, GlobalTextOffsetY, t1, strlen(t1)); WriteText(Socket, WindowId, GcId, GlobalTextOffsetX, GlobalTextOffsetY + 15, t2, strlen(t2)); WriteText(Socket, WindowId, GcId, GlobalTextOffsetX, GlobalTextOffsetY + 30, t3, strlen(t3)); GetAndProcessReply(PollDescriptors[0].fd); } } } Compile it with: gcc main.c -o main Here is how it looks. Conclusion X Server is slowly being depricated in the linux world and being replaced Wayland. Still X11 is an interesting protocol to look at from the perspective of binary communication and management of resource which require fast speeds. In this post I tried to cover basic information and create a simple but working app that is simple, defined in single file and easily compiles. No external code except libc was used. I find it fascinating when you can open black boxes and see how gears move each other. Hope you liked it as well. © 2024, Hereket RSS feed",
    "commentLink": "https://news.ycombinator.com/item?id=40303661",
    "commentBody": "Opening Windows in Linux with sockets, bare hands and 200 lines of C (hereket.com)123 points by libcheet 10 hours agohidepastfavorite49 comments txdv 2 hours agoThe X Windowing system is a hackers delight. If you have a remote server with UI, you can set up a X Window server on your Windows/MacOS machine and forward via SSH X messages to use GUI apps on your server, but view the result locally. The Responsiveness of the UI depends on your network capabilities. reply bdowling 55 minutes agoparentThis is fun and all, but if you lose your connection, your windows will go away and your program will usually exit. It’s almost always more usable to run a desktop session in Xvnc on the server and connect to it with a VNC client, because if you get disconnected, you can just reconnect. reply amelius 11 minutes agorootparentVNC is also much faster in most cases, because the X protocol requires a lot of round trips that waste a lot of time. So instead the VNC server \"runs these round-trips locally\" (so to speak) and you only interact with the pixels remotely. X was developed when bandwidth was as limiting as latency but nowadays only latency is limiting so a different protocol makes more sense. reply t-3 42 minutes agorootparentprevYou can use xpra: https://xpra.org/index.html reply HPsquared 50 minutes agorootparentprevThis also works for running a Linux GUI on your phone in Termux. Termux+localhost VNC is the way for this. reply cyberpunk 1 hour agoparentprevMeh we used to have to install oracle databases this way, and the performance was always shit even over direct connections w/cross cables. I don’t think x over ssh is useful for much, can you imagine a browser this way? reply SassyBird 59 minutes agorootparentIt’s usually SSH that’s the bottleneck though. If you just expose your local X11 TCP server port and connect to it from the server (X11 client) by setting the DISPLAY env properly, it will be much more responsive. Often indistinguishable from local apps. Secure the port with Wireguard, if you want to be a bit more responsible and still have good performance. Checked with Firefox, which works like a charm this way, but is unusable over SSH. reply guenthert 39 minutes agorootparent> If you just expose your local X11 TCP server port and connect to it from the server (X11 client) by setting the DISPLAY env properly, it will be much more responsive. That's fine on a LAN with low or sub ms latency. If you need to connect to a server on the other side of the country, you'll want a less chatty protocol, e.g. X2GO (which gives additional benefits, e.g. of restartable sessions). reply rany_ 52 minutes agorootparentprevX over SSH works really well for me as long as I enable SSH compression. At least for my usage, I can't tell it apart from a native window but then again I'm not running sophisticated programs which update frequently. reply tjoff 1 hour agorootparentprevx2go is a bit smarter than pure x-forwardning and also allows you to resume a session at a different time (or on a different machine) similar to something like tmux. Much much better performance and does pretty well even on cellular. A bit rough around the edges but brilliant for some usecases. reply hiccuphippo 5 hours agoprevRelated, a talk about replacing Xlib with their own abstraction with zig: https://www.youtube.com/watch?v=aPWFLkHRIAQ reply izoow 3 hours agoparentWas just about to mention this. Also, just to add to this, even though it's a zig talk, it's not really the main focus of the talk. I enjoyed it and I don't even know zig. reply guenthert 51 minutes agoprev> I was very surprised to learn that it is actually just a “regular” network protocol for two parties to communicate like HTTP, FTP, IMAP, SMPT and etc. With the important distinction that all those protocols very intentionally use human readable ASCII requests/responses. Of course, for performance sake, ease of debugability was sacrificed. Which increases the value of a standard library to hide the protocol. reply aidenn0 6 hours agoprevI share the author's opinion that xlib is harder to grok than the X11 protocol, because it's the X11 protocol plus a queuing system where you will sometimes receive out-of-band messages, plus a large number of seldom-used utilities. reply vidarh 6 minutes agoparentSame here. My window manager, terminal, (very basic) file manager all use pure Ruby X11 bindings, and the more I looked at where Xlib deviates (wraps, obscures) the protocol, the more places it felt easier to just use the X requests directly. I haven't looked at XCB much, but my understanding is that it's a much more direct binding to the X protocol, so if I were to write an X client in C using a client library, I'd almost certainly look at XCB rather than Xlib. reply donio 4 hours agoparentprevWorking with X11 client libraries written in other languages is a revelation in how much nicer an X11 client can be. CLX (Common Lisp) or xgb (Go) are some good examples. (Talking about native implementations here not xlib bindings). reply toast0 6 hours agoparentprevYeah, I've not been a fan of xlib. xcb is a much better library, IMHO, although it's not much more than talking X11 yourself. With Xlib, it seems like they tried to make things 'easier' by having high level concepts and a lot of synchronous apis, but they don't really fit on top of X, so you're fighting the library. Unfortunately, xcb came later and lots of things were already built on xlib, so lots of software has unnecessary synchronicity that makes things slow when you use the network stuff. reply yjftsjthsd-h 7 hours agoprev> I was very surprised to learn that it is actually just a “regular” network protocol for two parties to communicate like HTTP, FTP, IMAP, SMPT and etc. Typo: Simple Mail Transfer Protocol And I suspect many of us tend to think of those as magical abstractions best dealt with through libraries as well:) reply throwthrow5643 1 hour agoprevCan you do the same but in Wayland next? reply odiroot 15 minutes agoparentI'd like to see exactly that. Hello World in Wayland is so much more complicated. reply bitwize 4 hours agoprevOne of the neat things we'll be losing with X11 is the fact that you can do graphics -- fast -- entirely with the wire protocol. It was really a protocol for a sort of smart graphical terminal, so it's like having an Amiga blitter at the other end of the network connection. From a \"zero to something on the screen\" standpoint, it's fast and convenient, as you don't have to manage your own framebuffer, shaders, dirty rectangle list, or any of that. Of course, as any Gen-Z graphics hacker will tell you, That's Just Not How Things Work Anymore, and rendering is and should be client-side, leaving the compositor to only present the final display. But it was fun while it lasted. reply duskwuff 3 hours agoparent> One of the neat things we'll be losing with X11 is the fact that you can do graphics -- fast -- entirely with the wire protocol. As long as you only want to do very basic graphics -- no antialiasing, no color blending, no subpixel coordinates. And it isn't even that fast; everything ends up rendered on the CPU, possibly even all on a single thread, using code paths that haven't seen much optimization in the last 20+ years. reply flohofwoe 1 hour agorootparentNothing on your feature list is incompatible with a client/server approach though. The only downside would be when large pixel image blobs need to be sent over a network each frame. In the end, modern 3D APIs are also just a 'wire protocol': rendering commands are recorded by the CPU into local command buffers and played back by the GPU (which is often connected to the CPU by a comparatively slow bus), the only limiting factor is the amount of data that's communicated between the CPU and GPU - and of course any additional latency that would be added by a network connection. reply sprash 2 hours agorootparentprevThis is why the XRender extension was introduced. There you have antialiasing, all blending modes you could wish for, subpixel coordinates, advanced drawing operations like gradients and it is fast because it is fully hardware accelerated. All working over a very efficient wire protocol. E.g. Cairo uses Xrender as a backend. reply nly 1 hour agorootparentIt's not all hardware accelerated though is it. Both the X server and Cairo depend on the pixman library, which is a CPU/SIMD optimized pixel manipulation library. Even xf86-video-intel, the intel X11 driver package, on my system depends on pixman. reply caf 2 hours agoparentprevActual hardware \"smart graphical terminals\" that used that wire protocol were built for a while, too - I had some Labtam / Tektronix XP400 X11 thin terminals. reply pantalaimon 1 hour agoprevC also has structs, there is no need to assemble data structures in byte arrays. reply pavlov 1 hour agoparentWith the caveat that structs are padded by default so that members are aligned on architecture-friendly boundaries. For example, if a struct contains a char a followed by an int b, typically b would be at offset 4, even though sizeof(a) is 1. To get tight packing, you need to explicitly tell the compiler to disable padding. reply anacrolix 59 minutes agoparentprevFound the fresh grad reply PlunderBunny 6 hours agoprevTo someone that’s reasonably computer savvy (professional developer but Windows and macOS only), what does X11 do? What are the benefits of this approach? What’s the ‘equivalent’ in Windows or macOS (if there is one)? reply simiones 19 minutes agoparentUltimately X11 is the main component that you use to draw and interact with a GUI on a traditional Unix or on a Linux system (Wayland is a more recent alternative, and there have been other attempts in the past, but X11 is still the most commonly used). There is no 1:1 correspondence on Windows. Some of what X11 does is part of Win32, other parts are in explorer.exe, others are built in at deeper layers; there are multiple alternative systems available on Windows too. Ultimately what X11 gives you as an app is a way to draw something on the screen, and to get input events from users. X11 also coordinates this between multiple separate apps, so that you get movable windows and focus and other such behaviors without having to have each app coordinate manually with every other GUI app. Copy-paste is another similar cross-app functionality that X11 offers. The way X11 does this is through a well defined protocol. Instead of relying on system calls, you open a socket to some known port and send drawing commands there, and receive input events from it (of course, many libraries abstract this for you). Because of this, it can work transparently regardless of whether you are drawing on the local machine or on a remote one. So, X11 itself can work as a Remote Desktop solution as well without the need of a separate program or protocol (though there are significant differences with pros and cons). reply erik_seaberg 6 hours agoparentprevA user on any X11 desktop can open a GUI from any X11 app, even one running in a datacenter. It's like a Javascript app in a browser today, but every Unix GUI app knew how to do it on late 1980s hardware, so you didn't even have to buy and admin a complete desktop computer for each user. Windows sort of has this with RDP, but it's tied in with the app's GDI desktop, and I don't know whether it works without buying a bunch of video cards for the headless app server. NeXTSTEP had Display PostScript (remote rendering worked like printing!) but macOS lost support for it. reply IAmLiterallyAB 6 hours agorootparentSomewhat misleading. Because these days, none of the network transparent primitives are used anymore. All the rendering happens server side, and bitmaps are sent over the wire. It's basically a crappy VNC. And at that point, just use RDP or VNC reply donio 3 hours agorootparentThat greatly depends on the type of applications you run and the toolkits and font rendering they use. My most commonly used applications (terminal emulator, Emacs) do their font rendering using the the glyph compositing functionality of the RENDER extension. Server side glyphs are created when a font is loaded and all the compositing is done on the server side based on the client's CompositeGlyphs requests. Same for images (in Emacs) using CreatePixmap and CopyArea. reply prmoustache 1 hour agorootparentprevXPRA using h264 or h265 does a decent job in my experience in term of performance to increase over ssh -X. On wayland from I am also getting good results with waypipe opening individual apps from VMs to make it a poor man's QubeOS without the complexity and without having to open the whole remote desktop. reply erik_seaberg 5 hours agorootparentprevYeah, I have nothing constructive to say about apps and toolkits that choose only local rendering with no hardware, but it's pretty funny to see Javascript apps beating them on performance. reply neerajsi 4 hours agoparentprevAfaik, Windows RDP used to do more complex remoting of drawing primitives so that the host computer would send the clients instructions for drawing individual elements. But for many years now, they switched to an approach of rendering all the graphics on the host side and then sending a video stream to the client using standard video compression. I think this compression based approach scales better for the common use cases, especially office apps where the display is mostly static. I guess the approach has almost gotten good enough that you can play games remotely that way. reply bananskalhalk 4 hours agorootparentYou got any source for this? I am only asking since I got the impression rdp was a superior protocol to vnc, nx etc because of the complex handling of graphical primitives. But I know next to nothing about the real technical details. reply toast0 6 hours agoparentprevX11 is a distributed systems clustering protocol for asynchronous message passing that outputs graphics as a side effect. It's like Erlang's dist, but with a side channel to a display. A more real answer, is the X server manages access to the input and output devices... Roughly speaking, it lets a client define a region (rectangle) and get clicks and mouse motion and keyboard input sometimes (maybe too often), and lets the client send things to be displayed. In modern times, that's mostly images, but it used to be lines and curves and letters and things, or like OpenGL display lists. The server can tell the client when it is exposed and need to redraw or it can use a backing store to keep obscured parts of the region local to the display. Additionally, clients can adjust other client's resources (this is what a window manager does) and clients can communicate with each other through the server (no full mesh like in Erlang dist) ... that part is a bit confusing. On Windows and macOS (either one), there's no sense of a network involved, similar things happen, but mostly with system calls, I think. Otoh macOS X has all those mach ports? does UI go through that? But there are X11 servers for most platforms that integrate reasonably well, so it's not like you can't use X concepts there, it's just a bit more setup to get started. Windows also has RDP which can be used to run a program on one computer and display it on another. The benefit of this approach is you can take better advantage of asynchrony... Many GUI libraries and toolkits run in a synchronous model where you do a request and can't continue until you get the answer. That's fine when everything is fast, but when there's a network between the client and server, it's better to send requests when you have them and only wait for the response when you need it. (See also xcb vs xlib) reply jack_pp 4 hours agorootparentI might be wrong but I think the closest thing in windows land is RDP with regard to low level rendering of the display over the network reply krackers 5 hours agorootparentprevYeah on macos the communication between your app and the window server (which is conveniently called WindowServer) happens via mach ports. Most of it is undocumented, in fact anything more \"low-level\" than using AppKit is undocumented, although IIRC it is in principle possible to use undocumented CG* apis to create and manipulate windows yourself without going through the appkit layers. I think each CG* api is basically a thin shim that communicates to the window server, which has a corresponding CGX* implementation which does the actual logic. This article has some details https://keenlab.tencent.com/en/2016/07/22/WindowServer-The-p... reply naruhodo 6 hours agoparentprevIt's a network transparent display protocol. Real life scenario: you have a headless server that has GUI software installed at a remote site. You connect to the network from home with a VPN. Then SSH in to the server with \"ssh -X user@server\" and run the GUI program in that terminal. The GUI appears on your local display. SSH sends the X11 protocol traffic through an encrypted tunnel from the remote server to the local X11 display server, because of the -X. reply TheDauthi 6 hours agoparentprevIn Windows, it's kinda split between the Windows Display Driver Model (WDDM) and the Desktop Window Manager (DWM). That's not a 1:1 match, though, as those two combined cover more components of a functioning whole than X11/XOrg itself does. X11 just split the components needed to draw everything you'd need for graphical environment into a different choice of layers. X11 got network transparency out of the box (a sibling comment touches this), and the capability of switching out the components more easily, while Windows had less work to do to smooth out the overall desktop experience. reply flohofwoe 1 hour agoparentprevSame thing as Cocoa or the windowing API in User32.dll, but as a network-transparent client/server architecture (usually behind a library though, so doing things like opening a window is quite similar, except that Xlib isn't as ergonomic as Cocoa or even Win32). reply somat 6 hours agoparentprevI am not very familiar with any of them at a low level but I think you can sum it up as Apple and Microsoft defined their display server as an api, a programing interface. MIT defined theirs as a protocol, a communication interface. With the intention that any api supplied should have a very flexible transport. reply pestatije 9 hours agoprevX11 Windows, not the obvious Windows reply leeman2016 6 hours agoprev [–] I think the “Windows” in the title should be written with small “w” reply p4bl0 3 hours agoparentYes, and the first sentence of the post should have \"a window\" rather than \"a Windows\", because as is it add to the title's confusion between X windows and MS Windows. reply galkk 5 hours agoparentprev [–] even if this is technical article, the title is very clickbaity. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post details creating windows in Linux through sockets and C programming without xlib, concentrating on the X11 protocol for communication with the X server.",
      "It includes functions for initializing communication, window creation, response handling, event processing, setting colors, and writing text to windows.",
      "The application operates continuously, managing errors, connection closures, and underscores grasping binary communication and resource management in X11."
    ],
    "commentSummary": [
      "The article delves into various protocols and techniques used for opening windows in Linux, such as sockets, SSH, VNC, xpra, and X2GO.",
      "It addresses the limitations of Xlib in comparison to alternatives like XCB when interacting with the X11 protocol.",
      "Comparisons between the traditional X11 protocol and modern graphics rendering methods are made, highlighting their respective strengths and weaknesses."
    ],
    "points": 123,
    "commentCount": 50,
    "retryCount": 0,
    "time": 1715210068
  }
]
