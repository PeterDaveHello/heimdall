[
  {
    "id": 37392676,
    "title": "I’m an FCC Commissioner proposing regulation of IoT security updates",
    "originLink": "https://news.ycombinator.com/item?id=37392676",
    "originBody": "Hi everyone, I’m FCC Commissioner Nathan Simington, and I’m here to discuss security updates for IoT devices and how you can make a difference by filing comments with the FCC.As you know, serious vulnerabilities are common in IoT, and it often takes too long for these to be patched on end-user devices—if the manufacturer even bothers to release an update, and if the device was even designed to receive them. Companies may stop supporting a device well before consumers have stopped using it. The support period is often not communicated at the time of sale. And sometimes the end of support is not even announced, leaving even informed users unsure whether their devices are still safe.I’ve advocated for the FCC to require device manufacturers to support their devices with security updates for a reasonable amount of time [1]. I can&#x27;t bring such a proposal to a vote since I’m not the chairman of the agency. But I was able to convince my colleagues to tentatively support something a little more moderate addressing this problem.The FCC recently issued a Notice of Proposed Rulemaking [2] for a cybersecurity labeling program for connected devices. If they meet certain criteria for the security of their product, manufacturers can put an FCC cybersecurity label on it. I fought hard for one of these criteria to be the disclosure of how long the product will receive security updates. I hope that, besides arming consumers with better information, the commitments on this label (including the support period) will be legally enforceable in contract and tort lawsuits and under other laws. You can see my full statement here [3].But it’s too early to declare victory. Many manufacturers oppose making any commitments about security updates, even voluntary ones. These manufacturers are heavily engaged at the FCC and represented by sophisticated regulatory lawyers. The FCC and White House are not likely to take a strong stand if they only hear the device manufacturer&#x27;s side of the story.In short, they need to hear from you. You have experienced insecure protocols, exposed private keys, and other atrocious security. You have seen these problems persist despite ample warning. People ask, ‘why aren’t there rules about these things?’ This is your chance to get on the record and tell us what you think the rules should be. If infosec doesn’t make this an issue, the general public will continue falsely assuming that everything is fine. But if you get on the record and the government fails to act, the evidence of this failure will be all over the Internet forever.If you want to influence the process, you have until September 25th, 2023 (midnight ET) to file comments in the rulemaking proceeding.[4] Filing is easy: go to https:&#x2F;&#x2F;www.fcc.gov&#x2F;ecfs&#x2F;search&#x2F;docket-detail&#x2F;23-239 and click to file either an ‘express’ comment (type into a textbox) or a ‘standard’ comment (upload a PDF). Either way, the FCC is required to consider your arguments. All options are on the table, so don’t hold back, but do make your arguments as clear as possible, so even lawyers can understand them. If you have a qualification (line of work, special degree, years of experience, etc.) that would bolster the credibility of your official comment, be sure to mention that, but the only necessary qualification is being an interested member of the public.I’m here to listen and learn. AMA. Feel free to ask any questions about this or related issues, and I’ll answer as many as I can. I just ask that we try to stay on the topic of security. My legal advisor, Marco Peraza, a security-focused software engineer turned cybersecurity lawyer, will be answering questions too. I’m open to incorporating your ideas (and even being convinced I’m wrong), and I hope that my colleagues at the FCC are as well. Thank you![1] https:&#x2F;&#x2F;www.fcc.gov&#x2F;document&#x2F;simington-calls-mandatory-secur...[2] https:&#x2F;&#x2F;www.fcc.gov&#x2F;document&#x2F;fcc-proposes-cybersecurity-labe...[3] https:&#x2F;&#x2F;www.fcc.gov&#x2F;document&#x2F;fcc-proposes-cybersecurity-labe...[4] If your comments are purely in response to arguments made in other comments, you have an extra 15 days, until October 10, 2023.",
    "commentLink": "https://news.ycombinator.com/item?id=37392676",
    "commentBody": "I’m an FCC Commissioner proposing regulation of IoT security updatesHacker NewspastloginI’m an FCC Commissioner proposing regulation of IoT security updates 2921 points by SimingtonFCC 18 hours ago| hidepastfavorite769 comments Hi everyone, I’m FCC Commissioner Nathan Simington, and I’m here to discuss security updates for IoT devices and how you can make a difference by filing comments with the FCC.As you know, serious vulnerabilities are common in IoT, and it often takes too long for these to be patched on end-user devices—if the manufacturer even bothers to release an update, and if the device was even designed to receive them. Companies may stop supporting a device well before consumers have stopped using it. The support period is often not communicated at the time of sale. And sometimes the end of support is not even announced, leaving even informed users unsure whether their devices are still safe.I’ve advocated for the FCC to require device manufacturers to support their devices with security updates for a reasonable amount of time [1]. I can&#x27;t bring such a proposal to a vote since I’m not the chairman of the agency. But I was able to convince my colleagues to tentatively support something a little more moderate addressing this problem.The FCC recently issued a Notice of Proposed Rulemaking [2] for a cybersecurity labeling program for connected devices. If they meet certain criteria for the security of their product, manufacturers can put an FCC cybersecurity label on it. I fought hard for one of these criteria to be the disclosure of how long the product will receive security updates. I hope that, besides arming consumers with better information, the commitments on this label (including the support period) will be legally enforceable in contract and tort lawsuits and under other laws. You can see my full statement here [3].But it’s too early to declare victory. Many manufacturers oppose making any commitments about security updates, even voluntary ones. These manufacturers are heavily engaged at the FCC and represented by sophisticated regulatory lawyers. The FCC and White House are not likely to take a strong stand if they only hear the device manufacturer&#x27;s side of the story.In short, they need to hear from you. You have experienced insecure protocols, exposed private keys, and other atrocious security. You have seen these problems persist despite ample warning. People ask, ‘why aren’t there rules about these things?’ This is your chance to get on the record and tell us what you think the rules should be. If infosec doesn’t make this an issue, the general public will continue falsely assuming that everything is fine. But if you get on the record and the government fails to act, the evidence of this failure will be all over the Internet forever.If you want to influence the process, you have until September 25th, 2023 (midnight ET) to file comments in the rulemaking proceeding.[4] Filing is easy: go to https:&#x2F;&#x2F;www.fcc.gov&#x2F;ecfs&#x2F;search&#x2F;docket-detail&#x2F;23-239 and click to file either an ‘express’ comment (type into a textbox) or a ‘standard’ comment (upload a PDF). Either way, the FCC is required to consider your arguments. All options are on the table, so don’t hold back, but do make your arguments as clear as possible, so even lawyers can understand them. If you have a qualification (line of work, special degree, years of experience, etc.) that would bolster the credibility of your official comment, be sure to mention that, but the only necessary qualification is being an interested member of the public.I’m here to listen and learn. AMA. Feel free to ask any questions about this or related issues, and I’ll answer as many as I can. I just ask that we try to stay on the topic of security. My legal advisor, Marco Peraza, a security-focused software engineer turned cybersecurity lawyer, will be answering questions too. I’m open to incorporating your ideas (and even being convinced I’m wrong), and I hope that my colleagues at the FCC are as well. Thank you![1] https:&#x2F;&#x2F;www.fcc.gov&#x2F;document&#x2F;simington-calls-mandatory-secur...[2] https:&#x2F;&#x2F;www.fcc.gov&#x2F;document&#x2F;fcc-proposes-cybersecurity-labe...[3] https:&#x2F;&#x2F;www.fcc.gov&#x2F;document&#x2F;fcc-proposes-cybersecurity-labe...[4] If your comments are purely in response to arguments made in other comments, you have an extra 15 days, until October 10, 2023. SimingtonFCC 13 hours agoThank you so much everyone for the interesting, high-quality discussion so far. My team and I are looking forward to continuing to engage with you for at least a few more hours.Just a reminder: As fun as discussing this in here with you is, the best way to influence what the FCC ends up doing is to file an official comment by September 25th at https:&#x2F;&#x2F;www.fcc.gov&#x2F;ecfs&#x2F;search&#x2F;docket-detail&#x2F;23-239 . Click to file either an ‘express’ comment (type into a textbox) or a ‘standard’ comment (upload a PDF). The FCC is required to address your arguments when it issues its final rules. All options are on the table, so don’t hold back, but do make your arguments as clear as possible so even lawyers can understand them. If you have a qualification (line of work, special degree, years of experience, etc.) that would bolster the credibility of your official comment, be sure to mention that, but the only necessary qualification is being an interested member of the public.Finally, I&#x27;d like to extend a special thanks to dang and the rest of the HN team for their help putting this together. They have been a pleasure to work with. dang 14 hours agoprevAll: To read the entire thread, you&#x27;ll need to click More at the bottom of the page, or like this:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37392676&p=2https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37392676&p=3 doitLP 18 hours agoprevThere’s some great recommendations in this thread but I just want to thank you for engaging with this community to solicit opinions from the trenches.This is really meaningful to most of us who see the regulations in our lives as something far away that we can’t influence.Another reminder for everyone that while you likely can’t influence something like a presidential election on your own, you can influence many other spheres with your knowledge and time that are closer to home and probably affect you more immediately. reply SimingtonFCC 18 hours agoparentThanks! I am thrilled that so many people are participating. The FCC is going to need a lot of this community&#x27;s input over the next few years as more and more devices go online. reply steamer25 16 hours agorootparentThis may be beyond the FCC&#x27;s purview, but given some of the comments (e.g., https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37393644) perhaps an entirely different strategy is warranted.Instead of trying to compel manufacturers, who may no longer even exist, to support their old products; perhaps the government should focus on protecting consumers and aftermarket vendors who update &#x2F; modify &#x2F; reverse-engineer older revisions--especially after they&#x27;re no longer meaningfully supported by the manufacturer. reply oger 14 hours agorootparentThere is an overlap with the right to repair topic. It does not make sense to have the DMCA hanging over your head when you are reverse engineering a product that is abandoned by the manufacturer - be it end of life or bankruptcy to name two reasons among many. reply Buttons840 14 hours agorootparentAlso, security researchers should have strong legal protections; they should be given the benefit of the doubt at every turn.Currently, researchers are sometimes threatened with decades in prison for testing the security of websites or devices. If they act in good faith as researchers, this should never happen.This is literally a national security issue. We currently stifle security research on essential IoT devices primarily so companies can avoid being embarrassed by their own poor security. reply EricMausler 13 hours agorootparentThis might be an unpopular opinion but I respectfully do not see it that way. I agree with promoting security for IoT devices, but there needs to be consent from the company being probed for vulnerabilities or else I find it hard to consider it legitimate research, regardless of intent.I dont think anyone would like it very much if someone came to their house and documented all the ways to rob it they could find, even if it&#x27;s for research purposes. There is an inherent risk of your vulnerabilities being broadcasted somewhere either on purpose or accidentally once that information is collected and organized by the researcher.It isn&#x27;t harmless and innocent to probe anything for weaknesses unsolicited. It is reasonable to respond to that as a threat. It is genuinely threatening behavior.Now I do understand it gets complicated when it&#x27;s a business being trusted with sensitive information &#x2F; access to devices in your home. I am just saying as part of the solution we need to keep possibly threatening behavior in mind and try to avoid the promotion of it as part of the solution unless there is really no other way (imo) reply saurik 13 hours agorootparentThe problem here is that the thing I am probing is something I own: the device in my house that I ostensibly purchased and am allowed to smash with a hammer or put in a blender for all anyone should care; the context is that the DMCA is often used by companies to claim that DRM on the device is there to protect copyrights--whether music the device had access to, even if it isn&#x27;t the reason many or even most people buy the device (such as a smart fridge with a speaker in it and the option to log in to Spotify), or the firmware software itself--and that it is thereby illegal for me to distribute tools to help people access to repair (which is the key thing here: there actually are already some legal protections for the act of \"probing\", but you kind of have to do it alone which is insane) a device I own and where finding vulnerabilities should be about me and my trade-offs, not the wishes of a manufacturer. reply EricMausler 11 hours agorootparentI hate it too, but the heart of this is that ownership is under question.People should not have agreed to buy things where there are parts of it they don&#x27;t own that they don&#x27;t even need, but they did. They did it a lot because it didn&#x27;t matter to them and now those devices are prevalent everywhere and it&#x27;s a PITA to try to buy the type of item you actually want - where you own it entirely.Ownership has never actually been absolute. When you buy land you cannot tear it up and make it totally unusable. If you buy a home under an HOA you may have to keep it in a certain type of order.Maybe what we need is a law that manufacturers always need to provide a \"dumb\" model of their products which can be completely owned by the consumer.However, I was speaking from a stance of acceptance that the companies are maintaining ownership of some functionality of the devices. I was primarily thinking about the way it accesses company owned infrastructure (servers and the information on them) but it extends into a grey area on the devices themselves.You should be allowed to reasonably tamper with the device, but you should also be attempting to communicate with the company about it. They shouldn&#x27;t be allowed to retaliate against you for requesting to tamper, they should need to reply reasonably quickly, and the reasons for which they are allowed to deny you should be regulated so they cannot just deny for no reason.I am saying we need to lean in to the situation we are in if we want actual results, and I think there is a lot of room to develop a reasonable legal framework on this subject that incorporates partial ownership.It shouldn&#x27;t be as restrictive as it is today, but it also shouldn&#x27;t be a complete free for all. We should at least attempt to make an effort to control security vulnerability information so criminal behavior and innocent behavior actually looks different. reply dotancohen 13 hours agorootparentprevnext [–]> I dont think anyone would like it very much if someone came to their > house and documented all the ways to rob it they could find, even if > it&#x27;s for research purposes.The correct analogy would be if someone documented all the ways to rob a house that is currently mass-produced and sold on the market. And yes, as a consumer I most certainly would approve of such activity, especially if I&#x27;ve yet to make a purchasing decision. Or especially if I&#x27;m already living in such a house, I need to know that it is not safe. reply EricMausler 11 hours agorootparentIn that scenario I would MUCH rather the company be aware someone is putting that lust together, notfiy me in advance of the research being concluded, provide updates, organize and manage the contents of that list, offer solutions, patch the fixes in new models, and generally work with the people who already purchased the house.I would not prefer someone to do it all in secret and then at the last second decide they want to inform the company.Once such a thing gets broadcasted, there is inherent risk created for a lot of those existing owners that did not exist. Opportunistic criminals are way more common than premeditated ones.Also if we gain the ability to monitor everyone who is currently probing houses for security issues, then if we are able to have a whitelist of people who pre-notified with their intent then we can more reliably examine people who might be looking to abuse the system.I guess part of my underlying assumptions here is that we are moving towards a surveillance state and there are no signs of stopping that reply ClumsyPilot 10 hours agorootparent> In that scenario I would MUCH rather the company ... notfiy me ... provide updates..Here is the problem - the company does not give a crap. You get robber, and it&#x27;s their fault? They don&#x27;t care. But they will sue the researcher, because the researcher has discovered that it&#x27;s their fault you got robbed. reply Buttons840 13 hours agorootparentprevDo you believe that your proposal increases the cybersecurity of society as a whole?You focus a lot on the rights and conveniences of a company, but the rights of a company are not more important that the security of society as a whole.There are good guys and bad guys out there looking for vulnerabilities. What you propose reduces the number of good guys more than it reduces the number of bad guys (since bad guys are less likely to follow the law). What you propose shifts the balance towards the bad guys and makes it more likely that vulnerabilities will be discovered first by the bad guys. You also propose security through ignorance; security via hoping that nobody notices.Again, I would really like to hear you assert that your proposal would increase the cybersecurity of society as a whole. I did not clearly see such an assertion in your comment. I want to see an argument focused on the security of society as a whole.I assert that we currently reduce our national security for the convenience of companies. reply EricMausler 12 hours agorootparentI proposed a preference for systemic solutions over building a soft dependence on white hat hackers.This benefits society as a whole because it clearly delineates actions with intent. If doing X is always not allowed, then all you need to do is find people doing X and you can hold them accountable.If you allow or disallow the same activity based on merit of intent, then you increase the level of plausible deniability to everyone who gets caught.I am not proposing security through ignorance. I am proposing security through consent. Nowhere did I say anything about not allowing research, I only said that if you do it unsolicited then it should be considered a threat.So, we could systemically allow for a right to research that involves notice to the company and their consent for you to test. It would not hinder white hat at all. If businesses resist for selfish reasons we can expand the law to prevent them from denying requests without a legitimate reason. For example, maybe it is okay for them to deny a request from an ex-employee with a grudge who has sent the company aggressive emails. Idk, maybe there are no valid reasons to deny. The point is we can create a framework that promotes security development above the table with all parties involved. And my proposition is that if that is possible then it should be preffered. reply Buttons840 9 hours agorootparentYou attempt to solve the problem of chaos (think grey-hat) by expanding law enforcement--by enforcing order on every internet user world wide. That&#x27;s going to require a lot of boots to squash a lot of faces. Curious kids who run port scans will stand before judges, journalists who press F12 will face the ire of the most powerful and decades in prison[0]. This will probably require some national firewalls as well. This will continue the status quo where companies leak the private information of countless millions and nothing happens, while individuals must be careful what they do with their own computer and their own physical devices.I attempt to solve the problem by embracing chaos and empowering those who seek to do good in the chaos. I&#x27;d like to see our IT systems become so hardened that no amount of chaos can harm them. Let the grey-hats and black-hats run wild, it is possible to build our technology well enough that they can do no harm. This would require those with the most wealth and power in our society to do a little more, to take on some additional responsibility and demonstrate they are worthy of the trust and power we have given them. Let individuals be free and make the creators of our technology responsible for their own creations.What you have proposed is what we already have, it is the status quo. When you hear about a major breach every other week, ask yourself whether or not it&#x27;s working.[0]: https:&#x2F;&#x2F;techcrunch.com&#x2F;2021&#x2F;10&#x2F;15&#x2F;f12-isnt-hacking-missouri-... reply sh34r 7 hours agorootparentprevThis is a very poor analogy. For one thing, casing someone&#x27;s home is not interesting research. It&#x27;s not news to anyone that locks only keep honest people out. You need physical access to break in. The legal system and the people nearby (neighbors and residents, and their firearms in the USA) are the main lines of defense here. Unlocked doors are a harm targeting one household.Conversely, with vulnerable IoT devices, we&#x27;re talking about internet-connected devices. The potential harm is to everyone on the Internet, not just one household, when they&#x27;re taken over and made part of a botnet. An attacker can exploit them from anywhere in the world, including residents of hostile jurisdictions that are tolerant (or actively supportive) of such activity. Russia, North Korea, Iran, etc. The protections people have relied on for centuries to defend their residences from bad guys don&#x27;t apply anymore.These IoT devices can also be used to gain a foothold in your home network, which are usually flat networks. It&#x27;s surprisingly difficult to find a \"router\" for home use at a reasonable price point that can setup VLANs, by the way. Even as a technical person.The better analogy IMO is to building codes, where your property rights are limited by society&#x27;s interest to keep your family safe, but more importantly, your neighbors safe too, because fires spread. It&#x27;s still an imperfect analogy for a number of reasons. Cyberattacks are a relatively novel kind of threat. All analogies are going to be imperfect. reply dchftcs 3 hours agorootparentI think a better analogy can be drawn by just considering the physical version of some things. For IoT, you can say if someone discovers a specific brand of physical lock can be broken in unexpected ways, they should be allowed to communicate this in a way that benefits the users of the lock without facing any legal risk. For internet banking, you can discuss a physical vault that safekeeps everyone&#x27;s gold, and say that someone who notices a broken lock should not be punished for telling the vault manager to fix the lock. Unfortunately the common situation is that the lock company and the vault manager will sue because they don&#x27;t want to admit they put their users and clients at risk - it sounds absurd, but that&#x27;s what happens in the electronic world. reply AnthonyMouse 13 hours agorootparentprev> There is an inherent risk of your vulnerabilities being broadcasted somewhere either on purpose or accidentally once that information is collected and organized by the researcher.A legitimate researcher is going to promptly notify you of any vulnerabilities they discover and you as a large organization are going to promptly remediate them.But the trouble isn&#x27;t that the law might impose a $100 fine on a smug professor or curious adolescent to demonstrate that some audacious but mostly harmless behavior was over the line, it&#x27;s that the existing rules are so broad and with such severe penalties that they deter people from saying anything when they see something that looks wrong. reply Buttons840 13 hours agorootparentI once found a vulnerability. I pressed F12 and saw unintended information in the source of a webpage. I just closed the tab, I didn&#x27;t report it.Our laws made it risky to do the right thing, so I didn&#x27;t do the right thing. reply EricMausler 11 hours agorootparentprevI agree the laws are too broad. I think we need add layers of granularity to them. Create more of a framework for settling the rules on what is and isn&#x27;t allowed. Maybe we settle on everything goes, but the company should be involved.A legitimate researcher should be notifying the company that they are going to be looking for vulnerabilities in the first place. That is part of the distinction in behavior that I am encouraging. This way if someone is caught poking around for things to abuse unsolicited, at least there&#x27;s a little more merit to holding them accountable. We are able to treat it more like the threat it is.A good faith company can give researchers pointers on where to look. Maybe the company has a really good reason to prevent looking at certain things, and they are able to convince the researcher of that. I dk. Point is the framework for settling all that should be promoted rather than promoting people to act identical to criminals right up until they decide whether to sell &#x2F; abuse the information illegally or notify the company and try to get a reward. Does that make more sense? reply AnthonyMouse 6 hours agorootparent> A legitimate researcher should be notifying the company that they are going to be looking for vulnerabilities in the first place. That is part of the distinction in behavior that I am encouraging. This way if someone is caught poking around for things to abuse unsolicited, at least there&#x27;s a little more merit to holding them accountable. We are able to treat it more like the threat it is.The issue is this. You have some amateur, some hobbyist, who knows enough to spot a vulnerability, but isn&#x27;t a professional security researcher and isn&#x27;t a lawyer. They say \"that&#x27;s weird, there&#x27;s no way...,\" so they attempt the exploit on a lark, and it works.This person is not a dangerous felon and should not be facing felony charges. They deserve a slap on the wrist. More importantly, they shouldn&#x27;t look up the penalty for what they&#x27;ve already done after the fact, find that their best course of action is to shut up and hope nobody noticed, and then not report the vulnerability.The concern that we will have trouble distinguishing this person from a nefarious evildoer is kind of quaint. First, because this kind of poking around is not rare. As soon as you connect a server to the internet, there are immediately attempts to exploit it, continuously, forever.But the malicious attacks are predominantly from outside of the United States. This is not a field where deterring the offenders through criminal penalties is an effective strategy. They&#x27;re not in your jurisdiction. So we can safely err on the side of not punishing people who aren&#x27;t committing some kind of overt independent crime, because we can&#x27;t be relying on the penalty&#x27;s deterrent regardless. We need the systems to be secure.Conversely, if one of the baddies gets in and they are in your jurisdiction, you&#x27;re not going to have trouble finding some other law to charge them with. Your server will be hosting somebody&#x27;s dark web casino or fraudulent charges will show up on your customers&#x27; credit cards and the perpetrators can be charged with that even \"unauthorized computer trespass\" was a minor misdemeanor. reply screwturner68 9 hours agorootparentprevso are you saying that I shouldn&#x27;t be testing a product I purchased or a product that someone mandated I have in my house? I shouldn&#x27;t have to notify anyone, I own it and I should be able to do with it whatever I please. In addition if I do find an exploit I am not obligated to notify the company nor should I be. A good faith company should be doing their due diligence and not releasing unprotected&#x2F;poorly protected devices as is common today. reply AJ007 12 hours agorootparentprevThis is what is referred to as \"security through obscurity.\" If companies are going to publish&#x2F;sell closed source software to the general public, and make any claims regarding it&#x27;s security, that should provide more than enough consent to probe it. reply EricMausler 11 hours agorootparentI think the difference is in what&#x27;s yours and what&#x27;s theirs. If it&#x27;s yours, I agree. If it&#x27;s theirs, I disagree.The idea of absolute ownership is being eroded. You purchase a device but that device may use information you do not own. If you are manipulating the device to allow it to give you information you did not purchase and the contract you agreed to with the purchase was that you would not do this, then that is threatening. If what you learn by probing it allows you to breach the security of other people using the same service, then that is threatening.If you are concerned about the device, I don&#x27;t understand why we can&#x27;t live in a world where you are able to vocalize that and give the device provider a chance for feedback before probing it for weaknesses.If there is a security concern that you want to shine a light on, why is it that we need to address that concern in the dark? It is giving too much unnecessary overlap with people looking to exploit those security issues when we might not need to reply bostik 2 hours agorootparentA device that is installed in my home but which I do not own is an increased liability on me. reply ClumsyPilot 10 hours agorootparentprev> If what you learn by probing it allows you to breach the security of other people using the same service, then that is threateningWhat is threatening is that the company that sells baby monitors and keeps video recordings of your family members being naked has zero accountability for their security and almost no chance of being caught if they misuse it. reply deadbunny 8 hours agorootparentprevWhite Hat: Can I hack your website and services?Company: No we are super secure! No trying to find vulnerabilities.Black Hat: lol sells company data reply Two4 12 hours agorootparentprevWhy does everyone compare things to houses? If you want to be more consistent with your building analogy, IoT sold to the public or enterprises are more like bars, except that each user has their own privately owned bar that may or may not be stocked by a central liquor company. If a user wants to check it&#x27;s not possible for someone to break into his bar, or slip poison into his booze shipments, or redirect the shipments altogether, that&#x27;s legitimate in my mind. Even if someone buys a bar intending to hijack booze shipments, the liability is still partially on the liquor company if they have not taken reasonable precautions against known risks. Imagine buying a bar and the liquor company who you&#x27;re forced to use says \"if you rattle any of the doorknobs or test the alarm works, we&#x27;ll sue your pants off and throw you in jail\" - does that seem fair? reply EricMausler 12 hours agorootparentI was speaking towards probing the business not the things you own.Using housing as a metaphor is common because it&#x27;s an incredibly common thing people can relate to with personal experience, and is something people typically have relatively detailed intuitions built around what they are okay with and not okay with regarding it.It got the point I was making across, but I do think there was a misunderstanding about what I was applying it to. I was referring to people who probe businesses security vulnerabilities on the internet side of IoT, not people who check for vulnerabilities in things they own on the T side of IoT.As for the bar analogy, I agree that there is a lot of room for reasonable due diligence to test the security if there is potential for you to be at risk of its failings. This is more in line of my last paragraph, and I do still assert that solutions that avoid the need for people to verify security themselves should be preferable to one&#x27;s that do.If you&#x27;ve got 2 legally independent entities messing with the same device, and then abuse of the device does happen and it leads to damages - can you understand how much more difficult this becomes to sort out than if the company was solely responsible for the device? reply Sporktacular 10 hours agorootparentprevPart of systemic improvement to security comes from the market forces that reward producers putting out carefully designed and tested products and punish producers that don&#x27;t. Your suggestion of requiring prior notice, coordination, approval etc. incentivises them to defer the cost of proper development until there is a crisis, so they can rush out any rubbish product, and force users and researchers to do their security testing for them. Let them fear the unknown, with their necks on the line, and design accordingly. reply tremon 13 hours agorootparentprevthere needs to be consent from the company being probed for vulnerabilitiesWhat is the type of scenario that you have in mind here? Do you mean probing a web service for vulnerabilities, performing security assessments as part of pre-sale publications (think Consumer Reports, Anandtech reviews etc), or performing pen-testing on a device I bought and is now running on my home network? Because you appear to be arguing that I shouldn&#x27;t be allowed to examine a device I own without explicit manufacturer consent. reply EricMausler 12 hours agorootparentI was speaking towards internet side of things where you do not own the infrastructure.As a related note, I do firmly believe in right to repair, and if you own something you can do whatever you want with it.Partial ownership seems to be a thing now. So I think there is a lot of missing framework around managing that properly.Long story short - I think there is room for manufacturer consent &#x2F; acknowledgement &#x2F; notice to be part of the solution and if it can be part of the solution then it should be. We may need regulation around that, it likely cannot be left solely to the companies discretion and may even need an aggressive \"receipt but no reply by X days is considered consent\" clause - but I would like to promote solutions that come with communication between the effected parties reply ClumsyPilot 10 hours agorootparentprev> there needs to be consent from the company being probed for vulnerabilitiesSo they never give consent and no vulnerabilities are ever discovered?If I make and sell bread, there could be a surprise food safety inspection in the middle of the night on Christmas Eve, but don&#x27;t we dare inconvenience some software firm that holds intimate data on millions of people. reply uuuuuuuuuid 5 hours agorootparentprevI imagine someone in the many many comments has already suggested this. But just in case:It wound be great if all of my emails to security@somewebsite.con could be CC’d to security@fcc.gov and that would immediately convey to me, somewebsite, and the FCC (and anyone else) that I am indeed disclosing and not ransoming.I understand there would be a cost that the FCC would bear. I just think it would be a worthwhile cost to incur. reply lxbxc 59 minutes agorootparentThis seems like a pretty clear breach of first amendment rights (we have a right to choose what we say, and who we say it to). It is probably a good idea for researchers to implement this strategy, and obviously more protections are needed for researchers in this area, but eroding the bill of rights is not the way. reply unstatusthequo 15 hours agorootparentprevFully agree. If some company vanishes, consumers are left holding the shit end of a broken stick. It would sure help if there were protections for those that effectively volunteer their time and effort to keep things running for others. reply sumtechguy 17 hours agorootparentprevI would like to add most of the IoT problem is no patches at all. The firmware they get is usually bog standard with some very minor tweaks out of china somewhere.It is a problem of vendor locked in products where you have to buy a hub to do an update. If there even is an update. If you want to get a good picture of how sideways updating can even be watch the linus tech tips on where he wanted (and has the tech ability) to patch his light switches. But could not even get them to give him the correct firmware or even say if he could. Also many devices there is literally no way to even do the update. They flash it on the line and that is the last update it ever gets.Also Supported and actually maintained in the hardware world can mean different things. So you will need to get your definitions up front correct. Supported could mean to a HW manufacture if the thing burns out ship a new one. The firmware is a secondary consideration.Another aspect you will run into is licensing. I can sell a device but may not have access to the code. Example: The vendor who makes that code went EoL on their code 5 years ago. They will not even sell me the code as they may or may not even have anyone who works for them to give it away if they could. They may or may not want to sell me that software anymore as they have a new shiny they want to sell me. So I am stuck even though I want to update I can not do it. I had one vendor flat out refuse to give me the older docs because the item was EoL and they had a replacement product that cost like 5x. That was just to communicate with the thing. Not even to update it to a later revision. reply com2kid 17 hours agorootparent> I would like to add most of the IoT problem is no patches at all. The firmware they get is usually bog standard with some very minor tweaks out of china somewhere.I was on a team that worked with a firmware vendor, from the US, for a bluetooth chip.We would send in bug reports, they&#x27;d send us firmware with fixes. Except it was obvious they did not use source control because they would sometimes base patches off of old firmware versions that had the bugs they had fixed in newer versions. It was absolutely insane having to send emails like \"hi, your latest patch is based on firmware from a year ago, can you please instead fix the firmware you sent us last month?\" reply sumtechguy 14 hours agorootparentThose sorts of places are fun to interview at. &#x27;So what sort of source control do you use&#x27;. You would think everyone does that by this point. An easy slam dunk question to ask and for them to answer. I had one say &#x27;well sometimes we check it into sourcesafe but usually just copy it around the 5 of us on a fileshare&#x27; (this was like 4-5 years ago). reply mannyv 16 hours agorootparentprevSounds like broadcom to me. reply com2kid 15 hours agorootparentHilariously, not that time.I do understand why you might think that though. :-D reply MarcoPerazaFCC 17 hours agorootparentprevRe: the licensing issue, companies wanting to put a label on their product would probably want to extract similar guarantees up their supply chain. Especially with a voluntary program like the one the FCC is proposing, good practices won&#x27;t become the norm across the market overnight. But maybe, at the very least, the segment of product and component makers that take security seriously will begin to grow. I encourage you to share your thoughts in an official comment. reply structural 10 hours agorootparentAs someone who designs IoT devices like these for a living, the device manufacturers here are in many cases the smallest companies in the supply chain and have very little ability to influence things upstream of them, especially for specialty products or companies entering a new market. It&#x27;s often a major win to get a chipmaker to pick up the phone and sell us their product, much less receive any support at all.I wish I could put a label like this on all of my products and I&#x27;ve been wishing for this for over twenty years, but the reality on the ground is that our support ends when the support for the individual parts in our product ends. We&#x27;ve looked at our supply chain periodically to see if we can replace parts with better documented&#x2F;supported comparable parts, but frequently there just really aren&#x27;t any better options.This is a great idea in concept, but I fear that the flaw in the FCC&#x27;s proposed rulemaking is that only indirectly addresses the root cause (the software, documentation, and support&#x2F;updates provided by chipmakers for their parts). Furthermore, by focusing on device manufacturers who are the weaker partners in the chain, the regulation is likely to punish smaller, more innovative manufacturers. reply happymellon 21 minutes agorootparentIf it was forward looking, rather than retroactive then it would at least mean that chip manufacturers wouldn&#x27;t be able to sell their undocumented&#x2F;unsupported crap because all the buyers have to have it?If there are no buyers then their attitude should change. reply slavik81 16 hours agorootparentprev> If you want to get a good picture of how sideways updating can even be watch the linus tech tips on where he wanted (and has the tech ability) to patch his light switches. But could not even get them to give him the correct firmware or even say if he could.It was a mess, but it may not be a good example because part of the confusion was that there was no newer firmware. Their firmware version was being reported in hexadecimal, but the latest firmware version was listed in decimal. reply sumtechguy 16 hours agorootparentHe had a mix of random ones. They were telling him to buy a hub and hope for the best or go thru one of their vendors (more cost). Even if it that was slightly wrong that exact example could very easily happen. You have a group of devices in random levels of firmware states with no real nice way to tell what is what. reply snarf21 16 hours agorootparentprevThe biggest problem isn&#x27;t even new regulations. The liability for violation always tends to be a rounding error to profits. Then, even if there are teeth, there is no money for enforcement which makes it all pointless.Look at how the FTC and SEC have completely failed us in the 21st century. Better regulations would matter if we ever bothered to enforce the ones we already have. reply whats_a_quasar 15 hours agorootparentIDK man this is a pretty defeatist attitude and doesn&#x27;t lead to any steps to improve the situation. There&#x27;s an FTC commissioner here in the comments today who&#x27;s interested in the community&#x27;s input. If you don&#x27;t think it will have any effect that&#x27;s your prerogative, but members of the public providing good technical opinions can only be a good thing.I don&#x27;t agree with the vibe that past failures mean that regulations are pointless. Nothing is perfect at preventing abuses, but regulations do shape the actions of corporations and the terms of the discussion. Plus, the FTC is not one person - the commissioner making the post entered office in 2020, and so it seems broad to pin him with vague statements about the FTC completely failing us. reply autoexec 15 hours agorootparentprevIt&#x27;s better to get the policies in place now and then complain about the lack of funding&#x2F;enforcement. The mere threat of enforcement will cause some companies to design their products better and when a major security incident happens because of a bunch of insecure IoT devices and people are outraged it&#x27;ll be a lot easier to motivate action if we can say \"We already have rules that would have prevented this entirely, but the FCC wasn&#x27;t provided the resources to enforce them.\"That&#x27;s a clear call to specific action as opposed to \"We don&#x27;t have rules that would have prevented this, and also many of the rules we do have across several agencies don&#x27;t have enough funding to enforce rules designed to solve other problems.\" reply klausa 12 hours agorootparentprevHN when governments agencies have little leverage to enforce rules: The violations are a rounding error to profits! We need to make the laws more stringent.HN when EU passes laws that have significant teeth in them and let them actually enforce them: This is ridiculous overreach! It will kill innovation and make it impossible to do business there!Love it, never changeThese regulations put us on the path of trusting religious-like in government.We don&#x27;t need to have religious-like faith in government because we can vote for people who will do what we want them to and we can vote out the people who refuse to do their job. It doesn&#x27;t happen without the people getting involved and holding their government accountable though. You don&#x27;t have to pray when you can vote.Without regulation you could only ever have religious-like faith in private corporations because they have zero incentive to act benevolently and you have zero power to replace a CEO who is acting against the interests of the public. You have no vote, so prayer is all you have left. reply landemva 15 hours agorootparentHow well did that work for bank oversight in 2008, and again in 2023 with SVB? The accountability of \"my one vote will remove government&#x27;s failed regulators\" fails on the scale of $billions. reply autoexec 15 hours agorootparentYour examples are situations were deregulation&#x2F;lack of regulation caused problems. Without regulations, prayer didn&#x27;t work out so well. We all know IoT security is a problem, but after decades of that problem existing prayer hasn&#x27;t worked there either. No one person&#x27;s vote can fix government but collectively we have the option to enact change. I&#x27;ll take having the ability to make changes over being powerless to make changes every time. reply klausa 12 hours agorootparentprevIs there an argument that the government failed in oversight with SVB?I think this is a textbook slam-dunk by the government? They stepped in when the situation was _bad_, but not _catastrophic_ yet (mmmmaybe arguable), took over, and no depositors got hurt.Is there an argument that this could&#x27;ve gone better, apart from \"no banks ever fail\"? reply landemva 10 hours agorootparentFed had to set up a swap&#x2F;lend facility that weekend. Sort of like they make it up as they go.The specific regulator is going to retire. \"Abbasi and Mary Daly, president of the San Francisco Fed, came under scrutiny after a post-mortem report undertaken by the Federal Reserve found problems with how SVB was supervised.\" https:&#x2F;&#x2F;www.msn.com&#x2F;en-us&#x2F;money&#x2F;markets&#x2F;key-san-francisco-fe...And through regulatory capture the CEO of SVB was on the board of directors of the regulator!https:&#x2F;&#x2F;www.reuters.com&#x2F;markets&#x2F;us&#x2F;ceo-failed-silicon-valley... reply rjbwork 14 hours agorootparentprev>How well did that work for bank oversight in 2008, and again in 2023 with SVBHilarious own goal on this one. reply fallingknife 14 hours agorootparentprevMaybe I could have some faith if regulatory bureaucrats were fired when there are major regulatory failures e.g. 737 max. Maybe I could have some faith if police state agency employees were jailed for FISA abuse.Voting isn&#x27;t enough because even elected officials aren&#x27;t allowed to fire these people. reply landemva 10 hours agorootparentSpecifically, FAA allowed Boeing to use software to cover up design flaw (crammed bigger engines under wings which causes pitch up problem) so it would appear to drive like older 737s. Apparently only a test pilot has been charged for falsifying some paperwork. 737MAX should be required to get a new type certification due to the significant changes.Another example of regulatory capture leading to inadequate oversight is FDA, which has revolving door with drug companies. https:&#x2F;&#x2F;www.mdlinx.com&#x2F;article&#x2F;10-dangerous-drugs-recalled-b... reply avidiax 4 hours agorootparentprev> Maybe I could have some faith if regulatory bureaucrats were fired when there are major regulatory failures e.g. 737 max.If I were Boeing, I would hire the fired bureaucrat with a lavish comp package and make sure he&#x27;s at every meeting, conference, get-together, etc. looking well-tanned and happy.That makes negotiating with the fired guy&#x27;s replacement much much easier. reply paiute 8 hours agorootparentprevI’ve worked in security before and i don’t really think the government should be involved that much. There are so many different situations to consider. What i would support is the fcc coming up with a list of common patterns and then forcing devices to state which, if any, pattern they follow. I have a weather station for example which doesn’t really need any security on the device end. reply necovek 6 hours agorootparentDoes your weather station connect to the internet? (the discussion is about IoT devices)If so, plenty of IoT devices have been used in botnets, as point of entry into local networks (hello printer, home assistant, file share...), or simply killed off with a DoS attack. reply Finnucane 15 hours agorootparentprevWhich the manufacturers of IoT devices will give us willingly out of the goodness of their hearts? reply landemva 15 hours agorootparentYet government is made of people so it does not have God-like powers, even though it is often worshipped.I would prefer to plug in a box that does this segment&#x2F;filter. I will pay if it can be rebuilt from available source code. Make it easy to install and setup. If nobody purchases then nobody cares and why would government get involved? Seems like FCC scope creep.Forcing every IoT vendor to do it overlooks the problem of each vendor having and maintaining the skillsets.How about something like UL to create a slim standard and test against that standard. The aforementioned box idea could apply to be tested against the standard.https:&#x2F;&#x2F;www.ul.com reply andybak 14 hours agorootparent> Yet government is made of people so it does not have God-like powers, even though it is often worshipped.A slightly bizarre aside. reply ClumsyPilot 10 hours agorootparentprev> regulations put us on the path of trusting religious-like in governmentWe trust in government to set rules and punish rulebreakers. When that is not true, do we enact punishment ourselves? Results would be not pretty. reply landemva 6 hours agorootparentIf your ISP determines there is a botnet from your home IP and you refuse their request to fix it, then it seems appropriate for your ISP to take action or \"enact punishment\". reply eganist 14 hours agorootparentprevIndeed, this is awesome.Not sure if you&#x27;re able to comment on this, but is there anything in place to mitigate the risk of automated astroturfed commentary e.g via LLMs in this and other cases?Edit: on the fcc docket specifically, not on HN reply echelon 13 hours agorootparent> Not sure if you&#x27;re able to comment on this, but is there anything in place to mitigate the risk of automated astroturfed commentary e.g via LLMs in this and other cases?Look at HN account age, karma, and comment histories. reply yreg 13 hours agorootparentWhat about new users? reply echelon 13 hours agorootparentprevThank you so much for asking HN! I can&#x27;t think of a more informed, higher signal community to interface with and get open and honest feedback from. Really brilliant idea.I don&#x27;t have much input on this issue, but I wanted to ask that if you know folks in the US Copyright Office, that you recommend the same approach to them with regards to their upcoming regulatory stance on AI.The copyright office is going to hear one-sided input from artists and the largest tech companies (seeking to build moats), but they need to broaden their inquiry to include technologists, researchers, and startups. HN is an excellent place to increase their understanding.If you can, I would greatly appreciate it if you tip the copyright office off about HN! reply wolverine876 17 hours agoparentprevAgreed. Thank you Commissioner Simington for reaching out to us. It makes all the difference in the world.> while you likely can’t influence something like a presidential election on your ownIn fact, there is almost nothing of significance you can accomplish (or influence) on your own. We always do and always have needed to work together - and the results are astonishing: almost everything that&#x27;s ever been accomplished. reply COGlory 14 hours agoparentprevGoing to echo my thanks here as well. reply ryukoposting 15 hours agoprevAs a firmware engineer, I&#x27;m one of the people who actually writes the code that goes inside the IoT devices. I&#x27;m very interested in what the FCC might be able to do here.How does the FCC define a security flaw? Would updates only be distributed when there is a flaw that needs fixing?Remote update mechanisms can themselves present security problems in some domains. Thus, some devices should only be updatable if the owner has physical access to the device. Will the manufacturer be liable for damages caused by attacks on vulnerable devices that were not sufficiently updated by their owners?IoT is making its way into defense and enterprise environments where reliability is a matter of national security. An update nearly always results in some downtime for the device, even if it&#x27;s just a couple seconds. Sometimes, it may be in the best interest of a device&#x27;s owner to defer an update indefinitely, until that device&#x27;s continuous operation is no longer mission-critical. Even if the owner can&#x27;t control exactly what is in an update, they absolutely MUST be able to control when an update occurs. reply baby_souffle 14 hours agoparent> Even if the owner can&#x27;t control exactly what is in an update, they absolutely MUST be able to control when an update occurs.+1 for this at the consumer level. My oven may have a critical update, but - for right now - *nothing* is more critical than finishing dinner. I&#x27;ll let the update apply the day after thanksgiving when I&#x27;m doing the dishes.There are a few connected appliances brands that do this well: updates are broken down into two classes - \"critical&#x2F;security\" updates and \"all the other updates\" - and I get to pick from \"do nothing, notify, notify and download, notify, schedule&#x2F;auto-apply\" for both channels. Unfortunately this is not common because it takes planning and more than the bare minimum to pull off. reply klausa 12 hours agorootparentI think this is oversimplifying things.Is finishing the dinner more important than applying a patch that fixes actively exploited bug that locks your oven into cleaning mode and burns everything inside into ash over the next three hours? Or something that disables the safety checks and lets the oven overheat and burn your house down?(Granted, the latter shouldn&#x27;t physically be possible because it should have physical temperature killswitches etc.)People always (understandably so!) consider software updates to be annoyances; but especially when you give an example like _an oven_, the potential for _catastrophic_ failures is too great. reply MarcoPerazaFCC 12 hours agorootparentOne my favorite IoT botnet scenarios is an attacker taking control of thousands of ovens&#x2F;air conditions&#x2F;other high-wattage devices and using them to cause power outages. https:&#x2F;&#x2F;www.usenix.org&#x2F;system&#x2F;files&#x2F;conference&#x2F;usenixsecurit...I wonder how the impulse to connect everything to the internet will be remembered. reply ezzaf 7 hours agorootparentThe flip side of that is you can use control of all those high wattage devices to prevent power outages by shifting load to times when more energy is available.Hopefully, that&#x27;s how the impulse will be remembered. reply necovek 6 hours agorootparentOr by the rise of salmonela infections... reply withinboredom 1 hour agorootparentprevFinishing dinner can be more important than the house not burning down. A burned down house is likely insured. A dinner with a potential business client is not. reply lxbxc 55 minutes agorootparentSurely this has to be a joke. reply hot_gril 10 hours agorootparentprevThese seem like very rare scenarios. If we&#x27;re concerned about dire threats like this, the manufacturer needs a way to remotely send devices into an internet-disconnected \"safe mode\" before anyone&#x27;s even talking about updates. reply klausa 9 hours agorootparentHow do you, as a user, determine whether your oven is in \"safe mode\" that the manufacturer has toggled, or in \"safe mode\" that makes the UI look the same as the real one, but is actually a malicious code that waits until 3AM to start the cleaning mode?I agree that these scenarios are (relatively) far fetched _now_; but if we expect the future to include connecting appliances like that to the internet, then solving problems like those is table-stakes stuff.I understand that enforced software updates are annoying; but for high-stakes environments like this they strike me as a lesser of the two evils. reply hot_gril 9 hours agorootparentIf the attacker has total control, then all bets are off no matter what mechanisms you put in first. Adding a safe mode would at least allow manufacturer to stop any non-total exploit without relying on the more complicated update mechanism. Also, the appliance would more likely work in a kinda normal way in the meantime. reply chmod775 6 hours agorootparent> If the attacker has total control, then all bets are off no matter what mechanisms you put in first.You could have a second SoC on the device running off ROM, whose only purpose is handling this safe mode and controlling internet access of the main device. Keep it simple and make it essentially just a fuse that can be blown (turning off internet access) by a signed message from the manufacturer. Keep the hardware capability of this SoC to just that, so even if you have a vulnerability on that thing itself, an attacker can&#x27;t really do anything with it. Keep the code running on that SoC simple and preferably make it a FSM that is proven to be free of vulnerabilities. Also make sure the main device can&#x27;t interfere with it in any way.Once the fuse is blown, the user needs to press a physical button on the device to re-enable internet access. Preferably ship the devices with this internet access disabled by default.Even better yet, don&#x27;t build an internet connected oven... but that ship has sailed in many areas. reply klausa 9 hours agorootparentprev>If the attacker has total control, then all bets are off no matter what mechanisms you put in first.Great, so we now agree that it&#x27;s important to keep the system patched and up to date. reply Attrecomet 2 hours agorootparentJust as smart people agree that the manufacturer knows nothing about the situation at the appliance, and a forced update mechanism a la the first iteration of Windows forced updated (\"update&#x27;s here, restarting, too bad you&#x27;re currently doing important stuff that won&#x27;t be saved\") is a stupid idea and outside of private use often a non-starter. That kind of condescension is generally only something you can do to private tech users.Though I guess making the experience frustrating could keep more people from needlessly connecting everything to the network because it sound futuristic... reply hot_gril 9 hours agorootparentprevI didn&#x27;t say otherwise. Only that a forced update mechanism is insufficient for stakes as high as burning down the house. Maybe the patch fails to download&#x2F;install, or they take too long to develop the patch in the first place, or the patch doesn&#x27;t work for all models on the first try. There needs to be a simple kill switch if we&#x27;re talking about threats like this.Besides that, the safe mode oven should still be able to cook food manually. reply fragmede 9 hours agorootparentprevThat depends on updates never introducing new vulnerabilities. replyhot_gril 11 hours agorootparentprevI&#x27;m wondering why you&#x27;d have a smart oven in the first place. Seems like all risk and no reward. reply stevehawk 9 hours agorootparentThe ability to pre-heat my oven without standing in front of it. That&#x27;s really the big win. But also to be able to tell if spouse or children left it on. reply hot_gril 9 hours agorootparentBut I can walk to my oven and turn it on, which wasn&#x27;t a real problem even when I lived in a huge house. What am I missing? reply spiderice 9 hours agorootparentWe really can’t force you to see the obvious if you’re set on not understanding something. reply hot_gril 8 hours agorootparentThat&#x27;s alright, I&#x27;m good. Smart ovens are pretty rare, so it seems like a lot of people don&#x27;t get this. reply fragmede 9 hours agorootparentprevLucky guy, it sounds like you&#x27;ve never experienced overwhelming anxiety over having possibly left the oven on while out of the house. reply Const-me 1 hour agorootparentEven if you left the oven on, I believe it’s very unlikely to burn down the house.These devices are designed to work for hours with minimal supervision. Given the size of the user base, IMO ovens are extremely reliable. And electricity prices are too low to be anxious about the costs. reply dandy23 2 hours agorootparentprevA simple timer that switches off after a couple of hours would do. The timer could reset every time the oven door is opened. This should solve most issues. Long cooking could have a bypass button or somethong (if the door open reset is not enough). reply zidad 1 hour agorootparentI just remembered many old analog electrical ovens had this already , the only way to turn on the oven is by setting a timer (and when you needed it on for many hours you had to set another timer for yourself to remember to extend the oven timer ). reply hot_gril 9 hours agorootparentprevThat&#x27;d be a legit feature, but far less involved than a full-on smart oven. At most, it&#x27;d have a way to turn off the oven remotely (but not turn it on).Anyway, last time I had this anxiety, I checked my Ring camera in the kitchen that&#x27;s posted there for reasons like this. Works for the stove and faucet too. reply FetusP 5 hours agorootparentWhile I have neither, I&#x27;d much rather use a smart oven to see its status than have a constant camera feed of my kitchen. reply hot_gril 4 hours agorootparentIt only records on demand, mainly cause it&#x27;s on battery. Also doesn&#x27;t control anything in the house. reply MrDrMcCoy 9 hours agorootparentprevProbably for some feature or astetic that&#x27;s unrelated to the smart features, but is only available on the smart oven. reply galangalalgol 9 hours agorootparentThis os definitely most of it. Also, someone figured out they could do something with the parameters of the convection oven and get close to an air frier. Got the mode a year later. Lastly, when the meat thermometer hits temp, I get a notification. That is actually useful. reply fragmede 9 hours agorootparentprevThe more critical thing than finishing Thanksgiving dinner for your oven is not burning your house down. reply WalterBright 10 hours agoparentprev> Remote update mechanisms can themselves present security problems in some domains.I&#x27;ve proposed many times that the device have a physical write-enable switch on it, not a software switch. That way, a malware infestation won&#x27;t survive a reboot, and your backup hard drives won&#x27;t get compromised.I&#x27;m amazed that nobody does this. (Hard drives used to have a write-enable switch on them.) reply structural 10 hours agorootparentMany flash chips have write enable pins at the hardware level. So this support really does still exist in theory!However, these pins mostly aren&#x27;t used for any kind of switch in basically every PCB design I&#x27;ve seen. Either it&#x27;s \"always enabled\" so the storage can always be written, or it&#x27;s a chip that&#x27;s programmed from the factory and always disabled to prevent any kind of user update. reply WalterBright 10 hours agorootparentI&#x27;d sure hate to have my system ransomware compromised, and when I try to restore from a backup drive, the ransomware encrypts it, too, as soon as I plug it in.I also have, on occasion, flipped the from and to parts of the command to restore from a backup. I&#x27;d really like to have a hardware switch to make the drive read-only. reply fragmede 9 hours agorootparentThey exist, but only as very expensive specialty gear for digital forensic investigators.https:&#x2F;&#x2F;digitalintelligence.com&#x2F;store reply WalterBright 7 hours agorootparent> very expensiveIndeed, for a 2 cent switch. reply landemva 10 hours agorootparentprevWhy doesn&#x27;t MS do similar on all of their OS code by placing it on a read-only filesystem? Only allow updates when reboot into an update mode. reply Too 6 hours agorootparentAndroid does this. OS is read only. Updates happen on second partition and takes effect by swapping partition on reboot. Integrity is verified by secure boot. reply landemva 6 hours agorootparentInteresting. How is it verified? Maybe keep Merkle tree hash of eveything in TPM? reply WalterBright 7 hours agorootparentprevI have zero faith in software read-only modes. reply MarcoPerazaFCC 13 hours agoparentprevThanks for this thoughtful feedback. I encourage you to file an official comment, especially regarding end-user control of update timing. Maybe my response here https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37394935 addresses some of your other concerns? We&#x27;d love to hear your thoughts. reply ryukoposting 11 hours agorootparentThank you for the reply! I have submitted my official comment. reply MetaWhirledPeas 11 hours agoparentprevGood comments.> The FCC recently issued a Notice of Proposed Rulemaking [2] for a cybersecurity labeling program for connected devices.This sounds like it is intended for consumer products, and it also sounds optional. I would hope that users with a legitimate reason to do so (defense, enterprise) would have the capacity to not participate and forego the label. reply ryukoposting 11 hours agorootparentThe line between \"consumer product\" and \"enterprise&#x2F;defense product\" can be blurry. For example, event security teams may use their personal smartphones to communicate with medical staff.A lot of IoT companies (especially the startups) focus on the customers with the deepest pockets (enterprise and defense). If big-ticket customers demand this label, it generates a great deal of incentive for IoT companies to just say \"to hell with it, we want that label on everything we make.\"In any case, the words \"national security\" are usually a good way to get the attention of a three letter ;) reply MichaelZuo 14 hours agoparentprevThis is a good point, some IoT devices really can&#x27;t be designed to be physically serviceable, while still remaining reasonably compact, e.g. those that need very high levels of water resistance, especially saltwater resistance.And adding any remote update mechanism at all would more then likely decrease overall security.So there actually should be a counter mandate too, for devices that are impractical to design to be physically serviceable, while meeting certain size&#x2F;weight&#x2F;etc. requirements.To make sure remote update mechanisms, of any kind, are never implemented, unless the manufacturer can guarantee that the update mechanism itself doesn&#x27;t introduce new flaws. reply fragmede 8 hours agorootparentIt sounds like you&#x27;re looking for a carve out so you don&#x27;t have to upgrade your devices to have a modern microcontroller that supports remote updates and are using saltwater as a scary thing so no one challenges you on it.You can conformal coat a ESP32 with a sensor and battery and a wireless charger, and get remote updating. If hobbyists are doing that without commercial backing, what industry experts like you have access to must be even better. reply beambot 1 hour agorootparentWouldn&#x27;t a Starlink satellite qualify as an IOT edge device? How do you propose a user-servicable physical switch on a device in LEO?Not all devices have easy or cost-effective physical access -- that&#x27;s why IOT is particularly effective at bridging the digital-physical divide. reply MichaelZuo 8 hours agorootparentprevYou appear to be under a lot of mistaken assumptions.And in any case, the default ideal is to have an option to update or reprogram devices in-person.It&#x27;s never an ideal, that I&#x27;ve ever seen expressed on HN, to have a remote actor capable of doing so, unless in a totally air gapped environment. reply 01100011 10 hours agoparentprevIt would help if there were reference designs and testsuites for common embedded tasks like remote updates, configuration storage, input validation, etc.I don&#x27;t do much embedded work these days, but I remember a lot of shoddy, ersatz designs based on random OSS components. I remember a small mfg of hardware devices used widely in payment processing tell me they were secure because \"they used SSL\" despite not taking care of physical or system security in a coherent, effective way.Honestly, companies need to have some liability or other incentives to even care about security a lot of the time. reply alerighi 14 hours agoparentprev> Remote update mechanisms can themselves present security problems in some domains.Not really if done right to be fair. It&#x27;s just a matter of implementing a signature verification of the firmware updates that are installed on the device.> IoT is making its way into defense and enterprise environments where reliability is a matter of national security.If it&#x27;s a matter of national security surely you don&#x27;t use IoT devices connected to the public internet. At least the devices are in some private network, where the traffic is under your control. So if you don&#x27;t do security updates it may be acceptable under that circumstances. reply TeMPOraL 13 hours agorootparent> If it&#x27;s a matter of national security surely you don&#x27;t use IoT devices connected to the public internet.Of course they do. That&#x27;s the flip side of PaaS and reverse-NIH syndrome, the \"opex > capex\" thinking: \"Industry 4.0\" is built on web tech, with all the practices and assumptions baked in. Your critical infrastructure is, or is about to, be running JavaScript on a docker-compose cluster, and expecting to be piecemal-updated daily.And then, there&#x27;s also \"shadow IT\" - going behind the back of IT and using COTS SaaS to work around red tape is still... going around IT and giving untracked third-party vendors access to organizational information and operations. \"Making its way\" doesn&#x27;t only mean \"introduced by design\" - those vulnerabilities just creep in. reply SimingtonFCC 11 hours agorootparentI would love to see frank discussion on the record of consumer-grade vs infrastructure-grade practices and what label(s) would be appropriate for each! It’s not lost on me either that the roots of much high-ticket critical infrastructure is about to rest on web tech and highly evolved descendants of 8-bit micros. reply arp242 14 hours agorootparentprev> It&#x27;s just a matter of implementing a signature verification of the firmware updates that are installed on the device.In principle: yes. In practice: signing keys seem to get leaked all the time.It&#x27;s not a mechanism I would blindly trust in security sensitive domains. reply lnxg33k1 13 hours agorootparentWe could start by asking iot companies to be ISO 27002, stop saving passwords in excel files or in s3 bucket publicly accessible could helpSecurity is not an update, security is a cultural trait of an entity or an individual reply wepple 8 hours agorootparentprev> It&#x27;s just a matter of implementing a signature verificationcorrectlyWith rollback protection, a chain of signing keys to allow revocation, time stamping, correct parsing, enough scratch space to hold an entire separate image in A&#x2F;B, enough processing power to verify image signatures, etc etc.Doing this well is very hard. Given most IoT vendors don’t yet know how to prevent XSS, there’s near zero chance they’ll get updates correct in the next decade without solid open source frameworks to leverage. reply mcfedr 3 hours agorootparentAlso with right to repair, you need to be able to disable signiture checks and upload custom firmware reply WaitWaitWha 6 hours agoprevThanks for reaching out to the community.Instead of mandatory updates, there are lower hanging fruits you can win, and will have just as much, if not more positive security impact.1. No default password, one must be set at initial configuration2. Devices must function without public internet connection (unless it is one of the device&#x27;s primary function to transmit out)3. Devices must function without centralized host4. Explicit disclosure of all \"phone home\" destination hosts, and ability to change or disable this5. Explicit disclosure what information is transmitted out, and ability to disable thisI think the above five can be implemented relatively easily, requires no continued maintenance from the manufacturers, and improves the CIA triad of IoTs. reply neop1x 21 minutes agoparentI have zigbee and wifi smart home based on Home Assistant, zigbee2mqtt and ESP Home. It is completely local, no internet required and works perfectly. The automation is done in Node Red. If I need to do some action from the internet, I do it through wireguard VPN (one click on my Android phone).I especially like that zigbee is not even able to make connections to the internet itself. I \"own\" the devices.I understand that VPNs are hard for average users, but centralised, potentially insecure server infrastructures, generally situated in China, pose a significant security concern. reply kybernetikos 2 hours agoparentprev1. - routers have mainly solved this by having a unique, random password which is provided on a sticker on the device.Other than that, these are really good.I&#x27;d add something to address the problem of manufacturers going bust and then all their devices becoming paperweights. Perhaps:6. it should be possible for the user to install their own firmware &#x2F; updates. Optionally at the cost of losing guarantee and access to future manufacturer provided updates. reply systemvoltage 1 hour agoparentprevBy default, no telemetry. NO DATA OUT OF MY HOUSE WITHOUT EXPLICIT PERMISSION. reply simne 13 hours agoprevGreetings from Ukraine, European country with real Great war just now.I must say, we see extreme grow of cyber-crime as part of modern war. I think, in nearest future, cold war will guaranteed have huge cyber-crime part.And, hacking of IoT devices has very significant share of cyber-crime now. For real war it is question of life and death, because hacked devices with radio emission, are used by hostile intelligence, to find targets for attacks of heavy weapon, but also, we seen cyber attacks on electric-energy infrastructure, indented to make blackout (fortunately for us, unsuccessful).Chinese IoT devices are very special part of question, in many cases are connected to Chinese clouds, and this is also extremely dangerous, not only because potential unfriendly Chinese moves, but also because their security is not good enough, so in many cases, cyber-crime could intercept communications and interfere operation of device or even hijack control.For example, exists smart door locks with camera and I hear hackers hacked them and used them to observe work of air defense, so enemy could tune their air attacks to make more harm.In civilian life without war, videos from hacked door locks (or other IoT cameras) could be used for illegal surveillance, to coordinate riots, etc. reply SimingtonFCC 13 hours agoparentHi and thanks for commenting. My concern with this topic is motivated in part by the AcidRain family of energy infrastructure attacks and the larger questions they raise about infrastructure security. Teardowns on Chinese-sourced equipment have been somewhat worrying as well -- one report I&#x27;ve read highlighted about two dozen versions of SSH in a single base station. Best wishes and good luck. reply landemva 10 hours agorootparent> the larger questions they raise about infrastructure security.Not your mission to fix a network design problem which should air gap all of those devices. USA taxpayers can&#x27;t afford your agency scope creep. reply irjustin 7 hours agorootparentI&#x27;ll bite - so how do we get all those \"air gapped\"?It&#x27;s a leading question of course. reply landemva 6 hours agorootparentThe example was \"energy infrastructure\", so network group in those firms use their skills to set it up.If any government group should be providing guidance and best practices on how to air gap devices, maybe NSA should write the standards. This FCC proposal looks like a ploy to spend the ever-growing pot (reportedly ten billion USD each year) from the regressive USF phone bill tax instead of reducing the USF tax.As mentioned in another comment, a plug-and-play home device which provides network isolation and filtering for IoT devices may have a market. I would likely be a buyer at home.\"The bigger culprit is the FCC’s spending on USF, which is close to $10 billion per year, practically doubling in size since 2001.\"https:&#x2F;&#x2F;www.commerce.senate.gov&#x2F;2023&#x2F;5&#x2F;sen-cruz-it-s-past-du... reply irjustin 4 hours agorootparentI&#x27;m talking way out of my pay grade here.> If any government group should be providing guidance and best practices on how to air gap devices, maybe NSA should write the standards.I guess this is a bad joke? It&#x27;s hard to tell w&#x2F; the internet.> This FCC proposal looks like a ploy to spend the ever-growing pot (reportedly ten billion USD each year) from the regressive USF phone bill tax instead of reducing the USF tax.I can agree this is what it is under the hood [0].> As mentioned in another comment, a plug-and-play home device which provides network isolation and filtering for IoT devices may have a market. I would likely be a buyer at home.Here&#x27;s the key - there isn&#x27;t a market. Otherwise there would already be one (you are unique). That&#x27;s the crux of the problem. IoT is a race to the bottom when it comes to consumers. Consumers compare \"smart devices\" to what they already have - a light switch, a light bulb - commodities - they don&#x27;t think about security until it&#x27;s too late.So, that leads to:> If any government group should be providing guidance and best practices on how to air gap devicesYou can&#x27;t have \"guidance\" and actually get anything done in the consumer devices space. Standards and certifications - rejection of devices that don&#x27;t meet them.When it comes to dealing with communications FCC is the 3-letter-agency, and there&#x27;s no changing that.I guess the question boils down to - mass spying on Americans with un-secured devices sending data to China or let the FCC handle the problem by potentially expanding the USF?[0] https:&#x2F;&#x2F;docs.fcc.gov&#x2F;public&#x2F;attachments&#x2F;FCC-23-65A1.pdf page 45 replydtaht 17 hours agoprevThank you for engaging with the community in this way. Many years ago, in a fight to preserve individuals ability to flash their own routers, Vint Cerf, and I, and a coalition of many others, filed this report:http:&#x2F;&#x2F;www.taht.net&#x2F;~d&#x2F;fcc_saner_software_practices.pdf(retaining the ability to reflash our own routers, allowed my research project to continue, and the resulting algorithm, fq_codel (rfc8290), now runs on a few billion devices) The Linux and OpenWrt development process continues innovating and is very responsive to bugs and CVEs. It is a constant irritation that many products exist downstream from that that are 5 or more years out of date, and not maintained!Key bullets from that fcc filing are on page 12-13. reply SimingtonFCC 16 hours agoparentHigh-quality comment. Thanks very much! I&#x27;ll read your filing and think about it. But also, it&#x27;s a great example of impactful public FCC commentary. I hope your work inspires others to make their mark in the record. reply dtaht 15 hours agorootparentThank you very much for reading. It was the first, and last time, I ever took place in the public process and political action.https:&#x2F;&#x2F;www.computerworld.com&#x2F;article&#x2F;2993112&#x2F;vint-cerf-and-...We were within months of delivering a massive RFC8290-based fix for wifi performance and we´d been bricking routers left and right... and then got in a whole bunch that we could not modify... due to that proposed regulation... I lost my temper, organized 260+ to sign, made that filing, won, and went back to work. I should perhaps have pressed harder, as the binary blob issue has got ever more terrifying, deeply embedded into too many baseband processors.If I hold your attention a little bit? It would be rather nice if modern fq + aqm algorithms went into the internet nationwide. \"Bufferbloat\" is at epidemic proportions. Most the fixes arrived for it in Linux in 2012, and are only slowly rolling out 10+ years later, due to the accompanying epidemic of manufacturers´ not tracking new Linux kernels, (with all those accompanying vulnerabilities). I care very much about addressing security issues, but care about internet \"latency under load\" and better videoconferencing experiences more.There´s only a billion or so devices left to upgrade.https:&#x2F;&#x2F;www.usenix.org&#x2F;system&#x2F;files&#x2F;conference&#x2F;atc17&#x2F;atc17-h... reply SimingtonFCC 14 hours agorootparentThanks again -- will review both links (especially the latter!)The FCC hasn&#x27;t traditionally been a cybersecurity agency and will, most likely, never really be one; however, we can certainly do things through rules to empower experts, the public, and the agencies with cybersecurity expertise. If that one thing is all you ever did at the FCC, sounds like the public owes you a big debt of gratitude. reply fragmede 8 hours agorootparentWhere cybersecurity is a critical aspect of being able to communicate in our modern world, I urge you to rethink that. I can&#x27;t go by BestBuy and buy a TV that radiates rf noise all over the place, interrupting communications, but I can buy an IoT device that will get hacked and radiate packets all over the Internet and become part of a botnet, interrupting communications. reply dredmorbius 13 hours agorootparentprevAs communications increasingly overlaps with other elements of information --- data acquisition, storage, retrieval, processing, and transmission --- keeping the FCC out of the security space will become both more difficult and less tractable.We&#x27;ve already seen instances where broadcast channels have been hacked or hijacked, where false reports have been injected into news streams (at times affecting global financial markets, or disrupting emergency &#x2F; disaster responses), where communications providers have disabled public access to alerts (mobile providers and wildfires, Twitter&#x27;s recent hostile takeover), and more.There&#x27;s also the overlap between communications and monopoly (generally the FTC&#x27;s remit), which I realised a few years back: Censorship, surveillance, propaganda, and targeted manipulation (AdTech and similar tools) are all intrinsic properties of media monopolies:There are other concerns where media are highly decentralised or fragmented, including spread of rumours and confusion (e.g., \"fog of war\", or the general uncertainty in natural disasters or after political and military upheavals such as Germany as the Third Reich fell). But the monopoly -> media concerns issues seem well established. Most though not all of these are addressed by people such as Tim Wu, Bruce Schneier, Cory Doctorow, and Shoshana Zuboff, though I&#x27;m not aware that all the components I&#x27;ve identified had been linked previously.I&#x27;m aware that regulatory agencies are constrained by their legislative mandates, but communicating concerns over those limitations to Congress is also possible. reply CamperBob2 14 hours agoparentprevThere&#x27;s no small amount of irony in the fact that attempting to open your .PDF without the comforting assurance of SSL gives me a \"security warning\" that I have to go out of my way to circumvent. I&#x27;m sure that it won&#x27;t be long before it will simply become impossible for me to open the file \"for my protection.\"The push to mandate certificates and other gatekeeping mechanisms that enforce obsolescence for the sake of digital security theatre is ultimately going to benefit corporate bottom lines (especially those of landfill operators), but it will indisputably harm consumers.I guess I should turn that into a comment and submit it... reply vkaku 14 hours agoprevI&#x27;ve dealt with this multiple times, so let me give my perspective.- It is hard for manufacturers to do this with small teams. Mostly because they do not always have good CI&#x2F;CD or platforms available to keep being on top of vulnerabilities and so on and so forth.- Not all manufacturers write their own software and often contract it out to other experts in the field. This includes firmware and app developers.- If a manufacturer goes out of business or their website is hacked or whatever, the devices are going to send information to someone else, this is a big risk.- A lot of blast damage can be contained if home devices use local &#x2F; MDNS based service discovery as opposed to Internet based services. Many services could then either choose to reply locally or sometimes relay to the Internet if users policies allow. Unless people want other people unlocking their doors through the Internet, and they explicitly say it, Internet connection can not be mandated.- If a producer goes out of business they should be forced to give out a signed firmware that disables the key checking, then they must put up their source code for any users who wish to build and flash it themselves.- Some of these will not be practical to get manufacturers to agree on. IP issues will arise. Following decent open protocols for firmware upgrade and sharing platform specific specs can alleviate this. One should be able to re implement open firmware for their bulbs if everything else shuts down. reply tremon 13 hours agoparent> It is hard for manufacturers to do this with small teams. Mostly because they do not always have good CI&#x2F;CD or platforms available to keep being on top of vulnerabilities and so on and so forth.\"It is hard for hospitals to keep their ORs clean with small teams. Mostly because they do not always have good cleaning products or procedures available to keep being on top of contaminations and so forth\". I do not believe this is a valid argument to protect small firms.> Not all manufacturers write their own software and often contract it outTwo words: liability chain. This is standard practice in almost every other industry.I agree with the rest of your points, but I do not think that IP protections should trump regulatory requirements: if a company cannot comply with certain requirements due to contracts with their suppliers, the device should not be allowed on the market. reply Robotbeat 11 hours agorootparentLiability chain in many industries is a fantastic way to build a large legal moat to prevent competition from small players.The goal of any regulatory agency must be to ensure as much safety as can be done while preserving the ability of small players to enter the field and compete & while keeping the costs low for consumers. Otherwise, safety becomes a rationale that larger corporations are excellent at spinning to justify more regulatory moats. reply dcsommer 7 hours agorootparentA fair point. However, what are we optimizing for? An open&#x2F;fair market, or consumer safety? Balance is key, but I&#x27;m interested in any counter proposals that do a better job. reply MarcoPerazaFCC 13 hours agoparentprevThese are all great points and maybe a good reason why a voluntary program like this is the way to start, so a higher-tier of secure products can begin to emerge. We would also love to see the emergence of platforms that allow small teams to build on top of a secure, update-ready base. Some interesting discussion here https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37394546 reply bruce511 5 hours agoparentprev>> If a producer goes out of business they should be forced toGoing out of business is a loaded expression yhat covers many scenarios.For example if my company is acquired am I &#x27;going out of business&#x27; ?If I go bankrupt then my assets are sold off to pay creditors. Certainly the IP is an asset and it ultimately turns up somewhere. Releasing it before sale would be illegal in some places (disposing of assets while the business is insolvent for below-market value. )I know what we experience are abandoned PalmOS devices, but fundamentally PalmOS is owned by a legitimate company and has some nominal value.I think mandating requirements on the owner is a better approach. They reduce the asset value, so if it doesn&#x27;t sell it could be released as public domain. But that in turn gets very complicated if there are multiple code suppliers, and the downstream goes bust, but upstream is fine. reply bewaretheirs 13 hours agoparentprev> If a producer goes out of business they should be forced to give out a signed firmware that disables the key checking, then they must put up their source code for any users who wish to build and flash it themselves.Requiring an organization to do even a small amount of engineering as it is going under is simply not going to work in practice.IMHO the only possible way for something like this to work is to require vendors to upload buildable firmware source into a third-party escrow system before you can ship devices to customers. reply AnthonyMouse 12 hours agorootparentEscrow doesn&#x27;t really work either. You have the original code, but do you have the signing key? Is it still the correct signing key, or has an update rotated it without putting the new one in escrow? Are there different versions of the hardware that need different firmware?The only way to know that it works is to let people install custom firmware from day one, so they can discover if they can&#x27;t and raise their objections before the company is defunct. reply Etheryte 11 hours agoparentprevIf your team is not large enough to meet the required standards then you need to get a bigger team, not ask everyone else to forget the standards. You could make the same point about taxes, radio frequency use, etc. This is a non-argument. reply MetaWhirledPeas 11 hours agoparentprev> - A lot of blast damage can be contained if home devices use local &#x2F; MDNS based service discovery as opposed to Internet based services. Many services could then either choose to reply locally or sometimes relay to the Internet if users policies allow. Unless people want other people unlocking their doors through the Internet, and they explicitly say it, Internet connection can not be mandated.Networking ignoramus here. Are you suggesting the device could be prohibited from accessing the internet directly, and would be required to relay through a separate device (presumably with better security assurances)? Because that sounds like a good idea.Are there off-the-shelf firewall (or whatever) products that do this already? Quarantine the IoT devices and limit them to whitelisted, curated endpoints? reply dcow 9 hours agorootparentHomekit tried to do this. I don’t know if they still do.This can be done today by only advertising a ULA v6 prefix to IoT devices. The problem is the router has to now have global knowledge of what devices are allowed to talk to what services. Or the device has to work entirely locally with mDNS, DNS-SD etc. reply iandanforth 15 hours agoprevI think the most valuable security feature for IoT devices is being able to work without contact with a central service.If the value of a device is tied to opening a connection to and occasionally retrieving code from a third party it is inherently insecure. All I have to do is buy the company that owns the central server (or compromise it in some other less visible way) and I now have the ability to introduce malicious code to all devices that are receiving &#x27;security updates.&#x27; You won&#x27;t be able to make a rule to prevent asset transfer (correct me if I&#x27;m wrong) so you won&#x27;t be able to close this hole. And this assumes the manufacturer isn&#x27;t malicious in the first place.For people to be able to protect themselves and to protect the value of the property they have purchased (e.g. the company tanks and the central service is lost) a rule should exist mandating minimum useful functionality in a disconnected and&#x2F;or self-managed environment. reply nickff 14 hours agoparent>\"All I have to do is buy the company that owns the central server (or compromise it in some other less visible way) and I now have the ability to introduce malicious code to all devices that are receiving &#x27;security updates.&#x27; You won&#x27;t be able to make a rule to prevent asset transfer (correct me if I&#x27;m wrong) so you won&#x27;t be able to close this hole.\"Has this actually been a problem in the past? I do not know of any examples of this, do you?I hate having to create and maintain accounts and subscriptions for so many devices, but I&#x27;m not sure it&#x27;s a huge security problem. reply iandanforth 13 hours agorootparentGoogle&#x27;s acquisitions of Nest and Dropcam are the two which impacted me personally. Data ended up in the hands of people I didn&#x27;t want, features were removed that I found essential. Perhaps others can volunteer their stories, I&#x27;ve largely opted out of IoT because of these experiences and concerns. reply hunter2_ 10 hours agorootparentSuppose you buy a car from manufacturer A. You lose both keys (perhaps you and your partner each bring one on a canoe trip and capsize) so you have no choice but to ask the dealer to assign new ones. You find that Google now owns the entire brand A including its dealer network, and they only offer rekeying service in conjunction with an update that installs what you consider spyware. Do you opt out of the motor vehicle industry? reply wpm 6 hours agorootparentI opted out of the entire motor vehicle industry for far less. reply SonOfLilit 11 hours agorootparentprevThere are malicious actors in the business of buying popular App Store apps and introducing malware into updates. reply fireflash38 10 hours agorootparentOr buying chrome extensions. Even domains. reply ilamont 18 hours agoprevcommitments on this label (including the support period) will be legally enforceable in contract and tort lawsuits and under other laws.When it comes to U.S. laws that touch technology, enforceability is a mess. Spyware, spam, fraud, misleading labels, etc. are already governed by various state and federal laws, yet enforcement efforts are whack-a-mole at best.For IoT devices, having the proposed requirements sounds good in theory but I fear it is practically unenforceable, particularly for consumer-grade devices manufactured overseas.However, if powerful IoT platforms are also tied into the new regs - with Google, Amazon, Apple, Microsoft, PTC, HPE, etc. required to audit supposedly qualified devices and ban those that don&#x27;t meet the standards, with escalating penalties for failing to do so - that might shift the needle.My 2 cents. reply SimingtonFCC 18 hours agoparentYour point about buyers at scale is really important. The current effort is focused on sellers, but we think that if sellers have to define their security commitments, buyers will pay attention and their risk management people will insist on high standards.I fear it is practically unenforceable, particularly for consumer-grade devices manufactured overseasAlso a good point. The way we handle this for RF interference is to look at distributors and importers, not just manufacturers, but there will probably always be an untrustworthy product tier out there. reply Gormo 16 hours agoparentprevThey&#x27;re proposing an opt-in labeling program that essentially amounts for to the FCC underwriting certain attestations that vendors are choosing to make about their products.This means that someone applying the label without meeting the standards the label indicates would be guilty of exactly the sort of fraudulent advertising you&#x27;re describing, and contract and tort law are the relevant mechanisms of enforcement for this.I&#x27;m not sure what you mean by enforcement efforts being \"whack-a-mole at best\", but if you&#x27;re expecting some sort of preemptive regulatory barrier to be enforced by a bureaucratic agency in advance, that&#x27;s just not the way this sort of thing works or is intended to work, and the FCC certainly wouldn&#x27;t have the legal authority to implement such a regime.Legal actions for fraud, false advertising, trademark infringement (in the case of trademarked standards certification badges, e.g. UL) are frequently used mechanisms for this sort of thing, and seem to work well enough to ensure that vendors are deterred from fraudulently applying certification labels to their products. reply staticautomatic 18 hours agoparentprevIf there’s a private right of action you can bet the class action lawyers will do the enforcing. reply dredmorbius 13 hours agorootparentFair enough, but against whom?Fly-by-night foreign manufacturers or exporters would be difficult to prosecute. Unless the domestic importer, reseller, or transportation provider can be held liable, even class action lacks teeth. reply AnimalMuppet 18 hours agoparentprevHmm, yeah. Just as fraud telemarketers set up a new shell run by the same principals when the legal bills come due for their old one, so we&#x27;re likely to see new labels for a new shell company slapped on the same old insecure IoT box.So I&#x27;m not sure \"escalating penalties\" is going to cut it. It&#x27;s still whack-a-mole. You need a way to kill the mole, not just drive it to pop up a new hole.You need a way to get to the principals. They&#x27;re the mole.You need to either make them personally liable financially, or you need to jail them. Nothing else is going to stop serial fraud-behind-a-shell-company.I&#x27;m not sure I have an answer. But whatever answer there is needs to be applied not only to fraud telemarketers (please), but also to fraud IoT manufacturers&#x2F;resellers. reply distract8901 18 hours agoprevI think that IOT device manufacturers should be required to support their device for some minimum period of time AND be obligated to release the full source code for the device once they decide to end support. This also requires releasing the keys to any firmware signing mechanism or publishing a firmware update that removes such checks.The core problem is that without control of the firmware, consumers don&#x27;t really own these devices. The company can unilaterally decide one day to brick your device and force you to buy a new one. It should be obvious that this behavior is egregiously anti-consumer and anti-competitive. reply gsuuon 16 hours agoparentThis is great for hackers but doesn&#x27;t it make IoT devices incredibly insecure for normal users who wouldn&#x27;t even know their device has reached end of support? reply rfoo 15 hours agorootparent> doesn&#x27;t it make IoT devices incredibly insecure for normal usersHow secure or insecure a device is is unrelated to whether its source code is public.Disclosure: I might be biased on this, as I&#x27;m a reverse engineer. reply whats_a_quasar 14 hours agorootparentI think the parent comment is implying that if the source code is released at the end of the device&#x27;s supported life, it will be much easier for hackers to find vulnerabilities. Then users who aren&#x27;t paying attention will continue running that last version, and hackers will attack them using those now-public vulnerabilities.So you&#x27;d still need some mechanism to force-update devices in response to vulnerabilities found in open-source end-of-support firmware. reply gsuuon 11 hours agorootparentprevReleasing source code could lower the barrier a bit but the main thing I was calling out is releasing the keys - maybe they could be transferred to a trusted custodian instead. reply iforgotpassword 10 hours agorootparentIn certain cases probably yes, but maybe still worth it? If you have the keys you still need to get your maliciously manipulated build on the customer&#x27;s device... And this is assuming the manufacturer even bothered signing and verifying in the first place.So this would be bad for manufacturers releasing secure well designed devices without security vulnerabilities.... But if you think about it for a second, isn&#x27;t this good? As long as there is no known vulnerability, the manufacturer can say the device is still supported, and it costs them nothing, as they have no reason to release an update. And well, if there is a security issue, then it might be better to have the source and keys after all? reply hot_gril 11 hours agorootparentprevIf it were really unrelated, nobody would pay you to reverse engineer. re",
    "originSummary": [
      "FCC Commissioner Nathan Simington is stressing the need for security updates for IoT devices, highlighting common vulnerabilities and a shortage of timely manufacturer support.",
      "The FCC proposes a cybersecurity labeling program for connected devices, with security update support disclosure as a key criterion.",
      "Commissioner Simington encourages public feedback on this proposal to help in decision-making, with a submission deadline of September 25th, 2023."
    ],
    "commentSummary": [
      "FCC Commissioner Nathan Simington proposed regulations aiming for manufacturers to provide security updates for IoT devices for a specific period post-purchase.",
      "The FCC has launched a Notice of Proposed Rulemaking for a cybersecurity labeling program, highlighting the value of public comments in decision-making.",
      "Topics in discussion include the challenges of remote update mechanisms, probing IoT devices for vulnerabilities, the cooperative framework between researchers and companies, the role of government in IoT security, and concerns about cybercrime."
    ],
    "points": 2922,
    "commentCount": 770,
    "retryCount": 0,
    "time": 1693926441
  },
  {
    "id": 37392581,
    "title": "OpenTF repository is now public",
    "originLink": "https://github.com/opentffoundation/opentf",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up opentffoundation / opentf Public Notifications Fork 60 Star 2.6k Code Issues 32 Pull requests 8 Actions Projects Security Insights opentffoundation/opentf main 77 branches 0 tags Go to file Code Latest commit pdecat chore: ignore /opentf binary (#289) … b24c89c Git stats 31,648 commits Files Type Name Latest commit message Commit time .github Improve RFC description formatting. (#261) docs Fix link in architecture.md (#271) internal internal/states/statemgr: handle ignored errors (#277) scripts Release workflow (#173) testing/equivalence-tests Introduce a snapshot check for equivalence tests (#168) tools Remove traces of terraform-bundle (#145) version cleanup after 1.6.0-alpha20230802 release (#33623) website Fix issues website/docs/language (#244) .copywrite.hcl Configure copywrite to ignore more generated code .gitignore chore: ignore /opentf binary (#289) .go-version build with Go 1.20.7 (#33645) .goreleaser.yaml Release workflow (#173) .tfdev Rename root module name. (#4) BUILDING.md Adjust the BUILDING doc for building the code CHANGELOG.md internal/states/statemgr: handle ignored errors (#277) CODEOWNERS Adjust CODEOWNERS to not have any code owners right now CODE_OF_CONDUCT.md Create CODE_OF_CONDUCT.md (#176) CONTRIBUTING.md Update CONTRIBUTING.md to mention the need to update the CHANGELOG.md. ( Dockerfile Release workflow (#173) LICENSE [COMPLIANCE] Update MPL 2.0 LICENSE MIGRATION_GUIDE.md Create MIGRATION_GUIDE.md (#23) Makefile Renaming of Terraform to OpenTF README.md Add fork announcement links to README (#268) codecov.yml [COMPLIANCE] Add Copyright and License Headers commands.go Rename occurrences in root folder to to OpenTF (#172) copyright_headers.go build: Generate copyright headers automatically experiments.go Renaming of Terraform to OpenTF go.mod Remove checkpoint code - less is more (#151) go.sum Remove checkpoint code - less is more (#151) help.go Rename occurrences in root folder to to OpenTF (#172) main.go rename func main_test.go Rename occurrences in root folder to to OpenTF (#172) plugins.go Revert \"Add support for ~/.opentf.d (#22)\" (#38) provider_source.go Rename occurrences in root folder to to OpenTF (#172) signal_unix.go [COMPLIANCE] Add Copyright and License Headers signal_windows.go [COMPLIANCE] Add Copyright and License Headers telemetry.go Rename occurrences in root folder to to OpenTF (#172) tools.go [COMPLIANCE] Add Copyright and License Headers version.go Rename root module name. (#4) working_dir.go Rename root module name. (#4) README.md OpenTF Manifesto: https://opentf.org About the OpenTF fork: https://opentf.org/fork Join our Slack community! Important Note: This repository is currently a work in progress while we're preparing it for the first alpha release and fine-tuning the community contribution process. Please read the announcement post for important context and the contributing docs for instructions on how to contribute. Additionally, please be mindful that building this repository in its current state and running it might put you in violation of the Terraform Registry ToS, if that's where you fetch your providers or modules from. OpenTF is an OSS tool for building, changing, and versioning infrastructure safely and efficiently. OpenTF can manage existing and popular service providers as well as custom in-house solutions. The key features of OpenTF are: Infrastructure as Code: Infrastructure is described using a high-level configuration syntax. This allows a blueprint of your datacenter to be versioned and treated as you would any other code. Additionally, infrastructure can be shared and re-used. Execution Plans: OpenTF has a \"planning\" step where it generates an execution plan. The execution plan shows what OpenTF will do when you call apply. This lets you avoid any surprises when OpenTF manipulates infrastructure. Resource Graph: OpenTF builds a graph of all your resources, and parallelizes the creation and modification of any non-dependent resources. Because of this, OpenTF builds infrastructure as efficiently as possible, and operators get insight into dependencies in their infrastructure. Change Automation: Complex changesets can be applied to your infrastructure with minimal human interaction. With the previously mentioned execution plan and resource graph, you know exactly what OpenTF will change and in what order, avoiding many possible human errors. Developing OpenTF This repository contains OpenTF Core, which includes the command line interface and the main graph engine. To learn more about compiling OpenTF and contributing suggested changes, refer to the contributing guide. To submit bug reports or enhancement requests, refer to the the contributing guide as well. License Mozilla Public License v2.0 About OpenTF lets you declaratively manage your cloud infrastructure. Resources Readme License MPL-2.0 license Code of conduct Code of conduct Activity Stars 2.6k stars Watchers 30 watching Forks 60 forks Report repository Releases No releases published Packages No packages published Contributors 16 + 5 contributors Languages Go 89.9% MDX 9.4% HTML 0.4% HCL 0.2% Shell 0.1% Makefile 0.0% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37392581",
    "commentBody": "OpenTF repository is now publicHacker NewspastloginOpenTF repository is now public (github.com/opentffoundation) 470 points by cube2222 19 hours ago| hidepastfavorite155 comments cube2222 18 hours agoHey!As many of you asked for, we&#x27;ve finally made the repository public and will continue developing it in public from now on.This took us some time, but you can now read our announcement for more details[0].Thanks everybody for the support so far, and I welcome you all to interact with the repo, join the discussion, or even contribute.A possibly noteworthy detail as it&#x27;s been discussed on HN here a bunch, we&#x27;ve settled with the DCO[1] for contributions.Also, happy to answer any questions![0]: https:&#x2F;&#x2F;opentf.org&#x2F;fork[1]: https:&#x2F;&#x2F;developercertificate.orgDisclaimer: Work at Spacelift, and currently temporary Technical Lead of the OpenTF Project, until it&#x27;s committee-steered. reply Foxboron 16 hours agoparentAs technical lead for the OpenTF project, how does things like this get merged?https:&#x2F;&#x2F;github.com&#x2F;opentffoundation&#x2F;opentf&#x2F;pull&#x2F;36&#x2F;commits reply cube2222 16 hours agorootparentEven though you&#x27;re being downvoted I do agree that this should&#x27;ve been squashed (I don&#x27;t see any other problems here, if that&#x27;s not it).I&#x27;ve made sure via repo config that only squash commits are enabled from now on, so this will not happen again. Thanks for the feedback! reply Faaak 15 hours agorootparentI&#x27;m sorry, but making only \"squash commits\" is also a bad idea. You can have a MR with multiple independent, atomic, commits.The \"real\" solution is making the developers aware of the issue and cleanup up their history before doing an MR. reply orra 15 hours agorootparentAbsolutely this. A series of commits dealing with different aspects (e.g. whitespace fix, minor related bug fix, necessary refactor, then the feature) is ideal.For a start, it&#x27;s easy to review, and easier to disect if something breaks.When messy git history is provided (i.e. a history of the developer fixing their own code that they missed), squashing can be a reasonable fallback. But it&#x27;s never the best option, IMHO. reply timost 14 hours agorootparentI&#x27;ve found `git commit --fixup` and `git rebase --autosquash` to be very useful when accumulating fixes of previous commits. reply jenadine 11 hours agorootparentgit-absorb is nice too reply sanderjd 6 hours agorootparentprevNah, automatic squashing is better. Use multiple stacked pull requests if you want multiple commits. reply lmm 4 hours agorootparentWhy? That&#x27;s a whole lot of overhead for no gain. reply alexchamberlain 15 hours agorootparentprevI couldn&#x27;t agree more, but this is a discipline that is rare in my experience. With GitHub lacking fast forward merges, I&#x27;ve struggled to articulate why it&#x27;s important. reply Conan_Kudo 14 hours agorootparentGitHub projects can be configured to force fast-forward merges. reply alexchamberlain 14 hours agorootparentI just re-checked github.com, and the only options are merge commit, squash commit and rebase commit. Rebase comes the closest, but none of these are fast-forward merges. Worst of all: you can&#x27;t disable the green button if you don&#x27;t like any of them. reply mcpeepants 12 hours agorootparentThe \"rebase\" option combined with the branch protection rule of \"require branch to be up-to-date\" gets even closer, in my experience reply jenadine 11 hours agorootparentRebase don&#x27;t work if the branch you want to merge contains itself merges (that potentially fixes conflicts) replyFoxboron 16 hours agorootparentprevThe squash merge is not going to solve the lack of proper commit messages and the fact that things are breaking the test suite left, and right.Figuring out bugs with `git bisect` is not going to be a fun endeavour for people trying to understand incompatible changes. reply cube2222 16 hours agorootparent> and the fact that things are breaking the test suite left, and rightBranch protection doesn&#x27;t allow merging without a passing test-suite.> The squash merge is not going to solve the lack of proper commit messagesCould you expand? You choose a sensible commit message on squash, while the PR&#x27;s commits become fairly irrelevant at that point. reply Foxboron 16 hours agorootparent> Branch protection doesn&#x27;t allow merging without a passing test-suite.https:&#x2F;&#x2F;github.com&#x2F;opentffoundation&#x2F;opentf&#x2F;pull&#x2F;243EDIT: and just to point out. If you have 1 PR with 19 commits that break the test suite. The last commit fixing it doesn&#x27;t matter as you will be hitting one of those 19 commits at some point during a bisect.>Could you expand? You choose a sensible commit message on squash, while the PR&#x27;s commits become fairly irrelevant at that point.It&#x27;s optional. Nothing prevents you from just adopting whatever the PR said initially. Turning it on doesn&#x27;t automatically make it better. reply jefftk 15 hours agorootparent> you will be hitting one of those 19 commits at some point during a bisectBut not if you merge the PR as a squash-merge, which turns those 19 \"development\" commits into a single \"permanent\" commit.Using PRs as the unit of development, with all intra-PR work squashed into a single atomic test-passing commit, is a well functioning process that many teams use. reply jen20 15 hours agorootparentThis would be true if and only if GitHub allowed you to collaboratively review and modify the squashed commit message _as part of the approval_ process, a feature which I have been requesting from them ever since \"squash and merge\" became an option. reply jefftk 15 hours agorootparentThe teams I&#x27;ve worked on generally use a \"copy the PR description into the commit message\", which works well. And if there are oversights, the PR number is in the commit ID which is a link to the larger context. reply pnt12 2 hours agorootparentprevIt would be nice, but unfortunately it doesn&#x27;t align with their goals - they want you to use github features, not git. reply Volundr 14 hours agorootparentprev> EDIT: and just to point out. If you have 1 PR with 19 commits that break the test suite. The last commit fixing it doesn&#x27;t matter as you will be hitting one of those 19 commits at some point during a bisect.Then I&#x27;ll `git bisect --first-parent`, and either isolate it to your merge, or mark to merge OK. `git bisect` doesn&#x27;t have to walk your branch. reply Foxboron 13 hours agorootparent--first-parent is a nice option I wasn&#x27;t aware of. But it would still depend on upstream not merging PRs failing the test suite. reply starttoaster 15 hours agorootparentprevThe other 19 commits are also not the current state of the code, and if the test suite is all currently passing, and nobody is using a version of the code in production from the other 19 commits, then none of that matters anyway. So I&#x27;m still confused why anyone should care.The test suite did its job by alerting you to make changes before merging your work to the trunk branch, I don&#x27;t see this as anything anybody could possibly pick a fight over.And to be clear, I still use mainline terraform because I never really wanted a wrapper around terraform. It&#x27;s just silly to me to take issue with the terraform wrappers for this non-issue. reply Foxboron 15 hours agorootparentRight.Imagine you are a terraform provider developer that is working on making sure their code is working with `opentf`.Lets imagine opentf does an initial `v1.0.0` release of their code and your provider doesn&#x27;t work. But you know it worked with the last FOSS release of `terraform`.What do you do?You find the common ancestor between these two projects, lets say 8a085b427b74ce3829500a59508b77465f1bbef0 (as that is the last commit `opentf` has from `terraform`).You will now run `git bisect` on the history between `8a085b427b74ce3829500a59508b77465f1bbef0` and `v1.0.0`.You will do a binary search on the 100-200 commits here, and everytime the source fails to build, or the test suite doesn&#x27;t pass for whatever reason, you are making it much harder for the downstream provider to figure out why their code doesn&#x27;t work.You can easily just try do this today and see what happens. Does the current untidy git history cause you any problems? reply starttoaster 14 hours agorootparentMy bias here is that I don&#x27;t tend to use commits the same way you do. I would look through each PR that had been merged between now and then. Specifically looking for PRs that look like they might change the thing that I&#x27;m having issues with. Untidy git histories are so common that it&#x27;s not really worth counting on, to me. A PR is a body of work that I find actually seems to matter. I wouldn&#x27;t reach the same hangup you had. On the flipside, when people overload their PRs with 3-4+ deliverable items, that tends to irk me. reply Foxboron 14 hours agorootparentBisecting to find the root cause is always going to be a better strategy if you know there is a good version.I really recommend adopting this strategy. reply starttoaster 14 hours agorootparentBisecting can be a good strategy. But you need to look through 100 commits. I need to look through 5-8 PR diffs. Everyone thinks they have the best strategy because they get results with it. Anyway, I&#x27;ll try your strategy if mine is failing. reply lijok 12 hours agorootparentYou should play around with git bisect - seems like you&#x27;ve not used it much. It&#x27;s a life changer when it comes to finding what broke.Don&#x27;t forget, a project like Terraform is too big. No one person can know how the whole system works. Trying to look through PRs as a means of debugging is a fools errand. You have to take on a different mindset when working on these large codebases. reply Foxboron 13 hours agorootparentprevNo, it does a binary search over the 100 commits. You would probably hit the issue before you hit 7 or 10 commits depending on how lucky you are. replyKeyframe 13 hours agorootparentprevDon&#x27;t sweat much over it yet. Default &#x2F; point people to something like merge into PRs, squash PRs when bringing them to main branches, and keep everyone follow https:&#x2F;&#x2F;www.conventionalcommits.org&#x2F;en&#x2F;v1.0.0&#x2F; for commits untill you find your way &#x2F; more edge cases crop up and you&#x27;re set. reply lucasyvas 16 hours agorootparentprevGive them some time to figure out what merge strategy they want to enforce - it was probably overlooked as a repository setting and they probably clicked Merge instead of Squash and Merge by accident. reply Foxboron 16 hours agorootparentHow does the merge setting solve the complete lack of any useful information in the pull request? reply sanderjd 15 hours agorootparentYour comments here should go in the textbook for \"why people often prefer to work in private for awhile while zeroing in on their processes for a new endeavor\".There will always be someone who will gleefully jump down your throat for imperfections.But on balance it&#x27;s probably better to work in public anyway and ignore the haters (while also continuously improving processes). reply Foxboron 15 hours agorootparentMost people don&#x27;t spend this much time on PR before releasing their fork though.If they had worked on this publicly from the start I&#x27;m sure a lot of the current PRs would have generally been of better quality as they could get community input earlier. reply sanderjd 14 hours agorootparentOh I see now! Your comments about the merits of the pull requests are just bad faith; you&#x27;re actually making this totally different point about the project that has absolutely nothing to do with squashing or commit messages. Thanks for clearing that up. reply Conan_Kudo 14 hours agorootparentIt was definitely not bad faith. They&#x27;re pointing out that OpenTF isn&#x27;t bothering to hold to quality standards that Hashicorp had for Terraform before the fork and they aren&#x27;t trying to raise beyond those standards to reach the levels common in higher quality community projects like Linux, Kubernetes, LibreOffice, and OBS Studio.A project being run by professional developers who have a lot of experience working with the Terraform code should be capable of doing this. reply sanderjd 12 hours agorootparentWell, I disagree that it&#x27;s not bad faith.If your problem with a project is that it advertised itself to its target audience prior to releasing a repository, then a good faith comment would say something like, \"My problem with this project is that they have spent more time writing manifestos and blog posts and social media comments so far than they have spent developing strong processes and working on publishing a repository for the project\".But if that&#x27;s your real problem with a project, then a bad faith comment might look like \"This is a bad pull request, how could you let it get merged?\". The reason that is in bad faith is that it says nothing about your actual problem with the project, it&#x27;s just a totally random swipe that you don&#x27;t even actually care about. If there turns out to be a good answer to the question, like \"Oh you&#x27;re right, we forgot to require squashing pull requests when merging, I&#x27;ve fixed it now!\", then instead of recognizing that your complaint has been spoken to, you are likely to simply find further things to criticize, because the first thing wasn&#x27;t actually your real criticism, it was just a smokescreen.Now, if you are making this other, better, point that the OpenTF project should have more mature software development practices, at least equivalent to and ideally exceeding the better-known project they have forked from, then yep, I agree with that criticism and do not think it is necessarily being made in bad faith.However, I would be significantly more sympathetic to that criticism if it were a comment on an article entitled \"OpenTF project celebrates one full year since its conception\" rather than one entitled \"OpenTF repository is now public\".The project is brand new, and they clearly rushed to get out a public repository because of other haters who were giving them crap about taking too long to publish the repository, and their processes clearly haven&#x27;t matured yet. (Or I dunno, maybe it was even many of the same haters, because again, this is the tendency with people who criticize in bad faith, to just move on to the next random criticism that they don&#x27;t actually care about.)So if we get to a year from now and their processes remain immature, then yep, I&#x27;m right there with you on your criticism. But I think it&#x27;s crazy (and, sorry to keep repeating myself: likely in bad faith) to make this criticism of such a new project. There is absolutely no indication that the developers running the project are incapable of having mature processes for the project, from the tiny amount of data available from the tiny amount of time that has elapsed since they announced the project. reply Conan_Kudo 9 hours agorootparentI think you&#x27;re confusing X&#x2F;Y and faith here. You&#x27;re making the basic assumption that the comment itself is in bad faith because it&#x27;s not formulated the way you expect. That doesn&#x27;t stand up to scrutiny because everyone evaluates and expresses things differently, and many folks would consider that a bad faith evaluation of feedback (whether it is positive or negative in reality wouldn&#x27;t matter).I think there&#x27;s a stronger argument of an X&#x2F;Y problem in the statement, since they talk about what they see as output vs what they expect to see instead.And frankly, I am disappointed too, as these people working on this project should have spent all that time understanding how Hashicorp actually handled the codebase and ensured that their own engineers followed the same quality level for development. They&#x27;re all definitely capable of it, so they should actually do it.Otherwise it&#x27;s going to be hard to trust the fork to succeed. reply sanderjd 6 hours agorootparentThere&#x27;s nothing more I can say on the bad-faithness thing that I didn&#x27;t already say in my last comment. I think the comment speaks for itself, and I don&#x27;t agree that it is \"X&#x2F;Y\", or itself a bad faith evaluation.(I do think you may be missing that I was responding to the entire sequence of comments, which started with just a drive-by swipe at pull request merging process, not just the later comments expressing disappointment with the perceived emphasis on marketing over engineering.)I think your direct expression of disappointment is totally reasonable. I personally think it&#x27;s also super premature to be disappointed, but it&#x27;s your prerogative.But I just think the other commenter&#x27;s approach to expressing this criticism was way off base. replylmm 4 hours agorootparentprevLooks like a good PR to me. It accomplishes something useful, and the fine-grained commits are very helpful for automated bisect (and frankly, if you&#x27;re not doing automated bisect then what are you even bothering with a VCS for). reply bradleybuda 16 hours agorootparentprevShould have factored out the project name into a build step to make things easier for the next fork reply fishnchips 16 hours agorootparentprevGood point, we should enforce squash merging. reply Foxboron 16 hours agorootparentIt would be trivial to at least continue the standards set by the terraform project. Now there are commits messing with `internal&#x2F;backend` that breaks tests with the commit message \"more\".Someone is going to hit this with `git bisect` and it wont be their lucky day. reply Groxx 15 hours agorootparentAnyone bisecting with a repo that uses merges should be aware of the `--first-parent` flag by this point.Or if not: you&#x27;re welcome! reply fishnchips 16 hours agorootparentprevFair point, I think we can fix that. Thanks for highlighting that. replyyjftsjthsd-h 16 hours agorootparentprevThings like what? That looks like a straightforward rename reply OJFord 16 hours agorootparentI think that&#x27;s exactly it, a &#x27;straightforward rename&#x27; shouldn&#x27;t consist of 20 commits with crap messages including &#x27;missed that&#x27; (+ merge commit).But tonnes of people don&#x27;t care about git hygiene or using tools well in general, GP&#x27;s in for an exhausting time caring about it much in projects they&#x27;re not in control of. reply yjftsjthsd-h 12 hours agorootparentI mean, I guess? Some people like small commits, and most of them looked reasonable to me (renaming one thing at a time); criticizing commit style seems like bike-shedding, anyways. reply alexchantavy 4 hours agorootparentAgree. I guess it’s different styles but when reviewing code I’ll look at the whole PR and almost never go commit by commit. If you expect OSS contributors to have perfect git hygiene, your project will never get contributors. If a breaking change is introduced, revert the offending PR as a whole. reply Reventlov 16 hours agorootparentprevCommit messages like \"more\", \"rollback\", \"missed that\" are not really what you expect from such an organization, so, yeah, that should&#x27;ve been squashed with a descriptive and useful commit message. My repos look like this but… I&#x27;m not a professional developer. reply linuxdude314 16 hours agorootparentThey are from this organization.The whole thing is a massive farce that’s primarily a marketing push for a few companies that were too lazy or hostile to negotiate a deal with Hashicorp.I strongly recommend anyone relying on on “OpenTF” ecosystem project get back to mainline and ASAP.These groups have clearly demonstrated a lack of competency in execution, planning, strategy, and software engineering.If you take your production environment seriously, now is the time to run. reply fishnchips 12 hours agorootparent> were too lazy or hostile to negotiate a deal with HashicorpAnd how do you know about any dealings any of us did or didn&#x27;t have with them, now or in the past? Are you privy to any of that?> lack of competency in execution, planning, strategy, and software engineeringOne of my old bosses taught me a lesson. Any time you criticize something, you spend your capital. This capital is earned by building value, by being constructive. If you have any constructive feedback, now is the time to speak up or remain silent forever. replygalenmarchetti 16 hours agoprevI think this whole process has been beautiful. Hashicorp was well aware that licenses are tagged to versions of projects rather than the \"project\" itself, and used that to its advantage as a business to start maximizing profits to its enterprise offerings.The community was well aware that once you tag a license to a version, you can&#x27;t undo that. And they&#x27;re well aware that they can fork from that license forwards and build their own \"new\" project, version by version, that stays open source.This is going to be fascinating to see play out, and I think a case study in software licensing going forwards...can&#x27;t wait to see how OpenTF does down the road. reply geerlingguy 11 hours agoparentIt seems closest to Hudson vs Jenkins split, in terms of community impact &#x2F; response (though not on the licensing front): https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hudson_(software)Oracle almost always seems to be involved in these things, but surprisingly not with Terraform :D reply arwineap 11 hours agoparentprevHistorically it may be interesting to look at the hudson &#x2F; jenkins codebases reply paxys 16 hours agoparentprevThere is no distinction between licenses tagged to \"versions of projects\" (whatever that means) vs the project itself. Hashicorp was well within their rights to change the license moving forward, and you or I or anyone else are within their rights to continue using an older version and fork it – which is exactly what happened here. reply hiatus 14 hours agorootparentThe fact that you can continue to use an older version and fork it supports your parent&#x27;s statement that the license is tied to a specific version. The new license only affects newer versions and can&#x27;t be retroactively applied. reply paulddraper 13 hours agorootparentYeah, but that&#x27;s a weird way to put it. Meaningless truism.Copyrights are never not tied to a \"version.\" There is no concept of \"version.\"Copyright applies to a bunch of data. You have a copyright on a song. If you create a second song you can call it a new \"version\" of the original or not, none of this matters for copyright. reply paxys 14 hours agorootparentprevThis is how all copyright and licensing works. There&#x27;s nothing unique about Terraform. You can&#x27;t go back and retroactively take away a permission that you granted someone. reply thecosmicfrog 17 hours agoprev> We&#x27;re consulting with a couple of legal experts regarding the name, and it seems that even OpenTF won&#x27;t be the final name due to use of \"TF\" in it.Interesting that having \"TF\" in the name could cause issues.Source: https:&#x2F;&#x2F;github.com&#x2F;opentffoundation&#x2F;opentf&#x2F;issues&#x2F;273#issuec... reply ohad1282 16 hours agoparentWe learned that Word Mark is the potential issue here.Read https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Wordmark for more details(disclaimer - env0 founder here, co-lead the OpenTF initiative) reply halostatue 13 hours agoparentprevSince this started, I’ve thought that they should probably be using xenoform instead of terraform (e.g., OpenXenoform and xf command). reply throwawayapples 16 hours agoparentprevTerror Form has a nice ring to it. reply toyg 14 hours agorootparentToo similar to the original.On the other hand, Terror Fort... reply justsomehnguy 13 hours agorootparentOpen Terror Front then, komrade! reply b0afc375b5 7 hours agoparentprevI thought \"TerraFork\" had a nice ring to it. reply aidenn0 14 hours agoparentprevFor a similar reason YP becane NIS[1].1: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Network_Information_Service reply paulddraper 15 hours agoparentprevKinda suspected this.AWS created OpenSearch, not OpenES. reply sluongng 16 hours agoparentprevIsn&#x27;t Tensorflow logo \"TF\"? reply capableweb 16 hours agorootparentI&#x27;m guessing the issue is that it&#x27;s obviously \"inspired\" by \"Terraform\" which shorthand is TF.My second guess is that using \"Open\" together with something that implies \"Terraform\" is also a problem, as Hashicorp might sue them for defamation, as that name would imply that Terraform is not \"Open\". I&#x27;m not personally against that, I wouldn&#x27;t consider Terraform \"Open\" anymore, but I&#x27;m not sure a court would see it the same way. reply toyg 14 hours agorootparentThe criteria for trademarks is not defamation, but confusion.Given a product TerraForm, known also as TF, how likely is it that a consumer would be confused into thinking \"OpenTF\" is made by the same people who make TF?That&#x27;s the bar to clear. In the past, some trademark owners have been fairly lax, allowing unrelated \"Open\" versions of their software to be established. The classic case was \"SUN OpenOffice\", but I suspect they got away with it because \"office\" was not a wordmark - the trademark was for \"Microsoft Office\", which is very different. In a lot of cases, the \"Open\" versions emerged once the software was not sold anymore, so it was impossible to be confused.In this case, though, the software is still sold and likely carries trademarks and wordmarks. Unless OpenTF&#x27;s pockets are deep enough for some serious lawyerin&#x27;, it will be easier to rebrand. reply cstejerean 14 hours agorootparentI&#x27;m not seeing any trademark registrations by Hashicorp on TF, nor any mentions of TF in any of the Terraform marketing pages. Not to say that Hashicorp couldn&#x27;t try to be difficult anyway, but it feels like at this point doing this would just raise the visibility of the OpenTF project. reply jonfw 16 hours agorootparentprevTensorflow isn&#x27;t a direct competitor. My understanding (and I am not a lawyer) is that enforcing trademarks is based around whether or not a consumer could reasonably confuse the product with the trademark owners. A user wouldn&#x27;t reasonably confuse tensorflow with terraform, but might confuse openTF with terraform reply blowski 16 hours agorootparentprevTensorflow isn’t competing with TerraForm. reply comprev 15 hours agoparentprevOpenPC aka Open Planet Change\"planet change\" being an alternative to \"terra form\" reply comradesmith 14 hours agoparentprevOpenForme maybe? reply gray_-_wolf 16 hours agoprevThey should have go with \"terrafork\"... reply stephenr 16 hours agoparentLunarspoon. reply Havoc 10 hours agorootparentThat’s amazing. I could see that actually working as a name since everyone will get the joke yet it’s dissimilar. reply olalonde 16 hours agorootparentprevMoonform has a nice ring to it. reply lawik 15 hours agorootparentAirshape reply Pet_Ant 15 hours agorootparentprevMoonspoon reply swyx 15 hours agoparentprevperhaps opencorp, because terraform is only product 1... https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37393844 reply mschuster91 17 hours agoprevThanks! I&#x27;d ask for two things:The first is, please provide a standalone registry package for both modules and providers - the only I&#x27;m aware of is Artifactory, and I don&#x27;t really feel like running another big repository software in a Nexus shop.The second is related: please allow for easier forking of provider modules. The current workflow of either building locally and distributing binaries with collaborators that are manually copied sucks or waiting for upstream to accept PRs, particularly if upstream wants CLAs signed. reply cube2222 17 hours agoparentHey!> The first is, please provide a standalone registry package for both modules and providers - the only I&#x27;m aware of is Artifactory, and I don&#x27;t really feel like running another big repository software in a Nexus shop.Could you expand on this? Do you mean you&#x27;d like a self-contained binary to run a private provider&#x2F;modules registry? If that&#x27;s the case, then there are some open source projects for that, and we&#x27;ve done a proof of concept of an approach in which you can distribute providers via OCI registries like DockerHub or the GitHub Container Registry[0] as those are actually perfect for the use-case.This PoC will be followed by a public RFC soon.> The second is related: please allow for easier forking of provider modules. The current workflow of either building locally and distributing binaries with collaborators that are manually copied sucks or waiting for upstream to accept PRs, particularly if upstream wants CLAs signed.Do you possibly have an ideal workflow in mind?[0]: https:&#x2F;&#x2F;twitter.com&#x2F;opentforg&#x2F;status&#x2F;1696913055576387599Disclaimer: Work at Spacelift, and currently temporary Technical Lead of the OpenTF Project, until it&#x27;s committee-steered. reply OJFord 16 hours agorootparentBtw, unless you mean to say &#x27;... But I&#x27;m commenting here in a personal capacity, not necessarily representative of the views&#x2F;policy of the organisation&#x27;, that&#x27;s a claim, not something you&#x27;re disclaiming.It&#x27;s sort of a disclosure (which is almost an antonym) but you&#x27;re not acknowledging a potential bias, you&#x27;re saying this is why you should listen to me&#x2F;care to reply, so even that doesn&#x27;t really fit IMO. reply mschuster91 17 hours agorootparentprev> Do you mean you&#x27;d like a self-contained binary to run a private provider&#x2F;modules registry?Yes, indeed. But it seems the problem more was something with Google&#x27;s algorithm, I swear a month ago this here [1] wasn&#x27;t on the first page when searching for \"terraform private provider registry\".That also answered the second question.[1] https:&#x2F;&#x2F;github.com&#x2F;outsideris&#x2F;citizen reply daniel_ciaglia 11 hours agorootparentHere&#x27;s another one for modules and providers https:&#x2F;&#x2F;github.com&#x2F;TierMobility&#x2F;boring-registryDisclaimer: I worked for TIER before reply Coryodaniel 17 hours agorootparentprevCitizen is great. Definitely recommend it. Really easy to get up and running locally for PoC w&#x2F; ngrok. reply kookamamie 4 hours agoprevThe logo on the Github page could do with an improvement on dark backgrounds - specifically, the dark text has a light outline (alpha bleed?) which aliases. reply _joel 16 hours agoprevGood to see, waiting on https:&#x2F;&#x2F;github.com&#x2F;opentffoundation&#x2F;roadmap&#x2F;issues&#x2F;8 so can do some testing (yes can build from source, but I&#x27;d rather use the releases) reply bastardoperator 16 hours agoprevNice, on a total side tangent, the logo looks fairly awkward in dark blue against a dark background. The white stroke also isn&#x27;t bold enough so it looks very pixelated when also combined with a dark background. reply dentalperson 14 hours agoparentDefinitely bikeshedding, but it also kind of looks like the TensorFlow logo and for a second I thought there was a group breaking the project free from Google. reply chologrande 17 hours agoprevI&#x27;m just skimming, but it looks like the docs are fantastic. I&#x27;ve spent some time with terraform internals, and this seems like a significant improvement for a dev looking to work with this codebase. Gives a great overview to get started. well done! reply cube2222 17 hours agoparentI&#x27;m not sure which docs you mean specifically, but most of the docs are fairly unchanged (other than trademark stuff) from the original repo, so if any of the docs improved, then to give credit where credit&#x27;s due, the kudos should go to the Terraform Core devs.Disclaimer: Work at Spacelift, and currently temporary Technical Lead of the OpenTF Project, until it&#x27;s committee-steered. reply chologrande 9 hours agorootparentwow I can&#x27;t facepalm any harder, I hadn&#x27;t seen the architecture docs etc in the top level repo... and they&#x27;re at the top level. reply MuffinFlavored 16 hours agoprevDoes anybody have a diff of what this code base looks like compared to the latest \"good acceptable ok to keep using\" Terraform license commit?I guess I don&#x27;t really understand what had to be changed given the new license debacle&#x2F;changes. reply fishnchips 16 hours agoparentGitHub has this \"compare\" functionality - this gives you a diff between where we forked and the current \"main\" - https:&#x2F;&#x2F;github.com&#x2F;opentffoundation&#x2F;opentf&#x2F;compare&#x2F;8a085b427... reply managingahhs 13 hours agoprevCan Terraform become a CNCF project itself and that be the foundation it&#x27;s tied to? reply lijok 12 hours agoparentUnlikely to get accepted by CNCF (I would think). There&#x27;s big movement by the cloud vendors to create IAC-first APIs. Once those APIs gain traction and the industry as a whole signals that that&#x27;s the direction to go, we&#x27;ll see a standard emerge, and a new general purpose tool get built that will replace Terraform and all of its providers. That&#x27;s a few years away however, assuming that effort doesn&#x27;t die down. reply paulddraper 6 hours agorootparentWhy can&#x27;t that tool be terraform? reply wkat4242 12 hours agoprevOpen TeamFortress? reply tuyguntn 17 hours agoprevwhy only Terraform? for some reason I was under impression that other offerings of HashiCorp will be supported by OpenTF foundation reply joshpadnick 17 hours agoparentOpenTF core member from Gruntwork here. All great products require focus, and right now our sole focus for OpenTF is creating the best possible truly open source and community-driven successor to legacy Terraform.I&#x27;d personally love to see an open source path forward on other products that Hashicorp re-licensed like Packer, but those will need to be a separate project and initiative. reply merb 17 hours agorootparentI doubt that there will be such things. Vault for example. Its unlikely that it gets a big backer or will be a cncf project. reply Pet_Ant 15 hours agorootparentPresumably this: https:&#x2F;&#x2F;www.cncf.io&#x2F;Cloud Native Computing Foundation reply notpushkin 15 hours agorootparentprevI think Packer is a reasonable candidate for a CNCF project. reply Bilal_io 17 hours agoparentprevFrom the name OpenTF (Open Terraform) I assumed it&#x27;s specific to Terraform reply capableweb 17 hours agorootparentThe \"TF\" part could be anything! :)Open Technology Foundation is one suggestion.Backronyms are a thing people. reply andersa 17 hours agoprevThis shall serve as a great example for why no reasonable company would ever use a permissive license for their main product again. reply hotstickyballs 17 hours agoparentIt should serve as a warning for companies who want to leverage the open source community but then do a rugpull reply ohad1282 17 hours agorootparentI think it is reasonable for a company to start OSS and then change its license. But it indeed feels like a rugpull for all the contributors.That is why OpenTF is on its way to CNCF. To ensure it stays OSS forever.There is a difference between \"true OSS\" like K8s, OPA, etc and \"temporary OSS\" (backed by a company) like what Terraform used to be, Pulumi, GitLab ,etc. Those can be changed in the future.When developers chose OSS, they should consider if it is a CNCF OSS or a vendor backed OSS. What Hashi did is an important example.(disclaimer - env0 founder here, co-lead the OpenTF initiative) reply AaronFriel 13 hours agorootparent> Pulumi is true open source, uses the Apache 2.0 license, and does not and never will depend on BSL-licensed software in any way, HashiCorp owned or otherwise.https:&#x2F;&#x2F;www.pulumi.com&#x2F;blog&#x2F;pulumi-hearts-opensource&#x2F;Disclaimer: the following is my own opinion as an engineer at Pulumi.Pulumi is true open source, with a relationship similar to git and the many SaaS services that layer on top of git to provide meaningful value.To contrast with our competitor, Pulumi relies on open source languages and protocols. We could not, even if we wanted to, change the Python license. Nor could we change our protocols without breaking our users and our growing ecosystem.That&#x27;s the value of building on open protocols and standard languages. reply ohad1282 10 hours agorootparentfair point. makes sense. reply res0nat0r 17 hours agorootparentprevI suspect this project is going to consist of a very loud minority of folks. I&#x27;m working for a very large company right now and they&#x27;ve been mandating us to move all of our TF code to Terraform Cloud for the last year, and I&#x27;ve not heard a peep about this licensing issue. I&#x27;m assuming they&#x27;re going full steam ahead and don&#x27;t care about this issue. As long as the TF Cloud service is easy to use, still a SaaS so it&#x27;s TF&#x27;s problem vs the companies, and they allow a robust login &#x2F; access pattern via OAuth &#x2F; SAML, all is well. reply joshpadnick 17 hours agorootparentOpenTF core member here. If you&#x27;re comfortable opting into an ecosystem where most of the key products are offered and supported by a single vendor (in this case, Hashicorp), then yes, there are no licensing issues to worry about and basically nothing needs to change for now.But our philosophy at OpenTF is that users would rather participate in an open ecosystem where multiple vendors compete for their business. If you&#x27;re not happy with one vendor, you can easily switch to another; competition works to make all vendors better.When we look back at this comment a year from now, I&#x27;ll wonder how your company will feel about the responsiveness and new features they&#x27;re getting from Terraform Cloud when the primary incentive to stay is not because you think it&#x27;s the best product available, but because switching costs are so painful. reply res0nat0r 14 hours agorootparentHonestly, I think when it comes to the large companies I&#x27;ve worked for, they care more than anything else revolves around \"support\". 15+ years ago the my previous company was all Sun Microsystems based, owned millions of dollars in 880s, 6800s and even an E10K. They said Linux was off limits because they couldn&#x27;t blame&#x2F;call anyone when they needed \"support\", even when Redhat was already around.Eventually they saw the writing on the wall and moved to Linux systems and replaced all of the hardware, and have an enterprise RHEL subscription that we could call when needed.I think the story is going to be the same with the current company, mainly \"who can we blame if there is a security incident, or get me a Hashicorp person on the phone if we have some kind of Terraform related production issue.\" Having this in place seems to matter more than everything else honestly. reply zeroimpl 6 hours agorootparentI&#x27;m not sure companies care much about support for \"simple\" tools like Terraform, at least the non-hosted version. Operating systems have lots of dark corners, but if your Terraform deployment isn&#x27;t working then the problem is likely your code. reply waynesonfire 16 hours agorootparentprevProbably a good idea to continue with that initiative. OpenTF is new. However, your CTO should contribute to the OpenTF effort.I would like to see more companies that leverage open-source contribute back to the very community that enables their value creation. reply sanderjd 15 hours agorootparentprevI think you&#x27;re both right?I have come around to the idea that it&#x27;s good to firmly discourage this kind of late-in-the-game license change.But I also think that, on net, this episode will lead to fewer businesses choosing the open source model for their software, from the start. It just seems like playing business on hard mode to try to build an open source or source available product, when you can just build a SaaS and charge for it. I think this is really bad (I have a strong preference to not be stuck with opaque SaaSes for most things), and I&#x27;m not sure what incentive there is to try to find new business models, when you risk becoming public enemy number one amongst a big chunk of your potential customer base. reply fishnchips 17 hours agoparentprev> main productWell that&#x27;s the core problem - what is the product here. Terraform Cloud and Terraform Enterprise are products for sure. They&#x27;re not open source, though. Is Terraform a product? Well, it doesn&#x27;t do anything on its own, it requires plugins (\"providers\") for anything it does. Plugins are developed by or at least with third parties. It&#x27;s a gatekeeper of an ecosystem that at this point is a common good.Whether the ecosystem would exist without the permissive license and external contributions - really hard to say. But if your main play is to foster the growth of an ecosystem and then turn it into a product exclusive to your business, then I guess you should look for alternatives.(Marcin from OpenTF, private opinion) reply johannes1234321 16 hours agorootparent> Plugins are developed by or at least with third parties. It&#x27;s a gatekeeper of an ecosystem that at this point is a common good.While I guess that for many vendors they don&#x27;t care whether it&#x27;s open or not. For instance AWS. I doubt they truly care about it being open or not. reply fishnchips 16 hours agorootparentAWS probably doesn&#x27;t care much for it being closed either. But the benefit of being open is that folks can investigate, report and fix bugs. For example, at Spacelift we found a fascinating corner case where an RDS DB could be dropped if the call to get its details resulted in a transient API error. We wouldn&#x27;t be able to do it if the code wasn&#x27;t open. I also believe that the AWS provider in particular gets quite a bit of attention from the community outside Hashi and AWS. reply t-az-f 12 hours agorootparentAll the providers are still MPL licensed, however. Maybe I&#x27;m missing something, but what part of the license change for Terraform core prevents someone from investigating and fixing a bug in the AWS provider in a similar manner going forward?Even Terraform core remains source available and so &#x27;community&#x27; users can still take a look at the source code and identify&#x2F;report&#x2F;fix errors. reply fishnchips 11 hours agorootparentOh, the core license change is irrelevant here, and the providers are MPL.I was just responding to a comment on how AWS didn&#x27;t care if the provider was open. IMO there&#x27;s value for them in it being open. replycapableweb 17 hours agoparentprevIf a company isn&#x27;t ready to compete against someone&#x2F;something that is using the code the company has written and published as FOSS, then yes, please do not use FOSS licenses for your \"Open Source\" product.One would think that the companies thought this through before publishing FOSS code, but seemingly there is a lot that didn&#x27;t do that. reply sanderjd 14 hours agorootparentThis is essentially where I have landed. I think these companies should have just used a license like BSL from the get-go, and I hope that the next generation of product companies will learn that lesson.But unfortunately I think the lesson they will take from this instead is \"we should just build a SaaS with no source availability because that&#x27;s way easier and source-available just makes people mad anyway\".I think that&#x27;s a shame. reply pknomad 14 hours agorootparent> I think these companies should have just used a license like BSL from the get-goI think that&#x27;s the general attitude the software companies will have going in the future. Why even bother dealing with negative PR and push back against their ability to make money by going with FOSS? In hindsight, TF should have been released with BSL from the beginning.I am not a huge fan of Hashicorp changing its licenses for future releases but I am also skeptical of OpenTF&#x27;s motives since their members have big financial stake in that decision. reply fishnchips 11 hours agorootparent> skeptical of OpenTF&#x27;s motivesAcknowledged, there are always self-serving motives involved. Generally things don&#x27;t happen without a reason. But we donated the project to a foundation, and will over time build (and fund) a dedicated independent team who will follow their own vision and the community needs, not ours. So please judge us by our actions, not assumed motives.> their members have big financial stake in that decisionI can&#x27;t speak on behalf of others but to us at Spacelift it&#x27;s less about direct financials (we are actually not directly affected by the license change!) and more about being in charge of our own destiny and product roadmap. reply kstrauser 16 hours agoparentprevIt serves as a better example of why it’s important to learn what FOSS means and implies before using those licenses.It doesn’t mean “everyone does our work for free and then we keep the profit”. reply Pannoniae 16 hours agorootparentIt also shouldn&#x27;t mean \"everyone leeches off our software for free, they get the profit while we get the maintenance burden\" reply kstrauser 16 hours agorootparentExcept you can&#x27;t say they&#x27;re \"leeching\" when they&#x27;re using the software on the terms you offered it to them.I&#x27;d also love to know how much Hashicorp chips in to maintain the projects they build upon. For example, I&#x27;d bet the vast majority of Terraform usage is on Linux. Do they support Linux development? Do they support Go language development? It seems like the companies complaining about \"leeches\" (eyeroll) aren&#x27;t the ones actually paying people to work on upstream FOSS projects. reply Pannoniae 16 hours agorootparentThe major difference here is that they are not making a directly competing product to Go, Linux, etc. I find the word \"leeching\" appropriate because here, it&#x27;s not simply someone building on Terraform to sell something else, they are selling a direct competitor to hashicorp&#x27;s products. reply dralley 15 hours agorootparentIn another era \"building on X to sell something else\" would be still considered \"embrace, extend, extinguish\" (in the actual, originally intended sense), depending on the market power of the players involved.At least if the \"something else\" isn&#x27;t free software. reply galenmarchetti 16 hours agorootparentprevI get what you&#x27;re saying, but on a strictly legal standpoint, everything Hashicorp is doing is by the books...all previous versions of Terraform will remain under the old license and everyone can still use Terraform without fearing a future lawsuit, as long as they stick to those version. So no one made any legal missteps here, neither the users nor Hashicorp.I think its the ethical side, rather than the legal side, thats more complicated...the contributions from the community contributed to the Terraform \"brand\" that got bigger and bigger, and now Terraform is attempting to secure their monopoly on capitalization of the brand when previously there was an implicit understanding that the \"brand\" was open-source.However, you might also argue that there was an implicit understanding on Hashicorps side that the community wouldn&#x27;t build directly competitive projects when they held the lions share of the funding on the contribution&#x2F;maintenance side...I think the whole thing is pretty complicated - is Hashicorp leeching off of the contributors or are the competitive contributors leeching off of Hashicorp? Honestly I see both sides.The beautiful thing is that its totally legal and acceptable for OpenTF to do their own thing and continue Terraform under their own terms...so either way we get to see this play out :) reply kstrauser 15 hours agorootparentI agree that it seems to be an ethical issue rather than a legal one.I&#x27;m coming down strongly on the side of the users, though. Hashicorp chose the original license, and the one they picked is perfectly fine with the idea of someone else building off it. I mean, it was written by the Mozilla folks. They want people to build off their projects and make a nicer Internet!Hashicorp could&#x27;ve used a different license if they wanted to. They deliberately chose one that gives users the rights to build on Hashicorp&#x27;s work -- and yes, even to profit off it at a competitor. What I don&#x27;t think HC has is the right to act shocked when others use the software under the terms they were allowed to use it. reply JimDabell 4 hours agorootparentprevAllowing what you call “leeching” is a well-considered, purposeful choice on the part of the people who created these licenses. So yes, it should mean that, and if anybody doesn’t like it then they can use a different license. They shouldn’t use a license that is specifically designed for this purpose and then complain when it is used for that purpose. reply lijok 15 hours agorootparentprevCould you explain how and why Hashicorp \"get the maintenance burden\"?Surely, if maintaining it was such a burden, Hashicorp could just stop maintaining it? reply Pannoniae 12 hours agorootparentThere is a difference between maintaining something, and maintaining something for your competitors. The second one can reasonably be described as a burden IMO. reply ImPostingOnHN 6 hours agorootparentif your principles on FOSS change when someone uses your software in a way you don&#x27;t like, you never had any principles in the first place replyPannoniae 17 hours agoparentprevAlthough we are not there yet, but if we don&#x27;t do something to change it, there will be a moment where it will be true that \"no reasonable person releases anything under a permissive licence\", sadly.Just see the latest serde \"drama\", where everyone disregarded the \"no warranty\" clause in the licence and loudly demanded changes&#x2F;wanted to fork the project&#x2F;etc.FOSS has a huge problem of expectations from both upstream and downstream. There are very common arguments about \"I use this, you broke it&#x2F;made changes I didn&#x27;t like, so you are a horrible maintainer and person and you will have zero credibility forever\". If anyone uses FOSS dependencies, they also accept the risk of future versions being different. No one breaks versions already released, this is always about future versions. Demanding the maintainers to make specific changes&#x2F;not to make them for your usecase is extremely entitled. reply JimDabell 16 hours agoparentprevThe whole point of permissive licenses is to permit this kind of thing. It sounds like you think every company out there choosing permissive licenses doesn’t actually want to be permissive. Has it not occurred to you that people choosing permissive licenses usually want to be permissive? reply paxys 15 hours agoparentprevThat&#x27;s a good thing. Either launch a closed proprietary product from the get go or commit to maintaining a real open source project. You can&#x27;t have all the monetary advantages of the first while enjoying the goodwill and community support of the second. reply sanderjd 14 hours agorootparentThis attitude will just lead to pretty much every product being closed and proprietary. Which sucks for me, because I like to be able to read the source and run modified versions of tools I use, and have no interest in creating competitive derivations of them. So I think it&#x27;s a shame that people who try to make software like that get pilloried for being neither proprietary enough (which is apparently fine...) nor open enough. reply managingahhs 13 hours agoparentprevI assume that by reasonable you mean not one that will bait and switch their userbase.I&#x27;m all for proprietary companies not pretending to be opensource companies and actually using proprietary licenses. reply erinnh 17 hours agoparentprevWould a non-permissible open source license somehow changed this?Not sure what you mean. reply razbensimon 18 hours agoprevGreat work everybody! Env0 developer here reply dzogchen 17 hours agoprev [–] https:&#x2F;&#x2F;www.isopentfopenyet.dev&#x2F; is out of date! You had one job! reply Philpax 14 hours agoparent [–] ...why does a presumably static page need to store cookies? reply intelVISA 8 hours agorootparent [–] ;-) replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The opentf repository on GitHub is a developing project gearing up for its first alpha release. OpenTF is an open-source tool used for infrastructure management, utilizing high-level configuration syntax.",
      "OpenTF comes with several features like infrastructure as code, execution plans, a resource graph & automated changes. The repository also contains OpenTF Core, the command line interface, and the principle graph engine.",
      "OpenTF repository includes a guide for contributors detailing how to compile OpenTF as well as how to submit bug reports or enhancement requests. The repository is licensed under Mozilla Public License v2.0."
    ],
    "commentSummary": [
      "The OpenTF repository has been publicly launched on GitHub, inciting conversations about the employment of binary search and PRs (Pull Requests) to detect and rectify coding issues, worries about the merging process, and potential licensing problems in the Terraform fork.",
      "There have been discussions about likely trademark issues that may cause confusion with other products within the OpenTF project, and the frustration caused by licensing changes in Terraform.",
      "Various opinions have been voiced on the licensing decisions made by HashiCorp, focusing on the expectations of users and competitors, and there's palpable concern about the future of open-source projects and possible dissuasion for businesses."
    ],
    "points": 470,
    "commentCount": 155,
    "retryCount": 0,
    "time": 1693926030
  },
  {
    "id": 37394665,
    "title": "Rockstar is selling cracked game copies on Steam",
    "originLink": "https://twitter.com/__silent_/status/1698345924840296801",
    "originBody": "OH FOR CHRIST&#39;S SAKE https://t.co/y9jLN61VOf pic.twitter.com/vx8yDcz1B3— Silent (@__silent_) September 3, 2023",
    "commentLink": "https://news.ycombinator.com/item?id=37394665",
    "commentBody": "Rockstar is selling cracked game copies on SteamHacker NewspastloginRockstar is selling cracked game copies on Steam (twitter.com/__silent_) 442 points by robbiet480 17 hours ago| hidepastfavorite210 comments CobrastanJorji 14 hours agoMany years ago, I worked on a product that provided a bunch of old emulated games. We properly licensed them, but many of the license holders no longer had the original ROMs, ripping the game data off of some of the really old consoles was quite difficult, and the only ROMs available publicly were cracked copies with demo&#x27;s added. That was the birth of the demoscene, which was awesome, but bad for us trying to legitimately provide these games. So we ended up cheating. We used the cracked versions of these games, but we always loaded the games from a state just past when the demo would play, making them look normal and legit. Thank God all those early cracks put their demos only at the start and not, like, between levels 1 and 2, or we&#x27;d&#x27;ve been screwed. reply Bluecobra 12 hours agoparentIt would be kind of sad&#x2F;funny if one of the games had a bad crack and the game itself was broken and not caught by QA. For example, Earthbound has one final check that would cause the game to freeze and delete your save at the final boss. reply atherton33 11 hours agorootparentThere was an example of this reposted here just last week: https:&#x2F;&#x2F;www.benshoof.org&#x2F;blog&#x2F;case-crackedThe crack for The Colonel&#x27;s Bequest worked by hardcoding the RNG in the interpreter to always return the same number. This broke every random element of the game, which is undetectable on a single playthrough. reply Darmody 12 hours agorootparentprevTo me it happened the other way around.The original game from Steam won&#x27;t run on Linux but if I change the .exe for one that is cracked, it works.I&#x27;ve been keeping that .exe for years. reply avg_dev 12 hours agorootparentprevman that is absolutely brutal reply thaumasiotes 10 hours agorootparentprevThis is the case for many \"cracked\" DOS games. You can find archives that say \"we checked all the games to make sure they&#x27;re really cracked\", but I obtained a copy of Spaceward Ho! from such an archive, and the developers had pre-defeated this assurance measure by not invoking the copy protection until several turns into the game. reply ndiddy 10 hours agoparentprevWas it Gametap? reply Reubend 16 hours agoprevCould we get some more context than this tweet (which doesn&#x27;t really explain what&#x27;s going on)? reply robbiet480 16 hours agoparentThe game shown here, Midnight Club II, required the CD to be in the drive to play it. With the advent of Steam and companies releasing older games on Steam, they needed a way to bypass that check. Bypassing a CD (commonly called No-CD) was a very common crack&#x2F;DRM bypass back in the day. Rockstar didn&#x27;t want to bring up old source code and find someone who understood it enough to remove the check, so instead they just installed a No-CD crack into the existing EXE and uploaded the thing to Steam. reply rpdillon 12 hours agorootparentThis is a great example of how today&#x27;s \"piracy\" is tomorrow&#x27;s \"only working copy left\". I wish there were a more formal way to explicitly allow this, though I&#x27;m probably just pining for shorter copyright terms. This game was released 20 years ago, longer than the original U.S. copyright term of 14 years. reply chrisco255 11 hours agorootparentDisney lawyers, meanwhile, are looking to extend copyright to 50 years beyond the life of the author&#x27;s 3rd generation descendant or the heat death of the universe, whichever comes last. reply darth_avocado 10 hours agorootparentThe way things are going, the death of Disney may come quicker. reply warent 9 hours agorootparentprev\"whichever comes last\" got me haha reply baobabKoodaa 16 hours agorootparentprevSounds like Razor could sue Rockstar for copyright infringement. That would be hilarious. reply enos_feedler 12 hours agorootparentFormer cracker for rzr here :) did not do this game unfortunately. reply apgwoz 11 hours agorootparentOh, you \"didn&#x27;t\" do this game, wink wink, nudge nudge. ;) reply pizzafeelsright 10 hours agorootparentprevQuestion for you from the 17 year old me.Why did you do this? Fame? Money? Challenge?I didn&#x27;t know enough to so it myself and no one would teach me. reply blagie 10 hours agorootparentHaving done similar (not identical) things at that age, a lot of it is quite literally for the LOLs, and more than a bit is for community identity.Fame: Non-existent, since you don&#x27;t tell people.Money: Non-existent, you don&#x27;t get paid.In retrospect, I think a major drivers for teenagers for a lot of activities is a sense of identity. You feel like one of the role models in [name your favorite hacker movie]. It&#x27;s the same reason why punks wore spikes and mohawks, goths wore black, and people might pick a genre of music (even if privately). I&#x27;d guess a lot of more negative things, like vandalism, are similar too.You become part of a community too.And ultimately, you contribute to it. As much as it might be illegal, cracking software helps other kids who can&#x27;t afford that software. Few real engineers will use a hacked copy of AutoCAD, and literally everyone I know began to pay for music once they could afford it. On the other end of the bell curve are kids who can&#x27;t afford those. Providing them with access is a community service. And it&#x27;s going up against The Man. It&#x27;s illegal, but by the code of ethics we followed at the time, it was very ethical. reply Agingcoder 3 hours agorootparentprevIt’s a great way to learn - so challenge. There’s neither fame nor money here I think.At least in the 90s there were lots of tutorials to learn how to crack&#x2F;reverse engineer, from +orc’s documentation to fravia ´s fortress of reverse engineering - I’d expect similar tutorials to still be around.Reverse engineering also happens to be a very useful skill as a regular software engineer ( debugging compiler bugs, figuring out why software X is behaving strangely and what it is doing etc ). reply rmilk 1 hour agorootparentExactly true. Was a teenage software hacker, reverse engineered many games mostly because I was a bored teenager with free time and many games I legitimately bought. Mostly it was to cheat a little, like tweaking player stats or number of lives in a save file.All that reverse engineering experience gave me a particularly useful talent as a developer: an uncanny ability to sit down and grok other people’s code almost like magic.Solid experience with reverse engineering really is a good skill to have. reply wink 4 minutes agorootparentDepends on when the people did this and how complex the mechanism were at the time. I do remember just learning about JMP in assembler and that you could bypass a lot of stuff by changing a true to false or vice versa. Not exactly rocket science. (Not saying this to downplay anything, but what seems magical to many non-techies was actually very easy to do if you knew the trick, and it already worked for like 30% of the games - I&#x27;m not talking about the real stuff later on, not even sure how complicated NoCD was.)On the other hand, probably 15-20 years after I had last used a crack for a game I had to implement some basic protection like this into a piece of software (more like: make sure the customer will not run this demo version forever) and it was fun to discuss in the team what we all remembered from back then and which measures were adequate to implement. joshmn 8 hours agorootparentprevI&#x27;ve done something similar in recent past on a large scale:I did it because it was interesting, I wanted to prove DRM is a flawed concept and broken construct, and because the community which I built (as a result) was really great and a home to me when I didn&#x27;t ever experience one.It was never about money or fame, it was about providing something to people that had a value. People said the \"thing\" I provided was better than the \"real thing\", and that gave me a sense of pride: I&#x27;d never get hired by the company that made \"real thing\" to make their \"thing\" better because I didn&#x27;t have the credentials on paper.But at least my \"thing\" was better. reply effingwewt 12 hours agorootparentprevThank you for your service o7 reply jiofj 15 hours agorootparentprevThey could. They would lose, though reply wongarsu 15 hours agorootparentA No-CD crack might not be transformative enough to warrant copyright protection as derivative work in the US. But they could sue in a jurisdiction that is more likely to give them a favorable outcome. Handling of derivative works and the minimum threshold for copyright varies considerably between countries. reply itiro 13 hours agorootparentMost DRM crackers aren’t in it for money but to prove DRM is a flawed and ridiculous concept.That was my scene back in the day when there was less risk of the Feds kicking in the door. At least back then most of us saw it as a learning experience. reply Guvante 15 hours agorootparentprevLikely Rockstar would counter sue for violating their original Copyright and the terms of use attached to them.At best it would be a wash, there is a decent chance the damages for the countersuit would lead to a net loss. reply ArnoVW 14 hours agorootparentThe can sue them for anti-circumvention statutes in the DMCA. But not for infringement, since the developers did not do the infringement, they only enabled it. reply favorited 8 hours agorootparentHow did the cracked game enter circulation, if the crackers didn&#x27;t redistribute it? reply methou 5 hours agorootparentIn this very specific case, it&#x27;s a no-cd patch, you can be a legitimate owner of the copy but for some very valid reasons that do not want load the CD every time you play the game. (Like disk and&#x2F;drive wearing, or just don&#x27;t like the hassle) reply therein 11 hours agorootparentprevAfter some short searching online, looks like for copyright infringement litigation, the statute of limitation is three years. reply freejazz 14 hours agorootparentprevI don&#x27;t think people on HN understand what a derivative work is, considering how often I see it referenced incorrectly. You can&#x27;t make a derivative work without a license. That&#x27;s why it&#x27;s derivative. It derivates from the copyrighted work and is therefore within the domain of the copyright and under the control of the copyright&#x27;s owner.A Harry Potter spin-off about Hermione (I don&#x27;t know anything about HP, sorry in advanced) is a derivative of the original Harry Potter work. As I&#x27;m sure you are well aware, you cannot sell copies of your Hermione spin-off, because that&#x27;d be copyright infringement, because it is a derivative work. reply dragonwriter 14 hours agorootparent> I don&#x27;t think people on HN understand what a derivative work is, considering how often I see it referenced incorrectly.Very true.> You can&#x27;t make a derivative work without a license. TYou can, but it is a copyright violation to do so unless an exception (like Fair Use) applies.A derivative work is also a work eligible for copyright in its own right, and as such is copyright by the creator by operation of law when fixed in a tangible form, whether or not it also violates someone else’s copyright.> It derivates“derives”> from the copyrighted work and is therefore within the domain of the copyright and under the control of the copyright&#x27;s owner.No, producing it is within the legally exclusive rights of the copyright holder subject to the limitations on those rights, but once created the copyright in the derivative is not under the control of the copyright holder of the original (though transferring or licensing back may be part of the resolution of copyright violation lawsuit over its creation.) reply antiterra 8 hours agorootparentI thought Pickett v Prince established precedent that you can’t copyright an unauthorized derivative work.See 17 U.S.C. §103(a), which says that derivative works can be copyrighted, but that does not extend to any part of the work in which such material has been used unlawfully.(not a lawyer but I did audit this class at a law school) reply victorbjorklund 13 hours agorootparentprevI&#x27;m not sure about american law but in EU (at least Sweden) you def get copyright to detivative work even if you don&#x27;t have a license. If I create a derivative work based on Harry Potter the result will be that I have copyright to the derivative work BUT not to Harry Potter (I wish) so while I own the rights to my work I can&#x27;t produce (etc) the work (at least not in a commerical capacity) because JK rowling owns the Harry Potter rights. However JK does not have the right to use my derivative work without a license from me.A maybe more clear example is music. Songwriting is covered by copywrite. Singing is also covered by copywrite. If A writes a song and B sings the song without A:s premission it can be copyright infringment. However, A can not take a recording of B:s song and copy and sell it without B:s consent because B has the copyright to the performance (even if the performance was a copywright infringment). reply bri3d 14 hours agorootparentprevIf the patch is distributed on its own, without the original binary, is it still a derivative work? Is the unique, creative work of writing \"perform XYZ instruction at XYZ address,\" in lieu of the original executable, still derivative?This is actually an unanswered&#x2F;unproven question that comes up quite a bit in automotive tuning, where individuals and tuning companies modify OEM calibrations and create application software patches which, while they are unique and perform stand-alone functions, run on top of OEM ECU software. reply EvanAnderson 13 hours agorootparentThe history of General Computer Corporation&#x27;s[0] arcade enhancement boards is an interesting example of this kind of \"derivative\" work.GCC made an enhancement board for Missile Command and later for Pac Man (\"Crazy Otto\", which became \"Ms. Pac Man\"). Rather than employing simple \"ROM hacks\" as other enhancement board manufacturers did, GCC specifically built their enhancement hardware not to contain any code copied from the original game ROM. Their hardware patched the existing ROM only by overlaying their code onto the original ROMs, not by copying any of the original code[1].There&#x27;s some neat detail in the background slides here[2]. I&#x27;d love to hear that talk but I&#x27;m not immediately a recording of it.[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;General_Computer_Corporation[1] https:&#x2F;&#x2F;web.stanford.edu&#x2F;class&#x2F;sts145&#x2F;Notes&#x2F;3_game_business&#x2F;...[2] https:&#x2F;&#x2F;trilobyte.com&#x2F;pdf&#x2F;golson_ReplayFX_2015.pdf reply lmm 9 hours agorootparentprev> If the patch is distributed on its own, without the original binary, is it still a derivative work?Yes, just as annotations are recognised as being a derivative work even without the original.> Is the unique, creative work of writing \"perform XYZ instruction at XYZ address,\" in lieu of the original executable, still derivative?If you can convince a judge that, on the balance of probabilities, you were divinely inspired to write it with no connection to the original executable, then it&#x27;s not derivative. But good luck with that. reply bombcar 10 hours agorootparentprevYou can skirt incredibly close, however - search Amazon for “unofficial Harry Potter”. reply CapstanRoller 14 hours agorootparentprev>you cannot sell copies of your Hermione spin-off, because that&#x27;d be copyright infringement, because it is a derivative workBut you can distribute it for free, as fanfiction.Also, a no-CD crack does not contain any of the original work. It&#x27;s akin to a program that you can use to modify, say, your legally-purchased Harry Potter ebook in order to change all instances of \"wand\" to \"wang\" reply bragr 13 hours agorootparentFan fiction is illegal, or at best in a deeply gray area, it&#x27;s just that most people realize suing your super-fans is a bad move. There are exceptions of course, Anne Rice was famously super litigious over any attempted fan fiction of her characters which generated a lot of bad feelings online.https:&#x2F;&#x2F;www.vice.com&#x2F;en&#x2F;article&#x2F;88gqjz&#x2F;anne-rice-really-hate... reply PrimeMcFly 12 hours agorootparentParamount suing Star Trek fan productions is another great example. They recently took down the Wolf 359 audio book project for example. reply lmm 9 hours agorootparentprev> But you can distribute it for free, as fanfiction.Not legally.> Also, a no-CD crack does not contain any of the original work. It&#x27;s akin to a program that you can use to modify, say, your legally-purchased Harry Potter ebook in order to change all instances of \"wand\" to \"wang\"Doesn&#x27;t matter, it&#x27;s still a derivative work, just as a translation or annotation that doesn&#x27;t contain any of the original text is a derivative work. reply bogwog 15 hours agorootparentprevBecause Rockstar is a huge company, or because the dev wouldn’t have a case? reply 3abiton 10 hours agorootparentprevI wonder if No-CD was released under a specific open-source license, that would be hilarious reply parineum 15 hours agorootparentprevWhat&#x27;s the copyrighted work here? reply baobabKoodaa 14 hours agorootparentBoth the original game and the no-cd crack are copyrighted works. reply parineum 10 hours agorootparentWho owns the no-cd copyright? reply baobabKoodaa 10 hours agorootparentWell, obviously the people who wrote it. They don&#x27;t own the game, which they didn&#x27;t make, but they own rights to the cracking code, which they did make. replyjonny_eh 16 hours agorootparentprevRazor1911 was the cracking group in this particular case. reply OnlyMortal 16 hours agorootparentHeh. I recall their demos on the Amiga. reply tpmx 15 hours agorootparentProbably Norway&#x27;s most long-lived and industrious software export success. Founded in 1985. reply readyplayernull 14 hours agorootparentSomehow I expected them to be founded since 1911, cracking those Analytical Engines. reply nikanj 13 hours agorootparentIt’s 0x777, making fun of all the l33+ 666 groups reply OnlyMortal 13 hours agorootparent666. My favourite error code to return when there’s a “wtf” error. replygintoddic 16 hours agorootparentprevunderstated context here reply bonestamp2 16 hours agorootparentprevThat&#x27;s hilarious. I wonder what the license model is for the crack that they used. reply muttled 15 hours agorootparentIf there&#x27;s not a name for it yet, can we call it \"All&#x27;s Fair in Love and Warez?\" reply mcronce 15 hours agorootparentAlso known as the AFLW 1.0 License! reply rootw0rm 14 hours agorootparentprevit&#x27;s the \"all rights reversed\" license reply yomlica8 15 hours agorootparentprevAre we sure they didn&#x27;t just lose the source code entirely? reply rightbyte 15 hours agorootparentProbably unbuildable anyways without a lot of effort if you can&#x27;t recreate the workstation that was building it. reply fragmede 13 hours agorootparentThese days you&#x27;d save a VM image, but if we all move off x86, what good will that do? reply michaelt 10 hours agorootparentThese days you&#x27;d save a VM image, in case you need to rebuild the code in 20 years.Then in 20 years you boot up the image and find you can&#x27;t log in because your cloud Windows account was deleted 10 years ago for inactivity, your build toolchain is too outdated to download artefacts, the vendor of your text-padding library deleted it in a fit of pique, your code-signing certificates have expired, the guy whose cell phone is on the corporate account 2FA left the company 15 years ago, the OS vendor won&#x27;t allow new releases to use those obsolete, deprecated APIs..... reply Moomoomoo309 12 hours agorootparentprevQEMU can run VMs that are a different architecture than the host. There&#x27;s obviously a performance penalty to doing that, but it can be done. reply jamesfinlayson 6 hours agorootparentprevYou&#x27;d hope not, but it could be backed on something like a tape drive: too much effort to retrieve and then access. reply ewzimm 15 hours agorootparentprevDid anyone at Rockstar ever confirm that it was an official decision?I wonder if they did assign someone all that and they took a shortcut. reply kolanos 16 hours agorootparentprevDid Rockstart have to license Razor1911&#x27;s cracking software?It would be ironic if Rockstar was in violation of Razor1911&#x27;s copyright. reply nottorp 1 hour agoparentprevI think that if you had a twitter account you could click on something and see more context.Linking twitter has become worse than your average paywalled site, which you can look up on archive.something if it seems interesting. reply PrimeMcFly 16 hours agoparentprevI didn&#x27;t feel old today until I jumped on HN and saw someone who didn&#x27;t know what &#x27;cracked&#x27; means in the context of PC games. reply IshKebab 13 hours agorootparentHe knows what cracked means. I think you misunderstood. reply PrimeMcFly 13 hours agorootparentNot much room to misunderstand, and if he knows what cracked means what&#x27;s going on should be obvious. reply paint 13 hours agorootparentThis seems like a weird hill to die on? yes it&#x27;s obvious that rockstar (apparently) uploaded a cracked version of their game to steam. It&#x27;s not obvious why they chose to do that (ie \"what is going on\") reply PrimeMcFly 12 hours agorootparentI&#x27;m not dying on any hill, I think that&#x27;s a weird comment to make, let alone to make an issue out of my original comment at all.The way the comment was phrased read as though they didn&#x27;t understand what had happened, not that they didn&#x27;t understand why. Especially since no one has an answer to that, so no one can offer an explanation. reply lolinder 9 hours agorootparentprevI know what cracked means, but this didn&#x27;t communicate anything to me. It seems that you&#x27;d need to both know what cracked means and know who \"RAZOR 1911\" is in order to get what&#x27;s going on here from context alone. reply barbs 11 hours agorootparentprevNot necessarily. You could understand that a cracked PC game means its copy-protection has been removed by someone illegally but not have a detailed enough understanding of the process to understand the tweet. Personally I&#x27;m not familiar with Razor1911 so I wouldn&#x27;t have understood the significance of that string in the hexdump if it weren&#x27;t for the context provided by other comments here. reply magic_hamster 6 hours agorootparentprevConsidering the rapid change in HN audience I suspect this person is simply uninformed. reply demarq 16 hours agoparentprevCracking was a 90s term for pirating software reply phpisthebest 16 hours agorootparentpirating software (movies, and music) is a term from the 90&#x27;s by the MPAA, Riaa, and Games industry in attempting to link the act of simple copyright infringement, a civil non-criminal violation of the law to violent robbery on the high seas...Cracking is a method of removing undesired features or inclusions from software, often licensing controls, or other anti-consumer features.Many many many people \"cracked\" their software who where not eganged in the act of copyright infringement, they legally owned the software but for a number of reasons has no desire to run the invasive software bundled with the game or content they purchased. reply timmb 16 hours agorootparentThat was the scariest term they could come up with? The romantic swashbuckling seafarer, antagonising empires and declaring his own rules? Surely they could have done better.&#x27;software fraud&#x27;, &#x27;software theft&#x27;, &#x27;forgery&#x27;... hmm well there&#x27;s a reason I don&#x27;t work in marketing obviously. reply mrguyorama 14 hours agorootparentThey did those as well, and they also paid for extensive marketing material to make it seem like buying a cracked game was directly contributing to a mafia that was planning on killing your granny.Do you not remember the ads? The \"you wouldn&#x27;t steal a car\"?Piracy is just what they were able to get. Should have hired the bank&#x27;s PR managers, who turned \"failing to do due diligence on a customer&#x27;s identity\" into the customer&#x27;s problem. reply SOLAR_FIELDS 10 hours agorootparentWasn’t it “You wouldn’t download a car”?Which ended up being quite funny, because I very much would download a car reply dron57 9 hours agorootparentIt was \"you wouldn&#x27;t steal a car\". People on the internet rightly corrected it to \"download\". reply mjg59 13 hours agorootparentprevThe use of \"piracy\" to describe unauthorised publication of a copyrighted work dates back to the 18th century, it&#x27;s not something the MPAA came up with. reply lolinder 9 hours agorootparentYou&#x27;re right! Etymonline traces it back to 1706 (without a source) [0], and I found it in the original Webster&#x27;s [1]:> A bookseller that seizes the copies or writings of other men without permission.> PI&#x27;RATE, verb transitive To take by theft or without right or permission, as books or writings.EDIT: I just got out my OED, and sure enough:> 1668 J. Hancock Brooks String of Pearls (Notice at end), Some dishonest Booksellers, called Land-Pirats, who make it their practice to steal Impressions of other mens Copies... [0] https:&#x2F;&#x2F;www.etymonline.com&#x2F;word&#x2F;pirate#etymonline_v_16375[1] https:&#x2F;&#x2F;webstersdictionary1828.com&#x2F;Dictionary&#x2F;Pirate reply justapassenger 15 hours agorootparentprev> Many many many people \"cracked\" their software who where not eganged in the act of copyright infringement, they legally owned the software but for a number of reasons has no desire to run the invasive software bundled with the game or content they purchased.Yes, many people. But not “many many many” people. You try to make it sound like cracking to pirate was minority use case.It was a valid use case, sure, but as big as using torrents to download Linux ISOs. reply PeterisP 14 hours agorootparentI seem to recall that for some games the community recommended fix for performance problems was to install a crack so that the game wouldn&#x27;t try to read stuff from the CD, which might be slow depending on the drive you have, and would be very slow if the CD has some scratch so the drive repeatedly attempted to read the same spot until it succeeded. reply justapassenger 13 hours agorootparentSure, and I don&#x27;t question that. But at the same time - 99% of people outside of western countries had pirated copies of games (because it was legal in many countries, plus paying normal price was often month+ salary for a single game). Tons of teenagers from western countries (main gamers back in the days) had pirated games, unless they came from a rich family.Cracks helped to fix some serious usability issues (as DRM removal nowadays also helps with), but let&#x27;s not rewrite history to pretend that was what majority of people used them for. reply mattw2121 15 hours agorootparentprevThe term \"pirate\" definitely predates the 90&#x27;s and RIAA, etc. We used it quite liberally in the 80&#x27;s BBS era. reply dylan604 16 hours agorootparentprevmy favorite use was for software that required a USB dongle. if you lost the dongle, you lost access to the software. there is not \"back up\" option. so the cracking community came up with a way to emulate those dongles. the obvious abuse followed. we used the software for legit 1:1 installs to physical dongle on blade servers where all of the dongles could not be installed reply extraduder_ire 15 hours agorootparentMy favourite failure case of this is dongles on hardware devices, like lighting controllers. Especially when the dongle does in on an exposed edge of the device and can get knocked loose.I&#x27;ve heard stories of them getting disconnected because they were bumped, and the whole unit goes dead five minutes later. At least it&#x27;s not immediate. reply Stibinator 6 hours agorootparentprevI nursed my Lightwave dongle through my early career as an animator. I&#x27;ve lost so many pairs of glasses, several wallets, a couple of phones, but I know exactly which drawer that usb stick is sitting in now. Not that I reckon I&#x27;ll ever touch LW again. reply Bluecobra 12 hours agorootparentprevAnother alternative to cracking was to use something like DAEMON Tools to emulate the CD in the drive with an .iso so you could legitimately play multiplayer games without having to deal with stupid CD checks. reply TigeriusKirk 15 hours agorootparentprevhttps:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;byte-magazine-1981-05 reply itsnotlupus 16 hours agorootparentprevCracking is about removing anti-features, typically copy protections. It pairs well with pirating, but neither one strictly requires the other. reply nonethewiser 13 hours agorootparent> Cracking is about removing anti-featuresAnti what features? Piracy? reply function_seven 13 hours agorootparentAnti-backup, Anti-I-don&#x27;t-have-a-cdrom-on-this-machine, Anti-I-lost-the-stupid-dongle, etc.Like parent says, cracking and piracy pair well, but I&#x27;ve had to do it many times just for compatibility reasons, on software I had purchased. reply xxs 12 hours agorootparentThe anti-what-word-is-on-the-17th-page-3rd-paragraph-of-the-handbook was a very common on for so many games. reply Dylan16807 13 hours agorootparentprevAnd just anti-convenience! Nobody wants to swap CDs purely to tick a checkbox. replyechelon_musk 16 hours agoprevThis is more common than you might expect.The Windows port of Marc Ecko&#x27;s Getting Up: Contents under Pressure being sold on Steam is the DEViANCE crack.Open the game&#x27;s exe in a hex editor and you can plainly see \"DEViANCE\". reply RajT88 15 hours agoparentSystem sounds *.wav files were also produced with cracked software at some point (no clue if this is still in Win10):https:&#x2F;&#x2F;www.techrepublic.com&#x2F;forums&#x2F;discussions&#x2F;windows-uses... reply lelandfe 11 hours agorootparentI&#x27;m impressed both that you had a nearly 20 year old link ready, and that this URL still works. reply monocasa 13 hours agoparentprevI seem to remember hearing that wrt roms on at least one of the NES|SNES|PS1 Classic systems. reply barbs 12 hours agorootparentYeah same, although I think it was the ROMs distributed in the Wii Shopping Channel? reply jstarfish 16 hours agoprev> This explains the myth of the retail MC2 crashing on Vista - the game is most likely innocent, as the demo works great out of the box. IT WAS AGAIN THE CRACK breaking it.Myth? Innocent? That game was totally unplayable when it first came out (for 98&#x2F;ME?) so I doubt Razor made anything worse. I&#x27;d get most of the way through any race before the game randomly crashed.It would be funnier if it weren&#x27;t so absurd, since I&#x27;d have to go through finding the opponent in the world, chasing them to the starting line and doing the race itself each time. reply dalore 15 hours agoparentHe commented on that comment, it wasn&#x27;t the crack.> This gets better - Razor&#x27;s crack is fine, the reason both Midnight Club 2 and Manhunt crashed when these cracks were in use was the fact that Steam DRM included a .bind section that was code not marked as code - thus tripping Data Execution Prevention reply madars 16 hours agoparentprevThere&#x27;s probably an even stronger claim. It is not that Razor is not making things worse, rather a release from a reputable group is a strong indication that it works and that it will continue to do so many years in the future after activation servers are long gone&#x2F;DRM methods are deprecated&#x2F;etc. Quality and reliability is probably the reason why Microsoft used DeepzOne&#x27;s Sound Forge [1] and Turner Classic Movies used subtitles from Karagarga [2] :-)[1] https:&#x2F;&#x2F;boingboing.net&#x2F;2006&#x2F;07&#x2F;19&#x2F;windows-xp-sounds-cr.html [2] https:&#x2F;&#x2F;torrentfreak.com&#x2F;turner-classic-movies-airs-a-film-w... reply tj-teej 14 hours agoprevRelated story, I remember years ago as a kid I bought a Prince of Persia PC game at a yardsale (on a CD), but early on in the game there was a riddle where you needed a password to get through this door, it was some cryptic message of a few numbers.I don&#x27;t remember the exact format but it turned out the riddle was instructing me to go to page X, line Y and character Z of the manual for the game!I remember being so sad that I couldn&#x27;t play anymore because I didn&#x27;t have the manual but in retrospect I wonder if this was an anti-piracy strategy reply bri3d 14 hours agoparentYes, this was a common copy protection in old games!There&#x27;s a big list on mobygames here: https:&#x2F;&#x2F;www.mobygames.com&#x2F;group&#x2F;9360&#x2F;games-with-manual-looku... reply AdmiralAsshat 14 hours agoparentprevIt was common as well to use these things called Code Wheels:https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;code-wheelshttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Code_wheel reply pimlottc 11 hours agorootparent> https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;code-wheelsOh dang, these are fun, I remember the classic Monkey Island \"Dial-A-Pirate\" wheel [3]FYI you can use these without downloading the whole collection:- Under Download Options, click \"SHOW ALL\" to see the list of files [1]- Find the zip file for the game you want and click \"View Contents\" [2]- Click the \"HTM\" file listed [3]Kudos to the kind soul who took the extra effort to package them as single-file self-contained html docs!1: https:&#x2F;&#x2F;archive.org&#x2F;download&#x2F;code-wheels2: https:&#x2F;&#x2F;ia904503.us.archive.org&#x2F;view_archive.php?archive=&#x2F;22...3: https:&#x2F;&#x2F;ia904503.us.archive.org&#x2F;view_archive.php?archive=&#x2F;22... reply AbraKdabra 13 hours agoparentprevGTA IV has something similar, if you play a cracked copy eventually the camera starts to wobble and it makes it impossible to play, and it makes it look like a bug. I remember thousands of players asking in the forums why their camera was shaking without knowing they&#x27;re telling everyone they had a pirated game. Hilarious move from Rockstar.For those wondering, yes it happened to me, it was absolutely infuriating like \"man this fucking game is full of bugs\", lol. reply jamaicahest 2 hours agorootparentThe original Settlers 1 game, released in 1993, had ingenious copy protection built in. It had multiple levels of copy protection, that would activate, if the copy protection was attempted circumvented, i.e. cracked. It would not let you complete levels due to some characters missing&#x2F;never appearing and the likes, if you used a cracked version of the game. Much like you describe with GTA IV, users thought this was a buggy game, while in reality it was a buggy crack. reply rsstack 14 hours agoparentprevSim Earth had the same thing! It would ask you a question like \"How many moons does Saturn have?\" and the manual had some fact sheets at the end with all the numbers. Wikipedia was not around yet, and their fact sheets having slightly different numbers than encyclopedias due to different sources and publish date (moon counts change often, and measurements in meters for anything astronomical have randomness due to imprecisions). reply milesvp 14 hours agoparentprevI remember when I was young getting a game from my older sister&#x27;s college boyfriend. Gave me the game on disks, and also a photocopied manual just for this same purpose. Used to be super common for games to use these kinds of checks for anti piracy. I thought it was super funny though, because the game was pretty old, and I was confused why this guy didn&#x27;t know how to find a cracked version of the game to avoid having to pull out a 60 page manual just to play. reply szatkus 12 hours agoparentprevThis was even more confusing for me, because the versions of those games I played were usually already cracked and accepted any input. So I was wondering what&#x27;s the point. reply spelunker 13 hours agoparentprevI remember doing this for the original X-COM: UFO Defense. Actually I wonder how the Steam versions of these games work? Do they just include a PDF of the original manual? reply xxs 12 hours agoparentprev>I wonder if this was an anti-piracy strategyTotally, and exceptionally common. It was popular in the &#x27;80 and the early &#x27;90. reply ghusbands 15 hours agoprevNote that, as mentioned later in the twitter thread, the executable in the screenshots (testapp.exe) is not used. It was briefly used like a decade ago but has since been replaced; they just haven&#x27;t removed it from the distribution, for some reason. reply Thaxll 16 hours agoprevThis is not new: https:&#x2F;&#x2F;torrentfreak.com&#x2F;ubisofts-no-cd-answer-to-drm-080718... reply 0xcde4c3db 15 hours agoparentI don&#x27;t have examples handy, but I&#x27;m pretty sure I recall something similar being done for some CD-ROM re-releases of games with floppy-based copy protection. reply ineedasername 16 hours agoprevIt&#x27;s actually kind of like a bizarro version of open source: someone or some group may be the initiator of a project but some of the community that grows around the project also contribute back to it, making it a symbiotic relationship. Just, in the bizarro version, there&#x27;s an even more complex ecosystem filled with people who get to play a game where they hunt down some of the members of this community and make angry faces at them and sometimes put them in jail. reply h2odragon 16 hours agoprevcould the NoCD crack author do a DMCA takedown on these games now? Would it even need to be the author issuing such a request? reply capableweb 16 hours agoparentYou need to either be or represent the copyright holder. I&#x27;m 99% sure most warez groups have no interest in exposing themselves to any legal systems when it comes to what they do. reply creatonez 4 hours agorootparentIn Russia, developers of a Minecraft crack called TLauncher have targeted other developers of other Russian Minecraft cracking projects with takedowns and trademark complaints. How did they do it? They registered a company in the Seychelles islands to protect their identity. And of course, they&#x27;re relying on the fact that the Russian government is uninterested in protecting the intellectual property of Mojang. reply h2odragon 16 hours agorootparentprevIf I say I represent such a group, then; is it likely that anyone will disagree? DMCA cases seem to be about who has the scarier looking letterhead anyway.To whom would I have to prove or disprove my standing to take Rockstar games down, I wonder? Does Steam have any right to refuse such a request just because it&#x27;s patently absurd? reply mrguyorama 14 hours agorootparent>DMCA cases seem to be about who has the scarier looking letterhead anyway.This is only true of Youtube, where their \"DMCA\" process is entirely extralegal, which is why there is no penalty for an incorrect takedown request.If you file a DMCA, and Valve ignores it, you have to take it to court, where a judge will decide whether you prove you are the rightful copyright holder. As in the case with google, a company is free to take down content for any reason, including for bogus DMCA claims. reply elil17 15 hours agorootparentprevImagine you did this and ended up in court. If you admit you lied on the DMCA request, you&#x27;d be admitting to perjury. If you continue to claim to be the cracker, Rockstar could sue you for damages from IP theft. reply qingcharles 15 hours agorootparentPerjury is only if you make a statement under oath knowing it to be a lie. The DMCA doesn&#x27;t require you by statute to tell the truth. As long as you tell the truth under oath on the witness stand, if it got that far, then you&#x27;d be fine from a criminal prosecution perspective.Of course, you&#x27;d probably get counter-sued for a number of civil torts for being a fuckhead. reply elil17 14 hours agorootparentWhat you said is not true. The text of the law specifically clarifies that a false DMCA takedown request is perjury. reply sillysaurusx 14 hours agorootparentprevIt does. Each DMCA requires “A statement that the information in the complaint is accurate, and, under penalty of perjury, that you are authorized to act on behalf of the copyright owner.” reply PeterisP 14 hours agorootparentEspecially do note that you could lie on all the other parts of the complaint, such as the issue whether the violation actually occurred, but the one thing that&#x27;s under the penalty of perjury is whether you&#x27;re actually representing the copyright owner. reply baby_souffle 15 hours agorootparentprev> If I say I represent such a group, then; is it likely that anyone will disagree? DMCA cases seem to be about who has the scarier looking letterhead anyway.If you say you represent them, all the scary letter heads will go to _you_. reply dalore 15 hours agorootparentYou could say you wrote the source code for the cracker, but you did not distribute the pirated software, that was someone else. reply NoMoreNicksLeft 16 hours agorootparentprevYou need that in the sense that it would be a legitimate notice.No requirement such as that is part of the DMCA, and there is no penalty in statute for making illegitimate notices. reply Agingcoder 16 hours agoprevRazor 1911 ! I had completely forgotten about them. They cracked games in the 1990s, and if memory serves well, there was a nice ascii art logo that came with games.Apparently they’ve been active again since 2010, but in my ( much older ) mind, steam has made piracy mostly obsolete.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Razor_1911?wprov=sfti1 reply andrewmcwatters 15 hours agoparentI think the appeal of cracks is still there for the technically minded. Learning reverse engineering, understanding how to circumvent technologies.That seems to be the real point for these groups. Reputation from reverse engineering. I certainly enjoyed my time writing them. I don&#x27;t know of any group that does this and doesn&#x27;t support the developers of the IP in question. You still end up buying the software. reply abestic9 15 hours agoparentprevAs good as Steam might be, it’s still required for the games you purchased to run, and that doesn’t align with some people. You own your games on Steam as much as you own your music on Spotify. So priacy is still alive and well, and a lot of the arguments I see for it is stripping DRM and ownership.I prefer Steam over other platforms because multiplayer is effortless, with a friend or at a LAN party that means means more time actually playing the game. But if it’s not on Steam or not everyone can afford it, we’re probably playing a cracked, portable copy. reply jrflowers 13 hours agoprevOnce again Razor 1911 shows up as an important part of the software archival ecosystem. Good people. reply dusted 1 hour agoprevI think Razor should sue Rockstar for IP violation, Razor obviously owns the IP to unprotect the binary ;) reply sixthDot 16 hours agoprevModified or not, legally R.S. Games owns it anyway. reply mabbo 16 hours agoparentThey don&#x27;t own the no-CD crack. So technically, they are selling software they pirated. reply ohnoesjmr 16 hours agorootparentThey are not shipping the crack. They are shipping their own binary that has been modified by the crack. reply Ekaros 16 hours agorootparentThose modifications have a copy-right they do not own... reply jerf 14 hours agorootparentI&#x27;ve been waiting for ~23 years for the copyright system to grapple with the implications of 1. having a copyrighted work A 2. taking someone else&#x27;s \"patch\" (mod&#x2F;crack&#x2F;whatever, I call it \"patch\" as a general term) B and 3. combining them on your local computer to produce a final work C. We techies have been arguing about who has what rights, who can block who from doing what, who&#x27;s responsible for what, etc. in that situation for at least that long, when the mood strikes us. I&#x27;m still unaware of any really clear precedent on this and I&#x27;m pretty sure legislation remains utterly oblivious that such a thing is even possible, or how powerful it is. I&#x27;ve been on the lookout for even a hint of this for a long time and there&#x27;s hardly been anything.I guess the economics just haven&#x27;t worked out to produce a true showdown. Game mods are in my opinion the clear favorite for where this would finally rise to a court-level problem, and clearly there&#x27;s been a lot of conflict in this space, but nobody yet has been foolhardy enough to build a large enough business on selling some mod that when the owner tries to shut them down they actually go to a full-on, precedent-setting legal battle. (After all, economically, when you get to that level of capability, why not make your own game that you clearly own? That path has been trod many times.)So, my best answer to your question is, honestly nobody really knows what kind of rights Razor may or may not have to the final product of their crack, especially since it is not the crack itself being distributed. reply PeterisP 14 hours agorootparentThe general principle of copyright law is that copying&#x2F;distributing work that combines multiple copyrightable parts requires the permission of every author&#x2F;copyright holder. Copyright law does not attempt to establish a single owner for any given work, it&#x27;s perfectly fine with multiple parties having copyright protections over a single work, in which case any of them has a practical veto to doing anything with the joint product, as permission to use 99% of the work isn&#x27;t sufficient.For a very common example, let&#x27;s look at a translated book. Copying and distributing such a book requires separate permission from both the author of the book and the author of the translation; the translation is a derivative work, it&#x27;s covered by the copyrights of the original book and the author, but the translator also holds independent copyright on the translation in addition to the author&#x27;s interest.IMHO a derivative work of a program patched with someoone else&#x27;s code (no matter how small, as long as it meets the very low copyright law bar of &#x27;the slightest touch of creative input&#x27;) is quite similar.But the specific case of Razor 1911 might be disqualified by US copyright law section 103a which says \"[...] but protection for a work employing preexisting material in which copyright subsists does not extend to any part of the work in which such material has been used unlawfully.\" reply TylerE 16 hours agorootparentprevA much better analogy would be how writing code in an open source editor, compiled by an open source tool chain does not make the resulting binary open source. reply Steltek 14 hours agorootparentprevA compiler author does not own the output of the compiler. reply alphablended 12 hours agorootparentNo, but any other source (eg. headers) used during the compilation process might be owned by a third party.A crack does not compile anything, but even if you go that road, it will be argued anyway that the patch which is applied is copyrighted.Now, of course, it&#x27;s another thing to prove that the patch may indeed be copyrighted... reply neurostimulant 13 hours agorootparentprevThey can copyright certain sequence of bits though, like console makers did a while ago to enforce licensing (e.g. can&#x27;t boot this rom without these sequence of bits, but this sequence of bits is actually a nintendo logo which cannot be distributed unless you have nintendo&#x27;s permission). reply lxgr 13 hours agorootparentprevIs that always the case, or does it depend on the compiler&#x27;s license in the end? reply thereisnospork 16 hours agorootparentprevThey are also (arguably) selling software written&#x2F;designed&#x2F;intended for the express purpose of bypassing copyright protections, which as I understand is in and of itself a no-no under the DMCA regardless of underlying ownership.I ANAL of course.edit: per the sibling comment the crack might not be included, so this might not apply. reply gamblor956 16 hours agorootparenta no-no under the DMCA regardless of underlying ownershipThe \"regardless\" part is wrong. It is permissible for the owner of the software to include software for the express purpose of bypassing the protections they themselves placed on their software. Why would you think that the software owner isn&#x27;t allowed to do that? reply NoMoreNicksLeft 16 hours agorootparentIt would be permissible, if the \"software for the express purpose of bypassing the protections they themselves placed on their software\" was their own software.It&#x27;s not permissible for them to make available other people&#x27;s \"software for the express purpose of bypassing the protections they themselves placed on their software\" without the express permission of those other people.Neither statute nor case law sets a lower limit on the size of software that is protected by copyright... but if there were a lower limit, then it is clearly down towards the hundreds (or even dozens) of bytes. The crack certainly doesn&#x27;t sit underneath that lower limit.It&#x27;d be like purloining just one source code file, including it in your commercial software and relying on the defense \"hey, it was only a few hundred lines long\". reply anakaine 14 hours agorootparentThere is the matter of enforcement, however. If something is completely unenforceable, such as in this case where the owner is using a pirate groups bypass, then it may as well be permissible. It&#x27;s not expressly permissible, but the perceived breach is also not enforceable, so the argument becomes a moot point.Also, the patches typically had no license terms attached to their usage, or if they did it came in the format of attribution. The implications here is debatable, but we again come back to enforcement to close out the otherwise circular argument. reply NoMoreNicksLeft 13 hours agorootparentI&#x27;m pretty sure that the lack of license terms doesn&#x27;t make it a free-for-all, instead it means that there is no possible licensed use at all.If you pick up a copy of Photoshop and can&#x27;t find the license for it, you don&#x27;t get to go down to the street corner and sell bootleg copies. That defense won&#x27;t hold when you&#x27;re in district court fighting to stay out of federal prison, anyway.And while it&#x27;s true that this will never be enforced, if there are no principles here, then there can be no guilt from illegally copying these games. reply monocasa 13 hours agorootparentPractically (since no prosecutor is going to take this up on their own), you&#x27;d need someone dumb enough to affirmatively say \"that&#x27;s my circumvention tool that&#x27;s illegal under the DMCA\" in order to show standing for a civil case.So even if there was a no commercial use license somehow, it feels kinda like jury nullification where it&#x27;s not explicitly legal, but de facto legal because of structure of the rest of the judicial system. reply gamblor956 14 hours agorootparentprevwithout the express permission of those other people.That is false. They simply have to use the other software, i.e., the crack, within the terms of its license.In this case, the crack was distributed widely with a permissive use license. My hazy memories of that era specifically mention giving them credit and nothing else. There was definitely no commercial use restriction. reply PrimeMcFly 16 hours agorootparentprevEven if the crack was included it wouldn&#x27;t apply. reply happytiger 2 hours agoprevIt’s nice to see gaming companies finally figuring out what users have known since the 90s. reply GuB-42 12 hours agoprevMaybe Rockstar has former, maybe even current members of Razor 1911 among their staff.I mean, the scene is not a reliable way to pay the bills. You need to find a \"real job\" at some point, and the skills you get by cracking software and making demos could find good use in the video game industry. reply bravetraveler 4 hours agoprevDoes this mean, then, that their integration to Steamworks or whatever client-ensuring integration... is missing?One could presumably then archive the directory and go DRM-free reply leshokunin 10 hours agoprevHonestly, it&#x27;s fair game. I don&#x27;t expect every studio to have the source code handy and someone who knows how to build and modify the game anymore. If the crack does the job, I can empathize.Inversely, it&#x27;s not like the crack was made just out of educational curiosity. At one point it might have hurt sales... now somehow it helps.Not like the group would have a moral high ground to claim their copyright was violated. Though the idea is fun. reply lofaszvanitt 8 hours agoprevUbisoft has done this too if I remember right. They stole the cracked exe, what could the haxors do, sue them? reply apples_oranges 13 hours agoprevThis reminds me of a (popular) iOS game that had a little bug. I reported it hoping for a quick fix and they replied that the developer was no longer available to fix it, but they can refund me the app price.. reply justsomehnguy 16 hours agoprevhttps:&#x2F;&#x2F;nitter.unixfox.eu&#x2F;__silent_&#x2F;status&#x2F;16983459248402968...Who could have thought what a company with billions of revenue would use the cracks from RAZOR1911 for IP they are selling to the end users?Shocking! reply NoMoreNicksLeft 16 hours agoparentAnyone a little savvy would have guessed that.I&#x27;m betting even at the time of the game&#x27;s release, it was so fragile that someone breathing wrong on the build machine would cause the build to fail. Any time the Windows machine displayed the numeral 1 in the systray, it would be unbuildable. And on Tuesdays, Wednesdays and Fridays it would just fail to compile. That there were only 3 employees who could get it to work at all the last 3 months of development... and they all quit years ago.Now? Now it won&#x27;t build on Windows 11, or even on the old XP machine they dug up. It&#x27;s so riddled with Denuvo or whatever, that they&#x27;d have to spin up a team of 12 for two months just to delete that, and only for them to discover it won&#x27;t build afterwards.And, whatever else, they sure as hell don&#x27;t have anyone who&#x27;s good enough at assembly and IDA Pro to crack themselves. Probably too cheap to even get the single seat license for IDA Pro. reply ezconnect 16 hours agoparentprevDoes RAZOR1911 have a legal way to have a share of revenue since they are using his hard work? reply threeio 16 hours agorootparentRazor1911 is a cracking group from the mid 80s on... but it would be fantastic wouldn&#x27;t it? :) reply monocasa 13 hours agorootparentAt least some did. CD Projekt Red got started as a cracking and translation group. At the time (Poland before the fall of the iron curtain) there wasn&#x27;t actually anything illegal about what they were doing; copyright wasn&#x27;t really a concept in their legal system at the time, particularly for software. reply Zetobal 16 hours agorootparentprevThey disbanded some years ago :*( reply PrimeMcFly 16 hours agorootparentprevThey are not entitled to anything. Rockstar can use their crack as much as they want. reply extraduder_ire 7 hours agoprevI take it from this that we&#x27;re not likely to see any of rockstar&#x27;s games showing up on gog.com any time soon. reply elvis70 16 hours agoprevDidn&#x27;t Microsoft published a Word document from a \"pirated\" Word release in the past? reply bluejay2387 13 hours agoprevKind of mind blowing to see a name (Razor1911) from my C64 days make an appearance again 0.o reply meesles 13 hours agoparentThey&#x27;ve been a consistent name in cracking since then! reply nxobject 12 hours agorootparentI wonder if they&#x27;re like the Bourbaki group in mathematics – an anonymous group where members elect other members, with a trivial amount of cloak-and-dagger secrecy from the public. reply tus666 11 hours agoprevWould be funny if the hacker sued rockstar for profiting off his work. reply lousken 11 hours agoprevWouldn&#x27;t it be just easier for everyone not to include DRM in the first place? Waste of money, vast majority of zoomers dont use cracks anyway.(I am talking with the context of current games using denuvo, not this specific case) reply StanislavPetrov 3 hours agoprevThe copy protection wars were a blast back in the day. A decent number of games had methods of copy protection that were more interesting than the games themselves. I still remember the Wizardy IV copy protection (Mordor Charge Card). The game came with a book of thousands and thousands numbers printed on very dark brown pages that were difficult, if not impossible, to legibly photocopy on the machines of the day. I still have the book, and it takes a very bright light and (in my old age) a magnifying glass to make out the numbers for the copy protection challenges (which only come after completing a somewhat challenging first level). reply shmerl 15 hours agoprevGood, they shouldn&#x27;t have been DRMed in the first place, then they won&#x27;t need to be cracked. reply Havoc 15 hours agoprevRazor should sue rockstar for IP theft. reply o0banky0o 15 hours agoprevrazor1911 never started owning it when they made the crack, so, fair. reply jdjdjdjdjduuuu 13 hours agoprevAt least its not DRM copies.... reply yieldcrv 15 hours agoprevFans did the work for them, likely illegally, and it remains within Rockstar’s right to use itanalogous to free work-for-hire reply pengaru 15 hours agoprevRockstar owns the copyright, they can do whatever they want with their games.It is rather odd however, and paints Rockstar in a very negative light as a trustworthy purveyor of binary distributed software. Do you want to receive l33t warez when paying for software?I expect reproducible binaries produced by a controlled toolchain from a responsible developer. Linux distributions have higher standards for binaries they distribute for free ffs. reply raxxorraxor 2 hours agoparentIronically the leet warez often are more well behaved pieces of software than the average crap app on the store of popular mobile OS manufacturers.People had standards at the time, which wasn&#x27;t that long ago either. reply incrudible 13 hours agoparentprev> I expect reproducible binaries produced by a controlled toolchain from a responsible developer.I would estimate the number of videogames published for Windows PCs matching all of these critera to be roughly 0. reply pengaru 11 hours agorootparentIt&#x27;s not like windows game developers are universally incompetent. They have their source so they can reproduce their binaries at will. They understand the risks of malware and how embarrassing it would be to unwittingly ship some, so they should know better than to be shipping releases built using their personal machine they also browse the web with.For Rockstar to be shipping pirated cracked binaries as their own demonstrates a profound lack of responsibility and professionalism as software developers.But I&#x27;m sure there&#x27;s a non-zero amount of windows game developers being careless&#x2F;sloppy in general too. reply incrudible 10 hours agorootparentReproducible builds and controlled toolchains are not really things you are going to realistically have, shipping games for Windows - even in 2023. That does not necessarily mean the final build is coming out of Mikes office PC, however. reply pengaru 9 hours agorootparentYou&#x27;re taking what I said to mean a very pedantic definition of \"reproducible builds\" that even Linux distros largely only aspire to achieve.By reproducible I meant they can recreate their binaries from source code, not necessarily bit-for-bit.There&#x27;s zero reason to ship a Warez group&#x27;s cracked version of a game when you&#x27;re the copyright holder in possession of the source and ability to simply build an executable without the copy protection crap the crack is bypassing.It&#x27;s pathetic on Rockstar&#x27;s part. reply raxxorraxor 2 hours agorootparentThe game is old and recreating the tool chain required to rebuild the game might be a massive work investment.It probably is even less save, because the builds differ and perhaps behave differently and you might even need a full QA cycle. The likelyhood of an old crack working more flawlessly is higher. replypaxys 15 hours agoprevWhile not too big a deal on its own, if the binary was doing something it wasn&#x27;t supposed to (which was&#x2F;is common with cracked games from untrustworthy sources) it would open Rockstar up to a mountain of liability.I&#x27;m guessing this is some subcontractor taking shortcuts rather than an official company policy approved by legal. reply toast0 15 hours agoparentRazor1911 isn&#x27;t an untrustworthy source though. reply paxys 14 hours agorootparentJust because it says Razor1911 in the binary doesn&#x27;t mean it actually came from that group though. reply capableweb 16 hours agoprev [–] Why is this hex dump being used as a verification rather than just showing the two (supposedly the same) hashes of the entire executable themselves? Should be a quick 20 minute job for whoever call themselves \"journalists\" today.I suppose it&#x27;s possible for that particular string to get into the binary by some other means. Maybe failed anti-circumvention that checks for known strings in its own directory or something similar? reply sjsdaiuasgdia 15 hours agoparentFirst problem: You presume this person has another executable of provable provenance to check against.Second problem: There could be many different official executables for this game. Each would have a different hash. Provenance proving applies here too.Third problem: Two hash values doesn&#x27;t communicate the actual story as well as what this person (who may or may not be a journalist, that appears to be your assumption) chose to do. reply Zetobal 16 hours agoparentprevI don&#x27;t know why I have to write this comment but not every twitter user is a journalist... reply Twirrim 16 hours agoparentprevI don&#x27;t see any reference to them being a journalist, anywhere? Why are you expecting some random person who saw and got frustrated with something and shared it, to be a journalist?Are you a journalist because you&#x27;re frustrated that this person isn&#x27;t being a journalist...? That&#x27;s kind of the same logic. reply wtallis 16 hours agoparentprevThe location of the string is pretty telling: right after a 256 byte header, and occupying the first few bytes of a long run of zeroes. This isn&#x27;t how you&#x27;d expect to find a constant embedded by a compiler or linker as part of code implementing a check for the presence of a crack. reply usrusr 15 hours agoparentprevFirst time I hear someone suggest that hashes might be a superior form of journalism. The cracking group signature is a smoking gun. Hashes would only show that the steam binary isn&#x27;t bit-wise identical with the original release, which any solution to \"steam release can&#x27;t require a CD check\" would imply.(well, \"smoking gun\" in quotes, because I don&#x27;t really see Rockstar doing anything wrong here. Would it have been better if they had zeroed out that string?) reply asddubs 15 hours agoparentprev [–] why not use the hex dump, it says the name of the cracking group, that&#x27;s more easily verifiable than comparing hashes to files you might not have replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": ["'"],
    "commentSummary": [
      "Rockstar Games is allegedly selling cracked versions of games on Steam, stirring discussions around potential copyright violation and the efficacy of digital rights management (DRM) protocols.",
      "The discussion includes points on the legality of derivative works, distribution of cracked software, and various gaming industry's copyright protection strategies, highlighting the controversial takedown of a Star Trek fan project.",
      "The dialogues revolve around the rightful ownership of cracked software, with some users arguing that Rockstar should have avoided DRM, while others critiquing the company for sharing pirated binaries."
    ],
    "points": 442,
    "commentCount": 210,
    "retryCount": 0,
    "time": 1693933283
  },
  {
    "id": 37391848,
    "title": "Puck – Open-source visual editor for React",
    "originLink": "https://github.com/measuredco/puck",
    "originBody": "Hey hackers, OP here!I&#x27;ve been dipping in and out of this problem space for the last few years with many of my clients.Puck sits somewhere between an old-school WYSIWYG-powered CMS and headless one, allowing content teams to author content using real React components.Traditional CMS solutions were flexible but often resulted in page that completely broke the brand guidelines. Headless CMS solutions are a fantastic way of controlling brand by restricting UI changes to developers, but makes layout changes restrictive and slow as developers often need to get involved.Puck provides a visual editor for React that can sit on top of your existing headless CMS (or act as standalone). We&#x27;ve been dog-fooding it on a few pages at https:&#x2F;&#x2F;measured.co and on https:&#x2F;&#x2F;wellpaid.io. So far, so goodThe API is built for React, which allows FE devs to quickly integrate their existing component and add some form fields for author input, or connect it to a headless CMS of choice.It&#x27;s open-source under MIT, and pairs nicely with Next.js (check out the demo application). Next in the pipeline: support for multi-column layouts, richer demos, new plugins.Looking forward to hearing your comments!",
    "commentLink": "https://news.ycombinator.com/item?id=37391848",
    "commentBody": "Puck – Open-source visual editor for ReactHacker NewspastloginPuck – Open-source visual editor for React (github.com/measuredco) 401 points by chrisvxd 19 hours ago| hidepastfavorite93 comments Hey hackers, OP here!I&#x27;ve been dipping in and out of this problem space for the last few years with many of my clients.Puck sits somewhere between an old-school WYSIWYG-powered CMS and headless one, allowing content teams to author content using real React components.Traditional CMS solutions were flexible but often resulted in page that completely broke the brand guidelines. Headless CMS solutions are a fantastic way of controlling brand by restricting UI changes to developers, but makes layout changes restrictive and slow as developers often need to get involved.Puck provides a visual editor for React that can sit on top of your existing headless CMS (or act as standalone). We&#x27;ve been dog-fooding it on a few pages at https:&#x2F;&#x2F;measured.co and on https:&#x2F;&#x2F;wellpaid.io. So far, so goodThe API is built for React, which allows FE devs to quickly integrate their existing component and add some form fields for author input, or connect it to a headless CMS of choice.It&#x27;s open-source under MIT, and pairs nicely with Next.js (check out the demo application). Next in the pipeline: support for multi-column layouts, richer demos, new plugins.Looking forward to hearing your comments! simonw 17 hours agoWow, I&#x27;ve seen so many of these kinds of things over the years but this one is really special: extremely intuitive design, really powerful and flexible, and MIT licensed too. Super impressed. reply chrisvxd 17 hours agoparentThis comment made my day. Thank you reply 2pointsomone 7 hours agoprevThis is just so fantastic, I have been looking for something like this for the open-source edtech app builder Flow (https:&#x2F;&#x2F;github.com&#x2F;opencurriculum&#x2F;flow) for the past year! Talked to the WebStudio guy and did so much research, but nothing was just right. This feels JUST. RIGHT.Thank you for all the hardwork! reply 2pointsomone 7 hours agoparentBtw, a very easy big win for you would be to port the side styles&#x2F;interactions panel of WebStudio into this. And by port I mean extracting the code to make a common open-source library with the correct license and putting it in Puck. reply chrisvxd 2 hours agorootparentGreat idea - could add this as a core field type so you can use it via the fields API, i.e. `{ type: \"css\", cssProperties: [\"color\"] }` reply chrisvxd 2 hours agoparentprevOh, awesome. Let me know how you get on! reply Exuma 19 hours agoprevAwesome. I&#x27;ve literally been tasked with building something exactly like this, and it&#x27;s a pain in the ass nothing exists like this for Vue so I have to do it from scratch.I plan to make it more like builder.io&#x2F;demo however where CSS can be arbitrary, that way basic landing pages can be built.Do you have any tips of things you wish you did differently, or what was more painful than you expected, as well as anything that might help in this? reply chrisvxd 19 hours agoparentIt&#x27;s such a common problem, I&#x27;m amazed there aren&#x27;t more solutions out there.A sound data model really helps things out. I&#x27;d go API-first.Drag and drop is a PITA. Specifically multi-column layouts, which require nested dropzones and a bunch of \"intuitive\" UX. A good library can help here, but not do everything (we&#x27;re using react-beautiful-dnd which is a bit out of date - dnd-kit might have been a better shout). This hasn&#x27;t landed in our main branch yet, but you can see it under the nested-dropzones branch (https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck&#x2F;tree&#x2F;nested-dropzones).If you could write React wrappers for your Vue components, you could potentially leverage Puck directly. That would save a lot of time. And even if not, you might be able to fork it or reuse the data model.Happy to give you more pointers. If you want to DM, I&#x27;m @chrisvxd on Twitter&#x2F;GitHub and here&#x27;s my LinkedIn: https:&#x2F;&#x2F;linkedin.com&#x2F;in&#x2F;chrisvilla&#x2F; reply jcuenod 18 hours agorootparentI just published a dnd library for nested tree structures (https:&#x2F;&#x2F;www.npmjs.com&#x2F;package&#x2F;vue-tree-dnd), and I can&#x27;t believe how much of a PITA dnd is! Working on browser-compatibility took me back to pre-jquery days... reply Exuma 18 hours agorootparentInteresting.. do you think it&#x27;s a good use case for a drag an drop editor compared to other DND out there? reply jcuenod 18 hours agorootparentIt&#x27;s not for editing UIs like the OP&#x27;s post. This is for editing nested lists. So it&#x27;s probably not what you&#x27;re looking for. But I made it because when I looked for a vue library that could do what I needed, I didn&#x27;t find one that I wanted to use&#x2F;thought would work. reply Exuma 18 hours agorootparentI&#x27;m assuming you researched a lot of other DND libraries when building. Did any stand out to you that were better than the rest? IE supporting nested structures, and looked to be programmed well. In my research I found about 8-10 of them and just thought... ugh, I will do this later, to decide between them reply jcuenod 16 hours agorootparentWell, there are obvious leading contenders like `https:&#x2F;&#x2F;sortablejs.github.io&#x2F;Sortable&#x2F;` and, within the `vue` space, `https:&#x2F;&#x2F;sortablejs.github.io&#x2F;vue.draggable.next&#x2F;`. Most of the stuff I looked at was unmaintained (lots not updated for vue3).I really disliked the vuedraggable was handling nesting, and it&#x27;s just a wrapper around a sortable. At the end of the day, my problem was simple enough that I didn&#x27;t want a 500kb dependency. If you&#x27;re wanting to do something like the OP but with nesting, I&#x27;d definitely start by looking at Sortable, though (maybe wrapping it the way you want). replyagotterer 19 hours agorootparentprevIf you&#x27;re open to hosted service, is the best commercial visual + headless CMS I&#x27;ve come across that supports React - https:&#x2F;&#x2F;www.storyblok.com&#x2F;home. reply Exuma 19 hours agorootparentDoes it allow embedding in an actual app? Thats the problem I have with these is they all require some weird form of going to their domain. I need the editor (AND the rendered page) to be 100% on my own domain. I wish they had some editor as an open source library and id just pay to have an API key or something reply satvikpendem 15 hours agorootparentprevAre there more details on the data model? I&#x27;m actually building something like this but not for React, so it might be useful to reuse the data model as you say. reply chrisvxd 2 hours agorootparentThe data model is detailed here in the docs: https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck#dataThere&#x27;s not an awful lot to it. reply mattront 16 hours agoparentprevTake a look at the Vue Designer [0] (it is our app), an editor that let&#x27;s you visually build Vue projects, not just using existing components. You can even build components with the editor.[0] https:&#x2F;&#x2F;vuedesigner.com reply showerst 13 hours agoparentprevTake a look at grapesjs -- it&#x27;s a bit janky in places but it&#x27;s self hosted and overall works pretty well. It can output plain HTML so I think it could be integrated with vue. reply Exuma 12 hours agorootparentThe problem with that one is I want to completely avoid parsing&#x2F;rendering HTML. That creates huge headaches when you want to create some kind of \"component\" but then once the html is rendered, it cant be re-parsed into its original state without adding a bunch of junk to it, like helper classes etc. It&#x27;s just very brittle for what I want to do reply wbarber 15 hours agoparentprevPlasmic.app works with vue - why not just use that? reply Exuma 14 hours agorootparentThis was what I said previously, which I&#x27;m assuming plasmic doesnt do:> Does it allow embedding in an actual app? Thats the problem I have with these is they all require some weird form of going to their domain. I need the editor (AND the rendered page) to be 100% on my own domain. I wish they had some editor as an open source library and id just pay to have an API key or something reply zoogeny 18 hours agoprevThis looks decent and the idea is sound. I was looking at headless CMS recently and it only vaguely struck me that what is needed is the front-end builder component.Looking at the comments from the dev in this thread it seems this really only supports vertically stacked layouts right now? At least the demos were responsive but each component seems to assume that it fills the width of the screen. Making responsive components in a columnar layout might be more challenging for this kind of toolset to handle.Looking at the recipe for next.js app I noticed that the component where the page is rendered appears to be in `[...puckPath]&#x2F;client.tsx` which is a \"use client\" component. That makes me wonder about the entire framework and whether or not it actually renders the pages on the client or the server.If those two things are true then this might have limited application. Finding a way to handle responsive layout for columnar and&#x2F;or grid based pages will be non-trivial. Finding how to mix server and client components effectively will be non-trivial.That aside, it seems useful and decently structured. In places where we I&#x27;ve worked where there is a lot of customization desired, having a UI builder that customizes page layout in some data format (json or xml) has been very helpful. reply mono_spaced 18 hours agoparentScott from Measured here, we&#x27;re dog-fooding puck on https:&#x2F;&#x2F;measured.co.There&#x27;s a WIP branch with support for more sophisticated layouts here: https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck&#x2F;tree&#x2F;nested-dropzonesAnd I think `use client` is a Next 13 thing. Not sure of the details, but Puck definately does render server-side. reply chrisvxd 18 hours agorootparent+1 what Scott saidMulti-column layouts are incoming very soonAnd Puck does support either server or client rendering reply p2hari 14 hours agoprevJust love this. And trust me, I have seen many of these kinds , but this is really different in the right sense. So easy to add custom components and get going. Well done. Will definitely try more. Thanks for this. reply chrisvxd 12 hours agoparentThank you! reply talboren 19 hours agoprevlooks awesome, a small screenshot in your readme would have helped understand that it&#x27;s more of a drag and drop component reply talboren 19 hours agoparent\"open source visual editor\" doesn&#x27;t really comply with \"The self-hosted drag and drop editor for React.\" reply chrisvxd 19 hours agorootparentHey, thanks for the feedback! We&#x27;re still figuring out the wording and will take this on board. reply nraf 6 hours agoprevThis looks very cool. Is anyone aware of something similar for Angular? We have a half-baked version that&#x27;s been in pre-alpha for our webapp, but if there&#x27;s something out of the box that we could leverage... reply chrisvxd 2 hours agoparentI&#x27;m not aware of anything. You could potentially use Puck directly if you wrap your Angular components inside React components for the purpose of editing, and build a custom version of `` that walks the data object and renders straight to angular. reply promhize 9 hours agoprevWell done. This looks great!A couple of questions:1. How easy is it to customise and extend the interface of the editor while still using the core of Puck?2. This looks like it could be used to build an editor similar to Shopify&#x27;s theme editor or is that a stretch? reply chrisvxd 2 hours agoparentThanks! Some answers for you:1. You can override a bunch of stuff using React-like APIs. `renderHeader` allows you to take over the header, and the plugin API allows you to wrap the root of the preview content page and take over the fields area on the right hand side. We don&#x27;t yet support full take-overs, but we&#x27;ll continue to work on these. Plugin API: https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck#plugins2. I think you should be able to mimic a bunch of the behaviours. The main missing piece is multi-column support, which is landing soon via the `nested-dropzones` branch: https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck&#x2F;pull&#x2F;37 reply nathancahill 18 hours agoprevHow do you keep the saved data props&#x2F;values (title, description) in sync with the component props in the code? Let&#x27;s say I change `description` to `subtitle` in the code, what happens to that information? reply chrisvxd 18 hours agoparentI just re-read your comment and realised I didn&#x27;t answer it first time around.The best way to handle this is in the render function you pass to Puck, which can continue to support the old prop (`description`) and map into the new prop (`subtitle`), even if it&#x27;s not provided by the author.We don&#x27;t have a system for migrating props in the actual data yet, but it&#x27;s something we could look into. reply chrisvxd 18 hours agoparentprevWe let the user decide how they want to store the data via the `onSave` and `onChange` callback props you provide to the `` component. So you would likely save to your own database in the callback.The data shape is detailed here: https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck#data reply nathancahill 18 hours agorootparentI&#x27;m trying to understand if the layout immediately becomes brittle once the data is saved (unless someone goes in to the saved data and patches it by hand when the layout is updated). reply chrisvxd 18 hours agorootparentSorry I got the wrong end of the stick. Please see my other reply to your comment. reply MuffinFlavored 19 hours agoprevI would&#x27;ve expected some kind of WYSIWYG functionality for \"make this API call and map the fields&#x2F;properties of the response into the components\"Like on the demo where it says https:&#x2F;&#x2F;puck-editor-demo.vercel.app&#x2F;edit Users Reached 20M+, I thought instead of static text, it would&#x27;ve shown some kind of {{template}} that shows JSON query format like `jq` does to pluck fields from arrays&#x2F;objects of fetch() response bodies (how React would pass along props&#x2F;state) reply chrisvxd 18 hours agoparentWe don&#x27;t natively support templating strings, but since it&#x27;s rendered by React, you can always add that when integrating Puck.However you can use an adaptor if you need to pull data in via a third party API: https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck&#x2F;tree&#x2F;main&#x2F;packages&#x2F;adapto... reply MuffinFlavored 16 hours agorootparentI was trying to give feedback on how you might make your product \"more attractive\"&#x2F;increase value proposition to the type of person you are aiming to help this with: people who want to make a React UI through a GUI instead of in a text editor.I know how to pull data in via React&#x2F;JavaScript \"code\". If I can do that, I&#x27;m technical enough to not need a GUI to help me make a UI... do I? reply mono_spaced 16 hours agorootparentNot the OP, but our company Measured is building Puck as an open source project, so I&#x27;ll try and answer.Puck is targetted at content&#x2F;CMS use cases, rather than general UI building. So the ability to establish guardrails in the editor experience is intentional. For best effect, we envisage Puck being used alongside a well-considered library of on-brand composable components. The aim is to enable non-developer editors&#x2F;authors to freely update and build content, whilst keeping the UI consistent and on-brand.This is a problem area we&#x27;ve encountered many times in our client work, hence why we wanted to scratch this itch.Having said that, I do believe the Puck editor GUI _can_ be configured to work with remote data somewhat as you describe, using the adaptor linked above (but there&#x27;s currently no demo for this feature). reply bingemaker 16 hours agorootparentprevEven if you are technical enough, you might still need a GUI to avoid any surprises. Also the end user of this tool is not tech people, but content managers reply jameslk 15 hours agoprevNice, this looks pretty good.It&#x27;s always been my dream of having something like Retool, but using your own components and completely open source. Retool is a backend layer too, so that&#x27;s partially what&#x27;s missing to complete the picture. But if we had that as something like a framework, we&#x27;d start getting close to the days of drag-and-drop UIs. reply satvikpendem 17 hours agoprevThis is exactly what Framer did before pivoting to a website builder, it might be worth looking into them. How will you be different than them? reply chrisvxd 16 hours agoparentFramer is a design tool, but Puck is a content tool. We&#x27;re focused on allowing content teams to create pages using existing on-brand components. Like a WYSIWYG with guard-rails.We built it because we couldn&#x27;t find something that would let our clients&#x27; content teams produce content for their sites without 1) either going off-brand or 2) pestering their devs for layout changes. reply teddarific 15 hours agorootparentCan you elaborate what you mean by \"content\" tool? Are your ideal users creating marketing sites, blog posts, or other?In my experience, most of what content teams work with are some forms of CMS, and the design tools usually deal with layout and creating generic sites that work with the data structure inside the CMS. reply chrisvxd 13 hours agorootparentTypically marketing sites and blog posts etc. It could probably be extended to applications, but that’s not what we built it for. reply satvikpendem 15 hours agorootparentprevFramer also has a CMS and you can import React components [1]. They pivoted because there wasn&#x27;t much traction in that use case.[1] https:&#x2F;&#x2F;www.framer.com&#x2F;developers&#x2F;#overview reply danr4 14 hours agorootparentyour pivot comments seem irrelevant as he is not selling this as a product, he is using it as a white-label solution for his clients. reply albert_e 15 hours agoprevminor:maybe the HN post title should mention the name of the project \"Puck\" for future discoverability reply chrisvxd 12 hours agoparentGreat idea - might update it once the dust has settled. reply nvegater 17 hours agoprevThis looks very nice ! How would you compare it with slatejs, tiptap or lexical ? Is this only for layouts but not for content ? (Would it be very hard to include some rich text and make it work like a cms with rich text editing?) reply chrisvxd 16 hours agoparentThanks! It’s possibly I’m misunderstanding, but I believe Puck is a different problem space to the other solutions you’ve mentioned -Puck enables content teams to produce web pages using existing React components produced by their React developers in a fixed and predictable manor that keeps them within the brand guidelines.You can’t inject arbitrary blocks and can only interact with components that are defined by your developers.You can render fully fledged pages or even, in theory, applications.Regarding content, Puck supports inline editing or pulling in data via an API adaptor (such as from a headless CMS).We don’t have a rich text field type currently, but I’m not opposed to adding it. (Internally, we’ve added a markdown component to enable some basic formatting and longer form content: https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;measuredco-site&#x2F;blob&#x2F;02fc908b8...) reply chrisvxd 16 hours agorootparentIt actually could be interesting to add tiptap for collaboration! reply laurels-marts 13 hours agoprevI recall a post of a similar project but for Svelte some time ago I believe. Anyway this looks pretty slick! reply transformi 14 hours agoprevLooks neat! Do you consider adding input elements? (forms,wizards..) if so it will be my goto platform! reply chrisvxd 13 hours agoparentPuck is for integrating with your existing component library, so not completely no code.Having said that, a developer could add any type of form input as a type of component! reply arek_nawo 16 hours agoprevLove it! Good looking, polished UI. I&#x27;m probably most impressed by the easy integration and React API. Congrats. reply d0100 18 hours agoprevCan I make my own prop editor?Ex. instead of an input for the prop `name` I want a picker that fetches data from some API reply chrisvxd 18 hours agoparentYou can use adaptors for this. Adaptors let you request a third party API via the `adaptor` field type.Docs are limited, but there&#x27;s a reference data shape here: https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck#adaptorExample implementation here: https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck&#x2F;blob&#x2F;main&#x2F;packages&#x2F;adapto...Example usage here: https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck&#x2F;blob&#x2F;main&#x2F;apps&#x2F;demo&#x2F;app&#x2F;c...You can either use it for a specific prop (i.e. `name`) or spread the result of the API call across your entire component (use the magic `_data` prop). reply chrisvxd 18 hours agorootparentThis might be a better example, actually: https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck&#x2F;tree&#x2F;main&#x2F;packages&#x2F;adapto... reply matfrana 18 hours agoprevIs it something like React Bricks? reply chrisvxd 18 hours agoparentYeah, similar! reply robbiejs 19 hours agoprevLooks great, the animations of drag-drop looks really smooth. How is it done? reply jasonjmcghee 19 hours agoparentreact-beautiful-dndhttps:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck&#x2F;blob&#x2F;cae760fbfb8497de0931... reply chrisvxd 19 hours agorootparentYup that&#x27;s the one. Also recommend checking out [dnd-kit](https:&#x2F;&#x2F;dndkit.com), which we may migrate to at a later date. reply continuational 18 hours agoprevLooks good - does it support callback props, and how do you enter them? reply chrisvxd 18 hours agoparentIt pretty much supports anything that React supports, but it&#x27;s not possible to pass callback props in directly via Puck&#x27;s authoring form.However, you might be able to either wrap your component inside the `render` function and define your callback there, or use context to pass in a function from higher up the tree.If you share your use case, I might be be able to help you out. reply tebbers 19 hours agoprevLooks amazing, great work! reply wbarber 15 hours agoprevVery cool. Are you familiar with plasmic.app? I&#x27;m expecting to integrate it into my next site build and would be curious for your take having built something in the same general category. reply chrisvxd 13 hours agoparentYes, but turns out I don&#x27;t know enough about it. Related thread: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37395707 reply joseferben 15 hours agoprevReally cool! reply manishsharan 14 hours agoprevThis looks great. I would love to be able to use this to create UIs if it were to support integration with GraphQL data sources. reply chrisvxd 13 hours agoparentYou can certainly configure it to work with GraphQL if you need to. See this adaptor for an example on how to integrate with external data sources: https:&#x2F;&#x2F;github.com&#x2F;measuredco&#x2F;puck&#x2F;tree&#x2F;main&#x2F;packages&#x2F;adapto... reply tmwatson100 19 hours agoprevlove this reply btown 13 hours agoprevThis is really slick! A really fluid and intuitive interface.We use https:&#x2F;&#x2F;react-page.github.io&#x2F; (also MIT licensed) extensively at my startup; it attacks the same problem, and it&#x27;s been incredibly effective (and hackable!).Generally speaking, owning your own CMS data, in your own database, with a well-documented JSON data format, and adding the ability to take any React component you&#x27;ve written (that itself may interact with your own data) and make it not only reusable as part of a content editing system but also WYSIWIG, opens up a huge number of opportunities - including adding your own logic to transform content before display.https:&#x2F;&#x2F;builder.io is another alternative that&#x27;s very effective at the adapting-custom-components-to-WYSIWIG side of things, but does keep the data in its own cloud storage.I&#x27;m really excited to see innovation in this space, and I&#x27;ll be following Puck closely! reply chrisvxd 2 hours agoparentThanks for sharing react-page! I hadn&#x27;t come across this before.Builder.io is great but the hosted nature made it a non-starter for us. reply shivekkhurana 18 hours agoprevIs anyone here who has shifted exclusively to visual react builders ?I have been writing react since version 0.11 and am considering shifting to a visual for day to day development. reply albert_e 17 hours agoparentI am probably your opposite ... I recently learnt basic React in a weekend and built a functional MVP webapp by hand.For a second iteration of the app, I asked ChatGPT (Plus) to help me. Gave it existing code and gave increasingly specific UI and behavior requirements. After a few hours of pair programming ... I had a working new page (with backend API integration). The UI behavior I wanted went fairly deep -- with a lot of conditional logic to render styles, handle double clicks on text to make them editable form fields, etc.I am impressed with this approach at least for prototyping and MVPs.The resulting page was surely not very maintainable due to the complexity of embedded logic and conditionals ... but again I wouldnt have managed to manually code such complexity myself. Maybe if forced to do it manually i would have learnt more, modularized my code more, but spend a week instead of a day achieving the result. I am not a career developer -- so for my use case I will take this productivity boost.I think there is a great opportunity to merge a visual UI builder like this (puck) and an LLM backend&#x2F;interface to radically improve productivity and make prototyping as well as building real apps (production grade, modularized, maintainable) much more easier to build. reply jarek83 12 hours agoprevAlternative meaning - Polish city nearby me :) https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Puck,_Poland reply chrisvxd 2 hours agoparentThe name comes from (ChatGPT-researched) folklore: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Puck_(folklore)Puck is a... fairy... [that takes on] the shape of animalsPuck is also a little, er, mischievous and sometimes seen as a demon. But we prefer the first interpretation. reply omarfarooq 15 hours agoprevHow does this compare to https:&#x2F;&#x2F;www.plasmic.app&#x2F;? reply chrisvxd 13 hours agoparentPuck is focused on providing a solution for non technical folk to build on-brand web pages with their team’s existing React components. This enables them to build web pages with guard rails that respect their brand guidelines.Plasmic is a no-code tool for building websites and applications from scratch. A great solution for a different problem. reply yaaang 13 hours agorootparentHi! I work on Plasmic. Plasmic&#x27;s most common use case is actually the same one, letting content editors build pages in your existing website using your React components.Congrats on this release! We are actually open sourcing Plasmic soon, would love to discuss any possible ways to collaborate. reply chrisvxd 13 hours agorootparentOh that&#x27;s fantastic. I wasn&#x27;t aware and applaud the decision to go open source.Happy to discuss&#x2F;collaborate. I&#x27;m @chrisvxd on GH&#x2F;Twitter, and here&#x27;s my LinkedIn: https:&#x2F;&#x2F;linkedin.com&#x2F;in&#x2F;chrisvilla&#x2F; reply wbarber 15 hours agoparentprevLooks like we have the same question. reply albert_e 15 hours agoprevProbably ia cliche now but ...Have you considered integrating an LLM to expand the functionality?Based on some recent experimentation I was able to get some fairly complex React UI and behavior out of a pair programing session ... without having a lot of React experience and skill myself. Seemed ripe with potential. reply chrisvxd 14 hours agoparentIt’s probably a cliche but yes, we’ve been thinking about this. reply pat64 12 hours agoprev [–] My only major gripe with it is React. Either go all the way and build something for Svelte that does this lowering the bar to the bottom on both creation and understanding of the UI layer orDo this with Rust and target Wasm abstracting away the hard &#x2F; tedious parts of working with lower level languages and creating graphical applications.Like this + Tauri would be an absolute powerhouse but as good as it is, it’s still just another React maker. reply madeofpalk 11 hours agoparentThis seems like a weird gripe. There&#x27;s probably a high chance that a team&#x2F;company has a bunch of React components already built, or they have a bunch of devs who know React, and just need an editor for it. reply chrisvxd 12 hours agoparentprev [–] React is what we needed for our use case, but maybe we can eventually evolve it to a place where it can be used with different frameworks. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Puck, the newly developed tool, merges the adaptability of a traditional CMS (Content Management System) with the command granted by a headless CMS, empowering content teams to author using actual React components.",
      "Puck can function either as an independent editor or on the foundation of an existing headless CMS and is compatible with Next.js, an open-source development framework.",
      "The author is welcoming feedback for continued improvements, indicating plans for future updates to Puck."
    ],
    "commentSummary": [
      "Puck is an open-source visual editor for React which enables content teams to build web pages using React components. It can function with an existing headless Content Management System (CMS) or as an autonomous tool.",
      "The creator of Puck plans to add support for multi-column layouts and new plugins following positive feedback for its user-friendly design and versatility. Users have proposed improvements and expressed interest in utilizing Puck for their projects.",
      "The author discusses the merits and drawbacks of Puck, comparing it to alternatives such as Storyblok, Vue Designer, and grapesjs, and mentions Builder.io as another visual React builder."
    ],
    "points": 401,
    "commentCount": 93,
    "retryCount": 0,
    "time": 1693922914
  },
  {
    "id": 37393820,
    "title": "Learn WebAssembly by writing small programs",
    "originLink": "https://github.com/EmNudge/watlings",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up EmNudge / watlings Public Notifications Fork 8 Star 707 Code Issues 2 Pull requests 1 Discussions Projects 1 Security Insights EmNudge/watlings main 1 branch 0 tags Go to file Code Latest commit EmNudge Remove \"utf-8\" from .decode() calls in 009_data tests (#6) a81a469 Git stats 26 commits Files Type Name Latest commit message Commit time .vscode [ Rework ] Readme (#3) exercises remove table solution patch add patches tests Remove \"utf-8\" from .decode() calls in 009_data tests (#6) utils refactor getWastParser into utils .gitignore init README.md add patches build.mjs change comment syntax (and add logs for JS) package-lock.json init package.json add patches run.sh refactor getWastParser into utils solve.sh add patches README.md Watlings Learn the WebAssembly Text Format by fixing a bunch of small programs! Warning This project is incomplete and in active development. Feel free to help out by filing issues and creating PRs! Usage This project uses Node 16+ & NPM for compilation and testing. Clone the repository and install dependencies with: git clone git@github.com:EmNudge/watlings.git cd watlings npm install Test your answer to an exercise with the start command: npm start 001_hello If you'd like to view the solution to an exercise, use the solve command: npm run solve 001_hello Using Wat2Wasm Directly ( Recommended ) For syntax highlighting and up-to-date builds, you can optionally use the official WebAssembly Binary Toolkit which will provide you with a wat2wasm CLI tool. If it is found on your path as wat2wasm, it will be used instead of NPM WABT. While it is strictly optional, it can help with debugging. Recommended Editor We recommend using VSCode with the WATI extension. This should provide syntax highlighting, intellisense, and other helpful features as you work through the exercises. Motivations I've found just diving in to be the best way to build experience with programming. Rustlings & Ziglings have both had tremendous returns to my journeys with both languages. WebAssembly (and by extension WAT) has a more sparse educational landscape than most and I was hoping to fill some of the gaps by building a project with the same sort of structure. Pedagogical Philosophy Outlined here are some thoughts on what makes a good teaching experience. Typing Over Reading The goal is to learn by doing. Comments on each file outline a task and some background. However, a lot about a language can be gleaned by its syntax alone. We should be adding as little explanation as possible. Occasional gaps in knowledge can be filled by consistent exposure to the syntax within different contexts. Certain things can therefore be learned without any mention. Introduction text is superfluous. Words add visual noise, so we should be careful with our count. Coding itself should supplement ambiguities in the text. If you find a text confusing or too verbose, please create a discussion post! Create Struggle Studies have shown that one cannot learn effectively without effort. This applies to practically every domain of knowledge. These projects should be educational, not easy. This does not mean we should make the education itself elusive. We should not make learning more difficult, but instead more intentional. When introducing a lot of new syntax, keep the problem scope small, but force the user to read a bit. If the syntax is not new, increase the problem scope. Maybe many variations of the same task. Credits rustlings Ziglings About Learn WebAssembly by writing small programs! Topics learning guide webassembly wasm exercises wat wast Resources Readme Activity Stars 707 stars Watchers 2 watching Forks 8 forks Report repository Contributors 2 EmNudge EmNudge PhoneDroid John D.K. Languages JavaScript 56.2% WebAssembly 41.9% Shell 1.9% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37393820",
    "commentBody": "Learn WebAssembly by writing small programsHacker NewspastloginLearn WebAssembly by writing small programs (github.com/emnudge) 390 points by todsacerdoti 17 hours ago| hidepastfavorite68 comments ReleaseCandidat 2 hours agoBecause I&#x27;ve read it here and elsewhere quite often: What is missing from WASM in the browser isn&#x27;t \"just\" DOM access, but \"everything\" else - including fetch or XMLHttpRequest - too. Here is a list of all web APIs supported by browsers and not supported by WASM, the DOM is just one of them: https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;APIBut at least there is hope, that these interfaces will be available once GC is final and supported by browsers: Once GC is supported, WebAssembly code would be able to reference and access JavaScript, DOM, and general WebIDL-defined objects.Last paragraph at https:&#x2F;&#x2F;webassembly.org&#x2F;docs&#x2F;web&#x2F; reply ysavir 11 hours agoprevLooks very similar to the Exercism model, which also has a free WASM course filled with small exercises[1]. I wonder if the author considered contributing to that course or working together with them, it might get their work to a broader audience and leverage the existing toolset Exercism has to offer.[1]https:&#x2F;&#x2F;exercism.org&#x2F;tracks&#x2F;wasm reply emnudge 8 hours agoparentI really like Exercism! Unfortunately their exercise model is considerably more free-form where it teaches you considerably less and in much larger chunks. I think this is a great model for certain contexts, but the format I have in the repo is more similar to \"rustlings\" and \"ziglings\" where you&#x27;re taught syntax and features alongside the code examples.I don&#x27;t know that their Wasm module is necessarily \"broken\", so I&#x27;m unsure whether my contributions would be welcome. reply ysavir 7 hours agorootparentVery fair! It&#x27;s been close to a decade since I used Exercism so I don&#x27;t really know what their stuff is like nowadays. From what I remember, the focus was less on teaching you the language directly (via instructions) and was more on encouraging the user to reiterate on their code and experiment, and letting reviewers lead the direction of growth. reply raincole 8 hours agoparentprevOne thing I don&#x27;t like about Exercism is that except for the most popular languages, the exercises are often not \"sysematics\".In other words, it&#x27;s just a bunch of leetcode-like questions, ordered by difficulties.A proper course should order the exercises by language features. Exercism actually has built a fantastic interface for this[1], but not utiltized it for most langauges.[1]: https:&#x2F;&#x2F;exercism.org&#x2F;tracks&#x2F;csharp&#x2F;concepts reply tietjens 1 hour agorootparentI completely agree with this. I love the platform, the mentors, and the enthusiasm for languages. They’ve done a great series every month this year on a new set of languages, and have great YouTube interviews.However, the problems they offer do not help you learn the syntax or quirks of specific languages and for me are only a place to practice leetcode&#x2F;codewars style logic. Also important! But not what I need when I first begin a language. reply imiric 15 hours agoprevThis is great, thanks!One of my favorite ways to learn a new language or framework is via \"koans\"[1], which this reminds me of. It&#x27;s a gentle ramp up from basic to advanced features, and the TDD-like workflow of seeing a test fail, understanding why, and fixing it, is really conducive to learning, while giving you that dopamine jolt from \"a-ha!\".[1]: https:&#x2F;&#x2F;github.com&#x2F;ahmdrefat&#x2F;awesome-koans&#x2F;blob&#x2F;master&#x2F;koans... reply dfee 14 hours agoparentsounds like a great way to learn a language \"on your own\". unfortunately, Rust is missing. can anyone propose a link? reply billti 13 hours agorootparentIt credits Rustlings at the end of the page linked to (https:&#x2F;&#x2F;github.com&#x2F;EmNudge&#x2F;watlings#credits). reply Kalq 14 hours agorootparentprevIsn&#x27;t that basically Rustlings? reply dfee 14 hours agorootparenti think you&#x27;ve found what i&#x27;m looking for! https:&#x2F;&#x2F;github.com&#x2F;rust-lang&#x2F;rustlings reply ReleaseCandidat 16 hours agoprevJust a remark: if you want to play with WASM features like GC, use Binaryen&#x27;s `wasm-opt` instead of WABT, as `wasm-opt` supports way more WASM extensions. reply RagnarD 6 hours agoprevI&#x27;m cheered by ongoing progress in adoption of WebAssembly. While Microsoft is often given minimal notice here, I urge anyone interested in WASM to experiment with Blazor WebAssembly. It&#x27;s an incredibly powerful framework that lets you use C# and most .NET libraries (including NuGet packages) as compiled WASM in the browser. reply oefrha 52 minutes agoparentFrom reading about it, it seems to suffer the same problem as Go compiled to wasm: payload is huge, usually multi-MB after compression. reply hsbauauvhabzb 6 hours agoparentprevRe ‘most nuget packages’ What’s the limitation here? If it requires the ability to read a file on disk, does it straight up fail or does the file read interface push the action back into a server-side rendering type action? reply RagnarD 3 hours agorootparentThe NuGet packages are zip files containing compiled binary and possibly other resources. They&#x27;re referenced in the source code and included at compile time. Since they become integrated into the overall compile, there&#x27;s no need to reference them in the final runtime product. reply arek_nawo 16 hours agoprevPretty cool.I haven&#x27;t really explored WASM hands-on (I&#x27;ll give this guide a try) but, given that it&#x27;s already been a few years, I think it&#x27;s been hugely beneficial for web development.Not the \"JavaScript killer\" some where hoping for, though it was never meant to be one. Instead it integrates pretty nicely within the existing ecosystem, optimizing existing use-cases and allowing new ones when heavy computations are required. Net benefit for all web devs - faster libraries, impressive dev tools and more portable node binaries. reply danielvaughn 15 hours agoparentI&#x27;ve been watching WASM from afar, and it&#x27;s my understanding that it&#x27;s not a JS killer because it doesn&#x27;t have direct access to the DOM or to most DOM APIs. I&#x27;m curious if there&#x27;s another reason I&#x27;m missing? reply math_dandy 13 hours agorootparentIs being a \"JS killer\" even a goal of WASM? From what I understand, WASM&#x27;s goal is to allow computationally heavy workloads (e.g., image and audio processing) to the browser by providing a compilation target for C code. This is how we get nice things like Figma or MS Office running in the browser.Let WASM do the number crunching, let JS do the UI. reply Philip-J-Fry 11 hours agorootparentIt&#x27;s not the goal from what it seems. But it&#x27;s definitely what would make it the most interesting to a lot of people, and it&#x27;s what I think most people expected at some point.For a lot of companies the only place JavaScript is ever used is on their website frontend. And it makes you wonder, why does it even still need to be JavaScript? With the rise of SPAs and the fall of normal document based websites, browsers are basically just becoming their own platform like Windows Desktop, Mac, Linux, Android, iOS, etc. You could say it&#x27;s been that way for a long time, but more and more apps are becoming web based only because the browser is now powerful enough to run what used to be a desktop application.Browsers are literally just a VM with an address bar. We go to a URL and run a program, except right now there&#x27;s basically the limitation that the program has to be written at least partly in JavaScript. Being able to deploy an entire website as WASM is just the next logical step from what I see. reply math_dandy 7 hours agorootparentThe two language problem is, indeed, awkward.DOM bindings in WASM would be awesome. I would be a happy nerd if I could do all of my web dev in OCaml.In the meantime, WASM has real, just not for front end dev.The two language problem is hardly unique to web dev. It’s also ubiquitous in the machine learning&#x2F;data science space with Python and C&#x2F;C++&#x2F;CUDA playing the roles of JS and WASM, respectively. reply ReleaseCandidat 2 hours agorootparent> DOM bindings in WASM would be awesome. I would be a happy nerd if I could do all of my web dev in OCaml.DOM is not enough for that. You almost certainly would like to be able to communicate with your backend ;)Here is a list of the \"usual\" web APIs: https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;Web&#x2F;API And everything that needs network access or access to local resources (file system in the worst case) will never happen to WASM because of security considerations. reply xigoi 2 hours agorootparentHow is allowing WebAssembly to use the network any less secure than allowing JavaScript to use the network? reply ReleaseCandidat 1 hour agorootparentDon&#x27;t ask me :).At least WASM will get DOM access (and hopefully access to similar web APIs) as soon as the GC is stable and usable. Once GC is supported, WebAssembly code would be able to reference and access JavaScript, DOM, and general WebIDL-defined objects.https:&#x2F;&#x2F;webassembly.org&#x2F;docs&#x2F;web&#x2F; reply catlover76 6 hours agorootparentprev> I would be a happy nerd if I could do all of my web dev in OCaml.You don&#x27;t like Bonsai? Or do you just want something that doesn&#x27;t \"transpile\" to JS at all? reply math_dandy 5 hours agorootparentI find that these compile-to-JS languages are great until you want to bring in other JS libraries. Then you’re stuck writing bindings which is annoying, and often brittle if you’re not really careful. reply catlover76 4 hours agorootparentOh I didn&#x27;t even think of that--that sounds like a huge pain in the ass lol reply zarzavat 3 hours agorootparentprevYou can certainly bridge the DOM to WASM with a virtual DOM. The problems with WASM are not just interoperability.The biggest problem is tooling. You cannot build tooling for in-browser WASM because it runs in a browser sandbox. JS has the same problem but the difference is that JS has a known object model that the browser can provide good tooling for.Whereas with WASM the browser has little insight into what those opaque Memory objects contain. So you need to bring your own tooling and run it inside the sandbox, and the sandboxing does not make this easy.Let’s say for example you want to pause execution, inspect the object tree, and run a REPL while it’s paused. reply yieldcrv 3 hours agorootparentprevIf it was the JavaScript killer it will attract JavaScript devs and they’ll make it just like JavaScriptnot syntax-wise just community wise, where the package and package managers are a mess and why there is demand for a JavaScript killer reply lenkite 14 hours agorootparentprevYep. Give access to the DOM - perhaps via a batch update&#x2F;fragment mechanism and watch as it becomes a JS killer. But WASM is currently a starved prisoner locked up in a room only allowed to view the goodies outside the cell door. reply tcfhgj 10 hours agorootparentWhat would that change? DOM interaction can and is abstracted away by frameworks anyways and not performance critical reply ReleaseCandidat 15 hours agorootparentprevIt doesn&#x27;t have access to _anything_ (in the browser, in other runtimes there is WASI with POSIX functions). Everything has to be imported from or exported to JS.And currently using anything but C, C++ or Rust isn&#x27;t feasible, as the runtime needed for a GC is way too big. A Haskell \"Hello World\" for example is about 1MB (even after running `wasm-opt` on the generated WASM binary). reply progmetaldev 7 hours agorootparentI do agree things like the GC are very large if we&#x27;re comparing against standard JavaScript, so I don&#x27;t believe the technology is ready for standard customer facing websites. For things like internal applications&#x2F;extranet type applications, I think that the runtime download cost is minimal compared to the functionality that you are given with a proper framework (I can only speak of Microsoft Blazor, but that&#x27;s just language ignorance, and I know there are other that fit the model as well). As a web developer that also writes utilities to run on the desktop, for things such as ETL or fixing bad data, being able to not switch to another language or even really framework is a huge boon for my time. I know JavaScript, but being able to rarely have to deal with it keeps my head in what I&#x27;m solving, rather than having to context switch between interface and server. reply yebyen 14 hours agorootparentprev> isn&#x27;t feasibleThis is kind of subjective, and in the context of \"is this a JS killer\" which is what you&#x27;re answering, I&#x27;d agree, it makes sending the Wasm to the browser a bit of a non-starter that it requires a large bundle most of which is simply boilerplate for whatever runtime, without some type of local storage and persistent cache it&#x27;s difficult to imagine using Ruby in a Wasm for example. If you&#x27;re deploying to a container, where you&#x27;re able to use a cache warmer to ensure the wasm is ready before it&#x27;s called, then a 1mb binary might not be such a big issue.(I mean, it is still a big issue because the point was fast cold starts, and big assemblies mean no fast cold starts, but again, subjective value judgments... 1mb isn&#x27;t too big in many cases and I&#x27;d wager most of the cases that I&#x27;d really care about. But in a browser...)But if you&#x27;re not trying to run the Wasm in a browser then it&#x27;s still potentially quite useful. You might not be running all of your Wasm in a browser and it might still be a JS killer, and all of those might not be in conflict. reply ReleaseCandidat 13 hours agorootparentWell, the main reason why I&#x27;m taking a deeper look at WASM is because I&#x27;m creating a language and compiler that is optimized to compile to WASM. While I don&#x27;t think that my compiler will be the JS killer, I do think that WASM languages using a (the WASM) GC have a future. reply patmorgan23 13 hours agorootparentprevI mean Microsofts Blazor framework can use WASM to run C#(and its runtime) in the browser. reply titzer 13 hours agorootparentprevVirgil compiles to Wasm and brings its own GC as well, and the runtime is on the order of about 4KB. The GC is a simple semi-space copying collector and the compiler prunes away dead code from libraries, so binaries are pretty small. So overall I don&#x27;t think this is a Wasm issue as it is mostly a language runtime size issue. reply plopz 13 hours agorootparentprevIn the browser, can it integrate with SharedArrayBuffer, worker&#x27;s postMessage or transferrable offscreen canvas? reply ReleaseCandidat 13 hours agorootparentDepends what you mean by \"integrate\". It always has to import or export JS functions or memory. WASM (without WASI) has no direct connection to \"the outside World\", everything has to be routed via JS FFI. So you can import or export a SharedArrayBuffer to communicate with JS. https:&#x2F;&#x2F;developer.mozilla.org&#x2F;en-US&#x2F;docs&#x2F;WebAssembly&#x2F;JavaScr...But you need the WASM thread extension (for atomic access to the shared memory) to be able to use shared memory. reply connicpu 13 hours agorootparentprevWASM essentially can call javascript functions that were imported, and I believe javascript is able to read WASM&#x27;s memory (a big help for transferring strings). If you&#x27;re using something like Rust, all the glue code to call any JS APIs can be automatically generated for you with wasm-bindgen, so it really isn&#x27;t a huge problem usability wise. It&#x27;s just not great for performance. reply dragonwriter 12 hours agorootparentprev> And currently using anything but C, C++ or Rust isn&#x27;t feasibleSomeone should tell Anaconda that they can&#x27;t do this, then: https:&#x2F;&#x2F;pyscript.net&#x2F; reply tyingq 7 hours agorootparentThat uses Pyodide. From Pyodide&#x27;s own pages:\"At present a first load of Pyodide requires a 6.4 MB download, and the environment initialization takes 4 to 5 seconds.\"So, yes, it works. But there&#x27;s plenty of situations where a big download followed by a 5 second stall is a non-starter. replybrundolf 12 hours agoprevIt&#x27;s super interesting to me how much WebAssembly resembles a \"real language\" that&#x27;s sorta writable by-hand. I bet it lowers the bar quite a bit when targeting it reply eliben 6 hours agoprevCool project!I maintain a somewhat related repo here: https:&#x2F;&#x2F;github.com&#x2F;eliben&#x2F;wasm-wat-samples&#x2F; reply emnudge 6 hours agoparentThat looks super useful! I wish I knew about this when first learning wat. This would make a great reference! reply frithsun 9 hours agoprevVery neat.As WebAssembly becomes the lingua franca of different ecosystems, having a strong grasp of how it works is worth the time investment. Thanks for this. reply ozcanay 8 hours agoprevCool. Did anyone try targeting Qt applications for WebAssembly? I wonder how convenient it is to use. reply zdragnar 8 hours agoparentThere&#x27;s an interesting write up here: https:&#x2F;&#x2F;www.linkedin.com&#x2F;pulse&#x2F;qt-wasm-nicholas-petreley-1cPersonally, I didn&#x27;t find the author&#x27;s sample app to load very quickly- I think it was 10 seconds or so just to get something on the screen- and it was useless on my phone.That same app would easily perform better and have better device support were it written in js&#x2F;html&#x2F;css.I just don&#x27;t see a place for things like QT or native gui stuff in real world WASM. Number crunching or fast data processing, sure, or maybe a game, but a standard UI is crap if the whole thing is in a big canvas. reply ducktective 14 hours agoprevIs there a WA UI framework for web similar to Svelte or Vue? reply RetiredRichard 13 hours agoparentTechnically Blazorhttps:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;aspnet&#x2F;core&#x2F;blazor&#x2F;host-an... reply Kennnan 14 hours agoparentprevHand written wasm is too low level to use a UI framework with, but there are rust frameworks that compile to wasm for web. For example, Yew and Leptos are both web-first frameworks, and there are a few such as Dioxus or wgpu that are native-first and work on web. reply no_wizard 10 hours agorootparentWhat makes hand written WASM too \"low level\"?It isn&#x27;t, really, what the Rust frameworks do is compile down to a specific interop, sure (JS + WASM, its not pure WASM due to lack of DOM access for starters).That said, no reason a hand written WASM app isn&#x27;t feasible, with appropriate JS glue reply syndicatedjelly 16 hours agoprevGave WASM a try and ran into problems exposing connections to a SQLite database I wanted to connect to locally. Has anyone done something like that before and can point to good resources? reply yebyen 14 hours agoparentCheck out Spin! It includes sqlite support natively in the runtime since 1.4:https:&#x2F;&#x2F;www.fermyon.com&#x2F;blog&#x2F;spin-v14 reply syndicatedjelly 12 hours agorootparentLooks like it’s only available for Python, I was hoping for a more language agnostic solution. Thanks though! reply yebyen 11 hours agorootparentIt is? The docs example shows support for Rust, TypeScript, and Python:https:&#x2F;&#x2F;developer.fermyon.com&#x2F;spin&#x2F;sqlite-api-guide#using-sq...I&#x27;m not sure what holds back from being a completely language agnostic solution, but I know when I tried binding functions into my Ruby app with wasmer I had nothing but problems, I wound up using WASI exclusively to communicate with my WASM modules. I don&#x27;t honestly know how good the WASM language agnostic story is today. I gave a talk with my perspective as a Rubyist at OSS Summit and CDCon&#x2F;GitOpsCon a few months ago in Vancouver. The talk (and lightning talk variant) are called \"Exotic Runtime Targets: Ruby and Wasm on Kubernetes and GitOps Delivery Pipelines\" reply Joker_vD 16 hours agoprevWhile it&#x27;s an interesting (and effective) approach to learn something, what is the point of learning WebAssembly? After all, I thought that WASM was supposed to be something like \"LLVM for web\", a low-level IR for webdev languages to target and for browsers to execute efficiently, and not something that you&#x27;d write manually. Or am I wrong? reply ReleaseCandidat 15 hours agoparentActually it is quite high level (with the GC extension even \"higher\" than C), not comparable to \"real\" assembler. It has types. It isn&#x27;t fun writing WAT, but for small stuff it&#x27;s perfectly doable.That&#x27;s a record with 3 fields, its constructor and getters using the GC extension: ;; A `struct` with 3 fields, all immutable. (type $testStruct (struct (field $first i64) (field $foo f32) (field $baz f64))) ;; Constructor. `ref` is a reference (func $mkTestStruct (param $a i64) (param $b f32) (param $c f64) (result (ref $testStruct)) (struct.new $testStruct (local.get $a) (local.get $b) (local.get $c))) (export \"mkTestStruct\" (func $mkTestStruct)) ;; Getter function for the three fields: (func $getTestStruct1 (param $rs (ref $testStruct)) (result i64) (struct.get $testStruct 0 (local.get $rs))) (export \"getTestStruct1\" (func $getTestStruct1)) (func $getTestStruct2 (param $rs (ref $testStruct)) (result f32) (struct.get $testStruct 1 (local.get $rs))) (export \"getTestStruct2\" (func $getTestStruct2)) (func $getTestStruct3 (param $rs (ref $testStruct)) (result f64) (struct.get $testStruct 2 (local.get $rs))) (export \"getTestStruct3\" (func $getTestStruct3)) reply emnudge 15 hours agoparentprevAuthor here!My initial motivation to learn WASM (as someone from a primarily web background) was that I had a pretty poor understanding of WASM in general and so I had a lot of difficulty working with WASM builds in just about any capacity other than a heavy JS wrapper.There are aspects to how WASM works that are quite different from other kinds of assembly formats that make learning the basics pretty important. e.g. how memory is requested, provided, grown. How functions are received and exported. Capabilities of tables.A lot of this might be abstracted by massive wrappers, but you&#x27;re losing a lot in perf and debugability when using them. reply wanderlust123 15 hours agorootparentThanks for putting this together, I too learn best by doing, and this looks very helpful! reply chrisco255 15 hours agoparentprevSometimes you may need to debug the actual wasm code or understand what the compiler is outputting. Depending on the flags you set during compilation, you may want to optimize for size of binary or for performance. You may also want to compare the wasm produced by two different languages or different versions of the language compiler. Maybe you want to verify what libraries are actually getting bundled with your wasm. reply thamer 14 hours agorootparentUnderstanding what the compiler outputs is also essential to debug the inevitable issues that come up when porting an existing program to WASM. Since it&#x27;s a different platform with significant limitations, it&#x27;s important to know how to replace some core APIs and capabilities and how to interface with these alternatives.By limitations I mean things that a POSIX program would expect that aren&#x27;t generally available from WASM, like network programming, file system access, processes and threads, pipes and signals. Emscripten and WASI help to some extent, but the replacement APIs are rarely fully compatible. reply __s 14 hours agoparentprevFor awhile I was using a raw wasm program for a game engine&#x27;s random number generator. Stored all the state in global variables, so no heap necessaryEventually I moved the whole game engine into wasm & at that point it all got ported to Rusthttps:&#x2F;&#x2F;github.com&#x2F;serprex&#x2F;openEtG&#x2F;blob&#x2F;8b7069cc52ec8db3406a... reply hoten 15 hours agoparentprevSome reasons to understand the textual representation, besides curiousity:You are embedding a WASM engine and want to better grok how the import or exporting works.You are writing a compiler that targets WASM. reply mdswanson 14 hours agoprev [–] Is it just me, or does \"WebAssembly\" seem like an oxymoron? Maybe it&#x27;s because I&#x27;ve been involved with the web since its earliest beginnings. reply teddyh 13 hours agoparentYou might like this bit of speculative history:reply mdswanson 11 hours agorootparentThanks! That was fun. I hadn&#x27;t seen it. There&#x27;s the problem of bootstrapping METAL, but perhaps left for a different lecture! ;-) reply patmorgan23 12 hours agoparentprev [–] I mean technically it&#x27;s browser VM bytecode by it&#x27;s semantics. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"Watlings\" is a GitHub repository under active development aiming to assist users in learning WebAssembly (Wasm) through hands-on fixing of small programs.",
      "The project is open to contributions with users invited to file issues and make pull requests, utilizing Node 16+ and NPM for compilation and testing.",
      "The repository provides instructions for setup and usage, and recommends tools like the official WebAssembly Binary Toolkit and VSCode with the WATI extension for an optimal coding experience. The methodology focuses on learning by doing with minimal explanations."
    ],
    "commentSummary": [
      "The discussed articles concentrate on WebAssembly (WASM) and its utilization in web development, covering the benefits of using WASM for heavy workloads despite its limitations like lack of access to the Document Object Model (DOM) and limited tooling.",
      "Various programming languages, frameworks, and tools compatible with WASM are also reviewed, expanding its usability in the coding spectrum.",
      "Additionally, they share experiences and opinions on WASM's potential, providing insight into its practicality and future in web development."
    ],
    "points": 390,
    "commentCount": 68,
    "retryCount": 0,
    "time": 1693930389
  },
  {
    "id": 37391521,
    "title": "Android 14 blocks all modification of system certificates, even as root?",
    "originLink": "https://httptoolkit.com/blog/android-14-breaks-system-certificate-installation/",
    "originBody": "Docs Pricing Blog Contact Android 14 blocks all modification of system certificates, even as root When Android was initially announced in 2007 by the Open Handset Alliance (headed by Google) their flagship project was billed as an \"open platform\", \"providing developers a new level of openness\", and giving them \"complete access to handset capabilities and tools\". We've come a long way since then, steadily retreating from openness & user control of devices, and shifting towards a far more locked-down vendor-controlled world. The next step of Android's evolution is Android 14 (API v34, codename Upside-Down Cake) and it takes more steps down that path. In this new release, the restrictions around certificate authority (CA) certificates become significantly tighter, and appear to make it impossible to modify the set of trusted certificates at all, even on fully rooted devices. If you're an Android developer, tester, reverse engineer, or anybody else interested in directly controlling who your device trusts, this is going to create some new challenges. Before we get into the finer details, first I want to talk a little about the context around Android CA management and how we got here, but if you want to jump to the latest details you can go straight to the Enter Android 14 section below. \"Open Software, Open Device, Open Ecosystem\" While the initial principles of Android were very much focused on open software, controllable by users and developers, over more recent years Android has increasingly limited the control of users, developers & researchers over their own devices. The key turning point in this process was Android 7 (Nougat, released in 2016) in which the certificate authorities (CAs) on the device that were previously fully modifiable by the owner of the phone were split in two: one fixed list of CAs provided by the OS vendor and used by default by every app on your phone, and another set of user-modifiable CAs that users could control, but which was used only for apps that specifically opted in (i.e. almost none). The set of CAs on a device is a small configuration setting with big consequences, as your device's trusted CAs are the organizations guaranteeing the security of your encrypted network traffic. A CA can issue TLS certificates (as used in HTTPS to secure all communication on the web) for any domain name they like, and anybody who trusts that CA will trust those certificates as evidence of a secure & legitimate connection to that domain. That also means though that if you create your own CA and trust it then you can intercept your own HTTPS or other TLS traffic, to see exactly what your phone is sending & receiving, and potentially modify or block it. Being able to configure your device's CAs is key to this. That is a lot of power. Making this difficult to modify accidentally for non-technical users and impossible to modify without user knowledge is certainly reasonable. At the same time however, being able to control this is critical for privacy & security research, reverse engineering, app debugging & testing, for assorted enterprise internal network configurations, for anybody who doesn't trust one of the standard CAs provided by their vendor, and many other cases. With that one change in Android Nougat in 2016, each of those use cases became significantly more challenging. It became impossible for users on normal devices to control who was trusted to secure the communication of apps on their own devices, and a substantial hurdle was created that directly transferred power from users to vendors & third-party app developers. Rooting around the Nougat problem Although this is very inconvenient, fortunately it's long been possible to root Android devices, allowing full administrative access over the device, and making it possible to work around these kinds of restrictions. This isn't officially encouraged by Google, but it's been sufficient as a workaround to allow researchers, developers & reverse engineers to take control of their own devices for these advanced use cases. By doing so, it was possible to deal with Android Nougat's restrictions on rooted devices, manually adding the trusted certificate to the system store via the filesystem, injecting them into the /system/etc/security/cacerts/ directory. This is a bit harder than it sounds, because /system is generally read-only, even on rooted devices. There are two main ways to solve that: Make /system directory writable (requires a little reconfiguration & a device reboot) and then manually modify the real system certificates directory. Mount a temporary read-write filesystem over the top of the read-only directory, copy the existing CA certs into there, and then add your own additions on top too. In each case there are a few other steps required to ensure that the certificates have the appropriate naming, permissions, and SELinux labels to be accepted by the system (for more low-level details and discussion see this post), but it's relatively simple and HTTP Toolkit has long automated the temporary mount-based process (see the certificate injection script here). In practice, this means it's possible to provide one-click automated interception setup for any rooted Android device or emulator. These approaches have been effective not only on custom rooted devices and specialized Android distributions, but even in most of Google's own official emulator images (everything except the full 'Google Play' edition images, which are locked down to match a normal OEM device) not to mention other emulators from Genymotion to Bluestacks. Easy & effective CA setup has powered myriad tools that let you see what apps on your phone are sending & receiving: helping developers to debug their networking issues, keeping app developers honest about the data they share, and shining a light on security vulnerabilities in both apps & their APIs. These techniques are used by HTTP Toolkit's automatic setup, but also referenced in the setup guides for similar tools like mitmproxy, in endless blog posts, StackOverflow answers and forum threads, widely used in tools including popular Magisk packages and by organizations like the community-run CA cacert.org. These are widespread techniques that have worked for many years. Although the required root access has become more a little challenging more recently (due to first SafetyNet and later 'Play Integrity' using attestation to allow apps to block users who use rooted devices) this solution has generally been quite manageable, and a just-about-acceptable balance between \"inconvenient enough to disuade users unaware of the implications\" and \"accessible to power users who know what they're doing\". Enter Android 14 Right now, Android 14 is currently in its final stages of beta testing, slated for imminent release within a couple of weeks. One of its headline new security features is remotely updatable CA certificates, which extracts management of CA certificates from the core OS image entirely, and moves it into a separately updateable component, delivered & updated via Google Play. This allows for faster CA updates for Google, allowing them to revoke trust of problematic or failing CAs on all Android 14+ devices with just a Google Play System Update, without waiting for each phone vendor to release an OTA update for the whole operating system. Although I'm sure you can see what's coming, let me caveat first: at a very high level, the goal here is a Good Thing. CAs trusted by default like this are in a powerful position, and there needs to be serious oversight & consequences to ensure they stick to their responsibilities and continue to justify that trust. When they fail to do so, it's important that this power is taken away quickly, before it can be abused. In the most notable recent case, in January 2023 TrustCor was untrusted as a CA by effectively everybody (including Google), after close ties to a malware-distributing organization and associated US defence/intelligence contractor were discovered. In the other direction, the inability to widely distribute & trust new CA certificates has caused issues for new CAs on the block such as Let's Encrypt, who have had to repeatedly delay the rollout of improvements to their signing chain, because old Android devices missing recent CA root certificates would not have trusted them, and would thereby have been locked out of significant parts of the web. Mechanisms to improve the responsiveness of this system are valuable. In addition to just speeding up removals & additions, this should also widen access to those updates, since even devices for which vendors no longer offer official OS updates can continue to receive system component updates like this via Google Play for significantly longer. Unfortunately though, despite those sensible goals, the reality of the implementation has serious consequences: system CA certificates are no longer loaded from /system, and when using root access to either directly modify or mount over the new location on disk, all changes are ignored by all apps on the device. Uh oh. The mechanics The key change to enable this is here. Instead of reading from the venerable /system/etc/security/cacerts directory, this new approach reads certificates from /apex/com.android.conscrypt/cacerts, when it exists. That root /apex path is where Android Pony EXpress (APEX) containers are mounted. These APEX modules are independently updatable system components, delivered as signed & immutable containers. In this case, the certificates form part of Android's com.android.conscrypt module - its core TLS/SSL library delivered as an independently updatable system module. The exact mechanisms behind APEX are challenging to fully understand, as many low-level details seem undocumented, and what documentation there is includes links to key details only available within Google's internal sites. Tessting the resulting behaviour though, it seems that this is using some kinds of containerization primitives to expose the mounted content directly to individual processes, resulting in surprising behaviour when trying to modify these files elsewhere. As a result, delivering content through an APEX module makes it much harder (seemingly impossible) to manually modify, even with full administrative control. It's easy to test this for yourself, using the latest Android 14 beta official emulators. Both the Android Open Source Project (AOSP) and 'Play Services' images have always allowed root access (unlike the 'Google Play' images) and by creating an emulator using those you can easily open a root shell. Follow either of the two existing techniques though, and the expected updates do nothing. Let's walk through a demo. First, set up your device. You'll need the Android SDK installed, and you probably want Android Studio, since it makes this much easier, although you can use the CLI directly if you like. First, create an emulator: Through the Android Studio UI, select any device model, and the API 34 'Google APIs' image for your architecture. Or, using the Android SDK tools on the CLI, run avdmanager create avd -n TestAVD -k 'system-images;android-34;google_apis;x86_64' (your architecture may vary) Let's try messing with temporary mounts and see what we can do: Start your emulator, via the UI or emulator -avd TestAVD Open a root shell via adb shell, then su Try mounting an empty temporary filesystem over the various cacerts directories now present: mount -t tmpfs tmpfs /system/etc/security/cacerts mount -t tmpfs tmpfs /system/etc/security/cacerts_google mount -t tmpfs tmpfs /apex/com.android.conscrypt/cacerts mount -t tmpfs tmpfs /apex/com.android.conscrypt@340818022/cacerts # N.b. that last @id may vary in future updates In the emulator, open Settings -> Security & Privacy -> More -> Encryption -> Trusted Credentials Under the 'System' tab, all the certificates you've just hidden from view on disk are there! So, where's this coming from? We can try searching the entire filesystem to find the source of this data. For example, the top certificate shown is from 'ACCV'. You can also find that in Android's sources here, and it's present both there and in unmodified Android CA cert folders as 3c9a4d3b.0. We can search for this with: find . -name 3c9a4d3b.0 2&>/dev/null It doesn't exist! But in fact, it does: remove your 4 mounts again (umount ), retry that find command, and you'll see that this is indeed present in the original cacerts directories. Try the exact same steps with an Android 13 image, and you'll find that this modifies the certs just fine, and the Settings certificates list appears entirely empty, as expected: Let's try another route and see if we can rewrite the system image filesystem directly to modify this list: Stop your emulator, and restart it from the CLI with a writable system partition: emulator -avd TestAVD -writable-system Make everything writable: adb root adb remount adb shell avbctl disable-verification adb reboot adb root adb remount You can delete all the normal certificates now (fair warning: this may create problems when using this emulator in future!) with: rm -rf /system/etc/security/cacerts/* rm -rf /system/etc/security/cacerts_google/* You'll find that you can't delete the certs from /apex though! Despite the remount, it's read-only, and mount -o remount,rw ... commands to do so manually will all fail. The closest you can do, so far as I can tell, is to unmount the certificates entirely with umountso that they don't appear in the output of mount at all. Doesn't matter though: no matter how aggressive you get, seemingly no matter how much of the emulator's relevant internals you delete, AFAICT there's nothing you can do to stop these certs all happily loading up in the 'Trusted' list in the Settings. As in with the other method, those same steps will work just fine on every other version of Android, up until now. Note that this isn't just a detail about the Settings app, where these are cached or stored elsewhere. The certificates as shown here are reloaded each time, and they're representative of every app's view of the certificate store. No matter what you modify on the filesystem, every app will continue to see Google's list of CA certificates regardless. I've been playing with this for a while, and as far as I can tell there's no working method to modify the certs anybody sees. What is going on here? It's hard to tell precisely, so I'm guessing & inferring here (but if anybody does have more information, I'd love to hear it! Get in touch on Mastodon, on Twitter or directly). I think the most likely case is that as part of the wider modularization of Android, these system files and components are now exposed to apps through an entirely different mechanism. It looks clear from the Android internals that they're still being read from disk and the code to do so hasn't changed in many years, so this implies not everybody is seeing the same filesystem. This is similar to how Docker and friends use chroot, overlay filesystems and mounts to run containers with an isolated view of system files and other devices. Clearly, this has some serious consequences. As touched on above: if you're configuring your own system CA certificates on Android right now for debugging, reverse engineering, testing or research, that option is going away in Android 14, and presumably all future versions too. For now anybody interested in these use cases will just have to avoid updating, or use custom OS releases that don't use the APEX module to manage their CA certs. As time goes by though, this will likely become increasingly impractical, since it means either diverging strongly from Android mainline on a key internal component or running outdated software indefinitely. Concerningly though, this also implies that APEX system modules are going to be a wider problem. If, as it appears, content within APEX modules is unmodifiable to users even with root access to the device, then every future system component that's moved into the remit of APEX is another part of Android that becomes completely removed from user control. More investigation is required and it's hard to know the full implications of that now, but for the many forks of Android like GrapheneOS & LineageOS, and for advanced device configuration tools like Magisk and its many modules, it probably spells trouble. Personally, for now I'm investigating some other promising alternative solutions to allow interception of your own network traffic on Android, and I'll share details here as soon as I have something working, so watch this space. In the meantime, if you want to debug your own HTTPS traffic, you'll need to stick to Android 13. Want to inspect, debug & mock Android traffic on your Android 13 device anyway? Try out HTTP Toolkit - hands-free HTTP(S) interception for mobile, web browsers, backend services, Docker, and more. Published 20 hours ago by Tim Perry Become an HTTP & debugging expert by subscribing to receive more posts like this emailed straight to your inbox: No spam, just new blog posts hot off the press Terms of Service Privacy Policy Comparisons 100% open-source Dive in at github.com/httptoolkit Built in Barcelona by Tim Perry",
    "commentLink": "https://news.ycombinator.com/item?id=37391521",
    "commentBody": "Android 14 blocks all modification of system certificates, even as root?Hacker NewspastloginAndroid 14 blocks all modification of system certificates, even as root? (httptoolkit.com) 307 points by pimterry 20 hours ago| hidepastfavorite226 comments phh 19 hours agoAs an author of an old root for Android, and of a modern generic custom ROMs, and other Android OS stuff:The title is, and forever will be wrong. When we say you&#x27;re root in Android, you&#x27;re actually root. You can actually do whatever you want [1]. Magisk (the now modern \"root\" for Android) now includes stuff to even \"edit\" Java code, so even if it&#x27;s hidden deep somewhere, you should still be able to access it. (Even if somehow it moves from Java to native code, we&#x27;ll still find ways, don&#x27;t worry)The fact that the author didn&#x27;t manage to do it doesn&#x27;t mean it&#x27;s not possible. I could guess what&#x27;s the author issue (I have two ideas in mind: 1. it requires stop;start to restart zygote, because zygote cached CAs, 2. it needs to switch to correct mount namespace before doing the commands), but I won&#x27;t try it, I got tired of working on closed-source Android stuff.> More investigation is required and it&#x27;s hard to know the full implications of that now, but for the many forks of Android like GrapheneOS & LineageOS, and for advanced device configuration tools like Magisk and its many modules, it probably spells trouble.I just don&#x27;t understand this. GrapheneOS and LineageOS team have full source-code access. They can do whatever they please with it. (The limitation being that Google breaks stuff at an incredible rate, and following is a bit annoying)Anyway, I hope that Android becoming more and more user-hostile (and more specifically in this case power-user-hostile) will move more and more people to custom ROMs. (In my dreams I make a \"OwnerDroid\", an Android fork where the security model doesn&#x27;t have the first line saying \"the user is an enemy\", but even though I developed some tiny bricks of it, the overall project would take a huge amount of work)[1] Except for some kernel-level protections, but GKI reduces that risk. reply pimterry 19 hours agoparentThe crux is that previously any user could modify these certs directly, even on vanilla OS images from Google themselves, without installing any tools at all - just by writing to disk - and that&#x27;s both widely used and included in the setup guides for lots & lots of tools.Now, you can&#x27;t do that.Of course, with full source code access anything is _possible_. You can absolutely build your own Android system images from scratch disabling all these modules to work around this, and it&#x27;s certainly possible for GrapheneOS&#x2F;LineageOS to handle that too - but it will create a bunch of new work, and diverging from Android&#x27;s implementations of core components may mean more work in future. And for most affected users \"first, build your own system image\" is significantly beyond their comfort zone and level of time commitment.There will be other solutions eventually - it may be possible by digging through the namespacing and modifying the mounts of target processes individually to disable this, or there might be a way to somehow build & install your own APEX modules in a way that Android will trust, to replace the system module and thereby modify this directory, or who knows what else. There will certainly be per-process fixes possible with Frida, with hooks targeted to individual applications. More ideas welcome too :-DDespite all that though, it&#x27;s still going to be a major problem that makes it harder for users to fully control their own devices. reply izacus 18 hours agorootparent> The crux is that previously any user could modify these certs directly, even on vanilla OS images from Google themselves, without installing any tools at all - just by writing to disk - and that&#x27;s both widely used and included in the setup guides for lots & lots of tools.Yes, and that was used for some horrifying security&#x2F;privacy breaches that made this whole site preach about buying iPhones. reply j5155 16 hours agorootparentIf I understand correctly, system certificates can be modified without jailbreak or any root access on iPhones. reply threeseed 15 hours agorootparentYou can add new root certificates which is common for phones used in the enterprise.But not aware that you can modify the core root certificates. reply unethical_ban 18 hours agorootparentprevModifying system certificates is uncommon for the average user, but for techies and enterprise apps I imagine it&#x27;s a lot more common.It&#x27;s one thing for the OS to put dangerous things behind warnings, flags and prompts. It is another to cripple the OS. reply jeroenhd 18 hours agorootparentYou can install root certificates, though, and they&#x27;ll work on almost any app you could need in the enterprise. reply omniglottal 10 hours agorootparentBut can you uninstall the root certificates of an adversarial government (i.e., your own)? Is it now necessary that the chain of trust includes entities you don&#x27;t trust? reply jeroenhd 1 hour agorootparentYou can disable certificate authorities in the security settings, yes. reply WeylandYutani 17 hours ago[flagged]| rootparentprevnext [2 more] This site preaches iPhone because they make money from the Apple ecosystem.Developers hate piracy, ad blocking and most of all users. reply dang 13 hours agorootparentCould you please stop posting unsubstantive comments and flamebait? You&#x27;ve unfortunately been doing it repeatedly. It&#x27;s not what this site is for, and destroys what it is for.If you wouldn&#x27;t mind reviewing https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsguidelines.html and taking the intended spirit of the site more to heart, we&#x27;d be grateful. reply wink 18 hours agoparentprev> Anyway, I hope that Android becoming more and more user-hostile (and more specifically in this case power-user-hostile) will move more and more people to custom ROMs.What about people who kinda gave up tinkering with custom ROMs because the state of the stuff that matters (root checks by your mandatory banking app, some Google stuff) is either not documented (good luck finding an overlap of \"phone model\" + \"your local bank app\" + custom ROM\" as a tested and known-good thing).I&#x27;m all for freedom and choice, but I don&#x27;t think unless you&#x27;re willing to go through a couple of phones, a couple of days of work, or are a specialist in the first place, this is a reasonable way of action for average phone users. I know you said \"power users\", but I&#x27;m a power user with computers, my phones could be a lot dumber if I had my way - but it won&#x27;t happen if we have to increasingly use them as MFA devices or be at the whim of corporations with a better lever (i.e. banks, I&#x27;m not changing my bank account 3 times until I find one with an app that works on a rooted phone...) reply thot_experiment 14 hours agorootparentMagisk and Shamiko together have been working well for me to hide root from Google Pay&#x2F;my bank app for the past year or so (fingers crossed, ymmv). Highly recommend the experience of having a rooted phone though, it&#x27;s a nice feeling controlling your device, especially being able to control the traffic and just like... run unix utilities natively. I really wish it was something I didn&#x27;t have to spend so much effort achieving but it has been worth it. I find the experience of using a device I don&#x27;t have full control over beyond irritating. reply benabbottnz 14 hours agorootparentprevThe two things that stopped me from using custom Android ROMs:1. Discovered that emergency calls would crash the phone (during an emergency)2. The LineageOS April Fools prank. reply bayindirh 12 hours agorootparent3. You can&#x27;t use trusted SIM services such as e-signature with custom ROMs. I have an e-signature embedded into the cryptographic module of my SIM card, and no custom ROM can use that, because they can&#x27;t provide a secure pipe from SIM to antenna, and that&#x27;s a deal breaker. reply pierat 14 hours agorootparentprevPresumably as an April Fools&#x27; joke, LineageOS added an undismissable notification informing users that, \"You might be a victim of software counterfeiting\"Removing it requires updating to another build or rebooting into recovery and changing a setting using terminal via setprop .instructions: Okay I finally managed to solve the LineageOS Settings\"You might be a victim of counterfeiting\" april fools joke. Here are the steps to how I solved it 1. Boot in to TWRP-recovery 2. Open Terminal under the advanced tap 3. Type the following \"setprop persist.lineage.nofool true\" in the terminal 4. Reboot the phone and voila :) reply phito 3 hours agorootparentWhat a terrible idea... reply nilespotter 18 hours agorootparentprevJust use the bank&#x27;s PWA, you&#x27;ll be fine. Or sandboxed play services in a separate GOS user. reply vetinari 18 hours agorootparentIt is different issue than that.European banks are forced by EU&#x27;s Payment Services Directive 2 (PSD2) to authenticate using MFA for any payment over 50 EUR.So what is the second factor? Your phone. Once you pair the app in your phone with your account, you can authenticate your actions using that phone, even if you are otherwise banking using the web app on your computer. Most banks also insist on using their apps, they don&#x27;t allow generic second factors. Since their apps require Android with SafeNet or iOS, they pretty much enforce the Google&#x2F;Apple duopoly.For now, there are other ways -- sms, which the banks are trying to phase out.So I imagine situation elsewhere will be very similar. reply kaliszad 16 hours agorootparentBanks have no clue about 2FA&#x2F; MFA, they will happily put the bank app and the custom TOTP generator&#x2F; \"key\"-app on the same phone or, as a fallback, send SMS to the same phone the bank app is on. So in reality, it&#x27;s at best 1.5FA because when the phone is owned, the user already lost. And it is really hard to not have the banking app on the phone with many institutions. Some institutions now put the TOTP generation into the same app too. Oh and there are limits on the user name and password-length that make it easier for attackers to crack, in some cases (in Germany) the password can be exactly 5 characters long and the username tends to be the debit card number by default. In many ways, this is really cumbersome, not really secure and on top of everything else adding a false sense of security. Less advanced customers are either somewhat secure but then the product is barely usable or they can realistically use the service but the security is so-so. reply vladvasiliu 15 hours agorootparent> Banks have no clue about 2FA&#x2F; MFA, they will happily put the bank app and the custom TOTP generator&#x2F; \"key\"-app on the same phone or, as a fallback, send SMS to the same phone the bank app is on.This. My bank in France, BNP, does that. Every so often, when I connect to the app on the phone, it says something similar to \"in accordance witha strong authentication must be made everyof sign-ins\". You&#x27;re presented with only one button that says something like \"ok\". You press it, and you&#x27;re in business.This is after requiring me to type in my pin, which must be precisely 6 digits, and some sequences are forbidden, so you can&#x27;t type 1234 or similar. It doesn&#x27;t seem to interact with the secure enclave in any way.If this number of sign-ins is reached while I&#x27;m on a PC (which is the most likely), it&#x27;ll send a confirmation request on the phone, so at least it works there. When paying online, I&#x27;ll also get a confirmation request on the phone app.On my professional account, with the same bank, the situation used to be exactly the same. But a few months ago, they switched away from that to sending a confirmation code via SMS for bank transfers. Credit card payments still have the app confirmation request. reply wkat4242 14 hours agorootparentprevMy bank wants me to type a code received in the app into a number field a little bit lower on the screen in the same app. They consider this a second factor. Of course it&#x27;s nothing but busywork and security theater. reply usrusr 15 hours agorootparentprevThey do? My bank is very explicit about \"don&#x27;t ever run the front-end and the second factor on the same device\". Perhaps it&#x27;s a German thing, with all our Datenschutz fundamentalism that will happily consider even IP addresses PII? reply kaliszad 2 hours agorootparentMy experience is with select German and Czech banks and&#x2F; or \"Sparkasse\" which is a kind of savings bank used very often by private citizens. These tend to have better mortgage options in some cases but are quickly inconvenient if you have an unusual (digital&#x2F; SaaS) business or any kind of special requirements, like if you want to transfer larger sums of money into other countries with a decent exchange rate.> \"don&#x27;t ever run the front-end and the second factor on the same device\"This is required in some cases, probably unless you apply for the physical hardware token generator which costs extra. You must apply for the 2FA-app initialization through the banking app that you are supposed to run on the same phone. In both cases, it is basically impossible to have a backup. Also, the banking app and the banking key app are supposed to have a separate PIN&#x2F; short password or a biometric login. Of course, the biometric approach has all kinds of problems in legal challenges (e.g. something you know is protected differently to something you are). Also, something you know cannot be easily obtained while you are asleep. Also, you probably don&#x27;t want to use your password manager on your mobile phone - so there you are, typing a generated password to log into the key&#x2F; 2FA app for security theater. If there wasn&#x27;t the banking app right next to the key app, the bank could probably just use something like FreeOTP+ or Google Authenticator without reinventing the wheel, also enabling backups in the process and skipping sending physical mail with the initial setup tokens. But that would be too straight forward and not \"enterprise\" security or whatever. The situation in Czechia is more or less similar. The banks tend to belong to the same banking groups so the underlying infrastructure might be similar even though Czechia still does not have the Euro&#x2F; SEPA. reply threeseed 15 hours agorootparentprev> Banks have no clue about 2FA&#x2F; MFAOf course they do. But they need to balance security with end user experience.And since security for a bank is about risk management they can offset this risk in other areas to compensate e.g. additional processes for activities involving larger amounts of money. reply daef 17 hours agorootparentprevI don&#x27;t know where you&#x27;re from, but here in austria most banks offer &#x27;cardTAN&#x27; as an alternative to mobileTAN. I always assumed cardTAN is a thing everywhere...edit: with cardTAN you get a OTP&#x2F;TAN &#x27;calculator&#x27; into which you put your smartcard to generate TANs on the fly.I use it because to me this feels more like a real second factor, when I use my mobile for banking. reply jacquesm 15 hours agorootparentSame here in NL, for now. But: banks are pushing their apps hard, to the point where every authentication you have to manually switch - again - to indicate that you want to use the token generator and not their app (never mind cookies and so on, those are only for the marketing department, when for once they could actually use them to store your preferences).And there will likely be a time when the bank simply cuts access to the cardTAN system and only allow their apps. Screw them because that means I have to use a smartphone, which I really do not want. The cardTAN system has been very good so far in preventing fraud, once the phone is the token it suddenly gets a lot more complicated and less secure. reply PeterStuer 3 hours agorootparentprevThat used to be the universal way here (Belgium) before the banks went all in with apps. I&#x27;m not sure wether typing a challange&#x2F;response into a browser is inherently more secure than a phone app.For those wondering about 2FA with these apps, factor 1 is \"something you own\" namely that particular phone&#x2F;sim, and factor 2 is \"something you know\", your PIN.You can still use cardTAN, but the app is way more convenient, especially with QR. reply vetinari 17 hours agorootparentprevThe DACH world is specific in many things... but I&#x27;ve seen cardTAN outside it. In Slovakia, Tatra banka does use this system. I guess being part of Raiffeisen explains it. reply wink 12 hours agorootparentprevFun fact, I still have the thing here, used it for many years, but they made it obsolete. App only now. It&#x27;s a German Sparkasse :( reply 4ad 15 hours agorootparentprevcardTAN is being rapidly phased out in Austria. reply liotier 17 hours agorootparentprevMy French bank, CIC, sold me a Digipass scanner+pin authentication device. Adding yet another device to the usual kit bag won&#x27;t make it very popular but an option independent from Google&#x2F;Apple exists and I guess that its non-existence wouldn&#x27;t fly for long with regulatory authorities.https:&#x2F;&#x2F;www.onespan.com&#x2F;products&#x2F;transaction-signing&#x2F;cronto&#x2F;... reply nilespotter 14 hours agorootparentprev> Since their apps require Android with SafeNet or iOS, they pretty much enforce the Google&#x2F;Apple duopoly.That is positively insane. So if you don&#x27;t use vanilla Android or iOS, you can&#x27;t use a credit card for more than 50EUR? No phone, dumb phone, too bad? reply Izkata 17 hours agorootparentprev> Just use the bank&#x27;s PWA, you&#x27;ll be fine.Just over a month ago, a proposal to prevent that was posted here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36875940 reply bob1029 16 hours agorootparentThe authors of the PWAs would need to opt-in to this.We distribute LOB banking apps as PWAs to our customers. In no reality would I consider incorporating this into our tech stack. We use PWAs and avoid native apps precisely to maximize compatibility across arbitrary IT policies in our various customer installs.I don&#x27;t know if our customers want to use linux, windows, android or apple. I don&#x27;t WANT to know anymore. I just want to target a common API (HTML5), add some bandaids for iOS&#x2F;Safari (usually after WWDC each year) and move on with life. Throwing DRM and platform constraints into the mix sounds like I might as well go back to native (I won&#x27;t).We are one of the few vendors that will actually get into a heated argument and push back against customers over FUD security crap like this. If a prospect insists that we add some draconian DRM to our product stack, I would make it very clear to leadership that I do not think we should do business with that customer on technical grounds.If you find yourself in a situation where you need to trust the client implicitly, then you have catastrophically failed in the rest of your design. reply jabroni_salad 15 hours agorootparentI appreciate what you do if you really do deliver that, but plenty of FIs are happy to mandate things like Trusteer Rapport and I would anticipate that sector to jump onto WEI just as fast as media companies will. It&#x27;s going to be sold to execs as a zero operational cost lightswitch solution to preventing account hijacks.Up until about a year ago one major core provider had been using the password &#x27;money&#x27; for all their client accounts, many of which were domain admins since that is a &#x27;just make it work&#x27; button and they cannot actually tell you what privs their service accounts need. When we asked the clients to press them on it, we determined via cracking that they had changed it to &#x27;monet&#x27; as a workaround. The standards for excellence are SO LOW. reply bob1029 13 hours agorootparent> that they had changed it to &#x27;monet&#x27; as a workaround> The standards for excellence are SO LOW.I&#x27;m 99% sure I know which vendor you are referring to.Almost everything in fintech is a hacky mess. This is our competitive advantage. Doing the barest-acceptable thing makes us look like rockstars compared to every other vendor in the space. reply aftbit 18 hours agorootparentprevOutside of the USA, some banks require mobile apps. If you don&#x27;t have a working attested phone in these countries, banking becomes decidedly 20th century. reply SenAnder 14 hours agoparentprev> The limitation being that Google breaks stuff at an incredible rate, and following is a bit annoyingThat&#x27;s a strategy to keep the competition busy just keeping up: https:&#x2F;&#x2F;www.joelonsoftware.com&#x2F;2002&#x2F;01&#x2F;06&#x2F;fire-and-motion&#x2F;If you ask \"what competition (from Android forks)?\", that means it&#x27;s working. reply DistractionRect 19 hours agoparentprevArmchairing here, but from a quick gloss over the article it seems like it should be quite easy to stub out:> this new approach reads certificates from &#x2F;apex&#x2F;com.android.conscrypt&#x2F;cacerts, when it exists.Much like the how the current work arounds for safetynet, hiding root, and hiding magisk work, it should be possible to hide &#x2F;apex&#x2F;com.android.conscrypt&#x2F;cacerts from select processes as needed to make it fail over to the old way. reply jacquesm 15 hours agoparentprevSorry for your experience and thank you for all the work you did in this domain. But I&#x27;m afraid that custom roms will never be a mainstream thing no matter how much Google (or Apple) misbehaves. That&#x27;s a hackers only thing and then only a very small fraction of the hackers. reply rollcat 17 hours agoparentprev> Anyway, I hope that Android becoming more and more user-hostile (and more specifically in this case power-user-hostile) will move more and more people to custom ROMs.Indeed, Android 5.0 has been that release for me. The redesign left the UI in a state of inconsistent mess, took away dark mode, made my otherwise perfectly performant Nexus 4 sluggish, broke apps...Custom ROMs were unfortunately not the answer, at least not for me - and TBH I doubt less technical users will appreciate the trade-offs. I&#x27;ve tried SailfishOS, been on Cyanongen&#x2F;Lineage for a while, but ultimately if you want a device that just works, and works well...Everything is a compromise, might as well choose Apple. reply pmontra 15 hours agoparentprev> Android becoming more and more user-hostile (and more specifically in this case power-user-hostile) will move more and more people to custom ROMsI never owned a phone supported by any of the custom ROMs I investigated.Samsung Galaxy S2, Sony Xperia X Compact, Samsung A40.Except the first one, which was huge by the time and tiny nowadays, I buy the smallest phone I can find. Apparently no ROM developer is interested in those phones. reply diegoperini 18 hours agoparentprev> I hope that Android becoming more and more user-hostile (and more specifically in this case power-user-hostile) will move more and more people to custom ROMs.I 100% share your desire but this is wishful thinking imo. People tend to comply when given no other options. reply squarefoot 17 hours agoparentprev> Anyway, I hope that Android becoming more and more user-hostile (and more specifically in this case power-user-hostile) will move more and more people to custom ROMs.Or even ditch closed platforms for good. In other words: \"Oh, PinePhone 2, where art thou?\" reply ASinclair 19 hours agoparentprevIf you can modify an init.rc then you can bind mount over the apex mount before the Zygote runs. reply phh 18 hours agorootparentinit could chose to launch every process in a new mount namespace, which would break this. I have no idea whether it does that, it probably doesn&#x27;t, but my point is that as long as it&#x27;s not released and open source, it&#x27;s not worth looking at. reply tux3 18 hours agorootparentEven if you can look at the open-source code, it&#x27;s still a maintenance nightmare to try to build on top of it, it just moves too fast.Much like any user could fork Chrome in principle and scratch their particular itch, but the sheer pain makes that not worth it except for motivated, organized teamsI&#x27;m not sure reverse-engineering some Java bytecode is even the rate-limiting step at this point, I&#x27;m more demotivated by the knowledge that everything will break again with energy-sapping frequency reply ASinclair 16 hours agorootparentI&#x27;m in the unfortunate position that I&#x27;m in this maintenance nightmare at work. Though I solved this specific issue months ago. There will be many like it to come. reply pjmlp 18 hours agoparentprevAnything that isn&#x27;t on standard Android that any non technical person uses, doesn&#x27;t count, as that isn&#x27;t what regular public uses. reply moffkalast 19 hours agoparentprevSo to sum up: skill issue. reply bitsandboots 18 hours agoprevSo many good comments here, but I keep thinking about how thankful I am that PCs don&#x27;t work like smartphones, and it&#x27;s sad it&#x27;s regressed to this point.Android has so thoroughly defeated itself, that I feel crazy to say I&#x27;m thankful that microsoft doesn&#x27;t run the PC world like google runs the smartphone world.Windows itself is a bastion of stability and sanity compared to android. Things do not need to be upgraded prior to the hardware actually breaking of old age.Beyond that, just like google, microsoft doesnt control the entire hardware-software pipeline. But just like google, microsoft is in a place of power where they could have made it incredibly inconvenient to own your PC, by dictating norms through a store, or discouraging any deviation of environment by safetynet.My memory is bad here, but did this sort of thing ever end in antitrust lawsuits for microsoft in the past? And, when can we look forward to the same for google? reply jeroenhd 18 hours agoparentWindows has had regular CA updates for about two decade now. If anything, Android works more like Windows at this point.Microsoft has also added tons of DRM to Windows (which they later broke). Remote attestation is built into the OS as well.Google has inconvenienced Android developers by altering the Android internals you weren&#x27;t supposed to rely on anyway; Microsoft does this all the time as well.We may need to wait a few weeks for an updated Magisk module. Honestly, it&#x27;s really notm that bad. Just don&#x27;t click the update button on the five or six devices that will receive Android 14 before then. reply vetinari 17 hours agoparentprevMicrosoft tried, they just failed. For now. They are still trying. Windows 11 requires TPM and Secure Boot. reply sangnoir 17 hours agorootparentPeople forget that Microsoft tried to go the iOS route and control everything by signing everything from boot to executables which one would only get from the Microsoft app store. This is what spooked Valve into developing Steam Machines and Steam OS; I&#x27;m grateful for Proton, but it was necessitated by Microsoft aggressively closed designs. reply Vogtinator 16 hours agorootparent\"S Mode\" is still a thing. On top of what you listed it also enforces Edge as browser and Bing as search engine. I&#x27;m not kidding: https:&#x2F;&#x2F;support.microsoft.com&#x2F;en-us&#x2F;windows&#x2F;windows-10-and-w... reply Joeri 15 hours agorootparentS mode is like an ad-funded tier of a streaming service: you pay less up-front, but you are forced to watch more ads. Herding people to edge and bing is how microsoft makes sure they can present those ads. reply DistractionRect 17 hours agorootparentprevIt&#x27;s a super soft requirement. I have secure boot and tpm disabled on my pc and win 11 doesn&#x27;t care.Why? Because I can&#x27;t set my prefered GPU with uefi enabled (which is required for secure boot), and I occasionally passthrough my windows disk to a VM when I&#x27;m dual booted into my Linux OS (so naturally windows can&#x27;t use the tpm). reply Xeamek 15 hours agorootparentprevLets talk when You will have to go out of your way to even get access to privileged account in Windows. Right now comparing restrictions of TPM to android having majority of their api (and functionallity) gated is just laughable reply vetinari 14 hours agorootparentLet me remind you Windows RT for ARM. Same restrictions of TPM, some screws tightened somewhat more. reply Xeamek 14 hours agorootparent>Same restrictions of TPM, some screws tightened somewhat moreWell yes, that windows was basically a direct competition to android (or tried to). Not sure what has TPM to do with anything really, but regardless;I am not saying that Microsoft is pure hearted angel that would never dare to restrict client&#x27;s freedom. Obviously they did it before many times and certainly will in the future.What I am saying though, is that for now, Android is on completely different plane of user restriction then Windows (in it&#x27;s main version) is. And even if Windows is constantly looking for opportunities to tigthen it&#x27;s grip, none of the restrictions that are implemented right now can justify the conclusion, as if Windows is becoming so restrictive that it&#x27;s reasonable to compare it to Android. Criticize them all you want, I will as well. But let&#x27;s not bend the reality just so it&#x27;s easier to say &#x27;all corpos bad&#x27;, rather then putting a small ammount of effort to distinguish between the levels of opression reply sumuyuda 17 hours agorootparentprevI think they were successful in obsoleting a huge amount of functioning computers, forcing my people to buy new hardware to run Windows 11. reply vetinari 17 hours agorootparentFor now, most people and businesses ignore Windows 11; they are happy with Windows 10. In 2025, once the Windows 10 support ends, it will be more interesting. reply bitsandboots 17 hours agorootparentAnd this is part of my point: by the time microsoft kills old computers, if they even do, they&#x27;ll be 10 years old, not 2 years old. reply Gigachad 11 hours agoparentprevI can kind of see how this could be a win for users though. I&#x27;ve heard that some 3rd world countries demand users to install the country CA so they can MitM all connections. By making this very hard, it becomes unfeasible to get users to disable their privacy. reply Defletter 9 hours agorootparentThat kinda presumes that those countries will be understanding. Call me cynical, but it seems more likely that having an Android 14 device will be considered as implicitly wanting to not install the country CA. reply Gigachad 8 hours agorootparentThe update will eventually flow through to all devices sold. And these tiny shit countries don&#x27;t have unlimited resources to just build their own tech like China can. They often take the extremely easy approach to censorship and then give up when it&#x27;s too hard. reply hedora 8 hours agorootparentThe last time I checked, cell companies produced custom android builds for the phone on their networks.Presumably, they’ll just factory&#x2F;ota install the malicious certificates. replyjchw 19 hours agoprevI&#x27;m daily driving a Pinephone Pro. Interesting note out there: Chase.com tries really, really, really hard to block you from using non-standard browsers (like Librewolf) as well as phone&#x2F;tablet browsers (it will try to force you to use the mobile application.)At least until WEI becomes mandatory, this isn&#x27;t really a serious problem, since these braindead measures are all easily bypassed. However, I am interested if there is any potential legal avenue to pursue given that Chase is a bank. My first guess would be ADA compliance, but I&#x27;m not sure. At this point, I&#x27;m so fed up that I am not sure if it is an empty threat anymore to say that I&#x27;m interested in filing lawsuits over this.(I realize this is a tangent, but it&#x27;s relevant because it underscores yet another facet of how leaving the oligopoly of mobile phone operating systems is damn near impossible. Android will just keep getting worse, probably even if the Linux phone niche miraculously grows to a couple percentage points; we need something.) reply horsawlarway 19 hours agoparentDark ages are a-coming. Seriously.We are going to have an age of digital serfdom. You will use a device provided to you by some \"benevolent\" corporation. They will own every aspect of that device and you will only be allowed to drive it if you give them money (pay your access fee today!).They will lock down most other avenues, general computing will be reserved for \"corporate\" use only, and while there will be a \"free web\", it will be fairly technical and user hostile, and the vast majority of marketplaces (ex: anything that touches money) will avoid it like the plague. reply jchw 18 hours agorootparentNone of us individually can fix the problem we&#x27;re faced with, but I&#x27;ll tell you what we can do: Be the biggest possible pains in the ass about it, and that&#x27;s exactly what I intend to do. I&#x27;m planning on digging my heels as deep as they go and just causing as much trouble for everyone. Believe me, if my browser gets blocked based on user agent, the owners will hear about it. I will bypass it. (I am bypassing it in many cases.) If you try to push me to a mobile app, I&#x27;m either going to find a way to use your website, or I&#x27;m taking my business elsewhere at basically any cost necessary. For me, the end of the open web is scorched earth. I intend to gain approximately nothing from this, and I don&#x27;t care. reply horsawlarway 18 hours agorootparentYeah - No joke, I&#x27;m right there with you.I just don&#x27;t think it will matter. There is too much money on the table, and too much pressure on the \"security\" front to get most of the people implementing this to just... stop. They have rational reasons for doing the things they&#x27;re doing, and they&#x27;re sitting in the \"corporate developer\" spot, which will still get the goodies like a real server that can run real code.I&#x27;d like to see some real government regulation... my basic stance is - if I own the device, I should get a key to EVERY fucking lock it has, including all the digital ones. Which seems very sane, and completely mirrors the same stance for ownership of things like houses and cars (the owner gets all the keys).But the government (at least in the US) has lodged the corporate phallus SO far down its fucking throat it&#x27;s literally choking to death. So I don&#x27;t expect any miracles. reply cmurf 17 hours agorootparentBut you don&#x27;t really own the device. Since day 1 Apple has been opposed to this on all their hardware, but most especially iOS hardware. You have the right to use it as they provide, or destroy it. Ergo you own the physical device minus all firmware and software. You have no right to inspect, understand or modify the firmware or software in any way. By extension, there is no right to repair.This highly successful paradigm is now replicated by John Deere, and Tesla. WiFi radios are being locked down.I remember folks on HN warning of the slippery slope a decade ago, universally shot down. Security! reply horsawlarway 16 hours agorootparentSure, and this is why I utterly refuse to buy Apple hardware (note - I&#x27;m still forced to use Apple hardware by my place of employment... sort of making my point).It&#x27;s also why I&#x27;ve chosen to do things like selfhost my own services, run my own computing hardware (literally sitting in my basement), contribute to and fund open source initiatives, and continue arguing that the government should regulate this behavior.Because frankly... I agree with you: it&#x27;s a highly successful paradigm. If left alone and unregulated, companies that don&#x27;t abuse their customers in this manner will become less and less prevalent.I call it \"the little green man\" paradigm: They have a literal enforcer sitting inside your phone who only answers to them. They use that little green man to extort rent from you for services and goods that shouldn&#x27;t require any sort of ongoing or recurring expense, but will... because rents * * cough * * excuse me, \"subscriptions\" are just wonderfully profitable.I&#x27;m just not an optimist on this front. reply 2OEH8eoCRo0 18 hours agorootparentprevYou don&#x27;t have to gain anything- it&#x27;s called not sacrificing your principles. Something many here don&#x27;t understand. If we don&#x27;t like something we don&#x27;t have to put up with it but it might take some sacrifice. reply horsawlarway 18 hours agorootparent> Something many here don&#x27;t understand.This is a complete cop out, and a misunderstanding about how this works.This is a principle that works right up to \"Can I feed my kids\" and then it doesn&#x27;t work at all.Principles are flexible. Some are more flexible than others. You NEED food in a way that you don&#x27;t need general purpose computing. If you are forced to choose, I know which one people will pick.They will just put a finger on the scale to make it more and more difficult to choose an open solution. You will start losing things like income, job opportunities, government access, etc.They don&#x27;t have to make you switch... they just have to make an environment where you are less fit. Make your life harder at every step, limit your opportunities, and wait for you to go extinct. And... you will. reply 2OEH8eoCRo0 18 hours agorootparentI&#x27;m complaining about the users around here who will not sacrifice the smallest convenience for their stated principles. reply BizarreByte 16 hours agorootparentprevI just don&#x27;t see how &#x27;general computing&#x27; can ever be taken away from those determined to have it. Forget the latest, fastest CPUs for a moment and focus on what general computing really is.I can build a computer from scratch from existing knowledge I have stored in my head. Computing that I&#x27;m in control of really can&#x27;t really be taken away from me on a basic level.I don&#x27;t disagree though, the web itself is becoming a hellscape and I expect it to be completely and totally locked down within my lifetime. I don&#x27;t think the web most people know is savable anymore. reply horsawlarway 13 hours agorootparentIt&#x27;s not that you won&#x27;t be able to have a general purpose computer, it&#x27;s that nothing that touches valuable services will be accessible to it.You can run your toy rpi hobby server, but you won&#x27;t be able to buy goods, check your bank statements, file your taxes, buy your insurance, pay your rent, check your email or message your mom.Doing any of those things will require getting permission from the gatekeepers of those services, and your device won&#x27;t get it if you have root.In the BEST case: the government heavily regulates what those gatekeepers can do. In the worst... they \"convenience fee\" away absolutely all surplus productivity so a very small group of people holding digital keys gets to be stunningly rich. reply BizarreByte 13 hours agorootparent> it&#x27;s that nothing that touches valuable services will be accessible to it. > Doing any of those things will require getting permission from the gatekeepers of those servicesI don&#x27;t see how we aren&#x27;t already at this point.I can be locked out of my banking tomorrow for any reason by the bank or government, banking apps won&#x27;t run on rooted phones or even many browsers, I can be banned from email providers and I can&#x27;t reasonably host my own as big providers won&#x27;t accept messages from my server, etc.That&#x27;s not even touching on how companies like CloudFlare are effectively already the gatekeepers of traffic to any service you would want to use.From my perspective the future you&#x27;re scared of is here already and only getting worse. reply spiralpolitik 13 hours agorootparentprevWatch what happens when the bottom finally drops out of Intel and the cloud retreats behind their own custom ARM or RISC-V server optimized SoCs. Open hardware sources will dry-up.There are very few OSS hardware vendors that are in a position to pick up supporting the whole ecosystem enchilada. System76 is the only one that comes to mind. They seem to understand to some degree where the puck is heading.While &#x27;general computing&#x27; can&#x27;t be taken away, what an individual or small company can support won&#x27;t be able to compete with the locked down systems, especially if the upstream efforts are spread across multiple open source fronts. reply snvzz 12 hours agorootparent>While &#x27;general computing&#x27; can&#x27;t be taken away, what an individual or small company can support won&#x27;t be able to compete with the locked down systems, especially if the upstream efforts are spread across multiple open source fronts.This is a very pessimistic view.IBM never designed the PC to be future proof. It just happened to pick up.RISC-V standardization extends to the boot process and the platform, facilitating a standard PC that&#x27;s cleaner, simpler and better than the current incidental IBM PC derived platform, which has accumulated much baggage since 1981.The platform standard being open and simple minimizes the effort the software side (esp. the OS) needs to spend on supporting the hardware. reply contravariant 10 hours agorootparentprevI mean even if you can build a computer from scratch a few self built transistors aren&#x27;t going to weigh up against advanced microchips.Unless we have different ideas of what &#x27;from scratch&#x27; means. reply BizarreByte 9 hours agorootparentOur ideas of what it means are the same and I agree, but \"general computing\" doesn&#x27;t mean the latest, most up to date hardware. The ability to freely compute on a basic level isn&#x27;t under any threat.I guess I&#x27;m being kind of pedantic, but I think there&#x27;s a meaningful difference between being able to freely compute and being able to freely interact with systems run by other parties which is what is actually threatened. reply eternityforest 15 hours agorootparentprevThe problem is that too many people hate tech... The people who would otherwise want unrestricted general computing now want no tech at all, or they only want tech as a platform to explore ideas, sort of an external neural enhancement, but not as an ubiquitous presence used by everyone for most daily tasks.FOSS is falling farther and farther behind commercial tech, and people actively don&#x27;t want feature parity with commercial apps, they want faithfulness to an interesting technical vision, and they want things that stay out of the way and are made of modular pieces, rather than things that do as much as possible and come with their own opinionated workflow you just learn and use. reply 2OEH8eoCRo0 18 hours agorootparentprevJust wait until everyone&#x27;s favorite benevolent company misses earnings for a quarter or two. reply wsgeorge 17 hours agorootparentprevFunny how your comment reads like my iPhone user experience (minus the \"pay your access fee today!\")I personally do not have a problem with these serfdoms, as they meet a real, functional need. It does suck that there aren&#x27;t as many easy alternatives for smartphones as there are for laptop computing. reply px43 18 hours agoparentprevBy continuing to be a Chase customer, you are supporting their predatory stance, and signaling that it&#x27;s okay for the rest of the industry to adopt the stance as well. reply jchw 17 hours agorootparentI may very well leave Chase over this issue, but unless we can convince a critical mass of people to care about this issue deeply, I think we&#x27;re screwed. Me leaving Chase will do nothing, except perhaps restore a tiny bit of my dignity.But, I do have a bigger problem: where do I go to signal that I care? \"Anywhere\" is an answer, but is it a good one? Who can I trust to not do this?And in addition, if I&#x27;m going to leave over it, I&#x27;m going to at least make noise first. reply px43 5 hours agorootparentPeople have been making a ton of noise and leaving the large predatory for-profit retail banks for years. There was a massive uptick in 2008, and again in 2011 with the Occupy Wall Street movement.Find a local credit union. They are better in literally every conceivable way. They have stronger financial controls, better service, better fees for all their financial products, and basically every credit union is part of the STAR network which is the largest ATM network in the world.I&#x27;ve seen the exact complaint of yours a few times over several social networks in the past couple weeks, so the word is definitely out there. Chase is shit, but we all knew that already. Time to move your money, and stop supporting these crooks. It&#x27;s actually super simple. It takes maybe an hour to convert everything from Chase to a credit union. Open the account with the credit union first, and they&#x27;ll give you everything you need to transfer everything over, even credit cards that aren&#x27;t fully paid off etc. Then you walk into a Chase branch for the last time ever, and move it all. reply CalRobert 17 hours agoparentprev\"At least until WEI becomes mandatory\"Sadly I think Google has killed the open web with this. It was getting boring anyway. But it&#x27;s annoying how much harder it is to live without a phone&#x2F;\"approved\" browser, etc. now. reply criddell 18 hours agoparentprevIf there’s an accessibility feature that you need and can only get with an alternative browser, then you should contact Chase. It’s great if an expert user knows how to fix a problem by installing extra software, but it would be even better for Chase to make a change to their basic website that would help even novice users with similar needs. reply bonyt 19 hours agoprevI think android is - and has been - more heavy-handed than Apple here. Even when you could install and trust a new root CA, some apps can and would ignore this. Apps can use certificate pinning on both iOS and Android, but apps by default on Android just ignore user-added CAs by default on Android 7+, since 2016[1].On iOS, the process of trusting a root CA is (rightfully) tricky, requiring you to install a profile and jump through some hoops with some scary warnings, but in my experience most apps will trust it unless they&#x27;re using pinning.[1]: https:&#x2F;&#x2F;android-developers.googleblog.com&#x2F;2016&#x2F;07&#x2F;changes-to... reply jeroenhd 18 hours agoparentI can honestly see why Google did this in Android 7. Android, being much closer to a normal computer than iOS, has a huge stalkerware problem. Stalkerware isn&#x27;t stopped by prompts, weaponises backwards compatibility, and includes all manner of abuse.On iOS it&#x27;s shockingly easy to subvert your HTTPS privacy for years after you&#x27;ve let someone borrow your phone for five minutes.I would love the option to actually trust CA certificates I install (especially Firefox, a fucking web browser, doesn&#x27;t even opt into user certificates without a secret tap combo and hidden settings), but I don&#x27;t think this feature is important enough for the dozens of techies using them day to day considering the risk to every other Android user on the planet.In this case there&#x27;s no evil Google conspiracy to thwart the plans of your local IT department, this is just a side effect of Google&#x27;s excellent sandboxing improvement and long overdue CA store update mechanism.I&#x27;m sure Magisk modules will appear to work around this problem. The existing Magisk modules will be broken for a while but that&#x27;s par for the course after major Android updates. I&#x27;ll write a module myself if I have to. reply soraminazuki 12 hours agorootparentFirst, this is utterly false:> On iOS it&#x27;s shockingly easy to subvert your HTTPS privacy for years after you&#x27;ve let someone borrow your phone for five minutes.You need a passcode to install certificates. And people casually handing over their phones would be a much bigger problem if that really is widespread behavior.Second, can we stop using \"techies\" as some kind of magic word to make any technical concerns go away? reply vetinari 17 hours agorootparentprev> especially Firefox, a fucking web browser, doesn&#x27;t even opt into user certificates without a secret tap combo and hidden settingsFirefox uses it&#x27;s own CA store and installing your own is trivial. Ever tried to just open URL with your cert? The ui for certs isn&#x27;t nice, but you can still view them in &#x27;about:certificate&#x27;Installing into system store and then configuring Firefox to use system store is the hard way, on all supported systems. reply jeroenhd 15 hours agorootparent> Firefox uses it&#x27;s own CA store and installing your own is trivial. Ever tried to just open URL with your cert? The ui for certs isn&#x27;t nice, but you can still view them in &#x27;about:certificate&#x27;Not on Firefox for Android, it just makes me download the file. You can do it of course; just go to Settings > About Firefox > Tap the Firefox logo seven times > Go back > Secret Settings > Toggle \"Use third party CA certificates\".about:certificate shows me a bunch of buttons to export certificates, but there&#x27;s no disabling or importing from that screen. reply vetinari 11 minutes agorootparent> Not on Firefox for Android, it just makes me download the fileThat&#x27;s... interesting. I did import my ca cert exactly this way, so they must have changed it... bummer.In the about:certificate I can see the ca cert that was imported this way and inspect it. reply moelf 19 hours agoparentprevhuh, but on iOS you have apps that can ignore your VPN connection... https:&#x2F;&#x2F;restoreprivacy.com&#x2F;latest-ios-found-to-bypass-vpn-co... reply jeroenhd 18 hours agorootparentThe same is true on Android for processes with system capabilities&#x2F;root, I believe, because they can bind sockets to a specific interface and bypass the VPN you use. reply ylyn 19 hours agoprevIsn&#x27;t this just how mounts work? If you have a something mounted to &#x2F;apex&#x2F;whatever and each app has a separate mount namespace, then mounting over &#x2F;apex&#x2F;whatever in your namespace wouldn&#x27;t change anything in any other mount namespace. You&#x27;d need to either just alter the filesystem directly, or enter the other apps&#x27; mount namespaces and mount your tmpfs there too.Shared mounts might be useful here. Not sure. I&#x27;d need to take a closer look at what is going on here.But I would say this result is probably a byproduct of whatever namespacing&#x2F;containerisation Google is doing, rather than an intentional effort to prevent users from changing the root CAs even as root. reply pimterry 19 hours agoparent> But I would say this result is probably a byproduct of whatever namespacing&#x2F;containerisation Google is doing, rather than an intentional effort to prevent users from changing the root CAs even as root.Yes, I think in practice that&#x27;s true. The end result is still a big problem though!> Isn&#x27;t this just how mounts work? If you have a something mounted to &#x2F;apex&#x2F;whatever and each app has a separate mount namespace, then mounting over &#x2F;apex&#x2F;whatever in your namespace wouldn&#x27;t change anything in any other mount namespace.The latter &#x27;separate mount namespace&#x27; here is the surprising bit. Previously, you could open a shell, mount things into the filesystem (or just modify it directly) and apps would happily read files from those mounts.Now, for these cacert files, that&#x27;s not the case, and additionally with the new approach direct modification is impossible.Before this change, I wasn&#x27;t even aware that Android apps were using their own mount namespaces! There&#x27;s very little documentation on exactly how that works and I&#x27;m not sure if there&#x27;s been a case where its been clearly visible until now. reply auveair 19 hours agoparentprev> But I would say this result is probably a byproduct of whatever namespacing&#x2F;containerisation Google is doing, rather than an intentional effort to prevent users from changing the root CAs even as root.Technology is very convenient when it&#x27;s complex enough to find an excuse to fit your business objective (see manifest v3). reply MishaalRahman 17 hours agoprevLeft a reply to the author on Twitter, but putting it here as well in case they didn&#x27;t see it.Hi! I&#x27;m the guy who wrote the blog post about updatable certs in Android 14 that your article linked. Not sure if you&#x27;re aware, but there&#x27;s actually a system property you can set to bypass reading from the APEX cert directory.system.certs.enabled=trueFrom: https:&#x2F;&#x2F;android-review.googlesource.com&#x2F;c&#x2F;platform&#x2F;framework... reply pimterry 16 hours agoparentI don&#x27;t think that helps much unfortunately. That&#x27;s a java.lang.System property (i.e. a config value set within one JVM&#x2F;app) as opposed to an android.os.SystemProperties OS property (globally configurable on the device via adb). Reconfiguring the former requires modifying the app itself AFAICT.That&#x27;s useful for automated testing (which appears to be why they&#x27;ve added it) or for toggling settings between debug&#x2F;prod builds, but not so much if you want to globally trust a CA certificate on your device. Of course, if you know a way to externally set such a property so that it applies to every app, that would indeed work great, and I&#x27;d love to hear about it!(I&#x27;m the author btw, and I don&#x27;t see any such reply on Twitter? Classic 2023 Twitter ofc) reply MishaalRahman 6 hours agorootparentFinally had a chance to test it, and you&#x27;re right. It&#x27;s not a property that can be set via \"setprop\", unfortunately. reply sansnom 2 hours agoprevIt&#x27;s a very good news for security and also for 99.99% of the Android users. But get me wrong, it would be nice to support power user, they just need to add a feature to easily add a chosen CA and it would be perfect.Currently CA management was very dangerous because it was not updated (as stated in the article).New CA were not added so if you kept your phone long enough you would see insecure warning popping up. People would take the habits of accepting without thinking: very problematic behaviour. One solution is to used Firefox which doesn&#x27;t use the system CA unlike Chrome.Another more problematic one: untrusted CA were not removed (the author give the example of TrustCor but they were other examples in the past like DigiNotar). Who knows what happens to private key of old untrusted CA ? If they end up in the wrong hands people could get MITM. (Personally, I had to remove DigiNotar for my old phone.)And of course as the author said: it&#x27;s also problematic for new certificate authority like Let&#x27;s Encrypt which at a time needed the complex cross sign certificate to ensure the certificates work for everyone. [1][2][1] https:&#x2F;&#x2F;letsencrypt.org&#x2F;2020&#x2F;11&#x2F;06&#x2F;own-two-feet.html [2] https:&#x2F;&#x2F;letsencrypt.org&#x2F;2020&#x2F;09&#x2F;17&#x2F;new-root-and-intermediate... reply nottorp 19 hours agoprevThis sounds nice for security, hell for some developers but:What happens in 2-3 years when this version of Android is abandoned? You pray the hardcoded certificates will last you a couple more years? reply jakub_g 19 hours agoparentIt&#x27;s been a long known issue [0] that cert providers had to account for, but apparently not anymore [1] from Android 14> Android 14 makes root certificates updatable via Google Play> Android&#x27;s root store used to require an OTA update to add or remove root certificates. That won&#x27;t be the case in Android 14.TIL there&#x27;s a workaround though [0]:> If you use Android 7.0 or earlier, you may need to take action to ensure you can still access websites secured by Let’s Encrypt certificates. We recommend installing and using Firefox Mobile, which uses its own trust store instead of the Android OS trust store, and therefore trusts ISRG Root X1.[0] https:&#x2F;&#x2F;letsencrypt.org&#x2F;2023&#x2F;07&#x2F;10&#x2F;cross-sign-expiration.htm...[1] https:&#x2F;&#x2F;www.xda-developers.com&#x2F;android-14-root-certificates-... reply cosmojg 18 hours agorootparentGood ol&#x27; Firefox, keeping up its reputation as the only user-respecting major browser. reply jmholla 17 hours agoparentprev> What happens in 2-3 years when this version of Android is abandoned?I had to install a Let&#x27;s Encrypt certificate to get my self-hosted password manager working because Google&#x27;s updates are missing an intermediate certificate Let&#x27;s Encrypt uses. This is not a hypothetical down the road issue but an issue present right now. Why should Google be the final arbiter of who I trust? They clearly have their gaps.And let&#x27;s not even get started on the existing approved certificate providers that you shouldn&#x27;t really be trusting since they&#x27;ve been shown to provide certificates to people and organizations that shouldn&#x27;t have them. reply looperhacks 19 hours agoparentprevMy wife just had to replace her phone because of that. Apps generally don&#x27;t accept user certificates and the first apps stopped working because Google cloud (or something related) updated to a newer certificate reply izacus 18 hours agoparentprevCertificates are an APEX module now (which is the crux of authors complaints actually), which means they&#x27;re updated out of band by Play Services and don&#x27;t need an OS update from OEM. reply arusahni 19 hours agoparentprevThey&#x27;re updatable via Google Play starting with 14, so not tied to OS updates. reply nottorp 19 hours agorootparentBut google will abandon this Android version fairly soon as we all know… what Google Play updates in 6 years? reply jeroenhd 18 hours agorootparentGoogle still updates the built-in for Android 7. They don&#x27;t really abandon device support for old OS versions like iOS tends to.The current situation is that the CA bundle doesn&#x27;t receive any updates from Google. If your manufacturer repackages their CA bundle and still updates your device, you&#x27;ll receive a new CA bundle, but I don&#x27;t believe this is guaranteed.Furthermore, if you&#x27;re still running Android 14 after six years, your issue is with the manufacturer of your device. The latest version of the CA bundle will still work of course, but you should really be at least four or five Android versions higher at that point. reply arusahni 18 hours agorootparentprevGoogle already guarantees Pixel security updates for 5 years, so I&#x27;d say that&#x27;s at least the baseline. When Google removed Play Services support for the 4.x series they were 9 years old at that point. reply nottorp 18 hours agorootparentGoogle and guarantees in the same sentence?https:&#x2F;&#x2F;arstechnica.com&#x2F;gadgets&#x2F;2023&#x2F;08&#x2F;google-kills-two-yea...Random example that even has pixel in it. Not to mention the other randomly canceled services. reply arusahni 18 hours agorootparent&#x2F;shrug you do you. replyidiotsecant 19 hours agoparentprevObjective achieved : consumer buys new phone. reply bitsandboots 18 hours agoprevEvery android release I see things removed, and inconsequential things added. It seems like iOS has been doing the opposite, such that slowly they may meet in the middle, and then iOS exceed android in every way.Apple folk, can I get an honest opinion here: I&#x27;ve been using macOS lately and I hate it because it fails at really basic user experience things that&#x27;ve been common on windows&#x2F;linux for decades. Like finder, it&#x27;s just the worst.If I were to get an iphone next generation instead of an android, would I have the same negative reaction to iOS? Would you say that iOS is a more complete, useful UX than macOS, for the smartphone use case? I think I want to make the jump, but I also don&#x27;t want to waste my time&#x2F;money. reply mardifoufs 17 hours agoparentYes and when the Appstore restriction is removed and sideloading apps becomes trivial, I literally can&#x27;t think of a single thing android would have over iOS. It&#x27;s such a shame since android used to be much more than just iOS but with .apk. reply Given_47 17 hours agoparentprevI don’t use my iPhone for much more than for scrolling hn during breakfast, portable audio player, looking random things up if I’m on the go, and making calls. It’s fine for that. But the user is so restricted (u can look into jailbreaking), I try to use my phone the bare min and use my desktop for everything.For context this is also someone in the midst of dumping macOS for Linux as well reply atlas_hugged 17 hours agoparentprevThey have a return policy. Give it a shot with a prepaid carrier like Mint. reply ZeWaren 19 hours agoprevI have a private PKI I use to connect to my self-hosted software: email server, calendar provider, notes server, photo sync tool, etc.I NEED to be able to add my root cert to the list of certified authorities.I don&#x27;t need to change anything to the system provided list. I just need to add mine. It&#x27;s my device, I&#x27;d like to be able to change anything if I want to. reply agwa 18 hours agoparentYou can install your own CA certificate in the user certificate store, and it will be trusted by Chrome and any other app which opts into user-installed CAs, which should include email and calendar apps.What is unlikely to work is installing your own CA and using it to intercept traffic between apps and the app-makers&#x27; servers. That sucks - you should be able to inspect what your own device is doing - but your use case of using a private PKI for your self-hosted software is definitely supported. reply Brian_K_White 18 hours agorootparentYou should also have the final say in what is NOT trusted. Not merely adding a cert to trust. reply tssva 17 hours agorootparentYou can disable individual system certificates in the \"Trusted credentials\" settings panel. reply charcircuit 18 hours agorootparentprev>That sucksIt&#x27;s insecure. If you are a bank app you doesn&#x27;t want other people to be able to steal the users password by installing a new certificate. reply mardifoufs 17 hours agorootparentHow often does this happen on phones? Why do banks still allow desktop usage then? reply charcircuit 14 hours agorootparentIt doesn&#x27;t matter how often it happens. It&#x27;s a vulnerability that people will end up being exploited or the data will end up being stolen by another hacker.Not all banks allow desktop usage. Some banks restrict certain functionality from the web interface since it is less secure. reply feanaro 13 hours agorootparentIt absolutely matters how often it happens. Otherwise we should start imprisoning everyone in the hopes of getting that one serial killer by the same principle. Some cures are worse than the disease. reply zb3 17 hours agorootparentprevThis is not the same scenario as the user installing a new certificate themselves. reply charcircuit 14 hours agorootparentSomeone&#x27;s company can install a certificate onto employee&#x27;s work phones. reply Brian_K_White 18 hours agorootparentprevTough shit. If you are a lot of things you want or don&#x27;t want a lot of things. It doesn&#x27;t mean they have a right to the thing they want or don&#x27;t want. reply gh02t 19 hours agoparentprevSame for me, but don&#x27;t a lot of corporate IT policies deploy root certificates to devices too? You&#x27;d think there has to be a way to do it. reply jeroenhd 18 hours agorootparentUser certificates still work fine. Apps have to opt into the user CA store (many of them don&#x27;t) but any app deployed by IT should be fine. Chrome works, Firefox can be made to work, and I believe the Gmail app also works with user CA certificates. reply gh02t 17 hours agorootparentThanks for the clarification, I was pretty confused by the article on this detail myself. Per app opt seems like a reasonable compromise for my use as long as the browser recognizes my CA, as that&#x27;s the one I care about. reply jeroenhd 15 hours agorootparentThe biggest issue is that the developer needs to opt in, the user can&#x27;t decide \"my email client should trust this certificate\". reply 8organicbits 18 hours agoparentprevOne alternative is to use public CAs on your private networks. I&#x27;ve been working on tooling for this at getlocalcert [1]. Side stepping the need to add a trust root makes the public on private approach a net win for some networks. I honestly wasn&#x27;t expecting Android to block private CAs, but I guess here we are.[1] https:&#x2F;&#x2F;www.getlocalcert.net&#x2F; reply Hackbraten 17 hours agorootparentThat looks super convenient! However, some reverse engineering tasks would still require root CA certificates, for example observing app traffic. reply severino 18 hours agoparentprevI was also confused about that. I don&#x27;t use an Android phone currently, but I remember you could add your own CA certificates to an Android phone -without being root, just using some option under settings- and at least applications like the web browser would trust them. And I&#x27;m not talking about long ago. So I couldn&#x27;t understand if the need of rooting your device to install custom certificates was for something different. reply jeroenhd 18 hours agorootparentOn Android 7, Google changed the defaults for certificates. Previously, apps trusted system certificates and user certificates unless they opted out. On Android 7, apps have to opt into trusting then user certificate store.Browsers opt in, or in the case of Firefox, can be configured through hidden settings to opt in. Many other apps don&#x27;t, though.If you&#x27;re trying to intercept traffic or use apps that should opt in but don&#x27;t, the system store could be altered with root access so that these apps still trusted the certificates you&#x27;re trying to inject. However, most apps worth their salt implement certificate pinning, so that&#x27;s hardly reliable anymore. It&#x27;s Arnold workaround that works on some apps but not on most.Furthermore, Google Chrome and derivatives require certificates to be logged publicly so malicious CAs can&#x27;t mess with random domains. Your private CA isn&#x27;t logged in the public record, so adding the certificate to the system store actually breaks HTTPS for many browsers. You can add the cert to both stores to make it work, but it&#x27;s kind of a hack.On iOS loading certificates is easier, but you&#x27;ll still need to work around certificate pinning if you want to intercept HTTPS traffic. reply severino 17 hours agorootparentThanks for your explanation! What I remember is from an Android version more recent than 7, probably 10, but maybe the browser was Firefox so in that case there was no need to have your device rooted. reply CSDude 18 hours agoprevHTTP Toolkit was very helpful for me to extract hidden APIs from crappy EV charging apps in Turkey, combined with Frida to prevent SSL pinning and root detection.Then I realized, the reason they try to hide is maybe those APIs are abomination &#x2F;s reply chc4 19 hours agoprevI mean, you still have root and APEX packages aren&#x27;t doing anything tricky specifically to stymie modifications - they&#x27;re just mounted file systems. You&#x27;re still going to be able to modify system certificates, it&#x27;s just going to be less convenient and need something more than dropping a single file to a folder. Hell, the code is even still falling back to the old file system path if the APEX mount doesn&#x27;t exist, so you could just delete the entire module and go back to the old method. reply pimterry 19 hours agoparent> Hell, the code is even still falling back to the old file system path if the APEX mount doesn&#x27;t exist, so you could just delete the entire module and go back to the old method.That&#x27;s covered in the article - no, you can&#x27;t do this. If you entirely unmount the apex module from the filesystem from a root shell, so the CA certificates aren&#x27;t visible anywhere on the filesystem, apps will still read them successfully. And the OS blocks RW mounting of APEX modules so you can&#x27;t delete the cacerts directory within the module either.It looks like apps have separate namespaced mounts, managed by the OS itself from boot. Effectively they&#x27;re containerized, and as part of launching all applications the OS is mounting the certs directly into the process&#x27;s view of the world.If you can find a way to modify the filesystem the apps see from a root shell, that would be great! I&#x27;d love to hear about it. But believe me that I&#x27;ve tried quite a few of the obvious things already. reply chc4 13 hours agorootparentAPEX namespace membership is managed by the ld.txt config file for the dynamic linker, iirc. You can probably just remove the com.android.conscrypt line, or remove the entire conscrypt APEX package from the system and unpack the libs into &#x2F;system&#x2F;lib64 instead. Or patch the linker not check APEX signatures, and repack it without the CA folder. Or unmount the conscrypt APEX mount and replace it with a FUSE mount that proxies everything else the CA folder. Or...a bunch of different other methods. reply t0bia_s 17 hours agoprevHow green and sustainable this approach from Google exactly is when it makes forks like LineageOS harder to maintain?LineageOS is only way how to keep many devices up to date by security patches. Ability to have newer version of Android is just a bonus... or... uh wait. reply benmmurphy 8 hours agoprevThere are much more reliable ways to intercept traffic than messing with the root certificates. I believe corellium has a more solid strategy where they modify the TLS library to accept certs signed from their proxy and then the certificate from the origin server is passed through as an extension on the proxy certificate. reply 1vuio0pswjnm7 15 hours agoprevWhere are the diffs of Android 13 against 14. Isn&#x27;t this an \"open source\" project.If Google actively prevents \"rollback\" to a previous version, then how does a computer owner try out the new version. Once installed, there is no going back. Even if the owner discovers the new version is unsuitable. It&#x27;s Amazon with no returns. A new car without a test drive.Reading source changes might be an easier way to review the new version than running it in an emulator and trying to figure out what changed. Is it not possible. reply Brian_K_White 18 hours agoprevAnd recently there were discussions about browsers disallowing self-signed certs, even for local host, and going https-only, and the supposed excuse is you can edit your local root store.Well now what? reply keyme 17 hours agoprevPeople here just love their locked bootloaders for some reason. But once you free yourself of this silliness, and root all your devices after unboxing, you&#x27;ll be good for yet a few more years.Of course it&#x27;ll only keep being this easy temporarily. Here&#x27;s a scene from 2026 for your imaginative pleasure:Door: You need to scan your COVID25 vaccine QR code to open this door.QR App: This app will only run on a HW attested device------Shopkeeper: We only accept WhatsApp pay at this store.Payment App: This app will only run on a HW attested device------Your friend: We can only talk on this one messaging app that everybody uses.Messaging app: This app will only run on a HW attested device. Oh, but we promise that this encrypted blob of executable code that you can&#x27;t disable is here just to ensure the safety of your E2E encryption.------Your custom ROM rooted Android 18 phone: Running a secure messaging app that was banned from the Play Store and has only like 2 other active users in the world.The police: Papers please. Phone touches the scanner. Scanner beeps and turns red.The law: You have violated the Digital Safety Act. Daily driving a non-licensed general purpose computer is illegal as this may endanger \"our children\".The law: You have violated the Public Health and Safety Act. Daily driving a non-licensed general purpose computer is illegal as this may be used to circumvent your quarantine and vaccination control status checks.------I can go on and on. I think you get the gist of it. Once we have HW attestation fully figured out, these laws will come. Cash will go away. Your agency will go away. Etc.... And the punchline of the ghost story? The guys coding this stuff up? They&#x27;re here with us reading this thread. Commenting about the virtues of locked bootloaders for your security. reply bitsandboots 17 hours agoparentThis is just an effort by Big Outdoors to get us to go outside by giving us nothing else to do. &#x2F;s reply hnav 17 hours agoparentprevGooglers are adding attestation to web standards so you can&#x27;t use escape through the browser. To be fair, Google stands to benefit from this and they get paid in Google so the incentives line up. reply smoldesu 16 hours agorootparentEveryone with two motes of influence over the browser market wants to do this: https:&#x2F;&#x2F;httptoolkit.com&#x2F;blog&#x2F;apple-private-access-tokens-att...It&#x27;s bad. It&#x27;s especially bad on platforms where you don&#x27;t get to choose which browser you run, but we should protest it everywhere. reply exabrial 18 hours agoprevWe really need a third operating system for phones. reply bitsandboots 18 hours agoparentWe had them. Nobody bought them and here&#x27;s what we got. BB10, WebOS, Windows Phone reply exabrial 17 hours agorootparentI _really really_ enjoyed WebOS but it gambled way too hard on \"Web Only\" for the time period, and didn&#x27;t really learn the lesson from Apple&#x27;s attempt at the same thing. I only gave my device up after the screen broke.And damn, that hardware keyboard layout was fire. reply wiseowise 17 hours agorootparentprevFirefox OS. reply Hackbraten 17 hours agoparentprevThere is: https:&#x2F;&#x2F;pureos.net reply CatWChainsaw 8 hours agorootparentDo they have any relation with Purism? reply maven29 17 hours agoprevSay hi to ebpf, now shipping with android kernels. reply NoZebra120vClip 19 hours agoprevI&#x27;m not sure of the implications here, so, two questions:(1) What effect does this have on user-installed credentials, such as a certificate for OpenVPN? I used to be able to install those myself, with a few taps. They did produce the ominous message about someone monitoring my network activity, of course.(2) Will users still be able to disable CAs in preferences? I routinely go through the list of CAs and disable anything I don&#x27;t trust, mainly based on country of origin, so China, Russia, Turkey get shut off, et. al. Will this functionality still be available in Android 14? reply redleader55 19 hours agoparentThere are several ways[1] for an Android app to trust a CA:- by default, using the system installed CAs- if specified in the app manifest, it can trust the user installed CAs- included with the app, also in the manifest, it can trust any CA the author of the app decided to trust[1] https:&#x2F;&#x2F;developer.android.com&#x2F;training&#x2F;articles&#x2F;security-con... reply pimterry 19 hours agoparentprev1. No effect, as far as I can tell. User-installed credentials for other cases are unchanged, this just affects system-managed CA certificates2. Yes - you can still manually soft-remove CAs through the Settings UI reply curiousgal 19 hours agoprevI mean if they were willing to mess with something that was completely unbroken like the quick access tiles for WiFi&#x2F;data back in Android 11 (or was it 12?) I wouldn&#x27;t put it past them to mess with anything else. reply kevincox 19 hours agoprevAndroid isn&#x27;t really open. In order to have a \"certified\" device you need to remove user control. For example users by default aren&#x27;t even allowed to access app&#x27;s \"private\" data. That was enough to get me to move to something where I am in control.But if you move away from a \"certified\" ROM then you start to fail SafetyNet (or its successors) and many apps will refuse to work. Those apps want to make sure that the user isn&#x27;t in control of their devices, they want to make sure Google or a \"trusted party\" is.They say this is to ensure the security of your device that logs into your bank or whatever, but I guarantee that my LineageOS updated this week is more secure than my stock Google ROM that got its last update 3 years ago. If Google really wanted to prove security with SafetyNet they would stop attesting devices that haven&#x27;t been updated. But it isn&#x27;t about device security, it is about ensuring that the device is controlled by a big corporation, not the user. reply tkems 19 hours agoparentIn my opinion SafetyNet is no longer about security and is mainly DRM at this point. I think you are right on the money about the out of date devices too. I was going through my Dad&#x27;s old phone collection this weekend and noticed that several old Android phones have specs that are not terrible today but are not useable due to no updates from the OEM. So now they are mostly e-waste. These are perfectly useable phones (maybe outside of an old battery) for basic tasks. reply bootlooped 19 hours agorootparentThat makes so much sense. Back when I had a rooted device, I was once blocked from using... the Instant Pot app. Yes, a recipe app. It gave me a message saying something vague about security. reply r0b1n 19 hours agorootparentprevSafetyNet was always about DRM. The Play Store contains tons of malware despite SafetyNet, and malware does malware things despite SafetyNet.Also, SafetyNet makes alternatives to Google Cloud e.g. for Backups non-viable, so win-win for Google I guess. reply kevincox 19 hours agorootparentYou are confusing SafetyNet with Play Protect. Play Protect is about protecting devices from malware. SafetyNet is about protecting services from \"untrusted\" devices. It is a remote attestation API that validates that the device is running a \"trusted\" operating system. reply bboygravity 19 hours agorootparentprevWhat backups? It&#x27;s literally impossible to take backup images of an Android phone (as in: the entire thing, not just some Playstore apps and some of the settings).The last phone I used that supported taking a backup image of the entire phone was a 2013 BlackberryOS 10 device. reply r0b1n 19 hours agorootparentYou cannot even backup all of the playstore apps, tons and tons set the magic \"don&#x27;t backup\" bit.You are totally right in that there are basically no useful backups on android whatsoever. The closest thing is \"adb backup\" when you have root and developer settings enabled, which is saying a lot. reply bboygravity 2 hours agorootparentEven adb backup isn&#x27;t possible: it&#x27;s been deprecated for years and I&#x27;ve never ever gotten it to work even with root and the right dev settings.It starts creating an image of a couple of GB (takes a couple of hours, lol) and then just bugs out and stops. There&#x27;s no error checking or anything and when it bugs out it means you have start all over again. reply summm 13 hours agorootparentprevEven Firefox does this. Because of something something security. replysurajrmal 19 hours agoparentprevSecurity depends on your threat model. Your threat model and Googles are not aligned. They are protecting against threats you are happy to ignore or otherwise have other counter measures for. I think the real problem is assuming a one size fits all strategy works for everyone. reply tomatocracy 19 hours agoparentprevThere are some ridiculous examples of apps refusing to run on rooted devices or custom ROMs. The Heathrow airport app, for example - why does an app which just shows me flight times and maps care at all?! reply izacus 18 hours agorootparentYou want the honest answer?Because security consultants slapped that on some checklist and Heathrow will now bugger contractors that build Android app to implement root checks.Enterprise apps are full of this bs. I partially blame Google because it made checking for integrity so easy that every app owner now things it needs to use it. reply OfSanguineFire 19 hours agorootparentprevIf an app shows maps, it usually won’t run on a ROM like LineageOS that lacks Google Play Services. This is because the API that app developers overwhelmingly use to show maps is the Play Services one, not the vanilla AOSP one. (I’m not even sure if AOSP has a map API.)LineageOS with MicroG will run some of these apps and show a map using OpenStreetMap tiles provided by MapBox, but the functionality may still be broken because the MicroG’s maps support is not a full replacement. reply tomatocracy 19 hours agorootparentIn this case this isn&#x27;t about lack of Play Services maps etc - the app looks for root and refuses to run if it sees it. reply m3adow 19 hours agoparentprev> That was enough to get me to move to something where I am in control.What smartphone OS are you referring to? Sounds interesting. reply kevincox 19 hours agorootparentLineageOS with root enabled. reply bitsandboots 18 hours agorootparentThat gives you some control, but because lineage is mostly just using upstream android, and google&#x27;s \"contributions\" to AOSP continue the overall decline of android, and the majority of apps adhere to google&#x27;s behavioral demands of the play store, even lineageOS gets worse every year by way of it not being a hard fork of what was once a good OS.Not that I have a solution to the problem. Just saying the current and foreseeable future state is that smartphones are past their glory days, and the platform defeated itself. reply kevincox 18 hours agorootparentIt is definitely not perfect. But having root does allow you to do most of what I want to do.Unfortunately to participate in modern society you basically need iOS or Android, and iOS is far worse for user freedom. So I have taken the best option I could.I also help \"with my wallet\" by preferring websites for everything that has no need to be an app. But I am sure that I am the minority. reply varispeed 19 hours agoparentprevThis banking apps requirement is laughable if you can manage you bank accounts through the internet browser. I mean there are some banks that only work with an app, but majority of banks in my country work through the browser just fine.That being said, I have a separate phone just for bank apps and turn it on only when I need to use it for banking. reply zb3 19 hours agorootparent> This banking apps requirement is laughable if you can manage you bank accounts through the internet browser. I mean there are some banks that only work with an app, but majority of banks in my country work through the browser just fine.Well, that&#x27;s exacly why Google has proposed WEI - to make sure they no longer do, and the user is practically forced to have a device that has bundled Google spyware. reply Izkata 16 hours agorootparent> WEILink so people don&#x27;t need to go looking: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36875940 reply kevincox 19 hours agorootparentprevYeah, I have switched to a bank that is accessible via the web. But I fear that eventually they will all require an app. reply bitsandboots 18 hours agorootparentprevI&#x27;ve always thought so too - who is banking on their phone?And, loans aside, if I had money in a bank that forced me to change the way I live my life just to store money, I would move to a different bank and tell them that&#x27;s why they lost a customer. reply ianburrell 18 hours agorootparentHave you never needed to transfer money when traveling or out of houseIf US, have you ever mobile deposited a check? If rest of world, have you ever sent money?I use bank web site most of the time. But if not at home, it is really useful to use phone. It isn’t like banking is complicated that need computer and browser. Bank web sites tend to be awful on smaller screens, I don’t use it on iPad. Also, there are a lot of people that only have phone. reply bitsandboots 18 hours agorootparent> Have you never needed to transfer money when traveling or out of houseNo? It can wait for me to return home. Before wireless internet existed this wasn&#x27;t an issue, so how has that changed things?> If US, have you ever mobile deposited a check?I admit this was literally the only time I used banking apps, but nobody uses checks anymore. I haven&#x27;t needed to do this in years.> If rest of world, have you ever sent money?Yup, paypal website. Don&#x27;t even need the app. Works better than venmo etc because it works internationally and various competitors that are app-only only work in 1 country anyway. reply izacus 18 hours agorootparentprev> I&#x27;ve always thought so too - who is banking on their phone?Most people these days. reply seized 17 hours agorootparentprev... Who isn&#x27;t banking on their phone? That&#x27;s how I do it 90% of the time. reply charcircuit 18 hours agoparentprev>In order to have a \"certified\" device you need to remove user control.No, you don&#x27;t.>For example users by default aren&#x27;t even allowed to access app&#x27;s \"private\" data.Which is already what Android&#x27;s security model specifies. It means that other apps or other people using your phone won&#x27;t be able to steal data like your 2FA app&#x27;s private key.>Those apps want to make sure that the user isn&#x27;t in control of their devices, they want to make sure Google or a \"trusted party\" is.Their app may benefit, or even rely on the android security model. Unverified devices have the possibility of having that security model broken.>If Google really wanted to prove security with SafetyNet they would stop attesting devices that haven&#x27;t been updatedI agree, but there is a trade off where you will cut out old devices. This is why at first Google lets app developers choose if they want to avoid devices that can just be spoofed. reply zb3 17 hours agorootparent> Which is already what Android&#x27;s security model specifies.Which means removing user control over that data.> Unverified devices have the possibility of having that security model broken.Again, this \"security model\" implies removing user control. The apps protect user&#x27;s data from that user.. reply charcircuit 15 hours agorootparentNo user control is being removed. The data was managed by the app by design.There is no way for the phone to know who owns the device, nor would it be able to know that when ownership is transferred to not show sensitive information to the new owner. reply feanaro 11 hours agorootparentLet&#x27;s not pretend to be daft. The user can prove ownership by providing a PIN. They can also delete their data before transferring ownership to a new owner. (Not to touch at all upon the fact that selling devices is really uncommon to begin with.)Nothing about any of that requires the user to cede control of their own device as a \"solution\". reply charcircuit 8 hours agorootparentIf the user writes down the PIN a person that is not the owner can use that PIN despite not being the owner. replyajross 18 hours agoparentprev> They say this is to ensure the security of your device that logs into your bank or whatever, but I guarantee that my LineageOS updated this week is more secure than my stock Google ROM that got its last update 3 years agoThose are two entirely different threat models. The second clause of your sentence is about vulnerability to exploits, something that Lineage or other ROMs are at least better positioned to do than a vendor that has EOLed the device (though the amount of binary junk required by those distros puts a pretty firm cap on that promise -- they can only fix what they can patch!).The first clause talks about the need for back end service providers to be sure that no entity is interposted between them and their users&#x2F;customers. It&#x27;s a desire that no extra app can sit there and sniff interaction or prompt for passwords&#x2F;tokens&#x2F;secrets&#x2F;etc... Third party open ROMs not only fail to address this need, they actively hurt. You can trivially make a \"We&#x27;re Totally Your Bank We Swear\" app and deploy it to a LineageOS phone that steals the money from any account that authenticates with it.Is that a \"good\" security model or a \"bad\" one? There are arguments to be had. But prompt application of bug patches isn&#x27;t one of them. reply dvngnt_ 19 hours agoprevthe more they move towards apple levels of control, the less reason people have to sick with android. reply shortrounddev2 19 hours agoparentI use android because I dislike the Apple ecosystem and UI design. They could disable all side-loading of apps and I would still use Android because I just don&#x27;t use mobile as my primary driver. For me, phones are for texting and browsing Reddit while I shit. reply hbn 19 hours agorootparent> I just don&#x27;t use mobile as my primary driver. For me, phones are for texting and browsing Reddit while I shit.That&#x27;s the reason I use an iPhone. I don&#x27;t need a bunch of customization and homescreen tinkering, I just want a thing that gets the job done and is easy to troubleshoot. reply seized 18 hours agorootparentBut you don&#x27;t HAVE to do those things on Android.... My Pixel is exactly that, gets the job done without problems or fuss. reply shortrounddev2 18 hours agorootparentprevI want the same thing, but which also isn&#x27;t an Apple product reply bitsandboots 18 hours agorootparentIt really makes me think... should we all have bought into blackberry&#x2F;palm&#x2F;windows&#x27; smartphone efforts in the 2010s? They seemed inferior at the time but, in hindsight, it&#x27;s hard to imagine anything worse than where we are now. reply shortrounddev2 18 hours agorootparentThe Nokia Lumia 1310 was the best phone ever made. Best UI, best screen and Camera of its generation, and you could program apps in C# for UWP so they ran on Desktop or Mobile (For that reason, there are still hobbyists who sideload new apps on their Lumias since the SDK still exists and works on modern windows). Like all things, Microsoft made the best version of the product, but not the most successful version reply diogenes4 19 hours agorootparentprevHah, I have exactly the opposite reaction as you: I think Android is a complete mess in terms of usability.The big differentiator, though, is your social network. Having iMessages and FaceTime is about 95% of the value of the phone&#x2F;tablet for me because my friends heavily, heavily use them. reply shortrounddev2 19 hours agorootparentI use Line (kind of like a Japanese&#x2F;Korean whatsapp) to communicate with my wife&#x27;s family (Wife, sisters in law, mother in law), I use Facebook to communicate with my parents, and I don&#x27;t have any friends to communicate with on other platforms, so I don&#x27;t miss iMessage (maybe I don&#x27;t have friends because I don&#x27;t have iMessage).Otherwise the apps define most of the UI. Android is basically an app launcher to me. reply gambiting 16 hours agorootparentprevI think it&#x27;s the case of knowing what you know. IOS design language depends a lot on being familiar with iOS already - I think a lot of Android design is dictated to be understandable by people who really haven&#x27;t used a phone before so things are a bit clearer and more obvious. I know when I use my wife&#x27;s iPhone it&#x27;s so frustrating because it feels like you should be able to do action X but there isn&#x27;t any clear way on how to achieve it - I ask my wife and she shows me that it&#x27;s hidden behind some invisible menu or gesture and I&#x27;m like \"how were you supposed to know this???\" And she just shrugs \"it always worked like this\". Ok, I guess, but that&#x27;s really poor for discoverability. reply toolz 19 hours agoparentprevnot sure how typical I am, but I don&#x27;t buy android for really any other reason than I can get brand new smartphone that does everything I want for under $200 and has multiple sim slots (which makes international travel much easier)At this point apple or anyone else would have to beat the cheap android handily for me to consider switching and that seems like a tough market to beat. I&#x27;m always impressed by how well cheap androids work when compared to their 3-4x more expensive counterparts. reply jackdh 19 hours agorootparentYou can pick up second hand ( good condition ) iPhone&#x27;s for not much more. I would also then argue iPhone&#x27;s last longer and tend to get more updates for longer than their android counterparts.They can support multiple ESim&#x27;s now which I&#x27;ve had fantastic experience with when travelling abroad. Apps like Ubigi make it super easy to switch to a local sim. reply mrguyorama 19 hours agorootparentThe problem with used iPhones is that the hardware is still powerful enough to run modern iOS, the battery only has about a year left to live so unless you budget in a battery replacement, you&#x27;re basically tethered. This may finally be clearing up, but Apple&#x27;s iPhone batteries from the previous decade were abysmal and had no headroom for aging. That&#x27;s why they were doing the stupid downclocking of older iPhones, because the battery could no longer deliver the power to run full bore without browning out. reply simiones 19 hours agoparentprevLots of people choose Android entirely unrelated to control - especially as this change apparently only affects users of rooted Android devices, which are an extremely small minority of Android users. Other reasons include price, interop with other non-Apple devices, and just a preference for the usability of Android vs iOS. reply CatWChainsaw 8 hours agoparentprevBut phones are a duopoly for the average person. What would they leave android for? reply GenericDev 19 hours agoprevI&#x27;m so sick of this.I don&#x27;t feel like I own my devices anymore. reply exabrial 18 hours agoparentDon&#x27;t worry, you don&#x27;t. Just wait until they lobby and make it illegal do to do so! This will come under one of the following guises:1. Save The Children2. Save The Planet3. Save the Tax revenue4. Anti-Terrorism reply jeroenhd 18 hours agoparentprevWhy not buy a phone with known good LineageOS support if you&#x27;re afraid Google may update your phone? You can audit and compile the entire OS yourself and disable any CA certificates you may dislike. reply GenericDev 7 hours agorootparentOr. Hear me out. Why don&#x27;t these companies actually give me back the ability to control my devices? Why is the onus on me? Why don&#x27;t these fuckers do the right thing. So tired of this what-aboutism bullshit. reply jeroenhd 1 hour agorootparentYou&#x27;re buying their phones, not the phones of companies that give you full control. Most customers care more about not having to wonder about security than about having the ability to flash a new kernel.Show companies that there&#x27;s money to be made by buying devices to your liking or you&#x27;ll be subject to design decisions made for the vast majority of customers. Why should companies care about your specific wishes over everyone else&#x27;s if you&#x27;re not putting your money where your mouth is? They exist to make money, they&#x27;re no government or charity.Everybody has been screaming at Google about how Google can&#x27;t keep Android up to date since Android 2.1 launched. The geneewl comsensus is that if you wqnt updates and security, you need to buy an iPhone. They&#x27;re finally fixing this problem but every step along the way the percentage of a percentage complains that they&#x27;re the victim of Google&#x27;s conspiracy. reply varispeed 19 hours agoprev [–] Obviously governments can&#x27;t have an operating system where users can do as they please, e.g. bypassing government mandated MITM certificates so they can spy on citizens.So the groundwork is being prepared for coming things like Online Safety Bill here in the UK, where all communication will likely be under surveillance and so you won&#x27;t be able to mod your phone to \"opt out\".It&#x27;s a shame that such resourceful company like Google bends over to some control-freak right wing governments like we have. reply jeroenhd 18 hours agoparentKazakhstan actually tried a government mandated CA certificate. It&#x27;s causing constant \"you are being watched\" notifications on phones that loaded the certificate. Certificate security was increased in Andeoid and other opeeating systemsm exactly because of this threat.Every OS except Android receives regular CA updates, including them various Linuxes. Android devices are still trusting known bad actors like Startcom exactly because there&#x27;s no way to update just the CA store (and cheap Chinese brands definitely won&#x27;t release full system updates for this after dropping support a year after the phone came out).You can disable the toggle for every system CA in your phone&#x27;s settings if you want. That is, unless you think the big bad UK government bugged your phone to hide the CA that&#x27;s been planted there, but if that&#x27;s part of your threat model, the government certificate may be hidden on your phone already reply surajrmal 19 hours agoparentprevIt&#x27;s strange that you jump straight to thinking the government is involved. Moving most system components to be updatable independently of the core os is a good thing. Google should be taking these steps. Not being able to update apex files makes sense as any update will quickly overwrite your changes.This change just moves the bar for modification to be controlling the remote update source. I&#x27;m sure it will still be possible to alter that and therefore gain control. This would be similar to how you handle DNS. reply LocalH 19 hours agoparentprev> It&#x27;s a shame that such resourceful company like Google bends over to some control-freak right wing governments like we have.Why wouldn&#x27;t they? They obviously see an opportunity to grab even more control over the Internet than they already have. reply SpaghettiCthulu 19 hours agoparentprev [–] Do you consider the Democrats right-wing? How about the CCP? Authoritarian, sure, but there is authoritarianism on both ends of the political spectrum. reply cumshitpiss 19 hours agorootparent [–] American democrats would be considered right wing in other nations e.g. europe replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Android 14 restricts the ability to alter trusted certificates even on rooted devices, aiming to increase security by enabling Google to revoke the trust of problematic certificate authorities.",
      "This move could impact privacy, impede the adoption of new certificates, and cause difficulties for new certification authorities like Let's Encrypt.",
      "As a workaround, users can use Android 13 for debugging HTTPS traffic and HTTP Toolkit for examining and debugging Android traffic while alternative solutions for network traffic interception on Android are being discussed."
    ],
    "commentSummary": [
      "Dialogues cover a range of tech topics, including Android 14 changes that prevent system certificate alteration, secure communication and authentication for banking applications, and the utilization of cardTAN for authentication.",
      "There's discussion around challenges with closed-source software, restrictions imposed by tech companies, the future of open hardware, HTTPS privacy issues on iOS, and the effects of Android 14 on Let's Encrypt certificates and user CA certificates on Android devices.",
      "Topics also include potential implications of hardware attestation, compatibility of rooted devices with apps/services, varying operating systems' control and security, and concerns on governmental surveillance and control, illustrating the friction between security, control, and user freedom in the tech sphere."
    ],
    "points": 307,
    "commentCount": 226,
    "retryCount": 0,
    "time": 1693921377
  },
  {
    "id": 37390184,
    "title": "A currently maintained fork of SSHFS",
    "originLink": "https://github.com/deadbeefsociety/sshfs",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up deadbeefsociety / sshfs Public forked from libfuse/sshfs Notifications Fork 460 Star 299 Code Issues 6 Pull requests 1 Actions Projects Security Insights deadbeefsociety/sshfs main 5 branches 38 tags Go to file Code This branch is 37 commits ahead of libfuse:master. #9 Latest commit h4sh5 new report link for issues 1 23b94a5 Git stats 453 commits Files Type Name Latest commit message Commit time .github/ISSUE_TEMPLATE Fix script issues identified through shellcheck (libfuse#258) compat Fix script issues identified through shellcheck (libfuse#258) test updated from old-style decorator: https://docs.pytest.org/en/latest/d… utils Add support for mounting from /etc/fstab .appveyor.yml Add AppVeyor CI for Cygwin .dir-locals.el Added .dir-locals.el to setup correct indentation in Emacs .git-blame-ignore-revs add .git-blame-ignore-revs (libfuse#261) .gitignore Added build/ to gitignore. .pre-commit-config.yaml Fixup whitespace and configure CI to keep it that way .travis.yml Fixup whitespace and configure CI to keep it that way AUTHORS Released 3.7.3 COPYING Update COPYING ChangeLog.rst Released 3.7.3 README.md new report link for issues cache.c Fixup whitespace and configure CI to keep it that way cache.h Switch to libfuse 3.0. justfile Run black on python test files make_release_tarball.sh Fixup whitespace and configure CI to keep it that way meson.build Released 3.7.3 sshfs.c better debugging visibility by hex dumping iovs sshfs.rst Merge branch 'master' of https://github.com/g-easy/sshfs README.md This is a currently maintained fork of SSHFS SSHFS (original repo: https://github.com/libfuse/sshfs) has been declared to be unmaintained and it breaks our heart. So me and some friends have decided to fork it and give it some love. There's a rust fork in progress by Greg Shuflin (https://github.com/neunenak/sshfs/tree/rust). Rust is a modern and memory safe programming language, and in the long term, it's not a bad decision to port it to rust. However, there are some downsides to Rust, such as it being still a young language, unstable API changes, it not having a standard specification yet, and long and compute-intensive compilation process etc. So from a maintenance perspective, we are just here to fix issues, merge PRs, and give this project some love until the rust fork is ready (maybe even backport changes/features from there for a period of time). Everyone is welcome to create issues or PRs, please do contribute! SSHFS About SSHFS allows you to mount a remote filesystem using SFTP. Most SSH servers support and enable this SFTP access by default, so SSHFS is very simple to use - there's nothing to do on the server-side. Development Status SSHFS is shipped by all major Linux distributions and has been in production use across a wide range of systems for many years. However, at present SSHFS does not have any active, regular contributors, and there are a number of known issues (see the bugtracker). The current maintainer continues to apply pull requests and makes regular releases, but unfortunately has no capacity to do any development beyond addressing high-impact issues. When reporting bugs, please understand that unless you are including a pull request or are reporting a critical issue, you will probably not get a response. How to use Once sshfs is installed (see next section) running it is very simple: sshfs [user@]hostname:[directory] mountpoint It is recommended to run SSHFS as regular user (not as root). For this to work the mountpoint must be owned by the user. If username is omitted SSHFS will use the local username. If the directory is omitted, SSHFS will mount the (remote) home directory. If you need to enter a password sshfs will ask for it (actually it just runs ssh which asks for the password if needed). Also many ssh options can be specified (see the manual pages for sftp(1) and ssh_config(5)), including the remote port number (-oport=PORT) To unmount the filesystem: fusermount -u mountpoint On BSD and macOS, to unmount the filesystem: umount mountpoint Installation First, download the latest SSHFS release from https://github.com/libfuse/sshfs/releases. You also need libfuse 3.1.0 or newer (or a similar library that provides a libfuse3 compatible interface for your operating system). Finally, you need the Glib library with development headers (which should be available from your operating system's package manager). To build and install, we recommend to use Meson (version 0.38 or newer) and Ninja. After extracting the sshfs tarball, create a (temporary) build directory and run Meson: $ mkdir build; cd build $ meson .. Normally, the default build options will work fine. If you nevertheless want to adjust them, you can do so with the mesonconf command: $ mesonconf # list options $ mesonconf -D strip=true # set an option To build, test and install SSHFS, you then use Ninja (running the tests requires the py.test Python module): $ ninja $ python3 -m pytest test/ # optional, but recommended $ sudo ninja install Getting Help If you need help, please ask on the fuse-sshfs@lists.sourceforge.net mailing list (subscribe at https://lists.sourceforge.net/lists/listinfo/fuse-sshfs). Please report any bugs on the GitHub issue tracker at https://github.com/deadbeefsociety/libfuse/issues. Packaging Status About A network filesystem client to connect to SSH servers Resources Readme License GPL-2.0 license Activity Stars 299 stars Watchers 4 watching Forks 460 forks Report repository Releases 38 tags Packages No packages published Languages C 84.8% Python 11.5% Shell 1.7% Meson 1.6% Emacs Lisp 0.4% Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37390184",
    "commentBody": "A currently maintained fork of SSHFSHacker NewspastloginA currently maintained fork of SSHFS (github.com/deadbeefsociety) 301 points by feldrim 22 hours ago| hidepastfavorite128 comments zitterbewegung 20 hours agoIf you want something in user land and you don&#x27;t mind emacs there is TRAMP “Transparent Remote (file) Access, Multiple Protocol”. https:&#x2F;&#x2F;www.gnu.org&#x2F;software&#x2F;tramp&#x2F;I use it a lot when I am accessing files from my server on my MacBook Pro . reply Zambyte 18 hours agoparentMy favorite thing about using TRAMP is being able to cd to a directory on a remote system, and then cp a file either from my working directory to my local machine (or another remote!), or from my local machine to the current working directory.Before I started using TRAMP, my flow for this was: SSH to a remote system, locate where I want to copy a file to with cd + ls, kill my SSH session, and then scp or rsync the file over, and then usually SSH back into the system. reply kpw94 15 hours agorootparent> kill my SSH session, and then scp or rsync the file over, and then usually SSH back into the system.Naive question: why the need to kill the ssh session? Can&#x27;t you just open another terminal window or tab (or tmux&#x2F;screen tab if that&#x27;s part of your workflow) reply rzzzt 11 hours agorootparentI usually type ~ followed by ^Z to suspend the session for a quick scp operation, then resume with \"fg\". reply Zambyte 13 hours agorootparentprevThat&#x27;s also a way to do it. I prefer TRAMP over both ways though. reply shric 13 hours agorootparentprevNot the GP, but I assume it&#x27;s just because the ssh swssion is no longer needed -- it was only required to locate the file. reply wolletd 13 hours agorootparent> and then usually SSH back into the system. reply koito17 14 hours agorootparentprevTRAMP is amazing. Whenever I need to edit configuration files or code on a remote server, I get to keep the exact same Emacs setup as if I were doing things locally. There are noticeable delays in opening and saving files on slow connections, but it&#x27;s good enough that I can&#x27;t remember the last time I have used nano or vi in a remote server. reply lmm 11 hours agorootparentprevCouldn&#x27;t you use zmodem or something? reply jlarocco 11 hours agoparentprevFWIW a lot (most?, all?) of Emacs features work transparently with Tramp, including dired, eshell, and magit. reply jmclnx 20 hours agoprevInteresting, I alaways assumed sshfs was part of OpenSSH, learn something new every day.Also, looks like sshfs used in Slackware is abandoned.https:&#x2F;&#x2F;github.com&#x2F;libfuse&#x2F;sshfsA quote from the link, I wonder if this project will be the &#x27;one&#x27;:>If you would like to take over this project, you are welcome to do so. Please fork it and develop the fork for a while. Once there has been 6 months of reasonable activity, please contact Nikolaus@rath.org and I&#x27;ll be happy to give you ownership of this repository or replace with a pointer to the fork.I also wonder if it was abandoned due to the RHEL re-orgs like what happened to bluetooth. reply SubiculumCode 20 hours agoparentIt does seem like a good fit for the maintainers of openssh. I too had thought it was key linux ssh infrastructure. reply frutiger 20 hours agorootparent> I too had thought it [OpenSSH] was key linux ssh infrastructure.As a side note, OpenSSH is quite independent of the Linux ecosystem. It is developed as part of OpenBSD.openssh-portable is provided as a standalone software package that is broadly POSIX-compliant. reply jmclnx 20 hours agorootparent>openssh-portable is provided as a standalone software package that is broadly POSIX-compliant.Yes, glad the OpenBSD folks do this. Linux people could learn a lot from OpenBSD Developers (looking directly at Wayland). reply soraminazuki 18 hours agorootparentI think Wayland is a different beast because unlike SSH, it involves the kernel. reply epcoa 18 hours agorootparentprevNo it’s a horrible fit. OpenSSH is focused on a high quality, secure implementation of a rather complex protocol. And OpenSSH is not a core piece of Linux infrastructure any more than say gcc is. These projects serve other, greater ends. A FUSE driver is a bunch of baggage that is poorly suited to be maintained with it. reply fragmede 13 hours agorootparentGiven than fusefs provides FUSE support on BSDs, it seems more than \"a bunch of baggage\", given how useful it is. reply jjrh 10 hours agorootparentI don&#x27;t think the person was intending to say it&#x27;s not useful, only out of scope. reply mrweasel 18 hours agorootparentprevI kinda doubt it, SSH already have SFTP and SSHFS is .... quite honestly a tool that has no business existing.It&#x27;s a neat trick but it&#x27;s always going to be something that someone bolted on to a solution because they didn&#x27;t want to deal with a proper file server. Part of the appeal might be that NFS (3 or 4, take your pick) is still the best we&#x27;ve been able to come up with and neither is really that great for basic installation. Still SSHFS is a mess to deal with in a production setup. Some of the messiest production systems I&#x27;ve de-tangled over years have frequently been relying on SSH and SSHFS to do stuff assumes a permanent connection. reply johnvaluk 16 hours agorootparentSSHFS provides enormous value precisely because it doesn&#x27;t rely on configuring a file server or elevated privileges. It&#x27;s convenient, secure and performs well. The ability to create ad hoc mounts for any remote location I can access via SSH is awesome (though I prefer rsync or scp for file transfers).But relying on SSHFS in production... Yeah, that&#x27;s insane. reply jmclnx 8 hours agorootparentI use sshfs at work to mount some AIX Dirs on my Linux Workstation, very convenient. reply fragmede 13 hours agorootparentprevNFS has too many shortcomings for me to take your answer seriously. SSHFS is a very useful tool in the right places; if it&#x27;s a hammer and you have a screw, don&#x27;t use it. reply barrkel 12 hours agorootparentprevsftp doesn’t make it easy to copy files from one place to another on an ad hoc basis while developing, using the shell operations you’ve got to hand. reply rsync 19 hours agoprevA note …I have transitioned from years of macfuse + sshfs on Mac to just installing the excellent “mountain duck” tool which gives you finder and mount point access to an sftp endpoint.Very nice software and indispensable for me. reply ics 15 hours agoparentAs a recently returned rsync.net customer, I was a bit surprised to peruse the docs and see that Fuse&#x2F;sshfs is still up as a recommended option for Mac integration (see https:&#x2F;&#x2F;www.rsync.net&#x2F;resources&#x2F;howto&#x2F;mac_sshfs.html). A few months ago this led me down the path of trying ExpanDrive&#x2F;StrongSync, but this is the first I&#x27;ve heard of Mountain Duck (love Cyberduck though). I&#x27;m looking forward to giving it a spin now but if it has been working well for you please consider updating this page for others. Happy customer otherwise! reply mbirth 8 hours agoparentprevJust for the record: for macOS there’s now https:&#x2F;&#x2F;www.fuse-t.org&#x2F; which works without a kext (by spawning a local NFS server in the background and having macOS connect to it) and also has a sshfs implementation listed on https:&#x2F;&#x2F;github.com&#x2F;macos-fuse-t&#x2F;fuse-t&#x2F;wiki#sample-filesyste... . reply jmspring 14 hours agoparentprevMountain Duck has been my goto as well. That said, for VSCode the Remote SSH extenion from Microsoft helps greatly in working with repositories on VMs and other remote machines.Libfuse &#x2F; SSHFS for MacOS started becoming a real burden to try and use a ome years back and it lead me to mountain duck as well. reply qbane 19 hours agoprevI think SFTP is a good but underrated protocol, when mirroring a file tree bidirectionally makes more sense than cloning one to another. Having forked and studied from SSHFS&#x27; code, I am currently maintaining a list of resources and some personal thoughts on https:&#x2F;&#x2F;hackmd.io&#x2F;@q&#x2F;sftp-over-ws. reply arthur2e5 4 hours agoparentSFTP is a major step up from FTP, but there&#x27;s a lot of unrealized potential on the server side, so you can&#x27;t just work on better clients. Both OpenSSH and the GNU lsh server only offer an old version of the protocol -- v2, I think. That oldness is intentional: https:&#x2F;&#x2F;marc.info&#x2F;?l=openssh-unix-dev&m=168488976013498&w=2 reply dontcontactme 19 hours agoprevsshfs is no longer maintained? That&#x27;s sad, I used sshfs in school to be able to use my zillion vim plugins to edit code without having to install them all on the remote server we used for compute. I was surprised with how smooth of a system it was. reply kiririn 21 hours agoprevrclone mount is my go-to now for sshfs functionality - better performance, stability and caching options reply remram 2 hours agoparentrclone cannot write to the middle of a file though, without transferring the whole file. That is my main issue with it. Maybe sshfs has the same limitation though. reply madacol 21 hours agoprevNautilus (Ubuntu&#x27;s file explorer) allows to mount SFTP folders. Supposedly it uses `gvfs` under the hood.Note that SFTP uses an SSH connection for its file transfers, so I have not seen an UI difference from SSHFS reply rsync 19 hours agoparentIt allows you to browse sftp endpoints in the nautilus GUI but does it simultaneously create a mount point in the file system that you could use in the terminal?I don’t remember… reply chriswarbo 17 hours agorootparentYou can use the `gio mount` command to mount a given remote. It will appear as a folder in `&#x2F;run&#x2F;user&#x2F;$UID&#x2F;gvfs`.As an example, my phone has some systemd services which run `gio mount` for an SMB share and an SFTP share, when I&#x27;m connected to my home WiFi. I&#x27;ve got symlinks in my home folder to their associated gvfs directories, which become dangling when I&#x27;m not at home. reply ktpsns 18 hours agorootparentprevgvfs has a bridge to fuse, cf. https:&#x2F;&#x2F;manpages.ubuntu.com&#x2F;manpages&#x2F;trusty&#x2F;man1&#x2F;gvfsd-fuse.... -- that means: Yes, you can use gvfs mounts natively in all other non-GNOME&#x2F;GTK-applications running on your computer. reply pantalaimon 18 hours agorootparentprev> does it simultaneously create a mount point in the file system that you could use in the terminal?Yes it does. You can find it in &#x2F;run&#x2F;user&#x2F;$(id -u)&#x2F;gvfs&#x2F; reply the-alchemist 20 hours agoprevAnyone try rclone or sshfs on Mac OS X with macfuse&#x2F;osxfuse? reply binarymax 19 hours agoparentI use sshfs with macfuse on my M1, and mount a drive to a linux box in my office. It&#x27;s mostly OK, but has its quirks. Getting it setup was a bit of an adventure, and I questioned myself a couple times - but I powered through and it worked out just fine. reply rsync 19 hours agoparentprevSee my top level comment elsewhere… the answer is “mountain duck”. reply blue1 19 hours agoparentprevsshfs works (I use Monterey, M1), though it&#x27;s slowish. reply artificialLimbs 14 hours agoparentprevI use Macfuse to localfolder all of my servers. Works great. Have a little script for each server: mount_fooserver.sh:umount -f ~&#x2F;mounts&#x2F;fooserversshfs -o kill_on_unmount,reconnect,allow_other,defer_permissions,direct_io username@server:&#x2F; ~&#x2F;mounts&#x2F;fooserver -ovolname=foo reply dtgriscom 9 hours agorootparentInteresting. I use> -o reconnect,cache=no,defer_permissionsSo, I add \"cache=no\"; and omit \"kill_on_unmount\", \"allow_other\" and \"direct_io\". Looks like \"kill_on_remount\" is a cleanup option; \"allow_other\" allows other users to mount the same drive (I don&#x27;t need that) and \"direct_io\" is similar to \"cache=no\". FYI... reply vmlinuz 20 hours agoprevIt&#x27;s obviously a slightly different combination of technologies, but I&#x27;ve been using NFS over wireguard pretty happily for a while... reply chasil 20 hours agoparentNFS is more graceful in reconnecting when the TCP channel is reset, which is a great benefit.It also implements more filesystem functionality, as a \"df\" report will correctly reflect the remote filesystem&#x27;s usage.EDIT: NFSv4 also offers \"delegations,\" which give complete control of a file to a client in an expiring lease; the latest NFS clients also have \"polite delegations,\" which tacitly extend the lease period.SSHFS is very handy for a \"quick and dirty\" mount, though, with minimal configuration. reply Borg3 18 hours agoparentprevI myself went to other way around. While my VPN infra is very stable, I went into repo route. I use my very simple DVFS repo utility to sync files and never looked back. I like to have multiple copies of stuff here and there. reply notpublic 19 hours agoparentprev+1Switched from sshfs to NFSv4+wireguard few years back. Works great! reply chrkl 22 hours agoprevUnfortunately, this fork does not look very vivid. Last commit in March, almost not activity in terms of PRs and issues. I would not bet on it. reply deadbunny 21 hours agoparentWhat sort of activity level are you expecting from a stable project? reply chaxor 20 hours agorootparentPeople have a hard time orienting if coming from js, where a &#x27;stable&#x27; project means refactoring the entire code base to keep up with the dependencies refactoring their apis every 2 months. reply n3storm 17 hours agorootparentprevplus, they are investigating old edgy errors in many issues, rescuing them (already closed) from the old project. reply computersuck 7 hours agoparentprev\"Vivid\" is the javascript definition of touching shit when it works and breaking it reply dfc 21 hours agoparentprevVivid? reply AnthonBerg 20 hours agorootparentDefinition 3: “Full of life, strikingly alive.”Etymology: “Borrowed from Latin vividus (“animated, spirited”), from vivere (“to live”), akin to vita (“life”), Ancient Greek βίος (bíos, “life”).”I like it!https:&#x2F;&#x2F;en.m.wiktionary.org&#x2F;wiki&#x2F;vivid reply bdsa 20 hours agorootparentprevA fairly unidiomatic rendering of \"lively\", I think. reply saurik 22 hours agoprev> The current maintainer continues to apply pull requests and makes regular releases, but unfortunately has no capacity to do any development beyond addressing high-impact issues.Assuming this is true--and I think it is fair to trust the author of the statement when judging the same author--this doesn&#x27;t sound like a project that needs a fork, as it apparently in fact does have an active maintainer; if you want to help contribute to sshfs, you thereby can do that without forking it and causing a mess for everyone having to decide which one to use&#x2F;ship and without the bad blood inherent in resorting to the four-letter F-word of open source project management. reply Macha 22 hours agoparentThat&#x27;s the old status before being orphaned. The latest note at the top of the readme in the original repo reads:> This project is no longer maintained or developed. Github issue tracking and pull requests have therefore been disabled. The mailing list (see below) is still available for use.> If you would like to take over this project, you are welcome to do so. Please fork it and develop the fork for a while. Once there has been 6 months of reasonable activity, please contact Nikolaus@rath.org and I&#x27;ll be happy to give you ownership of this repository or replace with a pointer to the fork. reply computersuck 7 hours agoprevIs it google summer of code or some similar event right now?Looks like the most recent issues and PRs are just junk typo &#x2F; grammar fixes reply hot_gril 17 hours agoprevI remember using SSHFS way back in the day on Mac, also back then thinking \"SSHFS\" meant \"SSH + HFS.\" It was always confusing to grab the right tools for it, and it never worked very well. With remote codebases, I just SSH in and edit in Vim. reply thecosmicfrog 22 hours agoprevThe main file is a C file which is nearly 5,000 lines long. Impressive.https:&#x2F;&#x2F;github.com&#x2F;deadbeefsociety&#x2F;sshfs&#x2F;blob&#x2F;main&#x2F;sshfs.c reply redleader55 21 hours agoparentTo me, 5000 lines of C is not impressive nor scary. Functions are pretty small, there are a lot of comments - everything seems like a normal unit with some complexity. reply the_duke 21 hours agoparentprevWell... check out QuickJS: the bulk of the code is in a single 55k LOC C file: https:&#x2F;&#x2F;github.com&#x2F;bellard&#x2F;quickjs&#x2F;blob&#x2F;master&#x2F;quickjs.c reply acheong08 21 hours agoparentprevBoth impressive and scary reply crabbone 20 hours agoparentprevThis is nothing extraordinary. I don&#x27;t know why this is a tradition, but this is a very typical situation for C projects. reply unilynx 18 hours agorootparentCompilation used to be slower, and one 5K line file would be noticeably faster than 10 500 line files, not to mention possibly having to build extra header files to connect them together. That would encourage larger files. reply JoeAltmaier 18 hours agorootparentI&#x27;m not sure that&#x27;s true. Computers used to be smaller, and had a hard time with very large files. Swapping out of limited RAM and so forth. Not fast.I think long files are solely caused by somebody incapable of software design at any level. They just keep typing and never think about structure or separation of duties or whatever.I recall the WindowsCE DHCP service was one large file. An enormous busted-ass straightline pile of garbage code that didn&#x27;t handle most errors. Written by some intern. I re-wrote it for our platform and removed all the issues.Microsoft of course didn&#x27;t want my code because, arrogance. reply hot_gril 17 hours agorootparentprevAs a n00b, I enjoyed libs with everything in one file cause I didn&#x27;t know how to drop the lib into my codebase and build otherwise. Like how was I supposed to merge their makefile into mine, I dunno. And my code was in one file cause I was too lazy to mess with .h files. reply crabbone 16 hours agorootparentprevI could buy a similar argument for directories: you will almost never see a C project with sources in subdirectories of the top-level source directory -- this is because of the recursive Makefiles which earned quite a bit of a somewhat justifiable hate.But I don&#x27;t think compilation times explain the size of the source files. This hasn&#x27;t been a problem for such a long time that I cannot even remember when it could have possibly been a problem.I had seen the reverse problem, but not with C... rather with Python source files. The older parser used to be very bad and would start using too much memory if the source file was in the thousands of LOC. I had to witness this firsthand with SWIG-generated Python bindings. I don&#x27;t remember this kind of problem with C compilers &#x2F; other utilities though. reply MisterTea 18 hours agoparentprevThe plan 9front version is only 1431 lines long.https:&#x2F;&#x2F;github.com&#x2F;9front&#x2F;9front&#x2F;blob&#x2F;front&#x2F;sys&#x2F;src&#x2F;cmd&#x2F;sshf... reply moontear 20 hours agoprevHow are the different packages for the different *nix distros maintained? I see the link to repology, but that service only tracks the packages - who created the packages and where are they generated in the repo? reply feldrim 15 hours agoprev> This repository has been archived by the owner on May 26, 2022. It is now read-only.> This project is no longer maintained or developed. Github issue tracking and pull requests have therefore been disabled. The mailing list (see below) is still available for use.If you would like to take over this project, you are welcome to do so. Please fork it and develop the fork for a while. Once there has been 6 months of reasonable activity, please contact Nikolaus@rath.org and I&#x27;ll be happy to give you ownership of this repository or replace with a pointer to the fork.I saw that there are some semi-active forks focusing on different aspects: a rust rewrite, a persistent cache support version, or a bug fixing only version.The issue is that most software has bugs and vulnerabilities which has not been discovered yet while the software is not maintained. It means the problems will exist without a solution for the future. Open source software maintainers have been a significant part of our overall IT environment [0] but voluntary contributions are subject to human resource limits. SSHFS is one of those projects relying on a single maintainer which has ended up being archived. The packages on many distributions repositories are stuck as is. The several semi-active forks are also owned by a single person without a proper community. I&#x27;m not sure if any of the distro communities would pick one of those and package it to be the next version.So, the users of these software on their own, with the single, cross platform, ultimately portable packaging solution: the source code.0. https:&#x2F;&#x2F;xkcd.com&#x2F;2347&#x2F; reply fyrabanks 4 hours agoparentI have nothing but respect for Nikolaus, and SSHFS is absolutely a cornerstone of IT, but if you think the original project was protecting you from vulnerabilities.. I have a bridge to sell you.I also don&#x27;t really understand what your last sentence is getting at--I may be daft. reply feldrim 4 hours agorootparentIt may be my bad wording. All I am saying is that an archived and unmaintained project leaves the option of fixing bugs and vulnerabilities out. The hope is lost with no effort of fixing. And this is inevitable with current open source models. reply fyrabanks 1 hour agorootparentYeah, I get what you mean. I&#x27;m doubtful, but.. hopefully this turns out OK. reply blueflow 22 hours agoprevGood, it seems people can&#x27;t stand it if software just exists and does its job and doesn&#x27;t get new commits each month. reply londons_explore 22 hours agoparentI mostly care if projects don&#x27;t accept bugfixes. For example \"inotify feature longer works with the latest glibc release due to subtle API change\" might be an easy 10 line pull request to fix.But if the maintainer doesn&#x27;t take the pull request and make a release, then the effort of fixing it is wasted, and every single user has to workaround&#x2F;suffer from that bug into the future.There are loads of projects in that state - unmerged PR&#x27;s from years ago with sensible fixes, no new release, and no forks that are distributed to users. reply Aachen 22 hours agorootparentNot to mention this scenario except when it&#x27;s a security patch that just needs to be applied and released reply londons_explore 22 hours agorootparentprevI wish github and other code hosters made it easier to \"just make a release\".Next to the \"Download zip\" button on github, they should add a \"Download built .deb\" and \"Download built .exe\" - and those buttons should work on any fork, branch, PR, etc. And they should add all the necessary build infrastructure to achieve that.It turns out that at scale, build infrastructure is pretty cheap to run, since caching is so incredibly effective and there is only a need to rebuild a file once per (human) edit to a file or its dependencies. reply _joel 21 hours agorootparentMaking a .deb isn&#x27;t as simple as it might seem. If you want to use shared libraries, especially so. Which version of Ubuntu&#x2F;Debian&#x2F;Mint&#x2F;... whatever are you targetting? You can tools like FPM[1] (which is awesome btw, used it for some great hacks in the past), but that won&#x27;t make you .debs that are necessarily done to the debian guidelines but usable.There are a load os SaaS companies that do that allow you to make multiple targets though, so perhaps some integrations there would work.[1]https:&#x2F;&#x2F;github.com&#x2F;jordansissel&#x2F;fpm reply londons_explore 21 hours agorootparentPresumably some kind of Makefile or similar build automation config file would be in the repo to define which versions of which tools to use to do the build. reply pnutjam 20 hours agorootparentprevhttps:&#x2F;&#x2F;openbuildservice.org&#x2F;help&#x2F;manuals&#x2F;obs-user-guide&#x2F;cha... reply em-bee 21 hours agorootparentprevthe open build service (by suse) does that. are there others? reply _joel 19 hours agorootparentI&#x27;m certain there are more but I can only think of artifactory now and not sure that even makes the debs (does the repo stuff). Maybe there&#x27;s a business plan somewhere in there :) reply chriswarbo 16 hours agorootparentprevThat sounds more like papering over the cracks of legacy systems, introducing even more centralisation and power to a handful of unaccountable \"hosters\", and placing even more responsibilities on maintainers (who may be AWOL).- Cryptographically-verified, content-addressed storage (e.g. IPFS) is preferable to downloading random EXEs from \"github and other code hosters\". Indeed, for sources too! (I learned this lesson when Microsoft bought GitHub, and many projects jumped ship; that caused an outbreak of 404s for anything that was hard-coding github.com URLs!)- Rather than relying on someone else having produced opaque blobs for us, it&#x27;s better for everyone to be capable of building things, if needed. Nix (and Guix) are good for this, since they&#x27;re source-based, ensuring that the full build instructions are available (they will automatically download binaries, if available and signed by a trusted key; but the option of building ourselves is always there). This is also crucial if we want to validate those binaries for ourselves (I recall the \"trustix\" project is trying to crowd-source such validation too)- Another advantage of the Nix&#x2F;Guix approach is that build instructions can be parameterised, e.g. by the source. This allows anyone to plug in any version of the code they like (whether a git commit, or a local folder, or an IPFS URL, etc.). Again, if someone else has already built that combination (and someone we trust has signed it) then their existing binary will be fetched.This sort of approach doesn&#x27;t require any buy-in from hosting platforms, maintainers, DNS authorities, etc. reply pinusc 19 hours agorootparentprevWhen making a github release, you can attach whatever file you want, including .exe and .deb. The problem is that building packages is kind of a nightmare, as there&#x27;s at least one (or, as is the case far too often, many) build system for each programming language. Linux package management is also hard as each distro has its own way of packaging things. And you need a mac to produce macOS Applications...My point is, there is no way github could add a fully automatic \"build and package this release\" button. It would require tons of configuration (and trial and error...) from the user.But good news! If you _are_ willing to figure out how, you can make a github pipeline that compiles and packages your code (producing an \"artifact\"). Several projects I follow do exactly this. A complex problem like this essentially requires a bespoke solution, and to be fair github does give you tools to automate said solution. The problem is not the infrastructure but the complexity of build systems.I do agree there should be more ready-made pipelines to aid this process. When I tried to release a python program to work on linux, windows, and macOS, I quickly realized I wasn&#x27;t interested in figuring out how to make a working pipeline (after spending a weekend getting it to build on each OS in the first place). But surely that&#x27;s because python is particularly bad at package management... Well, most languages are particularly bad at it reply lmm 11 hours agorootparentBuilding packages is easy for most programming languages, it&#x27;s only very old ones and Python that are bad. While I wouldn&#x27;t expect GitHub to support every language, and many projects will need customization, them offering a basic pipeline for \"standard x\" for each of e.g. the top 20 languages (other than the awkward ones) would save a lot of effort over every project reinventing its own pipeline. reply _joel 22 hours agoparentprevI&#x27;d like software that connects to machine with write privileges, across network boundaries, to have some degree of maintenance, if that&#x27;s ok.It may not be just security too, as this integrates FUSE and SSH then there will be bitrot and API drift etc over the years. reply renewiltord 21 hours agoparentprevThe FUSE situation on Mac OS requires maintenance on the software or it will stop working. reply williamstein 20 hours agoprevRelated -- last month I wrote an implementation of something very similar to sshfs, but in Typescript over a WebSocket: https:&#x2F;&#x2F;github.com&#x2F;sagemathinc&#x2F;websocketfs reply Timshel 22 hours agoprev [–] Discovered that you can replace sshfs with rclone. And the project appear to be way more active : https:&#x2F;&#x2F;github.com&#x2F;rclone&#x2F;rcloneEdit: cf: https:&#x2F;&#x2F;rclone.org&#x2F;commands&#x2F;rclone_mount&#x2F; reply chriswarbo 17 hours agoparentUnfortunately `rclone mount` doesn&#x27;t support symlinks yet: it always deferences their contents. In contrast, SSHFS has options to either dereference them, or to use them as-is, or to transform absolute links into relative links (which may be more likely to resolve on the client) reply dpatterbee 19 hours agoparentprevI love rclone, I&#x27;m currently using `rclone mount` to mount a Backblaze B2 bucket to use as backing storage for Jellyfin and it works a treat. There are plenty of dials to tune things like cache size and duration to minimize unnecessary downloads from B2, and with my usage patterns it ends up astoundingly cost effective (although at some point I might move to Hetzner storage boxes for even cheaper storage). reply venatiodecorus 15 hours agorootparentthis seems really expensive compared to a local nas, at least over the lifetime of your service. is there a reason you chose to go this route instead of local storage for media? reply dpatterbee 15 hours agorootparentA local nas requires much higher upfront costs, I would need space to put it, and it requires much more ongoing maintenance and whatnot. If you factor the cost of my time it probably doesn&#x27;t really work out as cheaper. reply jetbalsa 18 hours agorootparentprevWasabi might been a good choice for you on that front reply FredFS456 18 hours agorootparentBackblaze B2 is $5&#x2F;TB&#x2F;month, Hetzner is $4.08&#x2F;TB&#x2F;month for 1TB, Wasabi is $6.99&#x2F;TB&#x2F;monthWasabi seems like the most expensive here, with the caveat that Hetzner requires ordering discrete steps of storage rather than the &#x27;pay-as-you-go&#x27; model of the other two reply ph4te 16 hours agorootparentThey are all OK to use, and each provider has pros and cons, depending on the use case.Hetzner is the cheapest; however, your data is stored in Germany or Finland. They have free bandwidth, but you are limited to 10 connections at a time.Backblaze B2 has 4 regions across the globe, storage is $5&#x2F;mo, there is no minimun retention time, but does have a cost for API Calls(transactions), and in addition charges for egress data(downloads), so your $5&#x2F;TB is a variable factor, and if you use your data, you may not achieve $5&#x2F;TB, the cost will grow depending on the use case(there are free levels of transactions and egress)Wasabi is $7&#x2F;TB and has 13 regions across the globe, with free egress and no api charges. It does have 90-day minimum storage charge, which means you are billed for every object for 90 days regardless of if you delete it before 90 days. In addition, the free egress has limits to prevent system abuse. There is a 30-day deleted storage charge available if you purchase in bulk with their RCS(reserved capacity) storage plan. It&#x27;s good if you want to store a lot of data that does not need deletion.I have accounts with all 3 of these for different use cases. reply mappu 10 hours agorootparentRegarding Hetzner Storage Box&#x27;s 10 connection limit, Hetzner also has Storage Share (Nextcloud hosting) at basically the same price point (~3 EUR&#x2F;TB at the 10TB+ size), only it comes with 200 connections. Rclone supports WebDAV for Nextcloud just as well. reply dpatterbee 15 hours agorootparentprevNote that in October B2 is removing egress costs and increasing storage prices to $6&#x2F;TB. reply Dylan16807 14 hours agorootparent* removing egress costs up to 3x your amount of stored dataI&#x27;m pretty disappointed overall by the price increase for storage. Compared to when they launched B2, they now need 1&#x2F;4 as many servers with 1&#x2F;2 the upfront cost to store each petabyte. reply vidarh 16 hours agorootparentprevDoesn&#x27;t Hetzner storage boxes also have lower redundancy guarantees? It&#x27;s been a while since I&#x27;ve looked, so not sure - it&#x27;s not obvious from their ordering page. They&#x27;re great either way, though, especially given the \"unlimited\" egress. reply jhvkjhk 20 hours agoparentprevrclone looks promising, but last time I tried it, it was very slow compared with sshfs. reply nickcw 20 hours agorootparentInteresting. I haven&#x27;t tried a speed comparison but I know we sped up the sftp backend recently. reply Filligree 19 hours agorootparentDoes the FUSE mount work on OSX? reply duped 18 hours agorootparentVFS on MacOS is a minefield. You either need to use a kext (bad option, for many reasons), a network file system (NFS or SMB) and pretend your VFS is a remote server, or create a FileProvider system extension (which cannot actually function as a VFS).If your workflow relies on a VFS that isn&#x27;t NFS&#x2F;SMB then don&#x27;t use MacOS. fuse-t is kind of clever in that it spins up a TCP server that transpiles NFS requests into FUSE requests, but it comes with a bit of a cost and eats a TCP port. The one benefit is that you can actually mount and use a file system entirely in userspace this way, which you can&#x27;t do on Linux without sandboxing (fusermount3 is SUID to get around this). reply callalex 17 hours agorootparent>but it comes with a bit of a cost and eats a TCP portI have never heard of someone running out of TCP ports on a personal computer since, well, the invention of TCP on personal computers. reply duped 15 hours agorootparentNo, but port conflicts do happen. reply lxgr 14 hours agorootparentprev> fuse-t is kind of clever in that it spins up a TCP server that transpiles NFS requests into FUSE requestsTIL, thank you!I&#x27;m really sad about losing native SSHFS capabilities on macOS (via FUSE, due to the kernel extension deprecation&#x2F;ban).I could even get behind the idea of banning all network file systems, but the fact that I can now use SMB and WebDAV(!), but not the one that I actually use all the time, is quite frustrating. reply tambourine_man 16 hours agorootparentprevMacFUSE always seems unbearably slow to me. Specially in the Finder. Has it improved?FUSE-T seems more future proof (no kext) and probably less likely to completely hang your Mac, but could potentially be even slower since it’s another abstraction layer in between.It’s odd that there aren’t any great open source SFTP solutions for the Mac. CyberDuck and FileZilla are barely passable. reply lxgr 14 hours agorootparent> less likely to completely hang your MacI think what hangs the Mac isn&#x27;t the remote file system as such, but rather some local app or (more likely) low-level OS service assuming that all mounted filesystems are local (or at least low-latency and highly available). reply tambourine_man 9 hours agorootparentThat too, but I remember having straight kernel panics. Granted, that was more than a decade ago. reply nickcw 19 hours agorootparentprevIt does. You can use it with macfuse or with fuse-t.See: https:&#x2F;&#x2F;rclone.org&#x2F;commands&#x2F;rclone_mount&#x2F;#mounting-on-macos reply rofo1 16 hours agorootparentprevIt does work, I use it regularly. However, it can hang the whole system in certain cases such as mount that went wrong, connection timeout between the servers (without -o reconect option on sshfs, but even with that sometimes). reply menacingly 18 hours agoparentprevrclone kind of drives me nuts not using standard ssh_config reply aidenn0 18 hours agorootparentNot just rclone, but it seems that so many things are moving away from using the ssh_config; I have things setup to \"just work\" for so many hosts with OpenSSH, and having to individually configure a half-dozen programs that build on top of SSH is a pain. Sometimes it&#x27;s because they use paramiko, other times it&#x27;s because they want to pass their own configuration options to ssh that mess things up.Sometimes you can manage to get things to use the ssh_config again (e.g. with xpra you can do \"--ssh=ssh\" but other times I&#x27;ve not yet figured a workaround. reply blueflow 18 hours agorootparentCan you name these programs? I want to add them to my &#x27;painful&#x27; list. reply aidenn0 16 hours agorootparentI only use programs for which I&#x27;ve found a workaround due to the pain, so I can&#x27;t list the ones that I don&#x27;t have a workaround for. TBF two of the programs (emacs tramp and git-annex) I use regularly actually mostly respect ssh_config by default, but they override the ControlMaster by default (to do their own connection muxing) which requires me to do an extra authentication step. reply menacingly 16 hours agorootparentprevjetbrains products. I think they&#x27;ve improved their situation, but it&#x27;s still a little quirky reply assbuttbuttass 18 hours agoparentprevI&#x27;m trying to use rclone, but it seems like it&#x27;s kind of hard to set up compared to sshfs. Do I really need to go through their 20 question setup script? reply remram 18 hours agorootparentYou can use connection strings [1] instead of a named remote that you setup ahead of time with the wizard. rclone mount :sftp,host=example.com:path&#x2F;to&#x2F;dir &#x2F;tmp&#x2F;mountpoint[1]: https:&#x2F;&#x2F;rclone.org&#x2F;docs&#x2F;#connection-strings reply soraminazuki 18 hours agorootparentprevYou could just edit rclone.conf directly. reply synergy20 21 hours agoparentprev [–] how so? rclone is more like scp to me only. reply carlhjerpe 21 hours agorootparenthttps:&#x2F;&#x2F;rclone.org&#x2F;commands&#x2F;rclone_mount&#x2F; reply elkhadiy 21 hours agorootparentprevMix up rclone&#x27;s mount with the Crypt and maybe even the Union backend to cloud storage for a very interesting proposition. I was using a similar setup to get unlimited storage on VPSes when google was offering unlimited gsuite storage. You just need to play around caching values and options on the Crypt side if you plan on streaming data from it. reply Timshel 21 hours agorootparentprevJust edited a link to the doc ^^ reply mrshadowgoose 21 hours agorootparentprev [–] rclone has a \"mount\" command. reply ape4 21 hours agorootparent [–] Sorry if this is documented (I did take a quick look). Does rclone mounted do whole file compression like rsync? I don&#x27;t see how the file API would support this. eg fopen, write, close, etc reply tredre3 19 hours agorootparent [–] In this scenario, rclone mount uses sftp in the background which compresses the entire stream (you can control that by passing args to the ssh command spawned by rclone) but it doesn&#x27;t do it per-file. In practice I don&#x27;t know if there is a difference. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "This is a spin-off of the SSHFS project which permits users to connect with a remote filesystem using SFTP, a secure file transfer protocol.",
      "The original SSHFS is unmaintained now, prompting the creation of this fork aiming to resolve issues, accept pull requests, and provide necessary support and updates until a separate rust fork is prepared.",
      "Developed using C, Python, Shell, Meson, and Emacs Lisp languages, the project is open to contributions and encourages users to report bugs on their GitHub issue tracker."
    ],
    "commentSummary": [
      "The discussion on Hacker News centers around alternative tools for remote file access such as SSHFS, TRAMP, and SFTP, along with user experiences and preferences regarding these tools.",
      "The potential cessation of SSHFS is debated and the author provides resources on SFTP-over-WS, discussing further alternatives like rclone mount, Nautilus, and NFS over Wireguard.",
      "Other topics addressed include open-source software project maintenance, build automation config files, package management for various programming languages, and comparisons between cloud storage platforms. User frustration concerning the lack of standardization and configuration inconvenience in various programs is also voiced."
    ],
    "points": 301,
    "commentCount": 128,
    "retryCount": 0,
    "time": 1693911891
  },
  {
    "id": 37399873,
    "title": "Can LLMs learn from a single example?",
    "originLink": "https://www.fast.ai/posts/2023-09-04-learning-jumps/",
    "originBody": "fast.ai About Can LLMs learn from a single example? We’ve noticed an unusual training pattern in fine-tuning LLMs. At first we thought it’s a bug, but now we think it shows LLMs can learn effectively from a single example. TECHNICAL AUTHOR Jeremy Howard and Jonathan Whitaker PUBLISHED September 4, 2023 On this page How neural networks learn A very odd loss curve Digging deeper How could the memorization hypothesis be true? What now? Summary: recently while fine-tuning a large language model (LLM) on multiple-choice science exam questions, we observed some highly unusual training loss curves. In particular, it appeared the model was able to rapidly memorize examples from the dataset after seeing them just once. This astonishing feat contradicts most prior wisdom about neural network sample efficiency. Intrigued by this result, we conducted a series of experiments to validate and better understand this phenomenon. It’s early days, but the experiments support the hypothesis that the models are able to rapidly remember inputs. This might mean we have to re-think how we train and use LLMs. How neural networks learn We train neural network classifiers by showing them examples of inputs and outputs, and they learn to predict outputs based on inputs. For example, we show examples of pictures of dogs and cats, along with the breed of each, and they learn to guess the breed from the image. To be more precise, for a list of possible breeds, they output their guess as to the probability of each breed. If it’s unsure, it will guess a roughly equal probability of each possible breed, and if it’s highly confident, it will guess a nearly 1.0 probability of its predicted breed. The training process consists of every image in a training set being shown to the network, along with the correct label. A pass through all the input data is called an “epoch”. We have to provide many examples of the training data for the model to learn effectively. During training the neural network attempts to reduce the loss, which is (roughly speaking) a measure of how often the model is wrong, with highly confident wrong predictions penalised the most, and vise versa. We calculate the loss after each batch for the training set, and from time to time (often at the end of each epoch) we also calculated the loss for a bunch of inputs the model does not get to learn from – this is the “validation set”. Here’s what that looks like in practice when we train for 11 epochs: Loss chart from training on pet breeds As you see, the training loss gradually (and bumpily) improves relatively quickly, slowing down over time, and the validation loss improves more slowly (and would eventually flatten out entirely, and then eventually get worse, if trained for longer). You can’t see from the chart where epochs start and stop, because it takes many epochs before a model learns what any particular image looks like. This has been a fundamental constraint of neural networks throughout the decades they’ve been developed – they take an awfully long time to learn anything! It’s actually an area of active research about why neural nets are so “sample inefficient”, especially compared to how children learn. A very odd loss curve We have recently been working on the Kaggle LLM Science Exam competition, which “challenges participants to answer difficult science-based questions written by a Large Language Model”. For instance, here’s the first question: Sample Kaggle question Which of the following statements accurately describes the impact of Modified Newtonian Dynamics (MOND) on the observed “missing baryonic mass” discrepancy in galaxy clusters? MOND is a theory that reduces the observed missing baryonic mass in galaxy clusters by postulating the existence of a new form of matter called “fuzzy dark matter.” MOND is a theory that increases the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 20. MOND is a theory that explains the missing baryonic mass in galaxy clusters that was previously considered dark matter by demonstrating that the mass is in the form of neutrinos and axions. MOND is a theory that reduces the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions from a factor of around 10 to a factor of about 2. MOND is a theory that eliminates the observed missing baryonic mass in galaxy clusters by imposing a new mathematical formulation of gravity that does not require the existence of dark matter. For those playing along at home, the correct answer, apparently, is D. Thankfully, we don’t have to rely on our knowledge of Modified Newtonian Dynamics to answer these questions – instead, we are tasked to train a model to answer these questions. When we submit our model to Kaggle, it will be tested against thousands of “held out” questions that we don’t get to see. We trained our model for 3 epochs on a big dataset of questions created by our friend Radek Osmulski, and saw the following most unexpected training loss curve: Loss chart from 3 epoch training on Kaggle comp The problem here is that you can clearly see the end of each epoch - there’s a sudden downwards jump in loss. We’ve seen similar loss curves before, and they’ve always been due to a bug. For instance, it’s easy to accidentally have the model continue to learn when evaluating the validation set – such that after validation the model suddenly appears much better. So we set out to look for the bug in our training process. We were using Hugging Face’s Trainer, so we guessed there must be a bug in that. Whilst we began stepping through the code, we also asked fellow open source developers on the Alignment Lab AI Discord if they’ve seen similar odd training curves, and pretty much everyone said “yes”. But everyone who responded was using Trainer as well, which seemed to support our theory of a bug in that library. But then @anton on Discord told us he was seeing this curve with his own simple custom training loop: Anton’s custom loop training loss chart …and he also showed us this accompanying extremely surprising validation loss curve: Anton’s custom loop validation loss chart Then we started hearing from more and more Discord friends that they had seen similar strange behavior, including when not using Trainer. We wondered if it was some oddity specific to the LoRA approach we were using, but we heard from folks seeing the same pattern when doing full fine-tuning too. In fact, it was basically common knowledge in the LLM fine-tuning community that this is just how things go when you’re doing this kind of work!… Digging deeper The hypothesis that we kept hearing from open source colleagues is that that these training curves were actually showing overfitting. This seemed, at first, quite impossible. It would imply that the model was learning to recognise inputs from just one or two examples. If you look back at that first curve we showed, you can see the loss diving from 0.8 to 0.5 after the first epoch, and then from 0.5 to under 0.2 after the second. Furthermore, during each of the second and third epochs it wasn’t really learning anything new at all. So, other than its initial learning during the beginning of the first epoch, nearly all the apparent learning was (according to this theory) memorization of the training set occurring with only 3 examples per row! Furthermore, for each question, it only gets a tiny amount of signal: how its guess as to the answer compared to the true label. We tried out an experiment – we trained our Kaggle model for two epochs, using the following learning rate schedule: Learning rate schedule Nowadays this kind of schedule is not that common, but it’s an approach that saw a lot of success after it was created by Leslie Smith, who discussed it in his 2015 paper Cyclical Learning Rates for Training Neural Networks. And here’s the crazy-looking training and validation loss curves we saw as a result: Result of 2-epoch CLR experiment The only thing that we have come up with (so far!) that fully explains this picture is that the hypothesis is correct: the model is rapidly learning to recognise examples even just seeing them once. Let’s work through each part of the loss curve in turn… Looking at the first epoch, this looks like a very standard loss curve. We have the learning rate warming up over the first 10% of the epoch, and then gradually decreasing following a cosine schedule. Once the LR comes up to temperature, the training and validation loss rapidly decrease, and then they both slow down as the LR decreases and the “quick wins” are captured. The second epoch is where it gets interested. We’re not re-shuffling the dataset at the start of the epoch, so those first batches of the second epoch are when the learning rate was still warming up. That’s why we don’t see an immediate step-change like we did from epoch 2 to 3 in the very first loss curve we showed – these batches were only seen when the LR was low, so it couldn’t learn much. Towards the end of that first 10% of the epoch, the training loss plummets, because the LR was high when these batches were seen during the first epoch, and the model has learned what they look like. The model quickly learns that it can very confidentally guess the correct answer. But during this time, validation loss suffers. That’s because although the model is getting very confident, it’s not actually getting any better at making predictions. It has simply memorised the dataset, but isn’t improving at generalizing. Over-confident predictions cause validation loss to get worse, because the loss function penalizes more confident errors higher. The end of the curve is where things get particularly interesting. The training loss starts getting worse – and that really never ought to happen! In fact, neither of us remember ever seeing such a thing before when using a reasonable LR. But actually, this makes perfect sense under the memorization hypothesis: these are the batches that the model saw at a time when the LR had come back down again, so it wasn’t able to memorize them as effectively. But the model is still over-confident, because it has just got a whole bunch of batches nearly perfectly correct, and hasn’t yet adjusted to the fact that it’s now seeing batches that it didn’t have a chance to learn so well. It gradually recalibrates to a more reasonable level of confidence, but it takes a while, because the LR is getting lower and lower. As it recalibrates, the validation loss comes back down again. For our next experiment, we tried 1cycle training over 3 epochs, instead of CLR – that is, we did a single LR warmup for 10% of batches at the start of training, and then decayed the LR over the remaining batches following a cosine schedule. Previously, we did a separate warmup and decay cycle for each epoch. Also, we increased the LoRA rank, resulting in slower learning. Here’s the resulting loss curve: 1cycle training over 3 epochs The shape largely follows what we’d expect, based on the previous discussion, except for one thing: the validation loss does not jump up at epoch 2 – it’s not until epoch 3 that we see that jump. However previously the training loss was around 0.2 by the 2nd epoch, which is only possible when it’s making highly confident predictions. In the 1cycle example it doesn’t make such confident predictions until the third epoch, and we don’t see the jump in validation loss until that happens. It’s important to note that the validation loss getting worse doesn’t mean that we’re over-fitting in practice. What we generally care about is accuracy, and it’s fine if the model is over-confident. In the Kaggle competition the metric used for the leaderboard is Mean Average Precision @ 3 (MAP@3), which is the accuracy of the ranked top-3 multiple-choice predictions made my the model. Here’s the validation accuracy per batch of the 1cycle training run shown in the previous chart – as you see, it keeps improving, even although the validation loss got worse in the last epoch: MAP@3 for 1cycle training If you’re interested in diving deeper, take a look at this report where Johno shares logs from some additional examples, along with a notebook for those who’d like to see this effect in action for themselves. How could the memorization hypothesis be true? There is no fundamental law that says that neural networks can’t learn to recognise inputs from a single example. It’s just what researchers and practitioners have generally found to be the case in practice. It takes a lot of examples because the loss surfaces that we’re trying to navigate using stochastic gradient descent (SGD) are too bumpy to be able to jump far at once. We do know, however, that some things can make loss surfaces smoother, such as using residual connections, as shown in the classic Visualizing the Loss Landscape of Neural Nets paper (Li et al, 2018). Loss surfaces of a ResNet-56 (Li et al, 2018) It could well be the case that pre-trained large language models have extremely smooth loss surfaces in areas close to the minimal loss, and that a lot of the fine-tuning work done in the open source community is in this area. This is based on the underlying premise surrounding the original development of fine-tuned universal language models. These models were first documented in the ULMFiT paper back in 2018 by one of us (Jeremy) and Sebastian Ruder. The reason Jeremy originally built the ULMFiT algorithm is because it seemed necessary that any model that could do a good job of language modeling (that is, predicting the next word of a sentence) would have to build a rich hierarchy of abstractions and capabilities internally. Furthermore, Jeremy believed that this hierarchy could then be easily adapted to solve other tasks requiring similar capabilities using a small amount of fine-tuning. The ULMFiT paper demonstrated for the first time that this is indeed exactly what happens. Large language models, which today are orders of magnitude bigger than those studied in ULMFiT, must have an even richer hierarchy of abstractions. So fine-tuning one of these models to, for instance, answer multiple-choice questions about science, can largely harness capabilities and knowledge that is already available in the model. It’s just a case of surfacing the right pieces in the right way. These should not require many weights to be adjusted very much. Based on this, it’s perhaps not surprising to think that a pre-trained language model with a small random classification head could be in a part of the weight space where the loss surface smoothly and clearly points exactly in the direction of a good weight configuration. And when using the Adam optimiser (as we did), having a consistent and smooth gradient results in effective dynamic learning rate going up and up, such that steps can get very big. What now? Having a model that learns really fast sounds great – but actually it means that a lot of basic ideas around how to train models may be turned on their head! When models train very slowly, we can train them for a long time, using a wide variety of data, for multiple epochs, and we can expect that our model will gradually pull out generalisable information from the data we give it. But when models learn this fast, the catastrophic forgetting problem may suddenly become far more pronounced. For instance, if a model sees ten examples of a very common relationship, and then one example of a less common counter-example, it may well remember the counter-example instead of just slightly downweighting its memory of the original ten examples. It may also be the case now that data augmentation is now less useful for avoiding over-fitting. Since LLMs are so effective at pulling out representations of the information they’re given, mixing things up by paraphrasing and back-translation may now not make much of a difference. The model would be effectively getting the same information either way. Perhaps we can mitigate these challenges by greatly increasing our use of techniques such as dropout (which is already used a little in fine-tuning techniques such as LoRA) or stochastic depth (which does not seem to have been used in NLP to any significant extent yet). Alternatively, maybe we just need to be careful to use rich mixtures of datasets throughout training, so that our models never have a chance to forget. Although Llama Code, for instance, did suffer from catastrophic forgetting (as it got better at code, it got much worse at everything else), it was fine-tuned with only 10% of non-code data. Perhaps with something closer to a 50/50 mix it would have been possible to get just as good at coding, without losing its existing capabilities. If you come up with any alternative hypotheses, and are able to test them, or if you find any empirical evidence that the memorization hypothesis is wrong, please do let us know! We’re also keen to hear about other work in this space (and apologies if we failed to reference any prior work here), and any ideas about how (if at all) we should adjust how we train and use these models based on these observations. We’ll be keeping an eye on replies to this twitter thread, so please respond there if you have any thoughts or questions.",
    "commentLink": "https://news.ycombinator.com/item?id=37399873",
    "commentBody": "Can LLMs learn from a single example?Hacker NewspastloginCan LLMs learn from a single example? (fast.ai) 268 points by jdkee 9 hours ago| hidepastfavorite76 comments jph00 9 hours agoThank you for posting this to HN! :DI&#x27;m one of the authors of this post -- Johno & I found it really interesting looking into this curious issue of rapid memorization from LLMs. I&#x27;ve been working with neural nets for 30 years, and fine-tuning language models since 2017, and this behavior is most surprising to me! Other folks have seen it in LLMs too, although I haven&#x27;t seen a analysis of this kind before (although we might have missed something).Let me know if you have any questions or thoughts. reply og_kalu 8 hours agoparentIn the palm-e paper (https:&#x2F;&#x2F;palm-e.github.io&#x2F;), when they try to unfreeze and train the LLM on new image data only, there is expectedly a lot of CF on NLP tasks but very interestingly, the effect diminishes greatly with the scale of the LLM prior to training.From an average -87.3% performance drop on the 12B model to -61.6% on the 84B model then just -3.9% on the 562B model. Felt like we were just shy of an insight breakthrough here.Is avoiding CF potentially just a matter of sheer scale ? reply jph00 8 hours agorootparentI think our experiments actually don&#x27;t show catastrophic forgetting! The accuracy does not decrease as loss gets worse -- it&#x27;s simply getting over-confident.So I&#x27;m not even sure we&#x27;re showing any problem to solve here -- it might be more of a opportunity, in fact! reply vvrm 3 hours agorootparentI have been training a natural intelligence model for 3 years now and she still doesn’t get nuance. Things are either good or bad in her book: nothing in between. My plan is to let her train with binary good&#x2F;bad labels till the age of 5 and then start smoothing the labels after that. Wonder if that works for your AI. reply vineyardmike 3 hours agorootparentThis took a couple reads, but it’s funny. The bad news is that I’ve been training mine for 17 years and nuance is still something that needs more training. reply tudorw 1 hour agorootparentprevin my mind I&#x27;ve built an &#x27;emotional engine&#x27; to add nuance to models understanding, take something like Plutchik&#x27;s wheel of emotions and create a high quality multi-modal dataset based on that structure, given our current technology takes inspiration from the brain, it would seem like having discrete models specialising in particular aspects of &#x27;intelligence&#x27; that are then organised into a mixture of experts is an interesting area to explore, and perhaps more accessible as smaller models require less resources. reply 3abiton 4 hours agorootparentprevAwesome investigative work, what&#x27;s the opportunity though, I don&#x27;t get it reply jph00 48 minutes agorootparentWe don&#x27;t know. It&#x27;s a report of some early experimental results. Our hope is that it will stimulate discussion and further research and development. reply Yenrabbit 8 hours agorootparentprevIt does start getting worse at some point right? reply minihat 5 hours agorootparentCross-entropy loss can start getting worse due to the model becoming less calibrated, even as the classification accuracy continues to improve. I first heard that here: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1706.04599Is this &#x27;overconfidence&#x27; the leading explanation as to why LLMs continue to show qualitative improvement even after their test loss levels off? reply jph00 8 hours agorootparentprevI&#x27;m sure eventually it would, but we haven&#x27;t gotten to that point yet in our training. reply samstave 5 hours agorootparentprevPlz eli5 catastrophic forgetting,I assume this means losing all the energy and compute input for a model to know, perform, infer on inputs already indexed(?) (What is the proper term here?)But is this the premise -you lose all prior investment of resource to a (I don&#x27;t know the term for an AI archetype of knowledge) {btw, I love the embedded etymology of knowledge\"The ledger of things that we KNOW\"} reply tarvaina 5 hours agorootparentSuppose we have trained a model to perform a certain set of tasks. Later we would want to teach it a new task. Catastrophic forgetting means that teaching it a new task makes it unlearn some or all of its earlier tasks.It occurs because training changes the weights of the model. The earlier set of weights was good for the previous tasks. The new set of weights is only good for the new task. Usually special care must be taken to overcome catastrophic forgetting. reply antupis 1 hour agorootparentI think some cases CF would be even good eg you want llm that produces only valid json data as output. reply josephg 15 minutes agorootparentYeah, this is essentially how finetuned models work. If you fine tune stablediffusion to produce anime images, it might forget how to produce images in any other style. But it will become much better at anime images than the base model. If anime images are the art style you’re after, this is a good trade. Same with fine tuning LLMs for SQL or whatever. reply samstave 4 hours agorootparentprevCan it be taught \"contextual matrices\" where by it builds a new layer of construct but preserves the other, then cross learns between parameters or something (sorry for my poor lexicon, I&#x27;m wet-learning :-)But imagine all LLMs in a macro view like a sponge entity reply tinco 2 hours agorootparentWe wouldn&#x27;t know how to construct those matrices because we don&#x27;t know where in the layers what knowledge is represented. One thing that helps a little bit is freezing the lower layers, so at least the model won&#x27;t forget its most fundamental knowledge.Note that the only reason that things are catastrophically forgotten, is that the original examples are not shown again. If the model learns in a single shot, there might simply be no time to show both the old and the new examples. I don&#x27;t think it would have a significant effect or else we&#x27;d know about this effect a lot sooner (i.e. the training of these LLM&#x27;s would get less effective from a certain point) reply jacquesm 58 minutes agorootparentYou could simulate this by selectively locking and unlocking &#x27;banks&#x27; of weights from a larger model to keep the influence there during training and to avoid losing them. Sort of a selective write-protect. replyYenrabbit 8 hours agorootparentprevOoh interesting, thanks for sharing! reply jwuphysics 8 hours agoparentprevHi Jeremy, always a fan of your work! Just a technical note since it falls under my domain of expertise (astronomy) -- the example about MOND described here should actually have choice (E) as the correct answer! reply jph00 7 hours agorootparentAs it happens I dug into this question in some detail a couple of weeks ago when analysing the dataset, including carefully reading the wikipedia page which the question comes from. AFAICT both D and E are kinda correct, but E isn&#x27;t quite right because MOND doesn&#x27;t entirely \"eliminate the observed missing baryonic mass\", but rather just reduces it from a factor of 10 to 2.Is that not correct? (Of course I fully accept your expertise in this matter and this is just my curiosity, not trying to tell you you&#x27;re wrong!) reply jwuphysics 7 hours agorootparentprevIn terms of the actual article -- really nice finding. Or I guess, nice set of experiments to decipher what lots of LLM researchers have been finding!I&#x27;ve noticed somewhat similar behavior while training graph neural networks to model physical systems, except that it takes way longer than a single epoch to get there. Or course, there&#x27;s no pretending involved with my GNNs, but the models do have very constrained representations, so once they start to figure out how to represent the physics at hand, the loss plummets dramatically. reply ilaksh 8 hours agoparentprevWhat is the base model? I think that was a big oversight to leave that out and attribute this to LLMs in general.Although I am not a researcher, it is obvious to me that not all LLMs are the same architecture, and I think that even ones with similar architecture can evolve to functionally operate quite differently on the same inputs.Yet most articles seem to refer to LLMs as if they were just one architecture and model. reply n9Mtq4 8 hours agoparentprevVery cool. This came up in a huggingface transformers issue a while ago and we also determined memorization to be the likely reason. It&#x27;s nice to see someone else reach the same conclusion.https:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;transformers&#x2F;issues&#x2F;18730 reply armatav 3 hours agoparentprevI wonder if you could perform inference, highlight the weights that were most used during that inference, grab the hottest 20%, freeze the rest of the model, and perform backpropagation solely on those to allow for more of this sort of rapid memorization behavior closer to the end user.Like online learning in a way. But you do it during inference time.There’s no way the entire model actually needs to be touched for something like “sky color is:” and “blue”. reply armatav 3 hours agorootparentIn fact I bet you could update like one or two neurons for certain concepts, and then transplant those neurons to another LLM to give it some idea of it. Like a literal brain transplant but for concepts. reply armatav 3 hours agorootparentAnd you could identify these neurons using dropout techniques and repetitively querying the model against them.Drop a set of neurons and there’s no change? Probably doesn’t contain the “sky color” concept.Drop a set of neurons and the model freaks out, definitely conceptual neurons.Rinse and repeat to find the distilled pattern across all the neurons.You could train an LLM against the neuron graph to do this for you. reply niemandhier 3 hours agorootparentprevMany neurons are polysynthactic, that makes interventions like the proposed difficult. reply ScoutOrgo 8 hours agoparentprevHey Jeremy, it seems like you could calculate exactly how much a model learns in a single step by calculating the loss for a batch a second time (with no_grad) after the loss is calculated the first time and gradients are updated. This seems like it could produce interesting outputs when graphing the difference of first and second losses at the batch or observation&#x2F;question level. reply startupsfail 6 hours agoparentprevInteresting, but you should show the example as concrete evidence, rather than hand waving arguments based on loss curves “evidence”. reply azg123 8 hours agoparentprevSuper interesting! Another area that I&#x27;ve seen these types of loss curves are recommendation models: https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2209.06053.pdf reply Nevermark 2 hours agoprevDo people really use the phrase “over confident” in this way? It is very misleading.What is happening is called “over fitting”.Think of data as dots. A model that generalizes well will create as simple of a function as possible that fits the training data points pretty well.But keep training and parameters will often get very large, creating huge up and down swings in the function curve, far outside the actual data values, in order to pass through the training data points exactly.So it’s technically a better fit to the training data, but it is now a crazy function, often producing extreme outputs on new data. Practically a worst case lack of generalization.Thus, “over fitting”.And “over fitting” isn’t the same as “memorization”. Large models can memorize small datasets without over fitting. They have so many parameters, it takes few changes to fit the training data. At which time, learning stops at an otherwise random function, and generalization is never achieved.That case is called “underdetermined”.There are models that produce both outputs and confidences (essentially predict their own error standard deviation per output, based on the input).So “over confident” can mean a model that predicted high confidence (low error deviation) inaccurately. reply jph00 46 minutes agoparentNo I don&#x27;t use the term overfitting for a model where the accuracy is getting better. I think it&#x27;s misleading. reply whimsicalism 7 hours agoprevWas this not sort of the clear implication of the fact that most LLMs are currently only being trained with one epoch?ie. if they are only being trained from one epoch, there is clear overfitting concerns just by doing even a second pass in the data.It does seem somewhat contrary to the findings of this paper [0] that found that old data was as good as new for at least 4 epochs.[0]: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.16264 reply fpgaminer 6 hours agoparent> Was this not sort of the clear implication of the fact that most LLMs are currently only being trained with one epoch?Slight nit: Many public LLMs are trained for at least slightly over one epoch, and usually several epochs on particular subsets of the data (like wikipedia). reply computerex 7 hours agoparentprevThey are not being trained only on 1 epoch. They are trained on multiple epochs for high quality data. Also Meta team with llama show that simply training more, more tokens, continues to reduce loss. reply jph00 7 hours agoparentprev reply whimsicalism 6 hours agorootparentthat&#x27;s the exact paper i link in my comment :) reply fpgaminer 7 hours agoprevI see similar loss curves when training ViTs (from scratch), which has always bothered me but I had bigger concerns so never delved too deep into it. The only difference is that I see the training loss go _up_ during each epoch. The cliffs between epochs are large enough that training loss goes down overall and validation loss keeps going down the whole time as well. The model gets close-ish to SoTA so I guess it&#x27;s \"normal\".I haven&#x27;t trained convnets at this scale so I&#x27;m not sure if similar behavior has been seen there, but you&#x27;d think someone would have mentioned it at some point. So perhaps these strange loss curves are a feature of Transformer based models in particular? reply lIIllIIllIIllII 6 hours agoparentThe original article mentioned LLMs needing powerful abstractionsthis is basically the case with transformer networks, which is apparent when learning from scratch. The model seems to be going basically nowhere and totally useless until suddenly, at some random point after a bunch of learning cycles the weights find some minimum on the error surface and bam, suddenly the model can do things properly. And it&#x27;s because the transformer has learned an abstraction that works for all of the input data in an attentional sense (think how you scan a sentence when reading). Not the best explanation but its from memory from a post I saw on HN a while back reply jph00 7 hours agoparentprevOh wow yeah - I&#x27;ve also seen other people&#x27;s training loss curves like that, going up during each epoch and then jumping down at the end of the epoch. I&#x27;ve never experienced that myself, and have no idea what&#x27;s causing it! reply whimsicalism 5 hours agoparentpreveven in the first epoch the loss goes up? that seems.. odd reply imjonse 4 hours agoprevI found the title misleading.Isn&#x27;t learning from a single example desirable, while memorizing undesirable in the context of training? The former is the goal we&#x27;re aiming for in order to match how animals learn, while the latter a failure mode that happens often. The article shows a case of unexplained memorizing, not of learning, right? reply Buttons840 8 hours agoprevDoes anyone know if LLMs have been used to augment their own training data?I wonder what would happen if you trained an LLM on a little input but then had it generate a lot of synthetic input added to the training data. I think of it as \"dreaming\". This seems like it would just add noise, but LLMs are able to improve their output by augmenting their own context (by \"thinking out loud\"), maybe they can do the same with their own training data? reply fpgaminer 6 hours agoparentThat&#x27;s effectively what RLHF is; a means for LLMs to self train on their own output exclusively by using a small human curated dataset as guidance as to what a \"good\" and \"bad\" output is. reply muxator 8 hours agoparentprevIt&#x27;s interesting that this conclusion is the exact opposite of a sibling comment, which proposes that a small, human-curated corpus may be more effective than big, synthetic datasets. reply Buttons840 8 hours agorootparentI have no \"conclusion\". I&#x27;m just wondering. reply jph00 7 hours agoparentprevYes, a lot of recent research uses LLM outputs as training data, and it&#x27;s been an extremely successful line of work. reply rsrsrs86 7 hours agoparentprevYou can find the answer by trying the following: generate random data according to a model, fit a linear regression (or any other distribution), sample from the distribution, add it as to the training set. reply jerpint 8 hours agoprevIf this holds true, this would support the idea that much smaller, human curated datasets will be of much higher value than synthetic datasets generated by LLMs reply rsrsrs86 7 hours agoparentWhichever has the most information wins. When the information has structure you can heavily exploit it for generating synthetic data. For this I point you to Apple Sim. It’s a repository of 3D models for interiors. You can generate many layers of information by controlling the renderer and then use it on real photos. That’s done all over images so vectorial spaces are pretty natural for embeddings. You don’t need to add much structure algebraically speaking.If your domain is heavily algebraic, you might even be able to generate correct examples arbitrarily, which is a situation I recommend anyone to be in. reply fpgaminer 5 hours agoparentprevI doubt it. If anything, ULMFiT era AI has finally killed the need for human curated data. ChatGPT 4 is already being used as an oracle model that everyday AI models are trained off of. A truly gargantuan oracle model will obviate all but the smallest of human input. reply tellarin 4 hours agorootparentGPT4 relies heavily on human curated data. Both for specific domains and for instruction following. Any new model that tries to go beyond it will also likely rely on such data. reply tomrod 8 hours agoparentprevI assume there is a value metric that balances quantity with quantity that may be exploitable in our mid-gains period of understanding the tech behavior -- meaning potential gains from synthetic data. That said, I also expect no-free-lunch to kick in at some point, and synthetic data doesn&#x27;t always pay attention to the data generating process for outliers. reply rsrsrs86 7 hours agorootparentYou will find active learning interesting. It starts by attributing a value to each point in your domain that it learns to match the expected gain in some performance metric.This metric can be learned so it’s okay if it’s really hard to specify. reply cuuupid 5 hours agoparentprevGoogle reached that conclusion ~2 years ago but has yet to show significant results, key word above being curated reply Solvency 7 hours agoparentprevWhy are we only able to theorize about these things? Why can&#x27;t we get know and why these things work? reply RhysU 8 hours agoparentprevThis is not surprising in the context of our wetware: \"Jane sees Spot run. Run, Spot, Run.\" reply Palmik 2 hours agoprevIf you find this interesting, checkout also \"Mass Editing Memory in a Transformer\" [1] and \"Locating and Editing Factual Associations in GPT\" [2].[1] https:&#x2F;&#x2F;memit.baulab.info&#x2F; [2] https:&#x2F;&#x2F;rome.baulab.info&#x2F; reply deyiao 3 hours agoprevI often observe similar phenomenna in CNN related reserch. which indicate that the model indeed can learn from a single example, but sadly, this requires the dataset to be randomly distributed, In real-world applications, new data does not meet this requirement. reply klft 5 hours agoprevGPT-4 (I haven&#x27;t really tested other models) is surprisingly adept at \"learning\" from examples provided as part of the prompt. This could be due to the same underlying mechanism. reply bathtub365 5 hours agoparentI’ve found the opposite in trying to get it to play Wordle. It’ll repeatedly forget things it’s seemingly learned within the same session, all the while confident in its correctness. reply jacquesm 51 minutes agorootparentLLMs are trained on &#x27;tokens&#x27; derived from &#x27;words&#x27; and &#x27;text&#x27; and even though there are tokens that are just one letter the bulk is a rough approximation to syllables as though you&#x27;re trying to create a dictionary to be used for data compression.It might be more effective to try to play &#x27;tokendle&#x27; before trying to play &#x27;wordle&#x27;. reply ben_w 3 hours agorootparentprevWhat approach are you using to get the LLM to split words into individual letters? reply cypress66 2 hours agoparentprevNot really. That&#x27;s called few shot learner.It&#x27;s basically unrelated to what happens during training, which is using gradients. reply justanotherjoe 5 hours agoprevisn&#x27;t it highly dependent on what is your one epoch of data? if there are a lot of repetitions of similar concepts in there then can you say it&#x27;s learning from one example? reply jph00 3 hours agoparentIf it was due to repetition there wouldn&#x27;t be those sudden cliffs after each epoch. reply spit2wind 5 hours agoprevWhat are the axis labels on the graphs? reply jph00 3 hours agoparentCross entropy loss vs batch number reply rafaelero 8 hours agoprevThat&#x27;s intriguing. But what I want to see is if that one example can change the whole web of knowledge previously established. So, for example, if we finetune the model with a sentence like \"Scientists discovered that a type of antigen can make a host immune to HIV\" will it then be able to infer that \"mRNA vaccines are a valid preventive approach to AIDS since they may be able to express a type of resistance known to make hosts immune to HIV\"? reply SubiculumCode 8 hours agoprev [–] Does this mean it is now computationally efficient to have the model learn&#x2F;memorize information on the fly, say the current chat context, as part of the model weights? One shot encoding (something the hippocampus is very good at) allows us to build experiences into retrievable memories tied into semantic concepts we&#x27;ve previously learned..in fact it gets better the more rich our semantic conceptualization of events become from childhood into adulthood.If memorization of events in llm is accelerated because of- these deep semantic frameworks, then does this provide a path towards long context windows? reply warkdarrior 6 hours agoparentMaybe, but there are a lot of unknowns. Does the \"memorization on the fly\" come with catastrophic forgetting of other information? How does one control for memorizing recent stuff vs. remembering older stuff? reply quickthrower2 7 hours agoparentprev [–] Beginner here, so just musing:I like the idea. You would need your own mutable copy of the model, which is usually huge. And you need to backprop so there is a bit more computation. It might be doable for a local model that is smaller than GPT3.5&#x2F;4.You also need to decide what is worth memorizing long term vs short term. reply pests 6 hours agorootparent [–] > own mutable copy of the model, which is usually hugeIt could just be the diff against the main model or similar. reply quickthrower2 5 hours agorootparent [–] But if you have say 50bn weights, and you run backprop, you are going to update most of the weights (except the dropout ones, but which ones drop out changes on every token I think). This means you need 50bn deltas. It might compress, but if you do then you need extra compute to do that. reply jacquesm 49 minutes agorootparent [–] You would do dropout on every epoch of training, not on every token. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Fast.ai researchers found that large language models (LLMs) can rapidly memorize examples from datasets after a single exposure, defying typical expectations.",
      "This discovery could potentially influence how LLMs are trained and utilized.",
      "The research team proposes solutions such as dropout and stochastic depth techniques, and the use of diverse datasets during training to deter models from forgetting. They encourage further dialogue on this topic via Twitter."
    ],
    "commentSummary": [
      "The post investigates the capacity of language models (LLMs) to learn from one example, their tendency for catastrophic forgetting, overconfidence, and utilization of inference during the training process.",
      "It explores how altering specific neurons in LLMs can affect their performance, underscores the value of human-curated data, and debates limitations of synthetic data usage.",
      "Lastly, it delves into the efficiency of LLMs in data memorization and the potential benefits of integrating long context windows."
    ],
    "points": 268,
    "commentCount": 76,
    "retryCount": 0,
    "time": 1693960805
  },
  {
    "id": 37395096,
    "title": "If you can use open source, you can build hardware",
    "originLink": "https://redeem-tomorrow.com/if-you-can-use-open-source-you-can-build-hardware",
    "originBody": "Skip to main content Redeem Tomorrow I used to be excited about the future. Let's bring that back. About Subscribe Hire me If you can use open source, you can build hardware Sep 05, 2023 hardwaredeveloper experienceparadigms As a technologist, hardware has always been my final frontier. Things you can touch, things that create physical outcomes, these can have so much more power than software alone. But the cost of that power is complexity. Electrons don’t care about our ambitions. Circuits can be harder to debug than code. And even if everything works perfectly on the level of logic and voltage, you’re still managing the complexity of physical objects, their wiring, their position in space, and even their heat dissipation. Building any product is hard, but building a hardware product is a superset of the basics of any product challenge, adding in the iron constraints of the physical world. It’s not enough to imagine how something looks: you have to also find a way to build it in a way that matches your imagination, while simultaneously accommodating all those physical constraints. It’s work. But also? It’s never been easier than it is today. I just built complete replacements for my heat pump controllers. I hated those dinky remotes. You couldn’t read them in the dark at all, and programming them was about as bad as anything you remember from the bad old days of VCRs. I imagined something that would solve their UI problems, and integrate my heat pumps into my home automation system. I’m not an electronics engineer, but my dreams are now real. I’ve got five of these across the house. Using open source code is a skill: knowing how to navigate repos and someone else’s code, understanding how to troubleshoot and navigate communities to get help, discerning between quality projects and junk… this experience is a hard-won component of being a modern software explorer. It can take you further than you might realize, past mere bits and into the land of electrons and atoms. Of course: microcontrollers Arduino was a revolution in developer experience. Beginners could write simple C code and and have a physical computing experience within the space of five minutes. But since the advent of Arduino, the landscape of microcontroller boards—components that can be programmed to emit and receive complex electronic signals—has exploded. Boards of every scale and configuration are available today, from the size of a peanut butter and jelly sandwich all the way down to a postage stamp. Microcontrollers are the foundation of the hardware adventure, allowing infinite iteration of custom logic on inexpensive components. Different designs sport different connectors and accessories. There are also different chip architectures out there, and boards built around ESP32, or the new Pico W, even include WiFi and Bluetooth capabilities. Unifying all of this are software ecosystems. Open source Arduino code exists to solve so many kinds of problems, from networking to button handling. Regardless of your board’s architecture, there’s usually a port of the Arduino environment you can use, opening up all that code for your project. If you prefer Python, the MicroPython and CircuitPython projects even offer an alternative to C/C++. But the ecosystem doesn’t stop at software. StemmaQT and Qwiic: an old standard with new strategy I2C is a two wire serial data standard that dates to 1982. In practice, it looks and works a lot like USB: two more wires add power and ground, and you can chain dozens of devices together on a single bus. For the typical hobbyist hardware tinkerer, the hardest challenge comes down to circuit design. Electronics is arcane, governed by both the laws of physics and decades of component lore. Building circuits means understanding how to use all of these to channel electrons consistently, without letting the magic smoke out. It means understanding how to adjust voltages, manage resistance, and do it all in a way that’s physically sturdy and manageable. This is a tall order. I’ve never had the time or motivation to learn enough circuit design to build anything more complex than arrays of blinking lights. But now, I don’t need to. If you build modern software, you’re well-versed in composition: grab a handful of existing projects—a database here, a UI framework there, an HTTP library to round it all out—and arrange them together. You write your custom logic—the stuff unique to your project—and let other people’s code do work that’s common across all projects. Thanks to I2C and a convenient cable standard—branded StemmaQT by Adafruit, and Qwiic by Sparkfun, two leading hobbyist component vendors—the same approach to composition is possible in an electronics project. Decide your requirements, and you can probably find a few boards you can quickly wire together—without soldering!—that will address your problem. In the case of my heat pump controller: ESP32-based microcontroller with a built-in screen Light sensor, so I can automatically dim the bright lights Temperature and humidity sensor, so I can have real data about the actual temperature in the room Rotary encoder board, to make a dial for setting temperature and toggling power All of that just plugs in via I2C. Each board, like a well-made library, abstracts its gnarly implementation details under the hood. You don’t worry about power management, or the details of how to interpret signals as input from a rotary encoder. Instead, after wiring things together, you look up the example code for each component, and adapt it to your project. In the past, actually using these components could be something of a mystery. But now vendors go to great lengths to maintain supporting libraries and docs—developer experience sells! Adafruit deserves special mention here: they have hundreds of useful, unique boards that support this compositional approach, and their supporting materials are just exhaustive. Again, if you know how to apply open source code, you can do this. From imagination to physical objects Once you create a working circuit, you can take it all a step further: design and manufacture your own custom enclosures. It’s really kind of nuts: for $500, you can buy an incredible, reliable 3D printer from Prusa. You can’t beat Prusa: the printers come out of the box working perfectly, they’re vertically integrated with Prusa’s excellent cross-platform slicer software, and the user community is among the most active and helpful of anything on the internet. At that price, its build volume isn’t mammoth, but it doesn’t have to be for electronics projects. Open hardware vendors often provide 3D models of their products you can bring into a CAD program. With these models, it’s possible to design plastic cases with perfect accuracy, allowing you to mount and arrange the various boards in your project. Best of all, iteration is fast and cheap. Trying a new version of a design takes only a few cents of material and time to print it. You can figure out quickly if your approach is working. Remember heat dissipation? Waste heat from the microcontroller was biasing my temperature sensor. It only took a couple evenings to find an iteration of the case that solved the problem (I moved both sensors to the top side of the enclosure). There is a learning curve to 3D printing. It might be the steepest factor here, in fact. Like electronics, 3D printing also has constraints to manage: you have to work with both heat and gravity, and design your models with that collaboration in mind. The physics of how layers are deposited impacts the strength and durability of your output, so the orientation at which you print can have consequences. Choice of materials also matters. I found PETG to be the ideal material for this kind of work: it’s easy to work with and super durable. By contrast, the more common PLA was too brittle. You’ll also want to pick up some CAD skills, but this is less painful and more fun than you might imagine. CAD seems to be the fine art of sketching simple flat shapes, pulling and pushing them into 3D objects, and carving away at small details. I couldn’t stand most of the affordable desktop CAD software—it feels icky, like using a poorly-aged Flash app in IE6. Then I found Shapr3D, for iPad. This is some futuristic shit. You tap away with your Apple Pencil, on a tablet computer, drawing things out of your imagination. You nudge your sketches into models, which turn into prints. There’s something far more intuitive about this process than using keyboard and mouse. The positive future shock makes me delirious if I dwell on it. Community is everything to learning emerging skills. Hobbyists are deeply engaged with 3D printing, and you’ll find help for everything from planning your models to debugging thermal drama with your prints. I think you should try it I’ve been dreaming of building my own electronics since I was a kid. I spent so many afternoons at Radio Shack, and even tried my hand at the occasional kit, with limited success. Every few years in adulthood, I’ve given it another try, observing a steady downward trend in difficulty. I’m telling you: we’re at a special moment here. The labor savings of open source, the composability, the fun: all of it has come to hardware. You can build things that solve real problems for yourself. I first imagined my heat pump devices over a year ago, and I have been frustrated they didn’t exist every day since. Now my dreams are real, and the largest energy consumer in the house can be automated and remotely controlled. That’s amazing. Previous The privilege of knowledge work in climate crisis Home About RSS (Full) RSS (Without Link Posts) Get Redeem Tomorrow in your inbox: ©2023 Danilo Campos",
    "commentLink": "https://news.ycombinator.com/item?id=37395096",
    "commentBody": "If you can use open source, you can build hardwareHacker NewspastloginIf you can use open source, you can build hardware (redeem-tomorrow.com) 268 points by gustavo_f 16 hours ago| hidepastfavorite101 comments petsfed 14 hours agoI&#x27;m going to complicate this a bit and say \"If you can use open source, you can prototype hardware\"Part of building hardware is making it robust enough to exist in meat space long term. That means thinking about how the humidity sensor is affected by ambient conditions (including the packaging bag, that one has bit me in the past) and having a plan for re-calibration if drift becomes too great. That means picking connectors for your wire harnesses that can handle the number of times you expect to connect&#x2F;disconnect them over the course of your things lifespan. That means tuning the length of that wire harness so you can&#x27;t damage it when you open the enclosure to change the battery or whatever. It means thinking about how ambient conditions affect the rest of the design, so you don&#x27;t have to clean the contacts on all the wire harnesses every so often, because you didn&#x27;t get gold contacts for both the harnesses and the connectors, and you live in a high humidity environment.Don&#x27;t get me wrong, I&#x27;m self-taught on virtually all of these points, it is achievable for the hobbyist. Just understand that swapping out one smart relay controller for another is pretty far from having a smart relay controller you&#x27;d even give to your sister-in-law for Christmas. reply generj 14 hours agoparentI’m a big proponent of open source hardware but as your post shows it often involves skills of many disciplines that requires vigorous thought or trial and error. Electronics and physics are unforgiving in a way processors are not.Even after reaching the prototype phase, the open source hardware is probably only useful to one person: it’s creator.There is a big difference between making a prototype and detailing the build in sufficient detail other hobbyists can replicate it &#x2F; modify &#x2F; use it. Documenting hardware is substantially harder than documenting software. If the project is cool a bunch of people will be excited to jump in; some of these people have zero experience soldering or ordering laser cut parts or whatever. Supporting them is hard.Then another step up to sell the design to other hobbyists, even just a few extra copies on Tindie.And then a huge step up from that to selling to the general public, where suddenly FCC interference certifications are needed and the company is liable if the design burns down a few houses. There’s a reason firms making hardware have real engineers on staff held to professional standards. Plus all the cash flow and business concerns when the marginal cost per unit isn’t under 1 cent like software.Each of these steps often involves multiple iterations of hardware and therefore lead time and cost. reply jacquesm 9 hours agorootparentEven seasoned professionals can get caught in the gap between &#x27;prototype&#x27; and &#x27;production grade&#x27; especially for things that are on the margin of what can be done with a particular hardware recipe. That&#x27;s when component variation can cause your product yield to go straight into the sewer. reply eternityforest 13 hours agorootparentprevThere are a lot of OSHW projects I&#x27;d love to work on, but the main thing that holds me back is knowing they&#x27;d basically go nowhere. I can&#x27;t post them online for others like with code.Nobody is going to build it, the physical building of it is way harder than the design, anyone who could build it is too busy building their own projects that will go in the junk drawer in a week.I would love to work at a real OSHW company, making IoT gadgets and stuff that for production and sale as polished commercial products with a software ecosystem behind them... but I lack a degree, live in Montana, and don&#x27;t drive, and there are not many companies like that(And most of them are making expensive FOSS phones that don&#x27;t run normal apps, cryptocurrency stuff, or glorified dev boards kinda pretending to be products) reply xnzakg 12 hours agorootparentReally depends on the specific pronect of course, but there&#x27;s definitely some \"posted online like code\" projects out there. It&#x27;s a more technical target audience of course, but I&#x27;ve seen plenty of projects with design files included ready to be sent to a PCB manufacturer. Two categories I can easily think of are mechanical keyboards and modular synthesizers. reply nico_h 1 hour agorootparentThere’s also ergogen, which is a project that generates the PCB for your split keyboard based on a few inputs. Then just send it to your favorite online pcb maker and you just have to solder the components .And there are a bunch of dactyl manuform case generators. (Which the online pcb fabs are now also offering to print in your favorite material) reply eternityforest 11 hours agorootparentprevKeyboards are an interesting case, people are so into them, and also specifically want them to be custom made just for them, so people are willing to build or even commission.I keep thinking that maybe high end flashlights could be the same way, I can definitely think of a few features that don&#x27;t show up in your typical light, and that it might be cool to try to make a few boutique lights to sell, but my business knowledge isn&#x27;t quite up to that, and I don&#x27;t exactly have much desire to do a whole lot of independent work, I much prefer having an employer. reply nico_h 1 hour agorootparentThe thing i see with flashlights is that the physical object is pretty complex and has to face thermal, power and environmental constraints that would destroy any keyboard.Maybe it could start as a gut replacement for an existing cheap flashlight and grow from there. reply vdqtp3 9 hours agorootparentprevFlashlight nerds are crazy, it&#x27;s definitely as big a market as custom keyboards reply bsder 12 hours agorootparentprev> Supporting them is hard.Ding!We had a bespoke wireless entry system for our hackerspace which kinda sucked. Eventually the board switched it out for OpenPath (which also sucks--to be fair).Why?Support. The board can now call someone and say \"We pay you. Fix this.\"Support is the bane of consumer products. I really wish we had some way to counter this. reply eternityforest 13 hours agoparentprevAnd all of this together still doesn&#x27;t solve the bigger problem with DIY hardware, which is the DIY itself.It it goes wrong, you cannot buy a new one or hire repairperson at a sane price. If it has a software side, it will probably need maintainence. If you want one, there&#x27;s a large chance you might want another to expand your project.While yes, I am able to design a reliable hardware device, unless you have a large budget it will not be immune to direct baseball bat hits or spilling epoxy in the connector. So, in practice, if you ask me to build something for you, I&#x27;ll try to find a way to do it with off the shelf parts as much as possible.Which sucks, because electronics projects are super fun, but the fun is dampened by the fact that in the end you have this completely unique irreplaceable thing that becomes a liability if you use it for anything important, which is generally tied to one application and becomes junk if you no longer need it, unlike the more general purpose off the shelf stuff.ESPHome and Amazon modules plus 3D printing gives a pretty good balance for a lot of things. Reconfigurable, machine-soldered reliability, a prefab software stack, but still enough flexibility to build novel things. reply bacon_waffle 6 hours agorootparent> It it goes wrong, you cannot buy a new one or hire repairperson at a sane price. If it has a software side, it will probably need maintainence.It&#x27;s not clear to me that the alternative provides these either. Just thinking about some of the appliance-type things I&#x27;ve had issues with lately: my oven would&#x27;ve made more sense to replace than hire a repair person, and my ISP-provided router is running their latest firmware which is horribly out of date... reply KRAKRISMOTT 13 hours agorootparentprevJust buy some spare tapeouts from digikey when building ¯\\_(ツ)_&#x2F;¯ reply eternityforest 11 hours agorootparentDoesn&#x27;t solve the issue of nobody else knowing how to build it, and the ones that do often somehow making 60$ an hour, now you&#x27;re stuck with this thing that could be your responsibility at any time. reply kbaker 14 hours agoparentprevAgreed. Also, the kinds of passive safety needed to not burn your house down in the event of a code error or other design issue.The hardware design is the last line of defense before you can do real-world damage.Things like fuses, ESD and surge protection, watchdog timers, often get overlooked in a hobbyist or even open-source design... it takes (sometimes hard-won) experience to know when these things are required. reply munk-a 13 hours agorootparentThere are also some physical constraints as well. I have an essential tremor - painting warhammer minis and doing anything with a sodering gun are forever out of my reach.That all said - I have written firmware for things that other people have wired and it&#x27;s quite fun! reply fanf2 13 hours agorootparentI have heard that using magnifying glasses or a microscope can help suppress shaking in the hands: it has a weirdly helpful interaction with the hand-eye feedback loop. Dunno if it would work for you, but it might be worth trying? reply munk-a 12 hours agorootparentI&#x27;ll have to give that a try - though it didn&#x27;t seem to help my father very much. He was a model railroader and just got used to taking several dozen passes at painting cars and locomotives. For me myself I&#x27;ve found that stress tends to make it worse so it&#x27;s a bit of a vicious cycle where trying to suppress shaking can spur it on more. Advice is never unappreciated though so thank you for you consideration! reply mitthrowaway2 10 hours agorootparentFWIW, I have a terrible hand tremor as well. I&#x27;ve found that with a good, wide-aperture magnifying glass or binocular microscope, I&#x27;m able to do soldering and even chip-level wirebonding. Having an armrest or other surface I can support my forearm&#x2F;wrist on, with a tight structural loop to the target, can also help a lot. reply jacquesm 9 hours agorootparentSecond the armrest suggestion, it makes all the difference. You can be rock steady if you don&#x27;t have to support the weight of your whole arm from the shoulder, the closer you can rest your hand to where the action is the more stable you&#x27;ll become. Another thing that helps is breath control. replyxnzakg 11 hours agorootparentprevAs much as I agree with this, buying off the shelf things, especially on the extremes of \"very niche\" (ok this kinda how&#x27;s under your \"hobbyist design\" or \"so general there are hundreds of knockoff versions with various cost cutting measures\", there is no guarantee that they have thought of all (or any) of the required safety measures... Check out Big Clive on YouTube if you haven&#x27;t already, and aren&#x27;t afraid of knowing about all the different ways products skimp on safety. reply ilyt 9 hours agorootparentprevwatchdog timer is not hardware protection. It might seem like it is, as the timer itself is in hardware, and it does occasionally protect from hardware related lockups, but it&#x27;s all too easy mistake to stick a watchdog refresh in a timer somewhere that still works even when rest of the code went tits up reply notsurenymore 12 hours agoparentprev> \"If you can use open source, you can prototype hardware\"You can prototype some hardware. I’ve looked into trying to build some stuff that goes beyond what a little prepackaged MCU dev board can do, and I can’t wrap my head around it. Too much stuff involved that in no good at. reply jacquesm 12 hours agorootparentCompared to software skills those are relatively easy to learn though and they have a longer best-before date than any kind of language&#x2F;framework kind of knowledge. reply crote 1 hour agorootparentRather the opposite, I&#x27;d say.Software is deterministic and quite easy to reason about. It either works, or it doesn&#x27;t. Hardware relies on actual physics, and even minute changes can be the difference between working perfectly fine and not working at all.A lot of hardware design is based on rules-of-thumb and institutional knowledge. Learning those as a hobbyist is incredibly difficult, and most of the time you essentially end up cargo culting what everyone else is doing - and there is no guarantee that everyone else is doing the right thing either! It is really easy to end up wasting hundreds if not thousands of dollars like this.This is exactly why companies like Adafruit have become so big. They take care of all the hard part, and provide the hobbyists with essentially a bunch of lego bricks which neatly click together. The only thing you have to do yourself is... the software. reply jacquesm 1 hour agorootparentI&#x27;ve never spent as much time on hardware bugs as I&#x27;ve spent on software bugs. If the software you&#x27;ve worked on is &#x27;easy to reason about&#x27; then you&#x27;ve led a charmed life!That&#x27;s probably also why all software is &#x27;bug free&#x27; ;)But seriously: both software and hardware have their unique challenges. But those can be overcome and just like software hardware can be &#x27;unit tested&#x27; by breaking down circuitry into manageable chunks. Adafruit is a success simply because they fill a need: the ability to create bespoke gadgets without investing lot of $ or learning a new skill. The market to programmers, not to hardware people, though I&#x27;m sure there is some overlap as well due to the convenience. But those skills are not substantially harder than software skills, they are just different.I&#x27;m kind of lucky: I got into software through hardware rather than the other way around. To me software was an infinite parts budget (bounded by RAM limitations, usually). Hardware was a running expense, computing a one-time expense (or so I thought, hah!). So I simply got more mileage out of my pocket money and Saturday job earnings by saving for a computer rather than by spending it on various hardware components. reply notsurenymore 12 hours agorootparentprevI’m not so sure about that. Learning a programming language for example is pretty easy, iterative, and had quick feedback for me. Learning years worth of math makes my eyes glaze over. I do agree on the latter half though, regarding how they’re useful for much longer. reply jacquesm 12 hours agorootparentYou won&#x27;t need &#x27;years worth of math&#x27; to be able to prototype hardware. There is plenty of tooling now that will take the sting out of timing and other nasty little details and there is plenty of hardware where those details don&#x27;t even matter all that much.Good starterpoint: and FPGA evaluation board, such as Digilent&#x27;s offerings. Those pack enormous power in a tiny setup and will teach you a ton of very valuable skills.If that looks like a hit you can decide to deepen your knowledge. reply TheOtherHobbes 9 hours agorootparentYou won&#x27;t need \"years worth of math\" to be able to prototype digital hardware.As soon as there&#x27;s a non-trivial analog element - anything frequency-dependent, resonant, exceptionally resistant to RF interference, or switching significant current - you absolutely do need that math.You can model resonant filters with DSP, but you still need to understand z-plane digital models. It doesn&#x27;t hurt to have some idea how they relate to s-plane analog models.Cook-book tinkering is plenty fun, but you really can make things explode or burst into flames if your project is switching and&#x2F;or carrying any significant load. reply jacquesm 9 hours agorootparentI&#x27;ve built massive RF stuff with high school math and it worked quite well, better than some off the shelf stuff, and that&#x27;s after a nice session with a spectrum analyzer to make sure you don&#x27;t end up spewing garbage all over the higher bands. What really helps is to have access to good measuring tools and to know how to use them, as well as people with more experience than you to help guide you.Stuff exploding or bursting into flames I&#x27;ve seen exactly once, on one of the most trivial circuits I ever built: a small boost converter for a windmill to charge batteries in low wind conditions. It worked extremely well. Until I disconnected the battery for service and then the boost converter kept on increasing its output voltage until the capacitors let out the magic smoke. Other than that stuff occasionally breaks. Oh, and if you do do RF stuff: beware of RF burns, that is a real risk, coils and capacitors in high power RF circuits should be treated with proper respect.I&#x27;d be much more wary of Lithium-Ion batteries than analog stuff and buck-boost converters are cheaper to source as complete units than to build yourself (though you definitely can if you want). Your typical hobbyist isn&#x27;t going to start off by building themselves an large inverter or a HVDC interconnect. They&#x27;re going to build amplifiers, other audio gear and maybe some measuring kit or digital devices. Sound generators, function generators and so on.By the time you reach the stage where you need to design a resonant LC circuit you&#x27;ll have picked up a lot of working knowledge and some of that will tell you what bits to avoid and what bits you can probably handle.I know plenty of HAMs that know enough math to be dangerous but they usually would not be able to do really complex stuff without access to tools (though I also know some HAMs that definitely would be able to do really complex stuff, they also have the corresponding higher level license).Let&#x27;s not pretend that everybody that builds electronics for hobby purposes is a math wizard, it just isn&#x27;t true. Though it definitely doesn&#x27;t hurt to have a basic understanding of RC and LC circuitry and to understand how to use op amps and other interesting components like that. Applying those is vastly different from designing them from scratch.Also: quite a few people have a ton of fun just building kits and slowly expanding their knowledge and there is absolutely nothing wrong with that. At the highest levels you will need that math, but there is plenty of interesting stuff to be done lower on the ladder. HN is the last place where I would expect such gatekeeping. reply mcshicks 8 hours agorootparentprevI think anytime you move past the lumped circuit model you can run into trouble. This includes digital circuits with fast edge rates. On the other hand a close reading of a component manufacturer&#x27;s application notes and reference schematics can help a lot of people who may have only limited formal training in electrical engineering. reply z500 11 hours agorootparentprevAny tips for getting started for a software engineer? I built a couple CPUs in a circuit simulator, I&#x27;d love to get these things running on silicon of some kind and benchmark them against each other, but I wonder if I would be biting off more than I can chew. reply jacquesm 10 hours agorootparentI&#x27;d definitely go the FPGA route initially, it has software like advantages such as being able to reprogram stuff without having to tear it all up and do it all over. It also elegantly avoids having to build up soldering skills (which is a bit of a pain with SMD) Once you get the hang of that some simple CMOS circuits hole-through on a breadboard would be a gateway drug to building stuff for real. If you want another in-between step I&#x27;d go for a kit of some sort, something that you want to have anyway but would rather build yourself, there are quite a few producers of such kits and they range in complexity from &#x27;blinking LED&#x27; to &#x27;build your own glass teletype&#x27; and everything in between (and even more complex).Compared to software it is a costly hobby though, and it also occupies more space beyond just a laptop. And it can be quite messy. replypetsfed 11 hours agorootparentprevCan you give an example? There may well be an easily accessed IC for it. reply notsurenymore 11 hours agorootparentMostly I was looking trying to do custom RF stuff, trying to create custom hardware. Could have used an SDR, but I think I still would need a solid handle on the math for that. reply petsfed 10 hours agorootparentThat&#x27;s definitely the realm of \"actual electrical engineer\". There&#x27;s a lot you can learn to get most of the way there without the math, but to actually understand why you&#x27;ve got e.g. an impedance matching network on your antenna trace requires some mathematical gymnastics that&#x27;s easiest to get in school. That can feel pretty frustrating, but on the other hand a lot of the hardware at work there can be had off-the-shelf as modules, so you don&#x27;t have to do any RF black magic. Just standard build-quality questions. reply01100011 10 hours agoparentprevThis reminds me of when I was in college(EE) and working at an electronics store. A small aircraft owner wanted help with a regulator to (IIRC) drop 28v down to 12v and handle a few amps. I resisted helping design a solution but he kept pushing so I suggested putting a couple TO-3 packaged 7812s in parallel. We bench tested it and it worked so he went on his way. A few years later I learned you never do that as one regulator can end up handling the load and it ends up overloaded. Instead you use a pass-transistor(or other mechanism) to allow a single regulator to do the job. I still wonder if that guy&#x27;s plane ended up going down in flames... reply ilyt 9 hours agorootparentYou can get away with it if there is some resistance in series with each one but yeah, the enemy here is that each of the regulators will have slightly different voltage and the unlucky one with highest will handle most of the current.Although I&#x27;d imagine you got lucky here because IIRC this particular&#x27;s chip voltage drops with temperature a tiny bit so technically the one that starts to heat up would drop voltage, letting other pick up the slack reply fho 5 hours agoparentprevI recently started at a big connector manufacturer... And I have to say, there is so much more that goes into connectors, even \"simple\" ones, than what is obvious to the end user. reply andyjohnson0 14 hours agoparentprevI&#x27;ve breadboarded a number of projects, but always awem to hit a wall when faced with the concerns you describe. Do you have any pointers for how to gain the knowledge to get past this? Right now I feel like I dont even know what I dont know. reply petsfed 13 hours agorootparentA lot of it comes down to being mindful of what you&#x27;re spending the most time on during assembly, but some of it is just hard-won. But I&#x27;ve learned a lot from reading Hackaday.Some simple things that you shouldn&#x27;t have to learn the hard way (but most people do):Make sure your wiring contacts are electrochemically compatible. Gold-to-gold is safe in almost every household environment.Strain relieve every wire. Solder is not meant to be structural.Every circuit component degrades over time. Heat, humidity, and dust accelerates that process. Make a plan to mitigate the ingress of each, and a plan to account for that degradation.Learn to design simple breakout-board carrier boards. The best breadboard layouts are still worse than a mediocre PCB, because the PCB doesn&#x27;t have flywires to catch on literally everything.Make sure you include mechanical support points for your designs, and pick the right size and material for your mechanical supports.All of this to say, your hardware thing is a thing first, and an expression of your software&#x2F;firmware design second. If it cannot physically survive being that physical thing, the elegance or resiliency of your code is meaningless. reply joshspankit 11 hours agorootparentPlease improve this (I have only dabbled), but I’ll add a couple points as well:- Don’t run data lines and power lines right next to each other (electric signals flow through a field surrounding the trace&#x2F;wire, not in or on the metal itself)- PCB pros avoid right angles for the same reason. Bevel your corners. (You see examples of this on every board if you’re not sure what I mean)- Verify PCB traces with a multimeter before soldering components to it (or if it’s been assembled by the PCB manufacturer, verify everything before powering it on for the first time) reply petsfed 10 hours agorootparent> - PCB pros avoid right angles for the same reason. Bevel your corners. (You see examples of this on every board if you’re not sure what I mean)If your design suffers from the consequences of this, your reach has probably exceeded your grasp. Its true that you can get noise from sharp corners, but unless you&#x27;re running SPI at maximum speed, it probably won&#x27;t cause any bugs in your project. And if you need to run that fast, you&#x27;re going to run into other, less straightforward signal integrity problems too.PCBs with right angle trances look ugly though. So I might still judge you for it, but only if you also wear white before Memorial Day. reply jacquesm 9 hours agorootparentAnd right angle traces are more prone to delamination, which is the major reason why you want to bevel your corners. reply prabhu-yu 2 hours agorootparentEtching would be difficult. ie, if you bend two traces side by side with 90 degree corner, watch the etching around the corner. ie copper may be left on the inner angle of the 90-degree turn.So, I do not use 90 degree turns for this reason, if not for the EMI reason. reply jacquesm 2 hours agorootparentYes, the EMI thing is real but not at typical hobbyist frequency ranges. But the mechanical aspects are far, far more important and right angles are simply a bad idea. Ideally the lines are smoothly flowing (like say at the bottom of the old KIM boards), but that&#x27;s not how auto routers place the traces. 45 degree angles in succession are a good enough compromise. They&#x27;re mechanically reasonably strong, they don&#x27;t delaminate and can be easily placed and used for bus patterns with closely spaced traces that will reliably etch without the outside being eaten up and the inside being &#x27;too late&#x27;. reply leptons 5 hours agorootparentprev>Don’t run data lines and power lines right next to each other (electric signals flow through a field surrounding the trace&#x2F;wire, not in or on the metal itself)Not true. The electrons certainly do travel within the copper. The movement of the electrons generates a magnetic field around the conductor, but the electricity does not \"flow through a field surrounding the trace&#x2F;wire\". The electric power absolutely does flow through the metal itself.>PCB pros avoid right angles for the same reason.This is a myth except maybe in very rare cases. Most hobbyists aren&#x27;t ever going to have a problem with right angle traces.https:&#x2F;&#x2F;www.nwengineeringllc.com&#x2F;article&#x2F;right-angle-pcb-tra...>Verify PCB traces with a multimeter before soldering components to it (or if it’s been assembled by the PCB manufacturer, verify everything before powering it on for the first time)You should be sure that your design works before sending it to be assembled. If you designed the PCB with proper software that does analysis between the schematic and the PCB design, then there really shouldn&#x27;t be any surprises that would require you to verify any PCB traces with a multimeter before soldering components. Sure you may have had it manufactured by a crap PCB company, but it&#x27;s unlikely, PCBs have gotten really easy to make. Software like KiCad if used properly make it practically foolproof to design a PCB that matches the schematic.Designing the schematic is another matter though, it&#x27;s very easy for a noob to get that part completely wrong and testing PCB traces with a multimeter is not going to fix that.>or if it’s been assembled by the PCB manufacturer, verify everything before powering it on for the first timeNot sure what that would accomplish. What are you going to test? Many components can&#x27;t even be tested unless power is applied. Seems like you&#x27;re suggesting superstition more than practical knowledge about hardware design and manufacture. reply andyjohnson0 11 hours agorootparentprevThank you. reply tuatoru 4 hours agorootparentprevThe Cave Pearl Project (arduino based underwater data loggers, used for real science in cave systems) has a blog and several Youtube videos with info about ruggedizing electronics for humid environments and temperatures from freezing to about 60 Celsius. [1] Two words: conformal coating.Lots of other good in-the-trenches reporting of hard-won knowledge in the blog. Many epoxy resins shrink significantly, for example. That may or may not be important for your project. The blog is not super condensed but it&#x27;s worth reading, especially for seeing the evolution of design and construction practise from the early years (2011) to now.There&#x27;s a book, now somewhat dated, on the Protection of Electronic Circuits from Overvoltages (lightning strikes, or fridge motors, for example): [2] TVSes (transient voltage suppressors) are still in use, however. Even varistors.Connectors are the bane of every electrical engineer&#x27;s life. There are more designs of connectors than of any other category of component, and probably there are good reasons for all of them to exist. I haven&#x27;t got any good references for this topic though.Other things like fuses, fireproof insulation on on your power cables, physical design such that prying objects can&#x27;t touch high voltages, and so are about protecting the rest of the world from your projects.Rod Elliott&#x27;s web site [3] is a mine of information for beginning to intermediate hobbyists. It&#x27;s focused on analog, audio specifically, but when you get down deep enough, everything in electronics is analog. you need to know about resistance, capacitance, and inductance, earthing (grounding) layout, and other similar topics.1. https:&#x2F;&#x2F;thecavepearlproject.org&#x2F;2023&#x2F;03&#x2F;17&#x2F;waterproofing-you...2. https:&#x2F;&#x2F;store.doverpublications.com&#x2F;0486425525.html Available on Amazon as an ebook.3. https:&#x2F;&#x2F;www.sound-au.com&#x2F;articles&#x2F;index.htm reply analog31 10 hours agorootparentprevTake things apart. Fix things, while observing how they break. There are amazing online videos on how to repair virtually anything that goes wrong with a home appliance. Make things that improve your life at home. These are things that a lot of hardware people did as kids, including myself. Get your hands involved.Look inside older stuff that predates 3d printing and cheap mold tooling, just to avoid the trap of everything being made the same way. In my case, since I&#x27;m interested in music, I&#x27;ve looked inside things like guitar pedals and amps, which often solve the problem of making something that&#x27;s robust, but that can be made profitably in short runs and small shops.Get a hold of the McMaster-Carr catalog, in paper form, and leave it in the bathroom. An old Digi-Key catalog if someone still has one. reply imachine1980_ 14 hours agoparentprevSome things that are cheaper at a low scale is quite expensive at scale, 3D printing is obvious here, your way to consume less 3D printing may be opposite to the way that regular plastic manufacturer does, so you need to adapt your process to the process of your suppliers. reply petsfed 14 hours agorootparentI wasn&#x27;t even touching manufacturing at scale, because sometimes you really do need just the one. But it should not be so fragile you can&#x27;t carry it from the garage to thermostat mounting position.I learned that the hard way when I automated the heat lamp that I put in my chicken coop. Having to noodle around with screw terminals while being pecked at by an angry rooster was not a great time. reply bytefactory 14 hours agorootparentThe rooster didn&#x27;t approve of your soldering technique? reply bonestamp2 13 hours agorootparentRooster thought he should have used chicken wire. reply ilyt 9 hours agorootparentprev3D printing looks like linear scaling and from what I saw 3D printing services are pretty cheap.Yeah they are more expensive than running printer in your garage because they need to earn money too but it&#x27;s not like the price grows with volume reply sokoloff 2 hours agorootparentAs someone who sells a low-volume niche product (as a sideline), the problem isn’t that 3D printing costs grow per-unit, but rather that they don’t meet people’s intuition of what plastic things should cost.A box that might cost $0.25 if injection molded might be $25 if 3D printed. reply peteforde 8 hours agoprevLots of gatekeeping and snark in these comments. Every time something hard gets easier, the pure who suffered hardest come out of the woodwork to inform you that the easy thing you&#x27;re doing is not as good as the hard thing they&#x27;ve been doing since you were in short pants.Composition is great for prototyping and small-scale production. As you level up and learn about optimizing BOMs and DFM, you will start to swap out MCU boards for your own designs; you&#x27;ll see how that $10 I2C rotary encoder can be replaced with $1 worth of resistors, capacitors, a Schottky diode and a hex inverter.Anyhow, I came to say that with companies like JLBPCB and PCBWay offering 3D printing and CNC services, you don&#x27;t even need to buy a 3D printer to get started.Heck, with https:&#x2F;&#x2F;wokwi.com&#x2F; you might not even need prototyping components. reply ugh123 6 hours agoparentTotally agree with your comment on the gatekeeping and snarkiness. Also my current foray into hardware (as a software guy) tells me there&#x27;s tons of low hanging fruit on the design rules side to cover all sorts of scenarios for \"production ready\" component selection, placement, and environment concerns.My gut tells me that the software market that serves hardware engineers isn&#x27;t nearly as creative or ambitious as that on pure software and even devops or infrastructure.Huge opportunity there. reply crote 1 hour agorootparentThe problem is that 1) \"design rules\" are in practice more like guidelines, and often need to be violated in order to actually get stuff made, and 2) all the data is wrong, contradictory, and cannot be trusted.A lot of the work of a hardware engineer is reading and interpreting datasheets and trying to separate the wheat from the chaff. The low-hanging fruit which can easily be automated is the easy part of the job, and writing the input data for the automation ends up taking more time than just manually doing it yourself.I have dabbled into writing some software extensions for KiCad, and some turned out to be very useful and now save me quite a lot of time. However, every time I tried to be \"clever\" and solve a seemingly easy problem, it ended up not being worth it in the end. reply e-_pusher 4 hours agorootparentprevYou are not wrong overall, but I am not sure if the opportunity is huge, at least IMO not enough to sustain a VC-backed company (or perhaps barely). As a benchmark, Altium has a market cap of 6B. The fundamental problem is that there aren&#x27;t that many HW engineers out there (compared to SWEs and SWE adjacents like DevOps etc). And the existing players are super entrenched into existing companies doing HW design.There are some interesting companies out there that I am watching, like flux.io. The problem there is that none of these companies are working on creating open-source tooling, so their endgame seems to be getting acquired by Altium, Cadence et al.I fear a future where doing even regular PCB designs will be gatekept by the Cadences and Synopysyes of the world, akin to how IC design is today. At least we have KiCad right now, which is getting really powerful and is fantastic for doing PCB development work. reply resonious 4 hours agorootparentprevI&#x27;m in a similar boat so maybe totally naive, but this seems true. I think the software industry is super rich in tooling because software engineers understand software, and can build their own software (haha..). Non-software fields have crap software because usually their only way to get some is to hire a software person who doesn&#x27;t actually understand the industry. Introducing a communication barrier like this massively dampens productivity. Things are much smoother when the person using the software can actually dig in and fix the kinks themself instead of filing a Jira ticket. reply kuratkull 2 hours agoprevInteresting, I am in the same boat with the author. Recently have started to dabble more in embedded devices. I am building a well water level sensor. First I tried to use an NRF based board, but I got bogged down with the SDK ecosystem, it&#x27;s really meant for experienced embedded engineers of companies. Then I fell back to much simpler ESP32-C3&#x2F;S3 boards, which are great, widely supported, easy to set up and pretty reliable. I hook it up to the distance sensor (HC-SR04) and make the distance calculations work. You also have to add a voltage converter if you want to run from batteries, because the sensor requires 5V - easy enough after some reading and failing. Then you have a mess of boards and cables, you need to solder it to a board which requires tools and a bit playing around. Now I was missing an enclosure, tried a few store bought junction boxes, none were perfect, and I decide to buy my own 3D printer (the future is now, print your own things, learn modelling, etc). Those are actually pretty easy compared to everything else, I printed my first modelsYou can’t beat Prusa: the printers come out of the box working perfectlyAt the cost of being old and slow. I wouldn&#x27;t be throwing roses to Prusa after they effectively ceded the market to everyone else.For $200, you can get a Sovol SV06 that&#x27;s a smarter iteration on the MK3&#x2F;MK3S (while also being open-source both in hardware and software); for $500 you can get a Bambu P1P that&#x27;s much faster and has better vertical integration through the slicer (and for $100 more than that you can get a P1S, which is high-temp ready while also doing all the same things as the P1P). reply Narushia 3 hours agoprevAs a software-only guy, this article brings me great encouragement for doing a hardware project in the future! :)Although, to be honest, my bigger problem is probably just simply not having a use case which I could use a self-built hardware project for. I don’t feel like I’m missing or lacking anything in my life or at home that could be fixed with a hardware project.Additionally, I usually want the absolute best solution to a problem that I can afford. Commercial products have satisfied me well so far. My mindset about this is that if I can just pay someone for a product that solves my problem, I will gladly do so instead of scratching my head with a self-built project (I consider my time more valuable than anything else).So I guess what really needs to happen to make me actually dip my toes in the hardware soup… is to have an annoying enough problem that cannot be solved with ready-made products on the market (either because they are bad or outright don’t exist). reply ranting-moth 1 hour agoprevI really like the software&#x2F;hardware opportunities we have today. But headlines like this just invite negative comments. It&#x27;s like saying \"if you can read a book you can become a nuclear physicist\".Or even \"You don&#x27;t need to learn svelte!\" (I love Svelte but statements like that are not helpful). reply lnsru 14 hours agoprevSounds like a typical content on today’s internet: enough buzzwords for search engine to find it and too abstract to be useful. reply the-printer 14 hours agoparentThis is a valid criticism, but I don’t think that it’s necessarily the author’s fault. reply 6D794163636F756 13 hours agorootparentI think it&#x27;s a flaw inherent to the current system. You have to make money to live and you do that, not by appeasing human readers, but by appeasing an algorithm. The world is not easily reduced into clear classifications but we&#x27;re currently forcing it into them reply iancmceachern 9 hours agoprevIf anyone needs help making their hardware projects or products real and take it to market please feel free to reach out. Contact info is in my bio. reply _benj 9 hours agoparentSaving your contact info :-)I’m not there yet but I’m working on transitioning from software to hardware… so I want to get there eventually! reply devoutsalsa 8 hours agoprevI not sure I could.I used to do microwave communications repair in the army. The most painful part of my education was basic soldering. I couldn’t solder for the life of me. I have the finger dexterity of a brick (which is to say none at all).A few years I took a comprehensive career aptitude assessment, which included testing finger dexterity. I thought I’d done really well after taking the test. I was informed I scored in the bottom 5%. If I became a surgeon, my malpractice insurance would cost more than my annual salary. reply krasin 3 hours agoparentJLCPCB PCB assembly service ([1]) is excellent and is really inexpensive. I used to reflow PCBs myself at home, but now I don&#x27;t bother.1. https:&#x2F;&#x2F;jlcpcb.com&#x2F;capabilities&#x2F;pcb-assembly-capabilities reply ilaksh 11 hours agoprevThat&#x27;s not building hardware. It&#x27;s connecting up and interfacing existing hardware components.Which probably makes more sense than designing hardware components for most applications.But it&#x27;s not the same as designing circuits etc. and the title is a bit misleading as far as that goes. reply darksaints 8 hours agoparentOf course it is building hardware. It just isn&#x27;t building all of it, which is what all of us do with everything we build, to some degree or another. I can run some wood through a CNC machine and I still count it as building something even if I didn&#x27;t grow the tree nor cut it down nor kiln dry the wood nor cut it to exact size I needed for it to be put into a CNC machine. reply chefandy 5 hours agoparentprevMaking a box of mac & cheese is still cooking— it&#x27;s just not from-scratch cooking. reply yafbum 4 hours agoprevEhh... Sometimes. I tried this modular approach with a project, some things worked very well, others not well at all. In particular I have a ton of EF interference noise in my audio circuit and no idea how to get rid of it. reply certyfreak 14 hours agoprevA thing preventing people from going into hardware(prototyping) is the cost. Software is cheaper than hardware. i.e. i reply ilyt 9 hours agoparentMonetary cost is only small part of it (as it got significantly cheaper too, at least for small electronics).The feedback loop is just very long. Few weeks to get PCB unless you pay a lot extra to get it in few days.And even if you own a 3d printer for mechanical parts that&#x27;s still day of printing reply leptons 4 hours agoparentprevNot exactly true. Many electronics manufacturers give out free samples. All kinds of free samples. When I was a kid (and even into adulthood) I would contact all the electronics manufacturers I could to get free samples. I had dozens of free Microchip PIC embedded CPUs and support chips. Back in the day Maxim semiconductor (now Analog Devices), and many others. I even got free stuff from Digikey, but that took some convincing of the right people at Digikey. Some of the products I begged and pleaded for - I got a full touchpad controller for free, including shipping, because I was a \"student\" and I was making a \"prototype\". It really wasn&#x27;t that difficult to get free electronics to learn with. And for the passive components - resistors, capacitors, coils, and other parts there&#x27;s always free broken electronics floating around, and I would harvest everything I could that I didn&#x27;t already have plenty of.https:&#x2F;&#x2F;www.microchip.com&#x2F;samples&#x2F;https:&#x2F;&#x2F;www.analog.com&#x2F;en&#x2F;support&#x2F;customer-service-resources...https:&#x2F;&#x2F;reddit.com&#x2F;r&#x2F;electronics&#x2F;comments&#x2F;1qvcr2&#x2F;how_to_prop...https:&#x2F;&#x2F;www.ladyada.net&#x2F;library&#x2F;procure&#x2F;samples.html reply crote 1 hour agorootparentSampling is a lot rarer these days. There is a reason your last two links are from 10+ years ago. Too many hobbyists tried to use sampling as a means of getting free parts for their personal projects.Sampling is intended to get a sample so the company&#x27;s expectation is that it will eventually result in an actual order. This will obviously happen when sampling to companies, and sampling to EE students means those students are more likely to choose your products when they enter the field.Sampling to hobbyists doesn&#x27;t really have any return on investment, so once they started getting thousands of requests they just shut it down. These days you are just expected to order low-quantity items from their distributors. reply syldarion 8 hours agoprevThe hardest part of the hardware experience for me so far has been the waiting. I recently took the next step in being a keyboard nerd and have been tinkering with custom macro pads.Currently printing the bottom of a custom osu! pad for the third time after a couple goofs.Absolutely a blast though, especially coming from doing purely software. Even if you&#x27;re just doing prototypes, highly recommended. reply fareesh 11 hours agoprevHardware building is an expensive hobby, and often involves aspects of engineering like heat, power, safety, etc.I don&#x27;t trust myself to build something that I can leave unattended and won&#x27;t catch fire. How does one get over this? reply _benj 9 hours agoparentI think outsourcing the “dangerous parts” i.e. buying a power supply instead of building one. Apart from that, most applications stay in the 5V range and few mA. If you are using something that requires more current then just over engineer. A motor that uses 0.5A? Buy a 3A mosfet, flipping 120v electricity? Buy a premade relay module that is already optically decoupled and just feed it 5V signals.When it comes to stuff failing in general at hobby level you either burn something instantly (plug the power to an IC backwards and see the magic smoke go away) or it just heats up VERY VERY FAST!I once plugged an external 5V power to a development board that was already USB powered but I didn’t know it… it started smelling like something was burning within a few seconds and I burned myself by touching it instead of pulling the heat camera :-) reply 01100011 10 hours agoparentprevI don&#x27;t know if you ever do, but designing with fat tolerances helps. If you&#x27;re just building something once, it often doesn&#x27;t cost much more to over-engineer it. Choose a more powerful processor than you need, add more cooling than you need, use more fuses and power-supply filtering than you need. Opto-isolate all I&#x2F;O. Test it in a hotter&#x2F;colder&#x2F;more-humid environment than you&#x27;ll use it in normally... reply jcalvinowens 4 hours agoparentprevUse listed current limiting power supplies. A 10W 5V wall wart is incapable of starting a fire no matter how badly you screw up. reply fellowmartian 11 hours agoparentprevOutsource dangerous building blocks to qualified people, overpay for quality components, learn proper wiring (ratings, crimping, etc). reply akkartik 12 hours agoprev\"If you build modern software, you’re well-versed in composition: grab a handful of existing projects—a database here, a UI framework there, an HTTP library to round it all out—and arrange them together. You write your custom logic—the stuff unique to your project—and let other people’s code do work that’s common across all projects.\"This approach certainly gets tried enough. I&#x27;d say it has some issues, though. reply Takennickname 14 hours agoprevIs there anyone on earth not using open source in some capacity? reply codetrotter 14 hours agoparentThis group of people for one.> the Sentinelese appear to have consistently refused any interaction with the outside world. They are hostile to outsiders and have killed people who approached or landed on the island.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;SentineleseBut more seriously I would say there is a difference between intentionally and incidentally using open source software.I run Linux and FreeBSD on multiple machines. I use open source software intentionally.My girlfriend runs Windows on her laptop. If we look closely I am sure we will find open source libraries being used both within the OS, and within other pieces of software that she runs. But all of that is incidental. She is not interested in software and that is fine.My mother and my grandfather both use LibreOffice. But only because I installed it for them. So neither my grandfather nor my mother really are intentional users of open source software. It just happened to be the case that their grandson&#x2F;son (me) knew about LibreOffice and installed it for them, so that they could use it to write documents and to open Word documents that other people sent to them. reply yjftsjthsd-h 14 hours agoparentprevDepends what you mean by \"using\" open source. If we include consumers of software that happens to have its source published but who couldn&#x27;t compile it even if they downloaded the source (so, >90% of Chrome users, for example), then yes there are lots of non-devs. Likewise, there are probably still some devs using licensed libraries proprietary applications using proprietary IDEs and compilers, though it&#x27;s certainly getting rarer. reply buildsjets 12 hours agorootparentWatching the penguin screen continuously reboot on Delta airlines’ janky in-flight entertainment system should not count as “Using Open Source”. reply bonestamp2 13 hours agorootparentprevI would bet that every form of motorized transportation has open source in the build or operating model somewhere. reply dizzydes 11 hours agoprevHow hard is it to remake and improve a random component on any electronic device I own? eg the control panel on my microwave or my entire TV remote.Would I need specific parts from the manufacturers?Would dissecting the existing component give enough detail for me to remake without the (I assume proprietary&#x2F;hidden) schematics? reply crote 1 hour agoparentA lot harder than building your own from scratch.When you are trying to improve an existing product, you first need to figure out what the existing part is doing. This is going to be incredibly difficult because you do not have access to the original documentation. Often it involves proprietary parts for which zero documentation is publicly available, and you are going to need quite expensive tooling to figure out what it is doing without those docs.In general I do not really think this is viable to a beginner for anything beyond completely trivial product. A microwave is a really bad idea due to the voltages and currents involved (you can easily end up killing yourself). A TV remote is probably doable, but mostly because you can do that without opening up the remote at all and just need to look at the (often standardized) IR signals coming out. reply TheOtherHobbes 9 hours agoparentprevuwave control panels are pretty simple - usually just some buttons, a display, maybe a rotary controller, and an embedded controller IC.But you really do not want to be experimenting with custom control unless you know exactly what you&#x27;re doing. Aside from the risk of nuking food and&#x2F;or accidentally bypassing the door switch and microwaving yourself&#x2F;partner&#x2F;kids&#x2F;pets&#x2F;etc, most uwaves have huge power capacitors near the controller board.An unplanned encounter with one of those can kill you.Here&#x27;s a sample circuit. It&#x27;s not super-complex. But there&#x27;s a lot to go wrong, and it&#x27;s really not a beginner project.https:&#x2F;&#x2F;www.electronicsforu.com&#x2F;electronics-projects&#x2F;microwa...Remotes are basically the same with (usually) an IR transmitter, more buttons, and no dangerous power switching. It&#x27;s not all that hard to clone one, but the hard part is making the tiny physical buttons and inventing a better UI.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=m7z4CU5mw9E reply jononor 3 hours agoparentprevThis is half reverse engineering (understanding the existing part), and half engineering. The reversing can be quite difficult for less common parts&#x2F;designs, and is partly a different skillset. But for standardized interfaces like an IR TV remote it can be pretty easy. reply _benj 9 hours agoparentprevMaybe a bit optimistic but I don’t think it’d be to hard.Most devices already use pretty standard components, a microwave for example would have “something” to switch the thing on and off. It might be a solid state relay or something like that. Maybe it has multiple, one to control the fan, light, motor to turn the things around, and the thing that emits the microwaves.But once you figure out what signal is needed to start those (a bit of intuition and a multimeter might suffice) you are off to the races!One you open a few house appliances it’s easy to see how they optimized for cost, so you seldom find fancy protocols or components unless they are absolutely necessary.In a toaster over for example, you might find a temperature sensor and it would likely take a bit of fever engineering to calibrate the temperature to the voltage output (I’m assuming that is a cheap analog sensor instead of something that spits a digital I2C signal for example).So yeah! It shouldn’t be too hard to hack your devices :-) reply em3rgent0rdr 7 hours agoprevIf you think building hardware is as easy as importing a library, you can burn your house down. reply lifeisstillgood 10 hours agoprevSide question, are there hobbyist groups or meet-ups that one would recommend ? reply ilyt 9 hours agoprevWhat &#x27;using open source&#x27; is some special thing people need to learn ? You install a program and you use a program, &#x27;open source&#x27; changes nothing there unless you want to start modifying it reply monero-xmr 2 hours agoprev [–] So I’m posting this way late and I doubt anyone will read the comment. But I did a hardware startup once and was surrounded by other hardware startups in the space we were in.Ughhhhhhhh operating system updates, internet issues, test kit from China that we had to use a specific version of cracked Windows XP and still do live support in broken English at midnight.Hardware is hard - Never again! replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author emphasizes the benefits and accessibility of creating hardware products utilizing open-source code and microcontrollers, highlighting the ease and flexibility of various boards and software ecosystems like Arduino, MicroPython, and CircuitPython.",
      "The author underlines the convenience of using a two-wire serial data standard called I2C and cable standards such as StemmaQT and Qwiic, which simplify the building process.",
      "They also draw attention to the advent of 3D printing and Computer-aided Design (CAD) tools that facilitate manufacturing custom enclosures for hardware projects, encouraging readers to delve into DIY electronics creation."
    ],
    "commentSummary": [
      "The summary discusses the difficulties and limitations of creating hardware using open-source resources, such as bridging the gap between prototyping and developing production-grade hardware.",
      "It emphasizes the DIY character of open-source hardware projects and highlights the significance of safety measures, proper measuring tools, and guidance for successful execution.",
      "It touches on the complexities of hardware design, the use of 3D printing, and the problems encountered while designing and prototyping, closing with the challenges and criticisms of constructing hardware projects without access to proprietary schematics."
    ],
    "points": 268,
    "commentCount": 101,
    "retryCount": 0,
    "time": 1693935215
  },
  {
    "id": 37391584,
    "title": "The Federal Helium reserve is for sale",
    "originLink": "https://www.gsa.gov/about-us/regions/region-7-greater-southwest/region-7-newsroom/greater-southwest-feature-stories-and-news-releases/gsa-announces-sale-of-federal-helium-system-assets-06222023",
    "originBody": "Skip to main content An official website of the United States government Here’s how you know U.S. General Services Administration Buy Through Us Sell To Government Real Estate Policy & Regulations Small Business Travel Technology About Us Search Per Diem Lookup Home About Us Regions Region 7Greater Southwest Region 7 Newsroom Greater Southwest Feature Stories and News Releases GSA Announces Sale of Federal Helium System Assets GSA Announces Sale of Federal Helium System Assets - Updated June 22, 2023 Refer to the project's website for updates and information. TEXAS - Today, the General Services Administration (GSA) announced the upcoming sale of the Federal Helium System assets, currently managed by the Bureau of Land Management (BLM), as directed by Congress under the Helium Stewardship Act of 2013. In accordance with that law, BLM is required to sunset its management of the system and report any excess helium and helium assets to GSA to follow the statutory disposal process. The sale process, planned to start July 12, 2023, will include the Cliffside Gas Plant, Federally owned Plant Equipment, Mineral Rights, Helium Storage Reservoir, Natural Gas Wells, and Federal Helium Pipeline. GSA expects the sales process will take between 8 and 9 months, and will engage with industry and stakeholders throughout to ensure an orderly and efficient transfer of assets. The Cliffside Gas Plant, located at 13301 Brickplant Road, Amarillo, TX, is situated on two leased parcels of land totaling 8.108 acres near Amarillo, Texas. The property encompasses a range of primary and support buildings, including offices, warehouses, maintenance facilities, laboratories, and storage areas. The Federal Helium System is also comprised of plant equipment, including a booster compressor, natural gas chiller skid, metering equipment, spare parts, emergency generators, storage tanks, and other machinery critical to the helium enrichment process. Some of the plant equipment is privately owned, with the BLM maintaining operational and minor maintenance responsibilities through a lease agreement. In addition to the facilities, the sale encompasses Mineral Rights acquired by the Federal Government from 1930 to 1942. These subsurface ownership interests cover approximately 38,000 acres of gas and approximately 60 acres of oil resources, providing an opportunity for future exploration and development. The Helium Storage Reservoir, known as the Bush Dome, is a natural geologic formation located approximately 3,000 feet below the surface. The reservoir has historically held up to 44 billion cubic feet (Bcf) of helium, which includes both federally owned stored helium and native helium commingled with natural gas. At the time of disposal, it is estimated that the storage reservoir will contain approximately 4 plus Bcf of proven and prospective federally owned helium (native and reserve), approximately 2 Bcf of privately owned helium, along with approximately 60 Bcf of federally owned natural gas (according to BLM Helium Operations Statistical Report Issued June 2022). The Federal Helium System further encompasses a network of 23 natural gas wells some of which serve as high-pressure injection wells. These wells have been instrumental in supplying natural gas to the system, and they offer potential opportunities for ongoing production and utilization. Crucial to the system's operation is the Federal Helium Pipeline, which spans approximately 423.24 miles, connecting the Cliffside Field to privately owned helium refineries across Northern Texas, the Oklahoma panhandle, and Southern Kansas. The pipeline facilitates the production, transmission, storage, and delivery of crude helium to refineries. The Federal Helium Pipeline works in conjunction with privately owned refineries and BLM and typically delivers more than 2 million cubic feet (MMcf) of crude helium per day to the refiners. It has been a reliable conduit, delivering millions of cubic feet of crude helium daily. Detailed information about the sale, including bidding procedures and asset specifications, can be found on the GSA website. Interested parties are invited to review the comprehensive offering and submit their bids within the specified timeline. For inquiries regarding the upcoming sale, contact William.rollings@gsa.gov. For inquiries regarding BLM, contact Mjanderson@blm.gov. For other questions, contact, R7media.inquires@gsa.gov. ### About GSA: GSA provides centralized procurement and shared services for the federal government, managing a nationwide real estate portfolio of nearly 370 million rentable square feet, overseeing approximately $75 billion in annual contracts, and delivering technology services that serve millions of people across dozens of federal agencies. GSA’s mission is to deliver the best customer experience and value in real estate, acquisition, and technology services to the government and the American people. For more information, visit GSA.gov and follow us at @USGSA. Print Page Email Page Last Reviewed: 2023-07-26 Home Resources for … Americans with Disabilities Citizens and Consumers Federal Employees GSA Employees Native American Tribes Presidential & Congressional Commissions, Boards or Small Agencies Small Business State and Local Governments Governmentwide Initiatives Centers of Excellence Climate Action and Sustainability Diversity, Equity, Inclusion and Accessibility Federal Cybersecurity ID, Credentials, and Access Management Information Quality Open Data Plain Language Customer Support Contact Us Customer Service Directors Vendor Support Center Organization Leadership Directory Staff Directory Reference Agency Financial Report Budget and Performance Catalogs Orders & Directives Forms Website Information A-Z Index Sitemap Also of Interest Data.gov Whitehouse.gov Tools eBuy eLibrary FBF.gov GSA Advantage GSA Auctions Facebook Twitter linkedin YouTube instagram Blog email JOIN THE CONVERSATION GSA.gov An official website of the U.S. General Services Administration Accessibility statement Website Policies Reports Office of the Inspector General No FEAR Act FOIA Requests Board of Contract Appeals Looking for U.S. government information and services? Visit USA.gov",
    "commentLink": "https://news.ycombinator.com/item?id=37391584",
    "commentBody": "The Federal Helium reserve is for saleHacker NewspastloginThe Federal Helium reserve is for sale (gsa.gov) 257 points by pontifier 20 hours ago| hidepastfavorite242 comments dang 12 hours agoWe changed the URL from https:&#x2F;&#x2F;disposal.gsa.gov&#x2F;s&#x2F;property&#x2F;a0Xt000000DPeSLEA1&#x2F;feder... to one with more background.I&#x27;m told that https:&#x2F;&#x2F;www.blm.gov&#x2F;programs&#x2F;energy-and-minerals&#x2F;helium&#x2F;fede... is also good.Thanks to the users who suggested these! reply Caligatio 15 hours agoprevTom Scott did a video on the National Helium Reserve a few years back: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=mOy8Xjaa_o8 reply aylmao 12 hours agoparentHuh, the video does mention they were in the process of privatizing it (at around 4:10 [1]) planning to be \"stepping out of the helium activity and transferring it to private entities\" by 2021 (guess it got delayed due to COVID?).The Wikipedia page for the Helium Act of 1925 [3], which created the National Helium Reserve, does mention USA was the only important source of helium at the time, and amongst other things the act banned Helium exports. Given the rarity of Helium, this sounds like a good idea.This privatization effort seems to be part of the Helium Privatization Act of 1996 [2], passed under Bill Clinton, and I couldn&#x27;t quickly find any reasoning for its implementation (perhaps I&#x27;m not Googling the right question?). I wonder why they decided it&#x27;d be better to privatize it, considering the USA (at least as of 2018) still accounted for over half of worldwide helium exports [4]. It does still sound like a strategic and rare resource worth keeping under tight control, IMO.[1] https:&#x2F;&#x2F;youtu.be&#x2F;mOy8Xjaa_o8?si=hMt24B9FMyy-TSBI&t=250[2] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Helium_Privatization_Act_of_19...[3] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Helium_Act_of_1925[4] https:&#x2F;&#x2F;www.sciencedirect.com&#x2F;science&#x2F;article&#x2F;pii&#x2F;S235248472... reply cogman10 10 hours agorootparentClinton famously said \"the era of big government is over\" [1] I can absolutely see privatizing a reserve as being one of many bills meant to cut back on the size and scope of the government.[1] https:&#x2F;&#x2F;clintonwhitehouse4.archives.gov&#x2F;WH&#x2F;New&#x2F;other&#x2F;sotu.ht... reply plussed_reader 10 hours agorootparentprevFits with erosion of regulation under Gingrich; veto override was on the table and Clinton capitulated, like with the telecom act of that year. reply nradov 6 hours agorootparentPresident Clinton supported the Helium Privatization Act of 1996. This wasn&#x27;t a veto override situation.https:&#x2F;&#x2F;www.presidency.ucsb.edu&#x2F;documents&#x2F;statement-signing-... reply pontifier 20 hours agoprevThis is the entire system including the facility, hundreds of miles of pipeline, helium rights for many helium producing wells, existing storage and delivery contracts, and 800 million cubic feet of helium.A stockpile of 1 billion cubic feet of helium only is for sale as a separate lot: https:&#x2F;&#x2F;disposal.gsa.gov&#x2F;s&#x2F;property&#x2F;a0Xt0000005z684EAA&#x2F;feder... reply max51 10 hours agoparentI know that the info can probably be found elsewhere, but it never stop to blow my mind when I see the gov selling off something extremely expensive with nothing more than a few lines of description and a picture of the front sign. I looked at the pdf document, almost all of it is legal stuff that doesn&#x27;t describe the actual facility. It feel like they already got interest (lobbying?) buyers and the auction is just a formality. reply quickthrowman 8 hours agorootparentFrom the IFB> 3. INSPECTION No one will be allowed access to the Property without the presence of a BLM employee or designee. Bidders are invited, urged, and cautioned to inspect the Property prior to submitting a bid. Photos provided by the Government may not represent the condition or existence of any improvements of the Property and are NOT to be relied upon in place of the Bidder&#x27;s own inspection. Any maps, illustrations or other graphical images of the Property are provided for visual context and are NOT to be relied upon in place of the Bidder&#x27;s own inspection. The failure of any bidder to inspect, or to be fully informed as to the condition of all or any portion of the Property, will not constitute grounds for any claim or demand for adjustment or withdrawal of a bid after the auction.A potential buyer is expected to do their own due diligence before submitting a bid. This collection of assets and contracts is likely worth tens or hundreds of millions of dollars, any potential buyer will have a team doing due diligence. reply vorpalhex 9 hours agorootparentprevNah, that&#x27;s just government auctions.I was looking at ground based inflatable satcom rigs - these things run 250k+. All the descriptions are a model number and _maybe_ what bands it targets. reply mpreda 13 hours agoparentprev> and 800 million cubic feet of heliumI don&#x27;t understand why you&#x27;d measure the amount of a gas in volume units (e.g. cubic feet) given that any gas is \"elastic\" in volume, i.e. can take pretty much any volume depending on the pressure. reply ceejayoz 13 hours agorootparenthttps:&#x2F;&#x2F;www.law.cornell.edu&#x2F;cfr&#x2F;text&#x2F;43&#x2F;3195.11> Standard cubic foot (SCF) means the volume of gaseous helium occupying one cubic foot at a pressure of 14.7 psia and a temperature of 70 degrees Fahrenheit. One liter of liquid helium is equivalent to 26.63 scf of gaseous helium. One U.S. gallon of liquid helium is equivalent to 100.8 scf of gaseous helium. One pound of liquid helium is equivalent to 96.72 scf of gaseous helium. If BLM approves, you may use appropriate gaseous equivalents of volumes of helium mixtures different from these figures. reply feoren 11 hours agorootparentprevI hate it when people don&#x27;t add the word \"standard\" to gas quantity units like this, but that is almost always what they mean. A \"standard cubic foot\" has the same dimension as moles; that is, it&#x27;s actually a count of the number of atoms or molecules. reply p_j_w 13 hours agorootparentprevIf it’s anything like SCUBA tanks, then the 800M cu ft is specified at 1 atm at room temperature. It’s a actually an intuitive way to express how much gas you’re getting. Specifying it by N would be borderline incomprehensible to most people. reply danzk 11 hours agorootparentprevhttps:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Standard_temperature_and_pre... reply runeofdoom 18 hours agoprevWhy is it for sale? reply VygmraMGVl 17 hours agoparent10 years ago, Congress decided we needed to transition off of it. Large amounts of the stockpile were sold off from 2013-2018 and this is the final part of the plan.https:&#x2F;&#x2F;www.blm.gov&#x2F;programs&#x2F;energy-and-minerals&#x2F;helium&#x2F;fede... reply hypercube33 13 hours agorootparentTransition off of it? Dont we need it for superconducting coolant and some other things? reply bonestamp2 12 hours agorootparentYes. MRI machines need it, although I guess that kind of falls into the superconductor category. But I call that use case out because it&#x27;s probably a good idea to have the government, or some trusted caretaker, look after at least two strategic stockpiles. reply westurner 11 hours agorootparentprevFWIU Nuclear Fusion can use (and produce) 4He (&#x27;He4&#x27;) as fuel.I think it makes sense to retain our nation&#x27;s helium reserves. reply twarge 5 hours agorootparentYou are thinking of helium-3, of which there is none stored here.It is very much harder to fuse helium-4. reply nathanfig 15 hours agorootparentprevThanks! reply nathanfig 17 hours agoparentprevHad to scroll past a ton of doomsayers and jokes to find this obvious question. I&#x27;d like to understand the decision before speculating the meaning. reply achates 9 hours agorootparentThe top voted comment is always some variation of \"capitalism bad\". reply 93po 15 hours agoparentprevCynical take: People in congress have wealthy contacts that want to buy and profit from this, and likely include the congress member as part of the profit sharing in some concealed mannerGenerous take: congress recognizes government entities are inefficient and do a poor job at things like properly pricing and providing goods and services, which is explicitly outlined as a reason congress gave: selling it at market-driven pricesThey give other reasons but there&#x27;s basically zero reason to trust them. The truth is likely somewhere between the two takes above. reply jmount 13 hours agorootparentIt isn&#x27;t a cynical opinion if that turns out to be what is cynically being done. reply TheDudeMan 12 hours agorootparentIt&#x27;s cynical if it is presented without evidence. reply xattt 9 hours agorootparentPast behaviour predicts future behaviour. reply parineum 14 hours agorootparentprevActually, both need to be true, to an extent.Government being inefficient is required for private companies to have any interest in ownership because profit is the incentive to solve market inefficiency.If the government was doing an awesome job, the private sector wouldn&#x27;t have any interest. reply velcrovan 13 hours agorootparentThis is quite a rosy take. The private sector is always interested in capturing new customers, and lobbying to shut down public services is a great way to do that. It&#x27;s pretty simple, first you strip the service or institution of funding, do other things to degrade operations, then you complain that it’s a huge problem that only the private sector can fix. Exhibit A, USPS. Exhibit B, US public schools. Exhibit C, the US VHA. Exhibit D, the UK’s NHS and Ontario Canada’s provincial healthcare system. reply kiicia 12 hours agorootparentalso any privatized railroad network reply parineum 10 hours agorootparentprevI can&#x27;t help but notice you didn&#x27;t give any actual examples of what you&#x27;ve said happens. All of those government programs still exist. Where&#x27;s the example of the shut down public service?Helium party balloons exist because the government is pricing helium below market value which both causes wasted helium and prevents private competition. Notice how USPS, which is required to operate as a business would (paying its own bills, which it does) has competition in the market?There&#x27;s definitely a role for the government in a lot of sectors but I can&#x27;t for the life of me imagine why helium should be owned and operated as a government service. reply selimthegrim 7 hours agorootparentLet a thousand HaaS startups bloom? reply RodgerTheGreat 13 hours agorootparentprevIf the government was doing a sustainably awesome job, the private sector could easily have interest in destroying it for short-term gain. reply fragmede 13 hours agorootparentprevlol, the 90&#x27;s called, they want their \"government can&#x27;t do anything erficiently\" hot take back.I thought we&#x27;d collectively realized that \"run the government like a business\" was this ridiculous notion that the owning class sold us to raid public coffers to enrich their own, to our detriment. reply parineum 10 hours agorootparentUSPS is run like a business and is one of the most successful and well liked arms of the government. reply bhickey 14 hours agorootparentprevOr someone wants to exploit a natural monopoly. reply aylmao 12 hours agorootparentUnfortunately, this is not a far-fetched possibility in this case, given the rarity of helium. reply parineum 10 hours agorootparentprevWhy is it a natural monopoly? It&#x27;s a monopoly right now because the government has prices so artificially low (subsidized by tax dollars) that private companies can&#x27;t compete. reply echelon 14 hours agorootparentprev> If the government was doing an awesome job, the private sector wouldn&#x27;t have any interest.Or, if the government was doing an awesome job, the private sector might want to get rid of public sector price ceilings.The private tax prep lobby wants to keep the government out of tax filing.Logistics companies want to kill the USPS. reply aylmao 12 hours agorootparentI&#x27;m from a country where the government has several institutions to provide healthcare. It&#x27;s not the absolute best, and depending on the institution one qualifies for it might not be quickest or cover all conditions.As administrations have come and gone, there&#x27;s been a back and forth between officials who want to privatize health, claiming inefficiency, dilapidated facilities and that the system is a drag on public finances, and officials who want to save the system from what they claim is purposeful gross mismanagement by administrations who want excuses to privatize it.Overall, even if not as pristine or efficient as the private sector, this system of healthcare does means the private industry has to compete with \"free\".When I have a cold, I don&#x27;t think I&#x27;ve spent more than $10-20 on a private doctor&#x27;s appointment, out of pocket with no insurance. I had a rare eye condition called Keratoconus. In the USA, the specialized procedure to treat it seems to generally cost between $2,500 and $4,000 per eye [1]. I paid about $650 per eye on a private ophthalmology clinic, again, with no insurance.EDIT: To add an addendum, and in the topic of \"efficiency\", whenever I&#x27;m back home I tend to have more face-to-face time with my doctor. There isn&#x27;t a team of nurses on every clinic to talk to and do the menial work. I even book appointments directly via WhatsApp with my gastroenterologist, and transfer money directly to their bank account, instead of going through a front-desk secretary, forms, and apps&#x2F;paperwork. Without insurance \"networks\" I hear of a good doctor and just go, no problem.This also means I tend to go to the doctor when I&#x27;m home, rather than when I&#x27;m in the USA. I find very interesting how for me personally, the experience seems to be much better in a country with an overall lower purchasing power than the USA.[1]: https:&#x2F;&#x2F;www.nvisioncenters.com&#x2F;corneal-cross-linking&#x2F;costs-a... reply Brian_K_White 12 hours agorootparentprevThe market will efficiently squander it on party balloons. reply parineum 10 hours agorootparentTo the contrary. If Helium is as rare, precious and limited as we&#x27;re led to believe, the price caps would be removed and helium prices would skyrocket to what the market would bear. I guarantee hospitals are going to pay more for helium than party city.Helium prices are artificially low leading to it&#x27;s irreverent use. replygarfieldnate 5 hours agoprevI&#x27;m hoping that the sale is restricted to US-based entities, because this seems like a precious resource which could easily get bought up by a foreign power looking to exert some influence. reply fmajid 1 hour agoparentPresumably that would fall within the remit of CFIUS. reply pmontra 14 hours agoprevFor what&#x27;s is worth, it&#x27;s about 22.6 M cubic meters, a cube with a side of 2.83 km.I didn&#x27;t check if they are storing it as a compressed gas but they probably do. 1500 psi is about 100 bar. No more a cube but still a very big array of 28.3 m tall tanks. reply jaycroft 10 hours agoparent283 meters, not 2.83km. Still big though. The helium is stored underground in a salt dome (that was once full of natural gas). See here for more: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;National_Helium_Reserve reply pmontra 2 hours agorootparentYou are right, 283 * 283 * 283 = 22,665,187 reply civilitty 15 hours agoprevIn case anyone was wondering, the (refundable) fee to submit a sealed bid is $5 million. reply posnet 17 hours agoprevAccording to the GSA themselves, the value of the helium there is ~$100,000,000 [0] though that is 2019 prices, I believe it has gone up since then.Apparently for diving purposes it&#x27;s as high as $2.0 per cubic foot. [1][0]: https:&#x2F;&#x2F;pubs.usgs.gov&#x2F;periodicals&#x2F;mcs2020&#x2F;mcs2020-helium.pdf[1]: https:&#x2F;&#x2F;gue.com&#x2F;blog&#x2F;the-price-of-helium&#x2F; reply tristor 14 hours agoparentDepending on who you ask, the value of the crude helium there is around $300M to $360M. The $2-$3&#x2F;cf for refined helium isn&#x27;t really that relevant, since what is included is unrefined, if it were refined it&#x27;d be worth many billions. reply westurner 11 hours agorootparentWhat is it worth as isotopes He3 and He4; e.g. for Nuclear Fusion, superfluidity and superconductivity experiments, and medical imaging that probably can be done without Helium? reply thorncorona 7 hours agorootparentNot much because the total market cap isn’t high for isotopes.. reply jquery 17 hours agoparentprevThat&#x27;s hilariously off, much like how the \"market value\" of rare earth asteroids is in the $trillions... due to a shortage that wouldn&#x27;t exist if we could mine said asteroids... the value of the helium is much, much higher than $100M. reply markl42 7 hours agoprevI wonder if the price is inflated reply markdbullock 5 hours agoparentCosts have ballooned reply anovikov 17 hours agoprevAverage concentration of helium in natural gas is 0.05%, anywhere from 0.01% to 7%. U.S. proven reserves of natural gas contain over 10 billion cubic meters of helium even when simple extraction methods (that capture about 1&#x2F;3 of it), are used. Problem is exaggerated. reply istjohn 15 hours agoparentI&#x27;d like to think we won&#x27;t have any use for natural gas in the not-too-distant future. reply jonlucc 12 hours agorootparentHank Green just posted a video about this recently, and he addresses this. In the past, helium was extracted alongside natural gas, but there is no reason the two need to be linked. As natural gas prices go down and helium prices go up, it makes sense to drill helium pockets only for the helium, and there are a few operations to do exactly this underway. reply njarboe 14 hours agorootparentprevI&#x27;d guess that by the time we are not extracting natural gas it will be economical to source Helium from Jupiter&#x27;s atmosphere. reply jhj 12 hours agorootparentprevIt&#x27;s an important feedstock for producing a wide variety of chemicals, and will likely continue being so. reply happytiger 14 hours agorootparentprevWhy would you think that’s likely? reply piuantiderp 9 hours agorootparentBoggles my mind how ignorant some people are when it comes to oil and gas. The modern world is not possible without them. No solar panels, no electric cars, no cellphones for everyone and their mom and no food for 10Bn people. reply happytiger 3 hours agorootparentYou are absolutely right. I am a lifetime environmentalist, but as I’ve learned I’ve become disenchanted with the current societal direction; it’s more based on ideological foundations than anything that squarely addresses the reality of objective sustainability.There is so much groupthink (most due to the political manipulation) that you can’t talk to people. They’re so caught up in group messages that they don’t think for themselves or have the data or Mind even get it.It’s the most worrying thing. reply anovikov 1 hour agorootparentprevIt is entirely possible and we are dead close to the deployment speed of renewables that will get us there with the natural rate of retirement of industrial equipment. Will be there by 2030 latest. People who claim otherwise did not observe the insane rate of production increases of all kinds of renewables-related tech.But, natural gas will be still produced as an industrial feedstock; annual world consumption of helium, assuming 100% recovery rate (which may be possible or almost possible if supply is tight), can be almost produced from the amount of natural gas consumed for non-energy use worldwide, i.e. as industrial feedstock. Which sort of guarantees availability in the future too. reply joelthelion 15 hours agoparentprevMost of that natural gas should stay under the ground if we want to somewhat mitigate climate change... reply blooalien 14 hours agorootparentNow we just gotta convince our rich overlords that life is more important than more money for the rich. That shouldn&#x27;t be too hard to accomplish, yeah? reply bonestamp2 12 hours agorootparentThat&#x27;s part of it. But electricity is still expensive, so I don&#x27;t see a lot of people wanting to switch their natural gas heating and cooking to electricity anytime soon. We need a massive investment in nuclear and solar to bring down the cost of electricity. reply BurningFrog 14 hours agorootparentprevYou can always pump it back after extracting the helium. reply Retric 12 hours agorootparentThat requires you to store a frankly insane volume of gas.It might happen, but only at vastly higher helium prices. reply mikrotikker 12 hours agorootparentprevGiven that fossil fuels have allowed artificial expansion of the human population that would be sentencing large swathes of people to death. reply nektro 6 hours agoprevwhat an awful idea reply aurizon 10 hours agoprevMany deep wells with impermeable cap rocks would assure a USA supply - these well vent their He because it is 1-3% He. Here is one:- https:&#x2F;&#x2F;www.firsthelium.com&#x2F;there are hundreds like it, reply gustavus 18 hours agoprevThe wikipedia on this provides some context> The National Helium Reserve, also known as the Federal Helium Reserve, is a strategic reserve of the United States, which once held over 1 billion cubic meters (about 170,000,000 kg)[a] of helium gas. The helium is stored at the Cliffside Storage Facility about 12 miles (19 km) northwest of Amarillo, Texas, in a natural geologic gas storage formation, the Bush Dome[2] reservoir. The reserve was established with the enactment of the Helium Act of 1925. The strategic supply provisioned the noble gas for airships, and in the 1950s became an important source of coolant during the Cold War and Space Race.I for one am in favor of keeping it as a national resource in order to prevent the development of a zeppelin capability gap between us and the enemy.EDIT:I appreciate the rebuttals below, apparently Helium is important in the usage and production of MRI, IC fabrication, and cooling nuclear reactors. Pushes a reconsideration of the sell off, plus the possible resurgance of steampunk. reply arcticbull 18 hours agoparentHelium is critical for all sorts of things, not least IC fabrication and cooling MRI magnets.This was one of the big issues at the start of the Ukraine invasion because they&#x27;re one of the world&#x27;s preeminent suppliers.The big problem is that there&#x27;s a finite supply - it comes mostly from natural gas wells - and it&#x27;s running out. Being lighter than air it just goes up and into space. Once we&#x27;re out, we&#x27;re out. reply perihelions 17 hours agorootparent- \"This was one of the big issues at the start of the Ukraine invasion because they&#x27;re one of the world&#x27;s preeminent suppliers.\"That one was actually neon. It has nothing to do with natural gas; it&#x27;s a byproduct of the cryogenic distillation of air, which steelmakers do on an industrial scale to get pure oxygen. As you point out, here&#x27;s not much helium in the Earth&#x27;s atmosphere; rather, since it (helium-4) is the product of alpha decay of geologic thorium and uranium, it accumulates in the same kind of places as natural gas. Hence: Texas.There was a large HN thread on the neon thing here,https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30457490 (422 comments) reply thehappypm 16 hours agorootparentAlso, helium tends to escape the atmosphere into space! Air is just a ton of colliding molecules, and something like helium has an atomic mass of ~4, compared to say nitrogen, which has an atomic mass of ~14, and it is in the N2 form, so it has a mass of ~18. So, an N2 molecule is way more massive than a helium atom. As a result, helium at the same temperature as nitrogen has a much higher average velocity and can escape the earth&#x27;s gravity at a high rate. reply pdonis 15 hours agorootparent> it is in the N2 form, so it has a mass of ~18I think you mean ~28 (2 times ~14). reply thehappypm 6 hours agorootparentYup, typo! reply arcticbull 17 hours agorootparentprevHelium too [1] although definitely also neon.[1] https:&#x2F;&#x2F;cen.acs.org&#x2F;business&#x2F;specialty-chemicals&#x2F;War-Ukraine... reply perihelions 17 hours agorootparentYour article&#x27;s talking about helium from Algeria, though?- \"The helium shutdown in Arzew [Algeria] is a result of high natural gas demand in Europe, due in large part to Russia’s invasion of Ukraine. Helium is found alongside natural gas in conventional wells. Algeria normally compresses natural gas into liquid form at Arzew for global transport by ship. During that process, it’s economical to extract helium because it liquefies at much higher pressures and lower temperatures than natural gas, explains industrial gas consultant Jon Raquet.\"- \"But now, much of Algeria’s natural gas is being sent to Spain via pipeline, making separation impractical.\" reply arcticbull 16 hours agorootparentMy understanding is that Ukraine and Russia both produce a lot of natural gas and hence helium, and that the supply to the west from Russia was cut off due to sanctions and further threatened in Ukraine due to conflict itself.The shifting mentioned in the article is further knock-on effects of the war and its impact on energy markets - and how those further constrain the global supply chain for He.This isn&#x27;t my area of expertise though so please do let me know if I&#x27;ve misunderstood. reply perihelions 16 hours agorootparent- \"produce a lot of natural gas and hence helium\"Right about gas, but it doesn&#x27;t follow that they&#x27;ve invested in infrastructure to cryogenically separate helium from gas fields, the way they did with neon (at steel plants). (That was the colorful thing about the neon crisis: every country in the world has enormous neon resources; the list of countries that can produce industrial amounts on 99% pure. There are higher grades available for specialized purposes, but using lower grades doesn&#x27;t save any helium.https:&#x2F;&#x2F;zephyrsolutions.com&#x2F;what-are-the-different-grades-of... reply gammarator 17 hours agorootparentprevNope! The problem is that Congress chose to liquidate the reserve’s holdings below market cost a decade ago. reply pirate787 15 hours agorootparentIt&#x27;s auction, what do you mean \"below market cost\"? reply natch 15 hours agorootparentprevSince we elect idiots, we get idiotic laws and actions. And then our children get the problems we deserve. reply mrguyorama 14 hours agorootparent\"The government is inefficient and can&#x27;t do anything right and if you elect me I can prove it!\" reply brianwawok 16 hours agorootparentprevYes exactlyAnd why the price to filly party baloons has gone up 10x over the last 10-20 years.. reply dghughes 17 hours agorootparentprevOr consumer-grade old style spinning hard drives. reply flangola7 17 hours agorootparentOld style? What other gases are used? reply Brian_K_White 10 hours agorootparentThey are saying that the spinning disks with helium are old, which is silly. Flash is fast and convenient but a terrible thing to rely on for data storage. reply dghughes 14 hours agorootparentprevRegular air I&#x27;d say 78%N 21%O + 1% other. reply gammarator 17 hours agorootparentprevNope! The problem is that Congress chose to liquidate the reserve’s holdings below market cost a few decades ago. reply mschuster91 17 hours agorootparentprev> Once we&#x27;re out, we&#x27;re out.Not exactly. Helium is a part of radioactive decay and as such continuously produced, so in a pinch we might use filters in the air from nuclear plants or large deposits of radioactive minerals as an alternative source. The question is just how much can be produced that way. reply dhx 6 hours agorootparentAccording to [1], in a given year, 5000 tons (I&#x27;ll assume metric ton which is more generous) of helium is produced by alpha decay of radioactive ores in the Earth&#x27;s crust. At 0.1785 kg&#x2F;m³ for Helium, this is 0.89 million m³ of helium produced by natural alpha decay each year.According to [2], in a given year, 160 million m³ of helium is extracted across the planet. This rate of extraction is 180x the replenishment rate.According to [2], there are at least 12061 million m³ of helium reserves known to exist and have been measured&#x2F;estimated.The timeframes for depleting this precious resource are incredibly short. The known 12061 million m³ of helium reserves, making the very generous assumption it can all be economically extracted, will be depleted by 2096.[1] https:&#x2F;&#x2F;link.springer.com&#x2F;article&#x2F;10.1007&#x2F;s41247-020-00072-5[2] https:&#x2F;&#x2F;pubs.usgs.gov&#x2F;periodicals&#x2F;mcs2023&#x2F;mcs2023-helium.pdf reply mschuster91 2 hours agorootparentThanks for doing the math. I had not thought that the situation was that bad... reply myself248 13 hours agorootparentprevMany, many, many orders of magnitude less than we need. This is the worst kind of \"technically correct\" which is so misleading as to be disingenuous.To keep up with demand, you&#x27;d need so much nuclear energy that the thermal byproduct would boil the oceans within a year or two.I think it&#x27;s safe to say that&#x27;s not a desirable outcome. Once we&#x27;re out, we&#x27;re out. reply dralley 16 hours agorootparentprev> The question is just how much can be produced that way.Not nearly enough reply UncleMeat 15 hours agorootparentprev> and it&#x27;s running outIn a \"it is literally possible to extract all of it and it will escape to space\" sense, yes. But in a practical \"humans are anywhere remotely close to exhausting helium deposits on Earth\" sense, no. The \"we are running out helium\" thing was never real. reply dylan604 17 hours agorootparentprevUntil we start fusing hydrogen for energy. reply extraduder_ire 17 hours agorootparentI haven&#x27;t done the napkin math for this, but I don&#x27;t think we&#x27;ll need enough power from fusion to generate useful quantities of helium. I think we might get closer with certain kinds of fission. (alpha radiation is helium, after it captures a few electrons. IIRC, where Earth&#x27;s helium comes from) reply bparsons 15 hours agorootparentprevNatural gas is running out? reply natch 15 hours agorootparentI think \"it\" meant helium? But regardless we may reduce our natural gas extraction significantly in the future.Even if there&#x27;s plenty left in the ground.So I&#x27;d imagine that reduction of extraction would also reduce access to helium. reply happytiger 14 hours agorootparentThe United States produces more natural gas than any other fuel and its consumption of gas is second only to petroleum.It’s the main fuel used to power electrical plants in the US (all those Teslas generally run on LNG).It’s also a fuel that doesn’t have a single source supplier. It’s Quatar, Russia, etc.All these folks talking about reducing gas use and ending global warning by reducing consumption are not looking at this objectively and geopolitically. They see it through the lens of contemporary American environmental politics.Up until 5-10 years ago natural gas was seen as the major reduction factor in the drop in coal usage and generally a win for the environment compared to continuing to use coal. It was the “better” fuel for the transition.Obviously we are going to move towards more renewable fuels in future because coming into balance with nature is necessary. But it’s unlikely it’s going anywhere anytime soon and behind closed doors, I think energy policy clearly points to gas as the “lesser of evils” energy source for the foreseeable near future. reply happytiger 4 hours agorootparentDon’t downvote me you cowards. Prove me wrong. reply happytiger 3 hours agorootparentCauda. replytrebligdivad 12 hours agorootparentprevWhat&#x27;s it&#x27;s use in IC fab? reply RC_ITR 17 hours agorootparentprevFusion is very unlikely to become a viable energy source in the near-term, but it is something we can use to make helium if we are desperate enough. reply hypercube33 13 hours agorootparentCurrently we need helium to cool the superconducting magnets used to generate fusion reactions so the cart there is before the horse kind of problem, until someone comes up with a better solution. reply CamperBob2 17 hours agorootparentprevI asked about this once and someone pointed out the obvious E=mc^2 issue: a fusion reactor will generate only a trivial amount of helium in the process of releasing a large amount of energy. reply smegsicle 15 hours agorootparentim in my post-energy-scarcity future, blasting plasma into space as fast as i can to squeeze out a party balloon reply ftxbro 18 hours agoparentprev> in the 1950s became an important source of coolant during the Cold War and Space Racethey are saying that like there isn&#x27;t a cold war or space race in the year 2023 reply parineum 13 hours agorootparentOr that helium isn&#x27;t important to them. reply mlyle 16 hours agoparentprev> I appreciate the rebuttals below, apparently Helium is important in the usage and production of MRI, IC fabrication, and cooling nuclear reactors. Pushes a reconsideration of the sell off, plus the possible resurgance of steampunk.]Also: liquid fueled rockets and space systems. Being able to nuke the other guy or space supremacy depends upon having helium. Maybe not that much. reply perihelions 12 hours agorootparenthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Autogenous_pressurization reply mlyle 8 hours agorootparentI wasn&#x27;t saying there&#x27;s no alternatives; indeed current ICBMs use very little helium.It&#x27;s not just about pressurizing the liquid fuels for main engines. It&#x27;s a purging gas; it can be used to pressurize RCS systems where other approaches are less practical; etc etc etc. reply SoftTalker 18 hours agoparentprevHelium is useful as a coolant in nuclear reactors. If we get back into nuclear power in a big way, we might want a good supply of it. reply WorldMaker 18 hours agorootparentHelium is critical to tools like MRI machines. If we wish to keep our healthcare industry from technically backsliding, we probably want a good supply of it. reply marcus0x62 17 hours agoparentprevIn addition to the other replies you’ve gotten, UHP (ultra high purity) helium is also important in certain welding processes, although there are, generally at least, substitutes in that field. reply skywal_l 18 hours agoparentprevHelium is not even the best lighter than air gas. See: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=ZjBgEkbnX2I reply rsynnott 16 hours agoparentprev> MRIIs this actually the case anymore? I had the vague idea that fancy modern superconductors now allowed these to run on liquid nitrogen. reply ska 15 hours agorootparentNo, it&#x27;s pretty much all helium for clinical work.Short of a quench (catastrophic heating, effectively) the most modern units hardly lose any, and often need less in the first place. An old machine might cost you near 6fig&#x2F;year in helium refill, especially if out of spec. Some new magnets don&#x27;t typically need any in a give year. reply cyberax 11 hours agorootparentprevHigh-temp superconductors are made of ceramic, so they are very inconvenient to work with. They are also mechanically brittle.So the largest high-temp MRI for now is only big enough to image the head. That being said, there has been a lot of progress in the high-TC superconductors in the recent years. reply KennyBlanken 18 hours agoparentprevThis isn&#x27;t a joke. This is a privatization of a critical, finite resource - a huge step in the wrong direction. There&#x27;s no way to manufacture helium. You can&#x27;t condense it from the atmosphere like other gasses because when it&#x27;s released, it rises and escapes the planet, permanently.The supply is going to become very strategic when we run out of helium for MRI machines and other important superconducting equipment, scientific or otherwise.We may develop suitable lower temperature superconductors, but there are thousands of MRIs that still need it, and plenty of medical centers that won&#x27;t be able to afford to upgrade to new systems. reply adastra22 17 hours agorootparentYou mean higher temperature. reply scrlk 18 hours agoprevhttps:&#x2F;&#x2F;www.innovationnewsnetwork.com&#x2F;helium-shortage-4-0-wh...Seems a bit short sighted to close the helium reserve and sell it off. The last 3 years have taught the value of having some slack in the supply chain. reply Symmetry 15 hours agoparentHopefully however gets these facilities will buy helium when its cheap and sell it when its expensive to provide just that sort of slack in the supply chain. My understanding is that strategic helium stockpile was just to make sure we have enough helium for our the US&#x27;s use in the event of a war. reply nico 16 hours agoprevNot saying this is what’s happening here, but this is a typical way in which corrupt government&#x2F;politicians make bankThey sell hugely valuable public assets to some private entity, which then sells it back (or lease or rent) to the government over the years, at a huge premiumThere are usually some kickbacks, and&#x2F;or indirect ownership through partners&#x2F;shell companies involved reply cvoss 16 hours agoparentThe current auction is part of a sale that has been in the works since 1996. If something untoward is happening, the public eye has had two and a half decades to spot it and correct it. And the eye has been on it; indeed, the mechanics of the sale were revisited and improved ten years ago.[1] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Helium_Privatization_Act_of_... reply nico 16 hours agorootparentThat’s great, glad to know there’s been plenty of scrutiny over thisAt the same time, we’ve had regulatory capture in a bunch of industries for decades and it seems there isn’t much the public can really do about itThe public being able to see what’s going on, for months&#x2F;years&#x2F;decades doesn&#x27;t necessarily mean they are ok with it, it might just mean they are powerless reply MagicMoonlight 16 hours agoparentprevYeah there&#x27;s literally no reason to ever sell something like this. It&#x27;s like selling all of the missiles. Oh now we need missiles, guess we&#x27;ll need to buy them from the new private missile reserve.They&#x27;ve done this with a lot of things in the UK and now we have crumbling buildings and billionaire politicians. reply dismalpedigree 9 hours agoprevI hate this so much. Almost as much as I hate that we have been squandering it with an artificial price cap so we can fill party balloons cheaply. We have strategic reserves so we have resources when they are needed. reply mnemotronic 11 hours agoprevI thought I heard that once the helium is gone, it&#x27;s gone. We can&#x27;t make it; we can&#x27;t pump any more out of the ground. That would seem to be a hard-stop. Is that really the kind of resource we want to turn over to capitalists; who are driven primarily by stock incentives and short-term profit? reply dtgriscom 8 hours agoparentHelium is produced by extraction from natural gas:https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Helium#Modern_extraction_and_d... reply credit_guy 7 hours agoparentprevNope, that&#x27;s not true.It&#x27;s a popular misconception, with a kernel of truth, but the kernel is very, very small: hydrogen and helium are light enough that they are not gravitationally bound to our planet. In other words, if you release some helium in the atmosphere, in time it will eventually escape to space.While this is true, it&#x27;s also irrelevant. Once you release a gas into the atmosphere, it&#x27;s economically lost. It does not matter if it stays in the atmosphere forever, or it makes its way to the larger Universe. For example neon. Or kripton. Or chlorine for that matter.Separately, there is plenty of helium in natural gas fields. We extract about 4 trillion cubic meters of gas per year. Natural gas contains between 0.01% and 7% helium. At the lower end, we pull out of the ground 400 million cubic meters of helium per year, but we simply don&#x27;t bother to separate it. This is more than three times the entire Federal Helium reserve.Now, if you read the article, you&#x27;ll find out that this Federal Helium reserve is being sold as per a law enacted in 2013. Why did Congress pass such a law? I don&#x27;t know, but presumably they have looked into the issue and determined that it&#x27;s worth their time to bring it to the floor and hold a vote on it. The original helium reserve was instituted before WW2, when dirigibles were a thing, and the US was concerned with the Nazi Germany&#x27;s lead in this particular technology. After WW2 though, dirigibles are only a curiosity here and there. Helium is not a strategic resource anymore. reply bhhaskin 10 hours agoparentprevYou can make helium, it&#x27;s just not very feasible. Make me wonder if the government has an alternative method to manufacturing it. reply DennisP 8 hours agorootparentNuclear fusion can do it, but producing that much helium from nuclear fusion would have to be done off-planet. Quick napkin math, it would release about as much energy as the entire planet gets from the sun in a month. reply dullcrisp 7 hours agorootparentMine the sun. reply perilunar 7 hours agorootparentEasier to mine Uranus or Neptune I would think. reply voidfunc 10 hours agoparentprevYou&#x27;ll be long dead and gone before it matters. Try not to worry about things that won&#x27;t impact you in the slightest. reply jeppesen-io 9 hours agorootparentCompassion for those alive or will be alive, is a worthy goalI&#x27;d argue it&#x27;s one of the ideals of living a worthwhile life reply SideQuark 9 hours agorootparentprevExcept it will matter if your lifetime is more than a decade or so.https:&#x2F;&#x2F;www.google.com&#x2F;search?q=world+helium+shortageWhy are the least knowledgeable about a topic the most certain of their uninformed opinions about it? reply sporkland 7 hours agorootparentI&#x27;d say dunning kreuger but I saw something once that it didn&#x27;t mean what the popular interpretation claims it means. And I also worry about social sciences reproducibility in general. reply tchbnl 10 hours agorootparentprevAh, because who cares about the people who come after. That&#x27;s their problem. reply voidfunc 10 hours agorootparentIt is their problem. It&#x27;s not your problem or anyone else&#x27;s problem right now. Stop trying to control the future. reply bastawhiz 9 hours agorootparentThe inability to respect the people who come after you is how we&#x27;ve ended up with every single generational problem that we face today. Literally every single one. reply coherentpony 10 hours agorootparentprevWell, I can&#x27;t control the past. My options are the present, and the future, and the latter depends on the former.So what are my options? reply voxelghost 9 hours agorootparent>So what are my options?Trust in the market forces to self regulate?Let Jesus take the wheel?Leave it to beaver?They all seems about equally realistic. reply jeppesen-io 9 hours agorootparentprev> Stop trying to control the futureEvery choice we make in life impacts and \"controls\" the future, by choice or not reply plussed_reader 10 hours agorootparentprevWhy not try to hand off an easier &#x27;playing hand&#x27;? Or is that controlling the future as well? reply stuaxo 8 hours agorootparentprevIt is already controlling the future to let it be used up. reply rgrieselhuber 10 hours agorootparentprevThis is basically boomerism in a nutshell. reply gonzo41 10 hours agorootparentprevStrong #boomer energy there buddy. reply RIMR 6 hours agorootparentprevThis is selfishness bordering on psychopathy. Just because you&#x27;ll be dead doesn&#x27;t mean you should be complacent about things that will fuck over future generations. reply daneel_w 17 hours agoprevBut why? Have they found new gigantic pockets of natural gas rich with helium? Or some scientific breakthrough allowing it to be produced radiologically? reply lo_zamoyski 17 hours agoparentIndeed: why? I suspect the answer is likely to be something worryingly banal, like \"we&#x27;re in debt\" (or, \"private interest knows a guy who wants to make some money\"). Economies run on state-sponsored usury don&#x27;t tend to last. reply notatoad 17 hours agorootparent>I suspect the answer is likely to be something worryingly banal, like \"we&#x27;re in debt\" (or, \"private interest knows a guy who wants to make some money\")wikipedia has the answers. tl;dr it sounds like both of those things: the reserve was in debt and was depressing the market for helium.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;National_Helium_Reserve reply cvoss 16 hours agorootparentActually, the existence of the reserve was not depressing the market. The sell off of the reserve, which was mandated in 1996 and began in 2005, was depressing the market. The sale was modified in 2013 to try to relieve the market flooding issue. The present auction is the final piece of the sale. reply mrguyorama 14 hours agorootparentprev>the reserve was in debtA public service (which is what a federal stockpile IS) cannot be in dept.Can&#x27;t wait until \"fiscal responsibility\" types are trying to sell off the justice department to the highest bidder because it \"is in debt\" reply jquery 17 hours agorootparentprevUgh, it is criminal how short-sighted this is. Helium is not easy to replace nor easy to store long term, it&#x27;s the perfect application for government ownership of a commodity, just in case we need it. reply Paul-Craft 15 hours agorootparentAbsolutely. And \"in case we need it\" is for stuff like cryogenics (e.g. MRI machines), and deep sea diving, not bullshit like party balloons. reply bostonsre 15 hours agorootparentprevAnyone know how much it costs to maintain the reserve infrastructure? Do they have facilities that need to be staffed to keep an eye on it or is do they just need to just have perimeter security? reply Jiro 17 hours agoparentprevThis has nothing to do with selling off the reserve, but they have found new resources, see https:&#x2F;&#x2F;www.cnn.com&#x2F;2016&#x2F;06&#x2F;28&#x2F;africa&#x2F;helium-discovery-tanza... . This one expects to start producing in 2025 (according to more recent articles). reply fnordpiglet 14 hours agorootparent> The team estimates that just one part of the reserve in Tanzania could be as large as 54 billion cubic feet (BCf), which is enough to fill more than 1.2 million medical MRI scanners.> “To put this discovery into perspective, global consumption of helium is about 8 billion cubic feet (BCf) per year and the United States Federal Helium Reserve, which is the world’s largest supplier, has a current reserve of just 24.2 BCf,” said University of Oxford’s Chris Ballentine, a professor with the Department of Earth Sciences.I’d note this is only enough for 7 years of consumption. I’m not sure what kind of game changer that is. reply zamadatix 10 hours agorootparentAs an alternative note that&#x27;s a single newly discovered pocket with more helium than this reserve held at its peak.Both figures absolutely pale in comparison to how much we throw out because it&#x27;s not profitable but the fossil fuels it&#x27;s in are, but that&#x27;s nothing new. reply webnrrd2k 18 hours agoprevThere is also property for sale in Menlo Park, as well as San Dimas and Laguna Niguel.https:&#x2F;&#x2F;disposal.gsa.gov&#x2F;s&#x2F;searchproperty?state=CA&type=ALL reply cossatot 17 hours agoparentThe Menlo Park property is the former US Geological Survey campus, which has been moved to the NASA Ames campus in Mountain View because the USGS couldn&#x27;t make rent to the GSA. It&#x27;s a nice campus although some of the buildings could use some superficial renovation. It&#x27;s got a lot of lab space. reply dredmorbius 10 hours agorootparentUSGS moving both lower on the floodplain in light of global warming and sea level rise, and to far less seismically-stable land (bay fill as opposed to bedrock, far greater liquefaction risk) is ... arch. reply thomasjudge 13 hours agorootparentprevSeems like Stanford might want to buy this reply wly_cdgr 18 hours agoprevQuit making jokes, y&#x27;all. There&#x27;s nothing funny about this. reply koolba 18 hours agoparentNot even the thought of it going to the highest pitched bidder? reply bandyaboot 18 hours agorootparentAnd so pitch inequality gets ever larger. *shakes head• reply pelagicAustral 17 hours agoparentprevClown balloons are filled with helium, so there is some form of connection between fuckery and the gas. reply tibbon 16 hours agoparentprevAgreed. Its a lot of hot air. reply geysersam 17 hours agoparentprevAre you also in favor of public monopoly on other natural resources such as rare earth metals and oil? reply omniglottal 11 hours agorootparentYes. reply jquery 17 hours agorootparentprevI don&#x27;t even agree with private oil being a thing, natural resources should belong to the public. reply hooverd 16 hours agorootparentprevYes. reply anigbrowl 14 hours agorootparentprevYes reply explodingwaffle 14 hours agoprev\"To protect your organization from excessive usage and Denial of Service attacks, we limit the number of allowed content delivery views within a twenty-four hour period. Try viewing the content again later.\"C&#x27;mon guys, I was reading that 240 page government contract! reply Mountain_Skies 14 hours agoparentThat&#x27;s a reasonable false positive given that bots are far more likely to \"read\" a 240 page government contract than a human. reply gumby 18 hours agoprevI guess they haven’t yet realized that those room temperature superconductors were a flop. reply arrowsmith 17 hours agoparentUm, doesn&#x27;t the lack of room temperature superconductors mean we need more helium, not less? reply gumby 14 hours agorootparentExactly, so we still need the strategic reserve. They shouldn&#x27;t sell it off. reply Brian_K_White 17 hours agoprevI don&#x27;t understand the zeppelin jokes. Are we really this ignorant? reply flangola7 17 hours agoparentWhat are we ignorant of? Airships of the non-inflammable variety use helium. reply orra 15 hours agorootparentThat&#x27;s why Excelsior is filled with safe, natural helium.https:&#x2F;&#x2F;archer.fandom.com&#x2F;wiki&#x2F;Skytanic reply Brian_K_White 15 hours agorootparentprevSo what? Apparently what you&#x27;re ignorant of is that airships are not why it&#x27;s important to preserve a store of helium. reply hooverd 16 hours agoparentprevWould you rather rigid airships be flammable? reply Brian_K_White 15 hours agorootparentAre you saying zeppelins are an especially important facility for the military? (I&#x27;m sure there are uses, but only the way there are uses for anything).I am saying it&#x27;s ignorant to imply that the helium isn&#x27;t important because it was originally secured for zeppelins. reply westcort 18 hours agoprevIf this isn’t a sign of the collapse, I don’t know what is. reply delecti 18 hours agoparentThe federal government has been trying to sell it off for almost 30 years. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;National_Helium_Reserve reply westcort 18 hours agorootparentMeanwhile, patients need 6 weeks of physical therapy before they can get an MRI as a direct result of a lack of helium. Even diagnostic MRIs in which PT is not indicated. The government trying to sell a crucial asset necessary for healthcare technologies is a sign that the government is not able to take care of domestic affairs.They may have been trying to sell it before, but the lack of leadership on a critical resource like this is a bad sign. reply delecti 17 hours agorootparent> They may have been trying to sell it before, but the lack of leadership on a critical resource like this is a bad sign.The helium reserve has been for sale for almost 30 years, hospitals have had plenty of opportunity to buy helium for their MRI machines. Your wait for an MRI isn&#x27;t because of helium, it&#x27;s because insurance providers want to avoid paying for things. reply 93po 14 hours agorootparent> Your wait for an MRI isn&#x27;t because of helium, it&#x27;s because insurance providers want to avoid paying for things.More accurately, it&#x27;s because of corrupt or wildly misguided politicians that are against single payer healthcare due to bribery from established healthcare and insurance companies reply delecti 14 hours agorootparentI was talking about the more direct cause, but yes, that&#x27;s the ultimate reason. reply abeppu 18 hours agorootparentprevDoesn&#x27;t this give companies that supply helium to hospitals an opportunity to purchase helium? It seems like if there&#x27;s a shortage for important uses in the economy, then moving helium out of a government reserve is exactly what you&#x27;d want, right?Your complaint is that you think for-profit hospitals should be gifted the helium rather than having to purchase it? reply toomuchtodo 18 hours agorootparentTwo issues come to mind immediately. The first is that the market might not be the most efficient mechanism for allocation for something like helium. Are party balloons more valuable than cryo coolant for particle accelerators, MRI machines, and science? Just because you can&#x27;t cough up the market price doesn&#x27;t mean your application isn&#x27;t valuable [1]. The second is we&#x27;ve seen what happens with OPEC when a cartel controls the supply of energy. A for profit cornering the market for a non renewable resource could lead us to suboptimal stewardship of said resource (because humans are short sighted, near term driven, and fundamentally greedy).In 1979, in the midst of one of the many energy crisis in the 70s, the Shah of Iran said “oil is too valuable to burn.\" We&#x27;ve lucked out that we haven&#x27;t run out of helium yet, but there is no guarantee we will continue to be lucky. The subcomments of this comment [2] explain the very real peril and concern.To your point \"Your complaint is that you think for-profit hospitals should be gifted the helium rather than having to purchase it?\", I would respond: Helium should be priced based on the end use as well as any systems in place to recover and recycle [3] [4], vs temporary use where it will quickly be vented to space, lost to us forever.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Market_failure[2] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37393338[3] https:&#x2F;&#x2F;www.chemistry.ucla.edu&#x2F;news&#x2F;new-liquid-helium-recycl...[4] https:&#x2F;&#x2F;pharmacy.ucsf.edu&#x2F;news&#x2F;2021&#x2F;06&#x2F;helium-recycling-proj... reply abeppu 16 hours agorootparentI think your comparison to OPEC is interesting, b&#x2F;c it sounds like you think the price of oil was artificially high, but in retrospect, I think many would say that it has been far too cheap to burn oil, and this has driven our multi-generational climate crisis. I.e. I think the market failure in stewarding precious resources was _not_ that OPEC tried to keep prices high, but that failing to price in the cost of damage to the climate and environment kept prices artificially low.In the helium case in the US, my understanding is that from 1996 to 2013, though the US was the dominant global supplier and _could_ have chosen to act as a cartel, the 1996 legislation fixed prices to be artificially low (with the aim of merely paying off costs, rather than maximizing revenue), which is claimed to have disincentivized private parties from developing new production capacity.I&#x27;m not some free-market zealot who thinks the invisible hand can do no evil. But in this case, if the problem is that (a) there&#x27;s currently a bottleneck upstream of important healthcare cases and (b) we want to discourage waste then we should want helium to leave the national reserve (i.e. there&#x27;s more supply available to hospitals and other parties), and we should want that to be at a reasonable price so it isn&#x27;t used frivolously (e.g. we wouldn&#x27;t want party planners to be induced to use more balloons just b&#x2F;c they&#x27;re cheap). So auctioning off some of what is held in reserve seems like a reasonable action.Wrt pricing that is presumably _lower_ for installations with recycling capabilities -- I would think that recycling might if anything make institutions willing to pay a higher volumetric price, since they get more total benefit from it. If the recycling technology is efficient and practically applicable in many contexts, more and more facilities ought to be pressured by high costs to introduce recycling ... or leave the market. reply toomuchtodo 16 hours agorootparentMy OPEC comparison was more centered on a small group controlling a critical resource who can control the price regardless of the needs of the consumers of said resource (not the historic price action). I agree with most of your points, but want to stress that the desired outcome should be responsible use and stewardship of what is both a highly useful and nonrenewable resource. Pricing is a component, but maximizing profit should not be the goal. I&#x27;d even go so far to say that you either wouldn&#x27;t sell to consumers of helium who could capture and recycle it but currently choose not to, or you would subsidize the installation of that equipment for them out of the proceeds of more frivolous uses.My personal opinion is the goal should be to maximize the utility of the resource, with any profits being second order effects. Instead, we too often end up like ancestors who raze the forest only to freeze to death in the winter [1].[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Holznot reply abeppu 16 hours agorootparentI think if you _don&#x27;t_ sell helium to non-recycling facilities in the near term, MRIs would stop altogether. The two articles about recycling that you shared are both research universities who considered it a PR-worthy accomplishment to put recycling in place to cover _some_ of their machines, which for the moment sound like they&#x27;re almost entirely about NMR; the UCSF article even says that after paying $500k, they&#x27;re still hoping to \"inspire\" other uses than NMR within the same university to begin recycling, i.e. the top-flight research university bragging about recycling still isn&#x27;t able to do it for clinical MRI machines.Do you know (or perhaps someone else can chime in) -- is it even feasible currently for a medical facility with 1-2 MRI machines to put a recycling system into place? Or is the recycling system of a size and complexity that only if you have a helium footprint above a given size is it realistic? Certainly, most places would not have the expertise on staff to design and implement such a system today.Worse, if recycling were a requirement to purchase helium, how do we estimate which medical facilities would _not_ buy an MRI machine because of the higher initial cost of the recycling system, or maintenance of its collection, compression, or purification components? How would that change patient outcomes (especially given that the initial complain about MRIs in this thread was long waits due to limited capacity)? reply pkaye 14 hours agorootparentIn reply to your other post (I could not comment on it directly)> ... then is there really still any meaningful relationship between helium supply and the patient wait time for MRIs as westcort complained? Or is it just that there are too few MRI machines in the healthcare system?The US is second highest in number of MRI machines per capita after Japan. Its probably staffing issues or maybe MRI scans are used much more widely in the US.https:&#x2F;&#x2F;www.statista.com&#x2F;statistics&#x2F;282401&#x2F;density-of-magnet... reply abeppu 14 hours agorootparent> Its probably staffing issuesI would have expected that since (in my experience) these machines are generally run by a technician, and the MRI itself is relatively quick (a few minutes), and hospitals can bill insurance thousands for an MRI, that once a medical facility has acquired and set up the machine the machine, that running patients through should more than pay for the time of staff immediately involved. reply toomuchtodo 16 hours agorootparentprevAny MRI machine made since the late 1990s has helium reclamation capabilities (\"zero boil off refrigeration systems\").https:&#x2F;&#x2F;mriquestions.com&#x2F;uploads&#x2F;3&#x2F;4&#x2F;5&#x2F;7&#x2F;34572113&#x2F;advances_i... (page 5) reply abeppu 15 hours agorootparentThanks for pointing at that! But if the description is correct,> ZBO magnets allow practically unlimited system operation without helium refill.... then is there really still any meaningful relationship between helium supply and the patient wait time for MRIs as westcort complained? Or is it just that there are too few MRI machines in the healthcare system?And, I suppose if anyone here knows -- why is it that NMR magnets at UCLA and UCSF required recycling systems which sound meaningfully less efficient (the UCLA article linked above reclaimed only 90%) rather than using the ZBO tech which is apparently standard in modern MRIs? replywestcort 16 hours agorootparentprevExactly. Some crucial resources need to be managed with a long-term outlook or risk market failures. Helium is one such resource. reply kraig911 17 hours agorootparentprevThe 6 week wait isn&#x27;t because of a lack of helium. It&#x27;s for lack of money to fund the MRI to begin with. It&#x27;s easy to point to lack of helium when really the cost of an MRI machine is expensive. The rare earth magnets alone of which are a greater scarcity than helium. My point is that it&#x27;s more than just helium scarcity for not getting easy access to MRIs. reply ska 15 hours agorootparentprev> they can get an MRI as a direct result of a lack of helium.It&#x27;s a ~1mm machine with ~10k of helium in it, and modern ones don&#x27;t need much refill. Even with old ones it&#x27;s expensive, but not out of whack with other costs.The helium market isn&#x27;t really the proximal cause of not having enough MRI hours to go around, but there are concerns about it getting worse. reply sidewndr46 15 hours agorootparentprevI don&#x27;t know what world you&#x27;re living in but I can get an MRI next-day if I need to. reply tssva 17 hours agorootparentprev> Meanwhile, patients need 6 weeks of physical therapy before they can get an MRI as a direct result of a lack of helium. Even diagnostic MRIs in which PT is not indicated.In February my daughter started experiencing knee pain. Her doctor ordered an MRI and 1 week later the MRI was performed. reply NoboruWataya 15 hours agorootparentprev> patients need 6 weeks of physical therapy before they can get an MRI as a direct result of a lack of heliumThen why hasn&#x27;t the government, with its huge helium reserve, stepped in to solve this problem?Maybe there is some hope the helium could end up being sold to people who actually want to apply it to socially beneficial uses like this, since the government apparently has no interest in doing so? reply EA-3167 18 hours agorootparentprev> Meanwhile, patients need 6 weeks of physical therapy before they can get an MRI as a direct result of a lack of helium. Even diagnostic MRIs in which PT is not indicated.I&#x27;ve never heard of this, can you link to something discussing this? reply SoftTalker 18 hours agorootparentDue to the cost of an MRI procedure, most insurers will require 6 weeks of PT&#x2F;rehab efforts on an injury before covering the cost of an MRI.I guess GP is attributing the cost of the MRI to the helium required to cool the magnet, but I&#x27;m not sure that&#x27;s a big fraction of the amortized cost for a single procedure -- a reference would be good. reply vidarh 17 hours agorootparentSome searches indicates most newer MRI&#x27;s are \"zero boil-off\" machines that recondense most of the helium, and that even older, leaky MRI&#x27;s might be using (losing) at most ~$20k helium per year.I&#x27;m in London, a MRI here starts at around ~250 pounds or ca. $315.Meanwhile $20k worth of helium replacement would be ~$55&#x2F;day spread across all uses of the machine.So I&#x27;m inclined to think you&#x27;re right.The more likely reason for the 6 week PT:Most things for which you as a patient might want an MRI for that aren&#x27;t obviously not something physio will help with are things you will end up needing physio for.I&#x27;m assuming they&#x27;ve done a simple cost benefit analysis where the proportion of cases where they actually need MRI&#x27;s are low enough that it&#x27;s cheaper to just send people straight to physio first. reply ska 15 hours agorootparent> nd that even older, leaky MRI&#x27;s might be using (losing) at most ~$20k helium per year.It can be a lot more than 20k but you are correct it isn&#x27;t the driving cost. reply SoftTalker 17 hours agorootparentprevThe cost of an MRI in the USA is at least 10x that number. That is why they generally require PT first.Of course if you&#x27;re an athlete at the major college or professional level, you can get one immediately. reply vidarh 17 hours agorootparentIs that for full body scans?Prices here do vary a lot, and you certainly can end up paying 10x that price for a full body scan from an expensive provider with a bunch of extras (though judging by a couple, some of those extras are cheap&#x2F;\"free\" (on the NHS) blood tests tacked on for no good reason other than to jack up the price).[You can get full scans for significantly less too, at least down to $1300 - I haven&#x27;t looked very thoroughly -, but most people opting for full body scans are not doing so to address a specific known issue, so the prices reflect that it&#x27;s a luxury service that&#x27;s rarely needed, and the price lists are full of pointless upsells]If the 10x is for specific body parts, it might pay to take a short trip to do your MRI&#x27;s rather than pay out of pocket where you are then. reply mrexroad 16 hours agorootparent10x is for specific body parts, largely due to the (predatory) disfunction of our health care insurance and for-profit care system. Even the x-ray I was required to have before an MRI, due to plate in my arm, was billed higher than your MRI. With that said, there are also private parties (e.g. not through health care provider) that offer full-body MRIs for only a grand or two; well, at least there were a decade or so, when we got one for my FIL. reply SoftTalker 16 hours agorootparentYes, if you go to an \"imaging center\" they typically cost less than at a hospital. Strangely, my doctor&#x27;s referral was to the hospital not the imaging center so per my insurance that is where I had to go. My insurance and the doctor&#x27;s practice and the hospital they sent me to were all owned by the same huge health organization... Hmmm. reply JumpCrisscross 17 hours agorootparentprev> cost of an MRI in the USA is at least 10x that numberI got a whole-body MRI in New York. It was under $1,000. reply seanp2k2 16 hours agorootparentafter insurancePost the prices that your insurance provider paid to the hospital for a real comparison. reply JumpCrisscross 16 hours agorootparentIt was a voluntary whole-body MRI. This was my out of pocket expense and the provider’s revenue. No insurance. replysjsdaiuasgdia 18 hours agorootparentprevA counter-reference from a Jan 2023 newsletter from the Radiological Society of North America - https:&#x2F;&#x2F;www.rsna.org&#x2F;news&#x2F;2023&#x2F;january&#x2F;helium-shortage-for-m...\"Despite news reports in October that the world is running out of helium, clinical MRI units throughout the U.S. were and remain unaffected.\"I wouldn&#x27;t be surprised if some patients are given bad info by either clinic or insurer. Blaming a global shortage, real or perceived, points the patient&#x27;s emotional response away from the provider. reply SoftTalker 17 hours agorootparentAt a gut level I would be inclined to agree.I&#x27;ve had an MRI (and had to do the prerequisite 6 weeks of PT).The MRI is a huge machine. It&#x27;s in its own room, and they have to be careful about allowing any metal too close to it. The scan itself took about an hour for a couple of different views, a tech had to get my body in the right position and support it with various pads and pillows. You cannot move at all, and if you do, they have to start over. Given the time for the scan itself, plus any setup and cleaning they might have to do, I&#x27;d guess one machine could do a dozen or so scans per day. At the hospital I went to, they only did scans two days per week, I don&#x27;t know if that was because they had limited staff or they need to allow for maintenance&#x2F;calibration of the machine. Also I had a scan with contrast, and the doc who did the contrast injection also had limited availability.So there are real limits on the supply of MRI time, my guess is that this drives the price more than anything. It&#x27;s not like an X-ray that just takes a few minutes. reply Wistar 18 hours agorootparentprevAlthough not specifically about the PT requirement, some stuff on the helium shortage across healthcare, research, and business.NBC: “The world is running out of helium. Here&#x27;s why doctors are worried.” https:&#x2F;&#x2F;www.nbcnews.com&#x2F;health&#x2F;health-news&#x2F;helium-shortage-d...Radiological Society of North America: “Keeping An Eye on the Potential Shortage of Helium for MRIs” https:&#x2F;&#x2F;www.rsna.org&#x2F;news&#x2F;2023&#x2F;january&#x2F;helium-shortage-for-m...The Harvard Crimson: “Helium Shortage Forces Harvard Physics Labs to Shut Down Equipment, Suspend Projects” https:&#x2F;&#x2F;www.thecrimson.com&#x2F;article&#x2F;2022&#x2F;6&#x2F;24&#x2F;helium-shortage...Marketplace: “Party City’s Bankruptcy partly due to high cost of helium” https:&#x2F;&#x2F;www.marketplace.org&#x2F;2023&#x2F;01&#x2F;19&#x2F;heliums-been-rising-i... reply stronglikedan 17 hours agorootparentprevI can&#x27;t link to anything, but I can offer my own personal experience of having to pay for 6 weeks of physical therapy before they would give me an MRI for my knee. I just opted to look up the routine online and rehab myself. I&#x27;d have gladly paid my MRI copay, but I&#x27;m not paying for PT without even knowing if I need it yet. reply trogdor 8 hours agorootparentI use Radiology Assist for easy, self-pay imaging. You can look up the actual cost of whatever scan you are interested in, at a facility near you, on their website. A few days ago I scheduled a 3 Tesla knee MRI, on the exact day I wanted - next week. My total cost is $375, and that includes a report by a radiologist, and a copy of the MRI images.(I tore my ACL in March and opted for physical therapy instead of surgery. My knee feels like it’s at 100% and PT tests show no difference in performance between my knees. I’m interested in seeing the degree to which there has been healing, if at all. I self-paid for my initial MRI back in April as well. It would have been more expensive through insurance!) reply adolph 17 hours agorootparentprevIs there a “lack of helium” or is there a competition for valuable uses of helium? MRI seems to use about 13% of annual helium production.12,000 * 10,000 &#x2F; 12.8 = 9,375,000&#x2F;year [0]1 cubic meter = 1,000 liters9,375 (MRI) &#x2F; 73,000,000 (Total production [1]) = 0.1284At any point, an MRI machine contains about 2,000 liters of liquid helium, though suppliers need to replenish any helium that boils off. Mahesh estimates that an MRI machine uses 10,000 liters of liquid helium over its life span. (According to GE Healthcare, a manufacturer of the machines, that life span is 12.8 years.) In 2015, there were roughly 12,000 machines in the U.S., making MRIs one of the biggest helium consumers in the world, far above balloon stores.0. https:&#x2F;&#x2F;www.nbcnews.com&#x2F;health&#x2F;health-news&#x2F;helium-shortage-d...Helium production in the United States totaled 73 million cubic meters in 2014.1. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Helium_production_in_the_Unite... reply anigbrowl 14 hours agorootparentprevFactions within the government have been trying to sell it off for that time. Other factions don&#x27;t feel like wasting political capital defending this hill because they can&#x27;t easily explain the issue to the public. reply gnatman 16 hours agoparentprevCollapse of what exactly? reply riffic 13 hours agorootparentin their context, everything. reply roschdal 18 hours agoprevnext [5 more] [flagged] stjo 18 hours agoparentDo you actually have an airship startup? What are the challenges you are facing? Do you need software engineers or funding? reply function_seven 18 hours agorootparentDoesn&#x27;t need a runway, that&#x27;s for sure. reply throwawee 15 hours agorootparentprevZeppelins are just a bubble. reply tonymillion 17 hours agorootparentprevThe great thing about an Airship startup is that there’s no worries about “up and to the right” growth.It’s mostly just up, and any direction you want to go. reply aurizon 10 hours agoprevMusk can put a topping bid. 20 times the other top. He can then ask the party balloon people to pay 100 times = kill that waste business dead dead dead, - deserves that sort of death. Then he can meet the science demand at a variable spot price. The 10-15% from other small gas wells will be rendered economic = re-vitalise helium extraction from these small fry = there are a lot of them this procedure would render economic = assure a long tern supply. It would also liberate He from being a market pawn. They call this - &#x27;a cat among pigeons&#x27; and boy would they scatter.... reply dwighttk 18 hours agoprevMaybe dollar tree can start selling helium balloons again reply yinser 16 hours agoprev [–] I’m appalled they didn’t loop in the HN community when considering the sale of Helium. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The General Services Administration (GSA) has publicized its plans to sell the Federal Helium System assets, as directed by Congress, which includes properties, equipment, mineral rights, and a helium storage reservoir.",
      "The sales process, which is expected to last between 8-9 months, will involve the engagement of industry stakeholders to ensure an efficient transfer of assets.",
      "Detailed information on this process is available on the GSA website, where interested parties can also submit their bids within the given timeframe. The GSA provides procurement and shared services for the federal government and manages a real estate portfolio and technology services."
    ],
    "commentSummary": [
      "The US Federal Helium reserve is being privatized, sparking controversy and raising concerns about the rationale of selling this valuable resource.",
      "Questions are being raised about helium's limited supply and potential scarcity, its extensive usage across industries, and potential environmental implications of its extraction from natural gas.",
      "Fears abound that the sale could result in a future shortage of helium, adversely affecting sectors like healthcare and scientific research."
    ],
    "points": 257,
    "commentCount": 242,
    "retryCount": 0,
    "time": 1693921677
  }
]
