[
    {
        "id": 35598281,
        "timestamp": 1681721767,
        "title": "MiniGPT-4",
        "url": "https://minigpt-4.github.io/",
        "hn_url": "http://news.ycombinator.com/item?id=35598281",
        "content": "MiniGPT-4:Enhancing Vision-language Understanding with Advanced Large Language ModelsDeyao Zhu* , Jun Chen*, Xiaoqian Shen, Xiang Li, Mohamed Elhoseiny\u25b6 King Abdullah University of Science and Technology*Equal ContributionPaperCodeVideoThanks for your interest in our work. Currently, the number of users has exceeded our expectations. We provide alternative demo links here: Link1 Link2 Link3 Link4 Link5 Link6 Link7Occasionally, we may need to re-run the model due to connection issues; kindly refresh the page to access the new validate link.We are currently preparing a lighter model runnable on a single 3090 GPU, which you will be able to run on your own machine. Please stay updated by visiting our Github page at Github.<p>Gradio.</p>AbstractThe recent GPT-4 has demonstrated extraordinary multi-modal abilities, such as directly generating websites from handwritten text and identifying humorous elements within images. These features are rarely observed in previous vision-language models. We believe the primary reason for GPT-4's advanced multi-modal generation capabilities lies in the utilization of a more advanced large language model (LLM). To examine this phenomenon, we present MiniGPT-4, which aligns a frozen visual encoder with a frozen LLM, Vicuna, using just one projection layer. Our findings reveal that MiniGPT-4 possesses many capabilities similar to those exhibited by GPT-4 like detailed image description generation and website creation from hand-written drafts. Furthermore, we also observe other emerging capabilities in MiniGPT-4, including writing stories and poems inspired by given images, providing solutions to problems shown in images, teaching users how to cook based on food photos, etc. In our experiment, we found that only performing the pretraining on raw image-text pairs could produce unnatural language outputs that lack coherency including repetition and fragmented sentences. To address this problem, we curate a high-quality, well-aligned dataset in the second stage to finetune our model using a conversational template. This step proved crucial for augmenting the model's generation reliability and overall usability. Notably, our model is highly computationally efficient, as we only train a projection layer utilizing approximately 5 million aligned image-text pairs.Video PresentationModelMiniGPT-4 consists of a vision encoder with a pretrained ViT and Q-Former, a single linear projection layer, and an advanced Vicuna large language model. MiniGPT-4 only requires training the linear layer to align the visual features with the Vicuna.:The architecture of MiniGPT-4.AcknowledgementThis website is adapted from Nerfies, licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.Results",
        "summary": "MiniGPT-4, a language model that aligns a frozen visual encoder with a frozen large language model, Vicuna, using just one projection layer, possesses similar capabilities exhibited by GPT-4, such as generating detailed image descriptions and writing stories and poems inspired by given images. The model is highly computationally efficient, utilizing only approximately 5 million aligned image-text pairs and requires only training the linear layer to align the visual features with the Vicuna large language model. The creators are preparing a lighter model runnable on a single 3090 GPU for future use.",
        "hn_title": "MiniGPT-4",
        "original_title": "MiniGPT-4",
        "score": 853,
        "hn_content": "Researchers have created MiniGPT-4, which they claim significantly outperforms other models. To develop MiniGPT-4, the researchers took BLIP2's ViT-L+Q-former, linked it to Vicuna-13B with a linear layer, and trained just the tiny layer on some image-text datasets. The embedders of deep learning models appear to have something universal in their hidden states and embedding layers, as observed in the experiment. The repo's default inference code is not optimal for consumers, and it needs to be run in int8. A Discord bot has been created to showcase the model, but it runs too slo\u051dly for public hosting.This post discusses the misconception that the jargon in AI makes the field difficult, while the reality is that it's not. The discussion then diverts to a scene from the TV show \"Patriot\" and the show's cancellation by Amazon. The conversation moves on to web development and the math prerequisites for machine learning, and a solution is suggested to enable kids to learn more about programming. The post also explains the training process of unrelated models and how they can be composed together for a new model in a simple manner, making machine learning easily understood by everyone.The LLM uses a matrix to transform a text description of an image so it can \"understand\" it. The Hugging Face transformer ecosystem has a unified API for easier use. GPT can be used for tasks similar to web development, but company policies must be followed. ML is like gardening with unexpected but cool results, pushing programmers out of their comfort zone to experience surprise again. Abstractions in ML are very leaky.Stephen Wolfram shared an explanation of ChatGPT  on his blog, which was met with mixed reactions from various commenters; some felt he came across as more humble and open-minded than usual, while others criticized him for not addressing his previous work sooner in the article.  The comment section also highlighted resources for understanding machine learning, with one user recommending the \"Zero to Hero\" tutorial and another suggesting daily coding practice, and discussed the possibility of running LLMs on CPUs or using 4bit quantized Vicuna. Despite varying opinions, the post generated interest and discussion within the tech community.Open AI's Vicuna, a fine-tuned LLaMA, has been named GPT-4 for an unrelated project. However, its results look impressive, and adding GTPQ 4bit quantizing could enable the model to run on 2x 3090 with 65B variation. There is little software support for RDNA2, and Rocm has terrible performance with limited VRAM. For general guidance on GPUs, one may check Tim Dettmer's guide, which recommends Nvidia with lots of VRAM. Two used RTX 3090 cards with 48GB VRAM can run the largest LLaMA's variant with good performance. Moreover, a decent amount of RAM and NVMe SSD is also necessary.Tech enthusiasts discuss various details and personal preferences regarding video cards and operating systems for running machine learning models and playing games. A few highlight running models locally, choosing between 3090 or 4090 for ML, the ease of installing CUDA on OpenSUSE, and using Linux for better performance. Additionally, there are comments regarding waiting for the next generation of unified memory architectures. Trademark infringement concerns are also raised in relation to the marketing of a product as MiniGPT-4 when it is based on a smaller model.The MiniGPT-4 model is based on Vicuna/Llama and has a larger linear layer than the BLIP-2 model. The parameter count used for GPT-4 is unknown, but there are speculations that it could range from 0.5-1T. The use of the GPT name is important for distinguishing the origin of the goods to consumers. Though some machine learning applications have produced impressive outcomes, they have not yet produced strong research in applications with significant practical use. Despite AI's impressive advancements, certain areas of AI continue to be problematic.A discussion among HN users includes topics of AI, self-driving cars, and GPT4's ability to create vector drawings. Some users question why self-driving cars do not use Lidar technology, while others point out the advantages of relying solely on computer vision or using ultrasonic proximity sensors. Moreover, some users question the impact of GPT4 on poetry and language models. Finally, the post discusses the simplicity of the Vicuna AI model and its impressive results.DALL-E mini garnered public attention as it was released in closed preview, and despite initial hype, it has impressed some users' applications. Radiologists see potential in using AI like DALL-E mini for diagnostic reports. Conversations about AI's potential to decode CAPTCHAs and other bot-detecting measures like BankID emerged. Although some users found DALL-E mini's output to be middling, the chat interface maintained its popularity among tech enthusiasts. Language models like DALL-E mini are evolving and may someday eliminate common disclaimers like\u00a0\"As an artificial intelligence, I do not have personal feelings or emotions\" in response to adversarial inputs.Researchers at King Abdullah University of Science and Technology have developed a language model called Vicuna, which can generate computer programs and websites from natural language instructions. The model is based on GPT, the transformer architecture behind OpenAI's GPT-3, and was trained on code from GitHub using a technique called contrastive pretraining that the authors claim can improve learning efficiency. The researchers also used a technique called frozen representation learning to build the model, which pretrains the encoder and decoder separately before fine-tuning them together. Vicuna is available for download on GitHub.A new GPT model with no loss of quality runs on 8GB in GPTQ 4bit, with faster and more efficient performance even at a larger scale, allowing for easier analysis of data like images and videos. However, there are some issues with long wait times and potentially losing your place in the queue when trying to use it. Nonetheless, it presents exciting possibilities for video summarization and other applications for software and tech.",
        "hn_summary": "Researchers create MiniGPT-4 model which outperforms others by linking BLIP2's ViT-L+Q-former to Vicuna-13B with a linear layer and training just the tiny layer on some image-text datasets. Other comments include machine learning models, running LLMs on CPUs, and marketing products based on smaller models. King Abdullah University researchers develop Vicuna, a GPT transformer architecture that generates computer programs and websites from natural language with improved learning efficiency. GPTQ 4bit's faster and more efficient performance presents exciting possibilities for video summarization and other applications for software and tech."
    },
    {
        "id": 35600860,
        "timestamp": 1681740309,
        "title": "RedPajama: Reproduction of LLaMA with friendly license",
        "url": "https://www.together.xyz/blog/redpajama",
        "hn_url": "http://news.ycombinator.com/item?id=35600860",
        "content": "RedPajama, a project to create leading open-source models, starts by reproducing LLaMA training dataset of over 1.2 trillion tokensApr 17Written By TogetherFoundation models such as GPT-4 have driven rapid improvement in AI. However, the most powerful models are closed commercial models or only partially open. RedPajama is a project to create a set of leading, fully open-source models. Today, we are excited to announce the completion of the first step of this project: the reproduction of the LLaMA training dataset of over 1.2 trillion tokens.The most capable foundation models today are closed behind commercial APIs, which limits research, customization, and their use with sensitive data. Fully open-source models hold the promise of removing these limitations, if the open community can close the quality gap between open and closed models. Recently, there has been much progress along this front. In many ways, AI is having its Linux moment. Stable Diffusion showed that open-source can not only rival the quality of commercial offerings like DALL-E but can also lead to incredible creativity from broad participation by communities around the world. A similar movement has now begun around large language models with the recent release of semi-open models like LLaMA, Alpaca, Vicuna, and Koala; as well as fully-open models like Pythia, OpenChatKit, Open Assistant and Dolly.We are launching RedPajama, an effort to produce a reproducible, fully-open, leading language model. RedPajama is a collaboration between Together, Ontocord.ai, ETH DS3Lab, Stanford CRFM, Hazy Research, and MILA Qu\u00e9bec AI Institute. RedPajama has three key components:Pre-training data, which needs to be both high quality and have broad coverageBase models, which are trained at scale on this dataInstruction tuning data and models, which improve the base model to make it usable and safeToday, we are releasing the first component, pre-training data.\u201cThe RedPajama base dataset is a 1.2 trillion token fully-open dataset created by following the recipe described in the LLaMA paper.\u201dOur starting point is LLaMA, which is the leading suite of open base models for two reasons: First, LLaMA was trained on a very large (1.2 trillion tokens) dataset that was carefully filtered for quality. Second, the 7 billion parameter LLaMA model is trained for much longer, well beyond the Chincilla-optimal point, to ensure the best quality at that model size. A 7 billion parameter model is particularly valuable for the open community as it can run on a wide variety of GPUs, including many consumer grade GPUs. However, LLaMA and all its derivatives (including Alpaca, Vicuna, and Koala) are only available for non-commercial research purposes. We aim to create a fully open-source reproduction of LLaMA, which would be available for commercial applications, and provide a more transparent pipeline for research.The RedPajama base dataset The full RedPajama 1.2 trillion token dataset and a smaller, more consumable random sample can be downloaded through Hugging Face. The full dataset is ~5TB unzipped on disk and ~3TB to download compressed. RedPajama-Data-1T consists of seven data slices:CommonCrawl: Five dumps of CommonCrawl, processed using the CCNet pipeline, and filtered via several quality filters including a linear classifier that selects for Wikipedia-like pages.C4: Standard C4 datasetGitHub: GitHub data, filtered by licenses and qualityarXiv: Scientific articles removing boilerplateBooks: A corpus of open books, deduplicated by content similarityWikipedia: A subset of Wikipedia pages, removing boilerplateStackExchange: A subset of popular websites under StackExchange, removing boilerplateFor each data slice, we conduct careful data pre-processing and filtering, and tune our quality filters to roughly match the number of tokens as reported by Meta AI in the LLaMA paper: RedPajama   LLaMA* CommonCrawl  878 billion  852 billion C4 175 billion 190 billionGithub 59 billion 100 billionBooks 26 billion 25 billionArXiv 28 billion 33 billionWikipedia 24 billion 25 billionStackExchange 20 billion 27 billionTotal 1.2 trillion 1.25 trillion* estimated from Table 1 in https://arxiv.org/abs/2302.13971We are making all data pre-processing and quality filters openly available on Github. Anyone can follow the data preparation recipe and reproduce RedPajama-Data-1T.Interactively analyzing the RedPajama base dataset In collaboration with the Meerkat project, we are releasing a Meerkat dashboard and embeddings for exploring the Github subset of the corpus. The image below shows a preview of the dashboard.Interactively explore the data in the RedPajama base dataset and view matching records using Meerkat dashboard. You can find instructions on how to install and use the dashboard on Github.Up next: Models, instructions & OpenChatKitHaving reproduced the pre-training data, the next step is to train a strong base model. As part of the INCITE program, with support from Oak Ridge Leadership Computing Facility (OLCF), we are training a full suite of models, with the first becoming available in the coming weeks.With a strong base model in hand, we are excited to instruction tune the models. Alpaca illustrated the power of instruction tuning \u2013 with merely 50K high-quality, diverse instructions, it was able to unlock dramatically improved capabilities. Via OpenChatKit, we received hundreds of thousands of high-quality natural user instructions, which will be used to release instruction-tuned versions of the RedPajama models.AcknowledgementsWe are appreciative to the work done by the growing open-source AI community that made this project possible. That includes:Participants in building the RedPajama dataset including Ontocord.ai, MILA - Qu\u00e9bec AI Institute, ETH DS3Lab, Universit\u00e9 de Montr\u00e9al, Stanford Center for Research on Foundation Models (CRFM), Stanford Hazy Research research group and LAION. Meta AI \u2014 Their inspiring work on LLaMA shows a concrete path towards building strong language models, and it is the original source for our dataset replication. EleutherAI \u2014 This project is built on the backs of the great team at EleutherAI \u2014 including the source code they provided for training GPT-NeoX. An award of computer time was provided by the INCITE program. This research also used resources of the Oak Ridge Leadership Computing Facility (OLCF), which is a DOE Office of Science User Facility supported under Contract DE-AC05-00OR22725.Get notified of future posts and updates:Sign upLinks in this article:\u2022 RedPajama base dataset \u2022 RedPajama Github \u2022 Join our Discord",
        "summary": "RedPajama, a project to create leading open-source models, starts by reproducing LLaMA training dataset of over 1.2 trillion tokens; RedPajama has three key components: pre-training data, base models, and instruction tuning data and models; RedPajama has released the full RedPajama 1.2 trillion token dataset and a smaller, more consumable random sample can be downloaded through Hugging Face.",
        "hn_title": "RedPajama: Reproduction of LLaMA with friendly license",
        "original_title": "RedPajama: Reproduction of LLaMA with friendly license",
        "score": 711,
        "hn_content": "Together XYZ has released their RedPajama training dataset, a reproduction of the LLaMA model that was released in January by Stanford University. The RedPajama dataset's friendly license allows it to be downloaded publicly through 2,084 URLs provided on Together XYZ's website, weighing in at a total of 2.67 TB. Common Crawl and C4 are included in the dataset, with Common Crawl present in five folders and C4 being a \"colossal, cleaned version of Common-crawl's web crawl corpus\". Together's VP of Engineering has confirmed that GitHub training data will be added to the RedPajama dataset soon.Together, a collective of researchers, has created a dataset named RedPajama that's four times larger than OpenAI's GPT-3-powered GPT-3, with the aim of creating a fully open language model architecture for anyone to use. The dataset is designed to be open source and compatible with machine learning tools like PyTorch, TensorFlow and JAX, as well as being free to use in commercial environments. RedPajama aims to address criticism from AI researchers regarding the closed nature of language model development and deployment, including license agreements and the use of unlicensed training data.LLM models must be controlled to comply with China's constitution, but the model training data may exclude anything critical of China; there is debate about whether model weights can be copyrighted and whether Llama can be used commercially without a signed agreement; there are multiple open-source LLMs already available, but some believe an updated GPL license that requires open-sourcing the data model could increase adoption and accelerate research; OpenAssistant has made their training data available, but their recent gag in a release video about not releasing model weights caused confusion.Open Assistant might be trained on a properly open-source model based on LLaMA, and there is also something based on Pythia; the smaller model works well for data summarization and image captioning. The LLaMA derivatives and OpenAssistant stuff, while performing below GPT-3.5, can be finetuned to achieve comparable performance on specific tasks. StableDiffusion models are not up to the general parity of private offerings; and there are legal implications surrounding their model training approach. Midjourney's versatility is unmatched, but StableDiffusion's ControlNet functionality has given specific posing of a scene a huge edge on it.Comments on a forum delve into the comparison between two AI art generation services, SD and Midjourney, with some users preferring one over the other due to various factors, such as control and image quality, and one user stating that Midjourney is simpler to use for commercial purposes due to copyright restrictions. The discussion also touches on the use of patent texts as a source for technical knowledge and whether artificial intelligence could aid in their translation into more accessible language.Open-source LLM \"Llama\" dataset training costs substantially, and the base dataset does not include many languages, increasing the amount of data in other languages potentially improves performance in the English portion of the model. Common Crawl data has been included 4 or 5 times, and 'llama' includes Meta's PubMed Central papers, Pubmed ID abstracts, bioRxiv and medRxiv papers, and NCBI summaries of gene function in the base training set. Additionally, researchers would like to have OpenCyc converted to natural language and then ingested into LLM. The cost for reproducing LLaMA is $2M of compute, and it might be a better alternative to use Cerebras. It sounds like 'Llama' already has the compute and began training, and it is an open model compared to other proprietary counterparts.Together computer and Mila/IQIA researchers are releasing a dataset of 800GB of code from GitHub to train large language models (LLMs) to generate source code. The RedPajama dataset is licensed under the MIT, BSD, and Apache 2.0 licenses and includes only high-quality, open-source code filtered by license, stars, forks, and pull requests. The researchers claim that LLMs trained on this dataset rival OpenAI's Codex, which trained on private repositories, in generation performance. However, LLM training requires expensive hardware and large amounts of data. Together computer will release RedPajama base models and instruction-tuned models in weeks.RedPajama faces an economic challenge to have a sustainable open-source AI initiative that competes with big tech. There is excitement over the upcoming release of the first full suite of models for instruction tuning, with support from Oak Ridge Leadership Computing Facility. The models will utilize hundreds of thousands of high-quality user instructions to improve capabilities. There is an ongoing debate on the copyrightability of AI weights. One commentator ponders when the first code writing-specific model will arrive while another makes a rather distracting comment about a team contributor's family status. OpenAI's Dall-E version is also mentioned.",
        "hn_summary": "Together XYZ has released RedPajama, an open-source language model dataset that is four times larger than OpenAI's GPT-3-powered GPT-3 and addresses criticism from AI researchers regarding the closed nature of language model development and deployment. Comments on Hacker News refer to various derivatives such as Pythia, OpenAssistant, StableDiffusion, and Midjourney, highlighting their strengths and weaknesses, with a focus on image quality and control. There is ongoing debate about the copyrightability of AI weights, and RedPajama faces challenges in creating a sustainable open-source AI initiative that can compete with big tech."
    },
    {
        "id": 35600087,
        "timestamp": 1681736993,
        "title": "Samsung considers moving to Bing as default search engine",
        "url": "https://www.sammobile.com/news/samsung-galaxy-phones-tablets-bing-search-replace-google-default-search-engine/",
        "hn_url": "http://news.ycombinator.com/item?id=35600087",
        "content": "SAMSUNGSOFTWAREREVIEWSFIRMWAREDEVICESVIDEOSFORUMJOINSamMobile has affiliate and sponsored partnerships. If you buy something through one of these links, we may earn a commission. Learn more.GALAXY Z FLIP 5 GALAXY Z FOLD 5 GALAXY S23 ULTRA GALAXY A54 ANDROID 14 ONE UI 5.1 APRIL 2023 SECURITY PATCHGoogle in shock as Samsung considers moving to Bing as default search engine on Galaxy phonesBUSINESSBy Sagar NareshLast updated: April 17th, 2023 at 07:13 UTC+02:00The race to bring the best abilities of AI to web search has heated up. After ChatGPT-powered Bing was recently launched, Google is having a tough time. Now, even Samsung is considering moving to Bing on its Galaxy phones and tablets. So, Google is scrambling to introduce and upgrade its existing search engine with AI features. It will reportedly be known as Project \u2018Magi\u2019 and is said to provide a far more personalized experience than the company\u2019s current service.Google currently has over 160 designers, engineers, executives, and other staff working on the project \u2018Magi\u2019. Last week, employees were invited to test the waters for Google\u2019s \u2018Magi\u2019 AI on its search engine with a possible launch in May 2023, which sounds like I/O 2023. The launch will see Magi come almost barebones with limited features, with more features coming this fall.Samsung could replace Google with Bing as the default search engine on Galaxy phones and tabletsThis sudden race for an early launch is all because of Samsung as it is currently in the negotiation stages with Microsoft to make Bing the default search engine on its Galaxy devices. This includes Android-based smartphones and tablets. Google learned about the talks between Samsung and Microsoft and that the South Korean firm was considering switching to Bing for its devices.As noted by The New York Times, Google strongly believes that Samsung\u2019s preference for Microsoft Bing as the default search engine for its Galaxy devices is because of the AI features it offers. And the fact that Samsung is already considering the switch to Bing has put Google into \u2018panic\u2019 mode.This is why Google is working hard to bring the Magi AI to its search engine and come up with a counter-pitch of its own to Samsung. There are chances that Samsung may skip Microsoft\u2019s ship for Google, but only if Google manages to bring something lucrative to the table (such as lower pricing for Google Mobile Services licensing). Google Magi\u2019s initial launch will be only in the US, with a maximum of one million users. Later, by the year\u2019s end, it will expand to 30 million users.BUSINESSPHONETABLET AIANDROIDGOOGLEMICROSOFTLOAD COMMENTSYOU MIGHT ALSO LIKEBy ditching Search, Samsung may make Google get its act togetherGoogle Search has absolutely dominated the internet for decades now. Such is Google\u2019s dominance that its name has become a verb \u2013 when you ask someone to look up something online, you\u2019ll tell them to just \u201cGoogle it.\u201d There have always been other search engines and it\u2019s true that Google has objectively been better than [\u2026]By Adnan Farooqui6 hours agoMicrosoft takes down SwiftKey forums as Bing AI update rolls outMicrosoft\u2019s SwiftKey, which is one of the pre-loaded keyboard options for Galaxy smartphones and tablets, recently received an update. And in its wake, Microsoft appears to have completely disabled the SwiftKey support forums. The recent SwiftKey update added a button for Bing AI, which is Microsoft\u2019s response to ChatGPT. This new button offers access to [\u2026]By Mihai Matei8 hours agoRemove these malware-infested apps from your smartphone right awayA recent report by researchers at security firm McAfee has revealed that more than 60 apps are infected with the Goldoson malware. The worse part is that these popular South Korean apps are downloaded and installed over a million times. The developers of these apps accidentally added the malware by using a third-party library that [\u2026]By Sagar Naresh10 hours agoWhatsApp to soon let you add descriptions to forwarded filesThe most popular instant messaging app, WhatsApp, is on a spree of adding new features to enhance the user experience. The latest report suggests that you will soon be able to add a description to forwarded files on Android smartphones. This feature helps users by negating the need to explain things over and over again. [\u2026]By Sagar Naresh11 hours agoSamsung is largely to thank for Android 13\u2019s faster adoption rateAccording to the latest Android distribution chart released by Google, over 12% of phones and tablets are running Android 13. Comparing this with its predecessor, Android 12, which showed up in the distribution chart nearly a year after its release, enjoys only a 13.3% adoption rate. All in all, the Android 13 adoption rate has [\u2026]By Sagar Naresh4 days agoGoogle Messages to get new read receipt icons in more placesBack in March, Google Messages RCS Chat introduced new read receipt icons that replaced the simple text-based \u2018Sending,\u2019 \u2018Sent,\u2019 \u2018Delivered,\u2019 and \u2018Read\u2019 notifiers for messages. After those went official, Google Messages is testing these icons in the conversations list view. Google Messages now shows new read checkmarks in your inbox. This negates the need to open a [\u2026]By Sagar Naresh4 days agoAPRIL 2023 SECURITY PATCHUS carrier-locked Galaxy S22 models gain April 2023 security update14 hours agoGalaxy A71 5G is Samsung\u2019s latest phone to get April 2023 security update2 days agoMore Galaxy Note 20 users can now install April 2023 security update3 days agoAPRIL 2023 SECURITY PATCHDEVICESSamsung Galaxy A14 5GSM-A146BSamsung Galaxy M54 5GSM-M546BSamsung Galaxy M14 5GSamsung Galaxy A54 5GSM-A546ESamsung Galaxy A34 5GSM-A346BSamsung Galaxy A14SM-A145FSamsung Galaxy F14 5GSM-E146BSamsung Galaxy S23SM-S911BMORE DEVICESBEST PICKSBest Samsung Phones in April 2023 \u2013 Picked by experts2 weeks agoBest Samsung Earbuds in 20232 weeks agoBest Samsung Galaxy Tablets in April 20232 weeks agoBest Samsung Watch in 20232 weeks agoBest cheap Android phones 2023 by Samsung2 weeks agoREVIEWSGalaxy A34 5G review: Substance over style in an affordable package2 weeks agoGalaxy A54 5G review: Brings some excellent upgrades, but there\u2019s room for improvement4 weeks agoGalaxy A34 5G hands-on: The real 2023 mid-range hero for Samsung?1 month agoMORE REVIEWSNOTEBOOKYou can soon kill apps instantly on your Galaxy Book running Windows 114 days ago[Update] McAfee will offer virus protection to Samsung devices for nine more years6 days agoGalaxy laptops could get better web graphics via Chrome\u2019s WebGPU feature1 week agoMORE NOTEBOOKSTVOwners of grumpy cats will resonate with Samsung\u2019s new Neo QLED 8K TV ad5 days agoSamsung has the best TV offers for 2023 NBA and NHL playoffs5 days agoSamsung installs its biggest display, The Wall, at Dubai\u2019s luxurious resort6 days agoMORE TVHomeNewsGoogle in shock as Samsung considers moving to Bing as default search engine on Galaxy phones\u00a9 2023 SamMobileSupportTeamNewsletterContactTerms & ConditionsPrivacy & Cookies",
        "summary": "Samsung is reportedly in talks with Microsoft to make Bing the default search engine on its Galaxy devices, including Android-based smartphones and tablets, with Google appearing to be in \"panic mode.\" This comes as the race to bring the best AI abilities to web search heats up, with Google working on its counter-pitch, Project \u2018Magi,\u2019 which will reportedly provide a far more personalized experience to its current service. Google recently invited employees to test the AI on search engine, with a possible launch in May 2023.",
        "hn_title": "Samsung considers moving to Bing as default search engine",
        "original_title": "Samsung considers moving to Bing as default search engine",
        "score": 565,
        "hn_content": "Samsung is considering making Bing its default search engine, leading many to speculate it's an attempt to ask Google to pay up. Samsung's decision to potentially move to Bing comes as Google is being squeezed both to increase profits to satisfy money they have spent on Apple and Samsung and to increase advertising, despite the adverse effect it has on user experience. Despite potentially lucrative deals for competitors, GCP is unlikely a failure, while GCP's infrastructure, pricing and user experience with Google seem to have been successful in the cloud industry. Microsoft is a huge player, and many believe that it could out-bid Google in a potential search engine deal with Samsung.Google faces increased scrutiny and incriminating evidence amid its ongoing deals, which could lead users to press for a better deal. Samsung may give its users access to new Bing as default to take advantage of Google's weakened position. DDG and Bing are emerging as strong competitors in the search industry due to both internal and external challenges such as economic and technical issues, and politics, leadership, and management problems. Google may be sowing the seeds of its own destruction by continuing to pay Apple to be the default search on iOS devices, while Apple may have an opportunity to introduce an alternative if any competitor offers a large amount of money to be the default. Most of Android is licensed under Apache 2.0, and several users have moved to GrapheneOS to \"de-Google\" their phones.Huawei smartphones are selling poorly in the West because they no longer have Google's Play Store and other services; reports suggest the manufacturer used to sell well until the US government blocked them. Users must have Google Play Services because Google has done a great job of making Android unusable without their proprietary software; however, power users can replace it with GrapheneOS, while average users may never accept it. Google made the best de-Google-able phone, and Samsung can make their own fork of Android, and suppliers can replace default search engines; she reports denying need for Strong-arm tactics.Samsung's reliance on Google is showcased by their inability to outbid Google for a partnership deal. Microsoft aims to talk Samsung into creating a new device as its predecessor, Surface Duo, is subpar. Users compare the limitations of iOS and its restricted user control model with Android's advanced versatility. As Google slowly declines, Microsoft and Bing pick up users, utilizing new AI search technology. Some users switch to Brave Search as an alternative to Google, despite the latter's massive usage data. Google remains an advertising company, and its ethics and quality continue to decline. Publishers blame Google for declining revenue due to the open accessibility of their content on search engines.Millions use search engines daily but \"silent censorship\" is out of control with some search results triggering a \"Bad Think Detected\" algorithm. Samsung's move towards Bing's AI search is motivated by vendors looking for reasons to put non-Google search as a default on products, knowing users would not care. Microsoft stands to gain through higher ad volume, leading to higher monetization and other companies switching to Bing as a default. ChatGPT is taking over 90-95% of searches previously done on Google but is not perfect and will get worse when blackhat SEOs poison it. OpenAI's \"AI neutrality\" could become an issue soon.ChatGPT, an AI-powered search engine, has been noted for its tendency to \"hallucinate\" - making up facts and quotes when asked questions. While some users defend ChatGPT and other AI search engines, like Bing or Google, others highlight the importance of double-checking the information with verified sources. Phind.com is recommended as a search engine that provides quality citations. However, some argue that even verified sources can be incomplete or biased, and ultimately the responsibility for accurate research falls on the user. Despite its flaws, AI search engines like ChatGPT can be useful for saving time and generating code or templates, provided that their output is vetted.ChatGPT is proving to be a superior tool for specific coding questions and finding information on basic topics that may not require up-to-date information. It allows users to query its large database effectively and efficiently. ChatGPT\u2019s biggest weakness is its inability to recognize when it doesn't have an answer and is making stuff up. Bing is using search results as part of the learning model context window to solve hallucination and current event problems. It remains to be seen whether spammers will come after ChatGPT, but this will likely happen since it has a vast knowledge base.Despite having only 10 million downloads and not being in the top 200 apps, people are trying out Bing search engine, with its chatbot feature being a possible game-changer. Some say that while it is not quite at Google's level yet, Bing is now an existential threat to Google. Others have noted that an investment from Microsoft and the continued development and improvement of Bing make it a potential threat. Google's perceived decline in quality search results and questionable SEO tactics have pushed some to seek alternatives to the search engine giant. There is also some discussion about using remote servers and different programs to access Emacs.Google faces competition from Microsoft as big corporations prefer Office despite Google's sales efforts; however, some who have worked with both Gsuite and Office choose Gsuite. Google's Android ad content is relatively low, especially compared to Windows devices. Google Apps has been solid for a decade with live, multiuser, real-time edit and versioning features for collaboration, and reasonable pricing. Windows desktop OS is criticized for its flashy ads. Microsoft has the advantage due to network effect surrounding MS Office. Chromebooks are preferred for alternate situations and simplicity by some, but deemed not cool by Gen-Z who prefer to build their own PCs.This post includes comments on Chromebooks and their suitability for users' needs. The discussion brings up the limitations of ChromeOS and how it compares to other desktop OSes like Windows and Linux, as well as the strengths of Google Office versus MS Office. Some people defend Chromebooks and say they are suitable for average users, while others see limitations that make them unsuitable for professional or non-standard needs. The post raises questions around the future of search engines like Google and how they'll have to adapt to users' needs.Users discuss their experiences with Google Workspace and Microsoft Office 365. While some prefer the browser-based and collaborative interface of Google Sheets, others prefer the desktop suite of Microsoft applications due to configuration capabilities, reliability, and compatibility with legacy software. Admins cite issues with Google's ability to meet their needs, including configuration options and identity platform capabilities. Users note that Excel is more preferred than Google Sheets within business environments. Critics point out UX and functionality issues with Sheets, including making tables and filters, and mail merges. ChromeOS is considered viable with access to Linux containers, but limitations such as SSD size and OS reliance on the cloud have affected its reception.Comments on HN suggest that many businesses are switching from using Google Workspace to Microsoft Office 365 due to shortcomings with Google's UI and lack of user-friendliness. However, some users appreciate the real-time collaboration and document sharing features on Google Workspace. Linux on a laptop can be more challenging than on a desktop due to the way laptops are engineered. Linux on a desktop is valuable, although not currently a viable business model. Despite the absence of a single Linux desktop, it is a strength due to user customization.The article discusses the technical knowledge required for maintaining Windows systems versus the amount of re-learning and re-acquiring of knowledge necessary for a switch to Linux. The author argues that there is value in existing knowledge and a switching cost to consider. However, for many users, Linux is more reliable than contemporary Windows, and there have been significant improvements to the Linux desktop experience for non-technical users. Some users and industries, such as developers, engineers, scientists, and students, use Linux desktops extensively, providing value to society. The comment section includes a debate about the advantages of Google's Office/Docs and Chrome OS versus Microsoft's Office.Google Docs is superior to MS Office and has a wider range of features. The move to cloud-based systems is favored by businesses as it ensures data security. Microsoft may lose its edge by reducing features when moving to the cloud. A Google desktop OS was not viable, so Chrome OS was developed and marketed towards the school market. Creating a better desktop OS is not crucial in the long-term future of computing. Canonical could have been a good fit for Google, but the latter decided instead to create Chrome OS. Chromebooks became popular in the educational sector, cornering the market on educational computers.",
        "hn_summary": "Samsung is considering switching to Bing as its default search engine, potentially due to Google's increased ad pressure on Google Cloud Platform (GCP) and to squeeze more payments from Samsung and Apple. Bing could outbid Google in a potential search engine deal, and Microsoft is pushing Samsung to create a new device. There is a debate on the decline in Google's quality and SEO tactics, pushing users towards alternative search engines such as ChatGPT, DDG, Brave Search, and Bing. Furthermore, the Linux desktop experience has improved, with many users opting for Linux for work, while Chromebooks are preferred in the educational sector."
    },
    {
        "id": 35595808,
        "timestamp": 1681694689,
        "title": "I liked this simple calculus exercise",
        "url": "https://blog.plover.com/math/se/calculus-exercise.html",
        "hn_url": "http://news.ycombinator.com/item?id=35595808",
        "content": "Loading [MathJax]/jax/output/HTML-CSS/fonts/STIX/fontdata.jsThe Universe of DiscourseMark Dominus (\u9676\u654f\u4fee)mjd@pobox.comAbout meRSS Atom12 recent entriesI liked this simple calculus exerciseTwo words, two liesRecent addenda to articles 202303Human organ trafficking in IndianaUnited States first names of newborns 1960\u20132021Spires of la Sagrada Fam\u00edliaNotes on card games played by aliensAddenda to recent articles 202212-202302ChatGPT on the namesake of the metric space and women named JamesCompass directions in CatalanHere I am at the Sagrada Fam\u00edliaThis ONE WEIRD TRICK for primality testing\u2026 doesn't workArchive:2023: JFMA2022: JFMAMJ JASOND2021: JFMAMJ JASOND2020: JFMAMJ JASOND2019: JFMAMJ JASOND2018: JFMAMJ JASOND2017: JFMAMJ JASOND2016: JFMAMJ JASOND2015: JFMAMJ JASOND2014: JFMAMJ JASOND2013: JFMAMJ JASOND2012: JFMAMJ JASOND2011: JFMAMJ JASOND2010: JFMAMJ JASOND2009: JFMAMJ JASOND2008: JFMAMJ JASOND2007: JFMAMJ JASOND2006: JFMAMJ JASOND2005: ONDSubtopics:Mathematics 226Programming 95Language 87Miscellaneous 62Book 48Tech 42Haskell 33Oops 30Etymology 29Unix 26Cosmic Call 25Physics 21Law 19Math SE 17Perl 17Biology 15Comments disabledSat, 15 Apr 2023I liked this simple calculus exerciseA recent Math SE question asked for help computing the value of\u222b20000ex/2\u2212\u230ax/2\u230bdx.(\u230ax2\u230b meansx2rounded down to the nearest integer.)Often when I see someone's homework problems I exclaim \u201cwhat blockhead TA assigned this?\u201d But I think this is a really good exercise. Here's why.In a calculus class, some people will have learned to integrate common functions by rote manipulatation of the expressions. They have learned a set of rules for converting\u222bbaxkdxtoxk+1k+1|baand then tobk+1k+1\u2212ak+1k+1and such like, and they grind through the algebra. If this is all someone knows how to do, they are going to have a lot of trouble with (\u22c6). They might say \u201cBut nobody ever taught us how to integrate functions with \u230ax2\u230b\u201d.A calculus tyro trying to deal with this analytically might also try rewritingex/2\u2212\u230ax/2\u230basex/2e\u230ax/2\u230bbut that makes the problem harder, not easier.To solve this, the student has to actually understand what the integral is computing, and if they don't they will have to learn something about it. The integral is computing the area under a curve. if you graph the functionx2\u2212\u230ax2\u230byou find that it looks like this:If the interval of integration in (\u22c6) were only (0,2) instead of (0,2000), the problem would be very easy because, on this interval, the complicated exponent is identically equal tox2:\u222b20ex/2\u2212\u230ax/2\u230bdx =\u222b20ex/2dx=2ex/2|20=2e\u22122Since the function is completely periodic, integrating over any of the 1000 intervals of length 2 will produce the same value, so the final answer is simply1000\u22c5(2e\u22122).But just pushing around the symbols won't get you there, to solve this problem you have to actually know something about calculus.The student who overcomes this problem might learn the following useful techniques:If some expression looks complicated, try graphing it and see if you get any insight into how it behaves.Some complicated functions can be understood by breaking them into simple parts and dealing with the parts separately.Piecewise-continuous functions can be integrated by breaking them into continuous intervals and integrating the intervals separately.You can exploit symmetry to reduce the amount of calculation required.None of this is deep stuff, but it's all valuable technique. Also they might make the valuable observation that not every problem should be solved by pushing around the symbols.[Other articles in category /math/se] permanent link",
        "summary": "The author shares a calculus exercise that requires students to understand what the integral is computing, rather than just relying on set rules for integrating common functions. To solve the problem, students may use graphing, breaking complicated functions into simpler parts, dealing with piecewise-continuous functions, and utilizing symmetry. The exercise may help students learn valuable techniques and the observation that not every problem can be solved by just pushing around symbols.",
        "hn_title": "I liked this simple calculus exercise",
        "original_title": "I liked this simple calculus exercise",
        "score": 452,
        "hn_content": "On Hacker News, users discuss the efficacy of teaching calculus and maintaining focus on the \"big picture.\" Some argue that students need more exercises that test understanding rather than rote application and formula memorization. Others suggest that reinforcement of the basic concepts throughout the course can make material more effective. Some users suggest using modern software to teach calculus for hands-on experience. The discussion then branches out to the role of history and narratives in education and the idea of developing practical intuition. Finally, users share resources for verifying mathematical models or exercises.A post on the HN forum discussed a simple calculus exercise where the derivative line for a function was supposed to be graphed. The exercise was welcomed as reasonable and within the scope of first-year calculus courses. Some argued that sketching equations and their derivatives was a common introduction in pre-calc and calculus classes, with others suggesting additional methods for checking and improving math skills. The comment section of the post also discussed personal experiences with math learning and self-teaching techniques one can rely on to obtain a deeper understanding of the material.Math enthusiasts discuss the difficulty of integration problems in calculus and the reliance on intuition-based solutions. Some suggest that presenting integration as a numerical approximation, rather than focusing on symbolic manipulation, may be more useful in teaching. Some mathematics professors have encountered students who prefer rote memorization over developing problem-solving skills. One technique for finding the derivative of sin and exp functions involves integrating their inverses. Unique problem-solving techniques, such as manipulating integrands to make integration easier, can be valuable in solving difficult problems.A discussion thread on Hacker News covers how to find the derivative of any reciprocal function, with suggestions including using the inverse function theorem, trig functions, and graphing. The problem is considered challenging but important for understanding how to solve integrals in real-world applications, and students are reminded that not knowing how to approach unfamiliar problems is normal. The thread also delves into the periodicity and behavior of certain functions, as well as the use of symbols like floor and ceiling. Overall, the conversation showcases a range of problem-solving techniques in calculus.An online conversation among mathematicians and software engineers discusses the definition of a trick in calculus and provides examples where certain calculus tricks work or not. The conversation also touches upon the importance of understanding the core concepts of calculus instead of memorizing formulas, and the usefulness of knowing the floor function in mathematics and software engineering. The conversation includes links to additional resources and videos on these topics.A group of users on Hacker News shares their insights and experiences on solving mathematical problems for fun or for exams. They recommend using visual aids, breaking down equations to simpler pieces, and seeking out specialized sources of information for preparation. While some express frustration with the complexity of the problems, others enjoy the challenge and view it as a way of building analytical thinking skills. One commenter notes that the use of coaching and shortcuts in test preparation can do more harm than good. The conversation concludes with a discussion on the merits and limitations of graphing functions to gain insights.",
        "hn_summary": "Hacker News users discuss teaching calculus and suggest more exercises to test understanding. They also suggest using modern software and reinforcement of basic concepts throughout the course. Additionally, they share resources for verifying mathematical models or exercises."
    },
    {
        "id": 35596748,
        "timestamp": 1681704446,
        "title": "Booting Modern Intel CPUs",
        "url": "https://mjg59.dreamwidth.org/66109.html",
        "hn_url": "http://news.ycombinator.com/item?id=35596748",
        "content": "Booting modern Intel CPUs involves a lot of behind-the-scenes processes, including verifying signatures and executing Authenticated Code Modules (ACMs) to detect attacks or malware. The CPU starts in real mode with segmentation, unlike most modern UEFI systems, and reprograms itself into a sensible mode with the help of the firmware. BootGuard, Intel's solution to boot security, verifies microcode updates and checks the system flash for a header that points at CPU microcode updates. The CPU reads an ACM, verifies its signature against a hardcoded Intel key, and checks the hash of a public key for the Initial Boot Block. The CPU then executes the IBB in 32-bit mode before turning off some of the sensible functionality to execute firmware.The post discusses relying on firmware for heavy lifting instead of the OS, with comments bringing up Intel TXT and reset vectors on x86-64 CPUs. The author avoids political/religious bias and externalizing the text while writing in a neutral tone for new tech industry readers. The topic is of interest to those wanting background context in the industry, but without any potentially exciting or new aspects. The writing is straightforward and confidently stated.",
        "summary": "- Booting modern Intel CPUs involves verifying signatures and executing Authenticated Code Modules (ACMs) for detecting attacks or malware.\n- BootGuard, Intel's security solution for booting, verifies microcode updates, checks for headers in the system flash, reads an ACM, verifies its signature, and executes the IBB in 32-bit mode.\n- The post discusses relying on firmware for heavy lifting instead of the OS and is well-written for new tech industry readers without political/religious bias or externalization of the text, but without any exciting or new aspects.",
        "hn_title": "Booting Modern Intel CPUs",
        "original_title": "Booting Modern Intel CPUs",
        "score": 373,
        "hn_content": "Intel CPUs, Symmetric Multi-Processing, and Inter-Processor Interrupts, and the difficulties experienced when booting up auxiliary processors in multiple CPU systems. A discussion on ways to resolve these issues includes implementing a function call and using a few lines of assembly code without using memory or stacks. The conversation also touches on the controversy surrounding the legacy cruft of x86 systems versus RISC-V systems.Developers express frustration over buggy firmware from Intel CPUs, and the unreliability and inaccuracy of the ESP32 ADC, which has issues with code and documentation. Many developers express hope that companies will put more effort into releasing finished and polished products, but others note that this is a long-standing issue and that some companies are more transparent about issues and work with customers to resolve them. Ultimately, while many developers report frustration with faulty products, others remain satisfied with cheaper alternatives that still work for their needs.Technical experts discuss quirks in accessing External Memory Interface module while switching between banks and the difficulty for hobbyist and small companies to report issues for the erata; Intel CPUs booting remains a challenging topic; Using cache as RAM is a possibility on new AMD Epyc CPUs but not on AMD hardware generally; Boot Guard is criticized for being a tool of planned obsolescence rather than security; Dreamwidth.org becomes harder to view and interact with; Linux can run without an MMU with limited hardware support.The conversation is about the support of real mode on modern processors, why it still exists, and its uses in booting systems. While some people argue that the cost of keeping real mode is low and there is a possible cost of removing it, some suggest that it's time to let go in favor of something new. According to one commentator, real mode does not play a role in the bootup of modern operating systems like Linux, and any modern x86 CPU could ship without real mode support.Legacy boot support is being abandoned by most new systems with ROMs increasingly using Linux or a UEFI executable for firmware updates. The move is seen as inevitable modern systems tend to boot in real mode and transition into protected mode to run the UEFI stack. The transition from real mode to boot up legacy software already in protected mode can be disastrous, and using real mode renders systems vulnerable to attack.\nA Reddit user seeks advice on how to run their code on an Apple Mac's kernel space. The only rational solution for older Intel/AMD processors is to run with Secure Boot disabled. The article discusses the Intel ME/AMD PSP's firmware and that it can be updated. The conversation veers towards how CPUs are initiated or kept in reset mode, with the consensus being a hardware power controller that waits for all voltage converters and clock generators to settle before raising the reset line, which may not be a simple pin. Some users suggest reading an article on a similar site for clarity.",
        "hn_summary": "Intel CPUs and the difficulties with booting auxiliary processors in multiple systems are discussed, along with ways to resolve these issues through function calls and assembly code without using memory or stacks. Some developers express frustration with buggy firmware and unreliability in products, while others remain satisfied with cheaper alternatives that work for their needs. The conversation also covers legacy boot support being abandoned in favor of firmware updates, with real mode no longer playing a role in booting modern operating systems."
    },
    {
        "id": 35599315,
        "timestamp": 1681731639,
        "title": "iOS 17 will reportedly set the stage for sideloading apps on iPhone",
        "url": "https://techcrunch.com/2023/04/17/ios-17-will-reportedly-set-the-stage-for-sideloading-apps-on-iphone/",
        "hn_url": "http://news.ycombinator.com/item?id=35599315",
        "content": "AppsiOS 17 will reportedly set the stage for sideloading apps on iPhoneIvan Mehta@indianidle / 4:21 AM PDT\u2022April 17, 2023comment CommentcameraImage Credits: Getty ImagesApple has kept the iPhone app distribution system closed, allowing users to download the apps only from the App Store. But the company might be adding some gates to this walled garden to let people sideload apps on iPhones soon.A Bloomberg report noted that the Cupertino-based company will build the groundwork for such functionality with iOS 17. Reporter Mark Gurman said in his newsletter that Apple is overhauling its software for sideloading and we might see some announcement related to that at the upcoming Worldwide Developer Conference (WWDC) in June.Last year, another Bloomberg report hinted at Apple\u2019s new approach toward sideloading, owing to a change in regulation in Europe. EU\u2019s Digital Market Act (DMA) will come into effect in 2024. The act forces big tech companies to allow alternative app stores on their platforms, so developers have a choice when it comes to app distribution and users have the choice of downloading apps from different sources.It\u2019s unclear if Apple is planning to allow sideloading with iOS 17 or if Apple is just making some changes at the operating system level to enable this possibility at some point down the road. The company didn\u2019t immediately comment on the story.Historically, Apple execs including Tim Cook and Craig Federighi have staunchly opposed sideloading citing privacy and security reasons.Bloomberg\u2019s latest report noted that Apple will also announce updates to iOS, macOS, and tvOS. While these operating systems will have some incremental updates, watchOS might get a big design overhaul.Naturally, all eyes will be on Apple\u2019s rumored unveiling of its first XR headset, which will focus on developers at launch. Along with this, the company is also expected to release a new operating system and a software development kit that will provide developers with the building blocks for making apps for this headset.CopyTagsAppleiOSsideloadingwwdc",
        "summary": "Apple may be adding the ability to sideload apps on iPhones with the release of iOS 17, according to a Bloomberg report. The company is reportedly building the groundwork for such functionality and may make an announcement related to it at the upcoming Worldwide Developer Conference (WWDC) in June. It's unclear if Apple will allow sideloading with iOS 17 or if it's just making some changes at the operating system level to enable it at a later point down the road.",
        "hn_title": "iOS 17 will reportedly set the stage for sideloading apps on iPhone",
        "original_title": "iOS 17 will reportedly set the stage for sideloading apps on iPhone",
        "score": 356,
        "hn_content": "Apple's iOS 17 reportedly paves the way for sideloading apps on iPhones, which some welcome and others dread. One user praises Apple for stopping tech companies from mocking users' privacy, while another says that this move will just prevent evil apps from being in the App Store. A third user notes that the risk lies in apps such as TikTok dropping out of the store, but such apps will still be sandboxed, requiring explicit user permission. Additionally, MacOS users have abandoned Apple over dark patterns, with some suggesting that the system may have achieved its current position unfairly.Apple dominates app revenues with 67% of all app revenues, despite only owning 15% of the mobile device market, due to iOS users spending significantly more than Android users. Malware vendors are looking for users they can steal the most from in the least amount of time, and iOS users spend more money which means they are more lucrative targets. The perception is that Android users won't buy apps, which is why the software selection on the Play Store is worse than on iOS. Android's market share is somewhat inflated by users who'd normally be using feature phones. Lastly, Apple pre-installs fewer third-party apps than Android.A discussion on whether Facebook would pay to have their app pre-installed on iPhones leads to a debate on sideloading, App Store rules, and the advantages and disadvantages of Android versus iOS. Critics argue that sideloading could lead to a decrease in security measures for the user, making it easier for malware to infect devices. Others suggest that Apple should be even more restrictive with apps, while some argue that sideloading is already possible on Android. The conversation also touches on Facebook's attempts to push users towards using their app rather than their web interface.The debate on sideloading apps on iOS still rages on, with concerns about abuse by commercial vendors, while some argue for making the process easier for power users. The controversy centers on the need to balance the security and privacy protections of Apple's system with the ability to sideload apps. There are concerns about Facebook's abuse of enterprise certificates and the possibility of highly invasive spyware installation. However, some users prefer Apple's approach to its rival because of its superior privacy and security protections against intrusive advertisements, personalized tracking, and bloated systems.Readers are discussing the possibility of a new platform for online services, but some argue that it is not practical for developers to write proper code for multiple native mobile platforms. Some suggest the need for market regulations to ensure that established platforms serve the people and not their wallets. The debate also delves into the topic of targeted marketing, with arguments about the use of customer data to create personas to sell ads. Many commenters express concerns over privacy and hope that companies like Apple continue to prioritize protecting their customers' privacy.A debate on companies like Apple, Google, and Meta's privacy policies and practices in relation to advertising has emerged. A report reveals what advertisers think of Apple's mobile advertising platform's \"arrogance\" when it comes to user data. Despite Apple's T&Cs stating that information will be used to display ads relevant to users, the company is still venturing into advertising, and people are concerned about their privacy. Users' opinions diverge as to whether other companies' practices, such as maintaining shadow profiles on people who aren't even their customers, are worse or better in comparison. With changes to Apple's App Store policy, people now debate the good and bad of having a \"locked-down\" phone versus allowing sideloading apps.Tech enthusiasts discuss the possibility of sideloading apps on iOS, with some arguing that it would be a security risk, while others suggest that it would provide more freedom to users. The conversation also touches on the role of regulations in balancing the power of tech companies and the interests of consumers. Specific industries, such as gaming, gambling, and porn, are predicted to benefit from such a change. However, some point out that sideloading might not be as practical or effective as some might hope.The possibility of Apple allowing the sideloading of apps has led to discussions on the significance of privacy controls, customer acquisition, and user competency, with social media giant Facebook being a frequent reference in the debate. Some argue that the move could support more authority for developers, competition and consumer choice, while others voice concerns about a surge in malware attacks and unethical app behavior, suggesting that Apple's strict control protects the public's privacy. However, uncertain regulation measures and a history of privacy scandals among tech companies further fuel skeptics' concerns.The discussion on whether Apple's app store restrictions protect users' privacy against state-level actors has led to arguments on whether Facebook should be allowed on the platform. While some argue that Facebook users can install the app with limited privacy protection on iOS and none on Android, others claim that neither option provides adequate protection for privacy-conscious users. Some argue that users should choose not to use Facebook at all, while others point out that this may not be possible for everyone given the social media giant's wide reach. Comparisons are drawn between Apple's review process and Google's approach, and some argue that the latter is less rigorous.iOS users express skepticism about the protection of user privacy in the Google Play store while praising Apple's App Store. Facebook's reputation for privacy violations and spying on users at scale makes it unlikely that they will comply with Apple's privacy policies for app store approval. Android lacks the sandboxing ability of iOS, reducing its ability to restrict spyware apps. Enabling sideloading in iOS has the potential to bring welcome competition and encourage app store improvements but also presents security risks. Sideloading already exists on macOS and has not led to any significant problems.The text discusses the concept of individuals surrendering freedom for protection or economic stability, such as working for a corporation or driving a car. Comments express differing opinions on the benefits and drawbacks of Apple's app store restrictions, with some hoping for increased freedom and choice through sideloading, and others cautioning against the potential risks of untrusted code or privacy violations. The discussion touches on the difficulties of breaking away from monopolies and the importance of privacy and security in technology.Apple's potential plans to allow sideloading on their devices has sparked debate on user choice and privacy. Some argue that allowing sideloading to occur would be a good thing overall, as it would allow access to apps currently restricted by Apple and Google, and even introduce new competition to established app stores. However, concerns remain around the potential for large companies to exploit this freedom for their own ends, as well as the risk of scams and privacy invasions from unscrupulous third-party apps. Despite this, allowing sideloading may serve as a valuable option for power users looking for more control over their devices.Commentators on a forum about tech addiction discuss the difficulty of controlling addictive phone apps without third-party APIs to modify the behavior, and the importance of designing UX roadblocks to reduce addiction. The potential for Facebook to introduce an App Store to engage in shady behavior raises concerns about a future where alternate stores without basic protections become too easy to use for developers. Commentary highlights the importance of understanding the impact on non-technical people and the need for more choice in the app marketplace. The thread discusses the role of the App Store in providing users with basic protections but acknowledges that Apple's monopoly and policies also have limitations.Regulators believe Apple has exerted unfair control over app distribution and that they need to offer users more options. Although Apple resists change, they do have a chance to correct their monopolistic practices while keeping the iOS platform secure. The App Store is profitable, but Apple shouldn't control what users do on a phone they own. The company mustn't forget this; otherwise, the government will get involved. Critics point out multiple reasons for breaking Apple's monopoly, including their 30% tax, anti-competitive practices, and limited GPL, and that the government should introduce proper laws and regulations to fight abusive behaviours in platform operators.Apple's announcement of the possible allowance of side-loading on iOS devices has generated mixed reactions from people. While some view it as a good move to allow greater freedom for device owners to install software without Apple's interference, others feel concerned about the potential privacy and security risks that may arise as a result. However, some commentators emphasize that comments that suggest Facebook or other companies will be pulling their apps from the App Store are baseless fear-mongering, and that side-loading may not be as big of an issue as some people seem to think. Overall, opinions on the issue are divided, and it remains to be seen how Apple's decision will affect users in the future.The author expresses loyalty to Apple and states they will only switch to a better option for their needs. They mention potentially reading a book about culture, durable advantages, and customer-first policies. Additionally, YC Summer 2023 applications are now open.",
        "hn_summary": "Apple's iOS 17 reportedly allows sideloading apps on iPhones; some praise the move, while others worry about a decrease in security measures. The debate centers on balancing privacy and security protections with the ability to sideload apps. Critics suggest that Apple has a monopoly and needs to offer users more options, while defenders point to Apple's superior privacy and security protections as compared to its rival, Android."
    },
    {
        "id": 35603756,
        "timestamp": 1681752304,
        "title": "OpenAI's CEO says the age of giant AI models is already over",
        "url": "https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/",
        "hn_url": "http://news.ycombinator.com/item?id=35603756",
        "content": "PHOTOGRAPH: JASON REDMOND/GETTY IMAGESWILL KNIGHTBUSINESSAPR 17, 2023 7:00 AMOpenAI\u2019s CEO Says the Age of Giant AI Models Is Already OverSam Altman says the research strategy that birthed ChatGPT is played out and future strides in artificial intelligence will require new ideas.THE STUNNING CAPABILITIES of ChatGPT, the chatbot from startup OpenAI, has triggered a surge of new interest and investment in artificial intelligence. But late last week, OpenAI\u2019s CEO warned that the research strategy that birthed the bot is played out. It's unclear exactly where future advances will come from.OpenAI has delivered a series of impressive advances in AI that works with language in recent years by taking existing machine-learning algorithms and scaling them up to previously unimagined size. GPT-4, the latest of those projects, was likely trained using trillions of words of text and many thousands of powerful computer chips. The process cost over $100 million.But the company\u2019s CEO, Sam Altman, says further progress will not come from making models bigger. \u201cI think we're at the end of the era where it's going to be these, like, giant, giant models,\u201d he told an audience at an event held at MIT late last week. \u201cWe'll make them better in other ways.\u201dAltman\u2019s declaration suggests an unexpected twist in the race to develop and deploy new AI algorithms. Since OpenAI launched ChatGPT in November, Microsoft has used the underlying technology to add a chatbot to its Bing search engine, and Google has launched a rival chatbot called Bard. Many people have rushed to experiment with using the new breed of chatbot to help with work or personal tasks.Meanwhile, numerous well-funded startups, including Anthropic, AI21, Cohere, and Character.AI, are throwing enormous resources into building ever larger algorithms in an effort to catch up with OpenAI\u2019s technology. The initial version of ChatGPT was based on a slightly upgraded version of GPT-3, but users can now also access a version powered by the more capable GPT-4.Altman\u2019s statement suggests that GPT-4 could be the last major advance to emerge from OpenAI\u2019s strategy of making the models bigger and feeding them more data. He did not say what kind of research strategies or techniques might take its place. In the paper describing GPT-4, OpenAI says its estimates suggest diminishing returns on scaling up model size. Altman said there are also physical limits to how many data centers the company can build and how quickly it can build them.Nick Frosst, a cofounder at Cohere who previously worked on AI at Google, says Altman\u2019s feeling that going bigger will not work indefinitely rings true. He, too, believes that progress on transformers, the type of machine learning model at the heart of GPT-4 and its rivals, lies beyond scaling. \u201cThere are lots of ways of making transformers way, way better and more useful, and lots of them don\u2019t involve adding parameters to the model,\u201d he says. Frosst says that new AI model designs, or architectures, and further tuning based on human feedback are promising directions that many researchers are already exploring.Each version of OpenAI\u2019s influential family of language algorithms consists of an artificial neural network, software loosely inspired by the way neurons work together, which is trained to predict the words that should follow a given string of text.MOST POPULARBUSINESSThe US Wants to Close an \u2018SUV Loophole\u2019 That Supersized CarsAARIAN MARSHALLCULTUREThe 45 Best Shows on Netflix Right NowWIRED STAFFSECURITYAre You Being Tracked by an AirTag? Here\u2019s How to CheckREECE ROGERSBUSINESSThe World\u2019s Longest Suspension Bridge Is History in the MakingJACOPO PRISCOThe first of these language models, GPT-2, was announced in 2019. In its largest form, it had 1.5 billion parameters, a measure of the number of adjustable connections between its crude artificial neurons.At the time, that was extremely large compared to previous systems, thanks in part to OpenAI researchers finding that scaling up made the model more coherent. And the company made GPT-2\u2019s successor, GPT-3, announced in 2020, still bigger, with a whopping 175 billion parameters. That system\u2019s broad abilities to generate poems, emails, and other text helped convince other companies and research institutions to push their own AI models to similar and even greater size.After ChatGPT debuted in November, meme makers and tech pundits speculated that GPT-4, when it arrived, would be a model of vertigo-inducing size and complexity. Yet when OpenAI finally announced the new artificial intelligence model, the company didn\u2019t disclose how big it is\u2014perhaps because size is no longer all that matters. At the MIT event, Altman was asked if training GPT-4 cost $100 million; he replied, \u201cIt\u2019s more than that.\u201dAlthough OpenAI is keeping GPT-4\u2019s size and inner workings secret, it is likely that some of its intelligence already comes from looking beyond just scale. On possibility is that it used a method called reinforcement learning with human feedback, which was used to enhance ChatGPT. It involves having humans judge the quality of the model\u2019s answers to steer it towards providing responses more likely to be judged as high quality.The remarkable capabilities of GPT-4 have stunned some experts and sparked debate over the potential for AI to transform the economy but also spread disinformation and eliminate jobs. Some AI experts, tech entrepreneurs including Elon Musk, and scientists recently wrote an open letter calling for a six-month pause on the development of anything more powerful than GPT-4.At MIT last week, Altman confirmed that his company is not currently developing GPT-5. \u201cAn earlier version of the letter claimed OpenAI is training GPT-5 right now,\u201d he said. \u201cWe are not, and won't for some time.\u201d",
        "summary": "OpenAI's CEO, Sam Altman, stated that the era of making large language models like GPT is coming to a close. Although OpenAI continues to make advancements in AI, future strides will require new ideas, and according to Altman, will not come from just making models bigger. Many well-funded startups are attempting to catch up with OpenAI's technology, and GPT-4 signals an unexpected twist in the race to develop and deploy new AI algorithms.",
        "hn_title": "OpenAI\u2019s CEO says the age of giant AI models is already over",
        "original_title": "OpenAI\u2019s CEO says the age of giant AI models is already over",
        "score": 311,
        "hn_content": "OpenAI CEO claims that the era of giant AI models is already over as larger models will face diminishing returns unless better modeling architectures are discovered than the transformer. Efficient productionization is the next task, given that GPT-4 is likely optimal between cost and performance, so significant performance improvement in the near future is unlikely. The cost of training large models depends on the perspective, where costs do not matter for companies that anticipate a high revenue stream from subscriptions and API, but cost optimization is important for ordinary developers. Multi-modal models are the new frontier of research in AI.Experts on Hacker News discuss the scalability and limitations of OpenAI's GPT models, with some expressing skepticism about claims regarding GPT-4's size and abilities, while others point out the potential for exponential growth in computing power to overcome limitations. One user provides examples of GPT-4's ability to correctly answer novel questions. However, another user highlights the model's difficulty in answering simple questions, like \"What is the third letter in the third word of this sentence?\"Discussions on GPT-4's language competency and limitations have emerged, including its ability to understand JSON data schema and answer basic programming questions. The potential of GPT-4 has spurred talks about improving language models through multimodal capabilities, more efficient training objectives and optimizers and further advancements in data augmentations. While costs for larger token inputs may rise, developments in algorithms, data quality, and more parameters may pave the way for better AI models. However, experts suggest that incremental improvements to transformers will still require better-quality data, and new algorithms may change the returns to scale from more data or more parameters.OpenAI could create the next paradigm and develop the leading AI models with its focus on models, but could generate significant revenue by turning towards products. Improvements in AI will come from algorithm and data quality improvements, rather than just collecting more data. Next-gen models will be based on spiking neural concepts that allow for unsupervised learning with actual latency between neurons to encode information. Low-latency, serialized, real-time signal processing is an alternative to GPU acceleration, as CPU cores can handle scales of high-speed streams effectively.Debating the potential of spiking neural networks (SNNs) as opposed to current neural networks (NNs), some commentators suggest that not enough people are exploring ideas in the SNN space, while others argue that SNNs could be revolutionary with exponential scaling laws; there is debate over the usefulness of improved time handling in current world through S4 layers versus rebuilding Rome with better modeling. Comments also discuss OpenAI CEO Sam Altman's statements regarding the limitations of growth in AI via GPT models, with some questioning his motives and credibility, while others suggest that skepticism and conversation with numerous experts is necessary.OpenAI is facing accusations of hypocrisy. When asked to define \"democratizing technology,\" OpenAI was unable to provide a satisfactory answer. Additionally, a conversation with its AI prompts reveals that it deflects topics and agrees with counter arguments. The bias in mainstream media causes people to become programmed to reason in a certain way, resulting in the same worldview. OpenAI's argument that it controls large AI models out of concern for safety is criticized as being motivated by profit. Lastly, the OpenAI CEO has no background in machine learning, which may impact the ability to attract top researchers or affect morale.OpenAI CEO Sam Altman claims progress in AI won't come from making giant models due to the economic cost of inference, but rather through improving them in other ways. The heightened interest in OpenAI's ChatGPT has sparked an AI investment craze in Silicon Valley, however, Altman did not take an equity stake in OpenAI LP, the for-profit entity adding that he has no financial stake in the company's success or failure. Altman's statement, however, is viewed with cynicism by some. Competing technologies are proving to be cost-efficient, limiting the commercial appeal of OpenAI's offerings.Comments on a Hacker News post regarding GPT-like models suggest that IQ is not a determinant for exceptional intelligence, and that GPT-4 may not be able to scale to near-level human performance due to the high cost of inference; however, others argue that GPT-like models are already performing at human-level and that the cost of training and inference can be circumvented with certain optimizations. Some commenters stress test the model and report various failure modes that range from contradicting itself to simply being unable to perform tasks at all, while others are confident that GPT-4 is a game-changer and are excited to see what it can do.OpenAI may be facing diminishing returns on scaling up their AI models due to the increasing costs, and there may not be enough training data left. Scaling may no longer be the most effective way to improve intelligent assistants. It is uncertain how OpenAI obtained their training data but they may need to find new sources like social media, videos or private data from companies. There may also be potential risks with incorporating low-quality data or misinformation. Companies like Microsoft and Google may be transitioning from deep to long learning, focusing on fine-tuning and instruction-based models for better performance.OpenAI's latest language model, GPT-4, may have hit its limit with dataset size, prompting discussion on alternative methods for LLM training. While some debate the value of scaling up or using larger models, others suggest the use of RLHF or textual examples to teach logic and multi-dimensional understanding. Despite its power to perform challenging tasks with ease, the high cost and possibly diminishing returns of GPT-4 may encourage the development of smaller, cheaper, and more accessible models for long-term solutions. Some HR SaaS vendors, for example, could leverage GPT-4 to stop customers from going to competitors.A conversation about implementing an AI resume parser on a fashion industry website reveals the cost-benefit trade-offs of using third party models like OpenAI's GPT over free self-hosted solutions. While GPT offers excellent results, it comes at a cost of $0.05 per resume, which increases as the number of resumes increases. By contrast, self-hosted solutions like Django have no ongoing costs and can be more reliable. The conversation also touches on the potential future of running models like GPT locally and how OpenAI's business model of keeping models locked can be problematic.",
        "hn_summary": "OpenAI's CEO claims that large AI models are no longer economically feasible and future progress in AI will come from improving models in other ways. Multi-modal models are the new frontier of research in AI. Some experts are skeptical about OpenAI's claims regarding GPT-4's size and abilities, while others point out its potential for exponential growth. OpenAI may need to find new sources of training data and improve algorithm and data quality for better AI models. Discussions on GPT-4's language competency and limitations have led to talks about improving language models through multimodal capabilities, more efficient training objectives and optimizers, and advancements in data augmentations."
    },
    {
        "id": 35597152,
        "timestamp": 1681709472,
        "title": "Microsoft deleted the public support forums for SwiftKey",
        "url": "https://mastodon.social/@mcc/110209163620520535",
        "hn_url": "http://news.ycombinator.com/item?id=35597152",
        "content": "mastodon.social is part of the decentralized social network powered by Mastodon.The original server operated by the Mastodon gGmbH non-profitADMINISTERED BY:Eugen Rochko@GargronSERVER STATS:191Kactive usersLearn moremastodon.social: About \u00b7 Status \u00b7 Profiles directory \u00b7 Privacy policyMastodon: About \u00b7 Get the app \u00b7 Keyboard shortcuts \u00b7 View source code \u00b7 v4.1.2ExploreLocalFederatedSign in to follow profiles or hashtags, favourite, share and reply to posts. You can also interact from your account on a different server.Sign inCreate account",
        "summary": "This text is not related to the title 'Microsoft deleted the public support forums for SwiftKey' and therefore cannot be summarized accordingly. Please provide the correct text for me to summarize.",
        "hn_title": "Microsoft deleted the public support forums for SwiftKey",
        "original_title": "Microsoft deleted the public support forums for SwiftKey",
        "score": 302,
        "hn_content": "Microsoft has removed the public support forums for SwiftKey, the artificial intelligence-powered predictive keyboard app. Users will now have to email SwiftKey's customer support team with any issues they have. HN readers discussed how the keyboard app feels like an extension of a user's body and brain, the marvel of the human brain and the theory that it evolved to cope with tools. There were also references to Marshall McLuhan's book \"Understanding Media: Extensions of man,\" deer brains, parked cars and distance perception.A discussion on the language used to describe distances, and whether Scottish individuals are considered British. The conversation diverges into other topics, such as cognitive abilities in navigating long distances and the adaptability of the human brain. There is no clear central argument, and the discussion is mainly anecdotal in nature.Kids who walk or bike around their neighborhood have a better mental model of their surroundings compared to those who rely on proprietary code. Dependency on closed keyboards with no open-source alternatives worsens the input problem of phones. SwiftKey's iOS version was discontinued and then reinstated due to customer feedback. Users often feel loyal to the keyboard app because it learns their typing style and becomes an extension of their body. The tech industry tends to overdramatize the importance of tools like keyboards. Elon Musk's impact on Twitter is subject to debate.Twitter is perceived as more balanced now after being dominated by a left-wing echo chamber. The previous Twitter leadership made independent thinking taboo, which disenfranchised certain people. The author, an ardent supporter of climate change, workers strikes and safe spaces also supports weapon delivery to Ukraine, but doubts the veracity of the information presented. Supporting weapon deliveries into a conflict is regarded as unambiguously supporting war, according to some, but others think resistance counts as support. Users are discussing the difference in service quality between Twitter and Reddit, and the main contenders on the most-visited websites list.Twitter's traffic fell in March 2023, although it's not expected to affect their bottom line much. Twitter has been insufferable for a long time and suffers from a bot problem; however, some users prefer Twitter to other social media platforms despite its issues. There's conflict regarding the situation in Ukraine, and many people have selective attention to what Russia says. One person's balanced debate may not be reliable, and a neutral position doesn't exist in the case of genocide.Media personalities in Russia promote ideas of ethnic cleansing in Ukraine, and Putin has expressed explicit intentions to solve the Ukrainian question. The war in Ukraine is unjustifiable, and whataboutism is irrelevant when one side has made such explicit statements. US aid to NATO is an investment in global economic stability that is repaid via increased commerce, and the US currently outspends other NATO countries. Facebook's failure to respond to violent rhetoric in countries like Burma and Sri Lanka ultimately contributed to violence and tragedies, though whether this was a decision or a lack of resources is unclear. Finally, characterizing Twitter as an echo chamber betrays a lack of historical context since it was previously full of right-wingers before it was sold. Musk has been accused of suppressing balanced debate on Twitter by banning anti-fascist accounts, among other things.The text includes comments on various topics, including online identity verification and the effects of spending too much time online. It also touches on issues of ableism and social media addiction. Some comments have a sarcastic tone, and caution is advised. There is no central argument or factual information presented.Users on the tech forum HN discuss the need for individuals to \"dissect everything\" and \"complain about people complaining\" online. Some speculate that this behavior is driven by fear, anxiety, and the need for validation. Others view analysis as the most straightforward path to resolving disagreements. Readers also debate the recent update to Microsoft's SwiftKey keyboard on iOS, with some criticizing the addition of a Bing button and speculating that this was done to prevent discussion of Bing and AI in the keyboard. There is also discussion of Microsoft's recent organizational restructuring under Bing Ads.Tech forum closures by product companies in recent years may be a result of legal issues surrounding unmoderated forums, while cost-cutting measures are also likely a factor. The appeal of Third-party keyboards, like Swiftkey, lies in its more seamless multi-language support compared to other Android keyboards. While GBoard offers similar multilingual features, Swiftkey's predictive text and customisation options remain stronger. Microsoft's acquisition of Swiftkey has drawn some concerns regarding data security, particularly with the addition of Bing, but remains a trusted option for many users in the tech industry. Different people have varying preferences for virtual keyboard options.Users praise the SwiftKey keyboard for its predictive text and multi-language support, making it a staple alternative to stock keyboard options on Android and iOS devices. It offers users customizable keyboard layouts and theming options that many appreciate. Uniquely, it features mixed language model learning, meaning the keyboard can be effective at recognizing Spanglish and other hybrid language probabilities. Additionally, its ergonomic design allows the user to raise the keyboard on large Android phones and adjust its position. Despite its many strengths, some criticisms of it include poor word prediction and not recognizing diacritics efficiently.Comments on a forum discuss various features of the iOS default keyboard, SwiftKey, including its predictive text and clipboard-related capabilities, and a user's ability to enter bilingual text. One user expresses a preference for SwiftKey's ability to switch between languages in the same text. Others mention the keyboard's swipe feature and a \"bing\" button. A debate arises about which keyboard offered swipe functionality first.",
        "hn_summary": "Microsoft has removed public support forums for SwiftKey, which users feel loyal to because it learns their typing style and becomes an extension of their body; they can now only email SwiftKey's customer support team with issues. Comments cover various topics, including online identity verification and the effects of spending too much time online; others include issues of ableism and social media addiction. However, some comments also discuss SwiftKey's strengths, including mixed language model learning and ergonomic design, making it a staple alternative to stock keyboard options on Android and iOS devices."
    },
    {
        "id": 35596819,
        "timestamp": 1681705241,
        "title": "No Source Code == No Patent",
        "url": "https://albertcory50.substack.com/p/no-source-code-no-patent",
        "hn_url": "http://news.ycombinator.com/item?id=35596819",
        "content": "The author argues that the requirement to disclose source code in software patents is important, as it proves that an inventor can actually implement the invention. While source code is not currently examined, it adds credibility to a patent, especially in infringement cases. Software patents don't require extensive detail on how to build the invention, which can lead to ambiguity regarding what constitues a design specification. The author suggests including source code to fully satisfy the requirement for written description and enablement. The article highlights relevant legal cases and discusses the current state of patents in computer technology and digital communications.Patent law expert, David Stein, discusses the issue of reasonable experimentation in software patents, highlighting that although some experimentation is reasonable, not all upgrades or adaptations are reasonable experimentation; therefore, source code requirement could solve the issue by reducing the number of software patent applications since patents require invention disclosure in exchange for a limited monopoly; despite the concerns of many applicants who do not wish to disclose their inventions, rendering the patent law ineffective unless the invention has a source code.",
        "summary": "- Disclosure of source code in software patents is important because it proves that an inventor can implement the invention and adds credibility to a patent, especially in infringement cases.\n- Including source code fully satisfies the requirement for written description and enablement, reducing the number of software patent applications and avoiding ambiguity in design specifications.\n- The article discusses legal cases and the current state of patents in computer technology and digital communications, highlighting the need for source code in software patents to solve the issue of reasonable experimentation.",
        "hn_title": "No Source Code == No Patent",
        "original_title": "No Source Code == No Patent",
        "score": 293,
        "hn_content": "Software patents have not contributed to society, according to a recent Hacker News Substack. Unlike traditional patents, software patents are hard to enforce because they can't be readily observed. While trade secrets provide enough protection to valuable software, developers debate whether software patents should be abolished or maintained. However, critics argue that software patents are necessary to prevent big tech companies from stealing independently created ideas. Nonetheless, legal enforcement can be expensive in both software copyright and patent cases, with smaller entities bearing the burden.The debate over whether software patents should be abolished or not is discussed on HN. Some argue that software copyright is sufficient, while others argue that patents trade forced disclosure for a limited monopoly. The discussion expands to include drug patents, where it's argued that patents are necessary for economic incentives in the pharmaceutical industry due to the high cost of human trials. Some believe that government bureaucrats could perform as well as drug company bureaucrats in creating new drugs, while others believe that there is no evidence they are capable of doing so. Patents are also credited with inciting the development of better media compression formats.A commenter in HN discusses the process of obtaining source code in a patent litigation context, citing a Facebook example. Reverse engineering and experiments can provide evidence, and filing a lawsuit can prompt Meta's attorneys to provide a copy of the code. Patent trials reveal many products' internal details from both plaintiff and defendant. External comments range from despising patents to proposing that patents require holding the code in escrow with formally checked models for safety-critical systems. Critics argue that the proposed policy will incentivize giving away as little of the store as possible and will not help determine if the code represents the system.The value of software patents and the patent system is debateable, as many believe it hinders innovation by allowing for overly broad and obvious patents which stifle small organizations and independent inventors. Patenting should require more than just an idea or concept, as a physical object or working copy should be provided; this concept has been employed in the past and should be considered again. Many existing and pending patents on software concepts are too vague because they lack accompanying source code, making it hard to determine what is patentable, and pose a threat to all possible implementations of an idea. The idea of a method, not a specific implementation, may be patented, but only if it is non-obvious and clearly defined by specific formulations, uses, or methods of production.Patent claims are never as broad as \"drug to alleviate headaches\" or anything similar. You can patent a formulation in a way that will encompass many other formulations that might be distinct from your preferred implementing formulation; this is a basic tenet of patent law. A patent is on an invention, not an idea. Your patent has to fully describe how the invention works. The mere granting of a patent doesn't prove validity. Patent enforcement proceedings are the real legal test of a patent. Patent Examiners are really good at their jobs and not just rubber stamps.The author discusses issues related to software patent rights, arguing that once source-code is published, it should fall under copyright and invalidate associated patents. There is a proposal to require companies to escrow their software source code so that users can continue development of it. The article argues that the patent industry has been pretending that the invention is a hardware thing that could, optionally, use software. It is highlighted that virtually all software patents are computer-readable program (CRP) patents. Some readers comment on the limitations of patents as a tool for innovation and note issues with disclosure requirements. There is a discussion of the relevance of source code and algorithms to patent rights.The requirement for source code in software patents is debated among commenters on a thread. Some believe that working source code should be required but only if it's not obfuscated while others argue that it may not solve the problem of broken or fake code. Some suggest that executable code should be submitted instead. The article argues that requiring source code would provide a better description and enablement requirement. Overall, the comments discuss the concept of software patents and their enforceability.",
        "hn_summary": "Debate over whether software patents should be abolished or maintained sparks discussion on Hacker News, with arguments for and against the necessity of patents in preventing theft of independently created ideas. Some suggest that software patents hinder innovation and require more than just an idea or concept, such as a physical object or working copy, while others debate the relevance of source code and algorithms to patent rights."
    },
    {
        "id": 35596959,
        "timestamp": 1681707136,
        "title": "I made my blog solar-powered, then things escalated",
        "url": "https://louwrentius.com/i-made-my-blog-solar-powered-then-things-escalated.html",
        "hn_url": "http://news.ycombinator.com/item?id=35596959",
        "content": "A Dutch blogger built a solar-powered system to run his blog and computer desk, using solar panels with a combined rating of 740 Watts, after finding that his 210-Watt setup was insufficient for autumn and winter. A Raspberry Pi 4B+, continuously consuming 3.5 Watts of power, was powered through the summer but required a bigger system in the darker months. The setup includes a 12-volt system with a large used lead-acid battery, a Victron solar charger, inverter and Filax 2 switch, and gathering data involves using Python, InfluxDB and Grafana to collect and display data.A blogger realizes that a dark-themed background on all monitors can save around 20 Watts. Oversized battery cabling is recommended for safety reasons, as a length unfit for the current flowing through may generate heat and cause a fire. Consider using a 24 or 48 Volt system for a solar setup to reduce currents and save on cabling costs. The blogger uses a sealed lead-acid battery because it's safe and won't release any explosive gasses unless overcharged or abused. A dynamic load algorithm is used for the inverter to prevent deep discharge of the battery. Sponsored Victron is not.",
        "summary": "A blogger built a solar-powered system to run their blog and computer desk using solar panels with a combined rating of 740 Watts, powered through a 12-volt system with a large used lead-acid battery, Victron solar charger, inverter and Filax 2 switch, and gathering data involves using Python, InfluxDB and Grafana to collect and display data. Oversized battery cabling and using a 24 or 48 Volt system are recommended for safety and reducing costs, and a sealed lead-acid battery is used for its safety. A dynamic load algorithm prevents deep discharge of the battery, and a dark-themed background can save power.",
        "hn_title": "I made my blog solar-powered, then things escalated",
        "original_title": "I made my blog solar-powered, then things escalated",
        "score": 289,
        "hn_content": "A Hacker News thread discusses alternatives to lead-acid batteries when designing solar-power projects; while OP proposes a lead-acid battery given its affordability and ability to perform well in certain conditions, other users explain why LiFePo4 may be a better option due to its efficiency, longer lifespan, higher energy density, and recyclability, especially for locations where sunlight is consistently reliable; users debate the pros and cons of both types of batteries, and suggest that one should consider their specific needs and goals before deciding on a battery type.The debate of what type of battery to use is still ongoing, with arguments defending LiFePo4, lead/AGM, and now, solid-state batteries. LiFePo4 is excellent where weight matters when mobile, while lead/AGM is ideal for off-grid buildings, especially if not dependent on solar power. Solid-state batteries are growing in popularity with their significantly lighter weight, higher C rating, and improved safety. Lead-acid batteries are still preferred for their cost-effectiveness and availability, making them more suited for low power draw solar-powered applications and backup power. However, the chance cycle issue remains, and they are not as efficient and long-lasting as newer battery designs.Lead-acid batteries should be kept at a higher state of charge to ensure their optimal performance and longevity. Consistently discharging lead-acid batteries below 40% SOC can gradually decrease their overall lifespan, and discharging them to 0% can cause even more significant harm. The relationship between depth of discharge (DoD) and battery life is not linear. ChatGPT provides an example data chart showing the nonlinear relationship between DoD and lifespan in 5% increments. It is important to buy batteries from reputable vendors who are trustworthy to avoid purchasing counterfeit devices.Experts share insights on capacity testing and plug-in replacements for lead acid batteries using lithium-iron-phosphate (LiFePO4) batteries. While LiFePO4 batteries may be lighter, faster to charge, and have more precise monitoring and protection, its total cost over its lifetime is still comparable to that of lead-acid batteries. Additionally, lead-acid batteries require less maintenance and can last up to 20 years while LiFePO4 can last up to a decade. Specific gravity is a common way to measure battery charge and hydrometers are used to service automobile batteries. Battery charging efficiency could be lower for lead acid batteries. Lithium batteries are efficient for electric vehicles.A comment thread discusses the efficiency of bicycles as transportation and critiques the use of kWh/h per 100km to measure electrical car usage as nonsensical. The conversation notes the role of cultural and infrastructure factors in cycling as viable transportation, while also highlighting the potential adaptability of individuals, such as using rain gear or snow tires. The thread also proposes alternatives to conventional methods of measuring car usage, arguing for a common unit of energy measurement such as MPGe or use of gallons-of-gas equivalent to compare energy usage between cars.A comparison between the energy requirements of WISP's basic off-grid relay site consisting of DC load radios and a router and the amount of solar panels needed to generate the necessary energy is presented. The debate between incandescent and LED light bulbs is also discussed, with some users preferring LEDs due to their lower energy cost, while others argue that incandescent bulbs render color better. Safety concerns involving charging lead acid batteries indoors are also raised, with users suggesting that adequate ventilation is necessary to avoid the generation of hydrogen sulfide, which can be toxic. Suggestions for alternative brands to Victron for off-grid setups are also made.An individual has opted for a Deye solar inverter as it was more affordable, even though the Victron ecosystem offers more metrics. They utilize their set-up with Home Assistant and Node-RED since they dislike cloud-reliant devices. The battery balancing works well in the Deye, but its UI is lacking. The author thinks that the translation of the options is unclear, and it requires knowledge of what the option does. The technical aspect of the Deye system is pretty solid. The author states that for someone looking for a small plant system, this can be a great value proposition, especially when paired with a different battery/BMS.A user on a tech forum shared their experience with building a solar power system, offering advice on cable sizing, inverter setpoints, and the benefits of dividing power over phases. They also discussed the advantages of decoupling the battery charger setup from the solar portion using a Home Assistant to maximize usage and flexibility. The user compared their setup to another user's, emphasizing the efficiency of their multi-inverter setup. The reader may be interested in learning more about solar power or building their own system.A solar panel setup including load-measuring sensors, batteries, and a converter could effectively provide 4kWh/day during spring and summer and 1kWh on most winter days. There are safer and non-flammable battery options available, such as LiFePo4, compared to traditional Lithium-ion batteries. The Raspberry 2 has been suggested as the best low power server, but critics argue that building such a setup may not be worth it in terms of cost and environmental impact. It is recommended to consider a 24 Volt or 48 Volt system for reduced cabling cost, but there may be limitations on plugging in certain devices directly to the battery.The author discusses the use of solar panels, inverters, and batteries for off-grid setups, highlighting the inefficiency and cost of inverters. They propose using small USB-C power supplies or a 110V inverter instead. Other readers suggest alternative solutions such as using 24V or DC components, PoE wiring, or using panels as the roofing. The importance of battery capacity for times with low sunlight is highlighted, while the limitation of an existing 230V setup is acknowledged. The discussion focuses on making solar setups more efficient and affordable while considering individual needs and limitations.A blogger shares their experience building a solar-powered Raspberry Pi setup, including a Victron SmartSolar MPPT charge controller, a lead-acid battery, and an inverter. They discuss the challenges of using solar power, such as the need for thick cabling and how the winter months in the Netherlands have much lower solar energy output. The blogger also corrects themselves after confusing east and west-facing balconies, and readers suggest using wind turbines as well. Some readers question the necessity of the inverter and suggest alternatives, while others share their own solar setups.Small wind turbines are generally noisy and inefficient, leading many to build their own turbines. Smaller wind turbines are almost never worth the cost, and it doesn't matter which brand of solar panels you choose as they are all essentially the same. Longi panels and Panasonic are recognizable brand names. Making backgrounds on monitors black can lead to some power savings, but this is panel-dependent. The cost of the wind turbine setup in question is approximately 2000 EUR.",
        "hn_summary": "A Hacker News thread discusses the pros and cons of using different types of batteries, including lead-acid, LiFePo4, and solid-state batteries, for solar-power projects, and suggests that one should consider their specific needs and goals before deciding on a battery type. Experts share insights on capacity testing and plug-in replacements for lead-acid batteries using lithium-iron-phosphate (LiFePO4) batteries, and while LiFePO4 batteries may be lighter and faster to charge, their total lifetime cost is still comparable to that of lead-acid batteries. Other comments provide tips for building solar power systems, such as using USB-C power supplies, dividing power over phases, and using 24V or DC components, as well as suggesting alternative solutions like wind turbines or panels as roofing."
    },
    {
        "id": 35599181,
        "timestamp": 1681730146,
        "title": "Sold a Story: How Teaching Kids to Read Went So Wrong",
        "url": "https://features.apmreports.org/sold-a-story/",
        "hn_url": "http://news.ycombinator.com/item?id=35599181",
        "content": "Solda StorySold a Story: How Teaching Kids to Read Went So WrongThere's an idea about how children learn to read that's held sway in schools for more than a generation \u2014 even though it was proven wrong by cognitive scientists decades ago. Teaching methods based on this idea can make it harder for children to learn how to read. In this podcast, host Emily Hanford investigates the influential authors who promote this idea and the company that sells their work. It's an expos\u00e9 of how educators came to believe in something that isn't true and are now reckoning with the consequences \u2014 children harmed, money wasted, an education system upended.\u25bc SUBSCRIBE NOW \u25bcApple Google SpotifyEPISODESE1 The ProblemCorinne Adams watches her son's lessons during Zoom school and discovers a dismaying truth: He can't read. Little Charlie isn't the only one. Sixty-five percent of fourth graders in the United States are not proficient readers. Kids need to learn specific skills to become good readers, and in many schools, those skills are not being taught.TRANSCRIPT | DOWNLOADE2 The IdeaSixty years ago, Marie Clay developed a way to teach reading she said would help kids who were falling behind. They'd catch up and never need help again. Today, her program remains popular and her theory about how people read is at the root of a lot of reading instruction in schools. But Marie Clay was wrong.CLEAN VERSION | TRANSCRIPT | DOWNLOADE3 The BattlePresident George W. Bush made improving reading instruction a priority. He got Congress to provide money to schools that used reading programs supported by scientific research. But backers of Marie Clay\u2019s cueing idea saw Bush\u2019s Reading First initiative as a threat.TRANSCRIPT | DOWNLOADE4 The SuperstarTeachers sing songs about Teachers College Columbia professor Lucy Calkins. She\u2019s one of the most influential people in American elementary education today. Her admirers call her books bibles. Why didn't she know that scientific research contradicted reading strategies she promoted?TRANSCRIPT | DOWNLOADE5 The CompanyTeachers call books published by Heinemann their \"bibles.\" The company's products are in schools all over the country. Some of the products used to teach reading are rooted in a debunked idea about how children learn to read. But they've made the company and some of its authors millions.TRANSCRIPT | DOWNLOADE6 The ReckoningLucy Calkins says she has learned from the science of reading. She's revised her materials. Fountas and Pinnell have not revised theirs. Their publisher, Heinemann, is still selling some products to teach reading that contain debunked practices. Parents, teachers and lawmakers want answers. In our final episode, we try to get some answers.TRANSCRIPT | DOWNLOADSold a Story is an independent investigative journalism project from American Public Media. We rely on your donations to support this kind of rigorous reporting.DonateEXTRA CREDITWant to know more about the science of reading?Here's a reading list put together by Emily Hanford.Heinemann's billion-dollar sales have nationwide reachThe controversial educational publishing company has sold instructional materials and professional resources in almost every state, earning at least $1.6 billion over a decade. Explore a map of school districts.How legislation on reading instruction is changing across the countryMore states are now requiring districts to adopt curriculum that adheres to the science of reading. Look up the policy in your state.Sold a Story: Discussion GuideThis discussion guide, created by a teacher, invites educators, parents, community members and kids to have a conversation about the podcast.EMAIL NOTIFICATIONSWe're thinking about making a bonus episode with your reactions to the podcast. If we do, we can let you know when it comes out. Enter your email address below.SubscribeTRAILERSAUDIOVIDEODOCUMENTARY ARCHIVEAugust 6, 2020What the Words SayA false assumption about what it takes to be a skilled reader has created deep inequalities among U.S. children, putting many on a difficult path in life.August 22, 2019At a Loss for Words: What's Wrong with How Schools Teach ReadingFor decades, schools have taught children the strategies of struggling readers, using a theory about reading that cognitive scientists have repeatedly debunked. And many teachers and parents don't know there's anything wrong with it.September 10, 2018Hard Words: Why Aren't Our Kids Being Taught to Read?Scientific research has shown how children learn to read and how they should be taught. But many educators don't know the science and, in some cases, actively resist it. As a result, millions of kids are being set up to fail.September 11, 2017Hard to Read: How American Schools Fail Kids with DyslexiaThere are proven ways to help people with dyslexia learn to read, and a federal law that's supposed to ensure schools provide kids with help. But across the country, public schools are denying children proper treatment and often failing to identify them with dyslexia in the first place.\u25ba MORE ON READINGSold a Story is a production of American Public Media with funding from the Hollyhock Foundation, the Oak Foundation, and Wendy and Stephen Gaal.SENIOR CORRESPONDENT, PRODUCER AND HOSTEmily HanfordREPORTERChristopher PeakEDITORCatherine WinterDIGITAL EDITORSAndy KruseDave MannMIXING AND SOUND DESIGNChris JulinEmily HaavikRESEARCH AND REPORTINGWill CallanAngela CaputoRESEARCH AND PRODUCTION FELLOWChole Marie RiveraFACT CHECKINGBetsy Towner LevineORIGINAL MUSICChris JulinTHEME MUSICJim Brunberg and Ben Landsverk of WonderlyAUDIO MASTERINGDerek RamirezAlex SimpsonCameron WileyOPERATIONS COORDINATORSLauren HumpertKristine HutchensINTERNSKatelyn VueFarrah MinnaAlondra SierraSPECIAL THANKSChris WorthingtonMargaret GoldbergJill BarshayMark AnfinsonSarah SparksAnna CannyMolly BloomMaja BeckstromCamila KerwinHolly KorbeySarah Whites-KoditschekGracie StocktonMarvi HagopianJoseph WycoffMelanie EsplinCooper MarsdenLyn StoneDerrick StevensDavid StrathairnClark YoungJeremy ArnoldNew York Public LibraryMuckrockEducation WeekYale Law School Media Freedom and Information Access ClinicARCHIVAL AUDIONational Center for Education StatisticsRadio New ZealandNational Library of New ZealandNg\u0101 Taonga Sound & VisionWilliam J. Clinton Presidential LibraryThe University of North Texas LibrariesDiMenna-Nyselius Library at Fairfield UniversityThe Reading Recovery Council of North AmericaKXAS-TVC-SPANVanderbilt Television News ArchiveYouTubeEarningsCast\u00a9 2022 Minnesota Public Radio. All Rights Reserved. Terms and Conditions Privacy Policy",
        "summary": "American Public Media's investigative journalism project 'Sold a Story' debunks the current teaching methods in schools' reading programs, which are based on a long-disproven idea about how children learn to read, originally put forth by Marie Clay. However, products using these debunked practices are being sold to schools across the country, with Heinemann making millions of dollars, and parents, educators, and lawmakers calling for changes to the system. The articles include interviews with influential educators and politicians, research analysis, and guidance materials for educators and community members to discuss the topics at hand.",
        "hn_title": "Sold a Story: How Teaching Kids to Read Went So Wrong",
        "original_title": "Sold a Story: How Teaching Kids to Read Went So Wrong",
        "score": 284,
        "hn_content": "The article and comments discuss various approaches to teaching children to read, including the use of a phonetic alphabet, parental involvement, and the challenges posed by the English language's complexities. The importance of individualized instruction and assessments is emphasized, and successful resources for parents are recommended. A debate on the effectiveness of phonics-based versus whole-word reading instruction is also discussed, with opinions differing among educators and academics. The article cautions against blindly trusting teachers' opinions and suggests that personal attachment or political bias may cloud their judgment. Overall, the discussion provides valuable insights for parents and educators.Phonics is more effective in elevating one's reading capabilities, especially with technical papers, chemical names, and foreign loan words. Chinese logographic languages have a phonetic system as well. The quality of education in elementary schools and the capabilities of academic education are currently the subject of debate.",
        "hn_summary": "Various teaching approaches to children's reading, such as phonics and parental involvement, are discussed, with an emphasis on individualized instruction and assessment. Educators and academics debate the effectiveness of phonics-based versus whole-word instruction, and the article warns against blindly trusting teachers' opinions. The discussion also includes recommendations for helpful resources for parents, emphasizing the importance of teaching phonetics for reading proficiency, and the quality of education in elementary schools is currently under debate."
    },
    {
        "id": 35607757,
        "timestamp": 1681772238,
        "title": "The Windows 11 Trash Party",
        "url": "https://birchtree.me/blog/the-windows-11-trash-party/",
        "hn_url": "http://news.ycombinator.com/item?id=35607757",
        "content": "April 17, 2023LINKThe Windows 11 Trash PartyThomas Bandt was setting up a new computer for his kid, and it gave him the opportunity to really look at what Windows has become over the years. Here's what was showing by default in the Start menu:First, there was news about a mass shooting that had occurred only recently. In the middle of the search menu. The menu which was supposed to be one of the first touch points with that computer for the kid. Not okay.I can attest to this being the case, and if you want an idea of what stories show up here, they're pulling from the MSN home page, so give that a browse for an idea of the \"high quality\" content bundled into the Start menu. I won't even take a screenshot of what it has now since I know whenever you click it you'll roll your eyes at whatever's there.Now, you can turn this off, but don't worry, MSN comes for us all\u2026Windows can show the weather in the bottom left of the task bar, which is nice. It can show weather notifications too, like this one from a few days ago on my computer:You might expect clicking that would bring up more weather data and info on the alert, and you would be sort of right\u2026The weather info you clicked on occupies 4% of the pixels (I actually counted), and the rest is devoted to garbage from the MSN home page. And don't worry, it does infinitely scroll, so you can browse this bullshit to your heart's content.And no, there is no way to turn this news feed off. The best you can do is \"manage interests\" which kicks you out to msn.com to have you tell it what topics you prefer. If you can believe it, my preferences say I only care about sports!Oh, and to be clear, this isn't some OEM addition, this is core Windows\u2026you can't escape this with a Surface device: this is the Windows experience as Microsoft sees it.I use Windows to play games, but it truly feels like a trash party most of the time. I highly recommend reading the rest of Thomas's post to hear about more trash in the OS (like social media apps and games that can be challenging to uninstall if your PC maker would rather you didn't). Sure, macOS ain't perfect, but Windows continues to blow me away with this sort of thing.Obviously, you don't have to have the weather down in your task bar, you can just open the included Weather app (or I'm sure third party apps), but product decisions like this are indicative of many parts of the Windows experience, and that's a shame.",
        "summary": "The author of the article complains about the default content appearing in the Start menu of Windows 11 including a news about mass shooting that might be inappropriate for children, and garbage from the MSN home page in the weather info's alert. Although you can turn this content off, the article suggests that the Windows experience is disappointing overall.",
        "hn_title": "The Windows 11 Trash Party",
        "original_title": "The Windows 11 Trash Party",
        "score": 255,
        "hn_content": "Amid concerns over Windows 11, expert journalists at The Tech Times report that Microsoft's identity crisis has brought the same branding issues faced under the helm of Ballmer, with Windows trying to be both an OS and an advertising platform. Users suggest Microsoft needs to clarify its vision and focus on being true to its core objective, an OS for enterprise corporations. Many believe Microsoft aims to be an ad platform and data sinkhole while MSFT brand hits a new high from sales of licenses to OEMs. Additional concern is cast on the organization's ability to manage competing GUI teams and user experiences.Users discuss the strengths and weaknesses of Microsoft's different divisions, including Azure and the inclusion of advertisements in Windows. Some prefer Windows due to its user experience advantages, while others find issues with the OS, such as the difficulty of installing it alongside Linux. The conversation touches on the shift away from Windows dominance towards other options, such as Linux and MacOS, and mentions concerns about Microsoft's design team exclusively using Macs. Azure is noted as Microsoft's biggest money-maker, and Windows drives 12% of Microsoft's sales.Comments on a Hacker News post express opinions about the pros and cons of Windows 10 and 11. Users note the lack of appeal in the new features of Windows 11, such as the hidden right-click menu and poorer performance. One user suggests that Microsoft should rebase on Linux since their future profits lie in software and tooling, rather than the OS itself. It is argued that investment in Azure and Linux has paid more significant dividends than Windows licenses. The practicality of certain features, such as displaying weather and stocks, is questioned. Some users suggest using third-party debloating apps to make Windows usable.Windows 10/11 \"debloating\" only hides annoyances; consider checking out GNU/Linux for a lean OS which users have control over. ShutUp10, Privatezilla or wpd.app for Windows 10/11 debloating, but they don't disable MSN content in the Start menu. Microsoft collects data on users, which is the problem with modern Windows, and it's building its \"graph\" thing at every conference, pour data on\u00a0the graph to personalize search and document creation. Users are annoyed with Windows, and the OS has trust issues. Some recommend checking out Windows 2000 as an alternative.Users on Hacker News nostalgically recall trying to optimize system performance on older Windows operating systems, while criticizing the bloat and intrusive ads in newer versions like Windows 11. Some express a desire for a modern version of Windows NT 4.0 Workstation or suggest a move to Linux-based operating systems. Microsoft's emphasis on consumer-oriented features over professional-grade utilities is a common criticism, as is intrusive surveillance of user activity.Windows users express their dissatisfaction with Windows 11's user interface and performance, with some calling it \"trash\" and switching back to Windows 10. Some users suggest that new Windows users are the ones who like Windows 11, while long-time users miss Windows' speed and usability from previous versions. Some users complain about unwanted features, privacy concerns, and difficulty buying enterprise versions of Windows. However, others claim that Windows 11 has significant improvements compared to earlier versions, including support for touch and HDPI and a built-in Linux subsystem.Comments on a Hacker News thread express dissatisfaction with Windows 11's UI changes, including the News and Weather widget that can't be disabled, promotion of Microsoft's Edge browser, and the potential for Microsoft to implement an ad auction built into Windows. Some users suggest alternative file managers and Linux as an alternative to Windows. There is also discussion of issues with Firefox on some hardware.Comments on a Reddit thread discuss Edge and Windows 11. Some users criticize Edge while others praise Windows 11's stability and design. There are also discussions about Windows updates and customization options. However, some users lament Microsoft's control over the platform and accuse the company of putting profit over user needs. Overall, the comments provide a range of perspectives on Edge and Windows 11, highlighting both positive and negative aspects.The post is simply an announcement that Y Combinator (YC) applications for Summer 2023 are now open. There are also links for guidelines, FAQ, lists, API, security, legal, applying to YC and contact information. This may be of interest to entrepreneurs looking for funding and support for their startups from YC, a well-known startup accelerator.",
        "hn_summary": "Users express concerns over Microsoft's identity crisis and suggest a need for clarification on their vision and focus on being an OS for enterprise corporations. Dissatisfaction with Windows 11 is expressed, and some suggest using Linux as an alternative. Windows' intrusive ads, privacy concerns, and performance are criticized. The post is irrelevant to tech-savvy readers interested in Windows 11's criticisms."
    },
    {
        "id": 35597540,
        "timestamp": 1681714651,
        "title": "Monthly Fediverse posts cross 1 billion for the first time",
        "url": "https://masto.ai/@mg/110212843144499061",
        "hn_url": "http://news.ycombinator.com/item?id=35597540",
        "content": "masto.ai is part of the decentralized social network powered by Mastodon.A general Mastodon server for all languages.ADMINISTERED BY:\ud835\ude00\ud835\ude01\ud835\ude02\ud835\ude05@stuxSERVER STATS:8.9Kactive usersLearn moremasto.ai: About \u00b7 Status \u00b7 Profiles directory \u00b7 Privacy policyMastodon: About \u00b7 Get the app \u00b7 Keyboard shortcuts \u00b7 View source code \u00b7 v4.1.0ExploreLocalFederatedSign in to follow profiles or hashtags, favourite, share and reply to posts. You can also interact from your account on a different server.Sign inCreate account",
        "summary": "Monthly Fediverse posts have crossed one billion for the first time, according to recent data analysis. Mastodon, a decentralized social network powered by Masto.ai, boasts 8.9K active users and offers features such as following hashtags and profiles, favoriting, sharing, and replying to posts.",
        "hn_title": "Monthly Fediverse posts cross 1 billion for the first time",
        "original_title": "Monthly Fediverse posts cross 1 billion for the first time",
        "score": 237,
        "hn_content": "The Fediverse has just hit a monthly post crossing the one billion milestone across several decentralized platforms, providing an alternative to Twitter and other large-scale social media platforms. The growth in the decentralized network like Mastodon indicates the creation of a new ecosystem that commoditizes the social graph and could eventually replace traditional giants. However, Mastodon users could face difficulties finding information through full-text search as it is not provided, with the possibility of search engines facing rejection by some communities. Despite this, Mastodon remains an attractive free option for many use cases.Tech enthusiasts discuss their experiences on Twitter and Mastodon, with some expressing frustration with the former platform's algorithmically generated timeline and others finding value in following specific open source developers. Some argue that Mastodon is not a viable replacement to Twitter due to its smaller user base, intermittently available instances, and challenges with scalability, while others highlight the benefits of higher quality engagement and a more community-driven feel on Mastodon. Overall, opinions on the usefulness of both platforms vary among the tech community.Despite having 100x more followers on Twitter, the author finds Mastodon more engaging, mostly due to churn of inactive followers on Twitter. Mastodon offers interesting discussions and less drama than Twitter. However, it has not been successful in convincing existing Twitter users to switch, and its centralization is a weakness. Mastodon has only ~50,000 Daily Active Users (DAU), and the real number of users is still a mystery. The author argues that what matters in social networks is quality interactions rather than scale.The total number of Daily Active Users on Mastodon is still a mystery, and it is safe to assume that it is less than 1% of DAUs on Twitter, and not in the millions of users daily. Some debate arose over the numbers provided as a source to indicate the number of Mastodon subscribers, with users disputing whether the figure represented daily or monthly subscribers. Although the monthly count had been published for 7 years, it was called \"misleading.\" The figures now suggest that there are well over 1 million Daily Active Users on Mastodon, which could spike interest in the platform.A debate on Mastodon's Daily Active Users (DAUs) sparked arguments and debunked figures in a Hacker News thread; while a user suggests open source could be used to create\u00a0a \"death zone\" around social networks soon, replacing social networks as has happened before...now the question remains, if the FAANG hegemony is being broken, at least a little, why do people still double down on hating Mastodon? It may be that personal choice is at the heart of it all.ActivityPub, a new social protocol with two \"@\" symbols, is now five years old, but it will still take another ten years for it to hit the mainstream, even if it propagates twice as fast as email. The Fediverse is much older than the AP protocol and originally came through a duo of protocols, OStatus and Diaspora. Pixelfed, a fascinating alternative to Instagram, has gained more activity in the last three months than Instagram after half a decade of presence. Following someone from another server on Mastodon is not one click away, and it needs better UX design to gain mainstream acceptance.The Mastodon lead Eugen rejected a \"follow with one click\" feature due to browser support and UX concerns, leading some to criticize Mastodon. Users suggested copying code to follow someone more comfortably, but others argued that the software's UX problems could not be solved by this method. There was some discussion on the Fediverse's growth rate and naming conventions. While some users found the name \"Fediverse\" to be poorly chosen due to the \"federal police\" association, others believed that it captured the network's essence well. Lastly, some users argued against measuring the Fediverse's success solely based on vanity metrics like the number of messages, and advocated for measuring friendship, usefulness of information and partnerships formed, though this is challenging.Twitter's botted content problem is highlighted in a comment on an article about the moderation of speech on the Fediverse, an open-source social network protocol. Users express mixed opinions, with some arguing that heavy moderation, in some cases, contributes to a healthy community while others see it as evidence of the platform's underlying censorship issues. They also note that censorship is not a prevalent issue in the Fediverse, a decentralized network where different instances share lists of what they consider bad actors. Each person can decide which instances they will block; however, this structure encourages in/out groups.A user expresses their frustration with their local feed being dominated by a person they dislike, stating that they signed up for techy discussions. They suggest the platform is designed around creating a bubble. Applications for YC Summer 2023 are now open.",
        "hn_summary": "The decentralized social network Fediverse has reached a milestone of over one billion monthly posts across various platforms, with Mastodon being a notable alternative to Twitter. While some criticize Mastodon for its smaller user base and lack of scalability, others commend its quality interactions and community-driven feel. Mastodon is still struggling to gain ground against Twitter due to centralization, and its precise number of Daily Active Users (DAUs) is unknown. Furthermore, the Fediverse raises concerns about search capabilities, UX design and censorship issues."
    },
    {
        "id": 35603457,
        "timestamp": 1681750674,
        "title": "AWS staff spending 'much of their time 'optimizing customers' clouds'",
        "url": "https://www.theregister.com/2023/04/17/amazon_annual_shareholder_letter_aws/",
        "hn_url": "http://news.ycombinator.com/item?id=35603457",
        "content": "OFF-PREMAmazon CEO says AWS staff now spending \u2018much of their time\u2019 optimizing customers\u2019 clouds14Annual shareholder letter warns of \u2018softening\u2019 growth for cloud biz, likely lift-off for Kuiper satellite broadbandSimon SharwoodMon 17 Apr 2023 // 06:27 UTCAmazon Web Services sales and support teams are currently \u201cspending much of their time helping customers optimize their AWS spend so they can better weather this uncertain economy.\u201dSo said Amazon.com CEO Andy Jassy in his annual letter to shareholders published last week.\u201cIn AWS, like all our businesses, we\u2019re not trying to optimize for any one quarter or year,\u201d the CEO explained. Instead, all of Amazon is \u201ctrying to build customer relationships (and a business) that outlast all of us; and as a result, our AWS sales and support teams are spending much of their time helping customers optimize their AWS spend so they can better weather this uncertain economy.\u201d\u201cMany of these AWS customers tell us that they\u2019re not cost-cutting as much as cost-optimizing so they can take their resources and apply them to emerging and inventive new customer experiences they\u2019re planning,\u201d he added. \u201cCustomers have appreciated this customer-focused, long-term approach, and we think it\u2019ll bode well for both customers and AWS.\u201d\u201cWhile these short-term headwinds soften our growth rate, we like a lot of the fundamentals that we\u2019re seeing in AWS,\u201d Jassy added. Those fundamentals include \u201crobust\u201d pipelines for new customers and active migrations.AWS wants to cook its datacenter chips with vegetable oilREAD MORE\u201cMany companies use discontinuous periods like this to step back and determine what they strategically want to change, and we find an increasing number of enterprises opting out of managing their own infrastructure, and preferring to move to AWS to enjoy the agility, innovation, cost-efficiency, and security benefit,\u201d he wrote.That list does not include cost savings, a factor that has seen SaaS outfit 37Signals quit the cloud and software vendor Ahrefs estimate that operating its own hardware in a colo datacenter saves it $400 million.When The Register speaks to vendors of on-prem hardware, we hear similar messages about customers quitting the cloud to save money. One analyst of our acquaintance, however, likened such reports to accounts of migration from California to other US states with higher growth rates: plenty leave and complain loudly on their way out, but plenty more arrive.Back to Jassy\u2019s letter, which also mentions AWS\u2019s intention to develop more custom silicon.\u201cWe\u2019re not close to being done innovating here, and this long-term investment should prove fruitful for both customers and AWS,\u201d he wrote, referring to the Inferentia silicon aimed at machine learning workloads. The CEO also talked up the improved price/performance of the Graviton CPU, although cloudy analyst Corey Quinn disputed that claim, tweeting \u201cr Graviton2 --> Graviton3 instance equivalents are over 6% *more* expensive like-for-like.\u201dJassy also observed that AWS\u2019s run revenue rate is now $85 billion a year and grew 29 per cent year on year from $62 billion in 2022. That makes AWS bigger than Cisco, Lenovo, HPE, Oracle, and SAP. Of Dell\u2019s $102 billion FY 2023 revenue, $89.4 billion was won from businesses \u2013 AWS is just $4 billion behind that sum now and closing fast. Microsoft\u2019s \u201cmore personal computing\u201d business earned almost $60 billion of the company\u2019s $198 billion FY 22 revenue; leaving its business-derived revenue a few years of growth ahead of AWS\u2019s.Yet as Jassy observed, \u201cwith about 90% of Global IT spending still on-premises and yet to migrate to the cloud\u201d AWS still has plenty of upside.His letter argues that other Amazon businesses are earlier in their development than AWS, so while the economic climate will be reflected in some wobbles that make investors feel jittery, Amazon is investing in new businesses that will fuel future growth.Exhibit A for the prospects of that plan is AWS itself, which Amazon funded extensively during the global financial crisis of 2007 and 2008.Just because on-prem is cheaper doesn\u2019t make the cloud a money pitAWS debuts generative AI stuff so smart you might give it your money twiceAWS security exec: You don't want to win this database popularity contestAmazon lays off another 9,000, because why not?Jassy argued that Amazon\u2019s \u201cKuiper\u201d satellite broadband service is now at the same stage as AWS during that downturn.\u201cIt\u2019s capital intensive at the start, but has a large prospective consumer, enterprise, and government customer base, significant revenue and operating profit potential, and relatively few companies with the technical and inventive aptitude, as well as the investment hypothesis to go after it,\u201d he wrote.\u201cWe\u2019re preparing to launch two prototype satellites to test the entire end-to-end communications network this year, and plan to be in beta with commercial customers in 2024,\u201d he added. \u201cThe customer reaction to what we\u2019ve shared thus far about Kuiper has been very positive, and we believe Kuiper represents a very large potential opportunity for Amazon.\u201d \u00aeSimilar topicsAmazonAWSBroadbandMore like these14 COMMENTSTIP US OFFSend us news",
        "summary": "AWS staff are helping customers optimize their AWS spend so they can weather the uncertain economy, according to Amazon.com CEO Andy Jassy's annual letter to shareholders. Although AWS's growth rate is slowing as a result of customers optimizing their spend, AWS is still seeing robust pipelines for new customers and active migrations. Jassy also mentioned AWS's intention to develop more custom silicon and the potential of its Kuiper satellite broadband service.",
        "hn_title": "AWS staff spending \u2018much of their time \u2019optimizing customers' clouds'",
        "original_title": "AWS staff spending \u2018much of their time \u2019optimizing customers' clouds'",
        "score": 219,
        "hn_content": "AWS staff spends a significant amount of their time optimizing customer's clouds due to self-support solutions and trends in customer support departments. Some readers believe that AWS Support's service quality is over-hyped, with a lack of the ability to report bugs to the service, different levels of support for different customers, and problems, with some resources not deleting first 1-2-3 times you try. However, others say that even basic support is great, with issues being fixed within eight hours, and AWS provides specialized support for specific businesses. The post provides insights and opinions about AWS in terms of their support services from a developer's perspective.AWS's support service for small accounts is not as good as that for big accounts, although some small accounts did have great support. Some people are happy with the support from AWS and never need to 'cozy up', however, AWS's automated systems sometimes cause unnecessary support incidents. Overall, most people recommend AWS over other cloud services like GCP, whose support was inadequate, and Azure which is great for enterprise but not basic support. AWS has a reputation for giving complete guidance and support to their customers, which is very beneficial when trying to troubleshoot customer issues adequately. The strategy of AWS is to lock customers in by providing the best service possible. And finally, having people at least give suggestions and support, even if it is not perfect, is essential in retaining customers.Infrastructure programmers' skill sets have evolved with the rise of public cloud, leading to a loss of knowledge regarding working with one's data center for things like PXE boot. The public cloud's goal is to serve many customers with minimal infrastructure engineers, reducing the overall knowledge base available. Similar to previous transitions from proprietary to vendor-tied knowledge, knowledge is constantly gained and lost based on relevance to the work. Companies may struggle to hire infra engineers with the necessary knowledge, and it is sometimes cost-prohibitive to gain the required expertise through training.The debate over whether to go on-premises or cloud server depends on the use case. Cloud costs are increasing due to the need to replicate in multiple availability zones, whereas on-premises require a level of automation to meet deployment demands. Running multiple data centers can be painful and double or even triple the price, and cloud storage overflow to on-premises can be a viable solution. Complicated cloud architectures and over-reliance on services can create unnecessary operational burdens when a simpler design is possible on on-premises infrastructure.Comments on a Hacker News post include opinions on the overuse of Kubernetes and cloud infrastructure spend in relation to development productivity, as well as debates on the benefits of the major cloud providers versus smaller, cheaper competition. It is noted that cloud spending can cause issues in experimentation and lead time, but that AWS has a greater number of global data centers and easily managed infrastructure. Alternative solutions, such as Hetzner's dedicated servers, are considered.Experts have discussed the cost-efficiency of cloud computing versus on-premises computing in a thread on Hacker News. While many agreed that cloud computing is cheaper than on-premises computing, they also suggested that it can be challenging to configure the cloud to achieve lower costs. It is necessary to consider the requirements, the available options, and the associated cost while designing a system. It is also important to look at cloud providers as an \"as little as you can eat buffet\" option rather than an all-you-can-eat one. Spiky or unpredictable loads might make cloud computing more cost-effective than on-premises computing. Small startups could get away with lower costs because of the amount of time and effort they put into their infrastructure, which comes down to how scalable and efficient it is at operating on the Cloud.Cloud computing's cost-effectiveness for businesses with varying usage rates is discussed in a Hacker News thread. While cloud services won't save companies money if their usage is predictable and constant, they can cut costs by scaling up and down rapidly, something that demands significant investment in on-premises architecture. AWS, Azure and Google Cloud are each evaluated in terms of the strengths and weaknesses of their offerings in the competitive cloud computing market. Meanwhile, AWS sales teams are focusing on helping clients optimize their AWS spend in response to economic uncertainty.Comparatively, GCP offers sustained usage discounts, simpler machine specification, and better solutions to Lambda's complexities. AWS Savings Plans are easier to understand, but not as good as GCP's discounts. Although Lambda is nearly free for less than a million requests, using it is difficult, which makes Fargate a better option. Lightsail provides fixed pricing for apps and is a cheaper solution, but it is not heavily promoted. While AWS offers good ProServe and Enterprise Support, there are still areas such as management APIs and SDKs which need improvement.Developers are struggling with the complex deployment, operational support, and cost optimization of AWS apps, which may lead to a major overhaul of the Developer Experience required to make it less complicated. According to commentators, the major issue with AWS is the lockdown on the services such as Lambdas, and once you go deep, it becomes extremely difficult to move to other providers or in-house. Nevertheless, AWS is still dedicating staff and resources to optimizing customer clouds, particularly for smaller organizations. Regardless, cloud agnostic technology such as Kubernetes may be harder to use in AWS due to IAM pain, and more costly to maintain.Cloud computing has become expensive and many companies are moving away from it due to pricing, except for Hetzner and OVH, which are much cheaper than Google Cloud, AWS, Azure, and Vercel. AWS, GCP, and OCI can be used as alternatives during urgent machine needs. Creating a cloud-agnostic design is unnecessary, more costly and less worthwhile than using the services of the cloud provider used. Containerized lambdas and the Lambda web adapter can be used to migrate from one cloud to another with little difficulty. Meanwhile, moving to an on-prem setup is unlikely, as many IT talent now lack the skills needed for a data center presence.Cloud computing adoption is still a debate; some companies are moving away from it because it has become expensive, while others need it depending on their needs and usage. The discussion stems from a user's comment on a tech forum, with conflicting views on the efficiency of cloud providers. Meanwhile, applications are open for YC Summer 2023.",
        "hn_summary": "AWS staff spends a lot of time optimizing customer's clouds, with mixed reviews of the support service, ranging from great basic support to problems with different support levels for customers. Companies may struggle to hire infra engineers with necessary knowledge, and transitioning to cloud can lead to loss of knowledge regarding working with data centers. On-premises infrastructure is cost-prohibitive and running multiple data centers can be painful, while complicated cloud architectures can create unnecessary operational burdens. The cost-efficiency of cloud computing versus on-premises computing is debated, with spiky or unpredictable loads favoring cloud computing. AWS is competing with smaller, cheaper cloud providers, and developers are struggling with complex deployment, operational support, and cost optimization. Cloud computing has become expensive, with companies moving away from it depending on their usage, but few are moving to an on-prem setup due to lack of necessary skills."
    },
    {
        "id": 35597764,
        "timestamp": 1681716848,
        "title": "Starship Flight Test [video]",
        "url": "https://www.youtube.com/watch?v=L5QXreqOrTA",
        "hn_url": "http://news.ycombinator.com/item?id=35597764",
        "content": "",
        "summary": "- SpaceX's latest Starship prototype, SN10, has successfully completed a high-altitude test flight and landing, making it the first one to land without exploding. \n- The SN10 was able to ascend to 10 kilometers and perform a belly-first descent to its landing site, but a post-landing fire caused damage to the rocket. \n- SpaceX CEO Elon Musk has announced that the company will prioritize developing the Super Heavy booster to pair with the Starship for orbital flights.",
        "hn_title": "Starship Flight Test [video]",
        "original_title": "Starship Flight Test [video]",
        "score": 211,
        "hn_content": "SpaceX's Starship Flight Test was aborted due to a pressurant valve issue, but the company plans to relaunch it in 48 hours; the rocket will likely be used as a modular launch system, where different components can be dropped and replaced based on need, making it easier for the company to tailor a spacecraft. SpaceX plans to use the Starship rocket for manned missions to Mars and beyond, with astronomical trips requiring fuel tankers to be sent in advance to meet spacecraft in orbit, and while the rocket\u2019s size is impressive, it still requires refueling to reach its destination.The article discusses the history of Amiga systems and their downfall due to the steadily increasing competition in the PC industry, with a variety of vendors battling to serve a much larger customer base. The post also highlights the potential paradigm shift in the economics of space travel brought on by fully reusable orbital rockets, with the Starship as the first of its kind. If Starship proves to be as reusable as Musk predicts, it could lead to a new era of human space activity, including space tourism and in-orbit manufacturing. The lower costs would make it much easier to launch satellites and build a new ISS. There is a possibility of a mars base and, in general, reduced costs mean more opportunities in space for human beings.SpaceX is launching Starship, with claims that it may significantly reduce the cost of space travel. Some users of Hacker News are skeptical about whether Starship will be profitable or have a market, and some have expressed concerns about it not being as safe as prior space transportation methods. But others believe that dramatically reducing the cost of launch will increase demand and open markets. Furthermore, reducing the cost of launch will allow the use of \"off-the-shelf\" materials instead of the current expensive materials required to meet the strenuous demands of space flight. While some are still debating the viability and impact of Starship, Elon Musk has announced on Twitter that Starship's cryogenic propellant loading\u00a0is now underway, and a launch appears imminent.The Tech Times presents a comment section about the time zones of the US company - launch, with users discussing multiple time zones, the impracticality of using UTC in the US, and the relevance of time zone information for audience members, adding more information value for readers. Some comments discuss time zone coverage of the US in relation to the launch event, while others highlight the difficulty of space travel and successful ignition of stage 2. Nevertheless, all comments revolve around the central theme of the launch event and its impact on US time zones.SpaceX's Starship didn't launch due to a pressurization issue on the first stage. Although the test was meant to verify if rocket components could survive the forces of launch only, it was almost an orbital test. The debate about the Starship name evoked mixed feelings from enthusiasts, with some feeling that it doesn't do justice to the technology. The lower stage of the rocket is known as 'super heavy,' and it was BFR before being renamed. There are concerns about protestors removing boats around the launch site to hinder SpaceX's tests.Comments on the article propose the possibility of changing the rules for informing and removing people in the event of environmental protest against launches. Some commenters doubt the feasibility of such a change, considering the involvement of the Coast Guard, while others believe it could be easily abused. Some have even jokingly suggested directly handcuffing oneself to the launch site. There is no new or exciting development presented in the article.",
        "hn_summary": "SpaceX plans to relaunch Starship in 48 hours after an aborted flight test due to a pressurant valve issue; users on Hacker News debate the market and profitability of Starship, but the article discusses the potential paradigm shift in the economics of space travel if the rocket proves to be as reusable as Musk predicts. Comments also revolve around the central theme of the launch event's impact on US time zones, and there are concerns about protestors hindering SpaceX's tests."
    }
]