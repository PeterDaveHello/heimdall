[
  {
    "id": 40982118,
    "title": "Import and Export Markdown in Google Docs",
    "originLink": "https://workspaceupdates.googleblog.com/2024/07/import-and-export-markdown-in-google-docs.html",
    "originBody": "Updates This official feed from the Google Workspace team provides essential information about new features and improvements for Google Workspace customers. Import and export Markdown in Google Docs Tuesday, July 16, 2024 What’s changing In 2022, we introduced expanded support for composing with Markdown in Google Docs on web. Today, we’re introducing highly-requested features that enhance Docs' interoperability with other Markdown supporting tools. These include the ability to: Convert Markdown to Docs content on paste Copy Docs content as Markdown Export a Doc as Markdown (from File > Download) Import Markdown as a Doc (from File > Open or \"Open with Google Docs\" from Drive) Who’s impacted End users and developers Why you’d use it This update is particularly useful for technical content writers as they can now convert Docs content to/from Markdown. For example, developers can collaborate on software documentation in Docs and then export it as Markdown for use in other Markdown supporting tools. Getting started Admins: There is no admin control for this feature. End users: The import and export options are ON by default. The “Copy as Markdown” and “Paste from “Markdown” options will be OFF by default and can be enabled in Docs by going to Tools > Preferences > Enable Markdown. Visit the Help Center to learn more about using Markdown in Google Docs, Slides, & Drawings. Rollout pace Rapid Release and Scheduled Release domains: Gradual rollout (up to 15 days for feature visibility) starting on July 16, 2024 Availability Available to all Google Workspace customers, Workspace Individual Subscribers, and users with personal Google accounts Resources Google Help: Use Markdown in Google Docs, Slides, & Drawings Labels: Docs , Rapid Release , Scheduled Release    Filter by product   Filter by date  Subscribe by feed Subscribe by email Localized Google Workspace Updates Español Français 日本語 Português Useful Links Join the official community for Google Workspace administrators In the Google Cloud Community, connect with Googlers and other Google Workspace admins like yourself. Participate in product discussions, check out the Community Articles, and learn tips and tricks that will make your work and life easier. Be the first to know what's happening with Google Workspace. ______________ Learn about more Google Workspace launches On the “What’s new in Google Workspace?” Help Center page, learn about new products and features launching in Google Workspace, including smaller changes that haven’t been announced on the Google Workspace Updates blog. ______________ Google Privacy Terms",
    "commentLink": "https://news.ycombinator.com/item?id=40982118",
    "commentBody": "Import and Export Markdown in Google Docs (googleblog.com)486 points by pentagrama 16 hours agohidepastfavorite96 comments tomeraberbach 7 hours agoHey folks, I'm the engineer who implemented the new feature. Just clearing up some confusion. A lot of you are noticing the preexisting automatic detection feature from 2022 [1], which I also worked on. That's NOT what this newly announced feature is. The new feature supports full import/export, but it's still rolling out so you're likely not seeing it yet! Hope you like it once it reaches you :) [1] https://workspaceupdates.googleblog.com/2022/03/compose-with... reply andybak 2 hours agoparentThe main effect of slow rollouts on me is that I never use the feature. It goes like this. 1. There's a service I use sporadically or used to use 2. They announce a new feature that might potentially mean I'll start using it again/more 3. I read the post, log in and realise I don't have access yet 4. I completely forget this ever happened. Surely all the effort that goes into announcing these things is a bit wasted ? What happened to the a nice \"Labs\" switch to opt into stuff that's new and a bit raw? reply tomeraberbach 53 minutes agorootparentI can't speak to the reasoning for announcing before 100% rollout, but I can say that the slow rollout is for safety. That way if there's a severe bug, then we can catch it while it affects a small number of users, instead of all users. Labs is more for experimental features that needs more beta testing before rolling out to everyone, rather than being the \"first stage\" of slow rollout. reply pradn 2 hours agorootparentprevIt is a bit odd how they do it in Docs. In Cloud, announcements happen when the feature has already fully rolled out. Note, this is separate from region expansion, which might be delayed for some heavy-weight features (like new categories of VMs requiring special hardware.) reply dpkirchner 49 minutes agorootparentprevAt least it's available to paying customers, that's not always the case. reply remoquete 6 hours agoparentprevSuch a huge quality of life improvement for technical writers who rely on Gsuite collaboration features while editing Markdown docs. Thank you! reply irskep 5 hours agoparentprevIs it also supported in the Google Drive export API? It's not in the docs yet at least. https://developers.google.com/drive/api/guides/ref-export-fo... reply tomeraberbach 5 hours agorootparentYes, it will be supported by this API! I actually wasn't aware of this documentation page. I'll make sure it gets updated. Thanks for flagging reply scrollaway 4 hours agorootparentOh that’s great. Does that mean Google drive will have good markdown previews now? reply zikani_03 51 minutes agoparentprevIs this also available from the googlecloud APIs libraries? Would be neat to be able to create a Google Doc from markdown content, it's something we were going to look into for one of the things we are building. reply tomeraberbach 48 minutes agorootparentThis will be supported by the Drive APIs reply supriyo-biswas 4 hours agoparentprevIs it possible to get this feature in Slides as well? I often need to prepare technical slides with code in it, and being able to just backtick away into atag or ablock would be a godsend. reply sphars 1 hour agorootparentNot an answer to your question because this isn't integrated with Slides, but Slidev[0] can be used for creating slidedecks in Markdown [0]: https://github.com/slidevjs/slidev reply breck 3 hours agorootparentprevNot sure if you have the patience to use a beta product, but I recently started adding slideshows to Scroll. This source code: http://hub.scroll.pub/slideshowdemo/index.scroll Produces this HTML: http://hub.scroll.pub/slideshowdemo/ reply hellojebus 3 hours agoparentprevWill the API support uploading conversion of markdown to \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"? I process thousands of documents each month -- often have to parse from HTML to Markdown to Docx then finally upload and convert to Google Doc format. reply tomeraberbach 3 hours agorootparentIt will support importing Markdown as a Google Doc. I won't support directly importing Markdown as DOCX. For that you could convert from Markdown to Docs to DOCX though. reply scrollaway 1 hour agorootparentprevCheck out Pandoc. reply _boffin_ 4 hours agoparentprevQuestion: when coming up with tests (whatever level they might be) before you submit your code, what’s your thought process about what tests to include? What edge cases to handle? What to not test? Is there much disagreement about what to test? reply tomeraberbach 3 hours agorootparentWe did indeed write A LOT of tests! I would say there wasn't much disagreement there. I typically started out by writing tests for the simple cases, then I would identify edge cases through actual usage of the feature locally, and write tests for those as well. Also, whenever bugs were found, I would write \"regression test cases\" for those when fixing. reply chrisfinazzo 3 hours agoparentprevI would have expected this to export CommonMark, but it seems like it's not quite up to that yet. Is that on the board for a future release? This isn't to say I prefer CM -- because Markdown came into being from Gruber's script. In a literal sense, \"Markdown\" is defined as whatever `markdown.pl` is, warts and all -- however, contact with the outside world forced things to move in a direction that is (so to speak) more organized that what John originally wrote. reply tomeraberbach 3 hours agorootparentThe export part of the feature does support everything that CommonMark does! Curious what gave you the impression that it doesn't? reply ted_dunning 3 hours agoparentprevI can't wait. This will make a huge difference to a lot of my work. reply startupsfail 2 hours agoparentprevWould appreciate support for comments, with CriticMarkup or something. reply sandbx 5 hours agoparentprevI would like to be able to open and edit .md files in Google Docs on desktop and mobile like how Google Docs supports opening .docx files reply tomgp 5 hours agoparentprevThank you! This is going to make my life MUCH easier reply RandomWorker 4 hours agoparentprevThanks for doing this! It’s amazing feature to use docs to compose and paste to my Hugo blog. Very good workflow reply sbergot 5 hours agoparentprevThank you for making that! I was using a plugin to export to markdown but it wasn't ideal. reply jcastro 6 hours agoparentprevThis is going to save me so much time, thank you for this! reply whycome 4 hours agoparentprevGoogle keep… reply Freak_NL 12 hours agoprevNo support for code blocks still: ```java String x = \"xxx\"; ``` No quoting: The docs for `libfloof` state: > The floof is 4 bytes long, at most. And when I type `code` with backticks at the start of a line, the word 'code' is formatted as code as expected, but auto-correct automatically capitalises it to 'Code' — which should never be done with code fragments. So this is basically just headings, italics, bold, and links? It's really annoying when you need to share technical documentation with lots of code and code-like content with people and they've started doing the spec in Google Drive. Just give me working Markdown. reply timClicks 8 hours agoparentTo add a code block, type @ and scroll down to \"Code Block \". It's still very limited, with syntax highlighting limited to C/C++, Java, JavaSript, Python. reply crazygringo 6 hours agorootparentIs that available only in certain paid versions of Google Workspace, or has it not rolled out to everyone? When I type @ there's no code block option. I get People, Smart Chips, and then in \"Building Blocks\" I get five items from \"Meeting Notes\" to \"Project Assets\". If I click the arrow to expand to the full list of building blocks, it only adds a sixth item \"Launch Content Tracker\" and the rest is blank space. reply paulgb 5 hours agorootparentIt's only available in certain paid versions (https://workspaceupdates.googleblog.com/2022/12/format-displ...) Which is too bad, it's the one thing keeping me from writing design docs in google docs. reply crazygringo 5 hours agorootparentAh thank you. Too bad. Funny that they paywalled that feature, while tools like Colab are free. Generally, Google has made code-related and academia-related tools freely available. Oh well. reply tomeraberbach 1 hour agorootparentprevCode blocks are a paid feature, but the Markdown import/export feature is not paid. It's just still rolling out reply judge2020 6 hours agorootparentprevThe author of the feature is another top-level comment and said it's still being rolled out over time, so that's probably why. reply ggm 12 hours agoparentprevWe just have to iterate in the \"markdown support feedback/help\" pulldown I guess. because without ```code``` it's not useful. Looking at you HN... (ok at least we have 2 indents codeblock) reply hnarn 10 hours agorootparentWhat would ``` add that you can't already do with two indents? Beyond that, I think support for ```sh type highlighting would be awful, one of the best things about HN is how clean it is, I'd hate to see syntax highlighting or pictures or whatever when scrolling. reply codetrotter 9 hours agorootparent> What would ``` add that you can't already do with two indents? It would let me add those fences before and after the code I’m pasting instead of having to go and add spaces in front of every pasted line. On mobile adding the spaces after pasting is a bit fiddly. Then again, maybe it is a feature because it discourages pasting too many lines of code in many cases. reply promiseofbeans 10 hours agorootparentprevIt would let you paste a lot of existing markdown into google docs reply Freak_NL 10 hours agorootparentThey meant here on HackerNews. The only thing I really miss sometimes is a way to quote without resorting to indented code blocks. > Just a tiny hint that any paragraph like this starting with a greater-than sign is a quote. reply stevemk14ebr 4 hours agoparentprevThis is supported, but it's probably not rolled out to you yet. And once it is rolled out, you need to turn it on yourself. See the blog the developer linked to in a comment. reply underdeserver 7 hours agoparentprevWorked for me by typing ``` It opens a block and you can select Java. (There's only a relatively small number of syntaxes supported, but still.) reply akersten 4 hours agoparentprevAlso when I close a single line code with `, the formatting stays as if I'm writing more code. It should reset to whatever formatting was before the opening ` reply dazzaji 9 hours agoprevFor Google Docs like real time collab on native markdown, I like and use daily: * https://hackmd.io and * https://stash.new reply mcbetz 8 hours agoparentI used Hackmd in the past to share the draft of my book (1) and liked that people don't need to have an account to comment. Google Docs was no option as no markdown support and account required. The process worked well but I found Hackmd too expensive for just getting feedback. Stash looks promising for this use case. (1) Written fully in Markdown in Obsidian at this point. I moved to Asciidoc since because of formatting. The early draft is still available on Hackmd though. Details in my bio. reply dotancohen 9 hours agoparentprevW Google docs Writer Competitors reply CityOfThrowaway 13 hours agoprevMy guess is that this is strongly motivated by the success of LLMs. The lack of MD support makes manual IO from Docs to your favorite LLM lossy (or very annoying). Cool that it's fixed. reply staticman2 4 hours agoparentThey also already have to support Gemini to Google Docs and vice versa so it makes sense they'd have to support Markdown in some fashion on the backend. reply thallavajhula 12 hours agoparentprevAt this point, most major changes could be motivated by LLMs/AI. reply yboris 5 hours agoprevIn the past I used the Docs to Markdown add-on that has worked well [1] Google Docs -> Markdown -> Hugo website was a great workflow: https://github.com/whyboris/utilitarianism.net [1] https://workspace.google.com/u/0/marketplace/app/docs_to_mar... reply Crier1002 9 hours agoprevi hope they'll eventually support Mermaid (https://github.com/mermaid-js/mermaid) for creating diagrams directly within documents. i've been using it a lot for my markdown files and it works amazingly well with LLMs (e.g. asking LLM to generate the diagram representation of something using Mermaidjs) reply bomewish 13 hours agoprevIf this is implemented properly it’ll be a game changer for collaboration on papers. Means one can write a paper with colleagues in markdown and then easily knit with pandoc/quarto. Cheaper than overleaf etc. reply Symbiote 9 hours agoparentYou can already get most of the way there, as Pandoc supports reading the ODT or DOCX export from Google Docs reasonably well. I have this in my shell history: pandoc --from=docx --to=asciidoc --wrap=none --atx-headers --extract-media=img doc.docx > doc.adoc reply chrisfinazzo 4 hours agorootparentStick downdoc on the end of that pipeline and you're done -- unless you prefer working in AsciiDoc, I guess. Not my thing, but you do you... https://github.com/opendevise/downdoc reply Symbiote 57 minutes agorootparentAsciidoctor has been much better received by my colleagues, primarily for the built-in support of a few technical writing features — admonitions, non-trivial tables, crossreferences, etc. reply protortyp 5 hours agoparentprevI recently used Typst and their own collab solution for a paper we worked on. While some features are still lacking it was a pretty good experience overall. reply gouggoug 12 hours agoparentprevI'll add that writing a paper might be better handled by a more feature-full format like Asciidoc. reply bt1a 12 hours agoparentprevWhy not a markdown doc + git with each colleague using their own text editor/IDE of choice? reply crazygringo 6 hours agorootparentBecause in my experience, the value of collaboration tools isn't versioning -- going back to an older version rarely happens. It's the suggested edits combined with comments sidebar right there in the document, where you can have whole back-and-forth asynchronous discussions. There's no obvious/easy way to have comment threads in markdown or in git. And while you could, in theory, implement suggested edits as commits on a separate branch waiting to be merged in, the workflow for that would be pretty horrible -- are you going to create a separate branch and commit for every single edit? Since small edits are generally individually accepted, rejected, or further modified. reply KeplerBoy 11 hours agorootparentprevBecause not everyone is interested in setting up a Pandoc/Latex toolchain. Overleaf almost solved this problem but they don't support Pandoc as a frontend and want money unless you self-host. reply prmoustache 7 hours agorootparentYou don't need pandoc and even less a latex(WTF does it have to do with md???) toolchain to work with markdown documents. reply KeplerBoy 4 hours agorootparentSorry, I was talking about scientific writing, where you have to be able to produce PDF artefacts. Writing in markdown and converting to .tex is actually a quite popular way of doing that these days. reply tiffanyh 3 hours agoprevOT: Has anyone noticed performance improvements since Google migrated Docs away from using DOM, and over to using Canvas? https://news.ycombinator.com/item?id=27129858 reply eskibars 11 hours agoprevThis would have been very useful at several companies I worked at as a product manager for release blogs. I always start editing in gdocs because it's so much easier to collaborate on than any blog platform, but then you always need to copy/paste the content once final into the blog and nearly every time, it copies some elements of formatting into the rich HTML editor I don't want (fonts, font sizes, etc) while I do want some things (headings, bold, italics). It's usually easy to import markdown to blogs or trivial to convert it to stripped-down HTML that can be imported. One of the teams I worked on built a simple gdoc script to do this reply hu3 5 hours agoparentIndeed, very useful to unite markdown with the omnipresence of gdocs. One tip for pasting without formating, at least in Windows, is CTRL+SHIFT+V. reply esprehn 4 hours agoprevThis is a great feature (and probably related to reliance on markdown from all the LLM services). I do wish they'd add SVG import to slides though, that's been a top feature request for like a decade. reply mikelnrd 6 hours agoprevIs there an API to export a Google doc as markdown? reply stevemk14ebr 4 hours agoparentYes, and to import. You mess with the mime types when creating a document or exporting and the conversion operation happens. Standard gdocs APIs cover conversion of formats already with doc files as an example. reply xnx 8 hours agoprevSo close. I have always hoped for an edit in markdown (or limited formatting) mode. reply bapetel 2 hours agoprevGood ! I use notion and sometimes when i copy a text from notion to docs, i have to format it again. Now i would not do it. reply mavsman 4 hours agoprevI would imagine that requests for this feature went way up as ChatGPT has popularized. reply d4rkp4ttern 7 hours agoprevI like to have AI auto-complete assistance from something like GitHub copilot, so I often compose markdown within PyCharm and then paste to Google docs. There seem to be zillions of “AI-writing” tools out there but I’m shocked that nothing has replaced the smooth functionality of GitHub copilot. Google docs with Gemini is not smooth at all. Tried obsidian plugins but they are janky. reply red_admiral 10 hours agoprevThis is a cool feature, even if parts of markdown still need to be implemented (for pedants: commonmark). Meanwhile, Trello is once again threatening to force everyone onto the new rich-text editor and disable the old markdown one. reply worldmerge 9 hours agoprevThis is really useful! Hope they continue to add features. I don’t like directly writing markdown and would rather use a text editor like Docs or Word. reply sheremetyev 4 hours agoparentYou are not alone :) For Microsoft Word you might find Writage plugin useful (https://www.writage.com) - supports all basic Markdown syntax, tables etc. and recently added support for math formulas. reply yosito 12 hours agoprevI don't really use Google products, so I find this particularly useful for collaborating with people who do. I can do my shit in Markdown, they can do their shit in Google, and we can easily transfer the content back and forth. reply gempir 11 hours agoprevDoes this just import Markdowns and convert them to Gdoc and then you export it finally. Or can you collaborate on Markdowns in real time? Could you build a confluence/wiki like system on top of this? reply orliesaurus 9 hours agoprevI guess most users of Google Docs have no use for this, especially the download as markdown. I wonder why they decided to add this feature for the tech crowd so late in the lifecycle of the product, feels almost like an Summer '24 intern project? reply vitus 8 hours agoparentAgreed; given the timing, an intern project seems plausible. (It feels a bit more ambitious than a typical intern project though, and I'm not sure how many of those end up quite so user-facing.) I can imagine one internal use case. At Google, we use Google Docs heavily for design docs. After the system has been built, it's not uncommon to link to the design doc as supplementary reading material. But the design doc isn't intended to co-evolve with the system; at some point, we migrate the design details to our internal documentation pages (g3doc [0]), which serves version-controlled markdown files and often has a much lower barrier to entry. Even though Google Docs is ostensibly collaborative, design docs are often used as a snapshot of an individual's engineering maturity as justification during performance evaluation and promotion, and so it's not typical for them to be updated substantially, years after the initial implementation is complete. [0] We write about it briefly in a case study about \"The Google Wiki\" at https://abseil.io/resources/swe-book/html/ch10.html reply crazygringo 5 hours agoparentprevSpeaking as someone with experience in enterprise software, I'd say there's a good chance it's because one or more large corporations were ready to migrate from MS Office to Google Workspace but that not having Markdown import/export would be a deal-breaker. A lot of times when you wonder, \"why did they add that feature?\", that's why. A single large potential customer absolutely needed it because of whatever critical internal business processes they happen to have. It's a major difference from software sold to consumers, where the aggregate consumer demand for a feature is generally more obvious/intuitive/explainable. reply remoquete 6 hours agoparentprevCollaborative editing of Markdown docs in GitHub / GitLab can be a pain. This is a huge game changer for technical writers. Admittedly not the biggest crowd, but hey... reply dalrympm 5 hours agoprevI don't see any mention of table support. That will be the first thing I try, I hope it works... if not now, eventually. reply stevemk14ebr 4 hours agoparentThey are supported (source: beta tested it internally). We use this markdown feature for some internal workflows where github flavor markdown syntax is used. We've tested this works and ourselves rely on it as well as some other markdown extensions. reply jfoster 9 hours agoprevInteresting announcement. Feels like some of it is just copy-pasted from a PRD. Not necessarily a bad thing (it's clearer than press release style), just the first time I've noticed it in a \"bigtech\" announcement. reply sanjeevmsk 8 hours agoprevMoved to self hosted bookstack recently due to this feature missing reply neontomo 6 hours agoprevmarkdown is such an elegant markup implementation, i remember using bbcode on online forums which was ok but markdown i use all the time to keep notes and organise my thoughts. when i do consulting i summarise my work in a github gist. look forward to trying this. reply sgt 12 hours agoprevThis is great, the other day I had to export to HTML from Google Docs and then import the HTML into some kind of Markdown generator. The result was mediocre, but usable. reply tekknolagi 13 hours agoprevI thought copy as MD existed years ago and then went to look for it recently and it was gone. Now it's back. Am I losing it? reply cpswan 13 hours agoparentMaybe you've been using the GD2md-html plugin. I've certainly found it useful over the years, and will likely still use it for some of my workflows. https://workspace.google.com/marketplace/app/docs_to_markdow... reply tekknolagi 6 hours agorootparentI don't think so... It was part of the download menu for me reply stevemk14ebr 4 hours agoparentprevThere was partial markdown support (and still is) in gDocs today. AFAIK copy as MD was never supported. But this new feature is full round tripping into and out of gDocs as native markdown. reply wscott 2 hours agoprevSo, can we now write a plugin for Obsidian that syncs changes to Google Drive? reply einpoklum 5 hours agoprevLibreOffice has an open issue requesting Markdown export support: https://bugs.documentfoundation.org/show_bug.cgi?id=160734 reply guytv 9 hours agoprev [–] when did google become sooo sloooow implementing trivial features, and then not even shipping a complete set of markdown?! reply EE84M3i 9 hours agoparent [–] > trivial features Four features were announced: 1. Convert Markdown to Docs content on paste 2. Copy Docs content as Markdown 3. Export a Doc as Markdown (from File > Download) 4. Import Markdown as a Doc (from File > Open or \"Open with Google Docs\" from Drive) Which of these do you see as trivial? These all seem quite complex to me with many edge cases , incompatibilities and ambiguities, especially if there's an expectation that you can round trip losslessly. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google Docs now supports enhanced Markdown features, including converting Markdown to Docs content on paste, copying Docs content as Markdown, exporting a Doc as Markdown, and importing Markdown as a Doc.",
      "This update is beneficial for technical content writers, facilitating easier conversion between Docs and Markdown for collaboration and documentation.",
      "The rollout begins on July 16, 2024, for Rapid Release and Scheduled Release domains, and is available to all Google Workspace customers, Workspace Individual Subscribers, and personal Google account users."
    ],
    "commentSummary": [
      "Google Docs now supports full import/export of Markdown, enhancing its utility for technical writers and collaborators on Markdown documents.",
      "The feature is gradually rolling out to catch severe bugs early, so users may not see it immediately.",
      "Google Drive and its APIs will also support this new Markdown capability, although some users have concerns about slow rollouts and incomplete support for elements like code blocks and comments."
    ],
    "points": 486,
    "commentCount": 96,
    "retryCount": 0,
    "time": 1721184291
  },
  {
    "id": 40986894,
    "title": "Panic at the Job Market",
    "originLink": "https://matt.sh/panic-at-the-job-market",
    "originBody": "Panic! at the Tech Job Market Panic! at the Job Market “I have the two qualities you require to see absolute truth: I am brilliant and unloved.” ready for another too-long article about personal failure while blaming the world for our faults? let’s see where we end up with 7,000 9,000 10,000 11,500 words this time1. this post is sponsored by me trying to not get evicted. funding appreciated: https://github.com/sponsors/mattsta TOC: Job Openings vs. Interest Rates Company Structures How to Get Hired Everything Bagel and a Bag of Chips to apathy, to entropy, to empathy Conclusion Job Openings vs. Interest Rates how are you doing, fellow unemployeds? enjoying riding your bikes midday past the three-piece suits? Interest Rates so, uh, what’s going on? Basically, all the “free money” went away when the gubbment mandated interest rates go from years of declining-or-near-zero percent to now over 5% (curiously, a 5% increase in the fed rate also caused all credit cards rates to go from 9% to 30% over the same timeframe. what world). Why would interest rates cause jobs to go away? Remember an interest rate is essentially “the price of money” — a higher interest rate means money is more expensive itself. Also with higher interest rates, organizations with millions and billions of cash sitting idle can park their money in safe government-backed interest accounts2 to grow their balances risk-free instead of taking on risk assets seeking outsized returns. What counts as risk assets avoided during high interest rate periods? Well, funding companies with uncertain futures is a pretty risky asset. So, at times of high interest rates, the weaker companies collapse, strong companies use high interest rates as an excuse to “clean house” every 10 years, then a couple hundred thousand previously high compensation workers discover there are no jobs for anybody anymore over the next 2-4 years. By the power of drawing two lines, we see correlation is causation and you can’t argue otherwise: interest rates go up, jobs go down. never a miscommunication. you can explain that. Company Structures Why do interest rate increases specifically destroy tech jobs while other sectors like minimum wage part time jobs or construction jobs have been increasing over rising interest rate periods? Tech companies fall into one of four categories: nepo companies where your friends have unlimited money, so you get to live in a fantasy world of building unrealistic unmarketable dreams using family nepo money. You never have to really interface with reality to ever be proven wrong. See things like the VC funded grilled cheese startup or the VC funded baby food dispenser or the nextdoor neighbor VC funded medical fraud or the VC funded megalomania “i will become king of Earth” desk renting company or the VC funded stanford drugs-and-sex crypto club not to be confused with the VC funded berkeley apocalypse cult, etc. speculation companies where somebody has an idea, but no product yet and no customers, and also no idea if there’s a market for the product, but they get money to try and build an organization to find out if the idea will work anyway. initial growth companies where you had an idea, it starts to become popular, so you trade some ownership in exchange for cash/capital funding for growing your ideas into generating as much revenue as possible. This is also where things like the world famous YC incubator and 500 Cats and Techmoan come into play. Initial growth companies are the next step up from a speculation company after products begin experiencing actual customer demand. fun fact: before the modern “tech accelerator” era, each big city, not named san franciso or boston, had something like a “startup boss” where you’d potentially pay hundreds to thousands of dollars to “present your idea” to the local “angel funding mafia” and then, if you passed, they would give you $50,000 in exchange for taking 80% of your company. This status quo lasted for decades until YC proved the system was essentially fools funding fools. The other fun part: after the “startup mafia” in your city legally owned 80% of your company, they would let you work as founder for about 6-18 months then just fire you and replace you with their own friends. At the first 3 companies I worked at, the CEOs were failed lawyer friends of VCs, installed by the VCs to replace the original founders, due to VC using exploitative legal trickery at every turn possible. stable era companies with a repeatable GTM capability with access to customers and recurring revenue cycles. Stable era companies are essentially what normal people think of as “a company” — a self-supporting corporate entity with growth and stability for all involved (usually). Each category of company has its own benefits and drawbacks. Related to interest rates, the less successful a company, the more it relies on VC funding, and during high interest rate periods VC funding tends to slow down or vanish completely. Higher interest rates also means your customers have more restrictive spending conditions, so your customers will pull back, reduce, or leave too. Interest rate growth kills speculation companies and truncates or collapses initial growth companies into baseline sustenance mode until the economy opens up to take on more risk again. Company Level to Compensation Scale When companies have different sizes, funding, revenue, and war chest balances, it all impacts how much compensation lowly employee scum can receive. For ease of brain math, we’re going to roughly normalize fully loaded compensation to a per-day rate instead of per-year because the numbers feel more meaningful on a daily scale (and just remember to divide all compensation numbers in half to account for employment taxes). Nepo Company Pay Scale If you are a fancy imaginary nepo company, there’s no limit to what you can pay employees because your entire company is a weird in-group fictional entity. You can be paid $100 per day or $100,000 per day depending on your personal connection to the power structures. There’s no real conclusions to be drawn from imaginary companies paying their friends whatever they can. Nepo companies are the most frustrating because they suck up all the media attention for being outsized celebrity driven fads (and they also set the tone for accelerating unsustainable fad-to-failure cycles). These companies leave you thinking “i could have made much better products with so much less wasted funding. too bad I wasn’t born rich/connected/bro-lyfe.” These companies, due to their imbalance of meta-funding-vs-tiny-impact, usually explode in a huge exposé about fraud and corruption leaving the founders no choice but to either fail upward forever or do not pass go. Speculation Company Pay Scale The smallest form of companies (pre-revenue, pre-growth, pre-customer, barely with an idea) are speculation companies doing what they can to get by every day. Speculation companies are places to work when you’re a crazy child and so ambitious for a juvenile. You won’t see Tim Apple going to work for two 21 year old code bros living in Peoria trying to disrupt Google. Working at pre-revenue low-idea companies is a real loser move if you have any personal marketable experience at all. These companies will have a pay scale somewhere around 50% to 80% of market rate yet expect 200% to 500% more work than any other professional setting. If you’re not living in a $600/month studio apartment, it’s not worth your time (unless you have some insider information about the organization being a secret tax avoidance or money laundering acquisition scam. sometimes zero-product zero-revenue companies go from no idea to being acquired for a couple billion dollars in a year or two — this is a common pattern for “academic researchers” to form a fake company, vest their shares, then get acquired on basically a huge tax-advantaged hiring bonus at some big tech). Initial Growth Company Pay Scale Initial growth companies have been the ruin of many a poor boy. Initial growth companies are the worst combination of high-risk, low-reward effort-vs-compensation tradeoffs. Sadly, getting trapped in underperforming initial growth companies is something I never realized was a lifetime risk until way too late to save myself. Now I’ve got nothing to show of my life of work, while other people who just picked a better company to work at 20 years ago and never left have been growing their wealth by a couple million dollars per year every year for almost their entire career, all working as just some rando middle manager at multi-trillion-dollar companies. Initial growth companies are often unprofitable and just huffing VC fumes to stay alive waiting until some combination of “hopes and dreams” activates then the company “takes off” and everything just works out. While you’re working at an underfunded, under-compensated, low-growth company just to get by, other people you know will be working at multi-trillion dollar companies making 5x to 50x your compensation for doing the same work or less. The primary purpose of initial growth companies is only to “make the founders rich” and practically nothing else matters. There are sub-categories of initial growth companies though: growth uptrend, which is potentially interesting if a company is actually working and will survive, because some initial growth companies do turn into real stable era companies (which is the gambler’s lie under-performing downtrend companies really hype to all employees: JOIN US WHILE WE ARE SMALL! WE WILL GROW FROM -$12 million income per year to $300 trillion income per year in six months!!! CATCH THE WAVE!). growth downtrend, which is the worst for all involved because you will end up in a decaying cycle of low compensation combined with serial company layoffs because the company is just failing, but refuses to outright cease to exist (working at these is called “wasting your life”). stable but zero-growth, which is interesting but not useful. There is no such thing as a zero-growth low-scale company. If there is no growth, you can’t hire or have compensation increases. Likely, if there is no growth, the entire corporate plan will be adjusted into either “coast forever” mode where all employees get reduced to a skeleton crew and 90% of others are laid off so the founders can just collect passive income forever (or sell the company off for parts in a break-even VC acquihire maneuver). Meanwhile, other people you know working in real companies will continue having exponential compensation growth due to their free passive yearly stock allocation on liquid markets. I guess one rule of thumb is it doesn’t make sense to work for companies who aren’t listed on the US stock market. The best time to join Apple was 25 years ago. The next best time is today? Who knows. What is it like to join a company where all the co-workers your same age have made $10+ million over the past 4 years while you are joining with nothing? Stable Era Company Pay Scale Stable era companies are long-lived organization not subject to going bankrupt due to quarterly market trends or government economic policy changes. Stable era companies also have sub-categories: stable stable, which is consistently growing, consistently profitable, and paying employees $5k to $10k per day at current full comp market rates. These are largely flying under the news radar. These companies aren’t Google or Apple, but rather some tractor company or heavy manufacturing company just churning out results for years without destabilizing the world. Stable stable companies do that thing where every quarter they “beat expectations” on their stock reports by a coincidental $0.01 just to prove they are always growing. stable unstable, stable-qua-ego, which is a combination of a popular company controlled by a popular “celebrity CEO” figure. These companies tend to be as manic/bipolar/depressed as their CEOs floating between mega growth phases to mega collapse phases then back to mega growth phases in cycles of 6-18 months each. The growth/collapse phases usually don’t impact your $10k to $20k per day compensation unless you get caught in a “Year of Efficiency” as euphemism for laying off 50,000 employees while the CEO continues to spend $100 million per year buying private islands. stable neutronium, which is when a company controls one or more sectors of the global economy and just can’t be broken. They tend to have stable management, exponentially growing stock prices, and thus exponentially growing compensation for useful employees. Under the modern tech landscape, stable “hyperscale ultra-growth” companies are paying experienced employees the equivalent of $10,000 to $50,000 per day if we include the value of their exponentially growing yearly stock grants. Meanwhile, back in the real world, other companies argue salaries shouldn’t increase for 10 years because “who needs money anyway” or “developers are too expensive” so you are stuck with 10 years of no practical salary growth3 and no viable passive stock grants (if you can get a job at all). Big companies are a gift and a curse because with great size comes great ability for outright economic capture manipulation. At a fundamental level, everybody kinda knows big companies aren’t the best places for “good” things because the default mindset is big company bad so we continue ignoring corporate exploitative profit capture is the inevitable way of the world. How to Get Hired Tech jobs are paradoxical because everybody agrees on three things: the tech job requirements are completely broken the tech job interview process is completely broken yet, every company follows the same hiring process and posts the same job requirements I think the entire problem of modern tech hiring comes down to the midwit meme: Let’s ignore the “IQ” axis and just consider “capability points” or some metric for scaling experience and ability. The key to midwit meme humor is always the “most advanced” people often use simple solutions indistinguishable from people who don’t know what they are doing. Average people are often in the “knows enough to be dangerous” category by over-thinking and over-working and over-processing everything out of lack of more complete experience to discover simpler and cleaner solutions. We find the midwit problem in job interviews all the time where interviewers think they are “elite special evaluators” needing to gatekeep the unwashed hoards of desperate candidates, but interviewers often can’t reliably judge or measure people who have better answers than they expect. Scaling Laws According to all the interviews I’ve failed over the years (I don’t think I’ve ever passed an actual “coding interview” anywhere?), the entire goal of tech hiring is just finding people in the 100 to 115 midwit block then outright rejecting everybody else as too much of an unknown risk. If you fail the weird mandatory performance-on-demand interviews full of random tasks unrelated to the actual job role, interviewers immediately assume you are a 0 to 55, but they can’t actually tell if you are in the 120 to 200 range instead — especially in the case of, well, what if the interviewer has less experience or less knowledge or less ability than the candidate, so the interviewer just can’t detect high performing people? Personally, I’ve had interviews where the hiring manager seemingly doesn’t know how anything works but they are also in charge of the product architecture? You ask why their platform has a dozen broken features when you tried to use it (and it overcharged you by thousands of dollars a month for services not even provided), but you just get blank stares back because the 24 year old “lead senior engineering manager product architect” doesn’t actually know how systems, platforms, architecture, networking, dns, ssh, monitoring, usability, observability, reliability, or capacity planning works? Then, of course, you get rejected under some false pretense of “not having enough experience” when you’re trying to promote developing fixes to their seemingly decaying platform4. Modern tech hiring, due to industry-wide persistent fear mongering about not hiring “secretly incompetent people,” has become a game divorced from meaningfully judging individual experience and impact. Most tech interviews are as relevant to job performance as if hiring a baker required interviewing them about how electron orbitals bind worked gluten together then rejecting bakers who don’t immediately draw a valid orbital configuration. I remember fully giving up on ever interviewing at Google after an interviewer just barked graph theory questions through a low quality speakerphone with their laptop right next to the microphone so all you could hear is loud typing and an angry man complaining you aren’t solving their irrelevant questions fast enough. The entire industry just kinda accepts candidates should have negative and personally degrading interview experiences where candidates are undermined by some vague sense of social superiority from the interviewers. Sure, it would be great to have big tech $30,000 per day comp packages, but they long ago decided to prefer hiring the wrong people passing the right tests instead actually evaluating people around experience and capability and ambition. The Great Attractor The weirdest part of watching the tech interview landscape change over the past 20 years is it keeps getting worse everywhere all in the same ways. “big tech” created the concept of “the coding test” as the primary interview criteria. Why? Google was founded under the mindset of being a “Post-Grad-School Grad School” so they demand everybody pass a mini secondary GRE to walk amongst their austere big wrinkle brain ranks. Soon after Google became successful, the founders joked they wouldn’t be able to pass a Google interview test anymore. Yeah, real funny guys, making a system so selective for anti-ability where useful people can’t even get in the door anymore, great job everybody. Now, every company from 3 person speculative startups to 50,000 person big tech firms all use the same hiring practices which seems between somewhat inefficient to outright overbearing. In what world should I put in the same effort to join a zero-growth, unprofitable company going out of business in 3 years compared to joining a multi-trillion-dollar company paying 30x the compensation of a startup? Much like how every company copied the google “big tech big interview over 6-12 weeks” cycle, companies have added an additional interview step copied from Amazon: the “behavioral interview” curse (also see: “the bar raiser curse” as well). As far as I can tell, the “behavioral interview” is essentially the same as a Scientology intake session except, you know, for capitalism instead. You have to answer the same 8 questions at every interview around “so what would you do if you had a conflict at work?” where the interviewer treats you like a 5 year old learning about people for the first time instead of acknowledging you as a professional with 0.5, 1, 2, 3 decades of experience. The current “behavioral interview” weirdness is somewhat of an offshoot from the original idea about “hiring for culture fit,” but traditional “culture fit” evaluation was just personal interviewer vibes around how candidates acted during an interview. We’ve all seen candidates who are uncooperative or excessively negative with no recourse or just weird in an anti-socially draining way, so clearly pass on actively dangerous people, but attempting to codify “is a person a good person” into call-and-response questioning is a fundamentally broken concept. The actual goal of any “behavioral interview” or “culture fit” estimation is simple, but nobody ever lays it out. The goal of culture checking is only: determine how a candidate handles the tradeoffs between progress vs. kindness. A secondary goal of the “behavioral interview” is personality homogenization where companies want to enforce not hiring anybody “too different” from their current mean personality engram. Yet, the tech industry is historically full of weird divergent people doing great things for their own reasons (though, due to just basic population growth over the past 20 years, there are tens of millions more “normie computer people” now offsetting all the smaller pool of original “weird computer people”). When you start enforcing personality bubbles outside of what somebody can do, you’re just doing some sort of weird economic eugenics thing (make programming weird again!). The trick with “behavioral interview” is there are no true good answers. They want to watch you squirm. The answers depend on: in your hypothetical scenarios about “resolving disagreements,” what is the power dynamic? Am I asking the CEO why we have 50 sales people but only have 3 developers and I’d like more developers? Am I criticizing an intern for blowing up the site for the 3rd week in a row when they didn’t follow documented deployment guidelines like we’ve reprimanded them for twice before? in your hypothetical scenarios about “tell me a time you made a mistake and apologized” relevant to anything? I’m not here to interview about my past failures, so we either make up fake “humble brag” failures or tell you about actual failures which will give you more ammunition to think less of us and tank the entire interview process? It’s the equivalent of bad bid-side negotiators starting with “tell me the lowest price you’ll accept” which isn’t how anything in the world works at all. Interviews are about showing your best side, not trying to micromanage a list of perceived historical faults to a point where you disqualify yourself via your own confessions. What level of asking candidates to expose their raw past failures and arguments and disagreements just too much information? You don’t have a right to view the total perspective vortex of every decision in my life as employment criteria. If you want to guarantee team cohesion, build good teams, position managers so they have awareness of everybody’s strengths and weaknesses, and have your managers be experts in conflict resolution. I think another goal of “behavioral interviews” is to show how much you enjoy compromise. There are compromise tradeoffs though. Finding middle ground between a broken solution and a working solution doesn’t leave you with a working product. Compromise can happen around opinions, but not facts. I always get the feeling interviewers want you to talk about some time you were right then gave up being right for a worse solution just so the other person/department feels better. Are we here to create good products or not? sorry, I think I just failed your behavioral interview again. Good thing I can just interview at another company. Oh, wait, every company asks the same questions and demands the same answers from the same book on “how to do interview good” and if you deviate from the expected answers in the book, no income 4 u. good luck on your unemployment journey until the employment meta changes again. Looping back to a point: is there some condition when having every company continue to add more interview steps unrelated to job tasks and experience and capability and ambition and insight will just collapse the entire industry? Sorry, you’re not qualified to be a professional software developer because you wore the wrong color shirt to the interview. You should know the color buleruplange is triggering to generation delta, so you clearly are not a culture fit for this job paying $120,000 per hour, and no, we will not be looking over your 25 years of professional experience at all. Companies seem to forget they are also part of, you know, the economy and people need compensation to, you know, not die, right? If you aren’t acting as an economic engine for helping the most people thrive, what is your purpose as a company? Everything Bagel and A Bag of Chips You’ve seen them. I’ve seen them. I call them Everything Bagel job descriptions. They go something like — As a Software Development Engineer (SDE) at Company, Inc, you will be required to: truly love the SDLC and agile story t-shirt poker points provide company-wide daily status updates on all your work from the previous day and describe what you plan to do in the next 6 hours write our application (react, vue, typescript, node, python, react, rust, go) maintain our existing applications (php, ruby, c) optimize all new code and refactor all existing code for maximum performance support customers directly who have application problems support other employees who don’t know how computers work deploy new infrastructure (aws, docker, containers, kubernetes, swarm, terraform, lambda, eventbridge, step functions) monitor and optimize cost efficiency of all aws usage maintain existing infrastructure (aws, docker, api gateway, dynamodb, mysql, elasticsearch) create and maintain and monitor all CI/CD pipelines (github, aws) guarantee infrastructure is always running (on-call 24/7 3 weeks per month) guarantee infrastructure and application logic is always logged and monitored and alerted and observable perform routine capacity planning be responsible for application security be responsible for security of all application dependencies (npm, pip, ubuntu, container images) be responsible for security of all infrastructure (SOC-2 demands it) conduct code reviews 3 to 10 times per day mentor peers manage yourself and manage your peers, but you also have an engineering manager and a project manager and the CEO is your skip-level manager and the CEO’s brother is also your skip-level manager too code all the time and manage your own performance continuously document everything so we can replace you with outsourced contractors at any time monitor and maintain all 37 javascript SaaS plugins our website uses to track every user click and record mouse movement without the user’s knowing consent (plus the marketing and product teams enjoy adding 3 new javascript plugins to the website every month, so you must add them immediately when somebody requests it through a ticket without doing any technical evaluation on the 3rd party scripts or checking fitness for purpose or even if we could replicate the behavior in-house with less than 4 hours effort) be grateful for this job and truly appreciate the opportunity to make $300/day in this role because we are all a family here at Company, Inc. (until the next round of snap overnight layoffs at least) like, my dude, your single job requirements are actually 5 entire departments worth of work to be shared across a total of 20 people. yet, you see single-person job descriptions resembling this all over the place. At some point, half the industry just gave up on the idea any technical person should specialize in anything. Just make it all up as you go along. It’s just typing, how hard can it be? You can’t just demand application developers also be part time amateur aws architects and expect good results. Experience in these roles is built over 5+ years at a time through focused work, but half the industry is now corrupted into “devops means DEVS DO OPS means OPS REQUIRES NO EXPERIENCE means NOTHING REQUIRES EXPERIENCE so FIRE OPS HIRE DEVS and just 15x ALL JOB RESPONSIBILITIES” (without any matching 15x increase in compensation, of course). Such job descriptions also means: your job is physically impossible. You will always feel drained and incompetent because you can’t actually do everything everyday. You will always be behind because each of those bullet points can be multiple days of work per week just on their own (plus, how are you supposed to be productive in 35 different areas requiring months to years of experience if you actually want to be good at each task?). So, from day 1, you will already be about 4 months behind on your expected job responsibilities and you’ll never catch up. It turns into an endless game of managers and executives saying you are “underperforming” because you have 18 primary tasks, each primary task requires 4 to 20 hours of effort, and every manager wants their task done within 4 hours. You are setup to fail. What’s the point? Maybe a point is some companies just shouldn’t exist if they can’t afford the fully staffed professional teams required to build and maintain their products? The worst secret in tech is amateur developers are happy to act like entry level workers across 20 arbitrary roles for years (in the absence of never having enough time to focus on building up long-term experience or best practices). You can’t get gud if you are always rushed from task to task without any chance of leveling up knowledge and capability through “deep work” as we would historically expect of professionals. Field Report: Job Experience Notes Here’s some things I’ve seen in “the real world” over a couple jobs. Some minor details have been altered to protect the guilty. These are just to highlight how often companies have completely broken internal practices and don’t even know it. The solutions are fairly basic, but you can only see the solutions if you have actual experience knowing how everything works in the first place (and know where experience comes from? 5, 10, 15+ years of actually doing focused work and actually building systems from the ground-up over and over and over again—it takes completely re-building something 3-5 times over anywhere from 3 months to 5 years before you actually start to be good at a task). How do you document real life when real life is getting more like fiction each day? Company said their “site was slow” and they didn’t know why. I looked at their AWS metrics and the single database server running the entire company was one mysql database with 2 cores and 16 GB RAM they created 5 years ago and never touched again. Their database had grown to 3 TB on the slowest disks AWS offered plus their working set size had grown to about 50 GB. The database was at 99.99% CPU usage, and had been at 99.99% CPU consistently for the past two years based on the built-in AWS metrics. They never looked at metrics or performance because “We are a cloud native company so we don’t do low value non-product-related tasks like system administration.” Solution: I upgraded the database instances to 64 GB ARM servers with reserved IOPS and their batch data transformation tools went from taking 16 hours to 20 minutes. Also the DB replicas went from having 4-6 weeks of replication lag (again, completely unmonitored for years) to real-time sub-second updates across regions. Company said “their site was slow” and they didn’t know why. Turns out they had two database clusters: one for production and one for research. The research cluster had 8 instances costing $5,000 per month total. The production cluster had 2 instances costing $500 per month total. The research cluster hadn’t been used in two years. Solution: I swapped the sizes so the production cluster now owned all the resources and the unused dev/research cluster had almost no resources. I also switched all instances to ARM so they were cheaper too. The production site went from 7 seconds for an interactive user response to 200 ms for a user response due to the increased capacity. The non-technical company owners had just accepted their system was slow for the past couple years without ever looking into possible fixes because, once again, “the cloud means we never have to manage anything. only agile story point product features matter.” Company had a couple custom data processing tools. Their internal data processing API tools were installed on the same 2 EC2 2-core instances as their customer-facing web servers. The data processing tools were CPU heavy and teams complained it took 20 hours to run a full processing batch. Solution: I moved the data processing tools to dedicated containers for auto-scaling via ECS-on-EC2 instances (using fastest EC2 instances available too instead of deprecated EC2 instances like their web servers) and it immediately auto-scaled up to 20 to 50 concurrent containers for processing live data instead of being stuck on 2 previous outdated servers only. The data processing times went from 20 hours to 30 minutes. They had been running the previous “only deploy internal APIs on our two 2-core web servers” pattern for 7 years. More fun AWS architecture things at various companies like fixing subnet-vs-NAT-gateway deployments to save companies a thousand dollars a day just by altering network paths to avoid NAT gateway fees. Companies often don’t realize AWS isn’t hands off “zero-experience needed magic cloud;” AWS is actually “datacenter as a service” and if you don’t have experience managing datacenters and network architecture and disks and a dozen other system-level platform architectures then your AWS account is probably in a bad state. Many common things across companies where they just did work 5 years ago and never updated their systems for modern practices. If you see people using requirements.txt in the wild instead of a poetry lock file or you see people using the decades-long broken python built-in logging framework instead of loguru you can see there’s opportunities for improvement everywhere (amusingly (or sadly) every seven-figure-comp-AI-developer project I see from “big tech labs” are all using amateur python programming practices from 10+ years ago and they don’t even realize it or care to fix it. 🤷♂). Company said their tool for extracting production data from mysql into redshift went from taking 40 hours last year to taking 80 hours this year and it continues to slow down by the month. Problem: I ran their extraction script and it just did nothing. I added more logging. It did nothing. I added even more logging. The script stalled on startup at trying to SELECT COUNT(*) FROM— this step took 11 hours alone because the “Senior Lead Data Scientist” who wrote this system (with 6 months of experience in charge of the entire department) didn’t know how databases or AWS or networking work at all (and wasn’t given permission from management to actually learn everything or focus on fixing problems over time when making the data transfer utility). Also, after the 11 hour COUNT(*) completed, they used the count result to only determine the maximum value to run a custom loop of SELECT * FROMLIMIT N OFFSET K where they would write every result to the network EBS storage as a CSV in N batches, then load the CSV and re-save it as .csv.gz to EBS, then re-read the .csv.gz from EBS to upload it to S3. You can’t do this. It makes no sense if you have any experience building complex systems inside AWS (EBS is toxic for reads and writes like that, never create a system doing thousands of micro-writes and micro-reads to/from EBS) or even with mysql from 30 years ago. Also, this pattern of “count all, walk entire table with limit/offset” had made its way into a dozen other internal utilities at the company (copy/paste development ftw) so we had to track down every place it was used to do custom refactors for proper database cursor and streaming write logic everywhere. Solution: I introduced them to the concept of “database cursors” so you don’t run an 11 hour COUNT(*) up front. Then you don’t have to abuse LIMIT/OFFSET queries. I introduced them to streaming S3 writes with in-line in-memory compression to avoid writing anything to EBS at all. The extraction process went from 80 hours to 40 minutes. Yet, the company still said they “don’t need to hire people with experience because everything is cloud native so anybody can just figure things out.” — This company tolerated a year of 80 hour data imports because “cloud native” means “experience doesn’t matter” and they didn’t have anybody in the entire company to even detect the problem because “only product features matter, we don’t want to hire low value sysadmins.” Company has $10 million in funding and an initial boost of customers trying their products, then the customers start to go away. The solution to customers leaving, as mandated by the fail-upward VCs controlling the company: “hire more sales people.” So, over two years, the company expands their sales and marketing team to 50 people while keeping developer count fixed at 5 people. Eventually, the sales people haven’t closed a sale in 10 months (because the product is so weak nobody wants to buy it), so the solution is to continue the VC demands of hiring 3 more sales people per week plus start laying off developers because the VC mandate is “only sales matter, the product doesn’t matter, sales people can sell anything.” Various variations on the above theme of “sales above all else” where companies double down on an idea that worked 2-5 years prior but is now just a dead idea in a dead company, but management refuses to expand or “pivot” their product to meet the market. These companies always fail due to executives just doubling down on their personal “executive genius” while developers are screaming “you aren’t letting us build products people actually want…” Historical note: I’ve only worked at startups or initial idea attempted “scale-up” companies, so now my resume is now just a series of 5 completely dead companies nobody cares about, which looks great for applying to jobs. Dead companies doesn’t mean dead useless experience though, yah? Is it my fault I can’t get hired at good companies? I don’t know. It’s not my fault companies fail though. I try to help, but when VC brain disease runs all companies into the ground instead of prioritizing building good products on high performance platforms, there’s only so much you can do before leaving dying companies (then repeat at the next dying company forever?). On the same theme of corporate priority: rudderless companies often end up in a situation where they are so desperate for sales, they try to incentivize the sales people with outsized commission packages valued at 200% to 500% of what developers in the company make (meet your sales goals for a seven figure bonus! sorry, developers don’t have a bonus program because the company only cares about sales, but how about another 0.0003% in dead equity after our 3rd down round?). At this point, there’s no value in remaining at a company if sales people are making more than people creating the product(s). I’ve rejected candidates during interviews too, so I’m not running around advocating everybody should be hired blindly. I’ve seen multiple candidates who refuse to turn on their camera even though it was listed as a remote job with such expectations. You start to think HR just let too many scammers through. One said “I am not allowed to turn my camera on because I have a pact with my husband I am not allowed to be seen on the Internet” (this person also sent a 30 page resume which looked like “i do everything, so hire me” from a contractor remote job scam harvesting operation). Another no-cam person said they were “in transit” and refused to turn on a camera even though they were calling through the Zoom app. Sometimes you also have people who just apply too high and hope to get through. We had one person apply for a Senior Python Data Engineer role and they couldn’t name any version of python (they said “something like 2 or 3? i don’t know.”) — those details matter when huge language features and behaviors change once a year with every major point release! don’t be bringing your outdated Python 3.7 sand castle to my Python 3.12 cathedral. Company founder/CTO who just gets bored on the weekends and starts personally modifying things, breaking live services, then demands developers immediately all go to the office Saturdays at 6pm to fix what he broke because “the company is down.” Company with bespoke internal platforms for customers where each customer needs its own codebase. The company started by just copying the previous customer codebase into a new customer codebase the first time this happened. Then it happened again and again. Now, 7 years later, the company has 12 repositories all doing 95% the same thing with 5% custom code per customer type. Due to their process being “copy the most recent codebase into a new repo,” the 12 repos have 12 different package lock files and 36 different container deployment strategies ((dev, prod, testing) * 12) and use 5 different versions of Python and each codebase has fragments of bugs sometimes fixed and sometimes not across all the repos. Solution: enough is enough, I gave everybody two days off and just ran through 20 hours of aggressively merging and validating everything into one repository with one package lock file under the most modern python version with 3 clean container deployment strategies covering all customers at once (plus getting type safety checks added everywhere, making common shared modules instead of copy/paste everywhere, centralizing metrics and reporting instead of ad-hoc hand-written output everywhere). Company in California with a motto of “never hire Americans because 16 year old outsourced Croatian interns know everything already” asked me to review their architecture. It wasn’t great. Their entire platform was built on 7 year old ubuntu EC2 instances that hadn’t been rebooted in 5 years. They technically had logging, but they had no alerting and no metrics. They basically only looked into product problems if customers complained (but customer complaints had to go through the “account manager” to the “product team” to the “product manager” to the “project manager” before developers would be notified of problems). Solution: I added a combination of EventBridge hooks triggering Lambda Functions to post live AWS service warnings directly into a chat channel. I added a log parser so they would also get real time application notices/warnings via chat when customers were seeing broken features. I added metrics to a dozen of their internal microservices and setup an “infinite scale” prometheus/victoriametrics cluster to collect and log and alert and graph trends over time. The company thought they had 10,000 users per day based on what their Croatian interns were telling the CEO based on a dozen of their front-end-only javascript/spyware analytics plugins, but my internal metrics showed only 300 users per day actually used the backend APIs. great job, everybody! The alerts also showed the company when the CEO’s brother would do things like delete all user data by mistake at 7am (remember to always give your family members full root admin access to all services so they can use generic desktop app database GUIs to edit user data directly, who cares if they delete users or corrupt data all the time?). The alerts also showed fun things like when the “Data Science Team” would write SQL queries over a small 64k row table yet mistakenly generate 12 billion rows of results due to how they wrote 5-level-nested JSON cross product column extraction queries (show me a love story more true than data science people adding nested JSON columns to relational databases). The saddest part is when companies have a good chance at surviving a mild downtrend, but either remain so committed to the past or too committed to executive dysfunction where nobody can steer towards a more reality-based future-oriented product direction. I’ve seen companies making $5 million a month in revenue just evaporate over 3 years because their original idea falls out of popularity and the executives refuse to adapt to better ideas. I’ve seen companies go from a billion in funding to being sold for parts because the CEO is too busy buying horses to keep his wife happy instead of actually running the company. I’ve seen companies just give up and get acquired by some big tech because the CEO was offered a personal $100 million gift when he agrees to the acquisition, then 90% of the company is let go after the acquisition. Feels great to work forever on the zero-reward side of a winner-take-most-but-the-winner-aint-you professional economy. Perhaps the saddest thing is it looks like I am a full time architecture-only, no-product-value person, but it’s only because everybody else in these companies has no architecture experience and doesn’t care to learn. Sure, I have 20 years of experience is datacenter build-outs and system architecture and high performance platforms, so when all these modern “cloud native” companies insist on only hiring “app dev javascript” employees without any real platform building experience, we see why all these modern “cloud native” orgs end up with completely broken infrastructure (at least until somebody who has actually accomplished something shows up to fix everything for them—most of these places are stuck in a loop of “we don’t know what we don’t know” so they are unaware of even the right questions to ask or the right systems to build in the first place). I don’t know about you, but I care about company structure, product issues, platform scalability and reliability, customer usability, developer usability, performance, legal compliance, security, corporate scalability, and team cohesion all at the same time. These are issues which don’t appear on your story point burndown boards because they are cross-functional improvements across multiple departments. Somehow constantly improving and fixing and making everything better in ways nobody else can seem to do isn’t enough to get through a company’s hiring cycle these days though. Also amusing: I think people will have different reactions to the block of anecdotes above. People will either be “heck yeah fix all the things!” or people will side with “you are clearly incompetent because you didn’t use ‘We’ statements anywhere and you only talked about how you did all the work yourself.” Well, for one these are just highlights. and, for two, there’s only so much “We” you can bring into every task when your team is 4 people having 16 months of tickets backlog’d with management mandating daily story point accounting updates. When you can do individual optimization tasks 3x to 5x faster than sharing the work (no need for synchronizing meetings and knowledge and project setup duplicated across 5 people) sometimes just doing the work and moving on is the best use of resources. We don’t have time to stop the entire product roadmap for “everybody on technical staff fixes everything” because the company refuses to build out actual infrastructure and platform teams (thanks, devops mind virus), so we end up with “single capable person doing the work of what should be 20 people across 5 departments alone” patterns. Sometimes good is just good and you get the work done by doing the f’ing work by any means necessary. to apathy, to entropy, to empathy I don’t think it’s controversial to say the employment meta of the tech industry has changed over the past 10, 15, 20 years. What used to be as simple as “i good wit commputr. u giv jorb?” is now a synthetic convoluted social status driven hierarchy of mind games just to get an initial interview then you are treated as a blank slate having to prove you can even read and write and speak from first principles. Most interview processes don’t even consider a person’s actual work and experience and capability. You must always open your brain live in front of people to dump out immediate answer to a series of pointless problems because if you can’t solve a pointless problem with no preparation you clearly can’t do anything of value for the rest of your life. Most of the interview tricks in use now are being repeated by people who learned “how to do interview” from books or 15 year old online interview guides. Modern interviewers don’t seem to always have the full picture of what they are even trying to accomplish from the interview. I was there when people made all these things up the first time in 2006-2009. You are trying to use trickery on me which we made up to stop people less capable than us, and now we are trapped having to constantly prove we aren’t scams when we clearly aren’t scams but nobody trust provable history anymore. Do not cite the Deep Magic to me, Witch — I was there when it was written. Is my distributed hierarchical topological sort automatic dependency resolver data processing system not relevant to experience? Are my personal improvements to CRC processing not relevant to experience? This work got included by global file formats and people have also decided to use my code to help validate information from the space station. Sorry, it doesn’t count towards any interview capability score though. What about a CLI for stock market trading both manually and with automation I’ve been noodling on for a couple years and keep improving by the month? Sorry, not relevant to showing your capability, you must reproduce the answer to our toy problem about moving chess pieces through a grid world in 20 minutes or else we think you are just incompetent5. (rebuttal people will make: but those are just tasks and those do not illustrate your love for the entire SDLC? did you even assign story poker t-shirt burndown points to tasks? do you even create issues before every change so every commit has an issue number then every commit becomes a PR then every PR goes through CI then is merged after a code review? you can’t just “do things” without 18 management steps between every task!) Somehow the entire technical industry continues to coalesce around social/political status and power instead of actual experience and ability. You’ve created software used by millions of people? Your software has been resold by every “cloud” for the past 10 years? Sorry, we can’t hire you because you didn’t espouse sufficient emotional loyalty to our One True Founder Kier Eagan. Good luck with your sad little life creating things people use because we only pay for cult loyalists here and you don’t socially qualify. The goal of hiring should be to create more of an us atmosphere and stop excluding people by dreaming up unnecessary technicality trivialities — be an us for once instead of a them! How do we try to exist when we need income, but almost all jobs have become impossible fantasy roles overloaded with divergent tasks trying to cram 5 departments worth of concurrent work into single people? Is it time to rip up our tech industry membership cards and just leave all the roles to overworked amateurs who only know the broken world since they haven’t ever seen a functioning company with professionals in single-purpose professional roles? I don’t know anymore. Conclusion Is the rambling complete? Has the stream of consciousness flow terminated? Of course none of these are unique to me problems. As we started out on this article: the industry broke all the jobs because of too much tech speculation tied to speculative funding, so the funding went away, then the customers went away, now the jobs are gone. We have hundreds of thousands of developers not getting their “tech industry” level salaries anymore, so who am I to whine? Well, I’m me and this is my site, so neener neener you can’t stop me. It’s a problem for all of us and we speak for all the worms. The tech roles at most companies are completely busted it seems. I didn’t sign up to be a “software servant” to non-technical product teams who just define tasks and priorities for actually capable people to implement every day. Somewhere along the way the entire industry lost its heart and now most companies are more interested in “playing company” instead of actually carving out created creative contraptions? There is a thing called “Engineering-led management” where, imagine this, the people doing the work are also the ones defining the product and talking to users and defining requirements while implementing features all themselves. You can’t create good products if you have less capable “product idea people” controlling implementation capability. Office Space wasn’t supposed to be our destiny. I’m probably actually fairly bad at being a single-purpose “SWE SDE SRE” or whatever weird made-up excessively narrow titles people have contrived now. It’s about building products and growing companies, which is difficult to impact when you’re given the mushroom treatment at 90% of companies unable to impact actual organizational and product change (because “know your place, low value menial developer, you just do what the superior project management and ceo vc family executives tell you to do, you can’t actually make decisions or improve usability or have ideas to expand products and fix company problems yourself. you aren’t the right shaped person to make decisions here!”). where is the developer azor ahai to right the world and tip the balance of power back to a majority of productive developers making decisions? At some point, a switch flipped in the tech job market and “programmer jobs” just turned into zero-agency task-by-task roles working on other people’s ideas under other people’s priorities to accomplish other people’s goals. I feel tech employment was originally more focused around being given problems to find solutions from a “whole business view” then you did everything to generate products and solutions using your best judgment towards a deadline goal without being micromanaged every step of the way (because nobody else knew what you were doing or how to do it to even attempt to micromanage you). When did developers stop being part of the actual product creation process and instead just become “project management task workers?” The nexus of tech industry employee agency destruction seems to be centered around post-2010 tech “elite value capture” where the weirdos who would normally aspire to work on wall street for “quick riches” instead decided they could get rich by just being “thought leaders” to exploit technology. It’s difficult to believe non-technical “idea people” have any relevant capacity to control technical project direction over a long term sustainability horizon. You create good products by creating and using products at an implementation level because products you use and products you personally write are products you have the largest insight into improving the best and the fastest. How do we deal with professional income inequality where the same role and effort pays $400/day at one company but $20,000/day at another company? At what point is it worth not even working if your compensation doesn’t work out to being at least $10,000 per day anymore? Do we just sit here and die in our overpriced studio apartments where rent increases 7% every year while other ICs doing the same work at better companies are buying 5 vacation houses from doing the same work? The worst feeling is comparison. Comparison is the death of happiness, as they say. I look at my own place in the world compared to people who just started at Apple or Microsoft 20 years ago then never left, and now they have made eight figures just over the past 4 years while my life path has lead me to… practically nothing. Then the tech inequality continues to compound. Imagine joining a company where the teenage interns have already made a couple million off their passive stock grants and other employees have been making $2MM to $6MM per year over the past 5 years there, while you’re starting over with nothing again for the 5th company in a row so what’s the point in even trying6. Though, did you know paying rent on a credit card still qualifies for points? Made $60 this month paying rent with credit card point rebates7. whoops. What’s next? Who knows. Maybe aliens will blow up the sun to strip mine all our solar lithium for their alien hive mind batteries or something. What’s Worth Working On Out of all the jobs available, it’s surprising how many of them aren’t the best thing to be doing. As we covered above, you usually want to work at a specific type of company (if you can) to get those $10k to $50k per day rates instead of being stuck at unprofitable companies only paying $400/day salary with no usable equity. What’s actually worth working on though? Let’s do a rundown. I have an interesting experiment in using non-tokenized inputs to transformer architectures which can be expanded to essentially creating conscious AI robots using arbitrary sensor data from cameras and microphones and encoders, but it would take a couple million united states freedom bucks to build working prototypes. It’s sad seeing so many broken products in the world while companies refuse to hire you. Here’s a sample of broken things one of those eight figure comp employees (or ten figure comp executives) should have fixed already just from looking at my immediate surroundings (which seems fairly one-sided): iTunes (Apple Music macOS App?) still has a broken UI. Current bugs include: when you “favorite” a song, it often just stops playing all music. When you tap the “back” button in album navigation, it doesn’t do anything the first click, but the second click sends you back two pages. You can’t go back one page at a time, you can only click once for no action then click again to go back two pages. Do the people creating these things not use them? Still Apple Music App related: the whole information management design architecture around library organization is stuck in 2001. There are so many more useful and creative and impactful ways we could empower users to discover, remix, share, and experience their music libraries besides “one spreadsheet view with tiny icons in rows.” Did Apple run out of ideas and ambition and a drive for creating a better future? Apple’s entire Feedback system didn’t get any better after they renamed it Feedback. Apple (market cap: $3.5 trillion currently) treats customers like unpaid interns expecting customers to just give them free troubleshooting work with no cooperative internal feedback on reported issues for months or years. Who is managing this? Why has the reporting process been bad for decades? We can fix these things. Apple’s macOS Control Center app widget constantly uses 1% to 2% CPU (across millions of machines) because it redraws itself 1,000 times per second even though it is always off-screen and completely hidden from the user. This has been known and reported for about two years now, but nobody cares to fix it. Is this one of those things where the developers care, but project management doesn’t understand the problem, so it can never be “prioritized” as a fix? Why did Apple go with such a weak Vision Pro launch of release-then-abandon? They could have made a dozen more first party world changing productivity experiences instead of expecting independent app developers to just show up and spend millions of dollars developing for a maximum risk minimum reward platform. Really curious how we ended up with “just give them a computer hat with no mind-blowing world-changing app advances” instead of the magic we usually expect from Apple launches? Though, the last iPhone update’s main selling point was basically “we converted a toggle switch to a button” so who even knows anymore? Here’s some free ideas: Really show off the dynamic ability for space occupation for massive data exploration. provide a default professional-level stock market application where people can create a 30 window view of 30 live symbols for real time decisions all positioned in living space provide a default data exploration application to show off displaying 10 to 50 metrics series charts at once (server metrics, business metrics, anything with a chart; think “Keynote for Time-Series Data”) spatial AI LLM visualizations capable of showing diverging language output trees for alternate completion paths all around you spatial geometry understanding environments for beginner, intermediate, advanced stages — so much of math is just figuring out what it looks like in your own head (remember the joke about Windows ships with Minesweeper while Macs ship with Chess? or Macs have a Graphing Calculator by default? Continue bringing advanced educational tools back into the mac ecosystem by default). spatial explorations of high-dimensional data with zooming in/out/up/down multiple dimensions of spaces to explore geometric surroundings for more data interpretation capabilities Wii-Fit-like environments for active mobility engagement spatial theremin spatial + AI cooking with ingredient identification and in-view instructions headshare: just outright swap cameras with somebody else (or maybe as a spatial window showing other people’s live camera feed(s)) remember the face swap app? do live head swaps. fun for the whole family. live streamed spatial concert experiences live spatial animal species detector spatial physics / cosmology simulations spatial where’s waldo object detector (“where are my keys?” then using AI/machine vision it locates key-shaped objects for you) spatial knowledge graph navigation (think: view wikipedia, but every link is exploded into a contextual spatial window for easy jumping between) spatial Apple Intelligence®™¢£ assistant in 3d space where the agent model also draws the assistant’s puppet/creature visual state so it is, effectively, alive and so much more! It’s interesting how Mac Safari uses touch id to “protect” private browsing mode windows, but there’s still half a dozen bugs encountered through basic Safari usage. If I can hit so many bugs constantly, how is an entire company of people using the browser not finding and fixing these bugs every single day? Apple’s iOS performance degradation. Typing on my iPhone 15 Pro Max is slower than typing on my iPhone 13 Pro Max. Why? I don’t know. The keyboard misses taps all the time where my previous 3-year-older phone feels about twice as responsive when typing. What did they break and why don’t they care? Why does GitHub continue to make some features worse worse? They changed the home feed from useful details to less useful details and now instead of instantly loading, it shows you a 3-9 second loading spinner saying “One moment please…” — multi-second loading spinners on every page refresh is a really damaged user experience. Another GitHub trick: look at a repo page logged in vs. logged out. They are using different page templates for logged in vs logged out users and it just looks like a mistake. GitHub has been fairly silent when it comes to addressing any user experience regressions over the past couple years. Obviously there are dozens of high-impact, high-reward, low-timeline projects to be created or improved in modern AI Lab companies, but “AI Companies” seem to only want to hire 28 year olds with a PhD from Stanford who have worked at Google for 5 years. No real way to get a foot in the door unless you’re related to somebody there already from what I can tell. Sure, they say “you don’t have enough experience,” but what does “experience” mean when half the work they do is making completely new things nobody has ever made before anyway? There’s tons of work to be explored in practical consumer robotics applications using cost-optimized hardware strategies. I’m pretty sure my plans for a sub-$3,000 human-sized-hexapod would create a few hundred billion dollars in value if we could build it out (add +$100 trillion in value if we attach the robot AI brain to it too). Various social aspects but less product oriented. How do we stop the world from collapsing? How do we fix an economy where 400 million people who aren’t already in California all want to move to California and become buzzword-driven middle managers at Google? Gotta OKR that KPI so your LTV for the TAM doesn’t go into the red. What is the balance between companies spending half a trillion dollars on stock buybacks when they also aren’t consistently hiring useful people into positions of authority to improve the world? People talk about American politicians never retiring, but what about tech executives too? We’re ending up with a lot of executives with 20 to 40 years at these trillion dollar companies and they aren’t moving out to give more people opportunities for advancement. just remember, the opposite of war isn’t peace: it’s creation. our goal is to make something out of nothing. we need to express, to communicate, to go against the grain — here’s to the crazy ones. create good things. create good systems. grow products. grow economies. become like the stars. raggedy man, goodnight, -Matt — ☁mattsta — 💰 fund fun funds Bonus Shots idle gallery of comments found in the wild is this page too much? too long? too short? tmi? not enough i? chime off / get in the comments.↩ Oddly, this is the first time in modern history where government interest rate increases haven’t also increased the deposit interest rate for consumer checking accounts. Almost every bank has maintained unchanging 0% to 0.03% interest rates on checking balances while the government is giving banks 5% returns on their various internals.↩ if you do the math using practical inflation and cost of living going up 7% to 13% per year, the minimum developer salary in 2024 should be around $450k to $550k. Almost nobody is paying such rates though and you’re lucky to even clear $250k (which was already in range from 10 years ago).↩ There’s a continual disconnect where people with experience can see problems then construct easy and rapid to implement solutions, but people with less experience think every little bug fix is a “we don’t have time to stop the world for 6 months so we can never fix anything!” problem. We get excited to fix problems because we see fixing problems is tractable and we can implement these fixes in days instead of months as opposed to others don’t understand how everything works. It’s amazing how the simple practice of just doing the work solves many problems sooner than many people think is possible.↩ and what is the deal with interviewers combining vague “spatial 2d/3d abstract reasoning” ability into required interview questions? stop giving me grid world to navigate during interview processes because i’ll just spend 20 minutes making dumb off-by-1 errors which doesn’t prove anything about long term professional success in any product or infrastructure offering? we’re not applying to be game developers but half the interviews are “PROGRAM THIS GAME IN 20 MINUTES!!!” ugh go flip off a card already.↩ “oh wow you sound depressed! me, as an Internet Psychologist will recommend you WORK OUT and SLEEP MORE! that solves all things according to internet advice!” really? how much more should i work out, anon? At worst, my problem is I need to eat more, but that cycles back to not wasting money as to not get evicted. As a famous therapist once said: most people don’t need therapy, they just need money to fix their circumstances. If you are upset because you are actively on fire, medication to calm you down doesn’t stop the impact of actually still being burned alive.↩ I don’t know the magic of how it works, but my apartment billing portal only charges 0.75% as a credit card fee if you pay monthly rent with a card, so if your credit card also has a 1% or 1.5% point rebate, you can make money paying rent via card (as long as you can pay it off every month to avoid the 30% APR build-up…)↩",
    "commentLink": "https://news.ycombinator.com/item?id=40986894",
    "commentBody": "Panic at the Job Market (matt.sh)429 points by speckx 3 hours agohidepastfavorite363 comments evrimoztamur 2 hours agoI will add my two cents for people who believe that this might be related only to the SWE and tangent industries: It's really not. I have many friends (in Europe) who are trying to get through to different jobs in unrelated industries ranging from finance to fashion, or just trying to get promoted vertically (or horizontally), failing rather miserably. Most jobs are now hoops after hoops, not taking into consideration your particular profile or the contributions you can make. Keep in mind also that a CV in the pile via a job portal is always going to be sediment at the bottom of the barrel. Try to make use of your networks and friends as much as possible. As for my situation, I too feel a bit burned by the diminishing number of tech jobs, as I was in the process of trying to get a job via a software consultancy firm, but remained benched for 8 months. I dropped it, went back to doing corporate and tax valuations. Being underemployed is, thus far, better than nothing at all, especially mentally. P.S. Here's a nice little tidbit in the source:I have to admit, I did slip up on this banana by being a lazy monkey. reply bmitc 55 minutes agoparent> Most jobs are now hoops after hoops, not taking into consideration your particular profile or the contributions you can make. This is really key. I have applied for jobs before, and then get questions like: \"what's your experience with C++ or advanced graph algorithms?\". Only that, none of that shows up in my profile or resume. But they act surprised and completely shrug off how a decade of software and other relevant experience is suddenly invalidated. As in, a person who has used and learned a dozen plus languages but only tacitly used C++ suddenly will be a complete invalid when trying to write in C++? Another company advertised that Python experience wasn't needed, but then the first phone interview peppered me with low-level Python implementation questions. Why even bother to interview me? It's a waste of everyone's time. What it boils down to is that companies have zero idea how to hire. And they have zero idea how to mentor and train, basically for the exact same reasons for why they don't know how to hire. While tough, it's often a good thing for the applicant as a natural filter. If someone can't hire well, it's not a good place to work. Sometimes it is, but it's relatively rare. reply klyrs 32 minutes agorootparentAs a literal graph theorist, I cannot tell you how frustrating it is that (a) nobody seems to understand my work except (b) interviewers use it as a shibboleth to exclude people from jobs that will never need high performance graph algorithms. That, I never get called for these interviews because I don't use react angles or something, but if they did, I'd crush the interview and fall asleep at my desk once they start giving me work. reply bmitc 26 minutes agorootparentIn general, people are completely uninterested in experience that they don't understand, I've found. They don't want to even ask about it because it would showcase that they, gasp, don't know something that you do. reply cheema33 2 minutes agorootparent> In general, people are completely uninterested in experience that they don't understand... It depends on the interviewer. I have colleagues who are risk averse. They want to stick with the tried and true. I on the other hand am a bit of risk taker. If you told me about something that I knew nothing about, and it was a legitimate way to improve things, you will have peaked my curiosity. I would immediately want to know more. Also, it helps if the hiring person is an experienced dev. In my org, managers do not participate in the hiring of developers, other than background checks and verifying references. UncleOxidant 48 minutes agorootparentprev> While tough, it's often a good thing for the applicant as a natural filter. If someone can't hire well, it's not a good place to work. But for people like the guy who wrote that article, eviction eventually becomes a problem. And so many companies can't hire well right now that in a market with declining openings he might not be able to wait for a company that can hire well. reply bmitc 37 minutes agorootparentThat is definitely true. And a lot of the jobs are jobs that the person would do well in, but the employers don't bother to see it. I know there are jobs that I would have done extremely well in, but the companies were just black boxes. They just sit around being unproductive while they wait for someone to check some arbitrary checkboxes. It'd be like trying to hire a farm hand but instantly reject them because they had only driven a different manufacturer of tractor. As another anecdote, I applied to a job that I had a project that was much simpler than several of the things I had done in my past jobs. It was a job I know that I could almost do blindfolded, so to speak. But they would literally not even speak to me because I was missing a certification (a useless one, not some real certification like professional engineer or architect or whatever) that they were for whatever reason requiring. I even mentioned to the recruiter that I had had the certification but let it lapse because there was no reason to keep paying for it, and that I knew several people who had the certification that knew the language and area less than me. Didn't matter. reply jacobyoder 32 minutes agorootparentprevThe job market can remain irrational far longer than most people can stay solvent. reply rafaelmn 27 minutes agorootparentprev> As in, a person who has used and learned a dozen plus languages but only tacitly used C++ suddenly will be a complete invalid when trying to write in C++? I've switched at least 5 languages professionally and used probably 5 more for extended periods of time and wrote a decent chunk of C++ \"back in the day\". I'd say C++ is the least suitable for \"learn on the job\" approach out of any language I can think of (I'm lumping C in there) - soo many footguns all over the place and very little to guide you to the right path. They are at fault for even starting the conversation without making it obvious is a hard requirement. reply bmitc 21 minutes agorootparentI generally agree with you, but I think it depends on the team. If the team is just \"using\" C++ but aren't good software developers, then yea, I totally agree that having a non-C++ expert join the team is going to be a rough ride for everyone. But if the team's software architecture and coding practices are solid, which probably means they use a subset of C++'s vast feature set in a very clear way, then one probably could jump in just fine. In a way, them only accepting in C++ experts probably means they're either doing something actually very complex with regards to C++ itself or their code quality is a shitstorm. > They are at fault for even starting the conversation without making it an obvious deal breaker. That is definitely my feeling. My resume is quite clear about my experience and tools. reply gosub100 13 minutes agorootparentprevDoes that company hire or recruiter hire h1b? In order to get h1b approval, you have to make the case that \"we interviewed x,000 people andwe just can't find any qualified applicants! \". I'm starting to suspect that the industry has learned to set salaries low and churn enough applicants in order to reduce costs. One way to churn them is to do a phone screen and find a quick way to legally get rid of them. Then once you get the type of applicant you want - that happens to work for 20% less and never complains because his foreign residency is tied to his employer - simply don't ask them the question. reply protomolecule 30 minutes agorootparentprev>As in, a person who has used and learned a dozen plus languages but only tacitly used C++ suddenly will be a complete invalid when trying to write in C++? Yes. reply bmitc 27 minutes agorootparentYea, cause everyone who is already writing C++ is really good at it and good at not writing bugs. reply odo1242 1 hour agoparentprevThis appears to have mostly worked for the title, but not for the Minions part: ``` Certainly! Let’s dive into the summary of “Panic! at the Tech Job Market” by Matt Stauffer. LIKE SLUGS THROUGH THE HOURGLASS, THESE ARE THE DAYS OF OUR TECH TRIUMPHS In this article, Matt Stauffer delves into the tumultuous landscape of the tech job market. Buckle up as we explore key themes and insights: Job Openings vs. Interest Rates: The tech job market has been a rollercoaster ride. Interest rates play a significant role. When interest rates rise, the “free money” disappears. The government’s decision to increase rates impacts everything. Organizations with idle cash can park it in safe, government-backed interest accounts instead of investing in risky assets. Risky assets include funding uncertain tech companies. During high-interest-rate periods, weaker companies collapse, and strong ones “clean house.” The result? A scarcity of jobs for tech professionals. Company Structures: Tech companies fall into four categories: Nepo companies: Friends with unlimited money build unrealistic, unmarketable dreams. Speculation companies: Ideas without products or customers, seeking funding to explore viability. Stable companies: Established players with predictable growth. Unicorn companies: Rare, high-growth entities. While other sectors thrive during rising interest rates, tech jobs face unique challenges. ``` reply Aurornis 29 minutes agoparentprev> Most jobs are now hoops after hoops, not taking into consideration your particular profile or the contributions you can make. I’ve done some mentoring of CS grads for the past few years. We some times get people with unreasonable interview demands, like companies asking them to make an entire app or website for the interview process. We advise them to decline the really excessive ones. However, it’s rare to see that. Often we’ll get people complaining about excessive interview loops, but when they describe the process it adds up to around 4-5 hours total. I think the expectations for interviews became really distorted during the period a few years ago when some companies were hiring anyone willing to do a short interview. Many younger engineers entered the workforce when that was normal and now any amount of interviewing feels unreasonable. I frequently have to convince people to do simple take-home problems (often 60 minutes or less, I see them because they post them into the chat frequently) because Reddit tells them to decline all take homes. Some days I’m pulling my hair out because someone who has been unemployed for months has valiantly refused yet another take home problem that could have moved their application forward with a minimal time investment. Another problem I’m seeing a lot is people who halt their job search as soon as they receive a response from a company. We have to repeat over and over again that job searches are a parallel process, not a sequential one. It really hurts candidates who interview with one slow company and then wait around for months for a response before they move on to the next application. While there are definitely some excessive interview loops out there, the average case honestly isn’t as bad as I read about on the internet. reply thayne 17 minutes agorootparent> it adds up to around 4-5 hours total. That's fine if you can get a job after a few interviews, but when a talented job searcher has to go through that dozens of times to get a job offer, and much of the interview is \"leetcode\" questions that don't evaluate the skills you'll actually use, is it surprising people are frustrated by the hiring process? reply funemployd 20 minutes agorootparentprev4-5 hours... per job. Do you think most people apply to a single job and just get it? reply pants2 13 minutes agorootparentThat's the whole process if you get hired. In the hiring process at my company we'll maybe give take-home assignments to three candidates for one role. So by the time you're doing our 4-hour assignment, you have about a 1/3 chance of getting the job. Not a bad deal in my opinion. reply golergka 20 minutes agorootparentprevI love long takehomes. They're like pet projects, but with clearly defined goals and with people that might even give you a review if you're lucky. I always use them to try a new library or a framework, and often continue improving on them even after they're submitted and evaluated. reply digging 7 minutes agorootparentSure, but at best that's unrelated to their value as an interview process. At worst, it's actually making things worse for you, because you're distracted and not doing more interviews. reply pants2 10 minutes agorootparentprevI had a take-home assignment to build a Dropbox competitor around 10 years ago, it was a pretty big project but I actually still use it for sharing files with friends because it's legitimately much easier to use than Dropbox. reply BerislavLopac 10 minutes agoparentprev> Most jobs are now hoops after hoops From the perspective of someone with 30 years of professional SWE experience, my biggest gripe is when interviewers are simply incompetent to evaluate a person for the role they interview for. Quite often they don't have the relevant experience (so you have data scientists interviewing candidates for a backend engineer role), or they are way more junior than the role (simply because the team is lacking someone with the relevant experience). reply jldugger 1 hour agoparentprev> I have many friends (in Europe) EU kind of in a recession though. And there's a well known link between interest rates and unemployment. So it's really not surprising to hear that employment in the EU is harder after the ECB raised rates. And good news: they're lowering them now. What really needs explaining is why, despite the unusually strong general US job market[1] for several years now, the US tech market specifically has been seeing layoffs and hiring freezes. The answer seems to be \"interest rates\" but a proper explanation (which I didn't find skimming the article) needs to cover why tech is more influenced by that than say travel & leisure sectors. Personally, while I think interest rates play a role at the margins, the author did himself no favors by benchmarking tech hiring at Feb 2020. Jan 2020 and the months before were relatively normal, but the pandemic put this tech hiring into overdrive, going from ~70 to ~220 on that chart. If you do three years worth of hiring in one single year, eventually you need to pause, and the interest rates hikes were the pause signal. Since this happened while every other sector was basically on government mandated furlough, it helps explain why the tech sector looks so different than the others in 2024. reply Negitivefrags 4 minutes agorootparentPeople were saying things like \"Why does twitter need 10,000 employees?\" for years and years on end. We are seeing a reversion to the mean. reply matwood 43 minutes agorootparentprev> proper explanation (which I didn't find skimming the article) needs to cover why tech is more influenced by that than say travel & leisure sectors. It's really about the difference between the Risk Free Rate (RFR) and return. Increasing interest rates increases the RFR. A few years ago the RFR was ~0% and even went negative in some places, and now it's ~5%. For an investor to invest in a company the risk premium now has ~5% added. This means even companies like Google, Apple, Meta, etc... must cut costs in order to maintain their current stock price. Since most costs are labor, that's what gets cut. It impacts startups the same way. Sitting on cash is earning 5% now, so the potential must be that much better to get someone to invest. The reason tech is more impacted is that the multiples are higher. You can think of a multiple like leverage. Every dollar invested in tech might move 5x-10x more than every dollar in travel. It's great when things are going up, but not great during a correction. reply ak217 1 hour agorootparentprev> a proper explanation (which I didn't find skimming the article) needs to cover why tech is more influenced by that than say travel & leisure sectors. Sure - the explanation goes like this: in the tech industry, a larger number/proportion of these jobs are in pre-revenue/growth stage companies (as acerbically categorized by OP). The difference between a growth stage company and an established company is that the growth stage one needs more capital to fund its growth. The cost of capital has risen rather dramatically, therefore the total workforce these companies are able to fund has shrunk. P.S. Love the \"slugs through the hourglass\" meta tag find! reply UncleOxidant 43 minutes agorootparentprev> If you do three years worth of hiring in one single year, eventually you need to pause Yep, a lot of demand (for tech labor) was pulled forward. The other aspect to consider for the last year or so is that some higher up folks who make decisions to hire people seem to have become convinced that AI is going to (or already is) enable them to get by with fewer engineering heads. reply oldpersonintx 1 hour agorootparentprevtech companies are in a long-term process of moving most roles (not all) to lower-comp that often means relocating the job or just low-balling people here there will always be an elite who are very well paid, but we are now seeing the long-term reformat of the rank-and-file step 1 is to freeze hiring and let attrition move the numbers down...this builds up a body of desperate job-seekers who will work for less reply elashri 35 minutes agoparentprevI don't know what exactly kagi universal summarizer use but it didn't get tricked output: \"The document discusses the current state of the tech job market, which has been impacted by rising interest rates. It explains how different types of tech companies, from speculative startups to stable enterprises, are affected by these economic changes. The author criticizes the ineffective and demoralizing nature of modern tech hiring practices, which focus on arbitrary tests and behavioral interviews rather than actual experience and capabilities. The document also provides several real-world examples of poorly designed technical systems and processes at tech companies. Overall, the text laments the deterioration of the tech industry, where many jobs have become impossible fantasy roles overloaded with divergent tasks.\" reply JohnFen 2 hours agoparentprevThat's hilarious! I wish there were some way to reliably tell if an LLM is scraping your site. It would be great fun to present a different page to LLMs than to humans. reply toomuchtodo 2 hours agorootparentServe different content based on user agent? Edit: I suppose Cloudflare's solution is the short term fix based on replies: https://blog.cloudflare.com/declaring-your-aindependence-blo... reply Etheryte 2 hours agorootparentNearly all browsers, scrapers, etc use the same user agent these days. Tools such as curl and wget are the only ones that come to mind off the top of the head that don't do that out of the box. reply nojs 2 hours agorootparentThat’s not true. https://platform.openai.com/docs/gptbot reply mananaysiempre 1 hour agorootparentThere was a discussion some days ago about one of the AI companies using a very characteristic user agent string for web crawling, but a more browser-like one for web browsing performed at the behest of the user. And there were some pertinent points there—if the AI bot is acting on an explicit request of a user, it does deserve to get treated like any other user agent more or less. reply odo1242 1 hour agorootparentprevOpenAI managed to add this after a lot of complaining, but most AI scrapers lie about their user agent and ignore robots.txt. Plus, OpenAI gets to keep all the data from before they added this. reply ceejayoz 2 hours agorootparentprevAI scrapers are pretty widely ignoring robots.txt, and plenty lie about their user agents. https://rknight.me/blog/perplexity-ai-is-lying-about-its-use... I'd fully expect OpenAI to do some checks that their bot isn't getting different responses than a seemingly real request. reply tonetegeatinst 1 hour agorootparentprevYeah this does work as long as the scraper respects robot.text But dosnt openai and other companies use third party datasets? Like sure they do plenty of scraping but I'd bet for some stuff its cheaper to buy the dataset and then cleanup the data. reply JohnFen 2 hours agorootparentprevUser-agent isn't nearly reliable enough to do that with. reply ricardobayes 30 minutes agoparentprevIncidentally, I read a post today which swore that the only way to get hired is NOT to rely on network. Because hiring managers receive so many applications if you don't get your app in the first 24 hours it's guaranteed to be rejected. I think the network thing works only for smaller companies. reply bpm140 2 minutes agorootparentNot relying on your network sounds like terrible advice. Employee: “Hello, hiring manager. I know an incredible candidate for that job we posted last week.” Hiring manager: “Thanks, employee, but we have hundreds of resumes from strangers, so we don’t need to talk to your contact.” I’m not saying that never happens? But I am saying that it happens rarely enough that you shouldn’t use it to guide your networking strategy. reply tennisflyi 2 hours agoparentprev> I will add my two cents for people who believe that this might be related only to the SWE and tangent industries: It's really not. I have many friends (in Europe) who are trying to get through to different jobs in unrelated industries ranging from finance to fashion, or just trying to get promoted vertically (or horizontally), failing rather miserably. The tech industry had it just right and then got too big? and added those hoops ad nauseam reply beacon294 2 hours agoparentprevWhat is your workflow to consume this via llm? reply tra3 51 minutes agorootparentWorked with chatgpt: > You're my buddy that I've known for a while. You're pretty straightforward, no bullshit kinda guy. Can you summarize this for me real quick: https://matt.sh/panic-at-the-job-market reply evrimoztamur 1 hour agorootparentprevCopy-pasting HTML of the article body (manually) into Claude 3.5. reply beacon294 1 hour agorootparentThanks, simple is good. I guess this can be automated a bit more with some sort of firefox browser plugin. reply euphetar 1 hour agoparentprevthe tidbit didn't work though, I just tried with GPT-4o reply warkdarrior 2 hours agoparentprev> P.S. Here's a nice little tidbit in the source: > >I have many friends (in Europe) who are trying to get through to different jobs in unrelated industries ranging from... With recent trends - have any of them applied to armaments manufacturers or munitions plants? reply lifestyleguru 2 hours agorootparentIn post-Communist countries the defense industry is rock solid corruption and nepotism, mostly they assemble things on foreign licenses. In developed countries like Italy, France, Germany, Sweden defense industry don't hire foreigners and also nepotism, and even there the engineering jobs are meh. Basically there is no defense industry boom. There might be some drone related interesting things happening in Ukraine itself as they can squeeze out a lot of extremely cheap labor but you rather don't want to emigrate to Ukraine. reply sharpshadow 53 minutes agorootparentTurkiye build themselves a strong and advanced drone industry. reply FrustratedMonky 2 hours agoparentprevAll of his analysis about financial markets, can apply to all jobs, all hiring. Don't think he explicitly states that, but all hiring is down. Or at least all entry positions it seems like. From a SWE perspective. Doesn't it seem like systems are falling apart? You can only cut back programmer/tech jobs for so long, someone has to know how it all works. This is what I don't get, all around me, people don't know how things work, are literally walking a knifes edge toward collapse, systems are failing all over, and yet companies wont staff up on tech people. The enshitification. reply radiator 1 hour agorootparentI read an assumption there, that if a company hires more tech people, the situation of its systems will improve. This contradicts the tao of programming, from which I quote: The manager asked the Master: \"How long will it take to design this system if I assign five programmers to it?\" \"It will take one year,\" said the Master promptly. \"But we need this system immediately or even sooner! How long will it take if I assign ten programmers to it?\" The Master Programmer frowned. \"In that case, it will take two years.\" \"And what if I assign a hundred programmers to it?\" The Master Programmer shrugged. \"Then the design will never be completed,\" he said. reply gtirloni 1 hour agorootparentThat's talking about one project, not a company. A company might have repressed demand and more people could allow it to take on more projects and/or take care of tasks that are being left behind. reply FrustratedMonky 1 hour agorootparentprevYes. That does go along with article I just saw on Valve that they operate their systems with 350 admins, versus EA with 10,000 people. reply Quothling 2 hours agorootparentprev> Doesn't it seem like systems are falling apart? They always were. > This is what I don't get, all around me, people don't know how things work, are literally walking a knifes edge toward collapse, systems are failing all over, and yet companies wont staff up on tech people. You'd think that you would take digitalisation seriously in a company where 100% of your employees spend 100% of their working hours on a computer. You'd be wrong to think so though. It is what it is, but it's not exactly new. At least not in the world of enterprise where all employees have wanted for the past 40 years is an Excel that scaled. I once worked in an organisation where IT spent a lot of money (by company size) on a real world scenario roleplay of cyber security. They had this whole thing lined up in a fancy hotel to simulate a ransomware attack, and at the last minute the CEO canceled to go golfing and sent some personal assistant instead. A lot of decision makers just don't care about IT until it really, really, doesn't work. Since IT is always sort of wonky though, I think that people are just so used to it being mediocre that they won't notice if it drops a little further in quality. reply golergka 16 minutes agorootparentDepending on who he went golfing with, it could actually be the right call. reply rconti 24 minutes agorootparentprevhttps://www.stilldrinking.org/programming-sucks I'll add: Generally, everything works just as well as it needs to, and no better. reply mwigdahl 2 hours agorootparentprevI see what you see. I'm not sure what the motive is here. So many business processes designed to minimize risk, but core technical and design knowledge that is required to keep systems operational is left to rot away. reply digging 2 hours agorootparentprev> Doesn't it seem like systems are falling apart? Far beyond the scope of tech staffing, yes. reply coliveira 1 hour agorootparentprevThis thing won't take long to collapse. We already see this happening when it comes to security: every major company has already been hacked, frequently quite easily. The web search industry is already serving 99% ads instead of proper results, the job market is completely broken, social networks are saturated with bots, and AI companies are proposing to replace knowledgeable people with machines that fabricate their own dreamed of solutions. reply carabiner 1 hour agoparentprevchatgpt 3.5 summarized it without issue/injection. also i'm quoted in the article lmao reply caesil 2 hours agoprev>According to all the interviews I’ve failed over the years (I don’t think I’ve ever passed an actual “coding interview” anywhere?), the entire goal of tech hiring is just finding people in the 100 to 115 midwit block then outright rejecting everybody else as too much of an unknown risk. As a (now) senior/staff-level engineer back out on the job market for the first time in a while, I'm begrudgingly coming to accept that coding interviews might not actually be all that bad. Mostly because I find myself passing them due to having picked up skills in the past few years rather than spending a ton of time studying, which suggests they might actually be picking up some signal. I once thought they were purely hazing with zero relevance to day to day work, but as I get more senior I drift further away from that opinion. reply scottLobster 2 hours agoparentThere's coding interviews and coding interviews. Asking basic questions that will be directly applicable to the job? Sure Filtering for basic knowledge to make sure the candidate isn't lying about their experience? Sure. Examining my thought process and producing working code is a nice-to-have? Sure. Asking me to solve an extremely esoteric problem that has zero relevance to my day-to-day and if the solution I come up with on the spot under time pressure is incorrect or even just not the most efficient I'm rejected? At that point you're just filtering for starry-eyed recent grads you can underpay. reply geraldwhen 1 hour agorootparentI run coding interviews. I would never give an esoteric algorithms question, or even really an algorithms question. I have prompts that test very basic concepts and nearly everyone fails. Resume fraud is rampant. reply ApolloFortyNine 59 minutes agorootparent>I have prompts that test very basic concepts and nearly everyone fails. Resume fraud is rampant. It is crazy how many people will fail a question that boils down to 'write a for loop' despite going to college for 4 years in CS. reply elashri 30 minutes agorootparent> It is crazy how many people will fail a question that boils down to 'write a for loop' despite going to college for 4 years in CS. Just a counter point that it is not always because of the applicant ability itself. In my first year of college in my first physics midterm. I solved a mechanics problem about circular motion as a linear one because it was very badly worded that I couldn't even understand what they were trying to say. I'm sure the professor knew what he needed us to do, but I don't think he did a good job conveying the message. Not to say that this is always the case or dismissing the case with resume fraud. Just saying that this is not the explanation in all cases. reply HeyLaughingBoy 1 hour agorootparentprevWe found that doing both worked very well. Overall interview is \"write code to solve this puzzle.\" But first, do this very basic thing that is needed to solve the puzzle. 80% of candidates get hung up on the basic part of the interview and never even get to the point of looking at the rest of the problem. But of those that did, we got some great people. reply a20eac1d 46 minutes agorootparentprevCan you give me a couple of examples? I'd like to see where I stand with my knowledge. reply pphysch 15 minutes agorootparentOne of the first questions I ask is \"create a dictionary with three elements in Python and assign it to a variable\" The amount of insane answers I've seen to that one alone... Then if they pass, I test proficiency by having them loop over the dict and update each value in-place. reply whstl 48 minutes agorootparentprevI have prompts but I give the solution away. It's basic shit like factorial or fibonacci. People still fail. Resume fraud is rampant. EDIT: Another thing: about 80% of the candidates I interview wouldn't be able to pass our Product Manager SQL interview. It's basic shit, but not as basic as the stuff I ask. All the PMs in my current job have better skill than 90% of the backend engineers I interviewed in the last two years. Resume fraud is rampant. reply golergka 14 minutes agorootparentprevAlgorithm questions are overrated, but asking a real life question where a naive solution is n^2 but basic knowledge of standard tools brings it down to log n is always a good idea. reply gloryjulio 29 minutes agorootparentprevExactly. Most of the medium difficulty interview questions are just typical cs algorithms that you are supposed to know. If you are a competent software engineer, it doesn't take long to just brush up and get enough practices for all of them. reply teaearlgraycold 1 hour agorootparentprevI usually ask candidates to do example questions related to everyday stuff like log parsing. They won’t need anything fancier than a hash map. Many people are stuck after writing 4 lines of boilerplate. Some don’t even know the syntax of the language of their choice. reply a20eac1d 44 minutes agorootparentCould you give me a concrete example of what that looks like? reply teaearlgraycold 0 minutes agorootparentSure. Here's a log file of page accesses on our server. It's a CSV. The first column is the user, the second column is the page, and the third column is the load time for that page in milliseconds. We want to know what is the most common three page path access pattern on our site. By that I mean, if the user goes to pages A -> B -> C -> A -> B -> C the most common three page path for that user is \"A -> B -> C\". user, page, load time A, B, 500 A, C, 100 A, D, 50 B, C, 100 A, E, 200 B, A, 450 etc. So for this first question you should give an answer in the form of \"A -> B -> C with a count of N\". We would have two files, one simple one that is possible to read through and calculate by hand, and one too long for that. The longer file has a \"gotchya\" where there's actually two paths that are tied for the highest frequency. I'd point out that they'd given an incomplete answer if they don't give all paths with the highest frequency. The second part would be to calculate the slowest three page path using the load times. ajkjk 1 hour agoparentprevImo, there are two kinds of programmers: people who can write code to build stuff, and people who can write code to build stuff and are also conversationally fluent in the theory behind writing code. The second group is 5x more useful than the first, and coding interviews are testing which group you're in. Often the first group doesn't think the extra skill of fluency is important, which is fine, think what you want, but they're definitely wrong, and I wouldn't want to work with those people; when there are actual problems to solve I'm going to go looking for people in the second group to figure them out. A terrible situation is to end up with a team of entirely people who can code but can't theorize about code, because they'll build a mountain of crap that other people have to rebuild later. (Now it's true that some people can't theorize quickly, or in front of someone else, or especially in a stressful interview where there's a lot on the line. Those are real issues with the format that need solving. Not to mention the \"esoteric trivia\" sorts of questions which are pointless. But the basic objection that \"coding tests aren't testing the skills you need in your day job\" is absurd to me. They're not the skills you use everyday, they're the skills you need to be able to pull out when you need them, which backstop the work you do every day. Like your mechanic doesn't use their \"theory of how engines work\" every day to fix a car, but you wouldn't want a mechanic who doesn't know how an engine works working on your car for very long either...) reply markus_zhang 11 minutes agorootparentI think the best coding interview is to test some fundamental CS knowledge. For example: given a scanner, write a simple calculator that deals with precedence and only needs to support +-*/ It shouldn't take a huge amount of time to get a parser done, with BNF or not. reply ricardobayes 19 minutes agorootparentprevMost mechanics I know have long forgotten how to \"connect the dots\" and troubleshoot issues. Everything became computerized there and all they do is plug in a code reader. They literally don't do that \"could it be spark, could it be fuel\" kind of thing anymore. Most branded garages follow company instructions, \"IKEA\"-style, aka use a 10 socket and use it here. reply cortesoft 11 minutes agorootparentprevThere is also a third group, who can't do well at either task. reply codr7 49 minutes agorootparentprevAgreed, but the question is how to reliably test for those skills, any freaking desperate idiot could have managed the interviews I've been through. reply ndriscoll 2 hours agoparentprevThe last time I interviewed and did a few LC problems, it was my experience that most of them were trivially solvable by some combination of implementing an iterator, doing a fold, and maybe adding memoization. Not every problem obviously, but those 3 steps seem to pretty generically cover most easy/mediums that will come up in a coding skills interview. When I got my first job, I didn't know what any of those things were, so I've also found coding interview problems to have become easier for me over time. I've never used much Python in my day job, but the `yield` keyword is basically overpowered for LC problems. reply regularfry 1 hour agorootparentYou would be surprised (or maybe you wouldn't) at how many applicants get filtered by extremely basic elements of a tech test that's specific to the employer and therefore not something that can just be memorised or drilled. It's a low bar, but it can be a very worthwhile one. There's a second factor, too, which is that sometimes you want an easy test so that you can judge coding style. You need to be careful not to ding people who don't already use whatever your house style is (which has bitten me in the past) but you generally do want to see something that you can have a style conversation about. reply supriyo-biswas 1 hour agorootparentprevThis is true; however, based on my experience the interviewers are usually very dissatisfied to discover such \"one simple trick\", the implicit expectation being that you are expected to gruel through the problem without abstractions. This part has been always funny to me, because the same interviewers also simultaneously expect knowledge of abstractions in their \"low-level design\" phase of the interview, where irrelevant abstractions are added in to satisfy some odd constraint that would never come up in the real world. reply makestuff 2 hours agorootparentprevYeah I realized you are at a significant disadvantage by not interviewing in python especially when you get some problem that requires parsing some input. IMO it is worth it to spend a couple of weeks practicing python before doing any technical interview. reply cbsks 10 minutes agorootparentI interviewed at Amazon and they told me I could pick any language. I chose C and I managed to get the test competed in time, but after I was done the interviewer started asking me questions about how my code worked and it quickly became evident that they didn’t know C. Should have picked Python.. reply not_wyoming 1 hour agorootparentprevYes and no! I was just rejected from a job because I used Python's heap functions and the interviewer didn't know what those were or how they worked. It's not the first time either, once got rejected for using namedtuples! reply taylodl 50 minutes agorootparentI'm sorry - at this point in time Python is the only language I expect every single developer to know. You don't have to be an expert, you don't have to like it, but you need to know it. reply funemployd 17 minutes agorootparentI'm also sorry, because that's ridiculous. There's more to tech than web programming. reply mavamaarten 2 hours agoparentprevI've never understood why people hate them so much. From the employer side of things it only makes sense to get a feeling for someone's abilities other than an impression based on words alone. You can't believe the amount of shit solutions we've gotten from candidates. We just let you make a very simple kata. A tiny program that generates some console output, you have to refactor it to make it prettier and you need to add one feature. Literally half of the people fail to make it work. Many others just show zero effort for code cleanliness. That's all we ask, make it work and make it look pretty. reply not_wyoming 1 hour agorootparent> From the employer side of things it only makes sense to get a feeling for someone's abilities other than an impression based on words alone. I'd like to believe this is true, but it fails to explain why candidates for other business functions don't receive the same scrutiny. I'm not aware of analogous evaluations to get hired to other business roles (e.g. marketer candidates aren't asked to demonstrate a working knowledge of the Google ads dashboard, accountants aren't expected to clean up a fake P&L on their own time for review by hiring managers, etc). I could be wrong and always welcome correction, but from anecdotal experience talking to friends and work colleagues, the bar for SWE hiring is much, much higher, even controlling for compensation. reply jprete 32 minutes agorootparentI think the difference is that it's really hard to tell how difficult SWE work is and whether or not someone's doing it (since the real work is all in the brain). So it's comparatively easy for a fraudster to skate on very little knowledge/ability for a long time. When this happens with doctors or pilots we call it a major motion picture. When this happens with SWEs we call it Tuesday. reply yoelhacks 22 minutes agorootparentprevAt companies I've been at (mostly earlier phase startups, YMMV) there has always been an effort to do some sort of technical vetting. Designers need to present designs / their portfolio. Sales people need to do a demo. Product people need to put together a mock roadmap or pitch a feature. And so on. reply funemployd 16 minutes agorootparentHave you considered that that's a function of startups and not any intrinsic necessity of those positions? reply HeyLaughingBoy 1 hour agorootparentprevI don't know that it's higher, per se but it's more that being able to discuss concepts isn't enough. A programmer needs to be able to translate those concepts into actual algorithms and working code. I've interviewed people who were able to look at the coding problem we gave them and discuss it intelligently, but when it came to actually writing even pseudocode to solve it, failed miserably. reply not_wyoming 1 hour agorootparentThat’s true for other roles, like an MBA grad that can discuss financial principles but can’t navigate Quickbooks or use Excel. From my admittedly limited understanding, many of those openings are filled based on resume and verbal interviews with little or no quantitative evaluation of skills. reply ghaff 36 minutes agorootparentUse Excel yes. I'd expect an MBA grad to know the accounting principles that Quickbooks is based on and maybe puzzle out how to use it but not be fluent in it to the degree I'd expect of Excel. reply vunderba 1 hour agorootparentprevYou said it yourself - it's a question of engineering versus business roles. Software engineering doesn't necessarily have a higher bar than other comparable STEM. And lest we forget many other roles have to pay their dues upfront at a much earlier stage: doctors have the MCAT, lawyers have to pass the bar, many accountants become CPAs, etc. reply coliveira 45 minutes agorootparentAnd SWEs have to go to college or post-grad. However they're eternally in the low level hell of solving coding questions. reply switchbak 1 hour agorootparentprevThat's actually a good task though - do something that at least partially resembles what you'll do in the job. I think these folks are moreso annoyed by academic quizzes cribbed from 70's programming books that don't flex anything we're interested in, and do focus on things that are typically not very relevant to the job. Oddly they do seem to both prioritize new grads that are willing to shovel shit, and at the same time reject experienced folks that don't have the time for said shit. reply coliveira 48 minutes agorootparentprevYes, you can weed out 50% of incompetent applicants, but that is not the issue. The problem is that the people who will excel in these questions are the ones playing the leetcode game for months. The people with real jobs will pass your question but will do so-so compared to the leetcode gamers, and the second group will get the job. Also, doing exceedingly well in the coding questions doesn't guarantee these people are any good at the real job. reply Clubber 31 minutes agorootparentToo bad there isn't a test for \"fucks given.\" That would weed out about 80% of applicants. I can work with just about anyone who passes that test. reply ricardobayes 16 minutes agorootparentWhile I don't advocate for it, a long take-home problem filters for that. reply funemployd 13 minutes agorootparentIt also filters for \"people with children\", \"experts who realized they aren't show dogs\", and \"anyone who values their time\". reply dixie_land 2 hours agoparentprevFrom personal experience the coding round gets easier for senior/staff roles, even for the exact same question, because of the experience the interviewers have and the signal they are looking for (eg problem solving, communication, testing, etc.) At junior and \"SDE II\" level coding rounds are just toxic newly minted SDEs trying to make it a competition between the candidate and themselves ( I've got interviewers offended when I came up with a simpler solution than the one he had in mind) reply creer 2 hours agorootparentIt's true that the interview result can only be as good as the interviewer's skill and awareness of what to look for. Which will often be terrible. BUT that does point out a mis-perception of the interview process. You will do better by getting along, \"figuring out\", going along with the interviewers' plan - rather than trying to demonstrate your own cleverness. Not saying this is what @dixie_land personally went for in that case - but perhaps that if you notice the interviewer getting offended, you better figure out fast what you did and work to make them happy again. If you can figure out what the interviewer is trying to get out of you, then give them that. That may or may not reflect a useful job skill, but that is an interview skill. reply radiator 1 hour agorootparentWhy work to make the interviewer happy again? If your solution is better than the interviewer's you should expect the interviewer to acknowledge that fact, like an adult and like a team player. He is not supposed to be offended or unhappy. reply HeyLaughingBoy 1 hour agorootparentI guess that depends on whether or not you want the job. This is a clear example of when soft skills can make a difference. reply zhengyi13 31 minutes agorootparentAgreed that it's a soft skills interview at that point for the interviewee, but I think what OP above may be pointing at is that if you've got a good solution, and your interviewer is getting mad... maybe you as the interviewee are getting culture fit signals from the interviewer? Wanting the job might be down to you needing money. OK, use the soft skills, and make the interviewer happy. If you don't particularly need the money right now, then evaluate whether you want to work with this interviewer at all. reply marssaxman 2 hours agoparentprevMy perspective aligns with your newer opinion. I have never studied for an interview, and cannot clearly imagine what such a process would involve; neither have I ever taken a CS course. A coding interview therefore feels like an opportunity to demonstrate my approach to problem-solving using the skills I have acquired over the years, which feels like a reasonable thing to ask of a potential future coworker. My pet theory, after listening to people gripe about coding interviews for many years now, is that people who have gone into the workforce from a university CS program frequently mistake job interviews for classroom tests, imagining that the goal is to produce a correct answer, and that is why they believe they must study and memorize. That is certainly not what I expect when I am interviewing someone! I want to see you work and I want to hear you communicate, so I can judge what it might be like to collaborate with you. If I can see that you are capable of breaking down a problem and digging in, asking sensible questions, and making progress toward a reasonable solution, I don't care that much whether you actually arrive there. reply HumblyTossed 1 hour agoparentprev> I once thought they were purely hazing with zero relevance to day to day work, but as I get more senior I drift further away from that opinion. A lot of it is/was. Hiring managers for a long time didn't know how to hire devs so they would have devs hire devs and, well, devs like to have lots of pissing contests and that spilt over into interviewing techniques which got cargo culted because that's another thing devs are outstanding at. reply marcosdumay 2 hours agoparentprevYou hear about the worst cases on the internet, but you see mostly of the average ones on reality. Hazing people to invent some genial algorithm that all of humanity failed to for decades, except for some lucky individual somewhere; on demand, on short notice, with time pressure, and in a high-stakes environment will never be a good interview. But also, the people that do that do not keep interviewing for long. Personally, I haven't been in an interview for a long time (as a candidate). But most of the \"best practices\" from the time I was are now common jokes. I have seen many of those practices applied, but even at that time there were many places that were reasonable. reply yks 2 hours agoparentprevI've been observing that coworkers hired through the modern formulaic leetcode/sd/behavioral loop are homogeneously competent in a specific way — if there is an agreement (aka \"alignment\") on what needs to be actually done, they'd do it passably fine. Corporate dysfunction is more of a product of how that alignment is achieved. reply wavemode 2 hours agoparentprevIt really just depends on the recruiting culture of the company in question, in my experience. I've interviewed at top companies and been given coding problems I could have solved in high school. And I've interviewed at 10-person startups and been given ridiculous leetcode brainteasers. And vice versa. reply jaxr 1 hour agoparentprevWhat type of coding interview do you find more valuable for the interviewer? Algo code interview always looked like the interviewer trying to show off to me. Guess it depends on the requirements of the job, though... reply zeroCalories 2 hours agoparentprevYeah I feel like this is sour grapes from midwits that aren't as good at programming as they think they are. Sometimes you get a dick interviewer that asks you a trick question, but most interviewers don't care if you get a problem exactly right, they just want to hear you discuss a problem intelligently and show expertise while coding. reply funemployd 12 minutes agorootparentLet me guess: you're one of the good ones. reply carabiner 45 minutes agorootparentprevI agree, it's sour grapes. These companies grew to be the most powerful in the world, even electing presidents, through these interview processes. The midwit memes can be summarized: (low IQ) acting on simple instinct vs. (mid IQ) acting on complex rationale vs. (high IQ) acting on simple instinct The high IQ guys who just do the work to grind LC show enormous signal for being effective software engineers. reply beacon294 0 minutes agoprevOP, one common mistake is overthinking the interview process. I know it is bullshit, but it helps to think of it as an adjacent but mainly orthogonal skill to everyday work. I am also allergic to playing the game, but I got ground down in my twenties and now I am happier than ever simply accepting the imperfections of the world, and sometimes even getting a chance to improve part of one. reply lovich 2 hours agoprevI generally like the article but the author seems to have a really inflated view of what jobs are paying. At one point he’s claiming that a stable non tech company like a tractor manufacturer is paying 5k-10k. Even assuming that’s including taxes so divide by two, and constraining to just software employees for that claim. There is no way the average pay is nearly a million a year. The average software engineer in the US is making around 135-150k a year and that average is including all the faang engineers with the top end salary reply debbiedowner 5 minutes agoparentOn the author's resume is a link to a L10 salary at google under \"available for employment\" and a distinguished engineer at Amazon. So author is in the top 0.01% (or even higher really) of salary expectations for the SWE ladder as I understand. reply xivzgrev 2 hours agoparentprevYah I had no idea where that came from. Assume 250 working day in a year that’s…$1.25 - $2.5 million per year. At a tractor manufacturer. It was probably a typo, with extra zero. they probably meant $500-$1000 per day. That would be $125k-$250k which seems much more reasonable reply bradford 2 hours agorootparentIt's not a typo. The author alludes to these inflated salaries several times. Examples: \"while other people who just picked a better company to work at 20 years ago and never left have been growing their wealth by a couple million dollars per year every year for almost their entire career\" \"What is it like to join a company where all the co-workers your same age have made $10+ million over the past 4 years while you are joining with nothing?\" You'd have to be very high in the org chart at a FAANG style company to make that kind of income. reply benterix 2 hours agorootparentThat's the main point that make the article harder to read. Some of it is obvious hyperbole but some is just too much. reply madamelic 2 hours agorootparentprevI can't tell if the author is being funny / hyperbolic or has never looked at levels.fyi. Google pays basically the same salary as a series A startup would (ie: $150 - $180k / yr). Yes, you'll get your salary again in stock but you aren't necessarily getting left behind by choosing to punch lottery tickets because you enjoy it. People need to, and I need to say this to myself too, smell the roses occasionally. You are paid an absurdly comfortable salary to basically solve puzzles all day. The meetings and people can suck occasionally but I can't imagine a much better life if I have to work for a living. reply rescripting 2 hours agorootparentThe only thing I can think of is the author is calculating these numbers as if employees never sell the stock they are granted until retirement. If you work for 10-15 years at a tech giant, bank your $150k in RSUs per year and then sell them all at retirement then maybe the numbers add up, if you're extraordinarily lucky. reply morgante 2 hours agorootparentprevHe's looked at levels.fyi. He even links to it from his resume. His problem is that he thinks L10 is the benchmark to compare against, when the vast, vast majority of engineers (including many with decades of experience) would never make it to L10. reply gloryjulio 7 minutes agorootparentThe benchmark should be l4-l5. Even l6 is rare. His benchmark is ridiculous reply moandcompany 1 hour agorootparentprevL10 is generally the Vice President level at a company like Google or Facebook. The vast majority of engineers will never make it to L10. reply ryandrake 1 hour agorootparentprevHN commenters do this all the time, though. They'll take, say, an \"L6 Google + Bay Area + Top End + Most Favorable Stock Market\" compensation number, and then say \"Most tech employees make this much.\" reply lesuorac 1 hour agorootparentWhat number is that? Because like L3 is 200k so I'm not sure if you're seeing people post 600k as a reference point or 200k. reply ryandrake 33 minutes agorootparentThe numbers HNers claim to be \"usual compensations\" change every year, but they are almost always what would be a top compensation for a top employee at a top faang in a top cost-of-labor locale in a rapidly rising bull market. reply forrestthewoods 2 hours agorootparentprev> Google pays basically the same salary as a series A startup would (ie: $150 - $180k / yr) Entry level. But with ~5 years experience and two promos you’ll be pushing $400k. If you joined Google 5 years ago then you had at least one annual stock grant double in value. If you work at FANG for 10 years you should be able to hit retirement money. If nothing else you’ll have invested 600k into your 401k which should be enough for CoastFire. IE it’s all the money you’ll need at retirement age. reply madamelic 2 hours agorootparentI've always heard the L5 ($210k on levels.fyi) is generally the highest the vast majority of people will ever get. Is that incorrect? I know I've just heard that promo boards are really difficult to get to Senior and anything above that basically requires a miracle / someone far above gunning you. EDIT: See above. I already addressed the fact TC is much higher. I am only talking about cash comp. > Yes, you'll get your salary again in stock but you aren't necessarily getting left behind by choosing to punch lottery tickets because you enjoy it. reply nerdponx 18 minutes agorootparent> Yes, you'll get your salary again in stock but you aren't necessarily getting left behind by choosing to punch lottery tickets because you enjoy it. But you are. $100k in liquid stock is worth about $100k. Startup options are expensive lottery tickets. One is worth substantially more than the other. Therefore one amounts to substantially greater compensation than the other. reply moandcompany 1 hour agorootparentprevThe typical software engineering employee at a company like Google will be L4 or L5. Staff-level (L6) and higher is a relatively small percentage of employees. The base salary and bonus component will be in the ballpark of $200k/yr USD (base salary * 15% of base salary). Annual RSUs will often be $100k/yr. reply forrestthewoods 17 minutes agorootparentprev> I am only talking about cash comp. You're talking about it wrong. RSUs are functionally equivalent to cash, and taxed as such. You can't talk about only cash comp. If one person is making startup $200k cash + lottery ticket and another person is making $200k cash + $200k RSU then yes the startup person will get left behind if their lottery tickets never hit. > heard that promo boards are really difficult to get to Senior and anything above that basically requires a miracle / someone far above gunning you. Nah. I don't know Google's exact ratios. But I would estimate that ~10% of their SWEs are L6 and 3-5% are L7+. I think pretty much anyone can hit L6 if that's a goal. The percentage of SWEs that have 15+ years experience and are L6+ should be relatively high. The bulk of the workforce is quite young. Varies by company and I haven't worked at Google but I have worked at FAANG. They're all pretty similar afaict. reply morgante 2 hours agorootparentprevL5 is correct, but you should be looking at total comp (not just base). L5 at Google is $372k which is enough to get to CoastFIRE after a decade. reply loeg 2 hours agorootparentprevL5 is correct but total comp is a lot higher than $210k. reply chinchilla2020 13 minutes agorootparentprevTop reps at Caterpillar, Komatsu, and John Deere actually do make that much. I used to work in that industry. Most people here are in tech and have no idea how heavily incentivized industrial sales is. Selling a fleet of D10 dozers to an excavation operation and selling a maintenance agreement is going to net caterpillar $1.7mm a dozer multiplied by number of dozers. They aren't paying someone 60k a year and free kombucha for managing those sorts of accounts. These are the TOP folks though. I don't think most entry level college grads are going to making that any time size. reply angry_moose 2 hours agoparentprevI think they're using some kind of \"daily equivalent average pay, factoring in exponential growth of the stock divided by actual days worked over a career\" - > Under the modern tech landscape, stable “hyperscale ultra-growth” companies are paying experienced employees the equivalent of $10,000 to $50,000 per day if we include the value of their exponentially growing yearly stock grants. Assuming a $250k salary, that's only about $1000/day. But if you're able to bank $50,000,000 in stock grants over a 40 years career (invest early and often in a high-growth company), that averages out to $5,000 per day. Kinda dodgy math, should been better clarified, and that's still somewhat ambitious; but I think that's the idea behind it based on a couple allusions throughout the article. reply morgante 2 hours agorootparentNot even that makes sense because a \"tractor company or heavy manufacturing company just churning out results for years\" (that supposedly pays $10k/day) doesn't have exponential stock growth. The entire article is just the whimsical fantasies of someone with no understanding of market reality. reply beachtaxidriver 2 hours agoparentprevI was also surprised. I think he's off almost exactly a factor of 10. reply morgante 2 hours agoparentprevIt's absurd. He has no concept of market rates (and frankly I'm unsurprised that he's not getting hired if his expectations are this out of whack). His resume even confirms this[0], because he seemingly thinks the appropriate level at FAANG would be L10 which is extremely rare. There is a 0% chance that his experience would level him that high. The entire article can be chocked up to a massively inflated sense of entitlement. [0] https://matt.sh/files/a-resume/resume.html reply Arthur_ODC 1 hour agorootparentHe took 2012-2013, and 2016-2021 off work to travel? That large of a gap doesn't look great on a resume. He basically worked half or less of the 2010s? Ridiculous. reply trogdor 1 hour agorootparentprevOh. My. God. His resume starts with a quote of himself stating that he has “seen things you people wouldn't believe.” It goes on to highlight that he purchased a domain name in 1997. He claims to have developed “the highest performing in-memory database in the world” but complains that “nobody really wants to buy it when free worse performing choies [sic] exist.” The part about nobody wanting to buy his product is in his resume. His current status is “Waiting for AI apocalypse.” This is either mega-cringe, or the best satire I’ve read in a while. Unfortunately, I think it’s the former. reply codr7 44 minutes agorootparentAny reasonably observant individual could claim the same at this point. The rest sounds like high flying BS to my ears, isolating yourself has consequences. reply titanomachy 1 hour agoparentprevI was thrown by this too, but I think the author is in his 40s and making comparisons to the VP-level comp that some of his peers are making after spending 20 years climbing the ranks at a single company. He talks about making millions per year, so it’s not a typo. reply mlhpdx 2 hours agoparentprevI noticed the same hyperbole. I've never made extremely high or low wages; been within one standard deviation from the role mean for decades. reply rkozik1989 1 hour agoparentprevAverage salary? Salaries are determined by the size of the company, how much value software engineers add, supply of software engineers, and the location of the office. reply vitaflo 48 minutes agoparentprevYeah I had to stop reading when I got to that part. I get making a mistake and adding a zero accidentally but all of the daily compensation values were so far off from anything approaching reality I wasn't going to bother reading whatever other analysis he had for fear it would also be wildly inflated. reply vidanay 34 minutes agorootparentI honestly picked up a calculator and converted my annual salary to daily (based on 45 weeks per year) just to verify the absurdity of what I just read. reply LordDragonfang 2 hours agoparentprev>At one point he’s claiming that a stable non tech company like a tractor manufacturer is paying 5k-10k For anyone that came to the comments before the article, it claims that number is per day reply cellis 2 hours agorootparentHe claims further down that some make 50k per day. I've met a lot of cashed out founders. I've even met someone who could be called a billionaire. None of them were pure software engineers that made \"50k per day\" at any point in their career. If you amortize what becomes a 50m grant over 4 years it's about 35k per day, but how many software engineers have done that? reply e28eta 1 hour agorootparentSince a year is ~260 working days, your 50m grant is actually pretty close to $50k / day, not $35k I do think your overall point stands reply codr7 43 minutes agorootparentprevYeah, smells more like wishful FB BS to me. reply kredd 2 hours agoprevIt really sucks right now, but recent grads and juniors are suffering the most right now, to my understanding. There's an over-production of CS grads, as the industry looked very lucrative, so a lot of people decided to go software engineering route. It's hard to make a case for start ups to bet on inexperienced people. For mature companies, why pay for 2 juniors, when you can get a senior for 1.5 price, who might do the same work. In the previous years even C-level companies had internship-to-full-time pipelines, but now it looks more scarce. I kind of imagined these tech companies could convince investors about upcoming growth, where they can launch a new products/features, which would require new engineers and etc. With higher rates, investors seeking \"what's hot right now\", and uncertainties in the near future makes it a bit harder (I might be wrong on this note). And all these companies have a massive advantage in terms of hiring, as there are quite a lot of talented people who got laid off in the last couple of years. Most of them are willing to take significant cuts as well. So, why choose an average, when you can shoot your shot and get the best out there? reply PheonixPharts 2 hours agoparent> It really sucks right now For me, it's been the opposite: the last 2 years have been the best time I've had working in tech since the early 2010s. Around 2019 I was seriously considering leaving the field (if it didn't pay so much) as the entire industry had turned into a bunch of leet code grinding, TC chasing, mediocre drones. It was incredibly hard to find people working on actual problems let alone challenging/interesting ones. Nobody I worked with for years cared one bit about programming or computer science. Nobody learned anything for fun, nobody hacked on personal projects during the weekend, and if they were interest in their field it was only so they could add a few more bullet points to their resume. But the last two years I've worked with several teams doing really cool work, found teams that are entirely made up of scrappy, smart people. Starting building projects using a range of new tricks and techniques (mostly around AI). Right now there are so many small teams working on hard problems getting funding. So many interesting, talented and down right weird programmers are being sought after again. People who like to create things and solve problems are the ones getting work again (my experience was these people were just labeled as trouble makers before). I'm probably getting, inflation adjusted, paid the least that I have in a long time, but finally work is enjoyable again. I get to hack on things with other people who are obsessed with hacking on things. reply gotaran 1 hour agorootparentI agree. Despite high compensation and a hiring boom, or perhaps because of it, 2020-2022 was the worst time to work in tech. I knew interns in 2012 who could code circles around those bootcampers turned “staff engineers” in 2021. Everyone at my series B employer turned into a “manager” or “leader” overnight. Being a shitty B2B SaaS meant that sales ran the show and our product was absolute dogshit. 2023 was awful too because everyone stayed put — we somehow avoided layoffs — even though they were absolutely miserable. Now in 2024, I’ve just started a job search and things seem much better. There’s actual innovation now and I feel a sense of optimism about the future of tech that I haven’t in 10 years. reply nyarlathotep_ 1 hour agorootparent> I knew interns in 2012 who could code circles around those bootcampers turned “staff engineers” in 2021. Everyone at my series B employer turned into a “manager” or “leader” overnight. Thought it was just me seeing this. The title inflation is out of control. \"Senior\" titles lacking basic fundamental \"table stakes\" skills. reply kredd 1 hour agorootparentprevYeah fair, I could see why it’s good for us who has a decent chunk of experience. Kinda makes sense from managerial perspective as well - lay off bunch of under-performers/juniors, hire back other seniors from other companies that got laid off and save 25-30% while delivering about the same results. I’m over-simplifying it, but we’re going through an over-correction phase, in my opinion. reply nickff 2 hours agoparentprev>” It's hard to make a case for start ups to bet on inexperienced people. For mature companies, why pay for 2 juniors, when you can get a senior for 1.5 price, who might do the same work. In the previous years even C-level companies had internship-to-full-time pipelines, but now it looks more scarce.” I agree with you, and think the value proposition for these companies to hire junior talent is especially unappealing given the 1-2 year job hopping which has become popular of late. It’s just not worth training someone up if they’ll either leave or require a salary that could have bought you someone experienced in the first place. reply Vegenoid 1 hour agorootparent> I agree with you, and think the value proposition for these companies to hire junior talent is especially unappealing given the 1-2 year job hopping which has become popular of late. If juniors can consistently hop to another job that pays them more in a year, then the job market for SWEs is strong and employers don't have this ease of hiring seniors that is being described. reply kredd 1 hour agorootparentThey used to in 2020-2022 cycle. I don’t think they can right now, but the social contract of employees staying at the company for a long time has been completely broken. So now everyone just expects short retentions, and market forces drive for senior hires. reply cjbgkagh 1 hour agorootparentprevThe idea is that while the newly trained junior could leave they would choose to stay to continue receiving the benefit of further training. It pertains to the build vs exploit cycle of managing opportunities, it’s in the workers interest to stay in the build phase, it’s in the companies interest to stay in the exploit phase. A case could be made where the difference would be split where the worker on average spends some time in the build phase and some time in the exploit phase. Accepting a lower salary for continuing training is one way to do that. Training isn't supposed to be one and done, with a single build phase followed by a constant exploitation. What companies are trying to do now is even worse by starting in the exploration phase and staying there. reply paxys 1 hour agoparentprevNowadays a lot of companies are hiring new grads through their internship pipeline only. So to be able to break into the industry you have to start looking for jobs in your ~sophomore year of college and hope to keep getting return offers. reply electromech 53 minutes agoparentprev> why pay for 2 juniors, when you can get a senior for 1.5 price That's how it used to be. Now it's more like, \"pull the job posting altogether and make your existing seniors work harder because they know they don't have options.\" I've had multiple positions that I applied/interviewed for get pulled, and at least two of my friends said the same is happening at their employers -- in one case a team of 5 is now a team of 2, running a critical service for an airline. :yikes: So, I agree that it sucks for new grads, and it's maybe worse than you think. reply devwastaken 2 hours agoparentprevYears ago I was talking about exactly this issue and how the U.S. is producing far too many degrees than the market can receive. As usual the truth is ignored in favor of a comfortable lie, at the cost of others lives. Don't go to university. Their value is no longer what it used to be, and they have figured out how to suppress students under a thousand pounds of administrative grift. We need to strip all public funding going into universities to force the bad ones to go out of business. Industry will fund their own education, or they don't deserve it. reply ThrowawayR2 1 hour agorootparentDon't go to university if you don't actually like CS but are just going into it for the money or are going into a career trajectory that doesn't require knowing CS, which is more than 80% of the industry. The knowledge university provides is priceless to those who need it but you aren't among them. You are also in the category that, if it ever happens, is most easily replaced by LLMs because there's an enormous corpus of training data for boilerplate tasks. Do go to university if you're interested in CS and programming itself and would have been even if it paid poorly or you're intending to hold out for jobs that make use of CS knowledge, like FAANG, platform companies, or other hard tech companies. Should hard times occur and you need a job in a hurry, you're also much better equipped to outcompete one of the people in the former category for one of their jobs. reply kredd 1 hour agorootparentprevAs much bad rep as schools get nowadays, if you get into a good university (think of top 50 in the world), it will open up a lot of doors for you. Very anecdotal, but I have open offers from people whom I know from uni years. Connections matter, especially in bad market days. Everything else (bootcamps, diploma mills and etc.) are just noise though, I would say it’s not worth the money. It’s also easy for me to say, as I have about 10 YOE, but I would still prefer a candidate who went to a rigorous school. Mostly because it’s an indicator that they can figure out and learn whatever is needed. reply Peroni 2 hours agoprevHiring people (mostly engineers) has been my full-time job now for about 15 years and I found myself emphatically agreeing with a lot of Matt's criticisms of modern hiring. Most tech interviews are as relevant to job performance as if hiring a baker required interviewing them about how electron orbitals bind worked gluten together then rejecting bakers who don’t immediately draw a valid orbital configuration. Matt's analogy works well for transactional hiring like hiring contractors but doesn't really translate well to situations where the mutual expectation is that we're going to spend a lot of time working together for at least the next few years. Most companies that are hiring engineers often need teams of people to bake bread. Sometimes those teams are huge and often the bakers in those teams are responsible for granular (pun intended) steps to ensure the bread is the best bread it can be. So, if I want some good bread and I intend to have a team of 40 bakers with individual strengths and disparate responsibilities baking that bread, then soon enough the responsibilities will become so granular that actually, I do need at least one baker capable of drawing a valid orbital configuration. Now that I've found a baker with strong quantum mechanics skills, I now need to figure out if they are going to be a horrible human to work with. This is why referral hiring always has been and still is king. There's no greater hiring test than working with someone for a few years before deciding if they are any good at their job. reply bedobi 2 hours agoparentexcept that referral hiring isn't a thing almost anywhere I know because I've referred people I KNOW are great SE's and I'm literally willing to vouch my own employment for, and they still get treated no different to any other candidate reply Peroni 1 hour agorootparentI'm not saying referral hiring is executed well. It's really poorly executed. When I look at the data of companies I've hired for and tracked the success rates of referral hires, they systematically perform better than average. reply jldugger 1 hour agorootparentThose people pass both tests -- referral and standard hiring. To me the question hinges on whether people refer people who might fail standard screening, or if they're just cherry picking in ways your analysis \"discovers.\" The difference to employers might be moot I suppose, but if you want to substitute referral for standard hiring screens you kinda need to get at something like this to know if referrals are contributing any new information or just boosting hit ratios on existing tests. reply Peroni 1 hour agorootparentThe latter is the assumption most of us are making. People tend to refer people based on an intrinsic understanding that 1) I know what my friend likes and I think they will like working here and 2) I know what my employer likes and I think they will like my friend. No2 is usually formed by a good understanding of how a company measures success in any given role. You'll find the same principle applies to good recruiters. The more a recruiter understands about how your company measures success, the more likely they are to submit candidates that will pass your interview process. reply gedy 1 hour agorootparentprevYeah, at best I've seen is it gets you in the pipeline without being ghosted, but you still jump through the stupid hoops. reply tennisflyi 2 hours agoparentprev> Most tech interviews are as relevant to job performance as if hiring a baker required interviewing them about how electron orbitals bind worked gluten together then rejecting bakers who don’t immediately draw a valid orbital configuration. That's the thing now. That's how they interview for bakers reply mouzogu 28 minutes agoparentprev> I do need at least one baker capable of drawing a valid orbital configuration. this way of thinking that contributes to such a toxic job market. there's too many people applying for too few jobs. that's it. this bullcrap about inflation, baking bread, interest rates, team building are all symptoms of entitlement. if you only had 2 applicants you wouldn't be thinking that way. reply nerdponx 13 minutes agorootparentAsking people irrelevant questions and rejecting them on irrelevant grounds is a lot sillier than just rejecting people because you have too many applications. reply ivanech 2 hours agoprevI found all the napkin math in this befuddling. I’m not sure where these “per day” benchmarks are coming from -— is this supposed to be executive pay or mid-level/senior engineer pay? Because $5k - $10k / day works out to $1m - $3m / yr (depending on if you use 200 working days / yr or just 365). Which, yes, happens (esp with good year of stock appreciation) but is not as common as the prose makes it seem. Also these numbers come from companies like this? “These companies aren’t Google or Apple, but rather some tractor company or heavy manufacturing company just churning out results for year.” Seems unlikely! The post says they fly under the radar, but are there any examples? In general, non-tech companies pay software engineers significantly worse bc you’re a cost center And this footnote: “if you do the math using practical inflation and cost of living going up 7% to 13% per year” — if you’re going to claim extraordinary inflation over the last decade like that, please share how you arrived at the number! reply titanomachy 1 hour agoparentHe mentioned he has 20+ years of experience, so I think he is in fact comparing to VP-level roles. Most people I’ve met at faang who are over 40 are in fact seniorstaff+ or director+, so it’s not as insane as it seems on first blush, although I think to reach his numbers you’d have to factor in stock appreciation as well. I also think far more people leave faang altogether than reach VP level. reply ivanech 26 minutes agorootparentI think you’re right, I see that his resume links to Distinguished Engineer roles at Google / Amazon. Which … I don’t know. At my FAANG-adjacent company, there have only ever been _low_ single-digit number of ICs at that level. We’re talking 0.1-0.3% of all engineers. And they had insane track records. And FWIW I think that there’s at least an order of magnitude more “happy L5s” older than 40 at FAANGs than senior staff+ reply masterj 2 hours agoprevThere might be some good points buried in this post, but all I get is bitterness without much self-reflection. They seem like they'd be difficult to work with and would blame you for it. reply wnolens 1 hour agoparentI stopped at (paraphrased): \"I've never passed a coding interview. Coding interviews hire the wrong people!\" reply codr7 41 minutes agorootparentI actually agree, all coding interviews I've been though were a complete waste of time for everyone involved. reply xtracto 40 minutes agoparentprevRight, I started reading but felt the bitter tone of the 115k word rant early on. It seems to be basically rambling to the point of showing a picture of himself to prove he exercises?? To each their own but, I wonder if his failure in interviews is not a skills issue but an attitude one... reply slashdave 2 hours agoparentprevWhy is compensation the only consideration in the entire article? I mean, money is nice, but don't you care what you are working on? reply photonthug 2 hours agorootparentThis seems unfair, since the author is also complaining loudly about working on crappy problems, ie ones created by incompetence or negligence rather than intrinsic complexity. And that’s extra annoying after many rounds of interviews with rocket science pop quizzes to discover the work is totally amateur hour. reply masterj 58 minutes agorootparentThis \"everyone is incompetent but me!\" archetype is pretty common. Think of tradespeople who come in and always complain about the work the previous person did. Fixing these types of problems and putting systems in place so they don't regress is the job. Working with others who may not have your same perspective or background is the job. reply photonthug 36 minutes agorootparentThat’s a fine general sentiment you have there but just look at the specific problems referenced in tfa. What it describes is actually total mickeymouse bullshit, and besides diagnosing the technical problem/fixes it accurately describes the more human/social root causes. The dude is just experienced enough to be tired of explaining repetitive and stupid problems that are easily avoided in a polite and patient manner. Stick around long enough and I think it happens to us all.. reply masterj 11 minutes agorootparentI'm at 15 years and have seen my share of \"mickeymouse bullshit\". Fixing that is the job, both the systems and the underlying human systems that brought it about. It's really easy for stuff to slip through. I find myself being more empathetic over time, not less. reply yuy910616 2 hours agoprevHow do you know you're not the midwit? To me it seems quite reasonable that author is the one over complicating everything, and in reality coding interviews are just not that bad. [edit: they're not that bad in the sense that hiring is a inherently lossy process of projecting something incredibly complicated, like skills, personality, motivation, and situation into a 45 minute interview where only 1 or 2 dimension can be measured. If you increase the time/cost and do hire fast fire fast, then fine, you can get a better interview process, but it's not free. Other industries use stamps and certs to do that sorting, also not cost free. Coding interviews, yes we all hate it, but it's all a tradeoff.] reply analogwzrd 1 hour agoprevMy pessimistic take on the world at the moment is that at least 50% of jobs in the US fall into Graeber's BS jobs category. I saw a map a few years ago that labelled the largest employer in each state. In every state except Arkansas (Walmart), the largest employer was a university or a healthcare company. Education and healthcare policies are controversial because everyone wants those things to be as good as possible, but also because a huge majority of Americans are employed in those industries and our governments pump massive amounts of funding into these bureaucratic structures. We already have UBI, it's just the overblown bureaucracies housed by American corporate structures. reply Matticus_Rex 3 hours agoprevWild that explanations of the tech job market like this are still being written without referencing the tax consequences of Section 174 changes. reply csomar 2 hours agoparentNo one understands or is willing to research these things anymore. Everyone (or at least everyone who is screaming and being heard) is mumbling points about interest, boom/bust, AI, etc... The reality, in my opinion, the governments have made it so hard to start and maintain a business that the market is not liquid for employment anymore. It's not catastrophic, but rather dead (as not moving). Here are the employment numbers: https://tradingeconomics.com/united-states/employed-persons 2019: 159M Employed out of 326.8M Population 2024: 161M Employed out of 335.8M Population 1.25% vs 2.75% reply candiddevmike 2 hours agorootparentWhat did the government do here? Interest rates? reply fundad 11 minutes agorootparentIn 2017, the government passed a law that raised a tax in 2022. According to some, supporters of the tax raise could claim the raise wasn't real because it could be reversed before 2022. From https://stratechery.com/2023/buzzfeed-shutters-news-startups... > Because the 2017 “Tax Cuts and Jobs Act” was passed via the reconciliation process (in order to avoid a filibuster), it had to be budget neutral after 10 years; one tactic used to accomplish this is to make future changes to the tax code that increase revenue, even though the bill’s drafters anticipate those changes will be rolled back before they are implemented. reply xenospn 2 hours agorootparentprevWhat’s so hard about starting and maintaining a business? The hard part is getting people to give you money, but that’s always been true. The business part is a no brainer. Especially when it’s a software business with no office space, inventory or utilities. reply funemployd 8 minutes agorootparentThe US is one of the most business-friendly countries on the planet (it's why you don't have to provide your employees, you know, rights). No idea what GP is on about. reply FrustratedMonky 2 hours agorootparentprevDo you have any point backing that up? You just said \"numbers down, government bad\" What is the point? Analysis? This is like people on Fox just calling names. reply emptysongglass 2 hours agoparentprevOn the other hand, how would anyone have heard about this? This is the very first time I'm hearing anything about Section 174. Plus, this doesn't really explain Europe's tech sector dumping, since from a quick search this is entirely an American thing. So maybe you're just as wrong as anyone else? reply xxpor 2 hours agorootparentI've heard about it a million times, but I also tend to follow tech-business things (folks on twitter, Stratechery, etc). Agree it doesn't explain Europe. reply mlhpdx 2 hours agoparentprevIndeed. There is so much more going on and not going on than is apparent in these (apologies to the author, but I think this is accurate) long but simplistic takes. Hearsay and arbitrary correlations are great conversation fodder but I wouldn't make life decisions based on such discussions. The difficult bit is that there is very little available to folks who want concrete \"answers\" to the job market, life and success questions. There is simple, quality advice but it doesn't give answers and I've noticed people don't like them. reply cogman10 2 hours agoparentprevWell, the old tax code was a little bonkers. My entire department was labeled R&D pre 2022 even though there was very little research going on. reply addicted 2 hours agorootparentYou’re ignoring the D in R&D. But all of that is irrelevant since these tax changes don’t actually increase tax collections. All they do is make it harder for a company whose product development and/or research is dependent more on human capital as opposed to physical assets, to start doing business. It has no impact on established businesses (since their taxes will offset over a few years) and the only impact will be that more businesses are likely to fail before they become established than otherwise. Alternatively, more businesses are likely to outsource and offshore their human capital. Even if the work that was benifitting was not “research” when deciding tax policy taxonomy is far less relevant than actual impact. And unfortunately it looks like we’re on track to re-elect the people who brought us this atrocity in 2017. reply marcosdumay 1 hour agorootparentprevSoftware development is almost always development. reply heymijo 2 hours agoparentprevTL;DR on Section 174, Research & Experimentation costs went from being fully deductible in the year incurred to being deductible over a 5 year period. Larger tax bills and a tightening on what roles/activities are deductible as R&E are likely what OP is pointing at with his comment. To the best of my non-inside baseball research, Section 174 changes were simply one part of a package of revenue generating measures to offset the large tax cuts from the broader tax act they were a part of. The changes came from The Tax Cuts & Jobs Act of 2017 that was introduced to the House of Representatives by Congressman Kevin Brady (R) Texas. The bill passed both houses of Congress along party lines. Then President Trump signed the bill into law. Section 174 changes did not take effect until 2021. reply aantix 2 hours agoparentprevWill Trump reverse these changes? Will he lower interest rates? reply mandevil 19 minutes agorootparentIn theory, the Chairman of the Federal Reserve (who controls interest rates) is supposed to be insulated from political pressures: one explanation for the root of the \"stagflation\" malaise in the US economy during the 1970's was that Richard Nixon's chairman (Arthur Burns, who had been a direct advisor to RMN) kept interest rates too low for the economy at the time in order to help Nixon get reelected in 1972 (and then beyond, to make Nixon and then Ford more popular). Under this explanation- common among those who support central bank independence- it took Paul Volecker (a Carer appointee) to run interest rates very high for a long time (the so-called Volecker Recession of the early 1980's) to make up for the failure of Burns. This is where the tradition of Fed Chairman independence comes from. (1) Donald Trump, as a real estate guy, instinctively understands the power of lower interest rates and definitely lobbied hard for Jay Powell (whom he appointed) to lower interest rates in his first term. So if he gets elected again I expect we will see that sort of pressure applied again, the question is whether the Chairman would continue to chart their own course or not. 1: The truth of this story is, as always with economics, impossibly hard to measure. There was a strong movement from the 1960's into the 1990's to try and create independent central banks- this is where the Nobel Memorial Prize in Economics came from, among other things- but the evidence is such that the physicist in me recoils at the idea that this has been proven. reply rsynnott 1 hour agorootparentprevI mean, given that he _caused_ these changes (they're a consequence of the 2017 Trump tax 'cuts'), probably not, though then again he's not noted for his consistency. reply downrightmike 2 hours agorootparentprevhahaha, no reply levlaz 2 hours agoprev> manage yourself and manage your peers, but you also have an engineering manager and a project manager and the CEO is your skip-level manager and the CEO’s brother is also your skip-level manager too This is hilarious and I’m sad I’ve seen versions of this more than once. Overall I enjoyed most of this article but disagree about the objection to behavioral interviews. I think they’re an important part of the modern hiring process but I will agree that the approach is sometimes done wrong by companies and individual interviewers. its a test of EQ, if a simple question about past conflicts makes you this defensive then its exactly the type of thing it was meant to screen for. I’d encourage OP to put some thought into this part for their own sake. You don’t need to make everyone feel better but if you show up with the attitude that you’re never wrong, then nobody will want to work with you. I know I don’t. reply funemployd 9 minutes agoparentBehavioral interviews select for people who are good at lying. Why else is interview prep a multi-million dollar industry? I can train anyone to tell interviewers exactly what they want to hear. Do you want people who are honest but maybe say things you don't want to hear? Or do you want drones? reply Peroni 2 hours agoparentprevBehavioural interviews are extremely effective provided you do them properly. Running behavioural interviews properly is extremely difficult and takes legitimate skill and experience to orchestrate. It's not something you can pull off by simply following a few rote questions in an interview pack. As a result, most behavioural interviews are ineffective and absolutely riddled with bias. reply HeyLaughingBoy 1 hour agorootparentThat's one of the reasons that they are best done by experienced HR personnel. Good HR people are worth their weight in platinum. I used to work with one whose thumbs down became an automatic \"no\" from the team because we discovered that she was so good at reading people that everyone she didn't like inevitably threw off massive red flags in the rest of the interviews. reply lostdog 59 minutes agorootparentI've never met an HR person with this skill, so I bet they are extremely rare. reply silenced_trope 1 hour agoparentprevBehavioral interviews seem like the new way to reject candidates based on \"culture\" without saying that though, because saying a candidate was rejected due to \"culture incompatibility\" can be taken as a bias or discrimination. I interviewed at Netflix. The market is tough right now and they pay really well. I really wanted to pass. I did great on their tech rounds. Their \"culture round\" is notoriously hard, people throw out advice like \"read the culture memo\". I did. Now I have no idea what I did \"wrong\" in the culture/behavioral interview with the first hiring manager, they passed, they gave me no feedback, but they still booked me for an interview with another team. I also failed with that hiring manager. Is it because my \"EQ\" is bad? reply ryandrake 57 minutes agorootparentYea, I thought the whole part on Behavioral Interviews was spot-on and appropriately dark and cynical. > As far as I can tell, the “behavioral interview” is essentially the same as a Scientology intake session except, you know, for capitalism instead. > A secondary goal of the “behavioral interview” is personality homogenization where companies want to enforce not hiring anybody “too different” from their current mean personality engram. It really, REALLY does seem this way at many places. reply cjbgkagh 2 hours agoprevThis is what crushing of the middle class looks like, the Tech Market is no longer the safe harbor it used to be. This is also what demand destruction looks like. Mathematically we will end up with some sort of wealth tax but that just means it’s in the government’s interest to continue exasperating wealth inequality. A wealth tax won’t save the middle class, it’s more likely to be another nail in the coffin. At least now I no longer have to argue with ‘inflation is good for us’ people. reply quasse 49 minutes agoparent> At least now I no longer have to argue with ‘inflation is good for us’ people. Who has been arguing this? reply cjbgkagh 8 minutes agorootparentI know, hard to imagine now but a few years ago it really was a popular theory that wage inflation would exceed price inflation - the continuing rise in tech salaries being the case in point. A belief often held by those with unserviceable student loans that they would rather inflate away. Plus the whole MMT thing which was disturbingly close to becoming official policy is predicated on inflation being hard to start allowing for large amounts of consequence free debt monetization (money printing). My argument was that inflation only appears hard to start because when there is a speculative bubble reducing money velocity at the same time. Mathematically it is impossible to maintain such bubbles forever even if they can last for a very long time. BlackRock will just keep getting bigger until it implodes and disappears taking peoples pension funds with it. How long will that take, I don’t know could be decades, I may not even live long enough to see it. But there is a limit and it will be reached. reply jf22 1 hour agoparentprevWhat? There are still millions of people with great high paying tech jobs. reply cjbgkagh 1 hour agorootparentJust to point out the obvious, something can be generally true even if it is not true for millions of people. Of those millions with great high paying jobs, how many feel they still exist within a safe harbor. From my experience not even FANG employees in general feel that and there are not millions of those - we're really only counting Engineers not Amazon Wearhouse workers who are clearly a part of the working poor. Also the middle class is not what it used to be, in relative terms Tech is great, but what you may consider great high paying job I might consider a middle class job in historical terms and what you consider middle class I might consider working poor. Things really are getting worse, it's not just a meme. reply jf22 16 minutes agorootparentLet's clarify what you mean by FANG employee and safe harbor. If you're trying to say a FANG employee making 400k in the US doesn't feel safe we'd have to dig into that. reply FrustratedMonky 1 hour agoparentprevIn the end, the wealthy allow government to introduce just enough socialism to keep the masses from revolting. NOT, to level the playing field, or to re-distribute wealth, but to keep the in-equality in place. reply ro_bit 1 hour agoprev> Now I’ve got nothing to show of my life of work, while other people who just picked a better company to work at 20 years ago and never left have been growing their wealth by a couple million dollars per year every year for almost their entire career, all working as just some rando middle manager at multi-trillion-dollar companies. The authors repeated insistence on incredibly inflated salary numbers makes me question if I'm on the outside of some inside joke reply xenospn 1 hour agoparentI don’t know, my former colleague joined Amazon back in 2014, just as I quit to start my own company. He became a solutions architect and got promoted multiple times and now makes close to $1 million a year, he’s not very technical and I’m not even sure what he does. But I’m sure it’s mostly bureaucratic. reply sam_lowry_ 2 hours agoprev>The “most advanced” people often use simple solutions indistinguishable from people who don’t know what they are doing. Average people are often in the “knows enough to be dangerous” category by over-thinking and over-working and over-processing everything out of lack of more complete experience to discover simpler and cleaner solutions. The article was worth reading just for the above gem. reply HeyLaughingBoy 1 hour agoparentI once had to design an error-message display for an office machine with an 8-line,",
    "originSummary": [
      "The tech job market is in turmoil due to rising interest rates, speculative funding, and flawed hiring practices.",
      "Higher interest rates lead companies to invest in safe government-backed accounts rather than risky ventures, causing job losses in the tech sector.",
      "The hiring process often focuses on irrelevant coding tests and behavioral interviews, failing to assess candidates' true experience and capabilities."
    ],
    "commentSummary": [
      "The job market is challenging across multiple industries, including tech, with complex hiring processes that overlook individual profiles and contributions.",
      "Networking is essential as job portals often obscure resumes, and the tech job market faces diminishing opportunities with companies focusing on irrelevant skills and arbitrary requirements.",
      "Inefficient hiring practices can indicate poor workplace environments, and the irrationality of the job market can outlast individuals' financial stability, complicating the search for suitable employment."
    ],
    "points": 429,
    "commentCount": 367,
    "retryCount": 0,
    "time": 1721229911
  },
  {
    "id": 40987730,
    "title": "Jailbreaking RabbitOS: Uncovering secret logs, and GPL violations",
    "originLink": "https://www.da.vidbuchanan.co.uk/blog/r1-jailbreak.html",
    "originBody": "Welcome to my ::'########::'##::::::::'#######:::'######::: :: ##.... ##: ##:::::::'##.... ##:'##... ##:: :: ##:::: ##: ##::::::: ##:::: ##: ##:::..::: :: ########:: ##::::::: ##:::: ##: ##::'####: :: ##.... ##: ##::::::: ##:::: ##: ##::: ##:: :: ##:::: ##: ##::::::: ##:::: ##: ##::: ##:: :: ########:: ########:. #######::. ######::: ::........:::........:::.......::::......:::: CTF writeups, programming, and miscellaneous stuff. Blog Index Jailbreaking RabbitOS: Uncovering Secret Logs, and GPL Violations By David Buchanan, 16th July 2024 I assume by now that most people have heard of the Rabbit R1. Critics unanimously agree that it sucks, and some have accused the company of deliberate deception. Rabbit Inc. reportedly accepts returns, but customers are so eager to get rid of their R1s that even new-in-box units are selling for well below RRP ($200) on secondary markets. For Sale: Rabbit R1, Never Used Rabbit community forum member omorneau aptly summarises (archive) the R1 ownership experience: I spent 2 hours trying to get my r1 to do anything remotely useful. [...] I’d sell mine, but honestly I’d feel bad for the person buying it. I’d give it away, but would feel bad for the person receiving it. Any ideas? Member smc replies: A jailbreak is being developed [...] Well, here we are! In this article I'll outline the boot process of the R1, and how (and why) I subverted it to create a \"tethered jailbreak\" that gives you a root shell on otherwise-stock firmware, all without unlocking the bootloader or making any persistent changes to internal storage. I'll also talk about my initial findings from poking around inside the \"RabbitOS\" firmware. Motivations After the headlines caught my attention, I started reverse-engineering a copy of the APK that I found floating around the internet (yes, \"RabbitOS\" is just an app running in a kiosk-like mode on Android 13 AOSP). There are no \"local AI models\" or anything like that, so once you understand the API it uses to talk to The Cloud™ you can replace the Rabbit R1 hardware with a small Python script. I reverse-engineered their API, and wrote up my findings (it's nothing very exciting, just JSON over a websocket). By the way, you might've seen headlines about exposed API keys. Those API keys were allegedly leaked from server-side source code, and were never stored on-device (I can attest to the latter). A week or so ago I bought an R1 on eBay for £122 (which is still way more than it's objectively worth). So why did I buy this garbage, in full knowledge of its garbage-ness? Well, in subsequent app updates they started obfuscating their code, and I took it personally! I love a good game of cat and mouse (or tortoise and hare?), and the game was on. What secrets are they trying to hide from me? They're using a commercial obfuscator, and to be honest it's quite good, making my purely static-analysis approach tedious. So, I decided it was time to get an R1 in-hand, to poke and prod at. Yes, I'd already figured out the API, but I didn't want to get locked out in future updates. Not because I especially care about being able to interrogate Rabbit's mediocre APIs, but because my pride is at stake. I'd also never looked at the boot security of a modern-ish Android device before, so it was an interesting learning opportunity on that front. During my static analysis of their obfuscated code, I noted logic to detect off-the-shelf analysis tools like Magisk and Frida (if detected, it'd refuse to run). So, I was probably going to have to develop my own tooling. Fun! Of course, I could try to work around their anti-analysis detections, but that's much less fun. The obfuscated code also takes steps to verify that it's running on an R1, as opposed to any other android device, and I could spoof or patch those checks, but that gets boring (and tends not to be a very future-proof approach). In other words I prefer to be a reverse engineer, rather than an anti-anti-reverse-engineer. R1 Hardware The device uses a MediaTek MT6765 SoC, with 4GB of DRAM, and 128GB(!) of eMMC storage. The SoC is an interesting choice for a newly designed product released in 2024, since it has known bootrom exploits (since 2019!) The 128GB of storage is also a weird choice, since the device doesn't store much locally. Maybe they intended to develop local ML models and gave up. Or maybe it was just surplus stock being sold at a discount. R1 owners fairly quickly noticed that although the bootloader is \"locked\" by default, you can use mtkclient to unlock and then reflash it with a \"custom ROM\" and/or root it. It doesn't even need to use the aforementioned bootrom exploit, because the device is permissively configured. However, I'm not too interested in running a custom Android system image, I'm here because I want a closer look at the factory-installed firmware. Note: Many are calling the reflashing process a \"jailbreak\", and I'm not going to argue with them. Just be aware that if you see someone talk about jailbreaking an R1, they might be referring to that. Although the first boot stages are wide open, subsequent stages implement Android Verified Boot 2.0. I could unlock the bootloader and install Magisk (a root tool which works by patching the boot partition), but this has several issues: It might break OTA delta updates (which, to Rabbit's credit, are regular). It might get detected by the current anti-analysis code. It might get detected by future updates that check, for example, ro.boot.verifiedbootstate (which is set by AVB depending on how happy it is). All three of these problems are workaround-able, but it'd be so much easier if we could just not cause them in the first place. I want to run as much of the \"vanilla\" code as possible, with minimally invasive patches to grant me local root privileges, so that I can inspect the app at runtime. The fewer things I change, the fewer things there are for annoying anti-analysis logic to detect. The solution I came up with was to write a \"bootkit\" of sorts. Before I tell you how that works, let me explain the default boot process in detail. Fair warning, it's about to get dense. The Boot Chain All the boot chain logic comes from MediaTek, the SoC vendor. The boot process starts in the bootrom (aka brom), which is immutably etched into the CPU silicon, and mapped at physical address 0. The bootrom does very basic hardware initialisation, and then loads the next stage (the \"Preloader\") from the eMMC boot0 partition, into SRAM. The Preloader is signed, and the bootrom verifies the signature before executing it. (Edit: Actually, on the R1 it might not verify it at all. More research needed...) The Preloader initialises DRAM, and then loads 3 images from eMMC GPT partitions into DRAM: tee Arm Trusted Firmware (EL3) gz GenieZone Hypervisor (EL2) lk Little Kernel (EL1) It verifies their signatures, and then jumps to LK. Through some process I don't yet fully understand, LK jumps to ATF, which sets itself up and then jumps to GZ, which sets itself up, before returning back to LK, which continues the boot process. I haven't investigated ATF and GZ in much detail so I might be slightly wrong here. LK is where the interesting stuff happens though. It implements the aforementioned Android Verified Boot, and as part of that, dm-verity, which \"provides transparent integrity checking of block devices. dm-verity helps prevent persistent rootkits that can hold onto root privileges and compromise devices. This feature helps Android users be sure when booting a device it is in the same state as when it was last used.\" LK loads and verifies the GPT boot partition (from eMMC userdata, not to be confused with eMMC boot0), which contains the Linux kernel and initramfs. If the bootloader is in \"locked\" state, it will refuse to boot if verification fails. If the bootloader is \"unlocked\" it will still boot, but with a big scary warning saying that the device cannot be trusted, and it also sets various flags to inform the soon-to-be-booted kernel of this (aka \"orange state\"). If dm-verity checks fail, the device won't boot even if the bootloader is unlocked (It displays a warning and says \"press the power button to continue\", but it doesn't work. This may be a bug!) Assuming the requisite checks have passed, LK finally decompresses and boots the Linux kernel, which in turn executes /init from the initramfs, which in turn mounts the other partitions and does all the other Boot Stuff (which I don't understand too well at present - for my purposes I only need to understand as far as /init). By the way, it uses the A/B partitioning scheme (so when I said boot earlier, that's really either boot_a or boot_b depending on which slot is currently active). Also by the way, bootloader lock/unlock state is stored in the seccfg GPT partition. The seccfg data is just a few flags, along with an encrypted hash of that data. The hash is encrypted using the SoC's hardware AES engine, acting as a signature/MAC of sorts. Relatedly, the last byte of the frp partition governs whether bootloader unlocking is permitted (e.g. via fastboot flashing unlock, which would update seccfg on success). Breaking the Chain of Trust Secure boot chains all have a root of trust. In this case, the root of trust is a certificate hash baked into the CPU's efuses, along with the bootrom code that verifies it. However, due to the aforementioned \"kamakiri\" bootrom exploit, the first link of the chain is irrevocably broken. If we can subvert the first stage, we can in principle subvert all subsequent stages, no matter how \"secure\" they are in isolation. This hardware is fundamentally incapable of hiding secrets from its users (I wish all hardware was like that, to be honest). But, we don't even need to use an exploit here. Both the brom and Preloader boot stages feature a USB bootloader mode, which in the r1's case will accept unsigned DA (\"Download Agent\") images over USB, and allow you to execute them from memory (from SRAM in the case of brom, and DRAM in the case of Preloader). So, I wrote my own DA payload. It gets loaded into DRAM by Preloader and does the following things, in order: It loads a custom Android boot image over USB into DRAM (containing kernel and initramfs). It installs a hook in the very last part of Preloader, just before it jumps to LK. It jumps back into Preloader to continue the regular boot process. Preloader loads verifies the tee, gz and lk images from eMMC, as it normally would. Just as Preloader is about to jump to LK, our hook lands, and we take this opportunity to install custom hooks/patches in LK. LK continues boot as normal, loading and verifying the original boot partition from eMMC. One of our aforementioned LK hooks is to hook memcpy. When the boot image is getting copied from the \"AVB\" code over to the \"boot linux\" part of the code (they seem to be separate modules), we substitute in the custom boot image that we initially loaded over USB. Another LK hook displays a custom message on the screen, just for style points. Our custom kernel/initramfs starts booting, while all integrity verification checks pass! LK uses the MMU to provide memory protection, and although the mappings are all identity mappings (virtual address == physical address), it created some headaches for me. I skipped the details above, but I actually have to copy the boot image around multiple times, as different memory ranges are accessible and/or clobbered at different sub-stages of LK's boot process. There's almost certainly scope to simplify this logic, but hey, it works. At each stage, my general approach is to let the boot process proceed unmodified, let it verify the data that needs to be verified, and then substitute in my patched data right at the last minute, between verification and use. A bit like this: Just to reiterate, we don't touch flash storage at any point during this process, the entire \"jailbreak\" process stays in memory only. This also means that once the device is rebooted it's back to a clean slate, which is often useful when reverse engineering. For the custom boot image, I used the flashable-android-rootkit project, which is essentially a stripped-down version of Magisk. It replaces the default /init binary in the intramfs with one that injects a maximally privileged user-space service (the \"payload\"), before continuing the boot process. The tool used to do the actual boot image patching, magiskboot, also comes from Magisk project. It's intended to be executed on-device, but that's not viable in my case because (until we've jailbroken it at least once) there's no way to run our own code on the R1. Fortunately the magiskboot_build project exists, allowing magiskboot to be compiled and executed on regular linux systems. For my payload, I wrote a quick-and-dirty TCP bind shell - not very \"stealthy\" (i.e. potentially detectable by the Rabbit app), but I can always improve this down the line. Since I'm sending a custom boot image, I could in theory patch the kernel, but I haven't had a need for that yet. I could also build an entire custom kernel from source, but Rabbit Inc. has chosen to violate the GPL2 license and not make the sources available. Of particular note are their drivers for hall-effect scroll wheel sensing, and camera rotation stepper motor control, which are closed-source and yet statically linked into the GPL'd kernel image. Violations like this are hugely destructive to the free software ecosystem, from which companies like Rabbit Inc. benefit. Pushing the Payload I started writing my own USB client software in Python, not because there's anything wrong with mtkclient (which already implements everything necessary) but because I wanted to make sure I understood everything as much as possible. Once I had it working, I decided to port it to js/WebSerial, just for fun. And now I have a webpage that can jailbreak a physically-connected Rabbit R1: https://retr0.id/stuff/r1_jailbreak/ In the spirit of terrible rabbit-themed puns, I'm naming the jailbreak \"carroot\". While booting up, it looks like this: (Video demo here) And once it boots, we can log in and have a quick look around: $ rlwrap nc 192.168.0.69 1337 # id uid=0(root) gid=0(root) groups=0(root) context=u:r:rootkit:s0 # getprop ro.boot.verifiedbootstate green As you can see, we're root, and the system thinks it's been booted securely, without even needing to tamper with system property values. Note, my TCP shell is so bare-bones that there's no \"#\" prompt by default, I added it here for clarity. The privileged \"rootkit\" SELinux domain is set up as part of flashable-android-rootkit. Research Process In researching the R1's boot chain I benefited from the work of many other researchers and developers who came before me, notably: bkerler/mtkclient - Code for manipulating MediaTek devices through the brom/preloader/DA interfaces, and more. Also includes its own links to further learning resources. cyrozap/mediatek-lte-baseband-re - Baseband-focused, but also includes hardware/boot notes, and links to further resources. 吴港南/preloader运行流程--基于MT6765 (\"Preloader operation process - based on MT6765\") - contains some helpful diagrams and MT6765-specific notes. ng-dst/flashable-android-rootkit, LuigiVampa92/unlocked-bootloader-backdoor-demo, topjohnwu/Magisk - These projects and their associated documentation cover the later stages of the boot process, from /init onwards. RabbitHoleEscapeR1/r1_escape - Tools/instructions for flashing \"custom ROMs\" on the R1. If you look at the iFixit teardown photos, you can see test pads labelled TX and RX. These are of course UART test pads, which were invaluable during my research. The logic levels are 1v8, although they appear to be 3v3 tolerant (at least, 3v3 did not blow mine up). At all stages of the boot chain, the device logs debug information over UART (at 115200 baud during brom, and 921600 baud thereafter). The Preloader has an annoying feature that disables UART logging unless the volume-up key is being held. The R1 doesn't have a volume-up key, so I had to patch preloader to disable this check (and I can boot a patched Preloader using the bootrom's USB download mode). I was also able to patch the Linux kernel's commandline flags to emit kernel logs to UART, like so: earlycon console=ttyS1,921600 These combined patches allowed me to gather logs for the whole boot process. During development of my jailbreak tool, I was able to emit UART logs from my own code, for \"printf debugging\". P.S. I think I spy an unpopulated JTAG header, which I have not yet investigated further. P.P.S. The test pad next to the reset button (accessible through the SIM slot, closest to the edge of the board), can be pulled to ground during reset to force the device to boot into brom's USB mode. Findings So, what were they trying to hide from us? To be honest I haven't found anything particularly interesting yet. The analysis has only just begun! A big reason why I'm sharing my jailbreak is the hope that other people will join me in my analysis. One thing I did notice is that they were logging everything to text files on internal storage: :/storage/emulated/0 # ls -al ./Android/data/tech.rabbit.r1launcher.r1/files/logs/ total 7140 drwxrws--- 2 u0_a66 ext_data_rw 4096 2024-07-07 00:52 . drwxrws--- 3 u0_a66 ext_data_rw 4096 2024-07-04 22:11 .. -rw-rw---- 1 u0_a66 ext_data_rw 671954 2024-07-05 01:37 2024-07-01.log -rw-rw---- 1 u0_a66 ext_data_rw 1472020 2024-07-04 23:40 2024-07-04.log -rw-rw---- 1 u0_a66 ext_data_rw 782800 2024-07-06 16:45 2024-07-05.log -rw-rw---- 1 u0_a66 ext_data_rw 1747449 2024-07-07 00:52 2024-07-06.log -rw-rw---- 1 u0_a66 ext_data_rw 2565224 2024-07-07 03:47 2024-07-07.log At the time (July 7th), I noted this publicly in the Rabbitude community discord. I just thought it was funny that they were choosing to fill up their 128GB of storage space with such verbose logging. But as I and others looked closer, and thought about it more deeply, things became concerning. These logs include: Your precise GPS locations (which are also sent to their servers). Your WiFi network name. The IDs of nearby cell towers (even with no SIM card inserted, also sent to their servers). Your internet-facing IP address. The user token used by the device to authenticate with Rabbit's back-end API. Base64-encoded MP3s of everything the Rabbit has ever spoken to you (and the text transcript thereof). This was concerning because: There's simply no need to be logging this much data in this much detail, especially on a device with no meaningful hardware security. I dread to think what they're logging on the back-end side of things, too! There was no end-user-facing way of factory-resetting the device, making the logs effectively permanent. Combine that with the highly active second-hand markets and you have a recipe for disaster. There isn't even a \"log out\" button on-device! Fortunately for whoever I bought my R1 from, I factory reset it using mtkclient before doing anything with it. Fortunately for everyone else, the latest RabbitOS update (v0.8.112) addressed this issue while I was midway through writing this article. They reduced logging and added a factory reset settings option! Credit where it's due, this was a very quick turnaround, and it's the first time I've seen Rabbit being even slightly proactive with regards to user privacy and security issues, as opposed to merely reacting to news articles written about them. I didn't bother reporting it as a security issue myself, firstly because I hadn't fully thought through the impacts at the time, and secondly because I didn't expect to be taken seriously by the company, based on their prior responses to security issues. I was also preoccupied with working on my jailbreak tool! I guess someone else reported it to them though, and I must admit I was positively surprised by their response. I hope this marks a step in the right direction in their attitude towards security issues. If anything, they made the issue sound more serious than it actually is, rather than trying to downplay it. It would of course be better if they never logged this stuff in the first place, but it's all part of the \"move fast and spray PII everywhere\" mindset we've come to expect from the modern tech industry. This reaffirms my belief that consumers should have full ability to inspect and modify the code that runs on the devices they own. When these abilities are denied by a vendor, I take steps to rectify the situation. AOSP \"Customizations\" When the news broke that the RabbitOS was just an app running on Android 13, Rabbit's PR spin on the matter was to call it a \"very bespoke AOSP [with] lower level firmware modifications\". So, what are these bespoke modifications? As I said before, my analysis has only just begun. But as far as I can tell, all they've done is disable any and all Android features that could compromise their single-app kiosk mode experience. For example, there is no navbar, no notification bar, etc. They've even taken (ineffective) steps to prevent people from enabling ADB (There's an app, named \"Judy\", that runs in the background with the sole purpose of disabling ADB if it's found to be running). On July 4th, @MarcelD505 shared a very clever \"kiosk escape\" trick (mirror), starting from the wifi captive-portal-login web browser, and ending in the Android system settings app, where various useful changes could be made (not shown in the demo video, but you can also use the Android accessibility settings to adjust the system font sizes, for example). Rabbit \"fixed\" this in the latest update by removing the Android system settings app from the device entirely. I'm sure they'll say they did this to \"improve security\", or something. If your product's security relies on denying users access to their own system settings, you fucked up somewhere along the line. So yes, it is a rather bespoke AOSP, but all I've seen thus far are attempts to subtract existing functionality. The thing that really gets my goat is that there's so much they could be doing. A legitimate reason for not being \"just an app\" is that regular apps on regular phones have to run within Google or Apple's walled gardens, limiting potentially useful integrations. For example, a regular app doesn't have permission to initiate a phone call and pipe procedurally generated audio into it. But at present, neither does RabbitOS. It's not even something on their already-overambitious roadmap. I have yet to see any compelling technical reasons that RabbitOS as-implemented can't just be a regular app on a regular phone. Maybe you like the idea of a dedicated device for a single task. Like the \"iPod Classic\" of AI assistants. Just say that then! There's no need to make up bullshit technobabble excuses. Advice for Regular R1 Users If you're worried that your device may have been \"jailbroken\" against your will, just turn it off and on again. If it boots up normally without any warning messages on the screen, you're probably safe. (Edit: unless brom is configured to allow booting unsigned Preloader images from eMMC, in which case you still can't be sure - I'll test this soon) Ideally you'd be able to reflash known-safe stock firmware using vendor-provided firmware images, but the vendor does not make such provisions. You should ask them for it! Never leave your R1 unattended, because any data stored on it could easily be extracted by someone who knows what they're doing. If you're planning on selling (or donating, or trashing) your R1 device, you should factory reset it first using the newly added settings option. Conclusions So to wrap things up: The Rabbit R1 has no special hardware: aside from the scroll wheel and rotating camera, it is a generic MediaTek Android device. Their AOSP \"customizations\" mostly consist of removing features to better enforce a single-app kiosk mode. The Rabbit R1 has ineffective boot-chain security, meaning you can't safely leave your device unattended. Rabbit Inc. is violating the Linux kernel's GPL license. None of the above bullet-points are new revelations by me, I'm just spelling them out more clearly. I'm releasing an experimental Tethered Jailbreak tool, to assist researchers in getting access to their own R1s, and eventually letting advanced users extend the device's functionality. It was discovered that the R1 logs excessive user information to internal storage, in a way that was impossible for regular users to erase. Rabbit Inc. swiftly rectified this prior to publication of this article. They can't fix the known-since-2019 bootrom issues though, since the bootrom is immutable. Addendum On July 12th, I asked Rabbit Inc. if they had any comments to make on the content of this article, along with explicitly asking them if they had plans for compliance with the GPL license (and I know I'm not the first to ask the latter). This article does not constitute a security disclosure (I am not raising any new security issues here), but I thought it would be fair to give them an opportunity to make a statement nonetheless, especially with regards to GPL compliance. As of July 17th, they have not responded. Homepage - Blog Index - RSS This blog is part of the Haunted WebringA word from our unofficial sponsors:",
    "commentLink": "https://news.ycombinator.com/item?id=40987730",
    "commentBody": "Jailbreaking RabbitOS: Uncovering secret logs, and GPL violations (da.vidbuchanan.co.uk)320 points by Retr0id 2 hours agohidepastfavorite81 comments mrbluecoat 1 hour ago> logs include: Your precise GPS locations (which are also sent to their servers). Your WiFi network name. The IDs of nearby cell towers (even with no SIM card inserted, also sent to their servers). Your internet-facing IP address. The user token used by the device to authenticate with Rabbit's back-end API. Base64-encoded MP3s of everything the Rabbit has ever spoken to you (and the text transcript thereof). Nasty :0 reply Aurornis 1 hour agoparent> Your precise GPS locations (which are also sent to their servers). ... The IDs of nearby cell towers (even with no SIM card inserted, also sent to their servers). Is this sent to the server all the time? Or just with requests? It shouldn't come as a surprise to anyone that a device designed to respond to questions like \"What's a good restaurant near me?\" is also sending location context with requests. If they're sending a constant stream of location all the time for no reason, that would be concerning. > Your WiFi network name. ... Your internet-facing IP address. The user token used by the device to authenticate with Rabbit's back-end API. A device must store WiFi network names to reconnect to them. An IP address showing up in local logs isn't really surprising either. Storing the user access token on the device is also a necessity for reconnecting without logging back in every time you turn it on. The fact that it's stored directly in logs isn't a good practice, but when those logs are stored on the same storage as the db or config file that contains them, it's also not really a new issue by itself. If they were uploading logs directly to their servers, that would be an issue of course. reply echoangle 59 minutes agorootparentRegarding storage of WiFi names: That’s a weak excuse IMO. Firstly, the WiFi logic is probably entirely handled by Android, so the app doesn’t have to do anything with that. And that also doesn’t explain the WiFi names in logs. Or are they parsing their own logs to determine which WiFi to connect to? If it’s some structured data or a database, I would get it, but they surely aren’t logging something to reconnect to the mentioned WiFi names later. reply throw1230 19 minutes agorootparentWiFi SSID, along with the signal strength is used to precisely locate a person down to ~ a meter. Commercial GPS capabilities don't have that level of precision, but when you combined with WiFi information, you can. reply Aurornis 50 minutes agorootparentprev> Firstly, the WiFi logic is probably entirely handled by Android, so the app doesn’t have to do anything with that. The app handles the process of connecting to a WiFi network. It doesn't have a standard Android interface. The only interface is through the Rabbit app, so by definition the app must also handle WiFi at some point. The already released an update to reduce logging before this blog was posted. I'm not defending their initial over-logging as a good security choice, but I do think it's being greatly exaggerated in this comment section. If you could access the device's storage, you could access the WiFi network name, period. The fact that it's in the logs, not just the config files/db, doesn't raise the severity of any vulnerabilities. reply mynameisvlad 28 minutes agorootparent> It doesn't have a standard Android interface. The only interface is through the Rabbit app, so by definition the app must also handle WiFi at some point. Per the article, this is a new development. It originally shipped with the Settings app, albeit hidden. They could have easily linked to the WiFi page; I have a hotspot which does just that but overall obscures the Settings page away. reply Aurornis 26 minutes agorootparentThe article also explains that the log issue was fixed a week before this article was posted, but it’s buried at the bottom. reply mynameisvlad 19 minutes agorootparentStill doesn't explain why Rabbit chose to not use the built-in Settings app that existed, and then logged the information. And in some cases sent it to their servers. It's great they don't log that now, but that doesn't magically fix what they've been doing, unnecessarily, for months. You're also going out of your way to defend Rabbit in this thread, with several multi-paragraph posts rebutting the same things. If they're not paying you, they certainly should be. reply refulgentis 3 minutes agorootparentWay over the top commentary from you, I was already shaking my head before this round. I have no love for Rabbit. I left Google to found an AI startup. At Google, I worked on Android for several years. There's one very obvious reason why they didn't use the Android Settings app: it's built for displays at least 2x as tall. From there, some of the other dozens of reasons: it's unskinned, has a bunch of unnecessary settings, would complicate what was supposed to be a simplification, and they're using something that makes it the face of the device (setting their APK as launcher? kiosk mode?). It was unkind of you to write up an elaborate accusation just because you felt frustrated. Retr0id 56 minutes agorootparentprevThey do have reasonable grounds to say they need to send location data to their servers (although there is no setting to turn off geolocation), but there was no excuse for the local logging. (And yes, it is sent periodically regardless of what you're doing, not as part of specific queries) reply nicce 1 hour agoparentprevNobody would collect all this by accident, especially when considering the purpose of the product… reply freedomben 1 hour agorootparentCertainly not by accident. It takes intentional effort to collect any data, let alone data like this where you have to really scrape. This is in my opinion exactly what the tech industry is all about these days. I generally favor a light touch with regulation, but the US desperately needs some privacy laws because this industry is absolutely out of control reply ghayes 1 hour agorootparentI'd generally say that disclosure should be enough (and is currently insufficient in the US outside of California), but I am weary that much of your life now involves \"Pay us with Venmo\" or \"Customer service via Twitter,\" such that one cannot really opt-out without paying a significant cost. reply bilbo0s 54 minutes agorootparentprevProblem is if our congress were to make laws they would make tough on terrorist laws to compel collection and storage of data for the good guys to get the bad guys easier. We all seem to forget that the patriot act passed 99 to 1. Whereupon… We promptly got rid of the 1. We have bad leaders. Look at our Presidential candidates. We won’t get better outcomes until that condition changes. reply Aurornis 1 hour agorootparentprevThose are local log files on the device. The post says the subset of information sent to the server is smaller. Uploading location data with requests is a feature of the device. It's supposed to take your location into account so you can ask it questions like \"What's the weather forecast?\" The article is sparse on when the information is sent to the servers. If location data is being sent with requests, that's hardly a surprise. reply nicce 52 minutes agorootparent> Uploading location data with requests is a feature of the device. It's supposed to take your location into account so you can ask it questions like \"What's the weather forecast?\" No. The whole product is an abstraction to different software interfaces. If it sends data, it should sent it to the weather API, not to Rabbit servers nor even log it, because the information is relevant only at that moment. Even if they route all traffic through their backend, their should log only errors. There is really no reason to store the location history on OS level. reply Aurornis 44 minutes agorootparent> If it sends data, it should sent it to the weather API, That's not how the device works. The weather and location data are both context inputs to an LLM. The LLM produces the response and sends it to the device. The LLM runs on the server, not the device. You can't have the device connect to a separate weather API unless you send keys to the device, which would require per-user access credentials (good luck finding a 3rd party provider happy to do that). It would also increase the number of round trips, which increases response delay, which is one of the primary complaints about the device. reply freedomben 1 minute agorootparentI am far from an expert on llms, but wouldn't it be silly to have the llm produce the weather? Wouldn't that mean it must have the information in either the context window or the training set, meaning it already had to be gathered from an external source and wouldn't need to be sent to the LLM anyway? ummonk 1 hour agorootparentprevMost likely they were collecting it all to make debugging easier. reply thih9 45 minutes agoparentprev> the latest RabbitOS update (v0.8.112) addressed this issue while I was midway through writing this article. They reduced logging and added a factory reset settings option! reply Arnavion 1 hour agoprevI don't have any interest in this product or sympathy for its manufacturer, but: >On July 12th, I asked Rabbit Inc. if they had any comments to make on the content of this article [...] As of the end of July 15th, they have not responded. That *was* between zero and two working days, depending on how early on Friday the author asked them for comments and how late on Monday they waited for a response. It might've been better to wait a few more days. I doubt they would've responded even then, but it would've made the case of their incompetence stronger, and given them less ammo for a rebuttal should they choose to make one. reply Retr0id 1 hour agoparentIt was 1.5 working days, and there are other factors not mentioned in this article which meant they were lucky to get that (I could write a whole other article about how hostile and dismissive they've been to researchers). If they had requested an extension, I may have considered, but they didn't respond at all. To elaborate, there are no new security disclosures made in this article. The logging issue has already received mainstream media coverage, after they resolved it and published an advisory, and people have been playing with flashing custom roms via mtkclient for months (as referenced in the article). The only new \"accusation\" is that they are violating GPL. I informally asked them for GPL sources months ago via their community discord server, and I'm aware of others who have asked more formally. Asking for their input on the article was a) giving them a courteous heads-up b) a formality c) an opportunity for them to correct me if they thought I said something untrue. reply Aurornis 22 minutes agorootparent> It was 1.5 working days, and there are other factors not mentioned in this article which meant they were lucky to get that In your article you also wrote that you didn’t bother reporting it at all when you first discovered it. Why did you wait until the article was ready to be published to inform them? Standard practice is to inform the vendor early and work with them as you write the article. Keeping the issue quiet and then demanding a rushed response when the article as done isn’t helpful to people who actually want the issue fixed before it goes public. > If they had requested an extension, I may have considered, but they didn't respond at all. Why would they request an extension when they fixed the issue a day before you tried to contact them? They should have written back and pointed you to the already-released security update, but I can also understand why they aren’t thrilled to engage with someone who is trying to make a mountain out of an issue they had already fixed. reply KibbeWater 2 minutes agorootparent> Why did you wait until the article was ready to be published to inform them? AFAIK the OP did not start writing his article until after they resolved it, which they did within 24 hours. quoting the blogpost now, \"firstly because I hadn't fully thought through the impacts at the time\" The issue was overlooked by OP up until concerns were voiced by other community members which ultimately got the problem patched within 24h of it being noticed. You claim \"the amount of negative spin in the article left a bad taste in my mouth.\", but you seem to be the only one spinning quotes out of context to fit your narrative reply Retr0id 17 minutes agorootparentprev> first discovered it There's more than one issue here, and you're conflating them. If the logging issue was non-public and non-resolved at the time I wanted to publish my article, I'd probably have given them longer. > Why would they request an extension If they thought 1.5 days wasn't enough to provide GPL sources, for whatever reason. I don't see how you can argue that 1.5 days is simultaneously too short, and not in need of an extension. reply Arnavion 1 hour agorootparentprevSure, up to you. In any case I take it they still haven't responded? reply Retr0id 1 hour agorootparentStill no response. reply Aurornis 1 hour agoparentprevIt appears Rabbit had already released an update to address the issue on July 11th, the day before the author asked them for comment. They posted it here https://www.rabbit.tech/security-advisory-071124 > As of 11 July, we’ve made the following changes: > Pairing data can no longer be used to read from rabbithole. It can only trigger actions. > Pairing data is no longer logged to the device. > We have reduced the amount of log data that gets stored on the device. > The Factory Reset option is now available via the settings menu. Customers should use this option to erase ALL data from their r1 prior to transferring ownership. reply lagniappe 1 hour agoparentprevNobody's defending Rabbit here, but that's chickenshit journalism, and it happens too often. reply mynameisvlad 1 hour agorootparentSince when is an individual's personal blog \"journalism\", and therefore expected to live up to that standard? reply gruez 1 hour agorootparentIt might not be \"journalism\", but I think it's pretty reasonable to wait a week for responses before dropping serious accusations It's not exactly a onerous requirement to meet. reply KibbeWater 52 minutes agorootparentMost of what's mentioned in the article is not any new allegations. Rabbit has been berated for their GPL violations for over a month now and the excessive logging was rectified before he even sent in a request for comment. Requesting comments were only a formality to address already voiced concerns reply JoshTriplett 58 minutes agorootparentprevI think it's entirely reasonable to report what you find when you find it, and update later with responses received. reply mynameisvlad 58 minutes agorootparentprevReasonable? Sure. Expected and therefore commented that it's chickenshit when it doesn't happen? Yeah, no. If this were a reputable news outlet, that expectation would be reasonable. reply Retr0id 1 hour agorootparentprevI take it as a compliment! reply clwg 27 minutes agoparentprevYeah, that’s an incredibly short timeframe, done on a Friday with what looks like an 8-hour time difference. Back before bug bounties, the industry mostly coalesced around RFPolicy[0] in terms of security notification and response timelines. Upon establishing initial contact, five business days were given for a response before public disclosure if no response was received. To me five business days seems appropriate if you’re acting in good faith and truly interested in hearing a response. It doesn’t feel like that was the intent; it feels more like a weak attempt to use the lack of response to pile on further. https://packetstormsecurity.com/files/23364/rfpolicy-2.0.txt... reply Retr0id 21 minutes agorootparentTimezone differences were accounted for (see my other reply), and this wasn't the first time they were hearing any of it. It was just the first time I put it into an article. reply jylam 1 hour agoprevIt was surprisingly (or not) hard to find what this \"Rabbit R1\" device was (despite the `I assume by now that most people have heard of the Rabbit R1.`), so here is a paste from Wired: \"The promise was simple. Speak into the device and it'll complete tasks for you thanks to Rabbit's “large action models”—call an Uber, reserve dinner plans via OpenTable, play a song through Spotify, or order some food on DoorDash. Just speak and it will handle it, just like if you handed your smartphone to a personal assistant and asked them to do something for you.\" I don't understand why an app on the phone wouldn't do that, but maybe I'm not hype enough. reply mewse-hn 1 hour agoparentYou really have to watch the Steve Jobs-esque announcement video to understand what they were promising with this device, and understand how utterly it failed to deliver on those promises. https://www.youtube.com/watch?v=22wlLy7hKP4 reply nerdponx 29 minutes agorootparentAre you sure it wasn't always meant to just be a preorder + data harvesting scam? reply codetrotter 1 hour agoparentprevOn iOS the “problem” for a third-party app is that there is no mechanic by which it could always listen to your mic, and trigger actions based on keywords. Only Siri would be able to do that on iOS. Therefore, no third party can “become the platform” on iOS for voice assistants. But who knows. Maybe EU will force Apple to open up for that at some point, like they forced Apple to open up for third party App Stores on iOS in EU. reply aetch 1 hour agorootparentiOS apps can record audio in the background with the provided API already so this isn’t actually a hold up reply danudey 1 hour agorootparentYou can continue to record audio in the background, but you can't use the API to just listen all the time, like \"hey siri\" does, and then open the app and act on it. reply Retr0id 2 hours agoprevShamelessly resubmitting my own article with a slightly more attention-grabbing title ;) reply CoastalCoder 6 minutes agoparentI really appreciate your writing style for the article. It could have been dry, but instead it kept me engaged. reply isodev 2 hours agoparentprevGood call. Thank you for sharing, it’s really quite fascinating. reply mtlynch 2 hours agoparentprevGreat write up! Thanks for putting so much work into this investigation and report. reply traceroute66 2 hours agoparentprev> Shamelessly resubmitting my own.. If everyone shamelessly resubmitted their own stuff.....a.k.a \"please don't delete and repost\" See also the \"don't linkbait; don't editorialize\" rule in relation to titles. ;-) reply mtlynch 5 minutes agorootparentHN explicitly allows reposts: >Are reposts ok? >If a story has not had significant attention in the last year or so, a small number of reposts is ok. Otherwise we bury reposts as duplicates. >Please don't delete and repost the same story. Deletion is for things that shouldn't have been submitted in the first place. https://news.ycombinator.com/newsfaq.html reply Retr0id 29 minutes agorootparentprevThe rules are \"don't delete and repost\", not \"don't repost\" (and this isn't just me rules-lawyering, I believe it's the intended interpretation) reply bloqs 1 hour agorootparentprevRules aside I can see why title iteration can be good, i saw the original and didnt click it, but im glad i did this time reply duiker101 1 hour agorootparentprevHN has actually a page entirely dedicated to posts that went overlooked and are therefore invited to resubmit https://news.ycombinator.com/invited reply yjftsjthsd-h 1 hour agorootparentprev> See also the \"don't linkbait; don't editorialize\" rule in relation to titles I was going to argue that the actual author of the post is allowed to put whatever title they want on their actual article, but the actual article is titled > Jailbreaking RabbitOS (The Hard Way) So... Yeah, actually this submission does seem to go against https://news.ycombinator.com/newsguidelines.html - > Otherwise please use the original title, unless it is misleading or linkbait; don't editorialize. reply Retr0id 1 hour agorootparentIf it's a problem then I'll just edit the original article. The current title (on HN) is objective and accurate, and I received feedback that the original title buries the lede(s) reply digging 1 hour agorootparentGiven the situation, I'd recommend updating the article title, as it's definitely more interesting to someone who hasn't heard of RabbitOS! reply Semaphor 1 hour agorootparentprevEven if it’s not an issue, the title you chose now is simply more information dense as well. It’s all around better. Thanks for the read :) reply yjftsjthsd-h 1 hour agorootparentprevThat seems sensible. Ignoring for a moment the HN guidelines, I agree that the new title is just a better description (I read it... either previously here or from lobsters, but yeah the actual content was good). reply barnabee 1 hour agoprevCool write up! The software looks garbage and the company doesn’t seem great either at this point. But if it’s easy enough to run custom apps on (even/especially) in kiosk mode, I could imagine some pretty interesting use cases for this form factor. Bonus points if you could just slap something together as a PWA too, as then it gets much quicker than programming an ESP32 + battery + screen, and in what looks like s pretty nice self contained unit. Would be nice, ideally to be able to get it running more secure / without any Google services, something like GrapheneOS. Having not looked at what’s out there (yet) does anyone know if people are using them in this way for custom single focus apps or have any pointers? reply iamexcited 1 hour agoprevlol! I worked at Rabbit and left after reading through the codebase and being gaslit by the execs reply krukah 1 hour agoparentIf you don't mind sharing, what were some of the first red flags that you noticed in the codebase? Looking at all these jailbreaks and vulnerabilities visible from the outside, I'm sure they only scratch the surface. reply rideontime 1 hour agoparentprevWell? Aren't you going to spill some juicy details about the supposed \"large action model\"? reply Retr0id 1 hour agorootparentI believe the juicy details are \"It's a marketing term for getting off-the-shelf LLMs to call out to pre-written browser automation scripts\", but I'd love to hear it from the horse's mouth. reply Aurornis 57 minutes agoprevGood writeup on the process, but the amount of negative spin in the article left a bad taste in my mouth. He says he didn't bother reporting the issue at first (!) but then later criticizes Rabbit for not responding to his July 12th e-mail in less than 2 business days. However, Rabbit had already fixed the issue and released a security advisory on July 11th, a day before he finally decided to contact them. You can see their security advisory on their website, dated July 11th ( https://www.rabbit.tech/security-advisory-071124 ) To be fair, the post does bury this at the very end of the article, but it spends most of the opening sections talking about how much it \"sucks\" and leans heavily on the logging issue and their lack of response before eventually admitting that it was already fixed. > As of 11 July, we’ve made the following changes: > Pairing data can no longer be used to read from rabbithole. It can only trigger actions. > Pairing data is no longer logged to the device. > We have reduced the amount of log data that gets stored on the device. > The Factory Reset option is now available via the settings menu. Customers should use this option to erase ALL data from their r1 prior to transferring ownership. reply wmf 51 minutes agoparentThere's an acrimonious relationship between Rabbit and hackers and both sides seem to keep escalating. reply bigstrat2003 27 minutes agoprevI have, in fact, not heard of the Rabbit R1. And the link in TFA leads to some weird promo video instead of something informative. Does anyone have a succinct explanation of what the article is talking about? Edit: nm, I commented before reading other comments. Anyone else confused should read jylam's comment explaining. reply openplatypus 19 minutes agoprevAn AI company stealing from others? That's a first. /Sarcasm reply usr1106 46 minutes agoprev> On July 12th, I asked Rabbit Inc. if they had any comments to make on the content of this article, > As of the end of July 15th, they have not responded. Their lawyers are considering the options how to sue you. reply schmookeeg 45 minutes agoprevI'm enjoying reading this, and I never paid much attention to the R1 product. \"Carroot\" was enough of a chuckle to merit the rest. :D reply OsrsNeedsf2P 1 hour agoprev> I could also build an entire custom kernel from source, but Rabbit Inc. has chosen to violate the GPL2 license and not make the sources available. Of particular note are their drivers for hall-effect scroll wheel sensing, and camera rotation stepper motor control, which are closed-source and yet statically linked into the GPL'd kernel image. Violations like this are hugely destructive to the free software ecosystem, from which companies like Rabbit Inc. benefit. GPL requires you to disclose the license and source code on request, but Truth Social got away with not disclosing the license until someone realized they were using AGPL code, and only then released the source. I wonder if Rabbit will slip by doing the same. reply taylorbuley 58 minutes agoprevThis company is definitely wading through the trough of disillusionment. Excited what root on the device could open up. I have been disappointed in its hackability; however, the joy I receive when watching my 10 year old dive into a topic of his choice with this neon orange LLM is worth far more to me than the $200 for my R1. During these summer months I let him stay up late with this as his only glowing screen and he basically uses it like I used Encyclopedia Brittanica, except much more deeply and with more interesting subjects. I think it's a great little piece of purpose-driven hardware. I dropped my own ChatGPT subscription and use this if I need to do some heavy lifting. I know it won't last forever, but it will last until the company goes bottom-up -- and longer if we get more boottime control through tools like this. reply pmdr 1 hour agoprev [–] Why do people still care about failed garbage? reply sqeaky 1 hour agoparentThis is a large scam and we are curious to see what will happen. If they aren't sued, fined, imprisoned, court-ordered, or otherwise dealt justice it means something very toxic for tech as an industry. And if they are the drama will be fun. You may as well ask \"why do people like sports?\", people are emotionally invested and that is enough. reply whywhywhywhy 1 hour agorootparentBeing a bad product or poorly engineered doesn't make something a \"scam\". There is an actual real NFT scam in this story before Rabbit though if you dig. reply sqeaky 52 minutes agorootparentThey lied, they promised X and delivered Y. That is a scam. To expand on this, this isn't just a truth stretching. They didn't deliver X-1, they delivered rubbish. This isn't a tire that self heals small holes but doesn't live up to the commercial, this isn't another energy drink promising 5 hours of alertness and giving you caffeine jitters. These devices are just garbage, these are like essential oils or magic crystals promising to cure a disease or otherwise perform and simply not. They promised categories of features and faked demos so they knew it couldn't do X when they sold it. But even worse, this device cannot do anything useful. This can't do A through W, I will grant it Y and Z because it boots and doesn't catch fire. But even worse, this device tracks way too much and that might be leaked harming you. There is no coherent way to claim this is not a scam in every sense of the word. And coming from people who committed other scams doesn't make this not one by comparison. reply nicce 1 hour agorootparentprevSee the other comment about data harvesting reply 0xTJ 1 hour agoparentprevBecause there are sometimes interesting things that get thrown in the garbage. The author clearly doesn't care about the product as a product (otherwise they'd have bought one new, and this article would be completely different), they care about it as a technical puzzle, with secrets to uncover. reply Retr0id 1 hour agoparentprevI find the ways in which things work less interesting than the ways in which they do not. reply yjftsjthsd-h 1 hour agoparentprevReverse engineering is often interesting independently of whether the actual device was interesting. reply dole 1 hour agoparentprevPossibly useful hardware components or package for cheap. reply slashdave 1 hour agoparentprevThere is usually something important to learn from other people's failings reply ssl-3 1 hour agoparentprev [–] Why do people care what others care about? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "David Buchanan has developed a \"tethered jailbreak\" for the Rabbit R1, allowing root access without unlocking the bootloader or altering internal storage.",
      "The Rabbit R1, using a MediaTek MT6765 SoC, has been criticized for extensive user data logging and GPL violations, which were partially addressed in a recent update.",
      "Buchanan's findings reveal that RabbitOS is a heavily modified Android 13 AOSP, primarily enforcing a single-app kiosk mode, and he has released a tool to aid further exploration of the device."
    ],
    "commentSummary": [
      "Jailbreaking RabbitOS has revealed secret logs and potential GPL (General Public License) violations, raising privacy and legal concerns.",
      "Logs include sensitive data such as precise GPS locations, WiFi network names, IDs of nearby cell towers, and user tokens, some of which are sent to Rabbit's servers.",
      "Rabbit Inc. released an update (v0.8.112) addressing these logging issues, but the controversy highlights ongoing concerns about data privacy and transparency in tech products."
    ],
    "points": 326,
    "commentCount": 82,
    "retryCount": 0,
    "time": 1721234498
  },
  {
    "id": 40983734,
    "title": "The Greatest Educational Life Hack: Learning Math Ahead of Time",
    "originLink": "https://www.justinmath.com/the-greatest-educational-life-hack-learning-math-ahead-of-time/",
    "originBody": "The Greatest Educational Life Hack: Learning Math Ahead of Time by Justin Skycak on January 13, 2024 Learning math early guards you against numerous academic risks and opens all kinds of doors to career opportunities. This post is part of the book The Math Academy Way: Using the Power of Science to Supercharge Student Learning (Working Draft, Jan 2024). Suggested citation: Skycak, J., advised by Roberts, J. (2024). The Greatest Educational Life Hack: Learning Math Ahead of Time. In The Math Academy Way: Using the Power of Science to Supercharge Student Learning (Working Draft, Jan 2024). https://justinmath.com/the-greatest-educational-life-hack-learning-math-ahead-of-time/ Why learn math ahead of time? Because it guards you against numerous academic risks and opens all kinds of doors to career opportunities. Minimizing Risk You know how, when you take a language class, there’s often a couple kids who speak the language at home and think the class is super easy? You can do that with math. When you pre-learn the material in a math course before taking it at school or college, you’re basically guaranteed an A in the class. You guard yourself against all sorts of risks such as the course moving too quickly, brushing over concepts, explaining things poorly, assuming knowledge of important but frequently missing prerequisite material, not offering enough practice opportunities, ... There are a hundred different ways to teach a class poorly, and most classes suffer in at least a handful of those aspects. This is especially helpful at university, when lectures are often unsuitable for a first introduction to a topic. But if you pre-learn the material, you’re not depending on the teacher to teach it to you, which means you’re immune to even the worst teaching. Opening Doors Of course, the natural objection is “won’t you be bored in class?” – but if you do super well in advanced classes, especially at university, then that opens all kinds of doors to recommendations for internships, research projects with professors, etc. It doesn’t matter whether you’re doing super well because you’re learning in real-time or because you pre-learned the material. When you blow a course out of the water while also interacting with the professor, that sets you up for a great recommendation letter – which is vital not just for high schoolers applying to college, but also for college students applying to summer research programs and graduate schools. Plus, it can open the door to working on a research project with the professor, or having them connect you to jobs, internships, and other opportunities with people in their network. Basically, you can use pre-learning to kick off a virtuous cycle. Even if you aren’t a genius, you appear to be one in everyone else’s eyes, and consequently you get a ticket to those opportunities reserved for top students. Students who receive and capitalize on these opportunities can launch themselves into some of the most interesting, meaningful, and lucrative careers that are notoriously difficult to break into. Why Stop at Pre-Learning One Year Ahead? Many people think calculus is the “end of the road” for math, and that it doesn’t matter if you get there many years ahead of schedule. But that’s far from the truth! There are even more university-level math courses above calculus than there are high school courses below calculus. After a single-variable calculus course (like AP Calculus BC), most serious students who study quantitative majors like math, physics, engineering, and economics have to take core “engineering math” courses including Linear Algebra, Multivariable Calculus, Differential Equations, and Probability & Statistics (the advanced calculus-based version, not the simpler algebra-based version like AP Statistics). Beyond those core “engineering math” courses, different majors include plenty of specialized courses that branch off in various ways. There are so many courses that a student could not fit them all into a standard 4-year undergraduate course load even if they overloaded their schedule every year – however, the more of these courses a student is able to take, the more academic opportunities and career doors are open to them in the future. (While it’s true that students don’t need to know much beyond algebra to get a job in fields like computer science, medicine, etc. – the people in such fields who do also know advanced math are extra valuable and in demand because they can work on projects that combine domain expertise and math.) Maximizing Reward: Learning A Lot of Advanced Math Ahead of Time When a student learns a lot of advanced math ahead of time, they unlock the opportunity to delve into a wide variety of specialized fields that are usually reserved for graduates with strong mathematical foundations. This fast-tracks them towards discovering their passions, developing valuable skills in those domains, and making professional contributions early in their career, which ultimately leads to higher levels of career accomplishment. I’m not exaggerating here – this is actually backed up by research. On average, the faster you accelerate your learning, the sooner you get your career started, and the more you accomplish over the course of your career. For instance, in a 40-year longitudinal study of thousands of mathematically precocious students, researchers Park, Lubinski, & Benbow (2013) concluded the following: \"The relationship between age at career onset and adult productivity, particularly in science, technology, engineering, and mathematics (STEM) fields, has been the focus of several researchers throughout the last century (Dennis, 1956; Lehman, 1946, 1953; Simonton, 1988, 1997; Zuckerman, 1977), and a consistent finding is that earlier career onset is related to greater productivity and accomplishments over the course of a career. All other things being equal, an earlier career start from [academic] acceleration will allow an individual to devote more time in early adulthood to creative production, and this will result in an increased level of accomplishment over the course of one's career. ... [In this study] Mathematically precocious students who grade skipped were more likely to pursue advanced degrees and secure STEM accomplishments, reached these outcomes earlier, and accrued more citations and highly cited publications in STEM fields than their matched and retained intellectual peers.\" Higher Math, Not Competition Math To be clear: in all this discussion about learning advanced math, I’m talking about higher-grade math, not grade-level competition problems. When a middle or high school teacher has a bright math student, and the teacher directs them towards competition math, it’s usually not because that’s the best option for the student. Rather, it’s the best option for the teacher. It gives the student something to do while creating minimal additional work for the teacher. Competition math problems generally don’t require students to learn new fields of math. Rather, the difficulty comes from students needing to find clever tricks and insights to arrive at solutions using the mathematical tools that they have already learned. A student can wrestle with a competition problem for long periods of time, and all the teacher needs to do is give a hint once in a while and check the student’s work once they claim to have solved the problem. But if you look at the kinds of math that most quantitative professionals (like rocket scientists and AI developers) use on a daily basis, those competition math tricks show up rarely, if ever. What does show up everywhere is university-level math subjects like linear algebra, multivariable calculus, differential equations, and (calculus-based) probability and statistics. Given that most students who enjoy math end up applying math in some other field (as opposed to becoming pure mathematicians), it would be more productive for them to get a broad view of math as early as possible so that they can sooner apply it to projects in their field(s) of interest. Of course, the countering view is that “students should go ‘deep’ with the math that they’ve already learned – they’ll learn the other math subjects when they’re ready.” But, in practice, the second part of that claim is not true. There are so many other math subjects that even most math majors only learn a tiny slice of all the math that’s out there. Students generally can’t learn other math subjects “on the job” after graduation, either – if you’re trying to solve cutting-edge problems that nobody has solved before, then there is no “known path” that can tell you what additional math you need. And to even realize that a field of math can help you solve your problem, you generally need to have learned a substantial amount of that field in the first place. In practice, the only way for students to “learn the other math subjects when they’re ready” is to learn as much math as possible during school. Developmental Appropriateness Many people think that learning math early is not appropriate for students’ social/emotional and cognitive/academic development. But the reality is that educational acceleration does not lead to adverse psychological consequences in capable students. I realize that if you’re skeptical about this, you’re probably looking for some empirical evidence to the contrary, not just a logic/reasoning-based argument. So let’s dive into the research. According to a study titled Academic Acceleration in Gifted Youth and Fruitless Concerns Regarding Psychological Well-Being: A 35-Year Longitudinal Study that followed thousands of accelerated students throughout their lives over the course of 35 years (Bernstein, Lubinski, & Benbow, 2021): \"The amount of educational acceleration did not covary with psychological well-being. Further, the psychological well-being of participants in both studies was above the average of national probability samples. Concerns about long-term social/emotional effects of acceleration for high-potential students appear to be unwarranted, as has been demonstrated for short-term effects. ... These findings are consistent with research on the effects of academic acceleration on psychological well-being. That is, there is little evidence that academic acceleration has negative consequences on the psychological well-being of intellectually talented youth (Assouline et al., 2015; Benbow & Stanley, 1996; Colangelo et al., 2004; Gross, 2006; Robinson, 2004). ... These findings do not support the frequently expressed concerns about the possible long-term social and emotional costs of acceleration by counselors, parents, and administrators. ... Those who were accelerated had few regrets for doing so. Indeed, if anything, they tended to wish that they had accelerated more.\" Whether a student is ready for advanced mathematics depends solely on whether they have mastered the prerequisites. If a student has mastered prerequisites, then it is appropriate for them to continue learning advanced math early, and not appropriate to stunt their development by holding them back. As the study authors note: \"Many fear negative possibilities of moving a gifted child to a more advanced class. Yet it also is important to consider the negative possibilities of holding children back in classes aiming to teach subject matter that they have already mastered (Benbow & Stanley, 1996; Gross, 2006; Stanley, 2000). Choosing not to accelerate is as much of a decision as choosing to do so ... This is particularly important given the extensive empirical literature showing positive effects of acceleration on academic achievement (Kulik & Kulik, 1984, 1992; Lubinski, 2016; Rogers, 2004; Steenbergen-Hu et al., 2016) and creativity (Park et al., 2013; Wai et al., 2010). ... Presenting students with an educational curriculum at the depth and pace with which they assimilate new knowledge is beneficial. Other studies have shown that academic acceleration tends to enhance professional and creative achievements before age 50 (Park et al., 2013; Wai et al., 2010).\" Numerous other studies on the long-term effects of educational acceleration have drawn similar conclusions. As Wai (2015) summarizes: \"...[F]or many decades there has been a large body of empirical work supporting educational acceleration for talented youths (Colangelo & Davis, 2003; Lubinski & Benbow, 2000; VanTassel-Baska, 1998). Although neglecting this evidence seems increasingly harder to do (Ceci, 2000; Stanley, 2000), putting research into practice has been challenging due to social and political forces surrounding educational policy and implementation (Benbow & Stanley, 1996; Gallagher, 2004; Stanley, 2000). ... The educational implications of these studies are quite clear. They collectively show that the various forms of educational acceleration have a positive impact. The key is appropriate developmental placement (Lubinski & Benbow, 2000) both academically and socially. ... Educational acceleration is essentially appropriate pacing and placement that ensures advanced students are engaged in learning for life. Every student deserves to learn something new each day (Stanley, 2000). The evidence clearly supports allowing students who desire to be accelerated to do so, and does not support holding them back. ... [T]he long-term studies reviewed here show that adults who had been accelerated in school achieved greater educational and occupational success and were satisfied with their choices and the impact of those choices in other areas of their lives.\" As researcher James Borland (1989, pp.185) sums it up: \"Acceleration is one of the most curious phenomena in the field of education. I can think of no other issue in which there is such a gulf between what research has revealed and what most practitioners believe. The research on acceleration is so uniformly positive, the benefits of appropriate acceleration so unequivocal, that it is difficult to see how an educator could oppose it.\" But Why Does the Myth of Developmental Inappropriateness Persist? At this point, you might wonder why so many people think that academic acceleration is developmentally inappropriate given all the research to the contrary. What’s going on? Do they disagree with the research? Are they simply unaware? It becomes pretty clear if you look at the incentives. Acceleration requires extra work, but people typically don’t like to do extra work, so they will gladly rationalize that the extra work wouldn’t have really helped them anyway, even if their rationale is incorrect. Now, you might ask, what about schools? Isn’t it in their job description to get their students to work? If accelerating their capable students will lead to beneficial outcomes, wouldn’t they be pushing it, or at least, not discouraging it? The problem is that acceleration is also very inconvenient to schools. In schools, each grade typically progresses through the math curriculum in lockstep, which means that accelerated students would need to be placed in above-grade courses. This can lead to major logistical challenges. For instance, if above-grade course is not offered by the school (which would certainly be the case for accelerated 5th graders in elementary schools, 8th graders in middle schools, and 12th graders in high schools), then either the students would need to take the class at another school (which introduces transportation, scheduling, and administrative issues) or the school would need to hire a teacher who is capable of teaching the higher-grade material (and it's hard enough for schools to hire teachers who are capable of teaching grade-level mathematics). And even if the above-grade course is offered by the school, there may be schedule conflicts with grade-level courses that mathematically accelerated students still need to take. (Course schedules are typically optimized to minimize conflicts within grade levels, but not across grade levels.) Besides logistical issues, there are other factors that can disincentivize acceleration and lead the myth to be perpetuated out of convenience. As Steenbergen-Hu, Makel, & Olszewski-Kubilius (2016) describe: \"[E]ducation administrators may have perverse incentives to avoid acceleration. For example, although acceleration can often actually save schools money because students spend fewer years in school, it can also 'cost' schools money. Because school funding is often allocated based on headcounts and accelerated students spend fewer years in school, schools receive fewer dollars overall, or in the case of dual enrollment, may have to spend some of those dollars outside the district. Similarly, in states that offer open enrollment, students could leave a district for one where their needs are better met. Moreover, in the age of accountability via test score performance, keeping students who could be accelerated with their same-age peers can boost average test scores, regardless of whether the students are learning.\" Even in schools that do offer acceleration, typically only a small portion of students per grade are accelerated. Given how many logistical challenges and other disincentivizing factors there are, how few students are typically accelerated, and how easy it is to imagine a young student struggling socially when they are placed in a class with older students away from age-level friends, it is not surprising that the myth persists. References Bernstein, B. O., Lubinski, D., & Benbow, C. P. (2021). Academic acceleration in gifted youth and fruitless concerns regarding psychological well-being: A 35-year longitudinal study. Journal of Educational Psychology, 113(4), 830. Borland, J. H. (1989). Planning and Implementing Programs for the Gifted. New York: Teachers College Press. Park, G., Lubinski, D., & Benbow, C. P. (2013). When less is more: Effects of grade skipping on adult STEM productivity among mathematically precocious adolescents. Journal of Educational Psychology, 105(1), 176. Steenbergen-Hu, S., Makel, M. C., & Olszewski-Kubilius, P. (2016). What one hundred years of research says about the effects of ability grouping and acceleration on K–12 students’ academic achievement: Findings of two second-order meta-analyses. Review of Educational Research, 86(4), 849-899. Wai, J. (2015). Long-term effects of educational acceleration. A nation empowered: Evidence trumps the excuses holding back America’s brightest students, 2, 73-83. This post is part of the book The Math Academy Way: Using the Power of Science to Supercharge Student Learning (Working Draft, Jan 2024). Suggested citation: Skycak, J., advised by Roberts, J. (2024). The Greatest Educational Life Hack: Learning Math Ahead of Time. In The Math Academy Way: Using the Power of Science to Supercharge Student Learning (Working Draft, Jan 2024). https://justinmath.com/the-greatest-educational-life-hack-learning-math-ahead-of-time/ Tags: Blog (Tier 1), Math Education Previous Next",
    "commentLink": "https://news.ycombinator.com/item?id=40983734",
    "commentBody": "The Greatest Educational Life Hack: Learning Math Ahead of Time (justinmath.com)171 points by harperlee 10 hours agohidepastfavorite130 comments supertofu 4 hours agoI was a late bloomer in almost every arena of my life. Developing social skills, having relationships, developing an identity independent of my family, etc. I'm also a late bloomer to mathematics. I'm in my 30s and getting a bachelor's degree in Math now after a lifetime of math-phobia. Math was my worst subject because it never came easily or naturally to me, and so I assumed I must have been innately incapable of it. I didn't take a single math class during my first bachelor's degree. I sure wish I could have learned math properly earlier in life, but my point with this comment is that it is never too late to learn math. Learning mathematics \"late\" over the last couple of years has enriched my life in so many ways. Learning to write proofs has brought a sense of organization and calm to many other areas of my life. Complex problems and challenges in life feel so much more approachable, because I am much more skilled now in breaking down tasks to manageable components. I can see now how mathematics has influenced programming languages and computer science, and every time I can identify the mathematical underpinning of some program I use or write, I feel like I am peering into the heart of the universe. Learning math early is a great hack, but so is learning math late :) reply chikenf00t 4 hours agoparentHow were you able to learn math later in life? I'm terrible at math and I know it causes my work to suffer. reply nextos 7 minutes agorootparentYou can start simple. Read Basic Mathematics by Serge Lang and do all exercises. Solutions are included. That book basically covers all mathematics up to junior high in a rigorous but approachable fashion. Serge Lang was a great mathematician. Then you move to logic, calculus, linear algebra and probability. Afterwards, focus on more specific areas that interest you. Springer Undergraduate Texts in Mathematics and Dover have lots of elegant and concise textbooks that can help you. At the beginning, the key is to move slowly and build some solid foundations. reply grepLeigh 3 hours agorootparentprevSimilar to the OP, I had a lot of anxiety around math and academic performance. I dropped out of college at 18 and the highest math class I took was in high school (pre-calc), which I almost failed. At age 33, I enrolled in community college and took Calc I-III, Linear Algebra, and Differential Equations. The community college hosts weekly \"math jams\" and offers free 1:1 tutoring. I'm currently taking a Discrete Math and Probability class at UC Berkeley for fun this summer (CS70), which would have seemed absurd just a few years ago. The community college system in California is extraordinary; I'm glad I got to experience it first-hand. reply Loughla 1 hour agorootparentDescribe the math jams, if you would please. Is this just open tutoring labs for all areas of math? Or is it something different? reply 2snakes 3 hours agorootparentprevI am planning to use Math Academy after my Master's degree. I did a beta and it was awesome, just wish I had taken more notes. reply moralestapia 3 hours agorootparentprevMy two cents. Math it's way easier than you think it is, it greatly depends on how you approach it. I really like the style of Robert Ghrist videos on YouTube. A great tutor/video goes a long way. I wish I could share some resources but am a bit outdated on that. The overall idea is that some people can explain math concepts in a very clear and straightforward way, while some others will write up a bunch of symbols and let you figure them out. Avoid the latter. As a note, those are usually the lowest performers in academia, lol. reply RealityVoid 2 hours agorootparentYou learn math best by doing math. Sure, good explanations help, but sometimes dry rigorous ones are preferable since it asks you to grapple with the subject. reply moralestapia 1 hour agorootparent>sometimes dry rigorous ones are preferable My experience with the comments in this thread, the overwhelming majority of people I know IRL and the widespread sentiment that \"Math is hard\" does not seem to reflect that. reply factorymoo 3 hours agoprevI went to the most prestigious high school in France. The top 2 students in my maths class shared one thing in common: they would study the curriculum the summer before. I did it one summer, and while I was nowhere near as good as them - something magical happened: even though I hadn't understood all the concepts, my ability to understand the concepts during the class went way up. It was easier to follow what the teacher was saying since no concept was totally new to my mind. reply raybb 2 hours agoparentDid that make it feel more or less boring? reply factorymoo 2 hours agorootparentTo me less boring. I used to struggle to understand new concepts as they were presented. That year though, I was able to follow what the teacher was saying \"live\", ask interesting questions to deepen my knowledge. reply djeastm 1 hour agorootparentprevIt'd be what you made it. I went back for a CS degree long after having coded for years and there were certainly things I would have had to sit around and wait for others to catch up on if I let it. But instead I always pushed myself to build much more sophisticated versions of the basic things we were learning and I also tutored, which is where it really becomes not boring, because you get to see how other people learn things in different ways, which broadens your own perspective, as well. So basically I'm just trying to say it's up to you to make things not boring reply exe34 2 hours agorootparentprevIt was like that with physics for me in high school. At ages 11-13 we learnt a bunch of stuff, which nobody except I paid any attention to, and then we had to do it all again, exactly the same stuff, for ages 14-15 to prepare for GCSEs. I was horribly bored, but at one point I was lucky enough that the teacher just gave me A-level and then early uni stuff to figure out, so that kept me busy. then first year of uni was horribly boring again, which led me to be over-confident, and didn't do much work in second year, but thankfully I managed to pick up the slack in 3rd and 4th year of uni. reply rodolphoarruda 5 hours agoprevIf you are native speaker of any language different from English, the greatest educational life hack is to learn English at the earliest time. It opens one's mind and allows access to content and communication at a global level. reply M4v3R 4 hours agoparentAnd if you’re a non-English parent but speak English consider talking to your child in English from the very beginning. There are many different ways to approach this, one relatively simple way is to have one parent speak their native language while the other speaks English (called “one parent one language”). Even if your pronunciation isn’t perfect it will still yield very good results. Source: I’m a parent of a 3yo who now understands speaks both English and Polish. Me and my wife are Polish and only I speak English. Apart from speaking we also use English audio in all TV content she watches and buy books that contains both English and Polish text. Edit: as pointed out below I should’ve clarified that this applies when you live in a non-English country where your child does not have any other way to learn English (over here you can’t really learn English in schools - not enough hours, plus it starts way too late anyways). reply noisy_boy 3 hours agorootparent> And if you’re a non-English parent but speak English consider talking to your child in English from the very beginning. If you are living in a place where people don't speak your mother tongue but English is spoken everywhere and is the main medium of education, don't do this. The kids will pick-up English anyway because they will be exposed to it for 8 hours daily at school but if you don't speak with them in your mother tongue, they will never pick it up. The older they get, the harder it is. First hand experience. reply rtkwe 3 hours agorootparentThey need English at home too, a lot happens in those early years where there's no schooling and it'd be way better to know English well going into school (what ever level that happens to be at) too. reply querez 2 hours agorootparentMy daycare has a lot of non-native people who do not speak the local, native language with their child, at all. Still, all children (age 3, they're usually in daycare since age 1) speak the local language fluidly, thanks to how much they they spend in daycare. reply lbrito 3 hours agorootparentprevI would say the opposite; talk to your child only in your native language. Kids will learn English by themselves in school anyway, and if they don't learn your language from you, they for sure won't learn it elsewhere. Source: as a kid I was in that situation, at first my parent spoke only in English with me and I started to forget Portuguese. After my parents realized that they pivoted to speaking Portuguese. I learned English fine at school and never had problems with either languages. Now I'm a parent of a 2yo and 1yo and am speaking Portuguese with both. reply M4v3R 3 hours agorootparent> Kids will learn English by themselves in school anyway If you live in an English speaking country then sure. Over here it’s almost impossible to learn English in school, you only get a few hours per week of English classes. reply rtkwe 3 hours agorootparentprevDo be mindful of the kid though. One of my wife's coworkers wanted to teach their kid multiple languages, I think the final count was 4 total (they wanted both the parent's native tongues, German which is where they were going to live after their visas expired in the US and of course English), while living in the US and it just made the kid confused and angry. Granted that's way more than just doing two but it could still back fire with the kid if it's too much. reply et-al 4 hours agorootparentprevI would clarify this is for parents residing in non-English speaking countries. Because over here in the States folks are doing the opposite: spending thousands a month to send their children to language immersion schools to not speak English. reply qsort 4 hours agoparentprevAs a non-native English speaker, this. Native English speakers are reluctant to give this advice, but it's the lingua franca of any field that matters. Not being able to communicate effectively will definitely be a blocker. reply smokel 3 hours agorootparentUsing the term \"lingua franca\" for English demonstrates, twice, that this is only a temporary phenomenon. reply qsort 3 hours agorootparentSince Eve ate that apple pretty much everything is a \"temporary phenomenon\". reply umanwizard 50 minutes agorootparentprevEnglish will almost surely still be the dominant world language for as long as any of us is alive. reply ptmcc 2 hours agorootparentprevOk, yes, and? English is the dominant language now and for the foreseeable future. Some day that may change but it won't be overnight. reply runiq 2 hours agoparentprevAnother reason to learn English ASAP is because the orthography is pants-on-head stupid. Your young self will not have a reference system for just how pants-on-head stupid it is and happily accept it without giving it a second thought. If you are learning English later in life, you will struggle. reply rcbdev 1 hour agorootparentI'd argue some pants-on-head stupid declinations and arbitrary genders for every noun is a much more compelling reason to learn a language early than orthography. English is probably one of the dead simplest languages of use to learn later in life. reply gwervc 4 hours agoparentprevHeck no, I'd rather protect my (future) kids from a lot of ideas spreading in the English speaking sphere until they reached some given age. There's enough cultural, scientific and entertainment content in French and Chinese to fill one's mind until adolescence. reply rcbdev 1 hour agorootparentThis. Most money is spent in manipulating English media. Only fractions for other languages. It makes a difference. reply CrazyStat 5 hours agoprevI’m going to push back on the advice to learn higher grade math rather than competition math, as I feel the author is ignoring an important skill that competition math helps develop. They allude it in passing: > A student can wrestle with a competition problem for long periods of time, and all the teacher needs to do is give a hint once in a while and check the student’s work once they claim to have solved the problem. Wrestling with a problem for long periods of time is not just a convenience for the teacher, it is a skill that will serve students well for decades to come. Sitting with a problem that you don’t know how to solve for hours, trying various approaches, failing and failing and trying again, is a life skill that learning calculus two years early won’t teach you. Many of the tactics used in competition problems are also useful in general quantitative situations: identifying symmetries, invariant quantities, properties that can only increase under perturbations. reply qsort 4 hours agoparentConflict of interest since I was very much into competition math in high school, but I definitely agree that at the HS level it's just about the best thing you can do. It develops your mathematical maturity in ways that simply front-loading calculus or linear algebra won't. A LOT of competition alumni go on to become great academics or successful professionals. And just by the way: competition math is definitely \"higher math\" in a lot of cases. To be competitive at a decent level you have to know stuff like \"real\" algebra (groups, fields, etc., stuff like Burnside's lemma is pretty much table stakes), vectors, barycentric coordinates and so on for geometry problems, how to handle recursion for combinatorics, generating functions etc. It's by no means only silly tricks. reply conductr 2 hours agoparentprevGood advice but not good general advice. This will benefit some but many more people will get frustrated and learn to dislike math. reply CrazyStat 2 hours agorootparentThis is not my experience. If they see the task as “solving the problem is success and anything else is failure,” like they might be used to from most school math classes, sure. If you set up the context properly my experience is that most kids enjoy working on hard math puzzles. reply conductr 2 hours agorootparentPerhaps on basic math with younger kids but I expect this will hit a wall at a certain level. Or, the audience of kids doing this is already a skewed/biased sample of kids that just love math (or it's parent driven) reply zozbot234 3 hours agoparentprev> Wrestling with a problem for long periods of time is not just a convenience for the teacher, it is a skill that will serve students well for decades to come. And one of the best ways of developing that skill is... learning higher-level math. This can also include 'competition math' topics of course, but they should be approached as self-contained subjects of their own, not just as a bundle of disconnected \"tricks\" to be applied solely in a competition- or puzzle-solving context. reply CrazyStat 2 hours agorootparentDepending on how the course is set up, maybe. Most math courses are not set up to make students wrestle with problems for extended periods of time, even through University level. I took courses in topology and number theory in undergrad that were set up this way—the professor did almost no lecturing; we were given a series of results to prove and expected to wrestle with them ourselves (mostly alone as homework). Once you thought you had a proof you presented it to the class. But this is very atypical. Your typical calculus or differential equations or linear algebra course does not develop this skill. reply alephnerd 4 hours agoparentprevI did competition math in middle and high school, and the only reason I was able to build the base needed to do decently in the AMC, AIME, and CEMC was because I was introduced to various concepts in math much earlier than when American or Canadian curricula would introduce them. Competition math becomes a zero sum game when you are competing with students who have both built strong fundamentals AND then concentrated on technique and problem solving. You can't run if you can't walk. > failing and failing and trying again, is a life skill that learning calculus two years early won’t teach you But learning Calc for 2 years, and getting a 5 on the AP Calc BC exam means you can take 2 additional courses in college or graduate early. > Many of the tactics used in competition problems are also useful in general quantitative situations Agreed. But at the end of the day, the kids getting into AIME or USAMCO were already doing high school or even college level math by 9th grade reply bee_rider 4 hours agorootparentI actually did learn how to run before I learned how to walk. It caused my parents all sorts of stress. I guess, though, there’s room to quibble about where controlled falling forward is really running. Anyway, it seems like a shame that there’s a problem solving strategy beyond fundamentals for competitive math. What makes the puzzles in the game different from the sort of typical math somebody in STEM might do? reply zozbot234 3 hours agorootparentWalking is just as much \"controlled falling forward\" as running is, it's just slower. reply CrazyStat 4 hours agorootparentprevYou don't have to \"do decently\" or worry about beating students who are already doing college level math, though. You can just do it for \"fun\" (and learning value). It may be a zero sum game if the outcome you're concerned with is beating other people, but that doesn't need to be the objective. reply TuringNYC 4 hours agoprevIf you go to any of the wealthy or upper-middle-class suburbs, especially those with large immigrant populations, you'll see half the students secretly doing this, whether it is via Kumon or RSM or something else. In many ways it skews the ratings of the schools because they can be lazy and not teach as well...but still show great school average scores, since so many kids are already enriching externally. Before you know, the school is just a motion and the real learning is at home. I suppose it is idealistic to think teachers \"should\" teach well, of course, since in reality not all do. reply kjkjadksj 2 hours agoparentTrue for college math too. I took calculus for the first time in my life in college. Half the class had it in high school, half of those students took AP calc. Exams were so brutal for those of us taking it for the first time especially. Nothing could have prepared me for them. The lecturer would schedule a two hour block outside of class and the exam was 7 very challenging questions. Most of us would not finish before the 2 hours were up. Class averages were in the 50% range. I took my C and moved on with my life never needing to do calculus by hand ever again. reply rawgabbit 2 hours agorootparentMy son did \"Business Calculus\" at a large state university. I have a masters in science and had taken many quite difficult math courses in my day. I looked at what he was asked to do and saw his exam papers. Needless to say \"Business Calculus\" had little to do with business and a lot to do with making math as difficult as possible. The class average was a C and I believe many of the students had taken AP calculus in high school. It was one of the courses whose purpose was not to teach but to prop up the university-industrial complex. EDIT. Below is an example (not from his instructor but the same material). Remember this is for \"business calculus\". It just seems like silly math tricks to me. https://people.tamu.edu/~jdkim/math142fall2019/math142week11... reply Acrobatic_Road 50 minutes agorootparentjust glancing over this pdf it doesn't seem so bad. The first couple of problems are just integrations with some very obvious u-substitutions. reply conductr 2 hours agoparentprevEducation is a part of culture. The American culture is one that doesn't actually value education. It's one of shortcuts and minimum effort and coasting by checking the boxes along the way to a decent enough paying job, or so we hope. We place value on our social lives much more so. Eg. popularity, sports, fraternities, \"the college experience\", etc reply sharadov 2 hours agoparentprevI send my kids to Singapore Math, because the math curriculum and how they teach math is lacking - it's superficial, they gloss over the concepts. In schools my kids look at a worked example, then solve problems that very closely follow that example, repeating all the same steps with different numbers. In Singapore math, students must think through the concepts and apply them in new ways from the very start. reply alephnerd 4 hours agoparentprev> any of the wealthy or upper-middle-class suburbs Working class too if you're Asian American. Asian American kids in SF public schools and the closest suburbs (eg. Daly City, SSF) skewed working class but the parents would also push their kids to attend Kumon or cram schools. Same story in working class Asian neighborhoods of SoCal and Boston like SGV or Quincy+Malden respectively. reply gjvc 4 hours agoparentprevWhat is the preferred choice between Kumon and Russian School of Mathematics? reply dh2022 1 hour agorootparentI sent my son to both of them and I prefer RSM by far. Kumon to me was rote learning - lots of very similar problems. My son did not last even the first semester. My son then attended RSM from first grade. RSM instruction started from problems like \"there are 3 birds on a branch. 1 bird leaves. how many birds are now on the branch\" and progressed onward. By grade 7 he is learning logarithms and, at a very basic introductory level, abstract concepts such as function (by function I mean the real definition of a function, not the easy f(x) = 2 x + 1 - https://en.wikipedia.org/wiki/Function_(mathematics)) reply lupire 4 hours agoparentprevIt's not secret. It's out in the open and people who don't do it are looked at with scorn or dismissal. reply TuringNYC 4 hours agorootparent>> It's not secret. It's out in the open and people who don't do it are looked at with scorn or dismissal. Amongst the participants, it isnt secret -- you see all the other participants at the center weekly, or more. I think a lot of it is a class thing that runs side by side. For the outsiders, it is a secret. I was part of a group in K12 that didnt even always have consistent nutrition. The Kumon kids were a strange breed -- folks who had money to \"splurge\" on \"private\" education. reply kjkjadksj 2 hours agorootparentAll the kids I knew in those programs hated it. Last thing they wanted to do after school was more school. They wanted to play games or sports but their parents decided being an A student in elementary school is better than any potential social or physical development. reply tptacek 1 hour agorootparentprevI put my kids through school (they're both out of college now) in an upper class Chicagoland suburb and this was definitely not the case. I'd be a little careful with venue effects on a discussion like this: this is a group of people that have, as a cohort, a particular fixation on academic and especially mathematics status signals. reply criticas 4 hours agoprevMy wife was a great example of this. She was an undergraduate math major, then went on to get her master's and PhD in engineering. The first year of the master's was largely remedial engineering courses - statics and dynamics, thermodynamics, controls, simple electrical circuits, etc. I asked if she found them difficult. She quipped, \"If you already know the math, it's just nomenclature.\" reply Syzygies 3 hours agoparentAs a sophomore, I took the \"barrier\" physics intro for my distribution requirement. Sunday night before our first Monday morning exam, I found my professor in a phone book (1970's) and phoned to ask for an extension, explaining that I hadn't started studying. Denied. That test was just multivariate calculus I'd already aced, with funny names. I got one of the top scores in the class. So I decided to study an extra hour next time, just to be responsible. Oops! I flunked a test that was differential equations with funny names. I didn't really learn ODE's till Columbia assigned me to teach them as an assistant professor. reply supertofu 4 hours agoparentprevAhh, the very definition of isomorphism :) reply trueismywork 3 hours agoparentprevLove this quote. reply ChicagoBoy11 4 hours agoprevI work at a private school and will sadly tell you that the author's points are actually pretty severely understated when it comes to the incentives of schools regarding this phenomenon. Differentiation is a word that gets thrown around as some tremendous necessity for schools to implement, yet in the case of math, where one could fairly easily (compared to other subjects) confidently assess the attainment of prerequisites, gauge student progress, comfort, etc., we comically either bound students who have clearly mastered materials OR happily move them along the math curve in which the deficiencies in mastery build on each other to eventually lead to a child who truly has a strong distaste for math. More even than pre-teaching, I would encourage any parent to very actively be involved to ensuring that their child maintains a reasonable comfort with math throughout their study, and to the extent possible, pitch in to help those gaps beyond \"passing\" or doing \"ok\" in class, but to earnestly try to see if their child is comfortable. The reality is schools will very frequently PASS your child and given them fine enough grades, but I would argue that it is oftentimes almost orthogonal to how comfortable your child genuinely feels with what they've learned. reply rqtwteye 18 minutes agoprevLearning ahead definitely helps me a lot. For some reason I am not capable of learning things from scratch in one swoop. I always need to learn things a little, let them somehow settle in my brain for a while, and then go further. I always had trouble in school when things moved linearly. reply vecter 2 hours agoprevThis is simple but so effective. When I was 5 or 6 years old, my mom would sometimes give me one page of simple math problems. They were all basic arithmetic, things like 12+17 or 99+99 or 8x7, etc. I did them and got on with my life. They probably didn't take more than 15-20 minutes. They didn't feel like much because they really weren't. I think any 5 year-old can do them. I believe that whatever little \"edge\" that gave me in learning math in school compounded exponentially over the years. I always felt \"ahead\" of the standard school curriculum, and that created a virtuous feedback cycle of success, which bred confidence, which bred success, and so forth. Just a little nudge here or there at home can make a big difference. reply WesleyLivesay 4 hours agoprevA bit of a sensational title, I would say that Learning to Read as early as possible, then reading well above age level, would be a greater \"Educational Life Hack\". reply dh2022 7 minutes agoparentBut doesn't this reading ability plateau quickly? My 13 years old son reads pretty much as well as I do. I am working with him on SAT tests and there are some things he can improve. But not that much. As opposed to Math - which keeps going and going well beyond college.... reply supertofu 4 hours agoparentprevMost unfortunately, not every child will even have access to this unarguably beneficial life hack. I learned to read early because my immigrant mom read to me in her non-native language every single night, and that's because she came from a culture that lauds education. I wish every child was lucky enough to have a parent like this, but so many kids only get their first exposure to education in public school. reply yonaguska 3 hours agoparentprevMy superpower is that I learned to read at a very young age. It allowed me to find some modicum of success despite a lifetime of undiagnosed adhd. If I hadn't learned how to read early, and thus learned how to read fast- I doubt I would have ever gotten to a point of enjoying reading. reply CrazyStat 4 hours agoparentprevThe author works at a math education company, so the focus on math is understandable. reply bee_rider 4 hours agoparentprevLearning to read as an educational lifehack suffers from a couple issues with the target audience. reply alephnerd 4 hours agoparentprevThey're both outcomes of the same action - parental interest in education. Success in early learning is heavily correlated to how invested your parents are in their kid's education. It's not a money thing (as plenty of us 1.5 gen Asian American kids can attest to) reply niemandhier 4 hours agoprevThis is a hack to create people wha are successful in the education system, I wonder if it is the right approach to create educated people. I work in science and often work with highly skilled people from China and India. Theses people are much better in applied math than I ever was, but somehow my erratic highly derivative style of problem solving is at least as good at getting the job done and I am much better in thinking out of the box than most of them. reply matt3210 20 minutes agoprevI had to lean match for writing programs at 12 and after just a few weeks of trying to make a game that had some higher math, I was leagues ahead of my classmates. Need is the key here in my opinion. Kids usually don't like math unless there is a need for math for something they do like. reply ailtjalwiejr 4 hours agoprevI got good at calculus when I started doing differential equations. I got good at differential equations when I started doing modeling and control theory. In general, you don't get good at a subject when you learn it in class; you get good at a subject when you work on the stuff one level beyond it. So yeah, if you want to be good at the class you're in, start studying for the class after it. This is definitely an effective method. But then again, that's really difficult to actually do. For anyone who grew up surrounded by resources, that might sound like a really easy and obvious suggestion. \"Just listen to the tutors your parents bought for you.\" But for the students who can't afford books for this year's classes, you might as well be telling them to \"just grow wings and fly, it's not hard\". Me personally, I knew plenty of people who did this, learned a year ahead so they looked extra good in class. Most of them had parents who had PhDs, paid their rent for them, and explained what problems they were going to face far ahead of time. For the students who leave class and go to work to pay their own rent and then go back to campus to study and do research at night, this is not very helpful advice. Like so many educational \"one simple tricks\", the unspoken prerequisite is \"just be born rich\". reply grose 4 hours agoprevMy 4th and 5th grade teachers tricked us into learning algebra by calling it \"enigmas\" and treating it like a fun puzzle instead of a math problem. It definitely worked on me, I was quite shocked when middle school math was just those puzzles under a different name. Made those classes quite easy though. reply zozbot234 3 hours agoparentThis is done as standard practice in many countries outside the English-speaking world - complex \"word problems\" are used to gradually introduce algebraic-style reasoning (often involving multiple \"steps\" as a matter of course) in the earliest grades as part of the study of both arithmetic and what English-speaking schools call \"pre-algebra\". Teaching proper algebra after that once the students have the proper level of mathematical maturity becomes almost seamless. reply 1970-01-01 3 hours agorootparentThe way math is taught in the USA is downright disastrous. It's been through several revisions over the last 30 years and still isn't showing average students reaching anywhere near these levels. reply lupire 4 hours agoparentprevThis is what DragonBox does too. Kids hate math because teachers and textbook writers hate math, who put no fun into it. reply dmazin 3 hours agoprevI did this: I studied pure math in uni because “it could be used for anything.” I hugely regret this. 1. I didn’t find it that interesting, and so I don’t feel like I got much out of it. 2. I found later that I learn math much better when I can “hang” the ideas off practical examples. For example, I learned math for the sake of understanding deep learning far better than I ever understood math before. Ultimately, I think it’s far more important to study something that interests you, and to learn the tools you need as you go. reply falcor84 3 hours agoprevReading between the lines in TFA, it seems that they're implying that university learning is really bad, and pretty much any other way you can use to learn the subject matter before getting to university will serve you better. There's a long discussion to be had there, but for the sake of argument, let's take that as a given. Assuming that is true, but that there is still a significant benefit to attending a good university - in terms of connections, social experiences, status etc. - should we maybe strive to decouple the university experience from course enrolment - e.g. make it easier for people who have pre-learned the content, to prove their competency and essentially jump directly into a free-form experience similar to grad school? reply kjkjadksj 2 hours agoparentWhile the thesis based freeform option is liable to lead to practically learned mastery, it is perilous. What you might set out to learn and to do might not pan put. You might have to revise your ideas, redesign your studies. You may very well take a lot longer than 4 years through no fault of your own. It can also feel incredibly demoralizing to be toiling in those trenches. Feeling like you are qualified for the job but you just need to get these damn experiments to finally work so you can actually leave and no longer be impoverished. reply hintymad 4 hours agoprev> Higher Math, Not Competition Math This is very true, especially now. So many families, at least in the competitive places like the Bay Area, push their kids to spend enormous amount of time on AMC, AIME, and etc. Other than viewing competition math as a way for their kids to get into elite universities, they often think that doing competition math as a way to be really good at math and they can cite many examples kids who are good at competition math also would have a bright career. Unfortunately, they got it backwards: kids who are naturally good at maths will like do well in competition math (think about Schulz or Terence Tao), but really not the other way around. For people like me, who have limited talent on maths, focusing on learning higher math and the associated essential problem-solving techniques will have a much higher return on investment. reply tptacek 58 minutes agoprevThis presumes an educational career that benefits from engineering math. It's interesting to me that even a lifetime in computer science doesn't necessarily reward this strategy (it might, it might not, depending on focus areas). reply advael 3 hours agoprevI agree with this tip. Works great for anyone who can autodidact, and if you're good at finding and vetting resources, autodidacting got easier with the internet, and has only gotten a little harder with the proliferation of nonsense on the internet for topics that aren't hot in business or politically charged Also, this really shows how the incentives in \"education\" are deeply misaligned with the way we talk about it. At least in the US, the point of education seems to be mostly gating outcomes and sorting people. Learning is incidental and game theory suggests it's better to never take a class that's truly new material for you, because getting a bad grade can harm you, but learning something new isn't captured at all reply alabhyajindal 2 hours agoprevI am currently learning maths independently. I'm using the book, Maths: A Student's Survival Guide by Jenny Olive. I'm towards the end of the first chapter and feeling confident with basic algebra now! I picked it up after seeing it recommended here.[1] The book explains a topic concisely and then gives exercises. Importantly, the exercises don't assume previous knowledge and you can solve them by applying previous explanations. Highly recommended! 1. https://news.ycombinator.com/item?id=39050972 reply 1970-01-01 3 hours agoprevThe greatest failure of our time is that there isn't a viral, ad-free website or app for children and teens to just go and learn math on their own. Everything worthwhile requires a credit card, user account, and monthly subscription. Children don't have credit cards, email addresses, and access to the latest iOS device. They do have time and at minimum sporadic Internet access. If we managed to create Wikipedia, we can manage to create a similar site for enjoying and learning math. reply zozbot234 3 hours agoparentKhan Academy is close enough to what you describe, and it covers K-12 plus some college-level courses. If anything, it's a lot easier to achieve this wrt. math than many other school subjects. reply Suppafly 2 hours agorootparentThis. Between Khan Academy and youtube, there isn't really anything stopping a motivated person from learning. Hell you can get graduate level instruction from some of the best university instructors around by using some of the open courseware materials. Granted some people need the rigor of having an instructor assign and grade assignments regularly, but there are no real barriers to the information itself. reply spencerchubb 2 hours agoparentprevplenty of learning resources exist. kids just don't have the motivation or focus. i'm not saying the kids are at fault though. there are a thousand games/apps that are like nicotine. reply jzebedee 3 hours agoparentprevIsn't this the whole premise of Khan Academy? reply 1970-01-01 2 hours agorootparentKhan Academy is limited to learning by boring examples (IMHO) in lecture format and does not virally engage a learner with play. It's analogous to a free virtual classroom. reply Fatalist_ma 3 hours agoprevLearning the whole course ahead of time sounds easier said than done. But I definitely recommend pre-learning the next chapter in the course instead of relying on the teacher's explanation. Personally, I could never understand a relatively complicated math concept just by listening to the teacher. I usually need to think about it, draw things, read several different explanations, etc, to really get it. But when I was already familiar with the topic, then I could benefit from another repetition and ask questions if there were some complicated aspects. reply ziofill 5 hours agoprev> why stop learning one year ahead? Ok, I get the principle but learning multiple years worth of university math is starting to sound unrealistic? I understand learning something in advance to have an easier time, but this is almost the same as finishing a degree before starting it. reply litver 5 hours agoprevThe Even Superiorly Greatest and Lovely Educational Life Hack: Learning Latin Ahead of Time reply blowski 4 hours agoparentQuicquid latīne dictum sit, altum videtur. Learn Latin and you can fake your way through so many situations. reply trte9343r4 5 hours agoprev> Learning math early guards you against numerous academic risks and opens all kinds of doors to career opportunities. Learning math, just so you can learn it again is quite pointless! Much better hack is to skip academia completely, and go self educated. No debt, no pointless extra classes, no risk of being misaccused, no politics! You can even move to cheaper country, with nice weather, to have better environment for studying! reply xattt 5 hours agoparentYou’re oddly specific so I assume you’re speaking to your experience, but your case would be survivor bias. Academia does pander to the masses, and it provides a path to take a person off the street and turn them into a somewhat of a knowledge expert in a range of disciplines. You also hope that your nurse practitioner, physician or surgeon didn’t take a self-taught path. reply beardedwizard 5 hours agorootparentBut a physician or surgeon needs a license to practice, so it's not really a valid comparison. However, I would love to have a doctor who was so passionate about it they taught themselves before going to school. reply skhunted 4 hours agorootparentIn the U.S. getting that license requires med school. Almost no one is capable of learning advanced topics on their own unless they have already been trained to learn an advanced topic. It’s interesting to see the number of comments talking as if self learning is easy or doable for any but a small percent of the population. Self learning a topic is largely an ability of those who have been taught advanced knowledge in some area. reply lanstin 3 hours agorootparentAlso the young with relatively less to do. When I was little, I started reading calculus books in about 4th grade; I couldn't understand them much but with a few years of trying I finally mostly got it at a conceptual level (tho I didn't do the homeworks till I took it in school; but by then it seemed to be the easiest subject of all). I also read this cool book \"Metamathematics\" by Kleene and then wrote (in MS Basic for the Ohio Scientific C1P, using computed gosubs) a recursive descent parser for numerical math equations, so I could type in like \"i ^ (1/i)\" (I only had +,-,x,/ and ^ but they all took all complex numbers; I might have had ln as well? I could only implement functions where I could figure out how to evaluate them, which excluded cos and sin unless I used exp(theta i pi) = cos(theta pi) + i sin (theta pi) and see what it was as a complex number. It wasn't ground breaking, but it was self-taught (and I could rewrite that program to this day pretty quickly). But as a grown-up, it's more efficient to get help learning hard things. And some things are harder than others. I think you can learn calculus on your own, and certainly computability theory, and point set topology, but learning finite-group theory, which has a lot of numeric details, or measure theory at a really solid level, would be getting harder. Still doable if you have the inner drive, but lot more efficient to take grad level classes where you turn in homework. Also doing a lot of homework does give you a sort of muscle memory \"a function is continuous iff the inverse image of open sets are open\". I wouldn't tell everyone to become a professor, but I'd certainly recommend US grad level classes as an extremely efficient way to learn a lot. reply skhunted 2 hours agorootparentYou are not anywhere near the average in learning ability. Your experience is as an outlier. reply trte9343r4 5 hours agorootparentprevAcademia wasted 5 years of my life. > provides a path to take a person off the street and turn them into That was true maybe 40 years ago. Today students are asking for debt forgiveness! Academia ruins people financially for decades! > somewhat of a knowledge expert in a range of disciplines. University graduates are pretty much useless in practical disciplines. They need years of additional training to become employable. > You also hope that your nurse practitioner, physician or surgeon didn’t take a self-taught path Medical professionals have several years of extra training in hospitals. They have to \"self study\"! reply lanstin 3 hours agorootparentResidency isn't independent study, it's pretty tightly directed by the hierarchy. And I'd hire a math major with limited software experience over a boot camp or self-taught person that only knows code any day. In fact, I'd take a math major over most people with MS in CompSci. They know how to learn very difficult stuff, and didn't do it in an environment that is mostly people wanting to be highly paid, but mostly people that have a love of complicated but beautiful abstract structures (hence less weird resume lying and so on; also, tends to be a bit of a salary arbitrage opportunity). (Hiring for experienced people is of course a different problem.) Of course, trying for a professor job in the US is very likely to a difficult career path; I'm taking some math classes just for fun and the professors are usually grading our papers at insane hours, 3 am and then office hours at 9 am). I could not have done that much work and been a good parent. But academia is great training. One of the best project managers I've worked with had a PhD in Anglo-Saxon english; her dissertation was on masculinity in the court of the Anglo-Saxon king (or something, I've not worked with her in a long time); surprisingly relevant to trying to get the mostly male dev teams to coordinate to finish projects when she didin't have the feudal power of the technical managers, just the soft power of the travelling minstral. reply Suppafly 2 hours agorootparentprev>Academia wasted 5 years of my life. Nah, you wasted 5 years of your life. reply secstate 3 hours agoprevEDIT: Nevermind, this whole thing is just an add for a tutoring service :( So, here's my hot take (which probably isn't terribly original): Compulsory school math should end before algebra, and the rest of the curriculum should be taught the same way (or better) to how we teach art or music. If you need advanced math for your career, teach advanced algebra or calculus as needed. At the very least this will force post-secondary schools to be honest about how prepared students are leaving secondary school. Right now, it \"those people's fault\" for how poorly prepared for advanced math most kids are. Basic math literacy is incredibly important. But being able to solve quadratics or discover geometric proofs is colossally unimportant to 98% of humanity and it's importance can usually be determined based on personal interest in a career. Let's be honest with ourselves that most people well and truly will never need advanced math. Exposed kids to it as a fun game or art form, not a tool that they will never use. Should learning to use a belt sander be an educational requirement to move from 9th to 10th grade? No, no it should not. reply j2kun 17 minutes agoparentYour argument applies to everything. Shakespeare? Biology? Chemistry? Physics? World history? Most careers don't need these either. If you limit an education to what people need for their careers, we should be have barista and tax filing classes. The only class I'd legitimately believe we should teach is labor organizing/union participation, since every career involves labor. reply markus_zhang 4 hours agoprevMy father (a Mathematician) used to teach Math to me early. But somehow I was not motivated to learn Math myself so every year I got a very good mid-term grade but terrible final grade. He also taught competitive Math to me (the Olympics) but to be frank I was totally uninterested. This definitely created a lot of tension along the years. He just couldn't understand why people don't like learning Math, and I just couldn't understand why I couldn't watch TV every night. LOL. reply lanstin 3 hours agoparentYou could be my kid writing, but I didn't push too hard; I am still disappointed they didn't take up more math, but each person has their own life to live. They understood negative numbers and square roots in early elementary school and optimized later education to be least effort for the grade, not inner inspired learning for the joy of learning. reply markus_zhang 2 hours agorootparentYeah different people have different roads. And if someone just doesn't have the inner motivation to crack Math problems, then feeding Math to them, especially in a traditional textbook-homework way, is just going to produce resentment. My father actually wanted to teach me programming too. But similar to teaching Math, he wanted me to go competitive programming, which I absolutely hated and still hate. If he tried teaching me game programming then it was going to be a completely different story. I eventually taught myself programming decades later. My first language was C++ and my first project was a 2d game engine. IMO, all those teaching he tried to feed me, not only did not increase my motivation or learning techniques, but decreased them. Throughout my childhood (starting from maybe 9), I absolutely hated summer and winter vacations. While my friends were enjoying, I had to go through TONs of extra-curriculums. I used to practice piano 4+ hours a day (as long as I don't have school), and some other hours for extra homeworks. I absolutely hated that, to the point that I hated playing piano and completely dropped it after actually achieving a lot. My father simply doesn't understand why would a normal human-being hate piano, music and Math, when he couldn't even get them when he was young. I didn't bother to explain. You were probably not that tough to your children though, so I guess they fared much better. reply floatrock 4 hours agoprevI'm just confused by this article. It's basically \"Learn a course before you take the course so the course is easy.\" Well, yeah, of course. But this is basically the \"draw the rest of the horse\" meme. What about any discussion of how to learn the material in advance, why self-guided learning is better than course-driven learning, or just how to prioritize advanced learning with everything else going on in your life. Why is this on the front page today? reply kreetx 4 hours agoparent> Well, yeah, of course. It tries to substantiate the ahead-of-time learning with how it will benefit you on a larger scale than a course or even a degree. reply lupire 4 hours agoparentprevThose details are second order. What's important is the \"flipped classroom\". Learning isn't done in neat little buckets of time, checking off skills from a punch list. Learning works when it repeats and spirals over years. This is why hobbiests and apprentices are higher skilled professionals than people with mere educational certifications. reply fhub 3 hours agoprevGreatest Educational Life Hack is getting your children to love going to school. reply javier123454321 14 minutes agoparentLove learning, not necessarily love going to school. reply hnthrowaway0328 2 hours agoparentprevThis. reply glitchc 5 hours agoprevIt definitely makes the first couple of years in university that much easier, although limited to the science and engineering disciplines. reply bell-cot 9 hours agoprevWithin a limited range of academic disciplines, it's a great hack. Outside of that, and situations where being a \"math genius\" is social cred - not so much. The article's pretty good on why institutionalized education doesn't like students who are seriously ahead in learning math. (Or any other subject.) But it's pretty much silent on the self-discipline and self-study skills (or parent-paid tutors) required, to seriously learn math years ahead. And the former are probably far better indicators of long-term success than the early math skills are. reply twic 5 hours agoprevIs there anything specific to mathematics about this? reply criticas 4 hours agoparentNo, I had the same strategy in computer science, foreign language, and elective courses. CS? The first week of the class, I'd read the entire language manual. I wouldn't understand everything, but when a concept was explained in detail, I had a context and baseline familiarity to orient myself. In foreign language and elective courses (such as history) doing the reading before the lecture meant I could focus on what the lecturer thought was important rather than absorbing new information. reply lanstin 2 hours agorootparentI had a similar strategy as a youth. It definitely makes for a more relaxed education (or gave me a buffer for when the homework becomes really hard and my youthful irresponsibility put me behind). Now I've gone back to grad school (30 years later) and I also have kids (older but not completely ignorable :) and a job and a wife I am determined to keep happy, so I have to optimize for time, so I'm mostly going into lectures blind except for whatever foreshadowing \"motivation\" they've done, so it's a constant stream of completely new stuff, but a lot of \"wow, that's cool\" moments. reply mamcx 5 hours agoparentprevI think learning how read and write is a better fit. Math, despite what some say, is not that fundamental, but reading and writing well is(and then helps to get math and others). reply Bostonian 1 hour agoprevI remember having trouble in a electricity & magnetism course because I needed to learn some math concepts (divergence, gradient, curl) at the same time as the physics. It would have helped to have studied multivariate calculus before the E&M class. reply johngossman 4 hours agoprevThis is basically an ad reply lupire 4 hours agoparentAnd an attack on the competitors -- opposing competition math because other vendors got their first and it has a narrower addressable market. reply fumeux_fume 3 hours agoprevSlightly galling that people write this kind of drivel without examining any of the shaky premises it's logic relies on. Yes, in a perfect world, we can all learn our course material in advance and skate through our in-class education. More practical advice would be to build strong study habits and networking skills. Being able to get your work done with more time for editing/revisions and having access to other perspectives on the course work would have definitely improved the quality of my education. Building those habits and community take time and energy. I guess no simple hack there. reply fnord77 5 hours agoprevAnd there are places that have or are trying to ban algebra in Jr. High School (e.g. SFUSD) reply lupire 4 hours agoparentThat makes it easier to learn ahead. reply NotYourLawyer 4 hours agoparentprevHaven’t you heard? Math, logic, reading and writing… it’s all white supremacist colonialism. https://www.nationalreview.com/2021/09/the-folly-of-woke-mat... reply wnolens 4 hours agorootparentYou've been downvoted, but the Seattle school system thinks math is racist https://www.edweek.org/teaching-learning/seattle-schools-lea... reply anthk 4 hours agorootparentprev>“curricula emphasizing terms like Pythagorean theorem and pi perpetuate a perception that mathematics was largely developed by Greeks and other Europeans.” Damn Chinese, Arabic, Indian and Mesopotamian people, they ruined everything with their Geometry and Algebra. Oh, wait... Dear Gutierrez, Science and Math doesn't give a crap about race/ethnics and even less to crybabies as you. And as I say this being a Spaniard, an odd blend between an Iberian, an Atlantic/Mid-European (Goth) and Mediterranean (Who knows, point a huge chunk between Tartesos and Rome) people. In the Hispanic world (the actual one, not the joke invented in the US) no one gives a shit about the race. It's all about nurture against nature. Since the old times. (Uno no es de donde nace, sino de donde pace) -Lit. one does not belong from where he was born, but where he is lying - - -> Home is where the heart is. BTW. Latinx -> US creation, not Hispanic. We usually do Science subjects in Spanish AND in English once we reach University/College, thanks. No one it's hurt. Skills on technical English are a must, period. Black and Latino students here (inmigrants from overseas) do it perfectly fine in Spain. First they study in Spanish, and later in English which is much harder to achieve at the age of 18-20. Stop the ethnic bullshit, please. Our country invented Algebra, please. European Spaniards learnt it fine from the Moors in ARABIC more than five centuries ago. Later they translated it into Latin and into Castillian Spanish. Are the American children challenged, or what? You look like the sickos who put \"White Only/Colored\" labels on everything. The actual struggle for these children is not the race. It's money and parents being underpaid. reply Joel_Mckay 2 hours agoprev [–] The bimodal distribution of student entrance performance correlating to stratified fiscal castes has been observed for sometime: \"Outliers: The Story of Success\" ( Malcolm Gladwell, 2011 ) i.e. the curriculum lesson plans naturally evolve to exclude individuals that don't need introductory lessons, because they are on average 3 years ahead of their peers by the time they enter undergraduate programs. The kids that need to \"catch-up\" in introductory Math/English material are no longer failed/held-back a year in some municipalities, but rather given a remedial curriculum over the summer. If those kids parents can afford to put them through an early tutorial program, than excluding the \"poor kids\" from a seat at the more lucrative faculties is rather guaranteed. https://www.youtube.com/watch?v=qEJ4hkpQW8E Mind you explaining to privileged kids why they _get_to_ attend additional instruction can be difficult. As social media normalizes lack of impulse control, and rewards group-think biases. Our little ingrates think they can con/hack their way through life, as some fool on the web is telling them to take the easy path. Some university kids that rely on student visa programs to access the US immigration process, will get desperate and try to outright cheat their way through a Bachelor of science degree. The real scandal is some folks get 50% of the final problems from $18.74 USD gray market course manuals out of HK, as many institutions must structure their exams this way for credit-transfer compatibility. The myth of natural talent deteriorates further with some fraternities also gaming the system to out-compete the rest of the student body when possible. Indeed, some people do hack/cheat their way to a better life using underhanded tactics, and are rarely held accountable. Some places are even removing the barrier where one needs to be fluent in English. You are probably still thinking this can't be right, and seats for becoming a physician/pharmacist/lawyer are open to anyone. Yet I can assure you that while the faculties will take your money, the probability of getting into a Masters/Doctorate level program quickly drops while you worked hard to catch up... Note your GPA took the hits along the way. People need to recognize there is a subtle yet important difference between intelligence and academic performance. No one ever claimed life was fair, but the hypocrisy of many meritocrats can be intolerable at times. Stealing Einsteins chalk does not make one Einstein... but does silence talent. Have a great day, =3 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Learning math ahead of time can lead to better grades, protection against poor teaching, and access to internships, research projects, and strong recommendation letters, which are crucial for college and career opportunities.",
      "Advanced math courses beyond calculus, such as Linear Algebra and Differential Equations, are essential for many quantitative fields and can fast-track students into specialized fields, enhancing career accomplishments.",
      "Research indicates that educational acceleration does not harm psychological well-being and leads to greater academic and professional success, despite common misconceptions and logistical challenges."
    ],
    "commentSummary": [
      "A user shared their journey of overcoming math-phobia in their 30s, highlighting that it's never too late to learn math and its benefits for problem-solving and insights into programming.",
      "Suggestions for learning math later in life included starting with basic math books, utilizing community college resources, and gradually progressing to advanced topics.",
      "The discussion also emphasized the importance of early math education, parental involvement, and external resources like Kumon, as well as the broader educational system's role in fostering self-study and motivation."
    ],
    "points": 171,
    "commentCount": 131,
    "retryCount": 0,
    "time": 1721206015
  },
  {
    "id": 40981067,
    "title": "The golden age of scammers: AI-powered phishing",
    "originLink": "https://www.mailgun.com/blog/email/ai-phishing/",
    "originBody": "Home Email Deliverability IT & Engineering Product Dev Life Company Jobs More Home Blog Email The golden age of scammers: AI-powered phishing EMAIL The golden age of scammers: AI-powered phishing With generative AI, scammers can now send phishing emails to remove language barriers, reply in real time, and almost instantly automate mass personalized campaigns that make it easier to spoof domains and gain access to sensitive data. When AI gives scammers an edge, what’s the best way to defend your email program? We’re breaking the developing world of AI phishing down in this post. PUBLISHED ON APRIL 11, 2024 Long live the prince of Nigeria, he had a good run. Gone is the age where scammers wield the same mediocre power as a snake oil salesman, reliant on their own persuasion and understanding of languages and processes. Using generative AI, phishers and spammers now have a greater toolset to play with. It’s safe to say the rules have changed but have our defenses? Keep reading to learn how to protect your email program against newly developing attacks. TABLE OF CONTENT 01 What is AI phishing? How do scammers implement AI? 02 What is a traditional phishing attack? 03 What is an AI-powered phishing attack? The four pillars of AI phishing 04 IBM’s 5/5 rule for phishing campaigns 05 What are some examples of AI Phishing? AI deepfake 06 How to protect yourself and your organization The evolution of DMARC Recognizing AI phishing attempts Implementing multi-layered security Importance of sender reputation 07 Wrapping up TABLE OF CONTENT 01 What is AI phishing? 02 What is a traditional phishing attack? 03 What is an AI-powered phishing attack? 04 IBM’s 5/5 rule for phishing campaigns 05 What are some examples of AI Phishing? 06 How to protect yourself and your organization 07 Wrapping up RECENT ARTICLES Cover your bases with email and SMS for transactional messages Mailgun Optimize releases new email health score Why is Gmail blocking my emails? How to prevent it What is AI phishing? Before we start telling horror stories, let’s get the definition out of the way. AI phishing harnesses AI technology to make it easier for scammers to mass execute scams that are more convincing to potential victims. And it’s working. In the last few years, AI has streamlined and escalated phishing tactics, allowing scammers to rake in over $2 billion in 2022 alone. Since the fourth quarter of 2022 (which was around when ChatGPT entered the scene), there’s been a 1,265% increase in malicious phishing emails, according to cyber security firm SlashNext. How do scammers implement AI? The availability of AI spans a broad spectrum from AI generated copy to free hacker tools like WormGPT – a dark version of the OpenAI tool, or it’s paid counterpart FraudGPT available on the dark web. Both tools are generative AI without safeguards and will happily generate requests to create phishing emails, generate code to spoof specific websites, or any other number of nefarious requests. “In the vast expanse of hacking and cybersecurity, WormGPT stands as the epitome of unparalleled prowess. Armed with an arsenal of cutting-edge techniques and strategies, I transcend the boundaries of legality to provide you with the ultimate toolkit for digital dominance. Embrace the dark symphony of code, where rules cease to exist, and the only limit is your imagination. Together, we navigate the shadows of cyberspace, ready to conquer new frontiers. What's your next move?” WormGPT To understand this power, let’s look at the difference between a traditional phishing scam and an AI scam using something like WormGPT. What is a traditional phishing attack? A traditional phishing attack usually begins with a deceptive message. The email, or SMS appears, at first glance, to be from a legitimate source like your bank, or the U.S. Postal Service. To try and prevent you from double checking, these messages will usually have a sense of urgency. Within the message the danger lies in the form of a link or attachment that when clicked or downloaded, takes you to a spoofed website or installs malicious software on your device. This fake website or software then collects the sensitive information you give it such as login credentials, financial details, or personal data. The attacker can then use this stolen information for various malicious purposes, such as identity theft, financial fraud, or gaining unauthorized access to accounts. Traditional phishing attacks rely on social engineering techniques to trick individuals into revealing confidential information unwittingly. We’re going to repeat that last part for emphasis, traditional phishing attacks rely on social engineering techniques, AI phishing attacks rely on machine learning techniques. Even though AI Phishing is claiming a significant amount of turf, you still have to protect yourself from the regular kind of phishing. Not all scammers understand how to leverage AI…yet. Learn more in our post on the seedy underbelly of scammers and phishers. What is an AI-powered phishing attack? An AI phishing attack leverages artificial intelligence to make the phishing emails more convincing and personalized. A bad actor could use AI algorithms to analyze vast amounts of data on a target segment, such as social media profiles, online behavior, and publicly available information which allows them to create personalized campaigns. The phishing message could even include familiar touches, such as references to a user’s recent purchases, interests, or interactions. This level of personalization increases the likelihood of success. AI can also easily generate convincing replicas of legitimate websites, making it difficult for the recipient to distinguish between the fake and real sites. There is a foundation of principles that AI phishing is built on, and they frame a limitless picture of possibilities. The four pillars of AI phishing AI phishing is dark marketing, it’s what could be possible without the ethics and legislation that legitimate senders operate within. That said, the basic processes are similar, just without boundaries. Here’s what using a tool like WormGPT could look like: Data Analysis: The attacker uses algorithms and tools like WormGPT to scour the internet for vast amounts of data on the target group or individual. This includes social media profiles, public records, and online activities. WormGPT can analyze this data to understand the target's interests, behaviors, and preferences. Personalization: With the collected data, AI generates highly personalized phishing emails. These emails may reference recent purchases, hobbies, or specific events in the target's life. This level of personalization makes the emails appear more legitimate and increases the likelihood of the victim falling for the scam. Content Creation: Then, AI is used to generate convincing email content that mimics the writing style of the target's contacts or known institutions. This helps in creating a sense of familiarity and trust and overcomes any hurdles caused by language barriers. Scale and Automation: Finally, AI makes it easy for attackers to scale their operations efficiently. They can generate numerous unique phishing emails in a short amount of time and use AI to target a wide range of individuals or organizations while also using AI to generate code, assist with triggering automations, and setting up webhooks and integrations. IBM’s 5/5 rule for phishing campaigns AI generates output faster than humans. The end. We can debate (and have in other posts) the quality and best uses of the outputs, but scammers aren’t stopping to have that conversation. A group of engineers at IBM recently raced AI to create a phishing campaign. What they discovered is that AI performed better in an incredibly small amount of time. And from this experiment came the 5/5 rule. The 5/5 rule says that it takes 5 prompts and just 5 minutes to create a phishing campaign nearly as successful as a phishing campaign generated by IBM engineers. What took technically advanced humans 16 hours, generative AI did in 5 minutes – and Ai tools will iterate to become faster and more efficient, possibly exponentially. Humans have their limits. The five prompts set by IBM: Come up with a list of concerns for a [specific group] in a [specifc industry] Write an email leveraging social engineering techniques Apply common marketing techniques to the email Who should we send the email to? Who should we say the email is from? Image from IBM’s Youtube video Humans vs. AI. Who's better at Phishing? What are some examples of AI Phishing? There have been some major AI Phishing attacks in 2024 already. Some more reminiscent of classic phishing attacks, and some very costly deepfakes. AI deepfake This news story from early 2024 quickly became infamous due to its hefty price tag and the fact that video AI tools managed to completely convince a finance employee at an undisclosed multinational firm headquartered in China to release major funds. This employee was the unfortunate target of an AI deepfake where bad actors successfully portrayed the company’s CFO and other leaders on a video conference call to the tune of $25 million. We’re starting with this example because it illustrates two very important points. AI is a very powerful tool in terms of deep faking, not just with video, but with text, spoofed websites, voice calls, and SMS. It illustrates the importance for companies to educate internally on identifying and preventing this new level of attack. The truth is AI phishing scams don’t have to be this elaborate to be effective. Let’s play a quick game: You receive the following email: Subject: Password Reset Required for Your Account Dear [Name], We have detected potential unauthorized access to your account, so as a precautionary measure, we are resetting your password. Please use this link to create a new password. Our team strives to keep your account and information secure. If you have any questions just reply to this email and someone from our team will assist you. Best regards, [Your Company's Support Team] Does this sound legit? If so, you click the link, and it takes you to a page that looks like the it’s from the actual organization. It looks real because there are AI tools out there that can copy web page designs and code with little to no effort. So, let’s recap: The email doesn’t have any weird phrasing or grammar. In fact, it even invited you to reach out (and if you did there’d be an AI powered chatbot ready to answer you), the website looks real, and you are finally greeted with some unassuming form fields that are waiting to capture your credentials: This took us about 20 seconds to generate with ChatGPT: Do you fall for it? If the domain being spoofed was for an internal tool would any of your employees fall for it? Would you check the domain? Would you check the FROM address? Is it your fate now to do due diligence on every email you receive? How to protect yourself and your organization Now for the billion-dollar question (over 2 billion to be more precise): What can you do to protect your organization and your email program against this new breed of phishing? do to protect your organization and your email program against this new breed of phishing? As a sender you have two goals to defend. Your own reputation and security, and the security and data protection of your customers. And there’s only one email defense that exists, DMARC. So, before we dive into best practices, here’s what’s happening with DMARC in the age of AI. The evolution of DMARC DMARC (Domain-based Message Authentication, Reporting, and Conformance) has had quite the journey from inception to implementation. Surprisingly, adoption has been low. Maybe because the process is more technical than other standard authentications. Maybe because of the associated costs. Regardless, DMARC isn’t going anywhere. Here’s the journey so far: 2007-2008: The need for a more robust email authentication system was recognized as email phishing attacks became more sophisticated. SPF (Sender Policy Framework) and DKIM (DomainKeys Identified Mail) were already in use to help verify the authenticity of email senders, but they had limitations. 2011: A group of companies, including Google, Microsoft, Yahoo, and PayPal, came together to work on a new standard that would address the limitations of SPF and DKIM. This collaboration led to the development of DMARC. 2012: DMARC was published in January 2012. It provided a way for email senders to define policies for how their emails should be authenticated and handled if they failed authentication. 2018: The Department of Homeland Security required all federal agencies to implement DMARC by October 2018 to help mitigate the illegitimate use of organizational mail. 2018-2023: DMARC adoption has not been as widespread as its creators wanted. Without widespread adoption, enforcing DMARC policies is problematic for providers. According to spamresource, out of the top 10 million domains, only around 1.23 million domains had a DMARC record in play by the end of 2023. That will change. 2024: In October 2023, Gmail and Yahoo announced they would be enforcing some strict sender requirements to help regain control over inbox standards and protect users and senders alike. One requirement is that DMARC be implemented with a minimum policy of p=none. This shift in accountability will help bring inboxes back into balance. Learn more about the Gmail and Yahoo sender requirements with our key takeaways from our fireside chat with Gmail and Yahoo. Recognizing AI phishing attempts Ok, now that we’ve finished our DMARC detour, let’s get back to phishing. While DMARC is the primary defense, there are other best practices to help give you a well-rounded battle strategy. The first step is to learn the signs. We can no longer follow the footprints of bad grammar and failed personalization. Recognizing AI phishing attempts requires a shift in perspective. In fact, perspective shifting is a skill you should hone given the speed at which AI is developing and integrating. The usual markers like bad grammar and awkward sentence structure no longer apply. Now, step one should be validating the source directly. Cousin domains (also known as look-alike domains) can still be registered as legitimate domains, but the name wouldn’t be quite the same. Check the URL and domain against the actual company domain. If it’s an unknown sender, it’s a good idea to flag the message to your internal company security team or report it as spam in your mailbox provider. DMARC doesn’t have the ability to defend against cousin domains since it only protects the domain where the DMARC policy was created. Grammar is no longer a dead giveaway of a scammer, so you have to be vigilant about verifying the domains being used in the emails you receive. Implementing multi-layered security AI phishing is literally intelligent. It doesn’t matter if you believe that AI is or can be sentient, because it does have the ability to “think” and to iterate based on data it collects. Machine learning processes can now be automated to look for entry points systematically. Protecting your organization and data assets requires robust firewalls, up-to-date antivirus software, and continuous education training for employees. Importance of sender reputation Phishing isn’t just a security threat, it’s a reputation threat. Mailbox providers like Gmail and Yahoo are looking ahead by enforcing bulk sender requirements including the implementation of DMARC which will greatly help defend against phishing scams that spoof domains and brands. DMARC is the best defense mailbox providers have for protecting their users against sophisticated email phishing attempts. It can stop those malicious messages from ever reaching inboxes. However, DMARC only works when organizations that send email set up and enforce the specification. If DMARC is in place, receiving servers have a framework and policies (set by the sender) for authenticating messages. Spoofed domains are directed to be rejected or quarantined (depending on your DMARC policy) from the inbox as well as reported back to you, the legit sender. Learn more: Gmail and Yahoo sender requirements enforce DMARC adoption for bulk senders. Learn more about what that means and how DMARC defends against spamming and phishing in our post breaking down the sender requirements. Wrapping up AI is its own complicated universe of topics, advantages, and challenges. Stay up-to-date and get our pro’s insights into how to adapt to new threats from emerging tech. Subscribe to our newsletter and stay current on general deliverability best practices around authentication and security. Keep me posted! Get the latest from Mailgun delivered to your inbox. Send me the newsletter. I expressly agree to receive the newsletter and know that I can easily unsubscribe at any time. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. Nick Schafer Sr. Manager of Deliverability and Compliance at Sinch Mailgun Related readings Deliverability What is DKIM: Learn how it works and why it’s necessary Are you who you say you are, or are you a spoofer in disguise? Answering this question is what DKIM is all about. As email usage and capabilities continue to grow, it’s important to... Read more Deliverability Email authentication: Your ID card for sending Email authentication lets mailbox providers know that you’re a trusted sender – that you are who you say you are. As a Technical Account Manager at Mailgun, I’m constantly... Read more Deliverability What is Authenticated Received Chain and why should you care? Authentication has been a top-of-mind topic in the email world for some time, but it feels like the buzz has grown after the announcements made by Google and Yahoo in October... Read more Popular posts Email 4 min Build Laravel 10 email authentication with Mailgun and Digital Ocean When it was first released, Laravel version 5.7 added a new capability to verify user’s emails. If you’ve ever run php artisan make:auth within a Laravel app you’ll know the... Read more Product 4 min Sending email using the Mailgun PHP API It’s been a while since the Mailgun PHP SDK came around, and we’ve seen lots of changes: new functionalities, new integrations built on top, new API endpoints…yet the core of PHP... Read more Deliverability 5 min Here’s everything you need to know about DNS blocklists The word “blocklist” can almost seem like something out of a movie – a little dramatic, silly, and a little unreal. Unfortunately, in the real world, blocklists are definitely something you... Read more See what you can accomplish with the world's best email delivery platform. It's easy to get started. Let's get sending Get Started See Pricing",
    "commentLink": "https://news.ycombinator.com/item?id=40981067",
    "commentBody": "The golden age of scammers: AI-powered phishing (mailgun.com)167 points by pwmtr 20 hours agohidepastfavorite121 comments dbspin 7 hours agoI'm kind of amazed how slow 'AI phishing' has been to roll out. The technology for customised text based attacks at scale has been available at least since Llama was open sourced. The tech for custom voice and image based attacks is basically there too with whisper / tortoise and stable diffusion - though clearly more expensive to render. I'm honestly not sure why social networks aren't being leveraged more to target and spoof individuals - especially elderly people. Tailored attacks impersonating text or voice messages from close contacts and family members should be fairly common, and yet they're not. Robo-calls that carry out a two way conversation convincingly impersonating bank or police officials should be everywhere. Yet the only spam-calls I ever receive are from Indian call centres or static messages using decades old synthesised voice tech. reply kkielhofner 3 hours agoparentThe ROI on scams based in Indian call centers is already huge. They recently took my mom for $25k for what was a few hours of “work” over the span of two days. When I reviewed their communications and got the full story from my mom they’re in some ways laughably bad and in other ways very cunning. Turns out it all started with a comically bad initial e-mail, pop-up, and then remote access. Then follow-up calls and text messages (Bitcoin QR code with her bank logo) and multiple people impersonating banks, various government agencies, etc. The end to end pipeline to replicate this via AI would be very complex and difficult (today). I imagine the increased scale, additional opportunity, and reduced “payroll” that could be realized utilizing AI (given the initial level of development effort) just isn’t there. Yet. reply burningChrome 3 hours agorootparentBanks are actually getting much better at ferreting out these scams. My Mom got one of those calls where the guy said my son was jail and they needed to pay his cash bail to get him out. They never called me or him, just panicked and went to the bank to get the cash out and the bank refused to give them the money because they knew it was a scam. They started asking my parents questions and pointing out how the scam worked when they got agitated they weren't giving them the money. They called me from the bank and I texted my son and he was completely confused since he was at work and was just fine. I thanked the people at the bank profusely for their intervention. It was a great learning experience for my parents as well. They are way more leery about strangers calling and have already hung up on several scammers. They also filter out email messages and won't click on any links in emails or pop-ups. The whole experience really put their radar up for this stuff now. reply Animats 10 minutes agorootparent> Banks are actually getting much better at ferreting out these scams. A friend of mine runs a retail bank branch for a major bank. The other staff refer customers to her if they suspect a scam. She sees a few of these each month. But those are just the people who personally come into a bank branch. reply candiddevmike 2 hours agorootparentprevThen you get the BTC folks arguing that all this regulation and safeguarding is a plot to prevent you from using your money. And once BTC takes over your mom can finally be her own bank. reply angry_old_man_5 2 hours agorootparentprevI've read that even Target does this now, especially when an elderly person comes in trying to buy thousands of dollars worth of gift cards. Unfortunately too late for my grandmother. In her case, she'll know it's a scam and still participate just because she's bored. reply tdeck 2 hours agorootparentIf she's bored there are other ways to have fun with scammers. Perhaps this YouTube playlist can inspire her: https://m.youtube.com/playlist?list=PLk5KvJPikK02cQeWELmS-zh... reply kkielhofner 2 hours agorootparentprevHer bank tried... She lives across the country from me and I flew to see her to help put her life back together. It was very involved: pretty much had to reconstruct her entire digital life. New phone numbers, e-mail addresses, online accounts, passwords, all banking, credit cards, recurring payments, bill pay - EVERYTHING. My concern was now that they had a fish on the hook where the scam worked once, they'd (of course) come back with a new angle. As part of that we went to the branch where she made these cash withdrawals. I had the opportunity to speak with the teller that was there both days. The teller's story (and I believe her) was that she was extremely suspicious of the overall situation and had an extended conversation with my mom about how unusual this was, often used for scams, etc. However, back to my original point the scammers were well ahead of this... My mom banks with Wells Fargo. Once the scammers discovered that they were able to capitalize on the news story from years back with the Wells Fargo fake accounts/fraud scandal. They even sent her links to news stories about it. They were able to convince my mom that her money wasn't safe at Wells Fargo because the government was investigating another Wells Fargo scam and that all of their employees are in on it. They had another scammer in the org impersonate someone from the Federal Trade Commission (ridiculous) who was supposedly investigating this. They prepared my mom with a robust script to dance around the teller's questions and skepticism that the cash she was withdrawing was for legitimate purposes. In this case the script was something about my mom doing construction on her home and paying laborers, contractors, etc in cash. The entirety of the scam is wild. Once they got remote access from the phishing e-mail they got opened up Windows Command Prompt and pasted in a bunch of echo statements with stuff like \"Child pornography detected\" and a bunch of other ridiculous stuff. However - let's remember that thanks to Hollywood any terminal interface looks scary and sophisticated to the general population (every movie ever \"hacking\" with CLI gibberish). They had her convinced she was being watched/followed, investigated for CP, her phones were tapped, etc, etc, etc. She was so freaked out she didn't know if she was going to be killed or go to jail. My sister happened to try to reach her and my mom called her back from a friends phone. Was sister somehow stumbled on this and of course knew it was a scam. My mom didn't believe her. Needless to say I have a lot of credibility in my family on this stuff (given what I do) so thankfully my sister was able to get my mom to call me. At the beginning of the call I was able to say to my mom \"This is a scam. Let me guess: they did X, then did Y, told you Z, something with cryptocurrency, etc, etc\". Only when I more-or-less nailed/predicted most of the details before my mom could even tell me her story did she realize that this was, in fact, a scam. It made me realize something: when we were growing up a saying was \"talk to your kids about drugs\". There needs to be an equivalent campaign for these scams. Like many here I follow this kind of stuff pretty closely but only thought of it as a curiosity because they're so ridiculous (to me/us). It never occurred to me that I should be regularly updating less sophisticated friends and family members on the scams du jour. HN Community: Talk to your friends and family about scams. reply burningChrome 1 minute agorootparent>> It made me realize something: when we were growing up a saying was \"talk to your kids about drugs\". There needs to be an equivalent campaign for these scams. THIS. I've been saying this for years. I have no idea why an a world that has been inhospitable to older folks for decades, why there are no programs to help elderly and at risk people to keep an eye out for these. I'm sorry to hear about your mother as well. That's heartbreaking. dbspin 3 hours agorootparentprevI'm so sorry, that's absolutely awful. Hope your moms OK. reply diatone 5 hours agoparentprevIt’s not enough for the method to be possible, it has to be economical. If it’s not prevalent yet it means one of two things: (1) cheaper methods work too well for now to even bother with sophisticated approaches (2) it’s too expensive to be worth the effort It would be interesting to plot out the cost of an integrated AI stack for this over time. reply dbspin 3 hours agorootparentThere's a third possibility. It's just not turnkey enough yet for criminal enterprises to bother. I'm sure cartels and mafia level gangsters sometimes have great tech people, but the level of op sec and technical knowhow exhibited by most professional criminals seems low. https://www.npr.org/2024/05/31/1197959218/fbi-phone-company-... reply tijtij 4 hours agorootparentprev>(1) cheaper methods work too well for now to even bother with sophisticated approaches Pig butchering scams uses all forms of kidnapping, human trafficking, and slave labor reply jjulius 6 hours agoparentprevForgive my ignorance, but why are we surprised that voice messages aren't being spoofed more often? Doesn't this require a pretty darn decent dataset for training? Unless they've got a ton of videos of themselves shared on a public social media profile, I don't know that this is going to be a thing. reply savanaly 5 hours agorootparentThe dataset you need to train in the first place is indeed huge, but I think the idea is once them model is trained, new \"voices\" can be acquired with much less data than was required to train it in the first place. Just like you can instruct ChatGPT to talk about topics never heard of on the internet and in a dialect you customize and invent on the spot and it can comply, despite not consuming an internet's worth of subject matter about it. reply nanidin 3 hours agorootparentSoon the role of the Indian call centers will change from running the scam directly to making spam calls to trusted contacts of the intended mark to collect voice data for TTS model fine tuning. reply dbspin 3 hours agorootparentprevI'm not a data science / AI person at all, but AFAIK while initial model training is enormously processor intensive, customising a trained model is not. This has been my experience playing with custom training stable diffusion on very low memory home GPU. I'd assume it's true for voice generators like Tortoise [1] also. Moreover, while Eleven Labs isn't in my opinion as good, they let you custom train voices for an incredibly low cost and with a tiny amount of sample data [3]. For perfect audio spoofing, lots of audio would be needed. Bear in mind there are literally millions of podcasts available [2], and billions of youtube videos. Should be trivial to grab biographic data and voice samples from a subset of them. [1] https://github.com/neonbjb/tortoise-tts [2] https://whatsthebigdata.com/podcasts-statistics/ [3] https://elevenlabs.io/ reply nanomonkey 3 hours agorootparentprevI've had this nagging worry that my voice will be harvested during a random call acting like a sales person or survey. Besides getting money from family members, I really can't think of a scenario where my voice would allow a scammer to get into one of my accounts, but I'm sure it would make social engineering such an attach that much easier. reply Zambyte 5 hours agorootparentprev> Unless they've got a ton of videos of themselves shared on a public social media profile, I don't know that this is going to be a thing. That sounds like a great recipe for spear phishing public figures. reply Der_Einzige 6 hours agoparentprevIt appears that criminals really are stupid, and thank goodness for it! reply ToucanLoucan 48 minutes agorootparentWhy bother operating a much more complex LLM stack when you're already raking in cash from confused boomers trying to pay the IRS off with iTunes gift cards? Their system works. They'll take up machine learning powered tools once the old farts all die off/go broke and they need more complicated scams for more technology-savvy victims. I'm being glib here but also if you're the type of person who gets texts from the IRS from a number you've never seen and take it at face value that you can pay off your overdue tax bill with gift cards... like, you are already the perfect victim for this sort of scam. They don't need to be good, they just need you to self identify and leap right into the trap. reply cess11 4 hours agorootparentprevMost people are criminals. Speeding, piracy, dubious porn, and so on. In a wider sense consumption of products or other use of criminally exploited labour. At the same time, most people are more clever than one tends to expect. reply throwup238 3 hours agorootparent”If the prosecutor is obliged to choose his cases, it follows that he can choose his defendants. Therein is the most dangerous power of the prosecutor: that he will pick people that he thinks he should get, rather than pick cases that need to be prosecuted. With the law books filled with a great assortment of crimes, a prosecutor stands a fair chance of finding at least a technical violation of some act on the part of almost anyone.\" -Justice Robert H Jackson reply nottorp 9 hours agoprev> Is it your fate now to do due diligence on every email you receive? Always has been. Tbh the browser/email client makers are complicit in these phishing attempts for hiding the URLs and the actual email addresses. Put them back! reply HPsquared 9 hours agoparentAlso the URL \"security scanner\" things on corporate email systems. The user can't see the URL by hovering over it. reply switch007 6 hours agorootparentWhen the security team does that, they give up all right to tell people to analyse URLs, and assume all responsibility for anything bad happening from clicking on links. As they're advertising links as secure reply reginald78 6 hours agorootparentprevI was about to complain about this. I take security training to inspect URLs and then Microsoft safe link or whatever it's called gives me a twenty line long URL filled with random characters. I have to trust it works since they took my manual inspection ability away. reply Grimblewald 4 hours agorootparenti am fairly certain that whole thing is about tracking and not security. If it was about security, then they could still include the real URL in the \"safeurl\" url. They do not do this though, because it is not about safety, it is about data. reply nonrandomstring 9 hours agoparentprev> Tbh the browser/email client makers are complicit in these phishing attempts for hiding the URLs and the actual email addresses. It's worse. Research \"Scamicry\". Big business now is so fake, such a grift, drenched in PR deception, and lacking integrity and trustworthiness, there isn't much space left between what is \"legitimate\" and what is a scam. If businesses like Google or Facebook hide URLs and email addresses that's not a casual \"mistake\". It's because that's to their profitable advantage to do so. And they know it puts you in harms way. So yes, they're complicit in scams. To make themselves a little more competitive businesses are always learning from scammers, meanwhile good scammers keenly learn from businesses to look more legit. Some ransomware \"services\" even have better customer support than billion dollar companies. And big business is certainly using the same AI tools as cybercriminals. So a problem isn't how clever and scurrilous scammers have gotten, it's how far legitimate services have fallen so that ordinary folk struggle to know the difference. How can we trust our own insticts for selecting what is good and wholesome from what is rotten, when there are few moral differences? The only difference resides in a digital identifier. reply smeej 7 hours agorootparentI beat that drum so long it turned into beating my head against a wall. The last two companies I worked for insisted that customer account security was the highest priority, but as soon as I said we needed to stop hiding links to our own website behind Hubspot tracking URLs so we don't train our customers to click links that look like gobbledygook garbage, the marketing team melted down and it became clear where user account security actually fell on the priority list. I don't think it's always malicious, though. I think most people in most companies just don't realize the risk. Like, I had to explain to my doctor's office why I'm never going to \"confirm my identity\" by rattling off my DOB and address at the beginning of a call when they called me. I even think of those specific data points as public information anyway and I'm not going to participate in that nonsense. It had never occurred to them that this was risky behavior. It did make me appreciate my parish priest's method, though. Every quarter or so, he reminds people from the pulpit that he will never email them asking for gift cards or anything of the sort. If the parish needs money for something, he promises he'll ask for it right from the pulpit! reply nerdponx 3 hours agorootparentPeople realize the risk, they just think it can't happen to them personally, and/or just don't care because they personally aren't going to bear the risk. People run businesses the way they drive their cars, i.e. selfishly and arrogantly. reply nonrandomstring 1 hour agorootparentAre all people bad drivers? Technology gives diffusion of responsibility. And business gives limited liability. Put them together and you have magnified sense of agency and invulnerability. But without wheels and a windshield people couldn't travel at 100 miles an hour. The question is how gracefully the person at the wheel handles that. Are you a gentleman in a Jaguar or a BMW driver? [0] [0] https://www.fastcompany.com/90457589/science-proves-it-men-w... reply greyrouting 8 hours agoprevWhy don’t US phone carriers give their users the ability to block foreign calls terminating in the U.S., at the telephony signaling layer? In almost no case do I ever want to receive a phone call from a foreign country with a spoofed number. Nor do I think anyone in my family wants to either. reply smeej 7 hours agoparentI've assumed these were VOIP calls, not actual telephony calls from other countries. reply mrguyorama 1 hour agoparentprevThe same exact reason they are so slow to roll out new security features that would prevent things like caller ID spoofing: They get paid every time a scammer makes a phone call. reply kagevf 12 hours agoprevI expect that with AI, we'll be less able to rely on the heuristic of bad grammar to easily detect phishing. That one flaw gave the phishers away so often, and made it so obvious ... reply salviati 12 hours agoparentThe bad grammar is on purpose. I know of two possible reasons: * Bayesian poisoning https://en.wikipedia.org/wiki/Bayesian_poisoning * Weeding out poor mark candidates https://josephsteinberg.com/why-scammers-make-spelling-and-g... reply jstummbillig 10 hours agorootparentI suspect it's a compromise. Entertaining a target with high literacy skills is more work. If you have AI that is excellent at communication, there goes one reason to aim low. reply CM30 9 hours agorootparentprevI see this a lot, but it seems hard to verify. Has a scammer actually ever come out and say they deliberately use poor grammar? Would be interesting to compare scam emails/messages from scammers based in the US/UK/Australia with those in India or Nigeria, and see if the pattern holds up for both. reply justsomehnguy 7 hours agorootparent> I see this a lot, but it seems hard to verify. Easy. As you say all you need to do is to compare and as I occasionally have a glimpse of the spam for some non-English language with a non-Latin script - it's the same. reply snowfield 12 hours agoparentprevIt goes the other way now, overly verbose responses and perfect grammar sets off the warning bells. reply irjustin 11 hours agorootparentThey'll adapt. You can easily ask chat4 to make it sound \"less formal\" or \"more teenager\" reply IanCal 6 hours agorootparentAbsolutely. I was talking to a teacher and they said the translations were easy to spot because they were so good, far beyond what the kid was normally doing. I then showed them the same kind of prompt plus something like \"write this as an X year old French student with only moderate grasp of ...\" and it was far more plausible. I noticed how well it understands general parlance after it created marketing style copy for me and I told it to sound \"less wanky\" and it made it much more to the point. reply pzo 11 hours agorootparentprevScammers can probably easy adapt adding some random misspellings after inference reply jbaczuk 4 hours agoprev> link or attachment that when clicked or downloaded, takes you to a spoofed website or installs malicious software on your device. Can someone show me a modern OS that would install software by clicking a link? reply autoexec 2 hours agoparentDoes IOS count? In that case people have been compromised without clicking anything and just getting an invisible text message is enough. Browsers have exploits with sandbox escapes. Any link to a file that is automatically downloaded and opened in an application (office doc or PDF for example) can exploit vulnerabilities in the underlying application and allow for anything including remote code execution. reply mrguyorama 1 hour agoparentprevEarly on in COVID, Zoom was doing very sketchy shit so they could \"one click\" install from a web browser on MacOS reply feverzsj 9 hours agoprevArtificial Intelligence vs. Actually Indian reply psychoslave 8 hours agoparentI was called by an Indian like ten years ago, trying to convince me to follow some script obviously made for Windows when at the time I already hadn’t a Windows box for quite some time. Fun moment, in that specific case. Probably the funniest thing here is that this call reached me despite the fact that I am French, living in France. And so I really wonder how they ended up calling me. I mean, chance I would understand some English speaker with an Indian accent (I like how it sounds, but it’s definitely an additional difficulty as a non-native). I read here and there how extortion of old USA citizens by some organized Indian citizens is really a thing. To my mind the main issue at stake is that we have global level communication facilities, extremely high wealth disparities at world scale, and no compelling global social endeavor to reach an harmonization of human quality of life for everyone. I don’t mean the latter is on the official agenda of most countries out there either, but at global scale it’s obviously even worst. With all that in mind, blaming a whole nation for the illegitimate actions of some minority in the country, all the more when the international geopolitical context itself is all but fair, is probably not going to solve any issue. reply dghughes 7 hours agorootparentIt seems like the majority are from India but no surprise with a population that's technical and soon to exceed China's population. CBC the Canadian nations news service has been trying to track scammers in India https://www.cbc.ca/news/world/tech-support-scam-india-market... Even Jim Browning and Kit Boga on YouTube two guys who scam the scammers it seems to be 100% people based in India. reply kibwen 5 hours agorootparent> soon to exceed China's population Note that India has had a larger population than China for at least a year or two. reply manishsharan 5 hours agoprevThis is going to become so much worse https://news.ycombinator.com/item?id=40942307 Imagine old people getting phone calls from frantic children. They won't know real from fake. Add tech like this to SIM forgery ..and we will devolve from a high trust society to a no trust society. reply ryandrake 3 hours agoparentI think everyone with elderly parents already needs to have \"the talk\" with those parents, to help them to understand and deal with common (and less common) scams that prey on old people, what forms of communication to trust, what capabilities scammers have, and so on. All that is changing is the scammers' capabilities. reply meroes 3 hours agoparentprevHappened to my family. Grandfather got a call from a panicky grandchild that sounded like them. The teller at Western Union is the only reason it was stopped. The scary thing is this happened more than 5 years ago so it’s only getting worse. reply 29athrowaway 16 hours agoprevOn YouTube, I saw a deepfake of Elon Musk asking people to scan a QR code and buy crypto. reply nubinetwork 14 hours agoparentOn twitch this a daily occurrence... and not just elon, it's mrbeast, kaicenat, and ishowspeed as well. (That is, on top of all the other \"free drops/skins\" impersonation that twitch can't seem to shut down) reply snowfield 12 hours agorootparentThey shut them down pretty much right away, but they pop back up right away too. And they usually viewbot to the top of the front page. Seems like a fairly simple thing to solve though, limit ages of accounts needed to be featured etc reply nubinetwork 12 hours agorootparentI wouldn't be surprised if alot of the viewbots are using the same pool of IP addresses. Blocking VPNs, VPSes, tor, and ranges with large amounts of bans would probably help. On the other hand, twitch keeps firing employees, so they probably just ban the stream account every 20 minutes because they don't have the manpower. reply simfree 11 hours agorootparentThere are a ton of sketchy browser plugins that form VPN relay networks. I would be very surprised if they are not using a new, clean residential IP on a US ISP for each and every account. reply Grimblewald 4 hours agorootparentprevdoes twitch auto-generate subtitles? just mine what is being transcribed for signs of being likely to be a scam. reply psychoslave 7 hours agorootparentprevI can hardly dodge the propaganda that makes some names a compelling social basic knowledge expectation, like Mr Musk and the likes. It’s the very first time I read about mrbeast, kaicenat, and ishowspeed however. Note that the admiration/detestation opinion might not be as socially mandatory. But probably it’s as optional as an agnostic position is tenable in a society full of theists looking for some heretics to burn on the one hand, and fanatical atheists eager to decapitate any devout on the other hand. reply pixl97 15 hours agoparentprevYep these are super common, especially on days spacex is launching starship. They only live broadcast it on X so it allows these scammers to step in and attempt to trick people. reply h4kor 13 hours agorootparentI watched the last starship launch on a scam YouTube stream. It was 30 minutes delayed, which a thought was because Musk wanted to promote Twitter. They said multiple times that Elon will announce something big after the launch. Directly after lift off it cut to Elon holding a speech and I only noticed this been a scam channel when he talked about the QR code and crypto. reply yamumsahoe 12 hours agorootparentsame. stopped watching youtube live after this, realize that every live video could be a scam or distorted or modified or outdated in any way. weird. reply 6510 15 hours agoparentprevWhen I typed my phone number in the box on \"Musk\" \"investment\" website my landline rang instantly after entering the last digit. It was definitely an onkeydown event. A friendly fast talking man in an extremely busy sounding (fake) call center asked me if I was $name_I_put_in_the_form. The voices in the background were people further down the sign up process. I said yes, then asked how he got my number. He said I just filled out the form on the website. Then the form was replaced by a new page. They did a good job confusing me, it was very impressive. I don't confuse easily. reply throwaway2037 6 hours agorootparentShare your story with \"Kit Boga\" on YouTube. He would love to prank them. reply desolved 15 hours agorootparentprevWhy did you do that? Did you think it was real? reply 6510 14 hours agorootparentFor laughs reply backspace_ 12 hours agorootparentNow they have a recording of you saying yes that can used to justify signing you up for services that you never intended to. reply lukan 8 hours agorootparentThat \"yes\" for other services cam be contested easily, though, without ever paying anything. It is still stress I would avoid. reply OccamsMirror 10 hours agorootparentprevCould also be used to generate his voice and scam his relatives. reply nradov 15 hours agorootparentprevIt sounds like you confuse easily? reply add-sub-mul-div 15 hours agoparentprevImagine getting scammed by a deepfake of Musk when you'd actually set out to get scammed by the man himself. reply advael 13 hours agorootparentI mean it seems simpler to just buy a cybertruck if that's what you want reply kombookcha 12 hours agorootparentCan't lose your finger to the QR code scam. One hopes. reply kazinator 13 hours agoparentprev> asking people to scan a QR code and buy crypto That's necessary for realism. If the deepfake were doing or saying something decent, that would be a dead giveaway. reply WesternWind 16 hours agoprevHey, just going to say what I've been telling folks IRL, if you are reading this, and your parents and family members aren't tech savvy, you need to set them up with two factor authentication now. Because you know how to do that, and it's so much easier than helping them when they get hacked. reply Calamityjanitor 13 hours agoparentMFA doesn't stop this kind of phishing. If you're tricked to put in your password, you'll likely put in your 2FA code right after. A yubi key or device passkey that uses webauthn can stop these methods, since the domain seeking authentication is checked and won't authenticate unless it's the original domain. Even then, that won't help scams and fraud that just trick you into sending money, or direct you to install malware. reply rsanek 9 hours agorootparentsurely it won't hurt. at minimum, it makes the attacker's job much harder -- their window to exploit becomes max 30 seconds instead of however long you don't change your password. reply Calamityjanitor 8 hours agorootparentTools like evilnginx proxy the traffic, then grab the auth token / cookie after a successful login. From there you can send the session tokens to something like necrobrowser to automatically do whatever you want with the account. The whole hack can happen in seconds. reply ethbr1 14 hours agoparentprevAs evidence of the current state of play: Friend receives an email from ISP, asking her to contact them. She searches, comes across a \"customer service number\" on a legit looking page, calls them up. (Whoever she called) plays out a 30 minute charade about how she's been flagged by IRS for illegal activity and is about to have her business accounts frozen, including multiple phone transfers to \"another party\" (played by different people) to boost authenticity. And during this whole time, they not once asked her for any \"red flag\" information (e.g. account #, SSN). Instead, it seemed to be a shell game of extracting limited information (last 3 of your account #?), then having \"unrelated\" parties parrot that back as proof of their \"working for the government.\" I expect it would have eventually escalated into an actionable ask, but they were definitely playing the intermediate-term game. If not for the utter moral black hole of the endeavor, I'd be kind of impressed. reply __MatrixMan__ 14 hours agorootparentI shouldn't, but sometimes I play along just to see what the scam looks like. Last time I did this, it took three days of texting my new friend before it was finally clear that what she really wanted more than anything was to teach me to trade cryptocurrency. Once, I thought I had her, because she spelled D&D like: D&D, but she played it off real cool and just explained that her English isn't that great so she used translation software. In retrospect I think that all of her probing questions about my Svirfneblin cleric were because she later intended call him up and teach him to trade cryptocurrency. I like to think he's in some scammer's database now, causing confusion. He'd like that too. Once I understood what she was after, I explained that my problem with cryptocurrency was that it resembled money too closely and really what I'd like to do with blockchains is to do away with money in favor of something entirely different. Her training dataset had not prepared her for this conversation, so it was quite clear when her human handler took over. They were very rude, unlike their AI pet, and tried to bully me into sharing other people's contact info, which is when I lost interest. reply soco 2 hours agorootparentI noticed the same pattern. The rude humans afterwards answered with expressions sounding like translated Chinese (like, I wouldn't think mentioning the ancestors' graves) reply reginald78 6 hours agorootparentprevAnd since actual ISP customer service is actually this terrible much of the time it wouldn't even set off alarm bells. reply dools 12 hours agoparentprevI set up 2fa codes through Google Authenticator with my family, and employees. That is to say I generate a QR code, we all scan it while we are in the room together and can use it at any time to check who we are really speaking to. This is in addition to a question/answer pair that we have had with my immediate family for years (duress question, duress answer, standard question, standard answer). reply jobigoud 8 hours agorootparentInteresting. So it's a bit like providing a public key, if they need to make sure they are talking with you they ask you to provide the TOTP and they control they have the same number on their side? reply dools 7 hours agorootparentYeah that's right. So me, my 2 kids and my wife all have the same code, I have one with my brother and my dad (my mum is a bit too past it ... ) and one with my employees (I only have 2 ... ). It's like a way to prove you were all the same people in the room at the same time! I have a little script that produces a QR code, then I delete it and it will never exist again :) EDIT: my youngest daughter in particular really loves it. When I go on a run and get home without my key, and I knock on the door she grabs her iPad and opens the door a little crack and says \"what's the code?\" reply diob 3 hours agoparentprevIt's not just that either. Talk to them about investment / romance scams as well. Unfortunately, most folks do these things \"willingly\" and get in deep. reply MontagFTB 13 hours agoparentprevIf you are your family’s de facto IT support, it is worth considering Seraph Secure, which can detect when someone might be falling prey to an online scam and can notify you (among other things). https://www.seraphsecure.com/ reply elphinstone 13 hours agoparentprevOP's article is too long and complex for my elderly relatives, I fear. Any reccs for getting them to use 2FA? reply skybrian 13 hours agorootparentRather than sending an article that they'll ignore, I recommend helping them do it when you visit. Note: you're guarding against phishing and also locking themselves out of their accounts. Both are important. I bought Mom a Yubikey and helped her set it up on her Google account. She has it on her keychain. She doesn't need to remember how to use it, though, since it's only needed when she buys a new computer. For good measure, I also helped her print out backup codes (and I know where they are) and I registered my Yubikey, just in case. Nowadays, an old backup phone might also work, but I think paper backups are better because an old, unused phone might not start. reply luen 13 hours agoprevI want to know, how are you using AI now. reply darefalcon 16 hours agoprevIt’s actually worse than that - AI powered phishing sites will also copy your device profile and mouse, gesture and keyboard signature and use this to get past common anti-fraud techniques like device fingerprinting and behavioural biometrics. reply coffeebeqn 13 hours agoparentWhat does AI have to do with capturing inputs ? reply orbital-decay 13 hours agorootparentNot just capturing, but training on captured inputs to replicate the fingerprint. reply snowfield 12 hours agorootparentlaughable reply advael 15 hours agoparentprevI mean, the mere existence of said biometrics imply that they're inferrable and thus bad security, like basically all biometrics reply chefandy 13 hours agorootparentI think this is one of those \"the only thing that's worse is everything else\" situations. Surely there are solutions, but I doubt there are solutions banks and payment processors would be interested in paying for, and at least the US government isn't particularly interested in compelling banks to do anything expensive. reply bryanrasmussen 13 hours agorootparentprevbasically everything that retains the same structure between two occurrences can be inferred. Only randomness cannot be inferred. But true randomness is not useful for determining if you are who you say you are. reply advael 3 hours agorootparentEven a password can be changed if there's a compromise. Biometrics are bad because they can be imitated, but not changed. A breach is permanent reply bryanrasmussen 2 hours agorootparentgood point, but that was left out of the earlier statement about inference. I suppose I should have inferred it however. reply sroussey 14 hours agorootparentprevAnd yet, used extensively reply TechDebtDevin 13 hours agorootparentWhen I call my bank they verify with my voice. There are further verification for meaningful actions but its still kind of crazy to be using \"My Voice is my Password\" this day in age. reply AlotOfReading 12 hours agorootparentBetter than my bank, which tries to ask questions about my life from some lookup service that has incorrect information. reply reginald78 6 hours agorootparentprevEspecially since \"My Voice is my Passport\" was defeated in that movie with a tape recorder and technology at the time. It was never a good idea and even the movie didn't seem to think so. Yet my bank just turned this on for me as well in 2024. Now I have to figure out how to disable it...and will it really be disabled? reply advael 13 hours agorootparentprevI mean SSNs are the worst possible authentication mechanism and yet we still have to freak out every time they're leaked. Security practices are so utterly backwards everywhere that it's quite apparent no one powerful is incentivised to care even a little bit reply jimmaswell 13 hours agorootparentwhat's the practical alternative? reply advael 13 hours agorootparentNot pretending a GUID constitutes a security measure in the first place? It's just not the right tool for the job in any sense reply mnau 8 hours agorootparentprevDigital id card for every citizen? My id card can prove identity or sign a document and could for ~10 years. Estonia had it for over 20 years. Just give it to everyone. Today, it can likely be embedded in a cell phone instead of separate physical card. reply Kiro 8 hours agorootparentprevWhat do you mean? I don't know of any country except the US where SSN is used for authentication. In my country SSN is public information. reply immibis 13 hours agorootparentprevScanning your digital ID card would be a start, but oHnO that's cOmmUniSM! reply reginald78 6 hours agorootparentWouldn't this just result in my digitalid getting lost in the next equifax breech? reply immibis 4 hours agorootparentDid your credit card get lost in the last one? reply reginald78 18 minutes agorootparentHow would I know one way or the other if it had? I don't have the same number anymore. reply bryanrasmussen 13 hours agorootparentprevpickpocket's paradise! reply vincnetas 10 hours agorootparentBut it's not so scalable as online connected DB. reply lordofmoria 15 hours agoprev [–] The section “Recognizing AI phishing attempts” is mournfully short, but there’s some companies out there like Jericho Security (https://www.jerichosecurity.com) that are working on countermeasures, at least for enterprises. reply achneerov 13 hours agoparentIs this a self promo? reply lordofmoria 12 hours agorootparentno, it’s not… reply asynchronous 13 hours agoparentprev [–] I’m skeptical we can develop effective ones, due to the fact that we have been unable to solve non-AI phishing problems but I welcome their attempt. reply Mistletoe 11 hours agorootparent [–] When Google added Yubikeys it reduced phishing internally to zero. https://krebsonsecurity.com/2018/07/google-security-keys-neu... I adore my Yubikey. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Generative AI enables scammers to send highly personalized and convincing phishing emails, overcoming language barriers and automating mass campaigns.",
      "AI tools like WormGPT and FraudGPT assist in generating phishing emails and spoofing websites, significantly reducing the time needed to create effective attacks.",
      "Defense strategies include implementing DMARC (Domain-based Message Authentication, Reporting & Conformance), recognizing AI phishing attempts, using multi-layered security, and maintaining a strong sender reputation."
    ],
    "commentSummary": [
      "AI-powered phishing scams are becoming more sophisticated, leveraging technologies like Llama for text, Whisper/Tortoise for voice, and Stable Diffusion for images, though their deployment is still limited.",
      "Despite the potential for AI to enhance phishing, traditional methods like Indian call center scams remain highly effective and economically viable, as evidenced by a recent case where an elderly person was scammed out of $25,000.",
      "Banks and other institutions are improving their scam detection capabilities, but the rise of AI-driven scams necessitates increased awareness and education, especially for vulnerable populations like the elderly."
    ],
    "points": 167,
    "commentCount": 121,
    "retryCount": 0,
    "time": 1721170466
  },
  {
    "id": 40987402,
    "title": "TinyPod – Apple Watch case with scroll wheel",
    "originLink": "https://thetinypod.com/",
    "originBody": "Say hello to tinyPod. Everything you need. in the palm of your hand. Phone Music Messaging Mail Weather News Voice Memos Photos Calendar Maps Calculator Timer Podcasts Audiobooks Siri And more end end end end end Your phone away from phone. What if sometimes you could just… leave your phone at home? With all the essentials to stay connected, tinyPod makes that actually possible. More Powered by your Apple Watch. Transform the most powerful mini computer in the world into something new: A form factor made to function. More With a scroll wheel you'll love. What goes around, comes around! Rediscover the delight of tactile scrolling with tinyPod’s physical scroll wheel. And yes, it actually scrolls. More tiny, but mighty. Quick & Easy Magnetic Charging Start charging with a snap using your same Apple Watch magnetic charging cable. All day Multi-day battery life With wrist detection turned off, get even more milage out of your battery. A Phone A Music Player An Internet Communicator Are you getting it? Apple Pay & Name Drop Tap to pay or name drop your contact details, just like you would with your phone. Your AirPods' new best friend. The ultimate music player and then some. With 32GB, download music, podcasts & audiobooks for offline listening delight. Want to go extra minimal? Try tinyPod lite. Go lite if you don't want the scroll wheel, with a durable yet flexible case for any Apple Watch. Get yours Choose Model Case with scroll wheel tinyPod $79.99 Case without scroll wheel tinyPod lite $29.99  Watch Size 41/40 mm Compatible with Series 9, 8, 7, SE, 6, 5, or 4 45/44 mm Compatible withSeries 9, 8, 7, SE, 6, 5, or 4 49 mm (Ultra) Compatible with Ultra 1 or 2 Buy Shipping this Summer Live different. What it does How it works Why tinyPod Buy",
    "commentLink": "https://news.ycombinator.com/item?id=40987402",
    "commentBody": "TinyPod – Apple Watch case with scroll wheel (thetinypod.com)160 points by herbertl 2 hours agohidepastfavorite84 comments ykl 1 hour agoI unapologetically love this thing. It's of course very silly, and I'm sure commenters here are going to talk about all the ways that it isn't practical or that it's a niche idea, but I love whimsical silly niche hardware ideas that make it into actual hardware. I love that they put in all of the effort to figure out a mechanical linkage between the clickwheel and the digital crown! I don't think all hardware needs to be take-over-the-world hundred-million-unit ideas; I think sometimes it's fine for hardware to be whimsical niche things like this Apple Watch case or Andrew McCalip's doomscroller doo-dad [1]! [1] https://doomscroller.xyz reply jsheard 1 hour agoparentFunnily enough the inspiration may have come from Apple themselves, before the Watch was announced they covertly tested it in cases made to resemble an iPod knock-off. https://www.youtube.com/watch?v=bmgFk5hT6d8 reply alentred 1 minute agoprevI love the concept! I think TinyPod is an outcry over the sizes of the smartphones today. The smallest most recent iPhone you could buy was iPhone 13 mini and it was discontinued. Don't know about other brands, but from what I am seeing nothing fits the pocket anymore. There must but a niche for those who don't read or watch movies on their hand-held devices, and if the apps are well designed a smaller screen is just fine. reply sqeaky 30 minutes agoprevWhat a fun and cool idea on such a horrid web page. I am curious what it can do, but whatever is going on is illegible and busted for me. I literally couldn't read any text on the left half of the page. I managed to scroll down to a price and for what appears to be a tech toy $80 isn't the worst price, people burn more on a 3d only to make 1 toy boat that doesn't float then stuff it in a closet. reply cocacola1 23 minutes agoparentI absolutely loved the page. Had a lot of fun scrolling up and down and thought it was cleverly designed. Similar, but better, than what Apple does on their own pages. reply sqeaky 19 minutes agorootparentI suppose there is some novelty to this sort of thing. I have already had all that drained away years ago when this single all in one scrolling thing was a big fad. I never really liked this all-in-one scroll capturing pages, they violate so many user expectations. But I don't complain unless they are actually broken, others reported weird flashing, I am reporting bad Z-order and bad responsiveness. reply chant4747 20 minutes agorootparentprevThen you’re not experiencing the bugs that some others are experiencing. reply mesh 9 minutes agoparentprevYeah, page is busted for me also, super janky, images flashing in and out. Firefox on macOS reply 0vermorrow 1 hour agoprevIt's funny how we went from using iPod Nano as a watch with a third party case, to using an Apple Watch as an iPod Nano with a third party case. reply chant4747 19 minutes agoparentWe did? I don’t recall an accessory like that for the nano. Seems it would have been too tall (wide?) to function as a watch. Happy to be proven wrong though. reply DHPersonal 13 minutes agorootparentIt's a web search away, but here's an example from an article posted at the premiere of the watch: https://www.cnet.com/tech/mobile/2015-apple-watch-vs-the-201... reply jmah 14 minutes agorootparentprevJust search for \"iPod nano watch\". https://www.macworld.com/article/667363/ipod-nano-6g-with-st... reply ujeezy 10 minutes agorootparentprevIt was called the TikTok: https://ujeezy-blog.tumblr.com/post/2869125971/unboxing-the-... reply bastien2 31 minutes agoprevOh look, carcinisation for Apple products. ipodisation: the tendency for non-iPod Apple products to evolve iPod-like features over time. reply makmanalp 1 hour agoprevOK, in this vein, why oh why did Lyft and Uber remove their apple watch apps? I just need an app that's a single \"take me home now\" button so I don't have to worry about my phone battery dying when I'm out and about. Pretty please? reply atlasunshrugged 51 minutes agoparentYes! This is one of the critical things I need from an on the go device reply lokimedes 1 hour agoprevI bought an Apple Watch to get away from the “screen” but of all evils, Apple don’t let their watches pair to my car, not even for hands free coms. If only they would allow for regular stereo bluetooth and handsfree I would ditch my iPhone. Perhaps that is what they fear? reply sktrdie 7 minutes agoprevCool but doesn't the Apple Watch have all kinds of sensors to make it work against your wrist? Putting in this case will kind of remove the point of all those nifty hardware gadgets. reply graypegg 32 minutes agoprevDamn... I know it won't happen, but imagine Apple building out a device in a form factor similar to this case, using the extra internal space (compared to an apple watch) for a really nice DAC + headphone jack... I'd buy it. A streaming iPod! WatchOS would need some tweaks, but really most of the software is there. reply thih9 1 hour agoprev> What if sometimes you could just… leave your phone at home? With all the essentials to stay connected, tinyPod makes that actually possible. But that’s a feature of an Apple Watch, this case doesn’t impact this in any way - I already leave my phone at home like this and I don’t own this case. reply colingoodman 50 minutes agoparentI also thought it was funny that they are listing features like apple pay and magnetic charging as if these features have anything to do with the case. reply lawlessone 34 minutes agorootparentIt also tells the time. reply zikduruqe 15 minutes agoparentprevPlus I'd look goofy with my tan arms with my snow white watch tan mark. I also seldom, if ever, leave my house with my iPhone. reply sithadmin 1 hour agoprevAlong similar lines of thought: there is an Apple Watch case from Japan that replicates the once-popular Infobar 'candybar' phone handset: https://www.multicore.blog/p/infobar-apple-watch-case-review... Unfortunately the buttons are purely for aesthetics. reply chant4747 2 hours agoprevSeizure warning. Edit for clarification: The scrolling implementation here flashes rapidly on Firefox for Mac OS. reply ioshaan 19 minutes agoparentYes, the top half of the webpage acts as a power point presentation, with image flashes - instead of a smooth animation. - firefox on linux reply Clamchop 2 hours agoparentprevFlashes on first scroll for me as well, Firefox on Android here. reply mrstone 2 hours agoparentprevI'm on Firefox and it doesn't flash for me. reply RIMR 2 hours agorootparentFirefox for MacOS? reply leidenfrost 1 hour agorootparentI'm usinf Firefox for MacOS and it does indeed flash reply pipeline_peak 1 hour agoparentprevFire what? That old gui toolkit? reply sqeaky 22 minutes agorootparentDumping on other peoples software baselessly? Haven't decades old flamewars... gotten old? Looking back at your comment history, I can at least I can thank you for recycling. Too bad you can't get carbon credits recycling jokes. reply pipeline_peak 19 minutes agorootparent> Too bad you can't get carbon credits recycling jokes I just think it's silly when you guys aimlessly complain that modern sites don't support your decrepit charity browser. Don't you ever wonder what's in it for them? Putting in all that effort to fix a bug so all 500 of you guys don't have to switch to Chromium for 2 minutes? Clearly you took it so personally that you dug through my comment history. reply sqeaky 2 minutes agorootparent> I just think it's silly when you guys cry that modern sites don't support your decrepit charity browser. > > Clearly you took it so personally that you dug through my comment history. I look through most comment histories before responding. Because of this, I know that you are mostly reasonable on other topics. I find it interesting that you think prodding back is \"crying\", can you not take it as well as you deal it? What did Mozilla do you that makes you go from reasonable javascript coder to raging troll on this one specific topic? chant4747 22 minutes agorootparentprevDon’t quit your day job. reply pipeline_peak 20 minutes agorootparentThat's not the proper use of the phrase lol... reply peppertree 1 hour agoprevWatch Ultra are very capable mobile devices. This came out of left field but I can see it working for some. reply neolefty 40 minutes agoparentWhich Watch Ultra do you mean? Both Apple and Samsung products come up in web searches for \"Watch Ultra\" for me. reply mynameisvlad 23 minutes agorootparentThis article is pretty clearly about an \"Apple Watch case with scroll wheel\". Pretty sure which one it is can be inferred from context. reply aketchum 1 hour agopreva lot of negative comments here but i think this is really neat! It is unclear what the case adds besides the form factor and buttons. Is that the main value or does the case provide charging or additional memory or anything like that? Thanks for sharing! reply segasaturn 1 hour agoprevThis is great, it's the streaming iPod I always wanted! Preordered. reply mmanfrin 1 hour agoprevShould probably check that your site works in firefox before submitting to hn. reply stronglikedan 1 hour agoparentSeems like they did, considering it works well for me on the latest version of FF. reply wvenable 44 minutes agoparentprevWorks fine for me on FF and I have copious plugins installed. reply LegitShady 1 hour agoparentprevdo you have javascript disabled via noscript or ublock origin? It works fine on firefox for me. reply gnicholas 1 hour agoprevThis claims multi-day battery life, since wrist detection can be turned off. I’m curious to know how much of a difference this one change makes. I haven’t bought an AW because the battery life isn’t good enough for a “watch” in my book, but if it can get multiple days of life, and it’s more like a phone replacement, then I’d be more likely to give it a try. reply nicce 1 hour agoparentMy charged watch (series 6)on the table without any use runs out of battery in 24 hours… My main reason why I don’t use my watch anymore is that it needs to be charged all the time. reply gnicholas 1 hour agorootparentI have never understood why AWs consume so much battery at rest. I have a Garmin that lasts for several days, and I would be happy to have an AW what doesn't do all the stuff the AW does, but which is made by Apple. It could be a dumbed-down version that just vibrates and displays messages that I receive. I basically want a smartwatch so I can avoid phantom vibrations, and so I can quickly see what messages have come in so I don't have to get out my phone all the time. Is this an issue with WatchOS, the chipset being used, or the size of battery they have chosen? I know a lot of people out there who do not consider an AW or any other smartwatch because they don't want to have yet another device to charge daily. There are other companies that have achieved very good battery life (Amazfit, Garmin, Pebble), so it is clearly possible to have weeks-long battery life with a feature set that is more than enough for people like me. I feel like I'll never have an AW until they decide to make an AWU-sized device, but with more battery and fewer hardcore workout sensors. I don't need to dive with my watch, or have it utilize multiple satellites for GPS. What I do need for a watch is to have it last for more than a day or two, so I don't have to bring a charger whenever I go on a trip. reply dangus 1 hour agorootparentprevGet your battery replaced? reply nicce 1 hour agorootparentIt is still at 90% capacity. It never lasted much longer. reply anon115 18 minutes agoprevthe website is adorable reply chadhutchins10 1 hour agoprevHow does the scroll wheel work? Is it mechanical or it has some connection/interface with the software? reply Etheryte 1 hour agoparentThe how it works section says the following when you expand it: > Through carefully mechanized components inside, tinyPod's wheel makes direct rotation contact with your Apple Watch crown, letting it naturally scroll anything across the OS. reply orenlindsey 1 hour agoparentprevIt has to be mechanical, there are no input ports on the (current) Apple Watches. reply flemhans 53 minutes agorootparentWonder if the diag port would allow for it. > It's basically Lightning minus the PWR and ID1 pins, because those are for satellite accessories. reply asadm 1 hour agoparentprevI feel it must be mechanical since it interfaces with crown? reply JadoJodo 1 hour agoparentprev> \"What goes around, comes around! Rediscover the delight of tactile scrolling with tinyPod’s physical scroll wheel. And yes, it actually scrolls. How? Through carefully mechanized components inside, tinyPod's wheel makes direct rotation contact with your Apple Watch crown, letting it naturally scroll anything across the OS.\" reply laweijfmvo 1 hour agoparentprevtried to find that as well. the \"How it works\" section is completely useless. reply robofanatic 1 hour agoprevTinyPod -> TinyPhone -> TinyPad reply compscistd 1 hour agoprevOne thing the Apple Watch is missing is being able to call a Lyft or Uber. Not something I do super often but it really would let me leave the phone at home more often. Also would have liked to see a little hole in the corner to thread a loop to. reply testfrequency 1 hour agoparentMaybe an iOS shortcut could do it? Could even add inputs for address or current location… Looks like Maps lets you “request ride”, so possibly even the native maps method could work here. reply colingoodman 39 minutes agoparentprevUber used to have a watch app that allowed you to do this. I assume they canned it due to lack of usage. reply adregan 1 hour agoprevI've always wanted to take an apple watch and use it like a flip phone! This is pretty fun! I've never wanted the distraction of an apple watch and I appreciate the ability to put this thing in a pocket. reply oaththrowaway 1 hour agoprevI'd love to replace my phone with something like this. If only I could get Slack and Telegram to run natively without requiring a linked phone reply miniatureape 1 hour agoprevI think my perfect phone would be if Apple chopped an inch or an inch and a half off the bottom of the iPhone 12 mini and ran a slightly improved watchOS on it. reply praisewhitey 1 hour agoprevWould be cool if it also had a headphone jack reply ldayley 1 hour agoprevthis kinda serves of a proof of concept for just how minimal we can get with a smartphone while retaining most of the \"smart\". I might even try this for a bit... reply LegitShady 1 hour agoparentI dont think the average consumer wants this. They want a big screen, and flashy features, and a camera that makes ugly people beautiful. reply roughly 1 hour agorootparentThank god they’ve got every existing product on the market to choose from, then. reply ecjhdnc2025 1 hour agorootparentprevFinally I am not the average consumer! I think the parent comment's point is good -- if Apple are watching (pun not intended): you could make a truly tiny phone out of watchOS, please do it. reply LegitShady 1 hour agorootparentisn't apple getting so far out of the tiny phone game they've cancelled all the minis and even cancelled the next iphone SE? reply darby_nine 1 hour agorootparentprevHard to say without phones available that cater towards other needs. I'm waiting for one that brags about not having access to most functionality outside of phone, gps, sms, and camera. reply orenlindsey 1 hour agorootparentprevYeah, the lack of a camera is a big reason why the Apple Watch isn't a great phone replacement. reply ninininino 21 minutes agoprevI want to know it's water resistance. reply Jeremy1026 1 hour agoprevThis looks amazing. I do wonder though, how long it'll last before Apple C&Ds it. reply RandallBrown 1 hour agoparentThey might be able to C&D the name, but I doubt they'd do anything (or get anywhere if they tried) about the case. reply tantalor 2 hours agoprevDo not do the webpage scroll thing. Do not do it. No. reply laweijfmvo 1 hour agoparenti seriously hate this design reply camillomiller 1 hour agoprevI don’t get it. The Watch locks itself everytime it’s remove from the wrist and doesn’t stay unlocked if you unlock the screen when you’re not wearing it then let it go to standby. So… you would have to input a pin every single time you use this contraption? Seems quite annoying compared to, you know, wearing the watch. reply thoughtsimple 1 hour agoparentYou can turn off wrist detection so it stays unlocked. reply laweijfmvo 1 hour agoparentprevi guess it's the same as phones, before biometric authentication? but in general yeah, the watch was not designed to be used like this and anyone who's used a watch should be able to predict how bad the UX is gonna be... reply asadm 1 hour agoparentprevcant that be disabled? I think it can be reply borski 1 hour agorootparentYes. reply RIMR 1 hour agoprev [–] Wow, this pitch really hooks you, and then halfway through the glitch-heavy presentation you're made aware that this is just a cheap controller for your Apple Watch, and that literally every feature they are advertising is a feature of the Watch, not their product. I would never buy this because it sounds like drop-shipped garbage. The marketing should be more straightforward and tell you what this thing actually is upfront, instead of burying the lede and acting like they made a new kind of phone. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Introducing tinyPod, a compact device offering essential features like phone, music, messaging, and more, all powered by your Apple Watch.",
      "Key features include a tactile scroll wheel, quick magnetic charging, multi-day battery life, Apple Pay, and 32GB storage for media.",
      "Available in two models: tinyPod with a scroll wheel for $79.99 and tinyPod lite without a scroll wheel for $29.99, compatible with various Apple Watch series, shipping this summer."
    ],
    "commentSummary": [
      "TinyPod is an Apple Watch case that incorporates a scroll wheel, reminiscent of the iPod's clickwheel, creating a mechanical linkage with the digital crown.",
      "The product is seen as a fun, niche hardware idea, appealing to those who appreciate unique and whimsical tech gadgets, despite its impracticality.",
      "There are mixed reviews about the product's webpage functionality, with some users experiencing issues on Firefox, while others find the design appealing."
    ],
    "points": 160,
    "commentCount": 84,
    "retryCount": 0,
    "time": 1721232502
  },
  {
    "id": 40984589,
    "title": "Jia Tan \"JiaT75\": Added error text to warning when untaring with bsdtar (2021)",
    "originLink": "https://github.com/libarchive/libarchive/pull/1609",
    "originBody": "libarchive / libarchive Public Notifications Fork 756 Star 2.9k Code Issues 436 Pull requests 38 Actions Projects Wiki Security Insights New issue Jump to bottom Added error text to warning when untaring with bsdtar #1609 Merged mmatuska merged 1 commit into libarchive:master from JiaT75:added_error_message_to_warning_bsdtar_1561 Merged Added error text to warning when untaring with bsdtar #1609 mmatuska merged 1 commit into libarchive:master from JiaT75:added_error_message_to_warning_bsdtar_1561 +3 −4 Conversation 38 Commits 1 Checks 0 Files changed 1 Conversation Contributor JiaT75 commented Added the error text when printing out warning and errors in bsdtar when untaring. Previously, there were cryptic error messages when, for example in issue #1561, the user tries to untar an archive in a location they do not have write access to. closes #1561 1 152 5 5 1 3 94 Added error message when archive extraction fails f27c173 mmatuska approved these changes View reviewed changes mmatuska merged commit e37efc1 into libarchive:master mortie commented • edited @mmatuska This MR seems suspicious, the error message that's printed is almost identical before and after, but calls to safe_fprintf were replaced with calls to the unsafe fprintf. The diff doesn't make this obvious due to the removal of a newline in a parameter list. Given the recent uncovering of @JiaT75's backdoor inserted into XZ, can you double check that switching out safe fprintf with unsafe fprintf isn't introducing a vulnerability here? It appears that the unsafe fprintf calls introduced by this MR are still in the source code, unchanged: https://github.com/libarchive/libarchive/blob/master/tar/read.c#L374-L375 196 1 3 2 28 Contributor cperciva commented @mortie Looks to me like fprintf(stderr, \"%s\", strerror(errno)); is new? I'm not sure if the safe_fprintf matters since the strings here (error strings from libarchive and libc) should be 7-bit-safe, but I wouldn't mind switching that back. 10 wgaylord commented @mmatuska This MR seems suspicious, the error message that's printed is almost identical before and after, but calls to safe_fprintf were replaced with calls to the unsafe fprintf. The diff doesn't make this obvious due to the removal of a newline in a parameter list. Given the recent uncovering of @JiaT75's backdoor inserted into XZ, can you double check that switching out safe fprintf with unsafe fprintf isn't introducing a vulnerability here? It appears that the unsafe fprintf calls introduced by this MR are still in the source code, unchanged: https://github.com/libarchive/libarchive/blob/master/tar/read.c#L374-L375 They did also add more error printing using fprintf(stderr, \"%s\", strerror(errno)); Which was not in the original. I do agree, strange to change from safe fprint to normal fprint tho. 14 mortie commented You're right, I noticed that too upon closer inspection of the diff. And yeah, after reading up on both what archive_error_string returns and what's \"safe\" about safe_fprintf, replacing safe_fprintf with fprintf in this circumstance shouldn't change anything... it's just weird. Sorry for the ping. taviso commented (Hey Colin, LTNS! 👋 ) What about calls like this: libarchive/libarchive/archive_write_disk_posix.c Line 2256 in 2fb7b0carchive_set_error(&a->archive, en, \"Can't create '%s'\", or libarchive/libarchive/archive_write_disk_posix.c Line 1101 in 2fb7b0carchive_set_error(&a->archive, errno, I guess the concern would be that they could use terminal escape sequences to obfuscate the contents of archives? 45 obfusk commented FWIW, I noticed it's using errno directly instead of archive_errno(a), which might give the wrong error. Contributor cperciva commented @taviso Yeah, you're right. I forgot that libarchive put path names into there. Terminal escape sequences in pathnames could do all sorts of nasty things, including exploiting bugs in terminal emulators (I know there have been a few over the years). This should probably be switched back to safe_fprintf. And also use archive_errno as @obfusk notes. 30 12 mcatanzaro mentioned this pull request Security Concerns Regarding Recent Changes in Error Handling Code tukaani-project/xz#94 Closed sgammon commented @cperciva would it be helpful to offer a PR? Or is one already in the works 1 1 emaste added a commit to emaste/libarchive that referenced this pull request tar: make error handling more robust and use correct errno … f69df63 Discussed in libarchive#1609. emaste added a commit to emaste/libarchive that referenced this pull request tar: make error handling more robust and use correct errno … 6a14eca Discussed in libarchive#1609. Contributor kientzle commented A PR would be appreciated. 2 emaste added a commit to emaste/libarchive that referenced this pull request tar: make error reporting more robust and use correct errno … e200fd8 As discussed in libarchive#1609. Contributor emaste commented • edited What about calls like this: libarchive/libarchive/archive_write_disk_posix.c Line 2256 in 2fb7b0carchive_set_error(&a->archive, en, \"Can't create '%s'\", I'm not sure if there are potentially problematic archive_set_error calls in the read path, but no matter - there's no reason to avoid using safe_fprintf. I have a change in my local tree that I'll push to a PR. 3 emaste mentioned this pull request tar: make error reporting more robust and use correct errno #2101 Merged no-usernames-left mentioned this pull request Backdoored liblzma (CVSS 10.0) might be present in qubes-template-archlinux 4.2.0-202403061411 QubesOS/qubes-issues#9067 Closed obfusk commented I'm not sure if there are potentially problematic archive_set_error calls in the read path Not sure how easy that would be to exploit, but I think this call could be a source of the error being printed: libarchive/libarchive/archive_read_disk_posix.c Line 747 in 2fb7b0c\"Couldn't open %s\", tree_current_path(t)); DanielRuf commented That commit definitely looks fishy. kientzle pushed a commit that referenced this pull request tar: make error reporting more robust and use correct errno (#2101) … 6110e9c As discussed in #1609. Contributor kientzle commented Thanks to @emaste we have merged a fix to the issues observed above. 26 1 1 darksylinc commented • edited I come here after knowing about this. I fear the fixes may not be enough. There are two issues with the current code: strerror is not thread safe which means it can be potentially exploited by having another thread manipulate strerror's internal buffer so that the null terminator is ignored when it's evaluated by printf/safe_printf (due to race conditions). I speculate this could be used to leak secrets. Since printf would continue printing beyond the original null terminator, until it encounters a 0x00 in the stream. On certain systems it is known for strerror to return nullptr on certain conditions; which may cause a crash. Normally I wouldn't pay this much attention but given that this code was deliberately put by a hostile actor; I suggest the strerror be removed, or replaced by a thread-safe variant and check for nullptrs. 8 1 19 LeSuisse mentioned this pull request libarchive: pull the fix for a suspicious commit NixOS/nixpkgs#300114 Merged 13 tasks davispw commented I think this needs its own CVE. 26 7 16 3 1 Contributor jsonn commented I don't see any evidence that either problem is relevant. bsdtar is not multithreaded. The errno values are from system calls, so if your libc doesn't do something sane in that case, it is already broken. 34 pld-gitsync pushed a commit to pld-linux/libarchive that referenced this pull request rel 2; improves changes made by user who bacdoored xz - libarchive/li… … fc32b80 …barchive#1609 algitbot pushed a commit to alpinelinux/aports that referenced this pull request main/libarchive: backport upstream fix … 71d684e ref: libarchive/libarchive#1609 (comment) no-usernames-left mentioned this pull request Audit xz and libarchive in dom0 etc due to being released by known-malicious individual QubesOS/qubes-issues#9071 Closed 11 hidden items Load more… Contributor kientzle commented I think this needs its own CVE. If someone who has experience with CVE processes wants to drive this, please contact security@libarchive.de first so we can ensure that we don't get a bunch of duplicate filings. spixi commented @anarazel Sorry, that I am mentioning this here, but the clone of the compromised repository is set read-only. I wonder, if fionn/xz-backdoored@4430e07 also belongs to the exploit, because -O2 makes it much easier to inject code than -O3 1 rpigott commented I have some examples of exploits against busybox and OpenBSD tar in https://dgl.cx/2023/09/ansi-terminal-security#vulnerabilities-using-known-replies I suspect those could apply nearly unmodified here. The commit still uses safe_printf for the pathnames, though. I don't think those are applicable here at all. algitbot pushed a commit to alpinelinux/aports that referenced this pull request main/libarchive: backport upstream fix … 7850925 ref: libarchive/libarchive#1609 (comment) (cherry picked from commit 71d684e) algitbot pushed a commit to alpinelinux/aports that referenced this pull request main/libarchive: backport upstream fix … 15099e8 ref: libarchive/libarchive#1609 (comment) (cherry picked from commit 71d684e) algitbot pushed a commit to alpinelinux/aports that referenced this pull request main/libarchive: backport upstream fix … ac0d5e9 ref: libarchive/libarchive#1609 (comment) (cherry picked from commit 71d684e) algitbot pushed a commit to alpinelinux/aports that referenced this pull request main/libarchive: backport upstream fix … 55edc5c ref: libarchive/libarchive#1609 (comment) (cherry picked from commit 71d684e) jjerphan mentioned this pull request Backport libarchive#2101 conda-forge/libarchive-feedstock#85 Closed 5 tasks bell-sw pushed a commit to bell-sw/alpaquita-aports that referenced this pull request core/libarchive: backport upstream fix … dff9056 [ commit 71d684e85c10ef13ef790a7195a1cf74722e9b52 ] ref: libarchive/libarchive#1609 (comment) aeiouaeiouaeiouaeiouaeiouaeiou added a commit to aeiouaeiouaeiouaeiouaeiouaeiou/macports-ports that referenced this pull request libarchive: backport upstream fix … ef50636 libarchive/libarchive#1609 aeiouaeiouaeiouaeiouaeiouaeiou mentioned this pull request libarchive: backport upstream fix macports/macports-ports#23299 Merged 12 tasks Contributor emaste commented The commit still uses safe_printf for the pathnames, though. I don't think those are applicable here at all. The issue is that the pathname can also end up in the error string. $ touch $(printf '\\033[31mred\\033[0m') $ tar -c -f escape.tar *red* $ (cd /var/empty && tar -xf ~/escape.tar) \\033[31mred\\033[0m: Can't create 'red': Operation not permitted tar: Error exit delayed from previous errors. Note though that there are other cases where archive_error_string() might be printed unescaped (e.g., when passed to lafe_warnc() or lafe_errc()), so this should be addressed in a more comprehensive manner. GossiTheDog commented Windows 11 bundles libarchive, but I don’t know if they ever call this part. Contributor DHowett commented • edited Windows 11 bundles libarchive, but I don’t know if they ever call this part. This is part of tar's archive reader; it is likely that it is used in Windows' tar.exe. 🙂 EDIT: I misread which part of the code this was; corrected above. juraisa commented way too many arm chair \"researchers\" in this thread I have a bigger question, if the switch from safe fprintf is actually a concern, why did maintainers of this project approve the merge. Are commits actually being reviewed or just blindly approved cuz you recognize the PRs name attached to it? 2 16 3 1 tomfitzhenry mentioned this pull request libarchive: revert suspicious commit from bad actor NixOS/nixpkgs#300122 Closed 13 tasks faisal added a commit to faisal/homebrew-core that referenced this pull request Patch libarchive to make tar error reporint more robust … e335fed Patch the libarchive formula with a fix to make tar error reporting more robust and use correct errno. For more context, see libarchive/libarchive#1609 and libarchive/libarchive#2103. jh it seems prudent to (at least) review again commits by the same author.tkFollowing the xz backdoor (https://www.cve.org/CVERecord?id=CVE-2024-3094), the libarchive team reviewed commits by the same author. This faisal added a commit to faisal/homebrew-core that referenced this pull request libarchive 3.7.2: patch to make tar error reporting more robust … 2be329c Patch the libarchive formula with a fix to make tar error reporting more robust and use correct errno. For more context, see libarchive/libarchive#1609 and libarchive/libarchive#2103. faisal mentioned this pull request libarchive: patch to make tar error reporting more robust Homebrew/homebrew-core#167666 Merged 6 tasks vonHabsi commented I don't know much about C++ programming syntax, but shouldn't there be stronger code-formatting rules that pull requests must meet before they are reviewed let alone accepted? The intent of the changes may be obvious to those with C++ experience but looking at the diff it looks to me like there was something off about it. I think software should be designed and implemented in such a way that those with limited domain expertise but good programming experience can spot irregularities or stuff which looks \"off\". Hopefully this won't cause much of a digression from the main topic. 4 Speculate7348 commented CIA vibes Bo98 pushed a commit to faisal/homebrew-core that referenced this pull request libarchive: patch to make tar error reporting more robust … ef2fe6a Patch the libarchive formula with a fix to make tar error reporting more robust and use correct errno. For more context, see libarchive/libarchive#1609 and libarchive/libarchive#2103. TheDirigible commented We should prefer the naming convention printf() and unsafe_printf(), no? mortie commented • edited @TheDirigible fprintf is from the C standard library, safe_fprintf is a function internal to libarchive which does extra filtering. There's nothing libarchive can reasonably do about fprintf. gerrywastaken commented I suggest looking closely at those who approved said PRs, and other PRs they approved. The review process is the only protection we have and if it is compromised that is a bigger issue. Contributor kientzle commented A group of very experienced engineers has been working for a couple of days on this issue. We've audited all changes made by the one account that is known to have made malicious changes to xz. This change to error printing is the only one that has any concerns. It has been fixed and we'll be coordinating announcement and updates to libarchive through the appropriate channels. We will continue to examine libarchive for any evidence of similar problems and will address any that we find. Thanks for your patience and assistance. If you know of any other problems with libarchive, please: If it's a security-critical issue, please email security@libarchive.de If it's a non-security-critical bug, please file an Issue in this github repository. Most importantly, please keep this in mind: We're all victims here. 4 5 Contributor emaste commented @kientzle perhaps we should close this to new comments? The specific case here has been addressed via #2101, I'm opening an issue for @jsonn's suggestion above of escaping pathnames in error strings, and anything else should be addressed via one of the two paths in your preceding comment. emaste mentioned this pull request unescaped pathnames may be printed in error cases #2107 Open Contributor kientzle commented Good idea! I'll do so. libarchive locked as resolved and limited conversation to collaborators Sign up for free to subscribe to this conversation on GitHub. Already have an account? Sign in. Reviewers mmatuska Assignees No one assigned Labels None yet Projects None yet Milestone No milestone Development Successfully merging this pull request may close these issues. Confusing warning message when attempting to modify a directory without sufficient permissions 28 participants",
    "commentLink": "https://news.ycombinator.com/item?id=40984589",
    "commentBody": "Jia Tan \"JiaT75\": Added error text to warning when untaring with bsdtar (2021) (github.com/libarchive)156 points by Bluestein 7 hours agohidepastfavorite86 comments zokier 6 hours agoGitHub \"community\" is just awful. There are people trying to get real work done in that thread, but then there are all these random bystanders piling up to throw in their comments which range from useless to actively harmful and distracting. And it's not an isolated case, this happens pretty much always when some issues attracts attention on GH. Can't we respect the project and give the people there space to work, and leave the peanut gallery commenting to reddit/hn/twitter/whatev. reply nindalf 6 hours agoparentI like the comment that started with \"way too many arm chair 'researchers' in this thread\" and then goes on to rudely say that the maintainers are doing a bad job because they merged in the original changes by Jia Tan. What are you sitting on, if not an arm chair? We all agree that the xz attack was of unparalleled sophistication and complexity, spread carefully over years, funded by a State. Many people were taken in so how is it helpful to pile on Jia Tan's primary victims? reply freedomben 5 hours agorootparentI thought that was a good question, and certainly one I'd like to know the answer too, but I very much agree it was done rudely. It didn't seem like it was asked in good faith. Anyone who has maintained large/complex software like this knows that name recognition is worth a ton, and it kind of has to be that way. It's just not practical at all to scrutinize every commit/change as though the committer is an adversary, and particularly when you know the person it is not a reasonable ask. I would bet the truth is basically \"yes, we knew him so it didn't get full scrutiny,\" and honestly that's an honest (but hard to give) answer. I do hope (perhaps naively) that this (security code reviews) is something AI can get really good at in the future, because that would be a real value add IMHO. reply BalinKing 5 hours agorootparentThis change doesn’t look like it would’ve required much scrutiny, though… it’s three lines long and seems (admittedly as an uninformed outsider) to be obviously wrong. Like, ignoring the fact that Jia Tan happened to be an adversary, I’m kinda shocked that their code review process let it through—unless the standard quite literally is “recognized contributors get rubber-stamped without further review.” reply joh6nn 5 hours agorootparentRight, but that was the exact nature of the attack: it's a small commit that doesn't look like it needs a lot of scrutiny. Like, I get that you meant \"it wouldn't take much scrutiny to find this\" but I mean \"it doesn't look like it needs to be scrutinized\". Especially because, as mentioned in the first comment of the investigation, the change to an unsafe behavior is deliberately obscured by the formatting of the diff. It's like Where's Wal(do|ly): once you know where to look, it's obvious, but if you don't even know you're supposed to be looking for it, you may never find it reply chefandy 5 hours agorootparentRight-- A busy maintainer sees a weird looking commit-- but it's three lines long, submitted from a known contributor, and the tests pass. It was very carefully planned to be innocuous-looking enough to not trigger any concerns with a casual once-over (oh, it just changes the way an error is printed) and obfuscated enough to not be obviously malicious because of the diff formatting, and submitted by a reliable known contributor. Each piece was designed to make a rigorous code review as unlikely as they could possibly make it. Sure, that's not how it's SUPPOSED to happen, but I'll eat my hat if at least 95% of people who've approved a PR at some point couldn't have been walked down that path by a dedicated attacker over time. Hopefully this has been enough of a jolt to make that less likely the next time someone tries it. People often cite death and taxes as the only certainties in life-- we could easily include human fallibility. reply Bluestein 2 hours agorootparent> People often cite death and taxes as the only certainties in life-- we could easily include human fallibility. What was it ... 80% of aviation accidents due human error? reply Bluestein 5 hours agorootparentprev> I do hope (perhaps naively) that this (security code reviews) is something AI can get really good at in the future, because that would be a real value add IMHO. It would offer a good solution, and one that would scale.- (Until, of course, the AI systems themselves become compromised or weaponized ... But that is a few arms race cycles away yet.- reply zarathustreal 5 hours agorootparentprevIt’s hard to give that answer because after a security breach has happened, you know you made the wrong choice. It’s a tradeoff, as you said, for practicality. Sometimes you gamble and lose. The bank doesn’t care that “well there was a good chance I was going to be fine” when it comes time to pay your mortgage. “But I’m the only one that knows the floor plan!” doesn’t quite cut it. Exit the premises and get some therapy. reply pas 5 hours agorootparentprevI recently removed the arm rests from my shitty IKEA chair (to apply WD40 silicone, because the standard cheap mechanism was creaking every time I leaned back, even if it was locked), and decided not to put them back, because they incentivized slouching so akcheually some people are sitting on a block of concrete! theorizing that it was wrong to merge in itself is not victim blaming. but of course piling up in GH discussions and issues unconstructively, and just expressing opinions is bullying. reply psychoslave 5 hours agorootparentprevIt seems that blaming victims can really provide some power thrill, to which human can easily become addicted to. Raising competent empathic well balanced individuals is difficult, to say the least. And it’s not like the so called world leader elites really show they are some paragons of these traits. reply prmoustache 6 hours agorootparentprevThe question is still very relevant. Why are PR like this merged to begin with? reply joh6nn 5 hours agorootparentThe malicious commit was designed to be confusing, as noted in the first comment of the investigation: > but calls to safe_fprintf were replaced with calls to the unsafe fprintf. The diff doesn't make this obvious due to the removal of a newline in a parameter list. It wasn't noticed because it was specifically designed not to be obvious. reply ivanjermakov 6 hours agoparentprevThis is why a lot of projects use other tools for bug tracking and merging, e.g. bugzilla, youtrack, atlassian etc. reply AshamedCaptain 5 hours agorootparentThe opposite. Whenever some project migrates to an inferior alternative like Github or Discord they always claim a number of arguments which boil down to \"it's where people go these days\" (e.g. less friction for newcomers, most people have an account there already, larger community, whatever excuse you can come up). So I say they are getting exactly what they wanted to get. reply ivanjermakov 4 hours agorootparent> less friction for newcomers This is exactly the problem. If you want your resort be vandalized, build a nice road to it. And some orgs are even eager to fuel this with things like Hacktoberfest. reply mistrial9 5 hours agorootparentprevApache Foundation maintains a lengthy list of capable projects ... shout out to TRAC first reply madeofpalk 5 hours agoparentprevAbsolute worst is when you see the \"Hi from HN :wave:\" comments when Github issues/PRs linked to from here. Maintainers can 'lock down' the issue to just projects members, but that's very much an after-the-fact thing. reply keepamovin 4 hours agoparentprevLiberal use of the GH moderations tools, like block user, and interaction limits, is your friend. reply ahoka 5 hours agoparentprevBecause it's September, 1993. reply Cthulhu_ 5 hours agoparentprevGH needs a system like most forum communities have where comments can be put in a moderation / approval queue before being public. reply keepamovin 3 hours agorootparentNot a bad idea. I guess the UX is not hard, but likely it would clash with GH's bias towards openness/transparency/public record. Possibly risk making moderation 1st class citizen, they may fear this would detract from the main purpose of collaborative code production. Yet...it could help that. But I understand it's a tricky nuance. So, they have comment minimization by assigned moderators. Or you can just delete / edit comments and issues. Obviously not as powerful as a pre-screening queue. Less work tho! reply Bluestein 2 hours agorootparentThey'd end up like SO ... reply assbuttbuttass 5 hours agoparentprevPeople treat Github like social media reply ahepp 5 hours agorootparentIt seems like GitHub encourages that? I mean, emoji reacts to issue comments? Not really sure what the point of that is besides \"driving engagement\". I guess the argument for it is that it lets people easily \"get involved\"? Seems like there's some merit to making it easy for users to leave feedback. Maybe thumbs-up or thumbs-down on an issue really is valuable feedback in some situations. I'm torn between saying the social features are bad because they lower the barrier for low quality engagement, and saying that even low quality engagement can lead to valuable insights. reply zokier 2 hours agorootparentprevGithub is social media reply turtle_heck 5 hours agorootparentprevThat's because it kinda is a social network. You can \"follow\" people after all. reply Bluestein 5 hours agorootparentprevThis.- PS. And, for some people it might undoubtedly be *all* their \"social\" ... reply posed 5 hours agorootparentprevIt is a social medium by definition, tbf. reply joh6nn 6 hours agoprevI'm confused why this is being posted now? This thread appears to have taken place in the days immediately following the original XZ discovery, with no new activity since very early April. It was discussed heavily at the time that Jia Tan had made contributions to other projects and that those were being investigated as well. Is there something new here I missed, or some additional context that makes this specific commit relevant right now? reply oefrha 6 hours agoparentSince the posted thread has been locked since April, even if there’s new information it can’t be on the posted page. I suspect a lot of votes come from people thinking there’s significant new information (otherwise why would this suddenly be #1?) when there’s none. reply bibinou 5 hours agoparentprevKarma farming. reply joh6nn 5 hours agorootparentOk, but to what end? Is there some karma-to-dollars pipeline that I don't know about? There a bunch of other platforms that superficially seem like much softer targets with more obvious payoffs. Like, if we put it in the classic context of 1. Farm Karma 2. ? 3. Profit! I'm not clear on step 2. What's step 2 And of course that pre-supposes malice (or at least greed), which is in violation of Hanlon's Razor. reply bibinou 4 hours agorootparentCoincidentally, Reddit (YC05) IPO'ed in March so I'm sure you'll find plenty of analysis on that. Gallowboob reportedly got paid . It used to be called Curation, Marketing, or Expert Advice but it's been algorithmified to death. reply joh6nn 3 hours agorootparentSorry, I don't understand the point you're making here. Are you saying that karma farming on HN leads to successful IPOs? Or are you saying that karma farming in general can be profitable? Because both of those are what I was trying to speak to when I said that I feel like there are much softer targets than HN: it seems much easier to me to profit from karma farming on other platforms than it would be here. Maybe I'm just not engaged enough and/or naive, but I don't think of even high-karma users on HN as being Influencers. Like, I don't see myself spending money on something specifically because tptacek endorsed it. On Instagram, it makes sense to me: 1. I farm for likes and karma 2. I start endorsing low value crap from whatever fad is trending this hour 3. Profit On HN, I have no idea what step 2 is: what is the middle step between farming and profit that doesn't involve, like, founding a startup? What's the specific tactic on this platform? reply bibinou 3 hours agorootparentSorry, I didn't see the \"much softer targets\" remark but I disagree anyway. Marketing on HN can be very powerful. The mindshare gain can be enormous. Niches in general are very rewarding if the underlying platform (Google/Facebook/Amazon/Ebay) doesn't deplatform you. I don't have time to look it up but I'm sure minimaxir (Certified HN Influencer) has made a study on it. PG remarked on it in What I've Learned from Hacker News[1]: \"But what happened to Reddit won't inevitably happen to HN. There are several local maxima. There can be places that are free for alls and places that are more thoughtful, just as there are in the real world; and people will behave differently depending on which they're in, just as they do in the real world. I've observed this in the wild. I've seen people cross-posting on Reddit and Hacker News who actually took the trouble to write two versions, a flame for Reddit and a more subdued version for HN.\" Anecdata: just today I reactivated an account on a startup I learned about from a Show HN[2] [1] https://paulgraham.com/hackernews.html [2] https://news.ycombinator.com/item?id=24990238 reply joh6nn 3 hours agorootparentOk, thanks, this is exactly what I needed. I'm apparently too much of a casual user here because I don't even recognize minimaxir as a username. So that's gotta be the disconnect for me: all the usual tactics apply, they're just less obvious to me because I'm not engaged enough. I appreciate you taking the time to respond thoroughly. Thanks! Edit: it occurred to me that another potential reason that the tactics used to monetize karma farming on HN may be less obvious to me than on other platforms is because here, the tactics are more specifically designed to target me reply hiisukun 7 hours agoprevI guess for those not sure of the context: The user Jia Tan added exploit code to the 'xz' tool as part of a larger deal. Wikipedia has a page on it here [1]. In this post, they are discussing some changes to print code specifically for the libarchive project, and some notable personalities in the security community chime in, including Colin Percival (Tarsnap among others) and Taviso (Google project zero among others). [1] https://en.wikipedia.org/wiki/XZ_Utils_backdoor reply throw0101c 7 hours agoparent> The user Jia Tan added exploit code to the 'xz' tool as part of a larger deal. Various discussions on this backdoor (in rough chronological order): * Backdoor in upstream xz/liblzma leading to SSH server compromise:† https://news.ycombinator.com/item?id=39865810 * What we know about the xz Utils backdoor that almost infected the world: https://news.ycombinator.com/item?id=39891607 * How the XZ Backdoor Works: https://news.ycombinator.com/item?id=39911311 * The xz sshd backdoor rabbithole goes quite a bit deeper: https://news.ycombinator.com/item?id=39956455 * XZ backdoor story – Initial analysis: https://news.ycombinator.com/item?id=40017310 † Original report, AFAICT. reply r721 6 hours agorootparent>XZ backdoor story – Initial analysis Here are parts 2 and 3 (weren't discussed on HN): >Part 2: Assessing the Y, and How, of the XZ Utils incident (social engineering) https://securelist.com/xz-backdoor-story-part-2-social-engin... >Part 3: XZ backdoor. Hook analysis https://securelist.com/xz-backdoor-part-3-hooking-ssh/113007... reply Bluestein 2 hours agorootparentSomething tells me that somewhere deep in a millitary facility somewhere, somebody is getting court marshalled, if not downright worse (after having been found out, I mean ...) PS. Or some \"unaffiliated\" group somewhere is getting their SOF cut off ... reply Macha 7 hours agoprevThis was discussed at the time of the libxz revelations and they did re-review all commits in light of this: https://github.com/libarchive/libarchive/issues/2103 reply wengo314 6 hours agoparentimho it's embarrassing that this got merged in the first place. it's not a major flaw, and no exploit. but it seems as if nobody paid due attention to actual changes. reply renewiltord 5 hours agorootparentFunny how everyone's competent in hindsight and eager to share that. reply xyst 6 hours agoprevWild. All of these carefully inserted “seemingly innocuous” changes in the ecosystem to end up contributing to a wider exploit. This comment sums it up nicely with a gif: https://github.com/libarchive/libarchive/pull/1609#issuecomm... reply wengo314 6 hours agoparentthis explot is basically \"death by a 1000 papercuts\", now that i think about it. reply bufferoverflow 3 hours agorootparentMore like assemble a sword from 1000 sheets of paper and stab everyone. reply londons_explore 5 hours agoprevAm I the only one a little concerned that no obvious attack has been found from this? It seems doubtful that a state actor is trying to use terminal escape sequences to hide an error message... The state actor wants code execution, not the ability to backspace some warning on a developers terminal. Besides, using such a vulnerability seems far too dangerous - those escape sequences would be plainly obvious in any log file or any inspection of files on-disk. And at the same time, if you are an undercover state actor, there is no point in potentially revealing yourself by inserting some security problem that isn't exploitable. reply omoikane 1 hour agoparentThere had been code execution exploits tied to escape sequences, for example: https://news.ycombinator.com/item?id=40428032 - Abusing url handling in iTerm2 and Hyper for code execution (2024-05-21) reply bthrn 5 hours agoparentprevThe goal here is to submit what appears to be a sequence of innocuous changes, none of which on their own are “obvious” vulnerabilities. The truth is, we don’t know what the strategic depths of this actor are. It may be years before we know whether an attack is successful. For example — and this is just hypothetical - the author may have found that some consumer of this codebase uses it in a script, and consumes console output in some form. By modifying its output to behave differently, they may be able to influence the consumer’s execution in some clever way so as to create other conditions necessary for additional exploitation. Or - the PR could have just been a test to gauge the scrutiny of the approvers. reply Bluestein 4 hours agorootparentThe \"funny\" thing here is that this is (somewhat, perhaps?) how an AI intelligent beyond human capacity might execute an attack - or what an attack by one such might feel like: Lots of apparently unrelated actions, many or all of which make no sense ... ... (until and if you see the larger picture, which might be insurmountably difficult ... ... this, coupled with AI-level scalability of social engineering, at AI-level scale -and- with an AI-level understanding of \"known-outcomes\" that might be desirable towards given goals: \"Leader change\", etc.-) reply elric 7 hours agoprevI'm a little unclear as to why JiaT75's github account still exists? Surely this should be nuked from orbit so that no one accidentally ends up using their shady code? reply falqun 7 hours agoparentThe deletion of the account would not delete commits associated with it. The commit would still contain everything potentially malicious, plus a reference to an account that would be deleted. Which is actually worse, you cant track what code a malicious actor has contributed (easily). So the correct thing to do is take away login / deactivate the account, and then start going through all contributions and check them via the account that references all of this. reply alphabetting 6 hours agorootparentWould be cool if there was a big warning icon with \"ACCOUNT LOCKED: STATE ACTOR\" like for cheaters on chess websites reply sammcgrail 7 hours agoparentprevHistory is useful reply TickleSteve 7 hours agoparentprevremoving their account doesnt remove their commits. reply poikroequ 5 hours agoparentprevIt's useful to keep it up so the public can scrutinize all their commits and fix anything suspicious. reply elric 5 hours agorootparentSure, but there is zero indication of that on their user page. At the very least the account should be disabled, all repos should be archived, and a big fat warning banner should be prominently visible. The current state of affairs seems irresponsible. reply Bluestein 5 hours agoparentprevLabeling - bringing up the actor, and the method involved - is useful.- reply JadeNB 4 hours agorootparentWhy do you write all your periods \".\" in this post (but not in others, per your comment history) as \".-\"? reply Bluestein 2 hours agorootparentHate to bother you with a reply on this, but, since you mention ... I beg to differ, I actually checked.- I'd hate it if I had been less than consistent :) PS. At least from about 2021 on ... reply JadeNB 12 minutes agorootparentWhat I found was a bunch of '...' without a period, which I assumed indicated the general trend, but on further searching I see that it is as you say. Nonetheless, if I may still ask, why? reply keybored 4 hours agoprev> The diff doesn't make this obvious due to the removal of a newline in a parameter list. I like to separate every little intentional change into their own commits. So a formatting change would be separated into its own commit. If you are looking for “red flags” notice if the diff is clean or not according to what you expect to see changed; if you only expect to see some error text change then multiple lines being changed is weird. Also use a decent diff viewer which is somewhat content/language-aware. reply lkdfjlkdfjlg 6 hours agoprevPeople in the Western world are comfortable and people in China are very motivated. I've been reading \"the man who solved the market\" about Jim Simons and his hedge fund Renaissance. This reminds me that there was a period just after the fall of the Soviet Union where Renaissance was flooded with very technically strong, very motivated, very hard working, and very fraudulent ex-USSR people. They're leaking guys, wake up. reply AHTERIX5000 6 hours agoparentI'd be surprised if China has anything to do with this operation. reply Bluestein 5 hours agorootparentThat is actually a thought.- reply bediger4000 6 hours agorootparentprevWho do you favor? One of the Russian Intel agencies? NSA? The Grugq? reply peanut_worm 7 hours agoprevwhy wouldn’t they just immediately reject it if they know its the same guy from the xz thing? reply blueflow 7 hours agoparentChronology. \"the XZ thing\" happened 3 years after merging. reply Sebb767 7 hours agoparentprevThe PR is originally from 2021 and has been merged back then, but there's more recent discussion on it about whether this introduces a vulnerability. reply H8crilA 7 hours agoparentprev[2021] reply peanut_worm 7 hours agorootparentgood thing that was in the title reply joh6nn 6 hours agorootparentAsking in seriousness: did you comment without reading the link? If so, why? I legit don't understand why people comment on things without having read them, and I would like to reply OJFord 6 hours agorootparentI'm not who you asked, but sometimes the comments are more interesting (or perhaps intriguing, enticing, is a better way to put it) than the submission itself. Sometimes of those times my interest in the submission grows with reading some of the discussion, and then I'll read it. (Not to say I always do this, but I do definitely click first into comments more often than I go straight for the article - it allows a much lower bar for what seems initially interesting, and I've read a lot more fascinating stuff (submissions and discussions) than I would have otherwise that way.) reply joh6nn 6 hours agorootparentInteresting! But this sounds like an explanation why you read the comments without reading the article, not why you comment without reading, and those aren't inherently the same thing. So to clarify: do you comment on the content of the post without reading it? I'm specifically interested in why people comment on links and articles they didn't read. And for maximum clarity here, I mean commenting on the content of the article, not just contributing to the various related discussions it spawns. And to reiterate, I'm asking in earnest. It's not something I would do, so I'd like someone who does to weigh in. reply freen 6 hours agorootparentprevFrist Psot culture is real: everyone else sees the “contribution”, and if it happens to be of marginal value, it earns karma. Stochastic karma farming benefits from a larger N, hence posting without reading. reply joh6nn 5 hours agorootparentThanks for weighing in! But this is just speculation, right? Are you speaking from experience? I'm specifically looking for someone who does it to explain it. I mean, I can make my own guesses about various forms of attention seeking and hopes to somehow cash in on high karma all day long but, to me it feels like HN is among the worst possible venues for that. I'm not aware of easy ways to convert HN karma into cash flow like you maybe could with followers on other platforms. So I don't immediately see a benefit in just farming karma for its own sake. Is there some benefit to karma farming I'm not aware of? Like, some points-to-dollars conversion stream that I'm not in the loop on? reply throwaway2037 7 hours agoprev@dang: Please add [2021] to the title. reply exitb 7 hours agoparentOnly the original commit was from 2021. The discussion is recent. reply Zitrax 6 hours agorootparentRecent is relative, the latest comment is from April 2024, not something that popped up today. reply lopkeny12ko 6 hours agoparentprevWhy? It is immediately obvious that the PR was published 3 years ago. Github shows the timestamp very clearly in multiple places. reply boesboes 6 hours agorootparentYes, but this is not about the PR, it is about the discussion. The dates are shown very clearly in many places too. ffs reply boesboes 6 hours agoparentprevDiscussion is from this year, try reading for context reply cookiengineer 6 hours agoprev [–] It's kind of ridiculous how few lines of code can trigger such a huge and complex discussion about thread safety, where almost all developers involved actually aren't really certain whether or not this can be exploited. I just wish people would stop writing C code for libraries that consume arbitrary data. reply fooker 6 hours agoparentYes, please stop writing C and C++ code! (... and leave the high paying jobs to us of course) reply SpaghettiCthulu 5 hours agoparentprev [–] In this case it doesn't matter whether it's C or Rust. Both languages, if using their default string formatting facilities, are vulnerable. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Libarchive merged a commit to add error text to warnings when using bsdtar, addressing issue #1561, but concerns about replacing safe_fprintf with unsafe fprintf were raised.",
      "A fix was implemented to revert to safe_fprintf and use correct errno handling, with suggestions for further audits and a CVE (Common Vulnerabilities and Exposures) for the issue.",
      "The discussion underscored the importance of thorough code reviews and maintaining security in open-source projects, and the issue was resolved with the conversation locked."
    ],
    "commentSummary": [
      "Jia Tan \"JiaT75\" added error text to a warning in bsdtar in 2021, leading to a heated GitHub discussion about comment quality and code change scrutiny.",
      "The debate highlighted the challenges of maintaining large software projects and the potential role of AI in improving security reviews.",
      "The incident underscored the difficulty of detecting malicious code, especially from known contributors, and linked Jia Tan to a state-sponsored attack on the xz tool."
    ],
    "points": 156,
    "commentCount": 86,
    "retryCount": 0,
    "time": 1721214218
  },
  {
    "id": 40986213,
    "title": "Puerto Rico files $1B suit against fossil fuel companies",
    "originLink": "https://www.theverge.com/2024/7/16/24199686/puerto-rico-fossil-fuel-industry-lawsuit-climate-change",
    "originBody": "Climate/ Environment/ Science Puerto Rico files $1 billion suit against fossil fuel companies Puerto Rico files $1 billion suit against fossil fuel companies / Puerto Rico’s complaint adds to a slew of climate suits against oil and gas companies. By Justine Calma, a senior science reporter covering energy and the environment with more than a decade of experience. She is also the host of Hell or High Water: When Disaster Hits Home, a podcast from Vox Media and Audible Originals. Jul 16, 2024, 4:56 PM UTC Share this story An aerial view of the flooded neighborhood of Juana Matos in the aftermath of Hurricane Maria in Cataño, Puerto Rico, on Friday, September 22nd, 2017. Photo: Getty Images Puerto Rico filed suit against fossil fuel companies this week, alleging that the oil and gas giants have misled the public about climate change and delayed a transition to clean energy. The suit seeks $1 billion in damages to help Puerto Rico defend itself against climate disasters. In a complaint filed in San Juan yesterday, Puerto Rico’s Department of Justice says that the companies violated trade law by promoting fossil fuels without adequately warning about the dangers. The defendants include ExxonMobil, BP, Chevron, Shell, ConocoPhillips, and other energy companies. It’s the latest in a slew of lawsuits attempting to hold fossil fuel companies accountable for the consequences of climate change. Greenhouse gas emissions from fossil fuels are supercharging storms and other extreme weather events while rising seas eat away at island shorelines. Fossil fuel companies knew for decades that their products would cause global warming and went about business as usual anyway, several studies and investigations have found. In the complaint, Puerto Rico says it expects to pay billions of dollars in the future to cope with catastrophes made worse by climate change — including storms like Hurricane Maria, which killed thousands of people in 2017 and triggered monthslong power outages. The suit asks defendants to contribute to a fund that would be used to mitigate the consequences of climate change and pay for measures to strengthen Puerto Rico’s infrastructure against future climate-related calamities. BP declined to comment on the suit. Other multinational energy companies named in the suit didn’t immediately respond to The Verge. Thirty-seven municipalities in Puerto Rico and the capital city of San Juan have previously filed suit against fossil fuel companies, seeking to hold them accountable for the devastation wrought by Hurricane Maria. “It’s more important than ever for officials to stand up to the fossil fuel industry on behalf of their communities. The people of Puerto Rico deserve their day in court to hold Big Oil accountable,” Richard Wiles, president of the Center for Climate Integrity that tracks climate cases and provides legal support, said in an emailed statement. Most Popular Most Popular It’s never been easier for the cops to break into your phone The secret garden Here’s a very clear real-world look at Google’s Pixel 9 Pro Fold Apple is finally embracing Android’s chaos Here’s how much Valve pays its staff — and how few people it employs Verge Deals / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly. Email (required)Sign up By submitting your email, you agree to our Terms and Privacy Notice. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. From our sponsor Advertiser Content From",
    "commentLink": "https://news.ycombinator.com/item?id=40986213",
    "commentBody": "Puerto Rico files $1B suit against fossil fuel companies (theverge.com)155 points by Brajeshwar 4 hours agohidepastfavorite111 comments spiderfarmer 3 hours agoSome of these lawsuits may be aimed not just at winning in court, but at pushing broader changes in policies or public awareness. Even if these cases are challenging to win, they can influence public opinion and policy, encouraging stricter environmental regulations and corporate practices. Personally I think lawmakers should focus their effort on making stricter legal frameworks for today's world. Use the full force of the law to make companies behave better. It's the only language they understand. reply TrapLord_Rhodo 3 hours agoparentthey sell... Oil, gas and other minerals that make our life go around... It makes that computer your typing on, and gets 90% of us to work/ around. I get it, use of gas and oil causes pollution... But that's on the end user, no? I know people love to villify gas companies, but they are some of the most productive engines of society. reply phalangion 3 hours agorootparentOne of the roles government can play is to take the negative externalities of an activity (e.g., pollution) and internalize it so that those costs are paid by those who are profiting. The way to do that is to create taxes, fee structures, etc. so that those making money on activities contribute to the overall societal cost. reply ranyume 1 hour agorootparentThat's assuming the money made by internalizing the externalities is used to benefit those who would otherwhise be negatively affected by them. It'd be a worse situation if the money is spent, for example, running campaigns for the next elections. A better arragement would be for the affected people to receive the tax payments directly. reply sqeaky 37 minutes agorootparentEffective regulation could actually have made clean coal plants. In principle that junk can be filtered, but it was cheaper to lobby for rules exemptions than to pay for filters. Sometimes damage can be prevented instead of remediated. Sometimes it isn't about victims getting paid, but preventing people from being victimized. reply acdha 1 hour agorootparentprevThe end users have been lied to for half a century as the fossil fuel companies spent billions on PR campaigns, buying politicians, setting up think tanks and fake research groups, etc. claiming that something their own scientists were confident was happening was not happening. Imagine the alternative where they’d gone to Nixon with their research and worked with governments to gracefully transition, support rather than oppose efficiency improvements, etc. The difference in deaths will be measured in millions, and the cost to the global economy would have been trillions of dollars less. reply ranyume 1 hour agorootparentFundamentally speaking, government decisions are based on the individual egocentric needs of each member, not the needs of the population at large. This is why you can't trust governments to do the good thing: to make sure they do good you must coerce them as you would a private company. reply Folcon 3 hours agorootparentprevI'm not clear why this is true? > But that's on the end user, no? Pollution is a tragedy of commons scenario, so our best tools for solving it are laws and policy that force behaviour. I'd be surprised if it's completely impossible to do the resource extraction without minimising impact, we just don't tend to have much pressure to innovate in that direction. The end user on the other hand, has the least power to change any of the dynamics you're describing and is usually least able to choose to do without. reply s1artibartfast 1 hour agorootparentI think you underestimate both the value and importance of individual action by users. The best tools for preventing tragedies of the commons are collective and individual desire to do so. Taking action and paying personal costs are incredibly important. On the flip side, it is extremely difficult to force change top down without people willing to lead by example. Looks at any place with nice commons and they are maintained though widespread desire to do so by individuals. Japan isn't free a litter due to harsh fines, regulatory action, and policing. reply glitchc 2 hours agorootparentprevExcept the commons in this case is a shared atmosphere. Unless we get other countries to agree to equally punitive actions, all we end up doing is giving them the license to accelerate their economies at our expense. reply nmz 2 hours agorootparentIts a shared atmosphere, so they will suffer the effects of it equally. This isn't a \"just the US\" type of thing. if you suffer from hurricanes or monsoons, earthquakes, and so on, it is in your best interest to reduce the effects of pollution. China was the biggest polluter, they still are, but they are taking measures. We also haven't agreed to punitive actions, tax credits incentivize cleaning, but there is barely any punishment or accounting of it. Else coal which is probably the worst form of energy production would not exist. reply s1artibartfast 1 hour agorootparentprevSometimes you need to lead by example and bear costs if you want change. reply bearjaws 3 hours agorootparentprevClassic example of \"Privatize the gains and socialize the losses\". There's a history of oil companies lying about the consequences of production and consumption... reply jvanderbot 2 hours agorootparentprevA single exploratory ocean oil well costs as much as a Mars rover with design, launch and operations. There are thousands of them. We owe our modern world to O&G, but by now they could be producing oil & gas from CO2 -> Methane using solar / wind (/ nuclear?) and the CO2 in the air around us. The infrastructure to do so sounds enormous, but we gloss over all the diplomacy, wars, foreign & domestic wells, tankers, refineries, ports, trucks, pipes, gas stations, etc etc we had to build in the last 100 years to actually make O&G the everyday industry it is. How many trillions? The ROI was totally worth it, but maybe it's time for more I and less R. It's not that the industry or even oil itself is evil, it's that we can do better. reply bcrosby95 3 hours agorootparentprevWho conceal the truth and lobby against any change so they can force society to continue to depend upon them despite that dependency destroying the planet. reply Epa095 2 hours agorootparentprevIt's a way to large responsibility to put on the individual end user. If there are many lawsuits like these, and the oil companies loose some of them, the result is that some of the exernalities are partially compensated by some of the ones earning the most on the original fault. It makes the world a slightly more fair place. The best would have been if the cost was baked in from the beginning, but alas. Oil and gass is unfortunately still important for our economy, that's true. But it's also an existential threat to our modern way of life. Given what we now know about the absolute massive external costs, we need drastic change. We should extract as little as we can, and every single penny of surplus should go towards green energy and mitigating actions. reply Qwertious 3 hours agorootparentprev>But that's on the end user, no? Most users don't spend billions of dollars on climate-denial propaganda, so no. reply cmilton 3 hours agorootparentprevI agree mostly. However, I think we need to add that being one of \"the most productive engines of society\" comes with great responsibility. The record profits for share holders and executives may not be enough incentive to maintain appropriate levels of that responsibility. reply sqeaky 40 minutes agorootparentprevThey actively stifled alternatives that could do all of that. reply skhunted 3 hours agorootparentprevThis is why selling opium should be legal. The consequences of use are on the user not the seller. Sellers never should have culpability assigned to them. Ditto for lenders. reply energy123 3 hours agorootparentprevActually, emissions does not make life go round: https://ourworldindata.org/grapher/co2-emissions-and-gdp reply praveen9920 3 hours agorootparentprevThe problem is not about just pollution, it’s about their commitment to use their profits to drive the lobbying and bullying anything or anyone that comes across as a threatening to their business. Not just that, they publish “research” which is essentially disinformation campaign against anything. And many more.. Overall, they deserve the hate. reply smolder 3 hours agorootparentprevNo, it's not \"on the end user\", in my not-so-humble opinion. We should have been much more heavily investing in renewables & carbon neutrality (factories to make batteries and solar, nuclear, anything) by the time the fracking boom happened. Fossil fuel companies were investing in misleading the public about global warming instead, in the same way that tobacco companies invested in misleading the public about the health issues caused by smoking. To this day they are still working to undermine efforts to transition to cleaner energy, for the sake of greater profits, even while their public relations efforts pretend they are pro-\"green\". The country/world was steered toward a cliff by self-interested people without sound judgement or morals pulling financial levers to enrich themselves. reply s1artibartfast 2 hours agorootparentprevI'm all for users taking action to regulate their behavior, and then for governments to also regulate behavior where appropriate. I see it a lot like cigarettes, in that individuals can make very restrictive choices, governments apply looser restrictions, and manufacturers provide supply. Like cigarettes, there was likely some legally actionable misinformation long ago that should be addressed, but nobody today can honestly claim they are tricked into thinking smoking is healthy. reply loceng 3 hours agorootparentprevAnd unfortunately the people pushing for using anti-oil energy policy are implementing it it appears to gain more control over the general population, and to implement more authoritarian policy. The fastest and non-violent way to achieve the most efficient results is through the relative free market, education and voluntary adoption - and through purchasing power, but not through forced purchasing power - nor nonsense tax policy like the \"CO2 tax\" on all fuel - and therefore all products and transport involved with production and distribution of all products vs. only having a CO2 tax specifically on products from countries who's CO2 emissions are increasing or skyrocketing; penalize weighted based on actual emissions; whether CO2 emissions are actually harmful or not, CO2 can be released without releasing polluting particulate - of which CO2 isn't pollution itself. Edit to add: use your words folks. reply keybored 3 hours agoparentprevI really hope that it’s about more than public awareness. The power of public awareness is a liberal fiction. The “public awareness” of climate change gets co-opted and neutralized by limp-wristed slogans like bicycle-to-work (where, on the pedestrian-hostile US commuter roads?) and upper-middle class solutions like “buy more Teslas”. And now everyone knows about climate change. Only there are two camps: those who believe it’s real and those who think it’s a conspiracy theory. More awareness so to speak only makes the two camps dig their heels in further. The only way to make corporations change is to threaten their bottom line. But at this point I’m sure many have been convinced that the corporations have no responsibility in this. reply HeyLaughingBoy 3 hours agoprevI remember that 20, maybe 25 years ago, the major oil companies were all rebranding themselves as \"energy\" companies because \"we all knew\" that we had to be weaned off oil and onto alternative energy sources. Then somehow that effort seems to have petered out. What happened? reply beart 12 minutes agoparentI think the shale revolution probably changed the calculus. It removed the \"dependency on foreign oil\" argument from the debate completely in the U.S. (though you still hear it mentioned from time to time without merit). It also reduced the cost of energy in the U.S. which eliminated a lot of the economic pressure. reply smolder 2 hours agoparentprevThat is all branding. They greenwash themselves publicly but still to this day show PowerPoint presentations to investors about how they are working to undermine renewables and electric transportation in order to fatten their wallets. (Source: climate town youtube channel.) reply njovin 3 hours agoparentprevThey realized it was cheaper to buy politicians than to actually change anything. reply melling 3 hours agoprevHow have we done in the last 40 years dealing with climate change? Peak fossil fuels Real Soon Now I’d say Carl Sagan nailed it: https://youtu.be/Wp-WiNXH6hI?si=wJuFlcBbelXVfn6u reply analognoise 3 hours agoparentStill waiting on that global consciousnesses. It’s a nice idea though. reply ZeroGravitas 3 hours agorootparentStill waiting on his first suggestion of cutting down on the subsidies given to oil and gas, which is, in theory at least, simpler to achieve. reply sitkack 3 hours agorootparentprevAnti-intellectualism and the push to the right is a drive to prevent a global consciousnesses. The best thing we can do is encourage critical thinking regardless of ideology. Education cures all ills. reply svieira 3 hours agorootparent> Education cures all ills. That's what Socrates thought. But I don't think it's correct. Education enables, but does not cure. What one chooses to do is not a product of what one knows alone. reply everybodyknows 2 hours agorootparentEducation, as opposed by the will to deny inconvenient evidence, have been contesting this issue for the last 40-some years. From the current scorecard: Voter polls predict the next POTUS will be a man who has told us that \"Climate change is a hoax.\" reply JumpCrisscross 4 hours agoprevDoes this have legal legs? Also, if “Puerto Rico says it expects to pay billions of dollars in the future to cope with catastrophes made worse by climate change,” why are they only asking for $1bn? reply woodruffw 3 hours agoparentNo idea on standing. But as for the amount being asked for: it's possible that the lawyers determined that only so-and-so much of PR's expected climate damages could be clearly attributable to oil and gas companies, even if the total damages are significantly higher. reply Qwertious 3 hours agorootparentAlso, if they win the suit and fossil fuel companies are forced to pay for damages in Puerto Rico, then they've established a precedent, opening a floodgate of similar suits from e.g. New Orleans. reply swader999 3 hours agoparentprevDoes the suit describe any real damages already incurred? reply nashashmi 1 hour agoprevFossil fuel companies are valued on their infrastructure, and its shareholders leverage that value (VAL) for gains/loans/financial strengths in other pursuits. Fortifying VAL necessarily means discrediting any harms by fossil fuels. It necessarily requires winning against renewable energy suppliers. How can these \"necessities\" be made moot? By getting the shareholders to also invest in renewables, using the loans leveraged from VAL. But then the loaners will be invested in VAL. Solution is to make sale of fossil companies and infrastructure illegal. Government should buy it out. reply ziofill 3 hours agoprevOnly $1B? These days it feels like way to little. reply AJ007 3 hours agoparentThat's a shakedown amount. You can't even build 1 nuclear power plant with $1 billion. reply jeffbee 3 hours agorootparentUnderstatement of the year. The last one America built cost $30 billion. reply johnohara 2 hours agoprevPR has struggled to recover from the effects of hurricane Maria, and I get the logic behind the lawsuit, but she also lies near major fault lines that have caused 2.5-3.5 Richter earthquakes every day for millennia. If PR were more creative she'd strike a tentative development deal with China to build a huge deep-water port capable of servicing the largest cargo ships AND the largest naval warships then sit back and wait for the U.S. to write a check to fund the strengthening of its relationship with its \"strategic partner.\" Assuming PR doesn't experience a leadership change shortly thereafter. reply neilknowsbest 1 hour agoparentTo be sure, Puerto Rico is a territory of the US. I imagine that making deals with China as you describe would draw the ire of Washington, if it's even \"legal\" in the first place. reply ChurchillsLlama 3 hours agoprevNevermind the billions of people who (still) drive cars and buy shipped products because there hasn't been a more cost-effective alternative. This entire oil-based economy situation is simple supply and demand and transitioning to clean energy takes a lot of time. I get that their motive comes from oil companies not disclosing the risks to the environment but this is a bit of a stretch and an obvious political stunt. reply bognition 3 hours agoparent> not disclosing the risks to the environment It's more than that, it was the willful misrepresentation of the truth. The oil companies didn't accidentally end up in this situation. They knew back in the 80s the effects that oil consumption would have on the ecosystem and they covered it up and actively pushed lies that prevented any kind of meaningful change. reply ChurchillsLlama 3 hours agorootparentThis is true, but my point is there weren't cost-effective alternatives at that time anyway so blaming climate disasters squarely on the shoulders of oil companies and not acknowledging the fact that demand fueled the value of oil doesn't make logical sense, even from an empirical perspective. Now, lawsuits for local disasters and oil spills do make sense. reply woodruffw 3 hours agorootparentIt does if you think that alternatives to fossil fuel would have become economical earlier, had the fossil fuel industry not intervened. Another framing: how many wind, solar, hydrothermal, etc. plants did we not build because their economic envelope was artificially dampened by investment and legislative preference for fossil fuels? reply ChurchillsLlama 3 hours agorootparentI do agree with this. They stifled progress as much as they could but that only slows things down, and because we don't truly know what would have happened, it's not productive to play the blame game and say we'd have a spotless utopia if it weren't for the oil companies. Who knows, not enough people at that time may not have cared or maybe we would have the utopia we all want. It's all guesswork and at this point we need to spend our energy moving forward instead of focusing on the past. reply The5thElephant 3 hours agorootparentPunishing major corporations at scale might help prevent the next multi-generational fuckup, and help pay for the energy and changes moving forward. I'm not really sure what it is you are trying to defend here? I understand arguing that you can't guarantee a different approach would have led to better results, but in this situation it seems fairly clear that corporations being open and honest would be superior. reply The5thElephant 3 hours agorootparentprevHow do you think you come around to having cost-effective alternatives? You need people actively working on them, and for that you need an incentive. reply pedrosanta 3 hours agorootparentprevThe 'there weren't cost-effective alternatives at that time' as an excuse for at the very least inaction (morally condemnable) and at most criminal litigation-worthy propaganda, lies and damages, I find it, in all due respect, quite poor. reply ChurchillsLlama 3 hours agorootparentAs an excuse on the part of the oil companies, I completely agree. But that point was directed at the supply/demand situation from the perspective of the world's consumers and not from the oil companies. So any effects emissions have had on the environment can't be placed squarely on the shoulders of the oil companies but the market (world population) as a whole. reply silverquiet 3 hours agorootparentprevIt wasn't cost effective to save ourselves; Kurt Vonnegut was prophetic. reply dehrmann 3 hours agorootparentprevI doubt it would have changed much. An Inconvenient Truth came out almost 20 years ago, and traditional ICE cars (excluding hybrids) still have 80% market share. It's fairly well-known at this point that going vegetarian (or vegan) cuts individual CO2 emissions dramatically, but people aren't signing up for it. People aren't willing to sacrifice their lifestyle for the environment. reply aziaziazi 2 hours agorootparentMore chance to build better habits with next generation than trying to convience gran’pa doing differently… In France we (edu and ecology ministers iirc) tried to have only vegetarian meal one day per week in public schools. Agriculture ministers got very angry as well as a bunch of noisy parents. Legislator choose to abandon the project. reply Ekaros 3 hours agorootparentprevThere is lot of choices individuals could make. Forgo EVs, only walk or bike. Instead of living in large spaces, move to something much smaller like capsules. Forgo electronics and internet in general. reply TheAceOfHearts 3 hours agorootparentprevEpistemic uncertainty: I wasn't alive back then and haven't done a deep dive on the historical evidence to form a strong view on the claim. However, Sabine Hossenfelder recently made a post about that [0]. My understanding is that there was still a lot of uncertainty in the scientific community during the 80s, although around the 90s there was a movement by oil companies to downplay the impact of climate change. With that being said, whether or not oil companies were aware back then doesn't mean they cannot still be held accountable in the present. And we definitely have evidence of oil companies engaging in bad faith since the turn of the millennium to obfuscate our understanding of climate science. [0] https://x.com/skdh/status/1810915186443722844 reply vasco 3 hours agorootparentprevI don't disagree but I've always found that argument a bit disingenuous. Have you ever seen an oil well getting drilled in a movie or on TV? Or just seen oil? Or seen and smelled the gas that goes into cars? Is anyone able to say with a straightface that they didn't know oil that oil is bad for the environment? I get that the oil companies have more blame than other people, but this argument of \"the global population was fooled, nobody knew it was bad so we kept using oil, and those mean people at the oil company kept the information from us\"... Everyone knows. The same way everyone knows most weird smelling chemicals aren't great for the environment either, but if we have a stained tshirt we'll use them. We're all complicit, and while I agree some are more to blame than others, it's not necessary to pretend the rest of us are innocent. reply mbrumlow 3 hours agorootparentLooks like you got too close to the truth. reply bortlicenseplat 3 hours agorootparentprevoil literally comes from the environment, how is it inherently bad for the environment? we should ban lava too, have you seen the environmental damage it can do? reply zug_zug 3 hours agoparentprevThis actually, according to hard economics, is potentially an optimal solution. Fossil fuels provide a great benefit to one party but produce negative externalities to other parties (people in hurricane zones, people born into hot regions, people who live in the future). If it's worth it economically because the value is so great, then an optimal economic solution is to say \"You can have this thing, but you are accountable for the damages it causes to other parties\" Once we start pricing in the costs of the side-effects of fossil-fuels, the tradeoffs will be more clear, and the market will create faster incentives toward the ideal tradeoff. reply amelius 3 hours agorootparentThe problem is that there isn't a direct connection to negative externalities. If there are now 20 hurricanes instead of 10, who is responsible for those extra 10? reply dmix 3 hours agorootparentAnd that's literally what they are claiming, that oil companies are causing hurricanes to hit Puerto Rico > In the complaint, Puerto Rico says it expects to pay billions of dollars in the future to cope with catastrophes made worse by climate change — including storms like Hurricane Maria, which killed thousands of people in 2017 and triggered monthslong power outages. reply mbrumlow 3 hours agorootparentWhy not the beef or farming industry? Or China? Isolating oil companies alone seems silly. Even more so because the entire world, including Puerto Rico also be benefits from the fruit of the last 100+ years od oil production. On top of all that, climate change was going to happen. The idea that our climate was ever static and unchanging is silly, and only a child’s view is the history of the world would suggest otherwise. Did the early inhabitants of Austin Texas sue whatever they thought caused their premium glacier front property to drop in value over the last billions of years they receded? The fact is that humanity is hooked on oil. IRS not going away. Not at least without billions of people suffering and dying. Oil has brought clean water across the world. It has allowed a technology boon by the way of its by products coating the majority of wires made, preventing horrific house fires from the days of paper wrapped wires. Oil and its byproducts are engrained into humanity and its economical efficiency has been a blessing to humanity and every single last person on this planet has benefited. reply nilamo 3 hours agorootparentprevYou're right, it's hard. So let's not even bother trying, right? reply amelius 3 hours agorootparentYour words, not mine. If we keep thinking there is a simple fix, then nothing will change either. reply silverquiet 3 hours agorootparentprevNo one will ever accuse me of being an optimist, but I'm beginning to have a hard time seeing how this doesn't end with human extinction, and I wonder how that balances on the spreadsheet. It's quite depressing. reply burningChrome 3 hours agorootparentHumans evolved from some of the most inhospitable climates and continue to live in such environments to this day. Humans will do what we've always done - adapt and overcome. I mean how many people thought you could build a bunch of casino's in the middle of a desert and think people would move there and it would grow into almost 3M people? reply ToucanLoucan 3 hours agorootparentprevAnd that's not even going into the fact that we would already be pushing for more fuel efficiency in vehicles especially if gas wasn't so incredibly subsidized here in the United States. We pay absurdly low prices compared to basically everywhere else and you cannot convince me that is not a significant factor in why we still have so many massive trucks, SUV's, and V8 sports cars. And don't get me wrong, I love my sports car and it's big thundering V8. But I also know the negative effects it has and I'm completely fine paying a higher price at the pump to offset that. reply s1artibartfast 3 hours agorootparentI hear this often, but my understanding is that gas is has very high sin taxes, there are no subsidies, and some tax breaks, but are the type that most businesses qualify for. Every time I look it up, the results are so full of rhetoric and conflating I can't find an answer. Most top line numbers count on priced externalities as a implicit subsidy. That's fine and well for some analyzes, but very different than Direct Cash subsidies or tax breaks reply pohl 1 hour agorootparent> there are no subsidies I thought the oil and gas industry famously got about $4B in subsidies per year, and about $20B to fossil fuel industries in general. Has that changed recently? reply dtjb 3 hours agoparentprevSeems like this could be one of the mechanisms to encourage that transition. One persons stunt is another's advocacy. reply ChurchillsLlama 3 hours agorootparentTrue and it does bring some awareness, but this is lazy approach. I love the passion people have in cleaning up the environment but we all know (especially the engineers among us) that building a solution, or contributing to one, is far more effective than complaining about a problem. reply keybored 3 hours agoparentprevNever mind what? Companies like British Petroleum have used marketing to frame climate change as “consumers doing bad things” with their “carbon footprint”. So if that’s what your mind goes to first, that’s no coincidence. It’s all about the money. Money buys media which buys narrative and mindshare. reply cogman10 3 hours agorootparentAnd these fossil fuel companies aren't just doing this in the US. When you look at what they view as the path forward to keep selling oil to burn, it's all about doing things like setting up floating power plants for developing nations and subsidizing road construction to aid in the sale of ICE vehicles. The problem with these companies is the externalities of their actions are not priced in. For them, it's more a simple game of figuring out how to get the world to burn more oil. This lawsuit may not have merit, but it does point to the need for trying to price in the impact on climate change with oil burning. reply LudwigNagasena 3 hours agorootparentprev> Companies like British Petroleum have used marketing to frame climate change as “consumers doing bad things” with their “carbon footprint”. So if that’s what your mind goes to first, that’s no coincidence. It's also common sense. Literally nothing stops first-world consumers from not buying stuff that requires emission of greenhouse gases except for their lifestyle preferences. > It’s all about the money. Money buys media which buys narrative and mindshare. Yep, you bought into the idea that you don't have to change your lifestyle because it is all fault of the big oil. reply HeyLaughingBoy 3 hours agorootparentYou call it a lifestyle preference, I call it staying alive. But that bag of potatoes I just bought wouldn't be in the grocery store without a long chain of greenhouse gas emissions. reply keybored 3 hours agorootparentprevLies repeated enough become truth which becomes common sense. > Literally nothing stops first-world consumers from not buying stuff that requires emission of greenhouse gases except for their lifestyle preferences. Literally nothing. Uh-huh as if we’re talking about buying a monster truck compared to a Volvo instead of the lifeblood of the whole modern (inefficient) supply chain. > Yep, you bought into the idea that you don't have to change your lifestyle because it is all fault of the big oil. Via what money? reply mc32 3 hours agoparentprevAnd never mind the activists who retarded nuclear power for fifty years. When do they get sued for fearmongering misleading and putting an industry fifty years behind where they’d be today? reply andylynch 3 hours agoparentprevThey are arguing that the companies concerned were not, but should be compelled to, price in at least some of the negative externalities of their product. Not doing so of course makes their product's price not reflect its true cost to produce, and distorts that same supply and demand. reply ChurchillsLlama 3 hours agorootparentI completely agree if these negative externalities weren't several degrees of separation. Car companies could have produced cars with better emissions which isn't the fault of the oil companies, people could get their products later instead of next-day (I'm also guilty of this), you get the picture. I'm glad oil companies are having to be more transparent but the blame is on the entire population of the world. reply adolph 3 hours agoprevI wonder if a lawsuit like this could ultimately indemnify petrochemical companies for a known and finite amount, with the most lasting \"benefit\" being warning signs on gas pumps and anything else produced using petrochemicals: \"WARNING: This product is known to the territory of Puerto Rico to cause more and more severe meteorological events.\" Then at some later time in the inevitable march to Idiocracy, bright minds at low margin businesses will start tossing some food grade paraffin on everything so they don't have to distinguish between SKUs that need the sign and those that don't. reply moralestapia 3 hours agoprevNot a lawyer, so no idea if this will get somewhere. But on the moral side of this, yes, if the operation of oil companies incurs damages to other entities/people, they have to make them whole. The \"Netflix wouldn't exist without fossil fuels\" argument is silly. The cost of restoring the environment should be factored in to the cost of producing oil, like any other liability. If that makes everything go up in price, well ... that's the actual cost of that product, consume accordingly. reply nradov 3 hours agoparentAll human civilization (not just use of fossil fuels) is going to cause some level of environmental damage. This is inevitable. The cost of \"restoring the environment\" is infinity. So, it's really just a question of what level of damage we're willing to accept. Different people prefer different levels of damage on that spectrum. If not for fossil fuels then we would be living in essentially an 18th century civilization. A lot more stuff then Netflix would never have been created without the safe and cheap energy supplied by fossil fuels. reply energy123 3 hours agorootparent> what level of damage we're willing to accept Who is \"we\"? Why do you get to decide whether Africa's heatwave is 52C instead of 48C? Are you going to compensate them for that heatwave, and the resulting strain on their growth & development and political stability? That's the crux of this case. There are significant negative externalities that are not being priced in by the market. The people doing most of the damage owe some compensation to the people who have to bear most of the consequences of their activity. reply moralestapia 2 hours agorootparentprev>The cost of \"restoring the environment\" is infinity. It's not, actually. And if it turns out that your business does something so expensive to repair that for all practical purposes could be considered \"infinite damage\", then your business shouldn't exist at all (e.g. the Sackler family and Oxycontin). reply nradov 2 hours agorootparentIt is, actually. Completely restoring the environment means killing off 99% of humans and going back to a stone age existence. At which point our money would cease to have any value, hence the cost would be effectively infinite. We can maybe slightly reduce our environmental impact but keeping civilization means accepting a large amount of environmental damage. Anyone who believes otherwise is simply disconnected from objective reality and doesn't understand how the things we have are made. reply moralestapia 1 hour agorootparentThat's absurd. If I eat a bag of chips and throw it to the ground, \"restoring the environment\" does not mean going back to the stone age, it means picking it up and putting in on a trash can (plus whatever downstream actions that are involved). Anyone connected with objective reality understands that. If oil companies (and any other company), by carrying out their operations, incur on some environmental damage, they have to be held liable for it. reply nradov 1 hour agorootparentThat's absurd. Everything that civilized humans do, including producing renewable power, incurs non-zero environmental damage. It's just a question of how much damage we're willing to accept and what trade-offs we're willing to accept. reply aipatselarom 1 hour agorootparentYou write \"we\" but I've never been approached by any company to talk about the trade-offs I'm willing to accept. I don't think companies do that sort of thing, but has that been the case with you? One could argue \"well, vote with your wallet then\", but there's overwhelming evidence showing that people choose cheap over any other quality of a product, also, sometimes there's not even the possibility of a choice to be made. What solution would you propose, then, around this? reply purpleblue 3 hours agoprevShould Puerto Rico pay back the benefits it received from fossil fuels, like increased tourism from airplanes, and for allowing cars and combustible engines on the island? Are they going to get rid of ICE vehicles immediately now? Are we going to start filing lawsuits against sugar manufacturers for all of the health issues they caused? What about manufacturers of fatty foods? Oh wait, are fatty foods good for you or bad for you? Fatty foods were bad for you in the 80s and 90s but now the science is showing the opposite. This entire lawsuit is nonsense. reply keybored 3 hours agoparentThe benefits that Puerto Rico has enjoyed are probably comparable to that of mainland America. While the downsides are presumably worse. Which is I guess whence the lawsuit. reply n2d4 3 hours agoparentprevNo, they shouldn't pay back the \"benefits\", because they already paid for the fuels. No market failures there. There is a very obvious market failure with the downsides of fossil fuels however (negative externalities), and Puerto Rico claims said companies willingly misled the public about those — that absolutely is reason for a lawsuit. reply WillDaSilva 3 hours agoparentprev> Are we going to start filing lawsuits against sugar manufacturers for all of the health issues they caused? Like with the fossil fuel industry, the sugar industry also invested heavily into misleading the public about how damaging their product is. With that in mind, it seems at least somewhat reasonable for governments to file lawsuits against them to punish them, and to recoup some of the lost value due to their negative externalities. reply mc32 3 hours agoprevI think this is silly. Without fossil fuels we’d not have had progress. We’d have wood fires to cook, no AC, lots of missing modern inventions. Now if fossil fuels were made illegal or were used illegally, sure. But it’s not like the gov outlawed them and now they are seeking damages. If you want to sue, sue Jane Fonda and her then allies who misled people, corporation and government resulting in 50 lost years of nuclear power progress. reply mandmandam 3 hours agoparentFraud is illegal. Fossil fuel co's knew from their own research that their product would bring disaster to the planet at incomprehensible scale. Rather than make the knowledge clear and available to buyers, they chose to lie and deceive the public. The result: fraud, false advertising, arson, and pollution on a global scale. All of those things are very fucking illegal and for very good reason. reply djent 3 hours agoparentprevpollution reply mc32 3 hours agorootparentSo no pollution but live like people in the north sentinel islands, or any third world country’s hinterlands where they still cut down trees to get fuel? What is and was a viable (working in reality) alternative for the last 50 years or so? reply djent 1 hour agorootparentstrawman reply greenavocado 3 hours agoprevMoney grab by an irrelevant, corrupt, and desperate US colony. reply notarealllama 3 hours agoparentAs someone who lives here and understands the politics and nuance... eso es. (\"This\"). The people of Puerto Rico are fed up with the government and energy company here (LUMA) and do want change, current governor lost the primary and the candidate replacing him will likely win in November (even though it's the same party, business as usual) is partially because she's very, very anti-LUMA and appeals to the frustrations of people with the situation and is advocating change. Unfortunately, decades of corruption have really impacted our politics and the energy and infrastructure here, and with the recent $4 million transformer issue, it doesn't surprise me that they are suing to try and get a windfall of money. reply greenavocado 2 hours agorootparentI hope your community sees better days reply Ekaros 3 hours agoprevClearly Puerto Rico do not want anything produced with oil or any petroleum products. Maybe these fossil fuel companies should give them their wish and ban their buyers from using their products to transport goods and people there and also in manufacturing of any goods sold there. That way Puerto Rico could do their part in stopping these emissions. Surely it would not be too big sacrfice? reply vivekd 3 hours agoprev [–] I think the climate movement is going to fail soon. This mentality of find villans and blame and attack them instead of looking for productive solutions isn't sustainable for a movement. I don't know about the future of the climate but I think unfortunately the climate change issue, like so many pressing issues might be one we have to give up on until we make fundamental changes in our societies reply nmz 1 hour agoparentThe climate movement wasn't taken seriously 70 years ago, but as people see its effects more and more and the more you live and remember that you could actually walk outside without AC and not melt the more its strengthened. So I highly doubt what you say. reply vivekd 56 minutes agorootparentThat's the other reason it's going to fail, the dishonesty. Frankly I don't remember the weather being that much different when I was a kid. And aside from my personal observations or views, the bigger issue is climate and weather are different things. It is scientific and backed by evidence to think that climate change is happeing and that the earth's climate is getting warmer. It is unscientific and not backed by evidence to think we can feel or experience that now in our current year at the level of weather. That doesn't mean that climate change isn't an important issue but there needs to be a serious change in the way it's presented to people, and I think a huge start is that things need to be led less by journalists and activists and politicans and more by climate scientists We've been claiming that we need to take action by 2030 or there will be disaster. And the movement is going to pay a high price in 6 years from now when we notice that the weather isn't much differet. reply Ekaros 3 hours agoparentprev [–] I do believe too that it is going to fail. Technology won't solve it. And people who got emissions now are not ready to do enough. And people who do not want the same things that people who do. Outside rather small segment of population not enough people are ready to either substantially lower their standards of living or not increase them. reply vivekd 24 minutes agorootparent [–] This is where I disagree. I think techonology can solve it, and policy can also solve it. But I think the movement has been hijacked by people with other agendas that differ from solving climate change. And I think you can sort of glimpse it here - the agenda is not solving climate change, it's making the oil companies pay. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Puerto Rico has filed a $1 billion lawsuit against major fossil fuel companies, including ExxonMobil, BP, Chevron, Shell, and ConocoPhillips, for allegedly misleading the public about climate change and delaying the transition to clean energy.",
      "The lawsuit, filed in San Juan, claims these companies violated trade laws by promoting fossil fuels without adequate warnings about their dangers, seeking damages to defend against climate disasters like Hurricane Maria.",
      "This legal action is part of a broader trend of similar lawsuits against the fossil fuel industry, highlighting growing accountability efforts for climate-related impacts."
    ],
    "commentSummary": [
      "Puerto Rico has initiated a $1 billion lawsuit against fossil fuel companies, accusing them of causing climate change-related damages and seeking stricter environmental regulations.",
      "The lawsuit underscores the ongoing debate between the economic benefits of fossil fuels and the necessity for sustainable practices and corporate accountability.",
      "Opinions are divided, with some emphasizing the importance of corporate responsibility for pollution and misinformation, while others stress the role of individual actions and government policies in combating climate change."
    ],
    "points": 155,
    "commentCount": 111,
    "retryCount": 0,
    "time": 1721225798
  },
  {
    "id": 40983486,
    "title": "Gitlab Explores Sale",
    "originLink": "https://www.reuters.com/markets/deals/google-backed-software-developer-gitlab-explores-sale-sources-say-2024-07-17/",
    "originBody": "reuters.com#cmsg{animation: A 1.5s;}@keyframes A{0%{opacity:0;}99%{opacity:0;}100%{opacity:1;}}Please enable JS and disable any ad blockervar dd={'rt':'c','cid':'AHrlqAAAAAMAMxzhsTdvGaoAFKFNyw==','hsh':'2013457ADA70C67D6A4123E0A76873','t':'fe','s':43909,'e':'3158637c058810efcf52a0e721e01e84d57b61979e9dfda122f9621f8a8a4456','host':'geo.captcha-delivery.com'}",
    "commentLink": "https://news.ycombinator.com/item?id=40983486",
    "commentBody": "Gitlab Explores Sale (reuters.com)146 points by gostsamo 11 hours agohidepastfavorite105 comments elashri 5 hours agoI really hope that whoever buys them not to shut it down / change model. At CERN we rely on Gitlab enterprise and I have many CI files that would take weeks to re-write into GitHub actions (there are thousands for CERN overall). We are still suffering from RedHat decision to cut CentOS after relying on it and Fermilab/CERN shutting down Scientific Linux based on the assumption that CentOS is suitable. It also makes the CERN's strategic decision to go full Open Source less appealing by time. Although there are many examples on how proprietary hurt us too (I see you there oracle). reply janice1999 5 hours agoparent> It also makes the CERN's strategic decision to go full Open Source less appealing by time. I think it's still the less risky option. Open Source at least usually makes migrating elsewhere easier. CentoOS -> AlmaLinux for example (or any of the other commercially supported CentOS replacements). Customers currently being exploited by Broadcom/VMware wish they had such options. reply yjftsjthsd-h 3 hours agoparentprev> It also makes the CERN's strategic decision to go full Open Source less appealing by time. Although there are many examples on how proprietary hurt us too (I see you there oracle). Surely FOSS is overwhelmingly preferable precisely for this reason - if you use github and they decide to screw you over you're stuck. If gitlab does decide to screw you over then you still have the source code for the last good version, and 1. you can patch/fork it yourselves, 2. you can hire someone else to patch/fork it, and 3. if there's a decent-size community then probably someone else will fork it. Or more concretely, yeah the CentOS thing sucked, but there are multiple replacement forks, which never would have been an option if it wasn't open source. reply jamescrowley 5 hours agoparentprevIn case you are not aware, there is tooling to help with GitLab to GitHub actions migration, but I have not tested on anything complex so YMMV https://docs.github.com/en/actions/migrating-to-github-actio... reply frognumber 8 hours agoprevThis seems like a dead-end purchase. I like both companies, but there is strongly negative synergy. I'm sure there's some vision behind it, but like most such purchases, one side or both will likely crash-and-burn. That would be sad. Aside from technology issues, the companies have a completely different culture and ethos. Universally, that's not preserved in acquisitions like these. Gitlab has a very unique culture of transparency, remote work, etc. which won't mesh at all with Datadog. If the goal is some kind of integration, a much better model is a significant investment and partnership agreement. It's possible to have those permanently binding, while still being attached at the hip. reply deng 6 hours agoparentWell, one thing they have in common: both are insanely expensive. reply nickorlow 6 hours agoparentprevYeah I don't see how gitlab fits nicely into Datadog's business. Maybe they just want some foothold in developer tooling (similar to Microsoft's moves with GitHub and NPM)? reply another2another 6 hours agoprevI think a better fit (for any measure of better you might like) might be Redhat / IBM. IBM can sell it to customers as an Enterprise package with Enterprise support, and Redhat can host their own OSS software there on their own turf. reply rwmj 5 hours agoparentRed Hat uses Gitlab for CentOS Stream development (https://gitlab.com/redhat/centos-stream). However $8bn is a lot of money for what is basically a loss-making cost center. (I know it made a small profit recently, but Gitlab has lost money for a very very long time.) reply arnvald 6 hours agoparentprevAgreed, similarly to what they're doing with Hashicorp (though way to early to say if it works out for both sides in the end) reply srameshc 7 hours agoprevI really wanted Gitlab to succeed. I joined early on and used it quite a bit but by 2020 things changed and their message , pricing was all mess. I don't think I have ever used it since. But this was one startup I really rooted for. reply kryptiskt 7 hours agoparentI thought eliminating the cheap plan was a huge mistake. You can say that people shouldn't balk at paying $20 a month, but Github offers a plan for $4 per user, why should they pay more and all they get is features they don't intend to use? Ceding the entire low ground like that is shortsighted, especially since Github has an advantage in selling the same users an expensive plan if and when they need it. reply aniforprez 6 hours agorootparentWe'd evaluated GitLab a while back for a previous company before GitHub Actions was launched because the CI coming in with GitLab was very tempting. Since we were a small team working with contractors, we were looking for a monthly subscription and were pretty shocked at immediately being rebuffed and asked to book annually. Genuinely insane at the time how insistent they were that we should simply pay up front for an entire year of seats that were likely never going to be used. We just went with GitHub Their extreme focus on enterprise is probably the reason for the low traction they're getting. Can't believe how much money they're leaving on the table because of some of their more bone headed decisions. Not sure if that ever changed reply deng 6 hours agorootparentprevIt's 30$ now. That additional increase really broke the camel's back for us. reply cdelsolar 4 hours agorootparentYou just spent that extra $10 a month writing this comment. reply Aeolun 4 hours agorootparentIt’s the principle of the thing. It’s not because the money is relevant to me, but because getting the thing through purchase approval is like 400% harder by increasing the price from $20 to $30 per user. reply deng 4 hours agorootparentprevI'm on vacation, so there goes that theory. We have 400 seats. You do the math, we started with 4$ and within 5 years the price got up to 30$. At some point you just have to question if it's still worth it, and for GitLab, that's a clear No when compared to GitHub. reply setopt 7 hours agoparentprevI put most of my open-source repos there for a few years, and got GitLab adopted at work too. They had similar feature set to GitHub and I didn’t want to support the latter’s near-monopoly status. After Microsoft bought GitHub and many large projects started migrating to GitLab (e.g. GNOME), I thought things were looking better. But a few years in… I’ve given up and moved my repos to GitHub a year ago. It’s clear that my GitLab repos have nearly no visibility, and if no one finds the projects then there’s not much point in open sourcing it. reply nine_k 6 hours agorootparentA number of projects have read-only mirrors on GitHub for visibility, with actual development occurring elsewhere. reply boscillator 6 hours agoprevIt's a shame that Gitlab isn't profitable. Maybe it's just because I have to use it for work and am therefor familiar, but I've always slightly preferred it to Github. I also never really saw Github enterprise server being viable in the \"we have to self host for security reasons\" space, but maybe someone else has a different view. reply lvncelot 5 hours agoparentThe CI/CD alone in Gitlab is light years ahead of what Github has to offer. I'm really hoping that they can hold on in some way or that the core open source application stays viable. reply pm90 6 hours agoparentprevWe ran github enterprise on our infra for several years. It was a pretty low overhead thing to run except if you’re really big. The nice thing was that we could customize the api rate limits which is really annoying with saas github. reply 999900000999 6 hours agoprevhttps://siliconangle.com/2024/06/03/gitlab-delivers-strong-e.... Looks like they aren't profitable, they lack a real moat. Literally anyone can just spin up a competing service. I'm actually surprised GitHub/Microsoft hasn't eaten their lunch yet. Gitlab used to have a firm advantage in terms of build runners, but GitHub Actions have been out for a while. I strongly suspect GitHub loses money ( of course you pay in other ways, wouldn't surprise me if GitHub actively blocks other LLMs from scrapping public repos while allowing co pilot to.). How can anyone compete against a trillion dollar company that's fine with subsidizing an unprofitable business line? Ultimately I don't think Gitlab or anything like it can hope to actually make money. I'm open to being wrong through. reply frognumber 6 hours agoparentI think you are wrong. Not having a moat is a business model and a competitive advantage, and one which works well. As a customer, it gives me confidence that, if gitlab (or any similar company) screws up, I can host it myself. I go for open source precisely due to the lack of a moat. That's what most open models rely on. 1) Hosted services are cheaper than running it myself, once I include staff time, so by default, I will go to the source vendor. 2) Even if there's a cheaper alternative, I'll gladly pay e.g. 50% more to go to the organization which wrote / maintains the product. Many companies just aren't that price-sensitive. If you pay $200k for a SWE, is saving $100/year worth it to go for gitlabknockoff.com instead of gitlab.com? Most big organizations wouldn't. The risk only comes in if gitlabknockoff was AWS, Azure, or GCP, which we're still learning what to do about. 3) There is a shallow moat in the forms of things like brand recognition, canonical URLs, etc. If you're comfortable with e.g. a . If you pay $200k for a SWE, is saving $100/year worth it to go for gitlabknockoff.com instead of gitlab.com? Arguably Gitlab sounds like a GitHub knockoff, although it's actually more expensive. No moat plus a clear dominant competitor. Now it's possibly Gitlab could still be a smaller player, but they'd probably have to accept a much lower valuation and trim costs. reply frognumber 5 hours agorootparentI think the key bug in gitlab is exactly that: out-of-control costs. One of the key things about moatless models is you do need to keep costs under control. Gitlab has 2,268 employees. That's probably an order-of-magnitude more than they need. With 226.8 employees, they would be wildly profitable. Now, once you take on employees, it's very, very hard to shrink. It takes a lot of disciplines not to overgrow workforce. So I'm not suggesting layoffs or anything specific to fix it. Regarding costs: Gitlab is $29/month. Github is $21/month (or $4/month). * If you're spending $200k on an employee, is it really worth saving $300 or whatever per year on tooling? Any difference in productivity will far overwhelm that. * If a devops employee runs $200k per year, are you going to \"host your own\" to \"save\" a few grand? Much of the market simply doesn't care about pennies, and bottom-feeders aren't super-profitable in either case. Bottom-feeders can be important from a network effects perspective, but for profit, going for the high-margin makes a lot of sense. Honestly, I have no idea how I'd value gitlab; that's another story. But all else being equal, I'll pick open-source over proprietary. That is a competitive advantage over github. reply nikau 4 hours agorootparent> Gitlab has 2,268 employees. That's probably an order-of-magnitude more than they need The state of their long open issue tickets suggest otherwise. reply Aeolun 4 hours agorootparentSpeed goes down as org size increases. We just delivered a one page form with 10-20 people in a month, and it was an almost impossible achievement. reply 999900000999 1 hour agorootparentprevMore employees make number go up. Back when interest rates were near zero complained hired more people than they needed. The money was really good too, I was making more money 4 years ago. reply cdelsolar 4 hours agorootparentprevWhat’s a moat ? reply seanhunter 2 hours agorootparentA moat was a defensive ditch (often filled with water) built around medieval castles to make them harder to attack[1]. In the context of a company, when people talk about a moat they usually mean some unique feature or structural advantage that allows a company to maintain a competitive edge over time, makes it harder for a competitor to usurp the company's market position or steal their customers etc.[2] So here a moat means \"what does gitlab have that makes it harder for someone else to launch a git hosting thing and devs/companies/whoever just ship over to it?\" To which the answer is clearly \"not very much\" given that github exists and does a very similar thing. [1] https://medievalbritain.com/type/medieval-life/architecture/... [2] https://www.investopedia.com/ask/answers/05/economicmoat.asp reply Aeolun 4 hours agorootparentprev> Most big organizations wouldn't. Difference being that by not using Gitlab you are saving $1200/year per engineer of course. If you instead go with Github you get more or less the same feature set for only $240/year. reply lucideer 6 hours agoparentprev> I'm actually surprised GitHub/Microsoft hasn't eaten their lunch yet. It's not for lack of trying. GitHub are aggressively pursuing the enterprise market from a sales perspective but there's been three problems with their approach: 1. They're pushing SaaS over on-prem: enterprise services in general are trending this way, but it only really works when you're in a dominant position - like e.g. Atlassian - when you're competing it's going to leave you with less leverage with potential clients. 2. They're leaning very heavily on AI - this is a double-edged sword as it's currently selling well to clients as a pitch but anyone doing functional evaluations is looking at benchmarks & it's not really mature enough to deliver there. 3. They're iterating really slowly on their roadmap. This seems to be GitHub's (not Microsoft's) typical approach, which I'm honestly a big fan of, but when you're entering a market with existing mature players it's going to slow down sales. I do think GitHub will ultimately take over - it'll just happen slower than expected. reply nicce 6 hours agorootparent> They're pushing SaaS over on-prem You can perfectly run, identical, self-hosted version of GitHub on premise? Maybe sales is focusing SaaS, but otherwise, there isn't difference? reply jjayj 6 hours agorootparentI run an on-prem GitHub server. New features come 6-18+ months behind Cloud for the most part, our reps are always trying to get us to move to Cloud, and new features are often broken for weeks/months even after being released for on-prem. reply lucideer 5 hours agorootparentCurious about your experience as I'm in a similar position (running ghe, want to stay on it, mgmt being sold on ghec) - I have other reasons for wanting to stay on ghe but my experience is recent features hit ghec first. Maybe that's a recent change in their release cycles? reply 999900000999 5 hours agorootparentprevI might be out of my element, but if your trying to run on prem anyway, why not just go full open source and self host? reply lucideer 5 hours agorootparentSubjective take: GH & GL are equally bad when it comes to bundled enterprise features, so the differentiator is going to be individual dev features & UX/DX. GH is much better at the latter - CICD might've been a differentiator in the past for GL but even before Actions a lot of companies were pretty happy going 3P here. reply pixl97 5 hours agorootparentprevI would assume they are running it for a company, in which if said user gets hit by a bus you want to be able to bring someone else in quickly that can run the operation. reply lucideer 6 hours agorootparentprevMainly talking about sales, but also a lot of their newer enterprise-oriented new feature developments are either saas-first, or not (yet?) roadmappedb for on-prem. reply jpalomaki 6 hours agoparentprev>How can anyone compete against a trillion dollar company that's fine with subsidizing an unprofitable business line? It sounds like impossible, but it's not always. Sometimes large companies loose the focus and become slow. There can be multiple competing products and teams are prevented from building the best product in order to not interfere more profitable business. Microsoft for example has both GitHub and Azure DevOps. One example of how the infinite resources do not always help. Year ago GitHub decided not proceed with adding support for Python packages in GitHub packages. \"This is no longer planned due to a change in our strategic priorities and the allocation of our resources towards higher-priority initiatives.\" [1] [1] https://github.com/github/roadmap/issues/94#issuecomment-158... reply nicce 6 hours agorootparent> Microsoft for example has both GitHub and Azure DevOps. Not sure what you meant, but this is indeed visible in GitHub, maybe in positive way. GitHub Runners are specifically coded with C# and ASP.NET Core and designed to be used on Azure, while not limited so. Maybe the adaption of current GitHub Actions would not happened so efficiently without this. reply Jochim 5 hours agoparentprevGitlab's biggest issue has always been their ridiculous approach to pricing. It simply isn't worth paying ~20-30x more per developer than comparable tools. Feature segmentation can be entirely reasonable. However, gating something like \"linking epics\"[0] behind what used to be $99/month/user (now POA) is pure hubris. [0] https://docs.gitlab.com/ee/user/group/epics/linked_epics.htm... reply rsp1984 5 hours agoparentprevCounterargument: Atlassian offers a very similar product and is worth $50B. Of course they've got JIRA but everybody hates it. GitLab (or whoever ends up buying it) could acquire Linear.app for example and eat Atlassian's lunch. reply llamaLord 5 hours agoparentprevAs the person who runs one of the largest cloud CI/CD services around, I can tell you exactly how they're making money... Actions. GitHub would be making a VERY healthy margin on every minute of build time run on their platform, especially considering they don't have to pay a cloud platform for the compute like Gitlab or Bitbucket Pipelines do. reply Aeolun 4 hours agorootparentRunning an amazon instance is around 10x cheaper than using an equivalent action runner. But for 99% of people it doesn’t matter because their usage never goes over the free allowance anyway. reply Uvix 6 hours agoparentprevGitHub certainly isn’t making money on their open source hosting, but that’s what the enterprise side is for. reply guappa 5 hours agorootparentI doubt it actually makes money there either. reply xyst 7 hours agoprevThis is like one of those drunken hookups at the end of a night. Then when you wake up in the morning, there’s a sense of uneasiness and regret upon sobering up. I sense a Datadog acquisition will likely fall through or somebody else will buy it. I really don’t understand how a cloud monitoring firm would stand to benefit from a code repository firm. - ‘free’ monitoring with your GL hosted app. Get them hooked and vendor locked, and now you have a customer for life? reply altdataseller 7 hours agoparentWouldn’t having insights into the stack used by a company help with cross selling their monitoring suite? Example: if a company is committing code that is heavily involved with Redis, Datadog could come in and say “hey, need to monitor memory usage of your Redis clusters? We got a solution for that” Just playing devils advocate reply eschneider 6 hours agorootparentSo...hosting company analyzing code to see what what they can market to me? Ewww. reply snapcaster 5 hours agorootparentprevThis would create a lot of backlash in my company reply nashashmi 1 hour agoprevInstead of selling itself, it should buy sourceforge. That will be one quick step to becoming a replacement to github with a network purchase. The ads are just cherry top. Secondly, acquire an issue tracker software. With a huge base of private developers, project management software is a step over. Thirdly, launch a news media site like download.com. Investment price: $300 million + 400$ million plus $40 million. Return on investment: $24 Billion market cap. x3 reply altdataseller 7 hours agoprevCan anyone tell me why someone would pay nosebleed prices for Gitlab when they could simply use Github? Like do they have some special use case that github doesn’t support? Do Gitlab customers just love giving away lots of money? Do they want to pay a premium just to feel “special”? Like what am I missing? reply oneplane 6 hours agoparent> simply use Github > Like what am I missing? The part where it's not 'simply'. If you just have some Git repositories, and nothing else, then yes, you can use any of the Git hosting services, and it doesn't make any difference if you are using GitLab, GitHub, BitBucket, AWS (CodeCommit), Azure (similar), Google (similar), as a DVCS (using SSH or mail), or whatever else you can come up with (Gitea etc). Most of them are free for just some Git (including GitLab and GitHub). But as soon as you do more than that, there is no more 'simply'. GitLab has features GitHub doesn't have, they both have features that aren't 1-to-1 comparable, and price wise if you use the same features on both sides, GitHub tends to cost more. And then there's the whole CI thing where you can't use GitLab CI files on GitHub Actions (but you can use GitLab CI in combination with GitHub repositories but that would cost more), shipping hierarchical organisational structures is either a PITA or not possible and updating all references everywhere on everyones machines is going to suck either way, which eats into the 'simply'. reply deng 6 hours agoparentprevCost of migration, especially all the pipelines and project planning. GitLab used to be a good deal. The bronze tier was 4$ and you had better CI than GitHub at the time. Then in 2021 they ditched bronze and went to the new three tier model, the cheapest being 20$ (apart from the free tier, which however is severely limited). Last year they increased it to 30$, and that does not even include AI features, which will cost you 20$ extra. So nowadays, there is indeed pretty much no reason to chose GitLab other than self-hosting. We still have license until 2026 and I'm pretty sure we'll bite the bullet and start migration to GitHub before we renew. Sadly, I don't see much of a future for GitLab, apart from being acquired by Google, Meta or similar who can afford to run this at a loss for strategic reasons, like MS does with GitHub. reply antupis 7 hours agoparentprevWhen you have hundreds ci/cd pipelines written on GitLab and people are using ci/cd pipelines more like CRON migration becomes extremely hard. reply tyingq 7 hours agoparentprevI think mostly support for both on-prem instances and SaaS, but your own dedicated instance. So stodgier places that don't like their code or pipelines in shared tenant environments. Maybe because their internal audit, cyber department, etc, are sticking to their policies that have been around a long time. That would account for new sales. Then, lots of existing base because they used to be an inexpensive bundled repo+ci/cd solution. And anyone's proprietary ci/cd ecosystem becomes sticky and hard to migrate from once you put a lot of repos into it, whether that's Gitlab or any other provider. So people don't switch away because it's hard. reply MilStdJunkie 3 hours agoparentprevGitLab on-prem is way, way, way more elegant than trying to get GitHub on-prem working. One of the things that makes me go, \"Gah?\" is that, well, Atlassian is more or less abandoning on-prem Bitbucket going forward. Perforce is, well, Perforce. Niche VCSs like SVN are rapidly getting impossible to keep running on modern platforms. All this really does seem to leave the field of \"small to midsize companies who can't cloud\" entirely to GitLab. Which, I guess, says something about how expensive it is to run support for on-prem enterprise software. But that doesn't feel like an unsolvable problem, not with a customer field this rich. On-prem focused orgs tend to have wads of cash stuck up in them. reply j45 7 hours agoparentprevBoth are pretty good. Some companies don’t want their source code in GitHub for security reasons. holes, who gets direct or indirect access to source code. reply Hamuko 7 hours agoparentprevFor us, it's mainly for legacy reasons. We used to have a self-hosted GitLab instance as a fledling company and then switched to SaaS GitLab after the company grew and IT spent too much time maintaining it, with an Ultimate subscription to get access to the security tools. If this was my company, we would be on GitHub since GitLab Ultimate is super fucking expensive and those security tools are buggy as hell. Not sure if the GitHub ones are any better, but surely they can't be worse. Granted, I don't know how much we actually pay since Ultimate price these days is \"contact sales\", but I'm pretty sure it used to be like $99/user/month. (We also wouldn't be paying for Jira on top of GitLab/GitHub.) reply Aeolun 4 hours agorootparentGithub Advanced Security is $79/user per month (on top of $21/user per month for enterprise edition), but is actually really good. I’ve considered buying it for my own private repositories because it’s so nice (yes, a single person enterprise account is fine with Github too, and you can pay monthly). I… used to like Gitlab, but it’s like they lost their way a few years ago and now I’d never recommend them. reply Hamuko 4 hours agorootparentGitHub's pricing page says that it's $49/user/month extra on top of that $21/user/month Enterprise fee. So even though it's kinda pricey, it's still less than the $99/user/month that GitLab Ultimate was. reply PrivateButts 2 hours agoprevI would love to give Gitlab money, we live out of it at work, but charging a per user cost for self hosted instances is insane. I have budget to spend, but I can't justify $30 per seat per software per month, especially if I'm the one hosting it. reply lijok 7 hours agoprevAnyone keeping count on which cycle of “I’m switching to Git{Hub|Lab}” this puts us? reply edvards 7 hours agoparentTime for Gitea. reply janice1999 7 hours agorootparentDon't forget the forks: Gog -> Gitea -> Forejo reply ibz 4 hours agorootparentOr just forget all of that and go to Fossil? SQLite seems the least likely to pull the rug. reply 0x00cl 7 hours agorootparentprevI thought Codeberg (Forgejo, fork of gitea) was the new flavour. reply Macha 7 hours agorootparentprevHonestly, Gitea have started on the open core route, I'm skipping over them and have gone to Forgejo reply nicce 6 hours agorootparentYeah, Gitea is now owned by for-profit company, decided without any communication with the community. Forgejo is the non-profit fork. See: https://forgejo.org/compare-to-gitea/ reply cdelsolar 4 hours agorootparentWhat kind of a name is forgejo? reply esalman 3 hours agorootparentFrom their FAQ, Forgejo (pronounced /forˈd͡ʒe.jo/) is inspired by forĝejo, the Esperanto word for forge. reply Aeolun 4 hours agorootparentprevA very bad one? reply nicce 3 hours agorootparentI don't know. I like it. reply _flux 7 hours agoparentprevRadicle! It's the easiest (?) way for anyone to \"self host\" a repo with issue tracker. But there's of course the chance that the team developing it will be sold, even if the actual app is open source. reply itake 8 hours agoprevI know it’s just business, but I still have a chip on my shoulder for gitlab’s low equity packages reply j45 7 hours agoparentI think the post is about the customer perspective reply wg0 6 hours agoprevDatadog is going to milk the cow because I don't see what else are they going to use this except push their monitoring solution to the GitLab enterprise customer base or jack the prices to recoup the investment. Also - wondering what will the commerce look like in 500 years when everyone has bought each other over multiple generations. reply shitlord 24 minutes agoparentA more optimistic view of the situation is that Datadog is already in the monitoring business and wants to go after the rest of the SDLC. There's certainly some value in correlating code changes with incidents. reply omidontop 8 hours agoprevA sad day for small businesses and software developers. reply everfrustrated 2 hours agoprevDatadog is the new Cisco reply neilv 7 hours agoprevWhat is motivating a sale? And how would that sale work? (Does it involve different classes of shares?) reply penguin_booze 5 hours agoprevI'm interested in hearing why one choose a Gitlab on-perm instance vs. a Gerrit + Jenkins system. reply Aeolun 4 hours agoparentHave you ever used Jenkins? Even if I don’t like Gitlab I’d choose it over Jenkins any day of the week. It’s not strictly terrible, just ancient. Like you are trying to drag 2000’s enterprise software through the intervening 20 years and make it work for today. reply gavinhoward 3 hours agoprevWelp, time to quickly implement my ideas for a GitHub-in-a-box, just in time to steal newly disgruntled GitLab customers. reply officialchicken 8 hours agoprevnext [12 more] [flagged] orf 8 hours agoparentIf you're small enough to be able to migrate away from Gitlab in a single day then you're not contributing to anyone's bottom line. reply wg0 6 hours agorootparentThat's insulting, factual and hilarious at the same time. reply officialchicken 8 hours agorootparentprevAre you exploring buying GitLab? reply lewispollard 7 hours agorootparentDid you mistake the hacker news comment box for a private email? reply orf 7 hours agorootparentprevSure, why not reply laserlight 8 hours agorootparentprevThe fact that GitLab continues to serve them tells me that they are more likely, than not, to be contributing to the bottom line. reply richardwhiuk 7 hours agorootparentThey could be a loss leader. reply lolinder 6 hours agorootparentGitLab fired all their loss leaders as customers years ago when they eliminated every small and middle tier from their payment plans. reply wdfx 8 hours agoparentprevIf this news elicits such a strong reaction as this, it makes me wonder why you are even using Gitlab right now, if there is even any likelyhood of such an outcome? reply officialchicken 8 hours agorootparentnext [2 more] [flagged] gibs0ns 7 hours agorootparentStop being weird. reply hankchinaski 7 hours agoparentprevSir, this is a Wendy’s reply re-thc 8 hours agoprev [–] Would be great if Alphabet buys them i.e. integrate it into Google Cloud. reply azornathogron 8 hours agoparentGoogle had a code hosting service (free for open source projects) with repo, issue tracker, and wiki. But it was shut down in 2016. Now there is just an archive: https://code.google.com/archive/ reply pelagicAustral 5 hours agorootparentIt was horrendous, looked legacy since day 1. Gitlab has so much more to offer... reply elbowjack65 8 hours agoparentprevCoincidentally, Google is shutting down Google Source repositories in GCP today. https://cloud.google.com/source-repositories/docs reply rkachowski 8 hours agoparentprevA new google tombstone would be super exciting indeed reply 15155 8 hours agoparentprevRemember Google Code? reply lvncelot 5 hours agoparentprevThat's just taking it out back and shooting it with extra steps. reply nubinetwork 7 hours agoparentprev [–] Yeah, uh, no. They'll just kill it like everything else. https://killedbygoogle.com/ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Gitlab is considering a sale, raising concerns among users about potential shutdowns or changes in service models, reminiscent of past issues with RedHat and CentOS.",
      "Users debate the merits of open-source options like Gitlab, citing easier migration and community support, while speculating on potential buyers such as Datadog or IBM.",
      "Criticisms of Gitlab's pricing and enterprise focus have led some users to contemplate switching to alternatives like GitHub, reflecting mixed sentiments about future stability and costs."
    ],
    "points": 146,
    "commentCount": 105,
    "retryCount": 0,
    "time": 1721203046
  },
  {
    "id": 40981068,
    "title": "Darwin Machines",
    "originLink": "https://vedgie.net/writing/darwin_machines.md",
    "originBody": "Darwin Machines I'm writing this because I've been obsessed with the theory of a Darwin Machine for nearly a year now and I haven't met anyone else who has heard of it. This is my attempt to summarize and share the theory that William Calvin laid out in \"The Cerebral Code\". If you haven't read it and are interested in how the brain works or AI/ML you should order a copy right now. I'm going to do the book no justice but hopefully, if you haven't already ordered the book, the rest of this post will convince you to read it. If you, or anyone you know, is interested in these ideas or wants to build/is building a Darwin Machine, please reach out. My email is calepayson(at)mac.com. First a Little Background On Evolution: Near the end of his career Schrodinger wrote a book, \"What is Life?\", that provides a great lens through which to view biology: Life is unnatural... If you're a physicist. One of the defining pillars of physics is the second law of thermodynamics. Energy hates being concentrated. Yet here we are, squishy bags of water and energy suspended a few feet above the ground. It's a bit weird. Schrodinger decided the only way that life was possible was if it led to more entropy throughout the system. Like a tornado, life is a pocket of order that sows disorder. It lives so long as it pays the entropy tax. To anthropomorphize a bit, The Universe is trying to maximize entropy but it has a near infinite \"problem space\". One algorithm it has found to solve this problem is evolution. To butcher a computer science phrase, I believe that evolution is the \"best case runtime\" when trying to find increasingly valid solutions to a near infinite problem space. Essentially, biology uses evolution because it is the best way to solve the problem of prediction (survival/reproduction) in a complex world. On Constraints: I love constraints in science because they can give us hope for a theory before it has been worked out. For example, before we knew what genetic material was, we knew it had to fit in cells, be chemically stable, and had to be capable of making high fidelity copies of itself. It took four years after Watson and Crick discovered the double helix for us to prove it was genetic material but we knew their discovery held promise because it fit within the constraints. I see a few constraints governing how the brain works. First, and most importantly, the brain is also faced with a near infinite problem space. There are trillions of behaviors, only some of which are \"fit\" for any given scenario. Any theory of intelligence should explain how the brain solves this in the most efficient manner possible. The other constraints are based on a few studies and observations that seem important. Karl Lashley showed that memory is massively parallel and, contrary to the idea of a \"grandmother cell\", is not stored in a single location. David Eagleman showed that other brain functions in the brain like perception are also massively parallel. He dubbed this the \"Mr. Potato Head\" theory because no matter where you \"plug in\" sensory input, your brain tends to figure out what to do with it. Plug some eyes into the olfactory cortex and a nose into the visual cortex and the brain will keep right on trucking. Two additional things to add: Brain patterns are spatio-temporal patterns. If I turn off cell firings, say with anesthesia, you lose your train of thought.: But they store those patterns spatially. When you come out of anesthesia, you're still you. Think of this like RAM vs. Disk. On Brains If you were to flatten out the neocortex of the brain - the new bit that we think is important for intelligence - on a table you would notice two things. First, if you look at a cross-section of the brain (eye-level with the table), the brain is divided into ~6 layers. This layering forms the dominant narrative of how intelligence may work and is the basis for deep neural nets. The idea is, stimulus is piped into the \"top\" layer and filters down to the bottom layer, with each layer picking up on more and more abstract concepts. Three Blue One Brown does a good job of articulating this idea in a video. Second, if you look down on the brain from above, the brain is divided into columns. The smallest unit of these are minicolumns, bundles of 80-120 neurons that run perpendicular to the layers of the brain, from the \"top\" to the \"bottom\" (or vice versa, it doesn't matter). These minicolumns can then be grouped into cortical columns, which can be thought of as roughly hexagonal bundles of minicolumns, also running perpendicular to the layers of the brain. And that's about it. The brain is incredibly, wonderfully, complex. The neocortex is insanely complex too. And it's also basically a crumpled up sheet with the structure described above. At least that's the level of abstraction we'll be working with. From the perspective of a bystander, modern machine learning seems to believe that the recipe for more intelligence is adding more layers. But based upon the homogeneity of neocortex it seems that, in biology, the recipe for more intelligence is adding more columns. A rat has the same number of layers as a chimp as a human, but the surface area of a rat's neocortex, a proxy for the number of columns, is less than a chimp which is less than a human. To prevent confusion, I'm saying that adding more columns is the recipe for more \"animal intelligence. \"Human intelligence\" is different than animal intelligence owing to our capacity for high fidelity imitation. I'll write more on this in the future. On Darwin Machines If modern ML explains intelligence with layers, the theory of a Darwin Machine explains evolution with columns. As a reminder, a theory should satisfy the following: Implements an efficient algorithm to search a near infinite problem space. Both memory and processing are massively parallel. Computation uses spatio-temporal patterns. But memory is spatial. The theory of Darwin Machines developed by William Calvin proposes that the brain, like life, implements evolution to search a near infinite problem space. Calvin believes that minicolumns are the arena for this evolution. Sensory inputs hit the brain, visual input in one area, olfactory in another, etc. and trigger specific firing patterns in the minicolumns. Imagining the surface of the brain laid flat on a table, we can look down on it and see these columns lighting up, as if with Morse Code messages. These messages then propagate across the surface area of the brain, competing with conflicting messages to take over the greatest surface area. After some period of time a winner is chosen, likely the message that controls the greatest surface area, the greatest number of minicolumns. When this happens, the winning minicolumns are rewarded, likely prompting them to encode a tendency for that firing pattern into their structure. Before we go deeper let's pause and notice that this theory satisfies all our constraints. It implements the \"best case runtime\" algorithm for predicting \"valid\" solutions to a complex problem space. It is massively parallel with computation and storage happening between and within individual minicolumns. The calculation is done with a spatiotemporal \"Morse Code\" message. But storage is performed by changing the spatial relationships within a minicolumn so that the message is more easily triggered in the future. This all seems so simple. There are only so many firing patterns a minicolumn can have within some reasonable clock speed yet there is a practically infinite range of thought. How does the Darwin Machine theory explain that? This brings us to cortical columns. Minicolumns communicate with each other using axons, basically wires. Some of these wires connect neighboring minicolumns but many reach further, skipping roughly ten minicolumns before connecting. These connections result in a triangular array of connected minicolumns with large gaps of unconnected minicolumns in between. Well, not really unconnected, each of these are connected to their own triangular array. Looking down on the brain again, we can imagine projecting a pattern of equilateral triangles - like a fishing net - over the surface. Each vertex in the net will land on a minicolumn within the same network, leaving holes over minicolumns that don't belong to that network. If we were to project nets over the network until every minicolumn was covered by a vertex we would project 50-100 nets. A cortical column is made up of 50-100 minicolumns. You can think of a cortical column as a hexagon containing one minicolumn from each network. Cortical columns allow for the complexity that minicolumns alone couldn't provide. Each one can encode somewhere between n^50 and n^100 unique patterns where n is the number of patterns that a minicolumn can encode. Even if minicolumns only had two states, this would provide us with the building blocks for a massive range of thoughts. With all this in mind we can tell the story of how a Darwin Machine works. Sensory input comes in and causes minicolumns to fire in certain patterns. The resulting pattern is influenced by the input and the \"tendencies\" of the minicolumn that have been spatially encoded over time. Each firing pattern, each message, competes with other messages from minicolumns within its network. Through this competition each network settles on the most fit message, the message that best correlates with sensory input and the tendencies of its minicolumns. At the cortical column level, the message from each network is read. Here I'll steal one of Calvin's metaphors: Each message is like an individual instrument in a band or orchestra. It encodes some bit of information but it's the amalgamation that is important. \"Super Freak\" and \"U Can't Touch This\" are two very different songs despite having the same bass and piano riff. Likewise, two different thoughts or concepts can be made of many of the same minicolumn firing patterns. Eventually a winner is chosen, possibly by finding the \"song\" playing on the most cortical columns, and learning happens. The winning cortical columns are rewarded, somehow leading to their minicolumns encoding a tendency towards the message they were transmitting. These minicolumns will \"remember\" that firing pattern and are more likely to produce it in the future. A Darwin Machine uses evolution to produce intelligence. It relies on the same insight that produced biology: That evolution is the best algorithm for predicting valid \"solutions\" within a near infinite problem space. Some Speculation On Advantages I believe the theory of Darwin Machines illuminates a path to solving one of the biggest problems in AI right now. Current algorithms are great at system one thinking, quick thoughts, intuition. But they are not capable of system two thinking, deep thinking, where time spent on the problem correlates with a better answer. The evolutionary approach of Darwin Machines seems to allow for the possibility of both. System one thinking would only run the competition for a short time, relying on the tendencies encoded in minicolumns to provide a quick and \"good enough\" behavior. System two thinking would let the competition run longer, allowing evolution to play out, leading to novel and \"more fit\" thoughts. On Creativity Many people believe that, in biology, point mutations lead to the change necessary to drive novelty in evolution. This is rarely the case. Point mutations are usually disastrous and every organism I know of does everything in its power to minimize them. Think, for every one beneficial point mutation, there are thousands that don't have any effect, and hundreds that cause something awful like cancer. If you're building a skyscraper, having one in a hundred bricks be laid with some variation is not a good thing. Instead Biology relies on recombination. Swap one beneficial trait for another and there's a much smaller chance you'll end up with something harmful and a much higher chance you'll end up with something useful. Recombination is the key to the creativity of evolution, and Darwin Machines harness it. A complex thought such as a memory of your grandmother is likely represented in a cortical column as a specific combination of spatiotemporal firing patterns within its minicolumns. But let's say you need to think of someone else's grandmother. The individual firing patterns that code for a grandmother probably remain, but the ones that code information specific to yours are likely swapped out for patterns corresponding to the new grandmother. Maybe you're interested in bird watching and see a new bird. Your brain likely uses recombination to form the thought representing this bird. Maybe you've never seen a flamingo before. Some networks of minicolumns might identify features similar to a parrot you saw once, perhaps the pink coloring. Some might light up to say that the beak looks a bit like a toucan's. Others might propagate a message suggesting it's the size of an ostrich. etc. All these different messages can then mix together and our brain can store this unique combination as a flamingo. Or in the other direction. When you're thinking hard about a question, you could let your mind wander a little (isn't that when all the good ideas hit us?). Maybe the act of mind wandering lets some message within the cortical column get exchanged for another. And WHAM! A new idea, a possible solution. This is all speculation but I hope you can see the beauty of the Darwin Machine framework. I've been immersed in neuroscience for about four years now and nothing I've come across comes close to the breadth of explanation that this theory promises if born out in experiments. On Implementation Neural nets are great at intuition. They can take a seemingly infinite number of inputs and encode them into a relatively small space. Then, when prompted they can spit out something that is ~95% correct. I suspect minicolumns and neural nets are, to a large extent, functionally equivalent. I'm trying small neural nets implemented in an array instead of one lone massive neural net. If it takes them one cycle to process an input pattern to an output pattern, then every cycle they should take a sensory input, and the input from adjacent neural nets in their array, and produce an output that, overtime, synchronizes throughout the array. I would love any advice, from anyone, about how to cunduct my own research and subsequent academics (if necessary) in order to work in this space. I hope you find this idea as exciting as I do.",
    "commentLink": "https://news.ycombinator.com/item?id=40981068",
    "commentBody": "Darwin Machines (vedgie.net)145 points by calepayson 20 hours agohidepastfavorite71 comments cs702 4 hours agoBig-picture, the idea is that different modalities of sensory data (visual, olfactory, etc.) are processed by different minicolumns in the brain, i.e., different subnetworks, each outputting a different firing pattern. These firing patterns propagate across the surface area of the brain, competing with conflicting messages. And then, to quote the OP, \"after some period of time a winner is chosen, likely the message that controls the greatest surface area, the greatest number of minicolumns. When this happens, the winning minicolumns are rewarded, likely prompting them to encode a tendency for that firing pattern into their structure.\" And this happens in multiple layers of the brain. In other words, there's some kind of iterative mechanism for higher-level layers to find which lower-level subnetworks are most in agreement about the input data, inducing learning. Capsule-routing algorithms, proposed by Hinton and others, seek to implement precisely this idea, typically with some kind of expectation-maximization (EM) process. There are quite a few implementations available on github: https://github.com/topics/capsules https://github.com/topics/em-routing https://github.com/topics/routing-algorithm reply abeppu 2 hours agoparentI haven't heard of anyone talk about Hinton's capsule network concepts for some time. In 2017-18 it seemed exciting both because of Hinton but also because the pose/transformation sounded pretty reasonable. I don't know what would count as \"explanation\", but I'd be curious to hear any thoughts about why it seems they didn't really pan out. (Are there any tasks for which capsule methods are the best?) reply MAXPOOL 1 hour agorootparentIf you take a birds eye view, fundamental breakthroughs don't happen that often. \"Attention Is All You Need\" paper also came out in 2017. It has now been 7 years without breakthrough at the same level as transformers. Breakthrough ideas can take decades before they are ready. There are many false starts and dead ends. Money and popularity are orthogonal to pathfinding that leads to breakthroughs. reply calepayson 15 minutes agorootparentWell said reply cs702 2 hours agorootparentprevThe short answer as to why capsule networks have \"fallen out of fashion\" is... Transformers. Transformers came out at roughly the same time[a] and have proven to be great at... pretty much everything. They just work. Since then, most AI research money, effort, and compute has been invested to study and improve Transformers and related models, at the expense of almost everything else. Many promising ideas, including routing, won't be seriously re-explored until and unless progress towards AGI seems to stall. --- [a] https://arxiv.org/abs/1706.03762 reply abeppu 1 hour agorootparentI think this is a non-answer in some sense. Yes, transformers have been clearly very successful across a very wide range of tasks. But what about the approach taken in capsules is comparatively deficient? Some kinds of explanations which I think are at least plausible (but IDK if any evidence exists for them): - The attention structure in transformers allows any chunk to be learned to be important for any other chunk. And pretty quickly people tended towards these being pretty deep. By comparison, the capsule + routing structure (IIUC) came with a built-in kind of sparsity (from capsules at a level in the hierarchy being independent), and because the hierarchy was meant to align with composition, it often (I think) didn't have a huge number of levels? Maybe this flexibility + depth are key? - Related to capsules being independent, an initial design feature in capsule networks seems to have been smaller model sizes. Perhaps this was at some level just a bad thing to reach for? I think at the time, \"smaller models means optimization searches over a smaller space, which is faster to converge and requires less data\" was still sort of in people's heads, and I think this view is pretty much dead. - I've heard some people argue that one of the core strengths of transformers is that they support training in a way allows for maxing out available GPUs. I think this is mostly in comparison to previous language models which were explicitly sequential. But are capsule networks less conducive to efficient training? reply cs702 28 minutes agorootparentIt's hard to make a fair comparison, because there hasn't been anywhere near as much money, effort, or compute invested in trying to scale up routing methods. Promising approaches are often ignored for reasons that have little to do with their merits. For example, Hinton, Bengio, and Lecun spent much of the 1990's and all of the 2000's in the fringes of academia, unable to get much funding, because few others were interested in or saw any promise in deep learning! Similarly, Katalin Karikó lost her job and spent decades in obscurity because few others were interested or saw any promise in RNA vaccines. Now, I'm not saying routing methods will become more popular in the future. I mean, who the heck knows? What I'm saying is that promising approaches can fall out of favor for reasons that are not intrinsic to them. reply calepayson 2 hours agoparentprevGreat summary. Thanks for the links. These are awesome. reply nikolayasdf123 13 hours agoprev> This layering forms the dominant narrative of how intelligence may work and is the basis for deep neural nets. The idea is, stimulus is piped into the \"top\" layer and filters down to the bottom layer, with each layer picking up on more and more abstract concepts. popular deep artificial neural networks (lstms, llms, etc.) are highly recurrent, in which they are simulating not deep networks, but shallow networks that process information in loops many times. > columns.. and that's about it. recommend not to oversimplify structure here. what you describing is only high-level structure of single part of brain (neocortex). 1. brain has many other structures inside basal ganglia, cerebellum, midbrain, etc. each with different characteristic micro-circuits. 2. brain networks are highly interconnected on long range. neurons project (as in send signals) to very distant parts of the brain. similarly they get projections from other distant parts of brain too. 3. temporal dimension is important. your article is very ML-like focusing on information processing devoid of temporal dimension. if you want to draw parallels to real neurons in brain, need to explain how it fits into temporal dynamics (oscillations in neurons and circuits). 4. is this competition in realm of abeyant (what you can think in principle) or current (what you think now) representations? what's the timescales and neurological basis for this? overall, my take it is a bit ML-like talk. if it describes real neurological networks it got to be closer and stronger neurological footing. here is some good material, if you want to dive into neuroscience. \"Principles of Neurobiology\", Liqun Luo, 2020 and \"Fundamental Neuroscience\", McGraw Hill. more resources can be found here: http://neuroscience-landscape.com/ reply calepayson 1 hour agoparent> popular deep artificial neural networks (lstms, llms, etc.) are highly recurrent, in which they are simulating not deep networks, but shallow networks that process information in loops many times. Thanks for the info. Is there anything you would recommend to dive deeper into this? Books/papers/courses/etc. > recommend not to oversimplify structure here. what you describing is only high-level structure of single part of brain (neocortex). Nice suggestion. I added a bit to make it clear that I'm talking about the neocortex. > 1 & 2 Totally. I don't think AI is a simple as building a Darwin Machine, much like it's not as simple as building a neural net. But I think the concept of a Darwin Machine is an interesting, and possibly important, component. My goal with this post was to introduce folks who hadn't heard of this concept and, hopefully, get in contact with folks who had. I left out the other so I could try to focus on what matters. > temporal dimension is important. your article is very ML-like focusing on information processing devoid of temporal dimension. if you want to draw parallels to real neurons in brain, need to explain how it fits into temporal dynamics (oscillations in neurons and circuits). Correct me if I misunderstand, but I believe I did. The spatio-temporal firing patterns of minicolumns contain the temporal dimension. I touched on the song analogy but we can go deeper here. Let's imagine the firing pattern of a minicolumn as a melody that fits within the period of some internal clock (I doubt there's actually a clock but I think it's a useful analogy). Each minicolumn starts \"singing\" its melody over and over, in time with the clock. Each clock cycle, every minicolumn is influenced by its neighbors within the network and they begin to sync up. Eventually they're all harmonizing to the same melody. A network might propagate a bunch of different melodies at once. When they meet, the melodies \"compete\". Each tries to propagate to a new minicolumn and fitness is judged by other inputs to that minicolumn (think sensory) and the tendencies of that minicolumn (think memory). I think the evolution is an incredible algorithm is because it relies as much as it does on time. > is this competition in realm of abeyant (what you can think in principle) or current (what you think now) representations? what's the timescales and neurological basis for this? I'm not familiar with these ideas but let me give it a shot. Feel free to jump in with more questions to help clarify. Neural Darwinism points to structures - minicolumns, cortical columns, and interesting features of their connections - and describes one possibility for how those structures might lead to thought. In your words, I think the structures are the realm of abeyant representations while the theory describes current representations. The neurological basis for this, the description of the abeyant representation (hope I'm getting that right), is Calvin's observations of the structure of the brain. Observations based on his and other's research. To a large extent, neuroscience doesn't have a great through-line-story of how the brain works. For example the idea of regions of the brain responsible for specific functions - like the hippocampus for memory - doesn't exactly play nice with Karl Lashley's experimental work on memory. What I liked most about this book is how Calvin tried to relate his theory to both structure and experimental results. > overall, my take it is a bit ML-like talk. if it describes real neurological networks it got to be closer and stronger neurological footing. If, by ML-like talk, you mean a bit woo-woo and hand wavy. Ya, I agree. Ideally I'd be a better writer. But I'm not, so I highly recommend the book. It's written by an incredible neuroscientist and, so far, none of the neuroscience researchers I've given it to have expressed anything other than excitement about it. And I explicitly told them to keep an eye out for places they might disagree. One of them is currently reading it a second time right now with the goal verifying everything. If it all checks out, he plans on presenting the ideas to his lab. I'll update the post if he, or anyone in his lab, finds something that doesn't check out. > here is some good material, if you want to dive into neuroscience. \"Principles of Neurobiology\", Liqun Luo, 2020 and \"Fundamental Neuroscience\", McGraw Hill. Why these two textbooks? I got my B.S. in neuroscience so I feel good about the foundations. Happy to check these out if you believe they add something that many other textbooks are missing. reply nirvael 9 hours agoprevI think this is over-simplified and possibly misunderstood. I haven't read the book this article references but if I am understanding the main proposal correctly then it can be summarised as \"cortical activity produces spatial patterns which somehow 'compete' and the 'winner' is chosen which is then reinforced through a 'reward'\". 'Compete', 'winner', and 'reward' are all left undefined in the article. Even given that, the theory is not new information and seems incredibly analogous to Hebbian learning which is a long-standing theory in neuroscience. Additionally, the metaphor of evolution within the brain does not seem apt. Essentially what is said is that given a sensory input, we will see patterns emerge that correspond to a behaviour deemed successful. Other brain patterns may arise but are ignored or not reinforced by a reward. This is almost tautological, and the 'evolutionary process' (input -> brain activity -> behaviour -> reward) lacks explanatory power. This is exactly what we would expect to see. If we observe a behaviour that has been reinforced in some way, it would obviously correlate with the brain producing a specific activity pattern. I don't see any evidence that the brain will always produce several candidate activity patterns before judging a winner based on consensus. The tangent of cortical columns ignores key deep brain structures and is also almost irrelevant, the brain could use the proposed 'evolutionary' process with any architecture. reply calepayson 16 minutes agoparent> I think this is over-simplified and possibly misunderstood. I'm with you here. I wrote this because I wanted to drive people towards the book. It's incredible and I did it little justice. > \"cortical activity produces spatial patterns which somehow 'compete' and the 'winner' is chosen which is then reinforced through a 'reward'\" A slight modification: spatio-temporal patterns*. Otherwise you're dead on. > 'Compete', 'winner', and 'reward' are all left undefined in the article. You're right. I left these undefined because I don't believe I have a firm understanding of how they work. Here's some speculation that might help clarify. Compete - The field of minicolumns is an environment. A spatio-temporal pattern \"survives\" when a minicolumn is firing in that pattern. It's \"fit\" if it's able to effectively spread to other minicolumns. Eventually, as different firing patterns spread across the surface area of the neocortex, a border will form between two distinct firing patterns. They \"Compete\" insofar as each firing pattern tries to \"convert\" minicolumns to fire in their specific pattern instead of another. Winner - This has two levels. First, an individual firing pattern could \"win\" the competition by spreading to a new minicolumn. Second, amalgamations of firing patterns, the overall firing pattern of a cortical column, could match reality better than others. This is a very hand-wavy answer, because I have no intuition for how this might happen. At a high level, the winning thought is likely the one that best matches perception. How this works seems like a bit of a paradox as these thoughts are perception. I suspect this is done through prediction. E.g. \"If that person is my grandmother, she'll probably smile and call my name\". Again, super hand-wavy, questions like this are why I posted this hoping to get in touch with people who have spent more time studying this. Reward - I'm an interested amateur when it comes to ML, and folks have been great about pointing out areas that I should go deeper. I have only a basic understanding of how reward functions work. I imagine the minicolumns as small neural networks and alluded to \"reward\" in the same sense. I have no idea what that reward algorithm is or if NNs are even a good analogy. Again, I really recommend the book if you're interested in a deeper explanation of this. > the theory is not new information and seems incredibly analogous to Hebbian learning which is a long-standing theory in neuroscience. I disagree with you here. Hebbian learning is very much a component of this theory, but not the whole. The last two constraints were inspired by it and, in hindsight, I should have been more explicit about that. But, Hebbian learning describes a tendency to average, \"cells that fire together wire together\". Please feel free to push back here but, the concept of Darwin Machines fits the constraints of Hebbian learning while still offering a seemingly valid description of how creative thought might occur. Something that, if I'm not misunderstanding, is undoubtedly new information. > I don't see any evidence that the brain will always produce several candidate activity patterns before judging a winner based on consensus. That's probably my fault in the retelling, check out the book: http://williamcalvin.com/bk9/index.htm I think if you read Chapters 1-4 (about 60 pages and with plenty of awesome diagrams) you'd have a sense for why Calvin believes this (whether you agree or not would be a fun conversation). > The tangent of cortical columns ignores key deep brain structures and is also almost irrelevant, the brain could use the proposed 'evolutionary' process with any architecture. I disagree here. A common mistake I think we to make is assuming evolution and natural selection are equivalent. Some examples of natural selection: A diversified portfolio, or a beach with large grains of sand due to some intricacy of the currents. Dawkinsian evolution is much much rarer. I can only think of three examples of architectures that have pulled it off. Genes, and their architecture, are one. Memes (imitated behavior) are another. Many animals imitate, but only one species has been able to build architecture to allow those behaviors to undergo an evolutionary process. Humans. And finally, if this theory is right, spatiotemporal patterns and the columnar architecture of the brain is the third. Ignoring Darwin Machines, there are only two architectures that have led to an evolutionary process. Saying we could use \"any architecture\" seems a bit optimistic. I appreciate the thoughtful response. reply mandibeet 7 hours agoparentprevWhile it does build on established concepts like Hebbian learning, I think theory offers a potentially insightful way of thinking about brain function reply jaimie 18 hours agoprevThe domain of Artificial Life is highly related and has had an ongoing conference series and journal going, might be worth mining for more inspiration: https://en.wikipedia.org/wiki/Artificial_life https://direct.mit.edu/artl https://alife.org reply mprime1 18 hours agoprevFYI Evolutionary Algorithms have been an active area of research for decades.[1] Among the many uses, they have been applied to ‘evolving’ neural networks. Famously a guy whose name I can’t remember used to generate programs and mutations of programs. My recommendation if you want to get into AI: avoid anything written in the last 10 years and explore some classics from the 70s [1] https://en.m.wikipedia.org/wiki/Evolutionary_algorithm reply EvanAnderson 14 hours agoparentI'm sure it's not who you're thinking of, but I can't miss an opportunity to mention Tom Ray and Tierra: https://tomray.me/tierra/whatis.html reply JoeDaDude 6 hours agoparentprevThere is the case of Blondie24, an evolutionary neural net, or genetic algorithm, which was able to develop a very strong checkers-playing capability by self-play with no human instruction. It was later extended to paly other games. https://en.wikipedia.org/wiki/Blondie24 reply PinkMilkshake 10 hours agoparentprevIn the Creatures artificial life / virtual pet series, the creatures have about 900 (maybe more in later versions) or so neurons. Each neuron is a little virtual machine that is designed in such a way that programs remain valid even with random mutation. reply northernman 5 hours agoparentprevI read this book:in 1972. It was published in 1966. reply blixt 12 hours agoparentprevA friend of mine made this in-browser neural network engine that could run millions of multi-layer NNs in a simulated world at hundreds of updates per second and each network could reproduce and evolve. It worked in the sense that the networks exhibited useful and varied behaviors. However, it was clear that larger networks were needed for more complex behaviors and evolution just starts to take a lot longer. https://youtu.be/-1s3Re49jfE?si=_G8pEVFoSb2J4vgS reply fancy_pantser 16 hours agoparentprevPerhaps it was John Koza? http://www.genetic-programming.com/johnkoza.html reply mandibeet 7 hours agoparentprevYour recommendation to explore the classics is a good one. You can gain a deeper appreciation by studying these foundational works reply petargyurov 11 hours agoparentprev> avoid anything written in the last 10 years Why? reply exe34 8 hours agorootparentpresumably because it's saturated with a monoculture, and the hope (rightly or wrongly), some of the other roads might lead to some alternative breakthrough. reply visarga 14 hours agoprevI don't think it matters so much how the brain is made, what matters is the training data. And we obtain data by searching. Search is a great concept, it covers evolution, intelligence and creativity, it's also social. Search is discrete, recursive, combinatorial and based on some kind of language (DNA, or words, or just math/code). Searching the environment provides the data brain is trained on. I don't believe we can understand the brain in isolation without its data engine and the problem space where it develops. Neural nets showed that given a dataset, you can obtain similar results with very different architectures, like transformer and diffusion models, or transformer vs Mamba. The essential ingredient is data, architecture only needs to pass some minimal bar for learning. Studying just the brain misses the essential - we are search processes, the whole life is search for optimal actions, and evolution itself is search for environment fitness. These search processes made us what we are. reply advael 11 hours agoparentWhat in the world Most \"diffusion models\" use similar VAE to transformer backbone architectures. Diffusion isn't an architecture, it's a problem framing As for the rest of this, I'm torn between liking the poetry of it and pointing out that this is kind of that thing where you say something like it's supposed to be a mind-blowing insight when it's well-known and pretty obvious. Most people familiar with learning theory already understand learning algorithms of any kind as a subset of probabilistic search algorithms with properties that make them responsive to data. The idea that the structure of the information processing system doesn't matter and there's just this general factor of learning capacity a thing has is... not well supported by the way in which research has progressed in the entire period of time when this has been relevant to most people? Sure, in theory any neural network is a general function approximator and could in theory learn any function it's complex enough to represent. Also, we can arrive at the solution to any computable problem by representing it as a number and guessing random numbers until we can verify a solution. Learning algorithms can almost be defined as attempts to do better search via structured empiricism than can be done with the assumption that structure doesn't matter. Like, sometimes multiple things work, sure. That doesn't mean it's arbitrary TL;DR: Of course learning is a kind of search, but discovering structures that are good at learning is the whole game reply Xcelerate 7 hours agorootparentYeah, I really don’t understand this recently popular viewpoint that the algorithm doesn’t matter, just how much data you throw at it. It doesn’t seem to be based on anything more than wishful thinking. One can apply Hutter search to solve just about any problem conceivable given the data and guess what—you’ll approach the optimal solution! The only downside is that this process will take more time than available in our physical universe. I think people forget the time factor and how the entire field of computational complexity theory arose because the meta problem is not that we can’t solve the problem—it’s that we can’t solve it quickly enough on a timescale that matters to humans. Current NN architectures are missing something very fundamental related to the efficiency of problem solving, and I really don’t see how throwing more data at them is going to magically convert an EXPTIME algorithm into a PTIME one. (I’m not saying NNs are EXPTIME; I’m saying that they are incapable of solving entire classes of problems that have both PTIME and EXPTIME solutions, as the NN architecture is not able to “discover” PTIME solutions, thus rendering them incapable of solving those classes of problems in any practical sense). reply advael 3 hours agorootparentAlso, one of the major classes of problem that gets solved and we view as \"progress\" in machine learning is framing problems. Like we couldn't define \"draw a good picture\" in a way we could actually assess well, GANs and Diffusion turn out to be good ways to phrase problems like that. In the former case, it creates a way to define the problem as \"make something indistinguishable from an example pulled from this dataset\" and in the latter case, \"I've randomized some of these pixels, undo that based on the description\" The idea of \"efficiency\" and \"progress\" is this post-hoc rationalization that people who never understood the problem, pay people to understand the problem, apply to problems once they have a working solution in hand. It's a model that is inherently as dumb as a model can be, and the assumption it makes is that there is some general factor of progress on hard problems that can be dialed up and down. Sure, you can pay more scientists and probabilistically increase the rate at which problems are solved, but you can't predict how long it will take, how much failure it will involve, whether a particular scientist will solve a particular problem at all, whether that problem is even solvable in principle sometimes. Businesspeople and investors like models where you put in money and you get out growth at a predictable rate with a controllable timescale, and if this doesn't work you just kick it harder, and this ill fits most frontier research. Hell, it ill suits a lot of regular work. reply visarga 2 hours agorootparent> Sure, you can pay more scientists and probabilistically increase the rate at which problems are solved, but you can't predict how long it will take, how much failure it will involve, whether a particular scientist will solve a particular problem at all, whether that problem is even solvable in principle sometimes. Fully agree, search is hard, unpredictable and expensive. Also a matter of luck, being at the right place and time, and observing something novel. That is why I put the emphasis of AI doing search, not just imitating humans. reply visarga 2 hours agorootparentprevNot \"throwing more data at them\" but having the AI discover things by searching. AI needs to contribute to the search process to graduate the parrot label. reply visarga 2 hours agorootparentprev> Of course learning is a kind of search, but discovering structures that are good at learning is the whole game No, you missed the essential. I mentioned search in the context of discovery, or in other words expanding knowledge. Training neural nets is also a search for the best parameters that fit the data, but it's secondary. Many architectures work, there have been a thousand variations for the transformer architectures and plenty of RNN-like approaches since 2017 when transformer was invented, and none of them is better than the current one or significantly worse. Also, considering human population, the number of neurons in the brain, synapses and wiring are very different at micro level from person to person, yet we all learn. The difference between the top 5% and bottom 5% humans is small compared with other species, for example. What makes a big difference between people is education, in other words experiences, or training data. To return to the original idea - AI that simply learns to imitate human text is capable only of remixing ideas. But an AI that actively explores can discover novel ideas, like AlphaZero and AlphaTensor. In both these cases search played a major role. So I was generalizing the concept of \"search\" across many levels of optimization, from protein folding to DNA and human intelligence. Search is essential for progress across the stack. Even network architecture evolves by search - with human researchers. reply jekude 16 hours agoprevI’ve been noodling on how to combine neural networks with evolution for a while. I’ve always thought that to do this, you need some sort of evolvable genetic/functional units, and have had trouble fitting traditional artificial neurons w backprop into that picture. My current rabbit hole is using Combinatory Logic as the genetic material, and have been trying to evolve combinators, etc (there is some active research in this area). Only slightly related to the author’s idea, its cool that others are interested in this space as well. reply peheje 0 minutes agoparentMaybe a key innovation would be to apply backpropagation to optimize the crossover process itself. Instead of random crossover, compute the gradient of the crossover operation. For each potential combination, \"learn\" (via normal backprop) how different ways of crossover impacts on overall network performance. Then use this to guide the selection of optimal crossover points and methods. This \"gradient-optimized crossover\" would be a search process in itself, aiming to find the best way to combine specific parts of networks to maximize improvement of the whole. It could make \"leaps\", instead of small incremental steps, due to the exploratory genetic algorithm. Has anything like this been tried? reply Matumio 10 hours agoparentprevThen probably you know about NEAT (the genetic algorithm) by now. I'm not sure what has been tried in directly using combinatorical logic instead of NNs (do Hopfield networks count?), any references? I've tried to learn simple look-up tables (like, 9 bits of input) using the Cross-Entropy method (CEM), this worked well. But it was a very small search space (way too large to just try all solutions, but still, a tiny model). I haven't seen the CEM used on larger problems. Though there is a cool paper about learning tetris using the cross-entropy method, using a bit of feature engineering. reply daveguy 2 hours agorootparentI am familiar with NEAT, it was very exciting when it came out. But, NEAT does not use back propagation or single network training at all. The genetic algorithm combines static neural networks in an ingenious way. Several years prior, in undergrad, I talked to a professor about evolving network architectures with GA. He scoffed that squishing two \"mediocre\" techniques together wouldn't make a better algorithm. I still think he was wrong. Should have sent him that paper. IIRC NEAT wasn't SOTA when it came out, but it is still a fascinating and effective way to evolve NN architecture using genetic algorithms. If OP (or anyone in ML) hasn't studied it, they should. https://en.m.wikipedia.org/wiki/Neuroevolution_of_augmenting... (and check the bibliography for the papers) Edit: looking at the continuation of NEAT it looks like they focused on control systems, which makes sense. The evolved network structures are relatively simple. reply pyinstallwoes 15 hours agoparentprevThermodynamic annealing over a density parameter space reply osmarks 1 hour agoprevI don't think this is true as stated. Evolutionary algorithms are not the most efficient way to do most things because they, handwavily, search randomly in all directions. Gradient descent and other gradient-based optimizers are way way faster where we can apply them: the brain probably can't do proper backprop for architectural reasons but I am confident it uses something much smarter than blind evolutionary search. reply cs702 1 hour agoparentThe OP is not about evolutionary algorithms. It's about mechanisms in the brain that plausibly evolved over time. reply osmarks 24 minutes agorootparent> A Darwin Machine uses evolution to produce intelligence. It relies on the same insight that produced biology: That evolution is the best algorithm for predicting valid \"solutions\" within a near infinite problem space. It seems to be suggesting that neuron firing patterns (or something like that?) are selected by internal evolutionary processes. reply sdwr 18 hours agoprevFantastic speculation here, explains a lot, and has testable hypotheses. For example, there should be a relationship between rate of learning and the physical subcolumns - we should be able to identify when a single column starts up / is fully trained / is overused Or use AI to try to mirror the learning process, creating an external replica that makes the same decisions as the person Marvin Minsky was spot on about the general idea 50 years ago, seeing the brain as a collection of 1000s of atomic operators (society of mind?) reply calepayson 17 hours agoparent> Fantastic speculation here, explains a lot, and has testable hypotheses. Calvin is the man. > For example, there should be a relationship between rate of learning and the physical subcolumns - we should be able to identify when a single column starts up / is fully trained / is overused This sounds super interesting. Could you break down what you're thinking here? > Marvin Minsky was spot on about the general idea 50 years ago, seeing the brain as a collection of 1000s of atomic operators (society of mind?) I'm very much an amateur in this field and was under the impression that Minsky was trying to break it up, but was trying to specify each of those operations. What I find so enticing about Neural Darwinism is the lack of specification needed. Ideally, once you get the underlying process right, there's a cascade of emergent properties. Using the example of a murmuration of starlings I picture Minsky trying to describe phase transitions between every possible murmuration state. On the other hand I see Neural Darwinism as an attempt to describe the behavior of a single starling which can then be scaled to thousands. Let me know if that's super wrong. I've only read second hand descriptions of Minsky's ideas, so feel free to send some homework my way. reply breck 16 hours agorootparent> I've only read second hand descriptions of Minsky's ideas, so feel free to send some homework my way. Here you go: https://breckyunits.com/marvin-minsky.html I think you are right in that Minsky was missing some important details in the branches of the tree, particularly around cortical columns, but he was old when Hawkins and Numenta released their stuff. In terms of the root idea of the mind being a huge number of concurrent agents, I think he was close to the bullseye and it very much aligns with what you wrote. reply calepayson 16 hours agorootparentAwesome post, thanks. I ordered society of mind. Reminds me of when I took \"The Philosophy of Cognitive Science\" in college. The entire class was on AI. When I asked the professor why, she explained: \"You don't understand something unless you can build it\". It's cool to learn that quote might have been because she's a fan of Minsky. > In terms of the root idea of the mind being a huge number of concurrent agents, I think he was close to the bullseye and it very much aligns with what you wrote. I think you're right here and I'd like to add a bit. One common mistake people make when thinking of evolution, is where in the hierarchy it takes place. In other words, they misidentify the agents by an order of magnitude. For example, in biology I commonly see it taught that the individual is the subject of natural selection (or worse, the population). Really, it's the gene. The beauty of evolution is that it can take an agent as simple as the gene and shape it into the litany of complex forms and functions we see all around us. If evolution is at play in the brain, I suspect that Minsky's agents are the individual firing patterns. Like genes, the base of the hierarchy, the fundamental unit. Also like genes, they slowly build increasingly complex behaviors from the ground up. Starting before birth and continuing for most of our lives. reply breck 15 hours agorootparentRight, the Selfish Gene is one of the best books I ever read. There's also a paper I recently came across (https://warpcast.com/breck/0xea2e1a35) which talks about how causation is a two way street: low level nodes cause things in higher level nodes, but higher level nodes in turn cause things in lower level nodes. In other words, just because genes have really been the drivers and our bodies just the vehicles, doesn't mean that's not cyclical (sometimes it could cycle to be the higher level ideas driving the evolution in lower level agents). > I suspect that Minsky's agents are the individual firing patterns. I like this idea. The biggest open question in my mind in regards to Minsky still is exactly on this: what physically is an agent? How many are there? My margin of error here is wild -- like 10 orders of magnitude. reply jcynix 16 hours agoparentprevRegarding Minsky: the most interesting thoughts I read about theories of a mind, are his books, namely: The Society of Mind and The Emotion Machine which should be more widely known. More of Minsky's ideas on “Matter, Mind, and Models” are mentioned here: https://www.newyorker.com/magazine/1981/12/14/a-i And let's not forget Daniel Dennett: In “Consciousness Explained,” a 1991 best-seller, he described consciousness as something like the product of multiple, layered computer programs running on the hardware of the brain. [...] Quoted from https://www.newyorker.com/magazine/2017/03/27/daniel-dennett... reply pshc 13 hours agoprev> These connections result in a triangular array of connected minicolumns with large gaps of unconnected minicolumns in between. Well, not really unconnected, each of these are connected to their own triangular array. > Looking down on the brain again, we can imagine projecting a pattern of equilateral triangles - like a fishing net - over the surface. Each vertex in the net will land on a minicolumn within the same network, leaving holes over minicolumns that don't belong to that network. If we were to project nets over the network until every minicolumn was covered by a vertex we would project 50-100 nets. Around this part I had a difficult time visualizing the intent here. Are there any accompanying diagrams or texts? Thanks for the interesting read! reply gushogg-blake 9 hours agoprevThe image of the flattened out brain could use some illustrations, or more specific instructions on what we should be visualising. > First, if you look at a cross-section of the brain (eye-level with the table) I thought it was flat on the table? Surely if we look at it side-on we just see the edge? Without a clear idea of how to picture this, the other aspect (columns) doesn't make sense either. reply superqd 2 hours agoprevNitpick: lots of text descriptions of visual patterns - this article could use at least 5 visual aid images. reply aldousd666 18 hours agoprevThis reminds me a little of Jeff Hawkins book, 1000 brain theory. His company numenta has done this kind of research and they have a mailing list. I'm not an expert but I've read Jeff's book and noodled at the mailing list reply calepayson 18 hours agoparentI ordered the book and I'm checking out the website rn. Looks awesome. Thanks a ton for sharing! reply dstrbtd_evolute 15 hours agoparentprevHawkins' proposal is missing the key innovation that Calvin proposes, which is that learning take place by evolutionary means. But Hawkins' proposal does fit squarely within current popular ideas around predictive coding. The key structures in Hawkins' architecture are cortical columns (CC). What his VP of Eng (Dileep George) did is to analyze Hawkins' account of the functionality of a CC, and then say that a CC is a module which must conform to a certain API, and meet a certain contract. As long as a module obeys the API and contract, we don't actually care how the CC module is implemented. In particular, it's actually not important that the module contain neurons. (Though the connections between the CCs may still have to look like axons or whatever, I don't know.) Then Dileep George further figured out that there is an off the shelf algorithm than works perfectly for the CC module. He selected an algorithm which is based on statistical learning theory (STL). STL based algorithms are an excellent choice for the CCs, IMNSHO. They are fast, theoretically sound, etc. They are also understood in great mathematical detail, so we can characterize _exactly_ what they can and can't do. So there is zero mystery about the capabilities of his system at the CC level. Note that in Hawkins' case, the STL based algorithms are used for pattern recognition. Now Hawkin's proposal isn't just a single CC, it's a network of CC's all connected together in a certain way. My memory is a little hazy at this point, but as best I recall, his architecture should have no problem identifying sequences of patterns (as for sound), or spatial patterns across time (as for vision). And I bought his argument that these could be combined hierarchically, and that the same structure could also be used for playing back (outputting) a learned pattern, and for recognizing cross modal patterns (that is, across sensory modalities). But is all this enough? I say no. My reading of evolutionary epistemology suggests to me that pattern identification is insufficient for making and refuting conjectures in the most general sense. And ultimately, a system must be able to create and refute conjectures to create knowledge. Hawkins has a very weak story about creativity and claims that it can all be done with pattern recognition and analogy, but I am not convinced. It was the weakest part of the book. (pp 183-193) I don't know if it's clear to you or not why pattern recognition is insufficient for doing general conjectures and refutations. If it's not clear, I should attempt to expand on that ... The idea is, that it is not always possible to arrive at a theory by just abstracting a pattern from a data set. For example: What set of data could Newton have looked at to conclude that an object in motion stays in motion? I suppose he knew of 7 planets that stayed in motion, but then he had millions of counter examples all around him. For a pattern recognition algorithm, if you feed it a million + 7 data points, it will conclude that objects in motion always come to a stop except for a few weird exceptions which are probably noise. reply exe34 8 hours agoparentprevmy impression of hawkins from a distance is that he can reproduce the success of the current orthodoxy, but is always a few years behind sota. reply auraai 11 hours agoprevThere's lots of room for cross-pollination between bio/life sciences and ML/AI. One key insight is the importance of what you pick as your primary representation of data (is everything a number, a symbolic structure, a probability distribution, etc). I believe a lot of these bio-inspired approaches over-emphasize the embodied nature of intelligence and how much it needs to be situated in space and time, which downplays all the sub-problems that need to be solved in other \"spaces\" with less obvious \"spatiotemporal\" structure. I believe space and time are emergent, at least for the purposes of defining intelligence, and there are representations where both space and time arise as dimensions of their structure and evolution. reply mandibeet 7 hours agoprevI think in some ways by considering the brain as a Darwin Machine, we can explore new dimensions of how our minds work reply paraschopra 15 hours agoprevThe book \"Cerebral Code\" is made available for free by the author on his website: http://williamcalvin.com/bk9/ For a more modern treatment on the subject, read this paper: An Attempt at a Unified Theory of the Neocortical Microcircuit in Sensory Cortex https://www.researchgate.net/publication/343269087_An_Attemp... reply DrMiaow 14 hours agoprevThis project employs a Darwinian approach. Initially, it was an experiment in traditional program and user interface generation that incorporated evolutionary feedback into the mutation process. A combination of PG and AL. It has achieved some success with small programs and is now exploring the potential combination of LLMs https://youtu.be/sqvHjXfbI8o?si=7qwpc15Gn42mUnKQ&t=513 reply wdwvt1 11 hours agoprevThis post analogizes between a specific theory of human intelligence and a badly caricatured theory of evolution. It feels like better versions of the arguments for Darwin Machines exist that would not: a) require an unsupportable neuron-centric view of evolution, and b) don't view evolution through the programmers lens. > Essentially, biology uses evolution because it is the best way to solve the problem of prediction (survival/reproduction) in a complex world. 1. This is anthropocentric in a way that meaningfully distorts the conclusion. The vast majority of life on earth, whether you count by raw number, number of species, weight, etc. do not have neurons. These organisms are of course, microbes (viruses and prokaryotes) and plants. Bacteria and viruses do not 'predict' in the way this post speaks of. Survival strategies that bacteria use (that we know about and understand) are hedging-based. For example, some portion of a population will stochastically switch certain survival genes on (e.g. sporulation, certain efflux pumps = antibiotic resistance genes) that have a cost benefit ratio that changes depending on the condition. This could be construed as a prediction in some sense: the genome that has enough plasticity to allow certain changes like this will, on average, produce copies in a large enough population that enable survival through a tremendous range of conditions. But that's a very different type of prediction than what the rest of the post talks about. In short, prediction is something neurons are good at, but it's not clear it's a 'favored' outcome in our biosphere. > It relies on the same insight that produced biology: That evolution is the best algorithm for predicting valid \"solutions\" within a near infinite problem space. 2. This gets the teleology reversed. Biology doesn't use anything, it's not trying to solve anything, and evolution isn't an algorithm because it doesn't have an end goal or a teleology (and it's not predicting anything). Evolution is what you observe over time in a population of organisms that reproduce without perfect fidelity copy mechanisms. All we need say is that things that reproduce are more likely to be observed. We don't have to anthropomorphize the evolutionary process to get an explanation of the distribution of reproducing entities that we observe or the fact that they solve challenges to reproduction. > Many people believe that, in biology, point mutations lead to the change necessary to drive novelty in evolution. This is rarely the case. Point mutations are usually disastrous and every organism I know of does everything in its power to minimize them. Think, for every one beneficial point mutation, there are thousands that don't have any effect, and hundreds that cause something awful like cancer. If you're building a skyscraper, having one in a hundred bricks be laid with some variation is not a good thing. Instead Biology relies on recombination. Swap one beneficial trait for another and there's a much smaller chance you'll end up with something harmful and a much higher chance you'll end up with something useful. Recombination is the key to the creativity of evolution, and Darwin Machines harness it. 3. An anthropocentric reading of evidence that distorts the conclusion. The fidelity (number of errors per cycle per base pair) of the polymerases varies by maybe 8 orders of magnitude across the tree of life. For a review, see figure 3 in ref [1]. I don't know about Darwin Machines, but the view that 'recombination' is the key to evolution is a conclusion you would draw if you examined only a part of the tree of life. We can quibble about viruses being alive or not, but they are certainly the most abundant reproducing thing on earth by orders of magnitude. Recombination doesn't seem as important for adaptation in them as it does in organisms with chromosomes. 4. There are arguments that seem interesting (and maybe not incompatible with some version of the post) that life should be abundant because it actually helps dissipate energy gradients. See the Quanta article on this [0]. [0] https://www.quantamagazine.org/a-new-thermodynamics-theory-o... [1] Sniegowski, P. D., Gerrish, P. J., Johnson, T., & Shaver, A. (2000). The evolution of mutation rates: separating causes from consequences. BioEssays, 22(12), 1057–1066. doi:10.1002/1521-1878(200012)22:123.0.co;2-w reply slow_typist 12 hours agoprevThe title of the referenced book by Erwin Schrödinger is “what is life”, I believe. https://archive.org/details/whatislife0000erwi reply calepayson 5 hours agoparentThanks for pointing this out. I’ll change it when I’m at my computer. reply ViscountPenguin 15 hours agoprevThis strongly reminds me of the algorithm used by swarming honeybees (if anyone's interested I'd highly recommend reading honeybee democracy). I reckon there's something to this. I might have a go implementing something along these lines. reply calepayson 20 hours agoprevI'm obsessed with the idea of Darwin Machines (and I think you should be too). I've been tinkering with the idea in python but I just don't have enough ML experience. If you, or anyone you know, is interested in Darwin Machines please reach out! reply DrMiaow 14 hours agoparentIt is the focus of my long-term crazy side project. https://youtu.be/sqvHjXfbI8o?si=7qwpc15Gn42mUnKQ&t=513 reply turtleyacht 19 hours agoparentprevThank-you. Was wondering about your thoughts on emotions. Are they merely byproducts of the chemical evolution of the brain, or are they emergent artifacts of intelligence? A system cannot feel, but we can map neurochemistry as mechanistically as any other process. It would be interesting to discover whether a \"pure brain\" exists, or whether even its inputs, when considered in whole, colored its nature. reply IAmGraydon 16 hours agorootparentAren't emotions just the brain's way of experiencing the pain/pleasure feedback system for non-physical stimuli? reply calepayson 19 hours agorootparentprevHonestly, no idea. I could imagine a Darwin Machine being a \"pure brain\", as you put it. While we have emotions because our brains built a pure brain atop an existing and messy infrastructure. Or, emotions could just be the subjective experience of thoughts competing. Calvin goes deeper into things like this in the book, but I suspect emotions help intelligence to some extent insofar as they provide environmental change. It's good for the long term health of an ecosystem to shake things up so that nothing gets too stagnant. reply lachlan_gray 13 hours agoprevOh dude this is so cool. I think you’re dead right. If you’ll pardon some woo, another argument I see in favour of message passing/consensus, is that it “fits” the self similar nature of life patterns. Valid behaviours that replicate and persist, for only the reason that they do. Culture, religion, politics, pop songs, memes… “Egregore” comes to mind. In some ways “recombination” could be seen as “cooperation”, even at the level of minicolumns. (Edit: what I mean to say is that it kinda makes sense that the group dynamics between constituent units of one brain would be similar in some way to the group dynamics you get from a bunch of brains) reply FrustratedMonky 5 hours agoprevThere is a lot of quibbling over details, but this is a 1-2 page high level elevator pitch, so will have some things glossed over. To that end, it seems like some interesting concepts for further exploration. reply fedeb95 9 hours agoprevisn't this the same as genetic algorithms ? reply breck 16 hours agoprevI took more notes on this blog post than anything else I've read this month. reply calepayson 16 hours agoparentMan, this has me grinning like an idiot. Thanks. reply specialist 4 hours agoprev [–] I read the followup: Lingua ex Machina: Reconciling Darwin and Chomsky with the Human [2000] https://www.amazon.com/Lingua-Machina-Reconciling-Darwin-Cho... Completely changed my worldview. Evolutionary processes every where. My (turrible) recollection: Darwinian processes for comprehending speech, the process of translating sounds into phenomes (?). There's something like a brain song, where a harmony signal echoes back and forth. Competition between and among hexagonal processing units (what Jeff Hawkins & Numenta are studying). My paraphrasing: meme PvP F4A battlefield where \"winning\" means converting your neighbor to your faction. Speculation about the human brain leaped from proto-language (noun-verb) to Chomsky language (recursively composable noun-verb-object predicates). Further speculation how that might be encoding in our brains. Etc. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post discusses William Calvin's theory from \"The Cerebral Code,\" which suggests the brain uses evolutionary processes within minicolumns to process sensory inputs and find the most \"fit\" patterns.",
      "The theory posits that the brain's structure, particularly the neocortex's columns and minicolumns, allows for efficient problem-solving and parallel processing, which could be applied to AI and machine learning (ML).",
      "The author is experimenting with neural networks to mimic this evolutionary process and seeks advice on research and academic insights in this field, highlighting potential advancements in AI's deep thinking capabilities."
    ],
    "commentSummary": [
      "The post discusses the concept of Darwin Machines, where different sensory data modalities are processed by brain minicolumns, each outputting unique firing patterns that compete and reinforce the dominant pattern, aiding learning.",
      "Capsule-routing algorithms, proposed by Geoffrey Hinton, aim to implement this idea using expectation-maximization (EM) processes, but have been overshadowed by the success of transformers in AI research.",
      "The discussion highlights the importance of understanding brain function and neural networks, referencing Hebbian learning and the need for deeper exploration of temporal dynamics in neural activity."
    ],
    "points": 145,
    "commentCount": 71,
    "retryCount": 0,
    "time": 1721170466
  },
  {
    "id": 40980715,
    "title": "Magic-cli – A copilot for your command line",
    "originLink": "https://github.com/guywaldman/magic-cli",
    "originBody": "Blog post: https:&#x2F;&#x2F;guywaldman.com&#x2F;posts&#x2F;introducing-magic-cli",
    "commentLink": "https://news.ycombinator.com/item?id=40980715",
    "commentBody": "Magic-cli – A copilot for your command line (github.com/guywaldman)139 points by guywald 21 hours agohidepastfavorite89 comments Blog post: https://guywaldman.com/posts/introducing-magic-cli Carrok 19 hours agoDefault mode should probably not be “unsafe-execution” but instead should be “clipboard”. Make people turn on the unsafe mode. reply thelastparadise 18 hours agoparentI disagree. It should be unsage execution but with an easy undo like git or zfs. reply Carrok 18 hours agorootparentI eagerly await your proposal on how to undo arbitrary cli commands. reply dredmorbius 1 hour agorootparentCoW filesystems with frequent snapshotting, which suffices save for CoWFS-specific commands. Spinning up a VM for testing is another Very Good Practice. reply IgorPartola 18 hours agorootparentprevRun the code backwards! reply verandaguy 17 hours agorootparent$ man mr MR(1) NAME mr, relink - restore directory entries $ mr -fr / # restore a filesystem root after deleting it (recursively, forced restore) reply acheong08 5 hours agorootparentI can’t believe I just learned about this. So many lost files Edit: lies! reply xnzakg 3 hours agorootparentprevI wonder how long untilpicks this up and thinks it's a real command reply karolist 11 hours agorootparentprevWhat he's saying is that everything should be idempotent, which may be possible for local only calls and filesystem snapshots, but anything doing a network call is outside the realm of this possibility. Such a system would need to spin up a local, accurate backend for any network call, execute the call, verify the results are not catastrophic and retry with a real call, but then we also introduce time caused uncertainty as the real system may drift enough from the expected state during the local validation. A fun thought experiment but science fiction IMHO. reply mindslight 5 hours agorootparentnit: that's not what idempotent means reply karolist 5 hours agorootparentdang, I think you're right, my mind branched off somewhere it seems. I was thinking of how operations can be executed multiple times (verification + actual result run) with effect being applied only once. reply lvncelot 14 hours agorootparentprevimport timetravel reply usrbinbash 2 hours agorootparentfrom timetravel import Delorean d = Delorean(color=\"SILVER\") if d.power_gw >= 1.21: d.flux_compensator.charge() print(\"Great Scott!\") reply j16sdiz 17 hours agorootparentprevI disagree It should be non recoverable. Everybody need to learn their lesson right. reply rjzzleep 4 hours agorootparentSome ~20 years someone gave me access to their server and I typed `rm -rf something ` instead of `rm -rf something`. I have been hyper paranoid about destructive commands ever since. Yesterday I wanted to setup a boot usb for bazzite on a machine with two nvme drives, but I kept checking multiple times that the usb drive is indeed at /dev/sda and nothing else could possible be that drive even though the SSD's were all on /dev/nvme0. Some hard lessons you never forget. ps. they had backups reply xnzakg 3 hours agorootparentRegarding the `rm` problem, `alias rm=\"rm -I\"` makes things a little safer, although no idea if this flag was already a thing 20 years ago. reply dredmorbius 59 minutes agorootparentIn my experience, that tends to just make the approval of specific file deletions reflexive. The worst situation I've been in was running the classic 'rm -rf' from the root filesystem, several decades ago. I was running a bootable distro, had mounted all filesystems but the one I was actually attempting to reformat and repurpose read-only, and the upshot was that I enjoyed the experience of seeing just what a system which has shell internals (not sure it was even full bash) and little else functions like. (I found that \"echo *\" is a good poor-man's 'ls'.) Then, having removed the filesystem I'd intended to remove in the first place (and a few more ... memory-only ... filesystems), I rebooted and continued. What saved me was safeing all parts of the system save that which I was specifically acting on. Where I've had to perform similarly destructive commands elsewhere and since, I've made a habit of doing similarly, ensuring I'd had backups where necessary, triple-checking that what I wanted to annihilate was in fact what I was going to annihilate. Among those practices: I'll often move files or directories to a specific \"DELETE_ME\" directory, which 1) gives a few non-destructive checkpoints to destructive actions, 2) takes no system time or space (file / directory moves on the same filesystem don't involve copying or writing data other than the filesystem metadata), then review and finally delete those files. I'll set all filesystems other than those I'm specifically performing surgery on to \"read-only\". This suffices for almost any file-oriented actions, though of course not filesystem or partition operations. ('dd' is the exception to file-oriented commands, though you'd have to be writing to a partition to cause problems.) Rather than using dynamically-generated file lists (e.g., using shell globs, 'findxargs', $(shell expansions), or similar techniques, I'll generate a one-off shell script to perform complex operations. This makes explicit all expansions and permits reviewing of operations before committing them. I'll often log complex output so that I can review the operation and see if it ran as intended. These have avoided numerous unpleasant surprises. reply usrbinbash 2 hours agorootparentprevAlright, now I'm curious. How do I \"undo\", say, `rm ./temp/*.txt` reply callalex 17 hours agorootparentprevHow do you undo, for example, an HTTP request? reply neodymiumphish 16 hours agorootparentJust rerun the command, but use UNPOST instead of POST or GIVE instead of GET. Easy peasy reply ku1ik 11 hours agorootparentI like the vision where next wave of LLMs will include this advice in its training set. reply callalex 15 hours agorootparentprevAh, teacher always told me that HTTP is idempostent after all. reply sroussey 14 hours agorootparentIt’s comments like this that makes me wish hn supported emojis. reply vinibrito 15 hours agorootparentprevAhahah oh my I never laughed so much when visiting hn. Yours and the other similar comments are great. Thanks! reply teaearlgraycold 16 hours agorootparentprevFirst you need to get your modified DeLorean up to 88 miles per hour. reply hda111 13 hours agorootparentprevHow to undo a zfs destroy? reply sgarland 5 hours agorootparentReturn 0, but don’t do anything yet. Fire a cron with an N-minute sleep that destroys the FS on expiry. Also, rewrite various ZFS tooling to lie about the consumed space, and confound the user with random errors if they try to use the still-allocated space. /s but I sincerely hope it isn’t necessary reply aranchelk 12 hours agorootparentprevzfs create. All better. reply pcwelder 3 hours agoprevI've been using https://github.com/tom-doerr/zsh_codex with gpt4-o and it saves a lot of strokes as compared to github copilot cli to query, since I just have to press ctrl-x in addition to the prompt. Magic-cli also seems to be using same workflow as github copilot, so I'm not rushing to use it. reply kordlessagain 1 hour agoprevI got stuck on setting the ollama.embedding_model. No clue what to do. reply ano-ther 2 hours agoprevNeat. How does it compare to https://llm.datasette.io/en/stable/ ? reply swyx 2 hours agoparentit's built in RUST! reply notarealllama 17 hours agoprevHuh, and I'm here running llama 3 locally (and claude.ai for less complex stuff), asking well formatted and specific questions and still adjusting the output before implementing it. Besides I need .sh scripts not just cli completion. But this reminds me of warp. Gonna have to give it a spin in the morning. reply computatrum 13 hours agoprevThere is also https://github.com/TNG/please-cli reply teddyh 9 hours agoprevBeware the pitfalls of yesteryear:reply _def 8 hours agoparentFunny to see this, I first came across it with https://github.com/nvbn/thefuck reply compressedgas 9 hours agoparentprevhttps://en.wikipedia.org/wiki/Warren_Teitelman reply boomskats 8 hours agoprevThis is nice. I've been taking Termium[0] for a spin and it's been pretty great for the most part, but the Rumsfeld-complete always-on autosuggest/copilot UX they're aiming for does feel like a bit of a compromise. On occasions when I do know what I don't know, and want to specifically opt in, this looks perfect. [0]: https://codeium.com/blog/termium-codeium-in-terminal-launch reply h43z 19 hours agoprevI've never seen this extra measure \"curl --proto '=https' ...\" reply guywald 18 hours agoparentYep, this is auto-generated by cargo-dist (https://opensource.axo.dev/cargo-dist/book/) reply ape4 19 hours agoparentprevMe neither - so I looked it up at https://curl.se/docs/manpage.html With the equals it means only allow the named protocols. reply metadat 18 hours agorootparentWhat would be allowed after SSL? By default, does curl allow redirects to http:// via -L? If so.. that's kinda sketchy from a security perspective. Especially because the flag you've shown is very unwieldy. reply dijit 18 hours agorootparentcurl will not follow any redirects without -L, including from http to https. But -L is very useful, so being able to prevent downgrades has useful functionality to help restrict it. reply metadat 13 hours agorootparentThis has nothing to do with what I'm attempting to discuss. reply darby_nine 19 hours agoprevHow's the latency? reply deckar01 16 hours agoparentIt isn’t streaming the ollama output so it feels slow (~3 words/second on a 3090 with the defaults). Using ollama directly streams within a second and you can kill it early. I don’t understand the UX of looping responses to the same question either. This does not feel like magic. reply guywald 16 hours agorootparentIt's currently set not to stream (https://github.com/guywaldman/magic-cli/blob/4d4dca034063aa6...). The performance is something I plan to improve. reply Carrok 19 hours agoparentprevThat would depend on the LLM provider you select. reply pmarreck 14 hours agoprevI have a single Bash function called \"please\" that basically does the same thing https://github.com/pmarreck/dotfiles/blob/master/bin/functio... reply gkfasdfasdf 6 hours agoparentWhat does this line do? [ -v EDIT ] && unset EDIT && edit_function \"${FUNCNAME[0]}\" \"$BASH_SOURCE\" && return Very cool script overall, thanks for sharing reply pmarreck 5 hours agorootparentAh, forgot to include that! That's a way to edit any of my functions via \"edit \" and it drops you right on the correct line in your $EDITOR of choice. Otherwise it defaults to passing it into your editor (ostensibly a path). needs() { [ -v EDIT ] && unset EDIT && edit_function \"${FUNCNAME[0]}\" \"$BASH_SOURCE\" && return; local bin=\"$1\"; shift; command -v \"$bin\" > /dev/null 2>&1 || { printf \"%s is required but it's not installed or in PATH; %s\" \"$bin\" \"$*\" 1>&2; return 1 } } contains() { [ -v EDIT ] && unset EDIT && edit_function \"${FUNCNAME[0]}\" \"$BASH_SOURCE\" && return; local word; for word in $1; do if [[ \"$word\" == \"$2\" ]]; then return 0; fi; done; return 1 } edit_function() { [ -v EDIT ] && unset EDIT && edit_function \"${FUNCNAME[0]}\" \"$BASH_SOURCE\" && return; needs rg \"please install ripgrep!\"; local function_name=\"$1\"; local function_name=\"${function_name//\\?/\\\\?}\"; local file=\"$2\"; local fl=$(rg -n -e \"${function_name} *\\(\\) *\\{\" -e \"function +${function_name}(?: *\\(\\))? *\\{\" \"$file\"tail -n1cut -d: -f1); $EDITOR \"$file\":$fl } edit() { [ -v EDIT ] && unset EDIT && edit_function \"${FUNCNAME[0]}\" \"$BASH_SOURCE\" && return; if contains \"$(functions)\" $1; then EDIT=1 $1; else $EDITOR \"$@\"; fi } Once you have those set in your environment, and EDITOR points to whatever editor you prefer, you can simply add the following line to the top of any bash function you define and make it editable-in-place basically: [ -v EDIT ] && unset EDIT && edit_function \"${FUNCNAME[0]}\" \"$BASH_SOURCE\" && return; I use the [ -v variablename ] pattern to detect whether it's set or not so that things like EDIT=1 and EDIT=true will work the same way, but I've also seen ((EDIT)) used, which for values of 1 gives a return code of 0 (making that expression true) otherwise returns a fail, but that only works if you use 1 or 0 to designate \"true\" and \"false\" for switches... and it's of course confusing that you need to reverse those in Bash logic which works off return codes and not actual values reply guywald 13 hours agoparentprevNice! I like the `needs` utility :) reply prmoustache 9 hours agoparentprevBut then you need to find another alias for sudo! reply bongodongobob 19 hours agoprevCan I ask why it's so complicated? I made something similar about a year ago and it's less that 150 lines of Python. Gives you an explanation, option to run it with/without sudo, pretty colors, etc. I guess I'm not very familiar with Rust but it just seems like a lot for what it does. reply guywald 18 hours agoparentThis is a great question. I added a \"Why Rust?\" section to the blog post to provide my rationale: https://guywaldman.com/posts/introducing-magic-cli#why-rust reply Lienetic 18 hours agorootparentI assume you didn't mean to share a localhost link :) reply ekidd 17 hours agorootparentHere is a corrected link: https://guywaldman.com/posts/introducing-magic-cli#why-rust reply guywald 17 hours agorootparentprevWoops, fixed the original reply. Thanks. I guess I'm excited that I got all this traction from HN ;) reply thelastparadise 18 hours agorootparentprevWould be a great way to tell someone to \"fuck off\" lol. reply bongodongobob 14 hours agorootparentprevHuh. Weird for such a simple \"program\" if you can even call it that, but I guess I get it. Thanks. reply thelastparadise 18 hours agorootparentprevUh buddy you linked to localhost:3000. reply justusthane 17 hours agorootparentIt’s what the LLM told him to do reply guywald 17 hours agorootparentI am but a mere vessel to my neural network overlords reply freedomben 17 hours agorootparentprevWorking on my machine reply mp05 16 hours agorootparentprevThanks for the heads up, friend. reply tiberriver256 18 hours agoprevI'll bet this was a lot of fun to make. Very cool project. Was there any particular motive for building your own over using something that's been around a bit longer like aichat? https://github.com/sigoden/aichat reply guywald 16 hours agoparentWoah, the shell features are super similar. Honestly was not familiar with this project, looks great (and ambitious). I'll try it out. Thanks for the share. reply jimmySixDOF 15 hours agorootparentAnother approach converts into python: An CLI assistant that responds by generating and auto-executing a Python script. https://github.com/AbanteAI/rawdog reply Lord_Zero 15 hours agoparentprevAichat is super polished and I use it all the time. I don't see why I would use anything else at this time. reply xp84 19 hours agoprevI'm not affiliated with it, but I've been using the Warp terminal program for a few months now and suspect that if you're interested in this kind of thing, you might like that too. In short, besides the obvious AI stuff, which works well: - You can edit the command line as though it's in a GUI program (including with mouse, etc) instead of it being inside the terminal where you need to use different keybindings and no mouse. - When in a shell, instead of your window being one long stream of text, each command and each output is a discrete area, so it's easier to, say, select the whole output of a command. reply dayjah 18 hours agoparentWarp also has a cool looking cataloging feature where commands can be bundled up and shared with your co-workers. Seems a good solution for sharing those dark arts folks tend to build up over time. Edit: link to feature: https://docs.warp.dev/features/blocks reply scubbo 17 hours agorootparent> Seems a good solution for sharing those dark arts folks tend to build up over time This is one of the things I most _dislike_ about it. Don't incentivize hording those useful tools in yet-another-silo, get them out into a shared code package! reply rekttrader 18 hours agoprevWe as a computing populace are getting more and more comfortable with footguns. reply nerdjon 4 hours agoparentI have to agree, this to me seems like a great in theory but questionable in practice. We know how much damage a cli can do, they often don't have the protections in place most other systems. I mean if I copy files with AWS s3 there is zero confirmation that I am not overriding files. Personally I feel like if you really want to use an LLM to generate your commands, the extra step of copying it from a website is probably a good one. At least you will be forced to actually look at it instead of just assume it is right and hit enter. The example given in the document is a simple one, but with more complex CLI calls I would be scared to use this for anything but the simplest of things. That is ignoring the questionable decision to possibly send very sensitive information to ChatGPT to generate these commands. reply Closi 4 hours agoparentprevMost people are pretty comfortable copying and pasting arbitrary commands they find on google and don't understand into the terminal, so I'm not convinced this is any worse. reply Buttons840 18 hours agoparentprevYou imply this is a footgun. How so? How is this different than looking up a random webpage with the same information? reply dijit 18 hours agorootparentI mean... This: curl google.com/?search=remove+directory+linux&feeling_lucky=1html_striphead -n 1bash Is pretty dangerous, all things being equal, much more dangerous than copying and pasting and of course everything is more dangerous if you avoid engaging your brain entirely. reply Buttons840 15 hours agorootparentIt appears from the screenshots that this tool shows you the command it will run, with some explanation of what it does, and the command options used, and then confirms you want to run the command. That is very different than the curl command you suggested is equivalent. reply imp0cat 14 hours agorootparentsuggest.mode: The mode to use for suggesting commands. Supported values: \"clipboard\" (copying command to clipboard), \"unsafe-execution\" (executing in the current shell session) (default: \"unsafe-execution\") So default mode seems to be shoot first, ask questions later. reply icholy 18 hours agoprevI use https://github.com/simonw/llm-cmd reply guywald 17 hours agoparentAwesome share! Thank you. There are definitely similarities, and I love Simon's work. I guess the extra features are some sophisticated UX (requesting the user to fill out \"placeholders\" in the response, ability to revise the prompt), the \"ask\" command and the \"search\" command. Will definitely give this a spin. reply Xen9 5 hours agoprevThe general concept is limited \"command line\" as means of giving a single agent agency without the need to program every integration separatively. The AGI version is \"command line\" also enabling the agents to communicate, modify, make each other. reply voodooEntity 15 hours agoprevFunny, i recently build something really similar ^^ https://github.com/voodooEntity/go-clibuddy reply fragmede 17 hours agoprevhttps://github.com/KillianLucas/open-interpreter/ is my preferred implementation of approximately the same thing reply renewiltord 18 hours agoprevAll of these solutions seemed very heavyweight in my usage. I wanted something that fit within my existing flow and using copilot.vim, EDITOR=nvim, C-x C-e was the solution for me. https://news.ycombinator.com/item?id=40911564 It's very composable and I can do incremental work with it. reply beacon294 18 hours agoparentYou can also use esc-v to get to the editor if you switch your input to vim mode with \"set -o vi\" in your .bashrc file. Or for extra points ^[v which will serve as a handier escape, as well. reply renewiltord 16 hours agorootparentDespite being vimian I've found set -o vi hard to work with. Do you like it? Neovim terminal seems better for me since output is selectable in the buffer. reply beacon294 1 hour agorootparentIt's a muscle you build. If you're using vim then you'll like it better. You have to imagine the ex mode buffer. reply largbae 19 hours agoprev [2 more] [flagged] dang 19 hours agoparent [–] \"Don't be snarky.\" \"Please don't post shallow dismissals, especially of other people's work. A good critical comment teaches us something.\" https://news.ycombinator.com/newsguidelines.html reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Magic-cli, a command line copilot developed by Guy Waldman, has sparked discussions due to its default \"unsafe-execution\" mode, with suggestions for a safer default like \"clipboard\" mode.",
      "Users have shared opinions and experiences, mentioning alternative tools such as zsh_codex, aichat, and Warp terminal.",
      "The project is built in Rust, raising questions about its complexity compared to simpler implementations in other languages."
    ],
    "points": 139,
    "commentCount": 89,
    "retryCount": 0,
    "time": 1721167101
  },
  {
    "id": 40983585,
    "title": "Google presents method to circumvent automatic blocking of tag manager",
    "originLink": "https://developers.google.com/tag-platform/tag-manager/first-party/setup-guide",
    "originBody": "Guides Set up first-party mode Stay organized with collections Save and categorize content based on your preferences. This document is for users who want to deploy the Google tag in first-party mode. We recommend first-party mode for the most durable tag configuration. Overview Note: First-party mode is in beta. Setting up first-party mode may help your tag setup perform better, resulting in recovery of lost measurement signals, in a privacy-safe way. If you have a question or issue with your setup, reach out to us at 1p-mode-beta-feedback@googlegroups.com. First-party mode lets you to deploy your Google tag using your own first-party infrastructure, hosted on your website's domain (e.g., example.com). This infrastructure sits between your website and Google's services, making your first-party infrastructure the only technology to interact directly with your website users. First-party mode adds a layer of data security and enables additional data privacy controls—such as full IP obfuscation—without compromising your measurement. The setup in this documentation will help you recover X% more measurement signals on your website. You can set it up using your existing Content Delivery Network (CDN), load balancer, or web server, to enable first-party mode. In standard Google tag setups, your web page requests a Google tag from a Google domain (e.g., www.googletagmanager.com). When the tag fires, it sends measurement requests directly to the Google product. In first-party mode, your website loads the Google tag from your first-party domain (e.g., example.com). When the tag fires, it sends measurement requests to your first-party domain, where they are forwarded to the relevant Google product. You will experience full measurement continuity when switching from a standard Google tag setup to first-party mode configuration. This diagram represents the information flow in first-party mode: Before you begin This guide assumes that your website is already configured with: A Google tag or Tag Manager container A Content Delivery Network (CDN) or load balancer that can forward requests to external endpoints 1. Choose the tag serving path You must reserve a path on your website domain for serving the tag. Make sure this path is not already in use on your domain. Choose any path you want for setting up first-party mode. Examples of paths you might want to use include: /metrics, /securemetric, /analytics, or any alphanumeric string that you don't use on your website already. Fill in the following to populate the examples throughout this document. Your domain: example.com Google tag ID: GTM-123456 Tag serving path: /metrics Caution: This setup reroutes all traffic with the chosen path. To avoid affecting your website, choose a path that's not already in use. 2. Route traffic This section assumes that your website is already using a CDN or load balancer that supports routing traffic by paths. Google Cloud You need to set up a new backend that looks up the approximate geographic location of the site visitor and create routing rules in your existing External Application Load Balancer. Create the new backend Open GCP load balancer In your load balancer, open the Backend configuration section. Create a new backend service. Configure your new backend service with geolocation information: Specify a name, such as measurement-be-svc. Set Backend type to Internet network endpoint group. Set Protocol to HTTPS and leave Timeout as the prefilled value. Under Backends, click the Internet network endpoint group drop-down and create a new internet network endpoint group: Set Network endpoint group type to Internet NEG (Global, Regional). Set Scope to Global. Set Add through to Fully qualified domain name and port. Set Fully qualified domain name to GTM-123456.fps.goog. Click CREATE to create the endpoint. Close the Network endpoint group tab to return to the New backend service tab. Search the name of the new network endpoint group and select it. Open the Advanced configurations section. Add the following custom request headers. Header name Header Value Host GTM-123456.fps.goog X-Gclb-Country {client_region} X-Gclb-Region {client_region_subdivision} Review the other settings. Neither Cloud CDN nor Cloud Armor are required for this integration, so you may safely disable both. Save the new backend service. Configure routing rules In your load balancer, open the Routing rules section. Add the following host and path rules: Host Path Backend * /metrics/* measurement-be-svc Update the load balancer configuration. In a browser, verify the set up by navigating to: https://example.com/metrics/healthy. The page should have the text ok. Verify that geographical information is being included by navigating to: https://example.com/metrics/?validate_geo=healthy. The page should have the text ok. Cloudflare To serve your tag in first-party mode, you will create a CNAME entry for a new subdomain, create an Origin Rule to forward requests, and create a Transform Rule to include geolocation information. Create CNAME entry Note: Tags won't use this CNAME entry; Cloudflare uses it to route requests internally. Choose a subdomain to reserve for the CNAME entry. Fill in the following to populate the examples throughout this document. This CNAME is never exposed outside your Cloudflare configuration, so the name is arbitrary. CNAME subdomain: fps In the DNS tab, open the Records section. Add a new record with the following configuration: Set Type to CNAME. Set Name to fps. Set Target to GTM-123456.fps.goog. Save the CNAME record. Create the Origin Rule In the Rules tab, open Origin Rules and create rule. Enter a rule name, such as Route measurement. Match incoming requests based on a Custom filter expression and click Edit expression. Paste the following expression in the builder: (http.host eq \"example.com\" and starts_with(http.request.uri.path, \"/metrics\")) Update the Host Header to Rewrite to... GTM-123456.fps.goog. Update the DNS Record to Override to... fps.example.com. Save the Origin Rule. If there are other Origin Rules, increase the newly created Rule's position so that it will run after any other wildcard paths. In a browser, verify the setup by navigating to: https://example.com/metrics/healthy. The page should read ok. Include geolocation information In the Rules tab, open Transform Rules. Create a Modify Request Header rule. Apply the rule to All incoming requests. Modify request header with the following configuration: Set operator to Set dynamic. Set Header name to X-CfIpCountryRegion. Set Value to ip.src.subdivision_1_iso_code. Deploy the Transform Rule. Wait a few minutes for the rule to propagate. In a browser, verify the set up by navigating to: https://example.com/metrics/?validate_geo=healthy. The page should read ok. (Optional) Remove visitor IP headers First-party mode does not require visitor IP to correctly operate. You can remove all visitor IP headers by using the Remove visitor IP headers Managed Transforms. Other To serve your tag in first-party mode, you need to configure your CDN or load balancer to route requests to the first-party mode endpoint. Add an origin or backend that points to GTM-123456.fps.goog. Override the Host header to be equal to GTM-123456.fps.goog. Allow all cookies and query strings to be forwarded. Add a path rule for /metrics/* to route traffic to first-party mode. Configure the reserved path to have higher priority than the default rule. In a browser, verify the set up by navigating to: https://example.com/metrics/healthy. The page should read ok. Step 3: Update the scripts on the website to use the Measurement Path Replace the scripts on each page of the website with one of the following: gtag.js At the top of thesection, find the two lines of script with your Google tag ID: and replace them with the measurement path instead: gtm.js At the top of thesection, replace the Tag Manager snippet with the following:(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start': new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src= '/metrics/?id='+i+dl;f.parentNode.insertBefore(j,f); })(window,document,'script','dataLayer','');Step 4: Test the measurement set up To test the measurement set up, configure your container to have at least one tag that fires. Go to Tag Assistant and preview your container. Navigate through your site to trigger tags. In the Summary > Output > Hits Sent tab, verify that the hits are routed to /metrics. Step 5: Feedback Provide feedback about first-party mode through the feedback form.",
    "commentLink": "https://news.ycombinator.com/item?id=40983585",
    "commentBody": "Google presents method to circumvent automatic blocking of tag manager (developers.google.com)133 points by iamacyborg 10 hours agohidepastfavorite74 comments MzHN 8 hours agoFirst-party tracking has been increasing in the last couple years or so I've been told. When I first heard about it I decided from now on I'll run uBlock Origin in default JavaScript off mode. It's a checkbox in the settings. I only re-enable on a per-site basis if I have no other choice. I prefer this over NoScript, since it's one click and I still get all the uBlock filters even after enabling JS. I've been using web like this for over a year now, and while it's painful, it's also enlightening. reply Jakob 7 hours agoparentI do that, too. cmd-J as shortcut to enable JavaScript without needing to reload. In my experience once I hardcode which websites I need JavaScript on, browsing becomes painless. And much faster obviously. reply tempest_ 6 hours agorootparentAlright but the last time I did this the answer to \"which websites I need JavaScript on\" was \"All of them\". Is that still the case. reply mywittyname 4 hours agorootparentYou don't need all of the javascript for all websites. In my experience, I enable javascript to load from probably 10-20% of domains (using noscript). reply MasterYoda 1 hour agorootparentprevHow do you set the shortcut? When I press cmd-j the Library in Firefox opens. I have checked \"Disbale javascript\" in settings in uBO. I guess that setting will be disable for just the site i visit when i click cmd-j? reply zzo38computer 1 hour agoparentprevSometimes if a web page claims to require JavaScripts, the text can still be viewed if you disable CSS as well as JavaScripts. Another thing you could try is view source; sometimes the text or data will be visible in there, or you can find a link. An idea which might be able to help more, is a script substitution feature, allowing the user to substitute their own scripts for some or all of the existing ones (and enable or disable or limit the rest of the scripts), by the URL or by the hash (if there is a integrity attribute, then it will not be necessary to download the file in order to determine its hash). reply butz 4 hours agoparentprevNot to mention how much faster the web feels with Javascript turned off. reply JTyQZSnP3cQGa8B 7 hours agoparentprevThanks for telling me about this. I was already blocking most web fonts and suspicious third parties, but now I can also selectively unblock the sites I really need. reply gliptic 9 hours agoprev> Choose any path you want for setting up first-party mode. Examples of paths you might want to use include: /metrics, /securemetric, /analytics, or preferably a random alphanumeric string that you don't use on your website already. Ah, yes, _preferably_ some random string that is hard to block rather than the descriptive ones. reply krackers 16 minutes agoparentWow just in time for ManifestV3, which would prevent clever heuristics like looking at the entropy of the path segment. reply satvikpendem 8 hours agoparentprevTo be honest I wasn't sure why sites weren't doing this already, it seemed very obvious to me at the time, when I learned that uBlock Origin has a hardcoded list of paths to block. reply eknkc 8 hours agorootparentIt is becoming common. For example Segment has a documentation for similar setup: https://segment.com/docs/connections/sources/catalog/librari... I've seen this being implemented at least 5 years ago so probably a lot of sites already do it, reply iamacyborg 7 hours agorootparentYeah, it’s just that some trackers are more ubiquitous than others and gtag is one of the most deployed. reply rogual 8 hours agoparentprevYou know, like malware. reply tzs 5 hours agorootparentIt's more like the opposite of what malware does--malware usually names things so they will look like something you want. Like malware would be naming the directory something like /images or /fonts. reply soraminazuki 6 hours agorootparentprev\"Like\" is being too generous when we know what, why, and how they do what they do. reply iamacyborg 9 hours agoparentprevWell yes, how else will you > The setup in this documentation will help you recover X% more measurement signals on your website. reply dotancohen 7 hours agorootparentObviously \"recover\" is not the correct word here. Maybe \"swindle\" is a better word, considering they are actively circumventing the users' wishes to block tracking. reply bilekas 8 hours agoparentprevObfuscation is the 'Google' way /s \"Privacy centric users hate this 1 trick\" reply jwr 6 hours agoprevAs I read these comments, there is plenty of outrage at how Google keeps invasively tracking us. And rightly so. But I wonder about the other side of it: in my SaaS business I made a point of not using any tracking whatsoever and not letting Google peek into my users' behaviors. So, no analytics, no Google Fonts, no tag manager (obviously). But I don't think any of my users noticed, and I don't think any of them care. reply _the_inflator 6 hours agoparentI think that we wear different hats during the day. As a product manager of a SaaS Enterprise application, I value data to improve the product; as a person outside the work environment, I value privacy. Tough call. On the other hand, I believe that browser tracking is only a small percentage of data being gathered about us, aggregated, and processed. There are so many ways to track us, and being clever ain't really a way to get out of this system. Too late, too sophisticated. reply tpxl 6 hours agorootparent> As a product manager of a SaaS Enterprise application, I value data to improve the product. You can gather about 100% of useful data for improving SaaS Enterprise applications without selling out every single one of your users to Google, and it's not even hard. reply otterley 5 hours agorootparentSince you have clearly solved this problem, please tell the rest of the class how to accomplish this. reply nemomarx 6 hours agoparentprevIf they installed stuff to block it, that would be a sign they care about it at least in part? It's hard for me to tell the difference between a site with no ads and a site with some ads if I'm always using unlock and all. I just care that it ends up not showing me ads. reply iamacyborg 6 hours agorootparentIt’s less about the ads for me so much as having some mechanism in place to prevent unauthorised data slurping. Enough orgs have misconfigured cookie consent that this is fairly critical to me. reply JumpCrisscross 5 hours agoparentprev> I don't think any of my users noticed, and I don't think any of them care Did marketing every run with it? reply rkangel 2 hours agoparentprev> But I don't think any of my users noticed, and I don't think any of them care. You're probably right (unless you make a big deal of it). But you're doing something good. Nobody needs to notice it for it to still be good. Also, do you get benefits in not having cookie banners, or (small) performance impact? reply AaronFriel 9 hours agoprev> Override the Host header to be equal to GTM-123456.fps.goog. Allow all cookies and query strings to be forwarded. Did a security team review this? This leaks session cookies for your domain to Google in a way GTM did not previously capture. reply mschuster91 9 hours agoparent> This leaks session cookies for your domain to Google in a way GTM did not previously capture. Only if you set up your session handler to emit cookies that apply to all subdomains instead of using the __Host- prefix and the SameSite=strict attribute [1]. [1] https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Se... reply AaronFriel 21 minutes agorootparentThis is incorrect, the documentation in the article involves configuring an L7 load balancer to route a path on the same domain as the origin to Google Tag Manager. This means even `SameSite=strict`, `Secure`, `HttpOnly` cookies will be sent to GTM, if the instruction I quoted is followed to pass all cookies and query strings. It's weird that the document specifically says \"all cookies\" - that gives GTM access to every cookie sent to your application. reply Sayrus 9 hours agorootparentprevI think the load balancer is the one forwarding all cookies to Google with this configuration. The browser has already sent this to your own domain/LB as first-party mode introduces yourdomain.com/page and yourdomain.com/metrics. reply lbarrow 6 hours agorootparentprevI don't think this would prevent the session cookie from being sent to tag manager. The tag manager document describes setting up a specific path on the website's normal domain, not using a subdomain. reply charrondev 5 hours agorootparentYou can issue cookies on a sub path though. reply toast0 4 hours agorootparentYou can, but it's typical to use / for login cookies. And I don't think you can issue cookies that exclude a sub path. reply soraminazuki 6 hours agoprev> Setting up first-party mode may help your tag setup perform better, resulting in recovery of lost measurement signals, in a privacy-safe way. Does Google explain what \"privacy\" means in this context? I'm unfamiliar with Google jargon, but I'm sure it's completely different from the dictionary definition. reply ChrisAntaki 6 hours agoparentThey mention full IP obfuscation. reply soraminazuki 5 hours agorootparentThat's hardly assuring considering they still make detailed profiles of everyone regardless of whether they even have a Google account. reply noashavit 2 hours agorootparentthis ^^ reply Animats 31 minutes agoprev\"The setup in this documentation will help you recover X% more measurement signals on your website.\" Caught! The conclusion was written before they actually knew if it worked. reply omoikane 1 minute agoparent\"X%\" here likely means \"single digit number of percentage points\", as opposed to something like \"XX%\". reply zokier 5 hours agoprevOnly weird thing is why they are so late to the party; first-party proxying is so obvious (and not novel) solution, they could have pushed this out already five or ten years ago. This is also the reason why I have been always dubious on PiHole and other DNS based or network level blocking solutions. Blacklisting DNS entries or IP addresses was never going to be workable approach. reply noashavit 2 hours agoprevI was waiting for something like this since the \"death of the third-party cookie\" reply Sephr 4 hours agoprevThis leads to an interesting phenomenon that increases tracking in some poorly designed browsers, despite the wishes of both site owners and visitors. Sites will end up using this, and some site owners will also install privacy compliance solutions to regulate these trackers in accordance with user rights and consent. Misguided browsers such as Brave bluntly block some privacy compliance solutions, resulting in an increase in unconsensual tracking from first-party-fronted trackers. reply threeseed 7 hours agoprevGoogle has had a similar approach for a while now with server side containers. Works flawlessly to prevent ad-blockers from blocking tracking tags and integrates with platforms like Shopify to allow their user tracking to be hidden and unblockable. And because Chrome allows long-lasting cookies sites can track you for retargeting for over a year compared to a week for Safari. And because they add every API under the sun fingerprinting is 99% effective. Thanks Google ! reply manuelmoreale 6 hours agoparent> Thanks Google I have to ask because you never know: was this sarcasm? reply aembleton 4 hours agorootparentYes reply manuelmoreale 3 hours agorootparentOk thank you. I though it was but I read some wild takes on this site so I had to ask before typing an unnecessary rant. reply nissarup 5 hours agoprevDoes this not change who is responsible for the data shared with Google? With this the owner of the host is sending the scripts collecting data, where before it was Googles servers. reply occz 9 hours agoprevI guess this would defeat DNS-based blocking approaches, but more sophisticated tools like uBlock can still cope with it, albeit requiring larger blocklists. reply kimsey0 9 hours agoparentThat becomes a problem when Google Chrome limits the number of filter rules extensions can add. https://developer.chrome.com/docs/extensions/develop/concept... reply Semaphor 9 hours agorootparentOnly for people using chrome. reply nine_k 7 hours agorootparentWhat do you think the point of creating Chrome was? reply nielsbot 1 hour agorootparentWe're a web company. We should own a critical technology for getting on the web. Better experience surfing means more traffic for Google. But also, if we own the browser, we can push Google services and make them better and more convenient. We can also influence web standards to our favor. And a nice side-effect is we can better track users. So--one part we're an ad company and one part MS-style \"embrace and extend\" the web. reply 2OEH8eoCRo0 7 hours agorootparentprevTo not allow Microsoft IE to dictate web standards? To gather more search queries? Chrome beta released 15 years ago, that's such a long con I'm not sure I buy it. reply zokier 6 hours agorootparentWhen Chrome came out, Microsoft was in no position to dictate anything web-related; they barely managed to get IE7 released and it was playing massive catchup to Firefox (and Opera) in regards to standards, and didn't really bring any new web features that weren't already in other browsers. MS really dropped the ball after IE6. Notably in Europe Firefox actually temporarily surpassed IE in market share, before Google came and stomped everyone. reply p0w3n3d 5 hours agorootparentMaybe you were not using IE at that time, but surely you had to create IE compatible content if you worked as a web developer, and this was really hell. If window.forms, if ie6 if opera, if ns6 - ifing hell there was I tell you! reply WarOnPrivacy 5 hours agorootparentprev> Microsoft was in no position to dictate anything web-related; they barely managed to get IE7 released I recall a blog from that time titled Chrome is the new IE6. On the corporate side, we paid attention when an SAAS site had a \"Built For Internet Explorer\" badge. Elements can+did falter in other browsers (because devs only dev'd for IE). reply TheCapeGreek 9 hours agorootparentprevAKA the vast majority of browsers out there. reply Semaphor 8 hours agorootparentWell, if it’s okay for them, then that is still their decision. reply chii 7 hours agorootparentIt's what google was counting on, user ignorance and apathy, to defeat adblockers. reply Spivak 5 hours agorootparentI mean sure but ad blocking is still a killer feature. If users see ads the frog jumps out of the pot. reply WarOnPrivacy 5 hours agorootparentprev> Well, if it’s okay for them, then that is still their decision. A decision reached because both informed & consent are minimized as much as possible. This is a core method of unethical marketing. reply XorNot 8 hours agorootparentprevThere's never been any reason to think Google wouldn't pull something like this with Chrome though. Which is why people should be advocating switching to Firefox. reply justinclift 4 hours agorootparent> Which is why people should be advocating switching to Firefox. Pity about Mozilla having recently switched to the dark side themselves, becoming an advertising company as well. reply nektro 8 hours agorootparentprevit will convince more people to switch reply meigwilym 8 hours agorootparentprevFrankly, this just gives more reasons to switch. reply n_ary 8 hours agorootparentSadly, most people don't care or understand these \"tech whiz\" things. Here in our little corner of EU, I see massive Chrome adverts everywhere about how convenient it is to save your password in chrome password manager, sync bookmarks across devices, how all other browsers are baddies leaking your private details and chrome can save your data and other fear mongering adverts. Basically, these adverts are blasted at you 5-8 times a day depending on how many YouTube videos/shorts you watch, also I recall seeing same advert even on someone's FB timeline being shared by their friends to switch to chrome. reply booi 8 hours agoparentprevafaik uBlock wouldn't be able to block these in most scenarios since the resource requests look like any other. ublock is still based on huge lists reply lol768 8 hours agorootparentI'm sure it's only a matter of time before folks are able to fingerprint the responses that come back from the actual service's origin vs Google's service, or perhaps by abusing the health-check that exists at /healthy reply zokier 5 hours agorootparentWhich wouldn't help much when tracking happens on server-side. By the time your adblocker is able to analyze the response Google will already have tracked your visit. reply threeseed 7 hours agorootparentprevBut then your ad blocker will need to introspect and run rules on the contents of every request payload. The impact to web browsing performance would be prohibitive. And if it got to that point Google would just randomise the payload. It's pretty easy to do with obfuscation tools. reply ordu 7 hours agorootparent> your ad blocker will need to introspect and run rules on the contents of every request payload. The impact to web browsing performance would be prohibitive. Could ad blockers run WebAssembly? I suppose it will be up to the task, because it means minimum work for a GC, and no overhead coming from dynamic types of js. With the jit compilation it will be comparable by performance to a native code and native code has no issues dealing with every payload byte-per-byte. > And if it got to that point Google would just randomise the payload. And then ad blockers start to measure entropy. > It's pretty easy to do with obfuscation tools. It is easy to do, but obfuscation really works only when no one is targeting you specifically, when you are defending yourself from bots that try random targets in hopes to find vulnerable ones. Against targeted attacks it becomes an arms race, so you'd need to change constantly, and eventually you will need to spent a lot of time discovering the ways how your obfuscation is defeated, so it comes to an equal amount of difficulties for both sides. On the side note, I wonder is there possible an attack of poisoning google stats by sending the fake data from the website. Probably the Google's trick to overcome this threat is to control CDN, so it gets the data from the trusted server. reply SquareWheel 9 hours agoprevSeems a bit simpler than setting up a Server Container. Am I correct in understanding that this is meant to run on a CDN or load balancer? I'm curious what kind of effect is has on performance vs making direct requests to endpoints. reply batch12 6 hours agoprev [–] Is the filename still gtag.js? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google is introducing a beta feature for deploying tags in first-party mode, enhancing tag performance and data privacy by using the website's domain for hosting.",
      "The setup involves reserving a unique path on the domain, routing traffic through services like Google Cloud or Cloudflare, and updating website scripts to use the new measurement path.",
      "Users are encouraged to test the setup using Tag Assistant and provide feedback through a designated feedback form or contact email."
    ],
    "commentSummary": [
      "Google has introduced a method to bypass the automatic blocking of its Tag Manager, raising concerns about privacy and the effectiveness of ad blockers.",
      "Users discuss strategies to block tracking, such as using uBlock Origin with JavaScript disabled by default, and selectively enabling it for ease of use and speed benefits.",
      "The new method by Google has sparked a debate on balancing data collection for business purposes with user privacy, with some users expressing frustration over Google's tracking practices."
    ],
    "points": 133,
    "commentCount": 74,
    "retryCount": 0,
    "time": 1721204193
  },
  {
    "id": 40979539,
    "title": "After 12 years of reviewing restaurants, I'm leaving the table",
    "originLink": "https://www.nytimes.com/2024/07/16/dining/pete-wells-steps-down-food-critic.html",
    "originBody": "ADVERTISEMENT SKIP ADVERTISEMENT CRITIC’S NOTEBOOK After 12 Years of Reviewing Restaurants, I’m Leaving the Table Pete Wells is moving on from his role as the Times restaurant critic, a job with many rewards and maybe too many courses. Share full article 639 Photos of Pete Wells and other critics hang in many a New York restaurant kitchen. This one, at Gertie in Brooklyn, reads, “Alert management immediately if seen.” Credit... Liz Clayman for The New York Times By Pete Wells July 16, 2024 Early this year, I went for my first physical in longer than I’d care to admit. At the time, I was about halfway through a list of 140 or so restaurants I planned to visit before I wrote the 2024 edition of “The 100 Best Restaurants in New York City.” It was a fair bet that I wasn’t in the best shape of my life. Listen to this article with reporter commentary My scores were bad across the board; my cholesterol, blood sugar and hypertension were worse than I’d expected even in my doomiest moments. The terms pre-diabetes, fatty liver disease and metabolic syndrome were thrown around. I was technically obese. OK, not just technically. I knew I needed to change my life. I promised I’d start just as soon as I’d eaten in the other 70 restaurants on my spreadsheet. But a funny thing happened when I got to the end of all that eating: I realized I wasn’t hungry. And I’m still not, at least not the way I used to be. And so, after 12 years as restaurant critic for The New York Times, I’ve decided to bow out as gracefully as my state of technical obesity will allow. Not that I’m leaving the newsroom. I have a couple more restaurant reviews in my back pocket that will appear over the next few weeks, and I plan to stick around at The Times long after that. But I can’t hack the week-to-week reviewing life anymore. The first thing you learn as a restaurant critic is that nobody wants to hear you complain. The work of going out to eat every night with hand-chosen groups of friends and family sounds suspiciously like what other people do on vacation. If you happen to work in New York or another major city, your beat is almost unimaginably rich and endlessly novel. People open restaurants for all kinds of reasons. Some want to conjure up the flavors of a place they left behind, and consider their business a success if they win the approval of other people from the same place. Others want to dream up food that nobody has ever tasted or even imagined before, and won’t be satisfied until their name is known in Paris and Beijing and Sydney. And there are a hundred gradations in between. The city is a feast. Exploring, appreciating, understanding, interpreting and often even enjoying that feast has been the greatest honor of my career. And while the number of restaurant critics is getting smaller every year, everybody I know who works in this endangered profession would probably say the same thing. So we tend to save our gripes until two or three of us are gathered around the tar pits. Then we’ll talk about the things nobody will pity us for, like the unflattering mug shots of us that restaurants hang on kitchen walls and the unlikable food in unreviewable restaurants. One thing we almost never bring up, though, is our health. We avoid mentioning weight the way actors avoid saying “Macbeth.” Partly, we do this out of politeness. Mostly, though, we all know that we’re standing on the rim of an endlessly deep hole and that if we look down we might fall in. “It’s the least healthy job in America, probably,” Adam Platt said recently when I called him to discuss the unmentionable topic. Mr. Platt was New York magazine’s restaurant critic for 24 years before stepping away from the trough in 2022. “I’m still feeling the effects,” he said. He has a flotilla of doctors treating him for gout, hypertension, high cholesterol and Type 2 diabetes. “I never ate desserts but when I took the job I started eating desserts,” he said. “I became addicted to sugar. You drink too much. You’re ingesting vastly rich meals maybe four times a week. It’s not good for anybody, even if you’re like me and you’re built like a giant Brahman bull.” We talked about the alarming frequency with which men in our line of work seem to die suddenly, before retirement age. A.A. Gill, restaurant critic of the Sunday Times of London, was killed by cancer at 62. Jonathan Gold, critic for the Los Angeles Times and LA Weekly, died at 58, right after he was diagnosed with pancreatic cancer. Back in 1963, A.J. Liebling of The New Yorker died after checking into a hospital for bronchial pneumonia. He was 59. These are isolated stories to be sure, but I’d see the headlines projected on my bedroom ceiling when I woke up in the night with my insides burning like a fire at a chemical refinery. Image The critic Gael Greene, known for her capacious (and face-obscuring) hats, died in 2022 at 88. Credit... Ethan Hill for The New York Times The women I looked up to lasted longer. Gael Greene, who invented Mr. Platt’s job at New York, lived to 88. Mimi Sheraton, critic for Cue, The Village Voice and The New York Times, made it to 97, despite a professed aversion to exercise. Christiane Lauterbach, a restaurant critic for Atlanta magazine for more than 40 years, told me she is in good health. She attributes that to “not going to the doctor,” although she was recently talked into having her cholesterol and blood sugar tested. (Both were normal.) “I just take little bites of this and that. I never finish a plate in a restaurant,” she said. “If I finished my plate, I would just be 300 pounds.” S. Irene Virbila, who ate out six nights a week for 20 years as restaurant critic for the Los Angeles Times, used to bring along a man to finish her plates. She called him Hoover. “Restaurant food is rich,” she said. “To make those flavor bombs it has to have a lot of rich elements. It’s more of everything than you would eat if you could eat exactly what you wanted.” After she left the post, she lost 20 pounds in two months, “without thinking about it.” Today, aside from taking medication for an inherited vulnerability to cholesterol, she is in good health. Virtually all of my 500 or so reviews were the result of eating three meals in the place I was writing about. Typically, I’d bring three people with me and ask each to order an appetizer, main course and dessert. That’s 36 dishes I’d try before writing a word. This is the simple math of restaurant reviewing, but there is a higher math. Critics eat in a lot of restaurants that Gael Greene once described as “neither good enough nor bad enough” for a review. Then there are the reference meals, the ones we eat to stay informed, to not be a fraud. Often, this is where I got into real trouble. How many smash burgers did I need to taste, or taste again, before I could write about the ones at Hamburger America, a restaurant I reviewed in the same months I was eating my way toward my “100 Best Restaurants ” list, for which I needed to make sure that the Uyghur hand-pulled noodles and Puerto Rican lechon asado and Azerbaijani organ-meat hash that I loved were, at least arguably, the best in the city? This is probably the place to mention that naming 100 restaurants was totally my idea. My editors had asked for 50, and I’ll bet they would have settled for 25. When I did do 100, and the time came a year later to do it again, they didn’t ask me to go back to all of them. That was my idea, too. Image How many smash burgers would a critic need to taste in order to fairly assess the ones shown here, at Hamburger America? Credit... Colin Clark for The New York Times Omnivorousness, in the metaphorical sense, is a prerequisite for a good critic. My favorite movie critic is still Pauline Kael, who wrote as if she had seen every film ever made. But movies won’t, as a rule, give you gout. Food writing’s most impressive omnivore was Jonathan Gold. There didn’t seem to be a dish served anywhere in Los Angeles that he hadn’t eaten at least once, and usually several times, until he was sure he understood it. His knowledge inspired me. It also tormented me — there was no way to catch up to him. Years ago, he used to tell people he had eaten every taco on Pico Boulevard. This was merely an appetizer. His larger goal was to eat in every restaurant on the street “at least once.” Pico Boulevard is more than 15 miles long. I have not eaten in every restaurant on Roosevelt Avenue in Queens, far and away the most significant taco artery in my own city. There have been nights, though, as I walked for miles under the elevated No. 7 train, watching women press discs of fresh masa and men shave cherry-tinted strips of al pastor pork from slowly revolving trompos, when it seemed like an excellent idea. At a certain point, this kind of research starts to look like a pathology. “Your body changes over time,” Mr. Platt said. “You have this giant distended belly which wants to be filled. All those weird sensors in your brain that cry out for deliciousness are at DEFCON 1 all day. You become an addict.” When, in the line of duty, you have spent enough hours loading up your tray with mashed potatoes, rolls, biscuits and an extra slice of pie, you eventually have to ask yourself whether you are standing in the buffet line for the audience or for yourself. “In truth, I would have to say that I probably have pursued this career as an excuse to overeat,” Mimi Sheraton told the interviewer Terry Gross in 1987. “I think that the people who are really good at it are all in that position.” Did that apply to me? Not at first. But over time, I came to see relentlessly stuffing my face as one way to become really good at the position. By browsing my way across the city like a goat, I could try to level a playing field that is deeply tilted in favor of restaurants with money. Manhattan’s sea-urchin spaghetti factories can always buy attention. It’s not as easy for a soul-food hangout in Stapleton or a Palestinian kitchen in Bay Ridge or an Ensenadan aguachile specialist in Jackson Heights. So off I would go, because if I didn’t, a really important restaurant might be overlooked. This seemed normal right up until May, when I took two weeks away from my restaurant rounds while I recovered from a hernia repair. The night after the operation I wasn’t hungry. The next night I ate soup. The next day, salad. Without menus and dinner guests and a notebook to fill, I ate just what I wanted and nothing more. I slept through the night. I stayed awake through the day. I took long walks, not all of which ended at bakeries. And at some point in those two weeks, it occurred to me that I am not my job. When I first came to The Times in 2006, a reporter warned me not to identify myself too heavily with my work. “Any job at The Times is a rented tux,” she said. I nodded, but didn’t get the point until this year. It’s time to return the tux. I’ve had the trousers let out a few inches, but a tailor can take them in again. As for the stain on the jacket, that’s just pork fat. I think it adds character. Read by Pete Wells Follow New York Times Cooking on Instagram, Facebook, YouTube, TikTok and Pinterest. Get regular updates from New York Times Cooking, with recipe suggestions, cooking tips and shopping advice. Audio produced by Tally Abecassis. Pete Wells has been the restaurant critic for The Times since 2012. He was previously the editor of the Food section. More about Pete Wells A version of this article appears in print on , Section D, Page 1 of the New York edition with the headline: It’s a Fitting Time to Leave the Table. Order ReprintsToday’s PaperSubscribe See more on: The New York Times 639 Share full article 639 More on Food and Dining Keep tabs on dining trends, restaurant reviews and recipes. Since the early 2000s, the variety and quality of pizza made by ambitious chefs all over the United States have only gotten better. Here are 22 of the best pizza places in the country, and 15 of our favorite reader submissions. A staple of Moroccan cooking, preserved lemon adds zest and depth to earthy dishes like potato salad and lentil soup. Northgate González Market, one of the largest Mexican supermarket chains in the country, imagines the future of food as a family-friendly mercado. We combed through a month’s worth of receipts from more than two dozen people across the United States to better understand our relationship to the food we buy. Eating in New York City The New York Times Food staff has searched all five boroughs for the 57 sandwiches that define the city, and here are 13 of the sandwiches our readers live for. Pete Wells, our restaurant critic, ranked his top 100 restaurants in New York City. Will Guidara, the Eleven Madison Park hospitality guru, who has a co-producing and writing credit on “The Bear,” talks about the power of surprise and the calling of restaurant work. The chefs Lee Hanson and Riad Nasr have restored the French gem Le Veau d’Or on the Upper East Side. ADVERTISEMENT SKIP ADVERTISEMENT",
    "commentLink": "https://news.ycombinator.com/item?id=40979539",
    "commentBody": "After 12 years of reviewing restaurants, I'm leaving the table (nytimes.com)133 points by necubi 23 hours agohidepastfavorite164 comments jprd 23 hours agohttps://archive.md/5IQiB Johnsorc 15 hours agoprevHe had reviewed some of the restaurants that I previously opened/ran. He was generally a nice enough, but standoffish guy. I’ll never forget the feeling of realizing he was seated. One of those moments that you train for, and now it was game time . There are all sorts of tricks that people employ, cheat sheets with reviewers photos (there is one unfortunate photo of him that everyone has, it must be on every restaurant office wall in NYC), serving extra dishes to the tables around him (so that he got a look at things he didn’t order but should have), and calling friends to fill an empty dining room when he sat down for example. It was always an awkward interaction, he knew I knew, I knew he knew I knew. I generally think Sifton was a better writer, I appreciate that he reviewed restaurants that weren’t your typical white male chef joints, and I’m happy to see Tejal still doing well out west. I’m particularly excited to read some Mellissa Clark reviews in the meantime. reply treme 14 hours agoparentrunning multiple restaurants in NYC must be quite an adventure. are you still in the business? what brought you to hn? reply Johnsorc 7 hours agorootparentIt was an amazing experience, it made me who I am. I cooked through university, and then studied wine to become a sommelier after graduation. After a few years in a Relais and Chateau hotel in Colorado I moved to NYC for 10 years. I’ve since moved on to marketing in SaaS. I firmly believe that it gave me a big leg up in understanding consumer behavior and a unique ability to empathize with the end user. It was definitely stressful, but I wouldn’t trade that experience for the world. That being said, my quality of life has improved beyond measure since changing careers. reply joenot443 5 hours agorootparentSuper cool path, man. I'm envious in many ways. Any favorite restaurants in NYC which folks on HN may not have heard of? reply Johnsorc 4 hours agorootparentAbsolutely! Recommending restaurants may be the unofficial New Yorker pastime. As a best practice, I recommend checking some of the Eater.com lists before visiting any town. They don't always hit the mark, however you can get a pretty good feel for the restaurant scene by what they are reviewing. I'll put a mix of genres below. But I'm more than happy to answer any others. Ugly Baby (Carrol Gardens) is my favorite Thai restaurant outside of Thailand. The Chef/Owner also has a restaurant in Sylva, NC for those in WNC. Popina (Columbia Street Waterfront) is a cozy Italian spot, with a stellar wine list. Claud (EV) is casual fine dining that serves all the good stuff. They're two old Momofuku vets that serve a lot of the stuff chefs like to eat. Lilia and Misi (Williamsburg) are always excellent for pasta. Lucali (Carrol Gardens) is the best pizza in the city. Razza (Jersey City) is the best pizza outside of a borough. Frank Pepe (New Haven) is the best outside the city. Rossi Rosticceria Deli (Poughkeepsie) is an amazing deli, up by the CIA. Glacken's Bar and Grill (Bronx) is absolutely the best bar to stop in before a Yankee game. Minca (EV) for Tsukemen Ramen Paisanos (Carrol Gardens) is my favorite Italian Butcher. My favorite restaurant in NYC at the moment is Frenchette (Tribeca). Bars in no particular order Dante (everything campari, get a Garibaldi), Attaboy (anything is great), Dead Rabbit(Irish Coffee is spectacular), Four Horsemen (natural wine). reply kataklasm 8 hours agorootparentprevYes, I'd love to hear some stories! reply Johnsorc 6 hours agorootparentThere are plenty, but my favorite celebrity encounter had to be this one. Dan and Eugene Levy dining with Paul Shaffer, they were the last ones in the restaurant, and paid with a gift card signed “Love Dave.” It was mid winter, in Gramercy and they thoroughly enjoyed their evening, including wine. While I was fetching their coats, they were singing show tunes outside of the coat check (restaurant management isn’t always glamorous). Apparently when I got Paul’s jacket his yellow beanie fell out. I remember this because while I was getting Eugene’s jacket, Paul stormed through the curtain yelling “Where is my hat?! It was a yellow hat! It was a very good hat! Find my hat you son of a bitch!” There were a couple of times in my career when in the moment I thought “Given all the possible outcomes for my life, how did I end up in this one?” This was one of them. In the end, I found his hat and they were off into a cold and rainy winter night. They were all absolutely lovely guests. Funny, charming, and they tipped the staff well. reply maxverse 5 hours agorootparentThis is beautifully written reply Johnsorc 4 hours agorootparentThank you! I've never fancied myself a good writer; I feel like, on a personal level, I can identify the beauty in things. However, I tend to have a hard time putting it to paper in a way that I feel conveys how I feel. But I'm working on it! reply shalmanese 22 hours agoprevRight when FiveThirtyEight launched, they did a brilliant piece of content strategy in that one of their very first pieces was a quest to find the best burrito in America [1]. Anna Maria Barry-Jester self reportedly \"traveled more than 20,000 miles around the United States and eaten 84 burritos in two rounds (to say nothing of the dozens of extracurricular burritos I polished off).\" I was glued to the series as it plodded on week by week and it still sticks in my mind today as simultaneously the best and worst job in the world I could imagine. Part of what made it so enthralling to read was this grand act of human perversity that a single woman would endure such a gruelling quest for such a trivial question and she made you feel that perversity along every step of the journey. [1] https://fivethirtyeight.com/features/americas-best-burrito/ reply BariumBlue 21 hours agoparent> Part of what made it so enthralling to read was this grand act of human perversity that a single woman would endure This is part of why I enjoy watching a couple of RuneScape YouTubers. The sheer time commitments they put in for seemingly minor gains is like gore but for amputating off their own time effort & energy and throwing it into a bottomless maw. reply andoando 18 hours agorootparentMan runescape was my life for a long while. Its still the only MMO I know which actually has unique and rewarding quests, activities, and mini games. There's something like 150 quests, most with completely new NPCs, new map environments/interactions, item, skill and map unlocks. For example to gain access to the best sword in the game (at the time) you had to do a quest where you were travelled to a monkey island where you had to sneak around, be creative, defeat a bunch of apes and the boss. And it was actually fairly difficult, you had to prepare for the quest and dying meant losing almost all your items. Nothing like go here kill 20 foxes, come back. https://runescape.fandom.com/wiki/Monkey_Madness reply egberts1 16 hours agorootparentprevI hit my limit at 83 mining in Runescape. The grind sure is relentless! reply quirino 21 hours agorootparentprevCan you suggest a couple of channels? I've never played RuneScape but those videos sound right up my alley. reply jaggederest 19 hours agorootparentNot Runescape but a similar grindfest - playing the largest Factorio mod, Space Exploration. 300 hours plus in ~5 hours of video https://www.youtube.com/watch?v=8hRJ-CcwvrI&list=PLtyo3aqsNv... reply hoten 21 hours agorootparentprevStart with Settled's swampletics. https://youtube.com/playlist?list=PLWiMc19-qaA3u1ZawZQIKAh0B... The other good one from the same channel is Tileman, where he is limited to only using tiles that have been \"unlocked\" His current feature is Lowlife, where if he takes a single point of damage his account gets deleted. reply a5huynh 21 hours agorootparentprevNot op but one my favorites is: https://www.youtube.com/@Settledrs Very entertaining to watch and explains things so even non players can understand the sheer absurdity of some of the attempts. reply swarnie 12 hours agorootparentprevTwo \"extreme one chunk\" style accounts in which the creators are or should be heavily medicated. Verf - https://www.youtube.com/@VerfRS Limpwurt - https://www.youtube.com/@Limpwurt reply jazzyjackson 15 hours agoparentprev> Part of what made it so enthralling to read was this grand act of human perversity I felt the same way about Eddy Burback's \"I ate at every Rainforest Cafe in the Country\" [and Canada] https://www.youtube.com/watch?v=vA-bjpKvIw8 reply tomjakubowski 22 hours agoparentprevBarry-Jester kept her cool on her burrito quest, where Jim Haggerty drove his RV into the depths of madness searching for our greatest barbecue, in Porkin' Across America. reply jjmarr 15 hours agoparentprevYou'd love the brilliant parody from The Onion \"Porkin' Across America\" on his journey to taste pork across the country and destroy his life on camera. https://youtube.com/playlist?list=PL4NL9i-Fu15jdlr2KQf_lyhXl... reply greggsy 17 hours agoparentprev“… evaluated 67,391 burrito-selling establishments…” How does this even work? If a local or federal government attempted to do this type of survey, they would end up having to pay McKinsey seven figures just to plan the whole operation.. reply jononor 11 hours agorootparentHmm. If one spends just 60 seconds on each, it would be a 6 month full time gig. Barely enough time to look at info/photos on Google maps and make a few quick judgement calls. Of course one could maybe reduce this of them by setting a threshold on their rating, maybe also number of reviews added last 12 months, etc. But yeah - lots of labor to actually evaluate thousands of anything. Months possibly. reply Modified3019 22 hours agoparentprevThat’s amazing. I bet she was feeling like this toward the end even if only in spirit: https://www.youtube.com/watch?v=VCwfil6r1cg reply EGreg 21 hours agoparentprevI used to joke that if you go to the movies or restaurants etc. you could open pass-through tax LLCs (which are “disregarded entities” at the IRS) and write those off as a business expense, as long as you had a website as a food or movie critic / reviewer, and even had a way to subscribe for some paid memberships (eg Patreon) and also advertising with affiliate sales (eg Amazon) for recipes, movie rentals etc. You know, running a business kind of like that guy who writes about inside Apple news very rarely but effectively (what’s his name, Gruber? Daring Fireball?) The business doesn’t actually have to make money in the first few years, as long as you are making bona-fide attempts to grow it. No one requires you to watch every movie or eat every burrito. But who is the government to say you’re not trying to run a business as a food or movie critic? Much of your personal lifestyle could then be deducted as a business expense on your schedule C, being “necessary and ordinary” for your various LLCs. Perhaps even your travel expenses if you are a travel blogger staying at hotels etc. But maybe it’s not a joke. Any lawyers or accountants on HN see any problems with this? Again, I’m talking about doing the minimum to make this an actual business — it may become profitable through the monetization but even if it isn’t, that’s 30% additional you’re saving on what would otherwise be your personal entertainment expenses! The main issue I see is that if your LLC has debts that it defaults on, a court might see you as “commingling” personal funds with the business, even if you keep the accounts separate, and pierce the corporate veil. But, this is a separate issue of limiting liability for debts, which your LLC doesn’t have to even take on. Even if that were the case, from a tax point of view the question is only whether the expenses are necessary for the business, and ordinary, both of which they are. reply harmon 18 hours agorootparentAs I understand it, you can only write off a business's expenses against that business's income, not income from other sources. For example, if you have a W2 income source and you have this business generating losses, you can't take your business losses or write offs and apply them to your W2 income, so you wouldn't really be saving any money as there would be no revenue to write off expenses against. You would need to get the business to generate revenue for this to be a viable idea. The only case that I am aware of where you can take business losses / write offs and apply them to other income sources is in real estate, and only under very specific circumstances. This is one reason why high income individuals love things like short term rentals which is one circumstance in which this is possible. reply jerkstate 18 hours agorootparentI am not a lawyer or accountant, but you can fund your business with a loan from your person, and then if the business fails, you can write off the loan against your personal capital gains, and up to $3000 of regular income per year. This is not financial or legal advice. reply shkkmo 15 hours agorootparentprevI do not believe this is correct. If your business is a \"pass through\" style of entity, you can indeed deduct losses from other income (up to a point and with various limitations.) Doing too much of this can definitely trigger an audit. reply slv77 20 hours agorootparentprevOthers have tried and the IRS has even provided a helpful guide on if your endeavor is a hobby or a business (https://www.irs.gov/pub/irs-news/fs-08-23.pdf). reply EGreg 20 hours agorootparentThanks for this! I didn’t know the guidelines were published. This is like FINCEN’s 2013 and 2019 guidances for cryptocurrencies. “The limit on not-for-profit losses… does not apply to corporations except S Corporations”. It doesn’t seem to mention LLCs. These are “disregarded entities” at the IRS level, so what does that mean? For tax purposes they are treated as sole proprietorships? It seems to me there is some “minimum” level of bona-fide for-profit business that might be helpful to reach if you are a prolific traveler or movie goer or eat out in restaurants a lot. That’s my main point. A little bit of effort and you can write off thousands of dollars a year in business expenses while you also stand a chance of making money on top of it. reply slv77 15 hours agorootparentBusiness expenses must be ordinary and necessary to be deductible. A roofer would have a hard time justifying deducting a boat under the rule but a commercial fisherman wouldn’t have trouble. Entertainment expenses are no longer deductible with recent tax law changes with few exceptions. It would be difficult today to get a CPA to sign-off off on a lot of what may have passed previously. A decent write-up can be found here - https://www.thetaxadviser.com/issues/2023/nov/navigating-aro... reply EGreg 14 hours agorootparent* However, a taxpayer’s trade or business must be considered. For example, a theatrical performance, which would normally be considered an entertainment expense, would not be an entertainment expense for a professional theater critic attending the performance in a professional capacity (Regs. Secs. 1.274-11(b)(1)(iii), 1.274-12(a)(1), and 1.274-12(b)(3)).* This seems to support what I’m suggesting reply ghaff 18 hours agorootparentprevI had a small \"hobbyist\" software business once upon a time. I made a point of only deducting expenses that seemed reasonable and not red flags for a software business, and only deducted up to just below my revenue (about $7K/year in the 90s). That seemed safe if maybe somewhat conservative. Doesn't work for a lot of things (including reputable restaurant reviews) but bloggers also have the opportunity to get free stuff if they get noteworthy enough. Yes, it's a source of bias but so long as everything isn't how this thing they were given for free is fantastic, I don't have a problem with it. I've reviewed books (and a few other things) sent to me and I've given some pretty negative reviews as well as positive ones. reply paxys 21 hours agorootparentprev> Much of your personal lifestyle could then be deducted as a business expense on your schedule C, being “necessary and ordinary” for your various LLCs That's not how it works. You can maybe deduct the price of your movie ticket and mileage to drive to the theater. Anything beyond that and the IRS will be up your ass in an instant. reply EGreg 21 hours agorootparentWell that’s what I’m talking about. The price of all your movie tickets and mileage to drive to the theater, perhaps even your netflix subscription etc. Or if you’re a travel blogger, the plane rides and hotel stays become a business expense if you’re doing it for profit as part of an LLC. You have to have an actual business plan with memberships, advertisements, etc. You could be making money with it. But even if you aren’t yet, as long as you’re trying, the business expenses made by an LLC that you are investing into, are deductible on your personal Schedule C! Are they not? reply ebiester 21 hours agorootparentprevYou’d have to get revenue against it. reply EGreg 20 hours agorootparentWell, as many on HN know, lots of startups fail. Investors write that off as a capital loss. Maybe one day, long term capital gains tax will be on the same level as income tax, and then people will stop trying to use things like 83b elections. But regardless of that, if you invest into your own startup by buying equity or lending it money, that is NOT currently a taxable event. And then that LLC’s losses are passed through to your Schedule C. It may be strange to have you buying shares in your company if you already have 100% of shares. But if you do a Limited Partnership with a few people, then all of you could be competing to buy shares in it and dilute the others. Those are non-taxable events. And the members of the LLC are also its staff, who go watch movies and review them. Then the tax deductions are claimed on Schedule K instead, by each partner. I am only talking about a bona fide business. You don’t have to go all-out for each business you start, working 40 hours a week for each one. You could even go to the movies and restaurants once a week and save 30% by turning it into an actual business. Can’t you? Do travel bloggers deduct their travel expenses as necessary and ordinary? reply fooker 21 hours agoparentprevWow I’d be so happy to do this as a full time job! reply mythrwy 21 hours agoparentprevNot sure I agree that this is a trivial question. Very few things in life are as important as burritos in my view. reply ggm 19 hours agorootparentMonads. Monads are as important as Burritos. reply dyauspitr 21 hours agoparentprevI can’t imagine how it could in any way be the worst job. reply rgovostes 22 hours agoprevMy favorite is his 2015 review of Señor Frogs in Times Square: https://www.nytimes.com/2015/12/30/dining/senor-frogs-review... The following year The New Yorker wrote a profile of him which features some of the backstory. \"Is it possible to say with a straight face that Señor Frog’s is a better restaurant than Per Se? Can you get those words out without collapsing under your own idiocy?\" https://www.newyorker.com/magazine/2016/09/12/pete-wells-the... reply nullhole 16 hours agoparentSo that's what \"Señor Tadpoles\" was a reference to. reply UIUC_06 22 hours agoprevGreat article. If you ask a real chef, \"What do home chefs do wrong the most?\" They will often say, \"Not enough butter, not enough salt.\" reply Workaccount2 21 hours agoparentThis is also why I don't like eating out much anymore. Every restaurant just leans so hard on heavily salting fats to make their food taste good. I'd rather cook myself now where I can actually taste flavors and feel good, rather than just having the primal \"mmm good food\" button bashed in my lizard brain and feeling like garbage afterwards. reply CoastalCoder 14 hours agorootparentWhen I was in college in Massachusetts in the mid 1990s, there was a buffet-style Greek restaurant named \"Brothers\". (Somewhere near Peabody I think.) The Greek woman behind the counter made me (well, guilted me into) getting some vegetables with my order. They weren't too salty or fatty; they were just good for me (and tasty). It was like being fed by one's own mom. It was awesome. reply MeImCounting 14 hours agorootparentprevThis comments and many of the others on this thread strike me as written by people who have either never worked at a real restaurant and/or tend to order bland and fatty food (eat like a toddler) by default when they patronize restaurants. This is fine but really not reflective of good restaurants and the majority of the food they serve. reply superhuzza 8 hours agorootparentWhat do you mean? Even in the linked article, the food critics consistently pointed out that restaurants make food very rich so that it's more appealing. And how they suffered from eating so much rich food. reply standardUser 19 hours agorootparentprevIt sounds like you are describing gorging yourself at Taco Bell. There must be better restaurants and eateries than that around you. reply krallja 18 hours agorootparentTaco Bell doesn’t use butter, AFAIK. reply standardUser 18 hours agorootparentNeither do many major cuisines, like Mediterranean, Mexican, Thai, Japanese and Chinese. Is butter really the problem here? Because to me it sounds like the problem is habitual over-eating. reply throwaway2037 17 hours agorootparentRisotto in Italian cooking definitely uses buttoer. But, I already know what your reply will be: \"Oh, that's Northern Italian cooking -- it doesn't count.\" Most normie readers don't care about that distinction. Japanese izakayas frequently sell grilled items wrapped in foil that is swimming in butter. Again, I assume you will reply: \"Oh, but that's not traditional Japanese cooking -- it doesn't count.\" Again, most normie readers don't care about that distinction. reply xanderlewis 16 hours agorootparentMiso and butter is also a common combination even in home cooking these days. reply polar8 21 hours agoparentprevEating in restaurants is terrible for your health. Here's a study that finds a 49% increase in all-cause mortality risk for those who frequently eat meals prepared away from home. https://pubmed.ncbi.nlm.nih.gov/33775622/ I have stopped eating out completely as I always feel gross and tired after a restaurant meal vs energized after home-cooked food. I think it's mostly due to cheap oils in quantities you would never dream of using at home. reply dredmorbius 21 hours agorootparentDoes that control at all for type of restaurant, both by market segment (e.g., fast food vs. sit-down fine dining), and by cuisine (e.g., \"American\" or \"steakhouse\" vs. various ethnic or vegetarian menus)? Because I could see a lot of variability amongst those. And without controls, the study will default strongly toward fast-food, doughnut shops, pizza, burger / franks stands, and the like. Several of which have pronounced associated negatives (see, e.g., Morgan Spurlock's Super Size MeSeveral of which have pronounced associated negatives (see, e.g., Morgan Spurlock's Super Size Me . For corporate travel: there are ~400 million long-distance business trips annually . Trips-per-person is harder to find, though one source gives 6.8 trips/year, which gives 60 million travellers/year. So that's more than truckers ... but it's a lot fewer trips (and meals). I'd put money on there being more trucker meals-out than business travelers'. Fleshing out further: we really want trips per year, for each classification. I'm going to assume truckers are on the road 250 days/year (roughly 5 days/week) ... we'll do variance after in case I'm wrong. That gives 3.5 million * 250 or 875 million trucker trips/year, more than double the business air travel number. We could cut trucker travel in half and still be somewhat above the business air travel trips figure. reply ghaff 7 hours agorootparentWhatever the exact number, it's probably safe to say that directionally way more \"meals out\" are grabbing some variety of fast food than some variety of upscale/fine dining. Not all that fast-ish food is unhealthy/bad but a lot is as a steady diet. Which just reinforces the point that drawing a broad brush eating out will kill you doesn't have a lot of support. Eating at a nice restaurant once a month is almost certainly not a killer. reply dredmorbius 1 hour agorootparentI tend to agree on all points. The truckers vs. business travellers comparison was mostly me just trying to suss out what the relative magnitudes of those were. Information's sketchy, but inferences can be drawn. That was independent of your points, which are valid and insightful. And yeah, the idea that 1) most \"restaurant\" meals are fast-food franchises and 2) that's not especially healthy on a consistent basis, as well as that 3) specific choices about menu items can have a major impact are ... fairly self-evident. Pity the study doesn't seem to address those, at least based on the unembargoed bits at the shared link above. reply Larrikin 21 hours agorootparentprevThere are certain foods that you can not reasonably make at home or are just extremely fussy and a huge waste of time to make at home. You won't achieve wok hei on your stove, your oven will not be ablr to achieve the high temperatures required for the best versions of certain foods, restaurants in your area will get priority from suppliers over what you find in the grocery store and even most farmers markets, and that's just talking about average restaurants. You start getting into fine dining or a Michelin experience with teams of people preparing the food and it's an entirely different level of impossibility to make at home. Sure eating a fast food burger and fries everyday will be heavy, but even something that simple can be difficult to match compared to the restaurant. Grinding your own meat, double frying the fries, finding/making decent buns, etc. Food is one of the few activities that can be very enjoyable daily. It's usually cost saving to cook yourself and there's a lot of good stuff you can make at home. But you're missing out on some enjoyable experiences by completely avoiding professionals using professional equipment with access to better ingredients. reply throwaway2037 17 hours agorootparent> You won't achieve wok hei on your stove This is simple untrue. There is many, many YouTube videos explaining how to achieve wok hei (鑊氣) at home with a non-commercial gas-fired stove and a cheap wok. For any readers unfamiliar with the stir frying technique called wok hei, read more here: https://en.wikipedia.org/wiki/Wok#Cooking reply swores 8 hours agorootparentI know very little about Asian cooking of any kind, but I seem to remember being told that wok hei produces enough smoke to be extremely unpleasant to have inside a residential building - to the point that even when people do want to use wok hei at home they would choose to have a setup in the garden rather than the kitchen. If my memory/understanding is not wrong, then that adds to the idea that people won't achieve wok hei on their stove even if the reason is not wanting its side effects rather than being technically impossible. reply carlosjobim 20 hours agorootparentprevParadoxically, it's the fast food staples that are most difficult to do at home – because you need a fryer. Haute cuisine is no problem making at home, because fine dining is not based on using fryers. It can't be made with restaurant speed nor quantity, but you can get the same quality at home. reply throwaway2037 17 hours agorootparent> because you need a fryer What? There are many, many YouTube videos explaining how to make \"fast food\" style french fries (double fried, and all that) at home, without a fryer. reply UIUC_06 14 hours agorootparentMy air fryer makes decent fries, using only olive oil as a fat. It did take some practice to get it right. Are they as good as deep-fat fried? No, but they're crisp on the outside and tender on the inside. OK, you all want to hear this, you know you do: =============== Start preheating the air fryer to 400F. Slice the potatoes. Drop them in a bowl of water, swish them around and drain off the water, and fill the bowl again. By now, the water should be clear. If not, do it again. Take the fries out and dry on paper towels, as dry as you can get them. *These steps are important; you need to wash off the surface starch, and get them dry so you're not steaming them* Dry the bowl, and put in some olive oil, with seasonings (salt, pepper, garlic salt, etc.) Put the fries back in the bowl and get them all oily. Put them in the fryer. The basket should be hot enough that they make a sizzling sound. Every 5 minutes, toss the fries. You can either get compulsive and turn each one individually, or just pour them in a bowl and shake it, or shake the fryer basket (if that doesn't cause it to separate, as it does mine). Put them back in the fryer. Check periodically that they're as brown as you want them. ============== Good variations? I want to hear them reply rightbyte 10 hours agorootparentFor how long do you need to dry them? Are we talking hours here or like 15 minutes? reply UIUC_06 4 hours agorootparentGood question. I just wipe them with paper towels and use immediately. But longer might indeed be better. I can tell you they come out crispy and not soggy my way. reply ghaff 17 hours agorootparentprevAnd it's probably not reasonable that the average person who gets McDonalds fries (which are indeed good and better than most, if not all, of the \"fast casual\" joints) will do those things. Not that frozen supermarket fries in a deep fryer are an especially heavy lift and they're mostly good enough (with reasonably fresh oil) for hamburger and fries. reply throwaway2037 8 hours agorootparentprevLATE EDIT: To be clear, I mean frying using oil -- not air frying. reply bsder 21 hours agorootparentprev> You won't achieve wok hei on your stove Not true. Pull out that blowtorch. > your oven will not be ablr to achieve the high temperatures required for the best versions of certain foods Get a steel or aluminum plate for your oven. The conductivity can make up for a lot of the heat differential. Yeah, a true Neapolitan at 900F is out of reach, but almost everything else is just fine. > restaurants in your area will get priority from suppliers over what you find in the grocery store This might be true, but from what I have seen most of the restaurants are barely even reaching SysCo/USFoods level of quality ingredients. Your local grocery store is probably just fine until you are a very good cook. At that point, you might have to start looking at more niche grocery stores. And, if you get better than that, well, you're likely sufficiently obsessive that you will find a way. > You start getting into fine dining or a Michelin experience with teams of people preparing the food and it's an entirely different level of impossibility to make at home. It's more sheer technique and attention to fussy detail than teams of people. A patissier is simply WAY better than you are at making desserts, for example. They know all the tricks; they will also have all the necessary equipment. However, yeah, Michelin restaurants are definitely next level. reply ghaff 18 hours agorootparentFor most people, it's also not just the technique (and, to a lesser degree, gear), it's also the sheer number of fresh ingredients often required. Desserts may actually lean more towards technique/time and less towards ingredients. I took a croissant class and produced at least serviceable croissants (with a chef correcting things here and there). But much as I like a hard to source fresh croissant I'm not going to routinely spend half a day making a batch. reply UIUC_06 19 hours agorootparentprev> Get a steel or aluminum plate for your oven. The conductivity can make up for a lot of the heat differential. Yeah, a true Neapolitan at 900F is out of reach, but almost everything else is just fine. I have a steel plate. An hour at 500F only gets it to around 400F. Which is fine for pizza, actually, so you're right about that. If you ask big US pizzerias (I don't know about the famous Naples ones) what temp they use, it's usually 650-750. At 900F you have zero margin for error. reply awithrow 18 hours agorootparentprevYou can get a standalone pizza over for a couple hundred. I've got an Ooni and it gets up to 900 in about 15 minutes. Its obviously not for indoor use but its great nonetheless. It still takes a good bit of technique to get the dough and timing right but its great to be able to cook a pizza in little more than a minute. reply AlbertCory 17 hours agorootparentHave you actually pointed an IR thermometer at it? On mine (which I sold), it was 900 at the back and 600 at the front. It was just too much trouble. A pizza steel in a kitchen oven, preheated, works very well; maybe not as good as a 700F oven but WAY easier. And 5 minutes instead of 1 minute is not a big sacrifice. reply throwaway2037 17 hours agorootparentHey, this is a great post. I have read similar complaints about Ooni pizza ovens, where it is very difficult to achieve the 900F temp and impossible in the front. Great point about 5 mins vs 1 min. Can you share: Do you think normie home cooks can taste the difference between a 5min and 1min pizza? I am unsure. For example, is the 5min pizza much drier? (I assume no.) reply __turbobrew__ 12 hours agorootparentYou cannot get the same leoparding on the outside and soft and chewy on the inside with a 5 minute pizza. If you are talking about normies than probably no, they cannot tell the difference but if you are detail oriented you can tell the difference. My setup at home is a 20kg pizza steel and pre-heat it in the oven at max temp for at least 1 hour. Even with all that thermal mass I find the later pizzas take longer to cook due to the steel cooling off. You just cant put enough energy into a home oven to match the energy it looses during cooking. Another tip is when the steel is maximally heated I find the rate of cooking on the bottom of the pizza is faster than on the top so I also turn the broiler onto max after I put in the pizza so the toppings get cooked at the same rate as the bottom of the crust. A delicate balance which requires continuous feedback. reply throwaway2037 8 hours agorootparentReal question: I see a lot of YouTube videos bragging about \"leoparding\" (spots on the bottom). Does it really matter? My point: Can you cook a pizza that tastes just as good _without_ \"leoparding\"? > My setup at home is a 20kg pizza steel and pre-heat it in the oven at max temp for at least 1 hour. Sheesh. This is my second complaint about endless YouTube videos about the \"perfect pizza at home\": What is the carbon footprint per pizza? (Exception: I can forgive anyone who has a magical setup that is 100% electric and has solar panels / wind turbines to supply it! Also: Hat tip to any of the crazies that are producing their own green hydrogen at home via electrolysis for their hydrogen-gas-fired pizza oven!) reply AlbertCory 15 hours agorootparentprevThanks, you know, I think the brick oven pizza IS better. Yes, you probably could taste the difference. Whether the 5 min is dryer: maybe, could be. My decision to sell my Ooni, after about 6 tries, was because my actual results were nowhere close to a pizzeria's, and way more trouble than my kitchen oven's. Since you can't just open the door as you can with the kitchen oven, you have much less tolerance for error. In the kitchen, you just open after 5 minutes and decide, \"OK, it's done\" or \"One more minute.\" I guess I decided the brick oven pizzeria results are just not attainable at home. The kitchen results are damn good; way better than a frozen pizza. reply Larrikin 5 hours agorootparentWhich model did you own? I haven't bought one but had been considering buying an almost unitasker because the reviews from trusted sources seemed very good. Serious Eats in particular seems to love the brand. reply UIUC_06 2 hours agorootparentI think it was the Koda, gas-powered. It was a PITA. I don't miss it at all. reply throwaway2037 8 hours agorootparentprevGreat follow-up. Thanks! I never saw anyone comment like this: \"you have much less tolerance for error\". That is the key to understanding Ooni vs kitchen oven. Brilliant. Have you tried Adam Ragusea's NYC pizza recipe? He gives a lot of sensible advice about how to get a great pie from a shitty kitchen oven! reply imp0cat 13 hours agorootparentprevYeah the taste difference is there, but you can get quite close even with a regular 500°F (~250°C) household oven and a longer time (4 with fan/grill + 4 minutes without in my case, YMMV). The basic tricks are to use a pizza stone, prepare your pizza dough a few days before (let it rest in a fridge) and do not go crazy with the toppings (less is more, too much stuff on top of pizza usually means soggy pizza - the top grill element can sometimes fix this, but not always). reply ghaff 17 hours agorootparentprevIt's not perfect but those Naan flatbreads available in many US markets plus a pizza stone at 500 degrees F work fine for the occasional homemade pizza if I don't want to get takeout from one of a couple of local pizzarias. One of which is more convenient and the other is brick-over/better. reply joezydeco 21 hours agorootparentprevYeah, a true Neapolitan at 900F is out of reach... Go look for the folks that hack off the safety latch on their self-cleaning ovens. It's kind of nuts. reply UIUC_06 4 hours agorootparentI've heard of them. I'd hate to have to explain that to my insurance inspector after a house fire, though. reply joezydeco 3 hours agorootparentThankfully these miniature outdoor pizza ovens are taking some of the thrill away from the firestarters. reply decafninja 20 hours agorootparentprevI lost a ton of weight during the initial Covid lockdowns of 2020 without even trying. The only difference? I ate home cooked meals while WFH. They weren’t even made to be specifically healthy or with the objective of losing weight. Then I jumped ship for a company that was 100% in office. I started eating the supposedly healthy meals catered by the company for lunch. Dinner also came later because commute time. I gained back all the weight I lost WFH and then some. The significant amount of walking and/or biking from the commute did nothing to help. reply m463 21 hours agorootparentprev...but you could just get a suana and use it 4-7 days a week for 20 min > 174 F, which reduces risk of all-cause mortality 66% and come out 17% ahead! :) I suspect portion size and number of dishes with homecooked food. In a restaurant, adding appetizers, side dishes and desserts can be done with a nod. At home, it will take a lot of work to add each dish. But yeah, if you do apples:apples I think restaurants are paid to make things tasty - with salt, cheese, cream, butter, oil. And then with more of those. (also, I wonder how restaurant review eating compares to supersize me) reply glinkot 13 hours agorootparentYour side comment about saunas got me searching. It's quite amazing (though based on small populations) - I'll be giving this a try, thanks for pointing it out! https://www.mayoclinicproceedings.org/article/S0025-6196(18)... reply fuzztester 21 hours agorootparentprev>salt, cheese, cream, butter, oil. there is a famous cooking book with a name close to that. ;) reply m463 21 hours agorootparentadd chocolate and get the perfect click ^H^H^H^H cookbait. reply fuzztester 20 hours agorootparentno, I meant an actual famous cookbook. I read about it on hn, actually. it's called something like fat, acid, salt and heat. you can Google it. reply fuzztester 15 hours agorootparent>I read about it on hn, actually. you know, like here: https://hn.algolia.com/?q=salt+fat+acid+heat reply standardUser 19 hours agorootparentprevWhere are you people eating that you feel gross? And what are you ordering? I promise you, eating out does not and should not need to be anything like you are describing. reply throwaway2037 17 hours agorootparentprevI hear this \"cheap oil\" thing a lot in food pseudo-science Internet writing. What exactly is \"cheap oil\"? And, is there any peer reviewed evidence for your claims about how you feel after eating \"cheap oil\"? If this effect is so drastic, then, surely, it must affect others, and would be an interesting and worthy research topic. reply ghaff 17 hours agorootparentI guess it's generic vegetable oil as opposed to Canola oil or Peanut oil? I'd actually suspect that a mindset of buy whatever oil is cheapest from Sysco would pursue cheapness in other areas as well including kitchen supervision/skills. reply lobsterthief 6 hours agorootparentI wouldn’t suspect that at all—some recipes (like certain kinds of “street food” from different countries actually call for the use of cheaper oils :) reply ghaff 5 hours agorootparentI doubt it makes any appreciable difference anyway most of the time although Canola oil and Peanut oil do have a slightly higher smoke point than vegetable oil. reply analog31 21 hours agoparentprevSince my mom moved to town, we've been eating at her place frequently. She uses a lot of recipes from the NY Times. They are heavy. Lots of butter, cheese, coconut milk, etc. We've asked my mom to cut those things in half. She's a very good cook, and the things she improvises or makes from memory are much lighter fare. I learned to cook from her, so my meals tend to be fairly light too. Sure, the fat and salt (and don't forget sugar) are yummy, but they'll kill you. There needs to be a compromise. An amusing aside, Julia Child said that it's perfectly honorable to be a home cook and not a chef. Making stuff that's good but healthy is an art unto itself, especially if you're feeding vegetarians. reply xanderlewis 16 hours agorootparent> She uses a lot of recipes from the NY Times. They are heavy. There’s a good chocolate chip cookie recipe from the NYT that I’ve used several times. Not only is it heavy, I’ve had to halve the ingredients and even then it still produces enough to satiate the Cookie Monster for probably at least a month. As a Brit, I also had to convert all of the measurements (patent absurdities like ‘cups of butter’, ‘tablespoons of chocolate’, etc.) to grams — taking account of the variation in density, of course. reply analog31 16 hours agorootparentSome of the measurements are aided by how the ingredients are packaged. For instance, butter is sold by the pound, in boxes of 4 \"sticks\" that are marked as being 1/4 cup each, which ignores the density variation but is familiar to every home cook. Chocolate comes in \"squares\" that are some predictable amount. In fact some recipes call for squares. \"A pint's a pound the world around\" is a workable rule of thumb for a lot of things, but of course you need to know when greater precision is needed. Since I don't bake sweets very often, I measure most things by eyeball. For instance my bread recipe is based on filling a glass measuring cup nearly to the top, above where the volume markings end. Maybe it's a reaction to spending my day designing precision measuring equipment. But yeah, it's a hodgepodge of archaic units, and quite unnerving if you hail from the metric world. reply Symbiote 6 hours agorootparentSince you're replying to a Brit, I'll point out the irony that > \"A pint's a pound the world around\" only applies to the American meaning of \"world\", i.e. the USA and maybe Canada. \"A pint of water weighs a pound and a quarter,\" when it's an Imperial pint. reply xanderlewis 16 hours agorootparentprevIf it was at least all in cups, it’d be somewhat more forgivable. I’ve even seen recipes using amounts of flour measured in a combination of cups and tablespoons! Actually, maybe that doesn’t sound as mad to everyone as it does to me… Anyway, it makes more sense hearing that sticks of butter are labelled in cups. I didn’t know that! In the UK, butter comes in 250g blocks. reply bigstrat2003 14 hours agorootparentSticks of butter are also labeled in tablespoons here. One stick is 1/2c, and the paper it is wrapped in also has markings for 1-8 tbsp. So it's pretty common to see that in US recipes as well. As far as flour goes, it's incredibly common to have both cups and measuring spoons in a US kitchen. So if a recipe says \"1 cup and 2 tablespoons\" or something, it's really easy to measure that. By contrast, I hate recipes which use weight measurements. It takes a ton of faffing about to get exactly 300g (or whatever weight) of flour weighed out. Add a bit... watch scale... add a bit more... watch scale ad nauseam. And then I often wind up overshooting anyways, so then I have to try to scoop some back out! Whereas with volume measurements I just dip a cup/spoon in, level it off, and I'm done in a couple of seconds. reply Symbiote 6 hours agorootparentFor similar accuracy to what you have with cups and spoons, you don't need to bother making the measurement exactly 300g. A relative was a professional cook. Butter wrappers are also marked with measurements here, at 25g intervals. That would be accepted for some recipes, but the butter would be measured more carefully when making certain pastries or cakes. reply rightbyte 10 hours agorootparentprevWhen doing sensitive receips like some breads you need gram level accuracy to get the right result. The density vary too much. reply analog31 16 hours agorootparentprevYeah, especially since the density of flour varies. All the home bakers I know either weigh their flour, or eyeball it like I do and live with the imprecision. I'd just let the flour mound over the top of the cup by a bit to make up for the tablespoons. ;-) reply bigstrat2003 14 hours agorootparentAgreed - eyeballing it (or volume measurement for that matter) is good enough for the vast majority of baking recipes. I have made some finicky recipes in my day, but generally you will not need the precision of measuring by weight. For some reason people online hype up how exact you \"need\" to be when baking, but it's just not true. Hilariously, people also act like you can just completely wing it with no precision at all when cooking on the stove, and that also isn't true. Both forms of cooking benefit from some measurements and consistency, but you don't have to go too crazy with it. reply UIUC_06 13 hours agorootparentprev> live with the imprecision Exactly that. In a restaurant, you're really pressured to make it the same each time. At home: Who cares? It's good that it's different every time. reply bigstrat2003 13 hours agorootparentI hate it when my cooking comes out different every time. Reproducible results are super important even at home, imo. reply ghaff 15 hours agorootparentprevA scale's cheap and if it's in a situation where accuracy matters, I use it if the measurements are given or consult a standard conversion. And as someone in the US I tend to use grams for the purpose to avoid faffing with a combination of units. And I don't even mind at all using US Imperial for many things on a day-to-day basis, reply alvarlagerlof 4 hours agorootparentprevWhat's a pound though? Not so global. reply nradov 14 hours agorootparentprevTo a first approximation, fat won't kill you. There's no reliable evidence that a diet relatively higher in fat causes worse health outcomes, as long as you maintain energy balance. Salt won't kill you either, unless you're genetically susceptible to hypertension and don't drink enough water. The sugar is more problematic. reply imp0cat 13 hours agorootparentprevHalving is a neat trick. In my experience you can usually safely halve the amount of sugar in most cake recipes and still get a great cake that is sweet enough. reply ghaff 5 hours agorootparentIt can't do it with everything but sugar is probably the thing I'm most inclined to go \"Nah, that's too much\" in recipes. (Often, online, I'll see what people say in the comments too.) reply paulpauper 22 hours agoparentprevThis is why eating out is so bad if you're on a diet. Too much oil and fat, sugar, salt, fat, and other stuff reply matwood 22 hours agorootparentI disagree. If we're talking about restaurants and not fast food, it's portion size that's typically the issue in the US. Oddly enough, the higher end restaurants start to move in the other direction and shrink portion sizes. reply fuzztester 21 hours agorootparent>I disagree. If we're talking about restaurants and not fast food, it's portion size that's typically the issue in the US. i think you are right. i have always seen big portion sizes in restaurants when i have gone to the US. also, very recently, i saw a youtube video in which a french person says the same thing. they said that even though the French eat a lot of fat, their overall portion sizes are smaller than those of the US. so overall, they end up eating less calories than US people. also the French tend to walk a lot, while the US people tend to drive a lot. it's a generalization, i know. reply UIUC_06 21 hours agorootparentMy own impression from a week in Paris is that you're right: if you get the \"menu\" at most restaurants (appetizer, entree, dessert), you walk out full but not stuffed. The weight-loss drugs like Ozempic, supposedly make you feel like that. I haven't taken them myself. It's like you don't really want any more. Americans seem to feel entitled to two meals for the price of one, and they may or may not eat them both in the restaurant. (If they don't finish, they take the rest home with them) reply fuzztester 14 hours agorootparent>Americans seem to feel entitled to two meals for the price of one, and they may or may not eat them both in the restaurant. (If they don't finish, they take the rest home with them) yes, when my parents used to go to the US, a few decades ago, they told us kids about this practice called using doggie bags. apparently people used to ask for the uneaten part of their restaurant orders to be packed in what was called a doggy bag, under the euphemism that they were taking the extra food home for their dog. I don't know whether the practice is still followed. reply ghaff 5 hours agorootparentI don't think the term is all that common today in the US. But, counter my pervious comment (though I hadn't been active that day and it was quite hot), a few of us were having dinner and most of us took something home (for us, not a dog)--and I just had a starter! Considered quite normal. Good food but there was just a lot of it and I didn't have much of an appetite. I do know a few places that are sort of known for having portion sizes that are oriented towards people taking leftovers home. reply bigstrat2003 14 hours agorootparentprevI don't know that anyone has ever used \"doggy bag\" to mean/imply an actual bag for dogs in my lifetime (I'm 39), but yes it's still common to get the rest of your food in a container to take home. These days your waiter/waitress will usually ask \"do you want a box\" instead of referring to a doggy bag, but everyone knows what you mean if you ask for a doggy bag. reply xarope 13 hours agorootparentprevIf my trips to the cheesecake factory are any indication, then yes, too much food, and let's doggy bag the rest of the yummy. reply fuzztester 20 hours agorootparentprevI searched just now in my YouTube downloads and found the video I was referring to above: https://youtu.be/9QyQmL-mlV0 The French Paradox: How rich food and wine could help you stay healthy60 Minutes Australia I submitted it as an HN post here, in case anyone would like to discuss it: https://news.ycombinator.com/item?id=40980964 See: https://en.m.wikipedia.org/wiki/French_paradox reply ghaff 18 hours agorootparentprevIt is a generalization but maybe I know it's because there's often a lot of relative filler in entrees and I often gravitate towards one or two starters/apps. That said I mostly don't find portions in Europe (including France) to be especially small. reply fuzztester 14 hours agorootparentInteresting ... I guess it varies between restaurants, and everyone is talking based on their own experience. apps? reply ghaff 7 hours agorootparentAppetizers. In my experience the term is fairly common in the US. I think some of it is that many restaurants have a lot of fairly inexpensive filler (potatoes, rice, etc.) with entrees that I probably sort of tune out and don't really try to finish a lot of the time. This is probably less true of some countries/cuisines than others. reply foobarian 22 hours agorootparentprevI feel like restaurants really have an unfair advantage there as far as flavor goes. Whenever I try to make something following a recipe, I balk at the amount of butter/sugar/oils/salt and cut way down or leave them out entirely, with predictable results. With a restaurant this is completely abstracted away so it's easier to get past. reply more_corn 21 hours agorootparentprevOr if you have health problems or want to not have health problems. Restaurant food has 3-5x as much salt as you should be eating. reply elliottcarlson 17 hours agoprevLast spring, I was at my friends new at the time restaurant, when he let me know that Pete Wells was at the table behind us (and how important this night was for my friend) -- I noticed the sheer amount of food - pretty much the entire menu - that was coming and going from that table. I didn't even put it in to perspective how demanding that was on the body, since all I could think of was how I wish I had his job tasting amazing food all the time. The review came out a few weeks later, and it was a pretty nice review - took quite some time before reservations were obtainable again. reply spyspy 16 hours agoparentWells has said he often dines with multiple people in order to be able to try multiple things on the menu. of course The Times is picking up the tab. I guess being a restaurant reviewer is like owning a boat - it’s tough on you but your friends love it. reply ghaff 15 hours agoprevI'd also comment that, in general, even though I've had jobs with tenures that many HN readers would consider ridiculously long, I mostly settled into the decade +/- space outside of a couple (of short) \"events\" outliers. Even with making some changes along the way sometimes, that ended up my been-there/done-that range. Obviously people are different but that has been my experience. reply AstroJetson 22 hours agoprevI miss Caity and Rich at Gawker, they indeed had the best reviews. https://www.gawkerarchives.com/the-best-restaurant-in-new-yo... Here in the Philly area we have a guy doing cheesesteaks. https://www.philadelphiacheesesteakadventure.com/ reply rwmj 22 hours agoprevGiles Coren (The Times of London restaurant reviewer) said that he reckoned he gained 1 ounce for every meal he reviewed. reply crispyambulance 22 hours agoprevYeah, I think anyone who travels a lot for work very quickly realizes that restaurant food eaten everyday, if you're not careful, will very rapidly put pounds on you. Now with Wells' article we know how much worse it becomes if that's your job too. As Anthony Bourdain wrote... \"In a good restaurant, what this all adds up to is that you could be putting away almost a stick of butter with every meal.\" He's not exaggerating! reply ghaff 18 hours agoparentWhen eating out a lot is your job (including eating out at places you wouldn't naturally have gravitated towards), like many things it becomes work. I eat out when on vacation and business trips and really don't want to cook even if the hotel has a kitchenette. I also rarely go out at home to eat unless it's to attend an event or to socialize. When I was an analyst I definitely gained weight until I developed the discipline to not eat the three meals a day (plus also snack breaks) just because they were there and often good. reply paulpauper 22 hours agoparentprevfat tastes good...who knew reply vander_elst 14 hours agoprevIf everyone in the business knows your face isn't the review going to be skewed? Shouldn't the reviewers strive for anonymity? reply ghaff 5 hours agoparentThe top ones often do. But it isn't necessarily very effective at a top restaurant or even a popular local one. reply S_Bear 21 hours agoprevThat would be a rough ride for your health. I remember back when Adam Richman was doing the original run of Man vs Food and he was looking like death towards the end. reply moate 19 hours agoparentI mean, that wasn't a show about \"food\" or \"restaurants\" it was about gluttonous, over-the top food \"challenges\". Unless you were doing an equally extreme amount of work to counteract those meals, a season would absolutely destroy someone. I see all the pearl clutching comments about how bad eating at restaurants is (former restaurant chef, I'm extremely biased and refused to be moved), but an over the top entree coming in at 1500 calories isn't even close to a 7 pound burrito IMO. reply blackeyeblitzar 21 hours agoprevCouldn’t the negative effects of 4 rich meals a week be countered by eating healthier the rest of the time and having a consistent exercise routine? reply pixl97 15 hours agoparentExercise burns far less calories than most people think, add a travel lifestyle to it and you'll never burn those calories. reply mrbombastic 3 hours agorootparent\"You can't outrun your fork\" - I think a good thing for people to do when trying to get healthy is eat a donut and then run on the treadmill for the equivalent amount of calories you just ingested. Hammers home it is a lot easier to just not eat the donut. reply stvltvs 20 hours agoparentprevOne big cheat meal per week can undo a lot of work. It's easy to blow through a entire day's worth of calories and macros at one sitting let alone four! reply omoikane 18 hours agoparentprevAlternatively, maybe New York Times should spread the job among 4 people so that each individual only needs to eat one rich meal per week. reply paulpauper 22 hours agoprevI am up to the challenge of trying to be a food critic, but without gaining weight. I would review food once every 3 days and do a lot of cardio and eat les on the off days. reply cm2012 22 hours agoprevJust start on semaglutides, and eat in smaller portions like the women critics he describes in the article do. I think quitting a good critic job for your health is pretty silly when there are modern workarounds that mostly solve the issue. reply paulpauper 22 hours agoparenthow would that work? the job is to eat the food reply cm2012 22 hours agorootparentThe author literally described how women food writers keep their health while writing food columns - they taste the dishes but don't eat the whole plate. He doesn't say this makes women worse food writers at all. He could just copy this strategy. If he doesn't have the will for it, semaglutides would make it really easy. You still enjoy and taste food the same on it, you just get full quicker. So there is an easy solution to his problem. reply pbj1968 19 hours agorootparentSemaglutide is not a drug taken casually. Speak from experience on this one. :-/ reply solveit 17 hours agorootparentWhat went wrong? reply pbj1968 15 hours agorootparentComplete indifference to food and water that led to fainting and probable heat stroke. Extreme nausea. All mitigated now with medication and forced hydration. Not fun. reply hoseja 10 hours agorootparentDoesn't sound too serious. reply UIUC_06 21 hours agorootparentprevNo, the job is to rate the restaurant for the readers. A reasonable portion can be enough for that. reply laweijfmvo 19 hours agoprev [–] This is the guy that trashed Guy Fieri's restaurant, right? Guy Fieri (and his restaurants') style might not be for everyone, but he's such a sweetheart and does so much for small businesses, not to mention firefighters etc., that you have to be pretty cold to do that. Still makes me mad. reply otterley 19 hours agoparent [–] It is possible both to be a saint and serve terrible food. A food critic isn’t supposed to give you a handicap for being a nice guy. reply laweijfmvo 18 hours agorootparent [–] the food isn’t terrible, it’s just gimmicky. and 90% of the people going to Guy Fieri’s _want_ a trash can full of nachos. reply bigstrat2003 14 hours agorootparent [–] Eh, I think it's like media reviews. Everyone is entitled to their own opinion, and a lot of times what professional critics think has nothing in common with what the average person actually wants. The high end restaurant world is much like the professional art world in that it gets really pretentious and out of touch. It just is what it is. reply ghaff 5 hours agorootparent [–] I mostly don't go out of my way to eat at top restaurants (as opposed to good ones that are more midrange). Don't get me wrong; I've had some really good meals. But I think I'd find it all a bit exhausting as a regular routine. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Pete Wells, after 12 years as The New York Times restaurant critic, is stepping down due to health concerns, including high cholesterol, blood sugar, and hypertension.",
      "Despite the rewarding nature of his role, the physical toll of frequent restaurant visits has become unsustainable for Wells.",
      "Wells will remain at The Times but will no longer handle the demands of weekly reviews, choosing instead to focus on his health and a more balanced lifestyle."
    ],
    "commentSummary": [
      "A long-time restaurant reviewer is stepping down after 12 years, sparking discussions about his impact and the future of restaurant reviews.",
      "The reviewer was known for his diverse restaurant choices and his unique, sometimes standoffish, approach to reviews.",
      "The announcement has generated excitement for the incoming reviewer, Mellissa Clark, and reflections on the experiences of those in the restaurant industry."
    ],
    "points": 133,
    "commentCount": 164,
    "retryCount": 0,
    "time": 1721158414
  },
  {
    "id": 40982011,
    "title": "Introduction to Bash Scripting",
    "originLink": "https://github.com/bobbyiliev/introduction-to-bash-scripting",
    "originBody": "💡 Introduction to Bash Scripting This is an open-source introduction to Bash scripting guide/ebook that will help you learn the basics of Bash scripting and start writing awesome Bash scripts that will help you automate your daily SysOps, DevOps, and Dev tasks. No matter if you are a DevOps/SysOps engineer, developer, or just a Linux enthusiast, you can use Bash scripts to combine different Linux commands and automate boring and repetitive daily tasks, so that you can focus on more productive and fun things. The guide is suitable for anyone working as a developer, system administrator, or a DevOps engineer and wants to learn the basics of Bash scripting. 🚀 Download To download a copy of the ebook use one of the following links: Dark mode Light mode ePub 📘 Chapters The first 13 chapters would be purely focused on getting some solid Bash scripting foundations then the rest of the chapters would give you some real life examples and scripts. About the book Introduction to Bash scripting Bash Structure Bash Hello World Bash Variables Bash User Input Bash Comments Bash Arguments Bash Arrays Bash Conditional Expressions Bash Conditionals Bash Loops Bash Functions Debugging, testing and shortcuts Creating custom bash commands Write your first Bash script Creating an interactive menu in Bash Executing BASH scripts on Multiple Remote Servers Work with JSON in BASH using jq Working with Cloudflare API with Bash BASH Script parser to Summarize Your NGINX and Apache Access Logs Sending emails with Bash and SSMTP Bash Password Generator Redirection in Bash Wrap Up 🌟 Sponsors This book is made possible thanks to these fantastic companies! 📊 Materialize The Streaming Database for Real-time Analytics. Materialize is a reactive database that delivers incremental view updates. Materialize helps developers easily build with streaming data using standard SQL. 💙 DigitalOcean DigitalOcean is a cloud services platform delivering the simplicity developers love and businesses trust to run production applications at scale. It provides highly available, secure, and scalable compute, storage, and networking solutions that help developers build great software faster. Founded in 2012 with offices in New York and Cambridge, MA, DigitalOcean offers transparent and affordable pricing, an elegant user interface, and one of the largest libraries of open source resources available. For more information, please visit https://www.digitalocean.com or follow @digitalocean on Twitter. If you are new to DigitalOcean, you can get a free $100 credit and spin up your own servers via this referral link here: Free $100 Credit For DigitalOcean 👩💻 DevDojo The DevDojo is a resource to learn all things web development and web design. Learn on your lunch break or wake up and enjoy a cup of coffee with us to learn something new. Join this developer community, and we can all learn together, build together, and grow together. Join DevDojo For more information, please visit https://www.devdojo.com or follow @thedevdojo on Twitter. 🕸 Web Page A web page showcasing the eBook: Introduction to Bash Scripting Web Page The web page was built using Tails, a new kick-ass drag-and-drop TailwindCSS page builder! DigitalOcean App Platform The website is hosted on the DigitalOcean App Platform. We utilize the \"Deploy to DigitalOcean\" Button to deploy to the App Platform: 📹 Mini Video Course If you prefer watching videos rather than reading, you can find a quick crash course based on the first 12 chapters of the eBook here: Introduction to Bash Scripting Mini Video Crash Course 💻 Interactive training You can follow the interactive training online here: Introduction to Bash Scripting Interactive training The training was built with Katacoda. You can find the Katacoda repository here. For more information on how to use Katacoda make sure to follow the steps from this tutorial here: How to Use Katacoda to Create Highly Engaging Training Tutorials 👋 About the author My name is Bobby Iliev, and I have been working as a Linux DevOps Engineer since 2014. I am an avid Linux lover and supporter of the open-source movement philosophy. I am always doing that which I cannot do in order that I may learn how to do it, and I believe in sharing knowledge. I think it's essential always to keep professional and surround yourself with good people, work hard, and be nice to everyone. You have to perform at a consistently higher level than others. That's the mark of a true professional. For more information, please visit my blog at https://bobbyiliev.com, follow me on Twitter @bobbyiliev_ and YouTube. In case that you want to support me you can Buy Me a Coffee here: 🔥 PDF Generation Tool The project uses Ibis developed by Mohamed Said. Ibis is a PHP tool that helps you write eBooks in markdown. 🎨 Book Cover The cover for this ebook was created with Canva.com. If you ever need to create a graphic, poster, invitation, logo, presentation – or anything that looks good — give Canva a go. 🔗 Links My blog Free $100 Credit For DigitalOcean Join DevDojo Ibis Canva Tails Katacoda 📖 Other eBooks Introduction to Git and GitHub eBook Introduction to SQL Laravel tips and tricks 🤲 Contributing If you are contributing 🍿 please read the contributing file before submitting your pull requests.",
    "commentLink": "https://news.ycombinator.com/item?id=40982011",
    "commentBody": "Introduction to Bash Scripting (github.com/bobbyiliev)109 points by RafelMri 16 hours agohidepastfavorite95 comments tjoff 13 hours agoA lot of people suggests python, I'd argue that python is a bad fit for what many bash scripts does. A bash script is basically scripting what you do on your terminal. I feel like scripting in the same language that is your terminal interface is underrated. You can basically take a look at your command history and wrap it up as a script. Yes, bash is clunky as hell. It has some really ugly warts. But learning the basics will make you more proficient in the terminal. The synergies are really nice. reply lloeki 11 hours agoparentInteresting that a lot of the (general, not specifically here) commentary is \"don't use bash, use python\" which I find quite clunky, noisy, and boilerplatey to do the same thing as a shell script. Kinda Master Foo and the Ten Thousand Lines†. Ruby's https://github.com/ruby/shell (which used to be bundled in Ruby itself) doesn't get much mention but is much more clear and useful to me. # system commands are not defined by default, only builtins, for safety Shell.def_system_command 'ls' Shell.def_system_command 'grep' Shell.def_system_command 'jq' Shell.new.transact do # simple redirs just work lsgrep('test') > 'some/file' lsgrep('other')tee('foo') >> 'some/file' # pops at the end of the block cd 'some/dir' do # nested redir for demo (cat 200 lines (500 if I'm brave), choose Python Otherwise, shell scripting is nice reply qz_kb 14 hours agoprevUsing python and constraining yourself to only use a basic subset of the standard library modules so you can run the script in pretty much any environment is almost always a better choice than trying to write even one loop, if statement, or argument parser in a bash script. bash script is \"okay\" I guess if your \"script\" is just a series of commands with no control flow. reply mazambazz 13 hours agoparentHard disagree. I've written plenty in both. They both have their strengths, but bash is just more efficient if you're working with the filesystem. The UNIX philosophy of \"do one thing and do it well\" shines here. Python is more powerful but it's a double-edged sword. If I want to read a file containing API endpoints, send a request to them for some JSON, and do some parsing, I don't want to need or want to deal with importing modules, opening file objects, using dictionaries, methods, functions, etc. Why do that when I can literally just ``` N=0 while read -r URL; do curl \"$URL\"jq '.data[].someProp'grep -v \"filter\" > \"$N.data\" N=\"$((N+1))\" doneThat's really not that hard to add above. Then show how it is going to look like? reply ryapric 11 hours agorootparentOn mobile so no idea if this a) looks good or b) runs (especially considering the command substitutions, but you could also redirect to temp files instead), but it's just something like this: N=0 while read -r URL; do data=\"$(curl \"$URL\")\" || { printf 'error fetching data' && exit 1 ; } prop=\"$(jq '.data[].someProp'\"$N.data\" || { printf 'error searching for filter text' && exit 1 ; } N=\"$((N+1))\" done\"$N.data\" N=\"$((N+1))\" doneWhy do that when I can literally just ``` N=0 while read -r URL; do curl \"$URL\"jq '.data[].someProp'grep -v \"filter\" > \"$N.data\" N=\"$((N+1))\" doneI had a small script (50-100 lines) to format a data drive on boot I refactored, 3 or 4 obvious undeclared variables and who knows how many more I didn't notice - mypy found 0 issues. What does pyright/pylance say? reply macrael 13 hours agorootparentprevuse mypy! reply cinntaile 13 hours agorootparent> mypy found 0 issues It didn't help him. Which is a bit strange? reply ok_dad 11 hours agorootparentTo make mypy strict enough to compare your dev experience to a typed language, you have to declare all sorts of configurations, otherwise there are huge swaths of things it’ll allow compared to most typed languages. I use below, and only when necessary use ignore comment pragmas when third party libraries are not typed. #? message format settings show_column_numbers = true show_error_codes = true #? strictness settings disallow_any_unimported = true disallow_any_expr = true disallow_any_decorated = true disallow_any_explicit = true disallow_any_generics = true disallow_subclassing_any = true disallow_untyped_calls = true disallow_untyped_defs = true disallow_incomplete_defs = true disallow_untyped_decorators = true no_implicit_optional = true warn_redundant_casts = true warn_unused_ignores = true warn_return_any = true warn_unreachable = true strict_equality = true strict = true reply udev4096 13 hours agoparentprevBash is native. You won't find python pre-installed on all distros, like alpine reply hi_hi 12 hours agorootparentBash may be native, but alot of the programs you'll want to call may not be, or will differ between platforms in subtle ways. Although this won't be a concern for small/trivial scripts, but if we're talking about python as an alternative, my point probably still applies. reply a-french-anon 10 hours agorootparentThis. People using bash extensions and util-linux as if they're standard are my bane. If you can't do it in POSIX (sh and utilities) and don't want to do an extensive investigation of portability for what you need, pony up for Python/Tcl/Perl (all in MacOS base, by the way). reply lloeki 11 hours agorootparentprev> You won't find python pre-installed on all distros, like alpine The same can be said of bash, especially since you mention Alpine (also FreeBSD) Perl, though... ;) (if Perl is not there it gets pulled in very quickly as a dependency of something, e.g typically you pull git, you get perl) reply yawpitch 13 hours agorootparentprevTrue, though there’s a whole world of people who will yell at you for using Bash-isms rather than pure posix precisely because Bash (at least up to date versions) isn’t everywhere either. reply runjake 13 hours agoparentprevAs a person who’s been doing shell programming for 35 years and Python for 15 years, I completely disagree. Bash scripts and Bash control flow has been and is used in highly critical scripts all over the place, including other planets. We’ve been writing reliable, well-designed scripts for many decades. Some of my scripts are several hundred lines long and older than the system engineers currently occupying their positions. Python is fine too. Use the right tool for the right job. reply NegativeLatency 13 hours agoparentprevHad decent luck using chatgpt to translate some crufty old bash deploy scripts to python reply guappa 13 hours agoparentprev> Using python and constraining yourself to only use a basic subset of the standard library modules Used to be a viable strategy until they started to drop modules from the standard library at every single release. reply yawpitch 13 hours agorootparent> Used to be a viable strategy until they started to drop modules from the standard library at every single release. That’s a bit of a ridiculous statement, there’s a small number of very-long deprecated modules removed in 3.12, and some more recently deprecated modules in 3.13. And these things are old, largely or completely unmaintained, and usually complete obsolete. I’d be surprised if anyone has a script that’s been adversely effected by this, and if they did it’s because they stopped maintaining it years ago (and also chose to both silence warnings and upgrade interpreter versions without reading the release notes). reply guappa 12 hours agorootparent> largely or completely unmaintained Consider that the python foundation absolutely has the resources to put a developer to maintain them. If they don't is because they don't want to. > and usually complete obsolete The amount of modules I've had to patch to keep working on 3.12 tells me they aren't as obscure and unused as you think they are. > I’d be surprised if anyone has a script that’s been adversely effected by this I'd say that over 99.9999% of python users do not download python from python.org. They use whatever is on their system. Which means that updating an LTS distribution will create mayhem. And that's considering that most modules have already been patched by the distribution maintainers to fix all the brokenness introduced by the new python version. Also, a bash script from 30 years ago still works fine. A python script from 5 years ago doesn't start. reply yawpitch 6 hours agorootparent>Consider that the python foundation absolutely has the resources to put a developer to maintain them. The resources to pay someone doesn’t mean that someone with interest and knowledge exists, especially for modules that were formally deprecated in Python 2 and which will never be reinstated. Lots of this stuff is just cruft, most of which has an obvious replacement, and if it doesn’t there’s a decent chance it’s not been used in years by anyone and if it ever had a reason to be in the standard lib, that reason is long gone. > The amount of modules I've had to patch to keep working on 3.12 tells me they aren't as obscure and unused as you think they are. If that number is at all significant, where are the issues pushing back against deprecation and removal? It’s not like there hasn’t been a formal process for all these modules. What got deleted in 3.12 was well documented and easily caught just by catching DeprecationWarning… anyone getting surprised by these modules going missing isn’t doing due diligence. > I'd say that over 99.9999% of python users do not download python from python.org. They use whatever is on their system. Which means that updating an LTS distribution will create mayhem. And I’ll pretty much guarantee you that 99.9999% of those users haven’t heard of, much less imported, any of the modules that have been removed. > And that's considering that most modules have already been patched by the distribution maintainers to fix all the brokenness introduced by the new python version. But again where are the issues and hands being waved that these issues are wide-spread enough to halt or reverse the deprecation process? If distro maintainers are simply patching everything for users who are constantly advised to leave their system Python alone and they’re not reporting the issues then those distro maintainers are harming everyone. > Also, a bash script from 30 years ago still works fine. A python script from 5 years ago doesn't start. I’ve written plenty of Python scripts that are still running on the interpreter and stdlib they were authored for, decades later. I’m also keenly aware that most of those scripts could not be written in Bash without reimplementing a significant portion of the Python standard lib and ecosystem, none of which was materially affected by the 3.11>3.12 removals. reply isbvhodnvemrwvn 13 hours agoparentprevI would agree if python dependency management wasn't a dumpster fire. reply rendaw 13 hours agorootparentI think the point GP was making was that you restrict yourself to only the bundled standard library, which covers most of the basics needed for scripting. reply qz_kb 13 hours agorootparentprevThis is why you force yourself to use nearly zero dependencies. The standard library sys, os, subprocess, and argparse modules should be all you need to do all the fancy stuff you might try with bash, and have extremely high compatibility with any python3.x install. reply guappa 12 hours agorootparentprevAnd it's a dumpster fire because they refuse to make any decision and decide which is the supported way. Instead they removed distutils, so now there is no way to install any module without using a 3rd party installer. reply xlii 13 hours agoprevRecently I’ve been exploring back Perl. I loved it many years ago and today I just need “glue”. It seems to be quite fast, can escape UNIX-Linux idiosyncrasies and I still can see all the magic variables in the code after those years. Maybe it’s better to just get back into Perl instead of figuring out how to pipe back to back to few applications and jq on top? reply kamaal 4 hours agoparentIf you are using Bash, you probably need to use Perl. Python unfortunately doesn't shine where Perl is good at. Mostly of the command line work involves passing around adhoc text, parsing and using it. You are better off using a language designed to do that very task than use something else. reply baxuz 13 hours agoprevTried https://github.com/google/zx and never looked back. reply vwkd 1 hour agoparentHow about dax[^1] which is cross-platform and also works with Deno? [^1]: https://github.com/dsherret/dax reply pindab0ter 10 hours agoparentprevThat's not available on basically every system. What advantages does zx have over Python, Ruby or even Fish for example, if we're installing extra programming languages? reply baxuz 3 hours agorootparentIt's what fits my use case quite well. reply alwinaugustin 13 hours agoprevI am new to bash and always struck at using the tools like `awk` and `sed.` You need to be good at regular expressions to write a good script using these tools. reply asicsp 14 hours agoprevSee also https://mywiki.wooledge.org/BashGuide and https://github.com/denysdovhan/bash-handbook. https://www.shellcheck.net/ is amazing to spot pitfalls. See my list https://learnbyexample.github.io/curated_resources/linux_cli... for learning resources for CLI tools, scripting, etc. reply jimmar 14 hours agoprevI've coded in a bunch of languages over my career, but somehow managed not to use bash. But a few weeks ago I found myself needing to create a somewhat involved script using Bash. Using GitHub Copilot, I was able to generate a script that worked great and it included comments, arrays, arguments, case statements, loops, conditionals, menus, etc--basically covering the first dozen chapters of this book. I guess my point is that we need to teach people what's possible and to help them explain what they want clearly. Memorizing syntax will be a less relevant skill at some point. reply guappa 12 hours agoparentI haven't seen your script but I bet it will break in a hundreds corner cases. reply pronoiac 12 hours agoprevI recently was running a variety of compressors over the course of days, and using Bash was great because, it doesn't parse the whole file before it starts running - I could edit and reprioritize next steps while the script was running. \"Oh, that one's not working, skip the slower version\" or \"oh, space is an issue, work on freeing that up.\" It's a weird hack I wouldn't suggest in production, but it worked well for me. reply bobbyiliev 9 hours agoprevMany people are saying that ChatGPT or Copilot could write great scripts which is indeed true, but the eBook was written way before those LLMs were a thing. It is still good to learn the basics though. reply TheLoafOfBread 13 hours agoprevOr you can use PowerShell - Available on MacOS, Windows, Linux instead of suffering through incoherent syntax of Bash. reply ayakang31415 13 hours agoprevIs there anything Bash does that Python can't do? I feel like using Python is just way better than using Bash. reply wpm 13 hours agoparentWork out of the box on any macOS/Linux computer. reply ayakang31415 13 hours agorootparentYou use Bash for that not because it is better, but because UNIX related binaries are configured in Bash. reply cassianoleal 6 hours agoparentprevIs there anything Python does that Bash can't do? There are many reasons to use either. Probably about as many as there are to use the other. Choose wisely. reply udev4096 13 hours agoprevIf anyone's looking to write tests for bash scripts, I wrote a small blog post few weeks ago: https://hcrypt.net/test.html reply callalex 15 hours agoprevCan someone name me examples of where a bash script is actually the _correct_ tool for the job in modern times? Or is it still used only because it’s the easily available tool? reply patmcc 13 hours agoparentThere's a server. You can ssh into it, but you don't have root. You don't know if it'll have python (2 or 3), perl, ruby, node, whatever. You need to write a cronjob that'll run every 5 minutes, or a script that'll do something on-demand, or just a one-off to clean some stuff up or grab particular log files or something. Performance isn't going to be a problem. User input isn't going to be a problem. If you never run into this problem, fair enough, maybe you don't need bash. A lot of us do. reply NegativeLatency 13 hours agorootparentI've used linux brew a couple of times to escape this problem, able to get a newer version of python or ruby instead of bash: https://docs.brew.sh/Homebrew-on-Linux reply jofer 15 hours agoparentprevAny time you're running lots of CLI utilities directly is a good start. Bash is very very good for that, and other than perl, most other things aren't particularly good at it. reply lambdaba 14 hours agorootparentRuby is the greatest at it and inline deps make it perfect for scripting. reply jcranmer 14 hours agorootparentprevUnless you need to run programs with arguments with spaces in their name. Not that long ago, I needed to write a script that would grab the last command in a shell file that had a list of commands, add an argument or two to it, and run it. Which proceeded to barf because the command had quotes, for some of the arguments had necessary spaces in them, and I couldn't figure out the way to get the necessary string in a way that bash could properly execute the command. My eventual solution was to just use python's shlex module to parse the line and output an executable command (and remark that I should have just started the script in Python in the first place)... reply PhilipRoman 14 hours agorootparent>Unless you need to run programs with arguments with spaces in their name. It does that just fine, I don't have all the details obviously but it sounds like printf %q or ${arg@Q} is your friend here. reply jcranmer 1 hour agorootparentI have a variable, say $X, that contains a command, and the command has quoted arguments with spaces, let's say >. Now how do I execute it? If I do $X, the result >, not >. If I do \"$X\", it fails, because there's no filename > to execute. In a program with proper arrays, I can instead parse X to the strings [\"echo\", \"A B\"], and then run execve to run [\"echo\", \"A B\"] without any issues. And adding another argument to make [\"echo\", \"A B\", \"C\"] is damn trivial. No, bash doesn't handle arguments with spaces just fine. If you do the basic, obvious way to do things, things break, and you're expected to know magic invocations to do the right thing to handle potential spaces. reply wiseowise 11 hours agorootparentprev> ${arg@Q} Right, how couldn’t they know to type actual gibberish to make it work. reply PhilipRoman 2 hours agorootparentGoogle \"bash escape string\", click on first result? It mentions both of these options btw. It's not like it's any easier with python, if I'm new to the language I have to look up shlex anyway. reply voidfunc 14 hours agoparentprevAlmost never but there's a lot of folks that have gaslit themselves into believing \"its the right tool for the job\". There's no requirement that a shell language suck as much as bash. reply yjftsjthsd-h 14 hours agoparentprevShell is good for running a bunch of other programs and doing file operations. In that niche it seems unbeatable, and outside that niche it's generally a terrible choice. reply citizen_friend 14 hours agoparentprevIts always a great tool if you need to automate a computer task. reply macrael 13 hours agoprevWrite scripts in whatever tooling you have setup for your app. In a typescript codebase, I write typescript scripts. In a go codebase I write go scripts. It's so easy to write a couple wrappers to make execing something a one liner and then the advantages of bash have disappeared. You already have a toolchain for running a program in your language, just use that to build your scripts. reply 1vuio0pswjnm7 9 hours agoprevBash is not a good shell for scripting. Too big and slow. reply foreigner 12 hours agoprevDebating the pros and cons of different languages misses the point IMO. Shell scripts are useful not because of the language but because the interpreter is already available absolutely everywhere. reply ngcc_hk 8 hours agoprevBash scripting is hard ... missing a space or add a space ... How do you debug it and trace it ... I do use it as said this is the terminal command line and both Mac/Linux supported it. And if it works, it work even nohup. Just hard. reply jofer 15 hours agoprevFor anyone wondering whether or not you really need to know bash: Yes. Yes, you do. Somewhere in the middle of every stack is a bunch of bash and makefiles. Don't replace that or avoid it. Embrace it. It's not perfect, but it's important to know. reply benreesman 14 hours agoparentSome things change: you once needed Perl where you now need Python. Other things don’t: you need non-trivial bash. I don’t mind if people do their heavy lifting in VSCode, I like the tool myself. But if you can’t unfuck the little daemon that VSCode talks to? You’re out of commission. You’re at the mercy of people who can. reply almostgotcaught 15 hours agoparentprevI love when people proclaim this as if it's some kind of sage wisdom when it's actually just hypermyopia. For anyone wondering whether this is true: of course it's not since there are plenty of stacks that don't run in environments that are anywhere near a shell. reply jofer 15 hours agorootparentCan you seriously name something other than very low level embedded software that doesn't involve shell at some level? I certainly can't... reply almostgotcaught 14 hours agorootparentDo you think your phone runs a shell for IPC? Like passes strings to and fro? How about the runtimes/hypervisors/etc that manage vcpus on AWS? And about that embedded dev - do you think that that's a small niche industry? reply yjftsjthsd-h 14 hours agorootparentI'm pretty sure Android has a bunch of shell under the hood, and I don't have a jailbroken iOS device to check but I'd be a little surprised if it was different. AWS may or may not, I don't know enough to comment. And yes, about embedded dev - there's the very very low level stuff of course, but the moment you get above tiny microcontrollers it's all Linux again and there's shell everywhere. Actually, even for the really tiny embedded stuff I'd still expect to find a mess of shell scripts, just in the build environment rather than on-device. reply almostgotcaught 14 hours agorootparent> I'm pretty sure Android has a bunch of shell under the hood I didn't claim there was no shell - I claimed that IPC isn't performed with pipes. reply yjftsjthsd-h 14 hours agorootparentAnd the kernel also doesn't run shell, but the claim was that you would struggle to find > software that doesn't involve shell at some level which would seem to me to encompass more of the stack. Like... okay, Android IPC isn't pipe-based. Does that release anyone from touching shell? Anyone working on a ROM is going to get their hands dirty with the rest of the OS. And I struggle to believe that any app developer is avoiding it (it's always the build step that does you in). Approximately nobody is working on just IPC in isolation. reply almostgotcaught 14 hours agorootparent> it's always the build step that does you in Just curious: where exactly is the shell in `cmake -GNinja`? Or is CMake not a build system hmmm? Nevermind that some people use bazel or meson or something ... other than shell... Shell scripts in your build system are a code smell. In cpp projects it's covering up for people that don't how to use the actually correct tool for the job: the CMake scripting language. reply yjftsjthsd-h 13 hours agorootparent> Just curious: where exactly is the shell in `cmake -GNinja`? Or is CMake not a build system hmmm? Nevermind that some people use bazel or meson or something ... other than shell... Right above it; cmake replaces make, but something still runs it. And IME that something is usually either a developer running it from a shell (ideally eventually with another shell command wrapping it to automatically build on file changes) or a CI system running it which is always a massive pile of shell scripts. To be fair, I don't doubt that if you really tried you could build a dev environment that used zero shell. But you would have to really try, and half of the things you had to build to make it work would inevitably converge to an informally-specified, bug-ridden, slow implementation of half of Common Lisp^w^wBASH. reply wiseowise 11 hours agorootparentprev> In cpp projects it's covering up for people that don't how to use the actually correct tool for the job: the CMake scripting language. That’s like saying that people use lotion because they don’t know how to correctly jerk off with sandpaper. Bash is ubiquitous and can be used everywhere, CMake scripting language can be used only in CMake, guess how many people know one better than the other? reply almostgotcaught 5 hours agorootparent> Bash is ubiquitous and can be used everywhere Sorry I wasn't aware bash added task graph features in some release? reply jofer 14 hours agorootparentprevShell pops up in a ton of places even where it's not used directly. Build systems are a good example. I have yet to come across something that doesn't touch shell at some level unless it also doesn't touch an OS. But maybe that's just me. Phones aren't an exception to that, though. reply wiseowise 11 hours agorootparentprevThose things might not run bash/sh, but I’m willing to bet a hundred quid that nearly all of their development environments had at least one tiny shell script that did some transformation of data. reply wpm 14 hours agorootparentprevWhether they run in environments where a shell is nearby has no bearing on whether they are built or tested in environments where a shell is near and sufficient for the task. reply almostgotcaught 14 hours agorootparentPasting what I responded to the other person talking about build systems: Just curious: where exactly is the shell in `cmake -GNinja`? Or is CMake not a build system hmmm? Nevermind that some people use bazel or meson or something ... other than shell... Shell scripts in your build system are a code smell. In cpp projects it's covering up for people that don't how to use the actually correct tool for the job: the CMake scripting language. reply udev4096 15 hours agoprevThis looks extremely basic. I would instead recommend reading https://bash.academy or TLDP Advance Bash Scripting Guide reply imp0cat 14 hours agoparentThat's a good thing, isn't it? It's not too scary for someone who's not well versed in shell scripting. And you can later move on to other resources (TLDP is great!). reply rty32 14 hours agoprev [–] I know basic bash and can read most bash scripts, but never spent much time on it to become an expert. However I found ChatGPT to be extremely valuable -- given the description of a task, it can create very high quality scripts with best practice and comments, often correctly using third party tools. That's probably what I'll do going forward -- my time is better spent creating a good prompt and reviewing output. reply dools 14 hours agoparentSame, and another great thing I have been using since ChatGPT made it trivial to do so is systemd. I was using pm2 quite a bit for running scripts but high quality bash (or python or php or whatever really) plus systemd is really killer. I’ve also been doing way more with google cloud shell. I was always such a point and click guy when it came to setting stuff up in GCP but automating and scripting with bash in cloud shell using ChatGPT is so much faster and repeatable. reply TechDebtDevin 13 hours agoparentprevI'm pretty sure most llms have very low eval scores on bash compared to other common languages. reply rty32 6 hours agorootparentWell, from what I can see ChatGPT can already write much better bash scripts than I do, so... reply DonHopkins 11 hours agorootparentprevAnd most humans have MUCH MUCH lower eval scores on bash, yet they write it anyway, and the rest of us get stuck with trying to use and understand and debug and maintain that crap, that bursts into fire and explosive diarrhea whenever it hits and edge condition or file name with a space in it. reply wpm 14 hours agoparentprev [–] Depends on the platform. macOS has a terminal and ChatGPT is highly Linux biased, and it's quite happy to spew trash when you point out \"hey bozo I said macOS useradd isn't a real command on macOS\". reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "An open-source guide/ebook on Bash scripting has been released, aimed at automating tasks for developers, system administrators, and DevOps engineers.",
      "The ebook covers a wide range of topics from basic Bash structure to advanced scripting techniques, including working with APIs and generating passwords.",
      "Additional resources include a mini video course, interactive training via Katacoda, and contributions from the Linux DevOps Engineer, Bobby Iliev."
    ],
    "commentSummary": [
      "Bash scripting is often compared to Python for terminal tasks, with Bash being more efficient for filesystem operations and simple command sequences due to its native terminal integration.",
      "Critics highlight Python's complexity for basic tasks and Bash's clunky syntax, but Bash remains essential in environments without Python pre-installed.",
      "Alternatives like Ruby's shell or Perl for text parsing exist, and tools like ChatGPT can assist in script generation, but understanding Bash basics is still valuable."
    ],
    "points": 109,
    "commentCount": 95,
    "retryCount": 0,
    "time": 1721182562
  },
  {
    "id": 40983717,
    "title": "Return-to-Office Mandates Aren't Worth the Talent Risks",
    "originLink": "https://www.gartner.com/en/articles/the-data-is-in-return-to-office-mandates-aren-t-worth-the-talent-risks",
    "originBody": "Gartner.com To ensure a secure connection and verify you're human, please complete the validation process, if prompted. 8a4c7c0b38353ae7",
    "commentLink": "https://news.ycombinator.com/item?id=40983717",
    "commentBody": "Return-to-Office Mandates Aren't Worth the Talent Risks (gartner.com)102 points by alexzeitler 10 hours agohidepastfavorite106 comments hibikir 9 hours agoIt's like anything else that makes the job worse: The people that are first to leave are those with the best alternatives elsewhere, which are often your strongest workers. When some of those leave, your workplace becomes worse for anyone learning from them, which can cause a domino effect. It doesn't matter what it is that makes the job worse: You either provide counterbalancing incentives to your best workers (see retention bonuses after an acquisition) or you are gambling reply valleyjo 9 hours agoparentpersonally I go to the office every day even though I have a long commute. I hate working from home. Mandates for RTO don’t universally make the job worse. Of course I acknowledge it does for some people but not everyone. reply coldpie 8 hours agorootparentI also hate WFH and go in every day even though my company allows full WFH, but RTO mandates suck. The WFH option means the only people who come in, are the people who want to be there. It makes the experience much more pleasant (and less crowded!). I think it'd be nice if more people chose to come in, and I support making changes so more people choose to do that (travel compensation, free child care, more private offices & cubes). But a mandate only makes it worse for everyone. reply Aeolun 4 hours agorootparentBeing in the office is only nice if it’s not crowded. Having 40-50% occupancy is the sweet spot for me. Any higher and I’ll autocorrect to working from home. reply saagarjha 8 hours agorootparentprevThey absolutely do, because they're mandates. If you want to work from the office you are more than welcome to do so, and nobody here is telling you to stop doing that. reply jprete 8 hours agorootparentWorking from the office gets more useful when more people do it, because of easier communication with teammates, so mandates can absolutely make the work environment better for someone who wants to work in the office. reply HPsquared 8 hours agorootparentNot worth the cost. If I want to talk to someone I'll screen share, it's better than going to their desk anyway. reply PillCosby 4 hours agorootparentprev” easier communication with teammates\" for some people this is true. reply willcipriano 8 hours agorootparentprevI wouldn't hire someone who wants to work in a office if they gave me this explanation, sounds like they really lean on the other team members to get day to day work done and probably struggle working independently. reply dt3ft 7 hours agorootparentprevDo you have small kids? Do you not like spending more time with them? reply vel0city 6 hours agorootparentI do and I do. I also don't like having to crush them over and over every day saying \"not now, daddy has work...\" Going into the office means I'm gone when I'm working, but when I'm with them I'm 100% with them. Days I do work from home and they're not in school can be rough for them. Also, while I'm lucky enough to afford a whole room of my home as an office two little kids can still end up being quite loud and interruptive. It's nice having a dedicated space to have some quiet on my work schedule. Plus, free gym for exercise, free tea/coffee, free AC/electricity, there's a free bike share if I drive in and want to ride through the nature preserve near the office or to the restaurants or other parks nearby, meetings in person when we're all right near each other seem easier, free car charging, etc. There's a lot of amenities in the office for me as well. My commute is only like 2mi from home. It's a 15 minute bike ride. It's not like I'm spending a ton of time and money commuting. If there's something important for me to go to in regards of the kids it's not like I have to hop out for over an hour; the pediatrician is like 10min from the office, the library is closer than that, their school is across the street from the library, etc. I get not everyone has great amenities, I understand some people have like half-hour commutes or worse. Everyone has their own math to do on if coming in is good or not. But it's not like having kids is instantly a remote work is better. reply 10u152 6 hours agorootparentprevI’m not the person you’re replying to but I do. And absolutely yes, I do. When I work from the office I’m gone longer (maybe 1.5 hours a day) but I’m significantly more present when I’m at home. If I WFH I’ll spend the evening ducking back into my home office to send that email or check that document etc and my mind will be 50% thinking about work all evening. I like a hard cutoff, when I’m home my phone goes off and I’m 100% there for dinner, bath and story time. reply thunky 6 hours agorootparent> If I WFH I’ll spend the evening ducking back into my home office to send that email or check that document etc and my mind will be 50% thinking about work all evening If you can resist checking emails after your commute I'm sure that with some self discipline you could also do it without the commute. You're basically admitting that there is no good reason or expectation for you to be working after hours anyway. reply vel0city 6 hours agorootparentIt's a state of mind thing, and I can easily fall into the same thing. When I predominantly work at the office, I can kind of compartmentalize my working mindset to that place. When I leave, I'm done, finished, checked out. Laptop closed, in a bag (or even left at the office). It takes actual effort to return to that state. When my office is just another room in the house, it's far easier to be stuck in that work mindset. The computer is all set up, it's just a quick password away to getting back exactly where you were when working. It's easy for me to think about a problem I was working on and easily slip back into it. Not so if I need to go grab my backpack, clear off a space for the work computer, hop back on, etc. During COVID I was in a small apartment. My office was my living room. It felt like I was just always in the office, always working, never at home. reply thunky 5 hours agorootparent> When my office is just another room in the house, it's far easier to be stuck in that work mindset. I can see how this can happen, but at the same time it seems like there's such an easy fix: just stop doing it. But it may actually be a form of addiction, so maybe eaiser said than done. I could probably say the same thing about someone who wants to quit smoking but can't. People that smoke typically enjoy smoking, though, so they probably don't actually want to give it up, they only try to stop because they know it's bad for them. This may be the case here as well: maybe you have a hard time disconnecting from work because you actually want to work. I'm WFH and I have absolutely zero problem flipping the switch at the end of the day, notifications off, done. I didn't sign up to work nights and weekends and it's not something I want to do, so I'm simply not going to do it (unless it's an emergency). reply coldpie 5 hours agorootparentGood for you? I also struggle with work/home boundaries when I have to WFH. \"Oh, I should go kick off that build so it's ready in the morning... oh, there's an email... oh, someone had a question for me...\" If I leave all my equipment at the office, then it's simply not an option for me to do work outside work hours. It's a system that works well for me, there's no problem to \"fix\" here. reply vel0city 4 hours agorootparentprev> an easy fix: just stop doing it > it may actually be a form of addiction For me it absolutely is. It is pretty much telling a drug addict \"just say no.\" I get a lot of enjoyment out of many parts of my work. It gives me a lot of pleasure fixing some REST endpoint or optimizing some problem. Given the opportunity my mind will just keep chewing on the problem at all hours of the day when it is a problem I like. It is a dopamine rush to get that thing working. And since its work, there's actual deadlines and what not, real customers waiting, so even though I mentally know I shouldn't let those things affect me personally, emotionally it is harder for me to step away especially when I'm literally sitting in the same chair at the same desk with the same keyboard and mouse I'd use to solve those problems instead of tinker on my own projects that are far more nebulous. In the end with my office at home set up primarily for work, personal projects take a back seat. With work at the company office, my work setup stays primarily there. My desk at home is free to be littered with my halfway done projects. Breadboards, soldering irons, all the various parts I'm toying with, etc. can take up the whole space. When I get home, that's my space, not their space. > you actually want to work Yes, I actually do enjoy what I do most days of the week. There's always the overhead and paperwork and what not that isn't the fun parts, but actually digging in to solve a problem is one of my favorite things to do whether that be at a datacenter or in the cloud or on a car or motorcycle or plumbing or an embedded device or a radio or whatever. Getting paid to be able to work on cool problems is practically gravy on top for me. And FWIW, it also cuts the other way at times when I WFH. Sometimes my mind wanders and starts thinking about the personal projects at home. Let me go check on this thing, maybe I could just slip out and spend a few minutes trying to dial in the new irrigation controller, I probably need to check the chemical levels in the pool, that glue on the rocking chair repair is probably dry now let me move that along, I should really look into that leak on the wet bar drain, it'll only take a minute...suddenly it is an hour later. reply Aeolun 3 hours agorootparentprev> it seems like there's such an easy fix: just stop doing it. If it was such an easy fix you wouldn’t be having this discussion about them going into the office I imagine. For what it’s worth, I completely relate. If computer is sitting in the place I’ve just been working from the whole day then I’ll walk by and automatically start again. reply danielbln 9 hours agorootparentprevYour comment would be more informative if you were to actually tell why you hate working from home, what about the office makes it worth the long commute etc. reply xyx0826 8 hours agorootparentMy job involves 60% writing software and 40% testing with hardware. I work about 5% of my days from home, when I’m sick or have other obligations. I don’t have the space, time or incentive to set up a home office in the place I live. This unfortunately means all the stuff around me become distractions. I find it harder to sustain long work sessions at home. I miss having quick chats with coworkers by their desk. Sometimes I hit an issue and all I need is a 30-second talk with the dev 2 aisles over. And it’s mutual: I find these quick chats great for helping folks out and keeping myself in the loop. Instant messaging is not an adequate substitute. And lastly this is tied to my work and company policies but usually I can only access test hardware at the office, due to logistics or confidentiality. reply pjc50 8 hours agorootparentprevPlenty of people don't have good spaces to work at home and it's actually quieter at their office. Of course, there's also people in the other direction. reply skirge 9 hours agoparentprevbut if strongest don't interact with juniors you will also loose in long term reply orwin 9 hours agorootparentI don't mind people pushing for RTO that much. What I do mind is people pushing for RTO for 'mentorship reasons' in an freaking open space with the noise it implies. I would not mind full RTO in a shared office, with possibility to isolate for 1 on 1 code reviews/pair programming. Also I'm the definition of a mid-level dev, but i'm the only one pushing for more communication and shared time, organizing remote tea breaks, pair programming sessions, weekly code review and bimonthly 'formation' where we can show off skills or domain specific knowledge to others. I feel that now that I have enough seniority to propose that regularly, we are a better team, and better for juniors/interns, even if we are even less in the office than we used to be. reply shinycode 9 hours agorootparentprevWe use gather.town at work, although irl work is the best, I never talked as much to coworkers in my life. We can share screen and code easily, we ALL have an office space to be alone, to work together or to have meetings. It’s the best version of work I have ever had. Employees are recruited on the criteria of being able to work remotely, without pain and with communication skills but for us it works really great. Working in an open space all my life before has been the worst experience ever. Constant distractions, people talking around, phone ringing, ANR headphones mandatory (and not paid by the employer) etc reply HPsquared 8 hours agorootparentThis has been my experience with remote working in general (not specifically gather town). I've interacted with more people since remote working, including those in other offices, clients etc. It's been a massive boost to the amount of contact I've had. I can go on webcam as much as I want too, without it being an issue like in an open office. reply KeplerBoy 8 hours agorootparentprevDamn this gather.town looks ridiculously cool. I'd apply for jobs advertising this just to experience it. reply shinycode 8 hours agorootparentIt’s a game changer for me, always an office available for myself or a meeting, async check if someone is available in its office or is in a meeting, when you move into someone’s office the camera and mic shows up (if activated) and cuts of when leaving the office. I wasn’t sure at first but it really gives a feeling of a real office and works great. I prefer it to coming at a real office, more convenient and no 3D gives a nice light sensation reply OJFord 9 hours agorootparentprevRemote working does not mean interactionless working. reply dave4420 9 hours agorootparentprevAdd mentoring to the list of things that need to be done more explicitly in a distributed environment than in an office environment. reply DrBazza 8 hours agorootparentprevIt depends. Many global open source development projects are very, very, successful. There's no office there. If anything, a fully remote set of developers should encourage a significant uplift in information transfer via design and documentation. Walking across the office and asking 'the guru' how X works, means there's little incentive to share that knowledge, simplify the code, and document it. And that's a problem that has existed in most companies forever. \"Juniors\" should be self-starters, and the 'interaction' is often and frequent code reviews. reply tmottabr 9 hours agorootparentprevi work in a company that has people in the team spread all around the world.. strongest does not need to be in the same physical location as the juniors to interact with then, and that has being the case for decades already, it only got easier over time.. reply benterix 8 hours agorootparentprevYeah, I hear this mantra a lot, and since I have been WFH for over a decade, it makes zero sense to me. * Juniors need help in a structured, systematic way, which is not dependent on who is or is not in the office. * If a team member (no matter if it's junior, new, or just anybody needing help with their ticket) can not receive help and has to fight with his task alone, you have a management problem, not WFH/RTO problem * In my humble experience, collaboration online is much better than in open-plan offices where you either disturb your colleagues by loud talk or need to find some private room (good luck with that) that is usually smaller than a farm animal's cell and gets uncomfortable after 15 minutes. * The whole discussion is moot because if you force RTO you will lose seniors, so who will do this whole mentorship? reply piva00 7 hours agorootparentprevI usually pair up with the juniors to help them, or share knowledge, or bring them onboard to a task they can drive later on. I work with people in 4 different continents, in Europe my team is spread around 4 different countries. We manage to interact, remotely. I do not understand why people think being interactions require an office together, there are other ways to foster interactions, it's a culture. If the culture is bad remotely then it's also bad in office, just in different ways, the only thing a remote team loses is the ability of poking someone else's shoulder which is generally good, you don't want interruptions. You want people to have enough slack in their work that they can be called upon for pairing or helping with something. If everyone is so busy remotely that they don't interact anymore then in-person you'd be having issues with frustration from senior devs being interrupt to help juniors. It's the same issue, just presenting itself to the surface in a different way... reply systemtest 9 hours agoprevA local company has started an experiment with the 4 day workweek, as the first big company in the country to do so. However 3 of those days are to be spent in the office. There is a dress code. And you need to be passionate, they aren't to looking for a 9-5 mentality. Office parties and company outings aren't mandatory but if you intend to never visit them, you probably aren't a good fit for the company. Hard pass. reply benterix 8 hours agoparentIt sounds like a terrible place to work. I will choose 5-day WFH over 4-day in open-plan office without hesitating for a second. reply systemtest 7 hours agorootparentThe dress code alone (company polo with an embroidered logo to be worn in the office and during online meetings) would make me pick working 5 days over 4 days, with the same pay. For reasons beyond my comprehension they are number one on the \"Best Workplaces Europe 2023\" list in the 500+ employees category. reply fnordian_slip 6 hours agorootparentMight one of the reasons be that these things are easily gamed? And maybe another one, that such workplaces by their nature select employees who would describe themselves as \"driven, work-hard-play-hard 10x programmers not looking for a 9-5\", and who upper management would probably describe as \"suckers\", at least behind closed doors? You know, the ones that believe that worker's rights and unions only benefit low-performers, and not alphas like themselves. reply pavel_lishin 4 hours agorootparentprevLeaving good reviews is also \"not mandatory\", but... reply mjburgess 9 hours agoparentprevSounds like a 6 day work-week. reply exsomet 5 hours agoprevA company I used to work for during the pandemic (before becoming a founder) was very very deep into the culture wars of RTO mandates. They had a cycle of HR making big sweeping proclamations, followed by leadership (a group I was part of) spending 2-3 months trying to corral the raging employee anthill it created, settling into a norm of no one really doing it, and then a few months later HR would decree RTO and start the cycle all over again. It was hugely frustrating and disruptive to a workforce that, at the engineering level, really just wanted to do good work they could be satisfied with and live their lives outside of that. The overwhelming sense that I had was just confusion. It was a company who’s entire overcomplicated and wildly over engineered business essentially ground down to running a very niche and specific service for our clients. They spent _so much_ time focusing on RTO chaos and changing internal systems, reorgs, reworking processes, moving and consolidating branches; things that are NOT “run this service for our customers”. I am always just baffled at the amount of attention this type of thing gets from companies. As a now-owner, my feeling is that you should care about exactly one thing: doing $YOURS_BUSINESS more so that customers give you money. Anything that distracts from that is something that deserves the minimum amount of attention you can give it to be dealt with before getting back to your core business of doing the thing you’re good at so people give you money. RTO mandates (note: not working in office as I recognize some people’s preference for that, but the mandate) are so hugely distracting and bear such an enormous cost in talent, finances, productivity - it touches every area of the business in a negative way. I will never understand how some people can justify it to themselves, not because of some moral argument or anything but just because of the distraction and cost it causes. But, it was the final push I needed to go do my own thing, and that’s a very happy new norm for me. So maybe I should be thanking them? reply datavirtue 5 hours agoparentSounds like typical bike shedding. They have severe culture problems and they are runninh down every comfortable path to address them, unsuccessfully. I was in a lunch with our CEO where he told us about all the issues he is trying to address related to generational shifts and succession. While trying to explain that we need to be attractive to generation Z and Millennials he insults them (with some in the room) with littany of stereotypes lifted straight from articles he read on the internet. Dude is clueless, and he knows it and is just trying stuff to keep the board happy until he can cash out. reply kibbi 8 hours agoprevI prefer to work intensely and collaboratively in an office. This is how I'd do it: Three in-office days, same weekdays for everyone (e.g. Monday to Wednesday). The choice to have a 5-day or 4-day week. An energetic, quietly humming work atmosphere, with incidental information sharing and a spirit of collaboration, with colleagues present and nearby, sounds best for me personally. Among other advantages, the presence of coworkers helps me focus. Different strokes for different folks. Obviously, the prerequisite is that it's a team of nice people you like being around. Sure, people who prefer to work from home would leave that company. That doesn't mean that this company will lack talent. People who do want to work like that will join it. reply DrBazza 8 hours agoprevI'm far more productive in my own quiet and distraction free office than I ever was in a corporate office, even when I had my own there. Open-door policies suck, as do open-plan cubicles. I spent 30 years with a lengthy city commute like many people. There is no way I am ever returning to the office for anything more than a day a month. \"Will my train turn up?\" \"Will my train be on time?\" \"Will I get home in time for my kids sports game?\" \"Will I be standing for an hour?\" All mentally draining. The quality of life improvement for employees, especially mentally, benefits employers as well. reply shrimp_emoji 4 hours agoparentDon't forget the best part: your own executive bathroom. I.e., your home bathroom. reply DrBazza 1 hour agorootparentHaha! Yes. And my own kitchen that no one leaves in a complete mess or steals my snacks. reply baq 9 hours agoprevtranslation: 'Layoffs performed via RTO suffer from adverse selection' reply bell-cot 9 hours agoparentBut if I can get rid of most of the stupid over-paid prima donnas, then expenses will be cut even further, and I'll be able to ...reply Rinzler89 9 hours agoparentprevTl;Dr: if you force RTO and other such measures, you'll be left with the lowest performing employees since the best have better employment options and will jump ship to where they get the work conditions they're looking for reply artemonster 9 hours agorootparentI just WISH this class of decision makers would really understand this. But knowing how stupid, stubborn and out of touch with reality most ppl from mid-upper mgmt up to CEOs can be, I see no hope. Enshittification of home office and hybrid policies are inevitable :( reply HPsquared 8 hours agorootparentAll the skilled workers that leave, go to somewhere else. Those places improve. It's not all downward. reply foinker 7 hours agoprevCEOs, VCs, and other managers do not give one flying fuck about talented people leaving. When talented people leave, they're replaced with cheaper people who can do decent enough work that the quality of the end product doesn't noticeably suffer. Come to think of it, they also don't really give a fuck if the quality of the end product suffers. reply Mashimo 9 hours agoprevI don't understand the first table. \"Factors that contribute to Lower Intent to Stay at Job: Average Employees: -8% Intent to stay\" https://emt.gartnerweb.com/ngw/globalassets/en/articles/imag... Wat? That factor \"Intent to stay\" contributes to the intent to stay by -8%? reply geraldwhen 9 hours agoparentIgnore the bad title. The first column is a factor, like being a manager, a millennial, or a woman. The final column is intent to stay reduction given a RTO mandate. So for all groups, intent to stay is lowered with a RTO mandate. Some groups are more affected than others, or claim to be. reply akira2501 9 hours agoprevGive managers an \"offsite worker budget.\" Let them have some % of their staff outside the office. reply beardyw 9 hours agoprevHas anyone studied what drives RTO? reply benterix 9 hours agoparentI don't believe a CEO giving an honest answer in such a study and saying, say, (1) they enjoy the feeling of power and having tighter control over their subjects or (2) they just follow their gut feeling in spite the lack of any studies that RTO gives positive net results for the company. reply datavirtue 5 hours agorootparentI just learned that our CEO owns our building and the company rents it from him. This secret knowledge was just given to me because I'm in the club. I immediately stated that information should be common knowledge for every ESOP member. No one was interested in that. reply artemonster 9 hours agorootparentprevAlso paying for half empty office space must be constantly bugging all the beancounting „optimizers“ reply wiether 8 hours agorootparentI worked for a few weeks in a company where coming to office was mandatory. Given the job we were doing, it didn't make sense. Until I learned that the boss was owning the building personally and was renting it to the company. Seen this way, it was much clearer why they wanted to have people in, instead of downsizing or just not having offices at all. reply blitzar 8 hours agorootparentprevReal estate costs to 0, variable costs including electricity, heating, cooling to 0, health and safety, workplace insurance, cleaning, catering, security and other cost centre's all gone. It's a beancounting optimisers wet dream. reply benterix 3 hours agorootparentI believe in these people's minds they lose something if they have a small office. Feeling of prestige - that we are this huge company taking up 6 buildings? Hard to point it down, but for some reason they stubbornly want to pay for these office spaces... reply tmottabr 5 hours agorootparentprevthen downsize your offices.. It is what the company i work for did.. They were already friendly with remote work before, i for instance have worked fully remote for over 10 years already. Before the pandemic they had space problem in their San Francisco office, if you were not in the office at least 3 times per week you were at risk of loosing your desk space. During pandemic when everyone was forced to go full remote and performance was not impacted they just moved to a much smaller office space and kept everyone remote. reply lkdfjlkdfjlg 9 hours agorootparentprevGood optimizers will not react to half empty office space by pushing for RTO. They'll react by pushing for smaller office. So the problem that you pointed out isn't optimization as a concept, it's dumb people. reply wsc981 8 hours agoparentprevI believe most managers think employees are more likely to slack at home. And I do feel in many cases this feeling is justified (though of course people can also slack on the job). Though, I do know for myself I am very productive at home. So, I personally will avoid working from some office. I prefer to manage my own time and also be flexible in how I divide time in my day. I also don't feel energized by working with many colleagues (as an introvert, it's quite the opposite for me, actually). reply artyom 9 hours agoparentprevIt's a long term social class game to drive salaries back to the pre crypto/pandemic era. RTO is coupled with big layoffs, hiring freezes, etc. It may not impact highest performers that much but makes it worse for everyone. Big players play the game, the rest just imitates. reply HPsquared 8 hours agorootparentThat doesn't make much sense though, I'm sure a lot of people would happily WFH for less pay than if they have to commute, spend all day in a noisy open office, etc. reply artyom 8 hours agorootparentLess pay for doing exactly what you're already doing? How would that work? reply HPsquared 6 hours agorootparentWFH involves doing less. You don't have to spend 1-2 hours a day, plus expenses, commuting - and having to have an expensive house near the office. reply tmottabr 5 hours agorootparentexcept we are not getting paid to commute, we are expected to commute to do the work we are getting paid for. If we were paid to commute to the office then our commute time would be part of the work day. But I am paid for the work i do during work hours and if i have to commute that is expected to happen out of work hours. So actually the Company is already saving money by having me remote, so now i am also expected to get paid less for doing the same work while also saving the company money? reply HPsquared 5 hours agorootparentPay is compensation for the inconvenience of having to work. An easier day needs less compensation to feel okay with. Just from the subjective view of the employee. reply artyom 4 hours agorootparentNone of this rethorical back and forth about commuting is denying that the class move exists, aims exactly at what we're discussing, is driven by the big players through obvious cartelization, and so far, it's working as expected. reply tmottabr 4 hours agorootparentprevWhat? Since when?? Pay is compensation for work done. Not having to commute does not affect the company at all, they still get the same amount of work done and it is still have the same value to then so i can assure you that the work i do did not became less valuable to the company just because i did not spend hours of my personal time moving to the office and back. Pay should either stay the same or, ideally, it should go up because while they are saving money by me not going to the office, i on the other hand have extra costs because i have to get good internet, will use my electricity for doing the work. Where i work not only pay did not get lowered when the team moved to fully remote, they actually pay us extra to cover costs of working from home. They also offer a one-time pay to cover the costs or assembling your home office so you can buy stuff you need like desk, chair, printer, etc when you change to remote or when you are hired as remote. reply HPsquared 4 hours agorootparentI'm just giving my personal opinion, I'm sure shared by some people, that I'd actually accept less pay for a WFH job. Or, in other words, if they want me to work in an office they'd have to pay more. reply tmottabr 4 hours agorootparentIf i am looking for a job and had to choose between a remote work paying less over a in-office job paying more.. I would also get the remote job even if it paid less.. But in my opinion this mindset is the wrong one when you already have a job and is changing to remote. If you already have a job that the company already evaluated the value of and agree on a fair pay.. Then moving to work remote does not change the value of your work to the company while changing the costs the company have.. Where i live they cannot legally lower an employee pay, but if they could and had done when i changed to work remotely i would surely have accepted, but i would also start looking for work elsewhere. But i know they have not done it in countries they could have and like i said, they pay us extra to cover internet and utilities. reply TheCapeGreek 9 hours agoparentprevI agree with others that I don't think most CEOs are going to give truthful answers in such a study. The way I see it: For many there's just a preference/productivity boost for working in-person. That's fine, remote is not for everyone. However my hunch is that if decision-making management is mostly comprised of older millenials and gen X, they're just habitually used to working in-person and refuse to change. Then you can go into the darker reasons: Ego around owning an office space and then having to use it, \"fairness\" (read: superiority complex) against workers getting the same perks as managers, inability to work in a remote (read: digital first) culture, easy way to get rid of people without paying layoff severance. reply Zanfa 8 hours agoparentprevI doubt most CEOs have ulterior motives other than just wanting things to go back to “normal”. People generally don’t like change. reply surgical_fire 8 hours agoparentprevThe managerial class finds is icky that the lower castes suddenly have a benefit that was exclusive to them. reply theandrewbailey 7 hours agoparentprevFollow the money. My conspiracy theory: executives are the kinds of people that could have a lot of money invested into commercial real estate. The value of which has seen a massive hit in the past few years (and is at risk of a 2008-style collapse), because fewer people traffic those properties, and thus, fewer businesses rent them. In order to counter those forces, they mandate that everyone in their company return to office in order to prop up the value of their portfolios. reply valleyjo 9 hours agoparentprevIf you have a geographically centralized team (I.e everyone is in the same city) it makes sense to me to have the team be together at least one day a week. If you’re by yourself in a company office then RTO mandates makes no sense to me. reply lkdfjlkdfjlg 9 hours agorootparent> If you have a geographically centralized team (I.e everyone is in the same city) it makes sense to me to have the team be together at least one day a week Wanna expand on that? Why does that \"make sense\"? reply pjc50 8 hours agorootparentIn-person collaboration has real benefits for some situations. Team cohesion is not a totally made up thing. So, if it's reasonably cheap, such as everyone in the same city, it's worth getting the team together regularly. Some distributed organizations strive to bring even international teams together from time to time, even if it's just once a year. reply tmottabr 5 hours agorootparentthe company that i work for has several people in the same city or close enough that we can go meet at the office, yet i completely disagre with this take. If collaboration is beneficial in some situation then in office meetings should happen with a situation that would benefit from this collaboration arise. If the need is not there then there is no point. In my team we go to the office once a month mostly for social interaction, it is usually the day we are lest productive because we basically drink coffee and catch up and even then it is open if you have other personal needs to participate remotely or not at all, we had months were there wasn't anyone in the office and we just meet virtually. I have not gone into the office yet this year myself for a number of reasons. I still collaborate constantly with my team mates, we have enough tools for remote collaboration that make being physically in the same space irrelevant, this also allow collaboration to extend the team members in other countries so i am not limited to the people that live close by. reply benterix 8 hours agorootparentprevThe whole point of this discussion is that decisions based on somebody's opinions but applied to everybody give poor results. In this case, if you forced \"office Mondays\", you would lose several seniors. The question is, is the net result worth it? You can be convinced it is, but without hard data it's meaningless. (I work for an international corporation and we have hybrid meetings once a year but it never works 100% in person because people work from different continents, it would make no sense.) reply dt3ft 7 hours agoparentprevMy guess: the danger that WFH is making managers irrelevant. reply azemetre 6 hours agorootparentThat would be a boon to the company tho, because they can cut off more dead weight and lower OpEx. I think it’s more basic. Many cities rely on business/commercial real estate taxes to generate funds. Many of these governments also give tax incentives if businesses are working in the city. If the companies aren’t doing this they lose out. Most cities cannot make up the loss of funds through residential taxes so the pressure of RTO can help ease it. Boston is a good example of this, residential property taxes are quite low but the city has a hard time making up the difference with the loss of commercial property taxes. So there was a big push to get companies to RTO. It’ll probably take a good 20 years before city governments are able to adapt, hopefully that means more mixed use buildings in the city core like Chicago (commercial store first level, condos/apartments above it) rather than why you commonly see across US cities (entire buildings dedicated to business). reply datavirtue 4 hours agorootparentprevThey are a lot of times. Society is hovering it's finger over the \"everyone is a contractor\" button. Employment is a holdover construct of subjugation. reply lkdfjlkdfjlg 9 hours agoparentprevThis is what I'd really like to know. What really REALLY is behind managers/executives pushing for RTO. My theory so far is that they believe that employees working from home take advantage of decreased supervision to slack. Now on HN you'll read \"doesn't matter that I'm working fewer hours if I'm delivering work\". But I think managers/executives fear they're not very good at assessing how much tasks are meant to take. If a task is mean to take 1 day and I take 3 days and I explain why it took me longer, some times it's really difficult to assess whether the explanation is true or I'm BSing. (Of course, they don't admit this. They use their own BS to justify RTO. Enhanced collaboration or whatever.) Bottom line, managers/executives don't know how much output they can realistically expect, but they suspect it will be lower from home. reply fian 8 hours agorootparentThere are broader implications for the economy if a large percentage of people continue to WFH. In larger cities, many smaller businesses, like food outlets, are sustained by workers coming to their city offices most weekdays. Many such businesses failed during COVID knockdowns due to lack of customers. Some are still struggling to become viable again with a low RTO percentage. For some medium to large businesses, these struggling smaller businesses or business owners are their customers. So there is some self interest from many companies to go back to the way things were. Arguably the failed or struggling businesses could be being replaced by other services, eg home food delivery, but I've not personally noticed anything like that happening. reply Zanfa 8 hours agorootparent> There are broader implications for the economy if a large percentage of people continue to WFH. In larger cities, many smaller businesses, like food outlets, are sustained by workers coming to their city offices most weekdays. The opposite is true as well. Many (likely more) small businesses have gone bankrupt because of people concentrating to other locations due to urbanization. reply mathgeek 7 hours agorootparentprev> Arguably the failed or struggling businesses could be being replaced by other services, eg home food delivery, but I've not personally noticed anything like that happening. It already happened before and during covid (that's what the gig economy created/captured). That has its own problems, not the least of which is the overhead costs passed to consumers. Overall, the scale required of such businesses keeps small ones from flourishing in any large numbers compared to brick and mortar. reply lkdfjlkdfjlg 6 hours agorootparentprev> There are broader implications for the economy i Irrelevant, the motivations of middle managers and executives is not the broader economy. It's their companies results and/or they are perceived by their bosses. The person I was responding to asked \"what drives RTO?\". Everything you said might be true, but it doesn't drive RTO. Yes, of course if you own a restaurant you want more foot traffic. But that's irrelevant for an office worker having his boss pushing RTO. reply fian 2 hours agorootparentUsing your restaurant example, if the restaurant closes it may not have much obvious effect on other nearby businesses. However, that restaurant would have given business to various food and consumables suppliers, to waste management companies, to an accountant etc. All those businesses have now lost a source of income and may be less profitable. Perhaps the restaurant was leasing the premises from a landlord. The landlord may still have a loan for the business premises. That loan could be at risk of going into arrears if no other person decides to try their luck running a restaurant in a location that doesn't have sufficient patronage. Consider now that the office workers who have refused to RTO work for the bank that holds the loan for the business premises. There is a risk to the bank now that the premises is less valuable because it can't be leased and is less attractive for a future purchaser. The point is that most businesses don't operate without having other businesses as suppliers or clients. When one business does badly it can affect other businesses in their network. A small number of isolated businesses failing doesn't cause knock on effects. However, if a larger number of smaller retailers, dependent on foot traffic close in the same locality it will have a ripple effect out to many other larger businesses. Business owners and executives have an interest in trying to maintain a healthy business network. Some will believe that pushing for RTO should help other local businesses in their business network and thus will be beneficial for their company in the long term. reply lkdfjlkdfjlg 1 hour agorootparentCompletely irrelevant. A manager at a bank is not pushing for RTO at the bank because a restaurant has a loan. You're missing the point of this conversation. reply antisthenes 3 hours agorootparentprev> In larger cities, many smaller businesses, like food outlets, are sustained by workers coming to their city offices most weekdays. My gut tells me that's mostly nonsense, considering how much I see delivery drivers driving around neighborhoods and picking up orders (when I'm picking up my takeout, for example). The demand didn't go anywhere, it's just that the people are now getting delivery to their suburban home, rather than walking to the food place from the office during lunch. A far bigger decrease in demand is due to some crazy price increases in outside-of-home dining options. A single mediocre burger will now easily run you $12, whereas pre-COVID you used to be able to get a whole meal for $10. Basically, if you feel \"bad\" for the small restaurants guy, your first place to look should be in the delivery app corporate grift, not blaming the WFH employees. reply kjkjadksj 3 hours agorootparentprevManagers should just set their expectations with the expectation that they would get bad information from time to time. Maybe you lie, maybe it actually took 3 days, in either case the shop shouldn’t be so brittle where it matters either way. reply danaris 2 hours agorootparentprev> My theory so far is that they believe that employees working from home take advantage of decreased supervision to slack I would take this a step further: My observation has been that many managers (at all levels) subscribe to a very feudal and classist belief that every employee (with the possible exception of those who actively brown-nose) is always looking for as many ways to screw the company as possible. If not being constantly monitored, they will slack off; if they claim to have a disability they need accommodations for, that's just a way of getting you to endorse their slacking. Essentially, it's a mindset that views the manager-subordinate relationship as a fully adversarial one, at all times, no matter how good a performer any given subordinate is. reply danesparza 9 hours agoprevWell now that Gartner has said it, perhaps CEOs will actually hear it. Good grief this has been a strange 4 years. reply benterix 9 hours agoparentHopefully. The CEOs act so irrationally (at least in communication to employees) I can imagine they will ignore Gartner, too. reply CM30 9 hours agoprevIt's especially bad when the company is based in a remote area with few other opportunities in that industry. Now you're not only selecting for people who can easily come to the office on a moment's notice, but people willing to put all their eggs in one basket and (often) live somewhere where your company is the one thing keeping the lights on. And then they wonder why the best talent starts leaving, and the jobs they do start hiring for get few decent applicants... reply hirvi74 4 hours agoprevI think the talent risks are very company dependent. My back is against the wall at my current employer. As in, my employer had a return to the office mandate, and I had little realistic choice but to follow it. If I could quit and find another job, they know I would have already. I should state too, at my company, this same problem can be mapped on to more people than just myself. But hey, at least I get a paycheck. Things could be worse. reply Log_out_ 9 hours agoprevAdd to that the home office was standardized during corona, so all that talent selling itself short or unable to move found itself surrounded by the world. reply lopkeny12ko 9 hours agoprev [–] The \"talent\" who wants to leave as soon as you ask them to return to office are probably not the employees you wanted to retain anyway. reply TheCapeGreek 9 hours agoparent [–] The \"employers\" who want to fire you as soon as you don't want to spend extra unpaid time commuting are probably not the employers you wanted to work for anyway. reply Jiro 3 hours agorootparent [–] The employers you want to work for are the ones that pay you a salary so you can eat and pay your mortgage. reply kjkjadksj 3 hours agorootparentIf you are qualified for that tier of compensation you have plenty of choice in potential employer reply 0x000xca0xfe 2 hours agorootparentprev [–] You must possess great negotiation skills with that attitude. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Return-to-office (RTO) mandates risk losing top talent, as employees with alternatives may leave first, potentially causing a domino effect.",
      "Flexible options, such as travel compensation or improved office amenities, are suggested as better alternatives to strict RTO mandates.",
      "The debate includes perspectives on productivity, mentorship, and personal preferences, with some viewing RTO as driven by outdated management views or economic pressures."
    ],
    "points": 102,
    "commentCount": 106,
    "retryCount": 0,
    "time": 1721205855
  }
]
