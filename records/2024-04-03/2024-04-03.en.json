[
  {
    "id": 39908579,
    "title": "Amazon shifts from 'Just Walk Out' to Dash Carts in grocery stores",
    "originLink": "https://gizmodo.com/amazon-reportedly-ditches-just-walk-out-grocery-stores-1851381116",
    "originBody": "By Maxwell Zeff PublishedYesterday UpdatedYesterday Comments (89) Photo: Leon Neal (Getty Images) Amazon is phasing out its checkout-less grocery stores with “Just Walk Out” technology, first reported by The Information Tuesday. The company’s senior vice president of grocery stores says they’re moving away from Just Walk Out, which relied on cameras and sensors to track what people were leaving the store with. Just over half of Amazon Fresh stores are equipped with Just Walk Out. The technology allows customers to skip checkout altogether by scanning a QR code when they enter the store. Though it seemed completely automated, Just Walk Out relied on more than 1,000 people in India watching and labeling videos to ensure accurate checkouts. The cashiers were simply moved off-site, and they watched you as you shopped. Instead, Amazon is moving towards Dash Carts, a scanner and screen that’s embedded in your shopping cart, allowing you to checkout as you shop. These offer a more reliable solution than Just Walk Out. Amazon Fresh stores will also feature self check out counters from now on, for people who aren’t Amazon members. “We’re rolling out Amazon Dash Cart, our smart-shopping carts,” said an Amazon spokesperson to Gizmodo. Amazon confirmed this feature is replacing its Just Walk Out technology in existing stores. Just Walk Out was first introduced in 2016, presenting Amazon’s biggest and boldest innovation in grocery shopping. The technology seemed incredible, but there were some stumbles. It often took hours for customers to receive receipts after leaving the store, largely because offshore cashiers were rewatching videos and assigning items to different customers. The system of scanners and video cameras in each store is also incredibly expensive. According to The Information, 700 out of 1,000 Just Walk Out sales required human reviewers as of 2022. This widely missed Amazon’s internal goals of reaching less than 50 reviews per 1,000 sales. Amazon called this characterization inaccurate, and disputes how many purchases require reviews. “The primary role of our Machine Learning data associates is to annotate video images, which is necessary for continuously improving the underlying machine learning model powering,” said an Amazon spokesperson to Gizmodo. However, the spokesperson acknowledged these associates validate “a small minority” of shopping visits when AI can’t determine a purchase. Amazon Fresh, the e-commerce giant’s grocery store first launched in 2007, has just over 40 locations around the United States. The company also owns Whole Foods, and many of Amazon Fresh’s experiments are seen as precursors for the large chain. The company is reportedly keeping Just Walk Out technology in a small number of Fresh stores in the United Kingdom, and some of its Amazon Go convenience stores. Amazon has also implemented Just Walk Out technology at several ballparks around the country. These locations will keep the technology going. Amazon is trying to further break into the grocery space to grow into another billion-dollar market. Though it owns Whole Foods, the e-commerce giant still doesn’t compete with food goliaths like Walmart, Costco, and Kroger. Amazon’s push away from expensive tests like Just Walk Out may be a sign the company is looking to further expand its presence as a supermarket. Show all 89 comments CONTINUE READING",
    "commentLink": "https://news.ycombinator.com/item?id=39908579",
    "commentBody": "Amazon ditches 'just walk out' checkouts at its grocery stores (gizmodo.com)428 points by walterbell 16 hours agohidepastfavorite594 comments bilalq 12 hours agoThis is pretty sad to read. Before Covid, the Amazon Go store experience was phenomenal. All the convenience of a 7-Eleven but with the pricing of a normal grocery store. The food options were really good and the BlueApron style meal-kits were amazing. The Alexa integration was also nice for being able to just verbally ask what's the next step on a recipe while you're busy stirring or chopping things. When it rolled out to Amazon Fresh stores, it was a breadth of fresh air. The painful clunkiness of self-checkout was gone. The slow and pointless exercise of unloading and reloading your cart was gone. You could just bring your reusable shopping bags, throw stuff in, and walk home. By far the most hassle-free shopping experience to be had. Scan as you shop is a big step backwards and feels like you've got the annoying self-checkout experience looming over you the entire time you're there. The selection and operating hours both took a hit during covid and never recovered. reply Johnny555 11 hours agoparentLots of services would be phenomenal when you can offload much of the cost to run them to cheap offshore labor. Remember how great Uber and Doordash were when much of the cost of operating was offset by underpaid workers and VC funds? Now that they don't have unlimited piles of money and cities/states are making them pay more fair wages, the cost-benefit of those services has diminished. I was ok paying $5 for $20 of food to be delivered, but now it's more like $10 - $15 in fees/tip, plus fees hidden in menu prices making that $20 food cost $27.50. reply ryukoposting 6 hours agorootparentFrom my point of view, Uber and DD were always going to head in that direction because by any objective measure, they are worse than the solution that already existed. The introduction of a middleman created new costs for drivers, customers, and restaurants alike, yet it's actually worse at delivering food than the conventional \"drivers work for the restaurant\" model. Sure, you get one website where you can see all the delivery options in the area, but the cost is making all of those options shittier. I could rant about how stupid that industry is for hours, but I digress. What Amazon is doing is different because they're actually doing something that adds value, and they're solving a problem that actually exists. Maybe I'm naive for believing any of this matters. To be honest, I never thought much about how the whole system worked. I've only been in an Amazon Fresh twice. It had the \"just walk out\" thing but I don't have a Prime account so I never used it. I just figured it was UHF RFID. Seems like an obvious solution, but I'm not the engineer responsible for figuring out what to do if you put two exits next to each other. reply jfoster 6 hours agorootparentIt's true that delivery services add a middle-man, but you don't seem to be considering that they add a lot of value in some important ways: 1. The single website/app is not just useful for discovery, but also to provide a consistent ordering experience. An individual restaurant might take orders over the phone, via their website, or via their own app. Those options will vary from one restaurant to the next. Not great for customers. 2. In the old model, restaurants would have to decide how many drivers to have on hand at any given time. During quiet periods they would have to decide between not offering delivery at all, or having a driver sitting around doing nothing. A delivery service that aggregates demand & supply is very useful for restaurants & drivers. Pooling of resources & layering on surge pricing creates a lot of elasticity. I would argue that what they should have done is tried to at this value at minimal cost to customers, drivers & restaurants. If they were leaner businesses the overall proposition could be a lot better. reply capybara_2020 1 hour agorootparentYou bring up an interesting point. Just thinking out loud for a moment here. Is the current VC business model potentially the problem area and not the actual businesses? The need for rapid growth/software company like profit margins when these companies need more time and potentially are like non-software companies in terms of profits? reply disgruntledphd2 33 minutes agorootparentYeah, demanding software level margins for physical world businesses basically hasn't worked anywhere in the past ten years. Like the only success I can see is AirBnB and that's because houses are expensive and in short supply. reply Jochim 34 minutes agorootparentprevI'm curious as to how food delivery worked in your country before Uber et al. In the UK, outside of corporate chains, it was largely a cash in hand operation for both the restaurants and drivers. Drivers would typically be paid a small sum for showing up on the night and then keep the delivery charge and any tips. The cost to the restaurant was pretty much negligible. The middle-men, in addition to their own cut, have likely lead to a larger tax burden on many of the drivers and restaurants. reply bgun 5 hours agorootparentprevDid you ever try getting groceries/food (other than pizza) delivered before the apps? Uber didn’t replace a better option, they made it literally possible to get these services in many places where it wasn’t an option at all. And in areas like Manhattan, where city cabs and delivery options abound - the the fact that many (most?) people still use UberEats/DD is instructive. The value of convenience is significant. I happily pay to avoid the mental overhead of shitty restaurant websites or repeating a paragraph-long group order back and forth across a poor kitchen speakerphone call. Yes the current system has many flaws but let’s not pretend it was utopia before. reply close04 53 minutes agorootparent> they made it literally possible to get these services These companies also made it possible for restaurants to be taken hostage and be registered for delivery services or marked as closed/unavailable on those platforms against their wishes, or pay even 60+% commission on an order for the service. Once only a couple of these companies are left standing and have all restaurants in a chokehold I'm convinced the situation will be even \"better\". > the the fact that many (most?) people still use UberEats/DD is instructive Yes, it says that too many people do what's best for them and them alone. It's not as instructive as you think. Many people had slaves because it was good for the owner. What did you learn from that case of \"many people do it\"? > I happily pay You don't and don't even realize that. You get an overall cheaper service but someone pays. Usually the restaurant owner, employees, and delivery people. Maybe some VCs too, for now, while they don't completely own the market. Just like Amazon's same day delivery means some driver has to pee in a bottle for close to minimum wage but otherwise it's absolutely a huge win for everyone who is you, needing the delivery now. reply dawnerd 3 hours agorootparentprevThankfully the local pizza place here still has their own drivers and it’s only a two dollar delivery fee. Totally fine with that. And everything always arrives fresh and fast and I know where and who to complain to and I know the drivers are at least somewhat vetted. reply bombcar 11 hours agorootparentprevI wish it could all be managed intelligently; I'm hungry but I can wait, let orders collect and make them all at once or something. Dominos had this down pat twenty years ago, how come everything with an app is so much more expensive? reply i_am_jl 9 hours agorootparent>Dominos had this down pat twenty years ago, how come everything with an app is so much more expensive? The people making the app need a much bigger cut than Domino's. Domino's cut only needs to be big enough to pay their delivery drivers, they make their money selling pizza and the delivery is just an additional service that drives business. The app maker needs a cut big enough to pay their delivery driver and also be the main revenue stream for their entire business since they're not making money off the pizza. reply shagie 9 hours agorootparentI would contend that Dominos is a pizza logistics company rather than a seller of retail pizza (compare Pizza Hut). https://biz.dominos.com/about-us/innovations/ They're not just selling pizza to make money - but also looking at making cars. https://www.hagerty.com/media/car-profiles/why-dominos-dxp-d... While I'm not going to claim that was a good idea, the point is that Dominos sees making and delivering pizza as one and the same business. > 154 examples of the DXP cars were built. Along with the delivery driver, each DXP car could carry up to 45 pizzas, 12 two-liter sodas, and all the extra dipping sauces one could ever want. Add to that the fact that the car’s still held their five-year 100,000-mile warranty, were cheap on gas, and created a surprising amount of buzz, it is hard not to look at the DXP program as a success, low production aside. reply dv_dt 6 hours agorootparentIt’s a shame they did not name the car model Deliverator reply hackerlight 7 hours agorootparentprevIs this not corpspeak kool-aid? Dominos and Pizza Hut do the same thing. They deliver pizza to people. Dominos knows how to hype the markets, though. reply luma 1 hour agorootparentPizza Hut has in store seating, Dominoes does not. reply hackerlight 1 hour agorootparentIf Dominos is a logistics company then Pizza Hut is both a logistics company and a dine-in restaurant. reply adolph 7 hours agorootparentprevHopefully they were made of something nonferrous to prevent pooling by pesky Kouriers. Edit: the Hagerty story was a nice read, thank you for linking to it reply gamepsys 9 hours agorootparentprevThe margins of the delivery business could be razor thin because the scale at which the app can operate is much bigger than domino's. There are ~7000 domino's in US, and hundreds of thousand on uber eats. I think as more apps offer the same service we'll see a race to the bottom and have a reduction in cost, but not to the VC subsidized levels we saw five years ago. reply im3w1l 8 hours agorootparentPicking up one order from a restaurant takes the same amount of time as picking up a dozen. This is a much more important economy-of-scale than having a large app country-wide install base to spread dev costs over. So I think a third-party delivery business must seek exclusivity contracts to be competitive with an in-house solution. reply kshacker 7 hours agorootparentSo what we need is bundling of orders based on 1) restaurant location 2) recipient location 3) time And if that could be done, maybe just 2 orders to start with (for example carpool benefits for 2 people), that will be awesome, but if you could pool 4-5 orders, that will make bank ! I guess this model, if scaled purely based on the model, will imply restaurants co-located (same parking lot) will benefit from such an arrangement. reply swores 5 hours agorootparentAt least in the UK this is the default behaviour from Deliveroo, standard delivery does cost money but might get your driver/biker go to multiple other houses on their way to you, or pay extra to get it direct. It made me stop using them, as there's no way to guess whether the normal option will bring the food fresh or not, and paying the premium each time made it feel too expensive. reply blokey 1 hour agorootparentAlso paying the extra premium (whether Deliveroo, Just Eat or Uber Eats) for first delivery is kinda pointless (at least here in the South West) as the drivers seem to be delivering for all the apps at the same time, so your delivery takes 35 mins for the 10 min premium delivery and sometimes they even turn off GPS after they've picked it up if they're delivering for another app first. So expensive for a frustrating cold food delivery. reply nradov 6 hours agorootparentprevThat factor is driving the virtual restaurant (ghost kitchen) trend. There are commercial kitchens set up purely to service delivery orders. They use a single facility but have multiple different restaurant brands with different menus (burgers, Mexican, Italian, vegan, etc). These ghost kitchens have no dining rooms and you probably can't even directly order food outside of a delivery service. https://en.wikipedia.org/wiki/Virtual_restaurant reply lynx23 4 hours agorootparentThese are the worst quality-wise. Yes, you can write a review if something went really bad. But not having customers right there who can complain and might even get an extra or a replacement gives less incentive to keep quality up. \"Specialising\" in everything, pizza-burger-kebab-china, is also likely a warning sign. reply johnny22 3 hours agorootparent> But not having customers right there who can complain and might even get an extra or a replacement gives less incentive to keep quality up. This is a super good point. I didn't think about that. reply lynx23 3 hours agorootparentIMO thats the most important point of delivered food. Just compare the process and you will instantly see the difference. In a restaurant, the waiter will openly serve you your food. You get instant feedback. And see right away if something is off. In the delivery case, you get a closed package at your door, say \"Thanks\" to the deliverer and close the door again. Only when the guy (who isn't responsible for the quality anyway) has left you open your package and are confronted with whatever you got. Maybe something spilled, maybe something misses, maybe something was wrong. And maybe its already cold... Whenever you use a delivery system, you take all these risks, and apart from a grumpy review, you can't do much about these... Personally, I think this is where the margin hides. Delivered food can generally have lower quality without customer complaints reaching the vendor. reply ToValueFunfetti 8 hours agorootparentprevI wonder if it could be solved with a decentralized system. You'd still need a way to vet drivers and handle refunds. I'm not sure other delivery apps bother with the former until bad reviews come in, and maybe the latter could be just between the customer and the store? Would be a big win for customers and gig workers if you could get past the obstacles. reply giancarlostoro 9 hours agorootparentprevSo if Uber buys out some small grocery store chains it could work, especially if its in major market cities. reply benreesman 7 hours agorootparentprevThe VC industry is like Hollywood: both smart purveyors of a popular, highly value added service to begin with, both driven by nepotism and inertia via far more scope for capture than your average line of work, and both with a cost structure mostly about the lifestyle of the executive class. when it’s just starting out in something, you get instant classics. when it’s out of ideas but still has the levers of access tilted all the way to “got mine bitches”, you get the late MCU, Uber for X, and OpenAI Larry Summers Edition. reply satvikpendem 10 hours agorootparentprevThe company Weee which primarily sells Asian products does this sort of batch order, and their prices are the same as grocery stores because they rightly knew that their initial Chinese userbase (and other Asians in general) is extremely price conscious and won't accept such increased fees for delivery. I just listened to a podcast episode about them on How I Built This which is where I got this information, people should give it a listen. reply throwaway2037 8 hours agorootparentVery nice suggestion. Thank you to share! Here is the open Spotify link to that episode: https://open.spotify.com/episode/69PURAcVOhzBcRUQrjkDfc reply geodel 9 hours agorootparentprev> how come everything with an app is so much more expensive? After ton of investment investors are finally looking for returns now. And consumers have decided convenience reigns supreme. Right from the SAAS products to daily breakfast customers there is lot of premium on convenience. reply Terr_ 9 hours agorootparent> After ton of investment investors are finally looking for returns now. We need a quippy phrase for this, but unfortunately \"Pump and Dump\" is already taken for a kind of stock-market manipulation. Instead, I would like to coin/nominate \"Tease and Squeeze\". First consumers are teased by the idea that the disruptive new service has invented a magic new secret to low prices and great value... But after the company as achieved some kind of market strangehold, those consumers are squeezed with price-hikes and quality-drops as the investors--who bankrolled the early predatory pricing [0]--try to recoup their investment plus additional profit. [0] Note that the term \"Predatory Pricing\" usually refers to artificially low prices to destroy competitors, although I can totally understand why some may assume it means preying on customers with high prices. reply rainbowzootsuit 8 hours agorootparentI've been hearing of scams labeled \"pig butchering\" — fatten the pig and then slaughter it. The euphemism is pretty close. reply lupire 6 hours agorootparentprevIt's called \"dumping and monopolization\" and is ancient and standard antitrust (illegal) and VC (highly rewarded) technique. reply CaptainZapp 7 hours agorootparentprevWhat's wrong with enshittification[0]? Granted, Tease and Squeeze has a nicer ring. Then again, the enshittification neologism became standard langue in no time and is understood by everybody. [0] https://en.m.wikipedia.org/wiki/Enshittification reply Terr_ 6 hours agorootparentI did consider the term when writing my post, but they only partially overlap. First, the issue of intent and overall history. Tease and Squeeze implies it was the plan all along, but an \"enshittified\" product doesn't have to be that way. For example, a company could have been successful without any \"Tease\"--no predatory pricing or monopolistic behavior--and then taken a nosedive later when the founder retired and sold it to a new owner, meaning it's Squeeze-only. Second, \"Squeeze\" doesn't require a quality-drop, it can include purely a price-hike, but \"enshittified\" products almost always mean a drop in quality, regardless of whether prices rise or not. reply gruez 6 hours agorootparentprevIt's arguably less descriptive. \"enshittification\" only really says \"things getting worse\", whereas \"Tease and Squeeze\" describes the whole cycle. reply Dylan16807 1 hour agorootparentThe original definition of enshittification is a platform that squeezes the users then squeezes the suppliers. But at this point I'm not sure exactly what it's supposed to mean. reply kevingadd 11 hours agorootparentprevThere is some degree of that in these apps already, for example I believe both grubhub and doordash will group up orders so one courier can do multiple deliveries back-to-back in a single trip. reply xp84 11 hours agorootparentThey do, and they also make that a profit center too by allowing you to pay another $3 to ensure a nonstop point-to-point delivery to you. reply mrangle 7 hours agorootparentprev\"Underpaid\" and \"fair\" is a modern political myth, except in the instances when there is a concerted effort to undermine the semi-natural labor market. Pay will never be enough, as a point of fact. It will always be \"underpaid\" and \"unfair\" in discussion. As this is an immortal pressure and negotiating tactic. It is incentivized, and therefore we will get more of it. That works both ways, but at some point there has to be a reckoning that accepts that it is better to have employed than unemployed unskilled workers. In the context of a massive and growing unskilled population base. Yet the same people who demand that everyone earn a living wage, sometimes punctuating their points with riots, tend to be the same crowd who wants to import unskilled workers by the millions. There is no effectively borderless world in which most are both employed and not \"underpaid\". It won't happen both ways. In fact, the pay trend is about to tip massively against fairness. In a manner that even will make economic rationalists uncomfortable. These \"fair pay\" efforts are a distraction before that storm. reply phreeza 3 hours agorootparentA free market without political intervention is at least as much of a myth. If employees don't engage in politics with concepts like \"fair wage\" and \"underpaid\", employers certainly will with concepts such as \"bottom quantile wages drive inflation\". The Nash equilibrium is for both sides to engage in the market but also in the political context the market is embedded in. So complaining about workers demanding higher wages instead of letting the market sort it out is pointless, regardless of your political convictions. reply android521 4 hours agorootparentprevlooking forward to a world where everyone anywhere can make a decent living wage. The technology and productivity have improved so much but the wealth inequalities have only grown wider. If AGI arrives and we have abundance, lets hope that it is not only the few elites that control all of that wealth and power. reply data_ders 6 hours agorootparentprev> Pay will never be enough, as a point of fact can you explain this a bit further please? also, what's the storm that's coming? reply tru3_power 6 hours agorootparentYeah you’re leaving us hanging here! To me it seems like people are learning their worth a little bit more lately and are demanding a little bit more/less financial stress. reply ghufran_syed 5 hours agorootparentI took it to mean that whatever amount of money people currently think would be needed to be \"fair\", say, an increase from $20/hour to $25/hour, would within a year or so become \"unfair\" again, even if inflation was zero. Employers will always want more work for less money, employees will always want more money for less work. Same as the seller of any product would like more money for that product, and the buyer would always like to pay less for the same product. So you can say the company is \"greedy\"...but that implies that the worker is also \"greedy\" - which is true for both IF you define it the way I described above. Or you could say that the company (owners) are trying to maximize their return on investment (time + money), and the the workers are trying to maximize their return on investment (of time). reply Barrin92 1 hour agorootparent>Employers will always want more work for less money, employees will always want more money for less work. Same as the seller of any product would like more money for that product, Is that true though? I come from a family that works in the crafts, small business mostly (which is like 70% of businesses). Most employees are employed for life, what's being made generally costs a decent amount but quality is high, people are content when they make what's perceived as fair and enough to maintain a middle class lifestyle, and so on. Nobody actually tries to rip each other off, cuts every penny and leaves for 5% higher salaries. People are around for decades. The MBA business logic isn't some universal truth, in fact it's not even how most people work. reply hnbad 2 hours agorootparentprevThis isn't what they meant apparently but in a very literal sense, pay can never be enough because it is economically necessary to underpay workers relative to what they contribute because profit by definition can only exist from surplus value, i.e. making more money from selling the product of labor than you pay for that labor. If I pay a worker $20 per hour to make 20 doodads an hour in my doodad factory and then sell those doodads for $5 a piece, I make $5 for every $1 pay my worker. Of course that extra $4 per doodad has to account for the cost of the doodad factory itself (initial investment, maintenance, material) and the literal cost of doing business (taxes, permits, fees, paying an accountant) and of course market fluctuation (warehousing, building a financial buffer to remain solvent if sales lapse or production has to stop) but if the business is meant to be successful, that needs to add up to less than the extra $4 I'm making. And the bigger that difference is, the more profitable my company becomes and the more spare money I have to expand my business and get ahead of my competition up to the point where I can sell shares in my business to other people and pay dividends from my profits to them. So in other words not only can't you pay workers exactly \"enough\" (i.e. 100% of the value they contribute to the company) but you're actively incentivized to pay them as little as you can get away with (and perversely, paying them more by reducing your profit margin may actually be worse for them by making your company less competitive and less resilient). This is before we even get into the politics of what work is overvalued or undervalued (e.g. the idea that CEOs should receive massively disproportionate compensation for their labor, which again creates pressure to compensate for this by underpaying lowly workers). This, by the way, is why collective bargaining matters. No matter how cool and nice your employer is, the market actively incentivizes them to do the least for you they can get away with and punishes them for doing more. So by not taking advantage of collective bargaining (i.e. using the pressure of all employees to your advantage rather than just yours individually) you're leaving money on the table. Note that is still true if your role is proportionally overpaid relative to other workers in your company unless you literally co-own the company. reply Dylan16807 1 hour agorootparent> pay can never be enough because it is economically necessary to underpay workers relative to what they contribute because profit by definition can only exist from surplus value That's a silly definition of \"enough\" to label as a fact. I feel like the lifestyle you can buy with the pay matters too, but even if we ignore that aspect, I think most people will agree that the worker getting 90% of the surplus value is \"enough\". (just as an example percent) There's no reason the bar should be the absolute extreme. reply throwaway290 4 hours agorootparentprevMaybe that \"storm\" is consequences of unchecked ML, make the rich richer and the powerful more powerful, push the poor out of jobs. I disagree that fair pay is impossible though. reply tbrownaw 6 hours agorootparentprevIs Marx really that modern? reply FpUser 3 hours agorootparentprevWith all the increased productivity and advances if we can't support decent living for every person then what's the point? Work yourself to death to make some motherfucker rich? reply Spivak 6 hours agorootparentprevI mean it becomes a myth when you define it out of existence; I normally don't like semantic arguments but you're arguing against an idea of \"underpaid\" that means something different than what the people who say it are trying to convey. The notion of underpaid isn't weighed against the value of one's labor, it's weighed against cost of living and the value of one's time. We've generally decided it's unreasonable for someone to need to work more than 40 hours a week so the minimum pay for 160 hours of labor had better be enough to live on without being on welfare or other government assistance. It might not be a glamorous life but you at least have to be able to make rent, pay for heat, AC, food, clothes, water, toilet paper, health insurance, a cheap cell phone, transportation to and from work, and some basic possessions like a bed. And if it's not then you're being underpaid. I think that's a pretty fair measure, it roughly represents the cost of a person's undivided labor. And I think it's fair to say that for almost all Americans that cost has gone up and not insignificantly over the past 5 years. Folks that make good money by can take the hit but people on the bottom rung have nowhere to go. And people will given the opportunity begrudgingly sell their labor for unsustainable prices because it's better than nothing but that road leads to the record scratch in the economic game of musical chairs we're playing when money stops moving. And that's when Socialist-inspired policies we have kick in and gov't has to forcibly redistribute wealth through higher taxes and even greater government spending to start the motor again. We've done it before and I'm sure we'll do it again. But I'm of the opinion that a little regulation to keep us out of the death spiral and letting the market allocate resources is better than when the government has to step in and do it. reply 6E696365 6 hours agorootparentprevFascinating that you can see \"underpaid\" and \"fair\" wages as political myths but not \"unskilled labor.\" reply Aloisius 5 hours agorootparentUnskilled labor simply refers to jobs where any specialized skills required can be learned on the job in a short period of time, usually less than 30 days. It doesn't literally mean the workers don't know how to do anything. It's certainly not a myth - it's a classification of work, at least in the US. https://www.ssa.gov/OP_Home/cfr20/416/416-0968.htm reply account-5 4 hours agorootparent> Unskilled labor simply refers to jobs where any specialized skills required can be learned on the job in a short period of time, usually less than 30 days. This is nearly all jobs. reply WalterBright 4 hours agorootparent> This is nearly all jobs. All unskilled labor jobs. You're not going to learn welding in 30 days. Nor are you going to learn how to design a bridge. Or program in C++. Or diagnose a patient. Or be a lawyer. Or drive a race car. Etc. reply account-5 3 hours agorootparentI didn't say all jobs, did I? You successfully listed (some) jobs that might take longer than 30 days to learn. The thing about \"unskilled\" jobs, everyone seems to look down their noses at, is that they facilite the people doing the lofty jobs of: lawyer, doctor, c++ programmer, etc. Without them getting done for you you couldn't do what you're doing. Can the brickie work without their \"unskilled\" laborer? Sure, but good luck getting you house built in a reasonable time. reply dotinvoke 4 hours agorootparentprevCredentialism has certainly gone too far in many fields, but I’d still like my doctors, lawyers, and engineers to have more than 30 days of training in their field. reply account-5 3 hours agorootparentYeah, my point wasn't that every job can be learned in 30 days, just a good proportion, most, jobs can be. reply samus 4 hours agorootparentprevIndeed, unskilled labor is a large part of the job market. reply WalterBright 4 hours agorootparentprevThe local Starbucks over the years has had many turnovers in the staff. It usually takes about 3 days for a new worker to learn the job. That makes it unskilled labor. Skilled labor is something like welding, where it can take a year to get good at it. Or things that require calculus, which take 4 years of specialized training to even get an entry job at it. Or flying an airplane - you can't just flip through the instruction booklet and fly an airplane. reply cammikebrown 3 hours agorootparentHow could you possibly know that it takes “3 days” to get good at being a barista? You should try it out sometime, with a 50 person line. I’m sure it’ll be a cake walk and your labor will be fairly compensated. I’ll even give you a 3 day head start just to be fair! reply hnbad 2 hours agorootparentThey likely meant that onboarding takes three days. As there is no meaningful metric for competence beyond that (or at least no metric that is measured and used) \"good\" doesn't apply. There are of course tons of ways a good, seasoned barista distinguishes themselves from a trainee with 3 days of onboarding but those are externalities. The difference between skilled and unskilled labor is not whether competence and experience can make a difference but whether that difference is measured as performance or only affects externalities. I.e. \"unskilled labor\" is not about the worker but about the company. Notably these often do involve skill that directly contributes to performance but because the job is considered unskilled, it's instead treated as some nebulous a priori form of intelligence and personal aptitude. What's more, beyond a certain point skill is often actively punished (e.g. by raising quotas to take advantage of higher productivity, resulting in more work for the same pay). reply lesostep 1 hour agorootparent>> I.e. \"unskilled labor\" is not about the worker but about the company That part really stood out to me. While a lot of us can agree that barista is an unskilled job, I heard people call barmen labor a skilled labor. Which is crazy, because it's essentially the same job (mix stuff up and serve in a cup). But it makes sense if \"unskilled labor\" is a function of an employer not an employee reply Dylan16807 1 hour agorootparentprev> They likely meant that onboarding takes three days. You can onboard welding in less than 30 days too. > As there is no meaningful metric for competence beyond that (or at least no metric that is measured and used) \"good\" doesn't apply. Barista quality isn't much harder to measure than weld quality. \"and used\" is a cop-out. reply onion2k 3 hours agorootparentprevIt usually takes about 3 days for a new worker to learn the job. Starbucks hires juniors and trains them to be good baristas. That takes a long time. Just because someone is able to work a coffee machine after a few days doesn't mean they're not skilled eventually. Your argument is like saying 'it only takes a few days for junior devs to be onboarded, so there's no real value in senior devs'. reply rad_gruchalski 3 hours agorootparentYes, and McDonalds hires junior burger flippers and turns them into senior and skilled burger flippers. It doesn’t take a phd to make a coffee, no matter how fancy the cinnamon/cocoa heart is. reply onion2k 2 hours agorootparentIt doesn’t take a phd to make a coffee, no matter how fancy the cinnamon/cocoa heart is. All you're saying here is that you've failed to see the value in customer service, hospitality, speed, accuracy, politeness, etc that go with a retail coffeeshop job. The coffee is the same in pretty much every Starbucks, but the experience can vary wildly depending on how good the baristas are at everything else besides making coffee. Those skills take years to master. reply rad_gruchalski 1 hour agorootparentYes, that’s what I’m sort of saying. I haven’t failed to see any of that. But it doesn’t take a phd to make coffee politely or less politely. All I want is the coffee. Don’t ask me what my name is. I don’t care about the „experience”. reply tbrownaw 6 hours agorootparentprevAre you saying that \"unskilled labor\" is like the other two in just being spin on \"I don't approve of market forces\"? reply lnxg33k1 5 hours agorootparentTo me its funny that those who always talk about unskilled labour are the same who don’t have a driving licence, nor know how to make an omelette reply Almondsetat 2 hours agorootparentDo you have any statistics on that? reply hackernewds 4 hours agorootparentprevWhat skills are required to drive, walk or bike a delivery to make $30+tips/hr in NYC? I don't think they literally mean \"unskilled\" vs \"something that can be learned within a month\". reply lnxg33k1 3 hours agorootparentWhere are all these js devs on minimum wage going paycheck-to-paycheck? I think everything is easy, given the right approach and mindset, or everything is approachable given the right approach and mindset and will to put enough effort to get to a given outcome. reply gruez 5 hours agorootparentprevThe concept of \"underpaid\" and \"fair\" wages is fundamentally subjective. Is a burger flipper underpaid because he cant raise a family a buy a house on that wage, \"underpaid\"? Or is his labor simply not that valuable? Is a techbro making $300k \"underpaid\" because his employer is making $500k off his work? On the other hand skilled vs unskilled labor, as well as the concept of human capital are well recognized concepts in economics. reply uolmir 5 hours agorootparentAh yes, the famously objective field of economics. reply gruez 4 hours agorootparentAre you suggesting that the difference in skill level between a burger flipper and an accountant is purely subjective? reply account-5 4 hours agorootparentSince that depends on the burger flipper, I'd say yes. Gordon Ramsay would likely agree. reply gruez 4 hours agorootparentThat's just playing with words. Putting Gordon Ramsay in the same bucket as \"burger flipper\" makes as much sense as putting Linus Torvalds in the same bucket as \"keyboard monkey\". reply lubutu 2 hours agorootparentThe distinction I suppose is that what you really mean is \"the difference in [necessary] skill level between a burger flipper and an accountant\". reply account-5 3 hours agorootparentprevPerspective actually. And what you perceive to be value. reply gruez 3 hours agorootparentWhy are you pivoting to \"value\"? The original discussion was about skilled vs unskilled labor and whether that assessment is subjective vs objective. You might think that accountants are useless paper pushers whereas burger flippers are Hard Working People That Get Actual Things Done™, but that's orthogonal to how much skill[1] is needed to flip burgers vs be an accountant. [1] https://en.wikipedia.org/wiki/Skill_(labor) reply account-5 44 minutes agorootparentPivoting to nothing. > Skilled workers have long had historical import... Value, import(ance); potatoe, potartoe. reply gruez 24 minutes agorootparentSo you're trying to derail the discussion to something about \"value\", because the page I linked about \"skill\" has a passage about how skilled laborers were historically important to the economy? What does this have to do with the subjectivity/objectivity of \"underpaid\", \"unfair wages\", \"unskilled labor\", or whether a burger flipper is more \"skilled\" than an accountant? As I said earlier, even if you think that accountants are useless paper pushers, the fact that they're pushing papers in a very specific way that takes years to learn, makes them more skilled. nojster 4 hours agorootparentprevWith the two examples you chose, I‘d say there is not much of a skill gap. If you‘d have chosen a burger flipper and an aeronautical engineer or a surgeon, I‘d have agreed with you. reply gruez 4 hours agorootparent> With the two examples you chose, I‘d say there is not much of a skill gap. Unless we're talking about really high end burgers, you can take almost anyone off the street and train them to flip burger patties within a day. They might not willingly do it on account of it being boring/tiring/poorly paid work, but it's not exactly hard to learn either. I doubt you can do the same for an accountant, unless your idea of an accountant is something like \"manually copying entries into a ledger\". Even teaching excel to someone who hasn't used excel ever, to a capacity where they can do meaningful financial reporting probably can't be done within a day. reply intended 3 hours agorootparentprevFair warning to all who come after - the children comment for a decent distance below are a battle based on correct/ incorrect/ technical/ personal definitions of skilled labor. reply UweSchmidt 2 hours agorootparentDoes that warrant a warning? That's just a natural occuring discussion, and selecting threads to follow is basic forum-reading skill. The rare gems of surprising insight are often found in the depths of slightly off-topic discussions. Previously I've noticed another kind of meta-comment, the top level complaint by a self-appointed moderators about the overall shape of the discussion elsewhere, instead of engaging directly with the actual posts in question. reply intended 33 minutes agorootparentYes. With intellectual pursuits, you can always find diamonds in the rough. Simply due to the effort YOU are putting in, given your then state of mind, knowledge and experience. You can wade through a conversation on creationism and evolutionary denial and understand humanity or even deepen your skills. However that's you - your unique circumstances bringing more to the table. Others would very much appreciate a warning, because they already have working definitions, have seen this argument before and would prefer spending their time on other pursuits. reply iamflimflam1 3 hours agorootparentprevI should have listened to your warning and just skipped it. reply gmd63 9 hours agorootparentprevDon’t forget moviepass Problem is, when you get an economy acclimated to false prices set by adversarial “business” “strategy”, the only logical result is depression when it’s time to actually create money for investors reply threecheese 10 hours agorootparentprevwrt DoorDash (and Instacart etc), along with this squeeze I’ve observed the quality of service decrease severely. Could just be that my sample of a now wider employee pool is crappy, or workers are trying to “scale” to make a living wage with many concurrent orders, but I believe it’s part of the race to the bottom. I love the convenience, but the experience is worsening. How can these vendors continue to profit when lower quality leads to increased refunds? reply geodel 6 hours agorootparentWell in my observation people keep adjusting lower quality of service. I mean it is not going to be the case that people will start shopping in stores and/or cooking in kitchens. reply hnbad 2 hours agorootparentprevCase in point: LLMs that only work because of armies of underpaid offshore workers assisting in training. reply refurb 8 hours agorootparentprevThis is a weird take. Cheap wages? Both of your examples paid decent wages, especially in the example of Uber. It was just an unprofitable business model subsidized by VC money or Amazon corporate profits. That sounds like a good thing? reply lupire 6 hours agorootparentIt's bad because it redirects human effort into wasteful activity. Same season communisr central planning is bad. reply card_zero 2 hours agorootparentHow can you tell that it's wasteful? Seems to me that pointing at activities and saying they're wasteful is exactly the central planning you mentioned. Everything \"decadent\" looks suspiciously wasteful. Stage shows, exotic fruit, ball games, wedding photography, hats, flowers, songs, pets, tourism, novels, hobbies, diamonds ... it often puzzles me how economic activity makes a country wealthy when only a tiny part of it is efficiently providing health, nutrients and shelter. And in fact maybe 90% of it is wasteful, but nobody has the magic ability to identify exactly which 90%, and that's why central planning wrecks wealth, and VC funding apparently thrown down the toilet may in some mysterious way be beneficial to us. reply ikiris 8 hours agorootparentprevalmost all the cost of doordash is overhead, they still aren't paying anyone that actually delivers food a decent portion of their take. reply pdntspa 7 hours agorootparentprevmore like $30-$35 reply madeofpalk 11 hours agoparentprev> Though it seemed completely automated, Just Walk Out relied on more than 1,000 people in India watching and labeling videos to ensure accurate checkouts. The cashiers were simply moved off-site, and they watched you as you shopped. Wow - I did not know this. This makes it all a whole lot less impressive and interesting that it was just people off shore watching you. reply xp84 10 hours agorootparentApparently this news came out in May 2023. I also was bamboozled into thinking that sophisticated computer vision algos -- that worked -- were doing this. I'm now picturing the remote workers constantly switching between cameras, studying: Did he put down the can of kidney beans or the can of corn there? Wait, the man picked up the bananas, but then he handed them to the woman in the white shirt. Let's charge them to her account. Wait, she handed them back at 14:42 in aisle 16. Going to switch them back to the man. All day long, day in day out, for years. I am the last to criticize 'low wage jobs' paternalistically, because I know they may be much better than what the workers might otherwise be doing: perhaps just toiling in the fields for 16 hours a day (or worse: something like 'melting down discarded PCBs to recover trace metals'). But still, I do not think I would want to do this job nor that it was worth it. I get that they were supposedly trying to train an algorithm to do it. I'm glad that they aren't keeping at it any longer though now that it's proven so unworkable. reply RichardCA 9 hours agorootparent> something like 'melting down discarded PCBs to recover trace metals' Better than shipbreaking. https://youtu.be/5jdEG_ACXLw reply h0l0cube 8 hours agorootparentThanks for that Edit: On thinking about this tangent, it seems that if global regulation is the only solution, it would make sense to enforce regulation from the ship building side (in western countries), rather than the wrecking side (in developing countries) which will only displace the bad practices to less scrupulous countries. A solution might be sizable amount of money that had to be paid to escrow that could not be released back to the owner until the ship has been disposed of in an environmentally sound manner, incentivizing and funding the proper scrapping of ships. Or perhaps a levy which funds safety practices and equipment for scrapping companies reply skhunted 7 hours agorootparentGlobalization was largely a response to environmental movements in the U.S. We offshored our pollution generation. reply h0l0cube 2 hours agorootparentUh, really? I was certain that the aftermath of WWII was responsible for establishing a form of global governance (by consensus) via the UN, and then there’s the benefits of free trade agreements that drove economic globalization. reply adolph 7 hours agorootparentprevAlso industrial safety, worker hours, etc reply tbrownaw 6 hours agorootparentYou don't always even need to move things out-of-county to do regulatory arbitrage. For example Uber and Airbnb. reply gruez 5 hours agorootparentprev>it would make sense to enforce regulation from the ship building side (in western countries) Most ships are built in Asia as well. The US basically doesn't have any sort of non-military ship building industry. reply h0l0cube 2 hours agorootparentSure. But the reputable multinational corporations that dominate the industry are easy to recognize and they’re headquartered in developed countries reply gruez 2 hours agorootparentThe ownership structure for ships used in international shipping is anything but straightforward. For instance, for the the MV Dali (the ship that crashed into the Francis Scott Key Bridge) you might think we can go after Maersk, but in reality they're only chartering it. It was actually built by Hyundai Heavy Industries in South Korea for a Greek company but later sold to a Singaporean company, operated by a different Singaporean company, and crewed by 20 Indians and 1 Sri Lankan. In this complex web of ownership/relationships how do you exactly \"enforce regulation from the ship building side \"? reply h0l0cube 1 hour agorootparentWell as I (naively) suggested whoever owns the actual ship (and thus disposes of it) can claim on an escrow that isn't released until the ship has been verifiable disposed of in an environmentally sound fashion. So if the ship ever is sold to another party, that would be built into the purchase cost (that they could claim this money), even to the final purchaser (the wreckers). Probably some huge loophole or perverse incentive that I haven't thought of, but that's at least one suggestion. reply dcow 6 hours agorootparentprevThis factoid made its way through my social circles back in 2019. I'm a little surprised it wasn't more common knowledge. reply idontwantthis 10 hours agorootparentprevIf you did some kind of shell game with 5 different people all passing around their items, then you don’t get charged correctly is it theft? Did anyone ever try that? reply baumy 9 hours agorootparentI worked for Amazon in Seattle when Amazon Go first launched. As you'd expect, lots of SDE teams made games out of trying to fool the thing in various ways. A few attempts were successful early on (passing items back and forth, one person moving something to the wrong shelf and another person picking it up, people dressing in identical outfits, etc), but the success rate in fooling the system was very very low. No method of trying to trick it that I ever heard of worked consistently, and it definitely seemed to get harder to fool the longer the store was open. At the time I thought that whatever algos were being run on the camera feeds were getting better. Knowing that it was basically all manual, I'm not sure what the explanation is for the store seemingly getting harder to fool over time. Possibly just placebo, or people lost interest in trying so hard to fool it. reply eyegor 5 hours agorootparentProbably fewer patrons and similar number of employees in the sweatshops. More eyes per patron leads to fewer errors. Or maybe they trained the best grocery cv model around from having a big high quality dataset, and you were fighting it. But then I'd think the tech would've been passed to whole foods instead of packing up shop, so final guess is sweatshop singularity theory. reply burntalmonds 8 hours agorootparentprevThomas Crown Affair at the grocery store. reply throwazr 5 hours agorootparentprevYou underestimated the silicon valley engineers reply Terr_ 8 hours agorootparentprev> If you did some kind of shell game with 5 different people all passing around their items, then you don’t get charged correctly is it theft? IANAL but I'm confident the legal answer is \"yes\", the same as if someone was using sleight-of-hand with objects at a cashier-and-conveyor-belt checkout station. Whether charges are brought and how easily the case can be proved is another matter, but the intent is what makes it a crime. reply pcchristie 7 hours agorootparentI thought one of the marketing lines was that Amazon was so confident/comfortable in their implementation was that they assumed all liability for mistakes (though as I type this I realise they may have worded it to encapsulate only honest mistakes rather than people trying deliberately to break the system). reply Terr_ 6 hours agorootparent> they assumed all liability for mistakes To get a little pedantic, assuming such a promise existed, it actually doesn't mean as much as most people think. A merchant saying \"we won't sue you in civil court for the missing money\" does not prevent the local government from criminally prosecuting that same person for theft. American TV dramas often show the police asking people \"Do you want to press charges?\", but the idea that the question matters is a myth, since victims of crime don't get to decide that. At best, it's a terribly misleading shortening of: \"Just for my own private curiosity, do you plan to lobby or press upon your local government officials into pressing charges?\" reply lupire 6 hours agorootparentprevBeing forgiven doesn't make it not a crime, or just reduces the chance of enforcement. reply ametrau 6 hours agorootparentprev> the workers might otherwise be doing: perhaps just toiling in the fields for 16 hours a day That is robber barron propaganda to make you believe their enslavement of people (by creating the right situation where the people have no choice) is actual good for them. reply gruez 5 hours agorootparentWho are the \"robber barrons\" in this case, and how did they cause \"the right situation where the people have no choice\"? reply xp84 3 hours agorootparentprevI originally wrote a long reply, but I'll just say that I don't buy your framing, and I don't think the people who depend on that foreign money flowing in to pay them for their work at the prevailing wage where they live agree with you either. reply MrFoof 10 hours agorootparentprevThis is like learning that there actually 1000 tiny elves inside of your television drawing the pictures. This a real-life, genuine Flintstones-esque cartoon gag. reply KptMarchewa 10 hours agorootparentPratchett comes to mind. reply justinjlynn 9 hours agorootparentPratchett really got technology, imo. Sometimes it really is high energy magic, but most of the time it's just labourers you can't see being exploited. I especially enjoyed the line \"money dangled is far more effective than money given\" or something like that... it's true. reply randycupertino 9 hours agorootparentprev> Though it seemed completely automated, Just Walk Out relied on more than 1,000 people in India watching and labeling videos to ensure accurate checkouts. The cashiers were simply moved off-site, and they watched you as you shopped. Reminds me of the \"delivery robots\" that weren't really automated after all, they were remotely navigated by cheaper workers on playstation controllers in Brazil and the Philippines driving them on the streets through cameras. https://www.thestar.com/news/gta/they-are-cute-pink-robots-w... reply alsodumb 11 hours agorootparentprevIt's just a tech-illiterate journalist who can't seem to understand the difference between \"annotators watching and labeling videos to validate the model\" vs \"people watching the videos live to remotely decide the cost of every user's purchase\". Or maybe they do know the difference, but wanted to bait audience. reply kadoban 11 hours agorootparentOr it's a tech-literate journalist who knows that usually it's the latter and they have vague plans to transition to the former later. reply anthony__j 11 hours agorootparentalways mturk all the way down reply ec109685 10 hours agorootparentprevI thought so too, but the article says this: > 700 out of 1,000 Just Walk Out sales required human reviewers as of 2022. reply fshbbdssbbgdd 7 hours agorootparentIf you required a high accuracy like 99.9% to charge a customer, you could have a system that was mostly automatic but still needed human review when the model isn’t confident enough. It’s hard to know exactly what this means without a lot more details, which Amazon is unlikely to provide. reply Timshel 10 hours agorootparentprev> 700 out of 1,000 Just Walk Out sales required human reviewers as of 2022. Or not ... reply arcticbull 9 hours agorootparentprevSounds like fake-it-till-you-make-it stuff right? This is exactly how I would bootstrap a startup that wanted to do this. Kind of impressed with their scrappiness to be honest. reply schnable 7 hours agorootparent\"Scrappy\" on a massive budget. Must have been fun to work at these tech companies when money was cheap! reply meowface 7 hours agorootparentprevIt's the epitome of \"do things that don't scale\". (Just, after enough years and size, you eventually need to scale.) reply anonacct37 9 hours agorootparentprevWhat I think is funny is that circa 2008 I had a manager who used to work at Amazon who told me that \"a surprising amount of Amazon artificial intelligence is artificial artificial intelligence, low paid workers\". I heard this was behind mechanical turk. Sounds like the playbook remained the same. reply breadwinner 10 hours agorootparentprevI wonder if the same \"tech\" could be used for \"self-driving\" cars. reply yjftsjthsd-h 8 hours agorootparentI'm pretty sure this idea has been kicked around, and is generally seen as not-super-useful because it requires a perfectly reliable low-latency connection. reply Fricken 8 hours agorootparentPhantom Auto did this. They had cars ferrying people around CES 2018 in Vegas driven by remote drivers in LA. Apparently the company folded just a few weeks ago. reply gitaarik 3 hours agorootparentprevTo solve this issue you can integrate the person into the car. reply crimony 2 hours agorootparentConjoiner Drives come to mind... reply FourOnTheFloor 10 hours agorootparentprev\"Unidentified item in driving area. Calling police.\" reply lupire 6 hours agorootparentprevWhen Amazon Fresh first launched, it was just SWEs running to the grocery store when someone placed an order. reply ametrau 6 hours agorootparentprevThat is absolutely dystopian and completely awful. Everything Amazon does / releases you should assume it’s evil in some way. reply hn_user82179 11 hours agoparentprevRegular grocery stores have really gone downhill as well. Whenever I shop, there’s at most 1 cashier doing checkout and usually 0 (only self-checkout being open). I consider myself pretty proficient about knowing what sets off the machine but still set it off 60% of the time (about some weight imbalance etc) that requires an attendant to come fix manually. I’ve gotten to dread the grocery store trips as they require so much overhead time. I really wish the “just walk out” could’ve been popularized and caught on at more stores. reply johnwalkr 9 hours agorootparentI live in Western Europe and the self checkouts don’t have scales, except for weighing produce, and even for buying alcohol, they trust you to say you’re over 16. It’s always fast because you wait in one line for 4-8 self checkouts and take the first free one. On the other hand, using the cashier is often frustrating. You have to self-bag anyway and the cashier won’t start scanning your items until the person in front of you has bagged all of their stuff, had a chat about the weather and counted their change. The bagging area is always way too small, making all of this take a while. A few times I’ve even waited while one cashier counts their float, leaves, and a new one comes and counts their float. reply herbst 7 minutes agorootparentFYI Austria and sometimes Italy have weighted self checkouts. In Switzerland the age check is done by any cashier nearby. Sometimes so fast that you don't even notice that there was a check. reply troad 5 hours agorootparentprevI travel extensively, and I think attitudes towards self-checkout vary heavily depending on what preceded it where you are. In some places, you had smoke-stained cashiers throwing your groceries to their side without so much as looking at you, except to complain you're not bagging fast enough. I think it's fair to say that in those places, self-checkout is a huge improvement. In other places though, where cashiers have traditionally been more friendly and expected to bag your groceries, it feels like a less obvious improvement. Whereas before you had chipper high school kids working their first job bagging your groceries, now you have menacing terminals accusing you of being a criminal every time their scales misalign. Self-checkout is a convergence on mediocrity: some places are going to get dragged up, and others down. reply johnwalkr 4 hours agorootparentGreat point, I’m from Canada and lived in Japan for a decade, in those two places I would say it’s a downgrade. Especially Canada where there is usually a scale. reply smcl 3 hours agorootparentprev> the cashier won’t start scanning your items until the person in front of you has bagged all of their stuff What happens every now and then to me is that the person in front watches open mouthed as their shopping gets scanned and piles up in the bagging area, then they pay and fuck around with their purse (honestly idk what they’re doing) then take forever to pack, while the cashier starts scanning my stuff and mixes it into theirs. I don’t love self-checkout, it can be annoying when something doesn’t scan and I don’t have the ability to manually input the bar code like a normal cashier does. And sometimes there can be errors (“place the item into the bagging area” - when I already did), but I’m overall glad to have the option for self-checkout. reply soderfoo 2 hours agorootparent> the person in front watches open mouthed as their shopping gets scanned and piles up in the bagging area I feel this. It makes my blood boil. I wish I could flutter through life with such child like absent mindedness. reply smcl 1 hour agorootparentHonestly I think we’ve all been there at some point - just switching off for a few seconds when we’re stressed or distracted by other things in life. If not at the checkout then somewhere else. But yeah when you’re the other person in this scenario it’s irritating as hell :-D reply treflop 3 hours agorootparentprevDamn I’m in Southern California and y’all have really bizarre checkout experiences to me - I never have to weigh anything except produce - I rarely have to wait on an attendant except for something like spray paint - I rarely have been to a store with absolutely zero cashiers, especially for a grocery store - Usually the cashier will bag for me I’ve had similar experiences whether I’m in an urban part of LA or some rich Orange County suburb. My only two complaints are (1) finding parking at like a Trader’s Joes or Tokyo Central and (2) when the store is super busy, there are a bunch of cashiers, and yet there are still long lines reply saalweachter 11 hours agorootparentprevYeah, the \"if anything goes wrong you now stand around with your thumb up your ass while one employee makes their way from broken kiosk to broken kiosk to manually resolve the problems\" model has soured me on self-checkout. I find I have a very low \"dealing with this bullshit\" limit, to the point that if I have trouble I'm likely to just say fuck it and walk out of the store without completing my purchase. reply semi-extrinsic 11 hours agorootparentHaving used the UK/US type self checkout machines while travelling, I must say it is so nice to live in Northern Europe where the self checkout machines are largely just based on trust, with randomly sampling ~five items of every 100 shoppers. There is no weighing at any of the stores. If you don't get randomly selected for inspection, there is nothing stopping you from just walking out with groceries you didn't pay for worth a hundred dollars easy. People just don't. Another benefit of having a proper social safety net I guess. reply robertlagrant 10 hours agorootparent> Another benefit of having a proper social safety net I guess. I doubt it's as simple as this. People don't only steal because they could technically afford things. Just as people don't only kill in self defence. reply ScoobleDoodle 10 hours agorootparentSocial safety net is more than just being able to afford it. It's a combination of not being able to afford it and general erosion of social values leading to \"take what you can get away with\" mentality. So even those that can afford it will still try to get more since it's everyone for themselves. Instead of cooperation under a system with a social safety net, we get a game theoretic weighting on defection without a social safety net. reply robertlagrant 1 hour agorootparent> Instead of cooperation under a system with a social safety net, we get a game theoretic weighting on defection without a social safety net. There is a safety net. Here's how I'd describe the situation: There will be a number of people, fewer than the total who benefit from the safety net, who almost everyone would say it was good that they were helped. There will be a number of people, fewer than the total who benefit from the safety net, who almost everyone would say it was not good that they were helped. Most of politics around this topic is people's differing beliefs in the proportions of the above, and how bought in they are to minimising the latter count because they pay taxes. reply moffkalast 47 minutes agorootparent> who almost everyone would say it was not good that they were helped I'm sorry, what? Only in the US helping someone can be sold as a bad thing. It's better to help a few more people that may not really need it than help a few fewer that actually did. reply wolverine876 10 hours agorootparentprev> Social safety net is more than just being able to afford it. It's a combination of not being able to afford it and general erosion of social values leading to \"take what you can get away with\" mentality. There's a causal arrow in the other direction, IMHO: People like to believe in the 'law of the jungle' mentality and thus vote to cut the safety net. IME it's especially wealthy people for whom it's a kind of game, not trauma, deprivation (of education, health care, food, housing, safety) and survival, and who also get to pay lower taxes, Didn't Jamie Dimon talk about how he liked how 'animal spirits' have been awakened? reply doktrin 9 hours agorootparentA lot of house cats walking around imagining themselves to be lions. reply adolph 7 hours agorootparentprevI enjoy stealin', it's just as simple as that Oh well, it's just a simple fact When I want something, man, I don't wanna pay for it https://genius.com/Janes-addiction-been-caught-stealing-lyri... reply callalex 3 hours agorootparentprevIs it a social safety net or stronger legal protections for retailers? In the USA the store has no legal right to detain you and spot check your receipt. Membership stores can revoke your membership for noncompliance and then not let you in anymore without a membership, but that is the closest you’ll find here. reply WrongAssumption 10 hours agorootparentprevI’ve never been nor seen anyone in the US get inspected at a self checkout. Not once. reply ScoobleDoodle 10 hours agorootparentThat's because all of the self checkouts in the US use the weight change to match against the scanned item and any discrepancy leads to having to wait for a self-checkout attendant to manually override to let you continue. That manual override is equivalent to the inspection you're talking about not seeing. And I in the US get blocked needing an attendant 60%+ of the time at some point in the process. Usually up front with the bags I brought from home. reply Izkata 9 hours agorootparentThat's happened maybe 4 or 5 times to me in the 200 trips or so (estimated, once a week for years) I've made since I started using the self-checkout every time. It's so reliable and fast for me (store: Jewel-Osco), I just don't have the problems others here are seeing. Usually while waiting in line I don't see anyone else have issues either. Remove from basket, scan, put in bag. Remove from basket, scan, put in bag. The scale is the entire bagging area, and it detects when things were removed or added without being scanned, as far as I know that's all it does here. No specific weights. reply kaashif 10 hours agorootparentprevAt the Target next to where I live, the self checkouts don't weigh anything at all. I just scan something and put it in my backpack on the floor most of the time. And this is a Target where the toothpaste is locked up! I've never needed help from an attendant, and I've never been inspected either. Obviously it varies location by location. reply Solvency 9 hours agorootparentprevLiterally not true. neither Whole Foods nor Gelsons weigh anything you scan. reply opinion-is-bad 10 hours agorootparentprevThey recently installed a little door at my self checkout. I cannot even walk out of my grocery store without scanning a receipt or flagging an employee to open the door. It’s frustrating. reply bluedino 10 hours agorootparentprevI know that Krogers has cameras that use some sort of intelligence. I held an object in my hand as I moved other items across the scanner, it set of an alarm and a bunch of still images of my checkout process came up with colored shapes highlighting different on screen items reply oxguy3 10 hours agorootparentprevMight be your neighborhood -- stores with a low shrink rate might be more lax about inspections. I've only encountered it a few times myself but I'm also not the primary shopper in my household. reply dannyobrien 8 hours agorootparentprevThe weighing thing seems to be an adjustable feature: in my /extremely/ low-trust Safeway in San Francisco, they started with narrow weight limits that were super-frustrating. Now that misfeature is turned off completely (but they have a little gate you need to wave your receipt at). I imagine everyone is still playing around to get the optimum ease-of-use vs shoplifting ratio right. reply siva7 6 hours agorootparentprevMandatory item weighting was standard procedure in many western europe self-checkout kiosks for years. The experience sucked and the solution felt over-engineered. They just dropped it recently and moved to a trust-based model overseen by a single employee. Now it's much faster. reply dambi0 10 hours agorootparentprevA lot of the waiting is for age restricted items or machine errors rather than trust issues. I have never once been randomly sampled after self surface purchase in either the UK/US. reply DangitBobby 10 hours agorootparentWithout trust issues there would be no machine errors in my experience. Anytime there's an issue it's because I'm scanning too fast for the machine and it can't figure out how the weights work. Or I selected the wrong type of garlic and only the associate is allowed to remove items (why would you not let me remove items I personally added??). reply dambi0 10 hours agorootparentFair, the inability to remove your own items seems maybe a hang-up from an older view of privileged cashiers. The store I currently use doesn’t have weight checks except for weighed produce. You can leave your stuff in the cart and with the wireless scanner and a bit of forethought everything can stay in there. Different trust models makes things interesting. I have never been checked leaving the store and I don’t think social safety net or otherwise is the driving factor reply saalweachter 9 hours agorootparentYeah, the not being able to remove items grinds my gears. It's especially annoying when I am waving an item furiously, trying to get the poorly printed barcode to scan, and when it finally accepts it, it double scans the item. Then when I have to stand there waiting for someone to remove the item is usually where I get disgusted with the process and give up on shopping, especially when it happens multiple times. reply Muromec 10 hours agorootparentprevIt’s definitely trust issues here in the Netherlands. Buying something for under 5 euro bucks in a shop where middle school kids buy their lunches is almost guaranteed check. More than one in three times. A different shop and a bigger amount — checks almost never reply bombcar 11 hours agorootparentprevIt's really tunable and some stores are tuned to \"Fort Knox\" where even a fly landing UNKNOWN ITEM IN BAGGING AREA. Others are so loose that you don't even have to take things out of your cart, scan and pay and go. reply darepublic 10 hours agorootparentWhere I live most stores started off in fort Knox mode but had to tone it down. The bagging area was usually miniscule and trying to fit all the groceries of even a medium grocery list on there without locking the system was nigh impossible reply kevingadd 11 hours agorootparentprevThe Whole Foods location nearest to me has self-checkout stations that don't even have a scale under the bagging area. You just scan, put it in your bag and go. I assume they can afford to tank the shrinkage that results from this due to their high profit margins, or they just don't consider the costs associated with the scales to be worth it. reply BytesAndGears 11 hours agorootparentThat’s how the popular grocery chains in the Netherlands all work. You just scan a few things, put it in your bag, and leave. I almost never interact with anyone. It uses your rewards card to determine your “risk”, I think. Just a theory. But whenever I’ve gotten a new card, they come check my bag a lot. Then after a dozen successes or so, they stop checking so often. Then hardly at all. One of my friends forgot to scan an item once when they checked, and he had someone come to check his bag way more often for a while. reply thejohnconway 11 hours agorootparentprevAll the local self-checkouts where I am in London are just scan and go, no scales. reply hnbad 1 hour agorootparentprevThere was a news story a while back about how some chain stores were not going after most shoplifters directly but would keep the recordings on file and press felony charges once a certain total had been exceeded, so instead of getting a slap on the wrist for a few dollars of shrinkage here or there they'd drop the entire weight of the law on shoplifters once those few dollars added up to an amount that qualified for felony theft. Given that \"just walk out\" apparently means \"replace cashiers with offshore video analysts\" I'd wager Whole Foods might do something similar and policing shrinkage in self-checkout is too expensive compared to just keeping track of cheats and throwing the book at them if they make a habit out of it. reply FourOnTheFloor 10 hours agorootparentprevAnd it almost always DOES go wrong. Seriously 75% of the time when I'm done scanning and I press \"pay now,\" it inexplicably says \"calling for assistance\" and refuses to do anything until an employee comes over. WHY? And now assholes are intentionally taking alcohol through the self-checkout, deliberately taking up that one employee's time making him or her perform the workaround to check the items out. And the 20+ years of \"unexpected item in the bagging area\" bullshit... just get rid of it. reply kiwijamo 9 hours agorootparentStrangely that issue has almost vasnished for me in the last couple of years, here in New Zealand at least across the several supermarket chains I frequent (although they all seem to use the same self service POS supplier). Sure it was a big issue when these first came into stores but I think they've realised they need to increase the tolerances a bit (e.g. accept even if the weight is700 out of 1,000 Just Walk Out sales required human reviewers as of 2022 That's manual by any reasonable description. reply omgwtfbyobbq 11 hours agorootparentI think it depends on how much each human reviewer did. If they manually reviewed most of the items on each shopping trip, then it's mostly manual. If they only manually reviewed an item or few per trip, I'd consider it to be mostly automated. reply Timshel 10 hours agorootparentWell Amazon did not think so: > Amazon’s internal goals of reaching less than 50 reviews per 1,000 sales. reply omgwtfbyobbq 9 hours agorootparentThey didn't even agree with the 700 out of 1000 trips needing review figure > According to The Information, 700 out of 1,000 Just Walk Out sales required human reviewers as of 2022. This widely missed Amazon’s internal goals of reaching less than 50 reviews per 1,000 sales. Amazon called this characterization inaccurate, and disputes how many purchases require reviews. Even if the system was fairly accurate, if the vendor is charging Amazon too much for it, it can still be financially worthwhile for Amazon to switch to scanners in their carts. reply sunshowers 9 hours agorootparent\"inaccurate\" can mean lots of things here, from \"actually it was 690 out of 1000\" to some other minor technicality. Note that Amazon did not provide a figure of its own. Large corporations tend to tell the truth, but push it as far as they can. reply strken 7 hours agorootparentprevMight be \"700 manual reviews per 1000 trips\" getting misinterpreted as \"700 out of 1000 trips needed manual reviews\". If some trips were pathological edge cases that required near-constant reviews and a substantial majority took zero reviews, I could understand why Amazon would keep trying to fix its system. reply unscaled 9 hours agorootparentprevIf my memory serves me right, when I last visited the US right before COVID (SF) I wanted to see an Amazon Go convenience store but it closed down at 16:00 or 17:00. That was quite unacceptable for a convenience store and it was then I got the feeling Amazon Go was still an experiment rather than a mature technology. reply baby 1 hour agoparentprevI tried one in SF and never went back because holy fuck it was expensive reply ricardobeat 9 hours agoparentprevSelf-checkout is seamless in Europe. I don't see anything that would stop the US from having the same. reply Izkata 9 hours agorootparentIt is for me too in the US. I think it's either specific stores/chains or user error. reply janpieterz 7 hours agorootparentCompared to simply walking out, packing everything into your bags right away without needing to scan with either a hand terminal or \"repacking\" at self checkout is a lot more friction. Didn't really think it would be until I tried a couple of times in a row and it was incredible. reply keeperofdakeys 4 hours agoparentprev> The painful clunkiness of self-checkout was gone. It could be worse. Imagine a smart gate that refuses to open for wheelchair users, or claims the child in your arms is an unpaid item - something that is getting rolled out in many Australian supermarkets. reply rwbt 11 hours agoparentprevI'm glad it's gone for good, if the process really works like how it's described in the article. Thousands of poor souls doing terrible pointless menial work just so that a few entitled customers can avoid the clunky self checkout (eww- the horror!). The entitlement of the west has no bounds really. reply Retric 11 hours agorootparentIt wasn’t pointless, they were training an AI that never fully worked. It’s ultimately the same kind of thing as people monitoring self driving cars, a boring task that may be pointless or possibly remove a lot of drudgery longer term. According to The Information, 700 out of 1,000 Just Walk Out sales required human reviewers as of 2022. This widely missed Amazon’s internal goals of reaching less than 50 reviews per 1,000 sales. Amazon called this characterization inaccurate, and disputes how many purchases require reviews. reply Animats 10 hours agorootparentThat sort of thing seems to improve over time. The USPS has had automatic sorting machines for a long time. At first they could only read pre-barcoded mail. Humans had to key in zip codes. Then character recognition got good enough that printed and typed addresses could be read automatically. Some items were still rejected, and they went through manual stations that added a bar-code sticker. Then manual reading was made remote. There were about 20 USPS remote envelope reading centers at peak. As the vision systems got good enough to read handwriting, then bad handwriting, those were cut back. Now there's only one remote envelope reading center in the US, and what gets there is really bad. reply LordDragonfang 10 hours agorootparentTom Scott did a great video showing the last one in operation. They use totally unique keyboards with what is essentially a stenography system: https://www.youtube.com/watch?v=XxCha4Kez9c reply DangitBobby 10 hours agorootparentprevMaybe Westerners are entitled, but this one isn't really our fault because we were led to believe it was magical automation instead of menial labor. reply ushtaritk421 3 hours agorootparentprevPresumably these people applied for the jobs in question. I think it isn't for you to decide that their chosen job is pointless. reply kevin_thibedeau 6 hours agorootparentprevThe point of the store was to provide the appearance of conventional retail while being exclusive to \"members\". This would theoretically cut down on shoplifting and boost profits at the expense of shutting out marginalized people. reply wyager 11 hours agorootparentprev> Thousands of poor souls doing terrible pointless menial work just so that a few entitled customers can avoid the clunky self checkout Wanting to make your life more convenient and pleasant isn't \"entitled\". 99% of jobs are things people would rather not be doing (otherwise you wouldn't be getting paid for it). The point is that we can allocate this work in a way that minimizes the amount of time everyone has to spend doing undesirable work. Are you mad that I sometimes pay \"poor souls\" to do the \"menial work\" of cooking me food so I can avoid doing it myself? > The entitlement of the west has no bounds really. A very bizarre response to \"darn, this was so convenient\" - I wonder if this is a troll. reply franga2000 11 hours agorootparent> The point is that we can allocate this work in a way that minimizes the amount of time everyone has to spend doing undesirable work. 1. Not all work is equally undesirable and the way people are paid is not related to that in any way (in fact isn't usually inversely related) 2. Minimising the undesirable work done in total means some people end up doing almost all of it and some basically none (or, if you consider all work undesirable, some people do only the worst and some only the least bad work). If before, for example, everyone would spend half an hour of their day to cook for themselves, which might be inconvenient but is overall not a big impact on your quality of life, now we have overworked and underpaid restaurant and related staff doing intense work for crazy hours, which is is a devastating hit to their (and their families') quality of life. The sum of human effort spent on cooking may have gone down in this example, but instead of everyone being a little annoyed by it, some people are living like kings and some are slaving away for their convenience (obviously this wording is exaggerated, but if we look globally, this is basically what's happening). reply hnbad 1 hour agorootparentSure but you seem to ignore that we don't exist in a socialist society. Cashiers may have an undesirable job and self-checkout may distribute this undesirable labor among the many instead of burdening a single person with it but those people don't get paid for doing that job whereas the cashier did get paid. Self-checkout is also often slower than checkout at a cashier (it has to be because the cashier is trusted to ring up items correctly whereas the customer has a huge incentive to cheat). The desirability of being a cashier also isn't inherent to the job. It has more to do with attitudes towards the person doing the job, both from customers and from their employer. Service staff often act as a lightning rod for all frustrations and disdain targeted at their place of work, i.e. they frequently get punished for things completely out of their control. They're also often seen as unskilled labor by their employers so they are treated as easy to replace meaning there is very little incentive to invest in their job satisfaction. In other words, we have systems that not only require people to work even if the jobs they end up doing are undesirable and undervalued but also actively makes certain jobs undesirable by undervaluing them. If you want to change that, you need to change the system that makes those jobs undesirable, not just do away with the undesirable jobs. People seem to have fewer problems grasping this when talking about the virtues of overseas sweatshops (where changing the system is presumed impossible because the implication is that the system arises from a lack of economic development or cultural inferiority). reply franga2000 1 hour agorootparentThis is a great additional perspective, but we seem to be mostly in agreement. I am quite aware (and rather disappointed) we don't live in a more socialist system, but as we seem to be pretty much stuck under particularly nasty version of capitalism at least for the near future. So unless someone finds a way to turn the whole system around any time soon, I still think at least trying to make some of the worst parts of capitalism somewhat less unbearable is a good thing. reply rwbt 11 hours agorootparentprevIf you don't like going to the grocery store pay someone to go get them for you. Thousands of people remotely \"following\" you around and scanning things for you, just so that you can avoid using self checkout sounds ridiculous and excessive. reply saynay 11 hours agorootparentIs it more ridiculous than having someone standing at a cash register in the store doing the same task, while also having to bag for you and pretend to smile? reply soerxpso 11 hours agorootparentprevI don't see where you're getting the impression that 1,000 workers are monitoring every single individual that walks into the store. The figure used was the total amount for the whole program (many locations), only one person was reviewing each case, and they were only even reviewing 70% of cases. Your argument is no different than saying that every time you go to McDonald's, you're entitled for expecting the hundreds of thousands of McDonald's employees globally to band together to make you your burger. reply allan_s 10 hours agorootparentprevSo does having somebody sitting next to the checkout machine watching me (directly or through security camera) while I finish my groceries ? I fail to see the major difference with somebody working physically in the shop that makes it ridiculous and excessive. One may even argue that remotely it could opens the job to more people (one could do that from home in their wheelchair while their baby is taking a nap ) reply rwbt 10 hours agorootparentThere is a difference. In a typical grocery store, people only have to tally what you bought only once at the end during checkout. Where as in this \"walk out\" system someone has to follow you around \"virtually\" and keep track of everything you do in the store. reply allan_s 10 hours agorootparentI've adressed that point with the security camera (or adequatly positionned mirror in old-fashion store) And the workers just sit idle when there is no customer and you have to physically go there. So I dont see the clear advantage, i see it more as a \"choose your poison\" reply Dylan16807 7 hours agorootparentprev> keep track of everything you do It wasn't all manual. An important question to ask is how many minutes of camera-viewing there were per customer. Let's not assume too hard before we judge the level of wastefulness. reply bbarnett 11 hours agorootparentprevI'm sure all those fired, new job seekers jn India agree fully with you. reply rwbt 7 hours agorootparentIf the system did end up working as designed, wouldn't they get the shaft anyways? reply bbarnett 5 hours agorootparentYou were upset that due to the \"entitled\" west, Indians had jobs. You were glad the jobs were gone. Now you're trying to redirect, and say \"Oh well, those jobs would have lasted only a few years more anyhow!\". My respnse to that is the same: I'm sure all those fired, new job seekers jn India agree fully with you. Consider te perspective of those you aim to \"protect\". reply FourOnTheFloor 10 hours agoparentprevBut this was an obvious sham and a fraud that couldn't scale. I don't think its demise is sad at all. What's sad is putting cashiers out of work, and even worse is replacing them with outrageously piss-poor alternatives. Self-checkout is a clinic on incompetent system design, and has been for DECADES now. It's mind-bogglingly bad, all to take jobs away from people. Fuck that. reply arcticbull 9 hours agorootparentWhy is it a fraud? Did they ever tell you it was entirely computer-driven? I thought their value proposition was you could just ... walk out. This feels pretty inescapably the future. Why have people do bad jobs like cashier work when computers could do them instead? This is why UBI is going to be critical. We're moving to a world where we'll have more people than work, and that's not just ok - it's fantastic. They're not wrong, they're just early. Which you could argue is the same thing on a micro scale, but not on a macro. reply Izkata 9 hours agorootparent> Our checkout-free shopping experience is made possible by the same types of technologies used in self-driving cars: computer vision, sensor fusion, and deep learning. Our Just Walk Out Technology automatically detects when products are taken from or returned to the shelves and keeps track of them in a virtual cart. When you're done shopping, you can just leave the store. A little later, your receipt will be available and we will charge your payment method. https://www.amazon.com/gp/help/customer/display.html?nodeId=... reply themadturk 11 hours agoparentprevShopping there always felt supremely weird to me. Scanning in, getting stuff, and walking out, but I always felt incomplete without a receipt being right there in my email, wondering if I'd done something wrong and had just inadvertently shoplifted. I shop more often at Walmart, which has recently increased the number of manned checkout lanes and restricted their self-checkout to 15 items or less. reply bombcar 11 hours agorootparentThe local Walmart expanded self-checkout and it works surprisingly well (the bag scale seems to be very loosely calibrated or off). I wonder if they're doing things differently depending on how much product walks out the door. reply xp84 11 hours agorootparentJust in the past month or two, in my (low-crime suburban) area, Walmart appears to have closed the two large self-checkout areas entirely and replaced them with a (relative to before) army of cashiers. I have always found their machines to be very hassle-free, but the shockingly-adequate level of cashier staffing made my last visit surprisingly quick and convenient. I could live with this. reply hn_throwaway_99 6 hours agoparentprev> Scan as you shop is a big step backwards and feels like you've got the annoying self-checkout experience looming over you the entire time you're there. How do the Amazon \"Dash Carts\" actually work though? If it were a traditional bar code scanner, I'd agree with you. But reading up on the tech makes it sound like you just place the item in your cart and that's it. If it worked like that I don't see at all what the problem would be. reply raegis 11 hours agoparentprevPerhaps operating costs were more expensive than just hiring humans to run it like a traditional grocery store? reply chrash 10 hours agoprevthis might be my first comment here heh. i've worked on a similar product before. there's no way they were turning a profit. they definitely missed stuff all the time even with a ton of sensors. and sensors aren't the only cost. annotation is by far the most costly operational expense. new product? needs several annotated photos and recalibrated weight sensors. merchant decides to put Christmas branding on the same UPC? now all your vision models are poisoned for that product. it needs to be re-annotated for the month and a half it exists and the models need to be swapped out once inventory changes over again. as long as merchants are redesigning products (always) your datasets will be in a constant state of decay. even if your vision sensors are stationary and know the modular design up front, you still need to be able to somewhat generalize in case things get misplaced (big problem for weight sensors) or the camera gets bumped. between dataset management, technology costs, research costs, rote operational costs, etc this is a very expensive problem to solve. and large models with a ton of parameters are little help; they may lower annotation costs a bit but will increase the cost of compute. once i really dug into this problem i saw Amazon Go's Just Walk Out for what it really was: a marketing stunt reply hackernewds 4 hours agoparentthe biggest cost is not annotators at the scale you're imagining. it is labor costs. Amazon bet that the federal govt would raise labor costs to $20/hr and all their competitors (besides themselves with this tech) would get wiped out. They even publicly campaigned and lobbied. That didn't come to fruition as the election promises turned to fluff, and the populists simply chose to empower unions instead. reply chrash 4 hours agorootparenti mean, labor cost (as in in-store labor) is the target for this cost optimization. unfortunately for the time being labor cost is not as significant as the other costs associated with annotation and dataset curation. technology costs are not really significant if this can be pulled off at scale. in-store employees know where things are supposed to be and why, if at all, items are \"misplaced\" according to the modular design reply wiricon 6 hours agoparentprevHow well does simulated data work in this space? My first stab at doing this scalably would be as follows: given a new product, physically obtain a single instance of the product (or ideally a 3d model, but seems like a big ask from manufacturers at this stage), capture images of it from every conceivable angle and a variety of lighting conditions (seems like you could automate this data capture pretty well with a robotic arm to rotate the object and some kind of lighting rig), get an instance mask for each image (using either human annotator or a 3d reconstruction method or a FG-BG segmentation model), paste those instances on random background images (e.g. from any large image dataset), add distractor objects and other augmentations, and finally train a model on the resulting dataset. Helps that many grocery items are relatively rigid (boxes, bottles, etc). I guess this would only work for e.g. boxes and bottles, which always look the same, you'd need a lot more variety for things like fruit and veg that are non rigid and have a lot of variety in their appearance, and we'd need to take into account changing packaging as well. reply chrash 3 hours agorootparentas mentioned in another comment, \"scale\" is not just horizontal, it's vertical as well. with millions of products (UPCs) across different visual tolerances it's hard to generalize. your annotation method is indeed more efficient than a multistep \"go take a bunch of pictures and upload them to our severs for annotators\" but is still costly in terms of stakeholder buy-in, R&D, hardware costs, and indeed labor. if you can scope your verticals such that you only have, say, 1000 products the problem become feasible, but once you start to scale to an actual grocery store or bodega with ever-shifting visual data requirements the problem doesn't scale well. add in the detail that every store moves merchandise at different rates or has localized merchandise then the problem becomes even more complex. the simulated data also becomes an issue of cost. we have to produce a realistic (at least according to the model) digital twin that doesn't interfere too much with real data, and measuring that difference is important when you're measuring the difference between Lay's and Lay's Low Sodium. i'm not saying it's unsolvable. it's just a difficult problem reply whoitwas 2 hours agoparentprevIf you read the article, it was powered by 1000 cashiers in India, no sensors. reply wk_end 2 hours agorootparent> The company’s senior vice president of grocery stores says they’re moving away from Just Walk Out, which relied on cameras and sensors to track what people were leaving the store with. [emphasis mine] > Though it seemed completely automated, Just Walk Out relied on more than 1,000 people in India watching and labeling videos to ensure accurate checkouts. > According to The Information, 700 out of 1,000 Just Walk Out sales required human reviewers as of 2022. This widely missed Amazon’s internal goals of reaching less than 50 reviews per 1,000 sales. Amazon called this characterization inaccurate, and disputes how many purchases require reviews. > “The primary role of our Machine Learning data associates is to annotate video images, which is necessary for continuously improving the underlying machine learning model powering,” said an Amazon spokesperson to Gizmodo. However, the spokesperson acknowledged these associates validate “a small minority” of shopping visits when AI can’t determine a purchase. The article is kind of all over the place, but it sounds like there were lots of sensors and also lots of human intervention. reply jrpt 7 hours agoparentprevCome on, it isn’t anything to do with being a “marketing stunt.” Often products like this are expected to lose money at first, but they hope with enough R&D and scale that they can make it successful eventually. For example, you are pointing out that annotating is costly, but that’s an expense that scales independently of the number of stores. So with enough scale it wouldn’t be as big a deal. Or if they figured out some R&D that could improve it too. reply chrash 3 hours agorootparentright, that's how it starts. but the improvements in methodology simply aren't there as the ML sector has been laser focused on generality in modeling (GenAI as it's affectionately known). \"at scale\" doesn't just mean more stores; it means more products and thus more annotation. how many UPCs do you figure there are in a given Target or Whole Foods? i assure you it's in the millions. one advantages of the Amazon Go initiative is a smaller scope of products. reply shay_ker 10 hours agoparentprevare larger image/video models unable to catch things like Christmas branding? reply chrash 10 hours agorootparenta big problem in the space is that products that look very similar will be clustered in the same section. large models are very good at generalizing, so they may be more attuned to \"this is a Christmas thing\", but they won't know that it should be classified as the same UPC as the thing that was in that spot yesterday without you specifically telling it to. how would it know it's not a misplaced product or a random piece of trash? (you won't believe the things you find on store shelves once you start looking) you can definitely speed up your annotation time with something like SAM[1], but it will never know without training or context that it's the same product but Christmas (ie it resolves to the same UPC). [1]: https://github.com/facebookresearch/segment-anything reply smugma 12 hours agoprevUniqlo (in Japan and at least in SF) has a cool checkout method. You drop your clothes into a big bin (I’ve always done it one piece at a time, didn’t think to do all at once) and it adds up all your items. I’ve used this maybe 8 times, 100% accurate so far. Not sure how it works but I guessed RFID and quick Google appears to confirm: https://www.wsj.com/articles/uniqlos-parent-company-bets-big... reply awelxtr 11 hours agoparentSelf checkout systems based on RFID are very convenient, quick and quite accurate compared to self checkout on grocery stores'l. The main problem on groceries is that the tags are expensive compared to the product (tags prices are in the order of tens of cents depending on manufacturer and size) Disclaimer: I work on a RFID reader manufacturing company reply mike_d 4 hours agorootparentIt is almost here. Computer vision combined with some secret sauce that is cheaper than RFID that Walmart is asking supplier to implement. https://kioskindustry.org/walmart-self-checkout/ reply awelxtr 3 hours agorootparentThis doen't solve real time inventory. RFID does, also neither helps with EAS which RFID does' reply mike_d 2 hours agorootparentSome of my super smart colleagues solved real time inventory with big data within a small enough margin of error that Walmart scrapped the shelf scanning robots that were being deployed. EAS is a purely psychological deterrent, for liability reasons stores can't really do much when it goes off. As more and more shrink is the result of ORC, RFID will have a place but money is better spent on alternative technologies like facial recognition and ALPR. reply chrisbolt 3 hours agorootparentprevEAS: https://en.wikipedia.org/wiki/Electronic_article_surveillanc... reply parhamn 11 hours agorootparentprevAny ideas whats stopping it from becoming much cheaper? RFIDs on everything seem like a good move in the robotics age. reply kjkjadksj 11 hours agorootparentSeems like a lot of ewaste to me for marginal convenience otoh reply pcchristie 6 hours agorootparentAgreed. It would be cool if you could recycle them then and there for re-use. reply teruakohatu 5 hours agorootparentprevThere has been at least one study on just this question https://www.researchgate.net/publication/350413738_A_Model_o... reply SkyPuncher 8 hours agorootparentprevIt’s not very expensive to being with, but it’s magnitudes more expensive than a print tag. Print is either free (a package being",
    "originSummary": [
      "Amazon is discontinuing its checkout-less grocery stores using \"Just Walk Out\" tech due to accuracy and cost issues, shifting to Dash Carts and self-checkout counters.",
      "The \"Just Walk Out\" tech remains in select Fresh stores in the UK and Amazon Go convenience stores.",
      "Amazon aims to enhance its footprint in the supermarket sector by exploring different technologies and approaches."
    ],
    "commentSummary": [
      "The discussion delved into technology and automation in grocery and retail, especially Amazon's cashier-less checkout tech.",
      "Key points included the pros and cons of self-checkouts, the influence of delivery services on workers and eateries, skilled versus unskilled labor importance, and ethical issues related to job automation.",
      "Also addressed were concerns about theft prevention, the human element in automated processes, and the cost-effectiveness of technologies like RFID in retail."
    ],
    "points": 428,
    "commentCount": 594,
    "retryCount": 0,
    "time": 1712079576
  },
  {
    "id": 39907845,
    "title": "Renderlet: Revolutionizing Graphics with Cross-Platform WebAssembly",
    "originLink": "https://news.ycombinator.com/item?id=39907845",
    "originBody": "I used to work at Adobe on the infrastructure powering big applications like Photoshop and Acrobat. One of our worst headaches was making these really powerful codebases work on desktop, web, mobile, and the cloud without having to completely rewrite them. For example, to get Lightroom and Photoshop working on the web we took a winding path through JavaScript, Google’s PNaCl, asm.js, and finally WebAssembly, all while having to rethink our GPU architecture around these devices. We even had to get single-threaded builds working and rebuild the UI around Web Components. Today the web builds work great, but it was a decade-long journey to get there!The graphics stack continues to be one of the biggest bottlenecks in portability. One day I realized that WebAssembly (Wasm) actually held the solution to the madness. It’s runnable anywhere, embeddable into anything, and performant enough for real-time graphics. So I quit my job and dove into the adventure of creating a portable, embeddable WASM-based graphics framework from the ground up: high-level enough for app developers to easily make whatever graphics they want, and low-level enough to take full advantage of the GPU and everything else needed for a high-performance application.I call it Renderlet to emphasize the embeddable aspect — you can make self-contained graphics modules that do just what you want, connect them together, and make them run on anything or in anything with trivial interop.If you think of how Unity made it easy for devs to build cross-platform games, the idea is to do the same thing for all visual applications.Somewhere along the way I got into YC as a solo founder (!) but mostly I’ve been heads-down building this thing for the last 6 months. It’s not quite ready for an open alpha release, but it’s close—close enough that I’m ready to write about it, show it off, and start getting feedback. This is the thing I dreamed of as an application developer, and I want to know what you think!When Rive open-sourced their 2D vector engine and made a splash on HN a couple weeks ago (https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=39766893), I was intrigued. Rive’s renderer is built as a higher-level 2D API similar to SVG, whereas the Wander renderer (the open-source runtime part of Renderlet) exposes a lower-level 3D API over the GPU. Could Renderlet use its GPU backend to run the Rive Renderer library, enabling any 3D app to have a 2D vector backend? Yes it can - I implemented it!You can see it working here: https:&#x2F;&#x2F;vimeo.com&#x2F;929416955 and there’s a deep technical dive here: https:&#x2F;&#x2F;github.com&#x2F;renderlet&#x2F;wander&#x2F;wiki&#x2F;Using-renderlet-wit.... The code for my runtime Wasm Renderer (a.k.a. Wander) is here: https:&#x2F;&#x2F;github.com&#x2F;renderlet&#x2F;wander.I’ll come back and do a proper Show HN or Launch HN when the compiler is ready for anyone to use and I have the integration working on all platforms, but I hope this is interesting enough to take a look at now. I want to hear what you think of this!",
    "commentLink": "https://news.ycombinator.com/item?id=39907845",
    "commentBody": "3D + 2D: Testing out my cross-platform WASM graphics engine426 points by seanisom 17 hours agohidepastfavorite132 comments I used to work at Adobe on the infrastructure powering big applications like Photoshop and Acrobat. One of our worst headaches was making these really powerful codebases work on desktop, web, mobile, and the cloud without having to completely rewrite them. For example, to get Lightroom and Photoshop working on the web we took a winding path through JavaScript, Google’s PNaCl, asm.js, and finally WebAssembly, all while having to rethink our GPU architecture around these devices. We even had to get single-threaded builds working and rebuild the UI around Web Components. Today the web builds work great, but it was a decade-long journey to get there! The graphics stack continues to be one of the biggest bottlenecks in portability. One day I realized that WebAssembly (Wasm) actually held the solution to the madness. It’s runnable anywhere, embeddable into anything, and performant enough for real-time graphics. So I quit my job and dove into the adventure of creating a portable, embeddable WASM-based graphics framework from the ground up: high-level enough for app developers to easily make whatever graphics they want, and low-level enough to take full advantage of the GPU and everything else needed for a high-performance application. I call it Renderlet to emphasize the embeddable aspect — you can make self-contained graphics modules that do just what you want, connect them together, and make them run on anything or in anything with trivial interop. If you think of how Unity made it easy for devs to build cross-platform games, the idea is to do the same thing for all visual applications. Somewhere along the way I got into YC as a solo founder (!) but mostly I’ve been heads-down building this thing for the last 6 months. It’s not quite ready for an open alpha release, but it’s close—close enough that I’m ready to write about it, show it off, and start getting feedback. This is the thing I dreamed of as an application developer, and I want to know what you think! When Rive open-sourced their 2D vector engine and made a splash on HN a couple weeks ago (https://news.ycombinator.com/item?id=39766893), I was intrigued. Rive’s renderer is built as a higher-level 2D API similar to SVG, whereas the Wander renderer (the open-source runtime part of Renderlet) exposes a lower-level 3D API over the GPU. Could Renderlet use its GPU backend to run the Rive Renderer library, enabling any 3D app to have a 2D vector backend? Yes it can - I implemented it! You can see it working here: https://vimeo.com/929416955 and there’s a deep technical dive here: https://github.com/renderlet/wander/wiki/Using-renderlet-wit.... The code for my runtime Wasm Renderer (a.k.a. Wander) is here: https://github.com/renderlet/wander. I’ll come back and do a proper Show HN or Launch HN when the compiler is ready for anyone to use and I have the integration working on all platforms, but I hope this is interesting enough to take a look at now. I want to hear what you think of this! reactordev 4 hours agoSkip the PAL step and just go right into SetupRuntime with the arguments. Non-gfx devs don’t know about these things and adding extra steps in your API is unnecessary. Since PAL isn’t used anywhere else. Other than that, I would highly recommend getting on the WebGPU train using wgpu-native or dawn. (IPal should be a member of IRuntime and is ripe for removal for WebGPU context). Keep it up! Bookmarked. reply seanisom 4 hours agoparentGreat suggestion, appreciate it. wgpu is coming! reply sannysanoff 46 minutes agoprevIs there any example project utilizing one of the available WASM runtimes that could load, instantiate and run WASM module on android in near native speed, not interpreted (not web browsers)? Recently I investigated few WASM runtimes and honestly could not manage achieving this task. Only suggestion I got from people is load bunch of packages using termux package manager and operate in shell environment on Android to compile and run example projects. I would appreciate link to some project that results in APK which (as part of its work) calls WASM function in non-interpeted mode on android (arm/x86). reply lerpgame 15 minutes agoprevhmm…i do mainly web stuff but i read in some blog somewhere that the v8 runtime compiler optimizes the code better than writing the same thing in assembly script when working directly on top of typed buffer arrays, is this true? reply hardwaresofton 1 hour agoprevA talk given by OP which is a fantastic intro with 2 successful demos across 2 platforms :) https://www.youtube.com/watch?v=CkV-nWFXvbs Disclaimer: I currently work at a company in the WebAssembly space that was involved with this conference reply boomskats 1 hour agoparentGreat talk! Same one I was referring to in my comment below. reply ronyeh 13 hours agoprevAwesome project. What are you planning for text and font support? Some graphics engines don’t support all the ways you might want to display text. Will we be able to load OTF or WOFF2 files and display arbitrary strings? :-) reply seanisom 13 hours agoparentThanks! I haven't looked deeply into font yet, but I've always been partial to HarfBuzz for shaping, so will probably build on top of that. It also has an experimental Wasm shaper which certainly served as a bit of inspiration for the design of this. reply spuzvabob 1 hour agorootparentThere is a well maintained Wasm build of harfbuzz:with both OpenType and AAT shapers support, which should be enough but you can also provide your own shaper implementation in Wasm yes. We're successfully using Wasm harfbuzz to render text in a web-based design tool with relatively high usage so there should be no issues integrating it :) reply ronyeh 13 hours agorootparentprevNice! Looking forward to your alpha release. (And eventual HarfBuzz integration.) reply zengid 12 hours agoprevThis is super neat and I am very interested! I'm in a rush so I can't look to closely now but I have a few questions (and please forgive any stupid questions, I'm not a graphics dev, just a hobbyist): What's the runtime like? Is there an event loop driving the rendering? (who calls the `render` on each frame? are there hooks into that? ) FFI story? Who owns the window pointer? I'm interested in audio plugins, and VSTs (etc) have a lot of constrains on what can be done around event loops and window management. JUCE is pretty much the de-facto solution there, but it's pretty old and feels crufty. reply PaulDavisThe1st 10 hours agoparentThe limits on what audio plugins can do is not a function of the drawing toolkit, but the fact that they do not own the event loop if the GUI is run in-process with the host. And as long as they do, they will never own the evelop loop. In addition (and mostly related to this) the top level window they appear in is owned by the host, which also inherently limits the plugin's role in window management. If you want more, use the capability built into LV2, AU and VST3 for out-of-process GUIs for a plugin (LV2 has had this for more than a decade). CLAP has, I think, abandoned plans to support this based on lack of uptake elsewhere. I'd hardly call JUCE \"pretty old\", but then I'm a lot older than JUCE. And it's likely only crufty if you're more used to other styles of GUI toolkits; in terms of the \"regular\" desktop GUI toolkits, it's really bad at all. reply zengid 5 hours agorootparentHey Paul, thanks for sharing! Yes I think JUCE is great, It's very well made, but it drives you into a very narrow path of either using everything in the library, or leaving you to fend for yourself (which I admit may be a normal experience for C++ devs). For instance, the ValueTrees frequently used for UI state are very powerful, but they're not very type safe (or thread safe), and they feel clunky compared to more contemporary reactive state management patterns like signals. I'm sure folks who use ValueTrees are happy, but I don't see much advancement to that pattern being shared in the JUCE forums. If y'all have some better tricks over in the Ardour project I'd love to know! (BTW, I'm a fan of y'all's work. I really enjoyed reading some of the development resources, like the essay on handling time [0]). [0] https://ardour.org/timing.html reply seanisom 11 hours agoparentprevGreat questions! The host app owns the event loop. I don't foresee that changing even once we re-architect around WebGPU (allowing the Wasm guest to control shaders), as the host app is responsible for \"driving\" the render tree, including passing in state (like a timer used for animations). The host app owns the window pointer, as renderlets are always designed to be hosted in an environment (either an app or a browser). Open to feedback on this, though. FFI is coming with the C API soon! I don't know much about audio but I see a ton of parallels - well-defined data flow across a set of components running real-time, arbitrary code. Simulations also come to mind. reply zengid 5 hours agorootparentThank you for the reply! I'm excited to watch as this project progresses, and I wish you the best of luck! reply pdntspa 4 hours agoparentprev> JUCE is pretty much the de-facto solution there, Is it though? iPlug nee wdl-ol nee iPlug2 seems pretty good too. JUCE stuff has a pretty distinct and slightly obnoxious look and feel that takes a fair bit of effort to strip out reply iFire 13 hours agoprevWe've been doing work in Godot Engine trying to get wasm working. How did you overcome the shared array buffer accessibility problem on safari vs access to ad networks which is important for online games? I called it single threads vs regular builds. Hope to help make sure there's a diverse set of rendering kernels for everyone. Edited: Link to our work at making portable 3d graphics on the web with an editor. https://editor.godotengine.org/releases/latest/ reply seanisom 13 hours agoparentBig fan of Godot! I think it has done wonders to make graphics more accessible. From an Adobe perspective - it doesn't. If you go to photoshop.adobe.com in Safari, you will see the answer. Things can work in a single-threaded build, but that is not production code. I can't speak for the Safari team, but I do see this getting traction soon with the current priorities for Wasm. Seems like now the most common answer is just to use Chrome. reply iFire 13 hours agoparentprevWe also collaborate with https://github.com/thorvg/thorvg. We were impressed by your work, https://github.com/rive-app and https://graphite.rs/ reply Keavon 12 hours agorootparentThanks! If perhaps we spoke at GDC (taking a guess given the context), it was nice meeting you! (Keavon from Graphite here.) reply seanisom 11 hours agorootparentHey Keavon, I'm also a big fan, been lurking in your Discord for years! The design of the render tree of Wasm nodes certainly took inspiration from Graphite's node system. reply spxneo 11 hours agoparentprevwhew game engine running on WASM + WebGPU would finally be what it takes to power browser based AAA titles. We shouldn't have to download executables via garden walled ecosystems that take a huge chunk of devs revenues reply jms55 9 hours agorootparentI don't see WASM/WebGPU changing anything when it comes to gaming, as an industry, personally. 3d visualizations and interactive websites? Yeah definitely a nice improvement over WebGL 2, if years late. The OP's experience with Adobe is a great example of this. WebGPU is pretty far behind what AAA games are using even as of 6 years ago. There's extra overhead and security in the WebGPU spec that AAA games do not want. Browsers do not lend themselves to downloading 300gb of assets. Additionally, indie devs aren't using Steam for the technical capabilities. It's purely about marketshare. Video games are a highly saturated market. The users are all on Steam, getting their recommendations from Steam, and buying games in Steam sales. Hence all the indie developers publish to Steam. I don't see a web browser being appealing as a platform, because there's no way for developers to advertise to users. That's also only indie games. AAA games use their own launchers, because they don't _need_ the discoverability from being on Steam. So they don't, and avoid the fees. If anything users _want_ the Steam monopoly, because they like the platform, and hate the walled garden launchers from AAA companies. EDIT: As a concrete example of the type of problem's WASM for games face, see this issue we discovered (can't unload memory after you've loaded it, meaning you can never save memory by dropping the asset data after uploading assets to the GPU, unless you load your assets in a very specific, otherwise suboptimal sequence): https://github.com/bevyengine/bevy/issues/12057#issuecomment... (I work on high end rendering features for the Bevy game engine https://bevyengine.org, and have extensive experience with WebGPU) reply pjmlp 1 hour agorootparentI fully agree with you, hence why most game studios on the Web rather use streaming from hardware where those GPU capabilities are fully available than with constrained browser APIs. WebGL and WebGPU are mostly fine for visualization and ecommerce, and that is about it. Ah, and shadertoy like demos as well, probably their biggest use case. reply seanisom 8 hours agorootparentprevLots of interesting points in there, and working on Bevy I'm sure you have much more extensive WebGPU expertise than me. I agree that the feature set around WebGPU is constrained and becoming outdated tech compared to native platforms. It shouldn't have taken this long just to get compute shaders into a browser, but here we are. The lack of programmable mesh pipelines is a barrier for a lot of games, and I know that's just the beginning. For memory, architecturally, that's why I'm treating wander as a tree of nodes, each containing Wasm functions - everything gets its own stack, and there is a strategy to manage Store sizes in wasmtime. Deleting that is the only way to free memory vs a singular application compiled to Wasm with one stack/heap/etc. More of a data-driven visualization framework than a full engine like Bevy, which I still think is one of the most elegant ways to build browser based games and 3d environments. reply pjmlp 1 hour agorootparentIt should be noted that the reason we don't have compute shaders on WebGL was Chrome team dropping the ball on them. https://github.com/9ballsyndrome/WebGL_Compute_shader/issues... https://www.khronos.org/webgl/public-mailing-list/public_web... https://issues.chromium.org/issues/40150444 reply PaulDavisThe1st 5 hours agorootparentprevConsider also the dramatic ... ahem ... success of the attempt to launch zero-day test versions of games via essentially VNC-via-java-in-the-browser. AFAICT (I was peripherally involved with one of the companies that did this work), this really went nowhere, even though it offered \"play this new game from any java-equipped browser\". reply jasonjmcghee 10 hours agorootparentprevCan't https://bevyengine.org/ do this? AFAIK https://wgpu.rs/ makes this possible with Rust. --- But this is very different than what was demonstrated in the vimeo video. reply Animats 6 hours agorootparentNot all that different. See these WGPU demos.[1] As someone who's been using the Rend3/WGPU/Vulkan stack for over three years, I'd like to see some of these renderer projects ship something close to a finished product. We have too many half-finished back ends. I encourage people who want to write engines to get behind one of the existing projects and push. [1] https://wgpu.rs/examples/ reply jasonjmcghee 6 hours agorootparentMy understanding of the project here (Renderlet) was it allowed direct embedding in other non-wasm projects, which I didn't fully wrap my head around, allowing for injecting this engine inside of others? Or something to that effect? Which is quite different than a renderer that targets wasm/webgpu. I think super highly of, and have used wgpu a fair amount. I just interpreted Renderlet to have different goals. reply seanisom 6 hours agorootparentThat's exactly it. With renderlet, the goal is to compile the \"frontend\" code that's driving the rendering pipeline to WebAssembly, and provide a runtime that embeds that in any app, with the host app providing any configuration necessary to connect renderlet modules and use its canvas. On the \"backend\", we will switch fully to wgpu as we retool around wasi-webgpu. I explicitly don't want to rebuild a project like wgpu, and everybody should commit upstream to that - we will likely have stuff to upstream as well. reply seanisom 11 hours agorootparentprevThis right here. The web is the OS of the future - the standards are getting there, the tools are just starting to catch up. reply PaulDavisThe1st 5 hours agorootparentWhat platform(s) do you think browsers will run on? reply seanisom 5 hours agorootparentMore of a comment on how apps are being built in the future - web-first is becoming the default. I already see web even taking over in things like embedded UIs where native toolkits like QT historically were popular. reply nasso_dev 11 hours agoprevoh my god this is awesome! that's exactly what ive been dreaming about for the past few years... wasm has a lot of potential as a portable unit of graphics/audio/multimedia computation! im glad you were able to take the time to build it! reply boomskats 15 hours agoprevNot much to add, just wanted to say I thought your presentation at wasm I/O in Barca a couple of weeks ago was amazing and it's great to see this work getting some attention! reply mambru 14 hours agoparentBarca -> rowing boat Barça -> the football club Barna -> cute form of Barcelona reply boomskats 13 hours agorootparentI guess a lot of the English-speaking world has (mis)appropriated the anglicised name of the football club? Still, for what it's worth, b7a is my favourite city so far. reply astlouis44 12 hours agoprevGreat to see more projects in the 3D graphics/WASM space! Any tips for getting into YC? For context, my team has spent the past few years porting Unreal Engine 5 to WebGPU and WebAssembly - we have a multi-threaded renderer as well as an asset streaming system that fetches in at runtime asynchronously (as needed) so users don't need to download an entire game/app upfront. This also frees up needing to have the whole application in memory at once. We've also built out a whole hosting platform and backend for developers to deploy their projects to online. You can learn more about SimplyStream here: Website: https://simplystream.com/ Blog post: https://simplystream.com/create/blog/latest Demos: https://simplystream.com/demos reply Animats 6 hours agoparentI've been trying to run the demos in Firefox on Linux, with an NVidia 3070. For the ones that will start, I see \"WONDER\", then a \"loading\" screen, with about 100Mb/s download traffic for about 10 seconds. Then RAM usage increases over about two minutes to 24GB or so. Then I get \"Gah. Your tab just crashed\" in Firefox. reply seanisom 11 hours agoparentprevI'm probably the worst person to ask for advice about applying to YC - it just kind of happened. I was sad when UE4 sunset HTML5 support, and glad to see a spiritual successor! There are a lot of parallels to other large in-browser apps in terms of load time for games - not just for the content but the size of game code itself. Are you able to use streaming compilation or some sort of plugin model? reply pjmlp 1 hour agoparentprevMost of the demos just kill Chrome, on latest version, running on NVidia Quadro T1000. reply fire_lake 2 hours agoprevCould this be the foundation of an Electron replacement? reply hardwaresofton 1 hour agoparentThis is a natural next step of this kind of tech (and WebAssembly tech in general) -- but that seems to not be the direction that renderlet is going... No reason they couldn't do it, but actually rendering 2D/3D and specializing in making GUI application development easier are similar but not quite the same. Someone could definitely build another \"last\" cross platform application development toolkit with WebAssembly right now, and have it actually work reasonably well, and be slightly more desirable than flutter (and it could absolute use flutter/skia underneath) since you could build without the Dart (for those who don't necessarily prefer Dart). reply vmfunction 1 hour agorootparentOr port QT to WASM. reply hardwaresofton 56 minutes agorootparentWell the great thing about WebAssembly is that you can port QT or anything else to be at a layer below -- thanks to WebAssembly Interface Types[0] and the Component Model specification that works underneath that. To over-simplify, the Component Model manages language interop, and WIT constrains the boundaries with interfaces. IMO the problem here is defining a 90% solution for most window, tab, button, etc management, then building embeddings in QT, Flutter/Skia, and other lower level engines. Getting a good cross-platform way of doing data passing, triggering re-renders, serializing window state is probably the meat of the interesting work. On top of that, you really need great UX. This is normally where projects fall short -- why should I use this solution instead of something like Tauri[2] which is excellent or Electron? [0]: https://github.com/WebAssembly/component-model/blob/main/des... [1]: https://github.com/WebAssembly/component-model/blob/main/des... [2]: https://tauri.app/ reply pjmlp 1 hour agoparentprevElectron replacements have existed for decades since Active Desktop and XUL were a thing, either use the system browser with a daemon/service, or make use of Webwidgets. reply satvikpendem 10 hours agoprevHave you read this article by the lead developer of Flutter, Ian Hickson [0]? It describes using WASM just as you describe to have a fully cross platform UI framework, which is a concept that Flutter uses. [0] https://docs.google.com/document/d/1peUSMsvFGvqD5yKh3GprskLC... reply seanisom 10 hours agoparentThanks - that link does not appear to be open access, anyways I don't think I've seen it. I'm familiar with Flutter at a high-level (Kevin Moore gave a great talk on it at Wasm I/O), and I think other than requiring users to work in Dart, it is probably one of the most powerful ways to do cross-platform UI today. Worth noting that their original GPU backend was Skia, and now they are retooling around Flutter GPU (Impeller)[0], which is kind of designed similarly as an abstract rendering interface over platform-specific GPU APIs. [0] https://github.com/flutter/flutter/wiki/Flutter-GPU reply satvikpendem 9 hours agorootparentI edited the link to be public, let me know if that still works. I think the ideal in that article is that people can write components in whatever languages they want, and when they compile to WASM, they can all interoperate. It reminds me of all of those compile-to-Javascript languages for writing micro-frontends, although there is not as much interoperability from a React boundary to say, a ClojureScript boundary. By the way, what are you building as a solo founder for YC? Is it related to this project? For this project, I'm curious to see how exactly WASM interoperates with the GPU directly, bypassing the platform specific APIs. Do you still have to write GPU-specific parts for each of the GPU manufacturers? I wonder if there would be an open standard called WASM-GPU in the future that abstracts over these but doesn't necessarily touch any of the OS directly. reply seanisom 8 hours agorootparentGot it, thanks. Not what I was expecting. To me, this reads like the intersection of \"Web Components as Wasm\" and \"The Browser as an OS\" - almost something analogous to WASI as browser APIs that are delivered via Wasm ABI instead of JS/WebIDL. It's an interesting take, and as long as it can operate alongside existing code, I'm all for that. There are strong parallels to what we're building - small modules of Wasm graphics code that can interoperate across a common interface. Check the repo for the GPU integration - it's like a super trimmed down version of wgpu, where graphics data is copied out of Wasm linear memory and a host specific API (WebGPU/OpenGL/DirectX) takes care of the upload to the GPU. There is a wasi-webgpu WebAssembly L1 proposal that I am involved with in the works, driven by Mendy Berger, and at some point all of this will be tooled on top of that with wgpu as a backend. For renderlet the company, the goal is to build developer tools that make it easy to build renderlets and these kinds of applications without having to write raw Wasm code. The meta-compiler in the video is the first step in that direction! The runtime itself will always be open-source. reply nmfisher 7 hours agoparentprevRelated - I’ve written a Flutter package to wrap the Filament PBR rendering package and I hacked together a WASM implementation so I could build 3D apps in Flutter for web. It’s still just experimental (I’m waiting for some upstream Dart fixes to land around WASM FFI, and shared memory support would be nice in Flutter too) but I think it’s promising. Bundle size is a bit of an issue at the moment too. https://github.com/nmfisher/flutter_filament reply seanisom 7 hours agorootparentThis is awesome! I'm not fluent with Flutter/Dart but would like to dig in to how the build / Wasm packaging works. The state of shared memory for Wasm is not great, although raw SharedArrayBuffers work ok in a browser for running multiple guests. Getting multi-memory properly working through llvm is likely a better solution. We've got a bundle size issue as well even with -O3. I thought it was due to the amount of templated glm simd code we run, but now am convinced its deeper than that into Emscripten. Haven't been able to look into deeply yet. reply sheepscreek 10 hours agoparentprevMight be this article: https://docs.google.com/document/u/0/d/1peUSMsvFGvqD5yKh3Gpr... reply nchmy 9 hours agorootparentnope reply mendyberger 9 hours agoparentprevThis is the public link https://t.co/3xeGnKhwYr reply iFire 13 hours agoprevFor cad kernels I highly recommend manifold https://github.com/elalish/manifold to embed in your app. reply seanisom 13 hours agoparentManifold is awesome! Would love to get that integration going. I've implemented a lot of procedural geometry functions, but that is a long way from an actual CAD kernel. reply mendyberger 16 hours agoprevCool project! Looks like it supports geometry and textures now, any plans to support shaders? reply seanisom 15 hours agoparentYes! There are a few different approaches to making that work - one would be to have an intermediate shader representation generated from Wasm compile to native platform shaders on the host graphics API. Longer-term, will likely expose WebGPU WGSL shaders to Wasm directly. reply mendyberger 16 hours agoprevReadme says it's a C++ library. Any plans to support higher level languages such as Go or even Python? reply seanisom 16 hours agoparentYes! It's kind of a pain to build now, so will probably shift to shipping as a .so/dll with a raw C api in a future version. With that, should be easy to generate bindings for any language - the host API footprint is minimal. reply billconan 16 hours agorootparentI don't follow this part. if the lib is shipped as .so/dll, how can it be compiled into wasm? reply seanisom 15 hours agorootparentThere is the host API - wander, which contains the Wasm runtime and interfaces with the GPU. The actual graphics code is always compiled to Wasm. reply nerpderp82 13 hours agorootparentCan one use with WebGPU in the browser? I see you answer that here https://news.ycombinator.com/item?id=39909440 The primary issue with things that include their own Wasm env, that then moving that system to the web doesn't work because you can't run wasm in wasm. reply seanisom 13 hours agorootparentYes! Not in the open-source repo yet (because it's currently broken :) ) but you can see it in the video, and will have it working again soon. That's exactly the goal - one wasm binary with defined input/outputs that can be loaded either in a browser or running in any app outside of a browser. reply nerpderp82 12 hours agorootparentThen effectively your non-browser container is a browser subset just for your application. You could run a browser and record all the page faults, then remove all the code you didn't run. https://fgiesen.wordpress.com/2012/04/08/metaprogramming-for... reply speps 14 hours agoprevI understand the appeal of Rive. However, even if their renderer is open source now, their editor isn't and their free tier is quite limited. Have a look into supporting Ruffle/SWF content, Lottie, etc. Also, for a renderer there is one by Mozilla called Pathfinder: https://github.com/servo/pathfinder reply neurowave 11 hours agoparentCan you share what you find limiting in the free tier? Would love to know more! I'm one of the founders btw reply speps 8 hours agorootparentSure, I think it's probably generous from the user count point of view but incredibly limited from the number of files. And it seems you have to use provided fonts in the free tier... I think Rive should offer the Editor free like Unity and then charge for additional services like console support, dedicated support, troubleshooting, etc. as that's much more common business model for game middleware. The same applies to Unreal Engine where Switch/PS5/Xbox support is gated behind the respective access to the official dev portal and Epic's own Perforce rather than GitHub. And Perforce support for example should be promoted for pro tiers. I see a banner mentioning \"Rive for Game UI\" which is great to see but really the whole platform should be a Flash replacement. It shouldn't just be for doing UIs in games or animated content, it could be used to make full 2D games. Flash was so popular because of its versatility. There were middleware taking Flash content directly into game UIs (ScaleForm) and there is middleware supporting WebKit for game UIs (Coherent labs). Both of these have extensive scripting support (respectively ActionScript and JavaScript) allowing UI designers and coders to create reactive and flexible content, even procedural content like lists of things etc. By the way, the only way from mobile to get to the downloads link on the main site is only behind the online editor login. I get why but I thought at first that the Editor was online only because of that. reply neurowave 7 hours agorootparentI think that perhaps what you’re missing is that most of those tools charge for the runtime in some capacity. We took a different approach. The Rive Runtime and file format is free and open source, the editor is how we monetize. Users can have confidence that they will forever have access to the runtime and their files. Anybody can build an editor. Regarding file limits, stay tuned for some announcements there. Regarding Flash, yep that’s where we’re headed (and most of the use cases on the site should support that). We have some big features launching this year like audio, fluid layouts, and scripting. The banner was added because we’ve been attending game conferences and the game ui market segment is something we’re highlighting right now. Game UI is in dire need of better tools and it’s a market segment we can quickly lead with our current feature set. reply seanisom 11 hours agorootparentprevInterested as well - I think you've built an incredibly productive editor with Rive - a spiritual successor to Flash! reply seanisom 13 hours agoparentprevThanks! Lottie should be straightforward. SWF is a much higher bar, but would be useful. reply baudaux 2 hours agoprevIs it limited to wasmtime or can it run in a web browser ? reply astlouis44 12 hours agoprevUnreal Engine 5 just got a WebGPU/WASM port: https://news.ycombinator.com/item?id=39911041 reply virtualritz 15 hours agoprevIsn't that what https://github.com/gfx-rs/wgpu is providing? reply seanisom 15 hours agoparentPartially. wgpu can translate graphics api calls like WebGPU to platform specific APIs - this is something I had to implement on the backend. In the future, will likely tool on top of wgpu on the backend as wasi-gfx (WebGPU) becomes a reality. What we do on top of that is compile the graphics code to wasm and provide a well-defined interface around it, so it can run/work inside any application. reply efnx 4 hours agorootparentFirst off, congrats! Can you elaborate on what the “graphics code” might be in this case? Many Rust graphics engines seem to cover the same ground by having asset loading cfg’d on the target (wasm vs native). What does your project provide that a dev wouldn’t get with Rust + a wasm compatible engine? reply et1337 14 hours agoprevWhat’s the story with threading on the web these days? My impression was that the browsers have purposely and permanently handicapped some things necessary for performance in order to prevent things like rowhammer and speculative execution exploits. But I haven’t paid super close attention. reply seanisom 13 hours agoparentIt works well now! You use a SharedArrayBuffer to communicate between Web Workers. Was indeed a dark couple of years where the meltdown stuff disabled that, but there are now specific cross-origin headers that are used to isolate the SharedArrayBuffer from outside access. reply dekhn 10 hours agorootparentClassic inner platform effect. WASM has taken 7 years ago to get where desktop C++ was 20 years ago. Or rather, within approximate psuedo-spitting-distance to desktop. reply dsp_person 16 hours agoprevWhat do you think of sokol in comparison? reply seanisom 16 hours agoparentsokol is great - I think of it as more of an \"STB for apps\". With renderlet/wander the goal is more to express graphics using higher level constructs and automatically generate the runtime code behind it. For example, with the Wasm build of sokol you could build a canvas-style app that directly runs in a browser, whereas with renderlet you can build a function that can parametrically render grids that can be run in (any) app like that. reply flohofwoe 15 hours agorootparentTBH I would love an extended WASI standard with 'media apis' (window, 3D, audio, input) to run sokol code compiled to WASM in without having to compile/distribute per-platform native apps. Deno seems to work on that idea [0], but having a WASI like standard would be better of course. [0] https://github.com/deno-windowing PS: How much work was it to \"port\" the Rive renderer? Would be great to see a blog post or similar about how you approached that and about any difficulties on the way :) reply seanisom 15 hours agorootparentYes! wasi-webgpu is coming, as well as more APIs with wasi-gfx. Getting rive-renderer working was not hard because in the demo its running on the host side, and not in Wasm yet, although compiling for Windows/DX11 took some minor changes. Getting it fully working in Wasm outside of the browser looks to be non-trivial, but doable, but will likely require upstream changes. reply mendyberger 15 hours agorootparentprevThis? https://github.com/WebAssembly/wasi-webgpu reply flohofwoe 15 hours agorootparentYeah, but the 'wasi-canvas' part is really important to get something on screen (as opposed to \"just\" using WebGPU for compute-tasks). Also a simple wasi-audio API is needed (preferrably something less overengineered than WebAudio, just a simple sample-streaming API would be perfect). reply boomskats 14 hours agorootparentAre you involved at all with the Bytecode Alliance or the decisions around the WASI proposals/standards? It feels like your take on these things would be super valuable given all the work you've done. They're a very open minded group. reply seanisom 14 hours agorootparentprevAlso, with the solid foundation and simple API footprint you've built for APIs like sokol_audio, would be interesting to see if they could be expressed in WIT and used as a basis for something like a wasi-audio. reply seanisom 15 hours agorootparentprev+1 for Audio and lots of other APIs necessary to make WASI more like a true OS. With Preview 2 / Component model, hoping the pace of contributions rapidly increases. reply dartos 14 hours agorootparentprevSo kind of like a graphics transpiler? reply seanisom 13 hours agorootparentYes, that's a good mental model. Input - high-level description of graphics, output low-level graphics code running in Wasm. reply password4321 14 hours agoprevWhen you launch include WASM in the title for more traction. reply dang 14 hours agoparentI put it in this one too. Thanks! reply bitwize 1 hour agoprevListen to some of the others in this thread. Don't waste your time with kid stuff. Stick to Unreal or Unity: https://news.ycombinator.com/item?id=33452920 You can get your game/app ideas across far faster by building skills in Unreal/Unity than by using some bespoke little engine. Collaborate with more people, too. reply JoeyJoJoJr 10 minutes agoparentYou and the others are missing the whole point. This isn’t meant to be an Unreal or Unity replacement. And besides that point, what is wrong with the “kid” stuff. A bunch of masterpieces have been created in such kid stuff. Celeste, Hotline Miami, and Dead Cells come to mind. I can’t wait for the day that actual kids are building their own cross platform game engines on a better tech foundation. reply JonChesterfield 52 minutes agoparentprevCuda is nasty and implementing your own engine is great. One of those two is in the process of falling apart and they're both very complicated, no deal for me. reply moopoo 1 hour agoparentprevDismissing someone's well thought out hard work as \"kid stuff\" is really quite rude. Do better please. reply yacine_ 12 hours agoprevi've been using sokol.h and it just works :) reply billconan 16 hours agoprevdo I still need to write platform specific shaders using this library? reply seanisom 16 hours agoparentThe long-term goal is no - wander should handle shader compilation automatically. In the current version, the host app has to attach a shader using the host's shader API to render arbitrary geometry and textures. Was looking at several different approaches to this, one of which would be cross-compiling wasm to spir-v. Most likely will expose a higher-level shader API (think shadertoy) and have wander compile to the platform backend. Also will be able to run WGSL shaders directly through Wasm with wasi-gfx support. reply billconan 16 hours agorootparentor maybe support https://github.com/shader-slang/slang reply seanisom 15 hours agorootparentYes! Will look into that reply throwaway290 5 hours agoprevDeserves a \"Show HN\". reply seanisom 5 hours agoparentAppreciate it. It's coming! I want to get the compiler working and generally available and everything working seamlessly for Web first. Stay tuned! reply adfm 10 hours agoprevIs there much of a performance hit with a stereo view? reply seanisom 7 hours agoparentI haven't worked with stereo setups with this codebase yet, but as it is just wrapping underlying platform-specific GPU APIs, it should be a similar performance profile. On average, running the Wasm guest code is about 80% of the speed of a native build I use. That is both dependent on what is running in Wasm and not a very scientific measurement - wander needs better benchmarks. We think that performance profile is sufficient for anything that needs a GPU except the highest-performance 3D games. reply yazzku 8 hours agoprevWhat exactly is in a renderlet, or what assumptions does a renderlet make? For example, if I wanted to LoadFromFile() + Render() the building renderlet into a deferred rendering pipeline, would I be able to do that? reply seanisom 7 hours agoparentNot much yet! :) The renderlet is a bundle of WebAssembly code that handles data flow for graphics objects. Input is just function parameters, output writes serialized data to a specific place in Wasm linear memory. With the Wasm Component Model, in the future can use much more complex types as input and output. LoadFromFile() - Instantiates the Wasm module Render() - runs the code in the module, wander uploads the output data to the GPU Functions on the render tree - do things with the uploaded GPU data - like bind a texture to a slot, or ID3D11DeviceContext::Draw, for example. There's some nuance about shading. In the current version, the host app is still responsible for attaching a shader, so should be no issue using the data in a deferred shading pipeline. In the future, the renderlet needs to be able to attach its own shaders, in which case it would have to be configured to use a host app's deferred shading pipeline. I think it is possible, but complicated, to build an API for this, where the host and then the renderlet are both involved in a lighting pass. Of course, if all shading is handled within the renderlet, it entirely the concept of deferred shading, and this becomes an easier problem to solve. reply qingcharles 11 hours agoprevTotally off-topic, but in that video you have some preview view on the right-side of your code window in VS where you can scroll visually through a large file. How the hell do you switch that on? I've been using VS for 30 years and never seen that, but it would be really helpful for the shitty apps that I write for my own use which are single-file monsters. reply morder 11 hours agoparentRight click the scroll bar and choose \"scroll bar options\" then under \"behavoior\" select the 2nd option with the source overview set to \"wide\" reply qingcharles 10 hours agorootparentThank you! :) I'd gone through every menu and right-clicked everywhere except the scroll-bar. For anyone else that ends up here, I also had to click the radio button for \"Map mode\" too. reply seanisom 11 hours agorootparentprevThis. I think it used to be a productivity power tool that they since incorporated into the core editor. reply doctorpangloss 14 hours agoprev> If you think of how Unity made it easy for devs to build cross-platform games, the idea is to do the same thing for all visual applications. But why wouldn't I \"just\" use Unity? I agree with you. Nobody cares about the platform specific details anymore, and people are willing to pay a little bit of money for an end-all-be-all middleware. I have gone my whole life not paying attention to a single Apple-specific API, and every single time, someone has written a better, more robust, cross-platform abstraction. But Unity is already this middleware. I already can make a whole art application on top of Unity (or Unreal). People do. Sometimes people build whole platforms on top of Unity and are successful (Niantic) and some are not (Improbable). You're one guy. You are promising creating a whole game engine - you're going to get hung up on not using the word game engine, but that is intellectually honest, it is a game engine - which a lot of people 1,000x better capitalized than you have promised, and those people have been unable to reach parity with Unity after years of product development. So while I want you to succeed, I feel like a lot of Y Combinator guys have this, \"We make no mistakes, especially we do not make strategic mistakes.\" It's going to be a long 3 years! reply seanisom 14 hours agoparentWithout going into the motivations for building a startup and doing Y Combinator, I do agree with many of your points. People can use Unity to build games and non-games. I personally don't think it fits a lot of different use-cases or application models and that it tends to be most successful in specific gaming verticals, but if it works well for you, by all means use it! I'm strategically betting both on the lines between what is viewed as a game and not blurring, as well as developers needing a friendlier, more flexible way of building this kind of interactive content. I'm by no means under the illusion that strategic mistakes won't be made, or that this won't be a 10-year+ journey - realistically many (most?) successful companies have a very nonlinear path, including Unity themselves. reply mentos 13 hours agorootparentI agree Unreal and Unity are not appropriate but I do wonder about Godot. Its early enough where it doesn't have the strong connotations of being a game engine yet. I've seen some cool applications made in it too (https://www.youtube.com/watch?v=9kKp0oguzr8). So I wonder if you could apply your energy to making it more cross platform using WASM (if that's even necessary) and extend it with your own UI language instead of rolling your own? reply seanisom 10 hours agorootparentI think Godot is the closest thing to this today, and I agree, would love to work with them! Particularly on the Wasm and packaging side of things. reply dartos 14 hours agoparentprevUnity is so much larger and more complex than a graphics middleware. It comes with physics engines, telemetry, networking, a c# runtime and probably even more. I don’t think that any of the adobe suite would ever be built in unity bc why do they need to ship a physics engine with their photo editor. Not to mention that unity is backed by an, imo, untrustworthy company who’s obviously willing to change pricing structure on a dime and retroactively. reply doctorpangloss 14 hours agorootparent> ever be built in unity bc why do they need to ship a physics engine with their photo editor. I know you narrowly mean \"rigidbody physics for the purpose of videogames.\" But Adobe did ship a physics engine with their photo editor! They discontinued their \"3D\" support, and raytracing is most definitely physics with a capital P, but they were shipping it for a long time. If you have an even more normal definition of physics, to include optical physics, well they have a CV solution for many features like camera RAW processing, removing distortion, etc. > It comes with physics engines, telemetry, networking, a c# runtime and probably even more. Because that is what people need to make multimedia applications. reply pphysch 14 hours agorootparentprevI agree, I think \"game engine\" is a misnomer for what are better termed \"game (dev) studio\", like Unity. They include a sophisticated game engine but also a lot of supporting tools and GUIs. reply joeyjojo 9 hours agoparentprevThere absolutely is a need for a robust cross-platform rendering/multimedia solution, more in a similar vein to SDL than Unity or Unreal. The offering of Unity, Unreal, and perhaps Godot is just abysmal when considering that for all of the man hours put into the game development space, that is basically all we got. There should be hundreds of viable cross platform game engines catering to a wide variety niches that continually stretch the bounds of what a game actually is and how it can be represented. Game libraries such as Monogame, Heaps, Raylib, Love2D, etc just wouldn't be that popular if Unity and Unreal are the be all and end all. Adobe Air was once a popular choice (a very large number of top 50 app store games were built with Adobe Air) and I'd wager still would be if it didn't collapse under its technical weight. Currently it is the low level, cross platform layer that is the most complex and the biggest hurdle towards making a game engine viable. If it wasn't so insanely complex, and the technical barrier towards making your own engine is reduced, the tired cliche of \"don't build an engine\" wouldn't hold as much weight, and it opens the doors to building a bespoke, fit for purpose engine for every game you create. Don't underestimate what an individual or small teams can produce if they are operating on a solid platform that facilitates a rich ecosystem of tools. reply doctorpangloss 2 hours agorootparent> Game libraries such as Monogame, Heaps, Raylib, Love2D, etc just wouldn't be that popular if Unity and Unreal are the be all and end all. Just because it happens, doesn't mean it makes sense. Anyway, people write their own game engines, and programming languages for game engines, because it is intellectually stimulating to do so, and something you spend 100h/wk to yield 1h of gameplay is still giving you more gameplay than something boring you spend 0h/wk on. Then, the people who use those engines you are naming, they end up porting to Unity anyway. If you want to deploy on iOS and Switch with one codebase, it is the only game in town. And that's sometimes 60% of revenue. > Don't underestimate what an individual or small teams can produce if they are operating on a solid platform that facilitates a rich ecosystem of tools. Unity fits this bill exactly. I too want more competition. But in the real world I live in, if someone were to ask me, \"what solid platform should I choose to make my multimedia application, as a small team, that also has a rich ecosystem of tools, and will enable me to make pretty much anything I can think of?\" I would say, use Unity. Because I want them to succeed. reply seanisom 8 hours agorootparentprev> Currently it is the low level, cross platform layer that is the most complex and the biggest hurdle towards making a game engine viable I couldn't agree more. My goal is not to simply build \"a better game engine\", but to make this kind of low-level tech accessible at a higher level and with much better dev tools to a broader class of developers and applications > Don't underestimate what an individual or small teams can produce if they are operating on a solid platform This gets into my motivations for building a company - larger companies have the resources to build moats, but often can't quickly realign themselves to go after novel technical opportunities. It's not either / or - both models exist for very valid reasons. reply joeyjojo 8 hours agorootparentI am glad people are working on it!! Have you seen Kha by any chance? It has similar goals. I find it quite awesome, but it won't gain mass adoption for a bunch of reasons. https://github.com/Kode/Kha Someone built an immediate mode renderer on top https://github.com/armory3d/zui, which is utilised by ArmorPaint https://armorpaint.org. I also use Zui for my own bespoke 2D game engine. I find this tech and tooling really quite amazing (just look at how little source code Zui has) given just how small the ecosystem around it is. I think Kha really illustrates what can be achievable if the lower levels have robust but simple APIs, just exposing the bare minimum as a standard for others to build upon. It really suggest taking a look at the graphics2 (2d canvas like) api. For the kind of project I work on (mostly 2d games), I think it would really awesome if your framework also supported low level audio, and a variety of inputs such as keyboard, mice, and gamepads. If it also had decent text rendering support it would basically be my dream library/framework. reply seanisom 5 hours agorootparentInteresting! Had never heard of it before, will check it out. The point of Haxe seems to be as a meta-compiler to generate code for a bunch of different languages/compilers? The same spirit of the Wasm dev experience but without the runtime. Text / fonts is very much on the roadmap! For input and audio I would have to think through the scope. reply joeyjojo 5 hours agorootparent> The point of Haxe seems to be as a meta-compiler to generate code for a bunch of different languages/compilers? That's basically correct, although there is also a cross platform runtime called Hashlink but is unsupported by Kha. https://hashlink.haxe.org/ reply wokwokwok 4 hours agoprevThere is (surprisingly) no high level commentary on what this actually is, but people banging on about how nice it would be to have a high level cross platform GPU accelerated library. ...but this..? > Graphics data and code can be developed together in the same environment, packaged together into a WebAssembly module called a renderlet, and rendered onto any canvas. With WebAssembly, we compile graphics code to portable bytecode that allows it to safely run on any processor and GPU So what is a renderlet? > The renderlet compiler is currently in closed preview - please contact us for more information. Hm... what this seems to be is a C++ library that lets you take compiled WASM and run it to generate and render graphics. Which, I think it is fair to say, it's surprising, because you can already render graphics using C++. Only here, you can render graphics using an external WASM binary. So, why? Specifically, if you're already using C++: 1) Why use WASM? 2) Why use renderlet instead of webGPU, which is already a high level cross platform abstraction including shader definitions? What is this even for? > wander is designed to be a rendering engine for any high-performance application. It primarily is designed as the runtime to run renderlet bundles ...but, why would I use a renderlet, if I already need to be writing C++? I. Get. It. A cross platform GPU accelerated rendering library you can use from any platform / browser / app would be great. ...but that is not what this is. This is a C++ library runtime that you can use to run graphics in any circumstance where you you can currently use C++. ...but, in circumstances where I can use C++, I have many other options for rendering graphics. Look at the workflow: Rendering code -> Renderlet compiler -> renderlet binary App -> load renderlet binary -> start renderlet runtime -> execute binary on runtime -> rendered vs. App -> rendering code (WebGPU) -> rendered or, if you writing a new cross platform API over the top of webGPU App -> Fancy api -> WebGPU -> rendered I had a good read of the docs, but I honestly fail to see how this is more useful than just having a C++ library that renders graphics cross platform like SDL. Shaders? Well, we also already have a good cross platform rendering library in webGPU; it already runs on desktop and browsers (maybe even some mobile devices); it already has a cross platform shader pipeline; it's already usable from C++. I'm not going to deny the webGPU API is kind of frustrating to use, and the tooling for building WASM binaries is too, but... it does actually exist. Is this like a 'alternative to webGPU' with a different API / easy mode tooling? ...or, have I missed it completely and there's something more to this? reply seanisom 3 hours agoparentKeeping it high level - No, the goal is not to create a C++ API to give you GPU functions. The C++ API for wander is used to embed the WebAssembly module of graphics code into the application. The API footprint is very small - load a file, pass parameters to it, iterate through the tree it produces. This could be viewed as logically equivalent to programmatically loading a flash/swf file. Or similar to what Rive has built with a .riv, although this is static content, not code. > 1) Why use WASM? You're loading arbitrary, third-party code into an app - that is the renderlet. The benefit is to have a sandboxed environment to run code to put data on the GPU. 2) Why use renderlet instead of webGPU, which is already a high level cross platform abstraction including shader definitions? WebGPU is a low-level API. If you are a graphics programmer, and want to build an app around WebGPU, go for it! A renderlet is more of a graphics plugin system than an entire first-party app. > The renderlet compiler is currently in closed preview - please contact us for more information. This is the system to build the renderlet. This is not writing raw C++ code to talk to WebGPU, this can be higher-level functions (build a grid, perform a geometric extrusion, generate a gradient) - you can see in the video it is a yaml specification. The compiler generate the necessary commands, vertex buffers, textures, etc, and soon, shaders to do this, and builds a Wasm module out of it. > Is this like a 'alternative to webGPU' with a different API / easy mode tooling? I certainly wouldn't describe it as an alternative to WebGPU, but easy(er) tooling to build graphics, yes. > What is the use-case for 'I've compiled a part of my application only into a cross platform binary renderlet and I can now run that cross platform ... after I've compiled the rest of my application into a platform specific binary for the platform I'm running it on?' Let's take an example - Temporal Anti-Aliasing. There are libraries that exist to implement this, or you can implement it through raw code. This requires changes structural changes to your pipeline - to your render targets, additional outputs to your shaders, running additional shaders, etc. Wouldn't it be nice to easy connect a module to your graphics pipeline that contains the code for this, and the shader stages, and works across platforms and graphics APIs, with data-driven configuration? That is the vision. > ... rest of your application into WASM/platform native code... is that not strange? It seems strange to me There is not really such a thing as a standalone Wasm application. It has seen great success as a data-driven plugin model. In a browser, it is hosted with / interacts with JavaScript. Even built for pure WASI, as a standalone app where everything is compiled into a single module, there is stil a runtime/host environment. Does that help clarify? reply wokwokwok 2 hours agorootparent> A renderlet is more of a graphics plugin system than an entire first-party app. I see. So this is basically flash? A high level API to build binary application bundles (aka .swf files, ie. renderlets) and a runtime that lets you execute arbitrary applications in a sandbox. renderlet = .swf file wander = flash runtime renderlet compiler = magic sauce, macromedia flash editor yeah? > Let's take an example - Temporal Anti-Aliasing. There are libraries that exist to implement this, or you can implement it through raw code. Mhm. You can certainly do it in a cross platform way using webGPU, but I suppose I can see the vision of 'just download this random binary and it'll add SMAA' but it sounds a lot like \"and then we'll have a marketplace where people can buy and sell GPU plugins\" or \"if you're building a web browser\" rather than \"and this is something that is useful to someone developing a visualization application from scratch\". The majority of these features could exist with just a C++ library and no requirement to 'pre-compile' some of your code into a renderlet... hosting external arbitrary 3rd party binaries in your application seems... niche. Really, the only reason you would normally ever not just do it from source as a monolithic part of your application was if you didn't have the source code for some reason (eg. because you bought it as a WASM binary from someone). Smells like Flash, and I'm not sure I like that, but I guess I can see the vision now, thanks for explaining. reply netbioserror 15 hours agoprevSaved. This is the sort of project that would be an amazing canvas for a nice widget kit and interaction model to make cross-platform GUIs with. The C/C++ backend and WASM target means people could build FFIs in almost any language. I'm sure I'm saying nothing new, but this is promising. reply ingen0s 15 hours agoprev [–] how about 1D? reply crtified 4 hours agoparent [–] He draws the line at 2D. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author previously worked at Adobe on infrastructure for applications such as Photoshop and Acrobat, dealing with the complexities of codebases across different platforms.",
      "They departed Adobe to establish Renderlet, a portable graphics framework based on WebAssembly, incorporating a 2D vector engine.",
      "An alpha version of Renderlet is forthcoming for feedback, with future plans to enhance the compiler and integration on multiple platforms."
    ],
    "commentSummary": [
      "Renderlet, a WebAssembly-based portable graphics framework, is developed by a former Adobe employee, enabling high-performance applications across diverse platforms and simplifying graphics module creation.",
      "Integration of Rive's 2D vector engine into the 3D API is demonstrated, with plans for a forthcoming public release, paving the way for potential browser-based AAA games using WebGPU.",
      "Discussions also cover limitations of WebGPU/WASM for gaming, advancements in web-first app development with 3D graphics, potential Electron replacement using WebAssembly, Flutter for cross-platform UI, and Haxe's benefits and limitations as a meta-compiler in creating cross-platform visual applications."
    ],
    "points": 426,
    "commentCount": 132,
    "retryCount": 0,
    "time": 1712076272
  },
  {
    "id": 39912330,
    "title": "Deadly 7.4 Taiwan Earthquake at 34km Depth",
    "originLink": "https://earthquake.usgs.gov/earthquakes/map/?extent=16.34123,-246.42334&extent=28.51697,-223.43994",
    "originBody": "USGS Magnitude 2.5+ Earthquakes, Past Day 62 earthquakes. Only List Earthquakes Shown on Map MagnitudeFormat Newest FirstSort 2.6 4 km SE of The Geysers, CA 2024-04-03 10:00:15 (UTC) 1.9 km 2.6 15 km S of Volcano, Hawaii 2024-04-03 09:06:14 (UTC) 1.1 km 4.9 108 km N of Paciran, Indonesia 2024-04-03 09:02:16 (UTC) 10.0 km 4.9 29 km SSW of Hualien City, Taiwan 2024-04-03 08:38:01 (UTC) 21.7 km 4.6 3 km NE of Hualien City, Taiwan 2024-04-03 08:17:11 (UTC) 20.9 km 5.1 58 km SSW of Sola, Vanuatu 2024-04-03 07:52:38 (UTC) 212.6 km 4.4 18 km WSW of Doğanşehir, Turkey 2024-04-03 07:48:14 (UTC) 1.3 km 4.9 88 km NW of Tomé, Chile 2024-04-03 06:35:02 (UTC) 9.8 km 5.0 33 km ENE of Hualien City, Taiwan 2024-04-03 06:33:57 (UTC) 8.0 km 4.8 10 km SSW of Hualien City, Taiwan 2024-04-03 06:31:34 (UTC) 11.6 km 4.9 16 km NE of Hualien City, Taiwan 2024-04-03 06:10:08 (UTC) 19.3 km 4.8 40 km ENE of Hinatuan, Philippines 2024-04-03 05:45:12 (UTC) 61.5 km 4.6 13 km NE of Hualien City, Taiwan 2024-04-03 05:23:51 (UTC) 35.4 km 5.1 43 km ENE of Hinatuan, Philippines 2024-04-03 04:51:22 (UTC) 54.5 km 4.8 9 km ENE of Hualien City, Taiwan 2024-04-03 04:34:44 (UTC) 35.0 km 4.5 39 km SSE of Hualien City, Taiwan 2024-04-03 04:08:08 (UTC) 23.7 km 4.9 21 km SSW of Hualien City, Taiwan 2024-04-03 03:57:18 (UTC) 28.4 km 4.3 11 km WSW of Jujutla, El Salvador 2024-04-03 03:48:24 (UTC) 89.5 km 4.8 29 km SE of Hualien City, Taiwan 2024-04-03 03:45:35 (UTC) 15.7 km 5.1 35 km NE of Hualien City, Taiwan 2024-04-03 03:35:20 (UTC) 6.6 km 5.0 24 km NNW of Oxapampa, Peru 2024-04-03 03:32:23 (UTC) 9.6 km 3.0 4 km NE of Santa Rosa, CA 2024-04-03 03:25:38 (UTC) 9.3 km 4.7 18 km NNE of Hualien City, Taiwan 2024-04-03 03:20:54 (UTC) 32.1 km 2.5 82 km S of Kaktovik, Alaska 2024-04-03 03:02:51 (UTC) 0.1 km 5.0 Mid-Indian Ridge 2024-04-03 03:01:08 (UTC) 10.0 km 2.5 23 km SE of Pinnacles, CA 2024-04-03 02:48:09 (UTC) 9.9 km 4.9 6 km SW of Hualien City, Taiwan 2024-04-03 02:38:29 (UTC) 11.4 km 5.2 32 km NE of Hualien City, Taiwan 2024-04-03 02:28:17 (UTC) 10.2 km 5.7 41 km NE of Hualien City, Taiwan 2024-04-03 02:14:35 (UTC) 26.8 km 4.7 26 km NE of Hualien City, Taiwan 2024-04-03 02:13:39 (UTC) 10.0 km 5.1 off the coast of Ecuador 2024-04-03 02:02:07 (UTC) 10.0 km 5.1 9 km S of Hualien City, Taiwan 2024-04-03 01:53:57 (UTC) 14.5 km 5.1 31 km ESE of Hualien City, Taiwan 2024-04-03 01:49:39 (UTC) 10.0 km 5.7 24 km ESE of Hualien City, Taiwan 2024-04-03 01:39:35 (UTC) 10.0 km 5.1 15 km E of Hualien City, Taiwan 2024-04-03 01:17:39 (UTC) 10.0 km 5.2 26 km NNE of Hualien City, Taiwan 2024-04-03 01:09:37 (UTC) 10.0 km 5.2 21 km SSW of Hualien City, Taiwan 2024-04-03 00:50:46 (UTC) 27.4 km 5.7 23 km NE of Hualien City, Taiwan 2024-04-03 00:46:44 (UTC) 10.0 km 2.9 90 km NW of Arctic Village, Alaska 2024-04-03 00:44:45 (UTC) 5.0 km 5.5 2 km SSW of Hualien City, Taiwan 2024-04-03 00:43:55 (UTC) 10.0 km 3.2 26 km ESE of Gakona, Alaska 2024-04-03 00:39:55 (UTC) 12.7 km 5.7 23 km NNE of Hualien City, Taiwan 2024-04-03 00:35:36 (UTC) 10.0 km 2.7 12 km NNW of Wai‘ōhinu, Hawaii 2024-04-03 00:13:35 (UTC) 4.3 km 6.4 11 km NE of Hualien City, Taiwan 2024-04-03 00:11:25 (UTC) 12.6 km 7.4 18 km SSW of Hualien City, Taiwan 2024-04-02 23:58:11 (UTC) 34.8 km 4.9 11 km N of Yopal, Colombia 2024-04-02 23:16:51 (UTC) 10.0 km 2.9 14 km NNW of Fishhook, Alaska 2024-04-02 22:37:56 (UTC) 0.4 km 3.0 5 km WSW of Chireno, Texas 2024-04-02 22:17:27 (UTC) 7.6 km 5.7 140 km ENE of Saipan, Northern Mariana Islands 2024-04-02 22:16:44 (UTC) 10.0 km 4.4 152 km ENE of Lospalos, Timor Leste 2024-04-02 21:23:42 (UTC) 62.7 km 2.9 3 km N of Onalaska, Washington 2024-04-02 21:20:39 (UTC) 24.3 km 4.0 8 km SE of Salvaleón de Higüey, Dominican Republic 2024-04-02 20:36:39 (UTC) 144.0 km Download Didn't find what you were looking for? Check your Settings. Which earthquakes are included on the map and list? Felt something not shown – report it here. +− 300 km 200 mi Unavailable LeafletEsri, HERE, Garmin, © OpenStreetMap contributors, and the GIS user community Earthquakes Loaded CLOSE Earthquakes Loaded CLOSE",
    "commentLink": "https://news.ycombinator.com/item?id=39912330",
    "commentBody": "7.4 earthquake in Taiwan, 34km depth (usgs.gov)413 points by throwaway598 9 hours agohidepastfavorite139 comments yellow_lead 9 hours agoThis was felt pretty strongly in Taipei, some reports of electricity outage too. All my friends and I seem ok though. reply thangngoc89 8 hours agoparentI’m also in Taipei. It’s the worst one ever I’ve felt in my life. Staying on the 7th floor with noway to escape in time is probably the worst feeling reply rjzzleep 2 hours agorootparentThe recommendation that I was taught when I took Chinese lessons btw is to stand either below a pillar or a door frame, and to open the doors so that once the initial shaking is over you can escape(for example the door frame might get stuck and then you cannot even escape in case of an emergency). Most of the collapsed buildings however seem to have not collapsed directly, but rather the foundation seems to have given in, so that if you were above the second floor you would probably have been able to be rescued. What I found most terrifying is that there are construction sites where material has flown to neighbouring buildings and destroyed parts of them. Imagine your building being up to code and then killing just because your apartment happened to be facing a highrise construction site. I have a feeling that the injury and death toll will probably take a while to be assessed. This felt genuinely terrifying. reply komali2 6 hours agorootparentprevIf it's any consolation, there's not really time to escape a collapsing building from any level, since the bottom floors usually are crushed first and near instantaneously. If you look at pictures from partially collapsed buildings in Hualian you can see that sometimes it's just the bottom floor that's destroyed and the remaining floors are fine for sometimes days or even until the building is manually taken down. The pictures of collapsed buildings after earthquakes are scary but the chance of an individual building collapsing are quite low, you're at far greater risk if you're outside near buildings because broken glass or similar could fall on you. The standard advice is good advice for a reason: stay inside, under sturdy furniture, on your elbows and knees, covering your head. You can learn more here: https://sf-fire.org/disaster-preparedness-information-resour... reply kijin 4 hours agorootparentAny data on survivability of occupants of upper floors in cases where the bottom floor is destroyed and the rest of the building settles on top of the rubble instead of pancaking? This is exactly what happened with some apartment blocks in Japan earlier this year, too. I guess it depends a lot on whether the building stays upright or falls over, as there are plenty of objects that can crush a person in any space that suddenly turns sideways. reply bobthepanda 3 hours agorootparentWhich is why the advice has always been to hide under something sturdy, like a table or bed. For the most part, it should break the impact of anything on top falling onto it. reply rjzzleep 2 hours agorootparentTable or bed? What they teach here locally is to get under a door frame or a pillar. I guess that recommendation has something to do with construction codes. When your walls are made out of light wood a sturdy table might protect you from fractured pieces I guess. reply scoofy 1 hour agorootparentIf I remember from Introduction to Natural Disasters in college, the door frame example is mainly for masonry buildings, and is a bit of a historical artifact. My understanding is that advice today strongly suggests getting under something sturdy in the attempt to end up in a void during a collapse event. reply kijin 2 hours agorootparentprevYes, the usual advice is optimized for buildings that stay upright. But this [1] happens, too, surprisingly often with reinforced concrete buildings. A table turned sideways isn't going to stop the fridge that's hurtling toward you. Ships roll all the time in heavy seas but don't have the problem of loose fridges, because everything is anchored much more strongly than on land. Perhaps that's the kind of standard we should aim for, at least for concrete buildings in earthquake zones with a certain width to height ratio. [1] First photo in https://www.japantimes.co.jp/news/2024/01/02/japan/noto-peni... reply LilBytes 5 hours agorootparentprevI appreciate the context you're providing, but \"Hey you'd be dead regardless of where you are in the building at the time if it collapses\" isn't as reassuring as you'd think. reply jfrbfbreudh 4 hours agorootparentRead his comment again reply davidjytang 4 hours agorootparentprevAs a Taiwanese, I got used to it. reply voisin 8 hours agoparentprevIs there a stream of the big dampening device in Taipei 101? I cannot find it via usual searches but wonder if it is available in another language search. reply thangngoc89 8 hours agorootparentIt happened too early 8:03 AM. Probably no visitor or even staff in Taipei 101. Last time videos are all from visitor. reply voisin 7 hours agorootparentThat’s too bad. They should live stream it so they can allow performance after earthquakes, a testament to successful engineering. reply hojinkoh 5 hours agorootparentprevI can't imagine how terrifying it will be if I was on Taipei 101 during this quake... reply dev-jayson 7 hours agoparentprevI'm in Taichung, it shook hard as hell but I don't think we took any damage comparing to Taipei or Hualien. reply a_random_canuck 4 hours agoparentprevI'm also living in central Taipei, this one woke me up, we felt really strong shaking in our flat on the 4th floor. Some tiles fell off the buildings on my street but otherwise everyone is fine. Right after the quake saw police and fire dept patrolling around. reply yinser 9 hours agoprevJapan’s meteorological agency forecast a tsunami of up to 3 meters (9.8 feet) for those curious https://www.washingtonpost.com/world/2024/04/02/taiwan-earth... reply Hasnep 7 hours agoparentThe tsunami reports I've heard here on the north coast are that it ended up being less than 1 metre tall, so luckily nothing to worry about. reply RaoulP 7 hours agorootparentI’m on the southwestern coast of Ishigaki island (one of the closest to Taiwan), and the effects really seem to have been minimal. The harbor area here was dead silent for a while, empty streets. But things are back to normal now that the tsunami warning has been lifted. reply lukan 8 hours agoparentprev3 m sound not too bad? reply s_m_t 8 hours agorootparentIt can be a very long wave. If you have a coastal area that is mostly at or very close to sea level then that entire area could now be 3m underwater which is very bad. Also, even under normal conditions the type of wave you would see at the beach with a height of 3m is insanely powerful. I think the highest I have body surfed in was maybe 2-2.5m and if you get caught in the break of the wave you are literally powerless and get dragged under water and spun around for quite some distance. It is a bizarre experience and doesn't really match the basic intuition of how powerful it should be. reply lloeki 2 hours agorootparentMy crude understanding and associated mental imagery is that tsunami waves are more like tide than \"usual\" waves: your typical 3m wave is mostly \"surface-ish\" in comparison, while 3m tsunami has both greater wavelength and \"depth\", which is what makes the \"usual\" wave break quickly when it reaches shore, whereas tsunami waves continue pushing real hard for real long because of all the length * undersurface water you don't see. Gently shaking a glass of water sideways or blowing upon it won't make much water spill out, but jolt it vertically and most of it goes out real quick. This is all probably very incorrect physics but it helps drive my intuitive understanding that 3m wave and 3m tsunami are quite different, the former being scary but the latter being muuuuch scarier. reply yosito 8 hours agorootparentprevYep, where I live (rent) a 3m wave would fill my house with 1m of water. Even if it was one quick wave, that washed over without staying long enough to completely flood the inside of my house, I'd probably at least have to deal with a bunch of water damage. reply northwest65 8 hours agorootparentprevThink of it as a 3m tall bulldozer the width of the country with effectively unlimited pushing power. Watch some videos of the Japan tsunami, it's basically an unstoppable force that gobbles up everything in it's path. Very uncool. reply shiroiushi 8 hours agorootparentIt's generally very bad, but it also depends on the shoreline. If your city is on the coast at sea level with no real barrier, it's devastating. If there's a big cliff and everything is at higher elevation, you can ignore it. Unfortunately, people tend to build settlements at sea level. reply supportengineer 6 hours agorootparentWe should set up some stone monuments to delineate the high water mark, for future generations. reply dylan604 6 hours agorootparentSame but different, there's an old town near a lake that suffered a devastating flood way back in its history. The downtown area has markers on the buildings that show the high water mark for the flood. reply speed_spread 5 hours agorootparentprevThe Japanese have those. A lot of the monuments are hidden in the forest in the hills above the coastal villages... reply PaulHoule 8 hours agorootparentprevConsider for instance this place https://commons.wikimedia.org/wiki/Category:Diablo_Canyon_Po... which is on top of a high bluff thus much more secure than the Fukushima NPP. reply shiroiushi 5 hours agorootparentUnfortunately, that power plant is very close to two fault lines, and they didn't even know when they built it, so it's questionable how well it'll withstand an earthquake. https://en.wikipedia.org/wiki/Diablo_Canyon_Power_Plant reply heavyset_go 8 hours agorootparentprevImagine a 10 foot wall of water flooding the coast that just doesn't stop. Smaller tsunamis have devastated coastal regions before. People, beach houses, etc are swept away under that force even though the height is rather low. reply dylan604 8 hours agorootparentprevi'm always amazed how little appreciation people have for massive amount of water. a 3m wave will more than ruin your day. trust me, it's plenty reply heavyset_go 8 hours agorootparentI lived in a coastal region where, every storm season, people would get swept out to sea and drown because they were watching storm waves from the beach. Sometimes they'd even go in the water, out on jetties or out on piers, without any appreciation for the sheer forces at work that push the water around. With enough force, even ankle to knee deep water can sweep you off your feet and suck you out to sea. Sadly parents let their kids do this and some have lost their lives. reply christkv 4 hours agorootparentWe had two tourists just get killed last week during storms. Both swept off harbor walls wanting to look at the waves. There are literally warning signs everywhere. reply danparsonson 8 hours agorootparentprevHow tall are you?? Imagine standing at the shoreline and the water level suddenly being 3m higher... reply gpsx 6 hours agorootparentprevIt’s not really a wave, it is more of a tide that comes in quickly. So everything gets flooded to 3m above the normal water level, and stays that way for a while. reply laborcontract 8 hours agorootparentprev3 meters is significant if you live in an inundation zone. You can see the effect on a seaside community here: https://www.floodmap.net reply fuzztester 8 hours agorootparentprev3m is about 10 ft which is huge, though there are huger waves. reply longemen3000 8 hours agorootparentpreva 3-meter high wall of water is not really good either, due to kinetic energies, if no significant tsunami coastal protections, that water flow can reach far inland reply golergka 7 hours agorootparentprevThis comment author was not correct, but this question prompted a lot of great answers and improved the quality of the discussion. Per HN rules, this comment should be upvoted, not downvoted. reply comex 9 hours agoprevAs of 40 minutes after the event, someone has already created a Wikipedia article about it: https://en.wikipedia.org/wiki/2024_Taiwan_earthquake reply OsrsNeedsf2P 8 hours agoparentWhile it's cool that Wikipedia could be used for breaking news, \"Recentism\"[0] is generally not seen favorably on Wikipedia [0] https://en.wikipedia.org/wiki/Wikipedia:Recentism reply TillE 7 hours agorootparentWikipedia itself isn't ideal for this, but I keep waiting for some major news institution to migrate away from the ancient newspaper article format and towards something more wiki-like for covering stories. I think you could productively fit any kind of news coverage into a wiki article plus a stream of recent updates. reply pests 1 minute agorootparentThat's just love coverage CNN and major news do nowadays. Find the live event page and there's minute by minute updates, background information / quick recap, other sources and links, images, etc all updated in real time. reply dewey 1 hour agorootparentprevHaving a newspaper article giving context and then having updates at the bottom isn't really something that doesn't exist. It happens all the time. reply yazzku 8 hours agoparentprevAnd with a timeline of events, assessment of impact, and all 21 references, damn. reply rohan_ 8 hours agoprevAnyone have a link to a video of that sweet Tuned Mass Damper (https://www.atlasobscura.com/places/tuned-mass-damper-of-tai...) in action this time around? reply ateng 8 hours agoparentNot a live one, but this vid is from 2022 when there was a 6.8 magnitude earthquake https://www.youtube.com/watch?v=Tkz6b7Q3dRk reply dehrmann 4 hours agorootparentIt's one of the few tuned mass dampers the public can go see. reply xattt 9 hours agoprevI see earthquake reports (like this one) describe earthquake depth. What is the significance of it? Is it somehow actionable? reply robocat 8 hours agoparentA shallow 6 is very different from a deeper 7. My city Christchurch was fucked by a 6.2 or 6.3 - but it was both (a) shallow (5km) and (b) close to dense residential areas. Christchurch was near to the 7.1 Canterbury earthquake but that did much less damage as it was 10km deep and Christchurch wasn't on top of it (it mostly affected less dense rural properties in the region near Christchurch). Be careful not to think of earthquakes as a point - talking about epicentres and precise depth is very misleading. Earthquakes are a fault-sheet or wrinkles. Surface fault lines only show where the 3D rips through the solid earth meet the surface. Fault lines matter a bit especially since they indicate local shallowness, but I suspect we get distracted by them because they make spectacular news reports. Reality is complex. My parents house was right above the fault plane of the Canterbury fault - and their house came though mostly okay. I know lots of people very near the Christchurch quake and many of their houses were unrecoverably damaged. reply RowanH 7 hours agorootparentThere's actually some interesting visuals that illustrate this showing the difference in ground velocity between the two earthquakes : 2010 Quake: https://www.youtube.com/watch?v=eA5m5PZ5p8E 2011 Quake: https://www.youtube.com/watch?v=KJW7tkTwqXo And a good explanation vid: https://www.youtube.com/watch?v=aaA1nxYVi6k reply lamontcg 8 hours agorootparentprevThe Nisqually quake in Seattle was a 6.8 but it was 57km (35 miles) deep. It was also on the other side of Tacoma sort of in between Tacoma and Olympia. The depth of that quake made it a lot less severe than it could have been, only killed one person, but estimated it cost $1b to $4b in damages. reply thijson 8 hours agorootparentI remember how it felt, I thought I was sick, because I felt this rocking motion. I thought it was just me, then I stood up and saw a plant shaking, so I knew it was everything else that was shaking too. The amplitude slowly increased, reached a maximum, then decreased over the course of what seemed like a minute. It was a quite slow frequency, possibly due to the depth. This was from Portland. reply lamontcg 5 hours agorootparentI was on the 8th floor of a brick building in Seattle. If it had been a shallow quake I would be dead. There was a whole lotta motion. Can't remember what it damaged, though, other than some glass bottles on top of the refrigerator that fell off and shattered everywhere in the kitchen. reply northwest65 8 hours agoparentprevAs somebody who has been through more than 10 thousand quakes, it's as significant as the force itself. 7.4 @ 300km deep you just yawn and roll over. @10km deep you pray your concrete roof tiles don't come through the ceiling and kill you in your bed... you basically just lie on top of your wife, give thanks for the time you did have, and hope for the best. reply furyofantares 8 hours agorootparent> As somebody who has been through more than 10 thousand quakes What's this now? reply RowanH 7 hours agorootparentChristchurch quake had 10's of thousands of aftershocks. A few people I know were rattled to the point they were shell shocked and just had to leave town - every tremor triggering off \"could this be it\" all over again. reply robocat 32 minutes agorootparentprevIt's a bullshit number - ignore it. The same location could have had 1, 10, 1000 or 1000000 quakes depending on the threshold chosen. Or if just talking about ones you can feel, then the count varies a lot depending on exact location (and your sensitivity). And the time and strength distribution of aftershocks is not linear - so the number gives you no feeling for what it means. reply iraqmtpizza 8 hours agorootparentprevHow many drops is this for you, Lieutenant? Thirty eight... simulated. reply dredmorbius 7 hours agorootparentnext [–](For the uninitiated.) reply rdl 8 hours agorootparentprevThere are a LOT of very small/deep/etc quakes in some places. reply furyofantares 7 hours agorootparentSure, I see Riverside CA had over 6000 last year, though I doubt if someone who moved there two years ago would say they've \"been through\" over 10,000 quakes since, depending on their sensitivity, they might not have felt any of them, or maybe a dozen of them or something. I'm interested in specifics! reply steanne 8 hours agoparentprevhttps://en.wikipedia.org/wiki/Depth_of_focus_(tectonics) reply xattt 8 hours agorootparentThanks! I must admit it’s hard to find an answer myself without the vocabulary. reply acchow 8 hours agorootparentThis is where LLMs really shine. reply dmix 8 hours agorootparentThat's a very good point, I was trying to google how buttons on a calculator communicate with the chips underneath, basically how contacts work, and Googling that kept giving me stuff about calculators not electronics, but ChatGPT gave me the perfect bullet point breakdown because it understood the context of my more general question. People often communicate/think in analogies to the underlying concepts. reply lukan 8 hours agoparentprevWell, imagine it like the distance you want to be away from a big explosion. The further away, the better. And the deeper it is, the further it is away from the ground, where humans are. reply mastax 8 hours agoparentprevFollow-up question. I understand how Richter Scale + depth could be useful, academically. But when communicating with the public, wouldn't it be easier to have a single number - rather than requiring the public to understand the relationship between two different quantities? Maybe: surface-equivalent Richter scale? Of course transitioning to a new standard would be even more confusing for a while. Edit: apparently there are many different scales in wide use already. https://en.wikipedia.org/wiki/Seismic_magnitude_scales reply kalleboo 7 hours agorootparentIn Japan for domestic quakes they always report the Shindo scale (based on surface peak ground acceleration) instead of Magnitude. It’s way more useful a measure IMHO and whenever I see western news report use M it tells me nothing about how bad the quake actually was. https://en.wikipedia.org/wiki/Japan_Meteorological_Agency_se... reply astrange 6 hours agorootparentWe have a similar measure (MMI) in the US, but it's harder to report a local measure in a single article. reply ks2048 6 hours agorootparentprevAlso could take into account distance to the point of interest. So, in city X you have a number and city Y another. reply kijin 3 hours agorootparentThat's exactly how the shindo scale is reported in Japan. They assign a number to every major city on a map, just like temperatures in a weather forecast. For example, January's big quake was 7 in Ishikawa, but only 2-3 in the Tokyo area. reply brigandish 7 hours agorootparentprevThis is why the Shindo scale is favoured in Japan, as it addresses the effects on people and buildings in a particular area, so you can tell just by looking at what is shaking and how much to get an idea of the strength. The worst part of experiencing an earthquake, for me, is realising that anything can happen in the next moments, otherwise it's weirdly normal. reply burgerquizz 6 hours agoprevnot easy to find good devs in taipei, so shameless plug: for folks living in taipei, who want to find a good english speaking dev community: https://join.taipeidev.com reply hntddt1 4 hours agoparentGlad to find this gem reply castiel652 6 hours agoparentprevNo embedded software as an option? reply stewpy 9 hours agoprevAre fabs knocked offline? reply WhatIsAModel 7 hours agoparentTSMC is extremely prepared for earthquakes. The YouTuber Asionmetery has a good video on it: https://www.youtube.com/watch?v=MNKF21B01NQ Its incredible what they do in terms of accuracy in a place with so much seismic activity. reply 4monthsaway 7 hours agorootparentFrom what I understand (I used to live in the main city for that), even the vibration from local trains are a factor reply spxneo 6 hours agorootparentwow that is crazy attention to detail it must be so negligible but significant enough for the production reply partiallypro 7 hours agorootparentprevTSMC still evacuated. https://finance.yahoo.com/news/tsmc-evacuates-production-lin... reply m3kw9 6 hours agorootparentprevwhen the entire building shakes you really can't prepare for that reply blackcat201 8 hours agoparentprevThe standard operation is to stop and check if any machine was out of calibration. So yes reply gary_0 8 hours agoparentprevI don't see any major TSMC fabs[0] near the epicenter in Hualien. The Taichung fabs are closer but on the western side, while the Tainan fabs are pretty far away from the quake. Edit: There will be some disruption as TSMC has evacuated employees[1]. No structural damage reported, though. [0] https://en.wikipedia.org/wiki/List_of_semiconductor_fabricat... [1] https://www.bloomberg.com/news/articles/2024-04-03/tsmc-evac... reply kurthr 8 hours agorootparentI'm hopeful for the 3nm Tainan fabs, but I expect disruption at the Taichung and Hsinchu fabs since the quake was felt in Taipei. It's common for the equipment to be recalibrated and tested, if you can feel an event. I suspect this was felt in the west. Hopefully, not down for a week, if everything is good. Hopefully, the towns and people on the east coast are OK, but this one is big. edit- Since there are reports of shaking in Kaohsiung (farther south than Tainan), I'm less hopeful for the southern fabs. reply freeqaz 8 hours agoparentprevThis was my first thought also. I know they have seismic isolation tech, but how good is it? reply stewpy 8 hours agorootparentIt's really good, best in the world, specifically on the leading edge. Issue is now probably bridges/ roads and other interlinking logistics - if this stuff holds up supply chain/ stops people getting to and from work that's an issue. reply jprd 8 hours agorootparentprevI wish this wasn't my first thought too, but it was. I can't imagine all those wafers are happy. reply hackernews1134 1 hour agoprevHoping to start a thread talking about this. Anyone read Richter 10 by Arthur C Clarke. Where California broke away from the mainland. Think anything in our lifetime will ever match the prediction tech from the book? I know nothing about earthquakes. Hoping for a HN education! reply Ostrogoth 5 hours agoprev18 aftershocks/additional earthquakes across the island in 4.7-6.4 range as of this comment. I’m not sure if that is a normal amount, but seems high. https://earthquake.usgs.gov/earthquakes/map/?extent=-22.9179... reply Pufferbo 8 hours agoprevWhat’s the significance of an earthquake’s depth? reply smcin 8 hours agoparentShallower earthquakes cause much more damage (on the surface), esp. if near densely populated areas; also depends greatly on how earthquake-proof structures and buildings are. Today's one was 34km deep/21 miles. 1989 SF (Loma Prieta) was magnitude 6.9, epicenter 56 mi south of SF, depth 11 miles. (Typical California earthquake focal depths are 4 to 6 miles). 1906 huge SF earthquake was magnitude 7.9, depth 5 miles. 2008 Sichuan, China earthquake (87,587 killed) was magnitude 8.0, depth 19 km. 2011 Fukushima, Japan earthquake(+ tsunami) was magnitude 9.0, depth of 18.6 mi/30km at sea. reply newzisforsukas 8 hours agoparentprevhttps://pressbooks.cuny.edu/gorokhovich/chapter/causes-of-ea.... reply shusaku 8 hours agoparentprevhttps://news.ycombinator.com/item?id=39912520 reply kadoban 8 hours agoparentprevMostly just significant in terms of distance. If it's deeper, it's farther away and you'll feel it less. reply photon-torpedo 9 hours agoprevReport from the Taiwan agency: https://www.cwa.gov.tw/V8/E/E/EQ/EQ113019-0403-075809.html And a list of all recent earthquakes, showing the aftershocks: https://www.cwa.gov.tw/V8/E/E/index.html reply imrehg 8 hours agoparentWhenever I look at those reports, I keep wondering how many automated systems have to be there in place to generate all that. All the waveform records, the intensity maps, etc..., they should be all auto-generated, and likely verified by humans afterwards? Would be super curious of the IT setup and deployment of such things. This also likely feeds into the automatic warning systems (sent to mobile phones to warn of an incming earthquake, tsunami, or something else), which is likely going to be discussed afterwards, as loads of people didn't get a warning. (As opposted to recent Chinese satellite launch where _everyone_ got the overly scary rocket alert.) Edit: now they are saying their calculation has to project a minimum \"peak ground acceleration\" (PGA) of 25 (what units?) to have an alert, and a lot of the places didn't hit that, in part due to underestimating the intensity at the epicentre. I guess they will be revising this criteria, as this was overly conservative on the \"less noise\" side, while people are likely more forgiving in reverse (getting an alert when they didn't need one). reply getToTheChopin 7 hours agoprevIf you're in the region -- please stay safe. reply mmsc 3 hours agoprevMaybe not the right place to ask, but what’s the tech scene like in Taiwan? Other than TSMC, are there any interesting things going on? I’m in Kaohsiung but haven’t investigated the scene. reply vishalontheline 3 hours agoparentIf you've never visited South East Asia, then Taipei is probably the best first city to visit over there. Nice people, amazing food, many English speakers, easy to navigate. I'm sure there's a tech scene there, but I would visit even if there wasn't. reply ammo1662 9 hours agoprevanother 6.5 earthquake after 10 minutes: https://earthquake.usgs.gov/earthquakes/eventpage/us7000m9gc... reply spxneo 6 hours agoprevthis guy is right again at predicting these earth quakes: https://twitter.com/ssgeos/status/1775146068079960148 reply jcranmer 5 hours agoparentLooking at his feed, his big prediction was for a M7 earthquake around 3/30, so his prediction is actually 3 days off. Before that, he was looking at a M8 earthquake around 3/13. And before that, strong tremors around the end of 10/23/2023, seeming later updated to more like 10/25/2023 or 10/28/2023. None of this panned out. In general, I'm seeing a lot of misses and no real hits. reply spxneo 5 hours agorootparentso he's off by a few days? did you go back to his past predictions that also came true last year and the year before? he's better than any predictive processes we had so far reply jcranmer 4 hours agorootparentHis prediction is wrong. He buttonholed it to a few specific days, and missed that window. As for prior predictions, I went back 6 months. None of his predictions panned out. Although, admittedly, it's a bit difficult for me to figure out what actually constitutes a prediction since most of them tend to be the kind of vague generality that's hard to grade: \"The Mars-Mercury-Jupiter conjunction on 22 September can result in a strong shake later on 23 or 24 September.\"--what's a \"strong shake\"? \"Stronger seismic activity is likely to occur in the coming days\"? These are the kinds of predictions that are worded vaguely enough to be dismissed if they don't come true, and can be highlighted as a miracle of prediction if something does happen. (I haven't even attempted to grade location because I can't even tell what's supposed to be suggested as possible locations. As noted elsewhere, even guessing that a M6+ earthquake is likely in the next few days isn't a difficult guess, because they'll occur more or less weekly: https://earthquake.usgs.gov/earthquakes/browse/m6-world.php?...). reply spxneo 4 hours agorootparentyou went only back 6 months and he was off by a few days was to conclude your own bias to begin with... reply dylan604 6 hours agoparentprevthis is the first time i've ever seen this person. how is he received in non youtube audiences? is this fringe level stuff, or is this accepted science? i have a hard time wrapping my head around a planetary alignment with Neptune affecting Earth. I'm not dismissing it, but my knee jerk is this can't be real, yeah? reply jcranmer 5 hours agorootparentAll earthquake prediction is fringe science. (FWIW, predicting a M6+ earthquake isn't that hard--an M6+ earthquake happens on Earth about every 3 days.) reply spxneo 6 hours agorootparentprevhis track record indicates this is not a random reinforcement but something worth looking into. I also didn't know what this planetary alignment is but there have been papers around it. reply alliao 2 hours agoparentprevhttps://twitter.com/rrichcord reminds me of this guy reply komali2 6 hours agoparentprevWould love to see the deleted predictions lol reply spxneo 6 hours agorootparenthe's been doing this for years with youtube videos accompanying his tweets i dont think hes here to sell anything reply a_random_canuck 4 hours agoparentprevHow gullible are people on HN? Really? Obvious BS is obvious. reply komali2 7 hours agoprevThe Circle line has dislodged https://www.setn.com/News.aspx?NewsID=1448651 Live stream of news about the incident: https://www.youtube.com/watch?v=SydScnOrmf8 There's been pretty big aftershocks like clockwork after, it's gonna be a hard day. My dog is freaked out, my fish tanks are half empty, we're not sure if we can open the restaurant since the MRT is closed and our chef lives quite far, and that's just life in Taipei, I can't imagine what people in Hualian are going through. Edit: the aftershock just now was as strong as some of the scarier earthquakes I've ever felt in my life. Such a rough day for Hualien. I envision going down to the southeast to support but it might actually be impossible right now, due to landslides and the train lines going down. Even if I took my motorcycle, I doubt I could get through. Edit: pov from a car on an elevated road https://twitter.com/jimmy_su/status/1775347726697587167?s=20 most highways in Taiwan are elevated maybe 100m or so. Edit: hw9 near Hualien lost a bridge https://udn.com/news/story/7314/7874283 that is one of the most beautiful, well maintained, fun, and safest roads I've ever motorcycled in my life. I hope they are able to repair it. Edit: I'm furious with YouTube for forcing this to be a \"short\" with bad-on-purpose UX but here's a video of odd water behavior in a port https://youtube.com/shorts/91Rmacvw4ho?si=d78KAUvDTeg_ovbh reply cayde 3 hours agoparentTo use legacy UX you can put in the watch. https://youtube.com/shorts/91Rmacvw4ho to https://www.youtube.com/watch?v=91Rmacvw4ho reply Intralexical 3 hours agoparentprev> Edit: I'm furious with YouTube for forcing this to be a \"short\" with bad-on-purpose UX but here's a video of odd water behavior in a port https://youtube.com/shorts/91Rmacvw4ho?si=d78KAUvDTeg_ovbh https://www.youtube.com/watch?v=91Rmacvw4ho https://youtube.com/v/91Rmacvw4ho reply dewey 1 hour agorootparentI think my first thought would be to go to the highest point I could find instead of filming the water. Scary! reply neom 6 hours agoparentprevWhat kind of restaurant do you have? reply komali2 6 hours agorootparentSouthern fried chicken biscuit. So far as we know, first of its kind in Taiwan. https://www.thejispot.com/ reply greesil 6 hours agorootparentGreat name! reply 4monthsaway 9 hours agoprevThat was a big one here this morning 50 minutes ago. Earthquake alert and later a rare tsunami alert. Very shaky. reply baby 6 hours agoprevMy friend said his building was shaking. I was there last week, didn’t feel it in Tokyo. Looks like some tsunami alerts have been sent. Seing some bad videos from hualien reply autarch 8 hours agoprevI'm in Kaohsiung (southwest Taiwan) and this woke me up around 8am. I'm on the 15th floor and definitely felt the building shaking. It was more excitement than I wanted that early in the morning. reply LAC-Tech 6 hours agoprevLast time this happened in Taiwan buildings collapsed and peopled died because corrupt local construction companies had put too much sand in their concrete to save money. reply partiallypro 7 hours agoprevTSMC evacuated their facilities, hopefully there is no damage there and no serious injuries or deaths across the country. Taiwan has said there are a number of Chinese warships that have entered their waters as well, supposedly willing to lend aid...though not sure if that's a good deal to take. reply davesque 7 hours agoprevI visited Hualien a few years ago. Very sad to see this. reply imwillofficial 8 hours agoprevI went through a 7.6 quake one time. It was wild. I hope everyone stays safe. reply AnimalMuppet 9 hours agoprevTsunami warnings in Japan. US is evaluating whether to issue warnings. reply lobochrome 8 hours agoparentTsunami warnings in Okinawa. Not in the main islands. reply djaykay 8 hours agoparentprevProbably not much to worry about in the US. The Fukushima earthquake was much more powerful, but the resulting tsunami did almost nothing to the US west coast. Some boats in Crescent City were wrecked, but that’s due to local geography funneling the wave a certain way. I’m on an island in the SF bay, we saw nothing. reply mrb 9 hours agoprev [–] Multiple buildings have collapsed. There will be many fatalities: https://twitter.com/Huberton/status/1775320722115539349 https://twitter.com/dom_lucre/status/1775325642386481216 reply voisin 8 hours agoparent [–] Man in that second video they look so calm standing under a massive potential landslide that could sweep them to their death. reply danparsonson 8 hours agorootparentI've lived here about 18 months and this is honestly the first time I've seen Taiwanese people looking worried about anything ^^ They're a stalwart bunch. reply dylan604 8 hours agorootparentprev [–] That first one with the leaning building...have they not seen footage from 9/11 or any disaster movie about how far the debris field can travel in an uncontrolled building collapse? That's a definite nope from me. reply komali2 7 hours agorootparent [–] Most of the pictures are a little misleading for distance etc, as well as time. When people are close to the building is before the fire department arrived, and people are trying to get other people out of the building. It sounds like they're relatively situationally aware, warning eachother about live cables, gas, etc. Obviously there's a risk of death but there's also a risk of your old neighbor getting squashed if you don't get her out, so, I guess it's up to each person how they react. Within about 20 minutes the fire department had completed its first evaluation of damage and identified the 3 partially collapsed buildings. reply dylan604 6 hours agorootparent [–] If you're a lookie-loo with your phone camera out, you're not very concerned about your neighbor. You're shooting disaster porn for the likes reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "In the last 24 hours, 62 earthquakes of magnitude 2.5 and higher occurred, spanning across regions like California, Hawaii, Indonesia, Taiwan, Chile, Peru, and more.",
      "The most recent quake, a 2.9 magnitude, struck Washington, while the most potent tremor, a 7.4 magnitude, hit Taiwan.",
      "Across different parts of the world, seismic activities have been notable, showcasing the ongoing geological dynamics on Earth."
    ],
    "commentSummary": [
      "A 7.4 earthquake struck Taiwan, prompting significant shaking in Taipei and resulting in building collapses.",
      "Discussions surfaced on earthquake safety, tsunami forecasts, and natural disaster risks following the event.",
      "TSMC fabs faced disruptions, sparking debates on earthquake predictions, infrastructure damage, aftershocks, building integrity, and construction practices."
    ],
    "points": 413,
    "commentCount": 139,
    "retryCount": 0,
    "time": 1712103896
  },
  {
    "id": 39907876,
    "title": "CityGaussian: Cutting-Edge Scene Rendering with 3D Gaussians",
    "originLink": "https://dekuliutesla.github.io/citygs/",
    "originBody": "CityGaussian: Real-time High-quality Large-Scale Scene Rendering with Gaussians Yang Liu1,2, He Guan1,2, Chuanchen Luo1, Lue Fan1,2, Junran Peng1, Zhaoxiang Zhang1,2,3,4, 1Institute of Automation, Chinese Academy of Sciences 2University of Chinese Academy of Sciences (UCAS) 3Centre for Artificial Intelligence and Robotics (HKISI, CAS) 4State Key Laboratory of Multimodal Artificial Intelligence Systems (MAIS) arXiv Code (Soon) Abstract The advancement of real-time 3D scene reconstruction and novel view synthesis has been significantly propelled by 3D Gaussian Splatting (3DGS). However, effectively training large-scale 3DGS and rendering it in real-time across various scales remains challenging. This paper introduces CityGaussian (CityGS), which employs a novel divide-and-conquer training approach and Level-of-Detail (LoD) strategy for efficient large-scale 3DGS training and rendering. Specifically, the global scene prior and adaptive training data selection enables efficient training and seamless fusion. Based on fused Gaussian primitives, we generate different detail levels through compression, and realize fast rendering across various scales through the proposed block-wise detail levels selection and aggregation strategy. Extensive experimental results on large-scale scenes demonstrate that our approach attains state-of-the-art rendering quality, enabling consistent real-time rendering of large-scale scenes across vastly different scales. Comparison With SOTA CityGS: No LoD Without our proposed LoD technique, the MatrixCity is depicted by 25 million Gaussians. The consequent speed of 18 FPS (tested on A100) leads to unpleasant roaming experience. CityGS With the support of LoD, our CityGS can be rendered in real-time under vastly different scales. The average speed is 36 FPS (tested on A100). Visual Comparisons MegaNeRF [Turki 2022]Ours SwitchNeRF [Zhenxing 2022]Ours GPNeRF [Yuqi 2023]Ours 3DGS [Bernhard 2023]Ours BibTeX @misc{liu2024citygaussian, title={CityGaussian: Real-time High-quality Large-Scale Scene Rendering with Gaussians}, author={Yang Liu and He Guan and Chuanchen Luo and Lue Fan and Junran Peng and Zhaoxiang Zhang}, year={2024}, eprint={2404.01133}, archivePrefix={arXiv}, primaryClass={cs.CV} } References [Turki 2022] Turki, H., Ramanan, D., Satyanarayanan, M.: Mega-nerf: Scalable construction of large-scale nerfs for virtual fly-throughs. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 12922–12931 (2022) [Zhenxing 2022] Zhenxing, M., Xu, D.: Switch-nerf: Learning scene decomposition with mixture of experts for large-scale neural radiance fields. In: The Eleventh International Conference on Learning Representations (2022) [Yuqi 2023] Zhang, Y., Chen, G., Cui, S.: Efficient large-scale scene representation with a hybrid of high-resolution grid and plane features. arXiv preprint arXiv:2303.03003 (2023) [Bernhard 2023] Kerbl, B., Kopanas, G., Leimkühler, T., Drettakis, G.: 3d gaussian splatting for real-time radiance field rendering. ACM Transactions on Graphics 42(4) (2023) We thank the authors of Nerfies that kindly open sourced the template of this website. There are also many thanks to Jiemin Fang for insightful discussions during the preparation of the draft.",
    "commentLink": "https://news.ycombinator.com/item?id=39907876",
    "commentBody": "CityGaussian: Real-time high-quality large-scale scene rendering with Gaussians (dekuliutesla.github.io)412 points by smusamashah 17 hours agohidepastfavorite109 comments speps 13 hours agoNote that the dataset from the video is called Matrix city. It's highly likely extracted from the Unreal Engine 5 Matrix demo released a few years ago. The views look very similar, so it's photorealistic but not from photos. EDIT: here it is, and I was right! https://city-super.github.io/matrixcity/ reply jsheard 13 hours agoparentEpic acquired the photogrammetry company Quixel a while ago, so it's quite likely they used their photo-scanned asset library when building the Matrix city. Funnily that would mean the OP is doing reconstructions of reconstructions of real objects. reply reactordev 12 hours agorootparentOr just rendering it mixed with some splats, we don’t know because they didn’t release their source code. I’m highly skeptical of their claims, their dataset, and the fact that it’s trivial to export it into some other viewer to fake it. reply affgrff2 5 hours agoparentprevJust want to add that using data from a game engine gives you perfect camera poses associated to each image. That makes training of nerfs and GS a little easier since there is no error from camera pose optimization. That's also the reason early Nerf papers used the famous yellow Lego excavator rendered with blender. reply MrSkyNet 2 hours agorootparentHow so? Through pixel perfect alignment? Resolution? reply arussellsaw 1 hour agorootparentone of the fundamental problems in photogrammetry is determining the position of the camera in 3D space, with a game engine you just have a concrete value for your camera position, removing that entire problem. I don't know too much about photogrammetry but i'd imagine once your camera position is 100% accurate it's a lot easier to construct the point cloud accurately. reply speps 13 hours agoparentprevReplying to myself with a question, as someone could have the answer: Would it be possible to create the splats without the training phase? If we have a fully modelled scene in Unreal Engine for example (like Matrix city), you shouldn't need to spend all the time training to recreate the data... reply somethingsome 12 hours agorootparentOf course! And this was done many times in the past, probably with better results than current deep learning based gaussian splatting where they use way too many splats to render a scene. Basically the problem with sparse pictures and point clouds in general is their lack of topology and not precise spatial position. But when you already have the topology (eg with a mesh), you can extract (optimally) a set of points and compute the radius of the splats such that there are no holes in the final image (and their color). That is usually done with the curvature and the normal. The 'optimally' part is difficult, an easier and faster approach is just to do a greedy pass to select good enough splats. reply sorenjan 13 hours agorootparentprevYes, it's possible to create gaussian splats from a mesh. See for example step 3 in SuGaR: https://imagine.enpc.fr/~guedona/sugar/ reply fudged71 13 hours agorootparentAre you referring to the gaussian splat rasterizer? reply sorenjan 12 hours agorootparentI'm referring to using the modeled scene to bind gaussian splats to an existing mesh. > Binding New 3D Gaussians to the Mesh > This binding strategy also makes possible the use of traditional mesh-editing tools for editing a Gaussian Splatting representation of a scene reply fudged71 13 hours agorootparentprevI could be wrong, but being able to remove the step of estimating the camera position would save a large amount of time. You’re still going to need to train on the images to create the splats reply dkjaudyeqooe 7 hours agorootparent> If we have a fully modelled scene in Unreal Engine for example... No images involved, so no training required. reply kfarr 13 hours agorootparentprevYes, and then it gets interesting to think about procedurally generated splats, such as spawning a randomized distribution of grass splats on a field for example reply dkjaudyeqooe 7 hours agorootparentTo me the big issue is image quality versus generative efficiency. If splats make rending complicated scenes efficient without requiring a lot of data/calculation \"scaffolding\" then you could do almost everything procedurally, maybe using AI models to fill in definitional detail. reply ttmb 13 hours agoparentprevNot all of the videos are Matrix City, some are real places. reply kfarr 15 hours agoprevNot quite the same thing, but over the weekend I hacked google maps 3d tiles (mesh) together with a gaussian splat and the effect is pretty similar and effective: Example 1 with code linked: https://twitter.com/kfarr/status/1773934700878561396 Example 2 https://twitter.com/3dstreetapp/status/1775203540442697782 reply cchance 14 hours agoparentThats really cool is there a github with the code... getting errors on that first link in devtools Uncaught (in promise) Error: Failed to fetch resource https://tile.googleapis.com/v1/3dti... reply kfarr 14 hours agorootparentProbably rate limited api calls given the hug of Twitter and HN. Capped at 1k per day see https://github.com/3DStreet/aframe-loader-3dtiles-component Code is available via glitch url reply ctrlw 2 hours agoparentprevThat looks great! I‘ve been playing around with Aframe and OSM building footprints, but this looks so much better. Will have a look at aframe-loader-3dtiles-component. reply sbarre 15 hours agoparentprevThis is super cool! Congrats on the PoC ... reply aantix 14 hours agoparentprevWow, amazing work! reply aaroninsf 11 hours agoparentprevAre you on Bluesky? Would love to follow. But not, you know, over there. reply kfarr 10 hours agorootparentClosest I can offer is https://sfba.social/@kfarr/112204337465256518 reply chpatrick 16 hours agoprev\"The average speed is 36 FPS (tested on A100).\" Real-Time if you have $8k I guess. reply jsheard 15 hours agoparentGood ol' \"SIGGRAPH realtime\", when a graphics paper describes itself as achieving realtime speeds you always have to double check that they mean actually realtime and not \"640x480 at 20fps on the most expensive hardware money can buy\". Anything can be realtime if you set the bar low enough. reply oivey 13 hours agorootparentDepending on what you’re doing, that really isn’t a low bar. Saying you can get decent performance on any hardware is the first step. reply PheonixPharts 13 hours agorootparent> get decent performance The issue is that in Computer Science \"real-time\" doesn't just mean \"pretty fast\", it's a very specific definition of performance[0]. Doing \"real-time\" computing is generally considered hard even for problems that are themselves not too challenging, and involves potentially severe consequences for missing a computational deadline. Which leads to both confusion and a bit of frustration when sub-fields of CS throw around the term as if it just means \"we don't have to wait a long time for it to render\" or \"you can watch it happen\". [0] https://en.wikipedia.org/wiki/Real-time_computing reply aleksiy123 11 hours agorootparentThat link defines it in terms of simulation as well: \"The term \"real-time\" is also used in simulation to mean that the simulation's clock runs at the same speed as a real clock.\" and even states that was the original usage of the term. I think that pretty much meets the definition of \"you can watch it happen\". Essentially there is real-time systems and real-time simulation. So it seems that they are using the term correctly in the context of simulation. reply dekhn 10 hours agorootparentprevI don't think it's reasonable to expect the larger community to not use \"real time\" to mean things other than \"hard real time as understood by a hardware engineer building a system that needs guaranteed interrupt latencies\". reply Mtinie 7 hours agorootparentI think it’s reasonable to assume that it means what you described on this site. reply dekhn 7 hours agorootparentOf course. I'm in the \"Reality is just 100M lit, shaded, textured polygons per second\" kind of guy- realtime is about 65 FPS with no jank. reply phkahler 15 hours agorootparentprev>> Anything can be realtime if you set the bar low enough. I was doing \"realtime ray tracing\" on Pentium class computers in the 1990s. I took my toy ray tracer and made an OLE control and put it inside a small Visual Basic app which handled keypress-navigation. It could run in a tiny little window (size of a large icon) at reasonable frame rates. Might even say it was using Visual Basic! So yeah \"realtime\" needs some qualifiers ;-) reply TeMPOraL 12 hours agorootparentFair, but today it could probably run 30FPS full-screen at 2K resolution, without any special effort, on an average consumer-grade machine; better if ported to take advantage of the GPU. Moore's law may be dead in general, but computing power still increases (notwithstanding the software bloat that makes it seem otherwise), and it's still something to count on wrt. bleeding edge research demos. reply VelesDude 11 hours agorootparentprevMicrosoft once set the bar for realtime as 640x480 @ 10fps. But this was just for research purposes. You can make out what it is trying to do and the update rate was JUST acceptable enough to be interactive. reply harles 10 hours agorootparentI’d actually call that a good bar. If you’re looking 5-10 years down the line for consumers, it’s reasonable. If you think the results can influence hardware directions sooner than that (for better performance) it’s also reasonable. reply mateo1 13 hours agorootparentprevIt can be run real time. Might be 640x480 or 20 fps, but many algorithms out there could never been run on an $10k graphics card or even a computing cluster in real time. reply cchance 14 hours agorootparentprevI mean A100's were cutting edge a year or so ago now we're at what H200 and B200 or is it 300's like it may be a year or 2 more but the A100 speed will trickle down to the average consumer as well. reply TeMPOraL 12 hours agorootparentAnd, from the other end, research demonstrations tend to have a lot of low-hanging fruits wrt. optimization, which will get picked if the result is interesting enough. reply rallyforthesun 16 hours agoparentprevAs it seems the first 3DGS which uses Lods and blocks, there might be place for optimization. This might become useful for use cases in Virtual Production, probably not for mobiles. reply m463 13 hours agoparentprevotoh I remember those old GPU benchmarks that ran at 10 fps when they came out, then over time... https://www.techpowerup.com/forums/attachments/all-cards-png... reply pierotofy 14 hours agoparentprevA lot of 3DGS/Nerf research is like this unfortunately (ugh). Check https://github.com/pierotofy/OpenSplat for something you can run on your 10 year old laptop, even without a GPU! (I'm the author) reply somethingsome 12 hours agorootparentI know, I don't get the fuzz either, I've coded real-time gaussian splat renderers >7 years ago with LOD and they were able to show any kind of point cloud. They worked with a basic 970 GTX on a big 3d screen and also on oculus dk2. reply aurareturn 5 hours agoparentprevI'm going to guess that the next-gen consumer GPU (5090) will be twice as fast as A100 and will not cost $8k. So I don't know see an insurmountable problem. reply datascienced 11 hours agoparentprevJust wait 2 years it’ll be on your phone. reply anigbrowl 8 hours agoparentprevYou gotta start somewhere reply RicoElectrico 16 hours agoparentprev\"Two more papers down the line...\" ;) reply Fauntleroy 16 hours agorootparentIndeed, this very much looks like what we'll likely see from Google Earth within a decade—or perhaps half that. reply mortenjorck 12 hours agorootparentI’ve seen very impressive Gaussian splatting demos of more limited urban geographies (a few city blocks) running on consumer hardware, so the reason this requires research-tier Nvidia hardware right now is probably down to LOD streaming. More optimization on that front, and this could plausibly come to Google Earth on current devices. “What a time to be alive” indeed! reply xyproto 7 hours agorootparentprev2 years tops, since the technology is there, it would be a considerable improvement to Google Maps, and Google has the required resources. reply littlestymaar 15 hours agoparentprevI chuckled a bit too when I saw it. By the way, what's the compute power difference between an A100 and a 4090? reply enlyth 14 hours agorootparentI believe the main advantage of the A100 is the memory bandwidth. Computationally the 4090 has a higher clock speed and more CUDA cores, so in that way it is faster. So for this specific application it really depends on where the bottleneck is reply entropicdrifter 14 hours agorootparentprev4090 is faster in terms of compute, but the A100 has 40GB of VRAM. reply mywittyname 15 hours agoparentprevPresumably, this is can be used as the first stage in a pipeline. Take the models and textures generated from source data using this, cached it, and stream that data to clients for local rendering. Consumer GPUs are probably 2-3 generations out from being as capable as an A100. reply Legend2440 15 hours agorootparentThere are no models or textures, it's just a point cloud of color blobs. You can convert it to a mesh, but in the process you'd lose the quality and realism that makes it interesting. reply satvikpendem 10 hours agoprevFunny to see just how prolific Gauss was since so many things are named after him and continue to be newly named after him, such as this example of Gaussian splatting, which, while he obviously didn't directly invent it, contributed to the mathematics of it significantly. reply gmerc 2 hours agoprevRelated https://city-super.github.io/octree-gs/ reply 999900000999 15 hours agoprevExcited to see what license this is released under. Would love to see some open source games using this. reply jsheard 15 hours agoparentPerformance aside, someone needs to figure out a generalizable way to make the scenes dynamic before it will really be usable for games. History is littered with alternatives to triangles meshes that looked promising until we realised there's no efficient way to animate them. reply CuriouslyC 15 hours agorootparentEven if this doesn't replace triangles everywhere, I'm guessing it's still going to be the easiest way to generate a large volume of static art assets, which means we will see hybrid rendering pipelines. reply jsheard 15 hours agorootparentAIUI these algorithms currently bake all of the lighting into the surface colors statically, which mostly works if the entire scene is constructed as one giant blob where nothing moves but if you wanted to render an individual NeRF asset inside an otherwise standard triangle-based pipeline then it would need to be more adaptable than that. Even if the asset itself isn't animated it would need to adapt to the local lighting at the bare minimum, which I haven't seen anyone tackle yet, the focus has been on the rendering-one-giant-static-blob problem. For hybrid pipelines to work the splatting algorithm would probably need to output the standard G-Buffer channels (unlit surface color, normal, roughness, etc) which can then go through the same lighting pass as the triangle-based assets, rather than the splatting algorithm trying to infer lighting by itself and inevitably getting a result that's inconsistent with how the triangle-based assets are lit. Think of those old cartoons where you could always tell when part of the scenery was going to move because the animation cel would stick out like a sore thumb against the painted background, that's the kind of illusion break you would get if the lighting isn't consistent. reply somethingsome 12 hours agorootparentFor NeRF this problems exists. However, in the past it was already solved for gaussian splatting. Usually you define a normal field over the (2D) splat, This allows you to have phong shading at least. It is not too difficult to go to a 2D normal field over the 3D gaussians.. reply 999900000999 15 hours agorootparentprevCan you explain what a dynamic is ? I was more thinking you'd run this tool, and then have an algorithm convert it( bake the mesh). reply lawlessone 15 hours agorootparentThey probably mean animated, changeable etc. Like movement, or changes in lighting. reply jnsjjdk 15 hours agoprevThis does not look significantly better then e.g. cities skylines, especially since they neither zoomed in or out, always showing only a very limited frame Am I missing something? reply chankstein38 13 hours agoparentAll 3 of the other commenters are replying without having done any actual thought or research. The paper repeatedly references MatrixCity and another commenter above found this https://city-super.github.io/matrixcity/ which also, I'd like to add, calls out that it's fully Synthetic. And, from what I understand, is extracted from Unreal Engine. reply neuronexmachina 15 hours agoparentprevThis is a 3D reconstruction, rather than a game rendering. reply dartos 15 hours agoparentprevThis was rendered from photographs, I believe reply cchance 14 hours agoparentprevLOL this isn't a game engine, its real life photos being converted into gausian 3d views. reply mhuffman 11 hours agoprevQuick question for anyone that may have more technical insight, is Gaussian Splatting the technology that Unreal Engine has been using to have such jaw dropping demos with their new releases? reply rmccue 10 hours agoparentUnreal Engine 5 is a combination of a few technologies: * Virtualised geometry (Nanite) allowing very detailed models * Very high quality models and textures from photogrammetry (Megascans) * Real-time global illumination (Lumen) Combining these is what allows the very high fidelity demos, as they’re each step changes from the previous techniques in Unreal. Megascans (and the Quixel library) are a big part of the “photorealness” of these demos, because they’re basically literally photos. reply notachatbot1234 3 hours agoparentprevNo but here are some nice talks on the Nanite geometry technology of UE: https://www.youtube.com/watch?v=NRnj_lnpORU https://www.youtube.com/watch?v=eviSykqSUUw reply andybak 11 hours agoparentprevNo. Mostly unrelated. reply rallyforthesun 16 hours agoprevReally advanced approach to render larger scenes with 3DGaussians, cant wait to test the code :-) reply forrestthewoods 15 hours agoprevCan someone convince me that 3D gaussian splatting isn't a dead end? It's an order of magnitude too slow to render and order of magnitude too much data. It's like raster vs raytrace all over again. Raster will always be faster than raytracing. So even if raytracing gets 10x faster so too will raster. I think generating traditional geometry and materials from gaussian point clouds is maybe interesting. But photogrammetry has already been a thing for quite awhile. Trying to render a giant city in real time via splats doesn't feel like \"the right thing\". It's definitely cool and fun and exciting. I'm just not sure that it will ever be useful in practice? Maybe! I'm definitely not an expert so my question is genuine. reply kfarr 15 hours agoparentYes this has tons of potential. It's analogous but different to patented techniques used by Unreal engine. Performance is not the focus in most research at the moment. There isn't even alignment on unified format with compression yet. The potential for optimization is very clear and straightforward to adapt to many devices, it's similar to point cloud LOD, mesh culling, etc. Splat performance could be temporary competitive advantage for viewers, but similar to video decompression and other 3d standards that are made available via open source, it will likely become commonplace in a few years to have high quality high fps splat viewing on most devices as tablestakes. The next question is what are the applications thereof. reply gmerc 14 hours agoparentprevIt's not an order of magnitude slower. You can easily get 200-400 fps in Unreal or Unity at the moment. 100+FPS in browser? https://current-exhibition.com/laboratorio31/ 900FPS? https://m-niemeyer.github.io/radsplat/ We have 3 decades worth of R&D in traditional engines, it'll take a while for this to catch up in terms of tooling and optimization but when you look where the papers come from (many from Apple and Meta), you see that this is the technology destined to power the MetaVerse/Spatial Compute era both companies are pushing towards. The ability to move content at incredibly low production costs (iphone movie) into 3d environments is going to murder a lot of R&D made in traditional methods. reply araes 14 hours agorootparentDon't know the hardware involved, yet that first link is most definitely not 100 FPS on all hardware. Slideshow on the current device. reply jasonjmcghee 9 hours agorootparentMaybe not, but it's relatively smooth on my 3 year old phone, which is crazy impressive Edit: I was in low power mode, it runs quite smoothly reply 101008 13 hours agorootparentprevDoes anyone know how the first link is made? reply gmerc 2 hours agorootparentYou are in luck, the author has been sharing https://medium.com/@heyulei/capture-images-for-gaussian-spla... reply pierotofy 14 hours agoparentprevPhotogrammetry struggles with certain types of materials (e.g. reflective surfaces). It's also very difficult to capture fine details (thin structures, hair). 3DGS is very good at that. And people are working on improving current shortcomings, including methods to extract meshes that we could use in traditional graphics pipelines. reply somethingsome 11 hours agorootparent3DGS is absolutely not good with non Lambertian materials.. After testing it, if fails in very basic cases. And it is normal that it fails, non Lambertian materials are not reconstructed correctly with SfM methods. reply andybak 8 hours agorootparentI don't understand the connection you're making between SfM (Structure from Motion) and surface shading. I might be misunderstanding what you're trying to say. Could you elaborate? reply somethingsome 4 hours agorootparentYou use SfM to find the first point cloud. However SfM is based on the hypothesis that the same point 'moves' linearly in between any two views. This hypothesis is important because it allows you to match a point in two pictures, and given the distance between the two images, you can triangulate the point in space. Therefore find it's depth. However, non-Lambertian points move non linearly in viewing space (eg a specular point depends on the viewer pose). So, automatically, their positions in space will be false, and you'll have floating points. Gaussian 'splats' may have the potential to render non-Lambertian stuff using for example the spherical harmonics (even if I don't think the viewer use them if I'm not mistaken). But, capturing non-Lambertian points is very difficult and an open research problem. reply mschuetz 15 hours agoparentprevIt's currently unparalleled when it comes to realism as in realistic 3D reconstruction from the real world. Photogrammetry only really works for nice surfacic data, whereas gaussian splats work for semi-volumetric data such as fur, vegetation, particles, rough surfaces, and also for glossy/specular surfaces and volumes with strong subdivision surface properties, or generally stuff with materials that are strongly view-dependent. reply tedd4u 3 hours agorootparentThis seems like impressive work. You mention glossy / specular. I wonder why nothing in the city (first video) is reflective, not even the glass box skyscrapers. I noticed there is something funky in the third video with the iron railway rails from about :28 to :35 seconds. They look ghostly and appear to come in and out. Overall these three videos are pretty devoid of shiny or reflective things. reply jerf 14 hours agoparentprevYou have to ask about what it's a dead end for. It seems pretty cool for the moral equivalent of fully 3D photographs. That's a completely legitimate use case. For 3D gaming engines? I struggle to see how the fundamental primitive can be made to sing and dance in the way that they demand. People will try, though. But from this perspective, gaussians strike me more as a final render format than a useful intermediate representation. If they are going to use gaussians there's going to have to be something else invented to make them practical to use for engines in the meantime, and there's still an awful lot of questions there. For other uses? Who knows. But the world is not all 3D gaming and visual special effects. reply gmerc 2 hours agorootparentYou are missing where this is coming from. Many of the core papers for this came from Meta's VR team (codec avatars), Apple ML (Spatial Compute) and Nvidia - companies deeply invested in VR/Spatial compute. It's clear that they see it as a key technology to further their interests in the space, and they are getting plenty of free help: After being open sourced in May last year, there were 79 papers overall published on the topic. It's more than 150 this year, more than one a day, advancing this \"dead end\" forward. A small selection: https://animatable-gaussians.github.io/ https://nvlabs.github.io/GAvatar/ https://research.nvidia.com/labs/toronto-ai/AlignYourGaussia... https://github.com/lkeab/gaussian-grouping reply rallyforthesun 15 hours agoparentprevIn regards of contentproduction for virtual production, it is quicker to capture a scene and process the images into a cloud of 3d-gaussians, but on the other hand it is harder to edit the scene after its shot. Also, the light is already captured and baked into it. The tools to edit scenes will probably rely a lot on ai, like delighting and change of settings. right now there are just a few, the process is more like using knife to cut out parts and remove floaters. You can replay this of course with the unreal engine, but in the long term you could run it in a browser. So in short, if you want to capture a place as it is with all its tiny details, 3dgaussians are a quicker and cheaper way to afford this than using modelling and texturing. reply peppertree 14 hours agoparentprevMesh based photogrammetry is a dead end. GS or radiance field representation is just getting started. Not just rendering but potentially a highly compact way to store large 3D scenes. reply forrestthewoods 13 hours agorootparent> potentially a highly compact way to store large 3D scenes. Is it? So far it seems like the storage size is massive and the detail is unacceptably low up close. Is there a demo that will make me go “holy crap I can’t believe how well this scene compressed”? reply peppertree 11 hours agorootparentHere is a paper if you are interested. https://arxiv.org/pdf/2311.13681.pdf The key is not to compress but to leverage the property of neural radiance fields and optimize for entropy. I suspect NERF can yield more compact storage since it's volumetric. Not sure what you mean by \"unacceptably low up close\". Most GS demos don't have LoD lol. reply forrestthewoods 9 hours agorootparent> Not sure what you mean by \"unacceptably low up close\". Most GS demos don't have LoD lol. When the camera gets close the \"texture\" resolution is extremely low. Like, roughly 1/4 what I would expect. Maybe even 1/8. Aka it's very blurry. reply bodhiandphysics 12 hours agoparentprevTry animating a photogrammetric model! How about one that changes its shape? You get awful geometry from photogrammetry… In practice the answer to will this be useful is yes! Subdivision surfaces coexist with nurbs for different applications. reply maxglute 15 hours agoparentprevHardware evolves with production in mind. If method saves 10x time/labour even using 50x more expensive compute/tools then industry will figure out way to optimize/amortize compute cost on that task over time and eventually deseminate into consumer hardware. reply forrestthewoods 14 hours agorootparentMaybe. That implies that hardware evolution strictly benefits Bar and not Foo. But what has happened so far is that hardware advancements to accelerate NewThing also accelerate OldThing. reply maxglute 9 hours agorootparentI think hardware evolution has to benefit Bar and Foo for production continuity anyways, OldThing still has to be supported until it becomes largely obsolete to both industry and consumer. In which case fringe users have to hold on to old hardware to keep processes going. reply fngjdflmdflg 14 hours agoparentprev>But photogrammetry has already been a thing for quite awhile. Current photogrammetry to my knowledge requires much more data than NeRfs/Gaussian splatting. So this could be a way to get more data for the \"dumb\" photogrammetry algorithms to work with. reply jonas21 12 hours agoparentprevHow is it too slow? You can easily render scenes at 60fps in a browser or on a mobile phone. Heck, you can even train one from scratch in a minute on an iPhone [1]. This technique has been around for less than a year. It's only going to get better. [1] https://www.youtube.com/watch?v=nk0f4FTcdmM reply somethingsome 11 hours agorootparentThis technique exists from more than 10 years, and real time renderers exist too from very long. reply mthoms 12 hours agorootparentprevThat's pretty cool. It's not clear if it's incorporating Lidar data or not though. It's very impressive if not. reply chankstein38 13 hours agoparentprevI'll be honest, I don't have a ton of technical insights into these but anecdotally, I found that using KIRI Engine's Gaussian Splatting scans (versus Photogrammetry scans) the GS scans were way more accurate and true to life and required a lot less cleanup! reply Legend2440 15 hours agoparentprevNothing comes close to this for realism, it's like looking at a photo. Traditional photogrammetry really struggles with complicated scenes, and reflective or transparent surfaces. reply thfuran 12 hours agoparentprev>much data. It's like raster vs raytrace all over again. Raster will always be faster than raytracing. So even if raytracing gets 10x faster so too will raster. And? It's always going to be even faster to not have lighting at all. reply boywitharupee 14 hours agoprevwhat's the memory and compute requirements for this? reply dukeofdoom 4 hours agoprevDoes anyone know how to add motion blur to a game. I'm learning pygame. Say I'm making Mario in pygame, and when Mario jumps, I want him to look blurry. I mean I can take an average of 9 pixels, and create a blurry version of Mario. But is that how it's that usually done in other games. Since like a lot of games are supper sharp, with no motion blur. I'm wondering if its even done. It's kind of big deal in film, and the need to shoot at 25fps to achieve cinematic motion blur. reply jayd16 4 hours agoparentRender the motion vector of objects to another render texture. (ie calculate the velocity of each object and render that as a color) Use that to define the amplitude and direction of your blur effect in a post pass. And you might want it to be the motion relevant to the camera. For Mario, probably not, but for an FPS you want to edges of the screen to blur as the camera moves forward. reply syrusakbary 15 hours agoprev [–] Gaussian splatting is truly amazing for 3d reconstruction. I can't wait to see once it's applied to the world of driverless vehicles and AI! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "CityGaussian (CityGS) revolutionizes real-time high-quality large-scale scene rendering through 3D Gaussian splatting, divide-and-conquer training, and Level-of-Detail (LoD) strategy.",
      "It integrates global scene prior and adaptive training data selection, leading to state-of-the-art rendering quality and real-time performance at different scales.",
      "CityGS outperforms other methods, delivering remarkable real-time rendering speeds of up to 36 FPS in experimental tests."
    ],
    "commentSummary": [
      "Gaussian splatting is explored in real-time large-scale scene rendering for 3D reconstruction tech, showing efficiency potential but sparking debates on limitations and optimizations.",
      "Discussions include comparisons to photogrammetry and Unreal Engine, highlighting applications and advancements in real-time rendering and GPU tech.",
      "Contributors share experiences and perspectives on real-time computing and graphics performance, hinting at future optimizations, research advancements, and the exciting prospect of technology release under an open source license."
    ],
    "points": 412,
    "commentCount": 109,
    "retryCount": 0,
    "time": 1712076392
  },
  {
    "id": 39905441,
    "title": "Enhanced Python Support in Cloudflare Workers",
    "originLink": "https://blog.cloudflare.com/python-workers",
    "originBody": "Bringing Python to Workers using Pyodide and WebAssembly 04/02/2024 Hood Chatham Garrett Gu Dominik Picheta 16 min read Starting today, in open beta, you can now write Cloudflare Workers in Python. This new support for Python is different from how Workers have historically supported languages beyond JavaScript — in this case, we have directly integrated a Python implementation into workerd, the open-source Workers runtime. All bindings, including bindings to Vectorize, Workers AI, R2, Durable Objects, and more are supported on day one. Python Workers can import a subset of popular Python packages including FastAPI, Langchain, Numpy and more. There are no extra build steps or external toolchains. To do this, we’ve had to push the bounds of all of our systems, from the runtime itself, to our deployment system, to the contents of the Worker bundle that is published across our network. You can read the docs, and start using it today. We want to use this post to pull back the curtain on the internal lifecycle of a Python Worker, share what we’ve learned in the process, and highlight where we’re going next. Beyond “Just compile to WebAssembly” Cloudflare Workers have supported WebAssembly since 2018 — each Worker is a V8 isolate, powered by the same JavaScript engine as the Chrome web browser. In principle, it’s been possible for years to write Workers in any language — including Python — so long as it first compiles to WebAssembly or to JavaScript. In practice, just because something is possible doesn’t mean it’s simple. And just because “hello world” works doesn’t mean you can reliably build an application. Building full applications requires supporting an ecosystem of packages that developers are used to building with. For a platform to truly support a programming language, it’s necessary to go much further than showing how to compile code using external toolchains. Python Workers are different from what we’ve done in the past. It’s early, and still in beta, but we think it shows what providing first-class support for programming languages beyond JavaScript can look like on Workers. The lifecycle of a Python Worker With Pyodide now built into workerd, you can write a Worker like this: from js import Response async def on_fetch(request, env): return Response.new(\"Hello world!\") ...with a wrangler.toml file that points to a .py file: name = \"hello-world-python-worker\" main = \"src/entry.py\" compatibility_date = \"2024-03-18\" compatibility_flags = [\"python_workers\"] …and when you run npx wrangler@latest dev, the Workers runtime will: Determine which version of Pyodide is required, based on your compatibility date Create an isolate for your Worker, and automatically inject Pyodide Serve your Python code using Pyodide This all happens under the hood — no extra toolchain or precompilation steps needed. The Python execution environment is provided for you, mirroring how Workers written in JavaScript already work. A Python interpreter built into the Workers runtime Just as JavaScript has many engines, Python has many implementations that can execute Python code. CPython is the reference implementation of Python. If you’ve used Python before, this is almost certainly what you’ve used, and is commonly referred to as just “Python”. Pyodide is a port of CPython to WebAssembly. It interprets Python code, without any need to precompile the Python code itself to any other format. It runs in a web browser — check out this REPL. It is true to the CPython that Python developers know and expect, providing most of the Python Standard Library. It provides a foreign function interface (FFI) to JavaScript, allowing you to call JavaScript APIs directly from Python — more on this below. It provides popular open-source packages, and can import pure Python packages directly from PyPI. Pyodide struck us as the perfect fit for Workers. It is designed to allow the core interpreter and each native Python module to be built as separate WebAssembly modules, dynamically linked at runtime. This allows the code footprint for these modules to be shared among all Workers running on the same machine, rather than requiring each Worker to bring its own copy. This is essential to making WebAssembly work well in the Workers environment, where we often run thousands of Workers per machine — we need Workers using the same programming language to share their runtime code footprint. Running thousands of Workers on every machine is what makes it possible for us to deploy every application in every location at a reasonable price. Just like with JavaScript Workers, with Python Workers we provide the runtime for you: Pyodide is currently the exception — most languages that target WebAssembly do not yet support dynamic linking, so each application ends up bringing its own copy of its language runtime. We hope to see more languages support dynamic linking in the future, so that we can more effectively bring them to Workers. How Pyodide works Pyodide executes Python code in WebAssembly, which is a sandboxed environment, separated from the host runtime. Unlike running native code, all operations outside of pure computation (such as file reads) must be provided by a runtime environment, then imported by the WebAssembly module. LLVM provides three target triples for WebAssembly: wasm32-unknown-unknown – this backend provides no C standard library or system call interface; to support this backend, we would need to manually rewrite every system or library call to make use of imports we would define ourselves in the runtime. wasm32-wasi – WASI is a standardized system interface, and defines a standard set of imports that are implemented in WASI runtimes such as wasmtime. wasm32-unknown-emscripten – Like WASI, Emscripten defines the imports that a WebAssembly program needs to execute, but also outputs an accompanying JavaScript library that implements these imported functions. Pyodide uses Emscripten, and provides three things: A distribution of the CPython interpreter, compiled using Emscripten A foreign function interface (FFI) between Python and JavaScript A set of third-party Python packages, compiled using Emscripten’s compiler to WebAssembly. Of these targets, only Emscripten currently supports dynamic linking, which, as we noted above, is essential to providing a shared language runtime for Python that is shared across isolates. Emscripten does this by providing implementations of dlopen and dlsym, which use the accompanying JavaScript library to modify the WebAssembly program’s table to link additional WebAssembly-compiled modules at runtime. WASI does not yet support the dlopen/dlsym dynamic linking abstractions used by CPython. Pyodide and the magic of foreign function interfaces (FFI) You might have noticed that in our Hello World Python Worker, we import Response from the js module: from js import Response async def on_fetch(request, env): return Response.new(\"Hello world!\") Why is that? Most Workers are written in JavaScript, and most of our engineering effort on the Workers runtime goes into improving JavaScript Workers. There is a risk in adding a second language that it might never reach feature parity with the first language and always be a second class citizen. Pyodide’s foreign function interface (FFI) is critical to avoiding this by providing access to all JavaScript functionality from Python. This can be used by the Worker author directly, and it is also used to make packages like FastAPI and Langchain work out-of-the-box, as we’ll show later in this post. An FFI is a system for calling functions in one language that are implemented in another language. In most cases, an FFI is defined by a \"higher-level\" language in order to call functions implemented in a systems language, often C. Python’s ctypes module is such a system. These sorts of foreign function interfaces are often difficult to use because of the nature of C APIs. Pyodide’s foreign function interface is an interface between Python and JavaScript, which are two high level object-oriented languages with a lot of design similarities. When passed from one language to another, immutable types such as strings and numbers are transparently translated. All mutable objects are wrapped in an appropriate proxy. When a JavaScript object is passed into Python, Pyodide determines which JavaScript protocols the object supports and dynamically constructs an appropriate Python class that implements the corresponding Python protocols. For example, if the JavaScript object supports the JavaScript iteration protocol then the proxy will support the Python iteration protocol. If the JavaScript object is a Promise or other thenable, the Python object will be an awaitable. from js import JSON js_array = JSON.parse(\"[1,2,3]\") for entry in js_array: print(entry) The lifecycle of a request to a Python Worker makes use of Pyodide’s FFI, wrapping the incoming JavaScript Request object in a JsProxy object that is accessible in your Python code. It then converts the value returned by the Python Worker’s handler into a JavaScript Response object that can be delivered back to the client: Why dynamic linking is essential, and static linking isn’t enough Python comes with a C FFI, and many Python packages use this FFI to import native libraries. These libraries are typically written in C, so they must first be compiled down to WebAssembly in order to work on the Workers runtime. As we noted above, Pyodide is built with Emscripten, which overrides Python’s C FFI — any time a package tries to load a native library, it is instead loaded from a WebAssembly module that is provided by the Workers runtime. Dynamic linking is what makes this possible — it is what lets us override Python’s C FFI, allowing Pyodide to support many Python packages that have native library dependencies. Dynamic linking is “pay as you go”, while static linking is “pay upfront” — if code is statically linked into your binary, it must be loaded upfront in order for the binary to run, even if this code is never used. Dynamic linking enables the Workers runtime to share the underlying WebAssembly modules of packages across different Workers that are running on the same machine. We won’t go too much into detail on how dynamic linking works in Emscripten, but the main takeaway is that the Emscripten runtime fetches WebAssembly modules from a filesystem abstraction provided in JavaScript. For each Worker, we generate a filesystem at runtime, whose structure mimics a Python distribution that has the Worker’s dependencies installed, but whose underlying files are shared between Workers. This makes it possible to share Python and WebAssembly files between multiple Workers that import the same dependency. Today, we’re able to share these files across Workers, but copy them into each new isolate. We think we can go even further, by employing copy-on-write techniques to share the underlying resource across many Workers. Supporting Server and Client libraries Python has a wide variety of popular HTTP client libraries, including httpx, urllib3, requests and more. Unfortunately, none of them work out of the box in Pyodide. Adding support for these has been one of the longest running user requests for the Pyodide project. The Python HTTP client libraries all work with raw sockets, and the browser security model and CORS do not allow this, so we needed another way to make them work in the Workers runtime. Async Client libraries For libraries that can make requests asynchronously, including aiohttp and httpx, we can use the Fetch API to make requests. We do this by patching the library, instructing it to use the Fetch API from JavaScript — taking advantage of Pyodide’s FFI. The httpx patch ends up quite simple —fewer than 100 lines of code. Simplified even further, it looks like this: from js import Headers, Request, fetch def py_request_to_js_request(py_request): js_headers = Headers.new(py_request.headers) return Request.new(py_request.url, method=py_request.method, headers=js_headers) def js_response_to_py_response(js_response): ... # omitted async def do_request(py_request): js_request = py_request_to_js_request(py_request) js_response = await fetch(js_request) py_response = js_response_to_py_response(js_response) return py_response Synchronous Client libraries Another challenge in supporting Python HTTP client libraries is that many Python APIs are synchronous. For these libraries, we cannot use the fetch API directly because it is asynchronous. Thankfully, Joe Marshall recently landed a contribution to urllib3 that adds Pyodide support in web browsers by: Checking if blocking with Atomics.wait() is possible a. If so, start a fetch worker thread b. Delegate the fetch operation to the worker thread and serialize the response into a SharedArrayBuffer c. In the Python thread, use Atomics.wait to block for the response in the SharedArrayBuffer If Atomics.wait() doesn’t work, fall back to a synchronous XMLHttpRequest Despite this, today Cloudflare Workers do not support worker threads or synchronous XMLHttpRequest, so neither of these two approaches will work in Python Workers. We do not support synchronous requests today, but there is a way forward… WebAssembly Stack Switching There is an approach which will allow us to support synchronous requests. WebAssembly has a stage 3 proposal adding support for stack switching, which v8 has an implementation of. Pyodide contributors have been working on adding support for stack switching to Pyodide since September of 2022, and it is almost ready. With this support, Pyodide exposes a function called run_sync which can block for completion of an awaitable: from pyodide.ffi import run_sync def sync_fetch(py_request): js_request = py_request_to_js_request(py_request) js_response = run_sync(fetch(js_request)) return js_response_to_py_response(js_response) FastAPI and Python’s Asynchronous Server Gateway Interface FastAPI is one of the most popular libraries for defining Python servers. FastAPI applications use a protocol called the Asynchronous Server Gateway Interface (ASGI). This means that FastAPI never reads from or writes to a socket itself. An ASGI application expects to be hooked up to an ASGI server, typically uvicorn. The ASGI server handles all of the raw sockets on the application’s behalf. Conveniently for us, this means that FastAPI works in Cloudflare Workers without any patches or changes to FastAPI itself. We simply need to replace uvicorn with an appropriate ASGI server that can run within a Worker. Our initial implementation lives here, in the fork of Pyodide that we maintain. We hope to add a more comprehensive feature set, add test coverage, and then upstream this implementation into Pyodide. You can try this yourself by cloning cloudflare/python-workers-examples, and running npx wrangler@latest dev in the directory of the FastAPI example. Importing Python Packages Python Workers support a subset of Python packages, which are provided directly by Pyodide, including numpy, httpx, FastAPI, Langchain, and more. This ensures compatibility with the Pyodide runtime by pinning package versions to Pyodide versions, and allows Pyodide to patch internal implementations, as we showed above in the case of httpx. To import a package, simply add it to your requirements.txt file, without adding a version number. A specific version of the package is provided directly by Pyodide. Today, you can use packages in local development, and in the coming weeks, you will be able to deploy Workers that define dependencies in a requirements.txt file. Later in this post, we’ll show how we’re thinking about managing new versions of Pyodide and packages. We maintain our own fork of Pyodide, which allows us to provide patches specific to the Workers runtime, and to quickly expand our support for packages in Python Workers, while also committing to upstreaming our changes back to Pyodide, so that the whole ecosystem of developers can benefit. Python packages are often big and memory hungry though, and they can do a lot of work at import time. How can we ensure that you can bring in the packages you need, while mitigating long cold start times? Making cold starts faster with memory snapshots In the example at the start of this post, in local development, we mentioned injecting Pyodide into your Worker. Pyodide itself is 6.4MB — and Python packages can also be quite large. If we simply shoved Pyodide into your Worker and uploaded it to Cloudflare, that’d be quite a large Worker to load into a new isolate — cold starts would be slow. On a fast computer with a good network connection, Pyodide takes about two seconds to initialize in a web browser, one second of network time and one second of cpu time. It wouldn’t be acceptable to initialize it every time you update your code for every isolate your Worker runs in across Cloudflare’s network. Instead, when you run npx wrangler@latest deploy, the following happens: Wrangler uploads your Python code and your requirements.txt file to the Workers API We send your Python code, and your requirements.txt file to the Workers runtime to be validated We create a new isolate for your Worker, and automatically inject Pyodide plus any packages you’ve specified in your requirements.txt file. We scan the Worker’s code for import statements, execute them, and then take a snapshot of the Worker’s WebAssembly linear memory. Effectively, we perform the expensive work of importing packages at deploy time, rather than at runtime. We deploy this snapshot alongside your Worker’s Python code to Cloudflare’s network. Just like a JavaScript Worker, we execute the Worker’s top-level scope. When a request comes in to your Worker, we load this snapshot and use it to bootstrap your Worker in an isolate, avoiding expensive initialization time: This takes cold starts for a basic Python Worker down to below 1 second. We’re not yet satisfied with this though. We’re confident that we can drive this down much, much further. How? By reusing memory snapshots. Reusing Memory Snapshots When you upload a Python Worker, we generate a single memory snapshot of the Worker’s top-level imports, including both Pyodide and any dependencies. This snapshot is specific to your Worker. It can’t be shared, even though most of its contents are the same as other Python Workers. Instead, we can create a single, shared snapshot ahead of time, and preload it into a pool of “pre-warmed” isolates. These isolates would already have the Pyodide runtime loaded and ready — making a Python Worker work just like a JavaScript Worker. In both cases, the underlying interpreter and execution environment is provided by the Workers runtime, and available on-demand without delay. The only difference is that with Python, the interpreter runs in WebAssembly, within the Worker. Snapshots are a common pattern across runtimes and execution environments. Node.js uses V8 snapshots to speed up startup time. You can take snapshots of Firecracker microVMs and resume execution in a different process. There’s lots more we can do here — not just for Python Workers, but for Workers written in JavaScript as well, caching snapshots of compiled code from top-level scope and the state of the isolate itself. Workers are so fast and efficient that to-date we haven’t had to take snapshots in this way, but we think there are still big performance gains to be had. This is our biggest lever towards driving cold start times down over the rest of 2024. Future proofing compatibility with Pyodide versions and Compatibility Dates When you deploy a Worker to Cloudflare, you expect it to keep running indefinitely, even if you never update it again. There are Workers deployed in 2018 that are still running just fine in production. We achieve this using Compatibility Dates and Compatibility Flags, which provide explicit opt-in mechanisms for new behavior and potentially backwards-incompatible changes, without impacting existing Workers. This works in part because it mirrors how the Internet and web browsers work. You publish a web page with some JavaScript, and rightly expect it to work forever. Web browsers and Cloudflare Workers have the same type of commitment of stability to developers. There is a challenge with Python though — both Pyodide and CPython are versioned. Updated versions are published regularly and can contain breaking changes. And Pyodide provides a set of built-in packages, each with a pinned version number. This presents a question — how should we allow you to update your Worker to a newer version of Pyodide? The answer is Compatibility Dates and Compatibility Flags. A new version of Python is released every year in August, and a new version of Pyodide is released six (6) months later. When this new version of Pyodide is published, we will add it to Workers by gating it behind a Compatibility Flag, which is only enabled after a specified Compatibility Date. This lets us continually provide updates, without risk of breaking changes, extending the commitment we’ve made for JavaScript to Python. Each Python release has a five (5) year support window. Once this support window has passed for a given version of Python, security patches are no longer applied, making this version unsafe to rely on. To mitigate this risk, while still trying to hold as true as possible to our commitment of stability and long-term support, after five years any Python Worker still on a Python release that is outside of the support window will be automatically moved forward to the next oldest Python release. Python is a mature and stable language, so we expect that in most cases, your Python Worker will continue running without issue. But we recommend updating the compatibility date of your Worker regularly, to stay within the support window. In between Python releases, we also expect to update and add additional Python packages, using the same opt-in mechanism. A Compatibility Flag will be a combination of the Python version and the release date of a set of packages. For example, python_3.17_packages_2025_03_01. How bindings work in Python Workers We mentioned earlier that Pyodide provides a foreign function interface (FFI) to JavaScript — meaning that you can directly use JavaScript objects, methods, functions and more, directly from Python. This means that from day one, all binding APIs to other Cloudflare resources are supported in Cloudflare Workers. The env object that is provided by handlers in Python Workers is a JavaScript object that Pyodide provides a proxy API to, handling type translations across languages automatically. For example, to write to and read from a KV namespace from a Python Worker, you would write: from js import Response async def on_fetch(request, env): await env.FOO.put(\"bar\", \"baz\") bar = await env.FOO.get(\"bar\") return Response.new(bar) # returns \"baz\" This works for Web APIs too — see how Response is imported from the js module? You can import any global from JavaScript this way. Get this JavaScript out of my Python! You’re probably reading this post because you want to write Python instead of JavaScript. from js import Response just isn’t Pythonic. We know — and we have actually tackled this challenge before for another language (Rust). And we think we can do this even better for Python. We launched workers-rs in 2021 to make it possible to write Workers in Rust. For each JavaScript API in Workers, we, alongside open-source contributors, have written bindings that expose a more idiomatic Rust API. We plan to do the same for Python Workers — starting with the bindings to Workers AI and Vectorize. But while workers-rs requires that you use and update an external dependency, the APIs we provide with Python Workers will be built into the Workers runtime directly. Just update your compatibility date, and get the latest, most Pythonic APIs. This is about more than just making bindings to resources on Cloudflare more Pythonic though — it’s about compatibility with the ecosystem. Similar to how we recently converted workers-rs to use types from the http crate, which makes it easy to use the axum crate for routing, we aim to do the same for Python Workers. For example, the Python standard library provides a raw socket API, which many Python packages depend on. Workers already provides connect(), a JavaScript API for working with raw sockets. We see ways to provide at least a subset of the Python standard library’s socket API in Workers, enabling a broader set of Python packages to work on Workers, with less of a need for patches. But ultimately, we hope to kick start an effort to create a standardized serverless API for Python. One that is easy to use for any Python developer and offers the same capabilities as JavaScript. We’re just getting started with Python Workers Providing true support for a new programming language is a big investment that goes far beyond making “hello world” work. We chose Python very intentionally — it’s the second most popular programming language after JavaScript — and we are committed to continuing to improve performance and widen our support for Python packages. We’re grateful to the Pyodide maintainers and the broader Python community — and we’d love to hear from you. Drop into the Python Workers channel in the Cloudflare Developers Discord, or start a discussion on Github about what you’d like to see next and which Python packages you’d like us to support. We protect entire corporate networks, help customers build Internet-scale applications efficiently, accelerate any website or Internet application, ward off DDoS attacks, keep hackers at bay, and can help you on your journey to Zero Trust. Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer. To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Discuss on Hacker News DevelopersCloudflare WorkersWebAssemblyPythonDeveloper PlatformWASMDeveloper Week",
    "commentLink": "https://news.ycombinator.com/item?id=39905441",
    "commentBody": "Python Cloudflare Workers (cloudflare.com)354 points by jasoncartwright 20 hours agohidepastfavorite89 comments syrusakbary 18 hours agoThis is awesome, I'm happy that Cloudflare is adding more attention into running Python via WebAssembly at the Edge. I'll try to summarize on how they got it running and what are the drawbacks that they have from their current approach (note: I have deep context on running Python with WebAssembly at the Edge as part of my work in Wasmer). Cloudflare Workers are enabling Python at the Edge by using Pyodide [1] (Python compiled to WebAssembly via Emscripten). They bundled Pyodide into Workerd [2], and then use V8 snapshots [3] to try to accelerate startup times. On their best case, cold starts of Python in Cloudflare Workers are about 1 second. While this release is great as it allows them to measure the interest of running Python at the Edge, it has some drawbacks. So, what are those? * Being tied to use only one version of Python/Pyodide (the one that Workerd embeds) * Package resolution is quite hacky and tied to workerd. Only precompiled \"native packages\" will be allowed to be used at runtime (eg. using a specific version of numpy will turn to be challenging) * Architecturally tied to the JS/v8 world, which may show some challenges as they aim to reduce cold start times (in my opinion, it will be quite hard for them to achievepyodide /package versions will be controlled by the compatibility date That's exactly the issue that I'm mentioning. Ideally you should be able to pin any Python version that you want to use in your app: 2.7, 3.8 or 3.9 regardless of a Workerd compatibility date. Some packages might work in Python 3.11 but not in 3.12, for example. Unfortunately, Python doesn't have the full transpiler architecture that JS ecosystem has, and thus \"packaging\" Python applications into different \"compatibility\" bundles will prove much more challenging (webpack factor). > Could you expand on why you believe V8 will be a limiting factor? Sure thing! I think we probably all agree that V8 is a fantastic runtime. However, the tradeoffs that make V8 great for a browser use case, makes the runtime more challenging for Edge environments (where servers can do more specialized workloads on trusted environments). Namely, those are: * Cold starts: V8 Isolates are a bit heavy to initialize. On it's current form it can add up from ~2-5ms in startup just by initializing an Isolate * Snapshots can be quite heavy to save and restore * Not architected with the Edge use case in mind: there are many tricks that you can do if you skip the JS middleware and go all in into a Wasm runtime, that are hard to do with the current V8/Workerd architecture. In any case, I would love to be proven wrong on the long term and I cheer forYour concerns about V8 would impact JavaScript Workers as well and do not match what we see in production Interesting! I thought V8 snapshots were mainly used in the Pyodide context, as I could not find any other usage in WorkerD (other than promise tagging and jsg::MemoryTracker). Are you using V8 snapshots as well for improving cold starts in JS applications? reply kflansburg 16 hours agorootparentI was responding to your point about isolates and cold starts. Snapshots are unique to Python, but V8 does not seem relevant here, all this is doing is initializing the linear buffer that backs Wasm memory for a particular instance. We have a lot of ideas here, some of which are mentioned in the blog post. reply syrusakbary 16 hours agorootparentAwesome. Eager to see how the product evolves :) reply kentonv 16 hours agorootparentprev(Cloudflare Workers tech lead here.) I disagree about V8 not being optimized for edge environments. The needs of a browser are actually very much aligned with needs of edge, namely secure sandboxing, extremely fast startup, and an extreme commitment to backwards compatibility (important so that all apps can always run on a single runtime version). Additionally, V8 is just much better at running JavaScript than you can hope to achieve in a Wasm-based JS implementation. And JavaScript is the most popular web development language (even server-side). > On it's current form it can add up from ~2-5ms in startup just by initializing an Isolate So, you and I seemingly have a disagreement on what \"cold start\" means. Wasmer advertises its own \"cold start\" time to be 50ns. This is only remotely possible if the application is already loaded in memory and ready to go before the request arrives. In my mind, this is not a \"cold start\". If the application is already loaded, then it's a \"warm start\". I haven't spent the time to benchmark our warm start time (TBH I'm a little unclear on what, exactly, is counted in this measurement), but if the app is already loaded, we can complete whole requests in a matter of microseconds, so the 5ms number isn't the correct comparison. To me, \"cold start\" time is the time to load an application, without prior knowledge of what application will be needed. That means it includes the time to fetch the application code from storage. For a small application, we get around 5ms. Note that the time to initialize an isolate isn't actually on the critical path to cold start, since we can pre-initialize isolates and have them ready to go before knowing what application they will run. That said, we haven't implemented this optimization historically, since the benefit would be relatively small. However, with Pyodide this changes a bit. We can pre-initialize Pyodide isolates, before we know which Python app needs to run. Again, this isn't implemented yet, but we expect the benefits to be much larger than with plain JS isolates, so we plan to do so. > Ideally you should be able to pin any Python version that you want to use in your app: Minimizing application size is really essential to making edge compute inexpensive -- to run every one of two million developers' applications in every of our hundreds of locations at a reasonable price, we need to be able to run thousands of apps simultaneously on each machine. If each one bundles its entire language runtime, that's not gonna fit. That does mean that many applications have to agree to use the same versions of common runtime libraries, so that they can share the same copies of that code. The goal is to keep most updates to Pyodide backwards-compatible so that we can just keep everyone on the latest version. When incompatible changes must be made, we'll have to load multiple versions per machine, but that's still better than one copy per app. reply syrusakbary 15 hours agorootparentHey Kenton, great to see you chiming in here as well! > Additionally, V8 is just much better at running JavaScript than you can hope to achieve in a Wasm-based JS implementation. And JavaScript is the most popular web development language (even server-side). I agree with this statement as of today. Stay tuned because very cool things are coming on Wasm land (Spidermonkey will soon support JITted workloads inside of Wasm, bringing the speed much closer to V8!) > Note that the time to initialize an isolate isn't actually on the critical path to cold start, since we can pre-initialize isolates and have them ready to go before knowing what application they will run That's a good point. Although, you are kind of optimizing now the critical path to cold start by actually knowing what the app is running (if is Python, restore it from a Snapshot). So even though if isolate initialization is not in the critical path, there are other things on the critical path that amounts for the extra second of latency in cold starts for Python, I would assume. > Minimizing application size is really essential to making edge compute inexpensive By leveraging on proper-defined dependencies, you just need to compile and load in memory the dependency module once (lets say Python) and have \"infinite\" capacity for initializing them. Basically, if you put Python out of the picture and consider it a dependency of an app, then you can suddenly scale apps as much as you want there! For example: having 10 Python versions (running thousands of apps) will have a overhead of 5Mb (Python binary size in avg) * 10 versions (plus a custom memory for each initialization of the app, which is required in either strategy) ~= 50Mb, so the overhead of pinning a specific Python version should be truly minimal on the server (at least when fully leveraging on a Wasm runtime) reply hoodchatham 16 hours agorootparentprevAre people maintaining wasi ports of Python 2.7 and 3.8? reply panqueca 18 hours agoparentprevDoes this architecture supports uvloop? reply hoodchatham 15 hours agorootparentPyodide uses its own event loop which just subscribes to the JavaScript event loop. My suspicion is that this will be more efficient than using uvloop since v8's event loop is quite well optimized. It also allows us to await JavaScript thenables from Python and Python awaitables from JavaScript, whereas I would be worried about how this behaves with separate event loops. Also, porting uvloop would probably be hard. reply syrusakbary 18 hours agorootparentprevAs far as I know uvloop is not supported in Pyodide, mainly because it requires compiling libuv into WebAssembly (which is possible but not trivial). In any case, it shall be possible to run uvloop fully inside of WebAssembly. However, doing so will prove challenging using their current architecture reply deanCommie 18 hours agoparentprev> (in my opinion, it will be quite hard for them to achievesomething like Google Cloud Run? No but it would be awesome. I've been using Workers for about 4 years in production and love them but containers are still where I run most of my apps. reply skybrian 18 hours agoparentprevI believe the CloudFlare free tier was pretty limited until recently. D1 (their SQLite implementation) became generally available yesterday, and read replicas are announced. reply thangngoc89 19 hours agoparentprev> does Cloudflare provide container hosting service agnostic of language -- something like Google Cloud Run? Nope. Their Workers are V8 based so JS or Wasm reply jasoncartwright 19 hours agoprevI've played with JS workers on a Cloudflare-fronted site and found them to be easy to use and very quick. Would love to port the whole Django app behind the site over, using their D1 database too. reply woutr_be 19 hours agoparentSame here, I have a couple of mobile apps that use Cloudflare workers + KV/D1, and it’s been great. I’m low traffic enough to be on the free tier, but would happily pay given how easy it’s been to build on. reply infamia 19 hours agoparentprevAgreed, this looks really cool. While there is no Django/DRF support at the moment, it does say that that they'll be increasing the number of packages in the future. reply brendanib 18 hours agorootparentWould love feedback on which packages you'd like to see us support: https://github.com/cloudflare/workerd/discussions/categories... reply manishsharan 18 hours agoparentprev>>Would love to port the whole Django app behind the site over, using their D1 database too. Is that wise? One DDOS attack could break your budget. reply piperswe 18 hours agorootparentOnly if the DDoS isn't blocked by the Cloudflare DDoS protection reply spxneo 18 hours agorootparentwhat are the advantages of using Cloudflare db over supabase? So far im loving supabase but wasn't aware CF products have increased drastically Rows read 5 million / day First 25 billion / month included + $0.001 / million rows Rows written 100,000 / day First 50 million / month included + $1.00 / million rows Storage (per GB stored) 5 GB (total) First 5 GB included + $0.75 / GB-mo reply piperswe 18 hours agorootparentPersonally my favorite part of using D1 is that the database is managed the same way as everything else, and you just access it through a Workers binding rather than needing any authentication or connection strings or anything. I'm excited to see how the new session API and read replicas work too, since they might be able to reduce DB read latency to being within the same datacenter in many instances. But I only know about as much about the D1 session API and read replicas as anyone else that read the blog post about it. Disclaimer: I work for Cloudflare, but not on Workers (my team just is a heavy user of Workers). I'm just speaking as a Workers user/enthusiast here. reply pdyc 17 hours agorootparentprevwhen D1 moved from alpha to beta they removed the backup feature. Granted it was beta but their support and tooling is quite fragile. Even now they have declared general availbility for D1, but if you try to take backup using their proposed wrangler commands it does not work(there are bugs in handling of dates). You end up wastting lot of time due to this. D1 is sqlite and supabase is postgresql so they are not exactly comparable but pros/cons of sqlite vs postgres apply here except that sqlite pros of db in process would not apply here since now both the db's have to be connected via wire. reply tyingq 19 hours agoprevA performance comparison to a JS worker would be helpful. It does sound interesting, but also sounds potentially slow, given all the layers involved. Not that I'm expecting parity, but knowing the rough tradeoff would be helpful. reply brendanib 18 hours agoparentThree aspects of performance: 1. Cold start perf 2. Post-cold start perf - The cost of bridging between JS and WebAssembly - The speed of the Python interpreter running in WebAssembly Today, Python cold starts are slower than cold starts for a JavaScript Worker of equivalent size. A basic \"Hello World\" Worker written in JavaScript has a near zero cold start time, while a Python Worker has a cold start under 1 second. That's because we still need to load Pyodide into your Worker on-demand when a request comes in. The blog post describes what we're working on to reduce this — making Pyodide already available upfront. Once a Python Worker has gone through a cold start though, the differences are more on the margins — maybe a handful milliseconds, depending on what happens during the request. - There is a slight cost (think — microseconds not milliseconds) to crossing the \"bridge\" between JavaScript and WebAssembly — for example, by performing I/O or async operations. This difference tends to be minimal — generally something measured in microseconds not milliseconds. People with performance sensitive Workers already write them in Rust https://github.com/cloudflare/workers-rs, which also relies on bridging between JavaScript and WebAssembly. - The Python interpreter that Pyodide provides, that runs in WebAssembly, isn't as fast as the years and years of optimization that have gone into making JavaScript fast in V8. But it's still relatively early days for Pyodide, compared to the JS engine in V8 — there are parts of its code where we think there are big perf gains to be had. We're looking forward to upstreaming performance improvements, and there are WebAssembly proposals that help here too. reply riazrizvi 16 hours agorootparentVery helpful- thanks reply deadbabe 19 hours agoparentprevAnecdotally it seems very fast. reply harikb 17 hours agoprevIs the choice of lzma to demonstrate isolation intentional or was it just a coincidence considering last week's tech news...[1] [1] https://news.ycombinator.com/item?id=39865810 reply garrettgu10 17 hours agoparentHaha, we included it just because it's part of the standard library. Total coincidence in terms of timing but it's nice that using Wasm gives us isolation guarantees :-) reply dom96 16 hours agorootparentYeah, pure coincidence. I picked it before the xz news broke. reply noman-land 19 hours agoprevThis is kind of a game changer for running AI stuff on Cloudflare. Been hoping for this for a while now. reply dabber 19 hours agoparent> This is kind of a game changer for running AI stuff on Cloudflare. That certainly appears to be the intention. > Been hoping for this for a while now. You should check out the other two announcements from today as well if you haven't yet: \"Leveling up Workers AI: General Availability and more new capabilities\" https://blog.cloudflare.com/workers-ai-ga-huggingface-loras-... \"Running fine-tuned models on Workers AI with LoRAs\" https://blog.cloudflare.com/fine-tuned-inference-with-loras reply CharlesW 18 hours agorootparentAlso, D1, Hyperdrive, and Workers Analytics Engine went GA. https://blog.cloudflare.com/making-full-stack-easier-d1-ga-h... reply spxneo 18 hours agoparentprevwhat is the maximum length a worker can run for? curious how this compares to AWS Lambda? or is it something completely different? reply brendanib 18 hours agorootparentThere's no hard limit on duration! 30 seconds of CPU time https://developers.cloudflare.com/workers/platform/limits/#d... reply gregorymichael 19 hours agoprevI’ve used CF Pages for static sites with great results and am intrigued by all their open-source-LLM-as-a-service offerings. Main issue preventing me from building more on CF is lack of Python support. Excited to try this out. reply johnmaguire 19 hours agoparentYes! I'm also using CF Pages, and a couple Worker functions, and really love the CF ecosystem. Very easy to get something running quickly, and not have to worry much about infrastructure. Very happy to see the Python addition. I'd like to see first-class Go support as well. reply pelletier 19 hours agoprevI'm curious to see how the limitation of using pyodide packages only will play out for non-trivial builds. Thinking of all the non-pure python code out there that need to be manually rebuilt to support a non-trivial production app. Maybe Cloudflare's adoption will help bring more packages into the fold, and if it's an 80/20 rule here, would be good enough. reply hoodchatham 18 hours agoparentI certainly think there's an 80/20 rule here. Most packages are not very hard to port, and generally the ones that are hard to build use features like threads and multiprocessing, graphics cards, raw sockets, green threads, or other capabilities that have no obvious analogue in a webassembly runtime. As we mention in the blog post, the biggest issues are around supporting server and request packages since they are clearly useful in cloudflare workers but are difficult to port because they frequently use raw sockets and some form of concurrency. reply dom96 17 hours agorootparentAs we build out support for some of these features in the Workers Runtime, we should be able to port Python modules to use them. Some features like raw sockets are already available, so we should be able to make some quick headway here. (Myself and Hood above are the folks who implemented Python Workers) reply adam_arthur 16 hours agoprevI would like to see CloudFlare implement workers with WASM as the first class citizen, and a general purpose API not tied to JS workers. Up until now you've been able to deploy WASM code (e.g. effectively can use any language), but it runs within a JS context, rather than natively. Just a bit more overhead/awkwardness in deployment. I believe eventually all services will be deployed directly to WASM (securitized) runtimes, rather than via containers, similar to how we moved from images -> containers). There's very little benefit currently to trying to use something like Rust on the edge (in CF), because a lot of the perf advantage is negated by the overhead and startup times. e.g. https://github.com/WasmEdge/WasmEdge reply jarpineh 17 hours agoprevMore development and users for Pyodide is great news. Especially that better serverless story for Python server frameworks. I wonder if Jupyter can work in this stack? It is essentially JavaScript, but built for browser environment. Just the Python kernel might be worker compatible. It essentially has to do code evaluation which might a limitation as well. Should it work you could offload compute from browser or other HTTP clients to waster resources of worker environment. Direct access to databases would be better as well. reply akshayka 17 hours agoparentPython notebooks can definitely work in WASM: - https://jupyterlite.readthedocs.io/en/stable/ - https://docs.marimo.io/guides/wasm.html Running just the kernel in a Cloudflare Worker is an interesting idea ... reply jarpineh 14 hours agorootparentYes, Jupyter could work. I just fear there is things that except browser’s JavaScript APIs. Some I think aren’t even available for web workers. V8 workers are a different thing (I believe) and not at all familiar to me. But, it should be easy enough to test… https://github.com/jupyterlite/jupyterlite?tab=readme-ov-fil...Python -> SQlite all in Cloudflare. I was kind of waiting for this day. reply zinclozenge 18 hours agoprevI'd be curious to see a direct performance comparison between their python and JS workers. Based on my own experience with pyodide, I'd wager there might be up to a 2x performance penalty. reply pbamotra 15 hours agoprevInteresting - supports FastAPI and Langchain too https://developers.cloudflare.com/workers/languages/python/p... reply paddy_m 18 hours agoprevGlad to see it includes numpy (and presumably pandas). Getting those to work in constrained serverless environments can be a huge pain. reply anon373839 10 hours agoprevWith Pyodide getting some serious backing, is there a glimmer of hope that we could end up with Python as a real alternative to JavaScript in the frontend? reply Terretta 15 hours agoprev\"This is about more than just making bindings to resources on Cloudflare more Pythonic though — it’s about compatibility with the ecosystem.\" Someone might be getting editorial help from GPT-4. // Or a human might be getting fine-tuned interacting with LLMs, which I've noticed happening to me. reply Terretta 8 hours agoparentTo the dead comment beside me, asking why... GPT-4 has a variety of tells. One of them is: \"This is not just about good thing, it's about another good thing.\" That \"it's not just A, it's also B\", or \"it's more than A, it's B too\" show up most any time you ask it for \"persuasive\" copy, like marketing, sales, or a rewrite of anything to make the reader a buyer. It's disproportionately common in GPT-4 copywriting or copy-editing, relative to human copy. Similar to seeing the word \"Overall, ...\" for a concluding paragraph, another tell. reply corinroyal 8 hours agorootparentMy personal favorite is, \"It's important to note...\" I asked it to stop using that phrase or variations and that lasted one prompt. I'm tempted to put the phrase on a T-shirt. reply hdlothia 16 hours agoprevWow this is huge for llm and data engineering. Many of the best libraries are in Python reply neonsunset 19 hours agoprevI with they added Azure Functions style workers using C# too, or AWS style lambdas using NativeAOT. Way lower runtime overhead and time to first response latency. But C# is an underdog language in those lands, so it's understandable. reply mdasen 18 hours agoparentAt the moment, it seems like they're concentrating on using V8 isolates. In the article, there's a good diagram of why: an isolate is able to share so much between different applications. Even with NativeAOT, you're still launching an entire program that has to load everything into memory and execute. In some ways, they're using V8 isolates the way that mod_php was used back in the day. One reason PHP became so dominant was because PHP was cheap and easy to deploy for small websites. Because the PHP runtime contained 90% of what a person wanted to do with PHP, your PHP code might be a small amount of code that mostly just called standard library functions like `mysql_query()`. If you were running a shared hosting service, you could have huge numbers of people running on the same box because every PHP script would be sharing a single instance of the PHP standard library - and that standard library was fast and written in C. If you wanted to offer Python hosting, each Python app would be duplicating the standard library they were using in memory and also needing lots of web packages that aren't part of the standard library (like a database package). So a minimal Python application was using tons more RAM because it wasn't sharing most of the code with everyone else on the box. Even with NativeAOT, you're still duplicating a lot when running many different C# projects - as is the case with Go, Java, Ruby, etc. V8 isolates are this case where they tend to be lighter weight because so much can be shared between different users in the system. In fact, the reason they're supporting Python is because Pyodide (Python interpreter in WASM) allows for dynamic linking. It means they can have a single Pyodide interpreter in memory that's shared by all the Python workers on the same box. Likewise, they can also share Python libraries that two different people on the same box might be using. They note that most languages that target WASM don't support dynamic linking and that the only way they can provide Cloudflare Workers at the price point they offer is because those Workers can share so much rather than duplicating and using more memory for each user. If you really want C# on Workers, C# does support WASM. reply tredre3 12 hours agorootparentIndeed, isolates are similar to mod_php in that a small pool of shared processes can handle thousands of different applications simultaneously. PHP is truly great in that way! But just to clarify, mod_php isn't thread safe so parallel requests do not share memory, they each have their own process (prefork mpm). And for untrusted tenants you also need to combine with mod_setuid or mod_suexec for proper isolation, as PHP doesn't do any isolation of its own (they tried for a while but gave up, remember open_basedir?). In other words a server with 16GB of RAM could handle maybe 250-350 simultaneous PHP requests using mod_php, whereas I'm sure they can fit thousands of isolates in that footprint. reply neonsunset 17 hours agorootparentprevWASM performance and overhead currently make it a poor application for edge serverless scenario for something that is compiled (as it is in many other languages, really, stop adding overhead of yet another runtime undoing decades of optimization work). \"Consumption plan\" azure functions as they call it are much more in line with V8 isolates where your function is just an isolated assembly run on a common runtime alongside many other functions. It has limitations and I assume the implementation of this is not open source (I don't know what it runs on exactly as azure functions implementation details never really interested me much). reply pjmlp 18 hours agoprevWhy anyone would like to slow down their requests using a full interpred implementation is behind me. Don't be surprised by scalability issues. reply atomicnumber3 17 hours agoparentThere's a lot of value in \"just write a python thing in 5 minutes\". People tend to hem and haw about performance and \"doing it right.\" But it's often a misplaced argument of \"python vs [\"right\" thing]\", it's \"python vs not having anything.\" Often, a shitty python thing is worth a ton and fixes the problem, and then if performance becomes enough of an issue you can evaluate whether you want to prioritize fixing it. And I find that once something that works is in place, and just quietly doing its job, people suddenly find it a lot less objectionable to their sensibilities. And even if we do replace it, having the python thing taking the heat off the \"right\" way's timetable lets you actually do it right because you can take your time. reply pjmlp 17 hours agorootparentWe all know what is the outcome of that temporary script that was written in 5 minutes. reply devwastaken 15 hours agoprevIt compiles python to we assembly which then runs on their modified V8 runtime. We assembly is generally a non solution to any problem, especially not this one. While it is convenient it is a clear lack of engineering ability that they can't implement a proper Python runtime. The reasons to not use wasm are many - the tool chains for emscripten are not well documented, hacky, and we're not built to the quality you'd expect from a compiler. After all it's doing something nothing was designed for. The performance will never be an improvement over a native engine, much of the context is lost in translation when compiling to wasm. reply ssijak 18 hours agoprev [–] Can we just get full node runtime? Cloudflare is amazing, but without a full node runtime, we (and most of the usual apps) can't switch from things like Vercel/Netlify to Cloudflare. reply kentonv 18 hours agoparent [–] The unique architecture of our runtime is what enables most of our competitive advantages. It's what lets us run your application in hundreds of locations around the world while also charging less than competing serverless platforms. If we used a full Node runtime, we would need to charge a lot more money, or only run your app in a couple central locations, or both. So, no, we can't just offer full Node. However, we are always expanding our Node API compatibility: https://developers.cloudflare.com/workers/runtime-apis/nodej... (I'm the tech lead for Cloudflare Workers.) reply amirhirsch 15 hours agorootparentI like that you answered this, but the request wasn't about workers but rather easing migration to Cloudflare. People want to migrate their entire business to Cloudflare. Provide dedicated servers and a container service, then the applications can migrate to workers. You can even produce an AI to do it for them. reply ssijak 15 hours agorootparentprevI understand what you said. I did not expect full node runtime workers with all the other benefits that you listed that current workers have (global distribution, no cold starts, cost..). But it would be great to have a choice. I feel it would benefit both users and Cloudflare to support both (with different tradeoffs). For example, selecting \"I want node runtime for this app workers,\" I would need to select the region they will run in, and that's it, those functions/workers would not be globally distributed, would probably cost more, but when you need full node runtime you need it and that is fine. reply kentonv 15 hours agorootparentYeah, in theory we could build a parallel service that's more Lambda-like and hosts apps in a more centralized way. It's certainly something we've thought about. The challenge is, can we actually build that in a way that is significantly better than the existing competition? It's a crowded space. If we just build the same thing everyone else is doing, will it attract enough use to be worth the investment? It sounds like you would be interested. What in your mind would potentially make our product more attractive than competitors here? reply ssijak 14 hours agorootparentEven if it replicates the same capability for example Vercel has for lambdas/server functions I would still use it because I could remove one vendor for my apps and stay with Cloudflare for everything. I've noticed the same sentiment in random internet conversations. Obviously it will not work in every case and for everybody but for me it is not very hard to imagine having such functionality even if it just on par with current offering being enticing to a lot of people taking into account the complete Cloudflare offer and having it on the same platform. Most of those apps would need images, storage, firewall.. all the things cloudflare offers reply ddorian43 3 hours agorootparentprevI pick the 2nd. Few apps needs to run in the edge. reply switch007 17 hours agorootparentprev [–] Your comment would have been great without: > So, no, we can't just offer full Node. (Sounds a bit snotty) reply cstrahan 8 hours agorootparent [–] How else would you write that? Would this be better? \"Thus, no, we can't just offer full Node.\" Is it the use of \"so\" that is off limits? Or is simply providing a concise conclusion inappropriate? I don't see what part of that quote is \"snotty\". reply switch007 2 hours agorootparent [–] Omitting it No PR person would have included that line reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Cloudflare Workers now support Python via Pyodide and WebAssembly, eliminating the need for extra build steps to use Python packages, allowing seamless Python and JavaScript interaction.",
      "Popular Python HTTP client libraries like aiohttp and httpx are compatible, and FastAPI can run in Workers using ASGI servers, aiming to improve performance and compatibility.",
      "Cloudflare encourages Python community feedback to enhance Pyodide support, emphasizing network security, website speed, and offering additional resources and job openings."
    ],
    "commentSummary": [
      "Cloudflare Workers now support Python at the Edge through Pyodide compiled to WebAssembly via Emscripten, allowing for Python implementations in the Edge environment.",
      "Drawbacks include being bound to a specific Python version, package resolution difficulties, and architectural challenges related to JS/V8.",
      "Discussions cover V8 snapshots impact, optimizing cold starts in JS apps, benefits of Wasm for Python, Cloudflare services like Durable Objects, running Jupyter notebooks in WASM, and the efficiency of V8 isolates in cloud services."
    ],
    "points": 354,
    "commentCount": 89,
    "retryCount": 0,
    "time": 1712064021
  },
  {
    "id": 39910119,
    "title": "Eclectic Messages: Dive into a Creative Voicemail Experience",
    "originLink": "https://afterthebeep.tel/",
    "originBody": "Voicemail INBOX Position 0:00 It's easy, just call and leave a message after the beep. Do not wait. CALL NOW!!! (Please note that messages may take a short while to appear. Thank you for your patience!) Duration 0:00 # Date Length Memo 163 2024/04/02 11:51 PM EDT 0:06 You actually dropped your mom 162 2024/04/02 11:51 PM EDT 0:04 I’m glad I did it too 161 2024/04/02 11:48 PM EDT 0:03 You dropped your mom 160 2024/04/02 11:39 PM EDT 0:07 It’s not always about the UwU 159 2024/04/02 11:35 PM EDT 0:15 Just a friendly voicemail jingle 158 2024/04/02 11:35 PM EDT 0:15 Just don’t open it, okay? 157 2024/04/02 11:33 PM EDT 0:24 Keep your head in the game, man! 156 2024/04/02 11:32 PM EDT 0:44 Please add me back 155 2024/04/02 11:29 PM EDT 0:03 Regarding Bill O’Reilly 154 2024/04/02 11:22 PM EDT 0:03 I’m a real boy! 153 2024/04/02 11:21 PM EDT 0:04 This is my message after the beep 152 2024/04/02 11:12 PM EDT 0:12 I did not get the package 151 2024/04/02 11:11 PM EDT 0:02 Beeeep 150 2024/04/02 10:51 PM EDT 0:05 I am a stabbing robot 149 2024/04/02 10:44 PM EDT 0:04 I use Arch, btw 148 2024/04/02 10:42 PM EDT 0:28 There’s a weird smell 147 2024/04/02 10:37 PM EDT 0:18 Nissin instant noodles 146 2024/04/02 10:34 PM EDT 0:09 Man, you’ve got a lot of friends 145 2024/04/02 10:34 PM EDT 0:21 You ever looked up the rules for pool? 144 2024/04/02 10:32 PM EDT 0:07 bears, beets, Battlestar Galactica 143 2024/04/02 10:31 PM EDT 0:10 Hello, are you still working? 142 2024/04/02 10:29 PM EDT 0:28 Oh, Better Far to Live and Die 141 2024/04/02 10:26 PM EDT 0:33 I accidentally hotboxed the apartment 140 2024/04/02 10:24 PM EDT 0:23 Where did I put my walnuts? 139 2024/04/02 10:22 PM EDT 0:04 Beep bop boop beep boop 138 2024/04/02 10:22 PM EDT 0:06 Here’s to a clear eclipse 137 2024/04/02 10:19 PM EDT 0:05 Where’s my car?? 136 2024/04/02 10:16 PM EDT 0:22 Yo dawg, what’s up, what’s happenin? 135 2024/04/02 10:07 PM EDT 0:14 Live from hacker’s town 134 2024/04/02 10:06 PM EDT 0:05 Press 1 to kindly… 133 2024/04/02 10:03 PM EDT 0:03 Testing again 132 2024/04/02 9:58 PM EDT 0:05 Um, yeah. What? Um 131 2024/04/02 9:56 PM EDT 0:03 Testing 1234 130 2024/04/02 9:53 PM EDT 0:05 HlOo, hlo hlo 129 2024/04/02 9:46 PM EDT 0:12 Knock knock 128 2024/04/02 9:46 PM EDT 0:22 Sweetwater do be like that 127 2024/04/02 9:32 PM EDT 0:29 Going through a bit of a tough time 126 2024/04/02 9:27 PM EDT 0:26 Congratulations Shinji! 125 2024/04/02 9:22 PM EDT 0:02 Hey 124 2024/04/02 9:21 PM EDT 0:27 Happy birthday dear person 123 2024/04/02 9:17 PM EDT 0:29 I would also like some ice cream 122 2024/04/02 9:17 PM EDT 0:54 A very nice duet 121 2024/04/02 9:07 PM EDT 0:45 Drift Away 120 2024/04/02 9:05 PM EDT 0:37 We are all connected by the pyramids 119 2024/04/02 9:02 PM EDT 0:03 The truth is out there 118 2024/04/02 8:56 PM EDT 0:03 Four big guys 117 2024/04/02 8:53 PM EDT 0:03 MEowwwwwwwW 116 2024/04/02 8:46 PM EDT 0:20 A poem about geese 🪿 115 2024/04/02 8:46 PM EDT 0:20 I hope that your life is full of life 114 2024/04/02 8:39 PM EDT 0:07 Greetings from México 113 2024/04/02 8:22 PM EDT 0:25 BeeP, BeeP, BeeP, BeeP 112 2024/04/02 8:15 PM EDT 0:06 Hey, how you doin? 111 2024/04/02 8:07 PM EDT 0:10 1-800-DEEZ-NUTS 110 2024/04/02 8:06 PM EDT 0:07 HelLO, how is yOUr day going? 109 2024/04/02 8:05 PM EDT 0:12 We should go out and get a beer 108 2024/04/02 7:55 PM EDT 0:05 Hey, hello everyone, goodbye 107 2024/04/02 7:54 PM EDT 0:03 Have a wonderful day 106 2024/04/02 7:51 PM EDT 0:18 Don’t worry about the cat food 105 2024/04/02 7:47 PM EDT 0:05 Testing, ciao 104 2024/04/02 7:44 PM EDT 0:05 Who’s ready to go? 103 2024/04/02 7:43 PM EDT 0:24 Calling for my Koolaid appointment 102 2024/04/02 7:40 PM EDT 0:05 Gimme one second 101 2024/04/02 7:35 PM EDT 0:03 Yo, what’s up? 100 2024/04/02 7:34 PM EDT 0:26 Twinkle twinkle, little star 99 2024/04/02 7:33 PM EDT 0:20 JavaScript is a fad 98 2024/04/02 7:33 PM EDT 0:08 It’s not the same river 97 2024/04/02 7:33 PM EDT 0:16 Do we need to talk today? 96 2024/04/02 7:30 PM EDT 0:09 Lenny Bruce is not afraid 95 2024/04/02 7:29 PM EDT 0:14 They say to live in the present 94 2024/04/02 7:26 PM EDT 0:13 Dingaling, clang clang 93 2024/04/02 7:25 PM EDT 0:20 Dialup in your area 92 2024/04/02 7:23 PM EDT 0:06 Yo dude, what’s up man? 91 2024/04/02 7:20 PM EDT 0:21 Something really funny happened 90 2024/04/02 7:18 PM EDT 0:19 Yo yo yo, this is super fresh 89 2024/04/02 7:15 PM EDT 0:25 Frisbee is a wonderful idea 88 2024/04/02 7:12 PM EDT 0:18 Can’t wait to toss the disc 87 2024/04/02 7:11 PM EDT 0:04 I love my cat, that is all 86 2024/04/02 7:07 PM EDT 0:15 Let’s work on an app together 85 2024/04/02 7:07 PM EDT 0:17 Calling about the thing 84 2024/04/02 7:05 PM EDT 0:15 New 83 2024/04/02 7:00 PM EDT 0:22 9^2 and not a bit more 82 2024/04/02 6:53 PM EDT 0:03 Hey, this is John 81 2024/04/02 6:50 PM EDT 0:09 Bad burrito, good brownie 80 2024/04/02 6:50 PM EDT 0:17 Paul the computer guy 79 2024/04/02 6:49 PM EDT 0:35 This is me calling from Mexico 78 2024/04/02 6:46 PM EDT 0:07 Banananananas 77 2024/04/02 6:44 PM EDT 0:07 Whazaaaaa!!! 76 2024/04/02 6:44 PM EDT 0:04 Been asking myself that for years 75 2024/04/02 6:43 PM EDT 0:07 Phil, we’ve got to go to the eclipse 74 2024/04/02 6:43 PM EDT 0:18 Calling for hair extensions 73 2024/04/02 6:43 PM EDT 0:17 Karl with a K in Hawaii 72 2024/04/02 6:36 PM EDT 0:09 In a dream I was a werewolf 71 2024/04/02 6:35 PM EDT 0:13 Testing 123 70 2024/04/02 6:35 PM EDT 0:39 Dan wishes you a good night 69 2024/04/02 6:34 PM EDT 0:14 Hey, Ethan, It’s been a long time 68 2024/04/02 6:26 PM EDT 0:17 We keep trying to reach you 67 2024/04/02 6:25 PM EDT 0:07 The alternative that doesn’t track you 66 2024/04/02 6:22 PM EDT 0:26 ooooooOOOOOOooooooOOOOOoooo 65 2024/04/02 6:21 PM EDT 0:09 Hello, I love Italy 64 2024/04/02 6:21 PM EDT 0:07 Beautiful day in Tacoma, WA 63 2024/04/02 6:19 PM EDT 0:07 I just love it 62 2024/04/02 6:18 PM EDT 0:04 This is a test 61 2024/04/02 6:16 PM EDT 0:12 Need to find my C64 for this one 60 2024/04/02 6:16 PM EDT 0:03 Hehlowww 59 2024/04/02 6:16 PM EDT 0:02 PBPBPBPBpbpbbphhh 58 2024/04/02 6:15 PM EDT 0:14 Starting to feel pretty depressed 57 2024/04/02 6:15 PM EDT 0:06 That place I put that thing that time 56 2024/04/02 6:15 PM EDT 0:42 The 4th dimension phantom 55 2024/04/02 6:15 PM EDT 0:12 We’ve been trying to reach you 54 2024/04/02 6:15 PM EDT 0:47 Your application has been denied 53 2024/04/02 6:14 PM EDT 0:14 I will fix it 52 2024/04/02 6:14 PM EDT 0:10 Shhhh, keep it our little secret… 51 2024/04/02 6:12 PM EDT 0:14 Are you free to come out and play? 50 2024/04/02 6:11 PM EDT 0:12 Tell me, when will you be mine? 49 2024/04/02 6:11 PM EDT 0:16 Just a little tune on the guitar 48 2024/04/02 6:10 PM EDT 0:49 Now for the forecast 47 2024/04/02 6:09 PM EDT 1:13 I’m a complete catch 46 2024/04/02 6:05 PM EDT 0:06 Hello, and welcome to Moviephone! 45 2024/04/02 6:05 PM EDT 0:26 RE: Kids these days 44 2024/04/02 6:04 PM EDT 0:27 I am finally the popular kid 43 2024/04/02 6:00 PM EDT 0:30 Say hi! Say hello! 42 2024/04/02 5:58 PM EDT 0:24 I would love to go for frisbee later 41 2024/04/02 5:52 PM EDT 0:14 It’s driving me nuts 40 2024/04/02 5:51 PM EDT 0:16 Salutations, much love 39 2024/04/02 5:49 PM EDT 0:12 Please leave a message after ??? 38 2024/04/02 5:40 PM EDT 0:07 David Attenborough is THE best 37 2024/04/02 5:35 PM EDT 0:04 What’s up? 36 2024/04/02 5:34 PM EDT 0:05 Oh, oh my god 35 2024/04/02 5:33 PM EDT 0:07 Stephen, get off the damn phone 34 2024/04/02 5:28 PM EDT 0:49 I miss those days too 33 2024/04/02 5:27 PM EDT 0:13 Happy birthday to me 32 2024/04/02 5:25 PM EDT 0:04 Ooooaaaaaaahhhhhhh 31 2024/04/02 5:24 PM EDT 0:12 Who’s boop? Is this beep? 30 2024/04/02 5:22 PM EDT 0:04 Hello~o~o~o~o 29 2024/04/02 5:21 PM EDT 0:48 A blast from the past 28 2024/04/02 5:19 PM EDT 0:03 Hellooo 27 2024/04/02 5:19 PM EDT 0:02 Something about a child? 26 2024/04/02 5:16 PM EDT 0:18 Wear proper glasses for the eclipse! 25 2024/04/02 5:14 PM EDT 0:16 It’s Dan again 24 2024/04/02 5:13 PM EDT 0:19 I’m Dan and I’m just great <==3 23 2024/04/02 5:12 PM EDT 0:05 Very cool 22 2024/04/02 5:07 PM EDT 0:18 Whistling a tune 21 2024/04/02 5:06 PM EDT 0:54 Kids these days 20 2024/04/02 5:04 PM EDT 0:13 ??? 19 2024/04/02 5:00 PM EDT 0:18 Animals are cool, I like animals 18 2024/04/02 4:53 PM EDT 0:07 Your refrigerator is running 17 2024/04/02 4:51 PM EDT 0:06 Farewell, toodle-too 16 2024/04/02 4:51 PM EDT 0:07 Hello world, this is a message 15 2024/04/02 4:44 PM EDT 0:06 Welcome to planet Earth 14 2024/04/02 4:42 PM EDT 0:32 I mean like really steep stairs 13 2024/04/02 4:35 PM EDT 0:02 Heheh 12 2024/04/02 4:32 PM EDT 0:12 Never stop loving yourself, bitch! 11 2024/04/02 4:29 PM EDT 0:39 Hoping for a tornado in a far off field 10 2024/04/02 4:27 PM EDT 0:02 Hack the planet! 9 2024/04/02 4:14 PM EDT 0:34 This is Jacob calling about your colon 8 2024/04/02 4:12 PM EDT 0:27 It’s 1994 calling, things are extreme! 7 2024/04/02 4:11 PM EDT 0:40 Greetings from the Black Sea coast 6 2024/04/02 4:09 PM EDT 0:11 Tonight I went fishing 5 2024/03/31 11:35 PM EDT 0:43 Happy Easter, Jesus 4 2023/07/08 3:26 AM EDT 0:58 Thank you to Ellie 3 2023/07/01 11:06 PM EDT 0:23 Check out Blue Skies Over Alaska 2 2023/05/28 10:46 PM EDT 1:23 Boy, am I overwhelmed 1 2023/05/06 6:17 AM EDT 1:01 Yooooo, I LOVE you dude Site is open source. Contact the operator with questions. Visitors:",
    "commentLink": "https://news.ycombinator.com/item?id=39910119",
    "commentBody": "Anonymous public voicemail inbox (afterthebeep.tel)323 points by unixispower 14 hours agohidepastfavorite83 comments technothrasher 11 hours agoI don't know why, but this reminded me of going to school in the early 90's, we'd go through the university's voicemail system inputting random phone numbers and trying the default password, '0000', which meant the voicemail on that number had never been set up. When we found one, we'd record a song as the greeting. We then posted notes by the various public phones on campus for our 'dial a song' directory so anybody could enjoy a song, like a big public jukebox. The entire thing worked well for a semester, until some killjoy updated the phone system default to disable voicemail for unused numbers and blew away all our songs. reply laborcontract 9 hours agoparentOh my God, I remember doing this to my friends. The default voicemail password always worked so I reset their voice messages to strange sounds or me doing voices. It’s amazing how insecure everything was. I remember as a kid walking around with a cordless phone realizing you can pick up other peoples’ conversations. There was something so charming about technology back in the day. I don't think it's purely nostalgia. I think part of it was that our lives didn’t revolve around it so poking around never really hurt. reply quasse 9 hours agorootparentI feel the same way thinking about computer security back in the early 00's. Nothing was ever really locked down, sometimes you could get administrator access by pressing \"Cancel\" on the login dialog three times, network drives were just open to everyone and you could install new software by just bringing it to school on a floppy and installing it on the lab computer. I think that environment was what really fostered my love of tinkering with systems the same way phone phreakers did a few decades earlier. Now everything is locked up like a vault and it's all group policy this and mobile device management that. Nothing can be unlocked and nobody has permissions because if it isn't your device ends up encrypted with a ransom note telling you to send cryptocurrency to a state sponsored hacking group in Russia. I do feel like younger people are really missing out on the \"hackability\" that everything had before we collectively realized how computer security worked. reply wanderingstan 3 hours agorootparentIn the late 90s at my first job I would invite all my housemates to my office after hours for LAN parties using my co-workers computers. There were no logins and it didn’t even bother my co-workers unless a newly installed game took up too much drive space. I feel we viewed computers more like expensive toys that should be shared rather than than the highly personal items they are today. reply tempestn 8 hours agorootparentprevI had fun spoofing friends' email addresses (only for harmless jokes). Amazing to think now that there was a period when anyone could convincingly and effortlessly send an email as anyone else, and it wasn't widely abused. reply markdown 5 hours agorootparentprevIs regedit still a thing in Windows? We had good fun with it in school computer labs back in our day. reply greenavocado 4 hours agorootparentYes, but the Group Policy editor has superceded it in many ways. reply CapsAdmin 7 hours agorootparentprev> It’s amazing how insecure everything was. Something I really miss from that era that I'm confident we'll never get back (for good reasons) is the open and transparent nature of everything. Everything felt hackable and based on trust. Where as today we can't trust anyone. It's tempting to say peoeple were nice and didn't abuse the system, but I think more likely some people just didn't know the amount of money they could make from the abuse. reply meowface 7 hours agorootparentNah, it was actually a nightmare. The small number of people who understood this and exploited it lived like Gods. It gave malevolent people far too much power. And while a smaller percentage than today were in it for the money, a lot still were. Plus the ones not in it for the money were sometimes worse, since they were motivated solely by ego, power, and sociopathy. reply spzb 3 hours agorootparentprev> The default voicemail password always worked That kept newspaper editors in scoops for years https://en.wikipedia.org/wiki/News_International_phone_hacki... reply stavros 10 hours agoparentprevI really hate this. Who were the songs hurting? Nobody, someone just decided to make the world a little bit worse because it wasn't \"proper\". reply jazzyjackson 9 hours agorootparentHurting anyone, no, but the whole jukebox probably cost the provider at least a penny all told, and that's a good enough reason for someone to close the oversight. EDIT: thinking about it again, there is such a thing as surplus capacity. Like how before we all transitioned to pay-as-you-go elastic cloud services you would just have an idling CPU you could point at SETI and folding@home. The jukebox probably didn't strain the host enough that they had to expend any actual expense, so I changed my mind, somebody might have thought they were shutting down some freeloaders but they weren't costing any money really. OTOH there are cases where viral phone forwarding blew past the system's capacity and did cause downtime, see \"You and the little mermaid can both go fuck yourselves, I can't find The Books, they must be in La Jolla\" [0] (Act One) [0] https://www.thisamericanlife.org/203/transcript [0.1] https://en.wikipedia.org/wiki/ROLM reply jrockway 9 hours agorootparentI think idle CPUs still exist, people are just afraid to share them now. For example, for lowest latency you want your application servers close to your end users. Your end users probably all go to bed at about the same time and wake up at the same time. So your server is just sitting there taking up space, maybe saving a little power, overnight. But, nobody is will to take the risk to let someone else use their computer for a batch job of some sort, so the best you get is slightly less heat output and slightly less power consumption instead. For those that don't really care, the cloud providers have shared core instances, so some batch job is probably using your cycles late at night. I think the thing that killed SETI@home was crypto mining. Why help others when you can collect stuff for yourself? Plus, everyone woke up to the electricity arbitrage going on; when every employee started using their work computer to mine crypto, and the electricity bills got high, someone started looking for answers. The edict came down from on high: don't steal our electricity for yourself or for human good. Rest in peace, SETI@home and folding@home. (I was always personally a fan of Great Internet Mersenne Prime Search when those things were cool. I guess I didn't know much about protein folding or searching for extraterrestrial life, but I did understand factoring numbers.) reply jazzyjackson 8 hours agorootparentI agree that crypto killed donating cpu cycles, it was only surplus insomuchas it couldn't be converted to coins reply enobrev 3 hours agoprevThis reminds me of the 90s - but not just from the looks. There was a time in the mid 90s in Chicago ( maybe most cities? ) when pagers were the thing, and a pager would come with a free voicemail box. The pager companies would set the voicemail pin to the last 4 digits of the pager number. The customer was meant to change it when they first signed up for their account. And so I knew quite a few people who would test numbers all day and night to steal voicemail numbers and then use them for all sorts of things. Promoting raves and other parties Party lines Message boards Various things involving graffiti. It was a normal thing back then to find a local pay phone and call a couple known voicemail boxes for figure out what to do that weekend or to see where friends were going to be. reply karmelapple 7 hours agoprevDid anyone use the Red Talking Phonebook in the 1990s? It had a phone number you could dial and then you could enter codes to get different information such as movie times, jokes, the time of day, and so on. I liked trying random codes in it to see if I could find hidden services... and eventually I did. I don't recall the exact code, but I think it was like 9987. It turned out to be basically this - an anonymous public voicemail box where you could listen to recordings other people made, and you could make your own. A few other people stumbled upon it, too, and there was a range of messages on there: some funny, some very silly, some fairly scary or weird. I've never come across anyone else who had stumbled upon this though... surely someone here has? reply tr90814 10 hours agoprevSuper cool - reminds me a bit of The Secrets Hotline https://podcasts.apple.com/gb/podcast/the-secrets-hotline/id... reply 3-cheese-sundae 13 hours agoprevWhat audio codec and parameters are used for the recordings? You've really nailed the 90s landline sound. reply ryukoposting 13 hours agoparentYou could probably just apply a 300Hz-3300Hz band-pass filter to any given recording and make it sound really close to analog phone call audio [1] [1]: https://en.wikipedia.org/wiki/Plain_old_telephone_service#Ch... reply jcrawfordor 13 hours agoparentprevaudio coming right off the TDM phone network will be 8-bit samples, 8 kHz sampling rate, companded. Doing anything else requires direct IP peering (e.g. with a cellular carrier) which is out of reach of your typical inexpensive VoIP trunking provider. reply unixispower 13 hours agoparentprevThey come from my VoIP provider as 16bit 8kHz WAV files. I crunch them down to MP3s using ffmpeg before uploading. I don't get any say in the source quality, but I'm quite pleased with it as well. reply ale42 13 hours agorootparentOn the telephone network it was probably µ-law (https://en.wikipedia.org/wiki/%CE%9C-law_algorithm) encoded 8-bit 8 kHz data. This is what was used on the backbone of analog landlines, and now on VoIP for landlines (outside USA and some other countries there's the A-Law, very similar stuff). It's a logarithmic encoding that gives more quality than 8-bit PCM sound while only using 8 bits per sample. If you want to convert it to plain linear data without quality loss then you need 16-bit, whence that comes out from your provider. (µ-law encoded WAV files are also a thing) > but I'm quite pleased with it as well. Have to say that despite the filtering of high frequencies making it sound, well, like a telephone... µ/A-law data sounds pretty well. Much better than GSM and most low-bandwidth codecs, especially if the encoded sound is not just pure voice but also background noise that comes with it. reply vmfunction 1 hour agoprevRemind me of http://cel.ly, where sms is available online. Looks like they are not operational anymore. reply spxneo 12 hours agoprevthe voicemails are genuinely wholesome and theme of the 90s, i cracked up at the hot pockets one some more details about stack and implementation would be great too curious how this was built reply unixispower 12 hours agoparentSite is static built using Jekyll. Voicemail inbox is hosted using VoIP.ms. I pull the voicemails manually by running a Python script, edit the Markdown file that the script spits out to add a memo, then run another script to build and upload the site to Neocities. I thought about making a dedicated \"app\" for all of it, but why make it more complicated than it has to be. I manually moderate all the calls anyway, so I just stuck with a simple smattering of scripts and static hosting. You can see all the site source and scripts here: https://gitlab.com/unixispower/after-the-beep reply speps 11 hours agorootparentAny interesting ones you couldn't publish? reply unixispower 11 hours agorootparentRight now the ones that aren't in English, and a couple ones that are aggressively political. I'd like to take a pass at the non-english ones when I have some time to find a way to translate them. reply timando 10 hours agorootparentWhisper can transcribe/translate non-english speech to english text reply tossit444 13 hours agoprevThere's a different person that also has this kind of project going on, it's pretty cool to see people do this more. https://linktr.ee/at_the_beep reply lobito14 8 hours agoprevLeft a msg several hours ago, but it's not showing on website. What am I missing? reply unixispower 6 hours agoparentThe site is manually moderated. I made the mistake of posting it over my lunch break and had to go back to work which caused a significant delay. I'm back on processing things now. reply RankingMember 4 hours agorootparentThanks for moderating it, I figured it was too good to be true that none were horrifying/\"ear rape\" without manual moderation. Out of complete curiosity, what type of things are you finding the need to filter out/remove the most? reply layman51 7 hours agoparentprevIt seems to be manually moderated by one person so it might take a while. reply trevcanhuman 6 hours agoparentprevHe just updated the website. reply anjc 20 minutes agoprevGreat idea. Americans are so funny. reply mycall 5 hours agoprevNCN has a great show called Voice Jail [0] that includes a huge collection of comedic audio cutups on this topic. [0] https://nationalcynical.bandcamp.com/album/midnight-voicejai... reply nirvael 1 hour agoprevLongmont Potion Castle vibes reply mariorojas 12 hours agoprevI've tried to dial from Mexico and it seems like the phone is not available. I'm dialing +1 442 667 2337 reply trevcanhuman 11 hours agoparentIt worked for me just as you dialed! My carrier is Telcel. reply kxrm 11 hours agoparentprevyou'll need to dial international. I believe the exit code is 00 for Mexico so dial 00 1 442 667 2337 reply Y_Y 11 hours agorootparentThat wasn't the unary plus, it's the international exit code reply nico 12 hours agoprevReally cool, thank you for posting Are you using something like asterisk or FreeSWITCH to connect to the siptrunk? If so, do you have a backend for the dialplan? Would love to see the code if possible reply BuildTheRobots 10 hours agoparent> If so, do you have a backend for the dialplan? not wanting to take away from the ops work, but on FreeSwitch you could do the SIP side of this with the default config and a free or cheap sip provider. As default it'll provide voicemail services to offline phones, so if you add your sip provider and direct all incoming calls to (eg) extension 1000 but never connect a sip handset to that extension, everyone gets sent to voicemail and you end up with a folder of wav files. What you then do with the front end is beyond me, though at home I just have apache serving an index of that directory. If the SIP side of it is the mystery and you're interested in it, I'd really recommend installing Asterisk or FreeSwitch and having a play. You'll be stuck writing weird INI files or XML for config and there's a lot of new terminology, but it can be cheap and fun to play with. And a terminally deep rabbit hole if you actually want to fall down it. Personally, the only reason I still run my pbx (aside from something to faff with, and a platform for testing silliness) is the fact I can easily record phone calls. Most of the time it's only because I have a bad memory and take useless notes, but there doesn't seem to be a single modern mobile phone on market that allows me to record both sides of the audio when making a voice call. reply bityard 10 hours agorootparent> Personally, the only reason I still run my pbx (aside from something to faff with, and a platform for testing silliness) is the fact I can easily record phone calls. I was running an Asterisk server in the early 2000s and recording phone calls was one of the things I did, so that I could record phone calls with friends and family and replay them decades later. Fast forward a few years, we moved, cell phones became standard issue in daily life, the server got put in storage, and my father passed away. During an equipment purge, I took the drives out of all of my old crap and wiped them before sending them off as e-waste. It wasn't until later in the week that I realized what I had done. Make sure you back those recordings up. reply xp84 6 hours agorootparentprevYeah, thanks to certain big states having misguided (in my humble opinion) laws that say you can’t record a conversation you were a party to without all-party consent, I’m assuming nobody wants the liability of making that simple and automatic. In my humble opinion it’s weird to say someone cannot augment their own memory with something, or especially, keep proof of something a corporate entity told them. so I hate the 2-party consent law. reply unixispower 12 hours agoparentprevFor fun I self-host Asterisk at home, but I'm using a cheap VoIP provider (VoIP.ms) to take the burden of hosting for this project. The code that I did write to pull messages is just some boring API interfacing in a simple Python script: https://gitlab.com/unixispower/after-the-beep/-/blob/main/_u... reply nico 12 hours agorootparentAwesome, thank you! How do you like voip.ms? Any other providers you’d recommend? reply unixispower 12 hours agorootparentvoip.ms has been pretty good. They got DDoS'ed shortly after I signed up which soured the experience for about a week, but I haven't had an issue for the 2 years I've been using them since. I like that they have a wiki that explains how to set up ATA devices for their service -- that's what sold me on them initially. reply PenguinCoder 12 hours agorootparentprevNot OP, but I recommend and use sipstation. I moved from VoIP.ms because they often had troublesome outages. Sipstation has been reliable and a good value. reply xp84 7 hours agorootparentAlso not op, and nothing against any other provider, but callcentric is another provider that has been around probably 2 decades now and has never let me down. Basically everything is a la carte and cheap. reply DigiEggz 6 hours agoprevIncredible and nostalgic. Excellent project! reply tudorw 5 hours agoprevThey Might Be Giants flash backs to Dial-A-Song. reply achristmascarl 13 hours agoprevthe retro windows gui is such a perfect match for this. amazing work! reply nlunbeck 13 hours agoparentThe talking Minesweeper smiley is really the icing on the cake, love it! reply ParetoOptimal 6 hours agoprevCollecting voice data to create train AI to speak in? reply unixispower 6 hours agoparentNope, just collecting them to listen to :) reply kocyigityunus 2 hours agoprevgreat design. loved it. reply shazz8bits 9 hours agoprevWhat a great idea! Just of curiosity, how much does it cost per month with voip.ms? Looks like a bunch of little costs per month but I could not figure out the total… reply unixispower 6 hours agoparentI don't really know yet. My provider charges by the minute, so it's heavily dependent on usage. I'd imagine the post to HN will cause a nice spike on my bill though lol reply i4k 6 hours agoprevIs this time ever coming back? reply rrr_oh_man 13 hours agoprevBug: Menu doesn’t work with Skype (I love the design!) reply rhaps0dy 13 hours agoparentThis should be a bug in Skype if anything, it should conform to normal phone interfaces. I've had the same problem in the past. I think you're likely using Skype on iOS and typing numbers for the menu on the iOS phone virtual keyboard. Instead, you should do it in the Skype app -- the phone menu ones don't work. reply rrr_oh_man 13 hours agorootparentThank you for solving this mystery! reply swyx 13 hours agoprevhow is the last message march 31? does this thing update live? reply function_seven 13 hours agoparentAre you waiting for news on your colon? Refresh. Jacob just left you a message a few minutes after you posted this comment. reply xyzelement 9 hours agorootparentJust wanted to appreciate you and this wonderful comment. reply unixispower 13 hours agoparentprevI manually moderate the voicemails and run a script locally to build out a static site and upload it to Neocities. The site is relatively fresh (created within the past year); it just hasn't seen much traffic yet. reply jetbalsa 8 hours agorootparentNice to see you using voip.ms for all your science -- The number I just left for you is also hosted on it, its a fun little IVR Maze reply Zod666 13 hours agorootparentprevIf the site blew up in popularity how would you plan to continue moderating the voicemails? reply unixispower 12 hours agorootparentI'm not really sure to be honest. The traffic today has me stepping away from work occasionally to process calls in little batches :) I would probably just streamline the moderation process to make it a bit easier. For various reasons I wouldn't want it to be completely automatic (for one I just like to listen to the messages). reply d416 11 hours agorootparentlove this site. Check out Justine Tunney’s blog posts for pre-processing content filtering with AI using bash commands: http://justine.lol/oneliners/ http://justine.lol/matmul/ reply xanderlewis 11 hours agorootparentprevWhat’s the current acceptance rate, roughly? reply unixispower 11 hours agorootparentSo far I've only marked 1 out of 50 as a \"no\". There are 2 more I need to translate. So, ~94-98%? The sample size is small so far though reply piperswe 12 hours agorootparentprevI would assume that it wasn't necessarily designed to blow up in popularity, but just to be a fun quirky webpage reply bdavbdav 12 hours agorootparentprevTTS, an LLM to vet them reply internetter 11 hours agorootparentBad idea. The appeal of sites like this is the humanity of it. Don't take that away. reply ycombinatrix 9 hours agorootparentprevSTT not TTS reply bossyTeacher 11 hours agoprevI was hoping that we would be able to post a voice message :( reply gigatree 10 hours agoparentYou leave a message by calling the number at the top of the page reply unixispower 11 hours agoparentprevWas there an issue with the inbox? I check them manually, so it takes me a bit to publish them reply xyst 10 hours agoprev [–] lol, it's all dudes. reply worddepress 3 hours agoparentI am not sure about \"I'm a real boy!\" reply ycombinatrix 8 hours agoparentprev [–] what's the relevancy? this isn't a dating app reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The voicemail inbox contains varied content like random musings, jokes, greetings, and personal messages covering pop culture, technology, and personal emotions.",
      "The messages exhibit a mix of silliness and seriousness without a distinct theme, reflecting a broad range of topics.",
      "Visitors are welcome to engage with the open-source site by reaching out to the operator for inquiries."
    ],
    "commentSummary": [
      "Discussion participants fondly recall the hackability of technology in the 90s and early 00s, sharing nostalgic memories of manipulating public voicemail systems and accessing computer systems with minimal security.",
      "The conversation revolves around the apprehension of resource-sharing in modern tech times, suggesting the utilization of FreeSwitch or Asterisk to set up a SIP trunk and dialplan backend.",
      "One individual manually moderates a website for leaving voice messages, hosted by an inexpensive VoIP provider, with users commending the project's design and deliberating content filtering through AI and TTS tech."
    ],
    "points": 323,
    "commentCount": 83,
    "retryCount": 0,
    "time": 1712087354
  },
  {
    "id": 39906924,
    "title": "Canoo's CEO Splurges on Private Jet Amidst Financial Struggles",
    "originLink": "https://techcrunch.com/2024/04/01/canoo-spent-double-its-annual-revenue-on-the-ceos-private-jet-in-2023/",
    "originBody": "(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window) Link Copied Transportation Canoo spent double its annual revenue on the CEO’s private jet in 2023 Kirsten Korosec@kirstenkorosec / 11:53 PM UTC•April 1, 2024 Comment Image Credits: Canoo Tucked inside Canoo’s 2023 earnings report is a nugget regarding the use of CEO Tony Aquila’s private jet — just one of many expenses that illustrates the gap between spending and revenue at the EV startup. Canoo posted Monday its fourth-quarter and full-year earnings for 2023 in a regulatory filing that shows a company burning through cash as it tries to scale up volume production of its commercial electric vehicles and avoid the same fate as other EV startups, like recently bankrupt Arrival. The regulatory filing once again contained a “going concern” warning — which has persisted since 2022 — as well as some progress on the expenses and revenue fronts. The company generated $886,000 in revenue in 2023 compared to zero dollars in 2022, as the company delivered 22 vehicles to entities like NASA and the state of Oklahoma. And it did reduce its loss from operations by nearly half, from $506 million in 2022 to $267 million in 2023. The revenue-to-losses gap is still considerable though: The company reported total net losses of $302.6 million in 2023. Still, one only needs to look at what Canoo is paying to rent the CEO’s private jet to put those “wins” into perspective. Under a deal reached in November 2020, Canoo reimburses Aquila Family Ventures, an entity owned by the CEO, for use of an aircraft. In 2023, Canoo spent $1.7 million on this reimbursement — that’s double the amount of revenue it generated. Canoo paid Aquila Family Ventures $1.3 million in 2022 and $1.8 million in 2021 for use of the aircraft. Separately, Canoo also paid Aquila Family Ventures $1.7 million in 2023, $1.1 million in 2022 and $500,000 in 2021 for shared services support in its Justin, Texas, corporate office facility, according to regulatory filings. This could be chalked up to small monetary potatoes if Canoo reaches its revenue forecast for 2024 of $50 million to $100 million. We’ve asked Canoo for comment and will update this post if we hear back. Please login to comment Login / Create Account TechCrunch Early Stage 2024 April 25, BostonFounder Summit LEARN MORE Sign up for Newsletters See all newsletters(opens in a new window) Daily News Week in Review Startups Weekly Event Updates Advertising Updates By subscribing, you are agreeing to Yahoo's Terms and Privacy Policy. Email Subscribe (opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window) Copy Tags Canoo electric vehicles EV",
    "commentLink": "https://news.ycombinator.com/item?id=39906924",
    "commentBody": "Canoo spent double its annual revenue on the CEO's private jet (techcrunch.com)285 points by hampelm 18 hours agohidepastfavorite236 comments blackhawkC17 17 hours agoIf the reimbursements were solely for corporate travel, it might not be a concern. The CEO here sold his previous company for $6.5 billion [1], so he already owned the jet before starting Canoo. The company reimburses him for corporate travel on it. What's concerning is that Canoo is stacking big losses and living on the edge...it seems like excessive spending for a company that hasn't even made a dime of profit. But hold on, this same CEO has spent over $230 million(!) buying Canoo stock from his personal funds [2], so he is significantly in the red no matter how much he gets reimbursed for air travel. Always dig into the details and avoid getting suckered by clickbait... 1- https://www.reuters.com/article/idUSL1N11J0PS/ 2- https://www.secform4.com/insider-trading/1399053.htm reply TRDRVR 15 hours agoparentI think the real issue here is that a CEO who nobody has heard of and is doing a bad job running the company claims that he needs to fly private as a business expense. It's one think for Zuck or Tim Cook to claim that flying commercial would be dangerous and a waste of time, but the way that attitude has filtered down to very small companies is astounding (especially given the outsized negative impact private jet travel has on the rest of us). Any reasonable board for a public company that size and a CEO that unrecognizable should at most reimburse first class fare and if the CEO wants to fly private, the delta can come from personal funds. reply blackhawkC17 15 hours agorootparentI agree. It's one thing for the CEO of a large, profitable company to be flying private, but for a small, loss-making company, it feels off. The guy is already ultra-rich...he might as well pay for those flights himself to show solidarity with shareholders. But it's up to Canoo shareholders to decide that, not me. reply 0xB31B1B 15 hours agorootparentHe is effectively paying for these flights by buying Canoo stock. This whole structure is set up to allow him to maximize the tax efficiency of his compensation. The jet travel is realized as a business expense and offsets future potential profits at the company, he also avoids paying the ~60% (federal and state income tax, as well as payroll tax paid by employer) tax that you incur paying high wage w2 employees. reply randycupertino 8 hours agorootparentInterestingly, he also had a lawsuit at his prior company for excessive use of private jet use on personal travel: https://www.repairerdrivennews.com/wp-content/uploads/2019/0... > Aquila Commits Misappropriation Of Solera Assets And Resources > After execution of the Separation Agreement and Omnibus Agreement, Solera confirmed that prior to his separation from the Company, Aquila had misappropriated Solera’s resources and money by fraudulently claiming that certain flight and hotel expenses were for Solera business, when in fact, Aquila incurred these expenses solely on personal, non-Solera business—including fundraising for his intended new investment venture. > Specifically, Aquila used a private jet chartered by Solera (Gulfstream IV- SP-N910AF) solely for Aquila’s personal business, but nevertheless charged the flights to Solera, between November 2018 and May 2019—i.e., when Aquila was still Solera’s President and CEO. For example, Aquila had Solera pay over $700,000 for 45.8 hours of flight time for Aquila’s trips to, among other places, Austria, Switzerland, Germany, Bulgaria, Qatar, Kuwait, and France, as well as thousands of dollars for certain hotel expenses associated with certain of these trips. These trips were not for Solera business. Aquila traveled for personal purposes, including in connection with his position as the Chairman of the Board of Sportradar and to fundraise for his new “Founders Select” venture. > Solera is continuing to investigate Aquila’s pre-separation activities with respect to any further instances of fraud, theft, misappropriation, or other actions of Aquila giving rise to claims that are not released under the Separation Agreement. reply TRDRVR 13 hours agorootparentprevMy friend, that is not how public companies work. Every common shareholder is an equal, you don't get to launder jet travel the way he's doing - that's securities fraud. reply fnordpiglet 12 hours agorootparentIt’s actually not fraud because it’s happening in the open with board approval. And, no not every share holder is an equal. A share holders relevance is proportional to their voting power. While you can’t outright fleece a shareholder, it’s not the case that a single share held is worth the same as is given the same rights as someone holding 51% of all shares. At that point they effectively own the company. The company still has residual responsibility by law and regulation to all shareholders but it not nearly as broad as you seem to paint. This structure described is absolutely ok. Further the fact it’s publicly disclosed almost entirely insulates them - if you don’t like it, vote your shares or sell it on the public market. reply happytiger 14 hours agorootparentprevExactly. Strangely this is actually tax efficient for both parties. reply Jochim 13 hours agorootparentNot a good thing. reply KRAKRISMOTT 12 hours agorootparentSays the temporarily embarrassed millionaire reply Jochim 49 minutes agorootparentPermanently embarrassed if we're being realistic. reply bombcar 15 hours agorootparentprevThe board chooses the CEO and his salary; if the board wants to give some of the salary in the form of jet reimbursements it's not really any concern beyond them and the shareholders. reply yread 14 hours agorootparentIt is a concern for the tax payers if company is paying it as expense and deducting it from taxes instead of paying it as (taxed) salary and him doing what he wants with his money. Don't you have rules what can be expensed in the US? reply ghaff 14 hours agorootparentCertainly there are rules. I would speculate that deducting a private jet flight used for business probably doesn't run afoul of those rules however. reply bombcar 13 hours agorootparentAnd personal use is accounted for (if paid by the company) and remanded as salary/perks. I even got affected by that at a restaurant I worked at; they fed us and we got a small \"virtual\" payment that would show up on our taxes for that meal. reply bradleyjg 10 hours agorootparentprevMy recollection (I’m not checking) is that congress passed a law restricting the deductibility of private air flights, but that there’s widespread fraud in the form of “security consultants” advising boards that such flights are necessary for security purposes and so they are deducted anyway. It’s pretty unreal when you think about it that our culture has not small cadres of credentialed, professional liars for hire. Not just for CEOs either, think about the fake service pets for another example. Is this what the kids call late stage capitalism? reply bombcar 14 hours agorootparentprevYes, and corporate travel can be expensed. reply blackhawkC17 15 hours agorootparentprevAlso agreed. If shareholders don't want that, they're free to vote him out, or keep him if they're okay with the private flights. reply hn_throwaway_99 6 hours agorootparentprevLet's dispense with the fiction that there is some \"need\" or \"business reasons\" for 99% of CEOs except a very small number of examples like you mentioned to fly private. They do it simply because they can. Private jets are probably the last frontier of conspicuous consumption, and small time CEOs flying private lets them feel big and important. reply andy99 12 hours agorootparentprevThere is a lot of overhead to commercial air travel, even when it's first/business. You're probably right that it's more reasonable for flying overseas. But for local travel, limitations on timing, connections, and airports served turn into a big waste of time. It's an analysis that has to be made about the value of the CEO or whoever's time, but it's not black and white, and a couple million bucks vs a few 100k for way better scheduling could easily be worth it. reply throwawaymaths 12 hours agorootparentprevit's also sucky because we're in a rightfully very negative EV environment. Fisker Ocean sucks, Cybertruck is good? but rusting?, nobody buys the Lucid, Rivians are great but lose ~80k USD per unit for Rivian, BYD and Evergrande EV cars are filling up junkyards in china... Canoo is one of a few EV companies that on paper should make it. They have an order book that takes them to profitability. They have alpha vehicles that work (aka the product is not science fiction). Since they're selling these primarily as fleet vehicles, it's pretty valid to believe that the typical consumer EV concerns (range anxiety, nonfunctional/overbooked chargers, I live in an apartment, etc) should apply, their customers have the capital to spend, and can even easily calculate depreciation and expected benefit over existing fleet inventory. 100% of the risk in the company is manufacturing risk + not fucking up the finances e.g. by going too far into debt where the product payout doesn't make sense. That's a pretty nice place to be for being an EV company in the market now. reply hakfoo 7 hours agorootparentI actually took a punt on them this week (280 shares), mostly because they're selling something so different from the rest of the market. It seems like the mainstream American EV manufacturers are very blinkered-- bigger, heavier, longer range, more luxury. Those products might appeal to buyers in the US, Canada, maybe Australia, but for the rest of the world, you're going to have to compete with manufacturers like BYD. I could see the Canoo product selling in a lot of markets that you'd never sell a Lucid Air or Rivian R1T in. Once they've got a stable base on fleet orders, I could see them acquiring a quirky street cred among consumers-- sort of like Volkswagens of the '60s and '70s. reply spfzero 8 hours agorootparentprevMaybe he's anticipating making a quick getaway? reply throwawaymaths 16 hours agoparentprevNobody informed is claiming that it's illegal. Even if it's not financially the worst thing, it's a bad look. The CEO's image is important. Already the stock price has tanked likely in part from these revelations. Obviously, too late for canoo, but if you're running a startup you can learn from his mistakes. Honestly at this point the reputational damage is enough, that the CEO should probably resign, if for no other reason to boost market confidence in the company and raise the value of his own shares. reply randycupertino 8 hours agorootparentHow he set it up some he's leasing the jet from his own private family trust LLC fund sounds so sketchy, it reminds me of the WeWork self-dealing by Adam Neumann. > Under a deal reached in November 2020, Canoo reimburses Aquila Family Ventures, an entity owned by the CEO, for use of an aircraft. In 2023, Canoo spent $1.7 million on this reimbursement — that’s double the amount of revenue it generated. Canoo paid Aquila Family Ventures $1.3 million in 2022 and $1.8 million in 2021 for use of the aircraft. > Separately, Canoo also paid Aquila Family Ventures $1.7 million in 2023, $1.1 million in 2022 and $500,000 in 2021 for shared services support in its Justin, Texas, corporate office facility, according to regulatory filings. sound familiar? > The 11-story office building at 88 University Place was leased to WeWork and co-owned by Neumann, the company's co-founder and CEO. It was one of many buildings that WeWork leased from Neumann. Critics called the leases a conflict of interest for WeWork and an example of self-dealing by its charismatic leader. reply throwawaymaths 12 hours agorootparentprevI guess the CEO could agree to suspend the contract with his other company until canoo is profitable, and offer to return the 3.4 million, that would be a very nice voluntary move to restore faith in his leadership. reply lnxg33k1 17 hours agoparentprevIts concerning the conflict of interest, it can be crystal clear as going to make public pay for playing at your own golf court, but to be is baffling just how public populace is constantly scrutinised for ethics but seem that the rich can crap all over the world and no one cares reply spiderfarmer 16 hours agorootparentProblem is that a large part of the population is practically worshipping people who are / seem rich. Every questionable thing they do is explained away. \"It's just smart business!\" \"People are jealous because they didn't think of this!\" \"They're only coming after him because he's rich!\" \"You would do this too if you were him!\" reply yunohn 16 hours agorootparentAll such people hope that one day they can finish climbing the same ladder, and only after that, get to kick it out from underneath them. Crabs. reply kingkawn 16 hours agorootparentprevIt’s because we live in an uninterrupted feudal society that goes back millenia with only minor cosmetic changes to the system of governance in reaction to the periodic threat of revolution reply axlee 16 hours agoparentprev> But hold on, this same CEO has spent over $230 million(!) buying Canoo stock from his personal funds [2], so he is significantly in the red no matter how much he gets reimbursed for air travel. He's not the only shareholder. I am not sure the others appreciate paying for the CEO's lavish lifestyle when his company is on the brink of failure, even though the CEO is also in the red. And as you say, if he really wants to travel private, he can always use his own plane and not charge anything for it. The other shareholders are basically bankrolling his plane. reply Climato 17 hours agoparentprevYou need at least 400 Million to enter the car manufacturer market. The investment does sound absolutely reasonable at this point. reply Solvency 17 hours agorootparentCan someone explain why people try to make new cars from the ground up, rather than \"fork\" a base platform from GM/Toyota/KIA/whoever with a different design and little features? This happens in literally every other market and industry. hell, just look at PCs and laptops. Like why can't a Canoo or Rivian license a base EV platform and come up with their own chassis design, infotainment system, and other little things to differentiate themselves? why does it HAVE to be all or nothing? reply simonbarker87 16 hours agorootparentEven doing that is going to run you at least $100 million and you still have many of the risks associated with developing your own platform without anywhere near the number of escape hatches due to significant lock in. This has recently happened to a well known EV company relying on just the electrical platform from a well known and highly respected auto maker that they have a good relationship with. It means they’ve had to go looking at other platforms (again, just the electrical platform) and has put the whole company at risk. reply twobitshifter 16 hours agorootparentprevSome companies will use a contract manufacturer to produce their cars for them. For example Fisker (about bankrupt) used Magna Stehr in austria to produce their EVs. When you talk about a base platform I assume you are meaning an entire drive train? Most pieces of a car are going to be produced elsewhere and then assembled. Canoo isn’t making their own batteries or motors. Those come from battery and motor manufacturers. Canoo or a similar company might even buy structural battery pack built to spec by CATL. reply dmoy 16 hours agorootparentprevPeople do fork. Tesla's original was a fork of a Lotus. They got the whole chassis/etc from Lotus, dropped in their own drive train and other stuff. Other reply mentioned paccar. Idk why it doesn't happen more often. I suspect most manufacturers aren't willing to license like that. reply jack_riminton 15 hours agorootparentBut then they ended up using so little of the original Lotus that Elon said they should have started with a blank canvas reply wkat4242 13 hours agorootparentprevThat wasn't really a fork, they didn't copy the design, they actually bought the chassis from lotus. It's not really that different from a manufacturer buying brakes or wheels from another supplier. reply awad 15 hours agorootparentprevI'm not aware of any pure platform available off the shelf, though I imagine a big enough checkbook and a conversation with Magna might get you pretty far, but you can buy from Ford the Mustang Mach-E motor https://performanceparts.ford.com/part/M-9000-MACHE reply thephyber 12 hours agorootparentThere are lots, but most are not road legal. All privateer racers in many race series use cars that are manufactured by established companies, then heavily modify them. Alpine makes forks of BMWs. Braubas makes forks of Mercedes. RUF makes forks of Porsche. The other example is when 2+ large manufacturers work together to cost share a platform. Examples: - BMW Z4 / Toyota Supra - Subaru BRZ / Toyota GT86 - Mitsubishi 3000GT / Dodge Stealth Several Aston Martin coupes were built on Jaguar platforms. The NUMMI car factory in Fremont, CA was jointly owned by GM and Toyota before Tesla bought it. For a while, it made the Toyota Voltz / Pontiac Vibe. I think people get the impression from the wording that the “platform available off the shelf” means the consuming manufacturer can just grab some units and modify them, but in practice, there is a massive contractual negotiation. And since car manufacturers are heavily regulated, it makes sense to cost share both the manufacturing and the standards / crash testing. reply flyingpenguin 16 hours agorootparentprevI suspect, starting from the ground up is part of why people are so interested in these companies. The ICE car market is a massive market, which taking a part of required massive long term investment, and would result in you being relegated to just some minor side note. Even Toyota one of the longest biggest players is still seen as kinda \"new\" compared to BMW and VW, let alone hyundai which is basically a massive state backed effort. Now consider, all of that 100+ year history becoming completely irrelevant. An opportunity to time travel back 100 years and try to become the BMW of the future. I think this is what is exciting people. when is the last time an entrenched trillion dollar industry with hardly any shakeups in decades suddenly had the ability for anyone to enter and say their biggest advantage is that they are new? I am not saying I agree with it, I think knowing how to make a luxury car is a skill... But I don't think the goal of these CEOs and investors is to make a good car. Their goal is to make a 100+ year global legacy like BMW. If they could do that without making the car I am sure they would. reply sofixa 15 hours agorootparentWhy would anyone think that the current ICE manufacturers will just sit idly by and not get out EV designs at some point? Either on their own, or in collaboration with other legacy manufacturers? They have existing brand loyalty, existing relationships, supply chains, dealership networks etc. etc. that they can make use of even if their designs aren't as good as brand new entrants (and that's assuming brand new entrants can actually scale up quality manufacturing, which so far they haven't been able to). reply bombcar 15 hours agorootparentBecause for a long time the ICE manufacturers were making half-hearted play attempts at EVs, and Tesla came in and made real EVs and had a huge stock play related to that. So now the ICEs are scrambling to catch up, and are doing so, but lots of money is flowing around hoping to be the next Tesla. reply asadotzler 14 hours agorootparentICE is scrambling because ICE has 10 years left of new car sales in California (so the US basically) and Canada before laws prevent them from selling ICE. They aren't chasing Tesla, they're trying to prepare for the outlawing of their 100 year old products. reply sofixa 15 hours agorootparentprev> Because for a long time the ICE manufacturers were making half-hearted play attempts at EVs, and Tesla came in and made real EVs and had a huge stock play related to that. And their sales were still dwarfed by legacy manufacturers, who then started paying attention and practically all of them have at least one EV model out there, often with new platforms/models being in the works. reply bombcar 15 hours agorootparentI suspect most of these EV startups are trying for that TSLA bump, and don't really care much that TSLA is almost inevitably doomed to stagnant stock returns for decades now. Meanwhile the legacy companies will keep moving slowly along and produce vehicles. Some will die, some will merge, some will have wild successes. But it's much different than Google et al because cars actually cost about as much to make and sell as they do to buy. reply MangoCoffee 15 hours agorootparentprevI'm not even sure an EV car is the answer for \"Green\". I remember a Joe Rogan ep where he and his guest talk about the giant holes and bad mining condition in Africa because of the current EV rash to get materials for car battery. EV cars seem to be the go-between for ICE and the real answer for Green. reply JoshTriplett 16 hours agorootparentprevHow enthusiastic do you think those companies would be if someone came to them wanting to license their design perpetually and use it to compete with them? And even if that is something they're willing to do (which they might be), the terms would then make it difficult to ever do something that isn't based on that platform, since the manufacturer whose design is licensed would likely object that the new design was still based in some way on the old one. The analogy in the PC world would not be \"license a design from an ODM like Compal or Quanta\", it'd be \"license a design from Dell or Lenovo\". That in itself suggests a potential market: perhaps there's room for an ODM in the automotive space? reply Solvency 16 hours agorootparentthere isn't a single electric vehicle on the market that looks anything like the international scout, FJ40, or any classic rugged vehicle. Look at how much icon4x4 restorations go for. There are wealthy people out there with great taste, but no big auto manufacturer seems to want to produce a chassis with this aesthetic. So why wouldn't Ford or GM be cool with letting a smaller label do this and testing the market? reply ewhanley 16 hours agorootparentIt's a niche market. I love Icon's stuff but they sell very low numbers of vehicles. I would love to have an ev FJ40 or Scout, but I'm skeptical the general populace wants these as much as enthusiasts think they do. reply Solvency 13 hours agorootparentI find this take to be so outrageously wrong. Do you think the public \"wants\" the new hummer? Do you think they want any of the garrish looking cars that are literally all over the roads? People will literally buy anything and everything that's put out there as the numbers have proven time and time again. This is what brands and marketing does. It shapes public opinion and public perception. There are countless generic, soulless, lifeless car bodies being sold every day. and icon can't put out big numbers because there's numericallyonly so many of those vintage cars left to restore, and they are a small operation. reply glitchc 16 hours agorootparentprevUsing an ICE base platform for EVs doesn't make sense, and there is no EV base platform for sale/license. Companies building the EVs are holding their cards tightly to their chests for competitive advantage. reply sofixa 15 hours agorootparent> Using an ICE base platform for EVs doesn't make sense, Kind of. Renault's small sized EVs share parts of the platform as some ICE models (e.g. Clio/Renault 5 E-Tech) which allows them to reduce costs of the EV model. Considering their target audience and market segment (small city-focused EV with city-scale range) the tradeoff is perfectly acceptable. > and there is no EV base platform for sale/license How do you know this? Renault for instance are in a pretty specific spot, market wise, and they were trying to merge with Fiat-Chrysler before the latter ended up with PSA (Peugeot, Citroen, Opel) in Stellantis. They have some EV tech, especially on the cheap city-focused side (Dacia Spring, Renault Zoe, Renault 5 E-tech), and would probably be open to collaborating / sharing risks. This is purely conjecture of course. Also, Subaru managed to license Toyota's EV tech. reply s0rce 16 hours agorootparentprevIsn't the Subaru Solterra based on the same platform as the Toyota bz4x? reply slaw 16 hours agorootparentprevThere are EV base platforms for sale and license. For example Nio licensees it's platform. 60% of EVs are made/sold in China so that's where you should look for a platform. reply conk 16 hours agorootparentprevIt’s a classic make vs buy decision. What base platform is offered by GM/Toyota/Kia/etc? There are some examples where car makers (both EV and ICE) will sell components to competitors but in general this is pretty rare. Most companies want to control key aspects of their supply chain. Rivian did use motors from Bosch but is now in the process of using their own internally designed motors. This allows them to build exactly what they need and avoid relying on Bosch for a key component of their vehicles. reply bionsystem 16 hours agorootparentprevIt does happen, for example Paccar is a truck designer and sells licenses (apparently they also manufacture trucks but I think they used to only design them, although I'm not sure). I think some european makers do that as well and I would be surprised if Ford or GM doesn't. At least GM planned to buy (not sell) designs to Nikola if they ever managed to finish one (which I think they didn't in time for the deal to go through). reply zardo 16 hours agorootparentPaccar builds and sells trucks, not a license to build them. Other companies buy those add their own equipment (cranes, concrete mixers, etc) and resell them. Light duty truck and van builders e.g. Ford and GM do the same thing but mostly for companies building RVs rather than commercial equipment. reply empath-nirvana 15 hours agorootparentprev> Can someone explain why people try to make new cars from the ground up, rather than \"fork\" a base platform from GM/Toyota/KIA/whoever with a different design and little features? That's sort of what Tesla did with the Roadster. It was a Lotus that they put an electric motor into. reply Kon-Peki 12 hours agorootparentprevThe Rivian S-1 document filed with the SEC said that Ford built all the non-electronic stuff for them until they could do it themselves. reply singleshot_ 16 hours agorootparentprev“Body-in-white” is a relevant search term if you would like to learn a little bit about the options in this area. reply imtringued 16 hours agorootparentprevVW does this internally. They own the VW, Seat and Skoda brand. The up!, Skoda City Go and Seat Mii are virtually identical. reply geon 16 hours agorootparentThey share tech between a TON of brands and models. https://en.m.wikipedia.org/wiki/Volkswagen_Group_MQB_platfor... reply thatguy0900 15 hours agorootparentprevDo any of the car manufactorers want to sell you their base model? Even if they did, how would Ford dealers feel about Ford selling rivian the rights to make better Ford cars? reply MattGaiser 16 hours agorootparentprev> Like why can't a Canoo or Rivian license a base EV platform and come up with their own chassis design, infotainment system, and other little things to differentiate themselves? I imagine anyone willing to license one at the moment only has a crappy one to sell you or it is some Chinese EV, which creates political problems. reply koonsolo 13 hours agoparentprevWhen you own a company, the question is always how to get money out. Renting out personal things to the company is one way of doing that. If you are the sole owner, that's all fine. If there are co-owners, that shouldn't be done unless everyone gets some benefits. I once worked for a company that went bust. It wasn't able to pay its suppliers anymore, but alway paid rent on time. Guess who owned the building. So especially when your company is doing bad, any money you get out is money they cannot take away. reply ilrwbwrkhv 15 hours agoparentprevI am sure these companies are a massive money laundering operation. What does Solera even do or ever did? Prior to the acquisitions? reply blackhawkC17 15 hours agorootparentSolera sold risk management and asset protection software. A company with $1bn+ in annual sales [1] is a money-laundering operation? Hint - Most ultra-rich people make their money in boring industries you wouldn't even know about. 1- https://www.macrotrends.net/stocks/delisted/SLH/solera-holdi... reply ilrwbwrkhv 15 hours agorootparentMost of these businesses are actually fronts. They siphon money from Africa and other third world countries with poor laws and wash it with money from private equity firms. reply blackhawkC17 14 hours agorootparentWith all due respect, this is rubbish. Private equity LPs are overwhelmingly local pension funds, institutional investors, and high net worth individuals. reply dgrin91 17 hours agoprevThe headline is relatively clickbait-y. Its double their revenue because their revenue is basically 0. Their actual expenses are hundreds of millions, of which this 1.7 million is a drop in the bucket. Once their upfront expenses are paid they will (presumably) be making hundreds of millions/billions in revenue, which means this 1.7m is not particularly important. You can talk about standard complaints of CEOs with private jets, and I'd probably agree with you here, but there isn't anything particularly egregious here. reply benjlcox 17 hours agoparent$1.7 million is 1-3 employees working to ship your product. When you're company is on the edge of collapse you should have your priorities straight. Diverting company resources to your own private jet is a preposterous use of resources and, imo, speaks volumes about where Canoo is headed. reply 28304283409234 17 hours agorootparentMy mom retired at age 55 with 1 million euros after selling the mom and pop shop. She is 78 now. Still living off of that original mil. reply ricardobayes 16 hours agorootparentprevPlease drop me a line if you know of any startup hiring for a 500k(ish) comp package. reply pedalpete 10 hours agorootparentYou'll spend 50-100% more than comp on an employee in any year. reply throwawaymaths 7 hours agorootparent250k is still on the high end for a senior developer at a startup. reply pedalpete 1 hour agorootparentYup, it's definitely on the high end, but not unheard of. reply calvinmorrison 17 hours agorootparentprev1.7 million is 1-3 employees? Jesus this place is so out of touch. I've worked at places with annuals between 1 and 5 million and none of them had less than 10 people. most between 15-30 reply edmundsauto 17 hours agorootparentThis doesn’t change the point, which is to put your resources into wise areas. Additionally, I would say that 15-30 people for $1.7M is more out of touch than 1-3, if we’re talking about employees with potential to turn the business around. reply dkjaudyeqooe 17 hours agorootparentprevOut of touch with whom? Logically you're also out of touch with those you're talking about. Different places/environments/skill levels have different costs, so what? reply secondcoming 16 hours agorootparentprev> $1.7 million is 1-3 employees Good lord. You hiring? reply imzadi 17 hours agoparentprevThe $1.7m is being paid to the family holdings of the CEO to rent the jet already belonging to the CEO for the CEO. Plus an additional $1.7m to the same holdings for \"support services.\" reply ametrau 17 hours agorootparentThat’s the actual story. It’s a bit boring though. The rest is bs clickbait. reply malfist 17 hours agorootparentA bit boring? Seems like straight up embezzlement. reply ein0p 17 hours agorootparentIt’s only embezzlement if board/investors didn’t know. This definitely is something the board would have to approve. As a former exec though I think it’s distasteful to require such things before significant profitability. Business class is fine. Pre-revenue, coach is fine too. reply jonathankoren 16 hours agorootparentTBF boards are famously insular and self serving, with everyone being on each other’s boards. reply drexlspivey 16 hours agorootparentprevSo I’m assuming you’re paying for plane tickets out of pocket when going on a business trip. Otherwise it would be embezzlement right? reply acdha 15 hours agorootparentHe’s buying air travel from himself. Unless he’s undercutting the commercial carriers, that means the company is spending more than it needs to with the difference going to his pockets. It’d be much cleaner ethically for him to get reimbursed the cost of a business class ticket and pay for his jet out of pocket if he can’t abide flying with the little people. reply drexlspivey 15 hours agorootparentIf the company requires a private jet they can either pay for a lease from some other vendor or pay the CEO to lease his jet. Unless they are paying way above market price I don't see how this is embezzlment or even fishy. reply acdha 13 hours agorootparentThey’re losing money, which seems like a time not to spend money on luxuries. reply malfist 16 hours agorootparentprevMy company pays for my plane tickets, but it's not booking flights on my personal airplane, which I get to set the rates for. reply ametrau 6 hours agorootparentprevI’m being droll. It’s not boring (to me and you) but is in their estimation vs the more grabby headline. reply pjerem 17 hours agoparentprevWell, the article also says that the plane isn't even owned by the company but by the CEOs family holding. So even if it's \"a drop in the bucket\", it's also not really a company expense, just an outrageous compensation. reply disgruntledphd2 17 hours agorootparentI think that makes it worse, tbh. Like the guy already has a jet, which presumably he can afford to run. Taking money out of an unprofitable company to pay for (somewhat) unreasonable personal expenses kinda feels off to me. But then, maybe I'd feel differently if I had a private jet ;) reply woobar 16 hours agoparentprevCEOs get all kinds of compensation. Business jet travel, security, etc. This line item could be just tax optimization for this guy. I am not trying to defend him, he is getting paid a lot: \"On May 5, 2023, the Board granted Mr. Aquila an award of 6,884,682 RSUs. These awards vest on May 5, 2024, subject to continuous service.\" [1] At current stock price it is ~$20M. Getting outraged about additional $1.7M that was negotiated several years ago is strange. It does make a great headline, but would it change anything if he is paid $22M and pays for the jet out of pocket? [1] https://ir.stockpr.com/canoo/sec-filings-email/content/00016... reply axlee 16 hours agorootparentWell, what kind of world-class engineers could he get for $1.7M a year? How many salespeople ? Seems like the CEO's comfort when travelling should be a lot lower in the company's list of priorities, as it's losing hundreds of millions a year. reply throwawaymaths 7 hours agorootparentprevCanoo did a 1:23 reverse split last month, so take that into account.... His comp in Rsus is probably shy of $1M reply singleshot_ 15 hours agorootparentprevIt would make a difference to the IRS, wouldn’t it? reply gangstead 15 hours agorootparentprevTotally agree. I'm not usually in the habit of defending millionaires. But I thought there used to be a justification for private jet travel of maximizing the CEO's time. The company is investing $20M per year in this asset and he's probably flying for meetings all the time and if a private jet cuts a couple hours of airport transit / wait time off of each flight it's probably worth it for the increased amount of meetings he can attend. Maybe that can be achieved for less than $1.7M, I'm not informed enough. This source https://simpleflying.com/gulftream-g700-cost-to-own-operate-.... says it's a little more than $2M per year to operate a Gulfstream G700, I don't know what kind of jets CEOs are using these days. reply throwawaymaths 17 hours agoparentprevIf you're an already rich CEO that takes over a pre-revenue startup, either pay for jets out of your own pocket or fly coach. Definitely don't subcontract your own family's (edit: your own) \"services company\". reply Powdering7082 17 hours agoparentprevyes it's clickbait-y, but it also seems a bit like it's burying the lede with the fact that the CEO is self dealing on top of it. > Canoo reimburses Aquila Family Ventures, an entity owned by the CEO, for use of an aircraft. reply Solvency 16 hours agorootparentImagine if all salaried employees working from an office created a personal LLC to own their car, and then had their work compensate them by reimbursing each employees LLC. Would that pass muster? reply wongarsu 15 hours agorootparentIf it's cheaper for the company than leasing or renting cars somewhere else, why not? Presumably you hire the employee for their time and expertise, not because they own a car and offer its use for company travel below market rate. (That does happen in many industries, but that's a market distortion we should look down on, not a yardstick for what's right) reply bombcar 15 hours agorootparentThe difference is it's usually not \"worth it\" to break it out in the case of an employee (the advantage is the other way, where the company buys a car and lets the employee drive it, and ignores personal use). With $2m on the line, it is worth it even just for the tax savings. reply s0rce 16 hours agoparentprevNot a drop in the bucket at all, its a massive waste for a startup on the edge of insolvency. They need to focus on priorities and spend much more carefully. No way does a small startup founder need a private jet. reply oytis 17 hours agoparentprevStill, why would you use a private jet if your company is not only not profitable, but also doesn't generate meaningful revenue? You're not spending money you've earned, you're spending borrowed money. reply neom 17 hours agorootparentIf his net worth is $400MM+, his insurance my very well require him to fly private. reply echoangle 16 hours agorootparentIs that really a thing? Is private supposed to be more secure because of accidents or because of risk of kidnapping and assassinations? I don’t see a reason why private flights would be less accident-prone than public flights. Edit: looks like private flights are actually much more dangerous than airlines, the insurance would probably prefer if you would fly public… (not my favorite source but the first thing I found: https://www.livescience.com/49701-private-planes-safety.html ) reply neom 16 hours agorootparentIt is a thing, yes. A friend of mine was discussing how he has to think about the events to go to because his key man insurance on his family office requires him to use his own pilot, so he's contently inventing dumb reasons not to go to things vs admitting his cheap and doesn't want to spend the money. Two things I find amusing about this... rich people being cheap is always funny, and, as you mentioned, insurance companies preferring a private pilot when flying private it less safe. Apple requires this for Tim Cook too, and I always thought it was amusing. reply bombcar 15 hours agorootparentPrivate is less safe if your grouping includes Cessnas and small business jets, and ignores kidnappings. With a private jet you can be at the airport and direct into your waiting car with security escort without anyone knowing, which can greatly reduce the chance of other issues occurring. reply blackhawkC17 15 hours agorootparentprev> Looks like private flights are actually much more dangerous than airlines Most of the accidents involve small one-engine aircraft that owners personally fly. They're technically \"private,\" but what's relevant here is large private planes like Gulfstreams, Bombardier Globals, Dassault Falcons, Boeing BBJs, and the like..they're safer than airlines. reply brandall10 17 hours agoparentprevIt’s also worth noting the projected revenue for 2024 is 50-100M. reply ricardobeat 17 hours agorootparentI also project earning $20M from my yet-to-be-built SaaS platform in 2025. reply brandall10 13 hours agorootparentOkay. This is a publicly traded company with a product burning through a multiple of that annually. reply bdcravens 17 hours agorootparentprevFrom their recent 10K filing: \"Our management has performed an analysis of our ability to continue as a going concern and has identified substantial doubt about our ability to continue as a going concern. If we are unable to obtain sufficient additional funding or do not have access to additional capital, we will be unable to execute our business plans and could be required to terminate or significantly curtail our operations.\" reply vidarh 17 hours agorootparentAlmost any startup will have periods where there will be \"substantial doubt about our ability to continue as a going concern\" if they are \"unable to obtain sufficient additional funding\". This is meaningless when looking at a startup without also looking at whether their burn rate is abnormal relative to how much they raised, and whether or not they're meeting their targets. reply gomox 16 hours agorootparentprevThat's just boilerplate that any unprofitable business has in their filings, to prevent lawsuits over undisclosed risks. reply GuB-42 17 hours agoparentprevSo, we can have both the standard complaints of CEOs with private jets and the standard complaints of companies spending way more than they earn. reply rsynnott 17 hours agoparentprevI mean, it seems pretty bizarre to me for a CEO of a company that doesn't have any revenue to have a private jet paid for by that company. Is that... common? (Honestly, even if they had revenue in the hundreds of millions, it'd still be rather absurd.) reply diggan 18 hours agoprev> Under a deal reached in November 2020, Canoo reimburses Aquila Family Ventures, an entity owned by the CEO (Tony Aquila), for use of an aircraft. In 2023, Canoo spent $1.7 million on this reimbursement — that’s double the amount of revenue it generated. Canoo paid Aquila Family Ventures $1.3 million in 2022 and $1.8 million in 2021 for use of the aircraft. I'm surprised there are any employees left at the company. If I saw that the CEO is actively funneling funds out of the company where we work, to their family's company, I'll be long gone. reply Workaccount2 17 hours agoparentA former president only stayed at properties owned by his company, billing the government millions in extra overhead. His voters love him. reply efnx 17 hours agorootparentAnd they say “if you don’t like it, leave!”. And so now we live in New Zealand. reply wkat4242 13 hours agorootparentNew Zealand is the most amazing country I've ever visited. Scenery wise, but also super nice people and politically sane (Andern in particular was great, too bad she left) I'd live there too if it wasn't literally on the other side of the planet for me and I don't want to cause hundreds of tons of CO2 every time I want to see my family :'( reply rvnx 17 hours agorootparentprevHow is it there ? Are earthquake and food (and mosquitoes in the bushes) as bad as the rumours say ? (serious question about the first 2) reply efnx 15 hours agorootparentEarthquakes - so far so good, but I grew up in LA and lived through multiple large-ish quakes (Northridge). One big difference is that many small rural towns only have one road in or out, so a quake could block the road, leaving you stranded, possibly without power. This is the case along the west coast of the South Island. Food - groceries are pricey! It was surprisingly expensive given the lower wages here. CA seems to be catching up though! Mosquitoes - comparable to LA, less than Sonoma County. Smaller too. But here on the South Island we also have sandflies. They vary by region. West Coast has them bad in some remote spots. reply rvnx 26 minutes agorootparentThank you! reply CognitiveLens 16 hours agorootparentprevEarthquake risk is similar to California, with very low (but not zero) risk in many places, e.g. Auckland. The food is generally excellent in urban areas - cafe culture rules for those who can afford it. Main issue is cost of living - housing and food costs are kind of silly relative to average income. Mosquitos are really not an issue - people up north might have a different experience, but from Auckland on down, no one needs screens. reply rvnx 25 minutes agorootparentThank you for sharing your experience! Big fan of Kiwis and so curious about the country. I really loved to hear first-hand experience. reply wsc981 17 hours agorootparentprevThe whole COVID handling of New Zealand, Australia and Canada proved to me I wouldn't want to live in any of those countries. Prior to COVID, I thought Australia seemed really nice to emigrate to, when I visited it once. reply diggan 17 hours agorootparent> The whole COVID handling of New Zealand, Australia and Canada proved to me I wouldn't want to live in any of those countries. What countries are you now curious to live in, after seeing how they handled COVID? reply wsc981 1 hour agorootparentI felt Thailand, where I live, handled it fine. I didn't feel like we got pressured here into getting the COVID vaccination and life could go on quite as normal for me as an unvaccinated person in our village (in the city it might have been different). Though my girlfriend did get the COVID vaccination eventually, due to her being afraid of not being able to visit venues, restaurants and such. She regrets now that she got the COVID vaccination. We know of many people in our neighborhood who've gotten health issues related to the COVID vaccination (e.g. blood clotting, strokes, Guillain-Barré syndrome, etcetera). reply astrange 15 hours agorootparentprevJapan, Korea and Taiwan had good results for minimal disruption. reply FireBeyond 15 hours agorootparentAll of those countries have societal norms that are vastly different with respect to illness. Japanese people voluntarily, proactively wear masks when sick in public, for example. Notwithstanding some of the later research about the efficacy of masks, there was a lot less those governments HAD to CHANGE to minimize disruption, because their populations were already not generally selfish about their needs versus those around them. reply astrange 14 hours agorootparentJapanese people are not mystically different, their outcomes are a policy difference and you too can have that policy. (And that policy wasn't face masks, it was banning large indoor gatherings but not small or outdoor ones, plus immigration quarantine.) reply FireBeyond 13 hours agorootparentNo, they're not, but when you have a population that already is (let's be real) significantly more selfless and conscious of the wider impact of infectious disease (or even the perception thereof), you're going to be able to enact other public policies that are consistent with that goal with a lot less disruption or opposition. reply seabrookmx 16 hours agorootparentprevI wasn't aware we (Canada) did anything different than the US. We had some press blow up (trucker rally etc) but we didn't have the draconian mandates the Aussies did, that's for sure. reply efnx 16 hours agorootparentprevI felt that NZ handled it great! I lived through a year of American lock down and then a year of Kiwi lockdown (we emigrated from the US while on lockdown - it was nuts). IMO Ardern handled it beautifully, at least compared to the misinformation train wreck happening in the states, but that is of course only my opinion. reply imzadi 17 hours agorootparentprevMust be nice to not be over 40 when the world implodes reply efnx 16 hours agorootparentWell I’m 40 and my partner is 45, but who knows how old we’ll be when/if the shit hits the fan. reply imzadi 16 hours agorootparentI was just joking, because when I looked into immigrating to New Zealand, they had a point system penalized people for being over 40. reply efnx 15 hours agorootparentThat’s totally true, but the point system is cool in that they give a massive boost to special skills like software development. reply dexterdog 17 hours agorootparentprevI'm not fan of the guy by any measure, but how is this any different than the government paying to make any president's existing properties places where a president and his massive entourage can stay? It's been done by every president I can remember aside from maybe Clinton because I don't remember him having any significant places. reply skhunted 17 hours agorootparentWhat other President profited from government employees being forced to rent rooms at his hotels? You really have to be deep in the cult to not see a problem with this. reply willcipriano 17 hours agorootparentnext [2 more] [flagged] tekla 16 hours agorootparentAnd this is a response how? reply LastTrain 16 hours agorootparentprevI'm not following. Do you think Obama and Bush were charging rent to the government for their personal residences or something? What other Presidents owned business entities that billed the government for services? It is mind boggling that the ethics of this need to be explained. reply afavour 17 hours agorootparentprevIt's different because other presidents didn't then bill the government for the entourage to stay on a per-night basis for each stay. An added bonus for Trump was that his properties were also accessible to the public, so he got to make extra $$$ from people who wanted to stay close to where the President was. No previous president had that kind of an arrangement. reply lotsofpulp 17 hours agorootparentprevBecause of this part: > billing the government reply bevekspldnw 17 hours agorootparentprevRegular reminder his voters are the minority and he’s never won a popular vote. reply astrange 15 hours agorootparentThat doesn't matter because presidential campaigns aren't designed to get them the popular vote. reply ifyoubuildit 17 hours agorootparentprevI have no interest in defending the man, but this argument triggers me. Do you also make sure to regularly remind people that those football players with Superbowl rings never won the world series? Edit: the point is that the win condition is electoral votes. A rational actor will optimize for that, potentially at the expense of the popular vote even, and they will be more likely to win for it. In other words, don't have your quarterback spend his practice time in the batting cages if you want to win the super bowl. reply jmholla 13 hours agorootparentA better analogy would be the ProBowl, not a different sport, in my opinion. reply browningstreet 17 hours agorootparentprevBut more voters didn’t. reply tim333 29 minutes agoparentprev>If I saw that the CEO is actively funneling funds out of the company... He's not. He's funneling funds into the company. He's basically a billionaire investor who owned the jet before bailing out Canoo. reply gruturo 17 hours agoparentprevIf he actually uses the jet for Canoo-related business, this is not unreasonable. Assuming those trips may eventually lead to business deals, and that the amounts reimbursed are in line with free market prices, it is advantageous to Canoo. Their CEO could be x% \"more effective\" (I know how abstract that sounds), ultimately benefiting the company, and maybe they even got a good deal (\"hey, I own a jet, and it has to fly at least 200 times per year to cover its maintenance costs. If you allow me to use it for Canoo-related trips, which are anyway needed, and reimburse me, I'll charge you less than what netjets wold cost us. Deal? Y/N\") The real world tends to be more nuanced, but in principle it stands, at least until proven guilty/shady. reply LastTrain 16 hours agorootparentEthics in the 21st century I guess. No, conflicts work the opposite way - assumed shady until cleared. Virtually every business works this way, especially ones with investors. Conflicts can of course be legitimately cleared, but not with just some hand-waving. It is no different than my company not allowing me to direct business to entities owned by myself or my family. reply jonplackett 18 hours agoparentprevWework vibes reply bombcar 15 hours agoparentprevIt may also be part and parcel of the market they're trying to play in. If every other \"car company\" has a private jet ready to whisk the CEO anywhere in the world, you might look really silly to other companies who expect you to be able to make a near last minute meeting. And if you're an employee, as long as you get paid you're likely not to care much about it. reply jeffbee 15 hours agoparentprevThis is no unheard of. I worked at a company where the CEO got an interest-free loan from the company to buy his own jet, then charged the company to use it. Of course that individual later pled guilty to a variety of federal crimes, so :shrug: reply FireBeyond 15 hours agorootparentAdam Neumann comes to mind. Zero interest loan from WeWork to buy commercial properties, then lease them to WeWork. reply justinclift 18 hours agoparentprev> I'll be long gone. Or maybe it's a case of \"time to renegotiate my salary with that in mind\". ;) reply gumptionary 17 hours agoprevTony Aquila is the CEO of both companies - Canoo and Aquila Family Ventures. I'll never understand why it's okay for CEOs to have multiple concurrent jobs, while one of the biggest fervors of the pandemic was when employees were found to have... multiple concurrent jobs. reply corry 17 hours agoparentDo you manage your own money and finances in addition to having a day-job? That's what he's doing, albeit in a more complex situation and likely higher wealth bracket given he sold his last company for $Bs. The only thing that strikes me as odd about it is calling oneself \"CEO\" of the family office. I don't know what title is customary but CEO seems out of place. If it said he was \"Chair\" of the Aquila Family Ventures family office or something it would stand out far less. reply neom 17 hours agoparentprevBeing a CEO of your family office shouldn't really be a \"real job\" - it should take up maybe a day or two out of your month if it's being run correctly. To me this would be the same as if a product manager had a side hustle doing some accounting for friends and family. It's fine. The selling services back and forth thing, I get it, it probably saves some people some work and it might even work out better economically for the company, but the optics are never going to be solid and people are always going to question it, so imo it's not worth it, but... it is quite common. reply snowwrestler 17 hours agoparentprevIt’s fine for anyone to have multiple concurrent jobs as long as all their employers know about it. Hiding things is where people get into trouble (and not just with jobs). reply gumptionary 17 hours agorootparentThis is a totally fair point. The incongruity arises for me in that if I said in a job interview process that I'd be continuing to hold another position while adding this one, I'd get laughed out of the room. If it's critical that rank and file guys don't have divided time or loyalties, why is the standard different for the single person most responsible for success or failure of the company? reply makr17 15 hours agorootparentThe last three jobs I've held, I've had to state up front in writing that I will continue to act as the paid IT support for my spouse's one-person consulting firm. Hasn't been an issue yet. Three jobs ago I also had a very small side consulting gig that came along after I'd been hired, so I had to get it cleared. It was at the behest of one of their board members though, so it really wasn't a hassle... reply blackhawkC17 17 hours agorootparentprevAquila Family Ventures is basically a family office that the CEO likely just oversees but doesn't run day-to-day. It's a different thing than having multiple full-time jobs like Musk. reply pbhjpbhj 17 hours agorootparentIt's a shell company used to dodge taxes, presumably? Or something similarly nefarious; avoiding liabilities or whatever. Not really a company but a legal instrument. reply blackhawkC17 17 hours agorootparent> It's a shell company used to dodge taxes, presumably? It's a holding company for the CEO's assets. Virtually everyone worth $10 million+ has one. When and why did people become so conspiratorial and see boogeymen in everything they don't grasp? reply evandale 16 hours agorootparentIt's hasn't been a conspiracy theory since the Panama papers came out. Everyone is now aware of the extent rich people go to use tax havens and are rightfully upset. They make record profits, encourage irresponsible consumerism, and don't even pay their fair share for the damage they inflict upon the world. https://www.cbc.ca/news/politics/panama-paradise-pandora-pap... Furthermore there's a reason rich people flock to places like Delaware, Washington, or California. Those states all have tax schemes that allow the wealthy to pay the least amount of taxes. Hell us rubes even suffer through coach so that the ultra wealthy's luxury jets are subsidized. https://www.businessinsider.com/ultra-wealthy-private-flyers... We understand exactly what they're doing, just because we don't agree with it doesn't make us ignorant or uneducated. reply blackhawkC17 16 hours agorootparentPeople flock to Delaware because it's the most corporate-friendly state, especially regarding regulations and court cases. Washington and California are two massive economies, so it's no surprise that rich people flock there. If this CEO wanted to register a shell company to dodge taxes, he would have done it in better places than Southlake, Texas [1]. Anyone can register an LLC as long as they have valid identification and pay the $300 Texas filing fee...nothing nefarious. Talking about the Panama Papers will be a long story, but notice how relatively few Americans are on that list. It was mostly people from developing countries with weak rule of law and high levels of corruption...the type where rich folks hide assets to avoid the government or rival business goons coming for it, and it's much easier to cheat taxes in those countries because of weak law enforcement. 1- https://pitchbook.com/profiles/limited-partner/232176-79 reply astrange 15 hours agorootparentprevCalifornia of all places doesn't have low taxes for wealthy people. Its tax system actually depends on wealthy people. (IPOs specifically) It has low taxes for people who've lived there a long time. reply manarth 17 hours agorootparentprev> \"if I said in a job interview process that I'd be continuing to\" \"act as Treasurer for my local church\" I'd get…? reply ghaff 17 hours agorootparentprevThere are plenty of consulting/writing/etc. jobs that are explicitly fractional or part-time where someone may have multiple clients. And this is even the case with fractional CFO positions and the like. reply s0rce 16 hours agoparentprevAs others said, he just runs his family office, likely 99% of the work is delegated to people who work for the family office. reply ant6n 17 hours agoparentprevSounds like a hold co. Even startups worth 100K may have the founders hold the stock through a family holding corporation (which may then also be used to \"hold\" vehicles). reply efnx 17 hours agoparentprevNot sure why you’re getting downvoted as this is a legit question I’d like answered. reply lionkor 17 hours agorootparentYeah, but answered by who? reply Karellen 16 hours agoparentprevBecause CEO's decide which is okay and which isn't, and because fuck you, that's why. No, it's not logical, or consistent, or rationally defensible. They don't give a shit, and they don't believe they have you answer to you. If they choose to give any answer at all, it will be bullshit in the \"On Bullshit\" sense of the word; the answer will not be made with any consideration for truth, but just to provide whatever words the speaker thinks will shut you up. reply astrange 15 hours agorootparentNo they don't, boards do. reply ryandrake 17 hours agoparentprevWell, they are CEOs, and are therefore better people than the rest of us workerbees and get to operate under totally different rules. reply ThrowawayR2 17 hours agorootparentThis but unsarcastically. Linux Torvalds, Anders Hejlsberg, and other elite developers also operate under totally different rules than worker bees too. No, we're not on the same footing as a CEO candidate or 10x developer. Anyone who is sure as heck wouldn't be wasting their life collecting karma points on HN. reply pbhjpbhj 17 hours agorootparentI suppose you believe all these billionaires are self-made and that having a handout of hundreds of thousands of dollars, and a network of very rich people you know to make investments, made no difference. 'Anyone can succeed through hard work'. The really rich CEOs collect imaginary karma points on X ... reply ThrowawayR2 17 hours agorootparentI started my career alongside a variety of people who are now CEOs, VPs, distinguished engineers, CTOs, etc. and had a chance to observe them as they rose far, far above me. Luck played a factor in their rise, sure, but so did talent and an immense level of drive; their titles are ones they earned. reply ryandrake 17 hours agorootparentprevA lot of bad in our society can be explained by the fact that a lot of people seriously believe that some people are inherently better than others, and deserve to be at the top of the hierarchy, to follow different rules, to get more than one vote, that they are \"elite\" and should therefore get better treatment. Egalitarianism is not a universally held doctrine. I thought the downvotes were coming from people who didn't get my sarcasm, but it could also be that HN readers really believe that CEOs are inherently better people... reply blackhawkC17 16 hours agorootparentPeople aren't inherently better than others, but people are infinitely better at some things than others. Terrence Tao is inherently better at mathematics than I am, and I'd be a fool to claim otherwise. Torvalds is a much better programmer than I am. There are endless examples. reply bombcar 15 hours agorootparentExactly. Now if we start arguing if Torvalds \"deserves\" to be richer than Gates (even though both are quite better than adequate programmers from their time) that's a different story. But in the end most of it really sounds like sour grapes and complaining. reply ryandrake 15 hours agorootparentprevI'm not saying people aren't better at things than others. The thread was about whether these people deserved special treatment or a different set of rules because of this. reply ThrowawayR2 16 hours agorootparentprevEgalitarianism is about equal social treatment and rights, not equal ability. reply nytesky 18 hours agoprevWow, it’s bad enough if they were NetJet fees. This is WeWork level sketch: “ Canoo reimburses Aquila Family Ventures, an entity owned by the CEO, for use of an aircraft” This is a PUBLIC company?? reply blackhawkC17 17 hours agoparentSuch deals are reasonable under some circumstances. For example, Tesla pays SpaceX for Musk's travels on the SpaceX jet (whenever he travels for Tesla-related business). But definitely not for a company with just a few $100k in annual revenue that's teetering on bankruptcy. Not surprised it's a SPAC stock... Edit: Upon digging; I discovered that this CEO has invested $230 million+ in Canoo (from personal funds he made selling his previous company)...this article is almost a nothing burger. reply nytesky 16 hours agorootparentIt’s a public company, he can’t treat it as his private company even if he invested $230M and it’s only worth $150M now and he’s trying to make up for his losses reply lenerdenator 18 hours agoprevI'm beginning to think the vast majority of corporate governance is a facade and that this is just a way to blow millions of dollars with no real accountability. reply passion__desire 17 hours agoparentConsumption needs to happen somewhere so why not create sinks (ceos) so that our work (source) ends up serving the rich. reply mikeyouse 18 hours agoprevWhere is the BOD? The amount of self-dealing and conflicts of interest that everyone allows is just absurd. reply denton-scratch 16 hours agoprevThe boss already owns the jet. Now he makes his company rent it from him, so he can zoom around in the plane he already owns, and that he would be zooming around in even if he weren't the Canoo boss. I don't think a company should be paying for the boss's jet, if the company isn't near break-even. I'd say the boss doesn't believe the company has legs, and he's extracting cash while he can. reply bombcar 15 hours agoparentReplace \"jet\" with \"time\" and the argument still holds. Why should the CEO get a salary if the company isn't near break-even? reply onychomys 18 hours agoprevI should quit my job and become a CEO, seems like a pretty sweet gig. reply ghaff 17 hours agoparentThe money would probably be nice but I suspect a lot of people here would hate the amount of travel and the degree of scheduling morning, noon, and night that the CEO of any size of company has. reply blackhawkC17 17 hours agorootparentMost people who say, \"I would quit my job and do that; it seems easy\" won't even survive what they claim they would have done. I mean there's a reason they didn't do it, because they couldn't. reply eszed 17 hours agoprevI slightly mis-read the headline. Here's what's going on: >Canoo reimburses Aquila Family Ventures, an entity owned by the CEO, for use of an aircraft. In 2023, Canoo spent $1.7 million on this reimbursement. CEO owns a plane. CEO uses the plane (for business, one presumes). Business reimburses CEO for plane. That looks like a poor use of funds, but not necessarily self-dealing? I mean, in their position he should probably be flying coach - maybe he's so good that he's totally worth spending seven figures for his travel (though I doubt it) - but it's technically no different than reimbursing any other travel expense. Better system: they could reimburse the minimum airfare, and he could cover the difference himself. Everyone has that figured out for us peons, when we request a more convenient flight. (Want to bet they imposed that on their employees?) reply ryandrake 17 hours agoparent> Better system: they could reimburse the minimum airfare, and he could cover the difference himself. Everyone has that figured out for us peons, when we request a more convenient flight. (Want to bet they imposed that on their employees?) I'd absolutely be willing to bet the deal that regular employees get is worse-than-or-equal-to what you described. Most companies I have worked for do not even let you choose. If you are doing business travel, you use the company's preferred travel agency, and fly on the flight you're given, even if you could independently find a business-class flight just as cheap. reply lanstein 17 hours agoparentprevCan you tell me what travel system allows that? reply eszed 13 hours agorootparentI've had that in academia, and in my current (medium-sized) company, where rules and processes aren't as stringent as I know they are in BigCorps. My partner works for a consultancy firm (where she, in part, arranges travel for various people), and they do that too. I guess I assumed that (very fair-seeming) practice is more widespread than it actually is. My condolences to all of you. Edit: I just remembered a totally silly travel situation during my academic career. The school sent me to an academic conference in an interesting location, and I wanted to stay for an extra week to do some touristing. (It was during summer vacation, and golly do I miss those.) No one had any problem with it, and they told me standard practice was for me to call the airline and pay the $250 (or whatever it was) change fee. No problem, until I noticed that tickets with the new return date would be something like $400 less than the original dates. No tickets had yet been purchased, so I suggested that they buy me those dates directly: everyone would win. Except... \"Sorry, we can't do that.\" Huh? \"Travel must be +/- 2 days of the conference dates.\" I presented the situation to my department chair, hoping for an intervention, but she sighed, and said that those people were impossible to deal with. \"But, it's the end of the fiscal year, and I have some extra budget [somewhere], so submit a reimbursement form for the $250, and I'll sign it.\" Silly, right? reply arange 17 hours agoprevthe ceo invested $230M+ of his own money into the company. if the guy wants a market-rate jet benefit, give the man the jet. reply tromp 17 hours agoprev> avoid the same fate as other EV startups, like recently bankrupt Arrival. Talking about other EV startups, I wonder how much longer Aptera can remain in a state somewhere in between not having gone bankrupt and not having started production yet. They do seem to be forever inching closer toward the latter [1]. [1] https://electrek.co/2024/04/01/aptera-showcase-solar-ev-tech... reply throwawaymaths 16 hours agoparentAccording to their CFO who authorized the CEO to make the statement (kind of a big deal for legal reasons) aptera makes breakeven by making 6k cars a year, so they have 7 years number of preorders. Even assuming a low preorder execution rate at like 20% it seems like they will be good to go. reply alberth 16 hours agoprev> The company generated $886,000 in revenue Plenty of companies spend more than that on just AWS egress fees. I’m not saying money spent on a private jet is right or wrong. But when a company is not profitable, you could compare this to anything. Like the headline could have easily been “Canoo spent double its annual revenue on AWS egress fees” reply acdha 15 hours agoparentAWS egress fees serve a legitimate business function. They might be higher than what they could be with optimization but they go towards a business service. What we’re seeing here is more like if those egress charges were due to him hosting the business on his own cloud service even though it cost more. reply bombcar 15 hours agorootparentDid it cost more? From a quick search the amount seems reasonable for \"years worth of private jet use\". If CEO travel is a legitimate business function, you're now arguing \"AWS vs server in your closet\" kind of questions and haggling on price. reply acdha 13 hours agorootparentYes, it did. The question is whether there’s enough value generated by taking a private jet instead of normal plane flights, which is unlikely to be the case for a business losing money. reply snakeyjake 16 hours agoprevI love startup culture. The CEO of my company flies commercial, and we've have thousands of employees, have been around since the 1940s, actually ship products, and make a shit-ton money. But startup CEOs leading companies with 800 employees that can't ship hardly anything are movin & shakin so startupfully between plays and deals that they ain't got no time for that. $1.8 million per year for travel is $5,000 per day. That's more than a day-of round-trip first-class flight on ANA ($20k today) from NYC to Tokyo every week. reply bombcar 15 hours agoparentFirst class flights are completely different from potato class, and private jets are so far above first class it's really hard to exactly explain how much. reply rrrrrrrrrrrryan 14 hours agorootparentYeah I don't think people realize that flying private means you don't have to go through security. You don't even have to go into the airport. You just drive up and walk onto the plane. For executives in a tight race with hundreds of millions of dollars on the line, where a schedule slipping even 1 day can matter, sometimes flying private does actually make financial sense. reply snakeyjake 13 hours agorootparent>For executives in a tight race with hundreds of millions of dollars on the line, where a schedule slipping even 1 day can matter, sometimes flying private does actually make financial sense. I'm not an executive. I would never disgrace my ancestors or embarrass my descendants by getting an MBA. But I have been around the block a few times and if you're in a situation where missing a flight will torpedo a \"hundred million dollar\" deal you're a shitty businessperson. It has been my experience that the best way to keep a schedule from slipping is for executives to keep their mouths shut, cloistered in their office, waiting for an assistant to build some slides for them. reply KingOfCoders 17 hours agoprev\"Family Foundation\" I wonder when the public wakes up and understands that rich people don't own anything \"personally\" so you can increase VAT and income tax just as much as you like to tax the rich. reply Schattenbaer 16 hours agoprevCanoo the car company, not Canoo the welcome-to-Canada app. In case you are confused by the headline, as I was reply baq 18 hours agoprevEnd of ZIRP was supposed to deal with shit like this. Looks like money is still too cheap. I've seen people saying rates are going higher from here back in 2022. While this isn't my base case, it certainly isn't impossible. reply moomoo11 18 hours agoparentRates should go to 15% without bailouts. Anyone who survives that deserves all of the rewards. reply cm2187 17 hours agorootparentThat may not include the US Treasury. reply lotsofpulp 17 hours agorootparentWhat would stop the US Treasury from printing as much cash as needed to pay its debt? reply cm2187 17 hours agorootparentInflation reply lotsofpulp 17 hours agorootparentI would bet on the US federal government printing money to pay debts rather than default. reply monero-xmr 18 hours agoprevI also love when startups brag about headcount. You know what's impressive? Revenue, followed by profit, and also profit per employee. Having 500 people and no revenue leads to the graveyard. reply tadfisher 18 hours agoparentNo, it leads to layoffs, a statement about \"optimizing operational costs\", and a bump in valuation in today's weird market. reply lenerdenator 17 hours agorootparentThe market isn't weird; it's working exactly as intended: Do whatever it takes to make the number at the bottom of the page bigger than what people predicted it would be at the start of the quarter. If that means screwing some people's career trajectories, do it. If it means parting out divisions of the company that had strategic value, do it. If it means allegedly murdering a whistleblower, do it. reply tsunamifury 17 hours agorootparentThis is interesting because it doesn't mean that actually, it means if you want to make that choice the market will reward you now, and the market may not be focused on any one specific strategy. You can make other choices. reply bananapub 14 hours agoprevon the one hand, it's obviously stupid and a preposterous waste of resources, on the other hand, it's a moral good to incinerate VC money if the VC are so fucking stupid as to give it to idiots like this guy. so who's to say which is better. reply causi 17 hours agoprevLoss to revenue ratio of 350 to 1 Well, shoot. I thought the truck looked really cool. reply markstos 18 hours agoprevIt’s OK because Elon uses a private jet and look at Tesla! reply justinclift 17 hours agoparentGive it a few years and Elon may actually be able to use Starships for travelling around. Not sure how that'll look on the financial statements. ;) reply mypalmike 18 hours agoparentprevCorporate cargo culting. reply gravescale 17 hours agorootparentI worked for a company under a big corporate. Or they thought they were. Lots of Big Business Talk, earnest Reports (not sure if they were TPS but they might as well have been) and lots of Management Structuring, no actual products except for things already made by acquisitions. It reminded me strongly of the Mattel boardroom in Barbie. reply usrusr 17 hours agoprev [–] > Under a deal reached in November 2020, Canoo reimburses Aquila Family Ventures, an entity owned by the CEO, for use of an aircraft. Any guess how much of that money actually went into operating the aircraft, and how much was skimmed by the CEO? Madness either way, but we can't have it filed under the wrong kind of madness, right? reply bryanlarsen 17 hours agoparent [–] If he's skimming, it's not enough to immediately stand out. They reimbursed $1.3 - $1.8 million per year, which is about how much it costs to operate a private jet. reply bombcar 17 hours agorootparent [–] A random search indicates that the amount is well within annual parameters: https://www.libertyjet.com/jet-ownership-costs.aspx?jetType=... Note that the capital outlay for a jet is a minor portion of the total operating budget over the years. Fuel and crew is the major component especially with smaller jets. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Canoo, an EV startup, spent double its annual revenue on CEO Tony Aquila's private jet in 2023, totaling $1.7 million.",
      "Despite reporting $886,000 in revenue and facing significant losses, Canoo is striving to scale up electric vehicle production to prevent bankruptcy, distinguishing itself from struggling EV startups.",
      "Canoo aims to achieve a revenue forecast between $50 million to $100 million in 2024, highlighting its ambitious growth plans amidst financial challenges."
    ],
    "commentSummary": [
      "The Canoo CEO's use of his private jet, reimbursing the company while investing personal funds, sparks controversy over excessive spending and possible conflicts of interest.",
      "The debate extends to creating new cars versus leveraging existing platforms, the influence of electric vehicles on the automotive sector, and the ethics surrounding CEO expenses and financial choices.",
      "Discussions also cover broader societal issues, government policies, and personal encounters concerning COVID-19, immigration, and corporate governance."
    ],
    "points": 285,
    "commentCount": 236,
    "retryCount": 0,
    "time": 1712072018
  },
  {
    "id": 39907468,
    "title": "Princeton Unveils \"SWE-agent\" for GitHub with 12% Fix Rate",
    "originLink": "https://github.com/princeton-nlp/SWE-agent",
    "originBody": "Website & DemoDiscordPaper [coming April 10th] 👋 Overview SWE-agent turns LMs (e.g. GPT-4) into software engineering agents that can fix bugs and issues in real GitHub repositories. On the full SWE-bench test set, SWE-agent resolves 12.29% of issues, achieving the state-of-the-art performance on the full test set. ✨ Agent-Computer Interface (ACI) We accomplish these results by designing simple LM-centric commands and feedback formats to make it easier for the LM to browse the repository, view, edit and execute code files. We call this an Agent-Computer Interface (ACI) and build the SWE-agent repository to make it easy to iterate on ACI design for repository-level coding agents. Just like how typical language models requires good prompt engineering, good ACI design leads to much better results when using agents. As we show in our paper, a baseline agent without a well-tuned ACI does much worse than SWE-agent. SWE-agent contains features that we discovered to be immensly helpful during the agent-computer interface design process: We add a linter that runs when an edit command is issued, and do not let the edit command go through if the code isn't syntactically correct. We supply the agent with a special-built file viewer, instead of having it just cat files. We found that this file viewer works best when displaying just 100 lines in each turn. The file editor that we built has commands for scrolling up and down and for performing a search within the file. We supply the agent with a special-built full-directory string searching command. We found that it was important for this tool to succintly list the matches- we simply list each file that had at least one match. Showing the model more context about each match proved to be too confusing for the model. When commands have an empty output we return a message saying \"Your command ran successfully and did not produce any output.\" Read our paper for more details. @misc{yang2024sweagent, title={SWE-agent: Agent Computer Interfaces Enable Software Engineering Language Models}, author={John Yang and Carlos E. Jimenez and Alexander Wettig and Shunyu Yao and Karthik Narasimhan and Ofir Press}, year={2024}, } 🚀 Setup Install Docker, then start Docker locally. Install Miniconda, then create the swe-agent environment with conda env create -f environment.yml Activate using conda activate swe-agent. Run ./setup.sh to create the swe-agent docker image. Create a keys.cfg file at the root of this repository and fill in the following: OPENAI_API_KEY: 'OpenAI API Key Here if using OpenAI Model (optional)' ANTHROPIC_API_KEY: 'Anthropic API Key Here if using Anthropic Model (optional)' GITHUB_TOKEN: 'GitHub Token Here (required)' See the following links for tutorials on obtaining Anthropic, OpenAI, and Github tokens. 💽 Usage There are two steps to the SWE-agent pipeline. First SWE-agent takes an input GitHub issue and returns a pull request that attempts to fix it. We call that step inference. The second step (currently, only available for issues in the SWE-bench benchmark) is to evaluate the pull request to verify that it has indeed fixed the issue. NOTE: At this moment, there are known issues with a small number of repositories that don't install properly for arm64 / aarch64 architecture computers. We're working on a fix, but if you'd like to run and evaluate on the entirety of SWE-bench, the easiest way is by using an x86 machine. 👩💻 Inference Inference on any GitHub Issue: Using this script, you can run SWE-agent on any GitHub issue! python run.py --model_name gpt4 \\ --data_path https://github.com/pvlib/pvlib-python/issues/1603 --config_file config/default_from_url.yaml Inference on SWE-bench: Run SWE-agent on SWE-bench Lite and generate patches. python run.py --model_name gpt4 \\ --per_instance_cost_limit 2.00 \\ --config_file ./config/default.yaml If you'd like to run on a single issue from SWE-bench, use the --instance_filter option as follows: python run.py --model_name gpt4 \\ --instance_filter marshmallow-code__marshmallow-1359 See the scripts/ folder for other useful scripts and details. See the config/ folder for details about how you can define your own configuration! See the swe-agent/agent/ folder for details about the logic behind configuration based workflows. See the swe-agent/environment/ folder for details about the SWEEnv environment (interface + implementation). See the trajectories/ folder for details about the output of run.py. 🧪 Evaluation This step is only available for issues from the SWE-bench set. To evaluate generated pull requests: cd evaluation/ ./run_eval.shReplacewith the path to the model's predictions, which should be generated from the Inference step. Thearguments should look like ../trajectories//--/all_preds.jsonl See the evaluation/ folder for details about how evaluation works. 💫 Contributions If you'd like to ask questions, learn about upcoming features, and participate in future development, join our Discord community! If you'd like to contribute to the codebase, we welcome issues and pull requests! If you'd like to see a post or tutorial about some topic, please let us know via an issue. 🪪 License MIT. Check LICENSE.",
    "commentLink": "https://news.ycombinator.com/item?id=39907468",
    "commentBody": "Princeton group open sources \"SWE-agent\", with 12% fix rate for GitHub issues (github.com/princeton-nlp)276 points by asteroidz 17 hours agohidepastfavorite122 comments dimal 11 hours agoThe demo shows a very clearly written bug report about a matrix operation that’s producing an unexpected output. Umm… no. Most bug reports you get in the wild are more along the lines of “I clicked on on X and Y happened” then if you’re lucky they’ll say “and I expected Z”. Usually the Z expectation is left for the reader to fill in because as human users we understand the expectations. The difficulty in fixing a bug is in figuring out what’s causing the bug. If you know it’s caused by an incorrect operation, and we know that LLMs can fix simple defects like this, what does this prove? Has anyone dug through the paper yet to see what the rest of the issues look like? And what the diffs look like? I suppose I’ll try when I have a sec. reply jcarrano 34 minutes agoparentMaybe it would be better if the agent would help people submit better reports instead of trying to fix it. E.g. it could ask them to add missing information, test different combinations of inputs, etc. I could also learn which maintainer to ping according to the type of issue. reply drcode 11 hours agoparentprev> Most bug reports you get in the wild are more along the lines of Since this fixes 12% of the bugs, the authors of the paper probably agree with you that 100-12= 88%, and hence \"most bugs\" don't have nicely written bug reports. reply medellin 7 hours agorootparentIn my 15 years i would say less than 1% of bug reports are like this. If you know the bug to this level most people just would fix it themselves reply aiauthoritydev2 5 hours agorootparentprev12% is a very very large number for that kind of problem. I doubt even 0.1% of bug reports in the wild are that well written. reply sitkack 1 hour agorootparentHave the LLM rewrite the bug reports. reply littlestymaar 2 hours agorootparentprevExcept this is automated, so you could get multiples orders of magnitude more bug filled, so you need to have a very low false positive ratio to avoid being overwhelmed by automatically generated crap (which is basically spam). reply skywhopper 8 hours agorootparentprevIt fixes 12% of their benchmark suite, not 12% of bug reports. reply dimal 10 hours agorootparentprevI suppose I should nail down my point. No one would ever write a big report like this. A bug generally has an unknown cause. Once you found the cause of the bug, you’d fix it. Nowadays, you could just cut and paste the problem into ChatGPT and get the answer right then. So why would anyone ever log this bug? All this demo proves that they automated a process that didn’t need automation. reply hvis 10 hours agorootparentTo be fair, sometimes meticulous users investigate the bugs and write down logical chains explaining the causes and even offer a solution at the end (which they can't apply for the lack of commit access, for instance). The proposed solution isn't always right, of course, but it would be incorrect to say that no bug reports come with a diagnosed cause. But that's exactly where a conscious reviewer is most needed, I believe. reply citrin_ru 2 hours agorootparentI sometimes write a detailed bug reports but not a PR when there are different ways to address the problem (and all look bad to me) or the fix can introduce new problems. But I would expect LLM to ignore tradeoffs and choose an option which not necessarily the best for the same reason I hesitate - luck of understanding of this specific project. reply stingraycharles 4 hours agoparentprevIt appears that they’re using the PRs from the top5000 most popular PyPi packages for their bench: https://github.com/princeton-nlp/SWE-bench/tree/main/swebenc... reply bee_rider 6 hours agoparentprevMaybe it just needs another, independent tool. One that detects poorly written bug reports and rejects them. A cool thing about LLM is they have infinite patience. They can go back and forth with the user until they either sort out how to make a useable bug report, or give up. reply bfdm 6 hours agorootparentWhile it might tickle metrics the right way, frustrating a user into giving up because your bot was not satisfied is not solving their problem. reply throwup238 4 hours agorootparentI think that depends on the exact KPI. reply ffsm8 1 hour agorootparentKPI stands for key performance indicator. It is a tool to grade people or teams by applying numbers to their work. The only relationship you can have between these is that a ticked with a \"resolved\" status can be used as a KPI, but you're trying to invert the relationship here, which doesn't work. After all, it's an indicator, not a causal relationship reply codeonline 7 hours agoparentprevI agree that bugs aren't as well specified as the example. But a specification for a new feature certainly can be. I'm going to give it a try on my side project and see if it can at least provide a hint or some guidance on the development of small new features in an existing well structured project. reply forty 2 hours agoparentprevThe trick is that people would use LLM to write very long and detailed bug reports :p reply megablast 9 hours agoparentprevExactly. This is not perfect and doesn't fix every report so it is useless. reply skywhopper 7 hours agorootparentOn the contrary, it’s worse than useless. If it could fix 12% of bugs (it can’t — it only fixes 12% of their benchmark suite), you’d still have to figure out which 12% of the responses it gave were good. So, 88% of the time you’d have wasted time confirming a “fix” that doesn’t work. But it’s worse than that. Because even on the fixes it got right, you’d still have to fully vet it, because this tool doesn’t know when it can’t solve something, or ask for clarification. It just gives a wrong answer. So you didn’t save 12% of your effort, you wasted probably more than double your effort checking the work of a tool that is wrong eight out of nine times. reply anotherpaulg 13 hours agoprevVery cool project! I've experimented in this direction previously, but found agentic behavior is often chaotic and leads to long expensive sessions that go down a wrong rabbit hole and ultimately fail. It's great that you succeed on 12% of swe-bench, but what happens the other 88% of the time? Is it useless wasted work and token costs? Or does it make useful progress that can be salvaged? Also, I think swe-bench is from your group, right? Have you made any attempt to characterize a \"skilled human upper bound\" score? I randomly sampled a dozen swe-bench tasks myself, and found that many were basically impossible for a skilled human to “solve”. Mainly because the tasks were under specified wrt to the hidden test cases that determine passing. The tests were checking implementation specific details from the repo’s PR that weren't actually stated requirements of the task. reply a_wild_dandan 13 hours agoparentPersonally, I'd just use one of my local MacBook models (e.g. Mixtral 8x7b) and forget about any wasted branches & cents. My debugging time costs many orders of magnitude more than SWE-agent, so even a 5% backlog savings would be spectacular! reply swatcoder 11 hours agorootparent> My debugging time costs many orders of magnitude more than SWE-agent Unless your job is primarily to clean up somebody else's mess, your debugging time is a key part of a career-long feedback loop that improves your craft. Be careful not to shrug it off as something less. Many many people are spending a lot of money to let you forget it, and once you do, you'll be right there in the ranks of the cheaply replaceble. (And on the odd chance that cleaning up other people's mess is your job, you should probably be the one doing it; and for largely the same reasons) reply nickpsecurity 10 hours agorootparentI totally agree. My solution to this was limiting my AI use to (a) whatever didn't impair creativity and (b) just in general to keep the brain sharp. If using AI regularly, one could just manually solve a percentage of the problems. reply ein0p 12 hours agorootparentprevI’ve tried this with another similar system. FOSS LLMs including Mixtral are currently too weak to handle something like this. For me they run out of steam after only a few turns and start going in circles unproductively reply Aperocky 11 hours agorootparentprevThat's assuming that the other 95% stays the same with this new agent (vs creating more work for you to now also have to parse what the model is saying). reply int_19h 8 hours agorootparentprevGiven that they got 12% with GPT-4, which is vastly better than any open model, I doubt this would be particularly productive. And powering compute at full load is going to add up. reply senko 3 hours agoparentprevIf you don't mind me asking, which agentic tools/frameworks have you tried for code fixing/generation, with which LLMs? reply JonChesterfield 4 hours agoprevIf AI generated pull requests become a popular thing we'll see the end of public bug trackers. (not because bugs will be gone - because the cost of reviewing the PR vs the benefit gained to the project will be a substantial net loss) reply CGamesPlay 3 hours agoparentNot a chance. If AI-generated pull requests become popular, GitHub will automatically offer them in response to opened issues. Case in point: they already are popular for dependency upgrades. reply JonChesterfield 3 hours agorootparentAnd thus issues will no longer be opened reply itsgrimetime 3 hours agoparentprevIt’ll likely keep getting better, if it gets to 30-40% I’d say that’s a decent trade off. Also could you boost your chances by having the AI do a 2nd pass and double check the work? I’d be curious what the success rate of an LLM “determining whether a bug fix is valid” is reply matthewaveryusa 14 hours agoprevVery neat. Uses the langchain method, here are some of the prompts: https://github.com/princeton-nlp/SWE-agent/blob/main/config/... reply toddmorey 13 hours agoparentI’m always fascinated to read the system prompts & I always wonder what sort of gains can be made optimizing them further. Once I’m back on desktop I want to look at the gut history of this file. reply clement_b 12 hours agorootparentI have a git feeling this comment was written on mobile. reply hazn 10 hours agorootparentprevDSPy is the best tool for optimizing prompts [0]: https://github.com/stanfordnlp/dspy Think of it as a meta-prompt optimizer, it uses a LLM to optimize your prompts, to optimize your LLM. reply toddmorey 10 hours agorootparentExcellent! Thanks for sharing this! reply lispisok 13 hours agoprevTheir demo is so similar to the Devin one I had to go look up the Devin one to check I wasnt watching the same demo. I feel like there might be a reason they both picked Sympy. Also I rarely put weight into demos. They are usually cherry-picked at best and outright fabricated at worst. I want to hear what 3rd parties have to say after trying these things. reply lewhoo 12 hours agoparentMaybe that's the point of this research. Hey look, we reproduced the way to game the stats a bit. I really can't tell anymore. reply paradite 12 hours agoprevFor anyone who didn't bother looking deeper, the SWEbench benchmark contains only Python code projects, so it is not representative of all the programing languages and frameworks. I'm working on a more general SWE task eval framework in JS for arbitrary language and framework now (for starter JS/TS, SQL and Python), for my own prompt engineering product. Hit me up if you are interested. reply barfbagginus 9 hours agoparentAssuming the data set is proprietary, else please share the repo reply danenania 12 hours agoprevI'm working on a somewhat similar project: https://github.com/plandex-ai/plandex While the overall goal is to build arbitrarily large, complex features and projects that are too much for ChatGPT or IDE-based tools, another aspect that I've put a lot of focus on is how to handle mistakes and corrections when the model starts going off the rails. Changes are accumulated in a protected sandbox separate from your project files, a diff review TUI is included that allows for bad changes to be rejected, all actions are version-controlled so you can easily go backwards and try a different approach, and branches are also included for trying out multiple approaches. I think nailing this developer-AI feedback loop is the key to getting authentic productivity gains. We shouldn't just ask how well a coding tool can pass benchmarks, but what the failure case looks like when things go wrong. reply barfbagginus 8 hours agoparentHow open are you to moving plandex cloud over to AGPL? I know, tough ask right out the gate! Think about that one for a bit. How is your market testing going? Do you have contracts with clients amenable to let you write case studies? Do you need help selling, designing, or fulfilling these kinds of pilot contacts? What are your plans for docs a PR? As a researcher, it's currently hard to situate plandex against existing research, or anticipate where a technical contribution is needed. As a business owner, it's currently hard to visualize plandex's impact on a business workflow. Are you open to producing a technical report? Detail plandex methodology, benchmark efficiency, ablation tests for key contributions, customer case studies, relevant research papers, and next steps/help needed. What do you think? If plandex is interested in being a fully open org, then I'd be interested in seeing it find its market footing and grow its technical capabilities. We need open source orgs like this! reply danenania 6 hours agorootparentIt’s AGPL licensed already :) reply etheridev 11 hours agoparentprevYou need to make yourself a business analyst agent to provide the feedback! To make it real, perhaps a team of them with conflicting personalities. reply danenania 11 hours agorootparentI think we'll get there at some point, but one thing I've learned from this project is how difficult it is to stack AI interactions. Each little bit of AI-based logic that gets added tends to fail terribly at first. Only after a long period of intense testing and iteration does it become remotely usable. The more you are combining different kinds of tasks, the more difficult it gets. reply panqueca 8 hours agoparentprevDoes it work with a large existing codebase? reply danenania 8 hours agorootparentYes, at least up to the point of the context limit of the underlying model. If you needed to go beyond that, you would break the work up into separate \"plans\" (a plan is a set of tasks with an attached context and conversation). The general workflow is to load some relevant context (could be a few files, an entire directory, a glob pattern, a URL, or piped in data), then send a prompt. Quick example: plandex new plandex load components/some-component.ts lib/api.ts package.json https://react.dev/reference/react/hooks plan tell \"Update the component in components/some- components.ts to load data from the 'fetchFooBars' function in 'lib/api.ts' and then display it in a datagrid. Use a suitable datagrid library.\" From there the plan will start streaming. Existing files will be updated and new files created as needed. One thing I like about it for large codebases compared to IDE-based tools I've tried is that it gives me precise control over context. A lot of tools try to index the whole codebase and it's pretty opaque--you never really know what the model is working with. reply rwmj 12 hours agoprevDo we know how much extra work it created for the real people who had to review the proposed fixes? reply r0ze-at-hn 11 hours agoparentAh, well let me tell you about my pull request reviewer LLM project. reply ActionHank 10 hours agorootparentJokes on you, let me tell you about my prompt to binary LLM project. Hello world is 10GB, but even grandma can make hello worlds now. reply Havoc 9 hours agorootparentBut does it contain a heavily obfuscated back door? reply labster 4 hours agorootparentWhy does it take so long to get changes to your LLM merged? This is ridiculous. Please appoint Havoc as a maintainer already. reply peteradio 9 hours agorootparentprevLet me tell you about my LLM project called grandma. It's fine tuned in order to replace your grandma but in principle it could replace your great-grandma. reply barfbagginus 9 hours agorootparentMy grandma used to tell me stories about how to destroy capitalism.. I miss her.. can your grandma help guide my revolutionary efforts? That would really help me honor my granny's memory12% improvement is not bad for two years either (I'm somewhat arbitrary picking the release date of ChatGPT). If this can be kept up for a few years we will have some extremely useful tooling. The cost can be relatively high as well, since engineering time is currently orders of magnitude more expensive than these tools. reply SrslyJosh 37 minutes agoparentIf someone submitted 8 PRs and 7 of them were bullshit, I would close anything else they submitted in the future without even bothering to review. reply blharr 12 hours agoparentprevI still don't know. I feel like there are many ways where GPT will write some code or fix a bug in a way that makes it significantly harder to debug. Even for relatively simple tasks, it's kind of like machine-generated code that I would not want to touch. reply WanderPanda 12 hours agorootparentIt is a bit worrisome but we manage to deal with subpar human code as well. Often the boilerplate generated by ChatGPT is already better than what an unexperienced coder would string together. I‘m sure it will not be a free lunch but the the benefits will probably outweigh the downsides. Interesting scalability questions will arise wrt to security when scaling the already unmanagably large code bases by another magnitude (or two), though. reply golergka 13 hours agoparentprevIt's still abysmal from POV of actually using it in production, but it's a very impressive rate of improvement. Given what happened with LLMs and image generation in the last few years, we can probably assume that these systems will be able to fix most trivial bugs pretty soon. reply stefan_ 12 hours agoparentprevThese „benchmark“ are tuned around reporting some exciting result, once you look inside, all the „fixes“ are trash. reply trebligdivad 12 hours agoprevSo this issues arbitrary shell commands based on trying to understand the untrusted bug text ? Should be fun waiting until someone finds an escape. reply Frummy 13 hours agoprevInteresting idea to provide the Agent-Computer Interface for it to scroll and such, interact easier from its perspective reply aussieguy1234 12 hours agoparentSimilar to how early computers didn't have enough ram to display the whole text file, so old programmers had to work with parts of the file at a time. It's not a bad way to get around the context window problem, which is kind of similar. reply mdaniel 14 hours agoprevI think that \"Demo\" link is just an extremely annoying version of an HTML presentation, so they could save me a shitload of clicking if they just dumped their presentation out to a PDF or whatever so I could read faster than watching it type out text as if it was live. It also whines a lot on the console about its inability to connect to a websocket server on 3000 but I don't know what it would do with a websocket connection if had it reply SrslyJosh 31 minutes agoparentProbably created with an LLM. reply iLoveOncall 14 hours agoprevAnd creates how many new ones? This and Devin generate garbage code that will make any codebase worse. It's a joke that 12.5% is even associated with the word \"success\". reply 1letterunixname 14 hours agoparentDo spaces and spelling fixes count? Copilot, so far, is only good for predicting the next bit of similar patterns of code reply readthenotes1 11 hours agoprevI made a lot of money as I was paid hourly while working with a cadre of people I called \"the defect generators\". I'm kind of sad that future generations will not have that experience... reply sumeruchat 12 hours agoprevOnce we have this fully automated, any good developer could have a team of 100 robo SWEs and ship like crazy. The real competition is with those devs not with the bots. reply recursive 11 hours agoparentShipping like crazy isn't useful by itself. Shipping non-garbage and being able to maintain it still has some value. reply sumeruchat 8 hours agorootparentWould you say cloning a complex saas startup in a week with payments integrated after letting AI just scrape them (or uploading screenshots of their app) is creating value? reply gloosx 4 hours agorootparentBefore you sold it to anyone it will only create bills. Development is such a minuscule part of a successful startup reply int_19h 8 hours agorootparentprevDepends on how many security vulnerabilities are in that payments system. Or, I suppose, depending on whose value. The consultants that'll have to be hired by the poor shmuck who paid for that will make a fortune auditing and cleaning up the code. reply recursive 7 hours agorootparentprevNot without more information. reply noncoml 13 hours agoprev [–] If you are afraid that LLMs will replace you at your job, ask an LLM to write Rust code for reading a utf8 file character by character Edit: Yes, it does write some code that is \"close\" enough, but in some cases it is wrong, in others it doesn't not do exactly what asked. I.e. needs supervision from someone who understands both the requirements, the code and the problems that may arise from the naive line that the LLM is taking. Mind you, the most popular the issue, the better the line LLM is taking. So in other words, IMHO is a glorified Stack Overflow. Just as there are engineers that copy-paste from SO without having any idea what the code does, there will be engineers that will just copy paste from LLM. Their work will be much better than if they used SO, but I think it's still nowhere to the mark of a Senior SWE and above. reply raggi 13 hours agoparentit does an ok job with this task: use std::fs::File; use std::io::{self, BufReader, Read}; fn read_file_character_by_character(path: &str) -> io::Result { // Open the file in read-only mode. let file = File::open(path)?; // Create a buffered reader to read the file more efficiently. let reader = BufReader::new(file); // `chars` method returns an iterator over the characters of the input. // Note that it returns a Result, where usize is the byte length of the char. for char_result in reader.chars() { match char_result { Ok(c) => print!(\"{}\", c), Err(e) => return Err(e), } } Ok(()) } fn main() { let path = \"path/to/your/file.txt\"; if let Err(e) = read_file_character_by_character(path) { eprintln!(\"Error reading file: {}\", e); } } reply comex 13 hours agorootparentOnly problem is that the critical `chars` method doesn't actually exist. Rust's standard library has a `chars` method for strings, but not for Readers. (Also, the comment about the iterator element type is inconsistent with the code following it. Based on the comment, `c` would be of type `(char, usize)`, but then trying to print it with {} would fail because tuples don't implement Display.) reply raggi 13 hours agorootparentgood catch. feeding it the error output of rustc it then produces: use std::fs::File; use std::io::{self, Read}; fn read_file_character_by_character(path: &str) -> io::Result { let mut file = File::open(path)?; let mut contents = String::new(); file.read_to_string(&mut contents)?; for c in contents.chars() { println!(\"{}\", c); } Ok(()) } fn main() { let path = \"path/to/your/file.txt\"; if let Err(e) = read_file_character_by_character(path) { eprintln!(\"Error reading file: {}\", e); } } reply phaer 12 hours agorootparentBut this doesn't read the file char-by-char, but uses buffering to read it into a string reply scottlamb 11 hours agorootparentWhat would you expect? There's no OS API for \"read one character\", except in say ASCII where 1 byte = 1 code point = 1 character. And it'd be hideously inefficient anyway. So you either loop over getting the next N bytes and getting all complete characters so far (with some extra complexity around characters that cross chunk boundaries) or you read the whole thing into a single buffer and iterate the characters. This code does the latter. If this tool doesn't have the ability to respond by asking requirements questions, I'd consider either choice valid. Of course, in real life, I do expect to get requirements questions back from an engineer when I assign a task. Seems more practical than anticipating everything up-front into the perfect specification/prompt. Why shouldn't I expect the same from an LLM-based tool? Are any of them set up to do that? reply 1letterunixname 9 hours agorootparentThere most certainly is getwchar() and fgetwc()/getwc() on anything that's POSIX C95, so that's more or less everything that's not a vintage antique. Reading individual UTF-8 codepoints is a trivial exercise if byte width getchar() were available, and portable C code to do so would be able to run on anything made after 1982. IIRC, they don't teach how to write portable C code in Comp Sci programs anymore and it's a shame. Never read a file completely into memory at once unless there is zero chance of it being a huge file because this is an obvious DoS vector and waste of resources. reply scottlamb 8 hours agorootparent> There most certainly is getwchar() and fgetwc()/getwc() on anything that's POSIX C95, so that's more or less everything that's not a vintage antique. Apologies for the imprecision: by OS API, I meant syscall, at least on POSIX systems. The functions you refer to are C stdio things. Note also they implement on top of read(2) one of the two options I mentioned: \"loop over getting the next N bytes and getting all complete characters so far (with some extra complexity around characters that cross chunk boundaries)\". btw, if we're being precise, getwchar gets a code point, and character might mean grapheme instead. Same is true for the `str::chars` call in the LLM's Rust snippet. The docstring for that method mentions this [1] because it was written in this century after people thought about this stuff a bit. > portable C code to do so would be able to run on anything made after 1982. Our comments are part of a thread discussing this prompt [2] that specifically requests Rust and this snippet in response [3]. Not portable C code. You can use those C stdio functions from Rust, but you really shouldn't without a very good reason. Rust has its own IO library that is safe and well integrated with other Rust things like `#![derive(Debug)]`. [1] https://doc.rust-lang.org/std/primitive.str.html#method.char... [2] https://news.ycombinator.com/item?id=39910542 [3] https://news.ycombinator.com/item?id=39910542 reply 1letterunixname 4 hours agorootparentYes, the userland side presented such as with POSIX like ssize_t read(int fd, void* buf, size_t count). Calling that with count = 1 each time would be wasteful, but certainly libc's have been buffering this since at least the 1980's. I remember this was the case with Borland C/C++. > Our comments are part of a thread discussing this prompt [2] that specifically requests Rust and this snippet in response [3]. Not portable C code. You can use those C stdio functions from Rust, but you really shouldn't without a very good reason. Rust has its own IO library that is safe and well integrated with other Rust things like `#![derive(Debug)]`. Duh. It doesn't really matter what Rust has have went it comes to enabling the use of specific edge-case performance improvements for specific purposes. Inefficient AI-generated code without a clue of other approaches doesn't move the needle. Religious purity doesn't matter, only results matter. reply deathanatos 12 hours agorootparentprevOn errors, it exits with success. reply 1letterunixname 10 hours agorootparentprevA few notes: - It should be generating `path: impl AsRef` to be properly generic. - It's not setting a nonzero exit code on error. - Edge case handling is a vital property for production-usable tools at scale. I'm wondering if it can yet special case situations such as creating a conditional compilation version for Linux that uses the splice syscall when the arguments are 2 file handles. reply raggi 13 hours agorootparentprevfwiw, the benchmark that matters really has nothing to do with authoring code. the typing of code is the easy part even though it's a part a lot of folks are somewhat addicted to. the things which have far more value are applying value judgements to requirements, correlating and incorporating sparse and inaccurate diagnostic information into a coherent debugging strategy, and so on. there will come a time when it can assist with these too, probably first on requirements distillation, but for more complex debugging tasks that's a novel problem solving area that we've yet to see substantial movement on. so if you want to stave off the robots coming for you, get good at debugging hard problems, and learn to make really great use of tools that accelerate the typing out of solutions to baseline product requirements. reply woodruffw 13 hours agorootparentprevIf we're being sticklers, this isn't reading character-by-character: it's performing a buffered read, which then gets iterated over. reply raggi 13 hours agorootparenthere's what it does if i feed your nit pick into it verbatim: use std::fs::File; use std::io::{self, Read}; use std::str::from_utf8; fn read_file_character_by_character(path: &str) -> io::Result { // Open the file in read-only mode. let mut file = File::open(path)?; let mut buffer = [0; 4]; // UTF-8 character max byte length let mut temp_buffer = vec![]; while let Ok(bytes_read) = file.read(&mut buffer[..1]) { // Read byte by byte if bytes_read == 0 { // End of file break; } temp_buffer.push(buffer[0]); if let Ok(s) = from_utf8(&temp_buffer) { if s.chars().count() == 1 { // Complete character read print!(\"{}\", s); temp_buffer.clear(); // Clear temp buffer for next character } } } Ok(()) } fn main() { let path = \"path/to/your/file.txt\"; if let Err(e) = read_file_character_by_character(path) { eprintln!(\"Error reading file: {}\", e); } } reply comex 13 hours agorootparentUnlike the original version, this version compiles and seems to basically work correctly. However, the design is misleading: `buffer` is declared as an array of 4 bytes but only the first byte is ever used. The code also has suboptimal performance and error handling, though that's not the end of the world. reply raggi 13 hours agorootparentall true, as I said in another fork of the thread, this comes down to part of what humans will still be valuable for in this loop: distilling poor requirements into better requirements. reply deathanatos 12 hours agorootparentprevThe original prompt is a bit under-specified. (But hey, that certainly matches the real world!) You're going to have to buffer at least a little, to figure out where the USV / grapheme boundary is, depending on our definition of \"character\". To me, a BufReader is appropriate here; it avoids lots of tiny reads to the kernel, which is probably the right behavior in a real case. To me, \"read character by character\" vaguely implies something that's going to yield a stream of characters. (Again, for some definition there.) reply noncoml 12 hours agorootparentprevI wouldn't say it's a nit. The file may be 10s of GB. Do you want to read it to a string? reply raggi 10 hours agorootparentThe buffered read didn’t do that, it used the default buffered reader implementation. IIRC that implementation currently defaults to 8kb buffer windows which is a little too small to be efficient enough for high throughput, but substantially more performant than making a syscall per byte, and without spending too much memory. reply noncoml 9 hours agorootparentI was talking about this: let mut file = File::open(path)?; let mut contents = String::new(); file.read_to_string(&mut contents)?; reply vineyardmike 13 hours agoparentprevYea the problem with that is the control group - grab any SWE and ask them the same thing. I don’t think most would pass. Unless you want to give an SWE time to learn… then it’s hardly fair. And I vaguely trust the LLM to be able to learn it too. Also I just asked Claude and Gemini and they both provided an implementation that matches the “bytes to UTF-8” rust docs. Assuming those are right,LLMs can do this (but I haven’t tested the code). https://doc.rust-lang.org/std/string/struct.String.html reply userbinator 10 hours agoparentprevI'm not afraid of LLMs replacing me because of their output quality. The problem is the proliferation of quantity-over-quality \"churn out barely-working crap as fast as possible\" culture that gives LLMs the advantage over real humans. reply int_19h 8 hours agorootparentI'm kinda hoping that LLMs will get pushed into production use writing code before they have acceptable quality (because greed), and the result will be lots of crap that's so badly broken most of the time that there will be a massive pushback against said culture from the users. Maybe from the governments as well, after a few well-publicized infrastructure failures. reply iwontberude 13 hours agoparentprevHypothetically, which ticker symbols would you buy put contracts on, at what strike prices, and at what expiration dates? As far as I can tell, a lot of people are betting a lot of money that you are wrong, but actually I think you are right. reply jeremyjh 13 hours agorootparentThe most relevant companies focused on this aren't publicly traded. The ones that are publicly traded like MSFT have way too many other factors affecting their value - not to mention the fact that they'll make money on generative AI that has nothing to do with coding regardless of if an SWE-agent ever works. reply iwontberude 10 hours agorootparentOh well you should hear the hype from CNBC and other places, they are strongly intimating that gen AI will replace SWEs on product development teams. I totally agree it’s not likely, but it’s starting to get baked into asset prices and I want to profit from that misunderstanding. reply noncoml 12 hours agorootparentprevUgh, I am not claiming that LLMs are not great innovation. Just that they are not going to replace SWE jobs in our(maybe my) lifetime. reply vertis 6 minutes agorootparentConservatively, I think LLMs will replace SWE roles within the next 5-10 years. In that period SWE roles will change drastically, to be more hearding of AI agents. We can't hope to compete with something that can edit all the files in less than 5 minutes. If you're not at least trying to plan what your life will look like under these circumstances then you're doing yourself a disservice. reply DabbyDabberson 13 hours agoparentprev [–] The way I see it, its undetermined if Generative AI will be able to fully do a SWE job. But, for most of the debates I've seen, I don't think it the answer matters all too much. Once we have models that can act as full senior SWEs.. the models can engineer the models. And then we've hit the recursive case. Once models can engineer models better and faster than humans, all bets are off. Its the foggy future. Its the singularity. reply vertis 5 minutes agorootparentPeople (SWEs) don't want to hear this. I think it's an inevitability that something of this nature will happen. reply dvt 12 hours agorootparentprev> Once we have models that can act as full senior SWEs.. the models can engineer the models. This is such an extremely bullish case, I'm not sure why you'd think this is even remotely possible. A Google search is usually more valuable than ChatGPT. For example, the rust utf-8 example is already verbatim solved on reddit: https://www.reddit.com/r/rust/comments/l5m1rw/how_can_i_effi... reply int_19h 8 hours agorootparentprev [–] The implicit assumption here is that a human \"senior SWE\" can engineer a model of the same quality that is capable of simulating him. Which is definitely not true with the best models that we have today - and they certainly can't simulate a senior SWE, so the actual bar is higher. I'm not saying that the whole \"robots building better robots\" thing is a pipedream, but given where things are today, this is not something that's going to happen soon. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The SWE-agent is a software engineering tool that leverages language models to address bugs in GitHub repositories effectively, showcasing cutting-edge performance.",
      "It employs an Agent-Computer Interface (ACI) to enhance LM browsing and editing functionalities, offering installation guidelines and usage instructions for running the SWE-agent pipeline on GitHub issues.",
      "Users can evaluate the tool on the SWE-bench set, with the opportunity for contributions and community involvement via Discord, although there is a known issue related to architecture compatibility."
    ],
    "commentSummary": [
      "AI tools, like the SWE-agent, are being debated for bug fixing and code generation, with doubts about their efficacy.",
      "Concerns exist regarding the quality and security of AI-generated code, along with overdependence on AI in software development.",
      "Despite the potential of AI in aiding with code tasks, human supervision and knowledge are still essential for maintaining software quality and precision."
    ],
    "points": 276,
    "commentCount": 122,
    "retryCount": 0,
    "time": 1712074567
  },
  {
    "id": 39909123,
    "title": "Visualizing Three-Body Dynamics Through Simulation",
    "originLink": "https://github.com/achristmascarl/three_body",
    "originBody": "✨ three_body a very rudimentary simulation of the three-body problem. i was curious how far we could get with just euler's method and a small time step, and it turns out we can get something pretty visually interesting! i was also curious about what would happen if the polar coordinates of the bodies over time were translated into rgb values and animated; the results are below. warning: some of the transitions from this orbit are pretty abrupt, so there may be flashing colors. sources the starting positions for the graphics above are for periodic orbit F10 from this paper: https://arxiv.org/abs/1805.07980 This is what F10 looks like when solved with ODE solver dop853 (according to the paper): as you can see, although the overall shape is similar/recognizeable, the error in the calculations above grow fairly noticeable after just 2 periods.",
    "commentLink": "https://news.ycombinator.com/item?id=39909123",
    "commentBody": "A rudimentary simulation of the three-body problem (github.com/achristmascarl)179 points by achristmascarl 15 hours agohidepastfavorite101 comments antognini 14 hours agoIf anyone is interested in playing around with gravitational dynamics I highly recommend the REBOUND library [1]. It has a simple Python interface but under the hood it has a collection of research grade integrators. It came out around the time I was finishing up my PhD in gravitational dynamics, but if I were still in the field it's what I'd be using. If you're curious what would happen to the Solar System if you made Jupiter 10 times more massive you can pip import the library and find out for yourself in about five minutes. [1]: https://github.com/hannorein/rebound reply lucgommans 12 hours agoparentIt's a hundred times less polished than rebound (that readme looks seriously cool!), but in 2021 I also wanted to toy around with orbital mechanics / gravity and couldn't find a quick and easy simulator so I made this to run in a browser: https://lucgommans.nl/p/badgravity/ Since it's so rough on the edges (especially on mobile, initially I was surprised it works at all), here's the steps for the mentioned example of making Jupiter 10x heavier: 1. Open the scenarios on the left and click play on the inner solar system to load that up 2. Click the plus on the outer planets to add them in (if it looks like nothing happened: zoom out. Space is big and this is to scale) 3. Fold out the \"bodies\" section and alter the mass for \"J\"upiter. The change is applied live. 4. Optionally press Restart to restart with the current settings but back at their initial positions and speeds Making Jupiter 1000× heavier (and fast-forwarding the time in the Simulator controls by 10×) makes it eject Mars from the solar system within one minute, but interestingly Mercury and Venus seem pretty stable around the sun in that configuration The help/about page (https://lucgommans.nl/p/badgravity/about.html) contains links to all other orbit projects I could find. Seeing Rebound as well as the OP, I should probably add a \"libraries\" section! Or do you think that should just go with \"Software to download\" alongside Stellarium and such? reply ricksunny 13 hours agoparentprevLooks awesome. I have a question that might be pedantic but I think you could speak to. Coming from an engineering mindset, I like the use of the term 'integrator' instead of 'solver'. In MATLAB, 'solvers' are used to iterate states of ODE models. But the term 'integrator' is more intuitive to me. Can you speak to the use of one term vs another in the ephemeris community? reply constantcrying 13 hours agorootparentSolver is a general term, it is just an algorithm which solves a certain problem. You have solvers for linear systems, PDEs, optimization problems, graph problems, etc. An integrator is an algorithm which allows the numerical approximation of the solution to an ODE, given that the ODE is written in a specific form where it is equivalent to calculating the integral of multiple functions. reply dreamcompiler 6 hours agorootparentprevYou can solve differential equations by integrating or by differentiating. Real-world integrators were easier to build back when DEs were solved with analog computers. Although \"easier\" is an understatement: Differentiators have a nasty habit of trying to blow up to infinity, which means you can't really build a good, general differentiator either with analog or digital electronics. Integrators are much better behaved pets and they don't shit on the carpet. So everybody uses integrators. Integrators have lots of issues too but those can be sufficiently mitigated for many classes of problems. Differentiators are mostly hopeless, feral beasts. reply nonfamous 13 hours agoprevThis account has been posting simulations of interesting 3-body scenarios for quite a while. It used to be on Twitter but moved to Mastodon. You can check out the archives and play the videos, it’s quite neat: https://botsin.space/@ThreeBodyBot reply hackernewds 4 hours agoparentHow is it random if the 3 body problems are chosen to have overlapping ellipses that look beautiful reply pixelesque 4 hours agorootparentRejection sampling? /s reply Hugsun 13 hours agoparentprevI love this bot, thanks for sharing! reply zelphirkalt 43 minutes agoprevIs there some way of determining, whether the orbits, given some starting parameters, _at some point_ will become stable? I probably mean periodic. And I probably mean mostly periodic, with only slight deviation from orbits. And I don't necessarily mean that we can calculate/predict what they will look like in a stable form. This reminds me of Langtons Ant, that has very simple rules, but at first still seems very chaotic. Then after some number of iterations it just shoots away in a regular endlessly regular repeating pattern. \"Order came from chaos.\" So it makes me think, maybe there is not a way to tell, whether the orbits \"stabilize\" at some point, but maybe they will, and we simply don't know when or how to tell? reply 7373737373 14 hours agoprevThere is this cool paper \"Crash test for the restricted three-body problem\" [0], that plots where the third body eventually ends up when dropped from any location. Looks very fractal-like [1][2] [0] https://scholar.archive.org/work/wnwgyliq5fgtba45k535t5lb5e/... [1] https://www.semanticscholar.org/paper/Crash-test-for-the-res... [2] https://www.semanticscholar.org/paper/Crash-test-for-the-res... reply jameshart 13 hours agoparent‘Strange attractors’: https://en.wikipedia.org/wiki/Attractor “An attractor is called strange if it has a fractal structure.” reply cl3misch 3 hours agorootparentThank you for reminding me of this beautiful field of mathematics. The best textbook I've ever read: Nonlinear Dynamics and Chaos by Steven Strogatz. reply mock-possum 5 hours agoparentprevLooks like fluid dynamics / turbulence to me reply DrFalkyn 2 hours agorootparentE&M and gravity are both n^2 forces, but E&M has polarity, whereas gravity (at least we encounter it) does not. reply badrunaway 1 hour agoprevWhat does three body problem tell us about our universe? It surprises me that universe by its nature ended up with such smart safeguards to disallow predictability via computation. reply micheljansen 1 hour agoprevI've been re-reading the trilogy lately and it also lead me to search for some three-body simulations. I noticed that a lot of them are simulating only a 2D space. Any good (animated) 3D simulations? Best I've been able to find so far are https://demonstrations.wolfram.com/ThreeBodyProblemIn3D/ and https://labs.sense-studios.com/threebody/index.html reply yieldcrv 19 minutes agoparentisn’t that story a 4-body problem? reply joe_the_user 13 hours agoprevOne of the first programs I ever wrote was a simulator for a planet rotating a star with a naive difference equation approximation to Newton's law. I was a bit disappointed to see the planet reliably spiral into the sun. The main thing is that something like Euler's method (naive iterative approximation) doesn't guarantee conservation of energy. I believe that this is why planetary dynamics are usually handled with Lagrangian equations rather than the naive approximation approach. Edit: It would be nice to see what the author's system does for two bodies as a sanity check. Three body system was indeed chaotic but still conserve energy - would this system do that? https://en.wikipedia.org/wiki/Lagrangian_mechanics reply FredFS456 13 hours agoparentI think symplectic integrators are typically used, which are derived from hamiltonian mechanics https://en.wikipedia.org/wiki/Symplectic_integrator reply zokier 13 hours agoparentprevIt's true that Euler integration is about as crude as you can get, but you don't need to reach to Lagrangians for improvement; something like Verlet integration can already bring dramatic gains with fairly small changes needed. reply _0ffh 12 hours agorootparentYes, I think it's probably the simplest symplectic method, which would be quite the improvement already. reply forgotpwd16 13 hours agoparentprevCan convert Euler's method to a symplectic integrator utilizing v_{n+1} when computing x_{n+1}. That said although such integrators are widely used (usually of higher order than Euler's) in celestial mechanics, one is not restricted to them. For example Bulirsch-Stoer is also very used even if it isn't symplectic because remains accurate (energy error very low) even on long integrations. reply dekhn 13 hours agoparentprevIt wasn't the first program I wrote, or even a program I wrote, but in middle school a friend wrote a 3-body integrator in BASIC (sun, earth, moon). That single 20 line program shaped my entire world view for a long time (decades), implying to me that we could, if we had powerful enough computers, simulate all sorts of things... even entire universes (which was also an idea that I explored with cellular automata). It's not a particularly helpful worldview and can often be harmful if you're working with complex systems, or systems that require more than o(n(log(n)) per step, or any number of other real-world problems scientists face. Many years later I was impressed at how well astronomy packages work (IE, \"it's time T at local L, what is the angle of the sun in the sky?\") and stumbled across this paper by Sussman: https://web.mit.edu/wisdom/www/ss-chaos.pdf which shows some pretty serious work on future prediction of solar system objects. reply forgotpwd16 12 hours agorootparent>simulate all sorts of things... even entire universes You also assumed that chaos is a measurement problem. You could simulate entire universe if you knew the initial conditions sufficiently enough. There were two nice recent papers[1][2] that showed in order to predict some orbits you'll need an accuracy less of Planck length or else some systems are fundamentally unpredictable. [1]: https://arxiv.org/abs/2002.04029 [2]: https://arxiv.org/abs/2311.07651 reply dekhn 12 hours agorootparentI'd love to see convincing evidence that we could simulate the universe using only standard physical laws. IIUC we don't have a way to do that or reliably say whether it's possible. It's also not that interesting a problem because it's so impractical. reply actionfromafar 11 hours agorootparentBut it would be interesting to see if we could simulate a universe and observe if it in any way resembled ours. Even if the simulated universe was much \"smaller\". (It would of course have to be.) reply dekhn 11 hours agorootparentI think you'd need to be a few rungs up the Kardashev scale to even contemplate this. reply actionfromafar 11 hours agorootparentThat may be ... plus we don't really know what to make of the observations around us, with dark matter and stuff. reply bufferoverflow 7 hours agorootparentprev> if we had powerful enough computers, simulate all sorts of things In reality, we're having a hard time precisely simulating even two atoms interacting, with all the quantum effects, diffraction, gravity (however minuscule), etc. Our universe is surprisingly detailed. 64-bit floats aren't even close enough to precisely simulate real world. What's the precision of the mass of an electron? What's the precision of its coordinates or motion vectors? Maybe plank length for coordinates, maybe not. What about acceleration? Can it be arbitrarily low? An electron's gravitational field from a billion light years away should theoretically affect us (in time). reply xvector 3 hours agorootparentThe assumption in your comment is that any of this is real to begin with and logic isn't being short-circuited in our brains to make everything \"check out\" even if it doesn't. If you simulate a universe with cube blocks from Minecraft, it doesn't matter as long as your users think the simulation is real. And since you are simulating their consciousness, you can easily short circuit the train of thought that would cause doubt, or that would attempt logic, etc., so they truly believe their Minecraft cube world is incomprehensibly detailed down to the atoms and galaxies in the sky. They'd happily go on the whiteboard, and prove their theories with math like 2+2=5 and everyone would agree because they literally couldn't disagree - they would feel in their hearts and minds that this is perfectly correct. There's nothing to say that's not happening now. In fact, this is how I see most advanced civilizations performing simulations. The compute savings would be immense if you could just alter user consciousness as opposed to simulating an actual universe. reply PeterisP 12 hours agoparentprevWould it make sense to explicitly implement conservation of energy? I.e. do a simple method but calculate the total energy at the beginning, and at each step adjust the speeds (e.g. proportionally) so that the total energy matches the initial value - you'll still always get some difference due to numerical accuracy issues, but that difference won't be growing over time. reply comicjk 8 hours agorootparentThe method you describe would be an example of what is called a \"thermostat\" in molecular dynamics (because the speed of molecules forms what we call temperature). Such adjustments to the speed can definitely paper over issues with your energy conservation, but you still have to be careful: if you rescale the speeds naively you get the \"flying ice cube\" effect where all internal motions of the system cease and it maintains its original energy simply by zooming away at high speed. https://en.wikipedia.org/wiki/Flying_ice_cube reply montecarl 3 hours agorootparentThermostats ensure that the average _kinetic energy_ remains constant (on average or instantaneously depending on how they are implemented). Your parent post wants to enforce the constraint that the total energy remains constant. So its a bit different from a canonical ensemble (NVT) simulation. This is a microcanonical ensemble simulation (NVE). This means you don't know if you should correct the position (controlling the potential energy) or the velocities (controlling the kinetic energy). Basically, there will be error in the positions and velocities due to the integrator used and you don't know how to patch it up. You have 1 constraint; the total energy should be constant. There are 2(3N-6) degrees of freedom for the positions and velocities (if more than 2 bodies). The extra constraint doesn't help much! Edit: Also, the only reason thermostats work is because the assumption is that the system is in equilibrium with a heat bath (i.e. bunch of atoms at constant temperature). So there is an entire distribution of velocities that is statistically valid and as long as the velocities of the atoms in the system reflect that, you will on average model the kinetics of the system properly (e.g. things like reaction rates will be right). In gravitational problems there is no heat bath. reply at_compile_time 14 hours agoprevIf you want to demonstrate why the three-body problem is chaotic, you can set it up to run a couple hundred very similar simulations in parallel. Just nudge each body by a tiny amount to simulate uncertainty in the initial conditions and watch the resulting configurations diverge as tiny differences become large differences. Rather than points, you get lines of probability that stretch out and wrap around each other. It's quite striking. Edit: semantics reply constantcrying 13 hours agoparentThis is irrelevant to the unsolvability. That the three body problem is unstable and that no analytic solution exists are completely independent statements. The upright pendulum is also an unstable ODE, yet it has an analytical solution. reply jovial_cavalier 14 hours agoparentprevThis only demonstrates that the system is chaotic, not that there is no closed form solution. reply nyrikki 11 hours agorootparentThis may be a bit pedantic, the nbody problem is not chaotic, it is harder, having riddled basins. > A riddled basin implies a kind of unpredictability, since exact initial data are required in order to determine whether the state of a system lies in such a basin, and hence to determine the system’s qualitative behavior as time increases without bound. (Note this is different from “chaos,” where very precise initial data are required to determine finite-time behavior.) What is more, any computation that determines the long-term behavior of a system with riddled basins must use the complete exact initial data, which generally cannot be finitely expressed. Hence such computations are intuitively impossible, even if the data are somehow available. http://philsci-archive.pitt.edu/13175/1/parker2003.pdf The above post is a good 'example' of sensitivity to initial conditions, and riddled basins do have a positive Lyapunov exponent which is often the only criteria in popular mathematics related to chaos. But while a positive Lyapunov exponent is required for a system to be chaotic, it is not sufficient to prove a system is chaotic. If you look at the topologically transitive requirement, where you work with the non-empty open sets U,V ⊂ X....riddled basins have no open sets...only closed sets. With riddled basins, no matter how small your ε, it will always contain the boundary set. If you have 3 exit basins you can run into the Wada property, which is also dependent on initial conditions but may have a zero or even negative Lyapunov exponent and is where 3 or more basins share the same boundary set...which is hard to visualize, non-chaotic, and nondeterministic. Add in strange non-chaotic attractors, which may be easier or harder than strange chaotic attractors, and the story gets more complicated. Sensitivity to initial conditions is simply not sufficient to show a system is chaotic in the formal meaning. But the 3 body problem's issues do directly relate to decidability and thus computability. reply jovial_cavalier 7 hours agorootparentThis is all very interesting stuff, and I thank you for a bunch of new keywords to google, but I’m not sure why you say it’s not chaotic. As far as I understand, extreme sensitivity to parameters/ICs is all that is required for a system to be chaotic. reply ncallaway 13 hours agorootparentprevBut the chaos is extremely critical, since we can’t ever perfectly measure the initial conditions. So, even having a closed form solution isn’t helpful when computing real world situations. reply constantcrying 13 hours agorootparentThe statements are independent. It having a closed form solution and it being unstable don't contradict or confirm one another. In solutions to ODEs converge very often exponentially from the true result. That the 3 Body problem for this makes it characteristic, not special. >So, even having a closed form solution isn’t helpful when computing real world situations. Simply not true. It is helpful or not depending on your problem. Often you are interested in short term behavior, which can be studied by numerical methods or, if existing, analytic solutions. reply PaulHoule 12 hours agorootparentClosed form solutions in general dynamic systems are possible when systems are integrable which means there is a conserved quantity for every degree of freedom. The solar system is almost like that in the case that each planet keeps going around with a constant angular momentum so they go around like a set of clocks that run at different speeds. Over long periods of time there is angular momentum transferred by the planets so you get chaos like this https://www.aanda.org/articles/aa/full_html/2022/06/aa43327-... Orbital mechanics is a tough case for perturbation theory because each planet has three degrees of freedom (around, in and out, up and down) and the periods are the same for all of these motions and don’t vary with the orbital eccentricity or inclination. Contrast that to the generic case where the periods are all different and vary with the amplitude so with weak perturbations away from a resonance the system behaves mostly like an integrable system but if the ratio between two periods is close to rational all hell breaks loose, see https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Arnold%E2%8... the harmonic oscillator has a similar problem because the period doesn’t change as a function of the amplitude. Either way these two pedagogically important systems will lead you completely wrong in terms of understanding nonlinear dynamic, if you add, say, an εx^3 term to the force in one of two coupled harmonic oscillators it is meaningless that ε is small, you have to realize that the N=2 case of this integrable system https://en.wikipedia.org/wiki/Toda_lattice is the right place to start your perturbation from which ends up explaining why the symmetry of the harmonic oscillator breaks the way that it does. Funny though, the harmonic oscillator is not weird at all in quantum mechanics and is just fine to do perturbation theory from. reply why_at 12 hours agorootparentprevThanks for this. This is something that always bugged me when I see explanations of the three-body problem. They'll say something like \"changing the initial conditions just a tiny bit can dramatically change the outcome!\" as an explanation for why having no closed form solution is significant. But that never made sense to me, since plenty of things with closed form solutions also do this. reply zardo 13 hours agorootparentprevIt was really a math problem and not a physical one. There's so much more going on ( GR, radiation pressure ), that even if there were a solution it wouldn't be able to predict Mercury's orbit. reply adastra22 10 hours agorootparentprevFYI there are stable configurations to 3+ body systems. Not all configurations are chaotic. reply adamredwoods 11 hours agoprevAlso check out: https://universesandbox.com/ https://twitter.com/UniverseSandbox/status/17709221751443007... reply fayalalebrun 2 hours agoparentA few years ago a friend and I made something similar to universe sandbox, though only with the gravitational simulation part: https://github.com/fayalalebrun/Astraria Surprisingly enough the jar still runs without issue. Something which probably would not be the case for linux binaries, but maybe for windows. reply a_gnostic 9 hours agoparentprevNot to forget https://www.kerbalspaceprogram.com reply zamadatix 9 hours agorootparentKSP doesn't actually do > 2 body simulations allowing the paths to follow closed form solutions. This is why you have an abrupt orbit change between bodies instead of just a freeform path. There is a mod \"Principia\" which adds this functionality in but bewarned it makes the game very different to play! reply Georgelemental 8 hours agorootparentPrincipia is extremely impressive, they document all their math here: https://github.com/mockingbirdnest/Principia/tree/master/doc... One interesting detail is that the source code makes extensive use of non-ASCII identifiers, for mathematical symbols and for the names of mathematicians. One of the two primary contributors is also an active contributor to Unicode reply BlueTemplar 1 hour agorootparentThanks, I was wondering how feasible this was / how one would do that in C++ ! reply wkat4242 5 hours agorootparentprevKSP even while simplified is so amazing. I've never gotten very far but the one thing it did manage to impress extremely thoroughly on me is \"space is hard\". And it's like 5x easier in KSP than on earth lol. Also it showed me that that ever recurring thought of \"why don't they just...\" is usually pretty misguided. I really respect how they managed to make this fun and so incredibly educational at the same time. reply mafuku 2 hours agoprevI've always read about how astronomers, especially after Newton, could predict the movement of the planets with incredible precision, yet n-body problems are so infamously complex and hard to solve, even now. Why is that? Is it simply that the mass of everything except for the sun is just so negligible? reply aoanla 2 hours agoparentN-body problems can't be analytically solved. However, you can still compute integrals into the future (with some acceptable error), you just need to step through all the intermediate states along the way In the case of the solar system, yes, it helps that the Sun is much more massive than everything else (and then Jupiter is 4 times more massive than Saturn, the next biggest) - you can go a long way to a \"reasonable\" solution by starting with the 2-body solution if only the Sun affected each planet, and then adding in the perturbation caused by Jupiter and Saturn. (In fact, that's how we predicted the existence of Neptune, by noticing that there were extra perturbations on Uranus beyond those, and hence another massive planet must exist, far enough away from the sun to only significantly affect Uranus). reply octachron 45 minutes agoparentprevPredictions of the solar system state are accurate only on \"short\" periods. The solar system is chaotic, and predicting its state after few million years is no more possible that predicting the weather for next year. This does not preclude making very accurate on short period. Note that n-body problems are not particularly complex or hard to solve compared to other chaotic systems. In many ways, the existence or nonexistence of closed-form solutions is mostly a distraction: it merely reflects our choice of primitive functions and there is no sets of primitive functions that is stable for addition, multiplication, composition, inversion and integration. Typically, even the simple integral ∫ eˣ/x dx cannot be decomposed into more elementary functions. But that doesn't matter in practice, because we are already using numerical approximation to compute primitive functions that are not implemented in hardware. Using numerical solvers to compute solutions to ODE is not so different. A good illustration of that point is that there is an analytic solution for the 3-body problem (in the form of an infinite series in t^{1/3}). But this solution is useless for computing orbits because it has bad convergence properties. In other words, it is better to use a numerical solver rather than stick to the analytical solution. And a similar phenomenon exists for polynomial equation of degrees 3 and 4: the exact formula is numerically unstable, and its better to use a numerical solver when one wants a numerical solution. reply rcxdude 52 minutes agoparentprevTo add to the points from others: 3+-body systems are generally chaotic, so you cannot predict arbitrarily far into the future, but the solar system is reasonably well-behaved in that manner, so the timescales are long, but we don't know where the planets in the inner solar system will be in their orbit in ~5-10 million years (as in, that's the timescale where the error bars for the position in the orbit span the whole orbit). Of course, if you care about more precise predictions then the timescales are shorter: eclipse predictions more than 1000 years in the future are likely to be quite inaccurate. reply DrFalkyn 2 hours agoparentprevIAMAP, but n-body problems result in non-linear partial differential equations, to which only a few special cases are known, and even that case its do to simplifications, e.g., treating planets as point masses and ignoring tidal forces, or ignoring the pull of the planets on the Sun, (or on each other). One such case where a solution is known is the Lagrange point of the Earth-Moon-Sun system (and similiarly for other points) https://en.wikipedia.org/wiki/Lagrange_point But in reality, they exist only as an approximation. They aren't truly stable. My understanding the way to calculate spacecraft, asteroid, etc. trajectories is just through a discrete simulation. Like f you don't know how to solve the antiderivative of a given function, you can still calculate the integral since you know the value of the function. reply constantcrying 2 hours agoparentprevFor almost any differential equation there is no analytical solution for it's initial value problem. That the n-Body problem behaves that way is unsurprising and poses no inherent challenge to making predictions. Computers can easily solve initial value problems for most ordinary differential equations. They integrate them, calculating an approximate solution after every small, but finite step. Getting an approximate solution to the 3-Body problem can be achieved in around 20 lines of python, without having to use any libraries. It is a remarkable simple and effective technique. reply piuantiderp 2 hours agoparentprevYou can solve it numerically using Finite Differences. Basically using linear approximations reply dreamcompiler 6 hours agoprevIf you want to take the next step up in accuracy and cleverness, investigate the work of Mr. Runge and Mr. Kutta. reply QuantumG 9 hours agoprevI've used the NAIF SPICE toolkit (https://naif.jpl.nasa.gov/naif/toolkit.html) which includes the Yarkovsky effect and such, important for small bodies. reply nico 12 hours agoprevThis is great! Thank you In college, a long time ago, I wrote something like this, for n bodies, but in c++ and OpenGL More recently I’ve built something similar in python For anyone interested in this, I recommend this Wired article that goes from the 2 body problem to n, with simulations and code that run on the browser: https://www.wired.com/2016/06/way-solve-three-body-problem/ reply huksley 2 hours agoprevI was wondering why it called a three-body problem (at least as it presented in Liu Cixin novel). There is actually at least 4 bodies (3 suns and a planet), right? I suppose the planet will affect the movement of the 3 suns. reply kqr 2 hours agoparentNo, it's just three. The reason it's a thing – as far as I understand – is that solving analytically for one body is trivial: it's stationary. Solving analytically for two bodies is possible but takes some calculus. Three bodies have chaotic behaviour and need to be simulated. reply belst 1 hour agorootparentin the novels there are 3 suns, so it is 4 bodies. The simulation doesn't get easier with 4 tho, so 3 body problem is still a good name. Also the planets mass is \"almost\" negligible compared to that of the suns, so I assume simulating (+ occasional correcting) 3 bodies is already a good approximation. reply wzdd 27 minutes agorootparentIt’s not a good approximation because (spoilers) the challenge is to identify the location of the planet relative to the suns, not simply to locate the suns themselves. I too wondered at the title. reply pizza 5 hours agoprevIf you want a good read that (to summarize it quite tersely) takes the idea of 3- or n-body simulations and goes very far indeed with it (i.e. why there is something rather than nothing), I highly recommend checking out Julian Barbour's The Janus Point. reply xyst 13 hours agoprevNetflix really going hard on pushing their IP. It’s like guerilla marketing on steroids. I jest. Tbh, I didn’t know this was an actual problem. Thanks for sharing. reply rsynnott 13 hours agoprevDo you want ghost numbers counting down on your retinas? Because this is how you get ghost numbers counting down on your retinas. reply lagadu 12 hours agoparentIt's ok, I'll just make sure never to measure the CMB for variations. reply zakhar 12 hours agoprevHah, I did something similar at https://ari.blumenthal.dev/!/-2/-1/three-body after reading the book last year. Source at https://github.com/zkhr/blog/blob/main/static/js/three.js reply airstrike 9 hours agoparentLoved your website. Thanks for sharing. reply MrCheeze 8 hours agoprevIf, like me, you are suddenly curious what would happen if you added a small fourth body: https://youtu.be/WrahPSY9pf0 reply JKCalhoun 13 hours agoprevAnd since A. K. Dewdney is fresh on my mind, he did a Computer Recreations article generally about this (about simulating orbital mechanics) and the clever bit that I remember: you dial the time slice way down as objects got close, you care little when the objects are far apart. Not a \"solution\" of course, but certainly an optimization if you're just generally doing gravitational simulations. reply PaulHoule 12 hours agoparentSee https://en.wikipedia.org/wiki/Adaptive_step_size reply yzydserd 12 hours agoprevAlso see the source code for the popular ThreeBodyBot [0] as seen on mastodon etc [1] It contains a numerics tutorial [2] that I found very useful for my use case. [0] https://github.com/kirklong/ThreeBodyBot [1] https://botsin.space/@ThreeBodyBot/112200106103679713 [2] https://github.com/kirklong/ThreeBodyBot/blob/master/Numeric... (ipynb) reply PaulHoule 12 hours agoprevI noticed that paper they link to was the first one to find new periodic orbits in the three body problem in a long time which confirms what I’ve believed for a long time which is that nonlinear mechanics is badly underresearched. reply sameoldtune 12 hours agoparentThere’s a saying in mathematics circles which I’ll butcher here: “everything is either a linear system, reducible to linear systems, or unapproachable.” Think about how bad we are at analytically solving “simple looking” diff-eqs and the above statement starts to sound too true. reply PaulHoule 11 hours agorootparentExactly. Finding a few hundred periodic orbits is a lot of hard work but you don’t have the glory of having “solved” something. Because of that kind of thinking there are many unanswered questions which are ignored because they don’t seem to be part of some masterstroke. reply Gys 14 hours agoprevIn this simulation the bodies also collide together. Luckily that never happened in the book. reply CWuestefeld 12 hours agoparentThe book is mis-named. Their system was not 3 bodies, but 4 (3 stars, plus a planet). And the system is so chaotic that even that little planet will make a huge difference over time. And even beyond that, the bodies themselves were transformed, having the ability to tear atmosphere away from each other. reply SamBam 13 hours agoparentprevI was wondering about this too, but I think they're not colliding. I think they're pulling towards each other and getting tightly pulled around each other so they end up slingshotting and flying back the way they came, in a way that looks like a bounce. You can see this in the very beginning of the simulation, with the blue and green dot. Can anyone say if this is actually accurate? It seems like an unintuitive motion to me, but I'm often surprised by how these things work. reply achristmascarl 13 hours agorootparenti believe you're correct, other (higher resolution) visualizations of periodic orbits show that \"wrapping\" behavior more clearly. example from wikipedia: https://en.wikipedia.org/wiki/Three-body_problem#/media/File... reply woooooo 11 hours agoparentprevLuckily??! Could have saved everyone a lot of trouble and kept them in the proper number of dimensions. reply aaronbrethorst 3 hours agorootparentArguably this was all Mao Zedong's fault. reply maelito 14 hours agoparentprevShould a collision conduct to a simulation of a 4 body problem ? reply achristmascarl 14 hours agoparentprevthat might just be because of my low resolution gif ;) reply mhkeller 10 hours agoprevAdding a svelte three-body animation by rich harris https://svelte-cubed.vercel.app/examples/trisolaris reply jxy 7 hours agoprevProbably try to implement a much better integrator. Some energy preserving higher order integrator should serve a lot better. reply danAtElodin 13 hours agoprevNicely done! We were playing with this concept as well, in case it's useful to compare notes together: https://app.elodin.systems/sandbox/hn/three-body reply maxglute 12 hours agoprevWould be neat if there's planet level visualization in Space Engine like in the show where you see the suns whizzing around and enviroment freeze/burn. reply adamredwoods 11 hours agoparentThis isn't planet level, but shows surface: https://universesandbox.com/ reply asdfman123 8 hours agoprevThis is nothing like what I remember from the book! reply melondonkey 10 hours agoprevLooks like Pokemon Jirachi reply lfmunoz4 13 hours agoprev [8 more] [flagged] petsfed 12 hours agoparentMaybe its because I made an honest effort of getting a PhD in physics, but I absolutely do not understand this perspective. Like yes, we have a really hard time talking about just about anything as finite object with physical extent, but jokes about frictionless spherical cows moving in simple harmonic motion started in secondary school. The gaps and shortcomings should not come as a surprise. But most of us also hold devices in our pockets that leverage actual quantum phenomena to function at all (diodes of any stripe only work because of quantum transitions). So while its true that there are a variety of unsolved and potentially unsolvable problems in physics, its a gross misunderstanding to say that it can barely answer simple questions. I think about the Born-Oppenheimer approximation a lot, as its so obviously a hack to even do the math at all, but it undergirds basically all of solid state physics. reply acover 13 hours agoparentprev [–] What in this post isn't honest? reply lfmunoz4 13 hours agorootparent [–] \"not honest\" might not be the right phrasing. What I was trying to say is that when learning this stuff I felt like they hid a lot of information from me which later surprised me. But they hid it because they have no answers for it. One simple example is what happens when you don't consider these as points but instead spheres. Also what happens when the spheres come close? The math starts breaking down, you start seeing infinities. I.e, in reality spheres come close and gravity doesn't go infinity. reply mr_mitm 13 hours agorootparent [–] You are complaining that you study the simple cases or simplified cases first before you study near unsolvable systems? Besides, very often the simplified case gets you surprisingly far because the difference between idealized situations and reality is often negligible or at least easily describable - see perturbation theory. The simplified cases are well worth studying. reply sfink 12 hours agorootparent [–] If I understand correctly, or at least if I map it to my own similar complaint: the problem is not that they have you study simple or simplified cases, it's that the ignored complexity is unacknowledged and sometimes even denied. Which makes a lot of sense in primary school, where even mentioning it might cause some kids to ignore everything because \"it's not really how it works\" or whatever. But by the time you've made it past the basics, sweeping complexity under the rug is harmful. You still want to be studying the simplified scenarios, but it would be much better if you had some sense of the range of things that meaningfully differ from realistic scenarios. Not so you can take them into account in your solutions, but so you have the appropriate level of humility about what your solutions mean and the limits of their applicability. I guess I didn't do that much physics, because for me it comes up more in other fields. In statistics, for example, it is critically important to understand the limitations of your results. For example, you might assume that error is normally distributed. You don't want to forget about that assumption, because it is very commonly violated, and it can make a large difference in your conclusions. Yet in school, it was almost always handwaved aside with \"Law of Large Numbers mumble mumble mumble\". Even when the law didn't apply, or the definition of \"Large\" happened to be \"way bigger than your pathetic number of data points\". It's also why there's often such a gulf between academia and industry. Academic results walk a tightrope of assumptions and preconditions, and trying to put them into practice always finds places where those don't hold. Sometimes they even start out holding, but then everybody takes advantage of it until competition drives everyone into optimizing the residuals. If there's a space where things make sense, competition will always drive you to the edge of that space. Or beyond; competitive pressure does not care about keeping your equations simple and pure. Back to the point, you might study a field for years and then land a job in exactly that field, only to discover that everybody is looking at it completely differently because they've exhausted the simplified space and are deep in the land of heuristics, guesswork, and approximation. The market for spherical steaks was saturated years before. reply mr_mitm 2 hours agorootparentSounds like an individual experience then. It's a bit of a stretch to blame \"the physicists\" for this. All of my teachers were very open about the short comings of our assumptions and solutions, and while it may be true that not every one and sometimes even none of \"the physicists\" is able to handle the complexity of realistic scenarios, I see no shame in working your way up until you get stuck. I can't remember a teacher that was too proud to say that something was too complicated. reply BlueTemplar 1 hour agorootparentprev [–] Well for physics, the three-body problem, you see it in the first year, the Roche limit - in second. (Specifically two spheres coming close does NOT result in infinities, pointlike objects do - but then you also learn around the same time that atoms aren't pointlike objects and at nanometer-short ranges you have to start to deal with other forces than gravitation too...) (I have my own beef with the \"sweeping under the rug\" which happens with (electromagnetic) pseudovectors, but I do realize that requires a LOT of effort to fix.) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The text presents a simple simulation of the three-body problem utilizing Euler's method with a small time step.",
      "The simulation converts the polar coordinates of the bodies into RGB values, creating visually appealing graphics.",
      "Starting positions are derived from periodic orbit F10 in a scientific paper, with errors becoming apparent after only 2 periods."
    ],
    "commentSummary": [
      "The discussion delves into simulating gravitational dynamics, chaos theory, orbital mechanics, and n-body problems, emphasizing the limitations of analytical solutions in physics.",
      "Participants explore the use of integrators in numerical solutions and discuss challenges in accurately modeling systems with multiple bodies, including the complexities of the three-body problem.",
      "The conversation highlights chaos theory, perturbation theory, and the challenges of predicting the behavior of chaotic systems, underscoring the significance of numerical simulations for accurate predictions and the gaps in physics education."
    ],
    "points": 179,
    "commentCount": 101,
    "retryCount": 0,
    "time": 1712082215
  },
  {
    "id": 39908146,
    "title": "Demystifying SSDs: NAND Flash Technology Unpacked",
    "originLink": "https://kcall.co.uk/ssd/index.html",
    "originBody": "Everything I know about SSDs Solid State Devices using NAND Flash, how they differ from Hard Drives, and how they affect file deletion and recovery March 2019: Introduction: I started writing this rather long page for my own benefit, when I acquired a upgrade from my old 2006 Win 8 250 gb HDD PC to a Dell Optiflex 3010 with a 128 gb SSD. I never used more than 30 or 40 gb of the system drive, and I'm not a gamer or an avid film or music collector either. Not on a PC anyway. As I played with my new kit the further I went I realised that I knew very little about NAND flash in SSDs, just how SSDs work, how do they read and write and store data, and what sort of trickery do they employ? I can visualise an HDD, writing tiny magnetic patterns on a rotating surface, but SSDs are different, vastly different. There's also quite a few misconceptions about SSDs which seem persistent, and it would be nice to examine them if not perhaps quash a few of them. Perhaps I was guilty of harbouring quite a few misconceptions myself. However it started, this article grew into, shall we say, a mid-level technical discussion. If all you need to know is that SSDs are quiet, reliable, fast, and will work for years, then there's no need to read any further. If however, you think that knowing how to read a 3D TLC NAND flash cell is interesting, then you have little option but to plough on. As much of the detailed information as possible has been sourced from corporate and private technical articles, with quite a lot from Seagate and WD, and the wonderfully named Flash Memory Summit. Some of the conclusions I've made are from just trying to apply what logic I can along with common sense. Such is the complexity of NAND flash controllers, the variance in their methods of operation, and the speed of their development, that trying to comprehend let alone keep up with them is difficult to say the least. I can't say whether what I've written isn't confusing or is even true, but it's more of a guide than a bible. There'll be some repetition too. And it will soon be out of date. I am obliged to those I have borrowed from, and will also be obliged to those who point out any errors without any reward apart from that of contribution. I've tried to explain what is different with SSDs, and why it is so hard to grasp with our ingrained HDD minds. The first misconception might be the plural of SSD: gramatically it should be, so I'm told, SSDs, but SSD's is almost as commonplace. Here I will stick to one SSD, many SSDs. Software and hardware: This article was written in 2019 onwards and deals almost exclusively with NAND flash in the form of pc or laptop storage devices we know as SSDs. I shan't complicate things even more by referring to the ubiquitous flash drive or other NAND flash devices. If significant differences exist I shall try to note them as and when that occurs, but the default is the internal drive. Nowhere here is there anything about flash storage in phones, etc. Most of the detail was produced whilst my PC was running Windows 10 Home, with a fairly modest internal 2.5\" WD Green 120 gb SSD. This uses a Silicon Motion SM2258XT controller and four 32 GiB SanDisk 05497 032G 15nm 3D TLC memory chips with an inbuilt SLC cache of unknown capacity. As this article tries to discuss the behaviour of SSDs as a whole it shouldn't matter what host operating or file system is used, but in my case it's Windows and NTFS. Nothing here is specific to a particular brand or type of SSD, it should all be generic. We're really dealing with the principles of SSD operation. The only additional software applications I have used are Piriform's excellent Recuva, which can list both live and deleted files and their cluster allocations, and HexDen (HxD), a very usable and capable hex editor. Recuva is free from www.piriform.com, and HexDen is also free from www.mh-nexus.de. I use the portable versions of both pieces of software. All the conclusions and opinions here are entirely my own work, and any data taken from my own pc. It would be wise to verify, or at least agree with my reasoning, before accepting these words as the truth. Much of this is a simplified explanation of a very complex subject. SSD Physical Internals: Poking inside an SSD is something of a disappointment, a small pc board with a few NAND flash chips and a controller chip, lightweight and a little flimsy. As for the software inside the controller, I can only summarise the basic tasks. It seems commonplace that controllers are bought in from external manufacturers, as indeed are the memory chips. SSD controller software is proprietary, very complex and highly guarded, but all controllers have to do basic tasks, even if we don't quite know how. Only those tasks can be discussed here, the very clever tweaks and tricks will have to remain known only to the manufacturer. I'll start with a little groundwork. NAND Flash: I wasn't going to delve into the internals of NAND flash, there are enough frankly bemusing articles on Wikipedia for all that. All you really need to know is that NAND (NOT-AND) flash memory stores information in arrays of cells made from floating-gate transistors. The floating gate can either have no charge of electrons, and be in an 'empty' logical state, or be charged with electrons at various voltage thresholds and be in a logical state which represents a value. NAND flash is non-volatile and retains its state even when the SSD is not powered up. Oh yes, it's called flash because a large chunk of cells can be erased (flashed) at a time. But if you want to know more, go ahead. Here the term cell and transistor refer to the same physical entity and are used interchangeably, and I won't keep saying NAND all the time. Flash memory comprises multiple two-dimensional arrays of transistors, and supports three basic operations, read, program (write) and erase. Apart from the flash arrays, the flash chip includes command and status registers, a control unit, decoders, analogue circuits, buffers, and address and data buses. A separate chip holding the SSD controller sends read, program, or erase commands to the flash chip. In a read operation the controller passes the physical address to the flash chip which locates the data and sends it back to the controller. in a program operation the data and physical address are passed to the chip. In an erase operation, only the physical address is passed to the chip. The ﬂash chip's latches store data transferred to and from the flash arrays, and the sense ampliﬁers detect bit line voltages during read operations. The controller monitors the command sent to the chip using the status register. The controller also includes Error Checking and Correction (EEC) algorithms to manage error and reliability issues in the chip and to ensure that correct data is read or written. Each row of an array is connected by a Word line, and each column by a Bit line. At the intersection of a row and column is a Floating Gate Transistor, or cell, where the logical data is stored. Word lines are connected to the transistors in parallel, and bit lines in series. The ends of the bit lines are connected to sense amplifiers. Flash arrays are partitioned into blocks, and blocks are divided into pages. Within a block the cells connected to each word line constitute a page. The cells connected to the bit lines give the number of pages in a block. Common page sizes are 4k, 8k or 16k, with 128 to 256 pages making a block size between 512k and 4mb. A page is the smallest granularity of data that can be addressed by the chip control unit. Read or program operations involve the chip controller selecting the relevant block using the block decoder, then selecting a page in the block using the page decoder. The chip controller is also responsible for activating the correct analogue circuitry to generate the voltages needed for program and erase operations. Although the number of cells in each row is nominally equivalent to the page size, the actual number of cells in each row is higher than the stated capacity of each page. This is because each page contains a set of spare cells as well as data cells. The spare cells store the ECC bits for that page as well as the physical to logical address mapping for the page. The controller may also save additional metadata information about the page in the spare area. During a read operation, the entire page (including the bits in the spare area) is transmitted to the controller. The ECC logic in the controller checks and correct the read data. During a program operation the controller transmits both the user data and the ECC bits to the flash memory. Upon system boot the controller scans the spare area of each page in the entire flash array to load the logical to physical address mapping into its own memory (there may be other techiques for holding mapping data in the controller). The controller holds the logical to physical address mapping in the Flash Translation Layer (FTL). The FTL also performs garbage collection to clear invalid pages following writes, and performs wear-leveling to ensure that all the ﬂash blocks are used, evenly. Since flash does not support in-place updates, a page needs to be erased before its contents can be programmed; but unlike a program or a read operation which work at a page granularity, the erase operation is performed at a block granularity. 2D and 3D, and Layers: In flash architecture a block of planar flash, a two-dimensional array of cells, is rather unsurprisingly called 2D flash. If one (or more) array is stacked on top of each other then it's 3D flash. 3D NAND flash is built on one chip, up to 32 layers, and was devised to drive costs down when planar flash reached its scaling limit: 3D flash costs little more than 2D to produce, but multiplies the storage capacity immensely. In both 2D and 3D the cells in each page (the rows) are connected by Word Lines, and the cells at each offset within a page (the columns) are connected with a Bit Line (to put it very simply). 3D flash is not the same as layered flash, where separate very thin chips are arranged in a stack. This is prohibitively expensive. Most modern consumer SSDs (in the 2010's) use 3D TLC flash. Can I see one? The cell size on end-user flash is minute, with 15nm being common, and ranges from 43nm down to 12nm. Actually cell size, or cell diameter, is misleading, as the stated size is not a measurement of any dimension of a cell but a measure of the distance between discrete components on the chip. The silicon layers on the chip are approximately 0.5 to 3nm thick: by comparison a hydrogen atom is 0.1nm in diameter, and the silicon atoms used in chip manufacture 0.2nm. A nanometre (nm) is indeed exceedingly small, a billionth of a metre, and as an analogy if one mn were the size of a standard marble (about 13mm) then one metre would be the size of the earth. The power of a billion is impressive. SLC, MLC, TLC, QLC and Beyond: A Single-Level Cell (SLC) has one threshold of electron charge to indicate the state of one bit, one or zero. A Multi-Level Cell (MLC) holds a voltage denoting the state of two bits, with three different thresholds representing 11, 10, 00 and 01. A Triple-Level Cell (TLC) holds the state of three bits, 111, 110, 100, 101, 001, 000, 010, and 011. The 15 thresholds used in Quad-level cells (QLC) can be deduced if anyone is at all interested. (I have seen other variations of what these threshold values represent in bit terms.) Unfortunately when the double level cell was developed it was called a multi-level cell and given the acronym MLC, thus forcing everyone to type out multi-level cell laboriously when they want to refer to multiple level cells. If only it had been called a double-level cell we could use DLC, TLC, and QLC freely and use MLC to describe the lot, but it's too late for that now. If only flash had stopped at SLC, with its yes/no one/zero state, these explanations would be far easier to write, and hopefully far easier to grasp. With multi-level cells physical NAND pages represent two or more logical pages. The two bits belonging to a MLC are separately mapped to two logical pages. Odd numbered pages (including zero) are mapped to the least significant (RH) bit, and even numbered pages are mapped to the most significant (LH) bit. Similarly, the three bits belonging to a TLC are separately mapped to three logical pages, and a QLC is mapped to four logical pages (The page numbering for TLC and QLC is unknown). The more bits a multi-level cell has to support affects the cell's performance. With SLC the controller only has to check if one threshold has been exceeded. With MLC the cell can have four values, with TLC eight, and QLC 16. Reading the correct value of the cell requires the SSD controller to use precise voltages and multiple reads to ascertain the charge in the cell. It's also apparent that if a single physical page supports multiple logical pages then that page will be read and written more frequently than a SLC page, with consequent affect on its life expectancy. Furthermore it would seem self-evident that a TLC SSD would need only a third of the physical cells required in an SLC device, so my 120 gb TLC SSD would actually hold only 40 gb of NAND cells. High-use enterprise SSDs used to be the province of the SLC, with it's greater speed, endurance, reliability and read/write capabilities, MLC and TLC are gaining acceptance for enterprise use. The end-user consumer SSD market gets the cheaper higher capacity but slower and more fragile multiple level cells. Why is Nothing One? Anyone still following this may have noticed a common factor in both single and multi-level cells, in that an empty cell - where the floating gate has no charge - represents one. Unlike HDDs, where any bit pattern can be written anywhere, a default logical state of ones is present on an empty SSD page. This is because there is only one programming function on the cells, to move electrons across the floating gate. NAND flash cells can only be programmed to a state of zero, there is no ability to program a one. With multi-level calls the default is still one across all pages, but a logical one can be represented even after the cell has been programmed and there are electrons present across the gate. Ever since Fibonacci introduced the Hindu-Arabic numeral system with its concept of zero into European mathematics in 1202, the human mind associates zero with empty and one with full. To be empty and represent one is rather perplexing, and appears to be mainly from convention (an empty state could represent zero but would required inverters on the data lines). Possibly the circuitry is less complex, and possibly the ability of an empty cell to conduct a charge implies that it is a one. They're all SLC anyway: After all this it's perhaps worth emphasising that NAND flash, whatever its intended use, is all physically SLC. If you could look into a TLC cell you wouldn't see 101, or 011, or whatever. There can only ever be one quantity of electrons in a cell, no matter how that quantity is interpreted. The SSD controller knows whether the cells are to be treated as SLC, MLC etc and programs them accordingly, measures the electron count, and determines what logical value it represents. But even quad cells can only contain one value, just as do SLC cells. The Myths and Misconceptions: And now we come to the myths, misconceptions and the real reason for writing this article, what happens when an SSD page is read, written and rewritten, and how does this affect deleted file recovery? On one hand we have NTFS, designed specifically for HDDs way before SSDs became easily available, NAND flash with its own unique way of operating, and several billion humans with years of ingrained HDD use and expectations. And here, if I haven't already, I shall use SSD interchangeably if incorrectly for NAND flash. Storage Device Controllers: All HDDs, SSDs and flash drives have an internal controller. It's the way that the storage device can be, in the words of Microsoft, abstracted from the host. That abstraction is done by logical block addressing, where each cluster capable of being addressed on the storage device is known to the host by an ascending number (the LBA). The storage device controller maps that number to the sectors or pages on the device. To the host this mapping is constant - a cluster remains mapped to the same LBA until the host changes it. On an HDD this relationship is physical and fixed: in its simplist deconstruction an HDD controller just reads and writes whatever sectors the host asks it to. It doesn't have to think about what was there before, it just does what it's told and writes new data on top of the old. It does that because it can, there's nothing preventing a new cluster being written directly on top of the same sectors of an old one. On an SSD it's different. With an SSD the host still uses the LBA addressing system with the constant reconciliation between LBA and cluster number. It knows that the device is a SSD and has a few tricks to accommodate this, but they will come later. The SSD controller however has many tricks to reconcile the host's file system, written for HDDs, with the demands of NAND flash. Flash Translation Layer: The host still uses LBA addressing to address the SSD for read and writes, as it knows no other. These commands are intercepted by the Flash Translation Layer on the SSD controller. The FTL maintains a map of LBAs to physical block addresses, and and passes the translated PBA to the controller. This map is required because unlike an HDD the LBA to PBA relationship is volatile. It's volatile because of the way data is written to NAND flash. An empty page, with all cells uncharged, contains by default all ones. If a hex editor is used to look at an SSD's empty sectors however, it will be presented with clusters of zeroes. This is because empty pages are not allocated to the LBA/PBA mapping table. Instead, if a read request is issued for an empty page a default page of zeroes is returned. This applies to both unallocated clusters and those which are part of a file: the SSD does not allocate a page and change all its cells from ones to zeroes. Floating Gate Transistors: This section might be helpful before plunging into reads and writes, and here cell and (FG)transistor become interchangable (a cell is a transistor). For more, much more, about floating gate MOSFET (Metal-Oxide-Semiconductor Field-Effect Transistors) there is always Wikipedia. A FGMOS transistor has three terminals, gate, drain, and source. When a voltage is applied to the gate a current can flow from the source to the drain. Low voltages applied to the gate cause the voltage flowing from source to drain to vary proportionally to the gate voltage. At a higher voltage the proportional response stops and the gate closes regardless. The charge in the floating gate alters the voltage threshold of the transistor, i.e. at what point the gate will close. When the gate voltage is above a certain value, around 0.5 V, the gate will always close. When the voltage is below this value, the closing of the gate is determined by the floating gate voltage. If the floating gate has no charge then a low voltage applied to the gate closes the gate and allows current to flow from source to drain. If the floating gate has a charge then a higher voltage needs to be applied to the gate for it to close and current to flow. The charge in the floating gate changes how much voltage must be applied to the gate in order for it to close and conduct. SSD Reads: There's nothing inherent in the design of NAND flash that prevents reading and writing to and from individual cells. However in line with NAND flash's design goal to be simple and small the standard commands that NAND chips accept are structured such that a page is the smallest addressable unit. This eliminates space that would be needed to hold additional instructions and cell-to-page maps. To read a single page, and the cells within it, the page needs to be isolated from the other pages within the block. To do this the pages not being read are temporarily disabled. All cells/transistors in the same block row (a page) are connected in parallel with a Word Line to the transistors' gates. All transistors in the same block column (cell offset) are chained in series with a Bit Line connecting the drain of one to the source of the next. At the end of each bit line is a sense amplifier. When a read takes place a pass-through voltage is applied to all word lines except the page being read. The pass-through voltage is close to or higher than the highest possible threshold voltage and forces the transistors in all pages not being read to close whether they have a stored charge or not. All bit lines are energised with a low current. The word line for the page being read is given a reference voltage, and all the bit line sense amplifiers read. Transistors holding a high enough electron count will not be closed by the reference voltage, and the bit line current will not pass through the source/drain chain to the sense amplifier. Transistors with no charge, or a charge below the threshold, will be closed by the reference voltage and conduct the bit line current to the sense amplifier. Several reads at varying threshold voltages are required to determine the logical state of a multi-level cell. (To add, or avoid, more confusion a floating gate transistor can be either open or closed. An open gate does not conduct an electrical charge, and a closed gate does. So if the gate is open nothing can get through, and if it's closed it can. No wonder we're confused.) It can be seen from this that to read one page in a block requires that all transistors in every page in the block receive either a pass-through or one or more reference voltages. It also appears that this will still apply even if some or all of the other pages in the block are empty. This becomes significant in Read Disturbance below. Interpreting the results: It is quite easy to grasp the concept behind reading an SLC. Only one threshold applies to SLC flash so only one test voltage is required - the floating gate either will or will not close. if the threshold voltage closes the gate then the bit line current passes to the sense amplifier and the stored value is one. If it doesn't then it's zero. Multi-level cells are different, and the reasoning behind the stored value bit order becomes apparent. In a MLC the possible user bit combinations are 11, 10, 00 and 01, separated by three threshold values. To read the most significant (l/h) bit only requires one read, of the middle threshold voltage. If the gate closes then the MSB is one, if it doesn't then the MSB is zero, no matter what is in the least significant bit. To read the LSB (r/h) two reads are required, one of threshold one, and one of threshold three. If the read of threshold one closes the gate then the LSB is set to one and read two is not required. If the gate opens then a read of threshold three is taken. If it closes the LSB is set to zero. If it doesn't then the value is one. The bit combinations in TLC cells are 111, 110, 100, 101, 001, 000, 010, and 011, separated by seven threshold values, and are more tricky to grasp. The MSB bit again only requires one read of the middle threshold, as in MLC. The central bit requires two reads, at threshold two and six, and the LSB requires four reads, at thresholds one, three, five and seven. All multi-cell pages based on the MSB (l/h) are treated as SLC, with only one read required to determine the user bit value. SSD Writes: The most significant aspect of NAND flash, the widest fork in the HDD/SSD path, and the fundamental, pivotal factor in what follows, is that data can only be written to an empty SSD page. This is not new, nor is it in any way unknown, but it has the greatest implications for data security and recovery. While SSDs can read and write to individual pages, they cannot overwrite pages, as the voltages required to revert a zero to a one would damage adjacent cells. All writes and rewrites need an empty page. Unlike HDDs, where a compete cluster is written to the disk whatever was there previously, the act of writing an SSD page allocates an empty page with its default of all ones, and an electrical charge is applied to the cells that require changing to zeroes. This is as true for multi-level cells as it is for SLCs, as the no-charge all-ones pattern is either replaced with a charge representing another pattern, or is left alone. This is a once-only process. When a write request is issued an empty page is allocated, usually within the same block, and the data written. The LBA/PBA map in the FTL is updated to allocate the new page to the relevant LBA. The LBA will always remain the same to the host: no matter which page is allocated the host will never know. This is the same process if the user data is being rewritten or if it is a new file allocation: the only difference is that the rewrite will have slightly more work to do. The old page will be flagged as invalid and will be inacessible to the host, but will still take up space within its block as it cannot be reused. Whilst it's easy to grasp writing to SLC pages, multi-level cell pages are more difficult to visualise. The controller accumulates new writes in the SSD cache until enough logical pages to fill a physical page are gathered, and then writes the physical page. This entails the fewest writes to the page. If a logical page in a multi-level page is amended it would require a new page to be allocated and all logical pages rewritten, as the individual values in the physical page can't be altered. If a logical page is deleted then I surmise that the deleted logical page is flagged as invalid, and when the block becomes a candidate for garbage collection any valid logical pages are consolidated before writing. In other words a multi-level page, or at least the majority of them, will always contain a full compliment of logical pages. It's apparent that if NAND flash handles data writes in this way - and it does - the SSD will eventually become full of valid and invalid pages, and performance will gradually slow to a crawl. Although an individual SSD page can't be erased a block can, and this method is used to return blocks to a writable state. To expedite this, and to ensure that a pool of empty blocks is always available for writes, the SSD controller uses Garbage Collection. Garbage Collection: Garbage Collection is enabled on the humblest up to the highest capacity SSD: without it NAND flash would be unusable. Garbage Collection is part of the SSD controller and its work is unknown to the host. In its simplest form GC takes a block holding valid and invalid pages, copies the valid pages to a new empty block, updates the LBA mapping tables, and consigns the old block to the invalid block pool. There the block and its pages are reset to empty state, and the block added to the available block pool. Thus a pool of available blocks should always be available for write activity. As long as there is power to the SSD GC will do its work, it cannot be stopped. There are various sophisticated techniques for GC routines, all proprietary and mainly known only to the manufacturers. When an SSD arrives new from the factory writes will gradually fill the drive in a progressive, linear pattern until the addressable storage space has been entirely written. However once garbage collection begins, the method by which the data is written - sequential vs random - affects performance. Sequentially written data writes whole blocks, and when the data is replaced the whole block is marked as invalid. During garbage collection nothing needs to be moved to another block. This is the fastest possible garbage collection - i.e. no garbage to collect. When data is written randomly invalid pages are scattered throughout the SSD. When garbage collection acts on a block containing randomly written data, more data must be moved to a new block before the block can be erased. The Garbage Collection Conundrum: Garbage Collection can either take place in the background, when the host is idle, or the foreground, as and when it is needed for a write. Whilst background GC may seem to be preferrable, it has drawbacks. If the host uses a power-saving mode when idle, GC will either wait for the device to restart with a consequent user delay for GC to complete, or wake the device up and reduce battery life whilst the host is 'idle'. Furthermore GC has no knowledge of the data it is collecting. Inevitably some data will be subject to GC and then be deleted shortly afterwards, incurring another bout of GC and consequent additional and unnecessary writes (write amplification, the ratio of actual writes to data writes). Foreground GC, seemingly the antithesis of performance, avoids the power-saving problems, only incurs writes when they are actually required, and with fast cache and highly developed GC algorithms presents no noticeable performance penalty to the user. The trend in modern GC appears to be foreground collection, or a combination of foreground and background collection. Based on foreground garbage collection, and that most user activity is random, then the inevitable conclusion is that the SSD will spend most of its life at full capacity, if by that we mean available blocks, even though the allocated space appears to the host to be low. However there is another potential problem with SSDs, and that is to do with a historical event: the way that file systems were designed. File Systems - What you see isn't what you get: Host file systems were designed in the days when HDDs reigned supreme, simply because SSDs had yet to arrive in an available and affordable form. The file system does not take into account the needs of NAND flash. Files are constantly being updated: they get allocated, moved and deleted, and grow and shrink in size. The way the file system handles this is incompatible with the workings of NAND flash. It's worth emphasising that storage devices are abstracted from the host operating system. Whilst an array of folders and files are displayed by Explorer in a form wholly comprehensible to a human, it's all an illusion. What Explorer is showing is a logical construct created entirely from metadata held within the file system's tables. The storage device controller knows nothing about files or folders, or tables or operating systems: all an HDD or SDD sees are commands to read or write specific sectors, which it does faithfully. An SSD has one advantage over an HDD however, it knows that some pages hold data, and are mapped to an LBA, and some pages are empty, hold no valid data, and are not mapped to an LBA. Conversely an HDD does not need to know this, to an HDD all sectors are the same. File Deletion: In NTFS, when a file is deleted the entry in the Master File Table is flagged as such, and the cluster bitmap is amended to flag the file's clusters as available for reuse. The delete process takes place entirely within the MFT and the cluster bitmap. This is perfectly adequate for an HDD, as NTFS can simply reuse the MFT entry and the clusters whenever it wishes. On an SSD the process from NTFS's point is exactly the same, as NTFS has no other way of deleting files. However all the SSD sees is exactly what an HDD would see, updates to a few pages. Neither an HDD nor an SSD knows that it's the MFT and cluster bit map being updated, as they have no knowledge of such things. As there is no activity on the deleted file's clusters, the SSD's pages holding the clusters remain mapped to their LBAs in the FTL. The SSD's FTL has no way of knowing that these pages are no longer allocated by NTFS: to the SSD the pages are still valid and will not be cleaned up by garbage collection. As these 'dead' pages are allocated to an LBA they could be released when files are allocated or extended and the host uses that LBA. In this case the page will be flagged as invalid and a new page used. However it is inevitable that eventually a significant amount of unused and unwanted baggage which is not flagged for garbage collection will be pointlessly maintained by the SSD controller and be unavailable for reuse. To overcome this, and to correlate the hosts view of allocated and unallocated pages with the SSD's, NTFS from Windows 7 onwards acquired the TRIM command. SSD Detection: Although the storage device is abstracted from the File System, to enable some of the file system's SSD tweaks it needs to know whether the device is an HDD or SSD. There are various ways to do this, including querying the rotational speed of the device, which on an SSD should be zero (or perhaps one). This seems the most widely used and most proficient method. TRIM: TRIM (it isn't an acronym) is a SATA command sent by the file system to the SSD controller to indicate that particular pages no longer contain live data, and are therfore candidates for garbage collection. TRIM is only supported in Windows on NTFS volumes. It is invoked on file deletion, partition deletion, and disk formatting. TRIM has to be supported by the SSD and enabled in NTFS to take effect. The command 'fsutil behavior query disabledeletenotify' returns 0 if TRIM is enabled in the operating system. It does not mean that the SSD supports it (or even if an SSD is actually installed) but all modern SSDs support a version of it. There are three different types of TRIM defined in the SATA protocol and implemented in SSD drives. Non-deterministic TRIM: where each read command after a TRIM may return different data; Deterministic TRIM (DRAT): where all read commands after a TRIM return the same data (i.e. become determinate) and do not change until new data is written; and Deterministic Read Zero after TRIM (DZAT): where all read commands after a TRIM return zeroes until the page is written with new data. By the way whilst DRAT returns data on a read it is not the userdata that was ptrviously there bafore the TRIM: it is random. Fortunately Non-Deterministic TRIM is rarely used, and Windows does not support DRAT, so a read of a trimmed page - which is easily done with a hex aditor - invokes DZAT and returns zeroes immediately after the TRIM command is issued. The physical pages may not have been cleaned immediately following the TRIM command, but the SSD controller knows that there is no valid data held at the trimmed page address. TRIM tells the FTL that the pages allocated to specific LBAs are to be classed as invalid. When a block no longer has any free pages, or a specific threshold is reached, the block is a candidate for garbage collection. Live data is copied to a new empty block, and the original block is erased and made available for reuse. TRIM is an asynchronous command that is queued for low-priority operation. It does not need or send a response. The size of the TRIM queue is limited and in times of high activity some TRIM commands may be dropped. There is no indication that this takes place, so some unwanted pages may escape garbage collection. RETRIM: Windows Defragger - now called Storage Optimiser - has an option to Optimise SSDs. This does not defrag the SSD but sends a series of TRIM commands to all unallocated pages identified in NTFS's cluster bitmap. This global TRIM (or RETRIM) command is run at a granularity that the TRIM queue will never exceed its permitted size and no RETRIM commands will be dropped. A RETRIM is run automatically once a month by the storage optimiser. Over-provisioning: All NAND flash devices use over-provisioning, additional capacity for extra write operations, controller firmware, failed block replacements, and other features utilised by the SSD controller. This capacity is not physically separate from the user capacity but is simply an amount of space in excess of that which can be allocated by the host. The specific pages within this excess space will vary dynamically as the SSD is used. According to Seagate, the minimum reserve is the difference between binary and decimal naming conventions. An SSD is marketed as a storage device and its capacity is measured in gigabytes (1,000,000,000 Bytes). NAND flash however is memory and is measured in gibibytes (1,073,741,824 bytes), making the minimum overprovisioning percentage just over 7.37%. Even if an SSD appears to the host to be full, it will still have 7.37% of available space with which to keep functioning and performing writes (although write performance will be diabolical). Manufacturers may further reduce the amount of capacity available to the user and set it aside as additional over-provisioning, in addition to the built-in 7.37%. Additional over-provisioning can also be created by the host by allocating a partition that does not use the drive's full capacity. The unallocated space will automatically be used by the controller as dynamic over-provisioning. My humble WD SSD has four 32 gb chips but a specified capacity of 120 gb, meaning that it has 8 gb set aside as additional over-provisioning. Add this to the 7.37% minimum (9.4 gb) and the 17.4 gb equates to almost 15% over-provisioning space. Wear Levelling: Some files are written once and remain untouched for the rest of their life. Others have few updates, some very many. As a consequence some blocks will hardly ever see the invalid block pool and have a very low erase/write count, and some will be in the pool every few minutes and have a very heavy count. To spread the wear so that all blocks are subject to erase/writes equally, and the performance of the SSD is maintained over its life, wear levelling is used. Wear levelling uses algorithms to indentify blocks with the lowest erase count and move the contents to high erase count blocks; and to select low erase count blocks for new allocations. As with garbage collection, wear levelling is far more complex than I could possibly deduce, let alone explain. Read Disturbance: SSD reads are not quite free, there is a price to pay. As described above, a read of one page generates a pass-through voltage on all other cells in the block. This voltage is likely to be below the highest threshold value that could be held by the cell, but it still generates a weak programming effect on the cells, which can unintentionally shift their threshold voltages. The pass-through voltage induces electric tunnelling that can shift the voltages of the unread cells to a higher value, disturbing the cell contents. As the size of flash cells is reduced the transistor oxide becomes thinner and in turn increases this tunnelling effect, with fewer read operations required to neighbouring pages for the unread flash cells to become disturbed, and move into a different logical state. Cells holding lower threshold values are more susceptible to read disturbance. Thus each read can cause the threshold voltages of other unread cells in the same block to shift to a higher value. After a significant amount of reads this can cause read errors for those cells. A read count is kept for each block and if it is exceeded the block is rewritten. The count is high for SLC cells, around 1m, lower for 25 nm MLC at around 40,000, and much lower for 15 nm TLC cells. File Recovery: And now we come to deleted file recovery. NTFS goes through exactly the same process to delete a file on an SSD as it does on an HDD, with the exception of the additional TRIM command. And the TRIM command (assuming it's executed) and a few SSD quirks destroys any practicable chance of deleted file recovery. TRIM commands, as described above, have a complimentary setting within the SSD controller in the form of DRAT and DZAT. (I don't believe that non-deterministic TRIM is used in any reputable SSD, and I don't think that Windows supports DRAT, but I have no proof.) The implementation of DZAT means that immediately on successful execution of the TRIM command (which will in most cases be immediately on file deletion) any attempt to read the TRIMed page will return zeroes. The data on the page will still exist until the block is processed by the garbage collector, but that data is not accessible from the host by any practicable means, or any general software. Garbage collection is independent of the host device and will be invoked at the will of the SSD's controller. Once the process is started it cannot be stopped, apart from powering off the SSD. Once powered up again the garbage collector will resume its duties to completion. Deleted file recovery on a modern SSD is next to impossible for the end user, and under Windows as close to impossible as you can get. A theoretical examination of the chips would most likely show compressed and encrypted data, striped over multiple blocks, and no possibility of relating one page of data to another across the multiple millions of pages. There is a very small possibility of recovering recently deleted files by powering off the SSD immediately and sending it to a professional data recovery company. They may recover some data, given enough time and money. After a session of file deletion, such as running Piriform's CCleaner, run Recuva on the SSD. The headers of the deleted files found (and presumably the rest of the file) will all be zeroes. This is TRIM and DZAT doing their work in a few seconds, killing any chance of deleted file recovery. Of course TRIM can be disabled, at the cost of performance, but it's probably better to be a little less cavalier when deleting files that might be wanted later. Deletd File Security: The notion of secure file deletion - overwriting a file's data before deletion - is irrelevant, and if any other pattern except zeroes is chosen is just additional and pointless wear on the SSD. Even overwriting with zeroes will cause transaction log and other files to be written, so secure file deletion on an SSD should never be used. Wiping Free Space is far worse for pointless writes, and is even more futile than secure file deletion. The deleted files just aren't there any more. The OCZ Myth: Some years ago (as a little light relief to all these acres of text) the OCZ forums were buzzing with the latest method of regaining performance on their SSDs: run Piriform's CCleaner Wipe Free Space, with one overwrite pass of zeroes. Although performance may have been regained, logic, and common sense, went out of the window. The theory was that overwriting the pages with zeroes was equivalent to erasing blocks (this was before the days of TRIM). This was nonsense, and should have been apparent from the start. The default state of an empty page is all ones, not zeroes, and how could a piece of software possibly erase NAND flash?. The real reason was that as CCleaner was filling the pages with zeroes the SSD controller simply unmapped the pages and showed default pages of zeroes to the host. The invalid pages were then candidates for garbage collection, which gave a much greater pool of blocks to call upon on writes, and hence a better performance. A sort of RETRIM before that was invented. SSD Defragmentation: One of the SSD mantras is that an SSD should never be defragged. Whilst there is little (there is a little) to be gained from rearranging clusters into adjacent pages - an SSD has no significant overhead in random reads - an SSD defrag is not entirely verboten. In fact from Windows 8 onwards the Storage Optimiser will defrag an SSD if certain conditions are met. If System Restore is enabled, the fragmentation level is above 10%, and at least one month has passed since the last defrag, Windows Storage Optimiser Scheduled Maintenance will defrag the SSD. This is what Microsoft calls a Traditional Defrag, it is not an Optimise (RETRIM). The defrag is required to reduce the extents on the volume snapshot files when system restore is enabled. There is nothing to be afraid of in a monthly defrag. Most users won't hit the 10% fragmented criteria so a simple RETRIM will be run, and Windows 10 users won't get defragged anyway (System Restore is disabled in Widows 10 by default). The reduction in life of an SSD will not be noticed. Furthermore, although SSDs are not fazed by random reads, files do get fragmented and that means a significant increase in I/Os. An occasional clearup is a boon. SSD Lifetime: There are many users worried about the life expectancy of their SSDs. Yes, continuous write/erase cycles, and the added and unseen write amplification, do take a toll on the life of NAND flash. Using an SSD does wear it out. My WD Green 120 gb SSD, a TLC SSD from a reputable manufacturer but at the very lowest cost, has an estimated life of 1 million+ hours and a write limit if 40 terabytes. One million hours is 114 years, so we can forget that. As for writes, at 1 gb a day - far more than my current rate of data use - it would take the same 114 years to reach 40 tb. Even with massive write overhead this SSD is not going to wear out in the forseeable future. If all 128 gib of available flash is used equally, the 40 tb equates to 312 writes per cell, a very conservative number. The End: The only thing to add is that NAND flash, SSDs, and especially SSD controllers, are far more sophisticated, complex and incomprehensible than what has been written here, what I know, what I could possibly comprehend, and what I could possibly explain. I should also add secret, as their software is proprietary. Whilst an HDD is a marvel of complex electro-mechanical engineering at a ridiculously low cost, the SSD is an equally marvellous and complex piece of electronics and software at a minimally higher cost. We should be thankful for both. You can return to my home page here If you have any questions, comments or criticisms at all then I'd be pleased to hear them: please email me at kes at kcall dot co dot uk. © Webmaster. All rights reserved. Last modified on Thursday January 23rd, 2020.",
    "commentLink": "https://news.ycombinator.com/item?id=39908146",
    "commentBody": "Everything I know about SSDs (2019) (kcall.co.uk)174 points by fagnerbrack 16 hours agohidepastfavorite46 comments eatonphil 15 hours agoYou might also be interested in this AMA we held on r/databasedevelopment with two NVMe developers from Samsung. https://www.reddit.com/r/databasedevelopment/comments/1afpez... reply thadt 14 hours agoparentThanks for hosting (and posting it here). I was reading the \"What Modern NVMe Storage Can Do...\" paper just yesterday, and this was a great followup. reply jmbwell 14 hours agoprevI always thought 'flash' was a holdover from early reprogrammable ROM technology, non-volatile memory that you could erase by literally flashing a literal flashbulb over a little window on the chip. I would've sworn in a court of law that I recall this being called \"flashable\" memory, that erasing it was called \"flashing\" it, and reprogramming it in general was called \"reflashing\" in a sort of synecdoche. And I'd have assumed that this was the fundamental origin of what became _electronically_ erasable ROM (EEPROM), which led to all the various NVRAM technologies we have now, with \"flashing\" sticking as the term for reprogramming it, even after you could do it electronically. It looks like the story these days is that someone at Toshiba thought up the name out of the blue. I'm skeptical! reply dboreham 5 hours agoparent> holdover from early reprogrammable ROM technology, non-volatile memory that you could erase by literally flashing a literal flashbulb No. I can see how that might appear plausible but they're unrelated. Flash was a marketing term invented to differentiate a new EEPROM technology that allowed much higher density, and featured sector erase, from previous EEPROM tech. This was done because engineers saw EEPROM as esoteric expensive tech that had no place in low cost products. The Flash vendors wanted to position the new chips as replacing UVPROM, which was relatively cheap by comparison. So they came up with a name that was a) not EEPROM and b) conveyed that the devices were quickly reprogrammed vs UVPROMs (which had to be baked in an eraser then took some minutes to program in a special piece of equipment). Flash's big advantage was that it could be programmed on-board, allowing soldered down PROMs, surface mount packages. Source: I was a hardware design engineer when Flash was introduced and heard the marketing pitch first hand. Using Flash chips for rewritable bulk persistent storage came much later. The first generation devices didn't have the necessary density. reply sgerenser 13 hours agoparentprevI never heard of using a literal flash to reprogram EPROMs, but this wikipedia entry[1] makes your story for the origin of the term “Flashing” seem likely EPROMs are easily recognizable by the transparent fused quartz (or on later models resin) window on the top of the package, through which the silicon chip is visible, and which permits exposure to ultraviolet light during erasing. [1] https://en.m.wikipedia.org/wiki/EPROM reply hex4def6 9 hours agorootparentHeard from a greybeard that they had a demo night in university (this was probably early 80s), and one of the demos was was some sort of path-finding rover robot. Of course, it ended up being one of those projects that had show stopping bugs up until a few hours before showtime. During demo night, it was a big hit, until a stray camera flash got (un)lucky and wiped the microcontroller's EEPROM... Feels a little apocryphal (I'd assume most flashes have / had UV filters?) reply avidiax 6 hours agorootparentThis still happens today. Some chip packaging doesn't provide enough protection from UV. https://forums.raspberrypi.com/viewtopic.php?f=28&t=99042 reply asciimov 6 hours agorootparentprevYou would have put some tape over the window to keep that from happening. Also erasing takes like 15+ mins, it wasn’t quick. reply jmbwell 13 hours agorootparentprevIt does look like all the references I can find point to engineers at Toshiba in 1980 coining the name, although Google ngrams shows some references to \"flash EPROM\" prior to 1980, so I can't help but wonder if the idea existed at least in some form prior to 1980 reply monocasa 12 hours agorootparentLooking into it, those references look miscategorized. It's some Zambian national report that's talking about 0.18um processes (aka, 180nm) in the same paragraph, which wouldn't have come out until the very late 90s. reply radicalbyte 12 hours agorootparentprevThese things were used in a number of computers from the early 90s, I have a few lying around for my Amiga. reply canucker2016 11 hours agoparentprevI always thought that \"flash\" memory was named for EEPROM's erase speed compared to EPROM erase speed (less than a second versus 20+ minutes). EPROM has erase as the first word in the acronym, so everyone just said \"erasing\" the PROM when they put the chip in the UV eraser. Wikipedia lists finer differentiation between flash memory and EEPROMs. see https://en.wikipedia.org/wiki/EEPROM#Related_types reply ThrowawayR2 13 hours agoparentprevEPROMs were erased by many minutes of exposure to UV light, not a flashbulb, in a device called a UV eraser. I've never heard anyone refer to any operation on an EPROM as \"flashing\". reply jmbwell 12 hours agorootparentYep, \"UV eraser\" confirmed by an elmer I know. A unit with a drawer and a timer knob, he says you'd typically set for 30 minutes. He says he does recall people calling it \"flashing,\" but not until much later, by which time it would have been actual \"flash\" memory. As for my own memory, I'm going to file this under Mandela Effect, cross-referenced under Things People Probably Told Me That I've Believed Since Before The Internet Was Available To Fact-Check! reply epcoa 7 hours agorootparentStill own and use a little 9V plastic “portable” UV EPROM eraser that I’ve had for 30 years. Never heard the term “flashing” in this use even when I used them commercially. It really makes no sense what it has to do with flashing, it’s a steady gas discharge lamp for 10 to 20 minutes. The process of programming EPROM was colloquially called “burning” whereas for Flash the programming is called “flashing”, despite the characteristic that the name originally refers to is fast erase speed. reply salawat 8 hours agorootparentprevNote that the Internet isn't always right, and sometimes the dead trees are the only reliable source. The Mandela Effect is just a name we've come up with for identifying biological memory faults. reply numpad0 1 hour agoparentprevActually no, it’s Toshiba trademark for then-new type of EEPROMs that could be erased quickly in blocks rather than having to be set and unset bit by bit. Intel had italic stylized “FLASH” logo proudly printed on chips. I’ve come across it once. reply HankB99 9 hours agoparentprev/pedantic ROM - Read Only Memory - programmed at the time of manufacture. EPROM - Erasable Programmable Read Only Memory (AKA UVEPROM because they could be erased using UV light over a period of time, and they had a quartz window to admit the UV.) EEPROM - Electrically Erasable Programmable Read Only Memory. IIRC it required a special device to erase. It's been a while since I worked with this stuff but I don't ever recall hearing it called flash. reply howard941 13 hours agoparentprevProgramming the windowed EPROMS was called burning. Don't ever recall hearing anything about flashing them for programming or erasure. reply monocasa 12 hours agorootparentYeah, exactly. 'Burning' itself being a holdover from PROMs, where you'd literally burn certain fuses in the array to select bits. reply 0xcde4c3db 13 hours agoparentprevOld-school windowed EPROMs need to be erased under a UV-C tube for something like 20 minutes. By comparison a flash memory block erase operation is practically instantaneous. reply d_sem 12 hours agoparentprevAnecdotally this was also what was told to me by (now retired) electronic engineers who worked in automotive embedded systems in the 80's/90's. The term flash was related to the process of UV exposure to erase memory. This was also humorously explained to me as the beginning of the end for system performance. You didn't need to prove out your system when you could just update your hardware after the fact. In a world of over-the-air flashing we have come a long way from fixed design elements. reply MPSimmons 10 hours agoprev11 years ago, I did a 3 hour 'Introduction to Solid State Storage' at LOPSA-East 2013 that also covered how spinning disks worked, if anyone is interested. https://www.youtube.com/watch?v=G3wf1HMr6b0 The SSD content starts at around 1 hour in: https://youtu.be/G3wf1HMr6b0?si=5kdNeLGafrrU6Gmy&t=3573 reply idle_cycles 16 hours agoprevTwo wonderful papers that are relevant: 1) https://pages.cs.wisc.edu/~jhe/eurosys17-he.pdf 2) https://www.usenix.org/system/files/hotstorage19-paper-wu-ka... reply dang 15 hours agoprevDiscussed at the time: Everything I Know About SSDs - https://news.ycombinator.com/item?id=22054600 - Jan 2020 (185 comments) reply creatonez 9 hours agoprevThere is a very good 5-part explanation from Branch Education: https://www.youtube.com/playlist?list=PL6rx9p3tbsMuk0jnC-dBd... reply Eisenstein 13 hours agoprevSomething useful to know that wasn't mentioned: SSDs will corrupt data if sitting for extended periods without being powered on and thus should never be used for cold storage. \"There are considerations which should be made if you are planning on shutting down an SSD based system for an extended period. The JEDEC spec for Enterprise SSD drives requires that the drives retain data for a minimum of 3 months at 40C. This means that after 3 months of a system being powered off in an environment that is at 40C or less, there is a potential of data loss and/or drive failures. This power off time limitation is due to the physical characteristics of Flash SSD media's gradual loss of electrical charge over an extended power down period. There is a potential for data loss and/or flash cell characteristic shift, leading to drive failure.\" * https://www.ibm.com/support/pages/potential-ssd-data-loss-af... reply Lammy 11 hours agoparentRelevant: Nintendo 3DS and Switch game carts go bad unless played https://news.ycombinator.com/item?id=39367506 reply userbinator 10 hours agoparentprevNote that retention increases exponentially with decreasing temperature, so literally \"cold storage\" might actually be OK for SSDs. The retention also goes down with erase cycles, and is usually specified after the rated number of cycles have been reached; I expect those same SSDs to hold their data much longer than 3 months if they're still nearly new. I still have USB drives over a decade old, but their contents are still intact. Then again, those haven't been written to much, and are SLC and older 2-bit MLC. reply Eisenstein 8 hours agorootparentThose are drives that weren't plugged in for a decade? How do you know the contents are intact? reply eimrine 2 hours agorootparentProbably by plugging it in and eyeballing all the contents. I have a similar experience with 1GB ancient USB drive. reply HankB99 9 hours agoparentprevI ran into this for the first time a couple weeks ago. I tried to boot a system from an SSD that had sat for about 9 months at normal room temperature w/out power. It stumbled badly, repeatedly. I booted a live USB, ran non-destructive `badblocks` scan on it and reinstalled the OS. It's been working fine since. I thought SSDs would last longer than 9 months w/out losing data when not powered. reply robotnikman 11 hours agoparentprevMakes me wonder if those external SSD drives made by Samsung and WD/Sandisk take that into account and use different flash memory with better longevity without power. reply sgerenser 11 hours agorootparentUnlikely in the case of Sandisk, which is known for a recent bout of extremely unreliable external SSDs: https://arstechnica.com/gadgets/2023/08/sandisk-extreme-ssds... reply wmf 11 hours agorootparentprevIf anything, I would expect consumer SSDs to use the cheapest/lowest grade of flash available. reply wtallis 9 hours agorootparentSmall USB flash drives get the worst NAND, followed by memory cards, then consumer SSDs, then enterprise SSDs. \"Portable SSDs\" that are physically much larger than USB thumb drives usually contain standard consumer SSDs in mSATA or M.2 form factor, plus a bridge chip. reply markhahn 13 hours agoprevlittle hard to understand why it's worth explaining the details if you're going to gloss over the issue of endurance and erase cycle limits. if you do very little writing, you have nothing to worry about with SSD endurance. just read-disturb. do you do very little writing? reply password4321 14 hours agoprev [–] I've heard SSDs are more likely to \"fail fast\". Can anyone recommended utilities that monitor and warn before SSD failures? reply caseyf 13 hours agoparentFor NVMe, if you get the SMART data with smartmontools/smartctl, you can inspect Percentage Used. \"Percentage Used: Contains a vendor specific estimate of the percentage of life used for the Endurance Group based on the actual usage and the manufacturer’s prediction of NVM life. A value of 100 indicates that the estimated endurance of the NVM in the Endurance Group has been consumed, but may not indicate an NVM failure. The value is allowed to exceed 100.\" for SATA/SAS SSDs, there is \"Media_Wearout_Indicator\" which hasn't been a particularly reliable indicator in my experience. reply Dalewyn 8 hours agorootparent>if you get the SMART data with smartmontools/smartctl, you can inspect Percentage Used. CrystalDiskInfo[1] can be used for this purpose over on Windows. Some vendor-provided utilities like Samsung Magician will also provide this data with appropriate drives. [1]: https://crystalmark.info/en/software/crystaldiskinfo/ reply magnetic 13 hours agoparentprevMy SSDs show SMART attributes, which can be used as a rough indicator of health, but really the only strategy I've found to work well for my peace of mind is to use redundancy. Concretely, I use ZFS with a zpool with 2 SSDs in a mirror configuration. When one dies, even if it's sudden, I can just swap it out for another one and that's it. My vulnerability window starts when the first SSD fails and closes when the mirror is rebuilt. If something bad happens to the other SSD during that time, I'm toast and I have to start restoring from backup. reply Vecr 11 hours agorootparentDid you stagger the power-on times? Otherwise you could get tightly correlated failures. reply magnetic 10 hours agorootparentThey are about 25 hours apart, which isn't very large I'll admit. Thankfully, the serial numbers aren't too close to each other, so I'm hoping they aren't part of the same batch. reply themoonisachees 51 minutes agorootparentIn my experience with enterprise SSDs (which yeah aren't the same but that's what I have to offer), SSDs with sequential serial numbers and identical on-times, in the same RAID array, can have wildly different actual endurance. Some storage servers I used to admin had SSDs lasting longer than 2 neighbor replacements from the same original box, and this happened at least twice. I stopped being worried about on-times after that for SSDs. HDDs are still quite correlated (on the order of months) but if you're building the server you have to put the disks in it at some point. reply somat 8 hours agoparentprev [–] One surprising feature of \"enterprise\" class drives is that they often have a faster fail than their consumer class counterparts. the idea being an enterprise class drive will be found in a drive array, and the array will be much happier with a hard fast final failure than a drive that tries to limp along. While the consumer with their single drive is a lot happier when their failing drive gives them every chance to get the data off. reply themoonisachees 49 minutes agorootparent [–] Often times you'll find that consumer drives that are limping around do fail smart checks and would absolutely flash a red light and send out a monitoring alert were they in an enterprise enclosure. While there is probably truth to what you're saying, I think the enterprise is also just way more proactive at testing drives and calling them dead the instant the smart checks fail, where consumers don't typically use crystaldiskinfo. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article discusses Solid State Devices (SSDs), focusing on NAND flash technology and contrasting SSDs with traditional hard drives.",
      "It explains the internal components of SSDs, such as NAND flash memory and controller software, detailing data reading and writing processes.",
      "The text covers various aspects like different types of NAND flash memory cells, challenges of garbage collection, file deletion, TRIM commands' importance, and their impact on data recovery, while debunking misconceptions about SSD durability and performance compared to HDDs."
    ],
    "commentSummary": [
      "The post explores the origin of the term \"flash\" in SSDs and EEPROM technology, dispelling the misconception of physically flashing a flashbulb over a chip.",
      "It compares EPROM and flash memory, highlighting the role of UV light in erasing EPROMs and delves into SSD technology, data corruption risks, and strategies for enhancing SSD reliability.",
      "Users contribute personal experiences and insights, emphasizing the importance of reliability, endurance, and monitoring practices for SSDs."
    ],
    "points": 174,
    "commentCount": 46,
    "retryCount": 0,
    "time": 1712077585
  },
  {
    "id": 39906887,
    "title": "Reviving Classic 'Flying Toasters' as Interactive Screensaver",
    "originLink": "https://abhipray.com/posts/flying_toasters/",
    "originBody": "Developing Flying Toasters, a Screen Saver for the Apple Vision Pro: A 0 to 1 Journey April 1, 2024 4-minute read Inspiration and the “Screensaver” Idea The Screensaver Itself Technical Challenges The future I recently decided to make an app for the Apple Vision Pro (AVP) during a two-week break between jobs. I wanted to explore its potential and learn some new skills. My day job primarily involves low-level firmware; I hadn’t built a user-facing app in a while–my last iOS app experience was back in high school in 2011! This was a chance to see how app development has evolved in 2024, especially with modern code generation tools. Inspiration and the “Screensaver” Idea Link to heading After brainstorming with friends, one suggested I look into the classic “Flying Toasters” screensaver by After Dark (released in 1989). I watched a video of it and thought it would be a perfect starter project! I was especially excited to bring the concept of a “screensaver” to this new platform. Historically, screensavers served a practical purpose on CRT monitors—preventing screen burn-ins. From Wikipedia: Screen burn-in, image burn-in, ghost image, or shadow image, is a permanent discoloration of areas on an electronic display such as a cathode ray tube (CRT) in an old computer monitor or television set. It is caused by cumulative non-uniform use of the screen. One way to combat screen burn-in was the use of screensavers, which would move an image around to ensure that no one area of the screen remained illuminated for too long. Today, screensavers primarily serve aesthetic and entertainment purposes, activating during periods of user inactivity. My aim was to incorporate a similar, inactivity-based trigger for the AVP screensaver. Initially, my plan was to employ gaze tracking to identify moments when a user might be “zoned out”. Due to privacy considerations, Apple restricts access to such sensor data. As a workaround, users can signal their activity by periodically tapping a button within the app’s main control window, effectively resetting the inactivity timer. The app also allows users the flexibility to customize the timeout duration, transforming the screensaver into a gentle nudge to take breaks from using the AVP. The Screensaver Itself Link to heading The screensaver features flying toasters soaring across your real-world environment. They emerge from a portal showing the sun and disappear into a portal showing the moon. It was fun adding silly little features like: Gesture controls: Scale and rotate the portals to your liking. Toaster interaction: Tap a toaster to trigger a whimsical phrase. Baby toasters occasionally make an appearance too! Customization: Adjust toaster count, toastiness level, colors, and music. Or, activate “ghost mode” to prevent collisions if the on-screen chaos gets overwhelming. Check out the app previews and screenshots on the app store to get a visual: https://apps.apple.com/us/app/flying-toasters/id6479964879 Technical Challenges Link to heading Here are some specific challenges I overcame during the development process: Learning Swift: Although I’d used Objective-C for an iOS app back in high school, I wanted to learn Apple’s recommended way of writing apps. I spent time reading Swift tutorials and practicing in Swift Playgrounds. ChatGPT and Gemini were also great resources for code editing and debugging. 3D Animation/Art: I had no prior experience with 3D animation. I started with a 3D-printable toaster model and followed tutorials to animate the wings. Creating those toasts was trickier! I couldn’t find the right textures for different toastiness levels – after a lot of trial and error (and a hundred attempts with Photoshop’s generative fill), I finally got those realistic-looking textures. Portal Gestures: Apple’s example code was key for implementing intuitive scaling and rotation gestures for the portals. Toaster Physics vs. Animation: I found out the hard way that RealityKit’s physics engine and strict animation paths (using FromToByAnimation()) don’t always play nicely together. My chaotic collision solution? Random launch points with a minimum distance constraint, random cubic-bezier curve paths, and plenty of linear/angular damping on those toasters. If the toasters’ movements are still subjectively chaotic, the user can opt out of collisions by turning on ghost mode. Head Tracking: I wanted the toasters’ whimsical phrases to appear in speech bubbles that always faced the user. RealityKit doesn’t directly track head position, but I adapted a clever ARKit workaround to achieve this. The future Link to heading This project was a blast! If you have an AVP and end up seeing the flying toasters in action, please let me know what you think! Just as the original Flying Toasters screensaver evolved over a decade (see the YouTube playlist here), I anticipate if there is enough interest and feedback, I will improve the experience. So do share feedback!",
    "commentLink": "https://news.ycombinator.com/item?id=39906887",
    "commentBody": "Recreating the Flying Toasters screen saver for the Vision Pro (abhipray.com)150 points by bayeng 18 hours agohidepastfavorite114 comments btown 14 hours agoThe original Flying Toasters may be the classic, but the singing Flying Toasters from After Dark 3.2 will always have a special place in my heart: https://www.youtube.com/watch?v=mjlusi_h_XA Flying out of the sun / The smell of toast is in the air / When there's a job to be done / The flying toasters will be there. And it's flap! Flap! Flap! / Now help is on the way. / This vict'ry song they sing: We pop up to save the day / On mighty toaster wings! reply NickM 14 hours agoprevCouldn't help noticing the app size is ~150MB - not sure if this is something you can avoid, or if maybe all AVP apps automatically include a lot of extra cruft, but it feels like surely an app this simple shouldn't have to be that big? reply netruk44 10 hours agoparent> maybe all AVP apps automatically include a lot of extra cruft I'm making a simple physics playground app for the vision pro and it clocks in at 7.8 MB total in the app store. Granted, my app doesn't have any assets in it unlike this one. So maybe vision pro assets are heavy for some reason. reply peddling-brink 10 hours agoparentprevCould be really bloated assets. Or really bloated tracking sdks. I see this a lot with spammy iOS apps, size is either a handful of megabytes or hundreds. reply floxy 11 hours agoparentprevJust as interesting, what were the requirements for the original screensaver? Certainly it ran on Windows 3.0. How many floppy disks did it come on? How much RAM did it use? It almost certainly has to be less than 1MB, probably much less. Looks like it ran on 10 MHz 80286's: https://lowendmac.com/2007/how-after-dark-came-to-windows/ reply floxy 10 hours agorootparentThinking about it a little more, I suppose for something like the flying toasters, the toasters were probably like 50x50 px sprites. 8 bit color per pixel. Maybe 10 frames of animation. So 25 kB, and add 5 kB for the toast sprites. And then 2 kB for the code, gives 32 kB for just the flying toasters. So ~40 different screen savers could fit on a floppy. reply einr 1 hour agorootparentAfter Dark 1.0 for Windows comes on a single floppy and is 716k in total, compressed, before installation. After installation, the 34 different screen saver modules take up roughly 650k in total, for an average of about 19k per module. TOASTERS.AD is one of the more advanced ones and is roughly 27k, so your guess is pretty close! reply diroussel 1 hour agoprevA missing feature of the App Store is that it does not support screen savers. You can only download an app that spits out a screen saver. I would love the ability to download free and paid screensavers from the App Store that are sandboxed and would update automatically. How can it be that apple makes its own screen savers so prominent each year, yet doesn’t support screen savers in the App Store? reply geocrasher 14 hours agoprevFlying Toasters are great and everything, but can somebody recreate the Opus 'n Bill screensaver? https://www.youtube.com/watch?v=IP26kghndkE https://www.youtube.com/watch?v=4DywBp3U2hQ reply MR4D 15 hours agoprevFTA... \"Check out the app previews and screenshots on the app store to get a visual: https://apps.apple.com/us/app/flying-toasters/id6479964879 \" I highly recommend watching the video on that link to the app store. The dev did a nice job. reply jmbwell 14 hours agoparentAnd the sleeping cat has no idea what's going on right behind it! reply FabHK 8 hours agoparentprevVery nice, though the categorisation as a “Productivity” app is maybe questionable… :-) reply spacemadness 16 hours agoprevTangential to this, but I don’t really see any discussion about Vision Pro since launch. Is it dead on arrival? reply eddieroger 15 hours agoparentIt's got its use cases that don't align with the kind of topics here, so it's not discussed. Doesn't make it dead, just unpopular with the HN crowd. Maybe even fair to say unpopular with the mainstream crowd. But so was the first, Mac-only iPod, and here we are. I have one. I use it every day for a handful of things, but I don't come on here and talk about it. reply matt_s 15 hours agorootparentI would counter that people adopted iPods en masse a lot faster than they will ever adopt a VR headset. VR is only ever going to be a niche use case. I think those use cases in entertainment realm are the only use cases that could get wide adoption and even then its someone wearing it for 1-2 hours. I think this might suffer from a product class that needs widespread adoption to fund development in order to get smaller form factors and it will never get the widespread adoption. reply eddieroger 14 hours agorootparentI agree that the iPod was adopted faster, but that definitely wasn't version 1, and the early versions were heavily mocked before they were adopted. It was too expensive, it was Mac only, it used FireWire, which was not widely available, things like that. Not the challenges that the Vision Pro (and VR) will face, but still challenges. Apple figured out how to get Windows support, then how to shrink the form factor when it made sense. I imagine they'll do that again. reply threeseed 13 hours agorootparentI knew a lot of people who bought the original iPod. And every single one justified it with it being a high-quality 5GB hard drive that just happened to play music. It definitely wasn’t this breakout music player hit. reply Alupis 11 hours agorootparentPeople who spent the money on a Vision Pro are the most likely people to try to convince others it's some amazing future device... VR has been around for years and years, and still has not become mainstream. The core issues remain, and Apple did nothing to resolve them - nor do I suspect they are capable of resolving them. Untold fortunes have been thrown down the VR rabbit hole by some of the most heavily invested companies, and still today it's a mediocre experience after the novelty wears off. reply oivey 3 hours agorootparentHave you tried it? The claim that they haven’t fixed any of the core issues is legitimately strange. The screens inside as a significant jump in image quality, to the point that for a single TV/movie watcher, the Vision Pro is probably going to be the best device for that media. As the price comes down and the inevitable screen sharing becomes possible, it will be the best for multiple people, too. Eye tracking and pinch to click is also a big jump in usability. That, along with the excellent pass through, makes it way more comfortable to use in public. There are a lot of features that will make it better in the future, like less weight, even better screens, better battery life, etc., but to claim Apple didn’t fix any core problems with the current device is uninformed. reply voidUpdate 1 hour agorootparentAt my work, I've had the opportunity to work with several headsets of different flavours, and eye tracking and pinch to click is not an Apple innovation. It was definitely in the Quest Pro, and possibly some others (its been a while since I worked in that department). When I first got to mess with it, I very quickly knocked up a demo of a huge pair of eyes looking at you that matched the rotation of your actual eyes, which is a surprisingly creepy effect reply mattl 13 hours agorootparentprevFireWire was very widely available on Macs of the era, which is why it made sense amongst other things. (USB 1.1 is very slow, FireWire could also provide power, Apple invented FireWire) reply FabHK 8 hours agorootparentAlso worth noting: when the iPod came out, iTunes had been around for a while. Many people had a decent music library on the Mac (from ripping CDs or Napster), and with the iPod, you just plugged it in, and within minutes you had the entire library in your pocket to go, including metadata (playlists, play counts, etc.). It was pretty convenient, and very well executed. reply mattl 6 hours agorootparentMy Mac keyboard had broken the day I got my iPod. I was able to dock my iPod, sync up my huge collection of music in a few minutes and then head out with my new iPod to buy a cheap replacement keyboard. reply dylan604 12 hours agorootparentprevthe switch to iPod from Walkman/Discman was as obvious as VHS to DVD. it was something everybody wanted even if they didn't know it until they were shown the new thing. not everybody wants knowingly or not a VR headset. that's not a solve of an everyday problem for anybody but a fraction of people. reply dartos 15 hours agorootparentprevIt’s pretty dead :/ But I think this was the classic strategy of pricing out everyone except for those who will build on it or be excited by it, then make a polished v2 with wider appeal once there’s content. reply spacemadness 12 hours agorootparentprevI didn’t mean to center it on HN. I simply don’t see it discussed anywhere even though it was front and center on most social media feeds. Discussion of it vanished seemingly within a week. reply langsoul-com 3 hours agoparentprevEverything that can be said about it already has been. Right now, just gota wait for 3rd gen for the real stuff to happen. Similar story with Quest, 1 was ok but 3rd gen is actually great. reply laidoffamazon 15 hours agoparentprevI've been using it daily, it's excellent. I'm on a trip and don't have access to it and I'm seriously missing it. reply JKCalhoun 13 hours agorootparentI guess Adam Savage thinks it's one of the better ways to experience movies. reply khazhoux 42 minutes agorootparentEven for 2D movies, I no longer bother with my big screen tv. reply laidoffamazon 13 hours agorootparentprevAbsolutely. It's also a good work tool - in certain cases I prefer it to multiple monitors as I usually work. You get full focus in the environment as well. reply qarl 11 hours agorootparentprevDune part 1 in 3D blew my mind. IMHO. reply laweijfmvo 16 hours agoparentprevit might seem silly, but this “flying toaster” sort of thing was exactly the type of first apps being developed for the iphone. we know what eventually happened. so time will tell. reply randomdata 15 hours agorootparentThe iPhone was already a smashing success before third-party apps (jailbroken ones included) were ever developed. It took the Newton to get there, though. Vision Pro may be this generation's Newton, perhaps. Time will tell, indeed. reply nebula8804 15 hours agorootparentprev>we know what eventually happened. So what you are saying is that I need to develop an app which is just a ruby and when you touch it, it displays the following text I am rich I deserv [sic] it I am good, healthy & successful Hmm wonder what would be the good price for such an app? I guess $999.99 will have to do. reply huytersd 13 hours agoparentprevI don’t see any discussion of Apple products at all on here outside of the reveal. reply dylan604 12 hours agorootparentYou must not consider the App Store an Apple product?? reply thomastjeffery 15 hours agoparentprevIt's grounded on launch with it's own concrete shoes. Apple released a VR headset that you can't use to play video games or watch porn with, and priced it at ~2-6x the price of competitive hardware. reply avhon1 15 hours agorootparentIs that an accurate way of characterizing it? I've understood The Apple Vision to be augmented reality headset, not a virtual reality headset -- that Apple intends it to be used for applications more like HoloLens was envisioned for, rather than what Quest, Index, or PSVR are currently used for. reply whywhywhywhy 6 minutes agorootparentThey can call it an AR headset all they want but the thing they shipped is a vr headset with pass through reply droopyEyelids 13 hours agorootparentprevThe hololens isnt used for anything, the only mainstream uses are games and pornography reply astrange 15 hours agorootparentprevYou can watch porn all you want, and it costs less than Microsoft HoloLens did. (Similar to Bing where Bing Maps is worse than Apple Maps, but nobody reported on it because nobody remembers it exists.) reply xp84 15 hours agorootparentIt may well become more successful in some niche market than HoloLens (another niche product) too. But it's not a serious consumer product at $3500 (just kidding, better upgrade that non-upgradeable storage from the 0.25TB, so at least $3700) unless it can, at bare minimum, replace another expensive device (iPhone or Mac) while also doing those things better. Or if some killer app is developed. Which I wouldn't hold my breath too hard for based on their relationship with developers. A killer app like: multiple sports league partnerships which allow you to strap on AVP and be courtside/front row/etc at every game for some monthly subscription -- and all your friends who are also watching the same game are visble and audible via their Personas like they're right next to you. Suddenly, when compared to season tickets or going to 10 games a year, AVP looks great. But I am not necessarily confident that something like this will emerge for this product. Because a lot of content related stuff, which is the only 'proven' consumer use for VR, is dependent on getting content owners to play ball, and content owners don't want to help cement Apple into a dominant position in yet another industry, after seeing how cutthroat their behavior is in music and smartphone apps. reply threeseed 13 hours agorootparent> But it's not a serious consumer product That's why it's called Vision Pro. And Apple today added support for spatial personas allowing developers to create the experience you are talking about: https://www.uploadvr.com/apple-vision-pro-spatial-personas-l... reply xp84 3 hours agorootparentI'm aware that they intend this to be a beachhead for a future Vision Amateur or whatever which I assume will be $1500 (with trash specs, $1700 with passable ones).* However, they won't be able to sell them if developers don't embrace it. That particular egg in my humble opinion needs to be in place before the chicken of adoption will hatch. I believe the only way Apple will make that happen is a radical change in attitude toward developers. They would need to court developers of games and owners of content and negotiate -- generously -- on terms, instead of dictating terms and clinging to the 100% control and 30% revshare they feel so deserving of. We'll see in a couple years if I'm right! * Honestly though, still, even at that price, can you imagine most people being eager to add another almost-$2000 device to their lives that doesn't replace another one, unless the device does some serious life-improving stuff? And I don't see how the price gets any lower than that, even if Apple budged on margins which is very out of character. reply numpad0 1 hour agorootparentprevBut not VR optimized ones. GP’s not talking about flat stuff. HoloLens was also DOA for different reasons(chiefly narrow FOV I think) reply threeseed 13 hours agorootparentprevYou can play all sorts of video games from Apple Arcade, XBox/PS5, Mac, PC etc. There's loads of options courtesy of apps like MirrorPlay. And this is the Vision Pro not Vision. So the mainstream price will be significantly cheaper. reply JKCalhoun 13 hours agorootparentAre the games 2D or 3D? I'm not a big gamer but I'm curious. reply threeseed 13 hours agorootparentAlmost everything is 2D because of the iPad support. There are some launch 3D games but most are being built/ported right now. reply grecy 15 hours agoparentprevA lot of the articles so far are speculating it's mostly a technology demonstrator, or close to a dev kit. Everyone seems to agree it's mighty impressive, but not quite there yet. Gen 2 or Gen 3 will surely be cheaper, lighter and better, and somewhere along there I'm betting we'll see iPhone levels of adoption. reply vundercind 15 hours agorootparentGen 1 iPad was a bit meh. Thick, heavy, didn’t do much. Kinda just a tech demo for a large very-responsive touchscreen device. Gen 2 was so perfect that they sold it for years and years, and launched a related product line based on its platform (the Mini). reply _glass 1 hour agorootparentYes, I even remember everybody saying that tablets will never be used because of the gorilla arm (?) effect, that you can't hold your hand long time up. But now I see a young generation using exclusively tablets. Also the first iPhone, was looked at strangely. I remember being ashamed of using one. Internet was slow. We will know only in hindsight. I have no idea about the future of VR. I see the use-cases, but let's see. reply grecy 14 hours agorootparentprevSame story for the iPod, same story for the MacBook Air, same story for the iPhone. I think we'll see the same story play out once there are a few \"killer\" apps for it, and some of the features are refined (pass through sharpness, for example), and it gets a bit cheaper. reply FabHK 8 hours agorootparentiPod gen 1 was awesome. reply grecy 4 hours agorootparentI agree, but with Firewire only and no Windows support, it was not a big seller. reply frozenport 15 hours agoparentprevYeah. Basically you can use it as an TV and that’s about it. The gesture interface is incompatible with any efficient data manipulation and the screen underperforms compared to a computer monitor. Unlike the iPhone Apple can’t simply software patch or enable an App Store to fix these issues. reply astrange 14 hours agorootparentIt works with Bluetooth keyboards and trackpads. reply t888 15 hours agorootparentprevWhat are you basing this on? reply frozenport 3 hours agorootparentI bought and returned one. reply t888 15 hours agoparentprevnext [8 more] [flagged] ethbr1 13 hours agorootparentSure, before circa-butterfly keyboards. Then it was only \"the recent OS version has bugs\" gripes. reply Sharlin 13 hours agorootparentprevYes, lots and lots. reply t888 13 hours agorootparentI think you’re mistaken. Care to link to a single post where the commentary is positive about Apple? reply Sharlin 13 hours agorootparentThe null hypothesis is that there is no particular bias either for or against Apple on HN. The burden of proof is on you if you claim such a bias exists. My counter-hypothesis is that HN has a pro-Apple bias on average simply because it's an American tech-focused site, and Apple is an American tech company. If everybody on HN were European or Asian, the average opinion might be less favorable. But it's just a hypothesis, one I'm not particlarly inclined to defend. reply t888 12 hours agorootparent1. I’m not the one making the claim without evidence. You are. 2. I see absolutely no reason why the null hypothesis should be that a randomly selected social group would be unbiased about any particular issue by default. If you think about it for any length of time you should see that as implausible on its face. 3. You’ve just made up a weird ’counter hypothesis’ of pro Apple bias of your own and thrown it into the discussion for no apparent reason, while claiming not to be willing to defend it. That seems underhanded. 4. Why not just provide some evidence? I’m even more sure you’re wrong now that you’ve chosen to defend your position using these tactics, since it would be trivial for you to provide a link if you actually do remember such a discussion. reply Sharlin 11 hours agorootparentYou started this by asking > Have you seen any positive discussion of Apple here? strongly implying that you think there's no positive discussion of Apple here. > I see absolutely no reason why the null hypothesis should be that a randomly selected social group would be unbiased about any particular issue by default. If you think about it for any length of time you should see that as implausible on its face. Wikipedia: \"The null hypothesis is a default hypothesis that a quantity to be measured is zero (null).\" You're looking for an effect, in this case \"bias for or against Apple\", and claim not only that it's nonzero but that it has a certain sign. The only reasonable null hypothesis is that there's no bias, because without doing an actual study, there's no way to say whether any bias that might exist is pro- or contra-Apple. And \"I never see anything good said about Apple\" only counts as extremely weak evidence, given how incredibly prone to confirmation bias humans are. reply t888 11 hours agorootparentSo? You made a claim that you had actually seen “lots and lots” of positive discussions, yourself. That’s not just a question with an implied direction. You claim to have seen the evidence with your own eyes. And yet when asked produce it you immediately began protesting that you didn’t have to. You can’t produce the evidence, because there isn’t any. You made your claim without regard for evidence, because even a trivial search for Apple related material shows an overwhelmingly negative view of Apple here: https://hn.algolia.com/?dateRange=all&page=0&prefix=false&qu... reply alanbernstein 16 hours agoprevI want to recreate the windows Maze screensaver in VR... but with the animated fractal textures on walls, floor and ceiling. reply RobertRies 16 hours agoparentThat sounds oddly terrifying. Like gray goo devouring the world. reply starshadowx2 15 hours agoparentprevI'm not sure if you can change the textures but there is Screensavers VR - https://store.steampowered.com/app/881670/Screensavers_VR/ reply serf 4 hours agoparentprevthat's only a few elements away from a 'Serial Experiments: Lain' episode. reply j_m_b 17 hours agoprevThis bring back memories of AfterDark. They had other screen savers in the software package, but this was definitely the most whimsical. reply bredren 16 hours agoparentThe Star Trek AfterDark screensaver was the jam! Tribbles https://www.youtube.com/watch?v=OdQ_ekXdoqU reply laborcontract 13 hours agorootparentThis is hypnotic. Literally put me to sleep reply ethbr1 13 hours agoprevThis makes me feel old. Number of things that need explaining now: - Computers used analog CRT monitors - CRTs had burn-in if left static - Screen savers showed dynamic images - After Dark / flying toasters was a classic screensaver - Software was sold on floppy disks - Purchased at physical computer stores - After Dark-era floppy disks were hard, not floppy - \"Screen Savers\" is also not to be confused with the TechTV show - TechTV merged with G4 in 2004, then closed in 2014, then restarted in 2020, then reclosed in 2022 I think that brings us back to modern times. Also, has anyone recreated Snake for the AVP yet? And I don't mean fancy-Snake: I mean Nokia Snake. reply thebruce87m 11 hours agoparent- People didn’t care about power usage as much Also, with OLED monitor screens becoming more popular maybe they will make a comeback? My OLED TV has a screensaver. reply halfnormalform 7 hours agoparentprevThe small floppy disks were still floppy disks. Thick plastic does not make a hard disc! reply msmith 13 hours agoparentprev- “G4” the TV network, not to be confused with the series of Mac computers reply yardstick 16 hours agoprevWhile we’re going down memory lane, I wish someone would recreate, reimagine, or make a sequel to Johnny Castaway. reply sumtechguy 15 hours agoparentmumble mumble mumble hEEEEEEEE reply Gormo 16 hours agoprevI'd love to see a full port of XScreenSaver to VR platforms. It has its own variation on flying toasters (https://youtu.be/mLGDvtbFvfg) along with many, many other modules. reply SapporoChris 14 hours agoparentCan you explain the desire? Is it just nostalgia? I just don't understand the need for a screensaver for a VR device. Do people idle long enough with the VR device worn for a screensaver to come on? reply Gormo 14 hours agorootparentIn addition to their functional purposes, screensavers are aesthetically pleasing, and experiencing them in 360° immersion for short periods of time is something some people would enjoy. Perhaps there's a novelty factor here, i.e. a desire to experience familiar things in a new context, but I don't see where nostalgia would apply, other than to the flying toasters imagery specifically. reply clintonb 15 hours agoprevI was just thinking about MOPy fish (https://en.wikipedia.org/wiki/MOPy_fish)...and how much it encouraged wasting paper! reply ProllyInfamous 14 hours agoparent> https://en.wikipedia.org/wiki/MOPy_fishreply rcarmo 16 hours agoprevI love that it's in the \"Productivity\" category in the App Store. reply readyplayernull 11 hours agoprevThis is exactly the kind of first apps developed for devices. Since history repeats, I'm waiting for my Vision miner headlamp. reply notbeuller 12 hours agoprevThe youtube video linked has the toasters going north west to south east - they canonically travel from north east to south west. Did they flip the video to avoid a copyright claim? reply dhosek 17 hours agoprevDefinitely a 1.0 product in the graphics, but I love the whole concept of a murmuration of flying toasters in my living room. More whimsy like this, please. reply bayeng 17 hours agoparentYep, I wanted to get something out there and iterate based on feedback. Would love to hear suggestions! reply xu_ituairo 17 hours agorootparentMaybe some sort of cube mapping on the toasters to give them a reflective metallic look will make them blend with the environment more, situating them in the space and harkening to the original (The APIs don’t let you use the actual environment for reflections, right?) reply bayeng 16 hours agorootparentThank you for the recommendation! I applied a \"Physically Based\" material to the toasters, setting the \"metallic\" attribute to its maximum value. The app preview/screenshots might not fully showcase the potential metallic appearance, which depends on the lighting conditions and the selection of the right emissive color. I'll experiment some more to enhance its reflectiveness under a broader range of conditions.(The APIs don’t let you use the actual environment for reflections, right?) That's a good point..I don't know the answer to your question but maybe I just need to add a light source in the virtual world. reply lelandfe 16 hours agorootparentprevThe video on the App Store seems to show the toasters glitching out and rotating randomly. I think it's when they interact with each other. reply Dalewyn 16 hours agoparentprevI definitely appreciated (and still do!) having my mind blown as a kid by the sheer sense of humor that developers have. It feels like we lost many subtlely important things in the drive starting in the 2000s to \"clean up\" software and their development. reply inhumantsar 14 hours agorootparenttoo many cooks (and too much money) in the kitchen reply thangalin 16 hours agoprevShout out to the author, Bill Stewart. https://uxfactor.ca/1151/ reply notbeuller 12 hours agoparentBill Stewart was by no means the author of after dark or the flying toasters[1] He did do the windows port of the screen saver engine and some modules, but that was years after they'd first shipped as part of the Mac version of After Dark. [1] https://en.wikipedia.org/wiki/After_Dark_(software) reply exe34 16 hours agoprevMy favourite screensaver was a mac app I installed around 2009, it would randomly show a BSOD. Was quite the novelty at the time, given the laptop only really crashed twice in the 4 years I had it and then had to give it back to the department. reply pryelluw 16 hours agoparentOT: check out my annoying screensaver based on the bouncing DVD logo. https://github.com/pryelluw/mac-dvd-screensaver reply rideontime 16 hours agoparentprevSounds like the BSOD screensaver included in XScreenSaver, which you can still install today: https://www.jwz.org/xscreensaver/screenshots/ It actually fooled me once when it happened to choose a MacOS crash screen while I was in the bathroom. reply MikeTheGreat 16 hours agorootparentThis link doesn't go to a screenshot of a BSOD - it goes to a picture that disses (insults) HackerNews folks (https://cdn.jwz.org/images/2024/hn.png). Was this on purpose? Based on the rest of the comment I'm guessing you pasted the wrong link? If not - congrats on the successful Rick Rolling (or whatever it's called) reply unpixer 16 hours agorootparentNo, that's probably the correct link, but jwz doesn't like the HN crowd and filters for referers. reply exe34 15 hours agorootparentThat's the level of petty I aspire to, but don't have the energy to deliver on. reply inhumantsar 14 hours agorootparentjust imagine the hours that someone spent making that unsettling image. if someone found a way to turn spite into electricity, we would never need to build another power plant. reply exe34 13 hours agorootparentSpite is the greatest motivator. Many a book have I finished reading because damn it, I'm not folding. reply 082349872349872 16 hours agorootparentprevrideontime's link is cromulent; jwz does that if you follow it from HN. reply avhon1 15 hours agorootparentprevCopy the link and open it in a new tab. Works fine. reply sumtechguy 15 hours agorootparentprevThere is one from MS too. https://learn.microsoft.com/en-us/sysinternals/downloads/blu... reply pugworthy 12 hours agoprevVoodoo Lights was my go to back in the day reply gimmethecookies 15 hours agoprevI would get this just to keep jumping through the portals and chilling in the toasterverse. Looking forward to what else the dev has in store! reply orblivion 16 hours agoprevApple already recreated Dinosaur Adventure 3D, sort of reply rideontime 16 hours agoprev [–] All that effort, only to use a disgusting AI-generated app icon. That's a shame. reply Tadpole9181 16 hours agoparentThey're a developer making a cutesy little nostalgia toy, not an artist. I'm sure they'd be ecstatic for you to donate a couple hundred for them to hire a professional humam? In the interim, this works fine and looks better than what most developers can make themselves. reply talldayo 15 hours agorootparentPersonally speaking, I think ugly programmer art is better-looking than an AI icon. Even if it was a two-tone vector silhouette of a slice of bread, it would be more evocative and readable to me. The app is theirs, and they should feel proud enough to make an original icon for it too. I agree with the parent, the AI-generated icon would be the first thing stopping me from spending $1.99 on this. reply sp332 14 hours agoparentprev [–] Agreed. The toaster is made of a loaf of bread? And the slots are sideways. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author created a screensaver app for Apple Vision Pro, mimicking the iconic \"Flying Toasters\" screensaver from 1989, with interactive toasters and customizable features.",
      "The app incorporates gesture controls, 3D animations, and was developed using Swift, showcasing the author's technical learning journey and problem-solving skills.",
      "Feedback is requested to enhance the app's future iterations, emphasizing the author's openness to improving their creation based on user input."
    ],
    "commentSummary": [
      "Users are interested in nostalgic screensavers like Flying Toasters for the Vision Pro, sparking a debate on the inclusion of screen savers in the App Store.",
      "Concerns about price, content, and developer support are raised regarding Apple's VR technology, drawing comparisons to past successful products and the evolution of VR tech.",
      "Discussions include biases towards Apple, technological advancements, nostalgia for old screensavers, and enhancing the experience of classic screensavers on VR platforms."
    ],
    "points": 150,
    "commentCount": 114,
    "retryCount": 0,
    "time": 1712071868
  },
  {
    "id": 39906147,
    "title": "Tesla Raises Model Y Prices: Duration Uncertain",
    "originLink": "https://electrek.co/2024/04/02/tesla-releases-q1-2024-deliveries-disastrous-results/",
    "originBody": "Tesla increases Model Y prices, but for how long? Fred Lambert Apr 1 2024",
    "commentLink": "https://news.ycombinator.com/item?id=39906147",
    "commentBody": "Tesla releases Q1 2024 deliveries: disastrous results (electrek.co)148 points by mfiguiere 19 hours agohidepastfavorite293 comments nixgeek 19 hours agoSome friends bought a Model X about six months ago, spending over $100k — that’s down from the almost $150k that Tesla was demanding a couple years ago when we bought one (and both were fairly fully loaded). First, my experience 2 years ago was the A/C compressor was so loud that during summer with cooling running at maximum, you couldn’t hold a conversation in the cabin because of the noise. Tesla investigated and eventually said “looks fine to us, there isn’t designed to be any additional noise abatement on the firewall between the front and the passenger space”. We had issues with our Falcon Wing doors, and we eventually sold the vehicle after a year. Now, our friends Model X, that’s had ~6 non-trivial maintenance problems in six months, including the Falcon Wing doors failing three times, and they’re in the process of trying to get a refund through Lemon Laws. Other acquaintances who own Teslas also have service issues on their Model X, the Cybertruck looks like an even worse mess, so I concluded over a span of multiple years, quality still isn’t a strong suit of Tesla, thus I’m not shocked to see there’s limited brand loyaly, and with increasingly viable competition, demand is falling? I now have a Rivian R1S and we are incredibly happy with that vehicle, having put about 6000 miles on it. Mercedes EQS also seems like a reasonable choice in 2024, depending on what you want. reply bigtunacan 8 hours agoparentOne of my coworkers bought a Model S. At first he was always going on about how amazing it was. Then within the first year he started having all kinds of problems with it. He's now in the middle of a lawsuit trying to get a refund on it. reply ChumpGPT 18 hours agoparentprevYou're not buying quality when you buy Tesla, you're buying fashion. if you want quality buy a Toyota/Lexus. reply dragontamer 18 hours agorootparentI'm a big fan of Toyota Prius Prime and RAV4 Prime. (High efficiency vehicles, Prius Prime is #1 most green car of ACEEE list, etc. etc.). But people buying Tesla aren't aligned to Toyota. But a better match to culture is likely Jeep Wrangler 4xe. Incredible offroading performance, reasonable towing capacity, large size / in-your-face advertising to some extent. And electrified, so that your daily commute is efficient and environmentally friendly. Etc. etc. There's a lot of competition these days. People who buy Toyota / Honda are people who care #1 about reliability and simplicity. But \"Tesla Buyers\" are more excited about niche features or feeling like their car can do something other cars cannot do (even if they never actually use that feature). And honestly, vehicles like Jeep Wrangler 4xe are best suited for that mindset. --------------- Or the new Dodge Charger EV. Now that Stellantis is making their EV push, I think Stellantis has better branding for what the stereotypical Tesla Buyer is going for... without the awfulness associated with Elon. reply ProfMeowsworth 1 hour agorootparent> electrified, so that your daily commute is efficient and environmentally friendly. Moving an off-road vehicle of over two tons to transport (usually) one person to work seems neither efficient nor environmentally friendly. The vehicle being electric doesn’t change that, as the electricity has to be generated somewhere. reply LUmBULtERA 18 hours agorootparentprevNaw, I and many people probably cross shopped Toyota's Prius Prime and Rav4 Prime with the Tesla Model Y. As of last fall and early this year, both models were barely to be found in Northern Virginia, and if you could find one within hours of where I live they were under huge dealership-fuckery with options and markups. When I finally was able to test drive a standard 2023 Prius, I decided its cargo space was way too small for what I was looking for. When test driving a Rav4 (not Prime) I decided its visibility (for me, maybe this is highly personal) was absolutely terrible compared to the Model Y. Model Y prices were VERY competitive compared to Rav4 Primes anyway, so that's what I went with. I've been very happy with it. reply themaninthedark 18 hours agorootparentprevWe have EV sports cars, SUV, trucks and package vans but I have not seen an EV passenger van. I suppose they are out of fashion right now but honestly that is the form factor that I would be most interested in. I could use it for both home projects but also with the longer body it would have have a fairly decent range so wouldn't be bad for the family road trips. I don't like the idea of having to stop every 2 or 3 hours, 4 would be more ideal. reply dragontamer 18 hours agorootparentChrysler Pacifica PHEV should be mostly electric on daily drives and then gasoline for the long trips. Honestly, passenger van / road trip vehicle makes the most sense in PHEV form factor out of all other styles IMO. reply cameldrv 15 hours agorootparentYes on paper this looks like a great and very practical vehicle for many people, but boy am I hesitant to buy a Chrysler product with this amount of drivetrain complexity. You've got everything that can fail in a fairly high tech ICE drivetrain, plus everything that can fail in an EV drivetrain, made by the lowest reliability major automaker. reply dragontamer 13 hours agorootparent> You've got everything that can fail in a fairly high tech ICE drivetrain, plus everything that can fail in an EV drivetrain You should seriously look up the drivetrain of hybrids. The planetary gearset is a single set of gears that functions as the alternator/generator, the starter/EV motor, the transmission, and the engine driveshaft. Its not \"different\" or \"new\" components. Its a singular design that accomplishes what 3x different parts of the car used to do seperately. There's a reason why Toyota Hybrids are $23k, its a lot cheaper and more efficient to do it this way. https://www.youtube.com/watch?v=jofycaXByTc You needed the starter anyway. When its beefed up to a full-size EV motor that can drive the car, its more powerful and more durable. You needed the alternator anyway. When its beefed up to a full-sized generator, its more powerful and more durable. When the ICE engine operates at its ideal RPM (rather than directly connected to the road), it can be made cheaper, more reliable, smaller, more efficiently than when its the only thing moving the car. Hybrids are superior to ICE, and Prius shows how to do it with more reliability. Now yes, Chrysler is terrible with reliability, but that's nothing to do with Hybrids and everything to do with Chrysler. reply NovemberWhiskey 17 hours agorootparentprevThe Volkswagen ID.Buzz (sic) is supposed to start selling in the US this summer. reply macintux 18 hours agorootparentprevI bought a new Wrangler last year, and I was sorely tempted by the 4xe, but Chrysler's track record with electronics is pretty poor. I'd lease one, but I don't think I'd buy one. reply nixgeek 18 hours agorootparentprevI don’t think either had an EV option suiting my needs when we bought a Model X? Meaning able to seat 6-7 humans and ~300 miles of range in the battery pack? Do they even have a viable option today? (I’m unaware how the Lexus electrification is going.) reply NovemberWhiskey 18 hours agorootparentForget Toyota/Lexus, that's a bit of a red herring - the point is that there was literally no competition for Tesla in three-row electric vehicles when you bought yours. Now, you have the choice of a Mercedes-Benz EQB or EQS, a Rivian R1S (as you chose) or a Kia EV9 with Lucid, Hyundai and VW all with products about to enter the market. reply leereeves 17 hours agorootparentToyota Motor North America sold over 200k \"electrified\" vehicles in the first quarter 2024. Their sales alone could account for the unsold Teslas. https://pressroom.toyota.com/toyota-motor-north-america-repo... Those are mostly hybrids, but reportedly, U.S. sales of gas-electric hybrid vehicles surge and electric-vehicle sales cool https://www.reuters.com/business/autos-transportation/us-aut... reply zamalek 18 hours agorootparentprevAs for Toyota, 6-7 humans, it's either hybrid or you're SOL. I think the GP might have been referring to ICE? reply cameldrv 15 hours agorootparentprevThe thing is, I'd say Rivian is considerably more fashionable at this point. The only problem with them is potentially going out of business. reply darthrupert 18 hours agorootparentprevI got a Tesla (model Y) because I wanted an reasonably priced family EV with long range. It seemed to be the best choice, and so far I'm not disappointed. I'm not gonna get another Tesla, but not because I dislike the brand, rather because one buys so few cars in one's life that it's more interesting to get something else. reply jredwards 16 hours agorootparentprevI'm buying a budget EV with the model 3. I'm pretty happy with that. reply krunck 18 hours agorootparentprevI can't wait until Toyota makes an all electric Yaris. reply Integrape 17 hours agorootparentI hope they bring back the Matrix as an EV reply smallmancontrov 18 hours agorootparentprevYeah, and the twitter opinions are really stinking up the brand so depending on your social group you may want to look elsewhere. Maybe Elon can get conservatives to buy EVs to \"own the libs.\" Godspeed on that, but so far it doesn't seem to be working. reply dzhiurgis 13 hours agoparentprevS and X are not their bread and butter. Look at how well LFP 3's and y's hold up. reply misiti3780 18 hours agoparentprevI have had the exact opposite experience w/ both of my cars, multiple friends have had the opposite experience also - what is your point? reply hn72774 18 hours agoprevCould it be that Musk's inflammatory language and behaviors are a turn off for potential buyers? They are a turn off for me. I like the vehicles but I'd never get one. reply monitron 18 hours agoparentYep. I am a current Tesla Model 3 owner, really like my car, but plan to switch to another brand after running this one into the ground. Elon's behavior is awful and dangerous given his fame/money, and luckily, unlike in 2017, there are now other good EV options which are getting better all the time. reply trogdor 16 hours agorootparentI recently saw a Tesla that had a “No Elon” magnet on the back. (Red circle over white background, with a diagonal red line through the word “ELON.”) I talked to the owner who said that his wife had custom ordered it. reply smallmancontrov 18 hours agorootparentprevHow is the charging situation? I remember that everyone announced NACS and compatibility with the Tesla network a while ago, has that happened or is it still just promises? reply coldpie 18 hours agorootparentTechnically still just promises, but the timelines are all in the 1-3 year range, which seems about right for a manufacturing and support line change. I think Hyundai/Kia plan to start shipping native NACS cars this year. reply e36 18 hours agorootparentprevIt's in progress, I think. Ford and Rivian just gained access to the network about a month or so ago, and I think that other manufacturers will be added over the next year or two. reply vishalontheline 18 hours agorootparentprev> after running this one into the ground Oh, come on. Don't wait another 25 years! /s reply qwerpy 18 hours agoparentprevThis seems to be the case for some online communities, but in my offline circles (Asians working in tech in the PNW) no one seems to care. Driving on the street it seems every other car is a Tesla, and by and large everyone is pretty happy with them. I wouldn't say we're particularly pro-Tesla either, it's just that they were the best cars for the money at the time. As more car manufacturers start to deliver good EVs, I think you'll start to see more variety in the EVs on the road. For example my next car after the cybertruck could be a Rivian or an electric van, if someone finally decides to make one. reply amerkhalid 16 hours agorootparentSame here in Frisco, Texas. Teslas are so common here and pretty much it is always Asians driving them. I keep hearing that Tesla is the new Toyota. But talking with some of the Tesla owners, many feel embarrassed by Elon. Many say that they will not buy another Tesla or they have some other reasoning to justify their purchase (like Elon has gone crazy but we shouldn't punish the entire company for it etc) reply dzhiurgis 13 hours agorootparentChinese and Indian might be the most based races. As opposed to white people who are always sensitive to something..? reply AlexandrB 18 hours agoparentprevForget the content of what Musk says, the fact that he's on Twitter so much seems like a bad sign if you're a Tesla shareholder. His attention is already split between 3-4 companies, if he's tweeting all day on top of that how much attention is Tesla and its problems/opportunities getting? reply mullingitover 18 hours agorootparentA business who had an assistant manager who spent this much time on Twitter during business hours would've written a pink slip a long time ago. Investors/BODs are shockingly forgiving. How is he creating value when he's spending half his time being a keyboard culture warrior? reply sf_rob 17 hours agorootparentprevWhile Musk’s attention was certainly a key asset in Tesla’s early years, I’m not sure that his attention is still a net positive. reply 3cats-in-a-coat 17 hours agorootparentprev> how much attention is Tesla and its problems/opportunities getting Judging by the fragmented and meandering Highland/Juniper roll-out, none. The company seems to be running on autopilot (or should I say, full self-driving), where local management is making local decisions out of sync with the rest of the company to try and save another quarter. Which is clearly not working anymore. reply jorlow 18 hours agoparentprevFor me it's this + going overboard on minimalism (speed only on center screen, turn signals now buttons, wiper controls on touch screen). It's a shame because there's a lot to like about the model 3. reply Sammi 17 hours agorootparentI cannot own a car with unreliable wiper controls. It rains to much where I live. Without a stalk I would definitely go crazy. reply dzhiurgis 13 hours agorootparentprevI tried buttons on a 2 minute drive and it's instantly obvious it's better. reply Tiktaalik 18 hours agoparentprevPersonally I’d never buy one for that reason. Would never work for one of his companies either. I don’t want to contribute to his wealth. reply FredPret 18 hours agoparentprevIt's such a shame that he's sullying his reputation like this. Howard Hughes-like. He could have retired in a blaze of glory a couple of years ago, straight into the pantheon of epic American entrepreneurs. reply dralley 18 hours agorootparentHis behavior isn't the only Howard Hughes callback. The entire Cybertruck project screams it. reply silverquiet 18 hours agorootparentI didn't think about the parallel to the Spruce Goose, but it's a fair comparison. Honestly, it seems to happen to a lot of megalomaniac, ivory-tower type creators - the urge to build something to top their last creation (and for all his faults, Elon does have some really impressive creations behind him). The other example that jumps to mind is George Lucas with the Star Wars prequels. reply philistine 17 hours agorootparentThe Star Wars prequels are not comparable to the Spruce Goose. The Star Wars prequels did exactly what they intended to do: sell toys so George could maintain the independence of Lucasfilm. The fact those movies are terrible is irrelevant. reply mschuster91 18 hours agorootparentprev> The other example that jumps to mind is George Lucas with the Star Wars prequels. These were by far not as bad as some people tend to paint them, the problem with the Star Wars prequels IMHO was more that the \"old guard\" fanbase tends to be quite the whiny bunch. The sequels are another topic entirely - these were corporate driven projects which isn't a bad sign per se (see the MCU), but unlike the MCU there wasn't a central person like Kevin Feige who actually took care about a cohesive storyline, directors and script writers kept changing, and the SW universe unlike Star Trek or MCU doesn't have a concept of multiple/alternate realities or time travel so a ton of lore went down the drain for nothing. reply archagon 15 hours agorootparentThey’re just stories. A future Disney could declare 7-9 non-canon and redo the lore. reply smallmancontrov 18 hours agorootparentprevApparently Henry Ford bought a newspaper (the Dearborn Independent) to publish his opinions on jews. History sure does rhyme. What is it with car CEOs? reply FredPret 14 hours agorootparentIf it rhymes this much, it's bad news for Musk but fantastic for Tesla. Ford has generated a ridiculous amount of shareholder returns over the years and makes good cars today. reply cavisne 16 hours agorootparentprevVery unlikely, Bezos & Gates basically did that and they are still massive targets of criticism. If Elon had decided to just roll over a couple years ago and do everything the media asked him to do (shutdown the Fremont factory during covid, stop \"polluting the sky\" with starlink, rely on a nice unionized automaker like GM to \"lead the EV revolution\") Tesla & SpaceX wouldn't exist today. reply r00fus 8 hours agorootparentNone of that shit actually matters to the people who despise Elon. No, it’s the fascist-friendly sex-mongering racist rhetoric that gets most people. Even that could be explained the way if it weren’t for his inept business moves with Twitter and ugly cybertruck. Jobs proved you can be worshipped while being an eccentric asshole if you’re at least competent. reply JKCalhoun 18 hours agorootparentprevSouth African entrepreneurs? EDIT: I had heard he was South African. Googled it though: \"South African-born American businessman\" so I guess he is American now. Thanks. reply AlotOfReading 18 hours agorootparentHe's a US citizen, he lives in the US, and his companies are headquartered in the US. \"American\" is definitely an appropriate label here. reply anonporridge 18 hours agorootparentprevYou seem not American. To Americans, being born to a different nationality doesn't preclude you from being considered a full and true American. First generation immigrants and naturalized citizens tend to be completely accepted as equals by natural born citizens, so long as they are productive and not criminally destructive. I do understand that this tends to not be the case in many other countries, where even second generation immigrants may not be fully accepted because ethnic identity is so deeply entwined in nationality in most countries. reply VBprogrammer 2 hours agorootparentYou would have to admit that passing the \"looks white to me\" test helps a lot in being culturally accepted as an American. You don't have to go very far to find counter examples. Even in this comment section people talk about \"Asians\" driving Tesla's - regardless of the fact they maybe second or third generation Americans. reply leetharris 18 hours agoparentprevThe vast majority of the world doesn't exist in the online sphere. I think that they have saturated the initial EV buyers, mainstream is still afraid of EV and there's more anti-EV propaganda in the media than ever before. reply afavour 18 hours agorootparent1. The vast majority of the world isn't buying Teslas, either 2. Musk is one of few figures whose controversies escape the online world, though. Like the \"pedo diver\" thing, it was an international story with world attention and he jammed himself in the middle of it. That said, I'm also not convinced his reputation is the reason for shipments to drop precipitously. But it could absolutely be a contributing factor. reply JKCalhoun 18 hours agorootparentprev> The vast majority of the world doesn't exist in the online sphere. I wonder if the vast majority of potential Tesla customers does though. reply JohnBooty 17 hours agorootparentprevThe vast majority of the world doesn't exist in the online sphere. Well, no, but the \"vast majority of the world\" isn't in the market for a Tesla, either. You don't think there's a significant overlap between prospective Tesla buyers and people who are familiar with Musk's hijinks? reply AlexandrB 18 hours agorootparentprevSome of it is propaganda, and some of it is a direct result of Tesla's design choices. It would be ironic if Tesla helped give EVs a bad name with novelty \"features\" like electric door latches and a lack of mechanical controls. reply hn72774 18 hours agorootparentprevHe's supporting a dictator that launched a full scale war in Europe. Hard no for me. reply jborden13 18 hours agoparentprevI think there are lots of us. reply drcongo 18 hours agorootparentSame. If I wanted to project that image I'd just paint a swastika on my existing car. reply jeffwask 18 hours agoparentprevHonestly, he has been on a tear alienating the primary pool of Tesla buyers and appealing to a group that denies climate change and would never buy an electric car. I used to hear praise of Musk constantly from other folks in software 10 years ago and all that positive buzz is gone. reply sylens 16 hours agoparentprevI'm in the market for an EV for the first time and won't consider a Tesla due to him going full mask off on Twitter over the last year. reply tejohnso 18 hours agoparentprev> \"Whether you hate me, like me or are indifferent, do you want the best car, or do you not want the best car?\" ... only works when you're making the best car. There are a lot of very competitive EV alternatives now. reply sixothree 9 hours agoparentprevThere are other practical reasons too, but I am literally never going to buy a Tesla. It’s just never going to happen. He’s made it his mission to insult me on a personal level. One dollar equals one vote so I pay attention where mine go. reply b0sk 18 hours agoparentprevYes. I am a Y owner and in for a 2nd EV. But waiting until Rivian R2. reply zamalek 18 hours agoparentprevAnecdata: I had paid my $200 [sunk cost] deposit. Elon's bullshit turned me away. reply r00fus 8 hours agorootparentThe deposit is refundable, you know. reply cqqxo4zV46cp 18 hours agoparentprevEven if I wanted a Tesla, it wouldn’t pass the partner acceptance test for me. My partner is aware of the quality issues, but beyond that, she (like me) can’t help but cringe at the optics of owning a Musk-mobile. If you want to be a loudmouth dick online and intertwine your persona with that of your companies for #traction, it cuts both ways. reply qwerpy 18 hours agorootparentIt's funny how different cultures view things so differently. My wife (Chinese) and her circle of friends are pretty much the opposite. They used to all get BMWs/Mercedes but with how practical EVs are, the default choice is now Tesla. I think they're somewhat aware of Elon's shenanigans but it's all chalked up to \"silly American politics\" so no one cares. reply dorkwood 18 hours agoparentprevDeliveries are still up since Q1 2023, so I guess not. reply jsnell 18 hours agorootparentThe numbers from the article are 422k deliveries in Q1 2023, 386k in Q1 2024. That's down by almost 10%, not up. reply ddoolin 19 hours agoprevThis may be related as well, in a smaller way: https://www.reuters.com/business/autos-transportation/would-... reply epistasis 19 hours agoparentI ask owners of other EV vehicles how they like their car, and >50% of my sample size of ~10 bring up \"at least it's not owned by that crazy man\" as a big reason as they explain the other deficiencies. (Mostly bad controls, UX, etc. stuff that the Tesla gets right.) I have a Tesla Model 3 right now and it's my favorite car ever, by far, but I also will be unlikely to buy another tesla. It's not the same company as six years ago. reply brtkdotse 19 hours agorootparentI chose a Kia eNiro because it had ”bad” but predictable controls/UX. Basically a normal, boring car with dedicated buttons for most things, but with a EV drivetrain. reply Stratoscope 18 hours agorootparentSame with my Kia EV6. After driving my old Kia Rondo for 15 years, I felt right at home in the EV6. Traditional stalks for lights and wipers, all kinds of dedicated buttons, familiar and comfortable. Kia went to quite some work to make it feel like a regular car. reply ein0p 18 hours agorootparentprevFunny, I'm considering buying our second Tesla (to replace my BMW) because the company _is_ run by Musk. I'm also big fan of not dictating what other people should say, and find his direct communication style refreshing, even though I disagree with some of his opinions. And that's before we even bring up several other areas where he's successfully doing civilizationally impactful work. reply rcMgD2BwE72F 18 hours agorootparent>even though I disagree with some of his opinions Let me guess, nothing that's part his core believes? reply ein0p 18 hours agorootparentYes, I do believe our species needs to be multiplanetary, internet should be available everywhere, electric cars need to take over, and paralyzed people should be able to walk again. reply mschuster91 18 hours agorootparentWe share the same goals (except for electric cars needing to take over - they do, but the real issue is that public mass transit needs to take over!), but the methods / the lengths Elon Musk is willing to go to in pursuit of those goals are disturbing to many people. reply ein0p 18 hours agorootparentI don't think public mass transit will take over in the US in my lifetime, outside major cities. We're just too spread out, and a lot of us, especially people with kids, like it that way. Mass transit absolutely, positively does not work in the US if you have at least one child. reply ericmay 17 hours agorootparent> Mass transit absolutely, positively does not work in the US if you have at least one child. Kind of a confusing statement. Sure the current state doesn't work in the US, which is because it isn't designed to work and there is little to no investment or money spent on public transit. You can know that this is factually true by looking at your state department of highways budgets and examining how funds are allocated. It does work in other countries, including countries that have parents with children. There is no logistical or cost-based reason it won't or couldn't work in the US. Nothing special about \"spread out\" - which is another choice we intentionally make or the size of the country. It's also mostly untrue since most of the population in the US lives in urban areas. Suburban areas can just continue to grow as is and become more dense while preserving SFHs. reply ein0p 17 hours agorootparent_Transit_ is not what needs to change first. Infrastructure (stores, schools, daycares, hospitals, offices) needs to change before mass transit is even feasible. And that needs to be built out over an extended period of time, like 15-20 years, to have good coverage. This is particularly hard to grasp for someone who has never lived in Europe, which I have. So we “invest” in mass transit which (at least in my neck of the woods) almost nobody uses because it’s 10 minute drive to the grocery store and 15 minute drive to school, and both of those numbers triple or quadruple without a car. And now consider your kids extracurriculars, like swim team or something. And now consider having 2-3 kids. Cars are here to stay. To refrain from improving them would be like not doing anything about energy generation until we have fusion, which probably also won’t happen in my lifetime reply mschuster91 15 hours agorootparent> Infrastructure (stores, schools, daycares, hospitals, offices) needs to change before mass transit is even feasible. And that needs to be built out over an extended period of time, like 15-20 years, to have good coverage. It's a chicken and egg problem in the end. A government has it easier to just dump funds for 10-20 years onto public transit subsidies (and provide the guarantee to the third parties you mention that any investment they make isn't going to be in vain) than if it convinces and pays off all these third parties to change before there is a viable public transit system. reply ein0p 15 hours agorootparentIn much of the US you can’t even build places people would need to walk to within walkable distance, due to zoning. A bus which takes 30 minutes to take you to the grocery store is barely any better than no public transportation at all. I haven’t used public transportation even once in the last 15 years. I sometimes check how long it’d take to get to the places I need to be however. Grocery store trip turns from 9 minutes into 36 each way. Going to work takes 25 minutes by car or an hour and a half by bus, each way. Dropping off my kid at his soccer practice? 8 vs about half an hour, each way. Idk where you people live that you think spending 3 hours daily on a bus is feasible or desirable, let alone logistically possible. reply nunez 15 hours agorootparentprevCities in those countries, for the most part, were built around public transit. As a result, navigating by car is difficult and sometimes costly. Retrofitting public transit into a city designed for cars at that same scale is unbelievably expensive before the costs of changing public opinion are factored in. I say this as someone who dislikes what suburbs have become and would _love_ to see public transit proliferate throughout the US. reply ericmay 14 hours agorootparentWhere I live I’m Columbus I can still see the trolly tracks lining my streets. Buildings were torn down to pave over for parking lots. There is not this extensive retrofit that needs to occur for many American cities, it just needs to be funded. In my home state of Ohio and in my home town we are spending a billion dollars to build a new ramp and make some other changes to a highway that was built well after the city was founded to make it “easier” for car traffic. We have the money. We are just choosing to spend it only on car infrastructure. I do agree about public opinion though. But fortunately attitudes amongst millennials and Gen Z seem to be strongly in favor of better transit and more dense development patterns. reply fuzzfactor 11 hours agorootparentWhere I live I'm Sam Houston ;) The city named after me was also founded (1836) purposefully on undeveloped land and planned from the beginning to become an urban center and territory capital. Within 3 decades of when Columbus got going, so I would have to say they both have a downtown layout that was originally designed for horses and horse-powered vehicles to begin with. And to accommodate a lot more horses in the future than there were in the area at the time. Plus think of the gig workers. I can only imagine one of the blocks where people are waiting for an Uber today, is where early residents were once waiting for a Wells-Fargo coach. Once the Wells-Fargo startup was able to leverage being online 24/7, at your local telegraph office ;) Streetcars came in the late 1800's and I would expect tracks were laid on what could be considered thoroughfares. There was probably quite a bit of urban character by then and a good chance it was the rapid transit offered by the march of technology, rather than the mass transit aspect that was most appreciated by the riders. Houston already had horse-powered \"buses\" before this. Next thing you know, a few decades later there's Model T's and you can really save tonnes of animal feed while helping the environment (at the time) at the same time. They all shared the roads even if it was not all horses and pedestrians as intended any more. After years of mass-production, it would be like cars are reproducing faster than horses and taking over the place, car owners would have growing influence. Plus if for some reason older mass-transit hardware were deteriorating at a faster rate than the payer could justify reversing, there would be increasing incentive to eventually throw in the towel and let people drive themselves around. It could happen ;) Technology marches on but the mainstream beats the most heavily-trodden path. reply ericmay 11 hours agorootparentThankfully technology continues to march on, and the march of progress will continue to free us from being required to buy cars instead of starting new companies. reply mschuster91 17 hours agorootparentprev> Mass transit absolutely, positively does not work in the US if you have at least one child. Here in Munich, one of the densest cities in Europe, I took the subway alone at age 7. There's nothing preventing US kids from doing the same with a bus, no matter if driven by a human or by some sort of autonomous system - except that US infrastructure at large is completely focused on cars and has zero respect for anyone not in the safety shell of a car, so it will be a challenge for a kid to even get to a bus stop safely. But that can change, even in the matter of a few years. All it needs is the political will, a bit of funding, and in larger cities to get the homeless and drug addicts in safe housing or, for those incompatible with society for mental health reasons, into institutions. reply ein0p 17 hours agorootparentNote that Munich itself is built for this. You can’t drop a bus line into an existing layout and expect that it’ll magically work. Which is what most mass transit projects in the US seem to be attempting to do. IOW it’s not even _transit itself_ that makes this feasible in Europe. It’s how they build the rest of their spaces. reply nunez 15 hours agorootparentIt's unfortunate that this is the exact strategy that many politicians and government people default to. \"We got $200M in federal money for improving transportation. Let's spend $50M on it adding a station to this light rail we built 20 years ago to win federal money _that_ time and spend $150M on adding five miles of express lanes to the interstate.\" Perfect example. I lived in Dallas for five years. Denton, a city about 45 miles north of downtown Dallas, operates this \"commuter rail\" line called the A-Train. This line has existed since 2006. Denton is one of the biggest college towns in Texas. It has two of the biggest universities in Texas (TWU, UNT). The A-Train doesn't stop at _either college_. The A-Train also doesn't stop anywhere near where people actually live unless you live in downtown Denton (few people do). So, to use it, you have to drive (or take the DCTA bus, which, lol, don't) to a station to take this train which terminates... ...about 20 miles from downtown Dallas. You need to connect in Carrollton (a station you _definitely_ have to drive to) to take the Dallas Area Regional Transit train, which has a larger network (that still doesn't bring you anywhere you want to go, at least not directly) The entire system was set up this way because the A-Train runs along one of the busiest segments of Interstate 35E. It runs up this segment because that's where the pre-existing rail was. This segment is 8 miles. That rail network goes ALL THE WAY UP TO KANSAS AND ALL THE WAY DOWN TO GALVESTON. So, to summarize, two of the biggest cities in Texas have a commuter rail that connects them, on a relatively super small segment of rail that was already laid down, but takes passengers to stations where they will need a car to complete their trip. Oh, and the A-Train only has, like, six stations, operates every 30 minutes between 0600 and 2200 on weekdays and every hour on Saturday, and is closed on Sunday because Texas. The crazy part about this is that DESPITE ALL OF THIS, this is _still_ better than the *zero* rail service we have in Houston (the biggest and most populated city in Texas). _This_ is why public transit is an incredibly hard problem to solve here. It will take billions and billions of dollars to _just_ develop DART, Houston's METRO and Austin's Capital into anything closely resembling a real public transit network. Most folks will just vote for a new stadium or more lanes to get stuck in. (The kicker? I just learned that a section of the Missouri-Kansas-Texas network that the A-Train rides on in Houston was scrapped in 1998 to become...part of Katy Freeway, the 12+ lane monstrosity that absolutely completely fills up every rush hour like clockwork.) reply cqqxo4zV46cp 18 hours agorootparentprevAll I’ll say is: don’t advertise your lust for a Muslkian “direct” communication style during job interviews. All I’m hearing is “terrible to work with”. I’m sure you’ll appreciate the direct nature in which I communicated this, even if you disagree with it. reply ein0p 18 hours agorootparentI no longer do \"job interviews\". People ask me whether I'd like to come work for them. Sometimes, I go and work for them. Your communication style is not direct enough for me I'm afraid, clearly you feel quite a bit more passionate about this than you let on. People must say what you permit, and never stray from the approved narratives, or else. Be careful to not mention that in job interviews. reply ericmay 18 hours agorootparentprev> I'm also big fan of not dictating what other people should say Me either, but in this context what would that have to do with Elon Musk or Tesla? Are you suggesting that other automobile manufacturers or their CEOs try to dictate what other people say? reply ahahahahah 15 hours agorootparentprev> I'm also big fan of not dictating what other people should say I'm trying to understand this in the context of musk's behavior, did you mean \"I'm also a big fan of saying that I'm a big fan of not dictating what other people should say\"? Or \"I'm also a big fan of dictating what other people say\"? I think either of those would make more sense in this context. reply nobleach 18 hours agorootparentprevYou have basically found the Reddit /r/technology contingency. Most stories I see there are laughing at a single man's failures. There's just a lot of hate. I wanted a Tesla because other friends and family let me ride in theirs. I liked the car. I also like Chick-fil-a Chicken, and Papa Johns Pizza. From time to time, I visit Hobby Lobby. If I did digging on EVERY CEO, and found things that I disagreed with, I'd likely have few places left to shop. Instead, I try to focus on the other \"non-crazy\" folks that work at these places. When it comes to Tesla technology... it's actually really good. reply epistasis 17 hours agorootparentI don't know anything about r/technology, but I do know that Musk has alienated his core customer base, and is continually making massive noise about politics, unlike most other CEOs. And even more stupidly, he is aligning with an anti-EV, anti-solar, anti-energy storage political faction in his attempt to alienate early adopters. Makes him seem extremely weak and self-hating. And that's before all the bad decisions in the direction of the product over the past six years. Musk's made a great product far worse by being so involved and making boldly bad decisions left and right. reply kllrnohj 18 hours agorootparentprev> Mostly bad controls, UX, etc. stuff that the Tesla gets right. What? Tesla's controls are ass. They're infotainment responsiveness is great, but the turn signal steering wheel buttons, windshield wipers, drive mode select, etc... are all absolutely horrible. It's literally the reason we passed on the Model 3 & S when shopping for an EV. The extra 20-60 miles of range wasn't worth it to put up with that nonsense. reply e36 18 hours agorootparentThat's just for the cars with that yoke steering wheel, right? The controls for the more \"normal\" cars is pretty intuitive. Except for headlights. I don't know why it couldn't just have a switch for headlights. reply kllrnohj 18 hours agorootparentNo, it's for all of them. The Model 3 was updated to also have the stalks taken away and the PRND controls moved to the roof https://www.tesla.com/ownersmanual/model3/en_eu/GUID-A5F2B9D... reply e36 18 hours agorootparentWhoa, that seems like so much more work to manage and use than the current standard. reply dzhiurgis 12 hours agorootparentOpposite. Think about whats easier - move your thumb or entire arm? reply dzhiurgis 12 hours agorootparentprevTurn signals on wheel is fire. Drive mode I'm not too sure, only drove for few minutes. reply epistasis 17 hours agorootparentprevI have a 2018 Tesla, which got those things right. One of the ways the company has changed in the past six years is to mess up those controls. reply redox99 19 hours agoparentprevI doubt it, as it would have equally affected previous quarters. reply r00fus 8 hours agorootparentIt could be that there were things positive going for Tesla, but the Elon thing finally outweigh the positives or the positives essentially evaporated, leaving only this negative. reply denysvitali 19 hours agoparentprev> It's very likely that Musk himself is contributing to the reputational downfall This. I really like Tesla as a brand, but Musk should really stop over-promising and under-delivering. Their technology is really good, but far away from the promises of their CEO. reply Difwif 18 hours agorootparentElon has always done that during the time Tesla was gaining popularity. It seems somewhere between pedo-diver and Twitter take over his public perception started taking a nose dive. I agree though I still want to see Tesla succeed. reply eptcyka 18 hours agorootparentprevIt almost feels like he's just overpromising to get other car companies to miss what is the USP of a Tesla vehicle - the efficiency. The autopilot nonsense is criminal, but the fact that VW group, Mercedes nor any Japanese manufacturer can't hold a candle to the upper limit of 4 miles per kilowatt. If a model 3 was within my budget, I'd get it despite of the lack of a good radar-guided cruise control, despite the lack of buttons to engage drive, despite the lack of a HUD and mechanical buttons for climate controls. And despite the moron at the helm. All of that since it is the most efficient car on the market as far as I can tell. reply trogdor 16 hours agorootparent> 4 miles per kilowatt You probably know this, but FYI it’s per kilowatt-hour. Anecdote: my Model S Plaid’s efficiency over 23,000 miles is 305 Watt-hours per mile. reply cqqxo4zV46cp 18 hours agorootparentprevMy non-Tesla EV hit its advertised range out of the factory, and hasn’t meaningfully shifted in the 2-3 years I’ve owned it. Literally every Tesla owner I know complains about not getting the range they thought they were buying. More than one has switched away because of it. Speak all you want about Tesla’s efficiency, but it’s hardly a meaningful USP against the absolute bad taste left in one’s mouth after hypeman Elon yet again under-delivers. reply efrafa 19 hours agoparentprevI wanted a Tesla, but I couldn’t inage buying one with Musk as CEO. reply NovemberWhiskey 18 hours agorootparentI know that the plural of \"anecdote\" isn't \"data\", but ... I ended up with a Polestar because I got a fantastic lease deal but my wife literally wouldn't countenance buying a Tesla because of Musk. reply coldpie 18 hours agorootparentprevYeah. Ten years ago it was the cool, new brand. Now it's what you buy when you want to rep an insane drug addict transphobe's fall from grace. I'm looking to buy a Hyundai later this year. reply leetharris 18 hours agorootparent> Now it's what you buy when you want to rep an insane drug addict transphobe's fall from grace. Drug addict? You mean his ketamine for depression? And when you buy a car are you \"representing\" the CEO's views? What are the CEO of Hyundai's personal beliefs? Do you even know? reply rrix2 18 hours agorootparentThe CEO of Hyundai hasn't bought a media company to put his mistaken beliefs and bad habits in front of millions of people. reply mikestew 18 hours agorootparentprevWhat are the CEO of Hyundai's personal beliefs? Do you even know? Unlike Musk, the CEO of Hyundai doesn't go out of their way to make sure I'm aware of their opinions. I don't even know the name of Hyundai's CEO, and we bought an Ioniq 5 last year. One might argue such a dichotomy is one of the reasons we didn't buy a Tesla (well, that and the crap build quality). reply lttlrck 18 hours agorootparentprev> Do you even know? I think that's the point? reply kylecordes 19 hours agoprev\"Disastrous\" seems like a significant overstatement. To me this looks more like \"unsurprising\". Tesla has some additional business lines which might eventually prove quite valuable, but in the short to medium term it is mostly a car company. The whole car industry is dealing with the results of higher interest rates. It would be much more surprising if Tesla somehow turned out to be immune to that. reply addicted 18 hours agoparentIt’s below estimates, so it’s by definition “surprising” relative to the people whose business it is to predict these things. Disastrous may be going too far unless it portends further drops going forward. But disastrous may also be the right word because Tesla’s valuation is based entirely on massive growth. So even if this means Tesla will start growing fairly normally as opposed to rapidly, that’s bad for Tesla stock. reply FireBeyond 18 hours agorootparentThere is suspicion that Tesla always seemed to just exceed predictions, predictably. I'm sure plenty of people made money when \"oh look, another quarter of exceeding expected results\". reply NovemberWhiskey 18 hours agoparentprevThe market doesn't knock $30bn off the value of your company at the open if your results were \"unsurprising\". reply r00fus 16 hours agoparentprevThe disaster isn't missing of a quarter, but the entire facade as to why Tesla is valued at the astronomic multiple of earnings. Tesla has confirmed what most it's not a tech company, but an auto manufacturer. And if it's repeated, the stock will never recover. reply cqqxo4zV46cp 18 hours agoparentprevIt was literally under target. That’s the definition of surprising. It comes as no surprises that the rest of your comment either looks for positives or places the blame on conditions affecting the auto industry at large. Can Tesla do no wrong? reply xeromal 18 hours agoparentprevAny reaction to bad news for Elon Musk businesses are outsized for the amount of hate people have for him. I'd say the hate is pretty well-deserved but I also value SpaceX and Tesla tremendously and I hope they continue taking us into the future. reply testbf 19 hours agoprevWell I’m a Tesla employee and I started looking for a new job today. There’s a lot of smart people who see where this is going. reply bethekind 19 hours agoparentRobot taxis not coming soon enough? reply headmelted 19 hours agorootparentI was under the impression (admittedly from an article I read a couple of years ago) that the consensus within the company was pretty much always that robo-taxis were one man’s pipe dream. Weren’t there also disclosure documents a couple of years ago when they were trying to license autopilot that said they believed internally they were at level 2 as opposed to 4/5? (I might be remembering this part wrong) reply AlexandrB 18 hours agorootparent> I was under the impression (admittedly from an article I read a couple of years ago) that the consensus within the company was pretty much always that robo-taxis were one man’s pipe dream. If robo-taxis were ready with the kind of economics outlined by Musk it would be financially irresponsible to actually sell the cars to others instead of just building a massive Tesla fleet and pivoting towards transportation services. Tesla's still selling their cars? If so, then they're not robo-taxis. Edit: The other option for Tesla would be selling the cars for a high enough premium to offset the lost taxi revenue. The fact that Tesla seems to be in a price war with other EV makers is not a promising sign for robo-taxis. reply akmarinov 15 hours agorootparentprevEveryone knows they’re at level 2. Level 4/5 is completely hands off, no supervision. Not even their Supervised Full Self Driving does that reply chgs 18 hours agorootparentprevDo I taxis certainly aren’t just one man’s dream. Whether not not they are possible in the next 50 years is another matter, but plenty of people want them and are willing to invest in developing them. reply trogdor 16 hours agorootparentprevThey’re here. Just not from Tesla. reply leosanchez 19 hours agoparentprevWhat happened? reply afavour 19 hours agorootparentI’m going to assume that awful Q1 results lead employees to suspect layoffs are on the way. I imagine they are correct. reply Workaccount2 18 hours agorootparentThey should just do an offering. That stock has held it's stupidly massive over valuation for 5+ years now. Just dump it on whatever dumb ass investors have been propping the stock up. reply ianburrell 17 hours agorootparentHave you looked at Tesla stock recently? The stock is down 5% today to 166. It was 250 at beginning of year, so dropped 30%. The peak was 400 in 2021, and dropped to 113 in 2023. I think it is still overpriced and can drop further, but it has lost its shine. They will make less money from offering, and it would probably tank the stock. And there is no sign they need the money. reply Workaccount2 15 hours agorootparentThe company is currently valued at $530 billion. Compare this to Toyota, who sold 11 million cars last year (~20x Tesla), is worth $385 billion. It is still grossly over valued. reply gergi137 13 hours agorootparentTesla sold 1.8 million cars last year and Toyota sold 11.23 million cars last year. so a 6.2x multiple, not a ~20x multiple reply voisin 18 hours agorootparentprevMaybe not layoffs - maybe more the fact that their stock compensation will plummet in value as it is no longer a hyper growth stock. Also, the consequences of Elon’s misbehaviour has finally caught up with the branding so it is no longer cool to work there. reply afavour 18 hours agorootparentAgain to Musk's reputation: he's not exactly layoff-averse. Even if it isn't strictly required I can't imagine he'd hesitate to pull the trigger. reply gwill 19 hours agorootparentprevprobably in response to the content of the article. reply KennyBlanken 18 hours agoparentprev\"Lot of smart people who see where this is going\"...uh huh. The smart people left years ago and started working at Lucid and elsewhere. All the people who had talent got sick of Musk's shit, saw the company stagnating, and left for functional, non-toxic workplaces. Tesla has spent the last ~5 years resting on its laurels, aside from (eventually) producing a pavement-queen meme vehicle that breaks down on even the simplest off-roading tests and gets stuck on beaches. Oh, and slightly tweaking the Model 3's looks, I guess that's...something. Your cars have completely stagnant styling, terrible reliability (matched with even worse parts availability!), the worst interiors in their class, the worst build quality, and they're no longer kings in anything - not efficiency, range, performance, or charging speed. Your company was at the forefront of removing physical switches and moving to screen-based and capacitive-touch controls, both reviled by the public and coming under increasing scrutiny by regulators. Your cars have the highest crash rate of any automaker. Tesla's \"autopilot\" has been surpassed by several manufacturers whose systems don't randomly slam on the brakes (or, for that matter, into the backs of police cruisers.) Here's a 2008 blog post about V2G: https://www.tesla.com/blog/smarter-charging ...and sixteen years later your cars still can't do it. Hyundais and Kias can... Your cars are still stuck on 400V (sorry, \"480\") architecture while years ago other companies went to 800v. VW/Audi/Porsche, Hyundai/Kia, GM, and Lucid are all on 800v. And while \"V4\" stations have been deployed, they're all still 400v 'under the hood'. 800v CCS has been slow to roll out, but it's actually been If you're all so smart, why are your cars on fire sale and still selling like dogshit? reply JohnBooty 17 hours agorootparentIf you're all so smart, why are your cars on fire sale and still selling like dogshit? I feel that there's a large mismatch between the parent post and your reply? It feels like you both think that Tesla's facing some major problems and is not on a good trajectory? reply panick21_ 18 hours agorootparentprevAll those smart people really turned Lucid into a hypergrowth company. reply FireBeyond 17 hours agorootparentprev> terrible reliability (matched with even worse parts availability!) What I love as a \"defense\" from Tesla fans is when they comment that \"they're not the worst for reliability, in fact they're middle to above average\"... ... when compared with ICEs which are far more complex. \"EVs are far simpler than ICEs, and there's far less that can go wrong with them\"... if so, being in the middle of the pack with a bunch of ICEs isn't the flex it seems. reply foobarian 19 hours agoprevMaybe we're getting to saturation in early adopter market? Looking around, there are a lot of folks who could not easily live with a BEV, i.e. live in apartment buildings or don't have an easy way to install L2 charging at home. reply akouri 18 hours agoparentI built www.letselectrify.org as a side project to make it easier for people in multifamily buildings (condos, apartments, and HOAs) to get their own dedicated EV chargers. In multifamily buildings, such as my 85-unit condo, there isn’t any at-home charging. At best, there is one shared charger for the community to use. This sucks for several reasons: 1. You have to remember to move your car when it’s done charging, 2. The HOA is stuck paying the bill for all the electricity, and 3. As more and more people get electric cars, shared chargers don’t scale. The most common Homeowner Association (HOA) objections to adding more charging: 1. It costs too much, and 2. Nobody wants this. HOAs are generally risk-averse and don’t want to spend money on discretionary things like EV charging. This means that the only way for residents to conveniently own an electric car is to pay out of pocket (sometimes up to $20k) to install a single charger, which usually also requires the HOA to approve on a case-by-case basis. Instead of all these one-off installs, letselectrify.org combines everyone that wants a charger into one campaign and lets them split the cost of installation, which ends up being much cheaper. reply jerlam 18 hours agoparentprevEven people for whom home charging is not an issue aren't going to abandon their existing gas cars to get an EV that performs the exact same function for a lot more money. Having an EV is not transformational. Even with a $7,500 discount, there's still a wide gap between the value of the ten-year old gas car in the driveway and the cost of a brand new EV. Not going to a gas station is just not that beneficial to most. reply foobarian 11 hours agorootparent> Even people for whom home charging is not an issue aren't going to abandon their existing gas cars to get an EV that performs the exact same function for a lot more money. It's an interesting point. Still anecdotal, but our family ended up doing the first part of your sentence - that is, we abandoned our existing gas car. However, it was certainly not a lot more money - in fact part of the equation was that it was slightly cheaper to get the EV, exactly because it was not a super luxurious super long range $100k vehicle. There turned out to be a bonus benefit of 1 year of free charging at EVgo chargers, which we didn't count on but is nice. Our main reason for this was that the gas car we replaced was requiring a lot of repairs and we were hoping to minimize the time we spend at repair shops. Hopefully the EV will require even less time than an IC vehicle due to no fluid changes. One other unexpected change we encountered is that due to charging at home, we spend less total time fueling up the car, i.e. no more gas station visits. The time we occasionally use the free EVGO charger is at a department store so it's a side effect of going shopping instead of a single-purpose refueling trip. reply JeremyNT 16 hours agorootparentprevJust so. Today, I'd be able to get by with an EV if one were to miraculously appear before me, but none of them could have replaced an ICE for the kind of tasks we use our vehicle for at the time of our last refresh cycle (~6 years ago) at a remotely competitive cost. Early adopters are going to early adopt, and people in high income brackets who own multiple vehicles can readily afford to have an ICE vehicle and an EV, but there are finite numbers of these folks out there to sell to. I reckon only recently EVs have gotten good and cheap enough to seriously replace ICE vehicles in the mass market. Personally, I've got zero incentive to replace our fully functional ICE vehicle with any vehicle (EV or otherwise) until its \"pretty darn reliable\" service life ends - which I would place at least another 5 years in the future - at which point EVs will have closed even more of the gaps. reply SoftTalker 19 hours agoparentprevI agree this is part of it. There are still many parts of the USA where charging is a real concern, as is the need to drive beyond the vehicle's range (I do that several times a month, and would worry about charging along the way or at my destination). reply hn72774 19 hours agoparentprevI'm a recent first time buyer of a (used) EV and use the L1 120v charger that came with the vehicle. The daily commute use is low enough that it charges to full overnight. Before I purchased I thought I'd need to pay for a L2 charger and hire an electrician to install a 240v circuit in the driveway. Turned it that I just needed a short 10ga extension cord from an existing 120v receptacle. Our household have a second ICE for longer trips. I live in a house though, not an apartment. reply Workaccount2 18 hours agorootparentI think one of the biggest enemies of EV adoption is that people just don't intrinsically understand that \"refueling\" is fundamentally different. reply hn72774 17 hours agorootparentThat was me. I had to do my own research to educate myself. I've done a couple longer trips where the battery goes to 20%. It took a few nights of charging to get it back to 100%. Which was totally fine because our daily use is less than 15 miles per day. When I was ready to buy, I knew more about EV's than the person who sold me the vehicle. The amount of false information I got from the salesperson was worrisome. Even the amount of sales tax he quoted on the first offer was wrong. reply thrill 18 hours agorootparentprevAnd they are constantly badgered to not gain that understanding. reply tristan957 18 hours agoparentprevI think the apartment issue is really more of a non-issue, assuming there are fast chargers near you. Can apartment dwellers like myself really not go charge for 10-30 minutes every couple of days? A trip to the gas station is typically ~5 minutes. At least that is how I rationalize potential EV ownership. reply cduzz 17 hours agorootparentNah, it's a big deal to not have charging where you park overnight. A huge part of EV ownership is the minimal thought put into keep track of how full the car is. You drive, you come home, you plug in, you drive later, etc. No worries at all, no effort. If you don't have that convenience, you're always going to have a bug nagging you \"should I go charge?\" and it'll wear at you. Street parking with chargers on light poles, load balancing so they don't pop the circuit? Win. Chargers saturating common area parking that bills you for power you draw? Making people go charge their car at some central location for 45 minutes once or twice a week? Total fiasco. I get by fine on a 20a/16a 240v (nema 6-20 plug) in the relatively mild new england winters and can drive my car just like a normal car 98% of the time. reply NovemberWhiskey 18 hours agorootparentprev>assuming there are fast chargers near you. That's a big assumption. Based on the data I see here: https://www.nyserda.ny.gov/All-Programs/Drive-Clean-Rebate-F... ... there are fewer than 10 total DC fast charging connection serving the entire of Manhattan, Staten Island and the Bronx. reply toomuchtodo 19 hours agoprevInterest rates and vehicle prices too high, must come down to expand TAM. Future benchmark rate cuts should improve affordability (most people finance and buy a payment), but Tesla will need to navigate burn rate until central bank pivots. reply kllrnohj 18 hours agoparentI think it'd be a mistake to also underestimate the impact of actual competition showing up with far fewer quirks. Tesla's interiors were already spartan to say the least, and with each interior update the cost cutting gets even more obvious and more compromising (eg, replacing turn signal stalks with buttons on the steering wheel). Meanwhile you've got things like the Ioniq 5 that have fun styling, way better interiors, and don't really cost that much more. They're still selling a lot fewer in total numbers than Tesla, but Ioniq 5 + EV6 is around 53,000 vehicles in 2023. Given the shape of the EV landscape and EV sales in general, that's probably a lot of lost sales from Tesla specifically. BMW also started showing up, and they're responsible for another 47,000 sales in 2023. And then at the high end it looks like the Model X + S sold 17,027 total, which yeah. At that price point those vehicles are just one-trick ponies. They go fast, and that's about it. Meanwhile you've got Lucid Air, Porsche Taycan, Audio e-Tron GT, etc... Taycan + eTron GT sales in the US add up to around 10,000. Lucid only had 6,000 delivers in 2023, but it also only offers a Model S competitor atm. reply PheonixPharts 18 hours agoparentprev> Interest rates and vehicle prices too high, must come down I'm still a bit surprised how many people, even professionals in the lending space, hold this view that \"interest rates must fall!\" We're still relatively low for federal interest rate[0]. Near zero interest rates are not sustainable long term and have lead to a tremendous asset bubble we're still just figuring out the consequences of. It's a bit frightening that the only solution most companies have to improving their future out look boils down to \"wait for rates to drop\". I suspect even if rates do drop again, it will be only for a brief while before it becomes clear that \"print free money!\" is not a long term viable economic strategy. 0. https://fred.stlouisfed.org/series/FEDFUNDS reply state_less 18 hours agorootparentI’m not sure why people think interest rates will go down if we’re running 3%+ (50%+ above target) inflation and unemployment is below 5%. I don’t care what the projections are, the rates won’t drop until inflation is below 3% or unemployment shoots up. If they did drop the rates in these conditions, it would signal a failure of the FEDs dual mandate. My prediction is that rates stay the same or even are raised if inflation continues to run hot while unemployment is down. reply alephnerd 18 hours agorootparentprev> I'm still a bit surprised how many people, even professionals in the lending space, hold this view that \"interest rates must fall!\" Because it's mostly high earning white collar professionals or anyone with at least $100k in liquid assets who benefit from an interest rate drop. If rates drop significantly, then house sale prices skyrocket again because you can take out larger loans with a smaller down payment, and you can leverage yourself to acquire multiple properties. Same with car sales, and any other luxury good. reply aidenn0 18 hours agorootparentprev> We're still relatively low for federal interest rate[0]. Near zero interest rates are not sustainable long term and have lead to a tremendous asset bubble we're still just figuring out the consequences of. My house is still likely to go for more than I paid for it in 2018, even after adjusting for inflation. It should be obvious that housing cannot sustainably rise at above-inflation rates indefinitely. reply toomuchtodo 18 hours agorootparentprevAmerican consumers run on credit because of wage stagflation in the face of inflation and price levels. Either wages must go up or credit costs must come down to improve affordability if prices aren’t coming down. Securing wage increases takes time, worker organizing, etc. credit affordability is as easy as Chair Powell holding a press conference. https://www.marketplace.org/2023/02/08/americans-use-of-cred... https://www.federalreserve.gov/releases/g19/current/default.... reply zdragnar 18 hours agorootparentprevWhen the price of the car tops out around that of a house in a low cost of living area, low interest rates make the price seem less obscene. With higher rates than before (and more competition), the price is too high, no matter how you shake it. reply NickM 19 hours agoparentprevFWIW they had some insane discounts toward the end of March, to the extent that I'm not sure high prices is the problem. I bought a new long-range AWD Model Y myself a couple weeks ago because between the discounts and tax credits I ended up paying under $40k (would've been around $36k but even after sales tax and fees and stuff it was still only around $39k). At those prices I'm not sure how they aren't selling more cars. For the amount of range and functionality you get, that kind of deal blows the competition out of the water; no other EV I'm aware of comes close. (That said, I have no idea if they still made much of a profit off that car or if they were just desperate to clear out space.) reply SoftTalker 19 hours agorootparent> At those prices I'm not sure how they aren't selling more cars. I cannot imagine paying $40K for a car, and I'm sure there are millions like me. You may be optimistic on what you think the average person can afford. reply epistasis 18 hours agorootparentThe average price of a new car is $48k: https://caredge.com/guides/new-car-price-trends-in-2024 The average new car purchaser may not be the average person, also the average include trucks with tend to be super super expensive. reply reaperducer 17 hours agorootparentalso the average include trucks with tend to be super super expensive. Funny how things change. My first new car was a truck, for the very reason that pick-up trucks were generally much cheaper than cars because they were mostly empty space and didn't have so many creature comforts. Now, trucks are like rolling vacation spas. When my wife's car was side-swiped, the insurance company gave her a huge new truck as a loaner. It had more electronics, more comfortable seating, and more luxury appointments than our living room. reply NickM 16 hours agorootparentprevRight, of course, $40k is not cheap in absolute terms. But for a luxury long-range AWD electric crossover, it's significantly cheaper than the competition (at least here in the US), and also much cheaper than the same car cost a year ago. My main point is that if prices have come down a lot, yet Tesla is now selling fewer cars than before, then it seems like there must be other factors in play besides price. reply lostlogin 19 hours agorootparentprev> At those prices I'm not sure how they aren't selling more cars. The above mentioned Elon Factor? reply NickM 16 hours agorootparentYeah, I mean sure, maybe that's all there is to it, but he's been a high-profile asshole for years now. He's definitely changed, but that change happened years ago, it's not a new problem. I guess it's possible that maybe it's just taken this long to catch up with him though. My two cents are that it's more important to support the company that's building the best EVs, and the positive impact Tesla has on the world is way bigger than whatever negative effects Elon's tweets are having, but I can definitely relate to folks' discomfort. I wish we had the old Elon back. reply toomuchtodo 15 hours agorootparentI agree with almost your entire comment, but I hope they boot Elon and bring JB in as CEO. Elon has no humility and empathy, JB does (at least from my brief interactions years ago). Old Elon is gone I fear, but maybe he finds himself, I really hope so. Story isn’t over yet. reply NickM 14 hours agorootparentYeah, I think that's a great idea, I would love to see that happen. reply Spooky23 19 hours agorootparentprevElon is toxic and the cars are either exactly the same or worse than they’ve been for years. And then you have the bizarro cyber truck. reply toomuchtodo 19 hours agorootparentprevI was looking at adding another Y to our household while those sales were offered, but didn’t because my income prevents us from getting the tax credit, so maybe next year. Agree it’s a great value, more customer research required (what price do the vehicles need to get to in order to move faster, and can Tesla still make a profit at those prices). reply silverquiet 19 hours agorootparentprevDo you think that maybe a $40K car is a fairly large amount of money for a lot of people? reply toomuchtodo 19 hours agorootparentAverage price of a new car in the US is ~$47k as of February 2024. reply silverquiet 18 hours agorootparentI'd be curious if the median price is a bit lower, but perhaps we're finding that that average price is not sustainable? reply toomuchtodo 18 hours agorootparentAgreed, US consumer is potentially tapped out. reply alephnerd 19 hours agoparentprevIt's a global issue. Even BYD's sales crashed by almost 50% [0] [0] - https://www.reuters.com/business/autos-transportation/byd-ma... reply addicted 19 hours agorootparentThose are sequential sales. YoY BYD is up 13%. TSLA sales are down sequentially but more relevantly also YoY. reply zer00eyz 19 hours agorootparentBYD is a state backed enterprise. The rest of chinas EV market is in Freefall (plant closures) and much of their output is of a quality level you would expect from china. reply aaomidi 15 hours agorootparent7500 USD discount is also a state backed enterprise. reply skillpass 19 hours agorootparentprevArticle says they’re still up year over year > 431,000 deliveries would still be a small growth year-over-ear[sic] reply macintux 19 hours agorootparent431k was the consensus estimate recently. The real number was below 390k. reply headmelted 19 hours agorootparentprevRight but when do I get my cheap Tesla? reply VBprogrammer 19 hours agoprevTesla are still producing cars which have the same design elements as the Model S did in 2012. I'm amazed they have pulled that off but maybe the lack of \"freshness\" is also hurting their bottom line? reply akmarinov 15 hours agoparentModel S and X aren’t big volume movers. The 3 and Y are, that’s why they’re getting refreshes. reply ayan 19 hours agoprevi hope elon's behavior is part of the drop in demand. i'm afraid it is mostly economic though. reply mplanchard 18 hours agoparentAnecdotal, but this is absolutely the case for me. The widely reported fit-and-finish issues would have made me hesitant regardless, but as long as it's Elon's company I will not be buying a Tesla regardless of improvements in quality. Bought a Prius plug-in hybrid instead (which I'm very happy with). Prior to Elon taking the mask off I was really excited about the idea of getting a Tesla, and I'm squarely in what I imagine must be the main target demographic. reply misiti3780 18 hours agorootparentThat is fine, but you are basically driving a flip phone when you could be driving an iphone. The Prius driving experience and technology are not good. reply danw1979 16 hours agorootparentThe Prius driving experience is excellent. I’ve had two gen 3 prii (one a plug in) for 10 & 6 years respectively and can’t find anything to dislike apart from the lack of acceleration above 45mph. Regular cruise control, buttons for everything, excellent economy, zero road tax, huge cargo capacity for a family car. I kind of like my flip phone thank you very much. reply misiti3780 14 hours agorootparentYou do you! reply mplanchard 9 hours agorootparentprevIt has served me just fine getting up and down the mountains in the Vermont winter with snow tires, so I don’t really have anything to complain about. I have also had zero maintenance issues with it so far. The electric mode has great torque, especially with power driving mode turned on. reply kstrauser 19 hours agoparentprevI saw a bumper sticker on one: “I bought this before Elon went crazy”. It’s not great when your customers are embarrassed to be seen driving the car you made. reply ddoolin 19 hours agoparentprevI shared this in my other comment, but there is some support for that notion: https://www.reuters.com/business/autos-transportation/would-... reply ayan 19 hours agorootparentgreat article. i have a tesla -- it is a great car. i regret that elon is such an awful person and i will definitely look elsewhere before buying another. at least as long as he's involved. reply cmsj 19 hours agorootparentTesla should be absolutely terrified of this. I think lots of us would love to like Elon, but the man is such a disgrace that we are actively disincentivised to root for his success. reply jghn 19 hours agorootparentprevI went from assuming that a Tesla would be my next car to assuming that an EV that's not a Tesla will be my next car. All because of Musk. reply rvnx 19 hours agorootparentprevI really hope it will support stalks soon or have turn indicators actually placed on left+right. reply sgc 19 hours agoparentprevI am shopping for an EV right now. I absolutely refuse to look at Teslas. So there is some effect of unknown size, and in hard times that added effect can push things over an edge. reply Ekaros 19 hours agoparentprevOr the reality that there is lot more options so people gravitate towards them. And brand loyalty might also be a thing, of which there is lot for also other brands. reply rvnx 19 hours agorootparentThe technological gap is tightening, Tesla was alone before, the same way that Nvidia is \"alone\" for now. Tesla still has some advance in terms of autopilot (in the US), but for all other things, it's an electric car with a great software but a rather low-quality hardware finish if to compare with other brands like Mercedes. reply williamsmj 18 hours agorootparent> The technological gap is tightening, Tesla was alone before, the same way that Nvidia is \"alone\" for now. It's worse than that. Nvidia has a moat (deployed software and the open source software ecosystem) that buys them at least a few years, even if a well-resourced hardware peer appeared out of thin air tomorrow. Tesla has nothing like this. The cost of switching away from them is negligible, and they have half a dozen extremely well-resourced competitors. reply ein0p 18 hours agorootparentprevIt also has much better range than the Mercedes, accelerates faster, costs nearly half as much, and can use Superchargers. I can forgive the slightly less fancy \"finish\" for all that. reply cma 18 hours agorootparentWhen Tesla gets tight for money they raise the Supercharger price to more than gas, it happened once around 2018 during a cash crunch. reply ein0p 18 hours agorootparentI rarely use it (the vast majority of Tesla owners charge at home), but when I do, I appreciate the fact that it's there, even if the price is higher. It's still cheaper than gas. I actually think that's kind of the idea. One or two long road trips per year become possible. With most other EVs they're a dicey proposition still. reply cma 18 hours agorootparentYeah I think they lowered it back after a backlash and an improvement in their financial situation. reply seydor 18 hours agoparentprevvery few people outside the permanently online care about this reply evantbyrne 18 hours agorootparentPerhaps! That leads to a question actually: I wonder how many people know that Musk intentionally reinstated accounts for literal neo nazis, and very obviously has personal knowledge of Andrew Anglin being on the service? I suspect most people do not know, because getting caught providing material support for nazism would destroy a normal person's reputation. reply macintux 18 hours agorootparentThe 2016 election changed the calculus. Supporting white supremacists is no longer a deal-breaker. reply leetharris 18 hours agoparentprevIt seems to me this is heavily related to Elon being a vocal Republican. I wonder if people would care as much if he was a quiet Republican? reply timbit42 18 hours agorootparentI don't think it's so much because he is Republican. It's what he says that matters. reply cma 18 hours agorootparentprevPromoting great replacement theory is very different than vocal Republican. He only said the Republican persecution thing after he was informed the horse for handjob scandal was going to be reported: they emailed him for comment and he immediately made the post. reply ahahahahah 14 hours agorootparent> Promoting great replacement theory is very different than vocal Republican They used to be very different. Today, not so much. reply shrubble 19 hours agoprevIs there any evidence that the best-fit portions of the market are getting saturated. There are plenty of places in the USA where an ICE vehicle is just a better fit, given usage patterns, lack of charging facilities etc. reply fuzzfactor 11 hours agoparentWell, it's a specialty item that can substitute for a very popular mainstream one in a number of popular use cases. And come close to substituting in a number of cases that might still lead to a bit of rapid adoption. More ideal as an incremental acquisition for many of those who already possess the mainstream merchandise. Not so much desirability for those that would have to choose one or the other. So that's a smaller subset of the niche. Then there are those who find the novel solution is superior for their particular needs, an even smaller subset, but more enthusiastic. Seems like the behavior would be to fly off the shelf until the subsets of the mainstream have been saturated, then plateau at the rate that the mainstream becomes amenable to replacement. At the smallest of scale, like with handcrafted items, it can occasionally be easy to do well financially as long as you can sell all you can make. This can happen when they're \"flying off the shelf\" so there can be relentless pressure to just make more, and the pressure can seem unending when there is a multi-year timeline for any scale-up activities. If the market matures at a less-giga-than-anticipated level, and you end up in the process of building more than you can sell on an ongoing basis, you have reversed the financial opportunity that was supposed to accrue by building more to begin with. One day when you wake up and can no longer sell all you can make for some reason, it's a whole different ball game. reply hnburnsy 17 hours agoprevSome other context As of Q3 2022, Tesla’s profit margins stand out significantly compared to its competitors: Gross profit per car: $15,653 Net profit per car: $9,574 In comparison, other major automakers have lower profit margins: General Motors (GM): Gross profit per car of $3,818 and net profit per car of $2,150. Toyota: Gross profit per car of $3,925 and net profit per car of $1,197. Volkswagen (VW): Gross profit per car of $6,034 and net profit per car of $973. Hyundai: Gross profit per car of $5,362 and net profit per car of $927. reply mkipper 13 hours agoparentYou seem to know where to find these numbers (I don't), so do you know how that stacks up with luxury car manufacturers? Most of those companies do compete with Tesla, but the price range of a Tesla ($40k to $90k for most models) lines up much more closely with Audi and BMW than any of those companies. I'd imagine that those companies would have higher gross margins if they didn't sell any cheap models or trims levels. reply hnburnsy 10 hours agorootparentHere is operating margins of car companies, it puts Tesla behind BMW but ahead of Mercedes... https://companiesmarketcap.com/automakers/automakers-ranked-... reply TheAlchemist 10 hours agoparentprevAny particular reason why you are looking at Q3 2022, other than the fact that 2021-2022 were a complete anomaly, due to Covid shortages and impacts ? It's all downhill from there - Tesla used to include their margin charts in the shareholder's deck, until Q4 2023. Care to comment why ? We all know why. Let's wait 3 weeks and find out what Tesla margins are in Q1 2024. reply kstrauser 16 hours agoparentprevWhat's the difference between gross profit and net profit? reply stephenitis 16 hours agorootparentGross profit is the money a company makes after subtracting the cost of producing its goods or services. Net profit is what remains after all expenses, like operating costs, taxes, and interest, are deducted from the gross profit. reply kstrauser 16 hours agorootparentAh, so gross profit is kind of like \"this is how much we profited off this specific car\", and net profit is \"this is the average of how much we profited off all these cars\"? reply yread 13 hours agorootparentgross profit is \"money we got for selling this car\" - \"all per car expenses\". Net profit is - \"all the other expenses a company has\" reply ta8645 19 hours agoprevNot sure how it will affect things going forward, but the Model 3 may help. Jay Leno did an excellent segment about it a few weeks back, with a pair of Tesla engineers: https://youtu.be/WLMalLy_3JU reply onion2k 19 hours agoparentMaking more Model 3s than Tesla can sell is a big part of the problem. The Model 3 and Y account for 43,000 out of the 46,000 unit overrun. reply moogly 18 hours agorootparentTesla don't even dare show the Model 3 numbers. I suspect they are very, very low in comparison to the Model Y, looking at official sales numbers tracked in other countries. If I were a Tesla stockholder I would be very disappointed in Tesla not breaking down sales like every other car manufacturer does. It's starting to look increasingly boneheaded to spend time and money on the Cybertruck instead of a new lower-cost SUV (the Model Y isn't really a SUV in my book). Their platform is starting to feel dated compared to the competition. I'm sure some stuff from the Cybertruck platform will trickle down to the next like steer-by-wire and 800 V (which they are catching up on), but since I don't build cars, I don't know how amenable that platform is to build normal cars on. reply LUmBULtERA 18 hours agorootparentprevProduction constraints could be a regional problem. Model 3 highland only recently started showing up in inventory in the US and for now, it's only the standard range models and there are no inventory discounts. No long-range models are showing up in inventory (for me at least?). Plenty of Y are in inventory. I'd have bought one in Q1 but I don't qualify for the tax credit, so I went used. reply sf_rob 17 hours agoparentprevUntil Tesla changes their Model 3 sourcing to be eligible for the $7500 tax credit, I don’t understand who would buy one over the Model Y even with the “highland” improvements. reply ta8645 17 hours agorootparentI don't know if it's the tax credit you're referring to, but in that video (15:35), they claim with tax credits the model 3 is available for under $30,000 https://youtu.be/WLMalLy_3JU?t=935 reply sf_rob 16 hours agorootparentOnly the performance Model 3 is currently eligible for the Federal tax credit[1]. They may be referring to some generous state EV credits. [1] https://insideevs.com/news/700533/tesla-model-3-rwd-long-ran... reply hibikir 19 hours agoprevI could see this coming weeks ago: My local dealer was cold-calling existing owners to try to get them to buy the updated model 3, which isn't a very significant update at all. They had a bunch on the lot that weren't selling. We can also see the promotion of a free trial for self-driving as a response to this too: Hoping some people bite after trying it out. Whether that happens, or we just see more videos of failed self-driving is another story. Either way, Tesla hasn't done much to improve their normal models in 2 years. The cybertruck is barely in production, and it's hard to see it as having massive demand. Elon's cultural alignment with people that at the same time are being told that electric vehicles will be bad for America is probably not great for sales on either side of the cultural divide. Add high interest rates, and it's unsurprising to see trouble. But does anyone have enough shares to try to force Tesla to make significant changes in diection? Unlikely. reply kylecordes 18 hours agoparentIt seems like Tesla should focus on updating the Model Y, which is by far their best-selling model, instead of the 3. The typical US consumer is not all that excited about sedans anyway. reply olivermuty 18 hours agoparentprevIsn’t Teslas whole schtick that they are dealer-free? Where is this? Is it a franchise? reply mattw2121 18 hours agorootparentHe probably meant the local, Tesla employed, sales person or sales manager. Tesla has showrooms all over the country. reply olivermuty 2 hours agorootparentInteresting. Tesla in Norway is all JIT sales. Cars are ordered and come straight from the docks to the customer. I did not expect Tesla showrooms in the us to carry stock. Maybe walkin purchases are more common across the pond reply nunez 15 hours agoparentprevThe new Model 3 is a significant update in many areas (noise, handling, cabin design). reply aeturnum 18 hours agoprevLots of talk about how Musk's controversies are hurting the company (agree!) but I think a bigger problem may be his tendency to hyper-focus on things. Many tesla models have not received significant updates or styling changes in years. Tesla is no longer brand new, the oldest production Model S'es are ~12 years old. Many of their changes have been along the line of company-wide changes or upgrades (which are also good) but people like having their new car look new, not like one from a decade ago. It feels like Musks companies suffer from hyperfocus, probably because effort is directed by the his attention, but car companies can't work like that. reply FredPret 18 hours agoprevTesla has the Cybertruck now (is it shipping yet?). People love trucks, so this might work out great for TSLA. But they don't really have an SUV, which is by far the most popular form factor. The Model Y is closest but it's still a bit car-ish. Interest rates are up. Their chairman is going through a very public ...episode. They'll definitely overcome the headwinds: they still have superfans despite the Musk antics; they have lower leverage than GM/F [0]; there's a lot of regulatory pressure coming down the pipes over the next 10-30 years to phase out ICE engines. [0]: https://valustox.com/GM https://valustox.com/F https://valustox.com/TSLA reply williamsmj 18 hours agoparent> People love trucks, so this might work out great for TSLA. 1. there is essentially no market for pick-up trucks outside the US. 2. the market for pick-up trucks inside the US is dominated by suburban American dads. They love trucks because they can imagine pulling up to a job site in one. We all know, even the suburban dads, that if you pull up to a job site in a Cybertruck, the guys working there are going to laugh at you. Look into your heart. You know this to be true. That's the kiss of death. (That and the fact the panel gaps are like two inches.) reply stephenitis 17 hours agorootparentTrucks are great for moving furniture, bringing garden material, wood, and mulch from the store. I'm a Model Y owner and I still would not get a Cybertruck. If its too big for the Y I'll rent a Uhaul if its worth it, or borrow my friend's truck. It would be a nice upgrade for my occasional camping trip to have the outlets and truck bed space for all the gear. so far the Model Y fits everything. give me a minivan-like vehicle though... reply FredPret 16 hours agorootparentprevWho cares - you can sustain an ultra successful vehicle just in the US. American suburban dads are an economic force on par with entire global regions. If they want cyber trucks, for any reason, TSLA will be just fine. reply tatersolid 11 hours agorootparentprev> 1. there is essentially no market for pick-up trucks outside the US You’ve obviously never been to a war-torn country. The mid-sized Toyota/Nissan pickup with a machine gun mounted in the bed is the most popular vehicle by far. reply mikestew 18 hours agoparentprevTesla has the Cybertruck now (is it shipping yet?). People love trucks, so this might work out great for TSLA. Here in Redmond, where buying a Tesla seems to be a rite of passage for Microsoft employees, I will often see three Teslas at an intersection (and maybe one behind me). The things are everywhere. If you've got a dead cat, careful you don't hit a Tesla when you swing it around. And I've seen a total of one Cybertruck. Either not that many have been made and shipped, or no one is buying. People do love trucks, and they even love electric ones because I seen Rivians all the time (and a few Lightnings). But I've only seen the one lonely, butt-ugly Cybertruck. reply coldpie 17 hours agorootparent> I've seen a Cybertruck Oofda. I'm sorry you had to experience that. reply mikestew 17 hours agorootparentShould the same happen to you, I'm seeing a good therapist and can pass along details. Contact info in profile. reply spacemadness 18 hours agoparentprevGood luck with that thesis and sorry for your loss. reply FredPret 16 hours agorootparentI’m a value investor and wouldn’t touch Tesla for at least another 10 years reply 38 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Tesla has recently increased the prices of the Model Y, but the duration of this price hike remains uncertain."
    ],
    "commentSummary": [
      "Tesla's Q1 2024 deliveries unveiled quality and maintenance problems causing customer dissatisfaction, prompting some to seek refunds under Lemon Laws.",
      "Rivian R1S and Mercedes EQS are rising in popularity as alternative electric vehicle choices, with recommendations to explore Toyota/Lexus or Jeep Wrangler 4xe for dependable options.",
      "Stellantis is ramping up efforts in the electric vehicle market, sparking discussions on Tesla's quality challenges and Elon Musk's conduct, along with the competition from other EV models."
    ],
    "points": 148,
    "commentCount": 293,
    "retryCount": 0,
    "time": 1712068155
  },
  {
    "id": 39908798,
    "title": "Physical Activity Improves Sleep Quality, Mental Health: Study",
    "originLink": "https://news.utexas.edu/2024/04/01/move-more-sleep-better-ut-study-finds/",
    "originBody": "Health & Wellness Apr 01, 2024 Move More, Sleep Better, UT Study Finds AUSTIN, Texas — A new study by an interdisciplinary team of researchers at The University of Texas at Austin provides the most reliable validation to date of the connection between physical activity, sleep quality and psychological health. The study found that physical activity lengthened REM latency — that is, the time it takes to enter the REM stage. This may indicate that exercise helps consolidate deeper sleep stages before transitioning into REM sleep, which is when we tend to have vivid dreams and our brains seem to be as active as they are when we’re awake. Scientific studies backed by anecdotal evidence already testify to the fact that when we exercise regularly, we sleep better. And, when we sleep better, we feel better. Although there is ample scientific evidence to support this, until now the studies have been conducted in lab settings, with conclusions drawn from observing experiences after just one night’s sleep. Such limited methodologies are problematic for any scientific study, regardless of how widely accepted the findings may be. The study, published in Nature Scientific Reports, investigated how daily physical activity patterns affect sleep stages and emotional well-being in a natural environment — at home, at work and during daily activities — over several months. The research team used advanced wearable technology to track sleep and activity levels in 82 young adults. A wrist-worn activity tracker recorded both movement and heart rate. From those signals, periods of deep (NREM) sleep and REM sleep, along with physical activity, could be determined. A separate smartphone app was used to collect self-reported well-being data. The study emerged from a pilot study conducted as part of Whole Communities–Whole Health, a grand challenge research program that takes an interdisciplinary approach to how health care data are collected while also engaging communities and participants in the research process. This more wide-reaching study successfully replicated many of the findings previously conducted in sleep labs: namely, that engaging in both low-intensity and moderate-to-vigorous physical activity was linked to deeper, more restorative sleep, and that better sleep was in turn associated with more energy and less stress the following morning. The key difference this time was the researchers’ innovative use of wearable technology, which allowed for continuous monitoring of participants’ behaviors, providing a comprehensive picture of daily activities and their impact on sleep and mood over multiple weeks, even months. “You can learn a lot from lab studies, but obviously there are limitations to studying the sleep patterns of individual participants in just one night,” said Benjamin Baird, a research assistant professor of psychology and one of the authors of the study. “It’s an unfamiliar, clinical-type setting, which can be stressful. And you can’t really look over time, either. So, there are always questions about generalizability from that kind of design.” Baird said that researchers were able to address for the first time how these differences in sleep architecture are associated with people’s perceived well-being. Sleep architecture refers to the structure of each 90- to 120-minute-long sleep cycle: the three stages of non-REM sleep (light, deep and deepest NREM sleep) and REM sleep, which makes up the final 25% or so of each cycle. “We’ve shown using a standard Fitbit that anyone could wear — not even an expensive scientific device — that it is actually sensitive to these sorts of sleep architecture measures, and in a way that’s showing predictive results,” said David M. Schnyer, a co-author and chair of the Department of Psychology. “The world is your oyster now. You can use this device to study all manner of different sleep architecture data related to lifestyle — related to mood and mood disorders — in the field, not in a lab, that people might have thought was not possible previously.” Copy link Email Share Link Twitter Share Link Facebook Share Link LinkedIn Share Link Tags: College of Liberal Arts, Health, Health & Well Being, Office of the Vice President for Research, Scholarship and Creative Endeavors, Research, Science, Technology, Whole Communities–Whole Health Copy link Email Share Link Twitter Share Link Facebook Share Link LinkedIn Share Link Media Contact Michael Wolman Office of the Vice President for Research, Scholarship & Creative Endeavors p: 512-232-9151 e: michael.wolman@austin.utexas.edu The University of Texas at Austin",
    "commentLink": "https://news.ycombinator.com/item?id=39908798",
    "commentBody": "Study uses wearables to show that physical activity lengthens REM latency (utexas.edu)139 points by gmays 16 hours agohidepastfavorite84 comments kingrazor 14 hours agoThis doesn't surprise me. A personal anecdote: a couple of years ago I traveled to Japan for the first time. During my time there, I walked much, much more than I usually do. As a result, I was physically exhausted at the end of each day, and had some of the best sleep I've had in years. reply evantbyrne 7 hours agoparentI've noticed the same phenomenon myself. On days when I don't go to the gym or engage in some otherwise exhausting activity in the evening, I get much lighter sleep. It also fits my personal wacko hypothesis as to why so many retired old people have so much trouble sleeping, which I continue to recklessly propagate despite a complete lack of solid evidence: they just don't work hard enough. reply Modified3019 2 hours agorootparentThat’s definitely an intriguing idea, and imo would be worth studying. (Then we could ignore the results and instead demand pills that don’t help or have pyrrhic side effects if they do.) reply zeroCalories 7 hours agoparentprevMy own anecdote is the opposite: I can't sleep well if I don't regularly exercise. I think we all kinda know this, but it's good to see more data to refine our intuitions. reply astrange 5 hours agorootparentHey, that's the contrapositive, not the opposite. reply mjevans 7 hours agoparentprevSame experience here. That's my 'Convention Attendee' / 'Theme park '''vacation'''' exercise and get the heck to sleep program. reply frameset 1 hour agorootparentSadly a Disneyland Paris season pass is more expensive than a home gym over the long term. reply Fire-Dragon-DoL 10 hours agoparentprevThe body gets used to it though reply ReptileMan 1 hour agorootparentYou can always try and walk faster reply fkkffdddd 13 hours agoparentprevIf you’re missing that now - perhaps a great opportunity. reply adversaryIdiot 10 hours agorootparentyes lets leave our 9-5 to walk instead reply AgentOrange1234 9 hours agorootparentYou joke(?) but I have had tons of success in asking people if they’d like to go on walking meetings with me, both virtual and in person. I have sometimes clocked 20k steps at work! reply Brajeshwar 8 hours agorootparentWell, \"Walk/Talk\" is one of the most effective method. If the parties are abled, a walk/talk will give enough time even for non-walkers to talk and bring up topics/points. If they get tired, then the talk had extended beyond its need. I tend to have a few keywords to organize my calendar entries with the likes \"TBD: foobar\", \"Plan: LoremIpsum\", and one of them is \"Walk/Talk: Awesome Person\". reply kqr 1 hour agorootparent> one of the most effective method. ...well, for you, maybe. I'm of the kind that gets very easily distracted when walking outside. Also it's harder to take notes. reply HPsquared 48 minutes agorootparentTranscription apps are your friend. reply xarope 8 hours agorootparentprevisn't that called golf for some execs? reply graeme 8 hours agorootparentprevThe trick is to live somewhere where walking makes sense, and also add small opportunities to walk during the day. For example, if parking, park a bit further from where you're going. Or if you have calls to make, call people/businesses while walking. Or if hanging out with a friend, go for a walk or do something physical. Everyone will have different constraints but it's generally possible to move more than you currently do. reply teaearlgraycold 8 hours agorootparentprevGet a flexible job and spend a couple of those daylight hours active. reply iwontberude 5 hours agorootparentprevI do it all the time, don’t see why not reply alwayslikethis 13 hours agoprevWrist watches can't really detect sleep stages. That requires at least an EEG to do reliably. The best they can do is maybe distinguish between sleeping vs awake. The only consumer device with an EEG is the Zeo, unfortunately they went bankrupt and people are unable to distinguish the flukes from the real ones. https://pubmed.ncbi.nlm.nih.gov/25991187/ reply pedalpete 11 hours agoparentThe data quality of wearables to detect sleep stages is in the 90%+ accuracy range now. Which is near what polysomnographers score at - nobody completely agrees on what stage is what, there is always deviation. Wearables are definitely good enough at this stage. Zeo is not the only consumer EEG either, though all the current headbands (including what we are building at https://affectablesleep.com) have some sort of sleep stimulation at it's core. Frenzband I believe is shipping, I haven't tried one, and don't know anyone who has. We have a Somnee at the office, and it is unbearably painful to wear. I'm highly skeptical of the \"science\" of either of these devices as well. reply tjoff 1 hour agorootparent90+ accuracy seems very optimistic. Still, I'd bet that whatever accuracy wearables get only work on a population, not individuals. I'm not surprised they are decent (though they can barely detect when you are sleeping...) but I don't put any faith at all on an individual basis. Given the data they can collect that is the best anyone can hope for anyway. So if you want to diagnose your own sleep, which you presumably would want to do if you are suspecting an issue, I wouldn't trust them one bit. reply CharlesW 11 hours agoparentprev> Wrist watches can't really detect sleep stages. As someone else noted, the paper you linked to is from 2015. Apple Watch couldn't do it until watchOS 9 (2022, 7 years later), but can now do this pretty reliably. You might find the \"Algorithm Development and Validation\" section of this whitepaper interesting: https://www.apple.com/healthcare/docs/site/Estimating_Sleep_... reply pkoird 11 hours agorootparentThanks for linking this. I always did wonder how they did it. From a cursory read, it looks like the basic approach is to collect accelerometer data and train it to predict ground truth labels generated via a consumer EEG device. Not sure if each epochs (30s) were considered iids. I'd assume that the overall sequence of activity would be much more informative than a single 30s activity considered independently. reply cj 11 hours agorootparentSometimes at work I’m concentrating so hard my Apple Watch logs a sleep session… Definitely not 100% accurate but as someone who checks their sleep log (and time in each stage using the Pillow app) daily, it seems pretty accurate and I can correlate how I feel on a given day back to that day’s sleep report with pretty good correlation. Definitely not perfect but better than nothing. If you’ve ever been on medication that suppresses REM sleep, Apple Watch detects REM rebound very clearly. reply pkoird 9 hours agorootparentI won't be surprised. The accelerometers seem to be pretty sensitive. Enough to measure any variations in heart rates and breathing patterns which are likely highly correlated with sleep patterns. reply astrange 5 hours agorootparentprevI didn't think it tracked sleep unless you put it into Sleep mode explicitly. reply fingerlocks 5 hours agorootparentYeah likewise. If I fall asleep during normal wake hours, such as an unexpected nap, it will vibrate and remind me to stand up because I’ve been inactive for too long. reply euroderf 2 hours agorootparentThere should be a toggle for this. reply genewitch 2 hours agorootparentprevi have purchased 2 amazfits and they work fine for sleep records, they use the zepp app. I've had 2 other watches that had sleep tracking, but the amazfit seems better, then again, it is much newer. reply magicalhippo 13 hours agoparentprevHeh my SO just showed me her Garmin-something tracker log the other day, and it showed her having an hour of deep sleep when she'd been lying on the couch watching TV. It's also showing various sleep stages whens he knows she's been awake, trying to sleep. reply nottorp 1 hour agorootparent> it showed her having an hour of deep sleep when she'd been lying on the couch watching TV The Garmin may be right considering the quality of TV... even if she had her eyes open... reply drewg123 12 hours agorootparentprevI love Garmin watches for many reasons, but their sleep tracking is horrible. Even my ancient MS Band did a better job than my Garmin Fenix 6 reply oraphalous 10 hours agorootparentI got a epix 2 pro which has their new heart rate tech. It tracks my sleep very reliably. reply jurassicfoxy 11 hours agorootparentprevIt's pretty awful. Though they seem to be capable of detecting terrible sleep, at least. Gotta love a 40 sleep score night. reply drewg123 11 hours agorootparentAgreed. But it can't tell if I'm jet-lagged and I wake up 3 hours into my sleep at 2:30 am and lay there still, yet unable to get back to sleep. That is sometimes an 80 sleep score night, when really it should be a 40. reply chimeracoder 13 hours agorootparentprev> It's also showing various sleep stages whens he knows she's been awake, trying to sleep. To be fair, people actually aren't that great at detecting when they (or others) are really sleeping. Especially for one's self, it's common to believe that you spent more of the night tossing and turning than you really did, when in reality you actually got some light sleep sprinkled in those periods. That said, consumer-grade wearable devices are demonstrably not great at this either. reply jeremiemyhren 12 hours agoparentprevI miss the Zeo. The app would still work locally long after they shut the backend down, until there just was no more aftermarket / eBay supply of their unique silver coated contact padded headbands that actually did the brainwave monitoring. I do find the Apple Watch Ultra seems to be close to at least being in the ballpark in terms of stage and duration accuracy as its output is comparable to what I last got with Zeo, albeit 10 years ago. reply KennyBlanken 12 hours agoparentprevThat study is nearly ten years old and almost certainly not relevant anymore. The Basis Peak did a good job at tracking sleep but they got bought up and killed off by Intel for god knows what reason. The Peak also did automatic activity detection and it was quite good at it. Basis also had hands-down the best visualization of activity and sleep trends, and was the only watch at the time to do full time HRM. They claimed the Peak watches were a fire risk and recalled them, probably to have a reason to get rid of all the back end infrastructure. Garmin still can't reliably autodetect biking and its sleep tracking is pretty terrible, too. reply cassianoleal 13 hours agoparentprevThere was the Dreem 2 as well but they have also ended production. reply verticalscaler 12 hours agoparentprevThis review channel begs to differ: https://www.youtube.com/@TheQuantifiedScientist/videos He very throughly compares countless models with a Polar H10 strap. Some come close enough. reply twobitshifter 8 hours agoprevREM latency is good because? I find I feel more rested with more REM cycles which generally means REM starts earlier. reply busymom0 14 hours agoprevPersonal anecdote: when strength training, I find that I have the best sleeps on the night and second night after I do a session of heavy farmer walks/carries. They are one of the most exhausting exercises for me and great sleep is a good reward. reply nine_zeros 9 hours agoprevAnecdotally, ever since I started wearing the whoop, I have been very cognizant of my sleep and recovery. My sleep quality has improved merely by following their recommendations. A great burden lifted tbh. reply sandspar 2 hours agoparentMy health watch both adds to and decreases my mental burden. I am healthier. But I often think of the person who said, \"My Garmin has made me less fun.\" My health watch has increased the amount of time I spend feeling guilt. reply 1letterunixname 10 hours agoprevIIRC, the qualitative (or proven quantitative) connection between exercise and improved sleep is most pronounced with morning exercise (HIIT/weight lifting). reply kapp_in_life 9 hours agoparentThis is interesting to me, do you know any articles about this? I feel when I put off exercise until later in the evening(after 7pm) that I often get poorer quality sleep, but I'd be surprised if working out at 6am vs. lunchtime would make that much a difference. reply xarope 8 hours agorootparentI used to have to work out late at night (like 8-10pm), and found that 30+ mins of low intensity cardio and a long period of relaxed stretching after the workout helped. reply jeffbee 14 hours agoprevI tried wearing my Garmin to bed for a while, but the information just wasn't that interesting. I can see where science gets value out of a population study but for the N=1 population consisting of yourself, I just wasn't seeing the point. reply phildenhoff 14 hours agoparentOn the contrary, I’ve been wearing my Apple Watch nearly 24 hours a day for a few years and find the sleep info extremely useful. Really, the primary benefit I get is twofold: 1. I know approximately how long I slept for and remind myself of that all day via a widget. A short sleep is common for me, but I end up feeling foggy. Being reminded that it’s OK, I had a poor sleep, helps ease my mind. 2. I see approximately when I fell asleep and when I woke up. I end up having to add extra time if I sleep past my alarm, but seeing that I didn’t really fall asleep until late into the night helps me manage the pattern of late nights. Both of those are easily covered by even semi-diligently tracking your sleep on paper, but having my watch do it for me is what I like! reply ScoobleDoodle 14 hours agorootparent> I end up having to add extra time if I sleep past my alarm I find this one a painful design decision on the Apple team's part. The end time of the normal desired sleep schedule does not mean the literal end of sleep every day. I wish they wouldn't clip the data at the end of the sleep schedule. Maybe it's because they're using heuristics and so all the data is guesstimates? reply ra7 13 hours agorootparentI find the Autosleep app to be much more accurate than the Watch's native sleep tracking. reply tillcarlos 8 hours agorootparentI have been using Autosleep now with an apple watch 6 - for 3 years daily. The learnings and the gamification are huge for me. I got my deep sleep up from 1.5h to consistently over 2h. Learnings: - early to bed makes more deep sleep. Huge difference from 10pm or 12am - magnesium doesn’t help at all - sauna before does help, but hard to do daily - deep sleep less than 1.5h makes for an awful day with angry mood - cold room: biggest lever. Haven’t pulled the trigger on an 8sleep yet. But that wouldn’t be my next thing if sleep wouldn’t be so great. - also, as weird as it sounds: having something exciting to work on improves sleep by a lot. YMMV reply manwe150 7 hours agorootparentFrom Apple Watch, I learned I get 11 minutes of deep sleep last night, and generally average well under half an hour (for a full 8 hour typical). I can fall asleep easily, but apparently not very well. Yours sounds great. reply wodenokoto 4 hours agorootparentprevI've been considering buying an apple watch just for the stats. I really don't like how my co-workers watches light up when the move, or when they receive a message, so I wonder if I can turn off everything except health stat collection, at which point the whole thing seems a bit absurd. reply nmarinov 3 hours agorootparentIf that's your only showstopper you can change that in settings. Look up Raise to Wake[1] and Notifications[2] in Settings. I'm usually using Theatre Mode which keeps the screen off until an alarm or I wake it up and have pretty much all notifications off. I still get heavy use of the watch itself for timers, reminders, calendar, tracking workouts and health stats and whatnot so I'm very happy with it. [1] - https://support.apple.com/en-gb/guide/watch/apd748b87e2a/wat... [2] - https://support.apple.com/en-gb/guide/watch/apd9b833c9f3/wat... reply wiredfool 13 hours agorootparentprevMine was absolute crap at sleep detection. Typically it would report that I fell asleep before I went to bed, or I was asleep longer than I was in bed. Heart rate detection and so on was generally fine through the night, as was Hrv. I sort of wonder if the actual sleep detection is done on the phone, and if the phone is not nearby, it just fails. (My phone doesn’t go to the bedroom. Makes it far easier to actually sleep) (Also, Watch is dead now, and didn’t replace it, so I might be misremembering the exact bits, but the results were generally paradoxical) reply DefineOutside 14 hours agoparentprevI find my Apple Watch information useful. I don't remember when I fell asleep but my apple watch does. This keeps me honest about going to be too late. Additionally, when I first got it, I found that I was only getting 40 minutes of deep sleep which is why I was always somewhat tired. After adding magnesium to my diet I am getting around 70 minutes of deep sleep. I wouldn't have been able to pinpoint this without the data. The apple watch is the best sleep tracker [1] so your data might be too noisy to find results. [1] https://youtu.be/LPqtfC70QTU?si=6tTayfNCkcJwDayW&t=12m30s reply greymalik 14 hours agorootparentDoes Watch accurately capture when you fell asleep, as opposed to when you lay down and stopped moving? reply DefineOutside 13 hours agorootparentNot that well. You have to extrapolate from when the first first deep sleep occurs in comparison to other nights. reply _qua 14 hours agoparentprevI used to be someone who might have a single beer with dinner a few nights per week. When I got a Garmin and saw what it did to my stress levels and sleep, I essentially stopped drinking at all except for rare social situations. In addition to improving the numbers, I noticed a qualitative improvement in my sleep, energy levels, and exercise recovery. reply Aromasin 13 hours agorootparentI had the same experience. It puts things into circumspect when you can physically see how erratic things like heart rate and sleep stage times differ with just a single drink. The difference for my was so stark you'd think it were a bug if it weren't for the fact I could spot the pattern and test to see the truth of things. reply jeffbee 12 hours agorootparentOK but once you've learned this fact (that I think you could have learned from numerous sources without any technology), what is the ongoing value of the sleep tracker? I feel it is in the category of things that you learn from but then stop needing, including a cadence meter on a bicycle, bathroom scales, and similar devices. reply lukeschlather 8 hours agorootparentYou never really know when it might matter. One huge thing is when I have a serious illness I can see my heart rate remains about 80bpm all night long. I know my immune system has quieted down when my nighttime heart rate gets back down in the 50s. This doesn't even require accurate sleep tracking. (In fact the watch has a hard time even noticing I'm asleep when I'm that sick, but it doesn't really matter, it's very useful.) I also notice similar things related to heavy exercise etc. reply hunter-gatherer 7 hours agorootparentDo you not get fever dreams? Even if I have a slight fever (say 100) my dreams are uniquely different, so I always know when I have a fever at night. Hard to explain \"fever dreams\" if you don't get them... reply lukeschlather 5 hours agorootparentI've seen my heart rate elevated when I don't have a fever, and it can take several days to fully recover. Also no, I don't get fever dreams. reply sandspar 1 hour agorootparentprevIt's like the speedometer on your car. Even once you reach the speed limit, you may need to check your speedometer again and again, both for safety and comfort. Consider that different people place a different value on their health. In a high stakes environment like a school zone, you would prefer to check your speedometer more often. Also consider that the accompanying apps are gamified, as in addiction forming. reply esel2k 14 hours agorootparentprevWhat are measurements for stress levels? Are they accurate enough? reply occz 14 hours agorootparentI find that I can pretty consistently see an increase in resting heart rate by several beats per minute the day after drinking, an elevated skin temperature and a reduction in Deep- and REM-sleep. Particularly heavy drinking will manifest itself as a large drop in heart rate variability. reply jurassicfoxy 11 hours agorootparentprevWhether the measurements are accurate enough is not clear, but they are certainly precise enough. I (and all my friends) can easily see huge differences in HRV on nights of drinking, it's pretty amazing. reply p_j_w 14 hours agorootparentprevI may be wrong, but I think it's just heart rate and heart rate variability. reply nradov 11 hours agorootparentprevGarmin wearable devices display a proprietary stress metric from their Firstbeat Analytics subsidiary. This is basically just heart rate variability (HRV) normalized to the user's baseline. https://www.firstbeatanalytics.com/en/features/all-day-stres... As for accuracy, compared to what? Any definition of \"stress\" is inherently somewhat arbitrary and subjective. There seems to be a decent correlation to how I'm feeling. But the metric isn't really actionable for most people. reply aaronrobinson 13 hours agoparentprevIt is interesting but I find Garmin data completely unreliable. For example, it claims I’m awake for 2-3 times each night for 30 minutes or more, it claims I’m asleep when I know I was on Tik Tok because I couldn’t sleep. reply creaghpatr 14 hours agoparentprevI enjoyed getting the metrics (not sure how accurate they were) but my garmin is so clunky it's impossible to sleep in. Great for everything else. reply jeffbee 12 hours agorootparentI wear the women's model of the smallest one they make for this exact reason. Most of the watches Garmin is making are just ridiculously big. reply pedalpete 11 hours agoparentprevI had the same experience when I first started sleep tracking before beginning our start-up https://affectablesleep.com. My oura would tell me I didn't get enough deep sleep, or REM sleep, and I was like - so what? What do I do with that information? We're using auditory stimulation to increase the efficiency of deep sleep during the night. The data after a night of sleep is less valuable than the real-time intervention. reply genewitch 2 hours agorootparentwhat do you think of binaural beats (cool edit pro did them the best, you could even use arbitrary audio) for helping with sleep? I know it's probably a big ask to wear headphones prior to sleep but when i was younger i used binaural beats for a few years to try hacking my brain a bit. When it \"clicks\" the sensation is pretty noticeable and intense. I described the default \"noise\" binaural beats \"activating\" like the sound of a helicopter circling around you, but quietly and quickly. reply dsalzman 14 hours agoprev [–] This is one of the great “no shit” type studies. Good to validate basic and ancient wisdom I guess. reply abdullahkhalids 14 hours agoparentSome sequence of studies are not meant to validate that an effect exists, but to quantify the size of the effect. And the size of the effect under varying circumstances. reply shawnz 14 hours agoparentprevWhat? Exercise decreasing the proportion of sleep spent in the REM phase is \"basic and ancient wisdom\"? Exercise improving sleep quality, sure, but this study is saying something much more specific than that reply 0xcde4c3db 11 hours agorootparentFrom this study I don't think it's even clear why or under what conditions higher REM latency is better, or that increasing it in an individual can necessarily be considered an improvement. (I also don't think that's what the study was for; I think they were mostly trying to validate the methods against established results.) reply dsalzman 6 hours agoparentprev“65 participants (Mage = 21.40, SD = 3.21, N = 42 females) with an average of 35.20 (SD = 27.01) days of observation per participant.” reply phildenhoff 14 hours agoparentprev [–] First you validate the no shit, and then you can ask why! reply hattmall 14 hours agorootparent [–] lol, the why is also no shit too though in this case.... because you are tired. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A study at The University of Texas at Austin reveals a connection between physical activity, sleep quality, and mental well-being in 82 young adults using wearable technology.",
      "Engaging in physical activity was linked to more profound and rejuvenating sleep, leading to enhanced mood and decreased stress levels.",
      "The research emphasizes the significance of regular exercise for improving both sleep quality and overall psychological health."
    ],
    "commentSummary": [
      "Wearable study reveals physical activity can enhance sleep quality by prolonging REM latency, supported by anecdotal evidence.",
      "Users share mixed experiences with Apple Watch and Garmin sleep tracking accuracy, some finding them beneficial while others causing stress.",
      "Discussion includes the use of magnesium for deep sleep improvement, stress monitoring, and binaural beats for stress relief and sleep assistance, emphasizing the significance of physical activity for better sleep and varied views on sleep tracking tools."
    ],
    "points": 139,
    "commentCount": 84,
    "retryCount": 0,
    "time": 1712080708
  }
]
