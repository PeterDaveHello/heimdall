[
  {
    "id": 38241304,
    "title": "HTML First: Simplifying Web Software Development and Increasing Accessibility",
    "originLink": "https://html-first.com/",
    "originBody": "HTML First HTML First is a set of principles that aims to make building web software easier, faster, more inclusive, and more maintainable by... Leveraging the default capabilities of modern web browsers. Leveraging the extreme simplicity of HTML's attribute syntax. Leveraging the web's ViewSource affordance. Goals The main goal of HTML First is to substantially widen the pool of people who can work on web software codebases. This is good from an individual perspective because it allows a greater number of people to become web programmers, to build great web software, and increase their income. It's also good from a business perspective as it decreases the cost of building software, and decreases the amount of resources required to hire - a notoriously resource intensive process. A second goal of HTML First is to make it more enjoyable and seamless to build web software. Most web programmers are familiar with the excitement of seeing their product come together rapidly as they transition smoothly between the text editor and the browser, with very few unexpected potholes or context switches. But today it takes several years of mastering tools and frameworks to get to that stage. HTML First principles should allow people to unlock that feeling, and level of mastery, much earlier on in their coding journey. The way we achieve these goals is by acknowledging that HTML is very easy to understand, and thus using HTML as the bedrock of our product - not only to define content and structure, but also to set styling and behaviours. Principles Prefer Vanilla approaches Use HTML attributes for styling and behaviour Use libraries that leverage HTML attributes Avoid Build Steps Prefer Naked HTML Be View-Source Friendly Use \"vanilla\" approaches to achieve desired functionality over external frameworks The range of things that browsers support out of the box is large, and growing. Before adding a library or framework to your codebase, check whether you can achieve it using plain old html/css. EncouragedClick to toggle content This is the full content that is revealed when a user clicks on the summaryDiscouraged import React, { useState } from 'react'; const DetailsComponent = () => { const [isContentVisible, setContentVisible] = useState(false); const toggleContent = () => { setContentVisible(!isContentVisible); }; return (Click to toggle content {isContentVisible && This is the full content that is revealed when a user clicks on the summary}); }; export default DetailsComponent; Where possible, default to defining style and behaviour with inline HTML attributes For styling this can be enabled with an SPC library like Tailwind or Tachyons. For behaviour, you can use libraries like hyperscript, Alpine, or similar. Yes, this does mean your HTML will look busy. But it also means it will be easier for other developers to find and understand behaviour, navigate it, and make changes to it. EncouragedClick MeDiscouragedClick Me#results-pane.active { background-color: green; } var resultsPane = document.getElementById(\"results-pane\"); resultsPane.addEventListener(\"click\", function() { this.classList.add(\"active\"); }); You may notice that this approach seems to violate Separation of Concerns - one of the most commonly-touted software design principles. We believe an all-or-nothing approach to SoC is flawed, and instead advocate an approach that accounts for Locality of Behaviour and acknoweldges the trade-offs between the two. HTMX on The Locality of Behaviour Principle Adam Wathan on separation of styling concerns. Where libraries are necessary, use libraries that leverage html attributes over libraries built around javascript or custom syntax EncouragedDiscouraged echo#update\"> const application = Stimulus.Application.start(); application.register(\"echo\", class extends Stimulus.Controller { static targets = [\"source\", \"output\"] update() { this.outputTarget.textContent = this.sourceTarget.value; } }); Steer Clear of Build Steps Libraries that require transforming your files from one format to another add significant maintenance overhead, remove or heavily impair the ViewSource affordance , and usually dictate that developers learn new tooling in order to use them. Modern browsers don't have the same performance constraints that they did when these practices were introduced. And if we use HTML First libraries like static tailwind or htmx, the amount of additional CSS and JS needed is usually minimal. EncouragedDiscouragednpx css-compile -i ./src/input.css -o ./dist/output.css --watch Aside: The build step practice is so deeply ingrained that even one year ago this opinion was considered extremely fringe. But in the last year has begun to gain significant steam. Some recent examples: @dhh - \"We've gone #NoBuild on CSS with 37signals\" Are build tools an anti-pattern by Chris Ferdinandi How do build tools break backwards compatibility Blake Watson - \"There has never been a better time to ditch build steps\" Prefer \"naked\" HTML to obfuscation layers that compile down to HTML This principle is most applicable to backend implementation. The underlying idea again here is readability. If a developer who has familiarity with HTML but not with your backend framework looks through your view files, they should still be able to understand 90%+ of what they see. As with above, this means sacrificing brevity for understandability. Encouraged \" method=\"post\">First Name \" /> Last Name \" /> Last Name \" /> DiscouragedWhere possible, maintain the right-click-view-source affordance The beauty of the early web was that it was always possible to \"peek behind the curtains\" and see the code that was responsible for any part of any web page. This was a gift to aspiring developers, as it allowed us to bridge the gap between the theoretical (reading about how code works) and the practical - seeing both code and interface alongside each other. For many sites, we could copy and paste the html or css and run it in ourselves to get a close-to-identical replica. \"Remixing\" existing snippets was not only a way to learn, but often formed the basis of our new creations. In the time since, the industry has adopted several \"improvements\" which have made this practice much rarer. For example, if we use React - the most popular frontend framework, we cannot hit \"View Source\", copy the code, and remix it, because 1. React has a build step, meaning the code we see in the developer tools is different to the code that the developer wrote, and 2. React code snippets must be wrapped in a react application in order for them to work. For sites that follow HTML First principles, we regain the ViewSource affordance again. In fact, HTML First sites often go one step further. Because if you define your UI interactions using HTML attributes, you can now also preserve these interactions when copy pasting into a new codebase, (provided your destination file includes the same js library). At some point we intend to levearge this to build an HTML First code snippet library. HTMX.org on the ViewSource affordance Wrapping Up The practices and principles described on this site are still considered niche in the industry as a whole, and the community of people using them small. One of my hopes with creating this site is to act as a Honeypot to find and connect like minded people with whom we can discuss and sharpen these ideas. If any of this resonates with you, I'd love to hear from you.",
    "commentLink": "https://news.ycombinator.com/item?id=38241304",
    "commentBody": "HTML FirstHacker NewspastloginHTML First (html-first.com) 793 points by tonyennis 18 hours ago| hidepastfavorite484 comments codeptualize 16 hours agoparentThis is fun in to theory and in simple examples, but show me a big project that applies this and how it made a difference.There are some bold objectives at the start that would be wonderful, but I’m a bit disappointed by the advice. I really don’t see how these would work in anything other than very basic scenarios, even less how they would achieve the objectives.I’m all for using the web platform to the max, and I’m absolutely for reducing complexity as much as possible, but I’m highly skeptical these principles will achieve that and I would not be surprised if it increases complexity by having multiple ways to do something.With peace and love but I can’t see from this list if you actually put these principles to the test or you just assumed it will do what you hope it will. reply tabacitu 15 hours agoparentWhy? Why does it need to be good for big projects in order to be good practice?I’m genuinely asking. I never understood this argument that people bring.In my view, the web is 95% small to medium projects. Most technologies should be focused on that - simple solutions for simple projectS. Add complexity later. reply xgb84j 15 hours agorootparentBecause in practice there is little value in making easier things easier. While 95% on the web are small projects, 95% of work is done on large projects.Many developers also dislike using many different frameworks, because that would require more learning. If you have to choose one technology it&#x27;s better to use one where you can do everything. Not one where you can do 95% really fast, but 5% not at all.I personally always use \"complex\" frameworks like Angular or React because sooner or later feature requests come in, where those frameworks pay off. On average it saves time for me to always use those frameworks. That might be different for you depending on the work you do. reply squidbeak 14 hours agorootparentDo you have any data to support that 95% claim? As big as FAANG and other huge development teams are, it seems to me it&#x27;s still only the tip of the pyramid, with the overwhelming majority of people in the industry working full time on small or midsized projects. It&#x27;d be interesting to see some concrete info on it. reply xgb84j 12 hours agorootparentThe point where frameworks like Angular and React pay off and what I think of as complex projects are those where there is a some nontrivial feature. This coukd be a project with 1 developer working on it for 6 months.For example a static page with a booking process with various entry points on the website, which slightly change the booking logic. Also you can book as a new user, as a logged in user, for somebody else etc. Also the logic is changing at regular intervals, because the business owner is trying different things out.Using Angular with reactive forms makes this easier to develop, maintain and hand off to other Angular devs.While it makes writing the static parts of the website more complicated, it makes developing the booking process easier. And overly complicated business processes are what is mentally challenging for me. This is where I want all the help I can get. Writing static pages is something I can do in any framework even when I am tired. Making this part easier or reducing boilerplate is nice but doesn&#x27;t make me much happier. Being able to build ridiculously complicated forms without my head exploding does :) Of course if you work on projects with relatively straight forward requirements there is 0 advantage in using Angular or React for you. It always depends on the type of work you do. reply listenallyall 8 hours agorootparent> a booking process with various entry points on the website, which slightly change the booking logic. Also you can book as a new user, as a logged in user, for somebody else etc. Also the logic is changing at regular intervalsThe more complex the business logic, and the more options there are, and the more it is expected to change, the more it benefits the development team to write that code in their language of choice on the backend, close to the data store(s), using native classes&#x2F;objects -- rather than being forced to write it in JS&#x2F;TS, serialize everything to&#x2F;from JSON, reliant on magic under the hood to lay it out in the DOM, with more and more \"state\" necessary to be managed client-side. reply _gabe_ 5 hours agorootparent> the more it benefits the development team to write that code in their language of choice on the backendWhy?TS is maintainable and very pleasant to code in. Most people’s computers are way faster than making round trips to a server. You talk about serializing everything to&#x2F;from JSON, but my phone can do that in milliseconds (if not faster). Compare that to 100-200ms of latency between a faraway server, and all of a sudden doing things client side makes sense.Engineering is all about tradeoffs. I’m tired of people trying to make blanket statements like “React is always better”, or “SSR is always better”. It’s not, and we know it’s not. There are several successful, performant, maintainable apps written using React. There are plenty written using a backend framework and SSR too. Heck, there’s successes that use both!The common denominators in the success stories? Competent engineers. And I expect a competent engineer can analyze requirements and determine what would be the best outcome for their target users. A booking site absolutely benefits from a front end framework that handles client side logic. It probably also benefits from a clever backend for processing the data after the user is finished with it. Let’s not pretend there’s a one sized solution that fits everything, because there isn’t. reply porker 3 hours agorootparent> Why?A tangential answer (focusing on backend not language) is because I&#x27;m (we&#x27;re) going to have to reproduce much of the fronted complexity of the business logic on the backend to validate what the frontend sends.I&#x27;m mostly agreeing with you. I&#x27;ve built multiple web-platformed insurance systems and booking systems in the last decade and moved from fully server rendered pages to client rendered forms. The complexity increased with that change but as you highlight once it&#x27;s done the ability to test different frontend flows is great.But I&#x27;d like a way to share more of the business logic rather than writing it twice. reply listenallyall 4 hours agorootparentprev> Compare that to 100-200ms of latency between a faraway serverA complex booking engine like an airline or Stubhub needs constant, almost real-time connectivity with a database, otherwise you risk selling product at a stale price, double-selling, selling to an unauthenticated person, getting taxes and fees wrong, missing custom post-sale add-on opportunities, and lots of other potential problems. The client has to make a lot of network calls, so you&#x27;re going to deal with latency, there&#x27;s no client-side solution that avoids it without risking the issues above. reply codeptualize 2 hours agorootparentHow are you going to do the updates without FE logic? Refresh the page constantly?The client being able to fetch just updates is a lot more efficient. If you open a web socket the server can even push.You make a great point why we use client side solutions. reply listenallyall 2 hours agorootparent> How are you going to do the updates without FE logic? Refresh the page constantly? The client being able to fetch just updates is a lot more efficient. If you open a web socket the server can even push.That&#x27;s exactly why HTMX has gained immediate traction so quickly, it solves many of these exact problems elegantly and easily, much of the time without a single line of JS. replyjosephg 13 hours agorootparentprevI suspect even at Google a lot more than 5% of effort goes into small to midsized projects. Bazel, ninja, protobuf, grpc, the API documentation website for Gmail, VP9, the Google transcode api, takeout, various corp network tools & services and so on.The big projects are of course important. But even chrome needs a simple little website with a download link. reply xgb84j 12 hours agorootparentThat&#x27;s a good point. I personally always like Angular and React, because even with most simple projects there is this one feature that is so ridiculously complicated that making it slightly easier to develop and maintain is important to me. I&#x27;ll gladly write thousands of lines of boilerplate just so I make it easier for me to succeed in developing this one endboss feature. If you do not have at least this one insane feature, Angular and React are definitely overkill. reply marcus_holmes 6 hours agorootparentI always see this as a communication&#x2F;management failure.Product folks come up with features. They have no idea how hard those features are to implement. Which in a way is a blessing; they&#x27;ll come up with the best features if they don&#x27;t have to consider the implementation details. But because there are always trade-offs in implementation they also don&#x27;t understand those.A feature that is super difficult to implement, and that therefore has trade-offs on speed, maintainability, etc, should be communicated back to the product folks. If you have to move to a framework just to implement this one feature, then that is either because this one feature is really badly or over-designed, or that one feature is absolutely critical to the entire site, which is stupidly rare and again a symptom that someone hasn&#x27;t really thought this through enough.The failure in communication is usually \"you&#x27;re just the nerd pushing the nerd buttons, you don&#x27;t have valid opinions on product design\" which is a cause of so, so many problems in our industry. reply Karrot_Kream 4 hours agorootparent> The failure in communication is usually \"you&#x27;re just the nerd pushing the nerd buttons, you don&#x27;t have valid opinions on product design\" which is a cause of so, so many problems in our industry.But are they that wrong? We compute to, well, do things with our lives. To find out how to go places, to pay bills, to talk with friends, to meet with people, to learn about things. A view that computation should come with technical (e.g. tech bloat) limitations in mind feels important only to technical people and not to actual computing. reply marcus_holmes 3 hours agorootparentYeah, I think so.If building it one way will take 3 months and involve shipping 500Kb of JS to every user, whereas building it a slightly different way will take 2 weeks and ship only 50Kb of JS, then I think the second option is better, even if it includes a slightly degraded customer experience (though tbh 500Kb of JS is all by itself a degraded customer experience).Our online lives would be a lot better if the product folks listened to the tech folks a bit more.I like to draw a parallel to music; if the producer doesn&#x27;t understand music at all, then maybe they should listen to the musicians a bit when it comes to creating a musical product. replyandybak 13 hours agorootparentprevThe \"big\" projects can do what the hell they want. They can afford to throw a ton of money at a problem.The small projects are where the people I care about are struggling. reply MrJohz 12 hours agorootparentAre people really struggling at that level, though? It has never been easier to write a complex page with minimal Javascript - there are more and more HTML elements that do what you expect (expandos and modals as some recent examples), Javascript is cleaner and more consistent across browsers (you really don&#x27;t need jQuery anymore), and CSS is more powerful but also so much simpler (flex+grid solve so many problems).Then if that&#x27;s not enough, you&#x27;ve got things like HTMX if you&#x27;re keen on doing everything in terms of html templating, you&#x27;ve got tools like Svelte if you want an isolated chunk of dynamic UI in a mostly static page, you&#x27;ve got bundlers like Vite that just work without any configuration if you get to the point where you need a build step, and you&#x27;ve got a multitude of lightweight frameworks for the next step.And on top of that, pretty much all the old ways still work. The browser is an incredibly stable environment! Outside of a handful of security-related removals, if it got into a mainstream browser, without a feature flag or an explicit \"experimental\" warning, it&#x27;s pretty much there for life. So if you want to go back to the old ways, there&#x27;s not much stopping you - but a whole bunch of quality-of-life development improvements along the way to make things even easier than they were back then. reply marcus_holmes 6 hours agorootparentFind a professional front-end developer who is willing to use simple HTML, JS & CSS and I&#x27;d agree with you.It&#x27;s almost impossible. The first reaction is always `npm init` reply azangru 2 hours agorootparent> Find a professional front-end developer who is willing to use simple HTML, JS & CSS and I&#x27;d agree with you.> It&#x27;s almost impossible. The first reaction is always `npm init`Consider a simple case — a static website containing several pages (it&#x27;s simpler than anything requiring a dynamic server, right?). If you are a professional front-end developer, you are almost certain to prefer some kind of a static-site generator over copy-pasting the html template with repeated elements (header, footer, navigation) multiple times, because you know that copy-pasting will bite you when you need to change something. You could use a static-site generator written in Ruby (but then you would gem install), or in Python (but then you would pip install); or you could use a Hugo binary (I&#x27;d love to see anyone call its templating language simple); or, if you are a front-end developer, you might npm init && npm install eleventy. Is this too complex a step? reply marcus_holmes 56 minutes agorootparent> or you could use a Hugo binary (I&#x27;d love to see anyone call its templating language simple)I dunno, I&#x27;m a Go dev, so it makes sense to me ;)> Is this too complex a step?If it just stopped there, sure, that would be fine. But it never does. My experience of front-end devs is that they will do anything to avoid writing any actual code. So there&#x27;s a tendency to pull in dependencies and bloat the thing until it suffocates in its own complexity. I&#x27;ve seen node_modules with thousands of subdirs, and a build process that takes minutes, for really very simple sites. reply MrJohz 5 hours agorootparentprevMost professional frontend developers are working on projects that require something more complicated than just the basics, because, well, that&#x27;s where the complexity lies, and so that&#x27;s where the work is.You can still find developers who are using the basics, but mostly they&#x27;re designing WordPress themes or working for boutique web design agencies, because those are the sorts of problems that are solved with just simple HTML, JS, and CSS.It&#x27;s like asking a Java developer when the last time they developed something without maven or gradle is, or Python developer why their first reaction is to use pip. If the majority of problems developers had to solve were simple enough that they didn&#x27;t need these tools, then there&#x27;d be far fewer developers and most of them would still end up working on the 20% of projects where they&#x27;re necessary. Because, well, that&#x27;s where the complexity lies. reply andybak 9 hours agorootparentprevSounds like we&#x27;re agreeing with each other and disagreeing with the big SPA framework guy? reply MrJohz 5 hours agorootparentI mean, I am a big SPA framework guy. That&#x27;s pretty much the main thing I use, day-in, day-out, because most of the projects I&#x27;m working on are complex enough that simply hand-coding the entire UI will not work.And, while only a minority of projects are that complex, those projects are the ones most developers are working on. Most other projects are probably better served with a wordpress install and a bit of theme customisation. Which means it&#x27;s going to be a minority of developers who work with the very minimal things that are sufficient in these sorts of cases. reply ceuk 12 hours agorootparentprevBig project =&#x2F;= Big companye.g. WhatsApp back before the acquisitionMaking it easier for people to build big, complex apps doesn&#x27;t favour large organisations with lots of resources. The opposite in fact. reply andybak 12 hours agorootparentnb I&#x27;m not agreeing with your original hypothesis.However I&#x27;m taking about even lower down the food chain than this. reply iopq 9 hours agorootparentprevSmallest projects just throw up a bootstrap template and call it a daysomething like this: https:&#x2F;&#x2F;www.hotelpalacebarcelona.com&#x2F;they don&#x27;t care it&#x27;s not \"html first\" reply codeptualize 14 hours agorootparentprevThis. Even for basic websites you benefit from some form of templating&#x2F;components for example to get the nav & footer on each page. reply timeon 14 hours agorootparentEven basic websites? It is developer vs user then.I think otherwise. I.e.: blog shouldn&#x27;t be web app just because it&#x27;s content management is. reply codeptualize 14 hours agorootparentNot at all. There are a lot of frameworks that support static exports and&#x2F;or pre-rendering. Often those produce incredibly fast results, in many cases faster than hand rolled solutions.If you use a CMS you have already a templating situation and dynamic content, using a framework, or jamstack like situation is not that different, depending on the specifics it might produce faster results. reply zilti 12 hours agorootparentprevYou don&#x27;t need a frontend framework for that. Fuck people who do. They&#x27;re the reason most websites are slow as molasses on my three year old phone, despite them being very basic sites. Just stuffed to the brim with unnecessary bullshit. reply MrJohz 12 hours agorootparentWhile I agree that there is probably an overuse of frontend rendering when templating in the backend would be fine, I suspect most of the problems you see have nothing to do with that. In my experience, the number one issue with slow sites is an overuse of trackers and advertising that drags everything down. reply docmars 10 hours agorootparentPrecisely. Using libraries &#x2F; frameworks like React, Vue, Svelte, etc. adds nearly no overhead to the core functionality of whatever it is you&#x27;re creating, _especially Svelte,_ since it compiles down to the bare minimum necessary to power any dynamic functionality (it doesn&#x27;t ship with a complete runtime), and supports static templates and markdown out of the box.I can say with confidence that unless I royally screw something up in my component lifecycles or render loops, everything is just as snappy as ever. No latency. No lag. Just a zippy fast web app with URL&#x2F;route changes that fly, fetched data populating quickly, and interactions feeling wonderful -- and that&#x27;s because said apps I&#x27;m developing _aren&#x27;t_ using any heavy tracking libraries.People are too quick to blame slow performance on modern view libraries, and even likelier: they&#x27;ve never used them before. reply codeptualize 11 hours agorootparentprevIf you statically export you won&#x27;t even notice, and when navigating it will actually be a lot faster when only the content is replaced..Have you checked this is the reason? not slow network? and not ads&#x2F;analytics and blocking assets? That&#x27;s not exclusive to frameworks btw, and probably less likely as most optimize these things for you.The website that is linked originally has a bunch of blocking assets.. lighthouse score is not amazing either.Just like the original article, you might want to test your assumptions a bit more. reply hhsectech 2 hours agorootparentprevThis.Big companies are in the minority and what they do would not classify as \"normal\" or \"standard practice\".It really bugs when people say \"it&#x27;s standard industry practice\" when actually what they mean is \"thats how the big businesses do it\". reply edanm 3 hours agorootparentprev> In my view, the web is 95% small to medium projects.I&#x27;m not sure that view is correct. For one thing, I&#x27;m not sure how you even define this.As technology has advanced, many of the \"small&#x2F;medium\" projects that used to require lots of dev time have turned into fully-built alternatives. The days when you need a dev to setup a blog are gone, as are the days you need one to setup a store, or a simple marketing website.Are these part of the 95%? In some sense, yes, but in the sense of giving advice on a framework to choose, not at all, because no dev will even be making that choice - it&#x27;s irrelevant.As for medium-sized projects, there are tens of thousands of small, internal company tools that aren&#x27;t even on the open internet. They probably fit your definition of being medium sized, let&#x27;s say have a few devs working on them for many years, certainly medium sized compared to FB etc - but I&#x27;m not sure that whether this approach is right or wrong for them. (Genuinely not sure!)I&#x27;m just saying, you need to much better define what you mean by small and medium sized, because some people might be thinking of my definition, while for some people medium-sized is, idk, AirBNB, which is tiny compared to FB but gigantic compared to most projects out there. reply elbear 3 hours agorootparentprevThis is not only about big projects.Their second principle, to use inline styling, makes it harder to create a consistent look across the entire website. Defining that in one place and referencing it everywhere is better and easier. reply codeptualize 15 hours agorootparentprevI&#x27;d be more than happy to see small or medium projects and how these tips improved them. Any real world examples would be great.I would also add that a lot of us do work on the bigger projects, which makes sense as bigger projects require more people. So at least in my life, and I expect many others, it is quite relevant.I also don&#x27;t believe the article qualifies that these tips are only for small to medium projects, I&#x27;d read it very differently if it did, but I would still like to see some real world examples though. reply ozim 10 hours agorootparentprevI would say that explaining where guidelines are applicable is on author side.For text at hand I understand that author expects this way should be “the best” for everyone.Then author gives examples that even in medium project at first requirement change or first additional non-trivial rule are going to have 2-way bindings plus bunch of other plumbing implemented where “html first” doesn’t have it and someone will have to write some JS monster to handle state etc. reply kissgyorgy 10 hours agorootparentprevIf your project is small, doesn&#x27;t matter what you use, it won&#x27;t be complex anyway. reply drpixie 11 hours agorootparentprevAnyway, a well organised big project is a collection of related small projects :)And what&#x27;s good for one small project is likely to be good for many small projects. reply nonethewiser 10 hours agorootparentprev> In my view, the web is 95% small to medium projects.In what terms? Sites in existence? I suppose. But sites by usage? Virtually all huge. reply resonious 9 hours agoparentprevI tried to push for an \"HTML first\" style frontend at my job, but we hired some run-of-the-mill frontend devs and they basically didn&#x27;t get it and just wanted everything to be divs with VueJS controlling all of the logic and content.One semi-objective thing we lost was accessibility. Much of the site is impossible to navigate via keyboard due to naively re-implemented behavior like links being divs with click event listeners. It&#x27;s actually somewhat worrying - when regulations hit us, we&#x27;ll have to scramble hard to get back what we threw out.But all in all I kind of agree with you that it&#x27;s very hard to find high profile examples of sites that are \"HTML first\". I believe in it, but haven&#x27;t actually seen it pan out. But I suspect the reasons for it not panning out might be purely in education. By the time HTML became powerful, frontend dev education was already deeply framework-focused. reply codeptualize 3 hours agorootparentThis article had as a “good” example a div with an onclick, I think he fixed it, but it shows a lot..Frameworks also have linters that will help a lot, it’s on you to use them reply listenallyall 9 hours agorootparentprev> it&#x27;s very hard to find high profile examples of sites that are \"HTML first\"Because the tools to create it are relatively new, and the sites you&#x27;re speaking of had already been written. What high-profile site didn&#x27;t already have a massive legacy React&#x2F;Angular&#x2F;Vue codebase, and a team of framework-trained developers, as of 2021? reply gedy 8 hours agorootparentprev> One semi-objective thing we lost was accessibility.TBH that&#x27;s not a framework vs HTML issue, that&#x27;s just sloppy or inexperienced devs reply chii 7 hours agorootparentI argue that it is a framework issue.If the rendering framework doesn&#x27;t support accessibility as a first class citizen (or better yet, automatically creates&#x2F;makes accessibility part of what is rendered), then the framework is not suitable for production use. reply LudwigNagasena 6 hours agorootparentReact simply diffs the DOM and updates it in an efficient way. If you are putting weird divs instead of anchors and buttons (or instead of special components provided by a React-based framework), that&#x27;s entirely on you. reply chii 6 hours agorootparentif you&#x27;re using react and then hand roll custom components and don&#x27;t do accessibility, then it&#x27;s just as bad as choosing a component framework which doesn&#x27;t do accessibility. I am not talking about react (or any framework directly) specifically.> entirely on youof course - choosing a framework or hand rolling one makes no difference. It&#x27;s still not production ready, if it doesn&#x27;t have accessibility built in. reply MrJohz 4 hours agorootparentI think the point they&#x27;re making is that you&#x27;d have the same problems with developers working HTML-first. Accessibility does not simply come for free in either situation, you need to make sure it&#x27;s present.Choosing, for example, whether to use a div with a click handler, or a proper button, is a decision you need to make regardless of whether or not you&#x27;re using a framework.So it seems incorrect to say that you lost accessibility in this case due to the framework. You lost accessibility due to developers who didn&#x27;t understand the web platform well enough to design proper accessible controls. If they hadn&#x27;t used a framework, they&#x27;d probably still not have made the site accessible. reply chii 3 hours agorootparent> developers who didn&#x27;t understand the web platform well enough to design proper accessible controls.And i actually think that it is _better_ for a developer not to have to do their own accessibility controls, but delegate this problem to the component framework. They have to know about the problem, but not have to spend cognitive budget thinking about it while they compose their UI from framework components - this should _automatically_ be taken care of by the design of the framework. replymatijsvzuijlen 4 hours agorootparentprevWhat could the frameworks do to make it more natural for inexperienced developers to do the right thing? reply philihp 16 hours agoparentprevFor a frontend developer who is younger than jQuery, starting a project following this advice would be a good opportunity to learn why we do the things we do like build steps, and remember how much development sucked before HMR.I suspect the author hasn&#x27;t actually done this on a project with more than one person, supporting 99% of browsers in the wild. I also suspect they didn&#x27;t run their own code, because either my screen is not as tasty, or \"onlick\" is not an handler of div. reply tonyennis 16 hours agorootparentYour suspicion is incorrect. Currently running 10 or so codebases with 8 devs using this approach. Thanks for catching the typo reply codeptualize 16 hours agorootparentThats great. Show us!! What projects, is it 8 devs per project or total, what was the impact, any downsides?Nothing is more convincing than real world success stories. reply tonyennis 14 hours agorootparentComing soon reply docmars 9 hours agorootparentprevDo you find that your team often has to reinvent the wheel in terms of what libraries like React&#x2F;Vue&#x2F;Svelte have to offer? Doesn&#x27;t that increase time and scope tremendously? reply whstl 8 hours agorootparentI actually find that I often have to reinvent a lot of the browser&#x27;s wheel when using React and friends, so it&#x27;s often a wash.Complete back button support beyond what the router offers, saving search&#x2F;sort&#x2F;filter in query string so users can copy&#x2F;paste&#x2F;bookmark&#x2F;back&#x2F;forward, handling connection and other errors gracefully, loading, accessibility, having to wrap Vanilla JS components into their own framework-compatible components, having to update things in different parts of the screen. And the last often requires a total paradigm change in terms of how data is handled in the app thanks to the introduction of state managers (React-sans-Redux looks totally different from regular React). All those require extra work on every project I worked, and no, libraries often don&#x27;t solve them completely or as easily as it is with previous backend tech.These frameworks are also steering a lot of software into some very problematic product decisions. Like using fancy third party components where stylized native would suffice (and be more useable&#x2F;accessible), using date pickers for absolutely everything that looks like a date (it sucks to type your birthday in those unless you were born this month), saving things in the browser instead of in the backend (so the site looks different in different computers), or just having some specific UI-framework forced on you so you have to use a certain framework.There are obvious advantages to frontend frameworks, and I&#x27;m a big fan of React&#x2F;Vue&#x2F;Svelte. I really like those things, been using those for years and I was doing what used to be called \"DHTML\" since the late 90s. But it takes so much more complexity than the average web app to reap those advantages... IMO they are definitely overused. reply codeptualize 16 hours agorootparentprevGood old times, I used to have a file watcher that would refresh the page on change using a browser extension, not anywhere near the convenience of HMR though haha.I do agree with you, it&#x27;s why I&#x27;m skeptical about the results of following this advice. I vividly remember how much things sucked, and obv the web has come a long way, but the tools have gotten even further. If I see how much mileage I get out of the tools I use on the daily, I would not be nearly as productive without them, and produce a lot more buggy, inaccessible, and shitty apps. reply epiccoleman 7 hours agorootparentprev> starting a project following this advice would be a good opportunity to learn why we do the things we do like build stepsHonestly, and sarcasm aside, I think this is an incredibly important thing for any new web developer to do.Trying to learn web development in 2023 (or even in 2014, when I started my career) is so hard, because you&#x27;re constantly standing on top of the shoulders of giants without even knowing how far you are from the ground.I started a refresh of my personal site a few months back and resolved to write all the html and css \"by hand\", vanilla style, as a way of forcing myself to relearn the basics, and it was really refreshing to strip away all the layers of extra stuff and build it with simple tools. And I actually learned a ton of stuff that was useful on a daily basis while I worked on a React project during my day job, stuff that I just had never had to do or learn or use because some framework was always helping me out.Recently I&#x27;ve been working on a little toy app in Phoenix, and I had the \"revelation\" that Eex &#x2F; Phoenix components were slowing me down instead of speeding me up, because I didn&#x27;t understand the underlying concepts as well as I needed to. As soon as I said \"fuck it, I&#x27;m writing vanilla html and only using Eex where it&#x27;s absolutely necessary\" I was able to get through a whole host of issues that were giving me friction and actually build what I wanted.I had a similar experience a few years ago when learning Phoenix. I just didn&#x27;t get Ecto at all, and the reason was simple - I didn&#x27;t know SQL and database design. Once I resolved to just figure out how to do the thing I was doing with raw SQL, Ecto immediately made way more sense.We obviously can&#x27;t peel back layers of the onion forever, or we&#x27;d never get anything done. At some point you have to get comfortable with abstracting away the details. But what I&#x27;ve found in web dev is that the big frameworks are written by people who&#x27;ve done the \"vanilla\" way so much that they&#x27;ve identified places where things hurt and built solutions that abstract that pain away. That&#x27;s all well and good when you understand why the abstraction exists and the problem it solves, but it can really be confusing before you&#x27;ve put in the work to gain some of that context. reply iopq 9 hours agorootparentprevand this is why that example doesn&#x27;t work - you find out onclick doesn&#x27;t work where you thought it would workwhereas you can addEventListener anywhere you want reply csbartus 14 hours agoparentprevAgree.I&#x27;ve created my first website in 1999 with plain HTML, CSS, vanilla JS, hosted on Geocities.Since then I&#x27;ve been using PHP&#x2F;WordPress&#x2F;Yii&#x2F;Laravel, Ruby&#x2F;Rails&#x2F;Sinatra&#x2F;Jekyll, React&#x2F;Typescript, ClojureScript to create both sites and apps.With React &#x2F; TSX components &#x2F; CSS-in-TS &#x2F; Effects &#x2F; Context I&#x27;m home. Finally a fully fledged programming language for the web &#x2F; front-end. A language made explicitly for the front-end, built om modern principles like functional, reactive programming.Now I can do software development. Before that, with HTML, CSS, plain JS, PHP it was ... just hacking, nothing else. (Rails was good for full-stack, was not shining on the front-end)I&#x27;ll skip frameworks when the web stack will be ready for the apps, too. Now it&#x27;s (perhaps) good enough for sites, I should admit. reply squidbeak 14 hours agorootparentPerhaps web publishing shouldn&#x27;t be presupposed to be &#x27;software development&#x27;? reply raincole 8 hours agorootparentThen use Wordpress. Or Substack. Or even Wix.\"But we need this and that custom dynamic logic...\" well now we&#x27;re in the realm of software development. reply docmars 9 hours agorootparentprevThe line is very blurry, and the moment you&#x27;d like dynamic, interactive content embedded within that static content is when it&#x27;s time to reach for a view library like React.At that point, I&#x27;m just going to start the project with React &#x2F; Vue &#x2F; Svelte every time because almost 100% of the time, I realize I need to support the features they offer that raw HTML&#x2F;CSS cannot, or if they do, are very poorly implemented by browsers, hitting limitations with them that become frustrating and prevent you from achieving the scope you&#x27;re aiming for.Using any of those three libraries&#x2F;frameworks is painless, and I can get a project going rapidly and with high confidence that I can support any functionality, interaction, animation, content, routing, and other common web problems, with great ease. reply zztop44 12 hours agorootparentprevBut very often it is software development. And there isn’t always some bright line between them.Like it or not, the web is an excellent platform for delivering software applications to users, especially one-off or infrequently used applications.Let’s use software development tools, rather than web publishing tools, to develop that software. reply docmars 9 hours agorootparentIt&#x27;s worth mentioning that the friction to deploy a web app is nearly zero these days, depending on how complex it is.As an example, shipping a macOS or iOS app, via official means, requires a lengthy review & approval process, upfront costs, buy-in into native languages with little to no use outside of these platforms, a limited selection of tools, and hard decisions about which version of the OS to support based on the features you need vs. the market share of older versions.People (and teams) choose web development for the lower barrier to entry, and as a platform, browsers get products most of the way to their goals, and fast. reply skydhash 6 hours agorootparentMy preference is local first desktop applications. Sometimes it’s because I prefer files, sometimes it’s because native apps are more fluid and more egonomic. reply zztop44 3 hours agorootparentWhat about for getting quotes on insurance? Or booking a restaurant? Or a flight or hotel? Submitting your taxes? Getting printable directions to a trailhead? Proving feedback on someone’s Figma document? Previewing a 3D model before getting it printed…Is it your preference to install a new local first desktop application any time you wish to do any of these things? reply skydhash 2 hours agorootparentThat depends where the data and the logic all. If they only store the data, but I’m doing all the computation, it may as well be a local app (figma, the 3d viewer..) or at least have an API so I can build my own interface.I’m not against Web Apps, but many take my browser as free real estate. reply zilti 12 hours agorootparentprevHopefully WASM will fill that area, and browsers can go back to being browsers. reply shadowgovt 10 hours agorootparentNot as long as the only way that wasm interfaces to the DOM is through the JavaScript layer. reply thinkingemote 9 hours agorootparentprevAll of the technologies you used previously were considered \"finally fully fledged\" until they weren&#x27;t!We will be doing something different in a couple of years and saying that the stuff we do now is out of date and the new stuff is home. It&#x27;s always been this way. We are tech nomads finding ourselves new homes as and when we move on. reply docmars 9 hours agorootparentUsing PHP and other tools&#x2F;frameworks that tightly coupled the frontend to the backend codebase made life miserable. While I was excited to get into web development back when these technologies were popular, they were anything but pleasant to use.With the introduction of Angular 1.x and eventually React, Vue, and Svelte -- creating web apps finally felt productive, easy to debug, and easy to ship. Wiring up interactions finally felt intuitive. No more jQuery code colliding with itself as you struggle to organize your project and cobble together a bunch of poorly maintained \"component\" libraries and pray they work together without obvious user-facing bugs on your site or app.Or worse: on a team of engineers.I won&#x27;t lie, learning how early build systems worked was a pain, but the curve was completely worth it, and I wouldn&#x27;t change a thing. Today, using tools like Vite with their default project templates is almost too easy, and you can hit the ground running in no time.Publishing to Vercel, Netlify, and other modern hosting stacks is a breeze, and they all support direct tie-ins with every popular package & build system. reply al_borland 10 hours agoparentprevToo many people today are being pointed toward React to do very simple things, like a single-page site that is nothing more than a little text, some images, and a few links out to various other places. These sites could easily be HTML&#x2F;CSS. There is a lot of complexity for the sake of complexity on the web right now. reply projectileboy 10 hours agorootparentThe worldwide jobs program that is modern-day Javascript would have you believe that elaborate front-ends are necessary to give end users the experiences they expect, which is an utter pile of lies. What users want is something simple that works. reply docmars 10 hours agorootparentprevOne of the worst feelings is building a site without a view library like React, getting 80% there, and then realizing you absolutely need dynamic functionality and&#x2F;or state management because the project&#x27;s scope changed or started calling for it, only to realize you now need to refactor much (or all) of the site to make it easier to maintain across the board.This is why I reach for a view library like React, Vue, or Svelte, even if I&#x27;m creating something simple. This is because I&#x27;m familiar with using these and they provide me with the ability to implement nearly any kind of dynamic functionality or interactions I could want, fine control over component lifecycle, and tight integration with my CSS library of choice to speed up development.End-users are none the wiser, that is of course unless I do a terrible job using these tools. reply professorsnep 10 hours agorootparentFor personal projects I usually use Astro[1] solely because 90% of the stuff I am making doesn&#x27;t require anything more than basic HTML&#x2F;CSS and maybe a couple static components, but I also have the flexibility to add SSR rendering or even more dynamic components like Svelte without making an entirely new project.[1]: https:&#x2F;&#x2F;docs.astro.build&#x2F; reply docmars 9 hours agorootparentAstro is an excellent choice! I&#x27;ve never used it, but always wanted an excuse to. I think it blends the best of both worlds, and the fact that you mix various view libraries is powerful! reply xigoi 2 hours agorootparentprevLibraries like Vue allow you to easily add some interactivity to a site without converting it entirely. Why not do that? reply nightowl_games 6 hours agorootparentprevCant you just use vanilla JavaScript at that point? reply boredtofears 5 hours agorootparentprevI have a suspicion the reason most people reach for a framework is primarily about two different things: modern tooling (modules&#x2F;bundling, typescript, etc) and templating. They don&#x27;t really \"need\" a virtual dom diffing rendering pipeline, but the fact that you get all these other things out of the box with little setup is what makes it the go-to solution.Then of course you&#x27;re left to reimplement basic browser functionality that you now lost (or more likely, you just grab another package that solves that and throw it in your payload). reply hinkley 15 hours agoparentprevWe have forgotten the old lessons. Backend first was a defense mechanism against people who believe their eyes and not the experts.When you make a product that looks like it works but doesn’t, they don’t understand. They put you on a path to overpromise and underdeliver.One of the lesser known features of unit tests are that they give the code that management can’t see more QA prior to being wired up. They narrow that awkward window from first paint to shipping. reply wheelerof4te 15 hours agoparentprev\"I really don’t see how these would work in anything other than very basic scenarios, even less how they would achieve the objectives.\"Well, what are the objectives? If they are complex, so should the code be complex. That&#x27;s the nature of our job. By adding an advanced framework you up the complexity by default. Instead of adding more code, you add more build dependencies. This is especially wasteful on websites.In my opinion, people today are afraid of writing code. Everyone wants some framework to write code for them. That is not how we push our industry forward. reply jaapbadlands 15 hours agorootparentNo one is afraid of writing code, we&#x27;re afraid of maintaining code, and solving tedious and repetitive problems that already have solutions. Frameworks abstract complexity, which in practical terms decreases the complexity I personally have to deal with, and shifts the complexity to the minds of a team of open-source developers who support the framework or library in parallel. Abstraction is exactly how we push the industry forward, not by building less, more basic, and shittier applications in a some faux-noble quest to use inline event handlers. reply wheelerof4te 14 hours agorootparent\"No one is afraid of writing code, we&#x27;re afraid of maintaining code, and solving tedious and repetitive problems that already have solutions.\"Then, enjoy maintaining React apps once React inevitably bites the dust and ends up in the JS framework graveyard. reply pault 14 hours agorootparentThe chances of this happening before your project is obsolete are pretty slim.Edit: it depends on what you mean by \"bites the dust\". If you mean \"isn&#x27;t cool anymore\" then I&#x27;d say that&#x27;s kind of irrelevant. If you mean \"isn&#x27;t supported anymore\", I don&#x27;t see that happening any time within the next decade at least. Rails isn&#x27;t cool anymore but it&#x27;s still supported and lots of people are still (more or less) happily using it at their day jobs. React is so widely used it&#x27;ll be kept on life support long after it has been supplanted by something better, if and when that happens. reply codeptualize 13 hours agorootparentAnother good example is jQuery, the last release was 2 months ago, and there is plenty of activity on GH. reply Xeamek 11 hours agorootparentprev>React is so widely used it&#x27;ll be kept on life support long after it has been supplanted by something better, if and when that happens.React might be 10 years old, but it changed like 5 times during that time. Something built in first or second version of React is pretty much an entirely different framework at this point. (Would it even build with using the newset toolchains?). It&#x27;s almost disingenuous to ignore that fact.So while it&#x27;s unlikely that there won&#x27;t be a thing called \"React\" in the future, it&#x27;s not that crazy of an idea. reply docmars 8 hours agorootparentReact&#x27;s first flavor (class-based components) are fully backwards compatible with today&#x27;s React versions. It doesn&#x27;t seem odd to me that a popular library identifies its pain points and improves its APIs & patterns over time. That&#x27;s the beauty of open source software with large communities guiding their growth.Today, it&#x27;s moving heavily towards server-side rendering because the client-side &#x2F; SPA format is already quite mature. Their approach with server components is an optimization path that uses concepts&#x2F;patterns from already popular server-side languages and frameworks + templating, and blends them seamlessly with client-side development, giving engineers the best of many worlds.This was a natural evolution from NextJS which popularized this way of using React, and it&#x27;s giving engineers more choices in how they build + optimize their apps. reply skydhash 6 hours agorootparent> This was a natural evolution from NextJSIt’s just going back full cycle, with a few extra steps. And the only clear purpose is SEO. reply codeptualize 14 hours agorootparentprevWhen there are so many projects that run on React, and so many companies rely on React, it&#x27;s inevitable that it will be supported for a long time to come, even if it would go out of fashion.And speaking from experience maintaining React apps is quite nice. React has great backwards compatibility, and where it doesn&#x27;t there are usually codemods available. Dependencies can be tricky, but that&#x27;s not exclusive to React.Also don&#x27;t forget React evolves, backed by multiple #huge companies, and still innovating. reply fsckboy 13 hours agorootparentprevI love maintaining and cleaning up code (I will insist on cleaning up according to my taste even if it already works fine in production, just like when I carve the turkey I eat some crispy and fatty pieces hot from the oven) It takes a great weight off my short term memory and ADD that I know that the code already worked, so if it stops working, I did it, recently.But here&#x27;s the thing, hot-shot devs, and hot-shot dev wannabes look down on maintenance; and humans are social creatures, me included. So I&#x27;m not going to do a job for you that you look down on, unless you carry me in (and out) on a sedan chair.Same for writing doc, I&#x27;m good at it and enoy it, but there&#x27;s no pleasure in doing something that other people don&#x27;t really value. reply docmars 9 hours agorootparentprevBetter than maintaining vanilla JS applications that reinvented React for no d*mn reason. At least there&#x27;s a massive pool of engineers who could jump into an old project and work on it right away, rather than wading through some clever engineer&#x27;s buggy attempt at a view state management system.Popular backend templating systems face the same problem with possible sunsetting and decay of collective knowledge over time.React is a great investment, and is here to stay for a long time because its team (and community) are massive, and are keeping pace with newer libraries&#x2F;frameworks that are in a lot of ways doing things better. React&#x27;s market share has hardly been touched by Vue, Svelte, Solid, etc. and less so by HTMX and other new attempts at un-frameworking the web. reply codeptualize 15 hours agorootparentprevIn some sense I agree, I am very mindful of the dependencies I add and I am not afraid to write something custom if that better fits the situation.But this article is not showing me how to do that and the things listed are not going to have an impact on the complexity of my projects as these basic things are solved quite well.> By adding an advanced framework you up the complexity by defaultIf you know your project will remain simple then by all means. That&#x27;s often not how it works though and then you end up writing a framework yourself once the scope gets increased and features are added.Adding to that that using a framework gives you so many things for free. There are so many aspects to a good website and leaning on a group of people specialising in all those things is often a smart move with better outcomes.I think the initial complexity might be a little bit higher, but there often is a big return on investment later on, and also immediately in terms of productivity.I&#x27;m not going to stop you from not using a framework, I think it&#x27;s great to experience it, have been there many times before, got burned (badly), and now make different decisions. reply selimnairb 13 hours agoparentprevEven if this isn’t always practical for larger projects today, I would argue that this should “ultimately” be the goal—-at some point the “standard” browser runtime should be expressive enough to not require lots of tooling to make most apps. reply MrJohz 13 hours agorootparentI&#x27;m not sure that&#x27;s always the case — we don&#x27;t expect assembly to be a high-level language after all! The more specific and batteries-included the browser becomes, the harder it is to go off the beaten track. My standard example here is date pickers — theoretically it&#x27;s just a simple component, and yet there is no one-size-fits-all option. What works for booking an appointment won&#x27;t work as well for putting in a date of birth. What works for a date of birth won&#x27;t work if you&#x27;re trying to book a set of nights in a hotel. You might want to include prices for individual days directly in the date picker. You might want to show which days are valid and which aren&#x27;t. You might want to show several months, you might want to show just a week.I don&#x27;t necessarily disagree that more components in browsers is a bad thing (I&#x27;ve been very happy to use the new modal element, for example), but I think the browser is working better right now as a lower-level (albeit still fairly high-level) platform that allows people to build a variety of documents and applications on top. reply meowtimemania 12 hours agoparentprevMost anything built with php or traditional SSR pages follows these concepts to some extent. reply rando832 4 hours agoparentprevhttps:&#x2F;&#x2F;www.gnu.org reply wheresmycraisin 11 hours agoparentprev> This is fun in to theory and in simple examples, but show me a big project that applies this and how it made a difference.Not everything has be a Large Enterprise Application. reply jasonwatkinspdx 13 hours agoparentprev37 Signals has adopted some of these ideas. Would their apps qualify as \"big\" for you? reply ativzzz 13 hours agorootparentTo be fair, 37 Signals (Basecamp) which is behind ruby on rails, changes their front end philosophy with every new major version of railsAnd to be fairer, it&#x27;s generally a pretty good philosophy for greenfield apps at that particular point in time, but if I started an app on rails 4 or 5 there&#x27;s no way I&#x27;m updating my front end every time they change their minds about how front end should workThey believe this now, in 4-5 years it&#x27;ll be XYZ next thing reply mekoka 12 hours agorootparentPeople buy into ideas and once they&#x27;ve paid the price, they dislike when that investment is challenged with new information. The resistance that I see in these thread to the idea that going back to HTML might be enough, to me looks very much like that.Basecamp (formerly 37signals) has a track record of challenging the status quo, whether in business or engineering practices and to actually be fair, they&#x27;re not changing their front-end philosophy on a whim or to simply follow a fad. They&#x27;re trying to solve real problems. In the past, their flagship product served as proof that exposed many established counter-advices as merely baseless beliefs. Over the years, they&#x27;ve demonstrated how many \"bad ideas\" could actually work better for you, once you allow yourself to become a bit more pragmatic.They might not be BIG, but they&#x27;re also not small. Imo, what they say and do engineering-wise tends to matter much more to average developers than what Facebook or Google might recommend.I think the question stands, is Basecamp a good enough example? reply firecall 7 hours agorootparentprevI wouldn’t say they’ve exactly changed their philosophy.To me it seems more like they’ve evolved it.From Rails UJS using jQuery, to vanilla Js, then TurboLinks and onto today’s tools like Turbo and Stimulus.The evolution isn’t a bad thing, and the older approaches still work in modern rails.They’ve changed and updates the build tools, but then you have to keep up.They went from Sprockets, to Webpacker, and then module loading to replace Webpacker.So they’ve haven’t changed philosophy as such, it’s just considered and measure evolution and refinement.Feels that way in practice to me anyway! :-) reply jasonwatkinspdx 11 hours agorootparentprevI think this is a rational strategy. They aren&#x27;t changing concepts just randomly for that alone. As we learn problems with the last approach we try something new to address it. If you&#x27;re starting a new app green field this is an ideal time to try to shed some baggage. reply aniforprez 8 hours agorootparentprevIt&#x27;s been a while since I used it but I did a limited trial of Hey and it was genuinely miserable to use. Not only did everything take a few ms extra, the entire interface was so incredibly janky and had no accessibility concerns at all. They were shipping their website to their mobile apps and it was horrid. I would not put Hey as a shining example anywhere for this philosophyIt&#x27;s been a long time since I used Basecamp but that was decent enough reply gijoeyguerra 14 hours agoparentprevThe entire WWW is the example reply ln_00 13 hours agoparentprevAem edge delivery service, Hey.com reply graypegg 16 hours agoparentprevI love the ideas here, but honestly the examples are a bit weak here.> Where possible, default to defining style and behaviour with inline HTML attributesbut their example wouldn&#x27;t work. should probably be which I think makes it a little more clear how weird this could get if you wanted to add more styles. You just keep growing the params passed to the ClassList add method, in a string. I would personally findbutton:active { background: green; }to be much more readable, but the author seems to imply this is complicated due to their approach of \"Locality of Behaviour\".--> Where libraries are necessary, use libraries that leverage html attributes over libraries built around javascript or custom syntaxI totally agree! But why is your example of a library not built around javascript or a custom syntax feature:That \"on input put me into #output\" I think is more jarring that the library shown as the bad example. Even better, this could just be some JS, without a framework at all.--> Prefer \"naked\" HTML to obfuscation layers that compile down to HTMLTheir example is to not use Rails ERB tag helpers, in your templates. I don&#x27;t think this is that big of an issue, these helpers can actually handle a lot of things that will look messy if you use the minimal amount of templating to write them. The example leaves off unique dom ids, turbo tags (very HTML&#x2F;no JS focused!) and iteration. reply tomrod 15 hours agoparent>> Where possible, default to defining style and behaviour with inline HTML attributesThis was my critiquing point as well. Style configurations should be separate from actions, with only references linking the two. It&#x27;s the only way that makes sense for anything meaningful.Yes, I could technically write a python app where all SQL database connections have hardcoded SQL as one one long file, but that is poor practice. This suggested principle seems the same to me. reply rndmize 13 hours agoparentprevI get the idea - using the build-in capabilities of html is nice, clean, and simple. But that wasn&#x27;t viable ten years ago, and it isn&#x27;t today - and I don&#x27;t particularly feel that htmx etc. is a better solution than something heavier like react.My go-to questions with anything like this are: how do things look if I want a dropdown? Multiselect? Datepicker? If we usedo we get a datepicker across browsers? (Looks like yes.) Is the look&#x2F;feel&#x2F;controls consistent across browsers? (No.) Can we style them to get there? (Also no.)Multiselects are similar - shift&#x2F;control-clicking to get multiple things is a flat no-go from a UX perspective - but at my last check, this is still how the default elements work, and it can&#x27;t be changed. Similarly, the look&#x2F;feel of multiselects (and even selects!) is terrible and largely cannot be changed.There&#x27;s a reason third-party components for this kind of thing get built for any new framework. The built-in stuff just doesn&#x27;t get it done. It&#x27;s the same reason 90% of my projects still have lodash as a dependency, even though the list of built-in stuff on MDN&#x27;s Array page grows year by year. It&#x27;s better than it was 10 years ago for sure - but its still not there. reply c-fe 13 hours agoparentQuick thought regarding date pickers, specifically:> Is the look&#x2F;feel&#x2F;controls consistent across browsers? (No.) Can we style them to get there? (Also no.)Assuming you design this website for users. Each users may use a different browser, but they probably use this same browser for all websites they visit. Hence IMO its more important that date pickers are consistent across all websites on 1 browser, then across 1 website on all browsers. (Its of course a different story if you need custom functionality.) reply MrJohz 12 hours agorootparentI find I&#x27;m in the opposite position - I would rather the date picker is not consistent, because different date pickers have different purposes. The date picker I want to use to put in my date of birth is different to the one I want to use to add an appointment to my calendar, and that&#x27;s different to the one I want to use to browse prices for different days, and that&#x27;s different to the one I want to use to be able to select a range of dates, and even that&#x27;s often different to the one I want to use to select the two dates of a return journey.Of the classic form controls, choosing a date is probably the one that has the most application-specific needs, and therefore the one that I would most expect to vary between applications. reply xg15 11 hours agorootparentWhat would be the specific difference between all of those?For many use cases you described, the primary UX flow should probably not have a date picker at all, but rather the date would be selected implicitly through other user actions: i.e. to add an appointment, you might start with a full-page calendar view and click on the appropriate day; for prices you&#x27;ll probably have \"next day\"&#x2F;\"previous day\" buttons built into the page.But those UX flows are orthogonal to the flows that actually do use a date picker, IMO. reply MrJohz 4 hours agorootparent* For DOB, what you typically need looks more like three text boxes. That said, the text boxes need to be able to work together in terms of validation - the 31st of February 2015 is not a valid date! This is why it&#x27;s better to think of this as a single form control with multiple input fields. Alternatively, I want something where I can pick the year first, but this typically leads to lots of scrolling.* For adding an appointment, I probably want something closest to the conventional date picker, but even then, if I&#x27;m making an appointment for a group, I might still want additional information about when people are available displayed directly in the calendar view as I&#x27;m choosing a date.* If I want to browse for the cheapest date, then I want a way of seeing all the dates available and the prices of those dates at the same time, meaning a relatively rich date picker control. If all I have is \"next day\"&#x2F;\"previous day\", then I need to manually click around a lot to get good deals.* If I want to select a range of dates, then I want a single control that allows me to select that range immediately, not having to open a \"start\" field and an \"end\" field separately. I also probably want multiple months visible, depending on how long my range is, so I can see the whole range at a glance without having to click back and forth between months.* This is more subtle, but a hotel visit requires a range of dates, but a flight to and from the hotel requires two discrete dates, which might potentially be indicated with yet another date picker variant.These are all flows that require me to pick a date, most of them from a calendar, and all of them could arguably be considered important enough for a native element (in the sense that I use all of these elements in my day-to-day web browsing). But they&#x27;re all very different, require different interactions and content, and have subtly different purposes. reply docmars 9 hours agorootparentprevAt that point, you&#x27;re creating and writing a different flavor of date picker -- and in static HTML land, there is no clean way to update page content dynamically based on user input, without some kind of JavaScript library interacting with those elements (talking to the UI) and coordinating input data, displaying new derived data&#x2F;info based on those selections with snappy, accurate feedback.There are hundreds of ways to support this using JavaScript because the community has cleverly come up with many different flavors of view handling to suit different mental models and preferences. What could be better? reply zeroCalories 12 hours agorootparentprevThe optimal date picker depends heavily on the platform too. Don&#x27;t want your crusty custom date picker over my platform specific date picker that I know well. reply ssss11 12 hours agorootparentprevYes but companies don’t think that way. Companies have a style that they want to apply to their product regardless of which browser renders it. reply xigoi 2 hours agorootparentAnd that&#x27;s precisely the problem. reply _a_a_a_ 12 hours agorootparentprevWell fuck them. reply guhcampos 12 hours agorootparentThanks. reply sensanaty 9 hours agorootparentprevThe default datepickers in browsers are not feature-rich at all though. They&#x27;re fine for extremely basic \"pick a date\" type of usecases, but as soon as you want to do anything slightly complex like picking a range, a date & specific time in one or having it be interactive in some other way like Google Flights showing you a range of prices alongside the date etc., you have to create your own datepicker component (or use an already built one). reply divbzero 12 hours agorootparentprevThis applies beyond date pickers too. To me, usability trumps consistency when your users access the website across a variety of platforms: mobile vs. desktop, touch vs. mouse, etc. reply Izkata 7 hours agorootparent> etc.Screen readers and voice input: https:&#x2F;&#x2F;a11ysupport.io&#x2F;tech&#x2F;html&#x2F;input(type-date)_element reply xg15 11 hours agorootparentprevUsability depends on the knowledge of your users how to correctly use the widget though - and that knowledge is greatly helped by consistency. reply mmcnl 12 hours agorootparentprevThe default date picker is laughable. For example there is no way to control the format in which the date is displayed. reply ckolkey 12 hours agorootparentUnless I&#x27;m mistaken, it&#x27;s shown in a format localised to the user, so... i&#x27;d much rather you keep your hands off that, and I&#x27;ll enjoy my DD.MM.YYYY reply arcanemachiner 10 hours agorootparentISO-style timestamps are the only only one that makes any sense.YYYY-MM-DD or GTFO. reply hoosieree 8 hours agorootparentno need to fight over it, compromise is both elegant and simple: YMYY-YD-DM reply Izkata 7 hours agorootparentNon-jokingly, Kazakhstan has YYYY-DD-MMhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Date_format_by_country replybrabel 3 hours agoparentprev> Is the look&#x2F;feel&#x2F;controls consistent across browsers? (No.)And to think that having a native look-and-feel used to be considered a must for any desktop application!I would be much happier if all websites&#x27;s UI components (not the actual website design of course) had the look-and-feel native to my browser (and if browsers actually cared to make them look good, TBH) rather than inventing their own dumb styles for everything. reply RoddaWallPro 12 hours agoparentprev\"shift&#x2F;control-clicking to get multiple things is a flat no-go from a UX perspective\" - Do you mean that this is NOT how you should do multiselects? If that is what you mean, then how _do_ you do them? If I have a list of items and I want to select 10 or 15 of them in a row, I currently don&#x27;t know of a better UI to do that with than shift+click. reply fiddlerwoaroof 11 hours agorootparentYeah, shift&#x2F;control-click is a longstanding workflow for multiselect and macOS, Linux and windows all support it with various platform-specific subtleties. The worst part of the web is losing all these sorts of features because some web designer thinks they’re a “bad UX” reply DangitBobby 10 hours agorootparentPresent a form with a 25 item native multiselect to 10 of your non-prgrammer family members. Ask them to perform two tasks:- Select 5 non-adjacent items- Select 5 adjacent items.Report back with success rates. reply fiddlerwoaroof 9 hours agorootparentThe nice thing about native behaviors is you only have to teach them once. Custom behaviors per application make it harder for people to develop a model of how their computer works because you have to learn a new interaction model per application. I’m pretty anti the notion that UX is intuitive in any sense: all human-computer interaction is learned at some point and we should focus more on educating people how to do tasks like this than pursuing some lowest-common denominator concept of “intuitiveness” or “discoverability”.Anyways, my favorite multiselect paradigm is the old windows one with two list boxes side by side and buttons in between. reply LeonB 4 hours agorootparentThat two-window approach was particular useful where you needed to be able to rearrange the order of the items.Now we tend to have a part of the record appearing to have texture (stripes or bumps) as a clue that grabbing it will afford pushing it up or down.There’s many little common standards like that which have never appeared in “out of the box” controls provided by the platforms. reply docmars 9 hours agorootparentprevWhy not do both? Gmail&#x27;s a great example of this. Hold shift while clicking two checkboxes in a range of emails, and watch as the entire range is selected for you to manage. :) reply n2d4 11 hours agorootparentprevMost normal users (aka if you read Hacker News, you&#x27;re not one of those) don&#x27;t and won&#x27;t know about shift and control clicking. A more UX-friendly alternative is to have checkboxes; you can still have shift&#x2F;control-clicking on top of that (for selecting many things quickly), but it shouldn&#x27;t be the only option. reply livrem 2 hours agorootparentHTML has had checkboxes since at least version 2 (1995), so just use those if you want to do multi-select using checkboxes. I don&#x27;t think you can do shift-clicking to select ranges though (without resorting to js) but control-click is of course redundant as that is just the default behavior for a list of checkboxes. reply rndmize 9 hours agorootparentprevThis is pretty much correct, though I feel there&#x27;s some finer points depending on the number of options (5? 10? 50?) and the expected number of values chosen (2? 4? 10?).Checkboxes are a good choice for a small number of options: https:&#x2F;&#x2F;m3.material.io&#x2F;components&#x2F;chips&#x2F;overview . I&#x27;d say past a dozen options though this starts to become unwieldy.Tag-style multiselects are fairly common (see https:&#x2F;&#x2F;react-select.com&#x2F;home for an example). These are good where the number of values a user is expected to have selected is small (less than five imo) but the number of options is large enough to make checkboxes impractical. If you&#x27;re expecting a higher number of things to be selected, you could have the option list stay open after an option is clicked, so they user doesn&#x27;t have to reopen it each time they want to add an option (and, in fact, the \"Animation\" example does precisely that).Two column designs ( https:&#x2F;&#x2F;crlcu.github.io&#x2F;multiselect&#x2F;examples&#x2F;search.html ) have mostly fallen out of favor, though I feel they still have their uses for larger lists with large numbers of selected values. reply contradictioned 11 hours agorootparentprevDrag and drop? At least that’s only using a pointer device without modifier key… reply andirk 12 hours agoparentprev from the rest of the discussion, `input` element is infamously shitty for having vastly different ways of interacting with it, whereas most other HTML elements have one signature. reply Jtsummers 17 hours agoparentprevThis one confuses me:> Where libraries are necessary, use libraries that leverage html attributes over libraries built around javascript or custom syntaxAnd then they demo using _hyperscript [0] as encouraged. However, that&#x27;s a library built around a custom syntax. It&#x27;s only using an HTML attribute to encode a script that&#x27;s in a new language you need to learn. Is this serious?[0] https:&#x2F;&#x2F;hyperscript.org reply athrowaway3z 14 hours agoparentI suspect this is a &#x27;List of tips&#x27; written explicitly to promote hyperscript.Its example is also pretty weak. Vanilla solutions (Tip 1) works just as well:reply assimpleaspossi 14 hours agorootparentnote that thetag does not use and does not need a closing slash and never has in any HTML specification.https:&#x2F;&#x2F;html.spec.whatwg.org&#x2F;dev&#x2F;embedded-content.html#the-i... reply josephg 13 hours agorootparentYep. It’s one of a handful of void elements along withand .Also using a slash to self close a tag is not part of the html spec and it never has been part of the spec. The browser doesn’t know what that means on any tag. If you writethe browser ignores the slash and thinks you still haven’t closed your Div. reply zlg_codes 12 hours agorootparentI&#x27;m adding context to this because you&#x27;re only telling part of the story:self-closing tags are necessary for void elements in XML and XHTML, both technologies that are still supported on the Web. Since XHTML processes HTML as XML, it forces it to be well-formed. Unlike HTML, which has all sorts of tag-soup and quirks modes and other things, because it&#x27;s lax in its syntax.Void elements lacking the need for a closing tag or closing slash is one of the weird edge cases in HTML. While it&#x27;s not in the HTML spec, it may still be seen in the wild in XML and XHTML documents and is not universally bad or unsupported. reply josephg 11 hours agorootparentYou can view HTML as a weird, quirky version of XHTML if you want. But XHTML lost the war. Browsers are HTML5 engines, not XHTML engines.And if you&#x27;re writing HTML, the browser considersto just be a weird way to write . The slash is non-significant. So confusinglyis not equivalent to .The problem I have with self-closing tags is that I&#x27;ve met so many web developers throughout my career who think that browsers understand self closing tags. I used to be one of them! And that will almost always, but not always work out fine:- React &#x2F; JSX supports self closing tags. So do a lot of other web frameworks.- Void elements ignore the &#x2F;. (And you don&#x27;t need to close void tags anyway). So you can write input, img, br, etc tags however you want.- HTML5 will auto-insert missing closing tags when it needs them. Eg,will render as you expect because the browser will automatically close the span when you close the div. (!)But it&#x27;ll confuse you in weird ways. Like- which the browser dangerously interprets as an open script tag. Subsequent text is interpreted as javascript!I think its good practice to be clear in all source files whether you&#x27;re writing XHTML (eg in .jsx) or writing real, god fearing HTML. And then never use self closing tags in HTML. Sooner or later, someone will think they matter and you&#x27;ll get bugs. reply zlg_codes 11 hours agorootparentI can&#x27;t disagree with making sure you&#x27;re using them when they matter and avoiding them when they don&#x27;t.There was no real &#x27;war&#x27;, XHTML 5 is still a thing. Browsers are HTML engines because people who write HTML don&#x27;t want to be forced into well-formed markup. They want the browser to guess what they meant and run with it.There&#x27;s also the whole \"we need to be compatible with almost every HTML file dating back to the early 90s\" conundrum that makes clean breaks in behavior, like XHTML, hard to pull off without pissing people off.It should be clear which one is writing based on the DOCTYPE element. IIRC XHTML still requires a DTD to ensure its schema can be validated, while HTML 5 did away with it altogether and now just usesreply josephg 10 hours agorootparent> There was no real &#x27;war&#x27;There was definitely a debate over how web browsers should interpret web pages - as XHTML or \"quirks mode\". HTML5 (with infinite backwards compatibility) was the outcome. Every major web browser implements HTML5 - complete with its super quirky and complex, but fully specified and consistent parsing rules.> XHTML 5 is still a thing.Is it though? On the web? I just tried, with this html: yoQ: What do you expect the background-color of \"yo\" to be?If this was an XHTML page, tags should be able to self-close. And in that case it should be black on white. But try it. Its not. The browser ignores the self-closing part of the tag, so \"yo\" is inside the inner div and it shows up in hot-pink. The outer div is then not closed correctly. (2 divs open, 1 div closes). If the page were processed as strict XHTML we&#x27;d also expect a warning or error, but the browser doesn&#x27;t care. Neither firefox nor chrome emitted anything in the console about any of this.As far as I can tell, the XHTML doctype has no effect here. The page is interpreted - as all webpages are - by the browser using HTML5&#x27;s parsing rules. Not XHTML&#x27;s.There are contexts in which XHTML still exists. Like JSX. But the browser is not an XHTML renderer. Rail against HTML5 if you want, but people need to stop pretending that the browser supports self closing tags. They are not part of HTML5. Pretending they are causes bugs. reply marwis 7 hours agorootparentYou need to serve it with the right mime time (application&#x2F;xhtml+xml) or in case of local files use .xhtml extension. Then it&#x27;s processed as XHTML and rendered as expected.Also you need namespace declaration otherwise it will be rendered as unstyled xml.This is all part of HTML5 spec: https:&#x2F;&#x2F;html.spec.whatwg.org&#x2F;#the-xhtml-syntax reply zlg_codes 4 hours agorootparentprevI&#x27;m going to let this link to a simple XHTML document speak for itself. I&#x27;ve configured it to work on lighttpd via the `mime-types.conf` file, and even have a commented-out meta tag you can use to fake it in cases where you can&#x27;t manipulate a server.https:&#x2F;&#x2F;zlg.space&#x2F;misc&#x2F;example.xhtmlLet me know how your browser sees it. replyjustsomehnguy 39 minutes agorootparentprevOfftopic but not: https:&#x2F;&#x2F;daringfireball.net&#x2F;projects&#x2F;markdown&#x2F;syntax#p reply bensecure 9 hours agorootparentprev> Eg,will render as you expect because the browser will automatically close the span when you close the div. (!)span is a bad example. indeed it will close - but then it will reopen (!) when the next text node occurs.is a better example, and it will also auto close when you try opening a new , which can be rather convenient when trying to write concise html. reply rhdunn 10 hours agorootparentprevXHTML may not be mainstream with people authoring web pages, but it is a thing within publishing pipelines that generate XHTML from other XML-based sources like JATS or DocBook. It&#x27;s also a thing at least in ePub 1 and 2 content (I can&#x27;t recall if they relaxed it to HTML for ePub 3 or later). reply Izkata 7 hours agorootparentprev> Void elements lacking the need for a closing tag or closing slash is one of the weird edge cases in HTML. While it&#x27;s not in the HTML specIt&#x27;s explicitly in the HTML5 spec as allowed, but not required. reply Jtsummers 13 hours agorootparentprevWhich makes the example even more egregious. There are certainly better ones that:1. Can&#x27;t be easily done with vanilla JS and so can justify using a library.2. Don&#x27;t need a library with a DSL in direct opposition to the claimed principle (avoid DSLs). reply mattlondon 17 hours agoparentprevI would agree - the example of an an attribute of `_` and then some obscure DSL statement as a value looks super weird and confusing.I would rather there was just an explicit `onclick` (or some other event) in there with a vanilla JavaScript statement so I know what is happening. reply gbro3n 17 hours agoparentprevAlpine.js would have been a better recommendation according to the authors advice as it is straight forward JS plus HTML attributes. reply dartos 17 hours agoparentprevI think hyperscript has some people trying to hype it up bc it’s related to HTMX, but imo is more of a fun novelty. reply brennopost 15 hours agoparentprevMaybe the author swapped the encouraged and discouraged. reply recursivedoubts 14 hours agoparentprevyeah, kinda.source: I&#x27;m the creator of hyperscript. reply Jtsummers 13 hours agorootparentI&#x27;m not saying hyperscript isn&#x27;t serious (I have no opinion on it at all actually). I&#x27;m saying the claim \"avoid DSLs\" followed by an example using a DSL is a sign of unseriousness on the part of the author of HTML First.Six principles and one of them is presented with an example that blatantly violates that same principle. I could see a mistake like this slipping through if there were many more principles and examples, but this is a relatively short piece for such an error to slip in. reply arcanemachiner 10 hours agorootparentprevPerfect. This place is overdue for an exhaustive debate about HATEOAS&#x2F;REST&#x2F;etc, and you have an incomparable talent for starting such a debate. reply recursivedoubts 10 hours agorootparentnot to brag, but that is kinda my superpower... reply rbosinger 10 hours agoparentprevYeah I stopped reading as soon as I saw this one. reply varun_ch 17 hours agoparentprevWhile I agree with most of the arguments here, this article feels a little contradictory - it recommends Tailwind but also tells us to &#x27;stay clear of build steps&#x27;. Shipping massive CSS&#x2F;JS resources goes against the whole inclusivity principle - many people don&#x27;t have super fast internet connections or powerful enough computers.. reply moritzwarhier 17 hours agoparentI don&#x27;t use Tailwind anymore at the moment, but in my experience, it does not lead to shipping massive CSS&#x2F;JS resources. In fact I don&#x27;t know about any client-side JS at all that is emitted by Tailwind (my last experience was 2.x, not sure if anything has changed).Regarding the CSS size, my experience was the opposite, Tailwind output was usually a lot smaller than hand-written CSS.I have nothing against plain CSS either though; but it&#x27;s at least as easy to make a mess. reply graypegg 17 hours agorootparentI think GP is talking about how, without the tailwind build step, you ship all of tailwind, which is unquestionably a lot of CSS that you aren&#x27;t using.Maybe if you use a CDN, so hopefully the user might have a local cache of it from somewhere else, that can be avoided?Still though, tailwind is pitched WITH it&#x27;s build step normally, making the author&#x27;s point about avoiding a build step a bit odd. reply JimDabell 17 hours agorootparent> Maybe if you use a CDN, so hopefully the user might have a local cache of it from somewhere else, that can be avoided?Browsers partition caches by origin now for privacy reasons, so this is no longer possible. If the user doesn’t have it cached from your website, they don’t have it cached. reply moritzwarhier 17 hours agorootparentprevThis was only the case in Tailwind 1 and heavily discouraged by the documentation, except for development.Tailwind requires a build step and shipping the 1.x development build was explicitly not meant for production.Trying to use tw 1 like this without a build step, you can&#x27;t even define a custom color scheme.If this is what you want, I&#x27;d use a library that actually supports this. Maybe tachyons? But tbh, without the build step I&#x27;d consider using Tailwind at all a massive mistake. Then I&#x27;d prefer handwritten CSS.Custom properties should make sth like this a lot more viable though. I&#x27;m sure there are libraries that better fit this use case, if you want to use a CSS library. reply robinson7d 17 hours agorootparentprevDid your experience involve the (recommended) build step? It uses, at least last I checked, a purgeCSS step to remove unused rules and decrease the css size. reply tipiirai 10 hours agorootparentprev> Tailwind output was usually a lot smaller than hand-written CSS:Tailwind output is massively bigger than the one with semantic CSS. Here&#x27;s a comparison:https:&#x2F;&#x2F;nuejs.org&#x2F;blog&#x2F;tailwind-vs-semantic-css&#x2F; reply troupo 17 hours agorootparentprevI think what the OP meant is: Tailwind requires a build step to extract use classes. Otherwise you need to ship all of it. reply kyleyeats 17 hours agoparentprevI made an atomic CSS library that doesn&#x27;t need a build step, if anyone wants one (spoiler, nobody does): https:&#x2F;&#x2F;casscss.github.io&#x2F;cass&#x2F; reply amenghra 17 hours agorootparentImho, bullet points on the border box seems weird to me (https:&#x2F;&#x2F;ibb.co&#x2F;d0sDsQ2). reply kyleyeats 15 hours agorootparentThanks for the note! The left padding and margin situation on the ul is the bane of my existence. reply amenghra 14 hours agorootparentCopy what other more popular frameworks are doing :PI haven&#x27;t looked at your css, but maybe changing the box model could help? reply geenat 1 hour agoparentprevGood options for zero build:* Self host tailwind v3 CDN.* https:&#x2F;&#x2F;github.com&#x2F;gnat&#x2F;css-scope-inlineBoth are surprisingly fast- parse 10,000+or class=\"...\" in under a second. reply nathanfig 13 hours agoparentprevDeno Fresh uses Twind, which avoids the build step: https:&#x2F;&#x2F;twind.dev&#x2F;But IIRC it doesn&#x27;t offer quite everything full Tailwind does. In general I was frustrated with Fresh for not being up-front about the fact that it is largely built on Preact and Twind, and you must buy into those libraries first. reply epiccoleman 17 hours agoparentprevTailwind has a standalone CLI which can be used for the build step. I do sort of agree that it&#x27;s a bit of an odd recommendation in the context of this article, but the build step can be extremely minimalistic, and another nice thing is that the results are still inspectable CSS.I use tailwind on my personal site, which is otherwise entirely just vanilla HTML, and it doesn&#x27;t feel very intrusive to run the CLI in watch mode when I&#x27;m writing styles. reply rs_rs_rs_rs_rs 17 hours agoparentprevYou don&#x27;t ship Tailwind... reply isodev 17 hours agoparentprevThe OP was making a point that the build step should not be required to run&#x2F;display a web app.For example, tailwind without a build step is just the entire library. This means one can go a long way and even have a functioning web application without introducing a build step.I would say stripping unused CSS is in the same context as optimizing images, fonts etc perhaps generally a \"cleanup & prepare assets for production\" step. reply MrJohz 14 hours agorootparentTailwind doesn&#x27;t exist without a build step (at least since v2) — the whole point of Tailwind is that it is a build tool, an alternative syntax for writing CSS.There&#x27;s a kind of development version where that build step runs in the browser on page load, but it&#x27;s still a build step in the sense of generating all that CSS dynamically, and it will produce a poor experience for a user if you try and use it in production. reply tabacitu 15 hours agorootparentprevI read it the same way, yes. Good point with the cleanup: - it’s one thing to need to run build for it to work; - it’s another thing to run build to make it smaller; reply usrbinbash 17 hours agoparentprevThe only thing a build step changes about CSS&#x2F;JS resources of this kind, is a minimization of the libs...which is entirely achievable without building, by simply including the already-minimized version.I think what the article is about when it says to steer clear of builds, is complex builds, where transpilations and similar changes in format have to happen, in order for the page to work. reply lolinder 17 hours agorootparent> The only thing a build step changes about CSS&#x2F;JS resources of this kind, is a minimization of the libs...which is entirely achievable without building, by simply including the already-minimized version.This isn&#x27;t true, though—Tailwind&#x27;s build step isn&#x27;t just stripping out white space, it removes unused selectirs, too, which can&#x27;t be done in advance. reply usrbinbash 16 hours agorootparentI wasn&#x27;t aware of that, thanks :-) reply qwertox 11 hours agoparentprevI gave up this year, it&#x27;s no longer possible to keep fighting these react, vue, angular monsters with their bundlers and transpilers and all the junk that comes with them, like node with npm which always throws at you the message that your brand new, seconds old project has 7 severe and 8 critical vulnerabilities in it, because it must download thousands of files, possibly including a wrapper for boolean values.The times where I could use the Python backend servers to also serve the frontend seem to be over for me. reply 6031769 11 hours agoparentRage! Rage against the machine!You (and indeed everyone else) has no real need for heavy JS front end bloatware. Just say no. Serve light pages from the backend (or cache) and do all the fancy work in CSS (if you must).Say hello to fast render times and global accessibility. reply qwertox 10 hours agorootparentYeah but have you noticed how hard it has gotten to include simple libraries like day.js or three.js? It&#x27;s still doable, but it&#x27;s not easy anymore. Then there&#x27;s some real value to be found in frameworks like Quasar which gets really painful to use via a cdn, which I&#x27;ve been doing for years now. Vue3 complicated things further so why not just move to react once and for all?Vanilla JavaScript just didn&#x27;t manage to solve what it kind of promised to solve via web components, the lack of templating is really a bad shortcoming.I really do need things like Quasar and the stuff that Vue (and react) offer because it really helps a lot in usability. I&#x27;ve just been doing Vue with Quasar \"by hand\" via local CDN without compiling and it was such a win, but the more these frameworks evolve the less it&#x27;s possible to ignore the fact that these are \"modern frameworks\" and the pain just grows too much. reply Yodel0914 11 hours agorootparentprevFor smallish or personal sites I&#x27;m 100% on board. For a large enterprise-y app, which in a previous era would have been a rich client deployable, the benefits of these hulking UI frameworks outweighs the costs. reply sethammons 10 hours agorootparentI&#x27;m unconvinced. In a ticket I just took over, we need to update the options in a drop down in a modal. Django and react. The PR I took over has already touched nearly a dozen files, and tests have not yet even been written to count towards that.This should be like three files max (one, ideally) on the BE and similar on the FE. Things I used to 15 years ago in a few minutes takes _hours_ even when you know what you are doing. reply 6031769 10 hours agorootparentprevTo the devs perhaps. To the users? Not so much.So many sites these days are so bloated and slow as to be unusable. Those of us devs who chose the other approach have to work harder no doubt but our users are much happier. Isn&#x27;t that the goal, after all? reply Yodel0914 9 hours agorootparentSurely that depends on your users.My current users value speed of feature release over almost anything else, because the system needs to adapt to their rapidly changing business rules.In my previous job, correctness was the most highly valued attribute, followed by adherence to consistent design across the org (which was large, and produced many sites that a user would navigate between all-but unknowingly).In either case, if I&#x27;d gone on a HTML purity rampage, I would not have been helping my users in any meaningful way. reply sergiotapia 8 hours agoparentprevHit the eject button! A lot of the great things about the web are there in Phoenix Liveview. Sexy reactive websites without the need of lunatic React&#x2F;Node shenanigans.Thought TBH the article&#x27;s examples are whack to me. Why would I write puretags instead of using the Phoenix form helpers that print out errors and other nice shit for me automatically. I get the spirit though. reply kissgyorgy 10 hours agoparentprevIt&#x27;s possible! Just try htmx! reply andai 16 hours agoparentprevThe main thesis seems to be that the user should be able to press View Source and understand what&#x27;s going on. I agree, at least for web sites. For web apps, at least anything over 50 lines, you are probably going to want to use a typed language. (Well, you could technically use .js with TypeScript compiler and type annotations in special comments but I did not find that very pleasant.)I used to be really big on this, though (and it makes me sad that these days most sites are 1 big unreadable line of HTML). In fact, I find a beauty and elegance in shipping the whole thing as a single HTML file with no dependencies (1 network request!), though I did eventually make a \"build system\" (my build system is cat) so I could have a sane editing experience. Boom, self-contained portable software in 1 human-readable file!Along the same lines, I think the coolest thing about web development is that you can make your first (interactive!) programs with Notepad and whatever browser ships with your machine. (Just drag the HTML file onto the browser!) It&#x27;s magic!Edit: Just found an unexpected benefit of self-contained HTML: makes your software immune to bit rot. I tried loading an old project of mine on Web Archive but it hadn&#x27;t archived the external JS file! Sad! Meanwhile, this one loads fine because all the JS is in the HTML! Winning!https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20210508133239id_&#x2F;https:&#x2F;&#x2F;andai....This is my homage to the old SodaPlay Constructor. (Never made an editor, sorry!) Feel free to view-source! reply xg15 14 hours agoparentI&#x27;m sceptical on this: by now there are lots of ways to \"peek behind the curtain\" in the developer panel: we have the DOM view, network tab, heap view, built-in javascript prettifyer. Sure, \"view source\" is still important, but I&#x27;d question if its importance is still as absolute as the HTMX people make it out to be. reply andai 10 hours agorootparentI wanted to show people how easy it is to do cool things with a computer, how low the barrier to entry is.* One HTML file. Your OS&#x27;s built in text editor and browser. You look at the code and you can see it there in front of you! It isn&#x27;t obfuscated. It isn&#x27;t even minified. Everything is right there, all together. You can just save the file and drag it onto your browser. No Git, no zipped project folders. No build system! No server! (No MIME type errors!).The \"frictionlessness\" of lowering the \"activation energy\", is not just nice for beginners... heck, it&#x27;s nice for me! I can just download this file from Wayback Machine and continue hacking on it!It does, of course, limit you to very small codebases, but that&#x27;s what I like! Many small projects. The spring physics creature linked above is about 300 LOC total. The ASCII bonsai tree is ~100: https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220823113003id_&#x2F;https:&#x2F;&#x2F;andai....*In terms of tooling&#x2F;setup, at least! Learning to code is another matter... (Neither of these projects are very readable for a beginner though, so that aspect needs some work.) reply chriswarbo 9 hours agoparentprev> In fact, I find a beauty and elegance in shipping the whole thing as a single HTML file with no dependencies (1 network request!)This is even easier now we have &#x27;data:&#x27; URLs. It&#x27;s also useful for avoiding problems on file:&#x2F;&#x2F; URLs, which don&#x27;t even need a HTTP server. reply mlhpdx 16 hours agoparentprevI don’t believe the author is advocating for single file systems, but I don’t want to speak for them. reply andai 10 hours agorootparentSorry, I didn&#x27;t mean to imply this! My original comment had \"I even go so far as to...\" but it got lost somewhere in editing. reply ricardobeat 18 hours agoparentprev“Locality of behaviour” is such a poorly defined rule. It’s just an invented name for going against separation of concerns. Calling CSS “spooky action at a distance” is a massive stretch too. Good principles here but the arguments are quite weak and could be much simpler. reply NortySpock 17 hours agoparent(coming from a C# shop with too many interfaces) I think it&#x27;s a natural counter-reaction to overly abstracted systems.If \"making the red-bouncy-plonk button instead become the blue-wobble-thunk button\" requires chasing through a maze of 3-to-7 interfaces and classes to find which classes need new implementations and which can be reused... Suddenly what sounded like a 10 minute change becomes half a day of swearing under your breath at either the compiler or the previous engineer.Sure, abstract things, but make sure there&#x27;s also a way to bundle behavior together in one common spot, so I don&#x27;t have to touch 6 files to update one component.https:&#x2F;&#x2F;htmx.org&#x2F;essays&#x2F;locality-of-behaviour&#x2F;#conflict-with... reply 1shooner 17 hours agoparentprevTailwind is a build step with just as much &#x27;spooky action at a distance&#x27;. If it wasn&#x27;t, we&#x27;d just use inline CSS.With Tailwind you&#x27;re trusting a 3rd party library to abstract the CSS spec for you, and for that abstracted quasi-spec to be followed by your build configuration. reply mattlondon 16 hours agorootparentInline CSS is a total anti-pattern apart from the absolute most basic pages IMO.There is no harm in a plain CSS file, and applying classes at the element level in the HTML.If you put in-line CSS in the HTML is not only leads to severe duplication, but is also a maintenance nightmare if you want to change anything. It works fine if all you are changing is a colour or whatever, but often there are margins, paddings, letter spacings, font sizes etc etc which lead to quite a lot of extra crap in each element on your page. Repeating those all over each if your HTML files is a real burden. Just use a single CSS file with sensibly named classes - it doesn&#x27;t need to be sass or anything, just plain CSS is fine. reply threatofrain 15 hours agorootparent> Just use a single CSS file with sensibly named classesIMO you no longer need an intelligent naming philosophy for CSS classes due to how far CSS has come. reply mattlondon 15 hours agorootparentWell the point I was trying to make was to not do what the article says and name your class e.g. \"green\", but instead to name it something more sensible like \"approved\" or \"updated\" or something about the semantic nature of the style, rather than what the style actually is.The reasoning is that maybe today it is just \"green\" but then what if one day the color in the CSS is changed, and it is not actually green anymore? You now either need to change the CSS class name everywhere, or leave it as \"green\" and confuse everyone because it is actually blue on-screen? This only scratches the surface - there are all manner of other considerations to think about (different display&#x2F;print medias, dark&#x2F;light preferences, HCM etc) reply iudqnolq 15 hours agorootparentThe core argument for tailwind is that it won&#x27;t just be \"make the approved text white on blue instead of white on green\". Maybe you&#x27;ll get \"make the approved text",
    "originSummary": [
      "HTML First is a set of principles that aim to simplify and improve the process of building web software.",
      "The main goal is to make web programming more accessible and reduce costs by leveraging HTML's attributes and default capabilities of modern web browsers.",
      "The principles encourage the use of vanilla approaches and libraries that utilize HTML attributes while discouraging build steps and obfuscation layers that make code less readable and hinder source code understanding."
    ],
    "commentSummary": [
      "The discussions cover multiple aspects of web development, including HTML, frameworks, libraries, project requirements, and accessibility.",
      "There are debates about using complex frameworks for small projects and the pros and cons of different approaches.",
      "The discussions also touch on topics such as date pickers, build steps, code analysis, and their impact on performance and user experience."
    ],
    "points": 793,
    "commentCount": 484,
    "retryCount": 0,
    "time": 1699804836
  },
  {
    "id": 38243949,
    "title": "Open-source D-POINT digital pen offers precise stylus input with six degrees of freedom",
    "originLink": "https://github.com/Jcparkyn/dpoint",
    "originBody": "D-POINT: Digital Pen with Optical-Inertial Tracking D-POINT is an open-source digital stylus that uses camera tracking and inertial measurements to achieve 6DoF (six degrees of freedom) inputs, with low latency, pressure sensitivity, and sub-millimetre accuracy. The stylus can be used on any flat surface, and works with consumer-grade webcams. writing-demo.mp4 This project was part of my undergraduate thesis for electrical engineering. I've open-sourced the code and design files in the hopes that they might be useful to somebody, but it's not intended to be a \"plug and play\" DIY project. If you want to try building it anyway, follow the setup guide. Design This is a very brief overview of how the system works. For all the details, plus literature review and lots of evaluation, read the full thesis (note: I haven't published this online yet). Hardware The main body of the stylus was 3D printed as two halves, shown below. The stylus contains a force sensor, a Li-ion battery which charges over USB-C, and an Arduino-based development board for logic and Bluetooth. Eight printed ArUco markers are glued to the back of the stylus, for visual pose estimation. Visual pose estimation (VPE) The VPE process involves the four main steps: Marker detection: First, we use OpenCV to detect the corners of each visible ArUco marker on the stylus. Rolling shutter correction: We use a simple 2D motion model to estimate and correct for the effects of rolling shutter on the observed corner locations. Perspective-n-Point (PnP): From these corner positions, we use a PnP algorithm to estimate the pose of the stylus relative to the camera. When possible, we use the pose from the previous frame as a starting point to refine with virtual visual servoing (VVS), otherwise we fall back to SQPnP. Coordinate conversion: Using the calibrated pose of the stylus and the drawing surface relative to the camera, we calculate the position and orientation of the stylus tip relative to the drawing surface. Inertial fusion We use an Extended Kalman Filter (EKF) to fuse the VPE estimates with the inertial data from the accelerometer and gyroscope, and refine the estimates in real-time using the Rauch-Tung-Striebel (RTS) algorithm. To account for time delay from the camera frames, we use a negative-time measurement update algorithm. The EKF is implemented using NumPy and Numba. Using inertial measurements allows us to dramatically reduce latency compared to a camera-only implementation, while also improving accuracy and report rate for fast movements.",
    "commentLink": "https://news.ycombinator.com/item?id=38243949",
    "commentBody": "Open-source digital stylus with six degrees of freedomHacker NewspastloginOpen-source digital stylus with six degrees of freedom (github.com/jcparkyn) 461 points by jcparkyn 14 hours ago| hidepastfavorite84 comments bloopernova 13 hours agoparentVery cool. They&#x27;ve done what I&#x27;ve daydreamed about, and actually got it to work!When I played Elite: Dangerous I used a \"hand on throttle and stick\" (HOTAS) setup, along with foot pedals. I couldn&#x27;t help but think that there must be a better way to control a spaceship: your ship can pitch, yaw, and roll in addition to being able to fire thrusters in 6 directions.I wanted a handheld ship model that I could move such that the ship in Elite would move in the same way. The linked project looks like it could do just that. Thrust would be controlled in a similar way, but with my other hand.Strange or new input models like that are so amazing to me. Our imagination can really fly high with these sorts of capabilities. reply sillysaurusx 8 hours agoparentOne of my fondest memories is when I was 16 or so. I bought a 3D mouse (it’s like a mouse that you can control by waving it around) and taped it onto a hat that said Marines. Then I immediately went into CS: Source and got ready to annihilate everyone.I think I played about the same, but it would’ve been funnier if I’d gotten creamed.The theory was that my head is much more precise than my hands, so using a combination of both should improve my aim. It might sound like you’ll end up looking left and trying to see out of the corner of your eye, but in practice the two-mouse system ends up working out. I’ve always wanted to revive the idea for modern times, but you end up looking like a huge dork with a dildo glued to your head. I like that style though.Your idea sounds way cool. You should make it! reply Arelius 12 hours agoparentprevI still hold onto my SpaceOrb369 for this sort of game. There is a guy that makes a converter to make it work over USB...https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;SpaceOrb_360https:&#x2F;&#x2F;www.tindie.com&#x2F;products&#x2F;vputz&#x2F;orbotron-9001-version-... reply myself248 12 hours agorootparentI have the slightly newer version, branded by HP as the SpacePilot, and use it daily in Fusion 360 CAD. It has a native USB connection, and 6 user-definable hotkeys below an unimpressive LCD.It requires some old drivers that aren&#x27;t officially supported (why would they remove support for perfectly good hardware from the newer drivers? To send good stuff to the landfill, of course!), but when Autodesk tried to move Fusion to the new driver model exclusively, user outcry persuaded them to leave the old drivers in as an option. Apparently there&#x27;s quite a few of us using those SpacePilots, and the phrase \"from my cold, dead fingers\" comes up not infrequently. reply Arelius 10 hours agorootparentFor sure, the HP one is a rebrand of the 3Dconnexion right?Those are great, but nothing really compares to the original SpaceOrb360 controller form-factor for gaming IMO. reply w-ll 9 hours agorootparentprevI plugged in my old SpacePilot Pro the other day and was so dissapointed that the drivers where so outdated, and like nothing was working. reply lowbloodsugar 9 hours agorootparentprevIf you weren’t playing Descent with this you were losing. reply matheusmoreira 11 hours agoparentprev> I couldn&#x27;t help but think that there must be a better way to control a spaceshipTwo sticks?https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;EliteDangerous&#x2F;comments&#x2F;16xi20a&#x2F;dua...https:&#x2F;&#x2F;youtu.be&#x2F;T2-IHgNYaKA reply bloopernova 10 hours agorootparentThat&#x27;s really nice, before now I hadn&#x27;t really understood how to use 2 sticks, but now it makes sense.I used a CH Pro throttle, which has enough hats to sort of mimic that 2 stick action. Main throttle back forward for main engine and retros. A smaller thumb stick&#x2F;hat for each of Y and Z axis.https:&#x2F;&#x2F;www.chproducts.com&#x2F;Pro-Throttle-v13-d-719.html reply sundvor 8 hours agorootparentThat works wonderfully with VKB&#x27;s STECS, which lets you swap physical detent profiles in roughly 20 seconds. So you have a forward&#x2F;backward axis on your throttle with a well defined \"W\" centre point, plus a high quality thumb stick for your lateral&#x2F;vertical thrusters.(In case anyone is wondering, I transitioned from the Warthog throttle with DeltaSim&#x27;s slew mod with zero issues, I find the STECS Standard way more versatile and flexible).I couple this with a Gunfighter Ultimate stick (V3), and Crosswinds pedals, all profile mounted. (My GFU grip has twist, but I don&#x27;t use it.)When you add TrackIR in my case (or VR for others), there&#x27;s quite a bit of immersion going on! :-)I play DCS and Star Citizen these days, also used to fly Elite Dangerous though. Building the combined quad screen workstation &#x2F; simrig has been a wonderful side project over the past few years. ;) reply jessriedel 10 hours agorootparentprevYep. I played Descent II this way and it was glorious. reply Matumio 1 hour agoparentprevIf you like the puzzle of firing thrusters manually, try \"ΔV: Rings of Saturn\". The game is 2D, but you get six keys to individually fire different thruster combos, and a separate key to fire the main engine.Then try staying in control with an unbalanced ship, or after you inevitably smashed one of the thrusters into a rock. It&#x27;s a pretty space-nerd game too, they simulate details like reaction wheel saturation. reply tadfisher 12 hours agoparentprevIn the sci-fi series The Expanse, the Rocinante is controlled in part by a 3DConnexion SpaceMouse, commonly used in CAD and 3D modeling. reply navane 12 hours agoparentprevthis 6dof \"joystick\" has been around for decades: https:&#x2F;&#x2F;3dconnexion.com&#x2F;nl&#x2F;spacemouse&#x2F; reply RF_Savage 9 hours agorootparentAnd it works surprisingly well for Descent. The original 3dconnexion one worked first try on linux too. reply marcosdumay 10 hours agorootparentprevI&#x27;ve never found an explanation of what exactly is in that.Is it a track-ball, a rotary encoder, and a 3D stick? reply abe_m 10 hours agorootparentI don&#x27;t know exactly, but using one, it has the sensation of using the trackpoint on a Thinkpad. The puck you push, pull, and twist to make the motion is a bit springiness. The harder to push it, the faster the motion happens in the software on screen. When you release, it springs back to neutral. The old ones (late 90&#x27;s vintage) had trouble coming back to center, and there was a hot key to rezero it if it was starting to drift. The newer ones don&#x27;t seem to have the issue. reply numpad0 2 hours agorootparentprevIt’s a knob that spring back to its origin when let go, that can move ~45 degrees or ~1&#x2F;4” each axes(subjectively). It feels a bit like those old bobbing dashboard toy in hand.Mechanically, it’s something like an Rx&#x2F;Rz two-axis joystick with sliding knob part on top that can be slid in X&#x2F;Y, pushed&#x2F;pulled in Z and twisted in Ry as well. All axes are spring centered. reply lambda 10 hours agorootparentprevThere&#x27;s a picture on the Wikipedia article: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;3Dconnexion and there&#x27;s a patent you can look at: https:&#x2F;&#x2F;patents.google.com&#x2F;patent&#x2F;US20050172711A1&#x2F;en?oq=2005...It&#x27;s flexible, and there are LEDs and linear optical sensors set up with an occluder in between that casts a shadow (or passes a light through a slit, according to the patent). The sensor detect where along the sensor the shadow or light falls, which indicates how much you have translated or rotated the control in a particular axis. reply Doxin 3 hours agorootparentprevImagine a 3-axis joystick that can also sense translation. So aside from pitch&#x2F;roll&#x2F;yaw you also get the linear up-down&#x2F;left-rigth&#x2F;forward-back axises. reply imsaw 1 hour agorootparentI can see how pitch roll yaw would work, but I can&#x27;t imagine how linear movements are made on the same joystick? Maybe up and down is push and pull but what about the other directions? Do you push the device itself? reply two_handfuls 11 hours agorootparentprevThis. Sadly the drivers suck. reply radarsat1 1 hour agorootparentI&#x27;ve always found it fascinating that companies that makes specialized hardware devices like this lean so hard into proprietary software, as if that&#x27;s the thing that gives them the edge on the competition.If anything the hardware is the hard part to copy and open source drivers could do nothing but benefit them and ensure wide platform compatibility and longevity, and yet so many companies like this insist on closing things up and forcing hackers to reverse engineer everything. It&#x27;s bizarre logic to me. reply abe_m 10 hours agorootparentprevThere is an opensource driver package for Unix type systems[1]. I find them to be pretty reliable. The stock Windows drivers do leave something to be desired.[1] https:&#x2F;&#x2F;spacenav.sourceforge.net&#x2F; reply Isthatablackgsd 10 hours agorootparentprevWould it help with scripting macro software such as AutoHotKey? I imagine it wouldn&#x27;t pick up some inputs due to proprietary driver.It have the same issue for my Logitech G600 that it can&#x27;t pick up some inputs. I set up the macros in LGHUB with keystrokes (multiple modifiers with keys) and use AHK to grab those and expands the capabilities of my G600 than what LGHUB offers. reply two_handfuls 8 hours agorootparentExactly, the inputs aren’t exposed as extra axes so those tools don’t see them. reply oceanghost 6 hours agorootparentprevYup. Use one every day for Fusion360 and Blender. reply blechinger 2 hours agoparentprevThe folks at Sublight Dynamics had a really neat product in this vein that I was excited about. Seems like the perfect flightsim controller. They had trouble getting fully to market. Website is still up though so I&#x27;m holding out hope! reply pests 12 hours agoparentprevI always imagined a sphere suspended &#x2F; held by a minimum number of strings (or rods?) &#x2F; attachments. By physically pushing, pulling, and twisting the sphere you could detect these movements via compression and tension in the attachments. You could motorize those strings&#x2F;rods to give resistence and feedback to the piloting. reply bloopernova 12 hours agorootparentYeah that&#x27;s almost exactly what I was daydreaming of! Weaker gyroscopes might mean a ship can rotate in one direction slower than others, and feedback to a controller could model that for the user. reply squigz 12 hours agoparentprevThis is why 2 sticks is a fairly common setup for space games reply mulmen 10 hours agoparentprevThere’s an entire rabbit hole of dual stick setups for space games. Quack HOSAS to get started. reply bloopernova 9 hours agorootparentOk Quack is adorkable.What would be the word for \"To Kagi\"? They use \"Fetch\" in the search field, but it hasn&#x27;t really stuck with me. reply userbinator 11 hours agoparentprevGiven that a spaceship isn&#x27;t all that different from a fixed-wing aircraft, and the stick + pedals arrangement has become a standard for controlling the latter for over a century, I think it&#x27;d be hard to improve on. reply marcellus23 10 hours agorootparentThe difference is that spaceships have thrusters, so they have the ability to accelerate up, down, left, or right, in addition to all the controls of a fixed-wing aircraft (throttle + stick + pedals). reply lowbloodsugar 9 hours agorootparentprevDo fixed wing aircraft spend a lot of the time going backwards? Do they, for example, need to turn around and point their engine in the direction of travel in order to slow down? If a fixed wing accelerates to 1000mph and then rotates it’s nose by 90 degrees, how fast is it going and in what direction? What about a space craft? reply nkrisc 8 hours agorootparent> If a fixed wing accelerates to 1000mph and then rotates it’s nose by 90 degrees, how fast is it going and in what direction?I don&#x27;t know how fast, but depending on which axis it rotates on and how fast, it may be going in several directions at once. reply hooverd 9 hours agorootparentprevWith no gravity or drag they&#x27;re way different. reply tomcam 13 hours agoparentprev> This project was part of my undergraduate thesis for electrical engineering. IUndergrad! If you didn&#x27;t get top marks on this there is no justice reply jcparkyn 13 hours agoparentThanks! I&#x27;ll get results in about two weeks (fingers crossed) reply cududa 8 hours agoparentprevI scrolled down to the picture first and the desk made me instantly think “ah, a dorm room” reply an_aparallel 11 hours agoparentprevuni marks != quality :-) I agree with you though. reply crazygringo 11 hours agoparentprevVery cool. The use of a webcam really makes me wonder if there&#x27;s a future where our regular single ~78° FOV webcams are going to be replaced by dual (stereo) fisheye webcams that can:- Enable all sorts of new UX interactions (gestures with eye tracking)- Enable all sorts of new peripheral interactions (stylus like this, but also things like a steering wheel for racing games)- Enable 3D 180° filming for far more flexible webcam meetings, including VR presence, etc.The idea of being able to use the entire 3D space in front of your computer display as an input method feels like it&#x27;s coming, and using a webcam the way OP describes feels like it&#x27;s a little step in that direction. reply swanee 8 hours agoparentI thought this was around the corner years ago when Intel and partners had RealSense modules being built into laptops but it seems like all the players have shifted focus to more enterprise and industrial markets. reply westurner 6 hours agorootparentWii Remote (2006), Wiimote Whiteboard (2007), Kinect (2010), Leap Motion (2010- Ultraleap (2019)),There are infrared depth cameras in various phones and laptop cameras now.[VR] Motion controllers: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Motion_controller#GamingInertial navigation system: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Inertial_navigation_systemInertial measurement unit : https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Inertial_measurement_unit :> An inertial measurement unit (IMU) is an electronic device that measures and reports a body&#x27;s specific force, angular rate, and sometimes the orientation of the body, using a combination of accelerometers, gyroscopes, and sometimes magnetometers. When the magnetometer is included, IMUs are referred to as IMMUs.[1]Moasure does displacement estimation with inertial measurement (in a mobile app w&#x2F; just accelerometer or also compass sensor data?) IIUC: https:&#x2F;&#x2F;www.moasure.com&#x2F;&#x2F;? wireless gesture recognition RSSI: https:&#x2F;&#x2F;scholar.google.com&#x2F;scholar?q=wireless+gesture+recogn...&#x2F;? wireless gesture recognition RSSI site:github.com : https:&#x2F;&#x2F;www.google.com&#x2F;search?q=wireless+gesture+recognition...Awesome-WiFi-CSI-Sensing > Indoor Localization: https:&#x2F;&#x2F;github.com&#x2F;Marsrocky&#x2F;Awesome-WiFi-CSI-Sensing#indoor...3D Scanning > Technology, Applications: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;3D_scanning#TechnologyAre there a limited set of possible-path-corresponding diffraction patterns that NIRS (Near-Infrared Spectroscopy) could sense and process to make e.g. a magic pencil with pressure sensitivity, too?&#x2F;q.hnlog \"quantum navigation\": https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36222625#36250019 :> Quantum navigation maps such signal sources such that inexpensive sensors can achieve something like inertial navigation FWIU?From https:&#x2F;&#x2F;news.ycombinator.com&#x2F;context?id=36249897 :> Can low-cost lasers and Rdyberg atoms e.g. Rydberg Technology solve for [space-based] matter-wave interferometry? [...] Does a fishing lure bobber on the water produce gravitational waves as part of the n-body gravitational wave fluid field, and how separable are the source wave components with e.g. Quantum Fourier Transform&#x2F;or and other methods?Because the digitizer reply westurner 6 hours agorootparent> e.g. a magic pencil with pressure sensitivity, too?Wouldn&#x27;t such a capability also be useful for surgical AR&#x2F;AI, robotics, and training? reply moritonal 11 hours agoparentprevI&#x27;m sadly bearish on this kind of stuff. The Mac touch-panel showed that even a context-aware, reactive and fully integrated input struggled to break the flow gained by keyboard+mouse.Even today some people are still on the fence about the new fangled mouse! reply two_handfuls 11 hours agorootparentThe Mac touch bar sucked, that why it didn’t gain traction. reply mjcohen 9 hours agoparentprevI have an Anker PowerConf 300 webcam which (on Mac or Windows) can go up to 115 degrees with the AnkerWork software. reply mncharity 11 hours agoparentprevNice. Especially the fusion.Some random-ish thoughts from exploring \"a laptop keyboard... with hand pose, 3D stylus, and touch\". Adding buttons yields a 3D mouse - but camera coverage can be a pain. Note the body is largely empty (and battery could be slimmed) - I could more-or-less type while holding a slim chopstick&#x2F;toothbrush-like stylus (even with the markers, and a weirdly big tip). A big tip (sliced from a ping-pong ball sized xmas decoration) could slide fairly smoothly on a ThinkPad keyboard (and gave room for a less compact force sensor, and an extra tip marker). Thin stranded silicone ribbon cable can be string-like flexible - I just tethered the stylus to an arduino to get started.Hmm... I wonder what the inertial sensor might make of something like a dimpled metal clicker, as a button (or three)? reply slaucon 13 hours agoparentprevThe rolling shutter compensation is pretty cool and isn&#x27;t something I would have thought of. Did you know that would be an issue from the start or notice it only after you built the rest of the system? reply jcparkyn 13 hours agoparentI knew it would have an effect (most of the literature for similar projects just uses global shutter cameras for this reason), but wasn&#x27;t sure how significant it would be. It turned out to be small enough that it usually wasn&#x27;t super noticeable, but in certain cases it really showed up (e.g., rotating the pen while keeping the tip in one place).The thing I was most surprised by was how effective my solution was, given that it&#x27;s a pretty gross approximation of reality. There are lots of much more sophisticated techniques for dealing with it, which I didn&#x27;t end up needing.One thing I would&#x27;ve liked to try out is using rolling-shutter-aware PnP [1], which can theoretically estimate pose and velocity simultaneously from one image, by exploiting the rolling shutter distortions.[1] https:&#x2F;&#x2F;www-sop.inria.fr&#x2F;members&#x2F;Philippe.Martinet&#x2F;publis&#x2F;20... reply jimmySixDOF 12 hours agoparentprevI&#x27;m a big fan of all things 6DOF ! Nice work on the hardware and computer vision pose work but I am almost more impressed by the software surface you are drawing into and able to rotate. Thats interesting and could be used with any tangible user interface control like a finger slider for the same effect. Good project for problem solving skills looks like you nailed it bravo!Btw the first 6DOF controller I had other (than a hacked WiiMote controller as a ir led Bluetooth receiver [1]) was the logitec mx air which was ahead of its day [2].[1] https:&#x2F;&#x2F;web.cs.ucdavis.edu&#x2F;~okreylos&#x2F;ResDev&#x2F;Wiimote&#x2F;MainPage...[2] https:&#x2F;&#x2F;www.cnet.com&#x2F;reviews&#x2F;logitech-mx-air-review&#x2F; reply wnolens 7 hours agoparentprevThis is really cool, and right out of my dreams.Since the move to full remote work at my company, I&#x27;ve been longing for whiteboard sessions. The best I could conjure up was to use an old iPad and load up a shared whiteboarding webapp in a browser on both iPad and my desktop, and then share screen from my desktop, using a cheapo stylus on the iPad to draw.It&#x27;s pretty good, but my iPad is super old and slow. Replacing it is not affordable. But a conventional web cam + a relatively low-tech stylus would be much better, and drop the need for an external device completely. reply abdullahkhalids 7 hours agoparentThe cheapest Wacom tablet [1] is 67CAD. Other brands have cheaper ones.[1] https:&#x2F;&#x2F;wacomstore.ca&#x2F;product&#x2F;one-by-wacom-small&#x2F; reply lagrange77 12 hours agoparentprev1. Very cool project2. Helpful documentation3. Nice real world example for the use of a Kalman Filter! reply sj4nz 7 hours agoparentprevFantastic. I love that this is brand-independent, like buying a mechanical keyboard. reply joshuahhh 6 hours agoparentprevImpressive work! I wonder: is the inertial tracking sufficient to cover for occasional occlusion of the markers? reply jcparkyn 1 hour agoparentThat depends what you consider \"occasional\", but for most definitions the answer would be no. I&#x27;m sure there are better ways to handle the inertial measurements than what I did, but even so, double integration drift causes errors very very quickly. I doubt it&#x27;d be possible to go over a second, and my implementation struggled with anything over ~150-200ms.However, it does an impressively good job with low camera frame rates. I tested it at 10FPS (discarding every third frame), and the results are barely distinguishable from 30FPS. Below that it starts having difficulty. reply tomp 12 hours agoparentprevVery cool!Could be useful for robotics &#x2F; VR as well. One-camera hand tracking anyone?Question: could you use gyro+accel to track pressure as well? Or at least \"taps\"?Another question: how much does it cost? in particular, the pressure sensor... reply jcparkyn 11 hours agoparent1: You could absolutely use gyro&#x2F;accel for detecting taps, but for proper pressure sensitivity (i.e., changing pressure in the middle of a stroke), there&#x27;s not much you can do except have a pressure sensor. It&#x27;s theoretically possible with a sufficiently accurate pose estimate and a springy pen tip, but not feasible at the level of accuracy I got.2: I paid about $20 AUD for the pressure sensor, but they can be had for quite a bit cheaper (~$5 USD) in the US (https:&#x2F;&#x2F;www.arrow.com&#x2F;en&#x2F;products&#x2F;hsfpar003a&#x2F;alps-electric). Only problem is they&#x27;re quite specialized, so not many places sell them. The custom PCB was another $10AUD, and the Arduino was about $20. There&#x27;s a full parts list at https:&#x2F;&#x2F;github.com&#x2F;Jcparkyn&#x2F;dpoint&#x2F;blob&#x2F;main&#x2F;setup-guide.md. reply extraduder_ire 13 hours agoparentprevOutside tracking with a camera is not something I would have thought of. Seems cool.Reminds me of how sad I am nobody&#x27;s done a good job of cheaply cloning the lighthouse tech that valve&#x2F;htc use. reply jcparkyn 13 hours agoparentI should point out that I&#x27;m not the first person to use camera tracking for this [1], but to my knowledge there hasn&#x27;t previously been a serious attempt to combine it with inertial or pressure sensors (which are both necessary for competing with graphics tablets) or make it open-source.[1] http:&#x2F;&#x2F;media.ee.ntu.edu.tw&#x2F;research&#x2F;DodecaPen&#x2F; reply two_handfuls 11 hours agorootparentIsn’t camera tracking + inertial sensors exactly how the Oculus Rift headset & controller tracking worked? reply jcparkyn 10 hours agorootparentYes (or something like that, I don&#x27;t know all the details), but they use infra-red light which requires a dedicated camera. I think they might also require more than one camera (although it is possible to do monocular IR tracking). reply mtsr 12 hours agoparentprevAFAIK you can actually get the sensors used for tracking at somewhat OK prices. But iirc the sensors actually do some part of the position calculations and as such aren’t simple enough to be really cheap. reply r2_pilot 5 hours agorootparentYep, they&#x27;re actually just tiny solar panels! I got several trying to figure out how to use the lighthouse system. Not enough hours in the day and at the time there wasn&#x27;t enough compute in a small package cheap enough for me. reply ipsum2 13 hours agoparentprevVery cool! It has the added benefit of being able to manipulate objects in 3d. How does it compare to graphic tablets in terms of accuracy? reply jcparkyn 13 hours agoparentCurrently it&#x27;s not quite at the level of graphics tablets, but it&#x27;s not too far off, and I think there&#x27;s quite a bit of potential to improve it using similar techniques [1].In terms of absolute accuracy, I measured an average error of 0.89mm (for the position of the tip) across the entire area of an A4 page with the camera in one place. In practice you have more precision than that though, because most of the errors are constant biases (not random noise).For example, here&#x27;s one of the tests [2] I did for the thesis, which compares the recorded stroke to what I actually wrote (scanned from carbon paper). After aligning the two captures (as a global 2D position offset, everything else is retained), the average distance from the recorded stroke to the scan was 0.158mm.[1] This paper (which I linked in another comment) uses some more advanced techniques for pose estimation which could definitely be applied here (but it&#x27;s closed-source, and I didn&#x27;t have time to re-implement it from scratch): http:&#x2F;&#x2F;media.ee.ntu.edu.tw&#x2F;research&#x2F;DodecaPen&#x2F;[2] https:&#x2F;&#x2F;github.com&#x2F;Jcparkyn&#x2F;dpoint&#x2F;files&#x2F;13329235&#x2F;main-sketc... reply orbital-decay 6 hours agorootparentOne thing with using graphic tablets for handwriting and drawing in practice is you really want your stylus to be thin, lightweight (15-20g), and have either neutral center of gravity or balanced towards the tip slightly. Also preferably battery-free (non-Wacom tablets were forced to use batteries due to patents, not anymore).Until it&#x27;s solved, the better practical use for this is probably a controller for VR or 3D software. reply abdullahkhalids 9 hours agorootparentprevNice. It seems there is a systematic error towards the edges of the paper, which can easily be fixed in software.Though it would be nice to do more tests. For example, there is some error when drawing sharp corners. It would be instructive to see how that changes as you change the angle, etc. And how that changes based on location on the paper. reply moritonal 11 hours agorootparentprevBrings back joyful memories of me begging random Professors from around the world over email for the source code of their papers. reply sshkey 8 hours agoparentprevwow, very impressive project! really I love it, I will try to build it one definitly. reply ezconnect 8 hours agoparentprevAdd a laser range finder on the camera and retroreflector on the pen and we have a cheap implementation of a 3D measuring device. reply charcircuit 13 hours agoparentprev [–] Too bad this wasn&#x27;t made as an OpenXR API layer so that it could be used with existing software reply ipsum2 13 hours agoparentThe great thing is that its open source, so you can add whatever niche APIs you want to it! reply charcircuit 10 hours agorootparentWhy would I be the one to do that? I already have a pressure sensitive 6dof stylus that is compatible with openxr.OpenXR isn&#x27;t a niche API when you are dealing with 6dof input devices. reply cududa 7 hours agorootparentI know this might be shocking, but OP didn’t make this for you. There’s actually all sorts of people out there making all sorts of things without considering your specific needs reply bloopernova 6 hours agorootparentPlease don&#x27;t feed the troll. They&#x27;re being deliberately argumentative. reply charcircuit 7 hours agorootparentprevWhy are you using that tone? I never had the intention to use this. I am just stating that there is a missed opportunity that exists. Why are you implying that I want this as feature for me to use? reply jcparkyn 5 hours agorootparentI&#x27;ll chime in and say that OpenXR integration is a good suggestion, just not something I had the time&#x2F;effort to implement (this is a university project, after all, and was focused more on the core tracking tech). I think people just took issue with the way you phrased your original comment. reply grodriguez100 7 hours agorootparentprev> Why would I be the one to do that?Because you are the one who is complaining. reply bloopernova 6 hours agorootparentPlease don&#x27;t feed the troll. They&#x27;re picking fights on purpose. reply noddingham 13 hours agoparentprev [–] It&#x27;s open source so... replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The D-POINT digital pen is an open-source stylus that offers precise and low-latency input using camera tracking and inertial measurements.",
      "It can be used on any flat surface and is compatible with consumer-grade webcams.",
      "The stylus incorporates multiple technologies, including marker detection, rolling shutter correction, and inertial fusion, to improve accuracy and reduce latency."
    ],
    "commentSummary": [
      "Open-source technologies and devices are being discussed for more precise control and interaction in virtual environments and games.",
      "The topics include the use of multiple input devices, limitations of proprietary drivers, potential applications in space games, and the use of webcams for new input methods.",
      "Discussions also cover space-based matter-wave interferometry, quantum navigation, touch panels, hand tracking, and drawing applications."
    ],
    "points": 461,
    "commentCount": 84,
    "retryCount": 0,
    "time": 1699822110
  },
  {
    "id": 38242946,
    "title": "Median Value of Second Prime Factor of Integers Confirmed as 37, according to Book",
    "originLink": "https://grossack.site/2023/11/08/37-median.html",
    "originBody": "A truly incredible fact about the number 37 08 Nov 2023 - Tags: sage So I was on math stackexchange the other day, and I saw a cute post looking for a book which lists, for many many integers, facts that Ramanujan could have told Hardy if he’d taken a cab other than 1729. A few days ago OP answered their own question, saying that the book in question was Those Fascinating Numbers by Jean-Marie De Koninck. I decided to take a glance through it to see what kinds of facts lie inside (and also to see just how many integers are covered!). Not only was I overwhelmed by the number of integers and the number of facts about them, the preface already includes one of the single wildest facts I’ve ever heard, and I have to talk about it here! Here’s a direct quote from the preface: 37, the median value for the second prime factor of an integer; thus the probability that the second prime factor of an integer chosen at random is smaller than 37 is approximately $\\frac{1}{2}$; My jaw was on the floor when I read this, haha. First it sounded totally unbelievable, since 37 is a tiny number in the grand scheme of things. Then it started to sound slightly more plausible… After all, about half of all integers have $2$ as their smallest prime factor. It makes sense that smaller primes should be more frequent among the smallest factors of numbers! But then I thought “how can you possibly prove this!?”. I’m not much of an analytic number theorist1, but I know that they have good estimates on a lot of facts like this. I decided it would be fun to try and find and understand a proof of this fact, and also write some sage code to test it! So then let’s go ahead and do it ^_^ First, I think, the sage code. I want to know if this really works! “Obvoiusly” there’s no uniform distribution on the natural numbers, so what does it even mean to choose a “random” one? The way the number theorists usually solve this problem is by fixing a large number $N$ and looking at the probabilities when you pick a random number between $1$ and $N$. Then you look at the $N \\to \\infty$ limit of these probabilities. So for us, we’ll want to first fix a large number $N$ and then work with numbers $\\leq N$. For $N$ kind of small, we can just find the second prime factor of each number $\\leq N$ and check the median! 1 def getSecondSmallestFactors(N): 2 data = [] 3 for n in range(1, N): 4 fs = factor(n) 5 if len(fs) > 1: 6 second_smallest = fs[1][0] 7 data += [second_smallest] 8 else: 9 # If there's only one prime factor 10 # say the second prime factor is infinity 11 data += [oo] 12 13 return data 14 15 @interact 16 def _(N=input_box(10^5, width=10, label=\"$N$\")): 17 data = getSecondSmallestFactors(N) 18 19 med = numpy.median(data) 20 show(\"median second prime: \") 21 show(med) 22 show(\"\") 23 24 below37 = len([d for d in data if d = p: 12 break 13 out *= (1 - (1/q)) 14 15 for q in Primes(): 16 if q >= p: 17 break 18 s += (1/q) * (1 - (1/q))^(-1) 19 20 out *= s 21 out *= 1/p 22 23 return out 24 25 total = 0 26 for p in Primes(): 27 if total > 0.5: break 28 29 l = lambda2(p) 30 total += l 31 32 show(\"{} of numbers have {} as their second prime\".format(l.n(),p)) 33 show(\"so {} of numbers have second prime at most {}\".format(total.n(), p)) 34 show(\"\") Evaluate Again we see that $37$ is the prime where roughly half of all numbers have something $\\leq 37$ as their first prime! So we’ve proven that $37$ is the median second prime! Also, this shows that we expect the actual density to be $\\approx .5002$. If we set $N = 10^7$ in the code from the first half5 to get a better approximation, we get $.5002501$, which is remarkably close to the truth! As another cute exercise – using the ideas in this post, can you compute the median third prime? As a (much) harder exercise6, can you get asymptotics for how the median $k$th prime grows as a function of $k$? Thanks for hanging out, all! This was a really fun post to write up, and I’m really excited to share it with everybody! This fact about $37$ was all I could think about for like a week, haha. I have more blog posts coming, of course, so I’ll see you all soon! Stay safe, and stay warm ^_^ Absolutely the understatement of the year ↩ Sur la loi de répartition du k-ième facteur premier d’un entier Yes, this paper is in french, but it’s really not so hard to read, especially with liberal use of google translate. Though if you want to avoid reading it, I’ve done the hard work for you, and everything in this blog post is in english. It also wasn’t too hard to find this paper, thankfully. It’s mentioned in a footnote in the entry for $37$ in Those Fascinating Numbers, so I had a decent starting point. ↩ I literaly got the base image by googling “grid of numbers high res” and clicking the first result, which was for elementary schoolers ↩ It might be helpful to remember a generating function trick that shows up fairly often (for instance in partitions and the riemann zeta function): \\[\\sum \\frac{1}{n} = \\prod_p \\left ( 1 - \\frac{1}{p} \\right )^{-1}\\] Don’t worry that this sum diverges for now. Just take note of why these two sides are equal. You should expand each term of the right hand side as a geometric series, then check what happens when you foil. ↩ (and run it locally, since factoring numbers that big takes so long that the online sagecell times out) ↩ If you read french, the De Koninck and Tenenbaum paper we’ve been referencing all post (Sur la loi de répartition du k-ième facteur premier d’un entier) is actually all about analyzing these asymptotics! If we write \\(p_k^*\\) for the median $k$th prime, then they show: \\[\\log \\log p_k^* = k - b + O \\left ( \\frac{1}{\\sqrt{k}} \\right )\\] where $b = \\frac{1}{3} + \\gamma - \\sum_p \\left ( \\log ((1-1/p)^{-1}) - 1/p \\right )$ and $\\gamma$ is the Euler-Mascheroni Constant. ↩",
    "commentLink": "https://news.ycombinator.com/item?id=38242946",
    "commentBody": "37, the median value for the second prime factor of an integerHacker Newspastlogin37, the median value for the second prime factor of an integer (grossack.site) 389 points by sacrosanct 16 hours ago| hidepastfavorite179 comments dataflow 12 hours agoparentThis doesn&#x27;t mean there&#x27;s anything interesting about 37.Rather, the only interesting fact here is that a finite median here exists at all. Once you&#x27;ve established that, it&#x27;s guaranteed to be some prime number, because we&#x27;re defining the median of a list to be an element of the list. It just happens to be 37 for this list, but it may as well have been anything else.What could make 37 interesting is if we relaxed the definition of the median to be outside the set itself (which is entirely possible), and yet the limit still, and it still converged to 37 somehow. That would be wild. reply LegionMammal978 11 hours agoparentAs we take the limit as N → ∞, the list continually grows larger. Thus, the number of instances of 37 continually increases, so that they occupy an asymptotically constant proportion (about 0.963%) of the values in the list; only ~49.061% of the values are less than 37, and only ~49.975% of the values are greater than 37. After a certain point, for even N, there will always be two instances of 37 surrounding the 50% mark in the list, so the median will still be exactly 37, and not some other value. I wrote up a longer explanation in another comment [0].[0] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38245162 reply tromp 2 hours agorootparentOut of the integers 1..2N+1, exactly N have smallest prime factor 2,while the remaining N+1 have smallest prime factor > 2.Thus it is fair to say that the median smallest prime factor is 3 rather than 2. reply tromp 2 hours agorootparentOops, that&#x27;s not correct, since 1 has no prime factor.We should instead look at the odd-sized range 2..2N, in which N elements have smallest prime factor 2, making 2 the unique median.Only in even sized ranges 2..2N+1 is the median shared between 2 and 3. reply antonvs 43 minutes agoparentprev> It just happens to be 37 for this listWhat do you mean by “this list” here? It seems to be misunderstanding the result. reply sriku 4 hours agoparentprevI&#x27;m curious about the first number to have absolutely nothing interesting to be said about it ;) reply xigoi 4 hours agorootparenthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Interesting_number_paradox reply 2-718-281-828 11 hours agoparentprevis it trivial that the series of medians for the second prime factor of numbers up to N is a specific number? isn&#x27;t it just as plausible that this median would increase? reply LanceH 4 hours agorootparent> isn&#x27;t it just as plausible that this median would increase?Every sixth number will have a factors 2 and 3. (so 3 is the second prime for 16.666% of numbers)Every 10th number will have factors 2 and 5.Every 15th number will have factors 3 and 5.Of course then you have to subtract out every 30th number which contains a 2, 3 and 5.They ignored duplicates and it would have been nice if they had defined \"first\" and \"second\" properly. Also note that a prime counts the 2nd factor as \"infinite\", adding one to the \"above 37\" bucket.Anyhow, you add those up and it&#x27;s easy to at least see that in any range of numbers it very quickly approaches 50%. Keep going to write out the Venn diagram and it happens to come out at 37. It&#x27;s low enough, I assume it could even be done by hand. reply drexlspivey 10 hours agorootparentprevThe median of the first prime factor is 2 reply cmiller1 10 hours agorootparentThe sequence of the medians of successive prime factors would be interesting reply codetrotter 9 hours agorootparentprevBut intuitively it’s weird that the median of the second prime factor is not 3, right? reply drexlspivey 9 hours agorootparentOnly multiples of 6 (1 in 6 numbers) have 3 as their second prime factor so I wouldn’t expect the median to be 3 reply eru 6 hours agorootparentI guess it depends on whether you count multiples of 4 to have 2 as both their second and first prime factor? reply NikkiA 5 hours agorootparentprevI&#x27;d expect the mode of the second prime factor to be 3, but not necessarily the median. replymg 14 hours agoparentprevI agree that this makes 37 somewhat interesting.Certainly more interesting than - say - 31.31 is a prime number too, and therefore somewhat interesting. But for sure not as interesting as 37, which as we just learned, is the median value for the second prime factor of an integer.Any suggestions of integers which are even more interesting?And while we are at it, is there an integer which qualifies to be the most interesting? reply jl6 14 hours agoparentMathematicians are locked in bitter struggle between the Zeroastrians who believe additive identity blesses 0 as truly the most foundational and therefore interesting integer, while the Unitarians favor multiplicative identity and thus champion 1. Uncountable souls have been lost to the conflict between these two groups. reply enriquto 13 hours agorootparentWe Pragmaticists (some would say \"abject pragmaticists\") advocate for a compromise solution between Zeroastrians and Unitarians by taking h=½ as the fundamental constant. It satisfies several interesting identities involving other constants, like i^i=e^(-hπ), ∫e^(x^(1&#x2F;h))dx=π^h, ∑n^(-1&#x2F;h)=hπ^(1&#x2F;h)&#x2F;3, the celebrated inequality (a+b)h≥(ab)^h or the curious fact that 1&#x2F;h is the smallest prime number. reply geraldhh 12 hours agorootparentPragmaticists brought a fraction to an integer competition and lost reply plank 3 hours agorootparentAh, but they won the Pi versus Tau competition ;-) reply narinxas 12 hours agorootparentprevthey lost the competition, but in the end it was them who paid the prize reply samcheng 11 hours agorootparentprevHalfasstrians? reply joenot443 13 hours agorootparentprevUgh, must we relate every thread about integer fascination back to Zerry&#x2F;Unny zealotry? It’s been going on for centuries now, nobody’s changing their opinion at this point. reply chaboud 12 hours agorootparentI, for one, think zero good will come of it…Two soon? reply eru 6 hours agorootparentprev> It’s been going on for centuries now, nobody’s changing their opinion at this point.Sure, but one side can still out-breed the other. reply narinxas 13 hours agorootparentprevbecause numbers have a natural meaning. roughly speaking each integer has as many meanings as its value. so 0 and 1 are just the very beginning.zero&#x27;s natural meaning is special, it&#x27;s the void. sometimes the &#x27;variable&#x27; stands in as having this meaning, sometimes the variable is zero.one is the easiest simplest to grasp. its meaning is \"I\", ego.two is duality in the broadest imaginable sense. wars are being fought right now over the precise meaning of 3 reply _0ffh 12 hours agorootparentThe Tao Produced One;The One Produced Two;The Two Produced ThreeAnd The Three Produced All Things. reply Shorel 12 hours agorootparentSounds very close to the firstness, secondness and thirdness categories from Charles Sanders Peirce.(Which I think are nothing but nonsense from a madman =) reply User23 10 hours agorootparentHe was an awfully pragmatic madman. He also discovered the universal and existential quantifiers independently of Frege, albeit a few years later.No offense intended, but to the extent his work feels mad to you, it might be a “you problem.” That said, he never did reduce firstness, secondness, and thirdness to unity to his own satisfaction either. His work is truly tantalizing.Oh and abduction has had some conceptual influence too.Sad that the Arisbe fansite got deleted. reply narinxas 12 hours agorootparentprevwe can be more precise now:the three produced the equation, which pretended that all things were (could be) equalized into equivalence. they called this algebra and parised some monotheistic god; they called this magic and GOTO one. reply smegsicle 8 hours agorootparentprevthats funny i always heard it was an origin with two other orthogonal rolesunless youre a dirty filioquist reply mjrpes 10 hours agorootparentprevPerhaps 0 and 1 are the same. If there only exists the entity called 1, lacking all properties or relations to other entities, what is left? A void called 1, no different than 0. The true mystery is: how did plurality arise? reply eru 6 hours agorootparent> Perhaps 0 and 1 are the same.Compare https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Field_with_one_element reply ajhurliman 13 hours agorootparentprevThis feels closer to a tarot reading than mathematics, and I’m here for it reply User23 10 hours agorootparentprevConsider for a moment that Aristotle, and thus most likely all the ancients, made a distinction between nothing and void. reply ak_111 1 hour agorootparentprevIs this a reference for some fiction? Or you just made it up? reply drsopp 12 hours agorootparentprevMy favorite is 2: Shared joy is a double joy, and shared sorrow is half sorrow. reply SamBam 8 hours agorootparentI&#x27;ve always felt 2 was the most important as well, if only because for there to be something (1) there has to be nothing (0), and thus the existence of anything defines 2 states, being and non-being. Without the pair (0, 1) there is no distinguishing anything in the universe. reply awwaiid 8 hours agorootparentprevMy spouse often claims that two is the best prime because she knows it annoys me. Or perhaps she is truly insane. Clearly 2 is the WORST prime, amirite? reply eru 6 hours agorootparentWell, it&#x27;s definitely the primest prime. reply hurryer 13 hours agorootparentprevIn modern math all numbers are built on set theory which has the empty set as it&#x27;s foundation.Empty set is more like 0 than 1. Check mate Unitarians. reply eru 6 hours agorootparentNo. Set theory is just one possible way you can build up numbers and mathematics.You can just as well build up numbers and the rest of mathematics from different foundations. They are all equivalent.Just like running your programs on ARM or on x86 or a toaster is all the same, thanks to emulators. (That&#x27;s assuming you have an arbitrary amount of memory, and don&#x27;t mind differences in runtime length.) reply bobbylarrybobby 3 hours agorootparentprevWhich is more foundational: the wheel or the axle? Sets aren&#x27;t worth much if you can&#x27;t take unions, which is where 1 comes from. reply layer8 13 hours agorootparentprevThe empty set is 1 set. Can’t have 0 without 1. reply fuzztester 13 hours agorootparentThe empty set is the set with nothing, i e. no thing. So it doesn&#x27;t need 1.;) reply phkahler 10 hours agorootparent>> The empty set is the set with nothingSo it is A set. In fact it&#x27;s \"the set\" that makes it a rather special one. reply layer8 13 hours agorootparentprevWouldn’t the set without nothing be more fundamental? reply fuzztester 11 hours agorootparentBrilliant. Go to the top of the class, er, set. Oops, forgot, sets have no order. List, then. reply fuzztester 10 hours agorootparentOrdered list, I mean. reply automatic6131 12 hours agorootparentprevDoes the set of sets that exclude themselves exclude itself? reply Akronymus 11 hours agorootparentNo, because it isn&#x27;t a set, but rather a class. reply OJFord 4 hours agorootparentA concept created at least partially to resolve this paradox. reply fuzztester 11 hours agorootparentprevThat&#x27;s a well-known old paradox, or close. Good on you, cobber. (AU slang :) reply fuzztester 10 hours agorootparentSee Russells&#x27;s paradox:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Russell%27s_paradox reply coldtea 12 hours agorootparentprevYou start from 1 empty set though.If you could start from 0 empty sets, you&#x27;d have a point. reply fuzztester 10 hours agorootparent>You start from 1 empty set though.Sez who, zigactly? If you are coldtea, I am coldertea. As in, I love my tea colder than you do yours. And starts who? Not me.Don&#x27;t kid around, dude. I dik around.>If you could start from 0 empty sets, you&#x27;d have a point.What if the set of empty sets has no element? :) reply coldtea 10 hours agorootparentWas the first comment under the influence of drugs?In any case, for the second comment: even if the set of empty sets has no elements, it&#x27;s still ONE set. replytasuki 4 hours agorootparentprevSurely addition is more foundational than multiplication? Multiplication is just repeated addition. reply User3456335 13 hours agorootparentprev0 and 1 are interesting as integers in the same way that a blank canvas is interesting as a painting. Very foundational, very useful but also very plain. reply mikea1 13 hours agorootparentIn my limited math experience, I really found an appreciation of the number one. My favorite part of high school algebra was realizing that \"solving for x\" was often just a repeated exercise of multiplying each side of the equation by a \"clever form of one.\" reply User3456335 12 hours agorootparentSolving for x often entails multiplying both sides by the same number, not necessarily one. Perhaps you&#x27;re referring to simplifying fractions where you do often multiply by a clever form of one? reply mikea1 9 hours agorootparentAh, yes, you are absolutely correct. The _clever form of one_ trick did not apply as often as I recalled! reply mnd999 13 hours agorootparentprevPretty interesting if you work in an industry where you use them to represent every other number. reply narinxas 12 hours agorootparentprevnot in binary notation they&#x27;re not reply anschwa 12 hours agorootparentprevOne of my professors would often refer to this struggle as taking place between the Nihilists and Unitarians. reply sorokod 13 hours agorootparentprevℵ0 uncountable? reply fallingknife 11 hours agorootparentprevMust be an integer number of souls, though, so even in a conflict of infinite time, it won&#x27;t be uncountable. reply fuzztester 12 hours agorootparentprevYou missed the Dualitarians, the Trialitarians, and so on through to the Infinitarians ... whoops, forgot Cantor!https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Georg_Cantor reply layer8 13 hours agoparentprev> is there an integer which qualifies to be the most interesting?I’d say that 664571016291591957042161991109590159107314773607 and 590488317782859198927092718316232684864014739572 qualify, which are the big- and little-endian versions of ASCII “the most interesting”, respectively. reply falcor84 14 hours agoparentprevhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Interesting_number_paradox reply TeMPOraL 14 hours agorootparentLike the Original Sin entered the Garden of Eden through the Serpent, mutable state breaks the time-invariant perfection of mathematics through the idea of interestingness, since it&#x27;s clear the least interesting things only remain so until someone notices. reply mg 14 hours agorootparentprevWell, that is about the question which is the most uninteresting number. And the paradox that - whichever number it is - this attribute makes it interesting.But since we are not looking for the most uninteresting number, but the most interesting one, we do not have to fight with issues of that calibre. reply function_seven 10 hours agorootparentTrue, but you must still contend with your observational influence. Whatever number you crown as \"most interesting\" will become even more interesting for wearing that crown!So you must take this duty with extreme care and thoughtfulness, for when you anoint such a number, your action may crystalize it as such for all eternity. Other numbers will have to go further to supplant it. reply mikepurvis 14 hours agorootparentprevI know it&#x27;s a joke, but I still feel like it would be more meaningful if it wasn&#x27;t so generic that it could kind of apply to anything. Like, there&#x27;s nothing specific to numbers about the idea that the least-\"interesting\" item in some set is itself interesting for possessing that property. reply SamBam 8 hours agorootparentBecause it&#x27;s numbers, which are sortable, you can ask which is the least member of a set. If a set of positive numbers doesn&#x27;t have a least member, does the set exist?There&#x27;s a similar paradox which asks what the smallest number that can&#x27;t be defined in fewer than thirteen words.There must be some number, right? For instance, 7603201560, or \"seven billion six hundred and three million two hundred and one thousand five hundred and sixty\" seems to require 16 words. Maybe you can shorten it by removing the \"ands,\" but I can come up with a longer number.But if there were such a number, then couldn&#x27;t we describe it as \"the smallest number that can&#x27;t be defined in fewer than thirteen words?\" And then it just got defined in fewer than thirteen words. So it can&#x27;t really be a member of that set.So does the set have any members? reply mg 14 hours agorootparentprevThen let&#x27;s see who manages to write the least interesting comment in this thread. reply falcor84 11 hours agorootparentprevThe way I understood it, this formulation relies on induction on the natural numbers. reply aquafox 13 hours agoparentprevHistorically, I&#x27;d say 60, because relative to it&#x27;s size, it has many divisors (12), and among them a lot of useful ones (2, 3, 4, 5, 10), which is why our time system and trigonometry are probably based on it (360 = 6*60; 360 has 24 divisors). reply User3456335 13 hours agoparentprevOne other special property prime numbers can have is being irregular. And guess what the first irregular prime number is? 37. Interesting that it appears so late because irregular prime numbers do make up around 41% of all primes. See: https:&#x2F;&#x2F;encyclopediaofmath.org&#x2F;wiki&#x2F;Irregular_prime_number#:....So the most interesting prime number really depends on what you consider more interesting. If you prefer the median second prime factor, then 37 is the best, but if you prefer the first irregular prime number then 37 is also the best. So it all depends on your perspective.Another reason to like 37 is that it ends in a 7 so that it \"sounds random\" when someone asks for a number and it is better than 27 because it is prime. 7 is too low and 17 has connotations with bad luck. Although 37 is quite scary too: it&#x27;s not just prime, which is pretty irregular, but it&#x27;s also an irregular prime. reply DevX101 13 hours agoparentprevI nominate 60. Babylonian mathematics was sexagesimal (base 60) which is a superior mathematical system to base 10. The number 60, a superior highly composite number, has twelve factors: 1, 2, 3, 4, 5, 6, 10, 12, 15, 20, 30, and 60, of which 2, 3, and 5 are prime numbers. With so many factors, many common mathematical operations are much simpler than in base 10. Base 10 has no special mathematical properties apart from as an accident of evolution, we primates ended up with 10 fingers.We still have some vestiges of the babylonian system however, 60 minutes in an hour. 360 (6 sixties) degrees in a circle. reply mikewarot 12 hours agorootparentSince small prime factor are so useful, why not use 2 3 times and 3 2 times along with 5 2*2*2 * 3*3 * 5 = 360360 is a very handy number, it has a high degree of usefulness, when you&#x27;re circumferential in your calculations. reply emmelaich 10 hours agorootparentYou&#x27;re perilously close to being a eikositriophile. We try not to talk about such things openly fnord.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;23_enigma reply gowld 6 hours agorootparentHow is that related? reply jkhdigital 10 hours agorootparentprevIt is another accident of evolution that we ended up with 12 finger joints, allowing one to count to twelve with a single hand by tapping the thumb on each finger segment in turn. reply necovek 5 hours agorootparentprevMost of your argument seems to stand for 30 instead of 60: 2 x 3 x 5 = 30, which is a smaller number with mostly the same properties as 60.If you want more divisibility (into quarters, eigths, ninths...), you can continue multiplying further, but 60 is as much a \"historical accident\" as 10 is an \"accident of evolution\". reply joe_the_user 13 hours agoparentprevMuch as I appreciate the reference, I think the fact this limit exists at all and is an integer is more interesting than what the integer is.A lot of paradoxes and confused ideas begin with \"choose an integer at random\" - what is the average value of number chosen between 0 and infinity, for example. reply addaon 13 hours agorootparent> and is an integerHow could a median prime factor not be an integer? reply nextaccountic 12 hours agorootparentThe median value of [1, 2, 3, 4] is 2.5 reply CrazyStat 6 hours agorootparentBut the median of [1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 4] is 2. As the individuals observed values collect more and more repetitions—as they do when making a list of the second prime factor, for example—it becomes increasingly unlikely that the median will be between two values, not equal to one of the values.It would be surprising if the median second prime factor was not a prime. reply andrewflnr 8 hours agorootparentprevThat&#x27;s the mean. reply saagarjha 8 hours agorootparentAnd it’s also the median. reply necovek 5 hours agorootparentDepends if you are looking at a mean closed to integers or not: one can define a mean without rational or real numbers. reply addaon 11 hours agorootparentprevSure, but 2 is the only even prime, so this is super constrained. reply tedunangst 11 hours agorootparentprevBut it&#x27;s not an integer before rounding. 37 is simply the nearest number to get approximately 50%. reply bandrami 8 hours agoparentprevI love that there could never be a least interesting natural number, because that fact would be interesting. In fact there can be no uninteresting natural numbers, because then you could list them, and the lowest one would be interesting for that fact. reply hurryer 13 hours agoparentprev17 is well known as the most random number between 1 and 20. reply layer8 12 hours agoparentprev37 is also the smallest base (or second int argument) not supported by itoa(). Surely not a coincidence. ;) reply rbonvall 11 hours agorootparentIt&#x27;s because the characters in the result can be one of 10 digits or one of 26 letters. reply resource0x 13 hours agoparentprevPrime numbers are not especially interesting. E.g. all groups of prime size are cyclic. But each composite number has its own \"character\". The \"interesting\" number among primes is 2. Almost every theorem about prime numbers has to consider 2 as a special case. reply 8bitsrule 4 hours agorootparentExcept that it&#x27;s interesting that prime numbers have led inordinate numbers of individuals to devote uncountable but significants chunks of their lives investigating them.It&#x27;s not their fault that they&#x27;re leftovers when an artificial grid is created by crossing-out every multiple of 2, 3, 5, or other prime numbers. Yet for some reason this seems to give them a fascinating aura for many. Maybe naming them &#x27;prime&#x27; instead of &#x27;leftover&#x27; is to blame. reply joewferrara 11 hours agoparentprevEvery prime is odd and 2 is the oddest of them all! reply doubloon 10 hours agoparentprevwhat is interesting to me is that we call imaginary integer numbers \"Gaussian Integers\", but we call the quaternion integer numbers \"Hurwitz Quaternions\" instead of \"Hurwitz Integers\". reply jvalencia 13 hours agoparentprevI love the number 27 3^3 2+7 = 3+3+3 reply joseluis 47 minutes agorootparentVery pretty. And to relate it somewhat to the topic: 1&#x2F;27 = 0.037 repeating 037 and 1&#x2F;37 = 0.027 repeating 027 :) reply mort96 12 hours agoparentprevThe most interesting integer out there must certainly be the least interesting integer! reply klyrs 11 hours agoparentprevTwo is the oddest prime. reply paulddraper 14 hours agoparentprev12Smallest abundant number reply kmoser 11 hours agorootparent12 is also the largest one-syllable number (at least in English). reply swayvil 14 hours agoparentprevI nominate 120 as \"most interesting integer\". For obvious reasons. reply AnimalMuppet 14 hours agorootparentUm, it&#x27;s not obvious to me. Could you specify? reply InfamousRece 13 hours agorootparentThe smallest triply perfect number? https:&#x2F;&#x2F;oeis.org&#x2F;A005820 reply swayvil 13 hours agorootparentprevSo many factors in such a small package, for one. reply goodmachine 3 hours agorootparent120 - or twelfty to friends - is a delight.\"The long hundred, also known as the great hundred or twelfty,[is the number 120 (in base-10 Hindu-Arabic numerals) that was referred to as hund, hund-teontig, hundrað, hundrath, or hundred in Germanic languages prior to the 15th century, and is now known as one hundred twenty, or six score.\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Long_hundred\"120 is highly composite, superior highly composite, superabundant,[3] and colossally abundant. With sixteen divisors, 120 is the smallest number to have that many divisors...\"https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;120_(number) replyabbaselmas 2 hours agoparentprevSheldon Cooper, the best number 73 (21st prime number), its mirror 37 (12th prime number)https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=HacqfsV7ug0 reply abbaselmas 2 hours agoparentAlso deep dive in the 73 and 37 https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=4DQndnAhdxk reply hoseja 1 hour agoparentprevI really dislike base-10 tricks. They are just cute, rarely have any deeper significance. reply magneticnorth 9 hours agoparentprevLove it when an article so clearly explains the answer to my first burning question - in this case, \"How in the world do you prove that?\" reply mcv 2 hours agoparentprevI once heard of a (tongue-in-cheek) list of interesting facts about numbers, and I think it listed 37 as the first uninteresting number, but I guess that was wrong. reply raghus 13 hours agoparentprevInterestingly, 37 also shows up in the Optimal Stopping &#x2F; Secretary Problem. reply Someone 13 hours agoparentI don’t know that problem and don’t feel like googling it, but it’s a reasonable guess that’s because 1&#x2F;e ≈ 0.36787944 reply drhagen 9 hours agorootparentThat seems unlikely. Those numbers only look related in base 10. 1&#x2F;e is about a third of 1 and 37 is about a third of 100, which is why they look similar in base 10. In base 16, 1&#x2F;e is about 0.5e2d58 and 37 is 25.And prime numbers are prime numbers regardless of base. reply gowld 6 hours agorootparentThat&#x27;s what PP was saying, in not so many words. reply Biganon 4 hours agorootparentprevAnd thanks to 1&#x2F;e being 0.367, in Pokemon Go when I catch 1000 Pokemon and each of them has a 1 in 1000 chance of being shiny, I have a 36.7% chance of having zero shinies among them, or approximately a 63% chance of the reciprocate, AKA having at least 1 shiny among them.1000 is arbitrary of course, but the bigger the number the closer to 1&#x2F;e.See \"Bernoulli trials\" reply skykooler 8 hours agoparentprevIt&#x27;s also the most common number picked when people are asked to think of a random number between 1 and 100. reply nathanfig 13 hours agoparentprevWas just about to comment this. Wonder if anyone more mathematically inclined can see a relationship. reply joewferrara 11 hours agoparentprevAmazing how simple the proof is. 37 is my new favorite prime number, haha. reply lvass 11 hours agoparentprev>0.000000000000000 of numbers have 2 as their second primeIs the article title correct without explicitly mentioning \"non-repeating\"? reply mauricioc 3 hours agoparentAn important part of reading mathematics is mentally filling in the \"correct\" interpretation for terms. The optimal amount of detail typically depends on the target audience. Part of that is because making notation fully specified in English is typically cumbersome: If they had written \"as their second non-repeating prime\", someone could come along saying \"shouldn&#x27;t it say &#x27;second-smallest&#x27; or &#x27;in increasing order&#x27; as well?\". In papers, the use of such terms would typically be accompanied by a formal definition using more precise (but not fully precise, see the talk below) mathematical notation.I mention this not to be pedantic, but because inferring the \"invisible\" part of mathematics (when it can be done) instead of asking humans to do it explicitly tends to be a big usability improvement in theorem provers. Andrej Bauer has a nice talk about it at https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=wZSvuCJBaFU reply kccqzy 6 hours agoparentprevGood nitpick. If you allow repeating primes, then the numbers with 2 as their second prime would be multiples of 4. So a quarter of numbers. reply tgv 1 hour agorootparentAnd the number of 2s (and 3s) would grow hard, which not favor a finite median. reply p0w3n3d 11 hours agoparentprevAlef 0 numbers have 2 as their second prime reply sophiebits 9 hours agoparentprevThe factors of 12 are 1, 2, 3, 4, 6, 12.The prime factors of 12 are 2, 3. reply spokeonawheel 4 hours agoparentprevgiven this knowledge, does this have implications that RSA would twice as crackable? Given casting a wide net, you could assume one of the prime factors is 37 and just try it against the pub key reply NooneAtAll3 13 hours agoparentprev> If we write p_k for the median k-th prime, then they show: log log p_k = ...is this natural log or some base?why not to use ln to keep ambiguity out? reply ravi-delia 13 hours agoparentIn analytic number theory we usually only care about growth rates in a very coarse sense- up to scaling by some constant, and asymptotically. Because the log of any base is precisely the same up to constants, it doesn&#x27;t actually matter. If you look at the expression, to the right of the equals sign is a big O- that&#x27;s the same big O as the one you might be familiar with in complexity.That being said, in math more generally when we need a concrete log the natural log is pretty much always the way to go- I haven&#x27;t seen ln in a little while. reply danielam 13 hours agorootparent> Because the log of any base is precisely the same up to constantsi.e., \\log_{b_1} n = \\frac{1}{\\log_{b_2} b_1} \\log_{b_2} nwhere \\frac{1}{\\log_{b_2} b_1}is the constant fixed for a given choice of `b_1` and `b_2`, i.e., the bases. reply nikhilsimha 12 hours agoparentprevThis is one of the best articles I have read in a long long time! reply whatever1 7 hours agoparentprevQuestion, has anyone tried Transformer networks for predicting prime numbers? reply matteoraso 7 hours agoparentThat would be an incredibly expensive way of generating prime numbers, far more expensive than just checking to see if it has any factors. reply zmgsabst 9 hours agoparentprevCoincidentally, 37 is also the first irregular prime. They’re why Fermat’s last theorem is hard.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Regular_prime reply falseprofit 10 hours agoparentprev2.5, the median value for the first prime factor of an integer reply owl57 9 hours agoparentProbably not. We are talking about some function of first N numbers and its limit when N approaches infinity. There is more than one reasonable way to clarify \"first prime factor\" and \"first N numbers\", but I think for all of these reasonable definitions the median diverges, having different subsequential limits for even and odd values of N. reply falseprofit 9 hours agorootparentI&#x27;m taking the median of the limiting distribution, and I agree that the sequence of medians you describe does not converge. reply gowld 6 hours agoparentprevHow so?1 has no first prime factor so must be excluded along with 0. 2 is always >=50% of the head sequences of the rest:2 3 2 5 2 7 ... reply Obscurity4340 14 hours agoparentprevWhat is the association between good passwords and prime numbers? reply politelemon 13 hours agoparentThere shouldn&#x27;t be a direct association, are you referring to something specific? Choosing a good password is about making it less predictable.Prime numbers do factor into cryptography though, they use prime numbers for key generation and key exchange. reply quickthrower2 12 hours agorootparentBut don&#x27;t use a prime number as your password ;-) reply spokeonawheel 4 hours agoparentprevthere is no such thing as a good password. I have heard of good SSO&#x27;s though reply mbfg 13 hours agoparentprevisn&#x27;t 37 the solution to the toilet problem, as well? i&#x27;m supposing the two problems are related. reply User3456335 12 hours agoparentIt&#x27;s very unlikely that they are related. 1&#x2F;e which is approximately 0.37 is the solution to the problem you&#x27;re referring to but the occurrence of 37 depends on the choice of base. It just happens to be the case that in base 10 we find that round(1&#x2F;e*10^2)=37 but it would be different in other bases.Meanwhile, the median value for the second prime is completely independent of the choice of base. reply XorNot 7 hours agoparentprevWell, this is just in time for a few birthday card ideas... reply yieldcrv 14 hours agoparentprevwhy is this kind of thing interesting? my undergrad math teachers were never able to convey thatis there something here to use this knowledge with? like cracking a lotto’s RNG by knowing a second prime probability? that would be interesting to me reply Tyr42 13 hours agoparentI thought it&#x27;d be infinite or something. So it&#x27;s cool to know it exists and it&#x27;s not 1, 2 or infinity. reply Someone 13 hours agoparentprevI don’t think this is _that_ interesting because the probabilities don’t add up to exactly 50%.We have:- the smallest prime factor of less than half of all integers is ≤ 31- the smallest prime factor of over half of all integers is ≤ 37So, clearly, the prime p where exactly half of all integers have something ≤ p as their smallest prime factor must lie between 31 and 37 :-)Alternatively, one could argue such a prime doesn’t exist. That, I think, is the better answer.That doesn’t imply there’s no good definition of that median, though because it’s 100% acceptable to have a set of numbers whose median is not an element of that set. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Median#Finite_data_set_of_numb...:“If the data set has an even number of observations, there is no distinct middle value and the median is usually defined to be the arithmetic mean of the two middle values.[1][2] For example, this data set of 8 numbers1, 2, 3, 4, 5, 6, 8, 9 has a median value of 4.5”So i guess the hunt still is on for a good argument as to why a non-prime such as 36 or even a real such as 36.716… should be called the median of the smallest prime factors of all integers (I wouldn’t know whether that exists) reply LegionMammal978 11 hours agorootparentAs the author says, this isn&#x27;t the median of any particular data set, but the limit of the median as the number of points goes to infinity:> \"Obvoiusly\" there&#x27;s no uniform distribution on the natural numbers, so what does it even mean to choose a \"random\" one? The way the number theorists usually solve this problem is by fixing a large number N and looking at the probabilities when you pick a random number between 1 and N. Then you look at the N → ∞ limit of these probabilities.And by using the λ₂(p) function, we can find the asymptotic proportion that each prime p appears in the data set: if the set has N items, then approximately λ₂(p)·N of them will be equal to p, and the actual number will asymptotically approach this approximation. Given this, we can look at the set in terms of the proportions of its elements. We have first, P(p37) = 1 − P(pMichael Redmond noted that AlphaGo&#x27;s 19th stone (move 37) was \"creative\" and \"unique\". It was a move that no human would&#x27;ve ever made Lee took an unusually long time to respond to the move. An Younggil called AlphaGo&#x27;s move 37 \"a rare and intriguing shoulder hit\" but said Lee&#x27;s counter was \"exquisite\". He stated that control passed between the players several times before the endgame, and especially praised AlphaGo&#x27;s moves 151, 157, and 159, calling them \"brilliant\".https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;AlphaGo_versus_Lee_Sedol reply lifeisstillgood 13 hours agoparentprevforgive my lack of maths to support the intuition, but as we discover ever higher prime numbers the second factor will tend upwards - towards the correct answer of 42? reply olejorgenb 13 hours agoparentNo, this is not an empirical result. The interesting thing is that this is a fixed number (and that it&#x27;s quite small). (\"After all, about half of *all* integers have 2 as their smallest prime factor\" is the beginning of the intuition needed I guess) reply NooneAtAll3 13 hours agoparentprevit&#x27;s more that when you filter out 37-and-below, the \"rest\" category as a whole takes ~50% of the numbers reply mbfg 13 hours agoparentprevnothing worse then when a good joke goes unnoticed. reply narinxas 12 hours agorootparentthe tears of clowns... reply narinxas 12 hours agoparentprev42 must mean both 41 and 43 taken together. these two primes are a twin prime above 37. and 29 and 31 both take together mean 30. the twin pair below 37 reply fuzztester 12 hours agoparentprevSee:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;37_(number)Also see:https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;1https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;2https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;3etc.Lots of interesting points in those, and not just about math reply spokeonawheel 4 hours agoparentI find it very odd that wikipedia exists up to and including 11, but then does not exist at 12. Any reason for this? reply zelda-mazzy 14 hours agoparentprev [–] It was a bit difficult to grasp at first, but it clicked after realizing it&#x27;s all primes up to 37, not just 37. Kind of a neat fact, and I enjoyed reading this. Thanks for posting! reply kstrauser 14 hours agoparentI don&#x27;t think that&#x27;s right. My reading of it was that 37 is the median prime among all primes. reply gattilorenz 14 hours agorootparentI think you’re both expressing the same concept :)37 is the median factor, it doesn’t mean that 37 is the actual second prime of 50% of numbers. The OP probably missed “median”, I know I did reply twelvechairs 14 hours agorootparentOriginal comment said \"all primes up to 37\" which isn&#x27;t correct there&#x27;s no point where 37 is being used as an upper limit reply gattilorenz 13 hours agorootparentI think that was an intuitive and imprecise way of expressing “median value”, so that 50% of primes are “up to 37” reply zelda-mazzy 8 hours agorootparentprevIm going off what the article originally said:\"We see that 37 is the prime where roughly half of all numbers have something less than or equal to 37 as their first prime! So we’ve proven that 37 is the median second prime!\" reply NooneAtAll3 13 hours agorootparentprevdid the title change or smth? reply Dylan16807 13 hours agoparentprev [–] > it&#x27;s all primes up to 37Can you elaborate on \"it\" in this sentence? What is \"all primes up to 37\", when you phrase things in an easier to understand way?I can&#x27;t tell if you&#x27;re suggesting the word median is being used in a misleading way? But it&#x27;s basically the definition of \"median 37\" that half your numbers are \"up to 37\". reply zelda-mazzy 8 hours agorootparent [–] I admit I read it wrong at first, but it made sense to me at the end of the article. So I don&#x27;t believe median was misleading. My initial thought was, as numbers get larger and larger, the chance that the second most common prime factor is 37 so 50%, which didn&#x27;t make sense because of how common 3 and 5 are. By the end I realized the function is taking into account the range of prime factors as an aggregate.Now I understand that with enough composite numbers, the chance that their second prime factor is 37 OR BELOW converges to 50%, which is pretty neat. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The book \"Those Fascinating Numbers\" highlights an intriguing fact in the preface about the median value for the second prime factor of an integer being 37.",
      "After initial skepticism, the author wrote Sage code to test the fact and confirmed that around half of all numbers have a second prime factor smaller than 37.",
      "The post suggests additional exercises related to prime factors and mentions a research paper about the distribution of prime factors and the asymptotics of the median kth prime in French."
    ],
    "commentSummary": [
      "The discussion revolves around exploring the properties and significance of numbers like 37, 0, and 1.",
      "Participants debate the concept of what makes a number interesting and delve into mathematical principles and relationships related to these numbers.",
      "Topics covered include prime factorizations, divisors, base-10 tricks, prime numbers, and triangular numbers."
    ],
    "points": 389,
    "commentCount": 179,
    "retryCount": 0,
    "time": 1699814748
  },
  {
    "id": 38240861,
    "title": "Idlethumbs.social: A Decentralized Social Network Powered by Mastodon",
    "originLink": "https://idlethumbs.social/@ja2ke/111396017651485944",
    "originBody": "Create accountLogin Recent searches No recent searches Search options has: media, poll, or embedis: reply or sensitivelanguage: ISO language codefrom: userbefore: specific dateduring: specific dateafter: specific datein: all or library idlethumbs.social is part of the decentralized social network powered by Mastodon. Administered by: Server stats: Learn more idlethumbs.social: About · Profiles directory · Privacy policy Mastodon: About · Get the app · Keyboard shortcuts · View source code · v4.2.1 ExploreLive feeds Login to follow profiles or hashtags, favorite, share and reply to posts. You can also interact from your account on a different server. Create accountLogin About",
    "commentLink": "https://news.ycombinator.com/item?id=38240861",
    "commentBody": "The Steam Deck OLED spot ad was made with Steam Deck OLEDsHacker NewspastloginThe Steam Deck OLED spot ad was made with Steam Deck OLEDs (idlethumbs.social) 388 points by neffo 19 hours ago| hidepastfavorite59 comments bigyikes 15 hours agoparentGorgeous! It&#x27;s a shame that CGI is so prevalent, because without context I would totally assume this was CGI. Some of the shots would fit right in with a Portal cutscene.Imagine playing on the one in the center of the orb. It&#x27;s the ultimate Steam Deck gaming throne. reply pdpi 13 hours agoparent> Some of the shots would fit right in with a Portal cutscene.The music really helps sell that idea. reply JCharante 15 hours agoparentprevThis is awesome. Video production just takes so many hours for each second and I don&#x27;t think people know how much work it takes until you help out on a shoot. reply Satam 7 hours agoparentIt&#x27;s why AI-generated movie shots would make a lot of sense. Hollywood spends billions of dollars, builds and blows up elaborate sets, and hires 100,000s of thousands of people... just to be able to have pixels move in a pleasing way. How much of that will be cut out when we just go straight to generating pixels? CGI goes in that general direction but it&#x27;s still very labor intensive. reply mplewis 2 hours agorootparentNo. reply sph 2 hours agorootparentprevCalm down, Satam.Unless that&#x27;s satire. But I&#x27;m not sure it is. reply iamflimflam1 15 hours agoparentprevI do a lot of YouTubing and the consensus is that every minute of video takes at least 1 hour of work - and this is just amateurs messing around. reply ancientworldnow 12 hours agorootparentIn the pro world it&#x27;s common for one person to spend hours on seconds, multiplied over dozens of people working on those same seconds. reply tomcam 12 hours agoparentprevWhen I see things like that I always think about their lifecycle. The frame will be stripped of the devices for another display. It&#x27;ll still hang around in some honored spot, then they&#x27;ll get new staff and it will be shunted into storage. In 3 years it will be disassembled and tossed into the dumpster because no one will have room for it at home. reply throwaway-432 10 hours agoparentI work for a company which has made a huge satellite constellation and after a revision of a hardware component has run its course thousands have made their way to space, incomplete&#x2F;failing units are shredded, and only a handful are kept. When the satellites eventually burn up in the atmosphere those ~3 builds are all that remain of the entire project, thousands of man-hours to engineer and build hardware that the world will never see. I think about those few survivors a lot. reply tomcam 5 hours agorootparentOh the pain reply Fatnino 7 hours agorootparentprevWe know you&#x27;re talking about spacex reply ip26 8 hours agoparentprevProps, acts and jigs are always like this. In reality, a small metal structure like this is not really so precious that it need be cherished or repurposed. Metal is very recyclable. It’s function was brief in time, but relatively high in impact. reply idontknowifican 10 hours agoparentprevis there something inherently bad in this? do you feel something is lost? reply tomcam 5 hours agorootparentI do feel a twinge sometimes. I tend to get a bit too sentimental about artifacts. reply extraduder_ire 13 hours agoparentprevI love how each of the decks being a proper computer made this much easier to pull off. Like, driving a display in a dummy device would probably get you the same effect, and take longer. But that&#x27;s likely the route a third-party production company would take. reply smusamashah 9 hours agoparentprevOn the note of OLED increasing battery life, does anyone know the max number of hours of gameplay you can get on a single charge when the game is as simple as \"snake\"?I have searched for answers on reddit and Google etc but I have only found the number to be 8hrs which is not for low power games. Given steam runs Linux and is hacker friendly, one should be able to juice it for much much longer if only early retro games are played. reply chucky_z 9 hours agoparent8hr sounds accurate. There’s a wattage slider and you can only set it so low. You might be able to get more out of using the desktop and forcing some idle modes, however it’s impressive enough as is at a few watts and many hours on a portable Linux machine occupying less total space than a 13” laptop. reply gumballindie 15 hours agoparentprevI am continuously amazed at how awesome valve is and what awesome products it makes. Also steam supporting linux single handedly advanced adoption of that os. Apparently the best types of companies are those founded by deeply technical people, still owned and run by them, no venture capital. In an ideal world we would favour such companies over toxic ones. reply depr 13 hours agoparentWithout taking away from the great things they are also doing, I&#x27;m mostly amazed at how bad and laggy the Steam app is, and has been for years, on all 3 platforms I&#x27;ve used it on.(I&#x27;m sure there are loads of people who have never had any issues but to me that&#x27;s like people saying there are no problems with Linux on the desktop because they don&#x27;t have any problems.) reply gumballindie 12 hours agorootparentIt could be improved yes, but that’s an acceptable kind of issues. Steam’s important functionality works well and is reliable - package management for games. It doesnt spy on me, doesn&#x27;t push crap, doesnt use dark patterns. We need more apps like steam tbh. reply randyrand 13 hours agoparentprevAnd they only take a 30% cut! Practically altruism. reply mey 6 hours agorootparentWhat is an acceptable fee structure for the service they provide? reply gumballindie 12 hours agorootparentprevThat’s messed up indeed. reply sph 2 hours agorootparentThey should do like everybody else, take 30% cut and NOT improve Linux. reply charcircuit 13 hours agoparentprev>Also steam supporting linux single handedly advanced adoption of that os.Android using Linux is what single handily advanced the adoption of Linux among consumers. reply fckthisguy 13 hours agorootparentAdoption on desktop is 100% more related to Steam support, at least in the gaming segment.Anecdotally, among friends and colleagues, people are only staying with Windows for gaming support.People generally dislike Windows but are forced to stay their for gaming. As support for Linux improves, they&#x27;ll be less willing to put up with Windows&#x27; BS. reply redundantly 13 hours agorootparentprevSaying Android is Linux is like saying macOS is BSD. reply rstat1 12 hours agorootparentNo it isn&#x27;t.Android is as much a Linux distro as any other. reply eptcyka 11 hours agorootparentAndroid is a Linux distribution unlike any other. They use a completely different framework for drivers for hardware, they have their own patches for binder and other things that see no use outside of Android and will never get upstreamed. They have their own libc which is not used in any other distro. Very little of the work that has been done to make Linux work better on Androids has benefited the rest of the Linux ecosystem. Even the WiFi&#x2F;Bluetooth drivers, which is a massive shame. reply charcircuit 9 hours agorootparent>They use a completely different framework for drivers for hardwareNo, both use kernel modules or statically compiled code for the part of the driver that actually talk to the hardware.>they have their own patches for binderBinder is part of mainline Linux, but yes I guess technically there are some patches that are related to binder, but remember that Android works on a mainline kernel. reply Krssst 11 hours agorootparentprevAndroid uses the Linux kernel and keeps up with upstream to some extent.macOS uses the XNU kernel.Though as a user that likes having control over the software, I recognize that not having GNU&#x2F;Linux being number one is a bit of a waste. (though one weekend of fighting NVIDIA and wayland tamed that quite a bit. Somehow my DE does not load with the proprietary driver unless I also load nouveau for some strange reason). reply charcircuit 9 hours agorootparentAndroid uses the latest LTS kernel and works using a mainline kernel provided mainline supports the hardware you are on.>though one weekend of fighting NVIDIA and waylandWayland is freedesktop software which is different than GNU. reply wiseowise 13 hours agorootparentprevNot as a desktop. reply HellsMaddy 8 hours agoparentprevNorm from Tested has a short vid on Twitter of him in the sphere:https:&#x2F;&#x2F;twitter.com&#x2F;nchan&#x2F;status&#x2F;1722688222713749881 reply thih9 3 hours agoparentprevPart of me thinks this crazy, the other part wants to see this running doom with 360 vision. reply FirmwareBurner 15 hours agoparentprevDo we know who&#x27;s the supplier of the OLED panel? Samnang? LG? BOE? reply Philpax 15 hours agoparentSamsung, but BOE may be dual-supplying it: https:&#x2F;&#x2F;twitter.com&#x2F;SadlyItsBradley&#x2F;status&#x2F;17227592388066431... reply PrivateButts 15 hours agoparentprevLast I heard, it&#x27;s the same supplier as the Switch OLED; that&#x27;s why it uses MIPI over eDP. Samsung is the manufacturer I think reply Hamuko 15 hours agorootparentThat&#x27;s what I&#x27;ve heard too. And yeah, Samsung makes the Switch&#x27;s panel according to iFixit&#x27;s teardown.https:&#x2F;&#x2F;www.ifixit.com&#x2F;News&#x2F;53272&#x2F;nintendo-switch-oled-teard... reply pests 15 hours agorootparent(GP)> \"same supplier as the Switch OLED\"> That&#x27;s what I&#x27;ve heard tooIs any of this confirmed or just rumor from the LTT video? reply smileybarry 13 hours agorootparentThe other comment chain (2 levels above but in the same first-level thread) links to this tweet with a code screenshot that seems to confirm it: https:&#x2F;&#x2F;twitter.com&#x2F;SadlyItsBradley&#x2F;status&#x2F;17227592388066431... if ((vendor_product->product == GALILEO_SDC_PID) || (vendor_product->product == GELILEO_BOE_PID)) { &#x2F;&#x2F; ...I&#x27;m assuming SDC (\"GALILEO_SDC_PID\") is Samsung Display [Corp?] (a search seems to confirm that&#x27;s their acronym). replykaraterobot 12 hours agoparentprevI got pretty excited that it was Jake Rodkin posting this on something with the Idle Thumbs name. reply pawelduda 15 hours agoparentprevUltra-bright means higher burn-in risk, or am I wrong on this one?Edit: thanks for clarifying reply upon_drumhead 15 hours agoparentOnly if you drive the display at the top end. If you end up driving in the middle, it helps prevent burn in> By counting the time each subpixel is displayed and at what brightness, a \"wear level\" can be determined for each pixel, using an algorithm to estimate the luminance degradation this can be compensated for. However, to do this, you must have some spare luminance headroom that gets utilized as the display gets older. Or alternatively, if the display unlocks full maximum luminance when new without saving any headroom, the algorithm would dim the other pixels over time to bring them down to the level of the burned-in pixels, so the peak luminance of the display would diminish over time as the burn-in occurs.https:&#x2F;&#x2F;arstechnica.com&#x2F;gadgets&#x2F;2023&#x2F;11&#x2F;why-oled-monitor-bur... reply MaximilianEmel 14 hours agorootparentDo we know if the steam deck has this feature? reply SXX 15 hours agoparentprevFortunately in case of Steam Deck it&#x27;s possible to replace screen in case this become a problem in a couple of years and new parts wont cost like a new device. reply eloisant 15 hours agorootparentI hope replacement is easier than with the OG Steam Deck because to replace the screen you have to completely disassemble the device, heat to unglue the screen...https:&#x2F;&#x2F;www.ifixit.com&#x2F;Guide&#x2F;Steam+Deck+Screen+Replacement&#x2F;1... reply dumptruk 14 hours agorootparentIt&#x27;s one of the improvements they listed regarding repair-ability> Improved display repair&#x2F;replacement to not require taking rear cover off reply BlueTemplar 11 hours agorootparentDoes it still work as a very efficient SD card cutter though ? reply eptcyka 11 hours agorootparentIt does. reply mdhen 15 hours agorootparentprevThey have made a number of changes to makebit easier to fix, not sure about the screen though. reply Kerbonut 7 hours agorootparent> makebitI make this same mistake on iPhone all the time. Is it just me or does Apple need to step up their keyboard and autocorrect game? reply lukevp 15 hours agoparentprevBurn-in on OLEDs is really just uneven wear. I don’t think it really matters how bright they get for that, unless panel heat is an issue at higher brightnesses. reply jdiff 14 hours agorootparentHigher brightness leads to faster wear. If the wear is uneven, this leads to faster burn at higher brightness. reply bitwize 12 hours agorootparentprevBurn-in on CRTs was just uneven wear, too, but still a pain in the ass. reply macNchz 11 hours agorootparentI remember encountering CRTs burnt in so badly it was hard to read stuff in the worst areas (e.g. the taskbar clock or login prompt) but I haven’t encountered anything remotely close to that with current OLEDs. My iPhone and TV have no signs at all, and the last device I used that had legitimately easy-to-detect burn in was a Nexus One test device that sat on my desk with the screen on all day every day while I built an Android app in 2012. reply quasarj 15 hours agoparentprev [–] Damn, no call out to DeckMate by name in the thread? Sad reply jw_cook 9 hours agoparent [–] I assume that&#x27;s what \"some Steam Deck clips made by an accessory designer on Reddit\" is referring to? Going back and watching the video again, yeah, it definitely looks like Deckmate grips holding all the decks to the orb frame. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "idlethumbs.social is a decentralized social network powered by Mastodon.",
      "Users can create an account, log in, and search for media, polls, or embedded content on the platform.",
      "The platform enables interactions such as following profiles or hashtags, favoriting, sharing, and replying to posts, as well as interacting from an account on a different server. Server statistics are also available. Further information can be found on the idlethumbs.social and Mastodon websites."
    ],
    "commentSummary": [
      "The Steam Deck OLED spot ad by Valve is being praised for its resemblance to a cutscene from the game Portal, sparking discussions about video production processes and the potential for AI-generated movie shots.",
      "Valve's support for Linux and their products, including the Steam Deck, are highlighted for their contribution to the adoption of the operating system in the gaming community.",
      "Other topics of discussion include the fee structure and potential improvements for the Steam app, different kernels in operating systems, the OLED panel supplier for the Steam Deck, burn-in risks, repairability, and the DeckMate accessory designed specifically for the Steam Deck."
    ],
    "points": 389,
    "commentCount": 60,
    "retryCount": 0,
    "time": 1699802441
  },
  {
    "id": 38240421,
    "title": "Accelerating AI with GPUs: A Comprehensive Toolkit for the AI Age",
    "originLink": "https://journal.hexmos.com/gpu-survival-toolkit/",
    "originBody": "Featured GPU Survival Toolkit for the AI age: The bare minimum every developer must know Rijul Rajesh Nov 12, 2023 • 14 min read Table of Contents Why CPU Knowledge Is No Longer Enough Executing Parallel Tasks Running AI Models Efficiently How GPU Driven Development Solves These Issues CPUs Vs GPUs: What’s the Difference? CPU GPU AWS GPU Instances: A Beginner's Guide Using Nvidia's CUDA for GPU-Driven Development What Is Cuda? How to Setup Cuda on Your Machine Basic Commands to Use Get Started with the Cuda Framework Array Addition Problem Optimize Image Generation in Python Using the GPU Training a Cat VS Dog Neural Network Using the GPU Conclusion Reference Why CPU Knowledge Is No Longer Enough In today's AI age, the majority of developers train in the CPU way. This knowledge has been part of our academics as well, so it's obvious to think and problem-solve in a CPU-oriented way. However, the problem with CPUs is that they rely on a sequential architecture. In today's world, where we are dependent on numerous parallel tasks, CPUs are unable to work well in these scenarios. Some problems faced by developers include: Executing Parallel Tasks CPUs traditionally operate linearly, executing one instruction at a time. This limitation stems from the fact that CPUs typically feature a few powerful cores optimized for single-threaded performance. When faced with multiple tasks, a CPU allocates its resources to address each task one after the other, leading to a sequential execution of instructions. This approach becomes inefficient in scenarios where numerous tasks need simultaneous attention. While we make efforts to enhance CPU performance through techniques like multi-threading, the fundamental design philosophy of CPUs prioritizes sequential execution. Running AI Models Efficiently AI models, employing advanced architectures like transformers, leverage parallel processing to enhance performance. Unlike older recurrent neural networks (RNNs) that operate sequentially, modern transformers such as GPT can concurrently process multiple words, increasing efficiency and capability in training. Because when we train in parallel, it will result in bigger models, and bigger models will yield better outputs. The concept of parallelism extends beyond natural language processing to other domains like image recognition. For instance, AlexNet, an architecture in image recognition, demonstrates the power of parallel processing by processing different parts of an image simultaneously, allowing for accurate pattern identification. However, CPUs, designed with a focus on single-threaded performance, struggle to fully exploit parallel processing potential. They face difficulties efficiently distributing and executing the numerous parallel computations required for intricate AI models. As a result, the development of GPUs has become prevalent to address the specific needs of parallel processing in AI applications, unlocking higher efficiency and faster computation. How GPU Driven Development Solves These Issues Massive Parallelism With GPU Cores Engineers design GPUs with smaller, highly specialized cores compared to the larger, more powerful cores found in CPUs. This architecture allows GPUs to execute a multitude of parallel tasks simultaneously. The high number of cores in a GPU are well-suited for workloads depending on parallelism, such as graphics rendering and complex mathematical computations. We will soon demonstrate how using GPU parallelism can reduce the time taken for complex tasks. Parallelism Used In AI Models AI models, particularly those built on deep learning frameworks like TensorFlow, exhibit a high degree of parallelism. Neural network training involves numerous matrix operations, and GPUs, with their expansive core count, excel in parallelizing these operations. TensorFlow, along with other popular deep learning frameworks, optimizes to leverage GPU power for accelerating model training and inference. We will show a demo soon how to train a neural network using the power of the GPU. CPUs Vs GPUs: What’s the Difference? CPU Sequential Architecture Central Processing Units (CPUs) are designed with a focus on sequential processing. They excel at executing a single set of instructions linearly. CPUs are optimized for tasks that require high single-threaded performance, such as General-purpose computing System operations Handling complex algorithms that involve conditional branching Limited Cores For Parallel Tasks CPUs feature a smaller number of cores, often in the range of 2-16 cores in consumer-grade processors. Each core is capable of handling its own set of instructions independently. GPU Parallelized Architecture Graphics Processing Units (GPUs) are designed with a parallel architecture, making them highly efficient for parallel processing tasks. This is beneficial for Rendering graphics Performing complex mathematical calculations Running parallelizable algorithms GPUs handle multiple tasks simultaneously by breaking them into smaller, parallel sub-tasks. Thousands Of Cores For Parallel Tasks Unlike CPUs, GPUs boast a significantly larger number of cores, often numbering in the thousands. These cores are organized into streaming multiprocessors (SMs) or similar structures. The abundance of cores allows GPUs to process a massive amount of data concurrently, making them well-suited for parallelisable tasks, such as image and video processing, deep learning, and scientific simulations. AWS GPU Instances: A Beginner's Guide Amazon Web Services (AWS) offers a variety of GPU instances used for things like machine learning. Here are the different types of AWS GPU instances and their use cases: General-Purpose Gpu Instances P3 and P4 instances serve as versatile general-purpose GPU instances, well-suited for a broad spectrum of workloads. These include machine learning training and inference, image processing, and video encoding. Their balanced capabilities make them a solid choice for diverse computational tasks. Pricing: The p3.2xlarge instance costs $3.06 per hour. This provides 1 NVIDIA Tesla V100 GPU of 16 GB GPU memory Inference-optimized GPU instances Inference is the process of running live data through a trained AI model to make a prediction or solve a task. P5 and Inf1 instances specifically cater to machine learning inference, excelling in scenarios where low latency and cost efficiency are essential. Pricing: the p5.48xlarge instance costs $98.32 per hour. This provides 8 NVIDIA H100 GPUs of 80 GB memory each, totalling upto 640 GB Video Memory. Graphics-optimized GPU instances G4 instances instances are engineered to handle graphics-intensive tasks. A video game developer might use a G4 instance to render 3D graphics for a video game. Pricing: g4dn.xlarge costs $0.526 to run per hour. Uses 1 NVIDIA T4 GPU of 16 GB Memory. Managed GPU Instances Amazon SageMaker is a managed service for machine learning. It provides access to a variety of GPU-powered instances, including P3, P4, and P5 instances. SageMaker is a good choice for organizations that wants to begin machine learning easily without having to manage the underlying infrastructure. Pricing of Amazon Sagemaker Using Nvidia's CUDA for GPU-Driven Development What Is Cuda? CUDA is a parallel computing platform and programming model developed by NVIDIA, enabling developers to accelerate their applications by harnessing the power of GPU accelerators. The Practical examples in the demo will use CUDA. How to Setup Cuda on Your Machine To setup CUDA on your machine you can follow these steps. Download CUDA From the above link download the base installer as well as the driver installer Go to .bashrc in home folder Add the following lines below export PATH=\"/usr/local/cuda-12.3/bin:$PATH\" export LD_LIBRARY_PATH=\"/usr/local/cuda-12.3/lib64:$LD_LIBRARY_PATH\" Execute the following commands sudo apt-get install cuda-toolkit sudo apt-get install nvidia-gds Reboot the system for the changes to take effect Basic Commands to Use Once you have CUDA installed, here are some helpful commands. lspcigrep VGA The purpose of this command is to identify and list the GPUs in your system. nvidia-smi It stands for \"NVIDIA System Management Interface\" It provides detailed information about the NVIDIA GPUs in your system, including utilization, temperature, memory usage and more. sudo lshw -C display The purpose is to provide detailed information about the display controllers in your system, including graphics cards. inxi -G This command provides information about the graphics subsystem, including details about the GPU and the display. sudo hwinfo --gfxcard Its purpose is to obtain detailed information about the graphics cards in your system. Get Started with the Cuda Framework As we have installed the CUDA Framework, let's start executing operations that showcases its functionality. Array Addition Problem A suitable problem to demonstrate the parallelization of GPUs is the Array addition problem. Consider the following arrays: Array A = [1,2,3,4,5,6] Array B = [7,8,9,10,11,12] We need to store the sum of each element and store it in Array C. Like C = [1+7,2+8,3+9,4+10,5+11,6+12] = [8,10,12,14,16,18] If the CPU is to execute such operation, it would be executing the operation like the below code. #includeint a[] = {1,2,3,4,5,6}; int b[] = {7,8,9,10,11,12}; int c[6]; int main() { int N = 6; // Number of elements for (int i = 0; i >> (cudaA, cudaB, cudaC); The result vector cudaC is copied from the GPU back to the host. // Copy the result vector back to the host cudaMemcpy(c, cudaC, sizeof(c), cudaMemcpyDeviceToHost); We can then print the results as usual // Print the result for (int i = 0; i = 4: return i # If within the maximum iterations, consider it part of the set return max_iters # Function to create the Mandelbrot fractal within a specified region def create_fractal(min_x, max_x, min_y, max_y, image, iters): height = image.shape[0] width = image.shape[1] # Calculate pixel sizes based on the specified region pixel_size_x = (max_x - min_x) / width pixel_size_y = (max_y - min_y) / height # Iterate over each pixel in the image and compute the Mandelbrot value for x in range(width): real = min_x + x * pixel_size_x for y in range(height): imag = min_y + y * pixel_size_y color = mandel(real, imag, iters) image[y, x] = color # Create a blank image array for the Mandelbrot set image = np.zeros((1024, 1536), dtype=np.uint8) # Record the start time for performance measurement start = timer() # Generate the Mandelbrot set within the specified region and iterations create_fractal(-2.0, 1.0, -1.0, 1.0, image, 20) # Calculate the time taken to create the Mandelbrot set dt = timer() - start # Print the time taken to generate the Mandelbrot set print(\"Mandelbrot created in %f s\" % dt) # Display the Mandelbrot set using matplotlib imshow(image) show() The above code produces the output in 4.07 seconds. To make this faster, we can parallelize the code with GPU by using Numba library, Lets see how its done. We will import Just-In-Time compilation, CUDA for GPU acceleration, and other utilities from numba import numpy as np from numba import jit, cuda, uint32, f8, uint8 from pylab import imshow, show from timeit import default_timer as timer The @jit decorator signals Numba to perform Just-In-Time compilation, translating the Python code into machine code for improved execution speed. @jit def mandel(x, y, max_iters): c = complex(x, y) z = 0.0j for i in range(max_iters): z = z*z + c if (z.real*z.real + z.imag*z.imag) >= 4: return i return max_iters mandel_gpu is a GPU-compatible version of the mandel function created using cuda.jit. This allows the mandel logic to be offloaded to the GPU. This is done by using @cuda.jit decorator along with specifying the data types (f8 for float, uint32 for unsigned integer) for the function arguments. The device=True argument indicates that this function will run on the GPU. mandel_gpu = cuda.jit((f8, f8, uint32), device=True)(mandel) The mandel_kernel function is defined to be executed on the CUDA GPU. It is responsible for parallelizing the Mandelbrot set generation across GPU threads. @cuda.jit((f8, f8, f8, f8, uint8[:,:], uint32)) def mandel_kernel(min_x, max_x, min_y, max_y, image, iters): height = image.shape[0] width = image.shape[1] pixel_size_x = (max_x - min_x) / width pixel_size_y = (max_y - min_y) / height startX, startY = cuda.grid(2) gridX = cuda.gridDim.x * cuda.blockDim.x gridY = cuda.gridDim.y * cuda.blockDim.y for x in range(startX, width, gridX): real = min_x + x * pixel_size_x for y in range(startY, height, gridY): imag = min_y + y * pixel_size_y image[y, x] = mandel_gpu(real, imag, iters) Now, we can use the GPU-accelerated Mandelbrot set generation in the create_fractal_gpu function. This function allocates GPU memory, launches the GPU kernel (mandel_kernel), and copies the result back to the CPU. def create_fractal_gpu(min_x, max_x, min_y, max_y, image, iters): # Step 1: Allocate GPU memory for the image d_image = cuda.to_device(image) # Step 2: Define the number of threads and blocks for GPU parallelization threadsperblock = (16, 16) blockspergrid_x = int(np.ceil(image.shape[1] / threadsperblock[0])) blockspergrid_y = int(np.ceil(image.shape[0] / threadsperblock[1])) blockspergrid = (blockspergrid_x, blockspergrid_y) # Step 3: Measure the starting time start = timer() # Step 4: Launch the GPU kernel (mandel_kernel) to calculate the Mandelbrot set on the GPU mandel_kernel[blockspergrid, threadsperblock](min_x, max_x, min_y, max_y, d_image, iters) # Step 5: Wait for the GPU to finish its work (synchronize) cuda.synchronize() # Step 6: Measure the time taken by GPU processing dt = timer() - start # Step 7: Copy the results back from GPU memory to the CPU d_image.copy_to_host(image) # Step 8: Display the Mandelbrot set image print(\"Mandelbrot created on GPU in %f s\" % dt) imshow(image) show() The above code gets executed in 0.0046 seconds. Which is a lot faster the CPU Based code we had earlier. Here's the full code for your reference. Training a Cat VS Dog Neural Network Using the GPU One of the hot topics we see nowadays is how GPUs are getting used in AI, So to demonstrate that we will be creating a neural network to differentiate between cats and dogs. Prerequisites CUDA Tensorflow -> Can be installed via pip install tensorflow[and-cuda] We will use a data set of cats and dogs from kaggle Once you have downloaded it, Unzip them, organize the pictures of cats and dogs in the training folder into different subfolders, Like so. This is the code we will use for training and using the Cat vs Dog Model. The below code uses a convolutional neural network, you can read more details about it Importing Libraries pandas and numpy for data manipulation. Sequential for creating a linear stack of layers in the neural network. Convolution2D, MaxPooling2D, Dense, and Flatten are layers used in building the Convolutional Neural Network (CNN). ImageDataGenerator for real-time data augmentation during training. import pandas as pd import numpy as np from keras.models import Sequential from keras.layers import Convolution2D, MaxPooling2D, Dense, Flatten from keras.preprocessing.image import ImageDataGenerator Initializing the Convolutional Neural Network classifier = Sequential() Loading the data for training train_datagen = ImageDataGenerator( rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True ) test_datagen = ImageDataGenerator(rescale=1./255) training_set = train_datagen.flow_from_directory( './training_set', target_size=(64, 64), batch_size=32, class_mode='binary' ) test_set = test_datagen.flow_from_directory( './test_set', target_size=(64, 64), batch_size=32, class_mode='binary' ) Building the CNN Architecture classifier.add(Convolution2D(32, 3, 3, input_shape=(64, 64, 3), activation='relu')) classifier.add(MaxPooling2D(pool_size=(2, 2))) classifier.add(Flatten()) classifier.add(Dense(units=128, activation='relu')) classifier.add(Dense(units=1, activation='sigmoid')) Compiling the model classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) Training the model classifier.fit(training_set, epochs=25, validation_data=test_set, validation_steps=2000) classifier.save('trained_model.h5') Once we have trained the model, The model is stored in a .h5 file using classifier.save In the below code, we will use this trained_model.h5 file to recognize cats and dogs. import numpy as np from keras.models import load_model import keras.utils as image def predict_image(imagepath, classifier): predict = image.load_img(imagepath, target_size=(64, 64)) predict_modified = image.img_to_array(predict) predict_modified = predict_modified / 255 predict_modified = np.expand_dims(predict_modified, axis=0) result = classifier.predict(predict_modified) if result[0][0] >= 0.5: prediction = 'dog' probability = result[0][0] print(\"Probability = \" + str(probability)) print(\"Prediction = \" + prediction) else: prediction = 'cat' probability = 1 - result[0][0] print(\"Probability = \" + str(probability)) print(\"Prediction = \" + prediction) # Load the trained model loaded_classifier = load_model('trained_model.h5') # Example usage dog_image = \"dog.jpg\" predict_image(dog_image, loaded_classifier) cat_image = \"cat.jpg\" predict_image(cat_image, loaded_classifier) Let's see the output Here's the full code for your reference Conclusion In the upcoming AI age, GPUs are not a thing to be ignored, We should be more aware of its capabilities. As we transition from traditional sequential algorithms to increasingly prevalent parallelized algorithms, GPUs emerge as indispensable tools that empower the acceleration of complex computations. The parallel processing prowess of GPUs is particularly advantageous in handling the massive datasets and intricate neural network architectures inherent to artificial intelligence and machine learning tasks. Furthermore, the role of GPUs extends beyond traditional machine learning domains, finding applications in scientific research, simulations, and data-intensive tasks. The parallel processing capabilities of GPUs have proven instrumental in addressing challenges across diverse fields, ranging from drug discovery and climate modelling to financial simulations. Reference Using Numba for mandelbrot generation Using Convolutional Neural Networks Hackernews post Linkedin post",
    "commentLink": "https://news.ycombinator.com/item?id=38240421",
    "commentBody": "GPU Survival Toolkit for the AI ageHacker NewspastloginGPU Survival Toolkit for the AI age (hexmos.com) 276 points by lordwiz 20 hours ago| hidepastfavorite151 comments johndough 15 hours agoparentThe code in this article is incorrect. The CUDA kernel is never called: https:&#x2F;&#x2F;github.com&#x2F;RijulTP&#x2F;GPUToolkit&#x2F;blob&#x2F;f17fec12e008d0d37...I&#x27;d also like to point out that 90 % of the time spent to \"compute\" the Mandelbrot set with the JIT-compiled code is spent on compiling the function, not on computation.If you actually want to learn something about CUDA, implementing matrix multiplication is a great exercise. Here are two tutorials:https:&#x2F;&#x2F;cnugteren.github.io&#x2F;tutorial&#x2F;pages&#x2F;page1.htmlhttps:&#x2F;&#x2F;siboehm.com&#x2F;articles&#x2F;22&#x2F;CUDA-MMM reply sevagh 14 hours agoparent>If you actually want to learn something about CUDA, implementing matrix multiplication is a great exercise.There is SAXPY (matrix math A*X+Y), purportedly ([1]) the hello world of parallel math code.>SAXPY stands for “Single-Precision A·X Plus Y”. It is a function in the standard Basic Linear Algebra Subroutines (BLAS)library. SAXPY is a combination of scalar multiplication and vector addition, and it’s very simple: it takes as input two vectors of 32-bit floats X and Y with N elements each, and a scalar value A. It multiplies each element X[i] by A and adds the result to Y[i].[1]: https:&#x2F;&#x2F;developer.nvidia.com&#x2F;blog&#x2F;six-ways-saxpy&#x2F; reply Handprint4469 15 hours agoparentprevThank you for this, comments like yours is exactly why I keep coming back to HN. reply lordwiz 6 hours agoparentprevThanks a lot for pointing it out, I have fixed the code and updated the blog. reply shortrounddev2 17 hours agoparentprevThis article claims to be something every developer must know, but it&#x27;s a discussion of how GPUs are used in AI. Most developers are not AI developers, nor do they interact with AI or use GPUs directly. Not to mention the fact that this articles barely mentions 3d graphics at all, the reason gpus exist reply oytis 15 hours agoparent> Most developers are not AI developersI remember how I joined a startup after working for a traditional embedded shop and a colleague made (friendly) fun of me for not knowing how to use curl to post a JSON request. I learned a lot since then about backend, frontend and infrastructure despite still being an embedded developer. It seems likely that people all around the industry will be in a similar position when it comes to AI in the next years. reply antifa 7 hours agorootparentMost AI work will just be APIs provided by your cloud provider in less than 2 years. Understanding what&#x27;s going on under the hood isn&#x27;t going to be that common, maybe the AI equivalent of \"use explain analyze, optimize indexes\" will be what passes for (engineering, not scientist) AI expert around that time. reply torginus 4 hours agorootparentMost things provided by your cloud cloud provider are just slightly modified and pre-packaged versions of software you can run anyway. Postgres on EC2 is a perfectly viable alternative to whatever Amazon offers. reply hhjinks 15 hours agorootparentprevWhat do you think the industry will look like in the near future? reply pixelpoet 16 hours agoparentprevNot to mention their passing example of Mandelbrot set rendering only gets a 10x speedup, despite being the absolute posterchild of FLOPs-limited computation.Terrible article IMO. reply pclmulqdq 15 hours agorootparentYou would expect at least 1000x, and that&#x27;s probably where it would be if they didn&#x27;t include JIT compile time in their time. Mandelbrot sets are a perfect example of a calculation a GPU is good at. reply lucb1e 16 hours agoparentprevOne can benefit from knowing fundamentals of an adjacent field, especially something as broadly applicable as machine learning.- You might want to use some ML in the project you are assigned next month- It can help collaborating with someone who tackles that aspect of a project- Fundamental knowledge helps you understand the \"AI\" stuff being marketed to your managerThe \"I don&#x27;t need this adjacent field\" mentality feels familiar from schools I went to: first I did system administration where my classmates didn&#x27;t care about programming because they felt like they didn&#x27;t understand it anyway and they would never need it (scripting, anyone?); then I switched to a software development school where, guess what, the kids couldn&#x27;t care about networking and they&#x27;d never need it anyway. I don&#x27;t understand it, to me it&#x27;s both interesting, but more practically: fast-forward five years and the term devops became popular in job ads.The article is 1500 words at a rough count. Average reading speed is 250wpm, but for studying something, let&#x27;s assume half of that: 1500&#x2F;125 = 12 minutes of your time. Perhaps you toy around with it a little, run the code samples, and spend two hours learning. That&#x27;s not a huge time investment. Assuming this is a good starting guide in the first place. reply mrec 15 hours agorootparentThe objection isn&#x27;t to the notion that \"One can benefit from knowing fundamentals of an adjacent field\". It&#x27;s that this is \"The bare minimum every developer must know\". That&#x27;s a much, much stronger claim.I&#x27;ve come to see this sort of clickbait headline as playing on the prevalence of imposter-syndrome insecurity among devs, and try to ignore them on general principle. reply lucb1e 14 hours agorootparentFair enough! I can kind of see the point that, if every developer knew some basics, it would help them make good decisions about their own projects, even if the answer is \"no, this doesn&#x27;t need ML\". On the other hand, you&#x27;re of course right that if you don&#x27;t use ML, then it&#x27;s clearly not something you \"must\" know to do your job well. reply sigmonsays 16 hours agoparentprevyeah a lot of assumptions were made that are inaccurate.I agree that most developers are not AI developers... OP seems to be a bit out of touch with the general population and otherwise is assuming the world around them based on their own perception. reply bigstrat2003 13 hours agoparentprevI&#x27;ve noticed that every time I see an article claiming that its subject is something \"every developer must know\", that claim is false. Maybe there are articles which contain information that everyone must know, but all I encounter is clickbait. reply BlueTemplar 13 hours agoparentprevEven worse, it says \"GPUs\", but isn&#x27;t CUDA a closed feature limited to Nvidia cards, and maybe even a subset of them ?(I&#x27;m not touching Nvidia since they don&#x27;t provide open source drivers.) reply sbmthakur 14 hours agoparentprevI would have probably opened it if it weren&#x27;t for the title bait. reply j45 15 hours agoparentprevUnderstanding now hardware is used is very beneficial for programmersLost of programmers started with an understanding of what happens physically on the hardware when code runs and it is unfair advantage when debugging at times reply outside1234 15 hours agoparentprevAnd honestly, for most \"AI developers\" if you are training your own model these days (versus using an already trained one) - you are probably doing it wrong. reply Der_Einzige 16 hours agoparentprevDon&#x27;t worry, you&#x27;ll either be an AI developer or unemployed within 5 years. This is indeed important for you, regardless if you recognize this yet or not. reply Matumio 17 hours agoparentprev> When faced with multiple tasks, a CPU allocates its resources to address each task one after the otherHa! I wish CPUs were still that simple.Granted, it is legitimate for the article to focus on the programming model. But \"CPUs execute instructions sequentially\" is basically wrong if you talk about performance. (There are pipelines executing instructions in parallel, there is SIMD, and multiple cores can work on the same problem.) reply pclmulqdq 17 hours agoparentI think this post focused on the wrong things here. CPUs with AVX-512 also have massive data parallelism, and CPUs can execute many instructions at the same time. The big difference is that CPUs spend a lot of their silicon and power handling control flow to execute one thread efficiently, while GPUs spend that silicon on more compute units and hide control flow and memory latency by executing a lot of threads. reply mhh__ 15 hours agoparentprevIt will do multipleS SIMD instructions at the same time, too. reply JonChesterfield 17 hours agoparentprevThe CPUs are good at serial code and GPUs are good at parallel code is kind of true but something of an approximation. Assume equivalent power budget in the roughly hundreds of watts range, then:A CPU has ~100 \"cores\" each running one (and-a-hyperthread). independent things, and it hides memory latency by branch prediction and pipelining.A GPU has ~100 \"compute units\", each running ~80 independent things interleaved, and it hides memory latency by executing the next instruction from one of the other 80 things.Terminology is a bit of a mess, and the CPU probably has a 256bit wide vector unit while the GPU probably has a 2048bit wide vector unit, but from a short distance the two architectures look rather similar. reply mmoskal 16 hours agoparentGPU has 10x the memory bandwidth of the CPU though, which becomes relevant for the LLMs where you essentially have to read the whole memory (if you&#x27;re batching optimally, that is using all the memory either for weights or for KV cache) to produce one token of output. reply winwang 16 hours agorootparentGPUs also have 10x-100x FP&#x2F;INT8 throughput watt-for-watt. reply hurryer 14 hours agorootparentprevGPU also has 10x memory latency compared to CPU.And memory access order is much more important that on CPU. Truly random access has very bad performance. reply bee_rider 17 hours agoparentprevI’m always surprised there isn’t a movement toward pairing a few low latency cores with a large number of high throughput cores. Surround single Intel P core with a bunch of E cores. Then, hanging off the E cores, stick a bunch of iGPU cores and&#x2F;or AVX-512 units.Call it Xeon Chi. reply Const-me 16 hours agorootparentI think one possible reason for that, ideally these things need different memory.If you use high-bandwidth high-latency GDDR memory, CPU cores will underperform due to high latency, like there: https:&#x2F;&#x2F;www.tomshardware.com&#x2F;reviews&#x2F;amd-4700s-desktop-kit-r...If you use low-latency memory, GPU cores will underperform due to low bandwidth, see modern AMD APUs with many RDNA3 cores connected to DDR5 memory. On paper, Radeon 780M delivers up to 9 FP32 TFLOPS, the figure is close to desktop version of Radeon RX 6700 which is substantially faster in gaming. reply bee_rider 16 hours agorootparentHmm, that is a good point. Since it is a dream-computer anyway, maybe we can do 2.5d packaging; put the ddr memory right on top so the P cores can reach it quickly, then surround the whole thing with GDDR. reply softfalcon 17 hours agorootparentprevNeat idea, probably even viable!I think they may have a hurdle of getting folks to buy into the concept though.I imagine it would be analogous to how Arria FPGA’s were included with certain Xeon CPU’s. Which further backs up your point that this could happen in the near future! reply pixelpoet 16 hours agorootparentprevYou mean like an iGPU?Edit: Oh, thanks for the downvote, with no discussion of the question. I&#x27;ll just sit here quietly with my commercial OpenCL software that happily exploits these vector units attached to the normal CPU cores. reply bee_rider 5 hours agorootparentI’m not sure who downvoted; I think it isn’t possible to downvote a response to one’s comment.I did decide not to engage because “you mean like ” seemed a bit brusque and dismissive, commenting on this site is just for fun, so I don’t really see the point in continuing a conversation that seems like it is getting off on the wrong foot. reply anonylizard 19 hours agoparentprevI think python is dominant in AI, because the python-C relationship mirrors the CPU-GPU relationship.GPUs are extremely performant, and also very hard to code in, so people just use highly abstracted API calls like pytorch to command the GPU.C is very performant, and hard to code in, so people just use python as a abstraction layer over C.Its not clear if people need to understand GPUs that much (Unless you are deep in AI training&#x2F;ops land). In time, since moore&#x27;s law has ended and multithreading becomes the dominant mode of speed increases, there&#x27;ll probably be brand new languages dedicated to this new paradigm of parallel programming. Mojo is a start. reply mft_ 18 hours agoparentI&#x27;ve wondered for a while: is there a space for a (new?) language which invisibly maximises performance, whatever hardware it is run on?As in, every instruction, from a simple loop of calculations onward, is designed behind the scenes so that it intelligently maximises usage of every available CPU core in parallel, and also farms everything possible out to the GPU?Has this been done? Is it possible? reply Simpliplant 18 hours agorootparentNot exactly it but Mojo sounds closest from available optionshttps:&#x2F;&#x2F;www.modular.com&#x2F;mojo reply kaba0 16 hours agorootparentprevNot for mixed CPU&#x2F;GPU, but there is the concept of a superoptimizer, that basically brute forces for the most optimal correct code. But it is not practical, besides using for very very short program snippets (and they are usually CPU-only, though there is nothing fundamental why it couldn’t utilize the GPU as well).There is also https:&#x2F;&#x2F;futhark-lang.org&#x2F; , though I haven’t tried it, just heard about it. reply jfoutz 18 hours agorootparentprevThere&#x27;s definitely a space for it. It may even be possible. But if you consider the long history of lisp discussions (flamewars?) about \"a sufficiently smart compiler\" and comparisons to C. Or maybe Java vs C++, it seems unlikely. At least very very difficult.There are little bits of research on algorithm replacement. Like, have the compiler detect that you&#x27;re trying to sort, and generate the code for quick sort or timsort. it works, kinda. There are a lot of ways to hide a sort in code, and the compiler can&#x27;t readily find them all. reply pjc50 18 hours agorootparentprevI&#x27;m not sure that&#x27;s even possible in principle; consider the various anti-performance algorithms of proof-of-waste systems, where every step is data-dependent on the previous one and the table of intermediate results required may be made arbitrarily big.It&#x27;s a bit like \"design a zip algorithm which can compress any file\". reply drdeca 14 hours agorootparentI don’t see why such a “proof of waste” algorithm would be an obstacle to such an optimizer existing. Wouldn’t it just be that for such computational problems, the optimal implementation would still be rather costly? That doesn’t mean the optimizer failed. If it made the program as efficient as possible, for the computational task it implements, then the optimizer has done its job. reply lwhi 18 hours agorootparentprevI&#x27;d imagine it wouldn&#x27;t be very difficult to build language constructs that are able to denote when high parallelism is desirable; and let the compiler deal with this information as necessary. reply howling 17 hours agorootparentprevYou might be interested in https:&#x2F;&#x2F;github.com&#x2F;HigherOrderCO&#x2F;HVM reply runlaszlorun 14 hours agorootparentHVM looks very interesting. Thx for posting. reply huijzer 18 hours agorootparentprevThere are many languages doing that more or less. Jax and Mojo for example. reply teaearlgraycold 18 hours agorootparentprevI’m not sure if that’s a good idea at the moment, but we should start with making development with vector instructions more approachable. The code should look more or less the same as working with u64s. reply sitkack 19 hours agoparentprevMoore’s law is far from over and multithreading is not the answer. Your opening sentence is spot on tho. reply Kamq 18 hours agorootparent> Moore’s law is far from over and multithreading is not the answer.Wut? We hit the power wall back in 2004. There was a little bit of optimization around the memory wall and ilp wall afterwards, but really, cores haven&#x27;t gotten faster since.It&#x27;s been all about being able to cram more cores in since then, which implies at least multi-threading, but multi-processing is basically required to get the most out of a cpu these days. reply ikura 17 hours agorootparentMoore&#x27;s law is \"the observation that the number of transistors in an integrated circuit doubles about every two years\". For a while clock speed was a proxy for that metric, but it&#x27;s not the &#x27;law&#x27; itself. reply Kamq 17 hours agorootparentYeah, but today number of cores is the rough proxy for that metric.How do you operate in that world if \"multithreading isn&#x27;t the answer\"? reply samus 15 hours agorootparentModern CPUs contain a lot more computing units than cores. For a while, hyperthreading was thought to be a useful way to make use of them. More recently, people have turned to advanced instruction sets like SSE and AVX. reply FridgeSeal 14 hours agorootparentThose things aren’t mutually exclusive. Also firstly, I suspect there’s more “low hanging fruit” in making more software make use of more cores. We’re increasingly getting better languages, tooling and libs for multi threading stuff, and it’s far more in the realm of your average developer than writing SIMD compatible code and making sure your code can pipeline properly. reply samus 13 hours agorootparentThreads are of course appropriate to implement high-level concurrency and parallelism. But for fine-grained parallelism, they are unwieldy and have high overhead.Spreading an algorithm across multiple threads makes it more difficult for an optimizing compiler to find opportunities for SIMD optimization.Similarly to how modern languages make it easier to safely use threads, runtimes also make it easier to take advantage of SIMD optimizations. For example, recently a SIMD-optimized sorting algorithm was included in OpenJDK. Apart from that, SIMD is way less brittle at runtime than GPUs and other accelerators. replybmc7505 18 hours agorootparentprevCare to elaborate? reply guyomes 18 hours agorootparentNo idea about the future of the Moore&#x27;s law precisely. Yet recent research results show that there is still room for faster semiconductors, as discussed on HN [0].[0]: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38201624 reply bmc7505 15 hours agorootparentI mean why isn’t multithreading the answer? reply samus 14 hours agorootparentMultithreading has the following disadvantages:* Overhead: the overhead to start and manage multiple threads is considerable in practice. Most multithreaded algorithms are in fact slower than optimized serial implementations when n_threads=1* Communication: threads have to communicate with each other and synchronize access to shared resources. \"Embarrassingly parallel\" problems don&#x27;t require synchronization, but many interesting problems are not of that kind.* Amdahl&#x27;s law: there is a point of diminishing returns on parallelizing an application since it quite likely contains parts that are not easily parallelized. reply bmc7505 13 hours agorootparentWell, yes. But assuming the question is how to reduce overall latency, what alternative is there besides algorithmic improvements or increasing clock frequency? reply samus 2 hours agorootparentRecently, SIMD has been increasingly used to make use of the increased number of compute units in a CPU. Sure, it&#x27;s not as easy and straightforward to use as multithreading (I never expected to say that about multithreading), but libraries and programming languages make more and more use of them.Edit: latency is difficult. But accellerating CPUs and using GPUs for compute was never about latency. Most I&#x2F;O bottlenecks are because CPUs have sped up so much and left the rest of the platform in the dust. Much of it is also due to fundamental limitations due to the speed of light. Increasing throughput is always easier that reducing latency. replydanielmarkbruce 19 hours agoparentprevGPUs aren&#x27;t that difficult to program. CUDA is fairly straightforward for many tasks and in many cases there is an easy 100x improvement in processing speed just sitting there to be had withSure, but if you&#x27;ve never used CUDA or any other GPU framework, how many lines of documentation do you need to read, and how many lines of code are you likely to write and rewrite and delete before you end up with thoseCUDA is fairly straightforward for many tasks and in many cases there is an easy 100x improvement in processing speed just sitting there to be had withC is very performant, and hard to code in, so people just use python as a abstraction layer over C.C is a way of life. Those of us who code exclusively, or nearly so, in C cannot stomach python&#x27;s notion of \"significant white-space.\" reply yoyohello13 18 hours agorootparentI code in both (c for hobbies and python professionally) and “significant white space” is a non-issue if you spend any amount of time getting used to it.Complaining about significant white-space is like complaining that lisp has too many parentheses. It’s an aesthetic preference that just doesn’t matter in practice. reply adventured 18 hours agorootparentA form of Sayre&#x27;s Law is very common in tech (eg spaces vs tabs; framework vs framework; language vs language). reply mhh__ 15 hours agorootparentprevI actually find python and C very similar in spirit.Syntax is mostly an irrelevance, they have surprisingly similar patterns in my opinion.In a modern language I want a type system that both reduces risk and reduces typing — safety and metaprogramming. C obviously doesn&#x27;t, python doesn&#x27;t really either.Python&#x27;s approach to dynamic-ness is very similar to how I&#x27;d expect C to be as a dynamic language (if it had proper arrays&#x2F;lists). reply dboreham 17 hours agorootparentprevYou get used to the significant whitespace. (C programmer since ~1978). reply bigstrat2003 13 hours agorootparentI never did, and it&#x27;s one of the things I hate most about Python to this day. I still use Python because it&#x27;s the best tool a lot of the time, but it&#x27;s such a terrible language decision to have significant whitespace imo. reply bart_spoon 17 hours agorootparentprevAll programming languages, including C, have significant white space. Python just has slightly more. reply Phemist 18 hours agorootparentprevWait till you start using the black formatter tool.Well-known for supporting any formatting style you like ;) reply adolph 18 hours agorootparentprev> cannot stomach python&#x27;s notion of \"significant white-space.\"Why belly ache about it? Whitespace is significant to one’s fellow humans. reply boredtofears 17 hours agorootparentPrecisely why it should be of no significance to the machine. reply drdrey 16 hours agorootparentSource code is not for the machine to read, it’s for your fellow humans reply boredtofears 9 hours agorootparentThat doesn&#x27;t mean that source code has no meaning to the interpreter. replyalberth 18 hours agoparentprevNx &#x2F; AxonGiven that most programming languages are designed for sequential processing (like CPUs), but Erlang&#x2F;Elixir is designed for parallelism (like GPUs) … I really wonder if Nx &#x2F; Axon (Elixir) will take off.https:&#x2F;&#x2F;github.com&#x2F;elixir-nx&#x2F; reply oytis 18 hours agoparentErlang was designed for distributed systems with a lot of concurrency not for computation-heavy parallelism reply matrss 17 hours agoparentprevI am really wondering how well Elixir with Nx would perform for computation heavy workloads on a HPC cluster. Architecturally, it isn&#x27;t that dissimilar to MPI, which is often used in that field. It should be a lot more accessible though, like numpy and the entire scientific python stack. reply zoogeny 16 hours agoparentprevI&#x27;ve been investigating this and I wonder if the combination of Elixir and Nx&#x2F;Axon might be a good fit for architectures like NVIDIA Grace Hopper where there is a mix of CPU and GPU. reply coffeebeqn 18 hours agoparentprevWould that run on a GPU? I think the future is having both. Sequential programming is still the best abstraction for most tasks that don’t require immense parallel execution reply dartos 18 hours agorootparentAxon runs compute graphs on gpu, but elixirs parallelism abstractions run on cpu reply password4321 18 hours agoparentprevI need a buyers guide: what&#x27;s the minimum to spend, and best at a few budget tiers? Unfortunately that info changes occasionally and I&#x27;m not sure if there&#x27;s any resource that keeps on top of things. reply alsodumb 18 hours agoparenthttps:&#x2F;&#x2F;timdettmers.com&#x2F;2023&#x2F;01&#x2F;30&#x2F;which-gpu-for-deep-learni...This is the best one imo. reply johndough 15 hours agoparentprevGoogle Colab, Kaggle Notebooks and Paperspace Notebooks all offer free GPU usage (within limits), so you do not need to spent anything to learn GPU programming.https:&#x2F;&#x2F;colab.google&#x2F;https:&#x2F;&#x2F;www.kaggle.com&#x2F;docs&#x2F;notebookshttps:&#x2F;&#x2F;www.paperspace.com&#x2F;gradient&#x2F;free-gpu reply fulafel 15 hours agoparentprevFor learning basics of GPU programming your iGPU will do fine. Actual real-world applications are very varied of course. reply coffeebeqn 18 hours agoparentprevYou can also rent compute online if you don’t want to immediate plop down 1-2k reply aunty_helen 17 hours agoparentprevWe’re back to “every developer must know” clickbait articles? reply mhh__ 15 hours agoparentAlthough I think they&#x27;ll be replaced by ChatGPT a good article in that style is actually quite valuable.I like attacking complexity head on, and have a good knowledge of both quantitative methods & qualitative details of (say) computer hardware so having an article that can tell me the nitty gritty details of a field is appreciated.Take \"What every programmer should know about memory\" — should every programmer know? Perhaps not, but every good programmer should at least have an appreciation of how a computer actually works. This pays dividends everywhere — locality (the main idea that you should take away from that article) is fast, easy to follow, and usually a result of good code that fits a problem well. reply igh4st 15 hours agoparentprevit seems so... Should take this article&#x27;s statements with a grain of salt. reply rushingcreek 18 hours agoparentprevGood read. However, the AWS P5 instance (along with P4d and P4de) is most certainly oriented towards training, not inference. The most inference-friendly instance types are the G4dn and the G5, which feature T4 and A10G GPUs, respectively. reply axpy906 17 hours agoparentCame here to say this author forgot G5. reply k1ns 18 hours agoparentprevI am very new to GPU programming in general and this article was a fun read. It&#x27;s amazing how far we&#x27;ve come, prime example being able to train a simple \"dog or cat\" NN that easily. reply arriu 18 hours agoparentprevAre amd GPUs still to be avoided or are they workable at this point? reply JonChesterfield 17 hours agoparentThe cuda happy path is very polished and works reliably. The amdgpu happy path fights you a little but basically works. I think the amd libraries starting to be packaged under Linux is a big deal.If you don&#x27;t want to follow the happy path, on Nvidia you get to beg them to maybe support your use case in future. On amdgpu, you get the option to build it yourself, where almost all the pieces are open source and pliable. The driver ships in Linux. The userspace is on GitHub. It&#x27;s only GPU firmware which is an opaque blob at present, and that&#x27;s arguably equivalent to not being able to easily modify the silicon. reply latchkey 16 hours agoparentprevAMD GPUs work great, the issue is that people don&#x27;t want to mess with ROCm&#x2F;HIP when CUDA is kind of the documented workflow. Along with the fact that ROCm was stagnant for a long time. AMD missed the first AI wave, but are now committed to making ROCm into the best it can be.The other problem is that there aren&#x27;t any places to rent the high end AMD AI&#x2F;ML GPUs, like the MI250&#x27;s and soon to be released MI300&#x27;s. They are only available on things like the Frontier super computer, which few developers have access to. \"regular\" developers are stuck without easy access to this equipment.I&#x27;m working on the later problem. I&#x27;d like to create more of a flywheel effect. Get more developers interested in AMD by enabling them to inexpensively rent and do development on them, which will create more demand. @gmail if you&#x27;d like to be an early adopter. reply Matumio 16 hours agoparentprevThe Mandelbrot example seems to make interpreted Python stand in for \"the CPU performance\"?If that&#x27;s true, then I&#x27;m surprised they only see a 10x speed-up. I would expect more from only compiling that loop for the CPU. (Comparing to interpreted Python without numpy.) Given they already have a numba version, why not compile it for the CPU and compare?Also, they say consumer CPUs have 2-16 cores. (Who has 2 cores these days?) They go on suggest to rent an AWS GPU for $3 per hour. You&#x27;re more likely to get 128 cores for that price, still on a single VM.Not saying it will be easy to write multi-threaded code for the CPU. But if you&#x27;re lucky, the Python library you&#x27;re using already does it. reply lucb1e 16 hours agoparent> Also, they say consumer CPUs have 2-16 cores. (Who has 2 cores these days?)Pretty sure my mom&#x27;s laptop has 2 cores; I can&#x27;t think of anyone whose daily driver has 16 cores. Real cores, not hyperthread stuff running at 0.3× the performance of a real core.As for the 128-core server system, note that those cores are typically about as powerful as a 2008 notebook. My decade-old laptop CPU outperforms what you get at DigitalOcean today, and storage performance is a similar story. The sheer number makes up for it, of course, but \"number of cores\" is not a 1:1 comparable metric.Agree, though, that the 10x speedup seems low. Perhaps, at 0.4s, a relatively large fraction of that time is spent on initializing the Python runtime (`time python3 -c &#x27;print(\"1337\")&#x27;` = 60ms), the module they import that needs to do device discovery, etc.? Hashcat, for example, takes like 15 seconds to get started even if it then runs very fast after that. reply 65a 13 hours agorootparentMy 2016 desktop had 22 cores and 44 threads. You can have the same processor for 4 real cores) then that&#x27;s what I&#x27;d get because that&#x27;s the optimum for my wallet and performance profile. reply z5h 18 hours agoparentprevWe have compilers (languages) like Futhark that aim to optimize explicitly parallel operations. And universal models of computation like interaction nets that are inherently parallel.Am I lazy to expect we’ll be getting a lot more “parallel-on-the-GPU-for-free” in the future? reply zozbot234 17 hours agoparentYou can already convert a compute graph to GPU-optimized code using something like Aesara (formerly known as Theano) or TensorFlow. There are also efforts in the systems space that ought to make this kind of thing more widespread in the future, such as the MLIR backend for LLVM. reply the__alchemist 19 hours agoparentprevAnother tip that took me longer than I wished to figure out.Use CUDA, vice graphics APIs+compute. The latter (Vulkan compute etc) is high friction. CUDA is far easier to write in, and the resulting code is easier to maintain and update. reply behnamoh 19 hours agoparentYes, and in the process, contribute to Nvidia’s monopoly. reply raincole 19 hours agorootparentVery few professional artists refuse using Photoshop or After Effects because it will \"contribute to Adobe&#x27;s monopoly\".But for some reasons professional programmers are judged under a much higher moral standard. reply ickelbawd 19 hours agorootparentI think because professional artists can’t typically make their software tools. Whereas engineers could in theory make their own tools. Naturally few do in practice though as tech has become far too large and specialized. But our roots are where our values and ideals come from. reply hutzlibu 18 hours agorootparentThat is a really theoretical point.If I start to work on a tool, then I cannot work anymore on what I actually wanted to do. And it just so happens ... that this is exactly what I did and I can just say, it usually takes way longer than the most pessimistic estimate one can come up with, so yes, one can decide to switch careers and try to get funding to (re)build what is not offered to acceptable conditions (but in my case the tool simply did not exist, though).Just like an artist can switch career, study CS, build on his own a tool a professional company build with a team over years - and then someday work with his tool to acomplish his original work. In (simplified) theories, lots of things are possible .. reply Aurornis 18 hours agorootparentprev> But for some reasons professional programmers are judged under a much higher moral standardNot in the real world. Most programmers who are trying to get a job done won’t avoid CUDA or AWS or other tools just to avoid “contributing to a monopoly”. When responsible programmers have a job to do and tools are available to help with the job, they get used.A programmer who avoids mainstream tools on principle is liable to get surpassed by their peers very quickly. I’ve only met a few people like this in industry and they didn’t last very long trying to do everything the hard way just to avoid tools from corporations or monopolies or open source that wasn’t pure enough for their standards.It’s only really in internet comment sections that people push ideological purity like this. reply z3phyr 18 hours agorootparentThe same attitude brought us adaptation of linux. So IDK reply arcanemachiner 17 hours agorootparentMost lottery tickets aren&#x27;t winners. reply yowlingcat 14 hours agorootparentprev> But for some reasons professional programmers are judged under a much higher moral standard.I believe the key word there is \"professional\" -- one of the challenges of a venue like HN is the professional engineers and the less-professional ones interact from worldviews and use cases so distinct that they may as well be separate universes. In other spaces, we wouldn&#x27;t let a top doctor have to explain very basic concepts about the commercial practice of medicine to an amateur \"skeptic\" and yet so many discussions on HN degenerate along just these lines.On the other hand, it&#x27;s that very same inclusiveness and generally high discourse in spite of that wide expanse which make HN such a special community, so I&#x27;m not sure what to conclude besides this unfortunate characteristic being a necessary \"feature, not a bug\" of the community. There&#x27;s no way around it that wouldn&#x27;t make the community a lesser place, I think. reply Karliss 18 hours agorootparentprevTool choice of artists has close to 0 impact on people interacting with final work. Choices made by programmers are amplified through the users of produced software. reply timeon 14 hours agorootparentprevAnd they ended up with Creative Cloud bloatware. reply bogwog 19 hours agorootparentprevIt isn&#x27;t the consumer&#x27;s responsibility to regulate the market. reply danielmarkbruce 19 hours agorootparentAnd, in this case NVIDIA earned it. They built a very useful software layer around their chips. reply calamari4065 18 hours agorootparentprevThen whose responsibility is it? Corporations? The government? Or maybe the tooth fairy? reply tjoff 18 hours agorootparentprevThat is a weak argument that could be used to justify tons of behavior, very convenient.Vote with your feet. Maybe you can&#x27;t or can&#x27;t afford it, then at least admit the problem to yourself and maybe don&#x27;t try to persuade others in order to feel better for your own decision. reply dzikimarian 18 hours agorootparentprevIf consumers don&#x27;t care about their money, then who would? reply ilaksh 19 hours agorootparentprevIs there something that is not vendor specific? Maybe a parallel programming language that compiles to different targets?..and doesn&#x27;t suck. reply atq2119 14 hours agorootparentThe part that I don&#x27;t understand is why AMD&#x2F;Intel&#x2F;somebody else don&#x27;t just implement at least the base CUDA for their products.HIP is basically that, but they still make you jump through hoops to rename everything etc.There are libraries written at a lower level that wouldn&#x27;t be immediately portable, but surely that could be addressed over time as well. reply the__alchemist 19 hours agorootparentprevI&#x27;m with you, and am surprised there isn&#x27;t comparable competition. reply tovej 19 hours agorootparentprevEh, CUDA can mostly be transformed to HIP, unless you use specialized NVIDIA stuff. reply gjsman-1000 19 hours agorootparentprevSo sayeth the person who has never written OpenCL. reply dinosaurdynasty 18 hours agoparentprevI wish someone would make the latter much easier, as someone who is definitely not the only person to get interested in this AI stuff lately who has a high tier AMD card that could surely do this stuff and would like to run this stuff locally for various reasons.Currently I&#x27;ve given up and use runpod, but still... reply nwoli 19 hours agoparentprevI agree cuda is really nice to write in, but what reason do you have to write raw cuda I’m curious? Usually I find that it’s pre written kernels you deal with reply the__alchemist 19 hours agorootparentCurrently doing computational chemistry, but per the article, it&#x27;s a fundamental part of my toolkit going forward; I think it will be a useful tool for many applications. reply drdrey 19 hours agoparentprevWhat about on macOS? Is OpenCL viable? reply convexstrictly 13 hours agoparentprevA great beginner guide to GPU programming concepts:https:&#x2F;&#x2F;github.com&#x2F;srush&#x2F;GPU-Puzzles reply dartos 17 hours agoparentprevI don’t think transformer models generate multiple tokens in parallel (how could they?)They just leverage parallelism in making a single prediction reply atomicnature 17 hours agoparentTransformers tend to be trained in parallel. BERT = 512 tokens per context, in parallel. GPT too is trained while feeding in multiple words in parallel. This enables us to build larger models. Older models, such as RNNs couldn&#x27;t be trained this way, limiting their power&#x2F;quality. reply zozbot234 17 hours agorootparentThis is only sort of true, since you can still train RNNs (including LSTM, etc.) in big batches-- which is usually plenty enough to make use of your GPU&#x27;s parallel capabilities. The inherently serial part only applies to the length of your context. Transformer architectures thus happen to be helpful if you have lots of idle GPU&#x27;s such that you&#x27;re actually constrained by not being able to parallelize along the context dimension. reply atomicnature 16 hours agorootparentIn RNN, hidden states are to be sequential; in transformers with attention mechanism, we break free of the sequential requirement. Transformers are more amenable to parallelism, and make use of GPUs the most (within the context axis, and outside). reply dartos 17 hours agorootparentprevAhh, that makes a lot of sense reply DougBTX 17 hours agoparentprevA quick search uncovers [0] with a hint towards an answer: just train the model to output multiple tokens at once.[0] https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2111.12701 reply bilsbie 18 hours agoparentprevCan I do this in my GeForce GTX 970 4GB? reply shmerl 16 hours agoparentprevShouldn&#x27;t the article mention SIMD? I haven&#x27;t seen it even being brought up. reply lucb1e 17 hours agoparentprev> AWS GPU Instances: A Beginner&#x27;s Guide [...] Here are the different types of AWS GPU instances and their use casesThe section goes on to teach Amazon-specific terminology and products.A \"bare minimum everyone must know\" guide should not include vendor-specific guidance. I had this in school with Microsoft already, with never a mention of Linux because they already paid for Windows Server licenses for all of us...Edit: and speaking of inclusivity, the screenshots-of-text have their alt text set to \"Alt text\". Very useful. It doesn&#x27;t need to be verbatim copies, but it could at least summarize in a few words what you&#x27;re meant to get from the terminal screenshot to help people that use screen readers.Since this comment floated to the top, I want to also say that I didn&#x27;t mean for this to dominate the conversation! The guide may not be perfect, but it helped me by showing how to run arbitrary code on my GPU. A few years ago I also looked into it, but came away thinking it&#x27;s dark magic that I can&#x27;t make use of. The practical examples in both high- and low-level languages are usefulAnother edit: cool, this comment went from all the way at the top to all the way at the bottom, without losing a single vote. I agree it shouldn&#x27;t be the very top thing, but this moderation also feels weird reply mikehollinger 16 hours agoparentAgreed. This isn’t actually that useful of a guide in the first place.Tbh the most basic question is: “are you innovating inside the AI box or outside the AI box?”If inside - this guide doesn’t really share anything practical. Like if you’re going to be tinkering with a core algorithm and trying to optimize it, understanding BLAS and cuBLAS or whatever AMD &#x2F; Apple &#x2F; Google equivalent, then understanding what pandas, torch, numpy and a variety of other tools are doing for you, then being able to wield these effectively makes more sense.If outside the box - understanding how to spot the signs of inefficient use of resource - whether that’s network, storage, accelerator, cpu, or memory, and then reasoning through how to reduce that bottleneck.Like - I’m certain we will see this in the near future, but off the top of my head the innocent but incorrect things people do: 1. Sending single requests, instead of batching 2. Using a synchronous programming model when asynchronous is probably better 3. Sending data across a compute boundary unnecessarily 4. Sending too much data 5. Assuming all accelerators are the same. That T4 gpu is cheaper than an H100 for a reason. 6. Ignoring bandwidth limitations 7. Ignoring access patterns reply StableAlkyne 16 hours agoparentprevAre there any surveys of just how many Windows Servers boxes exist?Even when I was working at an Azure-only shop, I&#x27;ve never actually seen anyone use Windows Server. Lots of CentOS (before IBM ruined it) and other Unixes, but never a Windows Server. reply lucb1e 16 hours agorootparentWe come across them all the time when doing internal network pentests (most organizations use AD for managing their fleet of end-user systems), and occasionally external tests as well. Stackoverflow is a site that comes to mind as being known for running their production systems on Windows Server.It&#x27;s useful to have experienced, but I do take issue with exclusively (or primarily) focusing on one ecosystem as a mostly-publicly-funded school. reply StableAlkyne 15 hours agorootparentHuh, TIL StackOverflow is on Windows Server reply lordwiz 20 hours agoparentprev [–] In this AI Age, It is crucial for developers to have a fundamental understanding of GPUs and their application to AI development. reply gmfawcett 19 hours agoparent [–] Crucial, for all developers? The great majority will get AI through an API. reply athreyac8 18 hours agorootparent [–] After a while there will be a time when you will have to be lending others API, for that yes crucial I guess. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "GPUs are crucial in the AI age due to their parallel processing capabilities, making them more efficient for running AI models.",
      "The article provides a guide on setting up CUDA and NVIDIA GPU drivers and showcases examples of managing GPUs and optimizing code with the CUDA framework.",
      "It demonstrates GPU acceleration with the Numba library and TensorFlow for generating fractals and training neural networks, highlighting the importance of GPUs in accelerating complex computations across various fields."
    ],
    "commentSummary": [
      "The discussion centers around the use of GPUs in AI development and the potential benefits and challenges involved.",
      "Different participants express varying opinions on the importance of AI knowledge for developers and the performance differences between CPUs and GPUs.",
      "The debate also includes topics such as the significance of understanding hardware, the dominance of Python in AI, the potential of multithreading and SIMD instructions for performance improvement, and the use of specific tools like Aesara and CUDA for GPU programming."
    ],
    "points": 276,
    "commentCount": 151,
    "retryCount": 0,
    "time": 1699799845
  },
  {
    "id": 38239728,
    "title": "Practitioner's Handbook: Emphasizing Open, Rigorous, and Reproducible Research in the Digital Age",
    "originLink": "https://stanforddatascience.github.io/best-practices/index.html",
    "originBody": "Preface 0.1 Authors 0.2 Acknowledgements 1 Study design phase 1.1 Define the research question 1.2 Choose Your Study Design 1.3 Study Designs 1.4 Recognize Different Sources of Errors/Uncertainties in Estimation 1.5 Typical Biases in Different Data Sources and Study Designs 1.6 How to Reduce and Estimate Different Types of Errors 1.7 Create Your Analytic Plan 1.8 Start Documenting Your Grand Study 2 Analysis phase 2.1 Start here 2.2 Statistical Analysis Plan (SAP) 2.3 Data generation 2.4 Data preparation 2.5 Data visualization 2.6 Data summarization 2.7 Data analysis 2.8 Data analysis - medicine 2.9 Statistical analysis report 2.10 Examples 2.11 Resources 3 Publication phase 3.1 Making Data Available 3.2 Making Code Available 3.3 Reproducible Environments 3.4 Open Publication Models 3.5 Documenting Processes and Decisions 3.6 Additional Resources FacebookTwitterLinkedInWeiboInstapaper AA SerifSans WhiteSepiaNight Open, rigorous and reproducible research: A practitioner’s handbook Open, rigorous and reproducible research: A practitioner’s handbook Dallas Card, Yan Min, Stylianos Serghiou 2021-12-14 Preface This book starts from the premise that there is a lot we can all do to increase the benefits of research. Let’s consider the main limitations of research that is not carried out and shared in an open, transparent, and reproducible way: If papers are published in venues that are only available to those who pay for access, the vast majority of the world will not be able to see the output of all the work that went into producing it; this limits the potential reach and benefit to others. Because of the complexity involved in many analyses, it is nearly impossible to describe every detail and choice that went into an analysis in the main paper; without accompanying code, it can be very very difficult for others to be certain about exactly what was done. Even if code is made available, there can be additional challenges to reproducing or re-analyzing past work, such as inaccessible data or deprecated software. If others are not able to easily re-analyze past work, that limits the ability of the community to explore other analysis pathways, combine datasets, attempt to generalize experiments to new settings, etc. If experiments are carried out without proper care in experiment design and analysis, there are likely to be more erroneous findings in the literature, making it harder for everyone to make sense of the object of study. The more that new researchers have to wade through results that may not be credible, they more they are delayed from making genuine advances Of course, there are numerous reasons why people don’t put more effort into making their work open, transparent, and reproducible: Perhaps most importantly, doing so does require some additional work, and current incentive structures do not necessarily reward these efforts; however, this is changing in many fields, and certain communities place a lot of value on such things. Moreover, the cost of mistakes can be high, and this sort of openness helps to avoid them. Some data is legitimately not possible to share, due to concerns about privacy, copyright, or other considerations. Using such data will generally be less useful to the world than using more open data, but some work will of course require it. However, there are still things that can be done to avoid the worst problems, including being transparent about the analyses carried out, the protocol for collecting data, and other techniques such as pre-registration, which can bolster people’s confidence in a piece of work. Many people worry that making their data and code open to the world will expose them to risk or ridicule, either because they fear they have made mistakes, or they think it will reveal them to be a poor coder. This is understandable, but generally misplaced. It is better to catch errors early. Moreover, most people will be happy if you share any code, no matter how bad it is, and doing so is one of the best ways to improve, especially if you begin with the end in mind. Finally, many people don’t know where to start. Most guides to open science and reproducibility take the form of complete books or corpus, and try to teach an entire philosophy and comprehensive approach to research, which can be overwhelming. In this document, we take a different approach. Our main goal here is to show how there are many ways to make your research more open, transparent, and reproducible on the margin, and that each step in that direction may bring some benefit. While there will always be nuances and requirements specific to each field, in general there is a great deal that we can learn from each other, and most ideas can be applied to any domain. In summary, this handbook is a guide to making science more open, transparent, and reproducible by presenting best practices in a way that is: modular: individual ideas can be used separately or combined practical: focused on the most tractable and impactful practices general: applicable to any field that works with data and statistical analysis concise: aimed at the busy scientists who doesn’t have time to take a full course right now We break this guide down into three mains sections. Each section contains many modular components, each of which can be considered and used independently or in combination with the others: Section 1: Careful study design to help ensure and demonstrate that results and conclusions are valid and useful: Thoughtful determination of experimental parameters, such as using power analysis to estimate an appropriate sample size Distinguishing between exploratory and confirmatory research Pre-analysis planning of statistical analyses Ensuring that all relevant data is collected in order to be comparable with past work Additional considerations, such as pre-registration, planning for potential problems, and consideration of ethical implications. Section 2: Adopting best practices in analyzing data and reporting results: Preliminary: decisions and considerations before working with any data. Statistical analysis plan: plan your analytic approach beforehand. Data generation: generate an appropriate set of data. Data preparation: transparently prepare your data for data analysis. Data visualization: visualize all data using informative visualizations. Data summarization: summarize all data using appropriate statistics. Data analysis: analyze all data and avoid common blunders. Data analysis - medicine: a few more considerations for medical research. Statistical analysis report: report transparently and comprehensively. Examples: published literature exemplifying principles of this manual. Section 3: Making relevant research materials available to all: Open Data: making the raw data available for further research and replication Open Source Code: making the analysis pipeline transparent and available for others to borrow or verify Reproducible Environments: making not just the data and code available for others, but making it easy for them to re-run the analysis in an easily reproducible manner Open Publication Models such that anyone can see the scholarly output associated with the work Documenting Processes and Decisions: making it clear to interested parties not only what was done and how, but also why, by mechanisms such as open lab notebooks In addition, appendices cover additional resources, such as frequently asked questions, discipline-specific considerations and linked to additional resources (of which there are plenty!) 0.1 Authors Dallas Card is a postdoctoral scholar with the Stanford NLP Group and the Stanford Data Science Institute. He received his Ph.D. from the Machine Learning Department at Carnegie Mellon University. Yan Min is a Ph.D. candidate working with Mike Baiocchi as part of the Department of Epidemiology and Population Health at Stanford University. She has previously completed her medical studies in China. Stylianos (Stelios) Serghiou is an AI Resident at Google Health working on using modern methods of data science to empower patients, doctors and clinical researchers. He received his Ph.D. in Epidemiology and Clinical Research and Masters in Statistics from Stanford University, where he was advised by John Ioannidis. He previously completed his medical training at the University of Edinburgh, UK. 0.2 Acknowledgements We would like to thank all early readers of this work, who’s feedback we sincerely appreciate. We are especially thankful to the Stanford Data Science Initiative community, Russ Poldrack, John Chambers and Steve Goodman.",
    "commentLink": "https://news.ycombinator.com/item?id=38239728",
    "commentBody": "Open, rigorous and reproducible research: A practitioner’s handbook (2021)Hacker NewspastloginOpen, rigorous and reproducible research: A practitioner’s handbook (2021) (stanforddatascience.github.io) 270 points by sieste 21 hours ago| hidepastfavorite24 comments necrophcodr 10 hours agoparent> While recording the versions of all packages used is a step in the right direction, an even more comprehensive solution is to package up the entire environment using something like Docker, or to use online computation, such as Google’s colaboratory notebooks.An even better way would be to describe the environment using Guix with channels or something similar accompanying the code, or a Nix flake or any similar environment descriptions with fully fixed dependency chains. Docker can be _forced_ to use a fixed version, but any `apt update` will ruin that completely, and both Nix and Guix are tools that on top of providing these environments for executing code with the same set and versions of tools, also provide the ability to generate container images that can be shared. reply tasubotadas 21 hours agoparentprevAnyone used it? Is it any good? reply baka367 20 hours agoparentIt feels like a great material at explaining the field to new joiners.My team is currently migrating from software to data science and this publication feels exactly like something that would bridge the gap reply nerdponx 15 hours agorootparentWhat company do you work at where they&#x27;re willing to train a bunch of developers up to data science from scratch? That&#x27;s a multi-year investment if you want a team that can actually solve real problems without causing more problems. reply shapefrog 14 hours agorootparentdata science isnt that hard! reply nerdponx 13 hours agorootparentIt&#x27;s not hard in the same way software engineering isn&#x27;t hard. That is to say: it&#x27;s hard to do well. reply mjburgess 14 hours agorootparentprevWell, it&#x27;s mostly impossible -- i guess that&#x27;s a certain sort of way it isnt hard. replyulrischa 15 hours agoparentprevVery cool that universities like Stanford that usually costs a lot of money offer their study material for free reply troelsSteegin 20 hours agoparentprevThe page embeds https:&#x2F;&#x2F;stanforddatascience.github.io&#x2F;best-practices&#x2F;index.h... reply dang 14 hours agoparentOk, we&#x27;ve changed to that from https:&#x2F;&#x2F;datascience.stanford.edu&#x2F;programs&#x2F;stanford-data-scie... above. Thanks! reply hackernewds 17 hours agoparentprevWould be helpful to feed into custom chatgpt that ask the gpt questions directly reply bazmattaz 14 hours agorootparentI just tried that but there is pagination. Would love to know if we can instruct GPT4 to click through the pages reply jiriro 15 hours agoparentprevOh, thank you. The original covers almost 50% of the screen (iphone) with the static heading! reply hackernewds 17 hours agoparentprev\"In summary, this handbook is a guide to making science more open, transparent, and reproducible by presenting best practices\" reply alwaysrunning 20 hours agoparentprev [11 more] [flagged] simonw 19 hours agoparentI genuinely don&#x27;t see how that&#x27;s relevant here.Are you saying that if a president of a university is caught doing something bad and fired&#x2F;resigns for it then every piece of output from that university related to that field should be disregarded? reply alwaysrunning 19 hours agorootparentI&#x27;m saying the timing is not the best. Read the room first. And I&#x27;m not saying he \"was caught doing something bad\" I am saying he is the President of the university, the leader, and he is a fraud.This isn&#x27;t a one-time thing, and this fraud stretches back to before he was president, there were already rumors of his fraud in his community, and they hired him anyway knowing he could be a fraud. He also worked to stop this from coming to light, and to this day hasn&#x27;t really admitted he was at fault except to say &#x27;I could have done better&#x27;, he is also stil a professor there. A 17 yo can figure this out but a university board can&#x27;t? come on.\"Marc Tessier-Lavigne, who has spent seven years as president, authored 12 reports that contained falsified information\"What kind of legal threats did you receive? Stephen Neal, the chair emeritus of Cooley, one of the biggest law firms in the Silicon Valley area, represented Marc Tessier-Lavigne and sent a number of aggressive letters requesting retractions or seeking to block the publication of articles that detailed Tessier-Lavigne’s involvement in alleged incidents of fraud. Neal is also a former attorney for [disgraced former Theranos CEO] Elizabeth Holmes.https:&#x2F;&#x2F;www.latimes.com&#x2F;science&#x2F;story&#x2F;2023-07-21&#x2F;how-stanfor... reply z2h-a6n 19 hours agorootparentAs other commenters have noted, large universities are quite heterogeneous and their administrations are fairly decoupled from their research activity, except in a big-picture sense. The timing is basically irrelevant because you might as well regard Stanford Data Science and the Stanford University Administration as separate entities for all directly-research-related purposes.I&#x27;m a researcher at a large university (admittedly a grad student, and therefore more insulated from university administrivia than a professor), and I don&#x27;t even know who my university&#x27;s president is. reply Jtsummers 19 hours agorootparentprev> I&#x27;m saying the timing is not the best. Read the room first.Instead of reading the room, perhaps read the page:>> 2021-12-14From the preface. This document is at least 2 years old, it wasn&#x27;t just published. reply sieste 18 hours agorootparentprevI didn&#x27;t know about the story when posting this. I also don&#x27;t think it&#x27;s relevant, even in a read-the-room sense. Bad press about the leader of an institution isn&#x27;t a reason to stop discussing the institution&#x27;s work. reply panarky 17 hours agorootparentprevJan Hendrik Schön, a researcher at Bell Labs in the field of condensed matter physics, committed scientific fraud by fabricating and manipulating data in his research.The fraud was discovered in 2002.I&#x27;m thankful that most people can understand the difference between the institution from the fraudster, because Bell Labs has produced some amazing work since then. reply atrettel 14 hours agorootparentFor those unfamiliar with the story of Jan Hendrik Schön, I suggest watching this excellent series of videos by BobbyBroccoli on YouTube [1-3]. The series does a good job breaking down the context and the situation that Schön was in, along with the incentives that encouraged Schön to commit fraud.[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=nfDoml-Db64[2] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Riio1eKOSKg[3] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=KsSuhP60qnI reply HFguy 19 hours agoparentprev [–] Stanford is a big place. Would not disregard all the work from anyone connected just because of something the president did. reply alwaysrunning 19 hours agorootparent [–] See my comment above, I am sure there are great ppl that work there but the timing? reply hackernewds 18 hours agorootparent [–] should I wait 2 years then it&#x27;s fine to use the data science handbook for my interview prep? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The handbook emphasizes the significance of open, transparent, and reproducible research.",
      "It addresses the limitations of research that is not widely accessible and the challenges of replicating previous work.",
      "The handbook provides practical guidance on study design, data analysis, and publication, promoting open science practices and the sharing of research materials."
    ],
    "commentSummary": [
      "Users on Hacker News are discussing a newly published handbook on open, rigorous, and reproducible research.",
      "The conversation includes discussions on using Docker or online computation platforms for creating reproducible research environments.",
      "Some users express interest in using the handbook as a resource for training their data science team, while others debate whether the recent controversy surrounding the president of Stanford University discredits the institution's work."
    ],
    "points": 270,
    "commentCount": 24,
    "retryCount": 0,
    "time": 1699794259
  },
  {
    "id": 38240212,
    "title": "Casino-style apps draining millions from addicted users, raising concerns over lack of regulation",
    "originLink": "https://www.nbcnews.com/tech/tech-news/addicted-losing-how-casino-apps-have-drained-people-millions-n1239604",
    "originBody": "Tech News Addicted to losing: How casino-like apps have drained people of millions NBC News spoke to 21 people who said they were hooked on casino-style apps and had spent significant sums of money. The industry is almost entirely unregulated. Stephanie Kubo / for NBC News Print Save Create your free profile or log in to save this article Sept. 14, 2020, 10:00 AM UTC By Cyrus Farivar Shellz, 37, a nurse from Houston, spends at least two hours a day with her husband playing a casino-style smartphone game called Jackpot Magic. The app offers a variety of typical casino games to play, including their favorite, called Reel Rivals, a game in which players accrue points by playing a virtual slot machine. As in a real casino, players exchange money for coins to bet. Unlike in a real casino, there is no way to win money back or earn a payout on coins. But that has not stopped Shellz and her husband from spending about $150,000 in the game in just two years. She asked to use her in-game username so her family does not find out how much money they have spent on the game. \"We lie in bed next to each other, we have two tablets, two phones and a computer and all these apps spinning Reel Rivals at the same time,\" she said. \"We normalize it with each other.\" Jackpot Magic is an app made by Big Fish Games of Seattle, one of the leaders in an industry of \"free-to-play\" social games into which some people have plowed thousands of dollars. Big Fish Games also operates a similar app, Big Fish Casino. Both are labeled as video games, which allows the company and others like it to skirt the tightly regulated U.S. gambling market. But unlike the gambling market, apps like Jackpot Magic and Big Fish Casino are under little oversight to determine whether they are fair or whether their business practices are predatory. NBC News spoke to 21 people, including Shellz and her husband, who said they were hooked on the casino-style games and had spent significant sums of money. They described feelings of helplessness and wanting to quit but found themselves addicted to the games and tempted by the company's aggressive marketing tactics. Most of the 21 players wished to remain anonymous, as they were ashamed of their addictions and did not want their loved ones to find out about their behavior. Addiction support groups turn to apps to help members stay on track March 31, 202003:08 A 42-year-old Pennsylvania woman said she felt saddened that she spent $40,000 on Big Fish Casino while working as an addiction counselor. \"The whole time I was working as an addiction counselor, I was addicted to gambling and with no hope of winning any money back,\" she said. Big Fish Games did not make anyone available for an interview, nor did the company respond to detailed questions. The company has said in previous court filings that only a fraction of the game's players actually spend money. In a response to NBC News' inquiries, the company issued a statement saying its games are not gambling and should not be regulated as such. \"These games are not gambling because, among other reasons, they offer no opportunity for players to win money or anything of value,\" the statement said in part. \"Our games are offered for free purely for entertainment, with an opportunity for customers to spend money within the game to enhance their gameplay experience,\" it said. \"The vast majority of Big Fish Casino and Jackpot Magic Slots customers play without ever paying any money. No court has yet considered all of the facts relating to how these games operate.\" Players have had some recourse in recent months thanks to successful lawsuits. After a long legal battle, 2 million players, including Shellz and her husband, will be eligible to get a small part of their losses back — about 20 percent for those who lost $10,000 to $100,000. The money will come in a $155 million class-action settlement, announced at the end of July, that will cover two major lawsuits filed against Big Fish Games; its former owner, Churchill Downs; and its current Australian parent company, Aristocrat Leisure, alleging that they were operating \"unlawful gambling devices.\" The preliminary agreement was recently approved by a federal judge in Tacoma, Washington. Churchill Downs and Aristocrat Leisure both declined to comment on the settlement. Aristocrat Leisure released a public statement in May outlining the general contours of the settlement, but it has not said anything further. Download the NBC News app for breaking news and politics While Big Fish Games admits no wrongdoing, it has agreed to implement \"addiction-related resources\" and a \"self-exclusion policy\" that would allow players who feel out of control to opt in to be blacklisted from playing the game. Big Fish Games also declined to comment on the settlement. While some players are happy to recoup some of their losses, gambling addiction experts and some lawmakers say it does not go far enough to help those whose lives have spiraled out of control after they got hooked on social casino games. They call for further regulation of the industry. \"What we would have welcomed as part of this settlement as a wake-up call for the industry is a change in practices,\" said Keith Whyte, the executive director of the National Council on Problem Gambling. \"I think their model is so lucrative and in some ways so aggressive that they're doubling down, and it's going to do a lot more harm. I think it's going to eventually be reined in, but it appears they are prioritizing short-term profit over long-term sustainability and responsibility,\" Whyte said. The game Joann, 46, who lives in southwest Florida, said she began playing Big Fish Casino about eight years ago. She estimates that she has spent $100,000 on the game. \"You know what I tell people? It's a cult, and they suck you in, and once you're in you can't get out,\" said Joann, who asked to use only her middle name. \"You want to play, and you want to spin.\" One of the named plaintiffs in the settlement is Crystal Fair of Texas, who said in a sworn declaration that she has spent $500,000 and described herself as being \"addicted\" to Big Fish Casino, playing it sometimes \"nearly 24 hours a day.\" \"I have considered walking away for good but then I think of all my time and more importantly all my money and it's hard to walk away,\" she wrote. \"That's how I know I'm addicted.\" She concluded: \"But if I could go back to the point in time when I installed Big Fish Casino, I'd never ever have done it.\" Several people said they felt the apps were engineered to keep them spending money in a variety of ways, including tiered clubs for players who spend significant amounts of money and free chips for people who try to quit. Suzie Kelly of Dallas previously told Reveal News how she spent about $400,000 on the game. She took out a home equity loan and used the money she inherited when her mother died to fund her habit. When she tried to cancel her account on several occasions, Kelly said, a \"VIP representative\" would call her and offer her free chips so she would continue playing. The Big Fish apps in some ways are similar to many other apps that offer casino games that can be played on smartphones. The home screen of Big Fish Casino, known as the \"lobby,\" offers players a chance to try various types of casino-style games, including roulette, blackjack, Texas Hold 'em, Video Poker and the most prominently featured game: slots. Shortly after they install the app, players are encouraged to join clubs — Big Fish Casino even offers a \"one time join bonus\" of 50,000 chips for joining a club. Once they are in a club, players can use a chat feature to strike up conversations with their counterparts and develop friendships. While anyone can create a club, the real action is in the invitation-only ranked clubs that compete against one another. Winning more chips and playing at higher stakes unlock new features, like high-roller rooms. There is also a system of \"levels\" and \"tiers\" to unlock as players spend and win more. Higher tiers come with larger potential winnings and bigger bets, which makes it easier to lose chips faster. Players who lose but want to continue playing in high-roller rooms can do so by either rebuilding their digital fortunes through hours of gameplay or taking a shorter route: buying more chips. Most people who play the Big Fish games do not end up spending real money. Less than 10 percent of users have ever bought virtual items while playing the games, according to an October court filing. But that 10 percent has translated into a lucrative business. According to data provided by Apptopia, an app analytics company, Big Fish Games took in an estimated $139.3 million from Big Fish Casino and Jackpot Magic players from February 2019 through July 2020. The app's tier system, along with its social functions, can be a powerful trap for some players. Joann said she continues to play, as Big Fish Casino grants her a set of free chips (known as a \"boost\") every day. Even so, she said, she spends at least $600 a month, largely to maintain her status within her club. \"I want to quit the club, and I want to stop, but I have friends,\" she said. No recourse Big Fish Games is one of the clearest examples of the convergence of the small-time harmless fun of video games and the rapidly expanding world of real-money gambling. While many video games have added premium features in recent years, including loot boxes — a mechanism to pay small, fixed fees for chances to win in-game prizes that has attracted the ire of some lawmakers — no other type of game appears to allow players to lose so much credit so quickly and be constantly encouraged to spend more. But for the time being, there does not seem to be anything stopping these gambling-style smartphone games from continuing. No federal legislation would halt this model, nor would any state-level legislation mitigate losses created by this type of game. Washington state legislators considered a bill that would have formally defined games like Big Fish Casino to not be considered gambling, but the bill did not pass. Some players of Big Fish games have filed class-action lawsuits against the company, arguing that its games should be regulated just like traditional gambling, which is unlikely to happen any time soon. Conventional slot machines, for example, are subject to rigorous outside testing to ensure that the odds are consistent for all players. In Nevada, there are rules about how many slot machines can be placed in liquor stores, among hundreds of pages of regulations. In Washington state — where Big Fish Games is located — slot machines are banned outright. But Washingtonians can download a smartphone game that offers would-be gamblers the chance to spend money on an experience nearly identical to that of an in-person slot machine, only without any chance of actually winning money. Still, the recent legal victories are a welcome bit of help for some players, particularly because many have lost their jobs because of the COVID-19 pandemic. Neva Barker, 58, a retiree in Portland, Oregon, estimated that she had spent $80,000 on Big Fish Casino and said she was thrilled to hear that she likely would get some of her money back. It is particularly needed now, because, Barker says, she lost some of her income to coronavirus-related cutbacks. \"This has been going through so many ups and downs,\" she said. \"I thought it was a myth that it was ever going to happen. That would be life-changing for me at this point.\" Cyrus Farivar Cyrus Farivar is a reporter on the tech investigations unit of NBC News in San Francisco.",
    "commentLink": "https://news.ycombinator.com/item?id=38240212",
    "commentBody": "Casino-like apps have drained people of millionsHacker NewspastloginCasino-like apps have drained people of millions (nbcnews.com) 267 points by apsec112 20 hours ago| hidepastfavorite367 comments dkarl 18 hours agoparent\"The company has said in previous court filings that only a fraction of the game&#x27;s players actually spend money.\"I was recruited by a sports gambling company and went as far as interviewing with them. I really enjoyed the interview (interesting tech, really smart people) and I&#x27;ve placed a few bets along with friends before in the past without ill effect, so I did some quick checking about how gambling businesses make money. As far as I could tell, across different gambling businesses, the focus is on \"whales\" -- chronic gamblers who spend as much as they can or more on gambling. The public image of these \"whales\" is the immensely rich person who visits a casino a few weekends per year and casually loses a hundred million that they won&#x27;t miss, but a lot of the \"whales\" are people like the ones in the article, middle class people who lose hundreds of thousands of dollars while desperately trying, and ultimately failing, to stop their addiction from ruining their lives.Online gambling makes it profitable to pursue smaller and smaller whales, because you aren&#x27;t limited by the amount of space inside your casino, or the number of people who live near or can afford to visit your casino. Your targets are everybody where you can legally operate, and you&#x27;re running A&#x2F;B tests and other optimization technology to increase an addictive behavior. I.e., their business model is to stoke a ruinous addiction across every social and economic class in every jurisdiction they can legally operate in.Standard disclaimers: I&#x27;m not an expert, not an insider, not in the industry at all. Also, none of the information I learned was directly about the company I interviewed with. I&#x27;m just talking about my understanding of how gambling businesses work from what I could glean online.Anyway, I didn&#x27;t take that job. reply DanielHB 15 hours agoparentThey are called VIPs, not whales, in sports-betting worldI worked with it for a while and if I was in a position to leave that industry I would have done it sooner. But I do have to say that at least the sports betting companies I worked on they did try their hardest to follow the law as much as possible.One thing I have to say is that it is abhorrent that betting websites are allowed to advertise at all. It should be threated the same as smoking ads regulations. reply gherkinnn 12 hours agorootparent> they did try their hardest to follow the law as much as possibleWell that absolves them now, doesn&#x27;t it? reply chii 11 hours agorootparentIt does doesn&#x27;t it? If someone chooses to gamble, it&#x27;s at least better to do so with regulated companies that have to follow the law. The alternative is to gamble illegally, where you might not even get paid odds or payouts.The world where the gambler stops gambling doesn&#x27;t exist. reply alexashka 14 hours agorootparentprevWait until you realize advertising should not be allowed. reply allenrb 14 hours agorootparentI can’t see how this deserves to be downvoted. As far as I’m concerned, anything other than “just the facts, ma’am” advertising is about preying on human weakness. It’s legal, but is it right? reply jjeaff 14 hours agorootparentI don&#x27;t think it is correct to say all advertising is preying on human weakness. Some people create good and beneficial products. advertising is how you get the word out about your product. reply weaksauce 13 hours agorootparent> Some people create good and beneficial products.and those would shine with a \"just the facts ma&#x27;am\" approach. reply jjeaff 10 hours agorootparentIf you put a commercial on TV with \"just the facts\" it&#x27;s still an ad. reply tekknik 5 hours agorootparentif you make a useful product it will be found regardless reply kortilla 4 hours agorootparentThat doesn’t work outside of mass market products. reply Terr_ 13 hours agorootparentprevThe real problem is where to draw the line, which is partly cultural.There&#x27;s a similar concept in legal contracts, with \"unconscionable\" terms. reply alexashka 13 hours agorootparentprevJust have a website&#x2F;app&#x2F;whatever that displays a database of products and information about each, comparisons, etc.There is no excuse for invading people&#x27;s lives with unasked for media of any kind.People who want to know about new products can go to places where such information is available and seek it out. replynobodyandproud 17 hours agoparentprevThis is the business model of many free-to-play games.For instance: Overwatch relies on whales to purchase their excessively expensive and worthless in-game skins, and fund the business. reply kaibee 17 hours agorootparentBuying skins in a game is the same thing as buying fashionable&#x2F;brand-name clothes. Gambling is different. reply meristohm 16 hours agorootparentI was a Hearthstone whale on a small scale relative to wealthier people and a large scale relative to my family&#x27;s annual income. I wanted certain gold cards (rarer) for aesthetic reasons in my decks, and shortly before I quit all Blizzard games (for the slot machines they are, to me) I bought fifty packs just to get enough dust to craft the golden legendary I wanted.I did something similar with World of Warcraft, buying a level boost that I ended up not using, just to \"round out my character list.\" It was a low point in my life and I will never go back to that behavior.I recognize these games can be used and enjoyed responsibly, just not by me and that&#x27;s okay. reply supertofu 15 hours agorootparentThis comment made me chuckle. Because I am a sober alcoholic. One of the things I remind myself all the time is: \"It&#x27;s wonderful that people can enjoy alcohol in moderation. I am not one of them.\" reply wickedsickeune 14 hours agorootparentprevIt makes me sad that you can&#x27;t play quite good games, just because predatory monetization has ruined them. It&#x27;s not your fault, it&#x27;s just the world we live in. reply meristohm 13 hours agorootparentHearthstone helped me get over my regret about selling all my Magic: the Gathering cards. I played Magic on the school bus in the 90s, had a lot of fun trading and making decks, and eventually sold it all because I didn&#x27;t make the effort to find people to play with.Hearthstone lowered that barrier significantly, and I still consider it an excellent game, aside from the predatory&#x2F;monetary trappings. I might still play it if it could be done with real magic at my dinner table with friends, for a one-time flat fee or for the caloric cost to summon all the components, assuming some reasonable magic system.As it is now, I like playing Cribbage with my wife, and am looking forward to teaching our daughter how to play Chess, Go, Backgammon, Arimaa, and any other game that isn&#x27;t packaged in a predatory wrap. reply nylonstrung 15 hours agorootparentprevYeah it&#x27;s exactly like buying Gucci, except if it was dispensed in a slot machine and you had to spin it 100 times to get the clothes you want.And the odds of the machine were rigged and personalized to you, which is illegal in real gambling reply pests 15 hours agorootparentOverwatch and almost all modern games moved past the lootbox mechanic because that was getting too close to many countries gambling laws.Now you just buy what you want.Like you go into a store and buy a Gucci wallet. You go into the Overwatch store and buy the latest One Piece Collab.No slot machine or anything. reply TheOtherHobbes 14 hours agorootparentThe Overwatch store is in your living room and available 24&#x2F;7, before&#x2F;during&#x2F;after intense gameplay. reply Miiko 14 hours agorootparentDo you know that Gucci has on-line store, also available 24&#x2F;7 from your living room? reply tekknik 5 hours agorootparentGucci isn’t affordable by many, a $30 skin is. Plus the overwatch skin is digital, you can’t resell it nor does it mean anything in the real world. Not the same. reply intelVISA 15 hours agorootparentprevRegarding RMT, I think Valve did the master play with their proto-NFT marketplace stuff, really ahead of the curve. reply DanielHB 15 hours agorootparentprevThere is a distinction between lootboxes with tradable items and those without, if the items are tradable it is literally gambling. But yeah, sucky either way reply pauldenton 13 hours agorootparentIt&#x27;s not the trading, it&#x27;s the paying money for lootboxes. Plenty of roguelikes&#x2F;roguelites have loot boxes, but they randomly generated chests you open by defeating bosses, not by pulling out your credit card reply AussieWog93 13 hours agorootparentprev>Yeah it&#x27;s exactly like buying Gucci, except if it was dispensed in a slot machine and you had to spin it 100 times to get the clothes you want.Not sure if you&#x27;re into buying designer stuff, but that industry is going in a similar-ish direction.People buy a bunch of undesirable crap just so they can be put on the VIP list and maaaaybe get the opportunity to purchase the actually desirable products at a far below market price.Not sure if Gucci themselves do this, but I know Rolex and at least one of the big handbag brands (Hermes?) operate this way. reply nobodyandproud 15 hours agorootparentprev> Buying skins in a game is the same thing as buying fashionable&#x2F;brand-name clothes. Gambling is different.It’s not a good fit either: A game company can terminate your account and you lose it all.Depending on the game, but in some you also cannot resell or transfer your skins. Therefore the only thing of value is the account, but terms of service also make this a non-starter.What’s consistent here is that the business model revolves around feeding and addiction and relying in said addicts (aka, whales). reply Tarball10 10 hours agorootparentprevYou can resell clothes. You can&#x27;t resell skins in most games, including Overwatch. reply candiddevmike 14 hours agorootparentprevBuying skins from the skinner box reply wellthisisgreat 17 hours agorootparentprevUnless the skin is in a lootbox reply mugwumprk 17 hours agorootparentprevI&#x27;m not in that industry, but if I was, I bet you could do something shady. Perhaps people who buy expensive skins have an increased chance of \"luck\" within the game. Critical hits may be more likely, more high quality gear drops. It&#x27;s possible there isn&#x27;t a clear line between gambling and fashion. At least, that&#x27;s if the industry is unscrupulous, and I generally assume that describes most companies. reply Darmody 16 hours agorootparentHaving played a lot of games, if that was the case, it would be vox populi. In all gaming communities there are very smart people and if the damage output is important, they&#x27;ll have it traced, if loot if important, it&#x27;ll be traced too. reply mvdtnz 14 hours agorootparentprevIn the Call of Duty games if you purchase a premium skin the matchmaking algorithm tries to match you into servers where fewer (or no) players have that same skin, to increase the feeling of exclusivity. This is not a secret, Activision even patented the idea. reply Terr_ 13 hours agorootparentI wonder if anybody specifically gets \"elite\" skins to increase their odds of being matched against easier opponents. reply alstonite 17 hours agorootparentprevIn my experience most free-to-plays just use a battlepass nowadays and don’t rely on whales (though obviously all games have them)Gambling based games like cs:go and genshin absolutely apply to what you’re saying though reply whateveracct 17 hours agorootparentBattle Pass is just a subscription with more steps. It was cool when I could just pay $50 for an online game and play it for years in dedicated servers so long as there were other people who paid $50 out there. reply StableAlkyne 15 hours agorootparentI miss community-hosted servers in games.Nowadays it&#x27;s all servers that are only run by the developer, who could just flip a switch tomorrow and tell you \"Remember that $80 you spent on Game 1 few years ago? You&#x27;re gonna have to pay up again for Game 2. Also we&#x27;re turning off the servers for Game 1.\" reply pests 15 hours agorootparentOverwatch 2 was odd because it was only half that.\"Remember that $80 you spent on Game 1 a few years ago? Well, you get Game 2 for free. Also, were turning off the servers for Game 1\"It doesn&#x27;t sound as wrong but the community still hated it. reply Jochim 15 hours agorootparent> It doesn&#x27;t sound as wrong but the community still hated it.It only seems odd if all context is left out.Blizzard&#x27;s whole pitch for Overwatch 2 is that it would introduce single player and co-op PvE content. It didn&#x27;t do that.Overwatch 2 was much stingier with rewards for gameplay than Overwatch 1.Overwatch 2 started locking new heroes behind a paywall, where they&#x27;d previously been entirely free in Overwatch 1.Overwatch 2 charged much more for it&#x27;s items, and limited specific items to bundles in an attempt to force players to spend much more than they would for the item itself.Overwatch 2 made multiple changes to balance, that weren&#x27;t always well received.The sad thing is that people seemed fairly excited for PvE Overwatch. That excitement was strangled through a combination of hubris, corporate greed, and an inability to deliver. reply spondylosaurus 14 hours agorootparentThere&#x27;ve been PvE missions for a few months now. I think part of the reason they were initially cut&#x2F;delayed was because of all the shakeups at Blizzard after so many people left and&#x2F;or got fired for misconduct.Also, you mention unpopular balance patches, but \"Blizzard sucks at balancing\" has been a complaint since the early days of OW1 :P I remember when the first Mercy rework dropped... and the Bastion rework... and everything about Brigitte... reply Jochim 12 hours agorootparent> There&#x27;ve been PvE missions for a few months now. I think part of the reason they were initially cut&#x2F;delayed was because of all the shakeups at Blizzard after so many people left and&#x2F;or got fired for misconduct.The missions they released have nothing in common with what was discussed. PvE was meant to have persistent hero levelling, skill trees, and a proper story. What they eventually released wasn&#x27;t far off what would&#x27;ve been a seasonal event game mode in the past, in addition to being laughably expensive and horribly broken.> Also, you mention unpopular balance patches, but \"Blizzard sucks at balancing\" has been a complaint since the early days of OW1 :P I remember when the first Mercy rework dropped... and the Bastion rework... and everything about Brigitte...The OW2 changes went beyond a broken hero. They made fundamental changes to the way the game is played with the reduction in team size and changes to tanks. reply pests 12 hours agorootparentAll this.I discovered OW1 a year before it was ended. I was addicted to this game like I haven&#x27;t been since I was a teenager. I would sleep and dream of the music.. it was bad.OW2 came out and it instantly changed things. Tanks were no longer fun to play. I haven&#x27;t played a single game of OW2 in almost 10 months. reply pests 13 hours agorootparentprevThey are only a glimpse of what was promised. They&#x27;re void of humans and filled with bots now. No replayability and just a learning down. reply pauldenton 13 hours agorootparentprevDo they have custom map support yet? Most of my time in TF2 was not spent on official maps. It seems like server browsers have been disappearing since the jump from MW1 to MW2, where the quality of the PC experience is dampened for the sake of making it more like the console experience. reply pests 12 hours agorootparentNope. Custom game modes and all that exist solely on existing maps or the testing plane&#x2F;box maps.The cloest Overwatch has ever gotten to a custom map was when a (offical) OW map designer was desinging a level with his viewers on Twitch one day. Blizzard than later suprised everyone by putting it in the game for a limited time. replymathgeek 16 hours agorootparentprevMany use both in order to capture multiple types of buyers. reply kurthr 16 hours agoparentprevA co-worker&#x27;s spouse took a job at a company like that. I heard about it at a company dinner. I knew that they were quite religious so I had to ask how that squared, and the response was, \"Oh, I would never use the product\". It made me feel really uneasy, since I knew I&#x27;m fairly libertarian and I&#x27;d have a problem sleeping on it. The argument is always, if I don&#x27;t take the money, someone else will. I guess I wouldn&#x27;t like working in a liquor store or a bank either. reply paulryanrogers 15 hours agorootparentIME religious beliefs require suspension of disbelief and a certain amount of cognitive dissonance.When I was religious I was uncomfortable with gambling and always voted to outlaw or heavily regulate it. Yet I can see folks I knew easily justifying taking such a job. The mentality was work for the heathen to win them to Jesus, and if you got really well paid then that&#x27;s more you can tithe to the kingdom. reply qingcharles 9 hours agoparentprevFrom experience the stats are roughly thus:- 4% of users pay for something- 1% of users fund the entire business reply iancmceachern 17 hours agoparentprevReminds me of most social media reply dragontamer 17 hours agorootparentSocial media doesn&#x27;t cause $100,000+ in direct losses like gambling does. reply iancmceachern 17 hours agorootparentIt does cause serious lifelong mental illness, which often results on $100k+ in indirect losses.https:&#x2F;&#x2F;mitsloan.mit.edu&#x2F;ideas-made-to-matter&#x2F;study-social-m...And they, including Mark, actively worked against doing something about it:https:&#x2F;&#x2F;www.google.com&#x2F;amp&#x2F;s&#x2F;www.cbsnews.com&#x2F;amp&#x2F;sacramento&#x2F;... reply zeroonetwothree 10 hours agorootparentThe article you linked certainly doesn&#x27;t use the words \"cause\" or \"lifelong\". reply charcircuit 17 hours agorootparentprevThis isn&#x27;t gambling as you don&#x27;t win anything of value. Every dollar you spend is guaranteed to never get you any money back. reply vkou 17 hours agorootparentprevSocial media can certainly ruin your life, but it doesn&#x27;t seem to do it quite as spectacularly and as thoroughly as a bad case of gambling addiction does.And if it weren&#x27;t for those bad cases, most of the gambling industry wouldn&#x27;t exist. They aren&#x27;t making their money from my friends flying down to Vegas and losing $50 each at the blackjack table. reply TacticalCoder 16 hours agoparentprev> ... but a lot of the \"whales\" are people like the ones in the article, middle class people who lose hundreds of thousands of dollars while desperately trying, and ultimately failing, to stop their addiction from ruining their lives.$4.4 m of net worth puts you in the top 1% by US standards. In the rest of the world (short of Monaco, Luxembourg and Switzerland and the likes), it&#x27;s much less. For example top 1% in France means a net worth of $2m.I find it hilarious the notion that the \"middle class\" would have \"hundreds of thousands of dollars\" of disposable income to splurge on gambling.I&#x27;d go as far as saying that being in the top 1% in, say, France, puts you in the \"rich\" class, not the \"middle class\" and that with a net worth of $2m you do not have line of credits allowing you to bet hundreds of thousands of EUR&#x2F;USD.P.S: I was invited at some dude&#x27;s place where he had this 3 meters high Jeff Koens sculpture (Ballerinas, kinda Jeff Koens&#x27; trademark), probably worth millions. He had four house employees serving coffee, cooking, etc. Reading HN I&#x27;d be tempted to believe he was actually a poor middle class chap and that only the Zuck and Gates are \"rich\". reply dasil003 16 hours agorootparentI&#x27;m confused, are you just mad about the label middle class, or do you believe that the only people spending large sums on gambling can afford it and therefore there are no ethical issues in this type of business?Because you seem to be setting up a straw man bringing in a lot of talk about net worths in the millions, when the conversation was about losing \"hundreds of thousands\". The median net worth for a US family is $192k according to a recent Nerdwallet article, so it&#x27;s absolutely in the realm of possibility that millions of Americans are vulnerable to losing hundreds of thousands to a gambling addiction. Certainly a lot of people would have their lives destroyed by losing $50k to a gambling addiction, and no doubt that happens plenty. Where we draw the line on what constitutes middle class doesn&#x27;t really seem all that relevant to me. reply Espressosaurus 16 hours agorootparentprevI think dkarkl&#x27;s point is that it&#x27;s not disposable income. Using the house HELC or emptying the retirement account to fund your gambling habit is an easy and ruinous way to get your hands on hundreds of thousands of dollars if you&#x27;re middle class. reply mathgeek 16 hours agorootparentprev> I find it hilarious the notion that the \"middle class\" would have \"hundreds of thousands of dollars\" of disposable income to splurge on gambling.Don’t forget that there’s also an entire industry looking to loan money to middle class folks. reply supertofu 15 hours agorootparentprevThe point of the article is that those hundreds of thousands of dollars are NOT disposable income -- they are life savings and home equity loans. What a callous comment. reply zeroonetwothree 10 hours agorootparentprevIf you read the article, one of the persons took out a HELOC to fund their addiction. Another one blew their entire inheritance. None of that is \"disposable income\". reply carlosjobim 14 hours agorootparentprev> I find it hilarious the notion that the \"middle class\" would have \"hundreds of thousands of dollars\" of disposable income to splurge on gambling.They get access to that money by borrowing it or embezzling it. Lots of middle class people have boring jobs with access to hundreds of thousands of dollars or millions of dollars. reply matt123456789 19 hours agoparentprev\"Suzie Kelly of Dallas previously told Reveal News how she spent about $400,000 on the game. She took out a home equity loan and used the money she inherited when her mother died to fund her habit.\"This is a symptom of problem gambling. The article makes it sound like this app is exploiting the same neurological reward pathways as regular gambling, and causing the same kinds of damage. The lack of monetary reward might prevent more people from trying this compared to other apps where winning money is a possibility, but exactly the same kind of people will get hooked on this version, and in the same way, and cause the same kind of damage as problem gambling for money. reply skippyboxedhero 19 hours agoparentThere is a book on this called Addiction by Design that covers a lot of this.But yes, I think the assumption of rational people is that the reason these practices are addicting is the money involved...when it isn&#x27;t the money but a carefully designed sensory experience that (somehow) taps into addiction. If you actually look at how the slots industry works though, they largely focus on the sensory experience not the gambling side. I have used slots and they do seem to dull your other senses&#x2F;captivate you whilst using them.Just imo, I gamble myself, have done so for all of my adult life, I know many people in the industry who are fine people, the spillovers for tech have been absolutely huge (for example, a lot of the bot detection tech we have today was invented in the gambling industry)...but slots&#x2F;casino should 100% be banned. I am not a banning person naturally at all but they are just awful. Any kind of tech that seeks to replicate that process (these apps, FIFA, etc.) should also be banned because it isn&#x27;t about the money, gambling is nothing to do with it. Casino products add nothing and the only people who find it appealing (in my experience) are gambling addicts. I used to work in equity research and covered the big UK gambling companies...at no point did I see any evidence that casino products had anyone but gambling addicts as customers either. You can have a laugh at the horse racing with your pals, lots of people put their accumulator on every weekend and that is it, maybe put 5 on a Prem match...but casino isn&#x27;t like this, it is pure cancer. reply teeray 18 hours agorootparent> they largely focus on the sensory experience not the gambling sideEvery time I’ve sat at a slot machine, it’s not even clear if you’re winning or not, or what the rules are. It boils down to “push button, watch absurd animations and sounds.” I just find all that sensory overload irritating, so I don’t usually stay. I can see, however, that if you like that experience, it could be powerfully attractive. reply anjel 18 hours agorootparentIn the old days (1970s-1980s?) you could ask a casino employee for a card with the gaming odds for the various games &#x2F; game bets the house was offering the gambler. About ten years back I was in a casino and had the same feeling of disconnect watching others play slots (IIR, it was in Palm Springs Ca.) So I see the casino manager walk by and ask him for a card on the odds for slot machines. He let out a long laugh and said \"I haven&#x27;t seen those in a long time but if I even had one to give you, I would get fired for showing you that kind of info.\" reply preinheimer 16 hours agorootparentEvery modern slot machine I’ve used will show you exactly that information. It’s somewhere in a help menu.It’s not at all comprehensible, imagine boilerplate TOS from a big company, with a third year statistics course mixed in. But it’s there. reply jacquesm 16 hours agorootparentprevDoesn&#x27;t the state regulate the odds there? If so it would be public information anyway. reply skippyboxedhero 16 hours agorootparentYes, all the online casinos have this information too. An interesting question is whether providers of these fake money casinos actually alter odds to maximise yields? Presumably. I believe FIFA has fixed odds for their gambling stuff. reply fbdab103 11 hours agorootparentThere was a recent post[0] where the author discovered that the company had deliberately tuned the loss rate so as to incentivize purchases. Which, I suppose is legally in their power. It is \"just a game\" where they can set the rules however they like.[0] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37642538 reply saiya-jin 14 hours agorootparentprevWhat are the chances somebody from law enforcement is going to decompile your cryptographically signed obfuscated binaries to hunt for exact numbers in equations that can span across whole codebase if you want... exactly.You can just spin a new company every few years claiming completely new software, so law has tough time building case and catching up and probably couldn&#x27;t care less unless somebody literally snitches on you. reply jacquesm 13 hours agorootparentThe casino industry is as highly regulated as they come. Code is inspected, fines are huge and licenses to operate can be withdrawn in case of established fraud.There are many ways casinos try to part their visitors from the money but fraud - these days, not the past - usually isn&#x27;t the driver. But psychology, greed and environment are just as effective, if not more effective at accomplishing the same goals. The best way not to lose any money in a casino is by not going there in the first place. Most people believe they are immune to the envy of thinking other people around them are winning but they&#x27;d be wrong and the whole environment there is geared to make you move into FOMO mode until you&#x27;re broke. replygarciasn 18 hours agorootparentprevYes. Exactly this. No one understands and there isn’t a need to understand. You put money in and either you lose it all or you win some percentage back that you lost before.I’m not a gambler, but out of all of the ways to lose your money in a casino the video slot machines make the least sense to me; they just don’t seem at all enjoyable win or especially lose. reply wombatpm 14 hours agorootparentI’ve never trusted video slot machines, probably because I know as a developer how easy it is to rig them. Always show a jackpot hand if you’d have increased your bet, payout a winning spin every so often to keep the mark sitting down, and have the big payouts only happen to some who punches in the right combo on the right machine during a specific window in time. reply Aerroon 2 hours agorootparentprev>It boils down to “push button, watch absurd animations and sounds.”Because that&#x27;s it. It&#x27;s just a random number generator that decides whether you win or not. Then based on that it generates all of the bells and whistles to show you, but what&#x27;s happening on the screen doesn&#x27;t matter. You&#x27;ve already won or lost by the time you pressed the button.It&#x27;s justif (Math.random()Like you have all these middle-eastern countries that ban alcohol, premarital sex, gambling- everything you can think of is illegal but people still need their vices. And then they lash out in dangerous and disturbing ways.I&#x27;m with you most of the way, but there is a middle ground. Every system needs some friction so it doesn&#x27;t become a runaway train.Don&#x27;t ban it, but don&#x27;t make it so easy either.Take porn. Before the internet, we (as kids) had to hunt for it. We had to network to find other kids whose dads had magazine stashes we could raid, or corner stores we could sneak peeks at the magazine rack of and rip pages out without getting caught. There was effort and risk involved. Obtaining it was an adventure and reward in itself. By the end of the day, you were tired-- and not always successful! It satiated some primal need for conquest, in addition to being sexually gratifying.Now you can get to it in two clicks, and the extremity of the content stops just short of snuff. If they&#x27;re being honest with themselves, nobody&#x27;s really happy with the current state of porn, which leads to escalating behavior in similarly dangerous and disturbing ways. All roads lead to eventual interest in CSAM, and even that&#x27;s not enough.In a weird turn of events, porn is actually contributing to the emasculation of men. We&#x27;re losing our ability to hunt because we expect everything to just be handed to us in two clicks. There&#x27;s no thrill in that chase. Incest porn dominates trending pages. Wanting to fuck your mother or sister--a captive audience--is as lazy as it gets. (Cousins would be an improvement...at least you&#x27;d have to leave the house.)Gambling is the same. It&#x27;s easy to lose. The rewards are fleeting but potent. All it is is clicking a button and wasting away. You&#x27;re reduced from being an apex predator to prey caught in a raccoon trap-- and held there by your own greed.Even in a free society, nothing should be this easy. We&#x27;re supposed to hunt lesser animals, not be predatory toward each other. Making vice so easy makes potential prey of us all. reply verall 14 hours agorootparent> All roads lead to eventual interest in CSAM, and even that&#x27;s not enough.What??> In a weird turn of events, porn is actually contributing to the emasculation of men. We&#x27;re losing our ability to hunt because we expect everything to just be handed to us in two clicks.Huh??If that&#x27;s how porn affects you then I think you needed therapy, with or without the pornography. reply debatem1 14 hours agorootparentprev> you can’t ban things because a minority of people don’t have self-control. If that were the case, we would ban beerWe did ban beer. Parts of the country still have bans on beer. Almost every part of the country has bans on certain types of beer, or certain behavior by beer makers, distributors, and sellers.The reason beer is broadly legal is not because it was illegal to ban it, but because the ban was unpopular and got reverted.We could do the same for gambling or anything else for that matter. There is no fundamental right to make money as you see fit in the United States. reply zeroonetwothree 10 hours agorootparentIt would be better to make the point that banning beer didn&#x27;t have the happy results proponents thought it would. Or take the \"war on drugs\" as a more recent example. Not only does it not prevent addicts from getting it, it leads to a huge increase in crime. reply vunderba 10 hours agorootparentprevYeah we did. It was called prohibition, and how&#x27;d that work out? People drank anyways but this time without strong regulatory bodies to ensure the safety and manufacture of said libations. reply adamesque 15 hours agorootparentprevRegulation isn’t perfect but it can do a lot to prevent the worst outcomes. reply pauldenton 13 hours agorootparentprevWe can change the incentives of these game makers&#x2F;designers, through the legal system. As an example, Paypal and credit card companies offer charge backs. What if you could charge back for all the money spent on a game, at the cost of getting your account&#x2F;IP banned and being forced to uninstall the app? If the 400,000$ the whale spent got returned to them, they would be made whole. It&#x27;s not like alcohol or tobacco where you&#x27;ve physically consumed resources. You are undoing access to digital resources and returning those to the company in exchange for all the money the player spent. reply matwood 19 hours agoparentprevGambling is also probably one of the worst addictions to get into. People tend to notice someone with a substance problem, but gambling often stays hidden until the person is completely overwhelmed. reply qingcharles 9 hours agorootparentBelieve me when I say that sex addiction is worse because it has a much higher stigma attached to it, so it is generally much more hidden.You could go to your wife and explain that you&#x27;ve spent the rent money on buying Smurfcoins to gamble on some lootbox lottery, but you can&#x27;t go and tell her you&#x27;ve spent it on paying women to push squirrels up your bottom. reply ethanbond 15 hours agorootparentprevEspecially now that you can do it on your phone reply rjh29 19 hours agoparentprevSurely it&#x27;s even worse, because it&#x27;s available 24&#x2F;7 wherever you are, instead of being somewhere you have to physically visit. reply maneesh 19 hours agorootparentPlenty of online casinos exist as well. reply andy800 17 hours agorootparentThis comment is naive, from someone who doesn&#x27;t understand the different dynamics.The \"play-for-fun\" casinos successfully utilize the onboarding process to attract, and even create, the people most likely to be exploited by these games. Real-money, online casinos require a real-money deposit to get started, therefore, few people download the apps to begin with without being at least a somewhat-experienced brick-and-mortar casino gambler who is prepared to deposit real money.Play-for-fun attracts casuals looking for the next Candy Crush or Bejeweled and might get a week of play (grooming, essentially) before even being asked for an in-game purchase. Further, specifically because play-for-fun is NOT gambling, they are unregulated and have no requirement to be fair or random. The developers can insert all kinds of manipulations and scripted outcomes that encourage more play and more importantly, more real-money purchases. They can amplify the payouts over time so initially, a few thousand coins is exciting, then tens of thousands, then millions. The coin purchases get more expensive as the player requires higher amounts to maintain their levels.Lastly, it isn&#x27;t like real online casinos aren&#x27;t addicting or potentially problematic. Through 9 months of 2023, New Jersey online casinos have generated $1.41 billion, 65% of the brick-and-mortar casino revenue ($2.17 billion). And since online casinos and sports betting are growing much faster, they will likely surpass b-and-m a few years from now. Basically, New Jersey has created an army of addicts in a single decade, and many other states are following suit.https:&#x2F;&#x2F;www.nj.gov&#x2F;oag&#x2F;ge&#x2F;docs&#x2F;Financials&#x2F;PressRelease2023&#x2F;S... reply preciousoo 19 hours agorootparentprevWhy the deflection? Both are a problem, no? One just slips past the “oh gambling is bad for you” mental defense reply sneak 18 hours agorootparentProblem for whom? We also have luxury stores selling expensive designer goods that people waste millions on.Why do we care so much about this specific form of people wasting their money? What’s wrong with letting people go broke the way they choose? reply just_a_quack 18 hours agorootparentThe comparison to luxury goods is not really accurate here IMO. When you purchase a luxury watch you get something tangible in return. These apps purposely prey on psychological weaknesses to get people addicted - a better comparison would be something like phone call scams. reply broken-kebab 16 hours agorootparentWait, per $ spent luxury clothes are generally as practically useless as skins in a game. And, people who sell them do it by tapping into social status instincts. So whether tangible, or not, I don&#x27;t see much difference reply ikr678 6 hours agorootparentYou&#x27;ve still created a tangible product, that someone gets utility value out of, and they could potebtially resell if needed.The good itself is produced by employees, has material inputs from suppliers, contributes to the economy in other ways. reply broken-kebab 4 hours agorootparentI can agree with reselling part (not sure if it works for every luxury item, but I guess in general it should). But economically it&#x27;s still the same. Revenue makes salaries, taxes, it contributes to specific research areas (as other commenter noted bot detection got funded by this induatry) etc. reply lossolo 11 hours agorootparentprevGambling engages the brain&#x27;s reward system, releasing neurotransmitters like dopamine, creating a pleasurable experience. This reinforcement mechanism, coupled with the unpredictable nature of wins, contributes to the development of addiction. The element of chance activates cognitive processes that can lead to irrational beliefs, such as the illusion of control or the gambler&#x27;s fallacy. Factors like accessibility, environmental cues, and social reinforcement further shape addictive behavior. Unlike purchasing goods, where the exchange is tangible and predictable, gambling introduces a unique set of psychological stimuli, risk factors, and reinforcement mechanisms that can lead to addictive patterns and challenges in self-control. reply broken-kebab 4 hours agorootparentThanks, this explanation makes much more sense. However, it&#x27;s still misses the fact that dopamine involved in our lives very widely, and addictions can be developed to practically anything. \"Normal\" games are a good example, as well as obsessive buying, or aesthetic procedures, caffeine, sugar. All this things (and many more) can become uncontrollable, and dangerous to the point of death. When people demand something to be prohibited because they got moved by a story of a poor soul destroyed by addiction they must realize logical implications. Like way more people affected by alcohol than by gambling, and yet at this times most people would point you that prohibition didn&#x27;t work. reply mvdtnz 11 hours agorootparentprevI really think you do not understand the seriousness of gambling addiction. This is not just some excessive discretionary spending. Gambling addicts have a compulsive behaviour that is virtually impossible for them to control. I feel terrible for people with this affliction. It is life-destroying. reply cinntaile 18 hours agorootparentprevI don&#x27;t think you fully understand the issue if you compare this to people buying expensive designer goods. reply broken-kebab 16 hours agorootparentIf you know something others don&#x27;t then please explain. Otherwise, why bother to comment? reply zeroonetwothree 10 hours agorootparentprevLuxury stores don&#x27;t engage in predatory dark patterns, like luring you in with \"f2p\" and so on.I would say the problem isn&#x27;t that it&#x27;s a \"waste\", it&#x27;s that the way it is sold is practically fraud. If the game was presented authentically as \"pay $100 to click a button 100 times and watch some animations\" then I don&#x27;t really think it would be very addicting. reply JakeAl 17 hours agorootparentprevand NFT JPEGs. I agree, there&#x27;s a lot of things people spend their money on, the collectibles industry for example is known for this. Luxury goods appeal to people projecting status because of brand names. Your question is valid, why do we only care about this specific form? In this instance I think it&#x27;s because it&#x27;s about designing apps to be addictive, although I don&#x27;t really agree with that being the case here. There&#x27;s online or even digital slot machines that are not designed to be addictive, they are just virtual slot machines. Then there&#x27;s trading crypto, options and stocks, industries whose marketing and pump schemes are all about projecting an image and manipulating emotions to convince people to buy into what are often scams if not an inversion narrative (which is where you buy into a system rigged against you by some kind of monopoly that when you look at the mechanics functions exactly the way a Ponzi scheme does). I also don&#x27;t think you are deflecting. reply Jochim 14 hours agorootparent> Your question is valid, why do we only care about this specific form?Why do you think people only care about this specific form? It&#x27;s definitely one of the most discussed forms but I&#x27;d think that&#x27;s mainly because it&#x27;s a relatively novel medium.I feel much the same way about betting shops, luxury brands, etc. as I do these \"games\". Luxury brands are often particularly detestable. It has become almost impossible to determine whether you&#x27;re paying for a good quality product or just burning money. Even when of good quality, brands often go far beyond what could be considered moral. Hermes springs to mind in particular, convincing people to debase themselves in the hopes of being offered the chance to purchase an overpriced bag. reply lossolo 11 hours agorootparentprevGambling engages the brain&#x27;s reward system, releasing neurotransmitters like dopamine, creating a pleasurable experience. This reinforcement mechanism, coupled with the unpredictable nature of wins, contributes to the development of addiction. The element of chance activates cognitive processes that can lead to irrational beliefs, such as the illusion of control or the gambler&#x27;s fallacy. Factors like accessibility, environmental cues, and social reinforcement further shape addictive behavior. Unlike purchasing goods, where the exchange is tangible and predictable, gambling introduces a unique set of psychological stimuli, risk factors, and reinforcement mechanisms that can lead to addictive patterns and challenges in self-control. reply jejeyyy77 19 hours agorootparentprevare you from the 80&#x27;s? reply mchanson 18 hours agoparentprevIt’s super gross that Apple and Google are taking a cut of these abusive business models. reply avidiax 15 hours agorootparentApple and Google are totally fine with gambling just as long as it&#x27;s not regulated. reply ren_engineer 18 hours agoparentprevthe lack of monetary reward is just a way to get around the legal definition of gambling, as you pointed out from an addiction perspective the result is the exact same as normal gambling. reply feedsmgmt 18 hours agoparentprevThose big spenders are called whales and they get explicitly targeted and catered to. Those business models choose the predatory path. reply xivzgrev 19 hours agoparentprevIt’s addicting but not gambling. Agree this should be regulated somehow reply thibaut_barrere 19 hours agorootparentIt is regulated at least in a number of countries.In France for instance, only certified operators are legally allowed to run online money games (https:&#x2F;&#x2F;www.economie.gouv.fr&#x2F;cedef&#x2F;jeux-et-paris-ligne).It is just as dangerous as « regular gambling ». reply raincole 19 hours agorootparentI really don&#x27;t know why \"only certified operators are allowed\" is a positive thing.For me it means the money bag is no longer on the table -- not because we removed it or invested it in something better, but because we gave it to the politicians&#x27; best buddies.Edit:I don&#x27;t know French so I might miss some nuances. There are some kinds of regulation that I consider positive, for example to put a certain % of the casino&#x27;s operating cash in a trust funding account (or buy insurance plans) so if they were found fraudulous, at least the victims would get compensated. But I don&#x27;t know if France does this. reply underdeserver 18 hours agorootparentPresumably because you set certain conditions and regulations on the certified operators, with the threat of revoking certification if they fail to comply with these regulations.I would suggest, for instance, that someone about to bet more than 99% of people must have a chat with an official who verifies that they know they&#x27;re addicted and present options for rehab. reply mandelbrotwurst 18 hours agorootparent> someone about to bet more than 99% of peopleHow would you calculate this? By total bet volume alone? A very wealthy person can safely gamble more than a less wealthy one and might reasonably be gambling without being addicted despite having been flagged by this simple algorithm. reply admax88qqq 18 hours agorootparentOh no an edge case!Then that very wealthy person talks to an official who verifies they can afford to bet that much. reply mandelbrotwurst 15 hours agorootparentSnark aside, there are other issues.What if someone has been betting frequently, but they&#x27;ve been winning so far? They&#x27;ll be deemed \"addicted\" by this algorithm. Should they be?How much will it cost to administer this program?How confident are you that it will improve outcomes?Why should I be required to share details of my finances in order to play?Legal gambling has issues but I would definitely vote against your proposal. Keep regulations simple, either allow the activity or don&#x27;t.It&#x27;s not worthwhile to try to duct tape over side effects with mitigation programs of questionable impact that will inevitably be expensive to administer, all while arbitrarily invading peoples&#x27; privacy. reply zeroonetwothree 10 hours agorootparentprevThat&#x27;s right, restrictions on entry into a market primarily benefit the existing participants. There is no significant benefit to consumers from this. Far better regulations would be about how they operate, not who does it. reply bluecalm 16 hours agorootparentprevIt&#x27;s simple really: we want free market when we want a given area optimised. Cheaper goods, better value, more efficient services. Do we want better gambling companies - more efficient at luring people in and getting them to spend money on gambling?I think there aren&#x27;t many sane people without vested interest who answer yes to the question.The solution of only running state lotteries at least ensures there won&#x27;t be much optimisation and the money goes to the public fund. What not to like? reply broken-kebab 16 hours agorootparentYou seriously overestimate \"optimization\" part. There&#x27;s no secret knowledge to manipulate someone. All tricks are simple, the root of the trouble is that some people are more prone to this particular type of addiction.And you propose to make gov&#x27;t to get an interest in exploting addicts. Which is questionable reply danielfoster 19 hours agorootparentprevMoney games are regulated in the US, too, but this is not a money game because there is no money to be won. reply TerrifiedMouse 19 hours agorootparentprevOperates on the same mechanisms as gambling. Might not be considered gambling in the eyes of the law but it&#x27;s gambling to the brains of the victims. reply bobobob420 16 hours agoparentprevIt’s a problem of stupidity and lack of education. If you take a 400,000 dollar loan on home equity to gamble your brain hasn’t developed correctly and you’re probably a risk to other people (drunk driving, bad driving, etc..). Anyways gambling shouldn’t be legal it’s too destructive to society. It needs to be much much more regulated (ie free cash flow has to be proved) reply jampekka 11 hours agorootparentThere are university professors addicted to gambling, so can&#x27;t be at least about formal education. US average credit card debt is $6k, most probably spent on useless crap. Probably majority of people are in that \"risky category\" because making people doing bad decisions is a great business model, and most business use that. reply saiya-jin 14 hours agorootparentprevI wish it would be so linear. But many otherwise brilliant people have &#x2F; had horrible vices and addictions in which they ended up on their own, and despite their own overall brilliance they were utterly powerless to them (or just surrendered with a big grin).People are more complex than that, don&#x27;t do the correlation vs causation mistake. reply crazygringo 18 hours agoparentprevFrom the headline, I thought these were regular gambling apps where you win&#x2F;lose money.But no -- this is something I&#x27;d never heard of. These are apps where you can&#x27;t withdraw winnings.People are spending $100,000&#x27;s with zero potential reward.I&#x27;m... baffled.Although now I guess I&#x27;m forced to ask myself, how is this any different from other free-to-play games like virtual multiplayer golf or Mario Kart or whatever that some people have spent $10,000&#x27;s for equipment&#x2F;upgrades&#x2F;cosmetics&#x2F;etc., that similarly don&#x27;t equate to anything in the real world. reply mugwumprk 16 hours agoparentI think this touches on an idea that isn&#x27;t necessarily intuitive. People may not always gamble for the monetary winnings; that&#x27;s just their excuse. It may be that people do so for the sensory input, and corresponding chemicals their brains release. It would make an interesting (albeit unethical) study: design a casino game where it&#x27;s impossible to win. Would people still get addicted? I suspect they would. reply azmodeus 15 hours agorootparentPeople still get addicted definitely for example the gatcha slot game: Watchers of Samsara in Dota 2.I am not sure why slots work but gatchas are fun in moderation. I personally try to avoid them though and only consume them very rarely. reply iandanforth 18 hours agoparentprevI am reminded of this Penny Arcade comic: https:&#x2F;&#x2F;www.penny-arcade.com&#x2F;comic&#x2F;2005&#x2F;04&#x2F;25&#x2F;an-artifact-of...\"It&#x27;s so pure I think I&#x27;m going to cry.\" reply pawelduda 17 hours agoparentprevCosmetic is cosmetic, someone likes the way it looks, pays for it, receives the cosmetic - IMO no different from buying any vanity item in real world.Paid upgrades&#x2F;equipment&#x2F;unlocks that give advantage to a player in a otherwise free to play game is a shitty spending-fest design that I avoid getting into, maybe unless the spending ceiling is very low. Still, I wouldn&#x27;t see it as a gambling because there is no randomness involved.The moment game devs add loot boxes though - well, IMO this shit should be banned. Especially when it&#x27;s stupid obvious that there is no randomness behind the scenes. reply treme 17 hours agoparentprevit&#x27;s different because the mechanics are carbon copy of other casino games with tighter reinforcement&#x2F;addiction potential then other &#x27;regular&#x27; games that have more space&#x2F;process in game experience loop reply liendolucas 19 hours agoparentprevQuote from: https:&#x2F;&#x2F;www.bigfishgames.com&#x2F;play&#x2F;bigfishcasino&#x2F;signup> \"You must be 18+ to access Big Fish Casino&#x2F;Jackpot Magic Slots. This game does not offer gambling or an opportunity to win real money or prizes. Practice or success at social gaming does not imply future success at gambling.\"So, you&#x27;re able to pour them money and no way to get it back. What exactly is the money for then? Why this does not qualify as a scam? Just because of the disclaimer? reply seanalltogether 18 hours agoparentIt&#x27;s no different then any other online game like clash of clans or pokemon go or even FIFA. You spend money to be allowed to spin the wheel more, the more you spin the better your chance at winning some in game shiny trophy to show off to others competing for the same shiny trophy. The addiction comes purely from the fact that thousands or millions of other people can see your progress and are competing against you to earn better. reply liendolucas 18 hours agorootparentI see, but they shouldn&#x27;t be allowed to use the word \"casino\" then. As far as I know, a casino (virtual or real) is a place where you gamble and have a chance (small but real) to get your money back. So basically people playing through this app are believing that effectively can win money when is not true. reply boomboomsubban 17 hours agorootparentThe first definition of \"casino\" is a place for social amusement, https:&#x2F;&#x2F;www.merriam-webster.com&#x2F;dictionary&#x2F;casino, and there are non gambling casinos still out there https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Catalina_CasinoI don&#x27;t think many people playing these games are fooled into somehow thinking they&#x27;ll win their money back. Certainly the 21 big spenders in the article knew they wouldn&#x27;t. reply liendolucas 17 hours agorootparentBut then why would you choose to go to this fake casino? If you also have the choice to gamble for real and at least a tiny chance to get something back or if you have high hopes \"win\", there seems to be absolutely no reason to put money in this game or fake bet app. Am I missing something? reply tarheels100 15 hours agorootparentI think the answer is in the question. They&#x27;re not playing to win money. They&#x27;re playing because whatever rewards that have been engineered into the game suck them in. Social aspects, FOMO, \"winning\" at a game, etc.Different people crave different rewards. Some people may care more about the financial reward, but they&#x27;re out playing some other gambling game that caters to them. reply woobar 16 hours agorootparentprevWhat is the reason for playing any computer game? To get a dopamine fix by reaching some virtual goal. People pay small (at least at first) amounts of money for access to the game or in case of free-to-play games for a better chance of getting to the next goal. If someone gets a bit of excitement every time they win a virtual jackpot, they might think a $1 is an acceptable price to pay for it. And then it just spirals out of control. reply yebyen 16 hours agorootparentprevMy parents use these games and I started as a way to commiserate with them, because I have always played games but they only started using computers after I was already well and truly addicted to computers writ-large.The Double U Casino used to have a team check-in, where you could send your team bonuses and they saw that you checked in with them. I know it sounds stupid, but this was a real way that I was connecting with my parents, and then they shut it down.Incidentally the name of our team was Roman Catholicism, because most of the teams were full and this was one that was not full. Whoever started Roman Catholicism left the group, and eventually we became the admins of Roman Catholicism. It was a sad day for me as a part of my family when Roman Catholicism closed its doors.I should call my folks! I think they still use the casino app, even without any money or social investment, they still enjoy it and I made sure they had nice tablets to use the app on. This is still working, even without the social aspect. It&#x27;s still valuable to us, we game as a family, even if we&#x27;re not always together.Anyway, would you ban Roman Catholicism because they&#x27;re believing in what is not really true? I think someone baited me into this position, I wouldn&#x27;t even make this ridiculous argument except that all of this literally happened and I am not making any of it up. Casino app keeps family together, son calls his parents more often after they get disconnected by the oppressive dev team that shut it down. I&#x27;ll be here all week, try the Clams Casino at the bar. reply dymk 17 hours agorootparentprevI really don&#x27;t think the core issue is being allowed to use the word casino or not. Whales pour their life savings into other things not labeled casino - the core gambling addiction remains the same. reply madeofpalk 16 hours agoparentprevIt&#x27;s disapointing to see zero criticism applied to Apple and Google.All of Apple&#x27;s credability about needing to maintain control over iOS apps and App Store goes out the window once it&#x27;s evident they make a fuck tonne of money selling casino games to children (and adults). reply notfed 15 hours agoparentI don&#x27;t even know how Big Fish Games can be criticized here?These people are literally, knowingly giving their money, with no expectation of getting any back. reply Jochim 12 hours agorootparentCompanies like Big Fish expend huge amounts of effort researching how to make their games more addictive.They are criticised because they have created something expressly designed to develop compulsion in as many people as possible. They aggressively tune their products to increase that compulsion and to prevent their victims from breaking it. reply chii 11 hours agorootparentTo play the devil&#x27;s advocate, how is it any different from a tv studio designing addictive tv shows?At the end of the day, there needs to be some level of personal responsibility. reply Jochim 1 hour agorootparentThe other reply to this from zeroonetwothree hits the nail on the head. The major difference is in the capacity for serious harm. That&#x27;s not to say that there shouldn&#x27;t be more oversight of manipulation in other industries.> At the end of the day, there needs to be some level of personal responsibility.Why is it that the concept of personal responsibility is never applied to those employing the psychological manipulation tactics? My belief is that it&#x27;s their personal responsibility to refrain from such behaviour. reply zeroonetwothree 10 hours agorootparentprevThe main difference is that a TV studio isn&#x27;t trying to get you to spend an unbounded amount of money. As a result it limits the total harm that can be inflicted, hence why TV addiction isn&#x27;t considered as bad a problem as other forms. reply madeofpalk 49 minutes agorootparentprevThe devil does not need an advocate. reply jay_kyburz 15 hours agoparentprevYes, It will not be a popular opinion around here, but I think it&#x27;s worth mentioning that it&#x27;s very difficulty for our Governments to help these abused people. A government need to draft legislation, debate it, and get it passed. All the wile assaulted by a powerful lobby group.Apple and Google simply need to draft a policy and decide to do it. reply LordHeini 18 hours agoparentprevSome time ago I watched a documentary about gambling addicts. They claimed they were playing because the game puts you in a kind of stupor which is like being high. Winning money did not matter to them as long as the high held on. It is a bit counter intuitive but winning money is not the point of gambling. If an addict wins money he will imedialty spend that money to gamble more.This app skips the winning and some degree spending, money part altogether. Which is smart if you want to exploit gambling addincts and avoid regulations. reply notfed 15 hours agoparentEvery time I&#x27;ve played slots, I just lose repeatedly. I struggle to understand how this can give a high. reply LordHeini 14 hours agorootparentIt is totaly weird indeed.Some People seem to get in the zone and get completely lost. Sometimes that happens to me while coding. But i can&#x27;t do it for long and unlike gambling it pays.It is hard to get up from the machine and some even shit themselves. The big casinos often have emergency teams for the people who get heart attacks and die on their chairs in front of the slot machine.It is truly bizzare I never understood the appeal but some people are drawn to this and get absolutely zombiefied.Gambling addiction truly is one of the worst things that can happen to someone. reply zeroonetwothree 10 hours agorootparentprevI&#x27;ve only ever gambled once and don&#x27;t see the appeal, but for some people they can enter a state of \"flow\". This is very satisfying. reply namanyayg 20 hours agoparentprevI was wondering where I had heard the name \"Big Fish Games\". I just realised that they created Virtual Villagers which was a huge part of my childhood, I loved that game.I also enjoyed Fish Tycoon and Diner Dash by them.Seems like they got sold to a casino operator? Unfortunate that this is what makes money. reply lionkor 20 hours agoparentThey also published some Nancy Drew games, I believe, one of which im currently reverse engineering! reply DaiPlusPlus 19 hours agorootparentPardon my tone, but what could possibly be of value to RCE in a mass-market mobile-gaming app? reply firtoz 19 hours agorootparentI&#x27;m not OP, but, reverse engineer all things. You can learn how they are made, you can learn reverse engineering in general, you can make mods, hacks, cheats, spinoffs. reply mplewis 19 hours agorootparentprevThey’re not mobile games. https:&#x2F;&#x2F;www.bigfishgames.com&#x2F;us&#x2F;en&#x2F;games&#x2F;1207&#x2F;nancydrewdange... reply lionkor 11 hours agorootparentprevTheyre not mobile games, they are pretty old point and click adventure games, with lovely art and humor.The reverse engineering is interesting because they rolled their own engine and most of the game is written in Lua 5.1.I also personally find it interesting as the binaries and code in general is tiny, so its a good way to learn. reply isidor3 19 hours agorootparentprevMaybe some personal enjoyment? reply f137 17 hours agoparentprevDiner Dash was made by PlayFirst, BFG and many other game download portals were selling it (Windows PC version) reply Apreche 19 hours agoparentprevWhen someone wants to setup a casino that awards players with real money for winning, it&#x27;s heavily regulated. Sure, they&#x27;re allowed to set extremely favorable odds for the house, so it&#x27;s still a scam. But they actually have to publish those odds and abide by them. And lucky players do actually come out ahead. Slot machines do occasionally pay out jackpots. The most important regulation, IMHO, is we do not allow minors to participate in this activity. This regulation doesn&#x27;t seem very controversial.But what if someone sets up a casino where there is no chance of a cash payout? No matter what, the player loses 100% of the money they put in. For some reason we do not regulate this kind of casino at all! It&#x27;s totally wild. This kind of casino should be the MOST regulated, or banned entirely. Worst of all, we let children participate!Slot machines that use worthless virtual currency, award only virtual currency, but let you buy virtual currency with real currency? Playing one of those is worse than playing a real slot machine, or even playing a rigged real slot machine! At least both of those have some non-zero chance of paying out real money.Lootboxes in video games? That&#x27;s gambling with a 0% payout. All you get are worthless JPGs. And we let children participate!Crane games at the arcade? Those are just vending machines with programmed odds. They are gambling! We let children play them.Baseball, Pokemon, or Magic cards? Other collectibles that come in blind boxes or sealed packs? These are gambling! Sure, some will argue that these are different because no matter what you are getting some minimum prize. A pack of Pokemon cards will always contain 10 cards no matter what. Well, what if I make a $5 slot machine that at minimum always pays out 50 cents no matter what you spin? How is that different from a $4.50 slot machine that has the potential to pay out $0? Changing the odds and payouts doesn&#x27;t make it not gambling.IMHO, all of these activities should be completely banned for children. No games of chance whatsoever if they cost real money per-play.As for adults, consenting and informed adults can throw away their money if they want. But all of these activities should be heavily regulated. And the casinos that don&#x27;t pay out a cent should be MORE heavily regulated than the normal ones. reply sokoloff 19 hours agoparentA lot of entertainment falls into this category though. A $15 movie ticket has a 100% to consume ~2 hours of your life and pay you nothing. A $5 order of fries will pay you about $0.50 worth of potatoes. Go to a ballgame and it’s just as bad as the movies; they’ll charge you for expensive food and drink inside and your favorite team might not even win.Trying to draw a bright, defining line between watching a movie and buying a video game and playing an arcade game or Skeeball seems practically impossible. We don’t want to force everyone to be stuck at home playing “blow the ball of yarn to the opponent’s side of the table”. reply zeroonetwothree 10 hours agorootparentThose analogies aren&#x27;t good because the outcome is not randomized. That&#x27;s what makes things addictive and dangerous (especially for children).I think it&#x27;s very easy to draw a line. When you pay money, the result has to be specifically given up front. It cannot be based on random chance. If you wan to buy a Pokemon card you have to buy a specific card (or a set with fixed cards included). If you want to buy virtual clothes for your avatar then you have to buy specific objects. If you want to buy a doll then you buy a specific model, not a random box. reply ikr678 6 hours agoparentprevMost of the reasons real money gambling is regulated is to do with stopping money laundering, not protecting gamblers.The incentives for the govt to regulate virtual gambling sims(that don&#x27;t pay out) arent as strong, especially when these companies pay tax on that VIP revenue. reply namanyayg 20 hours agoparentprevI&#x27;m not sure I follow, why is anyone playing these games at all? What&#x27;s the benefit, or what&#x27;s the social aspect? How do the clubs work to encourage more playing?I found the article to be a bit sparse on these details. Maybe there&#x27;s another source? reply oldtownroad 20 hours agoparentAddiction isn’t rational so the answer may be as unsatisfying as “people got addicted because they got addicted”. Many people addicted to real slot machines are addicted because you press a button and something happens, the fact that you can win real money is not much of a differentiator between these apps and real slot machines — because addicts in a casino aren’t walking away in profit either. reply sneak 18 hours agorootparentMost pleasure-seeking isn’t rational. I don’t understand why we single out this form of irrationally wasting money but not all of the other ones that are common. reply zeroonetwothree 10 hours agorootparentWe don&#x27;t single out this form. Many other addictive forms of pleasure seeking are also negatively portrayed (e.g., smoking, alcohol, drugs, video games, TV, etc.) reply wafriedemann 19 hours agorootparentprevJustifying their behaviour with &#x27;addiction&#x27; makes them completely unresponsible for their actions. If that&#x27;s the case you&#x27;d have to declare them incompetent for doing business and assign them an agent. reply just_boost_it 19 hours agorootparentThat&#x27;s a fairly unempathetic view. I don&#x27;t know what it&#x27;s like to be a gambler, but I do know that anyone who thinks they are completely rational is only fooling themselves. We are emotional animals with a tiny rational voice that can only shunt our emotions in a better direction. reply thibaut_barrere 19 hours agorootparentI agree! Looks like a variant of https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Curse_of_knowledge reply aaomidi 19 hours agorootparentprevTo add to your point, these are companies with the ability to spend millions to get research done on the most efficient way to manipulate people.This isn’t just gambler vs some other person.This is one person against a resource pool worth millions of dollars. No individual in aggregate has a chance against that. reply Waterluvian 19 hours agorootparentprevI think my number one pet peeve of this species is that people are so strongly inclined to assume that everyone’s experience is about the same as their experience. Empathy can be such an uphill battle. reply rjh29 19 hours agorootparentHacker News isn&#x27;t really representative of humanity as a whole. It is a very thin slice of intelligent and creative but also cynical and pedantic people with low empathy and emotional intelligence. That is not a value judgement, that is just what it is. Virtually every top comment in every article is nitpicking or dismissal; positivity, especially blind positivity without any evidence, is not valued here. reply JCharante 15 hours agorootparentWell, if we’re not here to nitpick then what are we here for? Should the comment to upvote ratio decrease? reply zeroonetwothree 10 hours agorootparentprevThey aren&#x27;t \"completely\" non-responsible, but they are somewhat because they are being taken advantage of in a predatory and almost fraudulent way.Just like if you fall victim to a phone scam, sure it&#x27;s somewhat your fault, but clearly it&#x27;s mainly the fault of the scammer. reply mplewis 19 hours agorootparentprevWhat exactly do you think an addiction is? reply sneak 18 hours agorootparentWhat exactly do you think happens when someone kicks an addiction? reply aaomidi 19 hours agorootparentprevIs it a net benefit for society for folks to lose out on all their assets and money for the sake of gambling?This is generational wealth that gets lost in gambling. It is the responsibility of a strong society to prevent scams, and to protect people from very damaging forms of manipulation. reply lotsoweiners 18 hours agorootparentExplain why that is a “responsibility of a strong society” rather than simply a fool and his money are soon parted. I like having the option to throw my money in a wishing well if I were so inclined. reply wussboy 18 hours agorootparentFor real?Because when a fool is parted from his money he and those who depend on him starve to death, and that, dear friend, is the part a strong society should be concerned about. reply xapata 17 hours agorootparentUniversal basic income might cleanly solve that problem. Might, because the addict might spend the weekly income on the addiction instead of food and shelter. reply scotty79 19 hours agorootparentprevNot every explanation is justification. reply matwood 19 hours agorootparentprevIf only people were so simple. reply jdietrich 19 hours agoparentprevI can&#x27;t give a short answer, but IMO the best long answer is the book Addiction by Design by Natasha Dow Schüll.https:&#x2F;&#x2F;press.princeton.edu&#x2F;books&#x2F;paperback&#x2F;9780691160887&#x2F;ad... reply matwood 19 hours agoparentprevI got addicted to an MMO (DAoC) long ago. Luckily for me it didn&#x27;t cost me much money other than the bot accounts I bought and maintained. But, it did cost me other things. I dropped out of grad school, stopped working out, stagnated at my job, and became completely obsessed with the game. I treated it as a second job. Looking back the why seems silly and embarrassing - I was part of a guild that needed my help. Eventually I had a long term relationship end over the game. The next day I gave all my accounts away and never played again. I still play single player games when I have time, but definitely no MMOs. reply metabagel 18 hours agorootparentI’m sorry for how this impacted your life, but congratulations for doing what you needed to do. reply matwood 18 hours agorootparentThank you. Everything worked out fine :) reply simonw 19 hours agoparentprevI can guess.These are games where you earn points (in the form of tokens). Those points place you on a leaderboard within your club.Just like if you were playing any their game which gives you a score and let&#x27;s you compare your score with other people.The catch here is that the games are all simulated Casino games - and one way to boost your score if you got \"unlucky\" is to spend real money on more fake tokens.The games are \"fun\" because they emulate 100+ years of casino development in terms of figuring out what mechanisms people enjoy the most. reply phatfish 19 hours agorootparentYup, it&#x27;s like Euro Truck Simulator, but you simulate being a gambling addict. Oops... reply afavour 20 hours agoparentprevSurely you could ask all the same questions of physical casinos? The answer to most of the question is “addiction”. reply almostnormal 19 hours agorootparentThe result is the same, but the path differs. I doubt addiction appears out of nowhere. First some kind of reason for an activity is needed. Real casino - chance to win, big fish casino - social status within the club. In both cases the addiction seems to be self-reinforcing: A chance to win all the lost money back vs. not wanting to lose the status that was so expensive to reach.Individuals are intelligent, but groups of people create peer pressure, and individuals become capable of the most stupid behavior imaginable. Just wasting money isn&#x27;t even the most extreme form. reply namanyayg 20 hours agorootparentprevHow is that the same? You can earn real money in a physical casino, here you cannot reply redhale 19 hours agorootparentYou are correct that the thing these people are addicted to is not the chance to win real money. So in that sense it&#x27;s not the same as other casinos.But the government regulates plenty of addictive things that are not \"winning real money\".The thing in common is a for-profit company taking advantage of a weakness of human nature, which in some cases leaves a meaningful number of people financially destitute. I think there&#x27;s at least an argument to be made that it&#x27;s worth putting up some protective measures. reply sneak 18 hours agorootparentI think there is a stronger and more general argument to be made that the government should not be in the business of telling people how or if they can spend their money on things they want to spend it on.Spending significant fractions of one’s income servicing one’s chosen addictions (alcohol and tobacco and reckless spending of money principally among them) is a long and great tradition enjoyed by an huge portion of society and it seems utterly contrary to the idea of basic liberty to get involved in impeding that. Most addicts love their addictions; most of the ones that don’t eventually stop. reply afavour 16 hours agorootparentThe problem with that logic is that when someone bottoms out on their addiction they become a burden society has to pay for. reply Jochim 12 hours agorootparentprevIt&#x27;s one thing to enjoy a vice, it&#x27;s another to intentionally manipulate someone else into falling deeper and deeper into that vice to your benefit. Prohibiting that kind of behaviour isn&#x27;t the same as prohibiting the vice itself.The sociopaths that gleefully exploit human psychology for their own financial gain should be stamped out.> Most addicts love their addictions; most of the ones that don’t eventually stop.Source? This doesn&#x27;t match up with any addict I&#x27;ve interacted with or seen in media. The majority seem to fall between being unaware, in denial, or deeply unhappy about it but are unable to break their dependency. reply dartos 20 hours agorootparentprevAddicts don’t gamble in order to make money, that’s just what gets you in the door.Once you’re in that addiction cycle, you crave the dopamine rush and play just for the feeling of maybe winning back a big loss even when in reality a big win probably won’t even make you break even.It’s why people just sit in front of slot machines for hours on end. reply SamoyedFurFluff 19 hours agorootparentActually the dopamine rush isn’t in winning. Slot machines are all flashing lights, overwhelming colors, patterns, and matching patterns designed to provide dopamine rushes purely through stimulation. The point isn’t even in the potential of winning anymore, it’s getting lost in matching patterns and pretty lights where the world disappears for as long as possible. Slot machines are designed to maximize engagement and winning actually interrupts it with rewards (slot machine addicts have actually reported being upset when the slot machine pays out, because it ruins their trance like state!) reply nullstyle 19 hours agorootparentActually thats making a ton of assumptions about the experience of gambling on slots. The world is more complicated than some Atlantic articles on casino design, unfortunately. Go play some slots with a group of friends and realize it. reply SamoyedFurFluff 19 hours agorootparentThe literal casino designers have explicitly laid out all their tricks about it. The fact you can see the other symbols not involved in the lines gives a feeling of a near miss. There are several machines which incorporate eyes to invoke parasocial relationships with the players. Multiple lines beyond the three, with obscure multiplier rules, also give a sense of mastery and understanding of mechanics as if it’s not a random number thing. And the fact is that pattern matching is inherent satisfying to people, so presenting endless pattern matching game is… well.. yeah… reply nullstyle 18 hours agorootparentNone of what you said refutes my point: The human experience of gambling (including slots) is much more broad than the designers influence upon it and more value can be had than from the winnings and the losings of money. It&#x27;s more than just shiny lights, and us gamblers aren&#x27;t zombie lemmings shoving every paycheck into the void. Go gamble with a group of people, watch the diversity of their experiences and I bet you&#x27;ll see gambling is more than your reductions. There is nuance to this that you are missing. replyberemaki 20 hours agorootparentprevAddiction is not related to the potential benefits of the habit. You can get addicted about anything depending on your personal dispositions.Simply said lot of \"games\" are disguised Skinner boxes, people with addictive personalities are very vulnerable to those. reply afavour 19 hours agorootparentprevYou don’t earn real money in a physical casino, you earn chips.You’re correct that those chips are exchangeable for real money but the chips still serve a very real purpose: to dissuade you from picking up the cash and walking out. The vast majority of people who win chips plug them straight back into the casino games and end up leaving with nothing. It’s all about the addiction to gambling itself, winning money is merely a potential bonus. So the end result is not a whole lot different than these apps. reply baobabKoodaa 19 hours agorootparentPurpose of casino chips is more practical and less nefarious than you imagine. Try playing a poker game with banknotes and coins and you&#x27;ll see what I mean. reply thefounder 19 hours agorootparentprevI think it has little to do with earning money. That&#x27;s just the hook. It&#x27;s a human condition&#x2F;disease. Just like the hoarders. You need to experience addiction first hand to understand it, be it video games, smoking, collecting useless stuff, or just any kind of addiction. reply lxgr 18 hours agorootparentprevIn a pretty significant way, you also can&#x27;t \"earn\" money in a physical casino, negative EVs and everything.There is a very limited set of circumstances in which playing a game with negative EV can be rational (e.g. if your utility function for money isn&#x27;t linear); everything else seems like a more or less thinly disguised attempt to exploit certain properties of the human mind&#x27;s&#x2F;brain&#x27;s reward system. (It&#x27;s a philosophical question on whether consent can even theoretically be given to that exploitation.)I&#x27;d argue that the magnitude of the expected loss per game (i.e. everything or only a fraction of it – but in iterated games it&#x27;s always everything as well) is much less relevant than that. reply schrodinger 17 hours agorootparentCertainly see your point, but there is still a difference. In a real casino, you _may_ come out ahead on isolated events, even though over an infinite time horizon you won&#x27;t. With these apps, that&#x27;s not even a minuscule probability! reply btbuildem 20 hours agorootparentprevIf you could earn real money in a physical casino, casinos would cease to exist.Edit for clarification: excluding the staff, who obviously earn wages there, if the average person made any money gambling in an average casino, casinos would quickly go bankrupt. reply xDetoursx 19 hours agorootparentYou can earn real money in casinos, that&#x27;s why they do exist. They pay out just often enough for people to believe that they are one pull away from hitting a jackpot.If they never paid out, people would never go and the casinos would not exist reply AlexandrB 19 hours agorootparentI recently saw a good video[1] covering the history and appeal of gambling machines. My takeaway is that the primary reason people play these is not because they think they&#x27;re going to win money. This especially true of pachinko where \"cashing out\" is a convoluted process of trading balls for prizes for cash.> If they never paid out, people would never go and the casinos would not existThis is self evidently false based on the linked article. Random chance games that have no possibility of ever having a net payout attract tons of players and make a lot of money.I think the problem is analyzing this with the economic \"rational consumer\" model of human behavior. Gambling is not rational but extremely popular because people are not rational. The whole industry is a trap that feeds users dopamine rewards in exchange for money. Once you&#x27;re in, the payouts have little to do with it.[1] https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=jQIHqkudgNY reply sebastianz 19 hours agorootparentprevHis point is that the average person that walks into a casino loses money by definition, as the casino designs its offers in that way.If the average person would win money, the casino would cease to exist. reply im3w1l 19 hours agorootparentprevThis whole article is about apps that are up-front about never paying out cash. Money turns into points, points can be lost or turn into more points. But points never ever turn back into cash. And yet people play. reply tromp 19 hours agorootparentprevPoorly phrased. You mean casinos wouldn&#x27;t exist if the expected winnings were positive (or more precisely, not negative enough to offset their fixed costs of rental, maintenance, and salaries). reply baobabKoodaa 19 hours agorootparentprevWhat a strange, nonsensical comment. reply bbarnett 20 hours agorootparentprevFor most people, you can&#x27;t earn anything at a casino. Almost no one comes out ahead, because no one leaves when ahead. They just keep playing, until all their money is gone.Sounds like these apps are more honest. reply smallstepforman 18 hours agorootparentprevUsing the word addiction is troublesome, since over 99% of the industry employees that work in that environment 40hrs a week are not “addicted” to gambling. If gambling addiction existed, then a large number of employees would also be “addicted”, but they are not. Its another effect fir people that cannot control their spending. reply novemp 18 hours agorootparentUh, what?By this logic, 99% of bartenders should be alcoholics. reply cal85 19 hours agoparentprevOccasional, unpredictable, variable rewards, with corresponding colourful splashes and satisfying noises, providing a temporary escape from uncomfortable feelings. reply _fat_santa 19 hours agoparentprevOne of my friends showed me an \"casino\" app on his phone where they don&#x27;t give you real money but you can earn (or buy) \"premium currency\" that can be redeemed for various rewards like a free dinner in Vegas or 20-50% off a room, which I would assume Big Fish Casino is doing something similar. It could be that or it could be the big A word that casino&#x27;s hate (addiction). reply andy800 19 hours agoparentprevWhy do people play Tetris or any other game? For most it is just a fun way to pass some time. However for others, it&#x27;s an obsession that is prioritized over real-life -- jobs, finances, etc.The clubs appear to be like guilds or teams in online games, players collaborate for high scores and to maintain a ranking on a leaderboard. The problem is that once someone joins a team, they feel pressure to generate points to contribute to the team&#x27;s success, which often requires in-app payments to obtain more coins to wager. reply TerrifiedMouse 19 hours agoparentprevOperates on the same mechanism as gambling, variable ratio reinforcement schedule - i.e. the player is rewarded after a random number of \"responses\"; similar to a slot machine. reply 1f60c 20 hours agoparentprevFrom my experience playing a popular blackjack social casino game, they seem free to make you hit a blackjack at just the right time to keep the dopamine (and real money) flowing. reply enlightenedfool 20 hours agoparentprevPlaying apart, it’s surprising they spend 1000s of dollars. reply wredue 18 hours agoparentprevIt’s the exact same reason why Destiny The Game subreddit consistently argued in favour of KRPG drop rates till it got to the point that not even the basement dwellers could get anything they wanted:They are addicted to “exclusivity”.This same type of thing impacts all video games with gambling aspects or drop rates.I’ve played Diablo 2 for decades and have never once dropped a rune higher ist, and the sub vehemently defends those drop rates.Many defended the Diablo 4 Uber rare rates.What’s the point in playing just for some strange exclusivity? Who knows. Gotta ask the people that defend the ever increasing annoying rarity of shit on the premise that they believe they alone play enough to end up in some sort of exclusive club of owners. reply zeroonetwothree 10 hours agorootparentPeople who play a lot want to feel that their \"time investment\" was \"worth it\". If things are too common that anyone playing 1 hour&#x2F;day can get the same stuff as someone playing 16 hours&#x2F;day then the latter group feel like they are \"wasting their time\".I would say, just play a different game that doesn&#x27;t have this toxic reward system. reply dustingetz 19 hours agoparentprevmy lifelong friend who developed schizophrenia as an adult (tick bite while jogging -> lymes disease -> schizophrenia, yes that&#x27;s a thing) is going through bankruptcy due to these apps. IIUC what happened is after years of use she hit a jackpot (which they allow or cause to happen every now and then), cashed out a big win which generated an IRS Form W-2G, deposited somewhere else across the fiscal year boundary, immediately lost it but now owes a pile of tax. Her net worth is now less than 0; she is currently living in a state funded halfway house after her latest stint in rehab -- having otherwise now reached the point of homelessness for the first time. Historically she has had the apps block her (over a decade of this addiction) but there are always new apps and they obviously target her with advertising. If I have it wrong it&#x27;s because it&#x27;s impossible to extract coherent information from a schizophrenic. The only reason to believe this is even real is, how does a schizophrenic know what is a Form W-2G? reply nyolfen 16 hours agoparent> (tick bite while jogging -> lymes disease -> schizophrenia, yes that&#x27;s a thing)women with schizophrenia actually tend to develop symptoms in their 20s, much later than men; lymes disease is real but also often a fixation for the mentally ill and hypochondriacs since the symptoms are so vague and varied, so it is likely that the bite is irrelevant and she fixated on it as her symptoms were developing for genetic (or whatever) reasons reply dustingetz 14 hours agorootparentthanks – I didn&#x27;t know that. She is 39 and was bit in her late 20s, showed early schizophrenia (wrongfully diagnosed as psychosis) in early 30s. So could be. reply peter_l_downs 19 hours agoparentprevThe apps discussed in the article do not allow cashing out. Sorry to hear about your friend’s difficulties. reply danielfoster 19 hours agoparentprevThis is very sad to hear— I am sorry. I also wonder why only older people are getting hooked on these games. Perhaps it is due to changes in the brain? These companies seem to target the weakest. reply diebeforei485 14 hours agoparentprevClearly the App Store isn&#x27;t protecting users. They&#x27;ve long been allowing gambling-like mechanics to hook kids (\"loot crates\", etc).I simply don&#x27;t understand why Apple can&#x27;t choose the moral high ground here and say no gambling on the stores. reply zeroonetwothree 10 hours agoparentApple makes $10+ billion&#x2F;year from this practice. So that&#x27;s one reason. reply skulk 14 hours agoparentprevDoesn&#x27;t Apple take around 30% of all in app transactions? No one gets promoted for cutting out a revenue stream for morals, much less before enough loud voices are angry about it. reply andrewjl 2 hours agoparentprevThe article mentions that Big Fish Games was at one point owned by Churchill Downs and now belongs to Aristocrat Leisure. The former operates racetracks and an online oddsmaker while the latter literally manufactures gambling machines.> These games are not gambling because, among other reasons, they offer no opportunity for players to win money or anything of value. Our games are offered for free purely for entertainment, with an opportunity for customers to spend money within the game to enhance their gameplay experience.[1]Right, no connection to gambling whatsoever.[1]: https:&#x2F;&#x2F;www.documentcloud.org&#x2F;documents&#x2F;6896112-BF.html reply H8crilA 19 hours agoparentprevOne thing that I never understood is the idea that \"gambling is fun\". In the culture that I&#x27;m from gambling is considered something left for the \"lower class\". It&#x27;s a bit similar to acting up while heavily drunk, not exactly something to be proud of.The first few times that I heard something to the tune of \"Vegas, baby!\" I honestly thought the person was being funny by ridiculing themselves slightly. reply crazygringo 19 hours agoparentHonest question: have you ever tried it? Ever played blackjack at a casino?I&#x27;ve only done it a handful of times, but it&#x27;s a gigantic exciting roller coaster ride of emotions as you win and lose real amounts of money, whether they&#x27;re in tens or hundreds of dollars or whatever scale you&#x27;re at.It&#x27;s way more exciting than the thrills from a superhero movie in the cinema because it&#x27;s real life, real money. It&#x27;s more exciting than sports because it&#x27;s your win, your money. When you&#x27;re winning, you can&#x27;t believe how much fun it is. All your life you were told an honest day&#x27;s pay for an honest day&#x27;s work, and now you feel like you&#x27;ve found a magic shortcut!And if you lose, well... next time. You&#x27;re sure you&#x27;ll make up for it and then some.It can honestly be hard to imagine until you&#x27;ve tried it. I was similarly confused until I experienced it. But it really taps into something deep in the primate brain, about hopes and dreams fulfilled, about getting lucky and rich, about being special.There&#x27;s a good reason I&#x27;ve only ever gone a handful of times, and limited myself to a small amount of money. Because it&#x27;s also scarily easy to see how you could get addicted to that feeling. reply BlarfMcFlarf 18 hours agorootparentI have and had the opposite experience. All I see is games with uninteresting choices, pointless rule systems due to those choices being uninteresting, and an endless parade of negative EVs trying to pretend they aren’t somehow. People who enjoy it clearly have a very different relationship with math and probability I guess. reply crazygringo 17 hours agorootparent> People who enjoy it clearly have a very different relationship with math and probability I guess.That sounds like you&#x27;re implying that only mathematically less-literate people gamble.I think that&#x27;s wrong, though. I&#x27;ve got as strong of a background in stats and probability as they come, and that hasn&#x27;t changed my enjoyment of it at all. Maybe it&#x27;s even added to it, since there&#x27;s the added challenge of finding the least-bad bet.You&#x27;re paying for the excitement of the ups and downs.You sound like someone who says they don&#x27;t like the movies because all they see are uninteresting plot predicaments, pointless obstacles, and an endless parade of non-optimal choices by characters all trying to pretend the ending isn&#x27;t going to be predictable.All I can say is, to each their own, but it definitely sounds like you haven&#x27;t grasped the essential emotional quality of the entire experience -- that perhaps you don&#x27;t have, but many other people certainly do. And that aspect doesn&#x27;t have anything to do with mathematical literacy. reply reducesuffering 14 hours agorootparentprev> endless parade of negative EVWait until you find out some Blackjack is exploitable to be positive EV and requires interesting levels of multitasking the first few hundred hours. Poker can also be profitable due to marks, even with a negative EV rake.But yes, many games, especially Roulette, Slots, and Craps, are blatantly negative EV. However, Craps is very fun due to the team table dynamics. reply tekla 11 hours agorootparentprev> All I see is games with uninteresting choices, pointless rule systems due to those choices being uninteresting, and an endless parade of negative EVsIf this was true, clearly you should be playing at the poker tables and raking in the cash. reply zeroonetwothree 10 hours agorootparentBeing able to identify a game as -EV doesn&#x27;t mean you are going to be great at poker? Or else why isn&#x27;t every statistician in the world a professional poker player? reply H8crilA 17 hours agorootparentprevI have played the slot machine, and it was hilarious how fast it used up the money I had put into it - I had a genuine laugh. I heard that the machines outside of main casinos in Vegas have much higher payout rates, so that you can take more time to lose your money. Makes sense, someone has to pay for the Eiffel Tower model.My question&#x2F;comment was about the overall cultural perception of gambling. I just found it strange in America - a small instance of a \"culture shock\". reply EVa5I7bHFq9mnYK 15 hours agorootparentprevI went to the old Monte Carlo casino, just for the experience, won 400 euro, but didn&#x27;t feel much excitement ... it paid for the helicopter ride though. reply criddell 18 hours agorootparentprevYou don’t even have to go to a casino. I personally wouldn’t look at a poker night with friends as being much different than getting together to play a board game. reply crazygringo 18 hours agorootparentIt&#x27;s different though. Poker with friends, you can only ever win as much as your friends put in, which usually isn&#x27;t going to be that much. You&#x27;re right -- it feels closer to a board game.But at a casino, there&#x27;s no similar limit to how much you can win. It feels like your dreams could literally come true in Las Vegas, that you could come back home and buy a new house. Poker with buddies doesn&#x27;t include that possibility. reply criddell 18 hours agorootparentPoker with buddies is still gambling though and it’s a lot of fun. Maybe more fun than casino gambling (depending on your friend group). I wonder if the GP thinks people who have a Thursday night game with friends are low class as well? reply crazygringo 16 hours agorootparentOh for sure -- I&#x27;ll take poker with buddies over a casino any night of the week.It&#x27;s funny, for whatever reason I don&#x27;t mentally put \"poker with friends\" in the category of \"gambling\". I mean obviously it technically is -- no argument there -- but when I think of \"gambling\" I think of \"potentially dangerous&#x2F;addictive\", and (hopefully) poker with friends isn&#x27;t.I&#x27;m also curious what GP thinks about whether poker with buddies is \"lower class\", or if it&#x27;s only a casino thing. (Or gambling dens? Backroom tables?) reply zeroonetwothree 10 hours agorootparentprevI find games for money really unfun, even if it&#x27;s for small stakes. It just makes it too much about winning rather than having a good time. replyskippyboxedhero 19 hours agoparentprevGambling is fun...if you aren&#x27;t an addict.Go down to the races, there is real excitement, real energy, it is fun. Saying it is \"lower class\" is poor (I would say that is ultimate \"low class\" mentality). Lots of people have other stuff going on in their lives, so they watch sport and having a small bet on makes it more exciting.The gambling culture that exists in the US is completely bizarre because it is designed towards the most extractive, most pointless forms of gambling because of political pressure (the gambling indus",
    "originSummary": [
      "NBC News has highlighted the addictive nature of casino-style smartphone games, which are disguised as video games to bypass gambling regulations.",
      "Popular games like Jackpot Magic and Big Fish Casino have minimal oversight, leading to players feeling helpless and becoming addicted, with some spending thousands of dollars.",
      "Some individuals have filed lawsuits to reclaim their losses, but there is increasing demand for tighter regulations in the industry."
    ],
    "commentSummary": [
      "The discussion focuses on the addictive nature of casino-like apps and online gambling, prompting debates on the need for regulation and banning of such activities.",
      "Participants also discuss the negative impact of vices like gambling and pornography, as well as the ethical implications of working in these industries.",
      "The conversation delves into the addictive nature of gambling, its psychological mechanisms, and the role of tech companies in enabling addictive behavior. Additionally, the regulation and ethical implications of gambling-like activities in video games and virtual casinos, such as lootboxes, are explored. Different participants hold contrasting opinions on the severity of gambling addiction, personal responsibility, and the societal perception of gambling."
    ],
    "points": 267,
    "commentCount": 367,
    "retryCount": 0,
    "time": 1699798415
  },
  {
    "id": 38239503,
    "title": "Improving Speaker Support for Asahi Linux: Addressing Limitations and Bugs in MacBook Air 13\" Model",
    "originLink": "https://github.com/AsahiLinux/docs/wiki/SW:Speakers",
    "originBody": "AsahiLinux / docs Public Notifications Fork 45 Star 1.7k Code Issues 25 Pull requests Actions Projects Wiki Security Insights SW:Speakers Jump to bottom Edit New page J. Neuschäfer edited this page · 13 revisions Pages 74 Home \"When will Asahi Linux be done?\" Apple Platform Security Crash Course Apple Silicon Subsystems Broken Software Codenames Devices Differences with other platforms Distro:Boot process guide Distro:Differences from Arch Linux ARM FAQ Feature Support FW:ADT Glossary HW: Clocks HW: SPRR and GXF HW:AGX HW:AIC HW:ANE HW:AOP HW:APCIe HW:Apple Instructions HW:ARM System Registers HW:ARM System Registers Dumps HW:ASC HW:AVD HW:Camera HW:CPU debug registers HW:Debug USB HW:GPIO HW:MacBook Pro keyboard backlight (FPWM0) HW:Memory map HW:SEP HW:SMC HW:SMP spin up HW:USB PD HW:WDT Installing Gentoo with LiveCD Introduction to Apple Silicon Low level serial debug M1 Series Feature Support M1 vs. PC Boot m1n1:Developer Guide m1n1:User Guide M2 Series Feature Support M3 Series Feature Support macOS Sonoma Boot Failures Open OS Ecosystem on Apple Silicon Macs Partitioning cheatsheet perf on M1 systems Project:References RE:Kernelcache Software known to have issues with 16k page size SW:AGX driver notes SW:Alternative Distros SW:Boot SW:DT bindings SW:Getting started SW:Hypervisor SW:Keyboard Layouts SW:MachO Boot Protocol SW:NVRAM SW:Speakers Speaker support in Asahi Linux Current state Known limitations Known bugs Project goals \"Smart Amp\" / safety support Distro integration notes SW:Speakers Test Cases SW:Storage SW:Ubuntu Asahi Gambas SW:Ubuntu Asahi Godot SW:Ubuntu Asahi Mesa SW:Ubuntu Asahi Qemu Tethered Boot Setup (For Developers) Tethered boot setup on macOS Trivia U Boot Yaks in need of shaving Show 59 more pages… Feature Support: M1 Series Feature Support M2 Series Feature Support M3 Series Feature Support Project related: Glossary FAQ \"When will Asahi Linux be done?\" Project:References Recent Changes Platform documentation: Apple Silicon Subsystems Apple Platform Security Crash Course Devices Codenames For users: Broken Software Alternative Distros For developers: Yaks in need of shaving (HELP WANTED!) Tethered Boot Setup (For Developers) m1n1:User Guide Boot loader Hypervisor U-Boot Devicetree bindings Open OS ecosystem on Apple Silicon Macs Clone this wiki locally Speaker support in Asahi Linux We are progressively enabling speaker support on Asahi Fedora Remix. Currently supported models: M1 MacBook Air 13\" (J313) Proper speaker support has been a multi-year development effort involving many people across all parts of the Linux audio stack. We want to offer the best speaker support of any Linux laptop platform, and that has meant driving Linux desktop audio forward a couple decades so that we can do what is expected of a modern laptop audio subsystem! Current state We are ready to begin releasing preliminary speaker support to users. Keep in mind that as Asahi Linux is the first desktop Linux platform with integrated advanced speaker DSP, there will likely be bugs. In addition, the DSP profiles will be improved and adjusted over time, and do not represent the absolute best possible results. Speaker DSP is currently only supported on Fedora Asahi Remix (things are moving fast), however alternative distros should be able to integrate this work relatively painlessly once things settle down (see the section below). Known limitations The DSP processing uses too much power, due to limitations of the default scheduler. Uclamp support will be enabled with an upcoming PipeWire release, and it should greatly reduce the power consumption of the DSP processing, even doubling battery life while playing audio in some cases. Known bugs In KDE Plasma, if you toggle mute using the keyboard hotkey while the master volume is set at anything other than 100%, on unmute the speaker volume will be too low. Touching the volume control (or pressing a volume hotkey) will restore the intended volume. The DSP chain introduces excessive delay, and trailing audio is \"buffered\" (if you stop playing something and start something else, you get a bit of the end of the first when the second starts). There is no final limiter/compressor in the current DSP chains (although there is an input compressor), so inputs with content in high-gain regions of the EQ curve might cause distortion or clipping (and speakersafetyd limiting). This is most prominent in the 200Hz region right now. This should not cause damage, but we recommed lowering the volume if you notice the sound is noticeably distorted. The 13\" MacBook Air EQ curve might be a bit harsh on the treble; pending re-calibration with an individually calibrated microphone to confirm/fix. Bankstown (the \"fake bass\" plugin) uses a relatively naïve algorithm right now, which doesn't work well for all music. Project goals Our DSP profiles aim to provide a balanced sound, with the features that people expect from high-quality laptop/small-speaker audio. In particular, we aim for: A balanced (neutral) tone at moderate listening volumes, with a mostly flat frequency response from a typical listening position Reasonably high peak volume with acceptable sound degradation (compression, limiting, etc.) \"Fake bass\" processing to make audible frequencies that cannot be physically reproduced by the speakers, extending the perceived frequency response of the system. Equal-loudness volume compensation, so that the sound does not become noticeably tinny as the system master volume is lowered. These are all techniques that are in wide use in consumer microspeaker systems in tablets and phones, though sadly not common on laptops from most non-Apple brands. All of these processing tricks are also used by macOS. Our goal is explicitly not to clone the full/exact macOS audio experience. We consider the macOS speaker DSP processing to be too tryhard; some of the things it does work well, some do not (or are outright buggy!), and some are just strange. Although audio is ultimately subjective, and we recognize that some people might prefer the \"macOS sound\", we aim for a more objectively neutral and balanced sound than macOS as a baseline. Users are encouraged to try adding their own effects (e.g. with EasyEffects) if they want to customize their experience and achieve certain sonic profiles. We believe that a balanced baseline that allows users to shape the sound to their own preference if they so desire is a better option than hard-coding specific effects (such as macOS' spatial audio processing) with no option to turn them off. There is no user-friendly (GUI) way to modify or tweak our DSP chains, so it's best if additional effects are left to existing utilities like EasyEffects that can be easily customized by the user. That said, for the types of processing we do intend to apply, failing to work properly where macOS does (e.g. objectively bad audio quality for certain kinds of inputs in particular, such as bad-sounding compression or distortion at high volumes where macOS sounds better at an equal output volume) is considered a bug. Feel free to file issues if you find test cases where macOS does a clearly better job. We're particularly talking about program-dependent problems here, not \"I like the macOS EQ/spatial/whatever stuff better in general\". \"Smart Amp\" / safety support In addition to the DSP processing, we also have the world's first (as far as we know) open source \"smart amp\" implementation. This allows the speakers to be driven to much higher peak levels than the worst-case safe volume level, greatly extending their dynamic range. Our implementation, speakersafetyd, monitors feedback signals from the amplifiers, estimates speaker voice coil temperature using a two-stage thermal model, and reduces the hardware speaker volumes when the speakers get too warm. We also have kernel-side interlocks to disable or limit speaker volumes if speakersafetyd is not running or non-responsive. Right now, we are shipping with a hard volume reduction limit of -7dBFS to catch potential bugs or misbehavior. If you notice that your speakers cut off for approximately one second and then come back at a reduced volume level, it is likely that you triggered this safety limit. Stop playback to let the speakers cool down (just in case) and let the limit re-arm, and then check /var/lib/speakersafetyd/blackbox for any blackbox dumps and file a bug attaching them together with any speakersafetyd logs (try journalctl -S '10m ago' -u speakersafetyd). If you play full-scale test tones or \"extreme\" music at maximum volume, it is expected that you will hit this limit and trigger a blackbox dump / panic. This is intended to help catch any badness while playing normal music, and we will remove this conservative limit once we are confident in the software stack (speakersafetyd has other safety limits built in and will gain more over time). You can watch speakersafetyd in action by using sudo journalctl -fu speakersafetyd. As a rule of thumb, with the speaker volume at max, you should expect speakersafetyd not to kick in when playing loudness-normalized music (e.g. YouTube). Playing overly loud music without normalization (e.g. increasing the browser app volume to 100% in the Plasma applet while using YouTube, which bypasses the normalization limit it applies, or using media players without normalization) is likely to trigger some gain reduction from speakersafetyd, but it should not hit the -7 dB panic limit unless it's something ridiculous. WARNING: Speaker safety models have yet to be fully validated on all models. We are enabling audio only on models where we are confident things are ready and safe to use. If you use any undocumented overrides to force-enable speakers on any other machine models, you are entirely on your own and may very well blow up your speakers. Distro integration notes You need: The latest Asahi kernel (tag asahi-6.5-25 or later) alsa-ucm-conf-asahi asahi-audio speakersafetyd bankstown LSP plug-ins (LV2 version) PipeWire 0.3.84. Depending on your packaging rules, you might need your package to create a few empty directories (see here) so asahi-audio can put files there. PipeWire module-filter-chain-lv2 (this may be a separate package or flags depending on distro) WirePlumber 0.4.15 with an unreleased patch. Please do not enable speakers without that patch, as it'll leave the raw speaker device visible which is confusing and could trigger bugs elsewhere. Either get your WirePlumber package to add the patch, or wait for the next release. The correct deployment order is asahi-audio/speakersafetyd > (whatever you use to get those installed for users, e.g. metapackage) > kernel. If you push the kernel first before asahi-audio, users will get either a nonfunctional (if no speakersafetyd) or functional but bad-sounding (if speakersafetyd is installed) raw speaker device with no DSP. Wiki for the Asahi Linux project: https://asahilinux.org/",
    "commentLink": "https://news.ycombinator.com/item?id=38239503",
    "commentBody": "Speaker Support in Asahi LinuxHacker NewspastloginSpeaker Support in Asahi Linux (github.com/asahilinux) 261 points by pantalaimon 22 hours ago| hidepastfavorite142 comments jasoneckert 21 hours agoparentA better title for this would be \"Asahi introduces advanced speaker DSP to Linux\" as that is the real significance of this new development.I imagine it will be incorporated into other distros soon as a result. reply mahmoudhossam 21 hours agoparentCan someone ELI5 why advanced speaker DSP is a huge thing? I read the linked document and couldn&#x27;t really figure out why this is important and why it differs from what we already have in Linux systems. reply johnwalkr 20 hours agorootparentManufacturers can do a lot with DSP to make small speakers sound better. But \"advanced\" is saying a lot here. Recent speakers in macs and macbooks are over-driven to sound better and louder, with the DSP modeling energy input to the speaker and temperature of the speaker and keeping it within its physical limits. Without this DSP, the speakers not only sound terrible but become physically damaged if you try to use them at more than a very low volume. Any modern smart speaker or smartphone you buy will use similar DSP to sound much better and louder than it ought to, given its size. I think other laptops also do something similar at the hardware level.Rightly or wrongly, Apple does it in software on the CPU but until now this wasn&#x27;t replicated in linux. So the Asahi project (which is for macs with M1&#x2F;2&#x2F;3 CPUs), has added this feature to linux[1] and is working on adding DSP models for each model of Mx Mac. In Asahi Linux Speakers have been disabled by default on all models until this feature as well as the specific DSP for each model is ready. Now they have reached the point where speakers are enabled for the first model, which is a huge milestone.[1] I originally wrote \"linux kernel\" but it is actually done in user space, with interlocks in the kernel to fall back to simple aggressive volume limiting. reply MichaelZuo 20 hours agorootparentSo if the DSP model were only slightly off, then it could permanently damage the speakers? reply cyberax 17 hours agorootparentYup. Directly outputting maximum sound energy (high-frequency high-amplitude) will permanently damage the speakers in just a few seconds. reply johnwalkr 19 hours agorootparentprevNo because you make the models conservative. In the link marcan mentions they will improve performance over time (presumably partly by making the models less conservative) and are \"shipping with a hard volume reduction limit of -7dBFS to catch potential bugs or misbehavior.\" reply MichaelZuo 19 hours agorootparentIf so, how are the speakers over-driven to sound better and louder?Do they have a very very conservative profile by default? reply jacoblambda 18 hours agorootparentSo speakers have a worst case maximum power and sound profile. That is the bounds that if you never exceed you will be safe. But if you push past those worst case bounds, now you are entering a dynamic system where things like temperature start determining the actual bounds of the hardware and the points where stuff starts causing damage.Apple provides a system that drives the speakers within those bounds as close to the actual bounds as possible to get the most out of the system that they realistically can.Asahi is trying to do the same but are choosing a profile that is far more conservative than apple to start with while they get things ironed out. This profile they have is still an improvement over the worst case bounds but it has very sharp&#x2F;jarring \"safeties\" that trigger when the system suspects it might be close to damaging the hardware (dropping immediately to a much lower, safe level vs apple&#x27;s profile which gradually shifts the audio to a safe point without making it obvious that it is doing so). reply johnwalkr 17 hours agorootparentprevYou could say Asahi Linux was very conservative about this because they disabled speakers altogether until now.It’s ok to be quite loud for any one peak for a short amount of time (let’s say 50dB for 10ms) but for indefinite time periods much less is ok (let’s say 30dB but these are totally made up numbers). There are also limits to how much energy you can put into the speaker before it overheats. There also may be some frequencies with different limits (this is total speculation on my part). So the DSP models the behavior of the speakers and tweaks the input to prevent them from overheating (in my understanding). Normally you won’t notice this unless you are trying to play a single tone at max volume. Without this advanced DSP, you would have to just limit the output to 30dB which in practice means high volume parts of your audio are clipped or you limit to a very low volume to have enough headroom to play the louder components of your audio. Considering how loud and good modern macbooks, smartphones and smart speakers sound compared to similar sized speakers from even 10 years ago I think the effect is pretty great. reply c0pium 17 hours agorootparentprevThe real answer to this question is yes. There’s a caveat by the devs that their safeguards make bugs unlikely, but a bug here means permanently damaged hardware. reply leidenfrost 17 hours agorootparentprevDoes Windows have this?If it does, can we \"import\" it to linux? reply pantalaimon 13 hours agorootparentIt&#x27;s not Windows itself, but vendors providing machine specific drivers. reply jasoneckert 21 hours agorootparentprevThe main reason DSP is a big thing is because Linux has never focused on it - Google has with Android and ChromeOS, as has Apple and Windows, but Linux speaker audio has always paled in comparison: https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111230163766956867That leaves it up to the laptop vendor to implement hardware to perform DSP (and the quality of this varies tremendously from poor to OK). Apple doesn&#x27;t use hardware for their speaker DSP (it&#x27;s all software) and their speakers sound better than anything else out there. Linux now has similar functionality thanks to Asahi, and it will only get better over time. reply oneplane 20 hours agorootparentprevIt&#x27;s a huge thing because you can&#x27;t really fit all the big speakers and audio stuff in tiny laptops and make them sound good. So we use extra steps (the DSP for example) to adjust how the speakers and amplifiers are controlled. Doing it this way allows us to have much better sound from tiny micro speakers. This is important because the alternatives are: - Bad sound and nothing you can do about it - No sound at all - Carry external speakers with you all the timeWhere in the past it was impossible to both have physically small devices and good sound, technological advances have enabled us to do more with less. So adding that technology means we can now have better sound than in the past. reply vladvasiliu 21 hours agorootparentprevThe way I understand it, the tiny speakers in laptops don&#x27;t sound great. But since sound perception is somewhat relative, manufacturers use DSP to try to improve the perception of the sound.Of course, this will never rival an actual \"serious\" amp and speakers, but it can drastically improve matters. Anecdotally, my HP laptop has a pretty crappy sound under Linux, but under Windows with the Realtek drivers, it sounds OK. The soundcard itself doesn&#x27;t seem too bad: if I use a pair of nice headphones or plug it into my dedicated stereo, even under Linux I hear no difference compared to using an external DAC connected through USB. reply globular-toast 21 hours agorootparentBut we could already do DSP with Pulseaudio and Pipewire. I guess is making the speakers DSPs \"built in\" and tweakable with GUI etc? As well as actually creating the speaker DSP profiles, I guess.The speakers safety thing seems like a completely new thing, though.All sounds like an absolute nightmare to anyone even remotely into audio. But I guess tiny speakers are occasionally useful. reply hotnfresh 20 hours agorootparentIn this, our modern world, tiny speakers are what most people listen to most things on, except maybe in their cars.Phones, laptops, tablets. The tiny speakers built into TVs, much smaller than even built-in speakers on CRT TVs used to be. Ear buds of various sorts, and smallish headphones. That’s most audio-listening accounted for (except in cars).Hell, I’ve got a good hi-fi setup and (separately) a probably-top-couple-percent 7.2 home theater audio situation (in one room… but not on the other TV) and even so I listen to things on tiny speakers more than on big ones. reply Wowfunhappy 20 hours agorootparent> In this, our modern world, tiny speakers are what most people listen to most things on, except maybe in their cars.Hmm... I think you&#x27;re probably right, but the one thing that gives me pause is the enormous market for Bluetooth speakers. I see Bluetooth speakers everywhere! I suppose most Bluetooth speakers are still \"small\" in the grand scheme of things, but they&#x27;re certainly larger than phone and laptop speakers.Earbuds are similarly omnipresent. I&#x27;m not sure it&#x27;s accurate to classify those as \"tiny speakers\"; the physics are different, because they only need to be loud enough to hear when they&#x27;re next to your ears. reply johnwalkr 19 hours agorootparentGood bluetooth speakers also use similar DSP to sound way better and louder than they would without it so I am not sure this is a counterpoint. The unique thing here is Apple does it on the main CPU, presumably because \"why not\", so you couldn&#x27;t safely power the speakers of your mac while running linux until the related features were added. reply sethhochberg 18 hours agorootparentAt this point even \"bigger\" speakers make heavy use of DSP, too - from household commodities like Sonos to higher end hi-fi powered speakers like the KEF LSX series, almost everyone in the industry making an active-amplified product has wised up to the idea that some processing can make use of clever acoustic tricks or compensations to make their products sound better (by whatever definition of better their brand sells) than they would being drive flat from the source. When you provide the whole integrated package its a no brainer. reply Aeolos 19 hours agorootparentprevCompensating physical limitations to create a neutral sounds profile is useful regardless of the size of the speaker.I have a custom-made subwoofer that can hit 12Hz (measured), and creating a DSP profile to compensate for my room + speaker acoustics has significantly improved the listening experience.[1][2][1] https:&#x2F;&#x2F;www.hifiberry.com&#x2F;shop&#x2F;boards&#x2F;beocreate-4-channel-am... [2] https:&#x2F;&#x2F;github.com&#x2F;hifiberry&#x2F;hifiberry-dsp&#x2F;blob&#x2F;master&#x2F;doc&#x2F;r... reply globular-toast 15 hours agorootparentIs this more than just EQ? I think AVRs do some latency compensation too, although that&#x27;s probably only a problem in multi-channel set ups. reply Aeolos 13 hours agorootparentIt&#x27;s primarily EQ calibrated via a frequency sweep of the room + speaker acoustics.The hifiberry DSP does primarily three things: - equalization for speaker + room acoustics - customizable crossover frequency for speakers (in my case a 2.1 setup) - loudness equalization across speakersThere may be a latency compensation module, but that&#x27;s not something I needed in my case.None of this is rocket science, but audio does sound significantly better after compensation. Specifically, my living room geometry was causing standing waves in the ~200 Hz range, making the low-end sound unpleasantly boomy. The calibrated compensation pretty much eliminated this, without needing to invest in physical sound traps and the like.This is a fun little project for really not much money. I recommend it to everyone who likes tinkering, all you need is aBut I guess tiny speakers are occasionally useful.They are to me. My laptop is much easier to carry on planes than my audio system, and I don&#x27;t always like having headphones on, for example when watching a movie in bed. reply wzdd 21 hours agorootparentprevI think the idea with the M-series laptops in particular is that you can drive the speakers at volumes that actually damage them very quickly ( see https:&#x2F;&#x2F;github.com&#x2F;AsahiLinux&#x2F;linux&#x2F;issues&#x2F;53 ). The idea AIUI is that you can use a DSP along with a physical model of the voice coil to get better sound than you would if the speakers were volume-limited.I don&#x27;t know how common this arrangement is in other laptops, but it&#x27;s the kind of hardware&#x2F;software integration that Apple is known for. reply prmoustache 16 hours agorootparentIt is just dynamic range audio compression to simulate loudness. It is not a new thing. reply wtallis 15 hours agorootparentIt isn&#x27;t just dynamic range compression. This is actually driving the speakers beyond their safe limits for sustained output as long as the temperature estimate (a function of the specific speaker&#x27;s characteristics and the recent history of the signal it&#x27;s been fed) is safe. \"Dynamic range compression\" doesn&#x27;t imply any of that. reply _joel 21 hours agoparentprevIndeed, I didn&#x27;t think much of the work until it dawned on me the effort needed to accomplish this behind the scenes. Interesting post. reply megous 19 hours agoparentprevOr not: https:&#x2F;&#x2F;www.hifiberry.com&#x2F;docs&#x2F;software&#x2F;guide-adding-equaliz... reply azinman2 18 hours agorootparentThis is more than just EQ. reply esjeon 20 hours agoparentprevFor DSP, we already can do that using something like Easy Effects[1][2].Unfortunately, this isn&#x27;t shippable for distros. The biggest issue is acquiring proper impulse-response data. In theory, it has to be tuned per-model, and turning basically requires pro-grade equipment and a recording studio. However, apparently many people assume Dolby is using the same profile for all laptops, so just copy-paste the same file here and there. Not really sure which is the real case.Anyways, Asahi can ship DSP turned on by default because the distro is specific to Apple. That&#x27;s how Apple boosts the quality of its hardware, and the same applies to a distro dedicated to it.[1]: https:&#x2F;&#x2F;github.com&#x2F;wwmm&#x2F;easyeffects[2]: https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;27122564&#x2F;which-version-o... reply mort96 18 hours agoparentThis doesn&#x27;t contradict what you&#x27;re saying, but it&#x27;s worth noting: speaker support on these laptops couldn&#x27;t be done through Easy Effects, and speakersafetyd does way more than just DSP. There is no safety mechanisms built in to the hardware&#x2F;firmware to prevent blowing out the speakers, so speakersafetyd needs to ensure that stuff doesn&#x27;t get too hot; and that can&#x27;t be done with a simple volume cap either, since the speakers sound terrible when driven at a guaranteed safe gain level. You need software with a model of how the speakers behave to monitor sense data and dynamically reduce the volume when the audio would otherwise have made the voice coils dangerously hot.And the system needs to be fail-safe, so that the speakers don&#x27;t get blown out if the daemon crashes or hangs.---As a separate topic, I disagree that this isn&#x27;t shippable for distros. Distros already have a bunch of hardware-specific stuff. Libinput, for example, has a hardware database to correctly handle or work around quirks for all sorts of input hardware.There&#x27;s absolutely nothing which would prevent Ubuntu from providing speakersafetyd&#x27;s hardware database, either as an optional package, or, if out-of-the-box Mac support is important, as a package that&#x27;s installed by default. reply coffeeling 13 hours agorootparent> Libinput, for example, has a hardware database to correctly handle or work around quirks for all sorts of input hardware.As a complete aside unrelated to the broader discussion, libinput is my nemesis and it has degraded my user experience of Linux.I hate, hatehatehatehate one finger tap to click. It&#x27;s a huge misclick generator, and libinput used to have it off by default for good reason.However, libinput gates all actually useful and not very error-prone gestures like two and three finger taps to right and middle click and multifinger swipes behind having one finger tap to click enabled. You either take it all or you get nothing.This is a huge regression from the old Synaptics interface which let the user freely assign different actions to taps with different amounts of fingers.The worst is that it&#x27;s completely intentional and has been the case for over five years because the old maintainer didn&#x27;t want to write tests. reply mort96 12 hours agorootparentI also take issue with parts of libinput... there are things which are relegated to the hardware database which should 100% be config options. I don&#x27;t mind the idea of having a hw database, but if I as a user disagree with a choice made in the hw database, I should be able to easily change it. It sounds like the \"all or nothing\" tap to click stuff fits the general vibe of not letting the user configure stuff too much.I also dislike how there&#x27;s no global libinput config file. I get that it&#x27;s supposed to be a library, and the user of the library (GNOME, KDE, Sway, whatever) is supposed to expose those options, but in practice, a lot of useful options aren&#x27;t exposed to the user. GNOME is especially bad about that.There are also weird choices, like: when you press down with two fingers and then move those fingers together (double click and drag), the cursor moves at twice the normal speed.Linux input isn&#x27;t universally better now than it was a decade ago and that sucks. reply russdill 16 hours agorootparentprevI&#x27;m picturing various vendors completely switching out speaker packages without changing any DMI strings because they simply don&#x27;t care reply hedora 19 hours agoparentprevHonestly, this sort of thing should be considered “shippable”, and the fact that it isn’t has been holding Linux back for 10+ years.I’ve been waiting decades for a Linux distro that just buys a few commonly produced laptops that are likely to be produced for a few years, and then tests the crap out of them and applies this sort of polish.Current gen thinkpads probably would have fit the bill for the last ~30 years, for example. I was hoping the pinebook pro would be this, but it has a few severe hardware issues (suspend battery life, DSP noise) that don’t look like they’ll be fixed. Similarly, the XPS line has the capacitor whine problem, and are based on Intel (which has been exclusively shipping power hungry hot messes for the last 10 years).If the M[1-3] end up being the models where Linux finally gains stable support for reasonable laptop hardware, then so be it. reply trelane 18 hours agorootparentWhat you&#x27;re describing is \"system integration.\" It&#x27;s a whole thing. What&#x27;s more, it&#x27;s a thing that already exists in the Linux world There are companies that buy and build hardware that supports Linux, and sell it to you with support. Why not just buy from them? reply Retr0id 17 hours agorootparentThe value proposition of M2 and M3 have been comparatively weaker, but on launch, the M1 macbooks blew everything else out of the water in terms of bang for buck, IMHO. You could perhaps beat them in terms of raw compute, but once you factor in the 120Hz HDR panel, excellent keyboard, sleek but still relatively robust chassis, it&#x27;s an all-round winner.Of course, it lacked Linux support on launch, but that&#x27;s why the Asahi project is so great. It&#x27;s providing that missing component of system integration.Framework, System76, etc. are producing some cool laptops, and I&#x27;d consider them if I were looking to buy a new laptop today - but I&#x27;m not. I have an M1 Pro MBP in my hands right now, and I have no need to upgrade it any time soon. reply goosedragons 13 hours agorootparentUntil you factor back in buying a usable config. And the fact that Asahi is still not totally feature complete. Three years on and DP alt mode for example is still a WIP. reply Retr0id 12 hours agorootparentFor my own personal use-cases, it&#x27;s been feature-complete for the last year or so, and I&#x27;ve been daily-driving it ever since. reply tedunangst 13 hours agorootparentprevWhich company sells the Linux laptop with the best DSP? reply matheusmoreira 6 hours agorootparentprev> I’ve been waiting decades for a Linux distro that just buys a few commonly produced laptops that are likely to be produced for a few years, and then tests the crap out of them and applies this sort of polish.So who is going to do all that work?I bought a laptop that has RGB LEDs in the keyboard. I didn&#x27;t particularly mind not having control over them on Linux but the problem was they defaulted to the brightest purest blue color imaginable. Booting Windows just to run the shitty manufacturer&#x27;s software was unsustainable so I reverse engineered it and made a Linux user space driver with libusb.That took a significant amount of time and effort. Just a bunch of LEDs, it seemed like a simple task. I actually had to record the USB messages with wireshark and then figure out what they meant, correlating the bits sent with my physical inputs. Hundreds of LEDs.I simply can&#x27;t fathom what it would take to apply polish like speaker safety to my own laptop. I honestly didn&#x27;t even know there was a safety risk involved before I read this thread. Do these Linux distributions really have so much money in the bank that users can expect them to buy hardware to test stuff like this on? It&#x27;s hard enough to ship software that works at all. reply serf 11 hours agorootparentprev>I’ve been waiting decades for a Linux distro that just buys a few commonly produced laptops that are likely to be produced for a few years, and then tests the crap out of them and applies this sort of polish.nearly every major distribution does this to some degree and has had for years and years; whether or not you&#x27;re happy with that level of &#x27;polish&#x27; is another thing, though. reply biorach 18 hours agorootparentprev> I’ve been waiting decades for a Linux distro that just buys a few commonly produced laptops that are likely to be produced for a few years, and then tests the crap out of them and applies this sort of polish.I suspect that the laptop market is far too fragmented to make this worthwhile reply xcv123 8 hours agorootparentThe top 6 vendors have 85% market share. Just choose Lenovo or HP or Dell. Top 6 vendors by number of units shipped, 2022 1 Lenovo 24.1% 2 HP 19.4% 3 Dell 17.5% 4 Apple 9.8% 5 Asus 7.2% 6 Acer 6.5% Others 15.5%https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Market_share_of_personal_compu... reply jandrese 3 hours agorootparentDo you know how many different models of laptop that HP alone is currently selling? One Hundred and Twenty. And that list has regular churn. You might think they&#x27;ll all be using the same firmware and chipsets but you would be wrong. There are dozens of configurations, some older, some newer, some higher performance, etc... It&#x27;s a huge mess. reply jorvi 12 hours agorootparentprevThey could do the Dell XPS 13” and 15”. Once you factor in the XPS rebadge Latitudes, that would be a pretty big number.They make for cheap pickups on the secondhand market too. And Dell already does a bunch of testing&#x2F;fixing for free as they ship them with Ubuntu. reply tuna74 15 hours agorootparentprev\"I’ve been waiting decades for a Linux distro that just buys a few commonly produced laptops that are likely to be produced for a few years, and then tests the crap out of them and applies this sort of polish.\"You can start that if you want to! reply Wowfunhappy 19 hours agoparentprev> Anyways, Asahi can ship DSP turned on by default because the distro is specific to Apple. That&#x27;s how Apple boosts the quality of its hardware, and the same applies to a distro dedicated to it.Aww, so you don&#x27;t think other distros will ship this even once upstream is figured out?Kernels already ship hardware-specific drivers, but I suppose that just comes with the Linux kernel, whereas this needs support on both the kernel and userspace sides... reply jakobson14 16 hours agorootparentIf a distro is shipping an image specific to macs? sureIf a distro is expecting you to install onto the rando asus gaming laptop you got at staples? not going to work.The thing about M-series apple macs is there are only like 10 models total to record profiles for. You can&#x27;t realistically do that and ship profiles for every x86 laptop under the sun. reply epcoa 15 hours agorootparentI am at a complete loss how this is any different or harder than shipping hundreds of bits of firmware or hundreds of quirks for random hardware (have you seen the entirety of the quirks tables in the Linux kernel) all based off hundreds of drivers shipped with the kernel.You maintain profiles in a repo and package them like anything else. No one has indicated how this cannot usually be zero config via hardware probing. reply seszett 15 hours agorootparentprevHow are you applying that to the Asahi packages though? They&#x27;re just packages for Fedora, a pretty generic distribution, and ArchARM, which is also meant to be installed on Raspberry Pis or Chromebooks after all. I know it because I run it on both Raspberry Pis, my M1 and a Hetzner server.it seems like precisely the contrary to an Apple-specific distribution. reply winterqt 19 hours agorootparentprevThey&#x27;ll be able to ship it, just requiring users to install an Asahi-specific package to enable it; see the \"Distro integration notes\" section. reply LudvigHz 12 hours agoparentprevWell, speakersafetyd is is shipped in upstream fedora, which definitely is not apple-specific.And you don&#x27;t need a recording studio to enable it on more hardware. marcan did the measurements for the MacBooks with a cheap measurement mic.So you can have great audio on any hardware by just doing the measurements and including them in the asahi-audio package, _in upstream fedora_.Source: marcan on mastodon[1][1]: https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111398502380681345 reply spookie 19 hours agoparentprevI wonder, can&#x27;t distros provide pipewire configs and patches? I&#x27;ve had great success with my laptop (other maker) with both a kernel patch for DSD and a quite straightforward pipewire config (the filters.avail folder has examples for Dolby surround!). reply Wowfunhappy 21 hours agoparentprevA demonstration of how important the speaker DSP is:https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111230163766956867 reply dfc 14 hours agoparentA lot of people are talking about it as if it&#x27;s self evident which one is better. Or that if I played the sound on a certain device it would be obvious. Can someone state what part of the video is the good part? reply JoBrad 10 hours agorootparentThe center audio is cut dramatically, making it much harder to hear the voice. It was very obvious to me, on an iPhone. reply Wowfunhappy 12 hours agorootparentprevIt starts with the DSP enabled, so that&#x27;s the \"good\" state. Then it&#x27;s toggled off and on a few times. reply kuschku 19 hours agoparentprevTbh? While I can tell a difference, I couldn&#x27;t tell you which one is supposed to sound \"better\". reply Aeolos 19 hours agorootparentAre you perchance listening on laptop speakers?With real speakers or headphones the difference is extremely striking. reply Wowfunhappy 19 hours agorootparentFor what it&#x27;s worth, it&#x27;s very clear to me which is better even on my iPhone&#x27;s speakers (as well as on my desktop&#x27;s \"real\" speakers, of course). Sound preferences are deeply personal, but I&#x27;m still pretty shocked GP can&#x27;t tell. reply diffeomorphism 18 hours agorootparentConsider hi-fi speakers vs monitors. The difference is very clear, but it would be somewhat wrong to call either \"better\". reply shmerl 17 hours agorootparentprevYou can hear the difference very well using regular headphones. The supposedly \"better\" one feels strongly amplified. reply bscphil 15 hours agorootparentI agreed with this so I made the levels equal (as measured objectively with EBU R 128): https:&#x2F;&#x2F;0x0.st&#x2F;HvXA.wavThe first (DSP processed) clip still sounds much better to me. The first time the unprocessed clip is played it&#x27;s rather noisy for some reason, that could be room noise picked up in the microphone though. The high end is missing from the second clip almost entirely (anything above 5 khz).However the DSP clip isn&#x27;t without significant problems. It sounds distorted to my ear, and slightly pitch shifted as well. It&#x27;s rather \"tinny\" sounding. I&#x27;d rate both clips extremely annoying to listen to in comparison to the original which seems pretty well mastered if you like this sort of thing: https:&#x2F;&#x2F;youtu.be&#x2F;ZRtdQ81jPUQ?t=52It&#x27;s hard to tell how much of this is due to it being a quick and dirty recording. Also, being able to play audio at higher volumes is supposed to be one of the big advantages of using this DSP chain, since temperature spikes created by transients are managed in software. (Just speaking for myself personally, I&#x27;ve never felt that my non-Apple laptop speakers needed to be louder, even without DSP.) reply Aeolos 17 hours agorootparentprevIt&#x27;s not just loudness, the DSP version also has a much more natural flat&#x2F;neutral sound profile.If you are interested, there are corresponding frequency response measurements from a measurement microphone in a sibling thread. reply jchw 18 hours agoparentprevIt honestly probably would help a lot of people to hear how it&#x27;s supposed to sound first. It&#x27;s easy to tell how striking the difference is, but it&#x27;s probably a lot more obvious how much better it is when you&#x27;re comparing to a \"ground truth\".https:&#x2F;&#x2F;youtu.be&#x2F;ZRtdQ81jPUQ?t=52 reply dfc 18 hours agoparentprevThe audio is so outside of the stuff I normally listen to that I don&#x27;t think I really appreciate the difference. reply nineteen999 11 hours agorootparentTotally with you, my 13yo daughter listens to this stuff all day but it&#x27;s not what I&#x27;d use to compare.Each to their own I guess. reply tambourine_man 18 hours agoparentprevHonestly, this kind of music is so annoying to me it’s hard to pay attention.One sounds way “fuller” (more bass perhaps) than the other, but I’m just looking at the timeline hoping the torture will end soon. reply jchw 17 hours agorootparentYou might be amused&#x2F;horrified to know, then, that this is (was?) the top track in Japan for many weeks straight (at least according to Billboard and YouTube.) reply tambourine_man 16 hours agorootparentI can imagine. Most people who enjoy this kind of music probably despise what I hear, too. reply dfc 18 hours agoparentprevSound on Linux is the one thing that seems to be more confusing 25 years later. I can remember scouring Usenet&#x2F;mailing lists trying to research which soundblaster card to get for the best experience. When I compare that to wrapping my head around Pipewire+Pulseaudio+Jackd+*effects I feel like I know way less about sound on Linux now. I don&#x27;t do any professional audio stuff I just want to listen to music on my Linux computers and occasionally play the sound throughout the house. Whenever I start to look into doing it \"the right way\" it is always overwhelming. reply morsch 18 hours agoparentI also know less about sound on Linux now. I don&#x27;t even know if my system is running Pulseaudio or Pipewire. I don&#x27;t need to know! I consider this an improvement. reply mdhen 16 hours agoparentprevPipewire and its compatbility programs is all you need. So arch that is pipewire, pipewire-alsa and pipewire-pulse. There&#x27;s also pipewire-jack if you need jack support. reply coldtea 12 hours agorootparentAh, the \"just switch to this distro\" fix. reply hedora 19 hours agoparentprevThey also added webcam support and an installer for the M2!If the status page is to be believed, it’s getting extremely close to daily driver status for me. reply rzzzt 21 hours agoparentprev> These are all techniques that are in wide use in consumer microspeaker systems in tablets and phones, though sadly not common on laptops from most non-Apple brands.Dell &#x2F; Realtek &#x2F; MaxxAudio (not sure who to attribute it to) offers such an implementation with mixed results. Some people go to great lengths to remove it and replace with something that offers a flat response -- personally, I didn&#x27;t mind the alterations it introduced and the speakers \"feel\" quieter without it installed. reply Wowfunhappy 19 hours agoparentFor what it&#x27;s worth, the article says:----- Our DSP profiles aim to provide a balanced sound, with the features that people expect from high-quality laptop&#x2F;small-speaker audio. In particular, we aim for: • A balanced (neutral) tone at moderate listening volumes, with a mostly flat frequency response from a typical listening position • Reasonably high peak volume with acceptable sound degradation (compression, limiting, etc.) • \"Fake bass\" processing to make audible frequencies that cannot be physically reproduced by the speakers, extending the perceived frequency response of the system. • Equal-loudness volume compensation, so that the sound does not become noticeably tinny as the system master volume is lowered. [...] Our goal is explicitly not to clone the full&#x2F;exact macOS audio experience. We consider the macOS speaker DSP processing to be too tryhard.-----So I suspect Asahi&#x27;s implementation will be far more conservative than the systems you&#x27;re referencing. It&#x27;s also worth noting Marcan is a musician. reply rzzzt 18 hours agorootparentThese are very similar things to the features the MaxxAudio control panel offered (and now that I think of it, my ancient Windows 8 tablet had Dolby-badged software on it with a similar feature set):- Custom response curves for the built-in speaker as well as some brand speakers&#x2F;headphones (responsible for the \"what did you just plug in?\" dialog that annoys many users)- User-adjustable EQ- Compression, limiter, AVL, \"night mode\", loudness: I&#x27;m lumping these together in one basket as I don&#x27;t know what components were in use behind the scenes- Reverb: for cases where you want to listen to music that comes out of a PVC drain pipe of a concert hall&#x27;s restroom- Possibly downmixing multi-channel audio for headphone users, but I&#x27;m not sure in this one either. reply Wowfunhappy 16 hours agorootparentIt&#x27;s similar but to a different degree. The goal is a neutral profile. reply agentbellnorm 16 hours agoparentprevThe Asahi devs are doing the lords work. Looking forward to using it in the future. reply devit 12 hours agoparentprevSeems really terrible engineering to design a laptop where malware can destroy the speakers.I guess there&#x27;s reason to wonder whether malware might also be able to set the whole machine on fire. reply coldtea 12 hours agoparent>Seems really terrible engineering to design a laptop where malware can destroy the speakersIt&#x27;s not something laptop specific: you can damage any pair of plain regular speakers (say hi-fi speakers) by sending them the right (meaning wrong) audio signals to them: burn the voice coil, fry the tweaters, etc. Audio engineers take certain precautions to what they send the speakers.Laptop speakers have software control of the speakers for protecting them from this, and to allow better performance as long as the components aren&#x27;t overheating, etc. reply londons_explore 3 hours agoparentprevAll modern hardware can be destroyed by something that gets sufficient permissions to poke hardware registers.You could for example blow all the efuses in anything with signed firmware versioning - meaning there would be no firmware release that will boot anymore.You can also typically increase system voltages to cause failure, erase flash so many times it fails in a few minutes, overwrite bootloaders in peripherals so they can&#x27;t be fixed without a soldering iron, etc. reply Gigachad 8 hours agoparentprevMacOS has SIP which makes it impossible for malware to alter these system components. reply nicce 8 hours agorootparentThen there us powerusers which disable SIP for better window control…But also, there have been many bugs in the past which bypassed SIP. reply jareklupinski 12 hours agoparentprev> malware might also be able to set the whole machine on firethat was one of my favorite parts of Mr. Robot reply jchw 20 hours agoparentprevHuh, is it really true this is the first? I figured this was just being done in hardware in some modern laptops instead of software. At least for basic stuff like EQ, if not compressor&#x2F;etc. Otherwise, what&#x27;s with all of the DSP stuff modern Intel laptops need on Linux, what with Sound Open Firmware and whatnot?(And if not that, I am mildly surprised ChromeOS&#x2F;Chromebooks don&#x27;t do much of this either.) reply p_l 19 hours agoparentTL;DR various variants of the same technique are covered by different patents, and Apple doing this on application processor avoids some of those patents.A good example of different approach is laptops branded with \"Harman Kardon\" speakers - Harman-Kardon has a patent on exactly this but involving separate DSP running transparently to the OS. Similarly there are various other solutions to improve sound quality of small speakers being done, and for some of that modern SoCs are bringing in dedicated DSPs onboard. reply mort96 14 hours agorootparentMan patents were a mistake. “Run DSP on a separate chip” should not be remotely close to the realm of things which the state creates a legal monopoly for. reply jchw 19 hours agorootparentprevInteresting. So, on top of, I presume, whatever DSP you get from the sound chipset&#x2F;SoC, there could be other layers of DSP throughout the hardware too. That seems like a real pain in the ass, to be honest. (Though personally I&#x27;d really prefer something that protects the voice coils from overheating to be in hardware at least, if nothing else.)(I still do genuinely wonder what&#x27;s going on inside of SOF on modern Intel laptops, too. That&#x27;s not separate from the chipset and I don&#x27;t think it gets tuned for specific laptop acoustics. So what does that do?) reply nudgeee 15 hours agorootparentI think modern Intel chips contain Tensilica Xtensa HiFi DSP [0] cores for audio processing, I’m pretty sure this is what SOF targets.I’m not an expert, but probably used for speaker DSP as well as mic&#x2F;speech processing (think for Cortana&#x2F;etc).Manufacturers of laptops probably provide their own firmware to load onto these cores as part of a driver.[0] https:&#x2F;&#x2F;www.cadence.com&#x2F;en_US&#x2F;home&#x2F;tools&#x2F;ip&#x2F;tensilica-ip&#x2F;hif... reply p_l 11 hours agorootparentPhoenix APU presentation talk about DSP for dropping processing into input&#x2F;output of audio (quite probably including things like turning an array of microphones into single source, etc.) reply p_l 16 hours agorootparentprevHaving recently looked for new laptop, they often have firmware loaded by driver on windows into DSP or sound chain, sometimes even to enable half of the speakers you need to custom load firmware on Linux which apparently includes DSP code that adapts stereo signal for multiple speakers with different parameters. reply wolf550e 20 hours agoparentprev@marcan wrote a lot about the DSP work and why it&#x27;s important &#x2F; what it does. He also wrote about bugs across the linux audio stack.https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111379933565349212https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111369113203280839https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111368139961624028https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111363323102625920https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111356347520217702https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111351807108120657https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111322854564301468https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111312763506327704https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111305404286878529https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111275789631652315https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111274712520670628https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111274302586522319https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111230163766956867https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111230007884019185 reply wolf550e 17 hours agoparentNew post \"So how does speakersafetyd work?\"https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111398084943456556 reply Topgamer7 11 hours agoparentprevMy Asus g14 sounds awful on speakers. Hopefully this can fix that :) reply rowanG077 21 hours agoparentprevThey really go the extra mile, and then another mile on top of it. I guess the only \"main\" feature remaining essentially all other laptops have is external screen support. reply hedora 19 hours agoparentAlso, touch id and neural network inferencing acceleration. Presumably, you’d get AI acceleration, but not reasonable battery life on a gaming NVIDIA laptop.Anyway, once speaker support arrives for the M2’s I’ll try switching back to Linux for my daily driver (almost all my dev work happens in an ARM VM under MacOS as it is…) reply rowanG077 19 hours agorootparentThere is a driver for the Neural engine. Touch id doesn&#x27;t work yet. reply MBCook 14 hours agorootparentDoes Touch ID work on the Intel Macs? reply aPoCoMiLogin 25 minutes agorootparentit does reply2Gkashmiri 20 hours agoparentprevi want to buy a used apple m1 machine just to use asahi. (coming from a linux guy who has never owned an apple mac machine)i have seen all the \"tables showing compatibility\" but how is it in real life? i should i buy a machine solely to daily drive asahi? reply Aeolos 19 hours agoparentI&#x27;ve been using Asahi on the M1 Air for >1 year now for my personal &#x2F; non-work laptop, and it works decently. With sound & webcam support now enabled, this can now now be used fine as a daily driver. Battery life during use is excellent, up there with the best of any linux laptop, and GPU acceleration is good and getting better every day.Missing features, so you can decide if those matter to you:- improved external monitor support- hardware video decoding - mainly for better battery life, because the CPU is more than fast enough for real-time software decoding. (This is work-in-progress.)- fingerprint sensor reply toomim 10 hours agorootparentAnd sleep. reply rowanG077 19 hours agoparentprevAs someone who daily drives a Linux M2 MBP: It depends if you can live with some caveats. The main ones are- No sound from the speakers (unless you have an M1 as can be seen from this post). But headphones work.- No external screen support- No Thunderbolt- No Fingerprint sensor- No Video decoding&#x2F;encoding acceleration. But the CPU is strong enough to easily keep up with 4k 60FPS. So you \"just\" pay for it with shorter battery life.- No support for some important GPU APIs (Vulkan, OpenCL, newer openGL) which some application you use might need.The above list is the current state and even a few months from now will probably look different. reply Wowfunhappy 19 hours agorootparentWhat about the microphone? IMO that&#x27;s a really big one, something you just expect all laptops to have in 2023.I suppose if you&#x27;re using headphones anyway (since the M2 doesn&#x27;t have speaker support) they may come with a microphone, but they may not... reply rowanG077 19 hours agorootparentNo microphone unfortunately. reply WesolyKubeczek 13 hours agoparentprevFor the sake of completeness, this problem is not at all endemic to Apple’s M hardware.Some of the older Thinkpads — W510, T400, and T410, so beloved and praised by Linux enthusiasts, used to suffer from the same problem — their speakers could get destroyed after a few minutes of playing audio. Just wondering if Lenovo’s drivers for Windows 7 included similar safeguards. reply jauntywundrkind 16 hours agoparentprevI hadn&#x27;t heard of uclamp before, mentioned as a way to save power on the compute intensive DSP work. Found this tweet by Marcan that seems to indicate it&#x27;s a way to pin the process to e-cores. https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111363323102625920 reply almostnormal 21 hours agoparentprevLinux had speaker [0] support since longer than I can remember. Reading the headline I was expecting something about software using it to create less low quality output. But it seems it is about modifying the \"modern\" audio output to work around limitations of laptop speakers.[0] https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;PC_speaker reply n2d4 8 hours agoparentThis is specifically about Asahi Linux, a distro that runs on Apple Silicon (which had no speaker support so far)You&#x27;re right that if you&#x27;re missing that context, it&#x27;s kind of hard to tell just from this issue alone. reply sampa 20 hours agoparentpreveverything about asahi feels like it&#x27;s an apple&#x27;s product: everywhere you look - it is always \"amazing\"!but so far no finally usable implementation exists even for m1 macbooks and they age quickly, and I doubt people will see anything usable in the end (yeah, you might get a fully working Linux on your old dusty m1 when you buy m7, happy?).so far it is achievements for the sake of achievements reply alin23 20 hours agoparentThings take significantly more time without documentation. Try reverse engineering something and you’ll wake up 7 days later with almost no result thinking what the heck were you trying to do in the first place. so far it is achievements for the sake of achievementsWe are people, and we need to feel that our hard work isn’t for nothing. Sharing achievements and getting some praise for it is one way to keep our ambition.Asahi devs are reading these comments. Don’t shit on their work for no good reason. reply viraptor 19 hours agoparentprevSo far M systems are pretty similar to each other, which means m2 was much less work than m1. And I suspect m3 will be less work than m2. There&#x27;s definitely a long delay on the first model, but extrapolating that to 6 next releases doesn&#x27;t make sense.> so far it is achievements for the sake of achievementsPeople are daily driving Asahi today, so that&#x27;s incorrect. reply seszett 14 hours agoparentprev> but so far no finally usable implementation exists even for m1 macbooks and they age quickly, and I doubt people will see anything usable in the end (yeah, you might get a fully working Linux on your old dusty m1 when you buy m7, happy?).I&#x27;m not sure what you mean, I&#x27;ve been running Asahi on my M1 for about a year now. I have enabled sound (without the safeties, but I&#x27;m not listening to anything remotely loud) and the only thing annoying is the lack of microphone (I have to plug headphones when I need a micro).It&#x27;s been totally usable for at least a year. reply jancsika 18 hours agoparentprev> This allows the speakers to be driven to much higher peak levels than the worst-case safe volume level, greatly extending their dynamic range.So software devs are going to drive the speakers past the worst-case safe volume level that was presumably set by hardware engineers? And they are going to do it with software running in a OS that isn&#x27;t realtime safe?Anyone else see a problem here?Also-- does anyone know what Asahi is using to test the safety of what they&#x27;re doing? reply jacoblambda 18 hours agoparent> Anyone else see a problem here?No.The worst case safe volume levels are levels determined by the speaker manufactures that if you never exceed, you can never harm the hardware (due to overheating, etc).You can and should exceed those levels to use the hardware as it is intended by the manufacturers however if are doing so, you are now moving from a static system (one set of safe levels) to a dynamic system where the safe levels are determined by a multitude of variables and as such you need to have software or hardware monitoring those variables to keep the system within those safe bounds. reply kalleboo 18 hours agoparentprevThat&#x27;s how it works on macOS already, that&#x27;s how these machines are designed to run. reply jakobson14 16 hours agoparentprevAnother person who doesn&#x27;t understand a damn thing about why the safety daemon is needed or how it works.If you keep careful track of the audio going through the speakers and the energy in each frequency range, you can figure out exactly what the temperature is at any given moment and make sure it stays under the limit. However, this requires a ton of math.Alternatively, you can just put a hard cap on the volume, such that no combination of frequencies could ever overheat the speakers. This is safe, but sounds like crap. It&#x27;s a far, far less nuanced way to do things and results in restricting how hard you can drive the speakers far more than is actually nesisary. reply mort96 18 hours agoparentprevWhat is your proposed alternative solution, given the constraint that without exceeding the guaranteed-safe volume levels, the speakers are garbage? reply Zetobal 18 hours agoparentprevYou never overclocked a CPU when you were a youngling? For example I undervolt my CPU and GPU for lower noise and heat with just 2-3% loss in performance. reply kccqzy 11 hours agoparentprevHere&#x27;s an example of testing speakersafetyd: https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111305404286878529How it works with the kernel side of things: https:&#x2F;&#x2F;social.treehouse.systems&#x2F;@marcan&#x2F;111398084943456556 reply karmakaze 20 hours agoparentprevThis seems to be a problem being solved at too low a level of abstraction. It should be able to use the same architecture for performing say a 7.1 to binaural headphone 2-channel output, all by only routing and processing signals. Perhaps this is how it&#x27;s being solved, but having \"speaker\" so hardcoded in the project work may not be the case, or seemingly so. reply wtallis 19 hours agoparentPart of what this is trying to solve requires working with zero abstraction over the underlying hardware: driving the laptop&#x27;s built-in speakers as hard as possible without literally melting them, which requires not just processing the audio data in realtime, but also accounting for the particular characteristics of each laptop model&#x27;s several speakers. reply karmakaze 19 hours agorootparentAll that info can be made available at a higher level. The only reason to do it at a lower one is to reduce surface area where software bugs could destroy the speakers.> Our implementation, speakersafetyd, monitors feedback signals from the amplifiers, estimates speaker voice coil temperature using a two-stage thermal model, and reduces the hardware speaker volumes when the speakers get too warm. We also have kernel-side interlocks to disable or limit speaker volumes if speakersafetyd is not running or non-responsive.This is the only part that seems to need to be low-level, anything else could be done at a higher one, generally EQ type settings like &#x27;loudness&#x27;. reply lonjil 15 hours agorootparent> This is the only part that seems to need to be low-level, anything else could be done at a higher one, generally EQ type settings like &#x27;loudness&#x27;.But that already is the only part that is low level. The EQ stuff is done with PipeWire. reply hedora 19 hours agorootparentprevExisting laptops provide that higher level of abstraction, and audio quality is uniformly garbage.It’s likely much easier for the open source people to do the work to deal with the underlying physics once, and then port it to all hardware. The laptop models are all essentially the same (they have a few electromagnets, cones and a few sounding boards). Each one has different parameters in their mostly-linear response curves. My guess is that after the first few models work well all the others will rapidly fall into line.Something similar happened with printers 20 years ago. The open source stack implemented state of the art dithering and font hinting once and ended up producing higher quality output than the commercial windows drivers for the same printers. reply mort96 18 hours agoparentprev??? The only higher level in the stack is the applications which want to output audio! This is already being done in a daemon running in userspace! reply AshamedCaptain 21 hours agoparentprev [–] This article is a bit bombastic and light on details: \"modern audio laptop subsystem\", \"advanced DSP\", \"the first desktop Linux platform with integrated advanced speaker DSP\", \"driving Linux desktop audio forward a couple decades\".... while as far as I can tell there are exactly 0 new things described.> These [DSP profiles] are all techniques that are in wide use in consumer microspeaker systems in tablets and phones, though sadly not common on laptops from most non-Apple brands.As anyone who has bought a laptop less than 10 years old can attest, practically _all_ laptops ship with \"DSP effects for tiny speakers\", to varying results. Microsoft has even standarized an API in Windows 10&#x2F;11 so that you literally can shop for different implementors in the Windows store (e.g. Sonic, B&O, etc.).> EasyEffectsArticle itself mentions previous work on DSP effects...> we also have the world&#x27;s first (as far as we know) open source \"smart amp\" implementation.Old Nokia devices shipped with xprot which is about a decade old. Speaker protection, DSP, noise cancelling, etc. back when pulseaudio was just renamed from polypaudio. https:&#x2F;&#x2F;blog.linuxplumbersconf.org&#x2F;2009&#x2F;slides&#x2F;Jyri-Sarha-au... reply viraptor 19 hours agoparentXprot was not open source. Here&#x27;s a reverse engineered version from much later https:&#x2F;&#x2F;notabug.org&#x2F;freemangordon&#x2F;pulseaudio-nokia&#x2F;src&#x2F;frema... which turns out to read the ambient&#x2F;battery temperature rather than coil-specific one. Kind of a similar idea, but more of a really simple precursor to what Asahi did, with no kernel level protection. reply AshamedCaptain 19 hours agorootparentI stand corrected, but even the open version happened \"much before\" this one from Asahi. For kernel-level, there&#x27;s already quite a bunch of previous work due to Android, so it doesn&#x27;t really count, either. reply TimTheTinker 20 hours agoparentprev [–] All of this may be old hat for macOS and Windows, but it&#x27;s entirely new to Linux. That&#x27;s kind of the point. reply AshamedCaptain 20 hours agorootparentEasyEffects is designed for Linux. xprot is designed for Linux. Both open-source. And used in consumer products.(And all of this is ignoring the bunch of Android stuff which while Linux doesn&#x27;t classify as \"desktop Linux\"). reply TimTheTinker 20 hours agorootparentI mean a vendor-specific DSP&#x2F;speakersafetyd&#x2F;hardware chain being exposed as the onboard speaker device for certain laptops, instead of the raw device.This has never existed as an OOTB experience. In Apple&#x27;s case, it&#x27;s absolutely necessary to avoid blowing up the speakers - hence why they disabled speaker output before the audio chain was done. reply AshamedCaptain 20 hours agorootparentIt is exactly like that on the Nokia Internet tablets. Speaker protection is literally the role of xprot, which is integrated into pulseaudio -- \"necessary to prevent the speakers from blowing out\". It even depends on things like the ambient temperature. reply TimTheTinker 14 hours agorootparentI wasn&#x27;t aware of that - thanks for the info! reply nicolaslem 20 hours agorootparentprev [–] I have been using impulse responses on Linux via EasyEffects for a while now. This is not new to Linux. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Asahi Linux project is working on developing speaker support for the Asahi Fedora Remix, starting with the M1 MacBook Air 13\".",
      "Current implementation has limitations and bugs, including power consumption issues and distortion at high volumes.",
      "The project aims to provide balanced sound with features like \"fake bass\" processing and equal-loudness volume compensation, and also has an open-source \"smart amp\" implementation for safety support."
    ],
    "commentSummary": [
      "The Asahi Linux project has added advanced speaker DSP to Linux, improving sound quality and volume in small speakers without causing damage.",
      "Linux has historically had lower audio performance compared to other operating systems, but this advancement helps to bridge the gap.",
      "Asahi Linux is working on hardware integration challenges and developing an open-source speaker driver protection system to enhance the audio experience on Linux laptops."
    ],
    "points": 261,
    "commentCount": 142,
    "retryCount": 0,
    "time": 1699791601
  },
  {
    "id": 38241583,
    "title": "Design flaw blamed for SanDisk Extreme Pro failures, according to research",
    "originLink": "https://www.tomshardware.com/news/sandisk-extreme-pro-failures-are-due-to-design-flaw",
    "originBody": "PC Components Storage SSDs SanDisk Extreme Pro Failures Result From Design and Manufacturing Flaws, Says Data Recovery Firm News By Anton Shilov published 12 November 2023 It doesn't look like a firmware fix will be enough. Comments (9) (Image credit: Attingo) A new report from a data recovery company now points the finger at design and manufacturing flaws as the underlying issue with the recent flood of SanDisk Extreme Pro failures that eventually spurred a class action lawsuit. It became clear in May that some of Western Digital's SanDisk Extreme Pro 4TB SSDs suffered from sudden data loss; at this point, the company promised a firmware update to owners of the 4TB models. However, the 2TB and 3TB models also suffer from the same issue, and Western Digital did not promise any firmware updates for these drives. Markus Häfele, Managing Director of Attingo, a data recovery company, told FutureZone that the problem lies in hardware, not firmware, which could explain the lack of corrective firmware updates for those models and SanDisk's continued silence about the source of the issues. A Hardware Problem (Image credit: Attingo) Attingo, which has been in the data recovery business for over 25 years, normally sees these failed SanDisk Extreme Pro SSDs at least once a week. The problem appears to be rather complex. According to Häfele, the components used in these SSDs are too big for the circuit board, causing weak connections (i.e., high impendence and high temperatures) and making them prone to breaking. He also says that the soldering material used to attach these components is prone to forming bubbles and breaking easily. It remains unknown whether the cause is cheap solder, the componentry, or both contribute to the issues observed. However, newer revisions of these SanDisk Extreme Pro SSDs seem to have been modified with extra epoxy resin to secure the oversized components. This suggests that Western Digital might know about the hardware problems. Nevertheless, these newer models are still failing, thus sending data recovery service customers to firms like Attingo. According to the head of Attingo, the issue seems to be affecting multiple product lineups, including both SanDisk Extreme Portable SSD as well as the SanDisk Extreme Pro Portable SSD. A Strange Attitude? Western Digital's handling of this situation, especially in communicating with customers and the media, can easily be criticized. Our colleagues from The Verge first reported back on August 8 that Western Digital's SanDisk Extreme 3TB SSDs can suddenly lose data, requiring expensive data recovery services to recoup precious files — if you're lucky. As it turns out, one of The Verge's editors lost a video stored on one of these drives and, after a quick investigation, discovered that he is far from alone with this problem. He noted that people continued losing data on 2TB SSDs after May, which is when Western Digital promised a firmware update for the 4TB drives. To follow up on its investigation, the Verge quizzed Western Digital about the recurring issue with its Extreme Pro SSDs but did not receive a response as of August 19, 2023. The website asked WD why storage that could potentially lose data was suddenly on sale at several retailers and whether the company planned to offer free data recovery services to its customers. The editors also questioned whether Western Digital proactively warned users about the possible issue. NAND memory-based drives can lose data due to multiple factors. Sometimes, the flash drive itself might have manufacturing defects that can cause data loss. This is more common with low-quality or counterfeit drives, but this is certainly not the case with the SanDisk Extreme Pro products bought from prominent retailers like Amazon. Worse yet, these external SSDs are aimed at professionals. While one of the issues is that some of Western Digital's SanDisk Extreme Pro suddenly lose data, another is that the company hasn't communicated well about the problems. We have contacted Western Digital once again for comment and await a response. Stay on the Cutting Edge Join the experts who read Tom's Hardware for the inside track on enthusiast PC tech news — and have for over 25 years. We'll send breaking news and in-depth reviews of CPUs, GPUs, AI, maker hardware and more straight to your inbox. Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. Anton Shilov Freelance News Writer Anton Shilov is a Freelance News Writer at Tom’s Hardware US. Over the past couple of decades, he has covered everything from CPUs and GPUs to supercomputers and from modern process technologies and latest fab tools to high-tech industry trends. SEE MORE SSDS NEWS MORE ABOUT SSDS Nextorage 2TB G Series SSD Just $97 at Newegg Xiaomi Reportedly Using China-Based YMTC's 232-Layer 3D NAND Memory LATEST Rode PodMic USB Review: Increased Connectivity, Higher Price SEE MORE LATEST ► SEE ALL COMMENTS (9) 9 Comments Comment from the forums endocine \"the resistors used in these SSDs are too big for the circuit board\" What does that mean, are the solder pads too small for the component, or ... something else? how can anything be too big for the board its soldered onto? Reply punkncat SanDisk having failure(s), unheard of..... ;) I am astounded they still can sell things under that moniker. Reply digitalgriffin Sandisk: here's a $5 rebate off your next drive purchase from us. Lawyers: $$$$ Reply USAFRet SanDisk: \"Even though your dead SSD is past the 3 year warranty, we're giving you a new, better one, for free.\" (me, Dec 2018) Reply SeaTech Something else that is interesting...apparently Western Digital intends to split/spin-off their Flash and HDD business after a merger plan with Kioxia fell through. Feels a bit odd really...depending on the news article you can get a rather different feel about this split..one is 'oh the flash business is not making money and there is too much supply on the market, let's get rid of it' while the other narrative has been \"the HDD segment is a legacy business that does not mesh well with flash technologies, better to separate things out'. One thing is for certain: if the split does happen as reported there may no longer be WD branded SSDs/ M.2 drives...as they plan to have the HDD business keep the name...no name is yet specified for the flash business. Why seagate has made things work while WD's business has struggled is a bit mystifying. WD's non-sanDisk M.2/SSD drives seem to be performing well....shame to see that spun-off. I guess Seagate will be the competition winner by default...after so many years...it was akin to the Nvidia vs AMD struggle and now...perhaps no more. Reply TwoSpoons100 endocine said: \"the resistors used in these SSDs are too big for the circuit board\" What does that mean, are the solder pads too small for the component, or ... something else? how can anything be too big for the board its soldered onto? There are a number of failure modes for SMT parts, especially the larger ones which are of subject to higher mechanical stress. Those pads look like IPC minimum size, probably so they could cram everything into a smaller space. Doesn't help with reliability. The part may also be suffering from thermal shadowing, being so close to other parts. Or it could simply be the soldering temperature profile isn't quite right. I've not heard of 'Bad Solder' myself, only 'Bad Soldering'. And although solder paste does have a limited shelf life, the fab houses building these boards will being going through tonnes of the stuff, so they are always buying in fresh. Reply ekio Outch. With the price they cost, being cheap about the design and manufacture is unforgivable. No Sandisk product for me anymore then. Reply 3ogdy Design flaw, yeah. I beat the drum about how bad SanDisk products are for a while around here. Not just SSDs, but other flash storage devices as well. They become read - only and then die. They have great pricing but the quality isn't there. You get what you pay for, I suppose. They're simply not worth the hassle of losing data. My 128 GB Samsung SSD 830 still works to this day. Unbelievable. Reply plateLunch SeaTech said: Something else that is interesting...apparently Western Digital intends to split/spin-off their Flash and HDD business after a merger plan with Kioxia fell through. Feels a bit odd really...depending on the news article you can get a rather different feel about this split.. Split is being pushed by an \"activist investor\". In other words, a money grubbing MBA who doesn't really care about product quality or customers. Flash is considered a fast growing business. Activist investors like that. Fast growing businesses command high stock price multiples, creating money for investors. The HDD business is not growing. Maybe it can make a profit but it does not have the flashy growth that activist investors like. Maybe related note... Western Digital's CEO came in as the lowest rated CEO as rated by employees in an Oct 14 article here on Tom's. Hmmm. When I saw that article, I was wondering if they suffer from quality problems with all the unhappy employees. And then this article comes out. Will probably take WD off my approved vendor list. Reply VIEW ALL 9 COMMENTS Show more comments MOST POPULAR Single-Slot GeForce RTX 4060 Ti Comes With Blower Design By Anton ShilovNovember 11, 2023 Fastest 3D Printers Benchmarked: Top Printers Ranked By Output Time By Denise BertacchiNovember 11, 2023 No, Nvidia Isn't Breaking GPU Sanctions Against China, Says Analyst By Anton ShilovNovember 11, 2023 MSI Shrinks Nvidia's GeForce RTX 4060 GPU By Aaron KlotzNovember 11, 2023 Intel Arrow Lake, Lunar Lake CPU Support Added To Linux Turbostat App By Matthew ConnatserNovember 11, 2023 Cooler Master Preps 1100W Passive Power Supply By Mark TysonNovember 11, 2023 The First Ryzen 7000 Zen 4 Linux Laptop Arrives On The Market By Matthew ConnatserNovember 11, 2023 Core i9-14900HX Shows Minor Improvement Over Core i9-13900HX By Matthew ConnatserNovember 11, 2023 Nvidia RTX 4090 Skateboard Touted as Gnarliest Status Symbol By Mark TysonNovember 11, 2023 One Hundred RTX 4090s With Melted Power Connectors Repaired Every Month, Says Technician By Anton ShilovNovember 11, 2023 New Synthetic Superatomic Material is \"World's Best Semiconductor\" By Francisco PiresNovember 11, 2023",
    "commentLink": "https://news.ycombinator.com/item?id=38241583",
    "commentBody": "SanDisk Extreme Pro failures result from design flaw, says researcherHacker NewspastloginSanDisk Extreme Pro failures result from design flaw, says researcher (tomshardware.com) 255 points by dangle1 18 hours ago| hidepastfavorite149 comments deepsquirrelnet 11 hours agoparentI used to work in manufacturing test for an SSD supplier. This would normally be covered by an “ongoing reliability test” in quality. But I also witnessed that quality can be a highly politicized arm of manufacturing companies, and finding issues with products is not always well received, while approving products is always well received.In many consumer products, tests like that are often not implemented or curtailed compared to OEM products. When you buy from a company like Dell or Apple, you get the benefit of having a large organization providing accountability. In other words, when a company like Dell represents their interests in receiving quality products to uphold their reputation, they also have a shared interest with the end consumer — but carry a lot more weight since they represent large contracts with the supplier. Suppliers tend to put more effort into testing their OEM products so as not to damage their business relationships.Anyway, this kind of thing happens all the time in consumer storage. Likely nobody was doing reliability testing on these drives in the first place since that costs money and can only expose problems they didn’t really want to know about. reply Scoundreller 4 hours agoparentIt&#x27;s funny because retail-boxed Intel CPUs used to overclock better, at least in the Celeron 300A days. reply jonny_eh 3 hours agorootparentExcept that a non-overclockable CPU isn&#x27;t a lower quality one. In fact, they may be sold cheaper to the OEM because they are less likely to be overclockable. reply Scoundreller 1 hour agorootparent> non-overclockable CPU isn&#x27;t a lower quality oneGenerally, it did mean this. If we are to believe that Intel largely made the same CPU, and \"binned\" their processors into different speeds based on what they were stable at. And locked their multipliers to speeds that they&#x27;ll be reliable at (lower quality = lower multiplier). But one could still set the bus speed to whatever they liked, and the retail boxed chips handled this better.There would also be a market demand factor to it. If they got a large order for 266MHz chips, they&#x27;d lock them at the multipler for that, even if they could handle 300 or 333 MHz.(Part of the rumour for some Celeron chips was that they were the same die but a fraction of the cache, so \"Pentium\" chips produced with a cache defect could have that section locked out and labelled a Celeron)Nowadays, CPUs can often throttle themselves, so this binning wasn&#x27;t as necessary to mitigate batch to batch variation. reply KennyBlanken 11 hours agoparentprevIn a perfect world this would be true, especially at the large business level where the integrator will get their ass sued by the customer or at least be forced to make good on the situation.In the retail and small&#x2F;medium business market the reality is that Dell, HP, and the like are under so much pressure to cut margins that they&#x27;ll go with whoever is cheapest, and customers almost never escalate things to tort.Dell PC power supplies are made for them by someone else, proprietary in size and connector, and gosh, wouldn&#x27;t you know it - they have a pretty high failure rate. They last just long enough to make it out of the warranty period, and then they make for a really nice revenue stream for Dell via replacement PSUs or pushing the customer to buy a new system entirely.Even failure within the warranty period is acceptable in the consumer market because integrators have it down to a science exhausting people on the customer support side. Long phone queue times, incompetent support agents who have to transfer you to different agents and likely drop the call entirely, silly policies like requiring a reformat&#x2F;OS reinstall for everything, and so on. reply aurareturn 8 hours agorootparent>Even failure within the warranty period is acceptable in the consumer market because integrators have it down to a science exhausting people on the customer support side. Long phone queue times, incompetent support agents who have to transfer you to different agents and likely drop the call entirely, silly policies like requiring a reformat&#x2F;OS reinstall for everything, and so on.This is one reason why I believe Apple computers last much longer than Windows computers. With Apple, they only sell a few models in high volume. So if there&#x27;s an issue, everyone will know about it and Apple will often have to do a mass recall or provide free repairs. And since Apple prices are higher, you&#x27;d assume that they use better-grade parts on average. reply the_jeremy 4 hours agorootparent> So if there&#x27;s an issue, everyone will know about it and Apple will often have to do a mass recall or provide free repairs.I wouldn&#x27;t say Apple is any better than anyone else - aging iPhone batteries and butterfly keyboards both had a class action lawsuit settlement, it wasn&#x27;t out of good PR that these got addressed. I suppose you are right that everyone will know about them, though, given that those were from memory. reply aurareturn 4 hours agorootparent>I wouldn&#x27;t say Apple is any better than anyone else - aging iPhone batteries and butterfly keyboards both had a class action lawsuit settlement, it wasn&#x27;t out of good PR that these got addressed. I suppose you are right that everyone will know about them, though, given that those were from memory.That&#x27;s the point. If 5% of PSUs failed inside a Dell computer just outside of warranty, no one would care except those affected. If the same thing happened on a Mac, you&#x27;d get a media storm and a class-action lawsuit and Apple will eventually settle by giving out repairs - even if the failure happened outside of warranty.I did get a free battery replacement for my iPhone 6S. reply fyokdrigd 5 hours agorootparentprevi only had apple devices fail in my hands. all with video memory corruption. never had a hardware failure when the company used Lenovo (ibm era) reply deepsquirrelnet 10 hours agorootparentprevBuying from an OEM certainly doesn’t come with any guarantees. It’s a price&#x2F;quality contract in almost all cases though. The OEM defines an acceptable defectivity rate in their contract (even if allowed DPM if high). This effectively establishes a requirement at the supplier to ensure they will meet it.For consumer products, you can assume that this added requirement doesn’t exist.Edit: as another example, it’s well known among hardware suppliers that being a supplier to Apple can be a double edged sword for this reason. They have very high quality expectations and they squeeze extremely hard on price. But for that, they bring high volumes. If your company doesn’t have their stuff together, they can easily get raked over the coals in Apple contracts. reply bayindirh 10 hours agorootparentprev> ...Dell, HP, and the like are under so much pressure to cut margins that they&#x27;ll go with whoever is cheapest, and customers almost never escalate things to tort.Can confirm. Have an office supplied HP business desktop. One day noticed that my system is slower than normal. After 5 minutes with smartctl, I found out that the SSD was constantly throttling down SATA link (SATA downshift), was not reading or writing more than ~250 MBps, and had some wonky latency issues.Got a new SSD, moved the drive with dd, and all my problems are solved. Previous drive was by Samsung, but it was a \"value\" drive which even Google knew nothing about. It was probably built with bottom of the barrel parts, and something went bad earlier than expected. reply bogantech 15 hours agoparentprev> On the one hand, the resistors used in these SSDs are too big for the circuit board, causing weak connectionsI am an electronics &#x2F; PCB hobbyist and I can&#x27;t for the life of me figure out how they came to such a weird conclusion. What does this even mean?Larger components will have more surface area at the joint and should be stronger than a smaller component> On the other hand, the soldering material used to attach these resistors is prone to forming bubbles and breaking easily, according to Häfele.Never heard of solder doing this - it seems more likely to me that the solder wasn&#x27;t reflowed properly in manufacturing.What&#x27;s more is that the component pictured is a capacitor.The only conclusion I can draw here is that the guy has no clue what he&#x27;s talking about reply bunnie 14 hours agoparentHard to tell from appearance only but my initial impression is that&#x27;s an inductor, not a capacitor. The circuit looks like a switching power regulator. The capacitors would be beige with silver ends, this one looks like an over molded inductor, similar to [1], and is used as the main power inductor in a buck regulator.If this is an inductor, my gut reaction is it has an insufficient current rating for the application and it is overheating. Inductors have a bunch of loss mechanisms that contribute to heating. Depending on the type of metal used to build the core, it can &#x27;hard saturate&#x27; and effectively walk itself off a cliff once the current draw gets too high. At some point, it gets hot enough to desolder itself from the circuit board. It&#x27;s possible they did not see this in validation because the power draw of SSDs depend heavily on the work load and process variations in the chips; erase current can have a fairly wide variation.fwiw, voiding of solder joints is a problem. The solder is applied as a paste - fine particles of metal solder suspended in solder flux. During reflow the flux evaporates and leaves the metal behind, but if the process isn&#x27;t tuned right bubbles of gas can be trapped in the joint. This can lead to reliability problems. It can also increase the effective thermal resistance to the circuit board, which for tiny components like this can often be the primary path for heat removal during normal operation.[1] https:&#x2F;&#x2F;www.digikey.com&#x2F;en&#x2F;products&#x2F;detail&#x2F;pulse-electronics... reply Scoundreller 11 hours agorootparentThe article says:> the problem lies in hardware, not firmware, which could explain the lack of corrective firmware updates for those models and SanDisk&#x27;s continued silence about the source of the issues.But I&#x27;d guess a firmware update that slowed down the erase process could let it cool down. But the performance hit.Are they not using charge pumps and these are some of the first SSDs upgraded to on-board inductored boost convertors?These messes could be solved if system power supplies had a 20V rail instead of requiring tiny devices to make it. Maybe an integrated manufacturer (hi apple) will spec out proprietary SSDs like this one day.Charge pumps are cheap and small, but not as efficient (ie: HEAT!):> By using the boost converter with the optimized inductor, the energy during write-operation of the proposed 1.8-V 3D-SSD is decreased by 68% compared with the conventional 3.3-V 3D-SSD with the charge pump.https:&#x2F;&#x2F;dl.acm.org&#x2F;doi&#x2F;10.1145&#x2F;1594233.15942532023 paper:> One of the main causes is the on-die charge pump circuit, which has a low conversion efficiency and induces high heat generation.> Using the in package boost converter, we show that the power consumption can be reduced by up to 39% while the temperature rise can be reduced by 50%.https:&#x2F;&#x2F;ieeexplore.ieee.org&#x2F;document&#x2F;10145971 reply dotancohen 7 hours agorootparentnext [–]> These messes could be solved if system power supplies had a 20V rail instead of requiring tiny devices to make it. Maybe an integrated manufacturer (hi apple) will spec out proprietary SSDs like this one day.Then you&#x27;ll get people (like me) who will deride Apple for requiring a proprietary component where COTS components are available, calling it an anti-consumer move. reply Scoundreller 5 hours agorootparentme too, but we&#x27;re talking about a few extra minutes of battery life here. That&#x27;s catnip to cat people. reply jona-f 3 hours agorootparentOh, if it were also smaller and lighter, we&#x27;d be in heaven. If it weren&#x27;t for the proprietary devil lurking in the corner, showing us a fake heaven while having us in chains, sucking the life of our dreams. reply 3seashells 4 hours agorootparentprevNo vacumoven? reply onetimeuse92304 14 hours agoparentprevI am electronics &#x2F; PCB hobbyist and I can definitely see how their explanation can be true. I can&#x27;t say it is, but I can see how it could be.If you design a PCB for a given size of the resistor but then decide to use larger resistors without redesigning the pads, you may have reflow problems and weak joints. This is simply due to the fact, that the components are positioned due to surface tension during reflow process (they are pulled into place as the solder melts). If the pads are for smaller components, there will be too little solder for larger surface and weight of the component and working at a wrong angle to pull it into place causing potentially higher rate of failure.> What&#x27;s more is that the component pictured is a capacitor.And that means what? From the picture I can tell that there is very little solder between component and the pad. Potentially too little to hold the component well in place.> The only conclusion I can draw here is that the guy has no clue what he&#x27;s talking aboutMaybe he does, maybe he doesn&#x27;t. Have you considered a possibility you are not an expert either? reply eaasen 9 hours agorootparentAs someone who designs circuit boards professionally, the explanation is clearly lacking. There might be a thermal issue or there might not be. There is nothing conclusive in the pictures either way. What I do see is the following:1. Underfill (the brownish-tan smooth material surrounding the components towards the bottom of the picture) around the IC, which is typically done to make parts more mechanically robust.2. No evidence of overheating on any of the thermal interface material that is left stuck to most of the components and no evidence of overheating on the PCB or the components themselves.3. Completely insufficient evidence to declare a soldering issue. The way to prove this one way or another is x-ray inspection to look for voids in the solder or a mechanical cross-section of the suspect solder joints.While this certainly could actually be the problem, I see insufficient evidence to conclude one way or another. Manufacturers don’t put underfill under a part unless it’s required through testing or experience with similar package types in prior designs since it adds cost, additional process steps and makes it a PITA or impossible to rework any bad components in the area.As to the pad size&#x2F;shape, there are three general classes of design defined by the IPC (standards body that deals with PCBs and PCB assemblies). Depending on how space constrained your design is, there are different recommended pad designs for passive components like these. They might be using one of the tighter spacing guidelines, but if their process is well controlled, it can be perfectly fine for the design life of the product.If you want to see small pad layouts done well, look at an iPhone logic board.If you want to know more about pad design for SMT parts, search for IPC-7352 reply arcticbull 8 hours agorootparentMy totally unsubstantiated guess from the description alone was &#x27;I wonder if they switched to a larger package component and forgot to update the pads.&#x27; That could be described as the &#x27;component being too large for the device&#x27; and while it might just fit, it may be borderline mechanically and electrically stable. That could also explain the added underfill. Is that possible? reply eaasen 7 hours agorootparentIt’s certainly possible someone did a BOM substitution and didn’t due diligence on it, but I doubt it. PCB assembly houses tend to notice components that are suddenly too big for their pads because they’ll have fallout in AOI or later testing.The underfill was likely added before full production as the result of reliability tests that showed some mechanical susceptibility of that IC. reply jchw 15 hours agoparentprevDoes seem a bit strange, but the original article[1] in German, translated using Google Translate, reads as follows:> “It&#x27;s definitely a hardware problem. It is a design and construction weakness . The entire soldering process of the SSD is a problem,” says Häfele. A hard drive has components that need to be soldered to the circuit board. “The soldering material used, i.e. the solder, creates bubbles and therefore breaks more easily.”> “In addition, the components used are far too large for the layout intended on the board,” says Häfele, explaining the technical problems: “As a result, the components are a little higher than the board and the contact with the intended pads is weaker. All it takes is a little something for solder joints to suddenly break.”It sounds like what they&#x27;re saying is that the solder pads are too small for some of the components. Not sure about what they&#x27;re saying about the solder though.[1]: https:&#x2F;&#x2F;futurezone.at&#x2F;produkte&#x2F;sandisk-ssd-ausfaelle-western... reply exmadscientist 15 hours agorootparent> Not sure about what they&#x27;re saying about the solder though.There&#x27;s more than one solder alloy in use. There&#x27;s more than one class of solder alloy in use. Some are easier to use, some are harder to use. Some are high-performance, low-tolerance, some are low-performance, high-tolerance. Some are expensive, some are cheap.The most troublesome family is SnBi. These are relatively new. They have a big \"greenwashing\" problem in that they solder at lower temperatures, which is \"environmentally friendly\" (and cheaper to run). Also the base metal is dirt cheap. (Wonder why manufacturers are interested?) It&#x27;s also very, very brittle. It also happens to be a low-temperature alloy... so it&#x27;s much easier to get hot enough to desolder during operation. Lots of trouble all around and in general a very high field failure rate. Not recommended... oh wait but it&#x27;s cheap and greenwashable. Sigh. reply qiqitori 9 hours agorootparentAre there places that use SnBi for production devices? I know Bismuth alloys are used to desolder stuff (and they work amazingly well for that), but the general rule is that you should clean it up before soldering something new. (And keep it for later use, because it isn&#x27;t exactly cheap.)It&#x27;s a heavy metal and reading https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Bismuth#Toxicology_and_ecotoxi... it looks like we don&#x27;t know a lot about it yet, but to me it looks extremely unlikely to be better for the environment than SnAgCu.Also Bismuth appears to be rare: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Abundances_of_the_elements_(da... Rarer than palladium. All the even rarer elements are generally known to be rare and&#x2F;or precious, or radioactive elements that normal people would never come across. reply exmadscientist 7 hours agorootparentLenovo had a lot of press releases about switching over. I don&#x27;t know to what extent they actually did it.I agree it&#x27;s probably not any better for the environment, but you know how the PR cycle goes. reply userbinator 9 hours agorootparentprevI won&#x27;t ever forget the widespread BGA failures caused by the RoHS-forced switch to lead-free solder. No doubt massive amounts of additional ewaste were created, but at least it&#x27;s \"environmentally friendly\" ewaste?Military&#x2F;aerospace are still exempt and continue to use leaded solder. reply qiqitori 8 hours agorootparentI don&#x27;t want to pick a fight, but here&#x27;s my rando opinion on that:Almost all electronic devices end up as e-waste after a few years. If a couple % fail prematurely, that doesn&#x27;t create a massive amount of additional ewaste, but rather a _very_ slight increase in e-waste. And it&#x27;s relatively benign e-waste. You could shred the board and sprinkle it over your field and it wouldn&#x27;t be a huge problem (* don&#x27;t take my word on this; there&#x27;s flux residue and somewhat toxic stuff used in other components, the plastics will probably leak BPA and other stuff, etc.) reply imtringued 38 minutes agorootparentprevIf you are talking about Nvidia&#x27;s flip chip problems. Those were actually caused by the glue holding the chip onto the substrate, not the solder. The glue expanded at a different rate from the solder balls and caused them to crack.This was especially the case on consoles. People kept reballing and doing other useless repairs that solved the problem by accident by melting the solder balls between the substrate and the silicon chip. Some even managed to remelt the solder balls simply by replacing capacitors, which then made everyone think the capacitors were the problem and everyone swallowed it because replacement capacitors were cheap. reply jeffbee 15 hours agorootparentprev> It sounds like what they&#x27;re saying is that the solder pads are too small for some of the componentsThe converse is also possible. Instead of being a design flaw with the pads too small for the component, it could be that a larger component was substituted during manufacturing. Even terrible freeware EDA packages have design rules that will flag improper solder pad layouts, so it seems like what might have happened is the physical part does not resemble its model. reply exmadscientist 15 hours agorootparent> Even terrible freeware EDA packages have design rules that will flag improper solder pad layoutsNo, they don&#x27;t. EDA software doesn&#x27;t really know what size the terminations are. It knows how big the pad itself is, and is very good at keeping those out of trouble, but it doesn&#x27;t know what size the solderable area is. You might tell it, or give it a 3D model, but make a mistake there and you&#x27;re right back here. As well, there are so many different kinds of terminations (pop quiz: what kind are these?) that even if it does know what size they are, it doesn&#x27;t necessarily know what size or shape the pad should be.Also the CM will totally edit this stuff and not tell you. Which they&#x27;re not supposed to do, and are probably better at if you&#x27;re a huge customer, but they still do it. EDA sure doesn&#x27;t know about that. replynurple 15 hours agoparentprevIf the correct amount of pad is not exposed at the edge of the part, the solder will have nowhere to form a fillet which is critical to its physical attachment. Solder is not glue, and even with more pad contact beneath this is a physically weaker connection which often results in tombstones like pictured in TFA.If you read the integration documents for these packages, you&#x27;ll see that they distinctly specify the requirements for these margins. Probably the length is the more important axis and may be what he was referring to when saying \"large\". I&#x27;ve seen this be a problem particularly during the \"chip shortage\" where jellybean parts like these capacitors have the weakest specs in a design, meaning unilateral substitutions can happen at many points in the design&#x2F;mfg pipeline.Indeed brittle solder is a real phenomenon which is often easily visible in hand soldered joints that we call \"cold\" joints. Formation of bubbles can happen for a number of reasons, but IME it&#x27;s the result of low quality solder or flux&#x2F;cleaning. The organic compounds gasify in the heat and form an internal structure similar to bread.ETA: an interesting paper exploring the cause and minimization of voiding in the reflow process. Particularly, the decrease in thermal conductivity in voided solder can critically contribute to its failure in high-heat operational environments.https:&#x2F;&#x2F;www.circuitinsight.com&#x2F;pdf&#x2F;controlling_voiding_mecha... reply exmadscientist 15 hours agoparentprev> Larger components will have more surface area at the joint and should be stronger than a smaller componentLarger components are also, well, larger, and have much bigger forces on them. For ceramic capacitors you need to avoid shearing and torquing as the body of the capacitor is very brittle and a small crack means a dead part, possibly dead short. Big ceramics are dangerous to use as they have a high failure rate. I personally won&#x27;t use anything larger than a 1210. Some of my colleagues think I&#x27;m nuts and should stop at 0805, but I think the flexible terminations available these days make 1210 viable. At least in medium volumes, I don&#x27;t ship SSDs!> I can&#x27;t for the life of me figure out how they came to such a weird conclusionWhat I see when I look at this is they have a part with a 5-sided termination (typical MLCC capacitor with metallized cap) but they have a footprint that only gets fillets on 1 of those 5 sides (typical would be 3). This is common for resistors... but resistors (a) have only 3-sided terminations anyway and (b) are made of robust alumina bodies, not fragile ceramics. So someone either got dumb with the footprint library or more likely overly aggressive to pack things in, not appreciating what MLCCs really need to be happy. I don&#x27;t think it&#x27;s part size changes, because the fillets along the length dimension that are visible look about right in size. reply negative_zero 5 hours agoparentprevThis is something that is in my area of expertise, and your suspicions are correct.Solder can \"bubble\" but this is a line process issue that is easily picked up even in old AOI systems (automatic optical inspections) from 10-15 years ago.To be frank, this article to me, reads like piece put together by somebody who has no idea what they&#x27;re on about to generate publicity for their company. Nothing to see here. reply Taniwha 7 hours agoparentprevIt looks to me like some glued on covering has been removed here, which in turn could have pulled the components off (could still be weak solder joints) rather than it being a manufacturing problem - the components don&#x27;t look too big for the pads to meMost modern manufacturing lines have manual and automatic (vision system) inspections that would detect badly soldered or toombstoned components like the ones shown here. reply bravo22 15 hours agoparentprevThe most charitable way I can read their statement is that the resistors are too large for the pad, and along with poor solder material it forms a weak joint which breaks over time.I have a hard time accepting that because there is not a lot of heat on that line nor is there a lot of physical stress, like constant vibration on SSDs. reply nrp 8 hours agorootparentThese SSDs are tiny. The controllers can easily get up to 80C during sustained writes, so there could be mechanical stress from thermal cycling. (Source: we also make small USB-interfaced high-speed storage devices and do a range of reliability testing for stuff like this) reply RantyDave 9 hours agoparentprevBut there was something in the article about epoxy - so potentially the components are glued down with a conductive epoxy instead of being actually soldered. Why you do this? Don&#x27;t know. But it would explain why the solder is losing the plot. reply sheepshear 14 hours agoparentprev> What does this even mean?It means you should click through to look at the pictures in the original article. reply londons_explore 14 hours agoparentprevIt reads to me more like the journalist writing the article summarized a technical report badly. reply bastard_op 16 hours agoparentprevI stopped buying WD anything early 2010&#x27;s, but then they acquired everyone else like Seagate, meaning even decent Hitachi disks would be now tainted to become typical WD garbage. I still won&#x27;t buy anything WD, but alternatives are hardly attractive with the market limited to like 3-4 players.Good old monopolies in effect, your options are bad or worse. reply bayindirh 12 hours agoparentIf Backblaze yearly disk stats and my personal experience in our datacenter is anything of importance, WD is generally the more reliable disk brand for the last decade or so.I remember an era where Seagate Constellation (enterprise disks) were so bad, I was replacing them a dozen per week.Also, from my experience SanDisk didn&#x27;t get tainted by WD acquisition. Their Extreme Pro SDs still as reliable as before, and their portable SSDs hit the speeds and reliability they advertise.Every manufacturer makes a design error almost once a decade. Seagate did it, Maxtor did it, WD did it before (their drives were very finicky), however all big producers are in good shape now, from my experience. I can equally trust a Seagate IronWolf Pro or its WD equivalent, or a Samsung SSD and its SanDisk equivalent.Problems happen, PCBs got revised, things got recalled. Everything is new, but nothing has changed. reply justinclift 11 hours agorootparent> Their Extreme Pro SDs still as reliable as beforeTry this: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38244389 reply bayindirh 11 hours agorootparentThese are SSDs. I&#x27;m talking about SD cards, which I just downloaded my photos from my camera while writing this comment. reply justinclift 10 hours agorootparentOops sorry. Completely missed that. o_O reply bayindirh 10 hours agorootparentNo problems, things happen. To err is human.Have a nice day.:) replyAussieWog93 13 hours agoparentprevIt&#x27;s funny you say that. I always thought WD were the more reliable brand, and Seagate were trash.I wonder if it&#x27;s just a case of each of us having one HDD of a particular brand fail on us violently, and then finding others who were in the same boat. reply tharkun__ 13 hours agorootparentPronounce this in German: \"Sea gate oder sea gate nicht\" (\"Sie geht oder Sie geht nicht\"). Meaning \"she works or she does not work\" is a German word play on early failure rates for Seagate drives.Coined when there was a time where if you didn&#x27;t have Seagate drives in a RAID you were more likely to loose your data than not ;)And yeah I started buying WD at that point. Backblaze stats weren&#x27;t a thing back then tho. reply themagician 12 hours agorootparentprev> I wonder if it&#x27;s just a case of each of us having one HDD of a particular brand fail on us violently, and then finding others who were in the same boat.That is absolutely the case and anyone with enough experience could confirm it. Both WD and Seagate have made some real trash drives, and both made at least one or two models that were trash at scale. If you timed it just right you could jump from one to another and experience massive failures with both! You also probably have a drive from each that&#x27;s been running for 20 years somehow. reply EricE 6 hours agorootparentAlmost makes me pine for good &#x27;ol Miniscribe ;) reply icehawk 14 hours agoparentprevI take it you mean \"like Seagate [acquired everyone else]\" because Seagate, Western Digital, and Micron are all competitors. reply asmor 14 hours agorootparentAnd don&#x27;t forget Hynix. They somewhat recently got into the B2C business, and while they command a premium, the SSDs both OEM and Retail I use from them have been very solid.There&#x27;s also Samsung. reply fomine3 8 hours agorootparentDon&#x27;t forget the last (or first) player, Kioxia. Their drive is often installed on sold devices rather than a DIY parts. reply vanderZwan 15 hours agoparentprevI hadn&#x27;t heard about the Seagate acquisition, that sucks. So what are my options now if I want a reliable external hard drive for example? reply justinclift 14 hours agorootparentJust to be clear, WD has not acquired Seagate. They&#x27;re still two different, competing, companies.The above post probably typo-d \"Seagate\" while meaning \"SanDisk\". reply autoexec 13 hours agorootparentI wondered if he was confusing the drama that happened with Seagate buying up Maxtor. A lot of people were upset when that happened because they trusted Seagate a lot more than Maxtor or Western Digital and suddenly the same shitty Maxtor drives many went out of their way to avoid were being sold under the Seagate name leaving people stuck with either buying WD or buying Seagate and probably getting Maxtor anyway. Seagate&#x27;s quality and reputation took a huge hit. reply coldtea 12 hours agorootparentOr with this April Fools:https:&#x2F;&#x2F;www.storagenewsletter.com&#x2F;2014&#x2F;04&#x2F;01&#x2F;seagate-acquire.... reply qwytw 12 hours agorootparentprev> WD has not acquired SeagateHasn&#x27;t it?https:&#x2F;&#x2F;www.westerndigital.com&#x2F;brand&#x2F;sandisk reply beebeepka 12 hours agorootparentReading comprehension. SanDisk is not Seagate reply rft 14 hours agorootparentprevFor external drives, I would seriously consider using SSDs. Unless you use them exclusively as cold backups and handle them carefully and seldom, I would be far too worried about accidental drops. I have killed some external HDDs this way, never killed an SSD, even though I am far rougher with them. For extra reliability, buy two disks from different manufacturers (e.g. Sandisk&#x2F;WD and Samsung) at different times and mirror the contents. Less chance of both disks going bad at the same time.Talking about 3.5\" HDDs, sourced from external drives: WD is still ok in my book. Both the Backblaze report [1] (newest, quarterly version, check the drive hours, WDC has less than HGST so far) and my own experience show they are ok. I used to buy HGST based on Backblaze&#x27;s reports, but now I am using WD external drives in my NAS. My oldest and most used disk (one of the parity drives) has more than 3 years power on hours with nearly 900 start&#x2F;stop cycles. It shows no signs of failure so far.I get these HDDs from external drives (called \"shucking\"), 10TB WD My Book or WD Elements Desktop. It is a bit random what you get, but between 7 HDDs (+1 currently in testing) over about 3 years, I only had one non-Helium drive that runs hotter than the other all Helium drives. No failures yet, no bit errors as well, performance is at least good enough for media storage, currently reading at about 180MB&#x2F;s sequentially.I saw one problem: USB errors with WD&#x27;s USB-SATA bridge and I even had to remove the newest disk to run the test, it would drop from the bus via USB. Might be because it is a refurbished disk or something fishy with the USB 3.0 ports on my server, so I won&#x27;t blame WD for it.[1] https:&#x2F;&#x2F;www.backblaze.com&#x2F;blog&#x2F;backblaze-drive-stats-for-q2-... reply shiroiuma 4 hours agorootparent>For external drives, I would seriously consider using SSDs.I wouldn&#x27;t. I use my external drives as offline backups, so they don&#x27;t get plugged in that often. SSDs lose their data if they aren&#x27;t powered up regularly. And of course, they&#x27;re much more expensive per TB than spinning rust. reply asddubs 14 hours agorootparentprevWhat&#x27;s wrong with the WD ones? I have a bunch of them and never had any problems replybastard_op 16 hours agoparentprevThe funny thing is since these have been getting news even months ago, there was almost immediate fire sales on all the main deal sites to sell them off. Everyone that bought them now have a waiting time bomb of a disk to use. Thanks Western Digital for your contribution to society. reply hobobaggins 15 hours agoparentCostco was selling them (still!): https:&#x2F;&#x2F;www.costco.com&#x2F;CatalogSearch?dept=All&keyword=ssdIs Costco completely unaware of these massive issues? reply bastard_op 15 hours agorootparentCostco is actually a decent org, and if anyone knew they were selling this time-bomb garbage, they would stop it, as they will warranty stuff for YEARS, just to be a somewhat decent company in a time of pirates. reply ben1040 15 hours agorootparentI own one of these disks and quit using it when the news came out, expecting I should hang onto it to get money back for a recall. Didn&#x27;t even occur to me I could just have brought it back to Costco all this time because of their extremely generous return policy. reply dryheat3 8 hours agorootparentprevNot the same series. \"Extreme Go\" is not the same product as \"Extreme Pro\". I have two of these from Costco and they have worked fine for several years. reply HankB99 13 hours agorootparentprevMaybe Costco caught up with this. I can&#x27;t find it on their web site (at least in the US.)All I see is the \"Extreme Go\" which I presume is a different product. reply bastard_op 15 hours agorootparentprevBlissful ignorance imho. reply RachelF 3 hours agoparentprevThey did warn you - they put the words \"Extreme Pro\" in the name.I guess the \"Extreme Pro\" solder reflowing skillz are required ;-) reply jiripospisil 17 hours agoparentprevSounds like Western Digital&#x27;s strategy is to play dead and wait for it to blow over. And it will most likely work. reply ipqk 12 hours agoparentThere will probably be a class action lawsuit where everyone that bought one gets a $20 coupon towards a new WD product, and the lawyers make millions. reply baz00 17 hours agoparentprevThey saw Apple get away with it and tried to do the same. reply bboygravity 16 hours agorootparentI&#x27;ve had a Fujitsu (if I remember correctly) drive many many years ago that had a hardware bug that would cause an IC on it to spontaneously flash fire and die.It was a known flaw. They got away with it too. reply RCitronsBroker 16 hours agorootparentprevno matter how bad the idea, there’s always someone waiting to turn Apple’s bad idea into a poorly implemented, even worse idea reply cvccvroomvroom 6 hours agoparentprevI&#x27;m unmoved and unsurprised. Retail parts are unreliable, cheap crap by the nature of the market created to perpetuate the fantasies of something for nothing.Coincidentally, I recently selected Max Endurance with a 15 year warranty for a noncritical application and a non-retail channel Industrial XI for something else.I&#x27;m also unsurprised there are no SLC or traditional EEPROM SD cards advertising these facts because of the race-to-the-bottom commodification of garbage by the price point obsession of users who don&#x27;t know any better. In an ideal world™, all network and computing devices would use ECC memory but no we can&#x27;t have nice things and would rather have silent corruption and bitsquatting to save a few cents.PS: C. 2001, I intentionally tried to induce errors for failure analysis purposes of industrial Maxim flash EEPROM ICs rated for 10k cell writes by using an environmental cycling chamber with heat, cold, and humidity. The damn parts wouldn&#x27;t fail beyond 2.5 orders of magnitude beyond that, and I started to question that writes weren&#x27;t happening. If I had more time, I would&#x27;ve burned it down to the ground until there were many errors to characterize it. At the end of the day, it had to be left at using turbo codes to ensure redundancy of data by cell and across chips. reply trinsic2 7 hours agoparentprevSSD&#x27;s, when the fail, they usually fail catastrophically. Use automated backup software to regularly copy data to an HDD for anything you don&#x27;t want to lose. And don&#x27;t use SSD&#x27;s for archiving, or long term backup purposes.Also I stay away from Sandisk. They have always occupied the cheap space of drives and they have always been known to cut corners for profit.Western Digital seems to be heading in that direction as well.I have had a good experience with Samsung since the beginning of SSD storage. reply zinekeller 6 hours agoparent> Western Digital seems to be heading in that direction as well.WD SSDs which are SanDisks in a trenchcoat? Or WD HDDs which are their original business? (Or maybe both?) reply trinsic2 6 hours agorootparentIt seems like both now, but their HDD&#x27;s we&#x27;re good before the switched to SMR.Now I use Seagate for my HDD drives. reply dboreham 16 hours agoparentprev\"resistors too big\" ...reply layer8 13 hours agoparentTom’s Hardware’s fault. The original source only says “components”. reply newaccount74 15 hours agoparentprevI told myself I&#x27;d never again buy a WD drive when I realised the WD Red NAS drives I bought were completely unsuitable for NAS because they secretely replaced the product line with SMR drives.And now you are telling me that the Sandisk SSD I bought as a replacement also has a fatal design flaw? And apparently Sandisk is a WD subsidiary?I&#x27;m feeling slightly less bad about spending a fortune on getting a bigger built-in SSD in my Macbook. Please don&#x27;t tell me they are flawed as well. reply Phostera 8 hours agoparentWell they do have the kill your MacBook when they fail problem. ref: rossman on YouTube. reply layer8 13 hours agoparentprevTFA is only about external drives. reply newaccount74 13 hours agorootparentYeah, I know, I replaced my NAS with external SSDs. replyToniCipriani 11 hours agoparentprevReminds me of my old Corsair Voyager. \"Rugged\" USB stick housed inside a fully rubber enclosure, which constantly causes the USB plug to snap off. Forgot how many times I had to RMA that thing. reply awiesenhofer 15 hours agoparentprevOriginal article (translated via Google):https:&#x2F;&#x2F;futurezone-at.translate.goog&#x2F;produkte&#x2F;sandisk-ssd-au... reply CodeWriter23 5 hours agoparentprevI’ll bet one of the purchasing agents found a good deal on resistors and thought they were equivalent and swapped them out. reply elzbardico 13 hours agoparentprevI always found it somewhat amusing that SanDisk is very similar to to the french Sans Disque. Like the Chevrolet No Vá situation for spanish speakers. reply whoopdedo 12 hours agoparentThat&#x27;s entirely the point as flash or SSD are alternatives to spinning platters of rust. It&#x27;s storage sans disk.The company was originally SunDisk but switched to avoid being confused with Sun Microsystems. reply elzbardico 10 hours agorootparentYeah, but when it fails (and dude, it does fail!), you are also Sans Disque. reply CTDOCodebases 12 hours agoparentprevI wonder if these drives were manufactured during the parts shortage?Kind of makes you wonder what other devices are ticking time bombs. reply lazide 10 hours agoparentMost of them, near as I can tell. Cars manufactured during that time have been having issues like crazy too. reply RDaneel0livaw 16 hours agoparentprevI&#x27;m astonished that after WD bought the SanDisk brand they kept it alive. You couldn&#x27;t pay ME to use anything under that name, it&#x27;s so negative. Maybe now with this critical failure they&#x27;ll just slowly start branding things with any of the other myriad of brand names they&#x27;ve bought \"hgst\" for instance and slowly kill the brand. reply tentacleuno 16 hours agoparentWhat&#x27;s wrong with SanDisk? Out of the loop here -- I had a SanDisk SSD around 5 years ago and it was absolutely great; it&#x27;s still going today (it&#x27;s seen quite a bit of use, too.) reply justinclift 13 hours agorootparentSanDisk used to have a good reputation, but after being acquired by WD they&#x27;ve turned to shit:* https:&#x2F;&#x2F;arstechnica.com&#x2F;gadgets&#x2F;2023&#x2F;05&#x2F;sandisk-extreme-ssds...* https:&#x2F;&#x2F;arstechnica.com&#x2F;gadgets&#x2F;2023&#x2F;08&#x2F;sandisk-extreme-ssds...* https:&#x2F;&#x2F;arstechnica.com&#x2F;gadgets&#x2F;2023&#x2F;08&#x2F;lawsuit-takes-wester...* https:&#x2F;&#x2F;arstechnica.com&#x2F;gadgets&#x2F;2023&#x2F;08&#x2F;sandisk-extreme-ssds... reply amatecha 16 hours agorootparentprevYeah, kinda no clue what the controversy is cuz I&#x27;ve never had any SanDisk drive fail. Only WD :) reply tentacleuno 15 hours agorootparentI&#x27;ve very rarely had an SSD fail in general, to be honest -- though I do generally stick to reliable brands[0], not \"Xykdidlwo\" or \"Dyewkdlo\" off Amazon.Right now I&#x27;ve got 3 SSDs in my server (2 mirrored so 1TB for apps, and a 500GB boot drive), and I&#x27;m interested to see which one goes first.[0]: Crucial, Samsung, Kingston, SanDisk (until I hear any information which discourages me) etc. reply stephen_g 15 hours agorootparentprevYes, at least in terms of their memory cards for cameras etc. I’ve really only heard them as being quite well regarded, as far as I can remember… reply somat 15 hours agoparentprevI don&#x27;t have any experience with their ssd&#x27;s but I have a few sandisk usb drives that have lasted far longer than any other brand in that hellish environment of being an os system drive. It is not really that bad but with the frequency that usb flash dies when used as a boot drive you would thing I am abusing them. The no-names I understand, junk from who knows where. but the worst offender was kingston, they are probably fine on windows as a rarely used backup unit. but as an openbsd system drive, hot garbage, I went through 6 in six months, I would expect better from a named brand. as a comparison I am still on the original sandisk units, 5 years and counting. reply lazide 13 hours agoparentprevOf the brands I’ve run across for SD cards, Sandisk has been top 3ish for quality. I’ve never had major issues at least for SD Cards?Samsung has been catching up though. reply jakobson14 10 hours agoparentprevWD bought HGST? HGST are supposed to be far and away the most reliable source of drives iir. reply whitepoplar 16 hours agoparentprevWhat brand would you trust the most, for SSDs and for SD cards? reply dharmab 16 hours agorootparentThere&#x27;s only four flash manufacturers: Samsung, Micron, SK Hynix and SanDisk&#x2F;Kioxia. All of them have had problems over the years. All of them will change the internals of products without changing SKUs or anything visible to the consumer.You best bet is:- Buy a variety of manufacturers and SKUs- Create backups regularly and test your restores reply lazide 14 hours agorootparentAlso, always run perf tests (especially using large writes - preferably up to the capacity of the drive!) for any drive that it is important &#x27;you got what you paid for&#x27;.The number of counterfeit, badly designed to the point of defective, or DOA SD Cards and SSD drives I&#x27;ve seen over the last few years is crazy.I literally won&#x27;t even buy USB sticks anymore. The last time I tried, all 5 different makes&#x2F;models I tried were so dysfunctional they were useless. Literally unfit for purpose. Major brands too! reply yjftsjthsd-h 12 hours agorootparentDid you buy in person, or in an online marketplace (ex. Amazon)? I only buy thumb drives at physical stores to try and avoid outright counterfeits. reply lazide 11 hours agorootparentBoth.A lot (all?) recent USB sticks have terrible thermal design, and will throttle seemingly arbitrarily to very low speeds under sustained load. Like 2.5MB&#x2F;s type speeds. They seem like they were made to to theoretically exist for the market niche, but no one expected them to actually be used by anyone who paid any attention at all.Same for ones bought in big box stores as Amazon or the like. Name brand or random brand.A lot of less expensive 2.5+ Gig Ethernet dongles do the same.Good performance for 5-10 seconds, then abysmal.I switched to SD cards, and at least the good brands of those had decent and predictable performance (50-75MB&#x2F;s sustained for the same price point). They were also a lot cheaper in general for the capacity. reply rasz 5 hours agorootparentprevThere is also YMTC https:&#x2F;&#x2F;goughlui.com&#x2F;2023&#x2F;10&#x2F;10&#x2F;psa-ssds-with-ymtc-flash-pro... reply ChuckMcM 12 hours agoparentprevOne of the more interesting things to me is that while every storage medium has failures (which is why RAID and backups are a thing :-) there are more failure modes with flash storage that present as abrupt storage failure. reply jbverschoor 12 hours agoparentprevThey \"assured\" me that mine won&#x27;t fail. They checked the serial numbers, and they&#x27;re not affected (3 disks).Now I&#x27;m in the dark again reply lukevp 17 hours agoparentprevWe have one of these as part of a critical video workflow. Anything we can do to mitigate it? Or do we just hope it’s not impacted &#x2F; replace it soon? reply FirmwareBurner 17 hours agoparentIf it&#x27;s a critical workflow on which your business rests, then you immediately replace it with a better model&#x2F;brand as that&#x27;s a business tax write-off. Plus you have the usual on-site and off-sie back-ups which you should already have for your business.You do have a back-up set up that you also test, right? Right?reply VHRanger 16 hours agorootparentIf it&#x27;s a video workflow it&#x27;s likely more of a working drive, backups don&#x27;t always keep up with the changes on the drive fast enough.Unless it&#x27;s part of a RAID array or something, but by that point you&#x27;d shell the money out for a better drive reply rwmj 16 hours agoparentprevThe fact you have one SSD in a critical workflow is an immediate red flag. You should have some kind of redundant solution with backups even if you didn&#x27;t suspect particular SSDs are prone to failure. reply lazide 13 hours agorootparent99% of small businesses just flat out ‘nope’ out when it comes to proper backups or redundancies though. reply ohyes 17 hours agoparentprevReplace it with a different SSD sounds like the only option. reply ikekkdcjkfke 16 hours agoparentprevI think one can enclose m2 ssd&#x27;s in usb adapters, then you just use well proven tech like samsung 970 pro, been chugging along on our build server for years now reply mgerdts 16 hours agorootparentMany of these adapters have their own quality problems which vary with the version of the controller. That version number is rarely available prior to purchase. reply asmor 14 hours agorootparentIf you have a critical application, you can afford a vendor that uses TB4 with a good reputation.Here are some options:https:&#x2F;&#x2F;www.owc.com&#x2F;solutions&#x2F;thunderbay-flex-8https:&#x2F;&#x2F;www.startech.com&#x2F;en-us&#x2F;hdd&#x2F;m2e4btb3 reply mpol 15 hours agoparentprevIf it&#x27;s critical, you should not use a cheap SSD. It is better to use a SSD for professional use, for servers.I have seen and heard too many consumer market a-brand SSDs break. reply asmor 14 hours agorootparentThe Extreme Pro lineup isn&#x27;t even considered a \"cheap SSD\", it&#x27;s their highest end offering before you dip into their G-DRIVE line of rugged SSDs. reply shocks 11 hours agoparentprevIt would probably help to describe your workflow so we can offer specific suggestions. reply jpk2f2 16 hours agoparentprevReplace it immediately, not soon. reply gjsman-1000 17 hours agoparentprevRAID and a backup strategy? There should not be a single point of failure. Just getting 2 new SSDs with a RAID 1 would be a massive improvement.And, of course, a separate backup for them because RAID is not a backup. reply lofaszvanitt 10 hours agoparentprevSomehow they forgot after 25 years of expertise what to do... plausible. reply wkat4242 17 hours agoparentprevLooks like this particular problem is easy to fix though. reply Zetobal 17 hours agoparentBy whom? Your granny who just lost all the pictures of their grandchildren? reply wkat4242 17 hours agorootparentNo but by me or anyone else who can hold a soldering iron :)It&#x27;s much much easier than a BGA cracking issue, or something internal in the flash which is basically unfixable. This is just some components tombstoning. It shouldn&#x27;t cost a lot to get it fixed (of course Sandisk should take care of that) reply dboreham 16 hours agorootparentThe article unfortunately was written by someone with no clue so we don&#x27;t know why tombstoned components (shown in the picture) were not caught in inspection&#x2F;test. They imply the failures happened in the field, but that&#x27;s not where tombstoning happens. Presumably what happened was that the supercap (looking like [1]) tombstoned in reflow. Then circuit test failed to test that it was installed so the unit was shipped. Subsequently in the field the unit suffered a sudden power loss with pending writes. Normally the supercap provides power for long enough to flush pending writes to NAND. But since it was open circuit, the power fail flush never finished, resulting in corrupted storage. Fixing the open circuit solder joint as you suggest does not remedy the problem for the user because their data is still gone.[1] https:&#x2F;&#x2F;www.digikey.com&#x2F;en&#x2F;products&#x2F;detail&#x2F;seiko-instruments... reply nurple 15 hours agorootparentOne capacitor on a tank array would definitely reduce its total capacitance, but they are nearly always in parallel and would not cause a failure of the whole tank, and the device would be inoperative if the output of the array was shorted.I&#x27;m skeptical that losing one capacitor in the array would cause the failure mode you&#x27;re describing. Especially if the age of the devices is considered, the array would have been designed with margin to withstand capacitance loss as the device ages. reply wkat4242 14 hours agorootparentPerhaps tombstoning causes it to short the whole array? I could see that happening if it&#x27;s positioned just wrong. reply lightedman 14 hours agorootparentprev\"I&#x27;m skeptical that losing one capacitor in the array would cause the failure mode you&#x27;re describing.\"Depends on what the capacitor is being used for in the circuit. In many cases, having a cap fail open results in a higher current draw which kills the unit if left in operation for too long. This is the case on some of the off-road lighting I manufacture. If one cap is present and fails open at ground, the circuit overloads. If the cap is connected to ground but not the rest of the circuit, the circuit doesn&#x27;t operate.Regardless, one component being off can cause a whole chain of maladies. reply wkat4242 15 hours agorootparentprev> but that&#x27;s not where tombstoning happensyeah I know, unless the board gets so hot it unsolders itself, which is very very doubtful (and definitely a fault of its own).I thought it was more of a stability problem though. Nothing a good backup should cover, and the device should be fine after soldering the component. reply kmbfjr 16 hours agorootparentprevBy anyone who can operate a stereo microscope and a surface mount solder station.A Fisher-Price “My First 40 Watt Weller Soldering Pencil” won’t cut it for this type of repair as you’re not just flicking diodes off a board to “unlock” something. reply wkat4242 15 hours agorootparentIt does for me.. I&#x27;ve soldered 0805 (and 1206 which was most of them fortunately) components with a screwdriver-tipped aldi iron as I didn&#x27;t have anything else available. It was not a great experience but being very careful with the corner of it it worked.But this is a super capacitor so it&#x27;ll be a lot biger than that.But a hot air rework station or a really fine temperature-controlled tip is way better of course, which is what I usually use. reply yjftsjthsd-h 11 hours agorootparentprevIf a fix requires soldering, then to >95% of people it doesn&#x27;t exist. I would be surprised if even most computer repair ships were up to it. reply wkat4242 1 hour agorootparentYes but this is more the problem with the mentality around today&#x27;s disposable electronics than a real human problem. A lot of these skills have been lost.In the 80s it was totally normal to get an electrical schematic with a TV for instance, and there were repair shops all over (or people doing it from home for a small fee as a side business).These days it&#x27;s not as impossible as people think. In fact very often when a TV fails it&#x27;s a through-hole capacitor that is trivial to replace for a couple bucks. I have repaired several at work and for friends and they still work fine (I always replace it with good quality high-temperature rated ones, manufacturers often use too low a temperature rating so the equipment will fail far too soon and the customers buy a new one). reply croes 16 hours agorootparentprevGuess who gets blamed if your soldered SSD fails. reply lambdasquirrel 16 hours agorootparentYeah, this stuff is harder than it looks. If you need too much time with the soldering iron, the temperature can conduct through the wire and fry other components, those sensitive ICs that are the flash chips in particular. reply mike256 16 hours agorootparentprevAre you sure the BGA is soldered correctly? Regarding the soldering, almost every 2nd component looks pretty bad. reply toomuchtodo 11 hours agoparentprevIs there a class action lawsuit yet? reply gruez 11 hours agoparentLiterally the first sentence from the article:>A new report from a data recovery company now points the finger at design and manufacturing flaws as the underlying issue with the recent flood of SanDisk Extreme Pro failures that eventually spurred a class action lawsuit reply toomuchtodo 11 hours agorootparentThank you. I skimmed too fast. My apologies. I am under the weather. reply einpoklum 10 hours agoparentprevExtreme pro pun title phrasing!Those extreme pros working for Sandisk - you can&#x27;t really trust their designs, there&#x27;s always some little bit that&#x27;s off about them. reply jeffbee 15 hours agoparentprevIf that&#x27;s really the issue, it&#x27;s trivial to fix and you can pick these up for nothing in the secondary markets. reply yetanotherloser 15 hours agoparentFor you and, indeed, for me too. But, sadly, not for many people. reply spandextwins 16 hours agoparentprev [–] 3 copies. Always. Spread them out on different companies and technologies. reply iancmceachern 15 hours agoparent [–] And physical locations replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Attingo, a data recovery company, has identified design and manufacturing flaws as the cause of recent failures in SanDisk Extreme Pro SSDs, leading to a class action lawsuit.",
      "The flaws stem from components that are too big for the circuit board, resulting in weak connections and increased vulnerability to breaking.",
      "Western Digital, the parent company of SanDisk, has not released a firmware update for the affected drives and has not communicated effectively about the issues, which are impacting multiple product lines."
    ],
    "commentSummary": [
      "Users are discussing the failures and design flaws of SanDisk SSDs, expressing dissatisfaction and concerns about data loss.",
      "Potential causes for the failures are mentioned, including soldering issues, component size, and firmware bugs.",
      "Alternatives like Samsung SSDs and Seagate HDDs are suggested as more reliable options, and the importance of regular backups and spreading data across multiple devices and locations is emphasized."
    ],
    "points": 255,
    "commentCount": 149,
    "retryCount": 0,
    "time": 1699806445
  },
  {
    "id": 38246668,
    "title": "Rust+Wasm: A Lightweight Alternative to Python for AI Inference",
    "originLink": "https://www.secondstate.io/articles/fast-llm-inference/",
    "originBody": "The Rust+Wasm stack provides a strong alternative to Python in AI inference. Compared with Python, Rust+Wasm apps could be 1/100 of the size, 100x the speed, and most importantly securely run everywhere at full hardware acceleration without any change to the binary code. Rust is the language of AGI. We created a very simple Rust program to run inference on llama2 models at native speed. When compiled to Wasm, the binary application (only 2MB) is completely portable across devices with heterogeneous hardware accelerators. The Wasm runtime (WasmEdge) also provides a safe and secure execution environment for cloud environments. In fact, the WasmEdge runtime works seamlessly with container tools to orchestrate and execute the portable application across many different devices. Fast & *portable* llama2 inference on the edge using #Wasm! The cross-platform executable is only 2MB, has zero Python dep, and utilizes local hardware acceleration (thanks to @ggerganov’s llama.cpp!). Runs on @realwasmedge — smooth as 🧈 👉 https://t.co/3xDavrhO76 pic.twitter.com/2Rv3DCj519 — Michael Yuan (@juntao) September 23, 2023 Chatting with llama2 models on my MacBook This work is based on the llama.cpp project created by Georgi Gerganov. We adopted the original C++ program to run on Wasm. It works with the GGUF formatted model files. Step 1. Install WasmEdge with the GGML plugin Use the following command on Linux or Mac devices to install everything. See here for more details. curl -sSf https://raw.githubusercontent.com/WasmEdge/WasmEdge/master/utils/install.shbash -s -- --plugin wasi_nn-ggml Step 2. Download a pre-built Wasm app and the model curl -LO https://github.com/second-state/llama-utils/raw/main/chat/llama-chat.wasm You should also download a llama2 model in GGUF format. The example below downloads the llama2 7B chat-tuned model quantized to 5-bit weights (see more here). curl -LO https://huggingface.co/wasmedge/llama2/resolve/main/llama-2-7b-chat-q5_k_m.gguf Step 3. Run it! Use WasmEdge to run the wasm inference application, and pass the GGUF model to it. You can now enter a question to chat with the model. wasmedge --dir .:. --nn-preload default:GGML:AUTO:llama-2-7b-chat-q5_k_m.gguf llama-chat.wasm [USER]: Here is a complete example of a conversation. wasmedge --dir .:. --nn-preload default:GGML:AUTO:llama-2-7b-chat-q5_k_m.gguf llama-chat.wasm [USER]: Who is the \"father of the atomic bomb\"? [ASSISTANT]: The \"father of the atomic bomb\" is a term commonly associated with physicist J. Robert Oppenheimer. Oppenheimer was a leading figure in the development of the atomic bomb during World War II, serving as the director of the Manhattan Project, which was responsible for the development and deployment of the first nuclear weapons. He is often referred to as the \"father of the atomic bomb\" due to his significant contributions to the field of nuclear physics and his leadership in the development of the bomb. [USER]: Was he a communist? [ASSISTANT]: J. Robert Oppenheimer was not a communist. While he was associated with the Manhattan Project, which was a secret government project, and was involved in the development of the atomic bomb, he was not a member of the Communist Party or had any known political affiliations with communism. Oppenheimer was a physicist and a scientist, and his primary focus was on the development of nuclear weapons during World War II. Configure the model behavior There are command line options you can use to configure how to interact with the model. Options: -m, --model-aliasModel alias [default: default] -c, --ctx-sizeSize of the prompt context [default: 4096] -n, --n-predictNumber of tokens to predict [default: 1024] -g, --n-gpu-layersNumber of layers to run on the GPU [default: 100] -b, --batch-sizeBatch size for prompt processing [default: 4096] -r, --reverse-promptHalt generation at PROMPT, return control. -s, --system-promptSystem prompt message string [default: \"[Default system message for the prompt template]\"] -p, --prompt-templatePrompt template. [default: llama-2-chat] [possible values: llama-2-chat, codellama-instruct, mistral-instruct-v0.1, mistrallite, openchat, belle-llama-2-chat, vicuna-chat, chatml] --log-prompts Print prompt strings to stdout --log-stat Print statistics to stdout --log-all Print all log information to stdout --stream-stdout Print the output to stdout in the streaming way -h, --help Print help For example, the following command specifies a context length of 2048 tokens and the max number of tokens in each response to 512. It also tells WasmEdge to print out statistics and to stream the model response back to stdout one token at a time. The program generates about 25 tokens per second on a low-end M2 macbook. wasmedge --dir .:. --nn-preload default:GGML:AUTO:llama-2-7b-chat-q5_k_m.gguf \\ llama-chat.wasm -c 2048 -n 512 --log-stat --stream-stdout [USER]: Who is the \"father of the atomic bomb\"? ---------------- [LOG: STATISTICS] ----------------- llama_new_context_with_model: n_ctx = 2048 llama_new_context_with_model: freq_base = 10000.0 llama_new_context_with_model: freq_scale = 1 llama_new_context_with_model: kv self size = 1024.00 MB llama_new_context_with_model: compute buffer total size = 630.14 MB llama_new_context_with_model: max tensor size = 102.54 MB [2023-11-10 17:52:12.768] [info] [WASI-NN] GGML backend: llama_system_info: AVX = 0AVX2 = 0AVX512 = 0AVX512_VBMI = 0AVX512_VNNI = 0FMA = 0NEON = 1ARM_FMA = 1F16C = 0FP16_VA = 1WASM_SIMD = 0BLAS = 0SSE3 = 0SSSE3 = 0VSX = 0The \"father of the atomic bomb\" is a term commonly associated with physicist J. Robert Oppenheimer. Oppenheimer was the director of the Manhattan Project, the secret research and development project that produced the atomic bomb during World War II. He is widely recognized as the leading figure in the development of the atomic bomb and is often referred to as the \"father of the atomic bomb.\" llama_print_timings: load time = 15643.70 ms llama_print_timings: sample time = 2.60 ms / 83 runs ( 0.03 ms per token, 31886.29 tokens per second) llama_print_timings: prompt eval time = 7836.72 ms / 54 tokens ( 145.12 ms per token, 6.89 tokens per second) llama_print_timings: eval time = 3198.24 ms / 82 runs ( 39.00 ms per token, 25.64 tokens per second) llama_print_timings: total time = 18852.93 ms ---------------------------------------------------- The next example shows it running on an Nvidia A10G machine at 50 tokens per second. wasmedge --dir .:. --nn-preload default:GGML:AUTO:llama-2-7b-chat-q5_k_m.gguf \\ llama-chat.wasm -c 2048 -n 512 --log-stat [USER]: Who is the \"father of the atomic bomb\"? ---------------- [LOG: STATISTICS] ----------------- llm_load_tensors: using CUDA for GPU acceleration llm_load_tensors: mem required = 86.04 MB llm_load_tensors: offloading 32 repeating layers to GPU llm_load_tensors: offloading non-repeating layers to GPU llm_load_tensors: offloaded 35/35 layers to GPU llm_load_tensors: VRAM used: 4474.93 MB .................................................................................................. llama_new_context_with_model: n_ctx = 2048 llama_new_context_with_model: freq_base = 10000.0 llama_new_context_with_model: freq_scale = 1 llama_kv_cache_init: offloading v cache to GPU llama_kv_cache_init: offloading k cache to GPU llama_kv_cache_init: VRAM kv self = 1024.00 MB llama_new_context_with_model: kv self size = 1024.00 MB llama_new_context_with_model: compute buffer total size = 630.14 MB llama_new_context_with_model: VRAM scratch buffer: 624.02 MB llama_new_context_with_model: total VRAM used: 6122.95 MB (model: 4474.93 MB, context: 1648.02 MB) [2023-11-11 00:02:22.402] [info] [WASI-NN] GGML backend: llama_system_info: AVX = 1AVX2 = 1AVX512 = 0AVX512_VBMI = 0AVX512_VNNI = 0FMA = 1NEON = 0ARM_FMA = 0F16C = 1FP16_VA = 0WASM_SIMD = 0BLAS = 1SSE3 = 1SSSE3 = 1VSX = 0llama_print_timings: load time = 2601.44 ms llama_print_timings: sample time = 2.63 ms / 84 runs ( 0.03 ms per token, 31987.81 tokens per second) llama_print_timings: prompt eval time = 203.90 ms / 54 tokens ( 3.78 ms per token, 264.84 tokens per second) llama_print_timings: eval time = 1641.84 ms / 83 runs ( 19.78 ms per token, 50.55 tokens per second) llama_print_timings: total time = 4254.95 ms ---------------------------------------------------- [ASSISTANT]: The \"father of the atomic bomb\" is a term commonly associated with physicist J. Robert Oppenheimer. Oppenheimer was the director of the Manhattan Project, the secret research and development project that produced the first atomic bomb during World War II. He is widely recognized as the leading figure in the development of the atomic bomb and is often referred to as the \"father of the atomic bomb.\" LLM agents and apps We have also created an OpenAI-compatible API server using Rust and WasmEdge. It allows you use any OpenAI-compatible developer tools, such as flows.network, to create LLM agents and apps. Learn more here. Llama on the edge. Image generated by Midjourney. Why not Python? LLMs like llama2 are typically trained in Python (e.g. PyTorch, Tensorflow, and JAX). But to use Python for inference applications, which is about 95% of the computing in AI, would be a bad mistake. Python packages have complex dependencies. They are difficult to set up and use. Python dependencies are huge. A Docker image for Python or PyTorch is typically several GBs or even tens of GBs. That is especially problematic for AI inference on edge servers or on devices. Python is a very slow language. Up to 35,000x slower than compiled languages such as C, C++, and Rust. Because Python is slow, most of the actual workloads must be delegated to native shared libraries beneath the Python wrapper. That makes Python inference apps great for demos, but very hard to modify under the hood for business-specific needs. The heavy dependency on native libraries, combined with complex dependency management, makes it very hard to port Python AI programs across devices while taking advantage of the device’s unique hardware features. llama-cpp-python requires pydantic 2.0.1, explicitly won't work with =2.0 oh, dear...@abetlen pic.twitter.com/KG5XDicLPQ — Eric Hartford (@erhartford) September 16, 2023 Commonly used Python packages in LLM toolchain are directly conflicting with each other. Chris Lattner, of the LLVM, Tensorflow, and Swift language fame, gave a great interview on the This Week in Startup podcast. He discussed why Python is great for model training but the wrong choice for inference applications. The advantages of Rust+Wasm The Rust+Wasm stack provides a unified cloud computing infra that spans devices to edge cloud, on-prem servers, and the public cloud. It is a strong alternative to the Python stack for AI inference applications. No wonder Elon Musk said that Rust is the language of AGI. Ultra lightweight. The inference application is just 2MB with all dependencies. It is less than 1% of the size of a typical PyTorch container. Very fast. Native C/Rust speed in all parts of the inference application: pre-processing, tensor computation, and post-processing. Portable. The same Wasm bytecode application can run on all major computing platforms with support for heterogeneous hardware acceleration. Easy to set up, develop and deploy. There are no more complex dependencies. Build a single Wasm file using standard tools on your laptop and deploy it everywhere! Safe and cloud-ready. The Wasm runtime is designed to isolate untrusted user code. The Wasm runtime can be managed by container tools and easily deployed on cloud-native platforms. The Rust inference program Our demo inference program is written in Rust and compiled into Wasm. The core Rust source code is very simple. It is only 40 lines of code. The Rust program manages the user input, tracks the conversation history, transforms the text into the llama2’s chat template, and runs the inference operations using the WASI NN API. fn main() { let args: Vec = env::args().collect(); let model_name: &str = &args[1]; let graph = wasi_nn::GraphBuilder::new(wasi_nn::GraphEncoding::Ggml, wasi_nn::ExecutionTarget::AUTO) .build_from_cache(model_name) .unwrap(); let mut context = graph.init_execution_context().unwrap(); let system_prompt = String::from(\">You are a helpful, respectful and honest assistant. Always answer as short as possible, while being safe. >\"); let mut saved_prompt = String::new(); loop { println!(\"Question:\"); let input = read_input(); if saved_prompt == \"\" { saved_prompt = format!(\"[INST] {} {} [/INST]\", system_prompt, input.trim()); } else { saved_prompt = format!(\"{} [INST] {} [/INST]\", saved_prompt, input.trim()); } // Set prompt to the input tensor. let tensor_data = saved_prompt.as_bytes().to_vec(); context .set_input(0, wasi_nn::TensorType::U8, &[1], &tensor_data) .unwrap(); // Execute the inference. context.compute().unwrap(); // Retrieve the output. let mut output_buffer = vec![0u8; 1000]; let output_size = context.get_output(0, &mut output_buffer).unwrap(); let output = String::from_utf8_lossy(&output_buffer[..output_size]).to_string(); println!(\"Answer:\\n{}\", output.trim()); saved_prompt = format!(\"{} {} \", saved_prompt, output.trim()); } } To build the application yourself, just install the Rust compiler and its wasm32-wasi compiler target. curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rssh rustup target add wasm32-wasi Then, check out the source project, and run the cargo command to build the Wasm file from the Rust source project. # Clone the source project git clone https://github.com/second-state/llama-utils cd llama-utils/chat/ # Build cargo build --target wasm32-wasi --release # The result wasm file cp target/wasm32-wasi/release/llama-chat.wasm . Running in the cloud or on the edge Once you have the Wasm bytecode file, you can deploy it on any device that supports the WasmEdge runtime. You just need to install the WasmEdge with the GGML plugin. We currently have GGML plugins for generic Linux and Ubuntu Linux — both on x86 and ARM CPUs and Nvidia GPUs, as well as Apple M1/M2/M3. Based on llama.cpp, the WasmEdge GGML plugin will automatically take advantage of any hardware acceleration on the device to run your llama2 models. For example, if your device has Nvidia GPU, the installer will automatically install a CUDA-optimized version of the GGML plugin. For Mac devices, the Mac OS build of the GGML plugin uses the Metal API to run the inference workload on M1/M2/M3’s built-in neural processing engines. The Linux CPU build of the GGML plugin uses the OpenBLAS library to auto-detect and utilize the advanced computational features, such as AVX and SIMD, on modern CPUs. That’s how we achieve portability across heterogeneous AI hardware and platforms without sacrificing performance. What’s next While the WasmEdge GGML tooling is usable (and indeed used by our cloud-native customers) today, it is still in its early stages. If you are interested in contributing to the open source projects and shaping the direction of future LLM inference infrastructure, here are some low-hanging fruits that you can potentially contribute to! Add GGML plugins for more hardware and OS platforms. We are also interested in TPUs, ARM NPUs, and other specialized AI chips on Linux and Windows. Support more llama.cpp configurations. We currently support passing some config options from Wasm to the GGML plugin. But we would like to support all the options GGML provides! Support WASI NN APIs in other Wasm-compatible languages. We are specifically interested in Go, Zig, Kotlin, JavaScript, C and C++. Other AI models As a lightweight, fast, portable, and secure Python alternative, WasmEdge and WASI NN are capable of building inference applications around popular AI models beyond LLMs. For example, The mediapipe-rs project provides Rust+Wasm APIs for Google’s mediapipe suite of Tensorflow models. The WasmEdge YOLO project provides Rust+Wasm APIs to work with YOLOv8 PyTorch models. The WasmEdge ADAS demo shows how to perform road segmentation in self-driving cars using an Intel OpenVINO model. The WasmEdge Document AI project will provide Rust+Wasm APIs for a suite of popular OCR and document processing models. Lightweight AI inference on the edge has just started! Join the conversation and contribute to the WasmEdge discord. Discuss, learn, and share your insights.",
    "commentLink": "https://news.ycombinator.com/item?id=38246668",
    "commentBody": "Run LLMs on my own Mac fast and efficient Only 2 MBsHacker NewspastloginRun LLMs on my own Mac fast and efficient Only 2 MBs (secondstate.io) 247 points by 3Sophons 7 hours ago| hidepastfavorite71 comments jasonjmcghee 5 hours agoparentConfused about the title rewrite from “Fast and Portable Llama2 Inference on the Heterogeneous Edge” which more clearly communicates what this article is about - a wasm version of llama.cpp.I feel like editorializing to highlight the fact that it’s 2MB and runs on a mac are missing some of the core aspects of the project and write up. reply PUSH_AX 2 hours agoparentNow I’m confused, because neither of the titles _clearly_ communicate that it’s a wasm version of llama.cpp in my opinion.It would probably be helpful to use the words “wasm” and “llama” to achieve that reply stavros 2 hours agorootparent\"Run LlaMA 2 on WASM in 2 MB RAM\"This has the added advantage of being completely gibberish to someone outside tech.Edit: wait, it&#x27;s not RAM, the binary is just 2 MB. That&#x27;s disappointing. reply grumpy_tired 12 minutes agorootparentBeautiful. I wish all titles on hn where this concise. reply doubloon 2 hours agoparentprevwell it requires nvidia so maybe its not actually portable. reply 3Sophons 1 hour agorootparent&#x27;portable&#x27; in the article refers to the software&#x27;s ability to run across various operating systems or environments, rather than its hardware dependencies? This means while the software can be installed and run on different OSs, certain hardware-specific optimizations (like those for Nvidia GPUs using CUDA) are necessary to achieve the best performance. reply threeseed 2 hours agorootparentprevIt also works with Metal hence why they mention it runs on Mac. reply 3Sophons 5 hours agoparentprevok.. should be run LLMs on my own devices with a 2MB portable app then? reply ed 6 hours agoparentprevWhoa! Great work. To other folks checking it out, it still requires downloading the weights, which are pretty large. But they essentially made a fully portable, no-dependency llama.cpp, in 2mb.If you&#x27;re an app developer this might be the easiest way to package an inference engine in a distributable file (the weights are already portable and can be downloaded on-demand — the inference engine is really the part you want to lock down). reply kristianp 4 hours agoparentIt might be more helpful if the title says 2MB of wasm. But as you say, the weights dwarf that. reply FL33TW00D 5 hours agoparentprevThis just wrapping llama.cpp right? I’m sorry but I’m pretty tired of projects wrapping x.cpp.I’ve been developing a Rust + WebGPU ML framework for the past 6 months. I’ve learned quickly how impressive the work by GG is.It’s early stages but you can check it out here: https:&#x2F;&#x2F;www.ratchet.sh&#x2F; https:&#x2F;&#x2F;github.com&#x2F;FL33TW00D&#x2F;whisper-turbo reply stavros 2 hours agoparentCan you elaborate on what you find impressive? I know nothing about this stuff so I can&#x27;t appreciate it. reply tansan 2 hours agoparentprevWho&#x27;s GG? reply europeanNyan 2 hours agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;ggerganov reply hluska 3 hours agoparentprevYou ripped on someone else’s work and promoted your own in the same comment?? You need to seriously reflect upon your ethics. reply FL33TW00D 3 hours agorootparentI appreciate the work that went into slimming this binary down, but it&#x27;s a ~negligble amount of work compared to llama.cpp itself.HN is inundated with posts doing xyz on top of the x.cpp community. Whilst I appreciate it is exciting - I wish more people would explore the low-level themselves! We can be much more creative in this new playground. reply spiderfarmer 2 hours agorootparentWhy not both. reply oersted 16 minutes agoparentprevI&#x27;m all for Rust and WASM, but if you look at the code it&#x27;s just 150 lines of a basic Rust command-line script. All the heavy lifting is done by a single line passing the model to the WASI-NN backend, which in this case is provided by the WasmEdge runtime, which incidentally is C++, not Rust.Rust is bringing zero advantage here really, the backend could be called from Python or anything else. reply wokwokwok 1 hour agoparentprevMmm…The wasm-nn that this relies on (https:&#x2F;&#x2F;github.com&#x2F;WebAssembly&#x2F;wasi-nn) is a proposal that relies on sending arbitrarily chunks to some vendor implementation. The api is literally like set input, compute, set output.…and that is totally non portable.The reason this works, is because it’s relying on the abstraction already implemented in llama.cpp that allows it to take a gguf model and map it to multiple hardware targets,which you can see has been lifted as-is into WasmEdge here: https:&#x2F;&#x2F;github.com&#x2F;WasmEdge&#x2F;WasmEdge&#x2F;tree&#x2F;master&#x2F;plugins&#x2F;was...So..> Developers can refer to this project to write their machine learning application in a high-level language using the bindings, compile it to WebAssembly, and run it with a WebAssembly runtime that supports the wasi-nn proposal, such as WasmEdge.Is total rubbish; no, you can’t.This isn’t portable.It’s not sandboxed.It’s not a HAL.If you have a wasm binary you might be able to run it if the version of the runtime you’re using happens to implement the specific ggml backend you need, which it probably doesn’t… because there’s literally no requirement for it to do so.…and if you do, you’re just calling the llama.cpp ggml code, so it’s as safe as that library is…There’s a lot of “so portable” and “such rust” talk in this article which really seems misplaced; this doesn’t seem to have the benefits of either of those two things.Let’s imagine you have some new hardware with a WASI runtime on it, can you run your model on it? Does it have GPU support?Well, turns out the answer is “go and see if llama.cpp compiles on that platform with GPU support and if the runtime you’re using happens have a ggml plugin in it and happens to have a copy of that version of ggml vendored in it, and if not, then no”...at which point, wtf are you even using WASI for?Cross platform GPU support is hard, but this… I dunno. It seems absolutely ridiculous.Imagine if webGPU was just “post some binary chunk to the GPU and maybe it’ll draw something or whatever if it’s the right binary chunk for the current hardware.”That’s what this is. reply behnamoh 3 hours agoparentprevThe way things are going, we&#x27;ll see more efficient and faster methods to run transformer arch on edge, but I&#x27;m afraid we&#x27;re approaching the limit because you can&#x27;t just rust your way out of the VRAM requirements, which is the main bottleneck in loading large-enough models. One might say \"small models are getting better, look at Mistral vs. llama 2\", but small models are also approaching their capacity (there&#x27;s only so much you can put in 7b parameters).I don&#x27;t know man, this approach to AI doesn&#x27;t \"feel\" like it&#x27;ll lead to AGI—it&#x27;s too inefficient. reply danielbln 1 hour agoparentI think we have plenty of headroom with MoE systems, dynamically loading LoRAs and such, even with the small models. reply nigma 2 hours agoparentprevI hate this kind of clickbait marketing suggesting the project is delivering 1&#x2F;100 of the size or 100x-35000x the speed of other solutions because it uses a different language for a wrapper around core library and completely neglecting tooling and community expertise built around other solutions.First of all the project is based on llama.cpp[1], which does the heavy work of loading and running multi-GB model files on GPU&#x2F;CPU and the inference speed is not limited by the wrapper choice (there are other wrappers in Go, Python, Node, Rust, etc. or one can use llama.cpp directly). The size of the binary is also not that important when common quantized model files are often in the range of 5GB-40GB and require a beefy GPU or a MB with 16-64GB of RAM.[1] https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp reply reidjs 6 hours agoparentprevCan I run this offline on my iPhone? That would be like having basic internet search regardless of reception. Could come in handy when camping reply 3Sophons 5 hours agoparentYou can run it on a variety of Linux, Mac and Windows based devices, including the Raspberry Pi and most laptops &#x2F; servers you might have. But you still need a few GBs of memory in order to fit the model itself. reply SparkyMcUnicorn 5 hours agoparentprevI got this project[0] running on a Pixel. Looks like it works on some iPhones&#x2F;iPads as well.[0] https:&#x2F;&#x2F;github.com&#x2F;mlc-ai&#x2F;mlc-llm reply simonw 4 hours agorootparentYeah I&#x27;ve been using their iPhone app for a while - it works great, though it does make the phone run pretty hot while it&#x27;s outputting tokens!https:&#x2F;&#x2F;llm.mlc.ai&#x2F;#ios reply woadwarrior01 1 hour agoparentprevI have a successful-ish commercial iOS app[0] for that. I&#x27;d originally built it using ggml, and then subsequently ported it to be based on mlc-llm when I found it.[0]: https:&#x2F;&#x2F;apps.apple.com&#x2F;us&#x2F;app&#x2F;private-llm&#x2F;id6448106860 reply antirez 35 minutes agoparentprevLinkbait at its finest. But it&#x27;s true that the Python AI stack sucks big times. reply danielEM 3 hours agoparentprevI&#x27;m getting lost in all that.Using llama cpp and mlc-llm. Both on my 2 years old mobile Ryzen APU with 64GB of RAM. First does not use GPU at all, tried plenty of options, nothing did work, but llama 34B works - painfully slow, but does work. Second is working on top of Vulkan and I didn&#x27;t take any precise measurements but it&#x27;s limit looks like is 32GB RAM (so no llama 34B), but it offloads CPU, unfortunately seem like performance is similar to CPU (that is my perception, didn&#x27;t take any measurements here too).So ... will I get any benefits from switching to rust&#x2F;webassembly version??? reply hnarayanan 6 hours agoparentprevIf a large part of the size is essentially the trained weights of a model, how can one reduce the size by orders of magnitude (without losing any accuracy)? reply rgbrgb 6 hours agoparentI don&#x27;t think you can reduce size without losing accuracy (though I think quantized GGUFs are great). But the 2 MB size here is a reference to the program size not including a model. It looks like it&#x27;s a way to run llama.cpp with wasm + a rust server that runs llama.cpp.I like the tiny llama.cpp&#x2F;examples&#x2F;server and embed it in FreeChat, but always happy for more tooling options.Edit: Just checked, the arm64&#x2F;x86 executable I embed is currently 4.2 MB. FreeChat is 12.1 MB but the default model is ~3 GB so I&#x27;m not really losing sleep over 2 MB.[0]: https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;tree&#x2F;master&#x2F;examples&#x2F;... reply 3Sophons 6 hours agoparentprevHello you might be talking about reducing the size of the model itself (i.e., the trained weights) by orders of magnitude without losing accuracy, that&#x27;s indeed a different challenge. But the article discusses reducing the inference app size by 100x reply hnarayanan 6 hours agorootparentOh. Did not think that was even a goal. reply 3Sophons 6 hours agorootparentI guess making it portable is still quite important? reply hnarayanan 2 hours agorootparentI am not trying to troll. I genuinely don’t see why a few MB on some binary matter when the models are multiple GB large. This is why I fundamentally misunderstood the article, my brain was looking for the other number going down as that’s genuinely a barrier for edge devices. replyest 5 hours agoparentprev> The core Rust source code is very simple. It is only 40 lines of code. The Rust program manages the user input, tracks the conversation history, transforms the text into the llama2’s chat template, and runs the inference operations using the WASI NN API.TL;DR a 2MB executable that reads stdin and calls WASI-NN reply isoprophlex 4 hours agoparent> \"Rust is the language of AGI.\"Oh Rust Evangelism Strike Force, never change reply hedgehog 5 hours agoparentprevIt looks like this is Rust for the application wrapped around a WASM port of llama.cpp that in turn uses an implementation of WASI-NN for the actual NN compute. It would be interesting to see how this compares to the TFLite, the new stuff in the PyTorch ecosystem, etc. reply gvand 3 hours agoparentprevThe binary size is not really important in this case, llama.cpp should not be that far from this, what&#x27;s matter as we all know is how much gpu memory we need. reply dkga 5 hours agoparentprevVery cool, but unless I missed it could someone please explain why not just compile a Rust application? Is the Wasm part needed for the GPU acceleration (whatever the user GPU is?) reply bouke 4 hours agoparentI suppose wasm provides the portability between platforms. Compile once, run everywhere. reply rjzzleep 5 hours agoparentprevIs there any detailed info on how a 4090 + ryzen 7840 compares to any of the new Apple offerings with 64GB or more unified RAM? reply renewiltord 3 hours agoparentNo. You just have to try it. Anecdotally, I can fit a larger Llama on my M1 Max with 64 GiB than my 3090 with 24 GiB. reply diimdeep 5 hours agoparentprevI do not see the point to use this instead of directly using llama.cpp reply kelseyfrog 5 hours agoparentHint: the Rewrite-it-in-Rust economy&#x27;s currency isn&#x27;t actually running things. reply gumby 5 hours agorootparentThe crypto of programming languages? reply 3Sophons 5 hours agoparentprevllama.cpp typically needs to be compiled separately for each operating system and architecture (Windows, macOS, Linux, etc.), which is less portable.Also, the article mentions the use of hardware acceleration on devices with heterogeneous hardware accelerators. This implies that the Wasm-compiled program can efficiently utilize different hardware resources (like GPUs and specialized AI chips) across various devices. A direct C++ implementation might require specific optimizations or versions for each type of hardware to achieve similar performance. reply pjmlp 4 hours agorootparentWhere have I seen this WORA before, including for C and C++?WASM does not provide access to hardware acceleration on devices with heterogeneous hardware accelerators, even its SIMD bytecodes are a subset of what most CPUs are capable of. reply diimdeep 5 hours agorootparentprev> Wasm-compiled program can efficiently utilize different hardware resources (like GPUs and specialized AI chips) across various devicesI do not buy it, but maybe I am ignorant of progress being made there.> A direct C++ implementation might require specific optimizations or versions for each type of hardware to achieve similar performance.Because I do not buy previous one, I do not buy that similar performance can be painlessly(without extra developer time) achieved there, and that wasm runtime capable to achieve it. reply zmmmmm 4 hours agorootparentSo the magic (or sleight of hand, if you prefer) seems to be in> You just need to install the WasmEdge with the GGML plugin.And it turns out that all these plugins are native & specific to the acceleration environment as well. But this has to happen after it lands in its environment so your \"portable\" application is now only portable in the sense that once it starts running it will bootstrap itself by downloading and installing native platform-specific code from the internet. Whether that is a reasonable thing for an \"edge\" application to do I am not sure. reply kamray23 2 hours agorootparentBasically, WASM is now what the JVM was in 2000. It&#x27;s portable because it is. reply tomalbrc 3 hours agorootparentprevJust use Comsopolitan at this point. reply syrusakbary 3 hours agoparentprevCongrats on the work... it&#x27;s an impressive demo!It may be worth researching to add support of it into the Wasmer WebAssembly runtime [1]. (Note: I work at Wasmer!)[1] https:&#x2F;&#x2F;wasmer.io&#x2F; reply anon23432343 2 hours agoparentprevSo you need to mb2 for sending an api call to the edge?Okaayyyy... reply kamray23 2 hours agoparentThis is offline. reply classified 1 hour agoparentprevHow is it still fast if it was compiled to WASM? reply rowanG077 2 hours agoparentprevI don&#x27;t think you can call anything wasm efficient. reply tomalbrc 3 hours agoparentprev> No wonder Elon Musk said that Rust is the language of AGI.What. reply bugglebeetle 6 hours agoparentprev [–] Wow, this is a “holy shit” moment for Rust in AI applications if this works as described. Also, so long Mojo!EDIT:Looks like I’m wrong, but I appreciate getting schooled by all the HNers with low-level expertise. Lots to go and learn about now. reply blovescoffee 5 hours agoparentNo it&#x27;s not. This does nothing to minimize the size of the models which inference on being run on. It&#x27;s cool for edge applications, kind of. And Rust is already a go to tool for edge. reply hnfong 6 hours agoparentprevIt&#x27;s \"just\" a port of GGML (written in C++) to wasm with some additional Rust code. reply bugglebeetle 6 hours agorootparentRight, but if the port achieves performance gains over GGML, which is already highly performant, that’s a. Wild b. a signal to move further GGML development into Rust, no? reply brrrrrm 5 hours agorootparentML has extremely predictable and heavily optimized routines. Languages that can target hardware ISA all tend to have comparable perf and there’s no reason to think Rust would offer much. reply Nevin1901 6 hours agorootparentprevHow would wasm&#x2F;rust be more performant over c++? I’m not sure the wasm version can take advantage of avx&#x2F;metal.Edit: the wasm installer does take advantage by installing plugins.Unless you’re talking about performance on devices where those two weren’t a thing anyways. reply cozzyd 5 hours agorootparentprevAs far as I understand, only the \"driver\" code is in rust. Everything else is just C++ compiled to WASM. Maybe it&#x27;s slightly better to have the driver code be in rust than python or scheme or whatever, but I imagine C++ would be basically equivalent (and.... you wouldn&#x27;t have to go through the trouble of compiling to WASM which likely loses significant performance). reply kamray23 2 hours agorootparentThat&#x27;s what I find weird here. The bit of the code written in rust is almost comically tiny, and the rest is just C++ you compiled to WASM which someone else already wrote. I think comparing this to a Python wrapper for the same code would produce very minimal difference in performance, because the majority goes into performance and formatting the prompt string really isn&#x27;t that complex of a task. I just don&#x27;t see what advantage Rust produces here other than the fact that it&#x27;s a language you can compile to WASM so that you have one binary. reply tomalbrc 3 hours agorootparentprevThere is no mention of it running faster than the original llama2.cpp, if anything it is slower reply est 5 hours agoparentprev> this is a “holy shit” moment for Rust in AI applicationsYeah because I realized the 2MB is just a wrapper that reads stdin and offloads everything to wasi-nn API.> The core Rust source code is very simple. It is only 40 lines of code. The Rust program manages the user input, tracks the conversation history, transforms the text into the llama2’s chat template, and runs the inference operations using the WASI NN API.You can do the same using Python with fewer lines of code and maybe smaller executable size. reply gumby 5 hours agorootparentPretty damning if 40 lines of rust to read stdin generates a 2 MB binary! reply lakpan 4 hours agorootparentPresumably that also accounts for the WASM itself reply 3Sophons 6 hours agoparentprev [–] yeah excited to see how this will evolve. BTW, maybe give it a try on your Mac and see how it performs. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Rust+Wasm stack is emerging as a strong alternative to Python for AI inference.",
      "Rust is considered the language of AGI, and the stack utilizes the WasmEdge runtime for secure execution.",
      "Rust+Wasm offers advantages such as smaller size, faster speed, compatibility with different devices, lightweight execution, portability, ease of deployment, and compatibility with various hardware.",
      "The article provides instructions on installing and running Rust+Wasm applications and mentions the potential to leverage hardware acceleration through the WasmEdge GGML plugin.",
      "The stack's potential for inference applications beyond LLMs is also discussed, using WasmEdge and WASI NN."
    ],
    "commentSummary": [
      "The project aims to optimize the performance of LLMs on Macs using a wasm version of llama.cpp.",
      "There is a discussion about the benefits and limitations of using wasm in running machine learning models.",
      "The focus of the project is on reducing binary size and ensuring compatibility with different operating systems and hardware dependencies."
    ],
    "points": 247,
    "commentCount": 71,
    "retryCount": 0,
    "time": 1699847324
  },
  {
    "id": 38239358,
    "title": "Expert Tips for Archiving Old and Future Projects",
    "originLink": "https://arne.me/articles/archive-your-old-projects",
    "originBody": "Archive Your Old Projects Posted on November 12th, 2023 from Frankfurt, Germany Yesterday, while looking through a folder called old things lol glhf, I fell into a rabbit hole of old abandoned projects—mostly websites and graphic design, but I also found one or two Flash1 projects and compiled .exe files2. And, while it was really fun remembering projects I’ve long forgotten, there was no structure, and it was often difficult to figure out what a project did and what it looked like—some even missed crucial data. This made me think about how I want to archive my projects going forward. Here is my new strategy: Leave it online If the project is on the web, doesn’t require maintenance and doesn’t cost you money, leave it online. Occasionally, you’ll need to move to a different domain, for example when re-doing a website. When talking to Ollie about this, he told me that some people leave their old websites online at . and I love that idea3. You can look up old content and redirect links, so your URIs stay cool. And in ten years it’ll probably still be online. Archive it If you can’t leave it online, save it to your file system. You don’t have to go all Johnny.Decimal, but at least create a dedicated folder and subfolders for every year. But instead of just copying your project to the archive folder and be done with it, consider these points to make life easier for your future self: Make screenshots Having a screenshot allows you to relive your memories more easily without going through the hassle of setting up a project. If you want to go the extra mile, do a screen recording showcasing your project—this has the bonus effect of hearing your voice from years ago, and it has more context. Add a README Explain what the project did, when it was created and abandoned, who contributed and how to get it running again. Back up the database Some of my projects are missing a database dump, so all the actual content is gone. Run sqldump or whatever export functionality your database supports and add it next to your files. Keep generated assets When using static site generators, add the folder containing the built HTML, CSS & JS to the archive. That way, all you have to do is run a static file server to be able to browse the complete website. Save it to the Internet Archive If you don’t own your platform (maybe you’re publishing to Substack or Notion), you can at least save your website to the Wayback Machine. I would also advise saving your content somewhere you control. Show me yours So that’s it, that’s my new project archival strategy. How are you archiving your projects? Am I missing anything? Let me know. If you don’t know what this is, Wikipedia’s got your back ↩ Not sure what to do with these besides deleting. ↩ You can find the previous version of this very website at 2023.arne.me. ↩",
    "commentLink": "https://news.ycombinator.com/item?id=38239358",
    "commentBody": "Archive your old projectsHacker NewspastloginArchive your old projects (arne.me) 238 points by abahlo 23 hours ago| hidepastfavorite60 comments hypertexthero 19 hours agoparentCreate a folder on your computer or get a sturdy box made of good cardboard with a lid. Name the folder “Process”. Write the word “Process” on the box.While working, occasionally take photos or screenshots of what you are doing showing your workspace, the computer desktop, the desk with pencils and papers and cables everywhere, the wall or piece of string with notes. Show the messy process of creating something.Type notes on text files and save them with a name like yyyy-mm-dd-note-title.txt. Write notes on bits of paper and notebooks and journals with pencils and pens that you keep all around the places you spend most of your time in, including within arms-reach of where you sleep.Practice writing down notes on a piece of paper in the dark, so you can do so when waking up in the night, before daybreak, to jot down thoughts and ideas from dreams.Record messages and melodies using your pocket computer and remember to save these in your Process folder, too. You are looking for your voice.Put these digital and physical notes in the Process folder and in the Process box.Thank yourself later, in years to come.You are what you observed. Experiences, memories, stories to be told. Put your marker on the map in time, that others may find and learn from. reply logifail 17 hours agoparent> Practice writing down notes on a piece of paper in the dark > Thank yourself later, in years to comeI only found out about this many decades after it happened, but on the occasion of my grandfather&#x27;s 60th birthday, way back in 1980-ish, my mother presented with him a large bound empty notebook labelled with his name, and explained that the purpose of the gift was that he was to start making notes about his life.It sounds incredible, but he started writing.All kinds of (what must have seemed) completely inconsequential stuff, what he remembered about the home he grew up in, the schools he went to, the friends he&#x27;d had, the whole nine yards.He died not that many years later.Note to everyone who&#x27;s read this far: grab the chance to do this - either as the one writing, or the one who gifts the notebook! - while you have the chance.\"Tempus fugit\" and all that. reply hypertexthero 16 hours agorootparentThank you for this idea.I’ve given notebooks to my mom to encourage her to write, but don’t think I ever wrote her name on the cover. The next one will have it.Also, consider recording a conversation between you and your loved one with the voice recorder on your phone. I have one brief recording of my dad’s voice in an old VHS tape that I burned to DVD and copied to the computer, and that’s it.Memories.Often the most powerful objects in films, to me, are photographs. Like the polaroids in Thelma and Louise and both Blade Runners.Also old school VHS footage, like in Bassackwards by Kurt Vile — https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=pOFWHty4XFQ — and What About That Day by Jenny O. https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=pxCBnKu5jyk reply scarface_74 12 hours agorootparentMy dad is 80 years old and he loves playing the piano and now the keyboard. He never learned how to read music and he plays by ear. He mostly plays and sings Motown classics. I’ve captured a few video clips of his playing and singing when I go back home.I back up all of my videos and pictures to iCloud, OneDrive, Google Photos and Amazon Drive (pictures only).As far as my own writing, my wife and I are what I call “hybrid digital nomads and snowbirders”. I have a blog over at micro.blog where I write about our journey. reply brnt 15 hours agorootparentprevTried it with my parents, not unexpectedly did they not want to partake in such overly personal tomfoolery.Not all people, perhaps not even most, enjoy creating. reply crucialfelix 3 hours agoparentprevWe should all realize that AI systems will be able to read and learn from journals and logs.It could help me to get guidance on current projects (learn from past mistakes and ineffective work patterns).It could help others when there are many archives like this, to learn from others success and failures.We all become training data for the future reply dwaltrip 14 hours agoparentprevWhat have you found to be most valuable &#x2F; meaningful years later? reply cloths 9 hours agorootparentYeah I also want to know this, I used to write diaries for years and cherish it, thought I would look back my life or extract something meaningful out of it, turns out I very rarely look at it.Same goes to old project archives, emails, I have both HDD and S3 Glacier for them, but so far I have never looked at them at all, for 10 years, And I doubt I will look at them in another 10 years.I am beginning to thinking Letting past go and You aren&#x27;t gonna need it philosophy towards such things reply ryl00 8 hours agorootparentI&#x27;m 52 years old, and I have diaries stretching back to 1980 (when I was all of 9 years old!). Over the years I gradually worked on transcribing them from handwriting to comupter text, and that&#x27;s made them much more accessible in the present day. E.g., when my father passed away in 2020, it was so easy to just search for \"Dad\" and revisit long-ago snippets from the past. (And to sadly realize that I&#x27;d taken his presence for granted over the years.)I still regret my roughly ten-year diary hiatus from 1985-1995, losing the bulk of my formative high school&#x2F;college years in the process. Because as I&#x27;ve grown older, and those memories become more and more distant, I&#x27;ve lost a lot of the day-to-day detail, trivial though it may have been, of my past. reply crucialfelix 3 hours agorootparentI&#x27;ve been planning to scan my old journals. Waiting for OCR to comprehend my messy writing. Now I think I will read them out loud, record it, speech to text. reply XorNot 11 hours agoparentprevI&#x27;ve been trying to write a response to this in a couple of tries, and the best I&#x27;ve got is: but also don&#x27;t feel beholden to this.The past isn&#x27;t always a fun place to go visit, even if it&#x27;s not traumatic. Who you were and who you are are different people, and getting dragged back to that old self can feel suffocating rather then fun.Strictly technical records? Great. Everything? Even if you want to keep it, you may find you don&#x27;t like revisiting it. I have zip files which exist because I don&#x27;t quite want to destroy old records entirely, but I certainly don&#x27;t want to actually scroll into photos from 10 years ago. reply imhoguy 18 hours agoparentprevJust a hint, which I think works well for some more complicated programming project setups: if the project is close to be shelved then preserve it in a virtual machine. Make some trivial auth, or auto login, put some notes on login&#x2F;desktop screen, setup some IDE inside, check if it builds with no Internet.Myself I use lightweight Xubuntu destkop for my VMs. I also dump hard disks of old Windows machines I am done with and make sure they run fine as VMs. reply atum47 14 hours agoparentprevI once created a simple counter [1]. I used it to remind me of eating every two hours. I thought to myself \"it&#x27;s a good counter, I&#x27;ll show it to people\" then posted it on HN. People were like \"that is just a counter, why are you showing us that?\" So i kind of stop sharing everything, haha.But my GitHub used to be a replica of my projects folder, i would upload everything. I don&#x27;t do that as much now a days.1 - https:&#x2F;&#x2F;github.com&#x2F;victorqribeiro&#x2F;simpleCounter reply matheusmoreira 10 hours agoparentI know how you feel. I tend to think like everything I do is insignificant and not worth sharing. As a hobbyist programmer I only work on things in my free time. I used to not publish stuff on GitHub because I felt my projects were incomplete, too small, too unpolished, too unmaintained. I&#x27;ve never submitted my projects here and only mention them in comments when they&#x27;re relevant and posting them is easier than explaining. I started making a deliberate effort to change that in the past few years. I&#x27;ve repeatedly discovered that people notice what you do when you put yourself out there.Years ago I bought a Clevo-based laptop from a brazilian manufacturer, reverse engineered the keyboard LEDs and wrote a Linux user space driver for it. I just published it on GitHub and forgot about it, assuming no one would ever care. One day I opened my email and discovered I somehow had users and someone even built a GUI around my little program. I was actually a little embarrassed that someone had posted an issue asking me how to use the thing and I didn&#x27;t even see it.I mentioned another Linux project here in comments, someone submitted it and I got to engage with the community about it. Recently someone submitted another project of mine, a programming language, without me talking about it. Seriously made my day when I opened HN and saw my project on the front page. Couldn&#x27;t even believe it at first.It takes a certain boldness to put oneself out there. I&#x27;m always ready for negativity and criticism. Still, the results can be very nice. reply zlg_codes 10 hours agoparentprevI relate to people not giving a shit about one&#x27;s creations. It has caused me to reconsider the self-hosting and blogging that I do.I decided to give my website one year of an honest chance. I&#x27;ll install basic analytics so I can see what, if anything people are interested in, and if I&#x27;m not satisfied or have a hint as to what about me or my stuff that people like, I&#x27;m out.There&#x27;s a point where sharing is painful due to the way prior things shared have been interpreted. There&#x27;s no therapy or fix for that. People either care about you and your stuff, or they don&#x27;t.I&#x27;ve learned people just don&#x27;t give a shit, even those allegedly close to me. reply Pannoniae 8 hours agorootparenthey, I (would like to) care about you! reply cloths 9 hours agoparentprev> So i kind of stop sharing everything, haha. I&#x27;d like to encourage you as well as myself, don&#x27;t let reality beat you :) reply LVB 18 hours agoparentprevMy main, albeit simple, local organizational pattern is: 1. everything under ~&#x2F;dev 2. all projects are their own folder under a year folder. And if I ever restart work on something older, I move it to the current year.I have hundreds of project folders and it’s helpful day-to-day to just be able to look in ~&#x2F;dev&#x2F;2023 for current stuff. But it is also relatively easy to find older things since I have a sense of roughly how far back they are. Making a new year folder right around Jan 1 and rolling forward active work is always a treat. reply andai 16 hours agoparent>it is also relatively easy to find older things since I have a sense of roughly how far back they areI have a ~&#x2F;dev&#x2F;file_list.txt, generated by find . > file_list.txt(I think I might have added a flag to exclude node_modules...)I drag the output file into Sublime Text, so I can search the entire directory instantly. (It also works for entire hard drives!) reply doctorhandshake 19 hours agoparentprevMy corollary axiom: “always be documentin’”, or, “document or it didn’t happen”.I’d say easily 3&#x2F;4 of the best stuff I’ve ever done was never bounced from the DAW&#x2F;NLE, turned into a non-realtime&#x2F;static artifact from code, or otherwise made archival, and far fewer projects &#x2F; prototypes &#x2F; physical experiments got the respect of any capture of any kind.On a certain level I like the wabi-sabi nature of that. On another I wonder how many opportunities to converse or collaborate about mutual interests or future opportunities went by the wayside because I ‘labored in obscurity’ for so much of my life.I’ve been doing some coaching for folks coming up in my industry recently and this has been an idea I’ve tried to convey early and often - “always be documentin’”. reply bxparks 18 hours agoparentI read this like 3-4 times and I cannot parse or understand this comment. What does \"DAW&#x2F;NLE\" mean? (DDG search says Digital Audio Workstation, and a whole bunch of links to something NLE Choppa). What does \"non-realtime&#x2F;static artifact from code\" mean? What does \"got the respect of any capture\" mean? What does \"wabi-sabi\" mean? How does all this relate to \"always documenting\"? reply dc96 18 hours agorootparentDAW&#x2F;NLE = digital audio workstation&#x2F;non-linear editing (you&#x27;d have to search both terms in order to get the correct context, especially if used right next to each other).The author is probably talking about video editing of some kind, whereby he either regrets not saving more source code or taking more screenshots of his work if I had to wager a guess. Not sure what the \"non-realtime&#x2F;static artifact from code\" refers to when it comes to video editing -- perhaps much of it was rendered from code? 3D software, programmatic editing, etc.?Wabi-sabi being used a bit weirdly in this context, but I think they mean the temporality of it all has innate beauty. Sometimes not capturing every single moment&#x2F;line of code is OK, and there is beauty in a moment not strictly captured, to be appreciated more since you&#x27;ll never see it again. reply doctorhandshake 15 hours agorootparentYeah sorry to be oblique .. you are correct in regard to the intended meaning of DAW, NLE, and wabi-sabi. As for static artifacts, in my case I work with generative systems quite a lot, often durational systems that make image &#x2F; sound &#x2F; lighting &#x2F; movement stochastically or non-deterministically over long periods, and are generally a living thing that has behavior. While a picture or other recording of those things represents a shadow image of what the real thing is, it beats nothing.In this case, I mention wabi-sabi as the zen acceptance, even beauty, of the transience of all things, because it makes the creative act primary, rather than a very un-zen attempt to hold on to something fleeting, which some would say is the source of all unhappiness. reply ohdannyboy 15 hours agoparentprevI really regret not archiving my projects as a kid. I didn&#x27;t care to save much of anything back then so they got lost to various HDD crashes and migrations to other systems.I started programming at 11 and don&#x27;t have anything I made before I was 19. Mostly video games in C++ and small PHP projects I did for money in high school. It&#x27;s fun looking back at what I have so I really wish I had the stuff from way back in the day.My oldest program of any significance, a console based poker game, was lost with Planet Source Code and isn&#x27;t in any of the publicly available archives. I started looking for it maybe 6 months after the site went down. reply thibaut_barrere 12 hours agoparentI did the same as you, and did not manage to keep source code, but I kept binaries at least (https:&#x2F;&#x2F;github.com&#x2F;thbar&#x2F;demomaking) of some demos and games I made.It took a while to find them back on the internet thanks to various archiving folks! reply esafak 14 hours agoparentprevIt is ok. Sometimes the memory is better than the reality. How good do you think your code really was? reply chrismorgan 1 hour agorootparentLook, I’d just like to try to figure out why moving using the numpad rather than the arrow keys let me outpace the monsters in that trivial QBasic game I made where monsters chase you. I don’t think it was a basic √2 oversight on diagonals, fairly sure it applied to horizontal movement too and was more like a 20% speedup. But I was probably seven at the time, no more than eight, and couldn’t figure it out back then.Well, maybe I could find it, seven layers of backups deep; I think it’d be named CHASE.BAS. But just as likely it’s gone, and now I’ll never know. (Hmm, next time I’m at my parents’ place I should try hunting.) reply ohdannyboy 13 hours agorootparentprevTerrible, it&#x27;s value would be entirely nostalgic. reply andershaig 20 hours agoparentprevI&#x27;ve started tracking an index of projects and their status in Notion. Then I create an extra page based on a template to put things on hold but make them resumable in the future.In my index, I track: name, status (active, paused, inactive), description, goal and a link to the archive doc if it exist.My archive doc looks like this (I generally delete any sections that aren&#x27;t relevant to keep these easy to create): #### *Handoff to Future Me: * ### *Snapshot Date*:--- ### *Project Summary* - *Objective*: Briefly state what you&#x27;re trying to achieve. - *Motivation*: What drove you to start this project? - *Current State*: Is it in the ideation phase, research phase, or have you already built something? --- ### *Essential Context* - *Related Projects or Dependencies*: Are there any other projects or tasks that are connected to this one? - *Technical Specs*: For example, in your lamp project, what type of metal, what voltage for the lamp, etc. - *Non-Standard Tools & Environment*: Any unique or specific tools you&#x27;re using. For example, a specific code IDE or a special type of screwdriver. --- ### *Progress and Milestones* - *Last Completed Milestone*: What was the last significant thing you accomplished? - *Next Steps*: Like you said, for your lamp: research, clean metal, buff, etc. - *Stumbling Blocks*: Any challenges you foresee or have encountered? - *Any Experiments&#x2F;Tests Conducted*: Brief on what you&#x27;ve tried and the outcomes. --- ### *Resources* - *Important Files & Locations*: Where are the project assets or codebase stored? - *Reference Material*: Links to guides, tutorials, or papers that are crucial. - *Key Contacts*: Who can you consult about this? Even if it&#x27;s an online community. --- ### *Handoff Summary* - *Why Stopping*: Why are you pausing this project? --- ### *Notes to Future Me* - Personal notes, reminders, or advice to your future self about the project. reply dewey 20 hours agoparentA closed source app like that seems like the worst choice for an \"archive\". Better to use a format that you can easily backup and that will still be readable in many years like a simple text file. reply skydhash 18 hours agorootparentNot really if you can code. Even apple notes is not that bad because the database is readable (and there are already script to export). What I fear is when companies lock you data on their servers and you have to keep paying or be a good citizen to access it. reply dewey 18 hours agorootparentThe nice thing about plain text, easy to find archives is that they can even be useful (maybe not for yourself any more) if you for some reason can&#x27;t use your computer any more. reply NetOpWibby 18 hours agoparentprevJust wanna say, thank you to the people in this thread sharing your archive strategies. Gave me a fuzzy feeling reading them all, idk why.Have a great day. reply pabs3 2 hours agoparentprevArchiveTeam can help get your old sites on archive.org, and Software Heritage can save your old code:https:&#x2F;&#x2F;wiki.archiveteam.org&#x2F; https:&#x2F;&#x2F;www.softwareheritage.org&#x2F; reply andai 16 hours agoparentprevRe: Saving to Web Archive: just a minute ago I found out that one of my old projects isn&#x27;t loading on Wayback Machine because they forgot to crawl the JS file. (Odd, not sure how they decide which dependencies to crawl...)I was just beaming about the virtues of shipping web apps as a single self-contained HTML file (all CSS and JS in the file, rather than linked as external dependencies) for unrelated reasons, when I found that my other web app on the Web Archive works fine because I had followed this principle!(So it also works in Wayback&#x27;s *id_ mode, i.e. shipping the original HTML unaltered, because the functionality is independent from where the HTML is served.) reply esafak 14 hours agoparentprevOr don&#x27;t. It is so liberating not to have to periodically migrate data from one medium and file format to another, and worry about corruption. What are you getting out of it? What are you going to do with your preserved data once you die; burden the next generation with it along with the rest of your junk? Cull data every with every migration. reply raybb 20 hours agoparentprevIf not putting them online publicly how do you store &#x2F; organize them?I just recently bought a NAS for 20 euros and have been thinking about setting it up but am skeptical of relying on it for anything too important. But then again don&#x27;t feel I can really trust anything too important to be in google drive either.I also even have a hetzner nextcloud instance that I use for most low&#x2F;medium importance stuff but I&#x27;ve found it a bit unreliable with the connection failing, mountainduck causing finder to crash, and the website getting quite sluggish when I upload a bunch of photos. reply calamari4065 16 hours agoparentAs everyone else said, redundancy equals reliability. You can automatically sync to AWS or backblaze for offsite backups. Locally you&#x27;ll want a second and&#x2F;or third backup. My proxmox server syncs to a USB hard drive locally, then I manually take that to the office now and then to sync to a different drive I store in my desk. Critical stuff is also stored in a third drive I keep in a firebox at home.You can automate as much or as little as you want, but you have to keep multiple copies around. You can&#x27;t trust any single source. Individual drives fail, tapes go bad, cloud storage can disappear or become corrupt.The 3-2-1 rule is a good place to start. Three copies on two different media, and at least one copy off-site reply jamesfinlayson 7 hours agoparentprevNot the best system but I back everything up to two separate hard-drives (code goes in GitHub as well). I&#x27;ve been trying to get everything off Google Drive after the stories of a file with just the character 1 set off piracy filters earlier this year (or maybe late last year). reply bombcar 20 hours agoparentprevThe key is multiple copies everywhere. Storage is cheap these days, so you can keep more than one copy - and digital hoarding doesn’t take up much space at all. reply bxparks 18 hours agorootparentThe problem with multiple copies everywhere that is:1) You can never remember which copy is the master or the most recent. And a backup is not a backup unless you test the restore regularly. But with multiple copies, we don&#x27;t have the time to test the restores of all the backups.2) If any of the syncing scripts stop working, you will not know for ages. Unless you have another layer of monitoring scripts that watch your backup scripts. But almost no one has the patience to do that.I have at least 3 copies of my important files, in 3 different locations. But I fail on both of my points above. reply wongarsu 17 hours agoparentprevKind of jealous of your 20 Euro NAS. But generally the key to longevity is having data in many independent locations. Since you&#x27;re already using Hetzner, backing up your NAS to a Hetzner StorageBox is easy and cheap. The StorageBoxes are occasionally down for maintenance and don&#x27;t have top performance, but for backup they are fine. Then you can just use the NAS as primary storage. reply bluehatbrit 19 hours agoparentprevI don&#x27;t store much stuff, so I mostly backup to AWS S3 and Backblaze (duplicated). I use Arq on windows and mac machines, and restic on linux. Job done! I&#x27;m looking at getting a NAS soon myself and then I&#x27;ll backup or save to that as needed.If you&#x27;re not storing much then it&#x27;s pretty cheap. For me it&#x27;s mostly just photos and important documents, it comes to no more than a few 100GB total and costs me maybe 5 USD per month if that. reply RajT88 18 hours agoparentprevWhere did you buy a NAS for 20 Euros?My old DNS-320 was ~100 euro new. And it kind of sucked. reply raybb 17 hours agorootparentAn ancient Synology Disk Station DS112j with a 1TB hdd from fb marketplace.I&#x27;ve never had a NAS before so wanted to play around with it before deciding to invest in a nicer one that can do more like handle Plex. reply RajT88 15 hours agorootparentAfter my DNS-320 I concluded to make it do everything I wanted, I need to really have a full OS I have control over.So I built a box from one of those 4 bay Mini ITX chassis&#x27;. More expensive but I am loving the FOSS options like JellyFin. reply vinc 12 hours agoparentprevI start my projects in `~&#x2F;tmp&#x2F;` and when I feel like I&#x27;m getting somewhere with them they graduate to `~&#x2F;src&#x2F;` and get published on GitHub (and a few mirrors for the most important ones). Anything on `~&#x2F;src` need to be backed up but things in `~&#x2F;tmp` can be lost without missing them.When I start working on a new feature for a project I create a PR on GitHub and document my research and then the implementation with screenshots.I also have a text file on my computer where I write a few lines everyday about what I&#x27;m doing. From time to time I send it to myself by email.It&#x27;s relatively simple and low effort but has proven to be very helpful many times. reply samsquire 6 hours agoparentprevIf you&#x27;ve got some nodejs, Javascript, Ruby or Python projects and you want to keep them around for posterity then I recommend thinking how you can package them up so they can be safely archived. You could use docker or a virtual machine image.In my editor project ( screencast https:&#x2F;&#x2F;github.com&#x2F;samsquire&#x2F;live-interface&#x2F;blob&#x2F;master&#x2F;scre... )and in its various components written in Nodejs, Ruby (sourceclassifier) and Python (dot renderer) and they&#x27;re all in disrepair because I failed to pin dependencies.Also recommend taking lots of screenshots. reply Izkata 16 hours agoparentprevI copy my entire home directory across to every new computer, so I have a lot of random crap laying around in random places that I occasionally rediscover by chance. The oldest stuff I have is from ~15 years ago, when my hard drive died in the middle of a semester in college and I hadn&#x27;t yet started making backups. reply axegon_ 11 hours agoparentprevFunny enough, I was scrolling through an old hard drive of mine about a week ago and on it I found a cli I made in c++ at some point during the first half of the 2000s to solve quadratic equations. I had completely forgotten I ever made it but I bet it cut the time I spent on my math homework drastically. I remember how boring and tedious I used to find them... reply donatj 20 hours agoparentprev> compiled .exe files> Not sure what to do with these besides deletingI was recently digging through some old backups for fun, and have so many little exe&#x27;s I built in highschool and college just laying around.I moved to Mac shortly after college and made the questionable decision to back up my old hard drives as Mac .dmg files before getting rid of the computers, so getting the exe&#x27;s into a running version of Windows to even test is a pain.A lot of the older ones are pretty neat little games and graphics demos made for DOS. Be neat to get a little VM up on my site running some of these but I suspect it might be a pretty large undertaking. reply aninteger 20 hours agoparent> Be neat to get a little VM up on my site running some of these but I suspect it might be a pretty large undertaking.It might not be too bad. I feel like there are a lot of little web assembly projects running on various sites that you could easily use. For a retro project I am working on I needed the MASM 5.00 reference manual and the site had PCjs running on it. Archive.org has there own web assembly emulator as well. reply ta988 20 hours agoparentprevNot that hard with dosbox look at what Archive.org has done. reply alexpotato 17 hours agoparentprevReminds of the quote from Adam Savage from Mythbuster:\"The difference between science and screwing around is that in science you write things down.\" reply aborsy 11 hours agoparentprevWhat’s the best way to encrypt data for archival, so that it can be decrypted decades later?The encryption software can be discontinued, or change over time and be backwards incompatible. reply nerpderp82 18 hours agoparentprevAlso consider archiving them to the web in a Digital Gardenhttps:&#x2F;&#x2F;maggieappleton.com&#x2F;garden-historyThe most grounding for me are screenshots and scripts with expected output. reply pplonski86 18 hours agoparentprevIm doing demo with my projects and record them as videos. They are on youtube, so if I want to show it to someone I just send link to youtube. reply Rygian 17 hours agoparentKeep a local copy of those. The youtube copies may disappear without prior warning. reply lloydatkinson 20 hours agoparentprev [–] A few months ago I went through my repos on GitHub and marked everything I built with Vue as “archived” which is nice as it prevents any new issues being opened and very clearly indicates the project is no longer maintained.I think it would have been a bad idea to simply outright delete them, though I did delete a few. reply JCharante 17 hours agoparent [–] May I ask what you switched to? I used Vue everyday for 3-4 years and then went all in on React when I joined a former employer. Looking at my Vue projects gives me a sense of nostalgia. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author suggests a strategy for archiving future projects, including leaving projects online, creating dedicated folders and subfolders for offline archiving, and taking screenshots and adding a README file for easy reference.",
      "They also recommend backing up databases and saving generated assets, as well as saving projects to the Internet Archive or other platforms for safekeeping.",
      "The author invites readers to share their own project archiving strategies."
    ],
    "commentSummary": [
      "The article emphasizes the significance of archiving and documenting old projects and provides insights into various methods for organizing, storing, and backing up data.",
      "It highlights the value of sharing projects and receiving feedback, while also stressing the importance of redundancy and maintaining multiple independent copies of data.",
      "The article explores different strategies and technologies including cloud storage and NAS devices, and discusses considerations for encryption and long-term preservation."
    ],
    "points": 238,
    "commentCount": 60,
    "retryCount": 0,
    "time": 1699789222
  },
  {
    "id": 38241235,
    "title": "Generate Images Quickly with Blazing Fast LCM Lora SD 1.5 for Browser Testing",
    "originLink": "https://twitter.com/abidlabs/status/1723074108739706959",
    "originBody": "Try out the Blazing Fast LCM Lora SD 1.5 in your browserIt&#39;ll generate images as fast as you can type https://t.co/GHiLWpuDGI pic.twitter.com/ZxLFsjL3Lz— Abubakar Abid (@abidlabs) November 10, 2023",
    "commentLink": "https://news.ycombinator.com/item?id=38241235",
    "commentBody": "Generate images fast with SD 1.5 while typing on GradioHacker NewspastloginGenerate images fast with SD 1.5 while typing on Gradio (twitter.com/abidlabs) 167 points by smusamashah 17 hours ago| hidepastfavorite26 comments jimmySixDOF 15 hours agoparentAnd here is a demo mashed up using LeapMotion free space hand tracking and a projector to manipulate a \"bigGAN&#x27;s high-dimensional space of pseudo-real images\" to make it more like a modern dance meets sculpting meets spatial computing with a hat tip to the 2008 work of Johnny Chung Lee while at Carnage Mellon.https:&#x2F;&#x2F;x.com&#x2F;graycrawford&#x2F;status&#x2F;1100935327374626818 reply echelon 7 hours agoparentThis is incredible.I dream of the day we can sculpt entire 3D worlds with quick, tactile gestures. Or pure thought. This feels tangibly close.Fantastic demo. Very much in the magic style of Johnny Chung Lee. reply brucethemoose2 10 hours agoparentprevNow combine this with an optimized SD implementation, like:https:&#x2F;&#x2F;github.com&#x2F;chengzeyi&#x2F;stable-fastOr AITemplate, and you are at 15FPS on a larger consumer GPU. 10 with a controlnet you can use for some motion consistency. reply mdrzn 37 minutes agoparentprevThe huggingface space seems broken reply r-k-jo 12 hours agoparentprevHere is a collection of demos with fast LCM on HuggingFacehttps:&#x2F;&#x2F;huggingface.co&#x2F;collections&#x2F;latent-consistency&#x2F;latent... reply smlacy 13 hours agoparentprevhttps:&#x2F;&#x2F;nitter.net&#x2F;abidlabs&#x2F;status&#x2F;1723074108739706959 reply Der_Einzige 16 hours agoparentprev [–] The fact that LCM loras turn regular SD models into psudo-LCM models is insane.Most people in the AI world don&#x27;t understand that ML is like actual alchemy. You can merge models like they are chemicals. A friend of mine called it \"a new chemistry of ideas\" upon seeing many features in Automatic1111 (including model and token merges) used simultaneously to generate unique images.Also, loras exist on a spectrum based on their dimensionality. Tiny loras should only be capable of relatively tiny changes. My guess is that this is a big lora, nearly the same size as the base checkpoint. reply ttul 14 hours agoparentTo me, the crazy thing about LoRA is they work perfectly well adapting models checkpoints that were themselves derived from the base model on which the LoRA was trained. So you can take the LCM LoRA for SD1.5 and it works perfectly well on, say, RealisticVision 5.1, a fine-tuned derivative of SD1.5.You’d think that the fine tuning would make the LCM LoRA not work, but it does. Apparently the changes in weights introduced through even pretty heavy fine tuning does not wreck the transformations the LoRA needs to make in order to make LCM or other LoRA adaptations work.To me this is alchemy. reply yorwba 12 hours agorootparentFinetuning and LoRAs both involve additive modifications to the model weights. Addition is commutative, so the order in which you apply them doesn&#x27;t matter for the resulting weights. Moreover, neural networks are designed to be differentiable, i.e. behave approximately linearly with respect to small additive modifications of the weights, so as long as your finetuning and LoRA change the weights only a little bit, you can finetune with or without the LoRA, respectively train the LoRA on the finetuned model or its base, and get mostly the same result.So this is something that can be somewhat explained using not terribly handwavy mathematics. Picking hyperparameters on the other hand... reply rq1 10 hours agorootparentThis is trivially not true.Pick eg. x -> sin(1&#x2F;x) around zero and its derivatives.The small modifications that you’re talking about are on the argument. These can lead to huuge changes in the values.The stability is more likely due to the diffusive nature of the models and well executed trainings. reply kelseyfrog 9 hours agorootparentI don&#x27;t recall SD or variants using discontinuous terms like 1&#x2F;x. Sigmoid, softmax, and SiLU are going to be what you&#x27;re looking for. reply rq1 9 hours agorootparentThey don’t use them indeed. I was replying to the general idea about the additions.OTOH Gaussian kernels smoothen almost everything. Maybe it will be stable even with sin(1&#x2F;x) as an “activation”. reply yorwba 4 hours agorootparentIf you want to use a counterexample to refute the general idea about additions, you need to pick one that fulfills the preconditions, like being differentiable. x → sin (1&#x2F;x) is not differentiable at 0 and for any other value where it is differentiable, there&#x27;s a small ɛ and a linear function L such that for all a and b somehow that produces coherent resultswith or without finetuning? Also is there a practical motivation for creating them? reply keonix 15 hours agorootparent> with or without finetuning?With, but it&#x27;s still bonkers that it works so well>Also is there a practical motivation for creating them?You could get in-between model sizes (like 20b instead of 13b or 34b). Before better quantization it was useful for inference (if you are unlucky with vram size), but now I see this being useful only for training because you can&#x27;t train on quants reply ShamelessC 9 hours agorootparent> With, but it&#x27;s still bonkers that it works so wellEhhhh… reply temp72840 15 hours agoparentprevThis is nuts. I did a double take at this comment - I thought you must have been talking about LoRAing a LCM distilled from Stable Diffusion.LCMs are spooky black magic, I have no intuitions about them. reply ttul 14 hours agorootparentWhen I was taking Jeremy Howard’s course last fall, the breakthrough in SD was going from 1000 steps to 50 steps via classifier-free guidance, which is this neat hack where you run inference with your conditioning and without and then mix the result. To this day I still don’t get it. But it works.Now we find this way to skip to the end by building a model that learns the high dimensional curvature of the path that a diffusion process takes through space on its way to an acceptable image, and we just basically move the model along that path. That’s my naive understanding of LCM. Seems to good to be true, but it does work and it has a good theoretical basis too. Makes you wonder what is next? Will there be a single step network that can train on LCM to predict the final destination? LoL that would be pushing things too far.. reply hadlock 13 hours agorootparentSounds like we&#x27;ve invented the kind of psychic time travel they use in Minority report. Let me show you right over to the Future Crimes division. We&#x27;re arresting this guy making cat memes today because the curve of his online history traces that of a radicalized blah blah blah reply smusamashah 14 hours agoparentprevOk. I have seen the term LCM Lora a number of times. I have used both stable Diffusion and LORAs for fun for quite a while. But I always thought this LCM Lora is a new thing. It&#x27;s simply not possible using current samplers to return an image under 4 steps. What you are saying is that just by adding a Lora we can get existing models and samplers to generate a good enough image in 4 steps? reply jyap 14 hours agorootparentYes check out this blog post: https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;lcm_loraI’ve used it with my home GPU. Really fast which makes it more interactive and real-time. reply catwell 13 hours agorootparentprevIt&#x27;s a different sampler too. reply esafak 11 hours agoparentprevThis is what happens when praxis runs ahead of theory. reply GaggiX 15 hours agoparentprev [–] lcm-lora-sdv1-5 is 67.5M, lcm-lora-sdxl is 197M, so they are much smaller than the entire model, would be cool to check the rank used with these LoRAs tho reply liuliu 12 hours agorootparent [–] 64. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Abubakar Abid has launched a new product called Blazing Fast LCM Lora SD 1.5.",
      "The product is designed to generate images rapidly.",
      "It can be easily tested in a browser."
    ],
    "commentSummary": [
      "The summary provided is deemed insufficient due to fragmented and incomplete information.",
      "Significant details are missing, making it challenging to create a concise summary.",
      "Further clarification or additional details are required to generate an accurate summary."
    ],
    "points": 167,
    "commentCount": 26,
    "retryCount": 0,
    "time": 1699804486
  },
  {
    "id": 38239640,
    "title": "Apple's Control Over iPhone Repairs Sparks Right to Repair Debate",
    "originLink": "https://www.nytimes.com/2023/11/12/technology/iphone-repair-apple-control.html",
    "originBody": "Credit... By Jackson Gibbs SKIP TO CONTENT SKIP TO SITE INDEX Section Navigation You Paid $1,000 for an iPhone, but Apple Still Controls It The company codes its devices with software that complicates repairs by triggering safety warnings and malfunctions. Credit... By Jackson Gibbs Share full article 144 By Tripp Mickle, Ella Koeze and Brian X. Chen Tripp Mickle, Ella Koeze and Brian X. Chen spoke to people with years of experience repairing iPhones. Nov. 12, 2023 For a decade, it was easy to get help repairing an iPhone. Cracked screens could be replaced in minutes, and broken cameras could be exchanged without a hitch. But since 2017, iPhone repairs have been a minefield. New batteries can trigger warning messages, replacement screens can disable a phone’s brightness settings, and substitute selfie cameras can malfunction. The breakdowns are an outgrowth of Apple’s practice of writing software that gives it control over iPhones even after someone has bought one. Unlike cars, which can be repaired with generic parts by auto shops and do-it-yourself mechanics, new iPhones are coded to recognize the serial numbers for original components and may malfunction if the parts are changed. This year, seven iPhone parts can trigger issues during repairs, up from three in 2017, when the company introduced a facial recognition system to unlock the device, according to iFixit, a company that analyzes iPhone components and sells parts for do-it-yourself repairs. The rate at which parts can cause breakdowns has been rising about 20 percent a year since 2016, when only one repair caused a problem. In a series of tests, iFixit determines which parts cause issues when swapped between working iPhones of the same model. The results reveal that the number of malfunctions has increased with later iPhone generations. Parts-pairing issues are more common in newer iPhones Red Fill Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Yellow Fill Sometimes stops working as expected when swapped, sometimes fine. Persistent alerts after swap. Year iPhone Face ID or Touch ID sensor Display Battery Front facing camera Taptic Engine (vibration) Rear camera LIDAR (distance sensor) 2023 15Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Sometimes stops working as expected when swapped, sometimes fine.Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. 2022 14Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Sometimes stops working as expected when swapped, sometimes fine.2022 SE (v3)Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone.2021 13Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Sometimes stops working as expected when swapped, sometimes fine.2020 12Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Sometimes stops working as expected when swapped, sometimes fine.2020 SE (v2)Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone.2019 11Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Sometimes stops working as expected when swapped, sometimes fine.2018 XS/XRPart doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Sometimes stops working as expected when swapped, sometimes fine.2017 XPart doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone.Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. 2017 8Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone. 2016 7Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone.2016 SEPart doesn’t work as expected when swapped with the same working part from an identical, new iPhone.2015 6sPart doesn’t work as expected when swapped with the same working part from an identical, new iPhone.2014 6Part doesn’t work as expected when swapped with the same working part from an identical, new iPhone.2013 5sPart doesn’t work as expected when swapped with the same working part from an identical, new iPhone.2012 5Note: Data reflects the iOS update 17.1; tested on Oct. 29, 2023. For the iPhone 15, only the Pro Max version has been tested. LIDAR is available only in the Pro and Pro Max versions of each applicable phone. Source: iFixit The software phenomenon, which is known as parts pairing, has encouraged Apple customers to turn to its stores or authorized repair centers, which charge higher prices for parts and labor. In recent years, only approved parts and sanctioned repairs have avoided the problems. Replacing a shattered screen typically costs nearly $300, about $100 more than work done by an independent shop using a third-party screen. To put it another way: The cost of replacing a cracked screen on a year-old iPhone 14 is nearly equivalent to the phone’s value, which Apple appraises at $430 in trade-in credit. Apple’s grip on the repairs creates an incentive for customers to spend up to $200 on device insurance, known as AppleCare, which provides free battery replacements and screen repairs. Apple collects an estimated $9 billion annually for the service. It has also spurred questions about Apple’s commitment to sustainability, with independent repair advocates saying the company could more effectively meet its goals of reducing carbon emissions by lowering repair costs to encourage people to maintain devices rather than buy new ones. An Apple spokesman said the company supported a customer’s right to repair a device and had created a self-service repair program to help. “We have been innovating to offer our customers the best choice and options when their product needs service,” he said. State lawmakers from New York to California have responded with laws that aim to make repairs easier. The Biden administration has encouraged the Federal Trade Commission to advance rules that would stop smartphone makers from restricting independent repairs. But most of the regulations don’t include explicit restrictions on parts pairing. Source: iFixitNote: Phones are not shown to scale. The iPhone 15 shown is a Pro Max. The Taptic Engine sometimes stops working when replaced and sometimes does not. Logic board The logic board is connected to all parts in an iPhone so, replacing it triggers any parts-pairing issues a phone may have. Home button Source: iFixitNote: Phones are not shown to scale. The iPhone 15 shown is a Pro Max. The Taptic Engine sometimes stops working when replaced and sometimes does not. Front-facing camera and Face ID sensor Logic board (will set off all parts-pairing issues) Battery Display Source: iFixitNote: Phones are not shown to scale. The iPhone 15 shown is a Pro Max. The Taptic Engine sometimes stops working when replaced and sometimes does not. Logic board (will set off all issues) Front-facing camera and Face ID sensor Rear camera Display LIDAR (distance sensor) Battery Taptic Engine (vibration) Source: iFixitNote: Phones are not shown to scale. The iPhone 15 shown is a Pro Max. The Taptic Engine sometimes stops working when replaced and sometimes does not. The iPhone 7, released in 2016, has been lauded as the last easily repairable model. Image of an iPhone 7, with the front display removed, revealing the inner parts of the phone. It has only one function — Touch ID — that stops working when the home button of the phone is replaced in a non-Apple-authorized repair. Image of an iPhone 7, with the front display removed, revealing the inner parts of the phone. The home button and the logic board are highlighted, indicating that if either were replaced, some function of the phone would stop working properly. The release of the iPhone X in 2017 represented a significant shift in the design of iPhones. Parts pairing increased, and more parts, including the front display and the front-facing camera, stopped working correctly when replaced. Image of an iPhone X, with the front display removed, revealing the inner parts of the phone. More parts are highlighted to indicate which would cause issues if replaced. Apple’s latest phone, the iPhone 15, has more features and, with them, more parts pairing. Image of an iPhone 15 Pro Max, with the front display removed, revealing the inner parts of the phone. Even more problematic parts are highlighted than on the iPhone X. Using software to control repairs has become commonplace across electronics, appliances and heavy machinery as faster chips and cheaper memory turn everyday products into miniature computers. HP has used a similar practice to encourage people to buy its ink cartridges over lower-priced alternatives. Tesla has incorporated it into many cars. And John Deere has put it in farm equipment, disabling machines that aren’t fixed by company repair workers. Apple and other companies have defended the practice by saying it protects customers’ safety and the company’s brand. Shoddy parts, like a faulty face scanner, could compromise the phone’s security, and if an independent shop messes up a repair, the customer often blames Apple instead of the shop, the company has said. The practice also allows Apple to create a record of parts in the device, which can be helpful to buyers of secondhand phones. But the increase of pairing parts with software has animated a movement that wants to make repairs cheaper and easier. Proponents, which include iFixit, say it would be better for the environment and customers’ wallets to extend the life of devices. They have urged lawmakers to simplify repairs, asking: “Who owns the device after it’s been purchased? The customer or the manufacturer?” “You basically have to ask permission before doing a repair,” said Nathan Proctor, who has lobbied states for repair legislation on behalf of U.S. PIRG, a nonprofit largely funded by small donors. When Apple expanded its software limits in 2017, it upended repair businesses. Shakeel Taiyab said iPhone repairs at his independent shop in South San Francisco had decreased about 15 percent this year. Some customers with issues like cracked screens keep using the phones because they find repairing or replacing it unaffordable. Free Geek, a nonprofit based in Portland, Ore., that donates repaired computers and smartphones to underprivileged people, decided that Apple’s software made iPhones too difficult to service, said Amber Brink, Free Geek’s director of technology. Last year, Free Geek received thousands of donated iPhones but repurposed only 280, Ms. Brink said. “It’s a headache,” she added. Consumers who opt against paying top dollar for an Apple-authorized repair may suffer the consequences. In February, after Gio Grimaldi, a 15-year-old in New Hampshire, shattered the screen of his iPhone SE on a snowboarding trip, he took it to a nearby repair shop. He said the closest Apple Store was 90 minutes away and had quoted $130 for replacing the screen — 40 percent higher than the independent store. When he took the phone home, it worked fine but was lacking True Tone, a software feature that adjusts the screen’s brightness and color to match the ambient lighting. “That’s just plain stupid,” he said. “I always love Apple as a company, but they’re really stuck up about third-party repairs.” Over the past year, New York, Minnesota and California passed bills requiring that electronics manufacturers provide parts, tools and manuals to third parties. After years of lobbying against such rules, Apple signed on to support California’s law and honor it across the United States. It has also encouraged the federal government to adopt similar rules, said Brian Naumann, the head of Apple’s repair service efforts, who spoke about the right to repairs during a White House event last month. “Apple has taken significant steps to expand options for consumers to repair their devices, which we know is good for consumers’ budgets and good for the environment,” Mr. Naumann said. But the California legislation failed to directly address Apple’s practice of using software to control the repair process. In Oregon, State Senator Janeen Sollman, a Democrat representing an area outside Portland, is part of a group of lawmakers aiming to pass a state law that would prohibit Apple and others from having restrictions on repairs. As the Oregon legislation has progressed, Apple has encouraged lawmakers to scale it back. Apple paid for a half dozen legislators to visit its Silicon Valley headquarters this year, and tried to impress on them how important security and safety were to repairs, Ms. Sollman said. She left California unpersuaded. “I said, ‘You’re making it more accessible, but it’s not a true right to repair if you have ultimate control,’” Ms. Sollman said. Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. His focus on Apple includes product launches, manufacturing issues and political challenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot taxis. More about Tripp Mickle Ella Koeze is a reporter and graphics editor for the Business section. She previously worked at FiveThirtyEight. More about Ella Koeze Brian X. Chen is the lead consumer technology writer for The Times. He reviews products and writes Tech Fix, a column about the social implications of the tech we use. More about Brian X. Chen 144 Share full article 144 Tech Fix: Solving Your Tech Problems Brian X. Chen, our lead consumer technology writer, looks at the societal implications of the tech we use. ‘Free’ iPhone Promotions: The so-called iPhone giveaways marketed by Verizon, T-Mobile and AT&T can make customers spend more on perks they don’t need. Google’s Pixel 8: The smartphone lets you use A.I. to add or remove elements from your images. It’s not clear we really need this. Meta’s Quest 3: The headset lets people see the outside world while immersed in virtual reality. The benefits are to be determined. ‘What Did He Just Say?’: Dialogue on streaming platforms is rarely crisp and clear because of myriad factors at play. Here are some ways to improve your experience. Venmo: The mobile wallet service is a cautionary tale of how apps may be exposing more information than you would like. Here is how to protect your data. Weather Tech: If you live in an area that’s prone to extreme weather events, it helps to be ready. These apps and tools can help. ADVERTISEMENT SKIP ADVERTISEMENT",
    "commentLink": "https://news.ycombinator.com/item?id=38239640",
    "commentBody": "You Paid $1k for an iPhone, but Apple Still Controls ItHacker NewspastloginYou Paid $1k for an iPhone, but Apple Still Controls It (nytimes.com) 165 points by giuliomagnifico 22 hours ago| hidepastfavorite208 comments daft_pink 19 hours agoparentThe reason I think users don&#x27;t mind Apple&#x27;s control of their devices is that the reality is that users don&#x27;t control devices, programmers do. Also, security requires constant updates and updates cost money, so it&#x27;s not realistic to use a device for a decade, because you won&#x27;t have security updates from any company at that point. Apple has better updates over time, which is reflected in it&#x27;s higher resale values.So on my iPhone, I feel that Apple protects us from bad programmers for the most part, because if you look at Android and the lower quality of many of their apps and the way large tech companies run over the users by installing spyware on their devices, but Apple to some extent is protecting us from Facebook and Google and keeping us more in control of our devices, by limiting which applications can be run on them. reply thfuran 19 hours agoparent>Also, security requires constant updates and updates cost money, so it&#x27;s not realistic to use a device for a decade, because you won&#x27;t have security updates from any company at that pointWhy can&#x27;t someone exchange money for a service they find valuable? As I understand it, that has long been a common practice. reply FirmwareBurner 19 hours agorootparent>Why can&#x27;t someone exchange money for a service they find valuable? As I understand it, that has long been a common practice.[lifts hand up] Uh-uh, me, pick me: because most consumers have been trained and conditioned by corporations that they only pay for the HW, the thing that they can feel and resell, and that the SW running on it should come for free and always be free despite SW updates being a continuous effort that costs money.Most consumers can&#x27;t put a value on SW ownership, unless that SW is a video-game on a disc in their hand. Thanks to Google, Youtube, etc, we&#x27;ve grown to expect that everything digital of value should be free even though it&#x27;s not. So ads it is. reply WirelessGigabit 14 hours agorootparentWhich is kinda weird. We used to have to pay for a new version of Windows or Mac OS (or however it was capitalized back then).Then it became free.When you got a computer with Windows 8 you would get 8.1 and 10 for free. 11 if you have the right TPM &#x2F; chip (doubtful). Same with Windows 10 to Windows 11, provided you meet the specs. Same with Mac OS (not versed enough to list the versions).I believe Apple started this yearly iOS update (and with that a more rapid deprecation).I don&#x27;t think people would want to spend $1,200 on a phone knowing they have to pay each year for a software upgrade. They also would not spend $1,200 on a phone knowing that next year you have to BUY a new one to get the latest software.And in Apples mind all of this is fine. iOS has the highest adoption of the last iOS version. So in terms of non-security bugfixes they can focus on the last version. Only security fixes might warrant an update for an n-1 version of iOS. reply WWLink 8 hours agorootparentThe problem with this is that you need to make those updates something people want to buy. And at some point, you have a game of diminishing returns. Even the hardware is starting to feel that way.Yet, security updates aren&#x27;t \"free\". I&#x27;d guess that keeping an OS secure is probably more expensive than developing new features. That part gets tricky.Also, supporting 5+ year old hardware gets harder since that hardware stops getting made and the new stuff gets more and more different. reply brandensilva 15 hours agorootparentprevYup the software side has been built into the pricing of the hardware. They weren&#x27;t the first to do this either since this business model has been around for quite awhile since we got away from buying software as a box.It&#x27;s also more convenient for the consumer to have a one and done payment.The only thing I wish is if there was a monthly maintenance package when my devices get older so I can keep getting updates that keep my device running fast, secure, and can maintain some form compatibility with most apps. reply bigboy12 16 hours agorootparentprevIf people are complaining then just don’t buy the phone!! Problem solved. reply CivBase 19 hours agoparentprev> Also, security requires constant updates and updates cost money, so it&#x27;s not realistic to use a device for a decade, because you won&#x27;t have security updates from any company at that point. Apple has better updates over time, which is reflected in it&#x27;s higher resale values.I&#x27;m absolutely still using PCs from over a decade ago and I&#x27;m still getting security updates. reply FirmwareBurner 19 hours agorootparentYou&#x27;re getting updates for PCs over 10 years old because thanks to the way IBM PC clones work, the OS kernel can be independently updated from the drivers of the peripherals, not tied to them as it is in the ARM ecosystem with obscure FW blobs that are tied to the interfaces of a particular Android&#x2F;Linux version.On Widows at least, drivers from the Windows Vista days still work just fine on Windows 11 as the ABI hasn&#x27;t changed that much since then. Good luck with that on Android. reply CivBase 19 hours agorootparentSounds to me like a design problem, not a justification for letting companies maintain control over the goods purchased from them. reply FirmwareBurner 18 hours agorootparentSure, but since time immemoriam this has been left to the \"free market\" to sort itself out, and the \"free market\" has let us to this point.Should some government regulatory body like the EU intervene to force their hand? Maybe.But do remember that in the \"old-days\" of dumbphones and featurephones you were getting no SW updates at all ever and replacing your phone every 2-3 years was the norm back then.It&#x27;s only now that we&#x27;re thinking about this as we start to think about phones more as general purpose computers in our pocket and less as phone dialing and messaging devices, like in the old days.One thing&#x27;s for sure, it&#x27;s that the free market will never self regulate itself on this matter, same how it has not self regulated itself in the auto industry were it not for the EPA and EU, we&#x27;d still be buying ICE cars that turn our cities into smog if we were to leve emissions to the auto manufacturers. reply tortoise_in 17 hours agorootparentprevLineageOs reply gigel82 16 hours agoparentprev> but Apple is ... keeping us more in control of our devices, by limiting which applications can be run on themHoly Stockholm syndrome level of cognitive dissonance batman! reply brandensilva 15 hours agorootparentLol major distopian vibes. \"The government keeps me safe by preventing me from doing anything against the law (that they decide at their own free will). I love my brain chip.\" reply paulmd 6 hours agorootparentWhy wouldn’t anyone love their brain chip? You’d obviously be programmed to. reply jstarfish 14 hours agorootparentprevHaha. It&#x27;s worded very poorly (\"safe from\" != \"in control of\") but they are not wrong.The whitelist approach to security has its merits. reply missingrib 8 hours agorootparentprevIt&#x27;s true though. Not us in particular, but 99% of smartphone users reply seanmcdirmid 8 hours agoparentprevAlso, the people mostly burnt by this are thieves who can only sell stolen iPhones for spare parts. To people who actually by their phones, this is a feature, not a bug. reply lovelyviking 9 hours agoparentprev>Apple to some extent is protecting us from Facebook and Google and keeping us more in control of our devices, by limiting which applications can be run on them.Right, Including protecting me from me unless I find extra pleasure in ‘calling big fruit boss every few days’ for running my own soft on my (supposedly) own phone.To avoid this ‘pleasure’ I have to pay developer fee yearly. If someone is looking for definition of ‘idiocy’ one should look no further.Yet there is always someone trying to justify even that. ‘It is more secure ‘ - they usually say forgetting to mention that security starts with control and ends without it.The obvious question to ask usually would be:So who would protect you from Apple itself?More entertaining question could be: Who is going to protect you from you?But then we recall about AI and we can guess the answer which spoils the whole entertaining aspect of the question.So the only question left is: What people would not justify when some big company does it? reply foogazi 9 hours agorootparent> So who would protect you from Apple itself?Pick your poison, right ?Someone is in control of the machine and it’s not me since I didn’t make itI don’t know who you are so I don’t trust youThus I pay to live inside the walled gardenIs it total freedom ? No, but it’s reasonable enough for me and my family reply lovelyviking 8 hours agorootparentPick your poison, right ?Right as long as you know what poison you choose. At least control someone who controls your machine, including the building process.>Thus I pay to live inside the walled gardenAt the moment it’s more like you pay for garden with imaginable walls while in reality there are no walls and frankly it doesn’t look like garden at all.The only real wall you face is when you are trying avoid living in this fantasy. There is more precise definition for such ‘garden’ - starts with prison. Is it total freedom ? no, but it seems it’s reasonable for …. I barely see something reasonable about it. It’s more like a luck of wish to stand for own dignity thinking that such stand is possible to avoid.When people (some people) thought sharing some data is not a big deal in current conditions. Did they think about another situation when current form of AI is around? Did you think about changes of the environment when you wrote ‘ it’s reasonable enough’? You didn’t even add ‘for now’ suggesting of course you know everything that ‘now’ is happening. And you even ready to expand this vision to whole family? I wish to be that sure about the future.I am not trying to attack you personally, I think it is very common ‘logic’ these days except I cannot see it as logic at all. reply badpun 14 hours agoparentprev> security requires constant updates and updates cost moneySecurity doesn&#x27;t require constant updates if the software they shipped didn&#x27;t have bugs in the first place. These updates are just fixing faults in software that I&#x27;ve already paid for. Similarly, if I buy a car that made have the airbags explode for no reason, the car is recalled and the airbags are replaced for free. reply JumpinJack_Cash 17 hours agoparentprev> > I feel that Apple protects us from bad programmers for the most partOh poor thing. They protect themselves and software houses from torrent-esque and crack-esque like solutions which can be easily found for everything that runs on Windows, including Office, not to mention the Windows OS itself and everything Android.That&#x27;s also the reason why Apple dominates the US market whereas Android has the majority of devices elsewhere in the world.Americans will fight between each other with hordes of lawyers at the cost of thousands of dollars for the stupidest things, but won&#x27;t spend 30 seconds torrenting in order fuck Hollywood,Amazon, Netflix and Microsoft in the ass.When you ask the reason why, their reply is : &#x27;convenience&#x27;When you ask why they fight for the stupidest things against fellow citizens using hordes of lawyers at the cost of thousands of dollars the reply is: &#x27;To prove a point&#x27;Bizzarre reply gamblor956 13 hours agorootparentAmericans actually like to pay people for the work they do...it may be bizarre, but it&#x27;s part of why America has the world&#x27;s strongest economy.Huh. How about that. A country of people who don&#x27;t just think they&#x27;re entitled to the labor of others. reply FireBeyond 16 hours agorootparentprev> They protect themselves and software houses from torrent-esque and crack-esque like solutions which can be easily found for everything that runs on Windows, including Office, not to mention the Windows OS itself and everything Android.It&#x27;s extremely easy to find pirated software for macOS, too. Let&#x27;s not pretend that Windows is Skid Row and macOS is a pristine gated community. reply JumpinJack_Cash 16 hours agorootparentmacOS is not how Apple makes money, they make money with iOS as per the article reply hoppyhoppy2 21 hours agoparentprevGift Article link: https:&#x2F;&#x2F;www.nytimes.com&#x2F;2023&#x2F;11&#x2F;12&#x2F;technology&#x2F;iphone-repair-... reply emmet 21 hours agoparentprevAnecdotal, but back in those \"good old days\" when you could get a screen replaced in 5 mins like this article said, on the three occasions I did this I ended up with the worst cheap Chinese knock off screens I have ever seen, the last time I ended up spending even more to get a genuine one.Hard to avoid this with small businesses when they need to make the enough of a margin at those cheaper retail prices.I&#x27;m sure this is fine for a lot of people, but I&#x27;m much happier to pay for AppleCare+ and get components that keep the experience that I&#x27;ve paid a grand for. reply nokya 20 hours agoparentI do not think this is a small business issue, but rather a dishonest small business owner working for disrespectful customers issue.A few months ago, I had to get a screen replacement and straight upfront asked the repair guy how much it would really (emphasized) cost me to get the screen replaced after he gave me a quote indicating that either the screen would cost nothing, or the work hours cost almost nothing.He smiled and admitted getting the original replacement unit would almost double the quote he had just given me, plus I&#x27;d have to wait a week until the unit arrives. I told him that&#x27;s what I wanted.Eventually, the repair cost me a bit more than double what he asked first. But I am satisfied, I noticed no defaults at all on my phone since the repair, it feels exactly like the original model. He cleaned it, and installed a screen protector on it (offered).This is clearly a case of \"theory built on one single personal experience\", I agree. But honestly, I don&#x27;t know anyone around me who would agree to pay a bit more just to get better service and I think that&#x27;s the core issue. reply Tade0 19 hours agorootparentWhen I called to ask for a quote when the screen on my phone cracked, the repair guy said upfront that it&#x27;s going to cost more than a used phone of the same model.To that I replied that this is fine, brought the phone, got a loaner free of charge (probably because the guy saw that I came in with a flip phone as replacement) and the next day it was ready for pickup.Honest business, five stars.I think they get rid of a lot of troublesome customers by persuading them to just get a new phone instead. reply jqpabc123 18 hours agorootparentprevI don&#x27;t know anyone around me who would agree to pay a bit more just to get better service and I think that&#x27;s the core issue.The core issue is that Apple has restricted your ability to *choose* to pay less or go elsewhere --- without disclosure or consent. reply makeitdouble 21 hours agoparentprevIt&#x27;s interesting you underline the knock off is Chinese, when half of the high quality genuine Apple parts are also Chinese.At this point I&#x27;d be more wary of a non Chinese parts for many of the replacements. reply gkanai 20 hours agorootparentThere&#x27;s a significant difference between a Chinese-made Apple OEM part and an aftermarket low-cost Chinese part. reply elcomet 20 hours agorootparentWhich is why it makes no sense to say \"Chinese\" to mean low quality reply nottorp 20 hours agorootparentThe Chinese will make a part exactly as good as you pay them to make it. reply makeitdouble 19 hours agorootparentI&#x27;m having a hard time trying to find a country with a reputation of consistently underpricing their electronics parts.Perhaps one would do that to get its name on the map as a newcomer, but soon enough investments need to be repaid and the prices would naturally raise up to match the increase in reputation and pad the margins. reply emmet 20 hours agorootparentprevHence my specifying knock off. 3rd party repair shops aren&#x27;t buying their parts from Belgium or Fiji reply ponorin 21 hours agoparentprevin your case you got screwed up bc you got a bad part, but you&#x27;re saying your solution to that is to screw everyone by disallowing even genuine parts for repair not blessed by apple? reply emmet 21 hours agorootparentDidn&#x27;t say that! Just that my past experience with 3rd party repair has been poor reply sigmar 20 hours agorootparentWasn&#x27;t this partly by Apple&#x27;s own making? Apple shreds devices to prevent people from salvaging parts for repairs[1], even phones that were usable[2]. and hasn&#x27;t sold genuine components until very recently.[1] https:&#x2F;&#x2F;www.vice.com&#x2F;en&#x2F;article&#x2F;yp73jw&#x2F;apple-recycling-iphon... [2] https:&#x2F;&#x2F;www.washingtonpost.com&#x2F;technology&#x2F;2020&#x2F;10&#x2F;07&#x2F;apple-g... reply jwells89 19 hours agorootparentUse of knockoff parts will occur no matter what Apple does because those parts are always going to be cheaper.That said, I think maybe the solution may be closer to something like allowing fake parts to function when placed in iPhones, with a couple of caveats:- A prominent top level section in Settings appears listing all non-genuine parts- When the phone has been factory reset, an alert appears at the bottom of the “welcome” screen and can be tapped to view the same list as above, so any prospective buyers of the device know exactly what they’re buying (and hopefully, can negotiate a better price as a result)This addresses the cases of both dishonest shops and dishonest sellers trying to pass off the used devices they’re selling as fully genuine.As for parts in used phones, I think those should remain device-locked until the user has explicitly unlocked them with a process that requires a second confirmation from the user after a week with a code sent by snail mail so thieves can’t coerce victims into part unlocking. reply mindslight 18 hours agorootparentThe auto repair industry has been getting along just fine with aftermarket parts in the mix. As a customer you have a choice, and need to be aware that the choice exists to competently engage with the market. Being slightly informed about the high level aspects of an industry you&#x27;re interacting with is just part of being an adult. If you don&#x27;t want to have a frank conversation with a repair shop about which aftermarket parts are adequate and which are less than ideal, then you can always overpay for the whole job at a dealership to avoid breaking the illusion.From what I understand, getting to this point has been a long fought battle of pushing manufacturers to open up parts availability and basic documentation (which continues to this day with Automotive Right to Repair and whatnot), Magnuson-Moss on the legal front, etc. Apple is at the early stages of its industry, and due to the power of digital restrictions technology has delusions of completely shutting out the third party ecosystem. But in a free society there&#x27;s only one way for this topic to evolve, and so the authoritarian arguments about the guarantees of centralized control aren&#x27;t particularly compelling. reply jwells89 17 hours agorootparentThe question is, how do we go about making sure that the general public as a whole is aware of the choice? For phones it seems like more of an uphill battle because people generally don’t think a whole lot about the quality of the parts going into their electronics repairs and the quality of the repair work itself until they’ve had some kind of disaster (phone catching on fire or something), whereas it’s more of a consideration for cars (perhaps due to the price difference or obvious mechanical nature of cars).At the very least though, I do think that buyers of used phones deserve to know what kind of parts were used in repairs. On cars this can be verified by looking up the car’s service records and taking it to a trusted mechanic prior to purchase but it’s not so simple with phones, which is where I think it could be useful for the OS to indicate use of aftermarket parts. reply theshrike79 17 hours agorootparentprevThe scale of operation you need to steal and sell cars for parts or sell stolen cars is in a different order of magnitude in difficulty than doing the same for phones.We are at a stage where the only ones stealing Apple devices are the ones too stupid to know they’re next to impossible to resell and the ones that are really good and know exactly what they’re doing. reply mindslight 14 hours agorootparentDiscouraging theft by getting rid of individual ownership seems like throwing the baby out with the bath water. reply theshrike79 13 hours agorootparentWe have a different view of \"individual ownership\".You probably see smartphones like computers, but I think they&#x27;re more like game consoles.I don&#x27;t complain to Microsoft because I can&#x27;t install Arch or sideload games on my Xbox.I&#x27;m perfectly fine not being able to install random applications on my phone if in exchange it becomes a harder target for malware and unappealing to thieves. replycameronh90 21 hours agoparentprevOne of the reasons I switched to iPhone was that Google only does their repairs here through third parties. Even though it was with official parts, the repair quality was never great and it often needed to be manually calibrated or go in for another repair to fix the things they broke in the first repair. My experience (YMMV!) with AppleCare has always been stellar. reply tekchip 21 hours agorootparentYMMV indeed. How does it go for folks who buy a device second hand, beyond apple care, perhaps because they can&#x27;t afford Apple&#x27;s first hand prices. No one is saying Apple shouldn&#x27;t provide Apple care or first rate service within coverage. This is about a broader picture. As noted in the article Apple knows how long Apple care extends for any given device, and if components have been replaced. It would be fairly easy for them (and their gobs of money) to perhaps do something equitable like disable the replaced parts warnings once a device leaves apple care. IMO they shouldn&#x27;t display those at all but in the interest of equity and compromise I&#x27;d settle for removal after Apple has self selected not to \"care\" about the device anymore. reply cameronh90 20 hours agorootparentNot really defending it as such, just offering my experience.That being said if I was trying to see it from Apple’s perspective, it does address a lot of problems pretty easily: thieves breaking devices down for parts or coercing users, customers having issues with their devices due to low quality repairs, users buying second hand phones with unofficial parts, various security concerns, etc. Apple do also sell old and refurbished devices also.That being said, I do think Apple should be solving this in a way that allows unofficial repairs, even if that involves taking your ID and proof of purchase into an Apple Store to get your device “unlocked” for free so you can do whatever you want with it, knowing it may hurt the resale value and impact the device’s security. More than that, I think it should be legally required under right to repair legislation. reply TexanFeller 16 hours agorootparentprev the worst cheap Chinese knock off screensMost of an iPhone is Chinese made reply SenAnder 16 hours agoparentprevDo you assume that Apple would be forbidden from offering repairs, if they stopped locking their hardware from the consumer?This is such a common comment in these kinds of threads: \"I&#x27;m happy with the choice they&#x27;ve forced on me, therefore the force itself is desirable.\" Like being happy your prison cell has a nice view. reply CivBase 19 hours agoparentprevImagine if Apple sold OEM parts at a reasonable price. Imagine if they weren&#x27;t pairing OEM parts to prevent repair shops from parting out broken devices. Imagine if they weren&#x27;t making deals with manufacturers to prevent the sale of standard parts to third parties - even parts with no Apple IP like the ISL9240 [0]. Imagine if they weren&#x27;t abusing Customs and Border Patrol powers to prevent distribution of legitimate parts via false acusations of counterfeiting [1]. Maybe then you could get a good screen from a small repair shop.It&#x27;s not about margin. It&#x27;s about parts availability.Apple stores are few and far between, but Apple products are ubiquitous. Official Apple repairs have them ship the device across the country to repair shops, which takes a lot of time. And they don&#x27;t do things like component-level repair (i.e. specific chips, resistors, and other board components). They just replace the entire board and charge you for the new one.An independent repair shop doesn&#x27;t have to compete on price. They can compete with fast turnaround, minimal travel, and component-level repairs. Or at least they could if they could get the parts.[0] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=lTpHa70DDX0&t=200[1] https:&#x2F;&#x2F;blog.giovanh.com&#x2F;blog&#x2F;2023&#x2F;10&#x2F;26&#x2F;apples-trademark-ex... reply vasdae 21 hours agoparentprevOf course they don&#x27;t use the same quality screens, because then the replacement would cost as much as it does in an apple store. reply emmet 21 hours agorootparentSorry yeah that was my point. I personally don&#x27;t find value in the cost saving. reply Krasnol 20 hours agoparentprevThis is SO WEIRD.I&#x27;ve seen this happen so many times around these discussions on HN:There is a valid argument in the source. There is discussion around the argument. There is some proof, there are political discussions. Etc. everything totally normal. But then there is this ONE comment. Usually just one:Anecdotal evidence to spread FUD. And it&#x27;s up above all that usually discussion.Where is this coming from? Is this natural behavior of people who are also afraid of the freedom to be able to buy parts elsewhere? Is this advertising? reply hotnfresh 20 hours agorootparentNah, it’s the kind of experiences you expect in a low-regulation market. You either pay a premium—beyond what would be justified if “defector” manufacturers and vendors weren’t a factor, i.e. if effectively-enforced regulations were mandating a higher quality floor—to a vendor with a good reputation you expect them to want to maintain, or you pay in expertise and time-cost. If you don’t pay in one of those two ways, you probably get screwed. Folks who already possess relevant expertise and have a hobby that looks a lot like the time-cost it takes to achieve the best measured-in-currency outcome in the above, may regard the situation as entirely fine. Folks with enough money not to care that simply paying for a decent product is priced above where it “should” be, also may not care. Everyone else just has to live with a bad situation, and sometimes people who’ve run into that post on HN. reply jwells89 19 hours agorootparentIt’s a bit surprising to me how little regulation there is concerning the quality of replacement electronics parts, especially those that handle power (battery, power delivery) which can be very dangerous when the wrong corners are cut. reply Krasnol 19 hours agorootparentprev> Nah, it’s the kind of experiences you expect in a low-regulation market.Nah, it&#x27;s not. The market for Android devices has been there for years and it works.Sure, you can be screwed over, like in everything in life, but it&#x27;s not such a common thing that it would make it an equally relevant argument against liberalization.I agree, though: people who can afford premium won&#x27;t bother. Neither with alternative ways nor with people who can&#x27;t afford premium. Maybe it&#x27;s even intended to keep the brand somehow exclusive and special...sad world. reply hotnfresh 19 hours agorootparent> Nah, it&#x27;s not.It’s what I’d expect, because that’s how most markets look to me—pay in time, overpay in money, or probably get crap—but perhaps experiences vary. reply Krasnol 19 hours agorootparentIn the fix-it market, you only not overpay.The rest is the usual price for parts and work. Like every normal service, too.No reason to deliver crap, as you want to have the customer recommend you and come back again if they have another issue. Since there are enough alternatives, you have to deliver. reply jqpabc123 20 hours agorootparentprevWhere is this coming from?My theory --- people have some sort of natural affinity toward cults. Even when it is counter to their own best interests.And Apple is approaching cult status. reply bandyaboot 20 hours agorootparentprev> Is this natural behavior of people who are also afraid of the freedom to be able to buy parts elsewhere?No…I doubt that’s it. reply nottorp 20 hours agoparentprevCommon misconception that hardware matters and thus we are not in a duopoly situation with Google and Apple being the only options for software.Doesn&#x27;t mean Apple aren&#x27;t -holes with repairs, but in my opinion the above software problem is worse. reply wahnfrieden 20 hours agoparentIt massively limits human creativity and productivity all for protectionism under the guise of safety reply JakeAl 17 hours agorootparentThey don&#x27;t care about safety they care about lock in to their ecosystem. I&#x27;m not into ANY of these ecosystems. I don&#x27;t want MSFT installing Edge ever, or OneDrive, or having Phone sync software on my PC that links my contacts to Office&#x2F;Outlook Online, or have Bing web search forced into my search bar or Google for that matter, ALL to track you and push ads on you from the people they get their money from.And don&#x27;t even get me started on cars tracking everything you do. In many cases you don&#x27;t have a choice. I want a smartphone that doesn&#x27;t lock me into all these ecosystems. I want a car that lets me turn off all tracking, bluetooth sensors to monitor my tire pressure, etc.The reality is people are stupid. They couldn&#x27;t manage using a computer safely so the industry gave them a phone and sold them on safety. The fact that something like 80% of people are getting their news on a phone and not a computer should tell people they are trapped in a bubble that controls what they see, know and think. What good is having a choice if you don&#x27;t know you have a choice? They simply want consumers. reply Terretta 19 hours agoparentprevHeadline is wrong. Market paid $1K for the iPhone experience.Look at ads: specs versus \"life goals\" enablement. This is not a hardware product or parts bin price.If you pay $1,000 for a meal, you damn sure expect the restaurant to control the experience since the price isn&#x27;t the cost of ingredients. And if you want to cook, that&#x27;s great, but you&#x27;re not getting to bring your own parsley, you hack together your own meal elsewhere.. . .Even if food became free, people would pay -- and pay well -- for the curated Michelin star experience.So how to learn to think more about the diner&#x27;s experience than the kitchen experience or the \"right\" to monkey with some other chef&#x27;s prix fixe menu, to better build that kind of user appreciation for one&#x27;s own product?For sure, a Michelin star is hard to achieve. reply goosedragons 19 hours agoparentThe article is less about Apple&#x27;s grotesque restrictions on what you can do with your hardware via software (e.g., no emulators, etc.) and instead about Apple&#x27;s grotesque restrictions regarding the parts you can use to fix your phone.I don&#x27;t think too many people want the restaurant to have a say on what side they make to go with their leftovers from the previous day. reply daft_pink 19 hours agorootparentBut the reality is that no ones going to spend $100 to fix a 10 year old phone, when you can&#x27;t get the security updates for it. Security updates cost money and programmers and the reality is that Apple is the best at security updates, but no one is really concerned about how to repair an iPhone in 10 years, because an iPhone is only realistically usable until the security updates run out. reply BiteCode_dev 19 hours agoparentprevI go to high end restaurants, the Michelin being the only north star I rely on in the day and age of fake reviews and terrible average consumer taste.Sure, I want the restaurant to control the initial offer, and at this price I expect it to be amazing.But I guarantee that at this price range, they will let me do what I want with my food.I can bring my own bottle of ketchup and put it on it. They will look disgusted, but I can.In fact, as a vegetarian, it&#x27;s not rare I ask them to adapt their ENTIRE menu just for little me. And they do it.So the comparison does not hold.But I get your point, a lot of people do want Apple to tell them how they should use their device.That&#x27;s something that is hard to swallow when you like FOSS, but it&#x27;s a reality. reply pierat 19 hours agoparentprevWow, such a ridiculous HN take.A top notch restaurant does not keep or retain ownership of your stomach, bowels, or shit after eating at their restaurant.Apple \"sells\" hardware in a completely fraudulent way, by retaining control as a rental or lease, but advertises it as a sale.You can play whatever word games and bad analogies, and they&#x27;re not even wrong. reply swasheck 19 hours agorootparentit’s more appropriate than you’re allowing it to be. your extension of the metaphor loses sight of the topic. the duration of the controlled experience of a meal is definitely shorter than the duration of phone ownership and so if you want to attack the metaphor based on duration and utility of the experience then that would be far more congruent reply pierat 18 hours agorootparentNo, again some garbage analogy is not even wrong.I buy hardware and pay money for a purchase.This purchase has remote control software that obeys the company, and not me, the owner.I cannot remove this remote control garbage.This makes the device a rental on the approval of Apple, and not myself, the legal owner.If I were to do this, I would be charged with felony hacking under CFAA and similar statutes.... But Apple sycophants defend these egregious behaviors. reply paulmd 6 hours agorootparent> sycophantsargument discarded for incivilitywhy is this so absolutely normalized? every single android user seems to have this dripping hatred for half of the population, and only waits for the perceived “proper company” to let the mask drop. Why is that so utterly normalized for android users?Obviously the fact that it’s normalized is self-reinforcing, people do it because they see other people doing it and it’s routinely allowed and tolerated. I will probably get my knuckles rapped more for saying this than you are for open bigotry.Over, I remind you, a fucking cellphone. You’re a bigot because other people chose a different cellular telephone. What a silly thing.Every single phone discussion has to have someone doing the “brainless apple sheep” or “people just buy for blue bubbles!” or “mindless apple sycophants!” routines. Every one. Even on hacker news of all places, where absolutely everyone has a very technical interest in this stuff, and good reasons for picking the things they do. replyroflc0ptic 21 hours agoparentprevhttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20231112101006&#x2F;https:&#x2F;&#x2F;www.nytim... reply oneplane 20 hours agoparentprevAt yet here we are with nobody having a better plan. The issue is still the same as it has been for the past 20 years: making a (PKI-based) security feature means you can never share the secret parts or make it optional, otherwise it is immediately defeated. You can&#x27;t have selective security where it works sometimes but not all the times. And trading out that security system is not an option.PKI specifically is an all-or-nothing scenario. This is all why Intel does the same with the ACM in all their CPUs. And AMD with their AGESA (which went closed a short while ago).There is only a single scenario I can think of where there might be a &#x27;have it both ways&#x27; situation, but it&#x27;s just worse than we have now: you have to identify yourself as the owner, the company has to keep track of that, and you can only sign public keys for your own components. This, however, creates two problems:1. A company keeping track of every user (no need to come up with a clever comment about \"they are already nothing that\")2. Users can be coerced (has already been done with thefts and activation locks) and this weakens the ecosystem as a wholeAt this point it doesn&#x27;t even matter how intentional or not digitally signing components is, it is an effective security model and it works better than anything else.Everyone loves complaining about everything they don&#x27;t like, especially on the internet, but so far the amount of realistic and effective solutions are NONE. reply AshamedCaptain 20 hours agoparent> At yet here we are with nobody having a better plan. The issue is still the same as it has been for the past 20 years: making a (PKI-based) security feature means you can never share the secret parts or make it optional, otherwise it is immediately defeated. You can&#x27;t have selective security where it works sometimes but not all the times. And trading out that security system is not an option.This is BS. A security system where the user is not in control of the secret is not a security system but DRM almost by definition. And trading it out is not only an option, but likely the preferred outcome if you ask the majority of buyers. reply MichaelZuo 19 hours agorootparentQuite a lot of people have a bonafide fear of their phone being stolen, especially when travelling and so on. reply oneplane 19 hours agorootparentprevIt seems you have no clue what you are talking about. A PKI where the CA private key is not secret is not really a PKI now is it?As for asking buyers: I doubt 0.001% of buyers in any market segments has a clue about PKI or public key cryptography at all. This is E2EE \"lets have a government back-door\" all over again: IT DOES NOT WORK. The Clipper chip was not that log ago, now was it? reply AshamedCaptain 18 hours agorootparent> A PKI where the CA private key is not secret is not really a PKI now is it?At the end of the day, _you_ are the one in control of the list of CAs that you trust. If you are, it is (maybe) security. If you aren&#x27;t, it is DRM. This is a simple rule with surprisingly little grey areas. See eIDAS...> I doubt 0.001% of buyers in any market segments has a clue about PKIDoes it really matter how is the DRM implemented? They don&#x27;t want to hear about Apple DRMing iPhone repairs, end of story.PKI is also not the only way to implement this. reply oneplane 15 hours agorootparentYou are confusing browser TLS and the trusted CA list with general CA in terms of PKI. So no, you are not in control and there is no list.> Does it really matter how is the DRM implemented?If you want to argue semantics instead of facts and merit: yes.> PKI is also not the only way to implement this.Yes it is. Unless you have some novel method you are about to disclose to the world, in which case, please do, because you&#x27;d have the equivalent of a cryptographic holy grail. reply wolfendin 19 hours agorootparentprev> And trading it out is not only an option, but likely the preferred outcome if you ask the majority of buyers.I’d bet if you ask the majority of buyers they wouldn’t know and wouldn’t care. reply rpdillon 19 hours agoparentprev> And trading out that security system is not an option.Why not? iPhones are premium tech-fashion items that attract criminals due to their value. Apple is trying to negate the value of the stolen item through DRM, but it seems perfectly reasonable for someone to say \"the solution is worse than the problem\", and opt to buy devices that don&#x27;t implement hardware DRM on e.g. their screens.> so far the amount of realistic and effective solutions are NONE.I&#x27;m not sure this is true...I&#x27;ve travelled a fair bit, and my approach to managing theft of my belongings is to limit the value of what I carry. This both limits the incentive for criminals (a $30 Tracphone is much less interesting than a $1000 iPhone) and limits the damage&#x2F;cost-to-recover in the case of theft. reply oneplane 15 hours agorootparentI don&#x27;t think I&#x27;ve touched on on theft as much as everyone else here seems to do, but in either case I&#x27;d still put that under the &#x27;trustworthy to a degree&#x27; umbrella. I want to trust that a device in a known state behaves in a known way. Or as some other people might perceive it: the thing should work and adversaries should not be able to make it un-work with great ease.This is something you could split up into multiple fractions:- Making theft less lucrative to the thief (by reducing the use to non-owners)- Making theft less impactful to the owner (by making non-owners not have access to the data)- Making interdiction and malware an expensive endeavour (by making it very expensive to modify the device without the owner knowing about it)Considering people may not want a $30 trackphone, but they just want their iPhone, the option of changing their behaviour is much less likely to be something Apple will invest in, and thus they invest in other things instead, like platform security. So if you assume that a consumer buys an iPhone because they want to, and assuming they want Apple to take care of making them not an easy target, we get into the current situation.You can also tack on the &#x27;haha apple expensive repairs they hate everyone&#x27; but there are much cheaper ways (for apple) to achieve that as a stand alone proposition. I&#x27;m sure they don&#x27;t mind the fat profits they get, even if it were just a side-effect, but I&#x27;m personally and professionally more concerned with the three points I listed earlier than anything else. reply ponorin 13 hours agoparentprevEvery people talking about theft security and counterfeit prevention is simply getting the point wrong.If \"counterfeit prevention\" system is complaining about a genuine part that literally came off of another genuine product, that&#x27;s not its actual job.If \"anti-theft\" system is trying to wrestle with the legitimate owner trying to fix their own product, that&#x27;s not anti-theft, or rather, the owner is not you. The owner is Apple, and that&#x27;s precisely what the article says.The \"security\" here is protecting Apple&#x27;s bottom line by ensuring you buy a new product for otherwise fixable damages.Just because it&#x27;s somehow more secure doesn&#x27;t mean it&#x27;s better for the consumer in any way. reply oneplane 8 hours agorootparentNone of your points stand.Counterfeit prevention is not just some sort of &#x27;this part is real but this other part is not&#x27;, it is about system integrity. How do we in the world of technology prove integrity? With cryptography. It&#x27;s the only thing we have.Same with your anti-theft proposition: if anyone can do whatever they want with my device, then nobody is deterred from stealing it.Same with security in the sense of interdiction, injection or extraction.None of these items, not a single one, can work without public-key cryptography. And until you (or someone else) comes up with a system where that does work, none of this matters and the status-quo remains as-is.And yes, all of this is better for the consumer, even if the 10 people who want to fiddle with their phone can&#x27;t do that without losing features. If you want a hackable device, get something else.I, for one, do not want just a device where practically anyone can manipulate it, even if that means I cannot manipulate myself it either.If you cannot come up with an argument that preserves integrity you don&#x27;t really have a point. reply ponorin 1 hour agorootparent> if anyone can do whatever they want with my device, then nobody is deterred from stealing it.did i say \"anyone\" should be able to change components? i didnt say anybody should be able to change components.> If you want a hackable device, get something else.iphone is a device made by human, iphone is already hackable (case in point, iphone usb-c mod or headphone jack mod). it&#x27;s just that apple&#x27;s lawyers would very much not have that.you just throw words like public key cryptography like it&#x27;s an axiom but the tool serves its purpose as much as it&#x27;s useful to us. you not caring about repairability doesn&#x27;t matter, you&#x27;re not apple anyway. people who got told their iphone cannot be recovered by apple but did get their data back thru 3rd party, does. (spoiler: it&#x27;s because this means apple lied about their product) reply billylo 21 hours agoparentprevI recently encountered a similar situation for my Macbook Pro. Touch ID sensor is paired specifically to your logic board. You must replace both if either one has a defect.Source: https:&#x2F;&#x2F;www.ifixit.com&#x2F;Guide&#x2F;MacBook+Air+13-Inch+Early+2020+... reply nikanj 19 hours agoparentI think this is an unavoidable side effect of Touch ID fully happening inside the module. The logic board has to have full trust of the module, because the module will simply inform the OS that fingerprint X was seen - the OS&#x2F;logic board have no way to confirm the information reply billylo 19 hours agorootparentIt’s their design choice.Most Windows laptop or Android phone do not have this hardwired coupling approach. reply natch 16 hours agorootparentYes design choice. Apple chose to design it for security. reply ponorin 17 hours agorootparentprevgoogle pixel does, but they did the unimaginable and released the tool where users can actually recalibrate the sensor. reply natch 16 hours agorootparentGoogle is not a good comparison, because Google engineering is inferior. reply ponorin 14 hours agorootparentThey suck at privacy, and they are indeed relatively new to hardware game, but I&#x27;d say they are better at security than you think, on par or even better than Apple. Like Apple SoC, it has a dedicated security chip. The new Pixel 8 even implements Memory Tagging Extension, which iPhone doesn&#x27;t yet have. And they do all this while allowing you to install third party rom. It&#x27;s how projects like GrapheneOS can exist. reply natch 12 hours agorootparentThey have security flaws that are 20 years old that could be solved by an 8 year old. reply nikanj 15 hours agorootparentprevWhich means, crudely simplified, that your biometrics can be extracted from an Android or a Windows. I’d prefer companies being extra paranoid about my biometrics, because they can’t be changed if they’re leaked reply InfamousRece 17 hours agoparentprevMost of the participants in this “Hacker” News thread are definitely not hackers ;) reply savanaly 16 hours agoparentAnd? reply thesuperbigfrog 20 hours agoparentprevDo you want to control your device or are you okay with someone else controlling it?https:&#x2F;&#x2F;youtu.be&#x2F;Ag1AKIl_2GM?t=57 reply wolfendin 19 hours agoparentAfter my phone was stolen (it went missing after a move and it was renamed) and I was able to to remote wipe and disable it, I am 100% okay with it. reply paulcole 20 hours agoparentprevMy iPhone works really well and I generally trust Apple. So I’m 100% fine with someone else controlling it. reply thesuperbigfrog 20 hours agorootparent>> My iPhone works really well and I generally trust Apple. So I’m 100% fine with someone else controlling it.The reality is that most people are choosing to let Apple or Google control their mobile devices.From what I have read, most free &#x2F; libre smartphones are not ready for consumer use. Are there are any \"good enough for grandma\" libre smartphones? reply mwint 19 hours agorootparentOne of my “good enough for Grandma” criteria is that she can’t click on a link in a Facebook post promising nine million Candy Crush points for installing an exfiltrate-all-the-data app from some App Store alternative. reply paulcole 16 hours agorootparentprev> From what I have read, most free &#x2F; libre smartphones are not ready for consumer useReplace “most” with “all” and you’re closer to the truth.Huge amounts of copium from anyone who thinks otherwise. reply JadeNB 20 hours agorootparentprev> I generally trust Apple.Why? I can&#x27;t imagine any kind of real trust relationship except with individual developers or small shops who can be responsive to individual customers. I certainly trust Apple more than Microsoft, but I can&#x27;t imagine any situation in which I&#x27;d say I trusted them (or any other megacorp) in an unqualified sense. reply NoboruWataya 19 hours agorootparentFlipping the question around, what exactly are you worried they will do?I&#x27;m on your \"side\" on this in that I dislike closed ecosystems, spyware and not having control over my own devices. But I am not in tech and the vast majority of people I know don&#x27;t care about this and likely never will, and every year that goes by without Apple remotely bricking their phone with no recourse only strengthens their apathy.Trust doesn&#x27;t have to be unqualified. You can accept that Apple&#x27;s incentives don&#x27;t align perfectly with yours while being comfortable that they align enough that Apple will provide you with the service you&#x27;re looking for.\"The user controls the program or the program controls the user\" is a false dichotomy to people who spend most of their time in the real world. reply thesuperbigfrog 19 hours agorootparent>> \"The user controls the program or the program controls the user\" is a false dichotomy to people who spend most of their time in the real world.It is not a false dichotomy: Apple controls who gets to use iPhones and what they get to do on iPhones.Can someone use an iPhone without an Apple account? If Apple were to lock or ban a user&#x27;s Apple account, what could the user do about it?Can someone run arbitrary software of their choice on an iPhone?>> You can accept that Apple&#x27;s incentives don&#x27;t align perfectly with yours while being comfortable that they align enough that Apple will provide you with the service you&#x27;re looking for.Yes, but for how long and under what conditions? How willing are people to change when they are locked-in to the Apple ecosystem? reply NoboruWataya 18 hours agorootparent> Can someone use an iPhone without an Apple account? If Apple were to lock or ban a user&#x27;s Apple account, what could the user do about it?> Can someone run arbitrary software of their choice on an iPhone?These are not restrictions that are likely to be relevant to the people I am talking about.You will ask me how I know. The statement is forward looking so obviously I can&#x27;t prove it, but I know people who have happily been using iPhones for 15+ years without ever giving a thought to these questions. (I know that because I&#x27;ve had this same conversation with some of them.)In the meantime, these people can go where they want, do what they want, say what they want, etc etc. They are not, in any real sense, being controlled by the software on their iPhone.If you live in the first world, pay your bills, are not a criminal and your phone usage is mostly limited to Instagram and WhatsApp, the likelihood of your Apple account being shut down without warning or recourse is very small. So for such people, the risk is too remote to dedicate much thought to. reply harph 18 hours agorootparent> using iPhones for 20+ yearsYou probably meant Apple devices in general? The iPhone is not yet 20 years old. reply NoboruWataya 17 hours agorootparentSorry, that&#x27;s right. For the iPhone probably about 15 years (ie, since not long after it first came out). Edited my previous comment. replywillis936 20 hours agorootparentprevCompanies earn trust by being honest and consistent for long enough. I trusted Apple until recently. They lied to me several times over the phone over several weeks (always in a very courteous and professional way). Such a small thing for them to throw away trust for. I had been slowly moving into their ecosystem and I&#x27;m now pulling out. Pixel 6 google edition can be found for ~$200 and can be loaded up with de-googled Android ROMs (Calyx, Graphene, others). reply ghostpepper 19 hours agorootparentWhat did they lie about? reply willis936 6 hours agorootparentThey told me that they had issued a refund for an order that UPS had failed to deliver when they had not. I called four times 7 days apart and was told each time that the refund was processing and would show up within 3-5 business days.When they did finally issue a refund it was for only half the order. I requested a chargeback from my bank and at this point they are siding with Apple. Not really sure why I keep money in a bank or use credit cards. reply askafriend 20 hours agorootparentprevI have a 20+ year relationship with them as a company that informs my trust with their products and services. reply paulcole 18 hours agorootparentprevWhy not? I’ve been using their products and services with essentially no issues for 20+ years. reply JadeNB 8 hours agorootparent> Why not? I’ve been using their products and services with essentially no issues for 20+ years.That&#x27;s exactly my problem—for a small company that is responsive to individual users, I could build on that trust and have some confidence that it might continue. For Apple, they don&#x27;t care about my trust at all; so, if there is something that they want to do that will harm me personally, then they have no reason not to do it as long as it will not negatively affect their standing with most of their customer base. It doesn&#x27;t matter how many years their interests have aligned with mine; if our interests diverge tomorrow, then, not only will they go with theirs, they won&#x27;t even consider mine. reply paulcole 6 hours agorootparent> It doesn&#x27;t matter how many years their interests have aligned with mine; if our interests diverge tomorrow, then, not only will they go with theirs, they won&#x27;t even consider mine.If you think the small companies are any different, you’re delusional. Everybody’s in it for themselves.But, that’s fine with me. I just think the odds of that are low based on Apple’s track record of 20+ years. replyndsipa_pomu 21 hours agoparentprevThis seems to be quite popular with certain manufacturers. Certainly printers (HP) often include anti-consumer technology. reply AshamedCaptain 20 hours agoparentprev> Unlike cars, which can be repaired with generic parts by auto shops and do-it-yourself mechanicsGive it a few years... reply jqpabc123 20 hours agoparentWait til Apple starts producing cars --- which they are supposedly working on.The Apple car will cost way more than the competition and only they will be allowed to repair it --- and their fans will love it --- because Apple. reply SoftTalker 20 hours agoparentprevAutomotive DRM has typically been cracked or bypassed by the time the car is a few years old. Dealers have the equipment in their shops and it eventually leaks. Mechanics are not hard to bribe. There are also crackers in Russia and China who work on this for their own profit. reply bzzzt 19 hours agorootparentThey also said that about video games. Now some single player games have an &#x27;always online&#x27; requirement and can not be cracked anymore since they rely on content not stored locally. I can see that happening with cars. reply merlinoa 13 hours agoparentprevYou paid 1M for a house and the government still owns it reply jbverschoor 19 hours agoparentprevYou paid 4M for your home of land, but are still subject to regulations of the country.It’s your home, but you’re not even allowed to run a nuclear reactor in your garden. reply cantSpellSober 19 hours agoparentSame comment here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=38240503An incredibly poor analogy for the subject of the article, at least that comment didn&#x27;t take it to the level of \"nuclear reactor\" reply jqpabc123 19 hours agoparentprevReally? You are seriously going to compare repairing your iPhone with a threat to people&#x27;s lives in your neighborhood and beyond? Your analogy is a bust --- the only thing threatened by repairing your iPhone is Apple&#x27;s profits.How did you ever get to this point? Did Apple infect you with some sort of mind virus? reply 160Marks 19 hours agoparentprevBut that depends on where you buy the house. It doesn&#x27;t matter what service you use an iPhone on, Apple still tells you what you can and can&#x27;t do.It&#x27;s not the house builder telling you what you can and can&#x27;t do; these things are not the same. reply jbverschoor 18 hours agorootparent> It&#x27;s not the house builder telling you what you can and can&#x27;t do; these things are not the same.The house builder is the app developer The gov&#x2F;municipality is AppleThe gov&#x2F;municipality tells you what you can and can&#x27;t do. The builder would do it, if you take all the risks and acknowledge that your new building in your garden is not allowed by the gov&#x2F;municipality.There really is no difference reply cantSpellSober 19 hours agoparentprevThis article is about \"parts pairing\"> Parts don&#x27;t work as expected when swapped with the same working part from an identical, new iPhone> The rate at which parts can cause breakdowns has been rising about 20 percent a year since 2016, when only one repair caused a problem(seems like most commenters just read the headline) reply ponorin 20 hours agoparentprevlet&#x27;s also remind ourselves of how apple&#x27;s \"official\" repair process works: https:&#x2F;&#x2F;www.businessinsider.com&#x2F;apple-repair-workers-sweatsh... reply 1vuio0pswjnm7 14 hours agoparentprev\"The breakdowns are an outgrowth of Apple&#x27;s practice of writing software that gives it control over iPhones even after someone has bought one.\"Perhaps we can write software that gives us control over our currency after it has been paid to Apple.We can innovate and give Apple options and choices. reply clircle 21 hours agoparentprevHmm, not sure if the data in the article is correct. I replaced the battery in my SE 2020, there is no persistent warning, but i can no longer check battery health reply nstart 19 hours agoparentprevI wish someone could ask Apple about the middle ground. You want to protect consumers? Fine. Alert customers to the use of non official parts but don’t brick any functionality then.I want Apple to tell me when that shop that promises original parts is actually giving me an original which I can track.I don’t want them stopping me from using it unless it’s genuinely incompatible at a firmware level. reply ghostpepper 19 hours agoparentI think what would happen is people would get their phone repaired by the sketchy corner store guy, ignore the warning (which would presumably only pop up after they&#x27;d gotten the non-approved part installed) and then some time later when their photos&#x2F;emails&#x2F;bank balance was accessed they&#x27;d go back to Apple to demand an explanation. reply dzikimarian 18 hours agorootparentAnd Apple should tell them, that they have sketchy part. Just like Nokia did when I brought them second-hand Symbian phone to fix 15 years ago.I paid for the repair & learned to be more careful. Nobody died. reply paulmd 6 hours agoparentprevThe ability to trivially override serialization would completely rule out the possibility of any sort of anti-theft provision. Phones would be stolen and stripped and sold as parts.Lest anyone forget, these features were legally mandated over the objections of hardware vendors, and they do have a pretty strong effect on theft rates, theft rates dropped by as much as 38% almost immediately after passing.https:&#x2F;&#x2F;transition.fcc.gov&#x2F;cgb&#x2F;events&#x2F;Lookout-phone-theft-in...https:&#x2F;&#x2F;archive.nytimes.com&#x2F;bits.blogs.nytimes.com&#x2F;2014&#x2F;06&#x2F;1... reply RcouF1uZ4gsC 21 hours agoparentprevThis control severely limits the utility of stolen iPhones, which is a good thing for me as an iPhone owner.There are other phones that consumers can choose that don’t have this pairing. But this pairing of parts is one of the reasons people choose and iPhone. reply ponorin 21 hours agoparentif this was their only intention they would let third party repair shops access to genuine parts or software tools. the reality is that third party \"apple certified\" repair shops are contractually less capable than uncertified ones, so much so that calling their service repair feels too generous.apple do this to sell you phones instead of phone parts. if any of what you&#x27;re saying was true it&#x27;s simply a happy accident. reply lcnPylGDnU4H9OF 21 hours agorootparent> happy accidentThat’s a perfect term for this. I would absolutely believe that Apple approached this from that exact anti-theft perspective but it sure is easy to see how such a feature might benefit their bottom line. It’s a matter of looking around and wondering where the inexpensive parts are. reply paulmd 6 hours agorootparentprevGiving third party shops official parts would still preclude the ability to enforce anti-theft unless you also gave them the software to pair it, and then you’ve once again precluded any ability to enforce anti-theft.Apple needs to know what hardware is going into a particular phone to implement the killswitches, which means it can’t be handled as bulk inventory. They will sell you hardware that has been paired to a specific phone, but they’re not going to not have pairing (which is legally mandated for anti theft, over the objections of hardware vendors at the time) and they’re not going to hand out the ability to bypass the anti theft by signing your own keys.Could they come up with some license-based model where the cpu wants to see apple attestation that the part is not stolen etc, perhaps, but, it’s not a trivial problem either.> apple do this to sell you phones instead of phone parts. if any of what you&#x27;re saying was true it&#x27;s simply a happy accident.Apple literally will sell you the parts though. How does that fit into your supposed “plot to force you to buy whole phones instead of parts”?People are silly. About apple and nvidia and a couple of other companies in particular - there is a real thing with negative parasocial attachment to these brands, people love to hate them.http:&#x2F;&#x2F;paulgraham.com&#x2F;fh.html reply chii 21 hours agoparentprevWhy doesn&#x27;t apple allow the owner to choose to decouple the pairing?It&#x27;s telling why they dont. reply m463 21 hours agorootparentI think you mean user.You don&#x27;t really own it in any meaningful way. (wish I could find out what my apps are doing - what network connections they make, how often they start up and under what conditions) reply jaas 21 hours agorootparentprevBecause thieves know that all iPhones are locked like this and thus don’t steal them.If they knew that some significant percentage were not locked they would be worth stealing again, and if it’s locked they just throw it in a dumpster.The fact that your phone is locked protects everyone else as well. reply j-bos 21 hours agorootparentSomehow I doubt even a percent of owners would choose to unpair. And if they do for repair purposes, there&#x27;s no reason they couldn&#x27;t re pair&#x2F;register. What am I missing? reply M4v3R 20 hours agorootparentNothing, the argument for pairing the parts is so weak that I’m genuinely surprised to see it here on HN so often. reply cantSpellSober 19 hours agorootparentprev> thieves know that all iPhones are locked like this and thus don’t steal themDo you even believe this? I haven&#x27;t seen any examples of thieves saying \"stick em up! Oh, iPhone? Have a nice day\"Easy counterexample:> an entire wall of iPhones (approximately 436) were gonehttps:&#x2F;&#x2F;www.usatoday.com&#x2F;story&#x2F;news&#x2F;nation&#x2F;2023&#x2F;04&#x2F;07&#x2F;apple-... reply Detrytus 14 hours agorootparentBut those were brand new iPhones, not activated, and therefore not locked... reply cantSpellSober 12 hours agorootparent...and Apple presumably have the IMEIs.Another easy example:> In the UK in 2016, there were almost half a million mobile phones stolen [...] _most of them iPhones_https:&#x2F;&#x2F;www.trustonic.com&#x2F;opinion&#x2F;smartphone-crime-turning-t... reply paulmd 6 hours agorootparentprev> Comparing data in the six months before and after Apple released its anti-theft feature, police said iPhone robberies in San Francisco dropped 38 percent. In London, they fell 24 percent.> In New York City, robberies (which typically involve a threat of violence) of Apple products dropped 19 percent and grand larcenies of Apple products dropped 29 percent in the first five months of 2014, compared with the same time period from 2013, according to a report from the New York attorney general’s office, which included data from the New York City Police Department. By comparison, thefts of Samsung products increased 51 percent in the first five months of 2014, compared with the same period a year ago, the report said.https:&#x2F;&#x2F;archive.nytimes.com&#x2F;bits.blogs.nytimes.com&#x2F;2014&#x2F;06&#x2F;1... reply ghostpepper 19 hours agorootparentprevThere have been reports of thieves threatening victims with weapons and demanding they disable icloud. Not saying that negates the benefit necessarily but it&#x27;s a relevant data point. reply luuurker 21 hours agoparentprevNo one ever stole my phone, but I had everything from broken displays to dead batteries, so at least in my case this is not good for me as a owner. reply mwint 19 hours agorootparentTextbook confounded reasoning: it’s possible no one stole your phone _because_ they’ve been made such undesirable targets for theft. reply luuurker 16 hours agorootparentThese \"locks\" might reduce theft, but not only they still happen, but you can also make money with a stolen phone. You can sell it for parts. An iPhone will annoy you about the replaced display, but the phone still works. You can transfer the old battery&#x27;s controller to the new one so the phone doesn&#x27;t know about the change. You can sell the shell of the phone, speakers, cameras, etc.Maybe now I benefit from these Apple restrictions and annoyances, but I&#x27;ve been using expensive phones since before Apple started doing this and yet my phone was never stolen. I&#x27;ve cracked a few displays and killed a few batteries though.What seems to help me is having some awareness of my surroundings. I live in a big city and every day I see people standing by the road waiting for a bus. Phones out, noise cancelling headphones, bikes passing right in from of them... I mean, it&#x27;s not that hard for a snatcher to take their phone. reply ozyschmozy 21 hours agoparentprevHow often does phone theft actually happen? I keep hearing this argument but in my ~15 years of owning non-apple phones and laptops, I&#x27;ve never had one stolen, or heard of anyone getting theirs stolen. Have I just been very lucky? reply cianmm 21 hours agorootparentI’m in Dublin, Ireland. It is not common, but not uncommon. Kids and teenagers zip around high-footfall areas in the city centre (such as our financial district) on escooters and electric bikes, and literally grab the phones out of your hand as you’re using them. Minimal violence because they know they’d likely lose, but still pretty traumatic and the Gardaí (our police force) are two swamped in everything else to do a thing about it.I know four people it’s happened to in two years, all four of them women. reply zimpenfish 13 hours agorootparent> escooters and electric bikes, and literally grab the phones out of your handLondon has a non-zero problem with this too - someone tried to grab mine earlier this year but they missed (and apologised as they rode off!) (and I had it on a strap anyway.) reply JCharante 21 hours agorootparentprevMy gf at the time had her phone stolen 2 years ago. Thought she forgot it at a cafe but after watching cctv someone took it out of her jacket like in a movie. Some coffeeshop employees will have their phones charging behind the counter but within customer reach and sometimes people steal the phones (happened to a close friend). reply vasdae 21 hours agorootparentprevThe answer depends on the country or even the city you live in or visit. In some places walking around with a $1000 phone is extremely dangerous to your life. reply ndsipa_pomu 21 hours agorootparentThat seems surprising to me, when surely there&#x27;s no easy way to steal a phone (iPhone or Android) and not have it completely locked and unusable. I would imagine that cars are eminently more desirable a target to steal as they&#x27;re often left unattended for hours&#x2F;days at the side of the road and they&#x27;re typically worth far more than $1k. It&#x27;s also relatively easy to attack a car waiting at traffic lights, over-power the driver and have access to the car and the keys, if the actual vehicle is required rather than just selling the parts. reply vasdae 21 hours agorootparentPickpocketing is quick and easy, sometimes not even a crime, and even though phones are locked, you can sell the Android phone for pieces. That&#x27;s not the case for the iphone. reply ndsipa_pomu 20 hours agorootparent> Pickpocketing is quick and easy, sometimes not even a crimeI find that difficult to believe. reply Lalabadie 20 hours agorootparentIn many places, it&#x27;s a crime according to the law, but if nothing happens with thieves or reported theft, then in terms of consequences it&#x27;s not a crime. reply ndsipa_pomu 20 hours agorootparentI think you&#x27;re using a different defintion of \"crime\" than I am (unlawful activity is probably the simplest). \"Unenforced\" would be probably a better term. e.g. Speeding in a car is a crime in a lot of places, but is often unenforced. reply luuurker 16 hours agorootparentprev> That&#x27;s not the case for the iphone.You can definitely re-use or sell iPhone parts. Most of replacement parts shops have access to are not sold directly by Apple.As mentioned in the article, some parts won&#x27;t work and others will show warnings. And sometimes you can reprogram chips with small devices easily available from China, which essentially defeats Apple&#x27;s hardware pairing. reply LtWorf 20 hours agorootparentprevMy friend got an apple laptop stolen.Only friend that got a phone or computer stolen that I know of. reply vuln 20 hours agorootparentprev> but in my ~15 years of owning non-apple phones and laptops> I&#x27;ve never had one stolen> Have I just been very lucky?No you’re not lucky. Your items aren’t worth stealing. Rarely does anyone steal android devices, or windows laptops the resale value isn’t there. Which should be obvious to the most casual observer. reply luuurker 16 hours agorootparentAre you suggesting that a thief won&#x27;t snatch your +$1k Galaxy S23 Ultra because they&#x27;ll only get $700 instead of $900 for a similarly priced iPhone?I&#x27;m not sure if they&#x27;re that picky. reply jqpabc123 21 hours agoparentprevThis control severely limits the utility of non-stolen iPhones which is not a good thing for an iPhone owner.There are other phones that consumers can choose that don’t have this pairing. But this pairing of parts is *not* one of the reasons people chose an iPhone because most buyers were oblivious to it since Apple never told them. reply lakpan 21 hours agoparentprevIn theory that sounds great, in practice you can find Facebook groups for ~stolen~ ahem lost iPhones for sale. The value of a bricked phone is never zero, so theft prevention isn’t as good as Apple claims. reply dotnet00 21 hours agoparentprevThis is such an absurd excuse. The competing android devices are not exactly known for being a more popular target for theft.This is just a copout pushed by Apple to justify obviously bad practices, and due to their reality distortion field, you guys eat it up. reply thih9 21 hours agorootparent> The competing android devices are not exactly known for being a more popular target for theft.Do you have a source? And which exactly competing android devices do you mean? Does the comparison factor in the popularity of the device? reply dotnet00 21 hours agorootparentThere isn&#x27;t a specific survey I can find pointing either way, which similarly makes the argument that theft is significant enough to justify restrictive and wasteful locks also moot.By competing devices of course I am referring to other flagships which are of a similar price and feature set, like flagship Samsung phones etc. reply cameronh90 21 hours agorootparentprevThat’s just because the thieves don’t consider the android devices worth stealing.London sadly has an ongoing problem with phone snatchers and pickpockets, so on two occasions I’ve seen them nick an Android. In the first case, they just chucked it on the floor a few metres further down the road. On the second, the guy loudly shouted “what the fuck is this shit?” as he cycled down the road and threw it into a canal. reply Aeolun 21 hours agorootparentI’m not quite sure what they expect if they snatch an Apple device? It’d just turn into a brick in a few minutes&#x2F;hours? reply cameronh90 20 hours agorootparentSo one of two things usually happen, either:(1) It gets shipped straight to Eastern Europe or China and broken down for parts which are resold back to unauthorised repair shops in the West as official Apple parts.Or more commonly (2) they will try to socially engineer the owner into giving up their Apple credentials so that they can sign out the iPhone and wipe it. If that fails, go to (1).When my brother’s partner had her iPhone nicked, they extracted her phone number off the SIM then started sending her messages linking to a phishing iCloud sign in page, saying something like “Your stolen device has been located, sign in here to recover it.”. reply ubermonkey 21 hours agorootparentprev>The competing android devices are not exactly known for being a more popular target for theft.You&#x27;re so close to getting it. reply chongli 21 hours agorootparentprevThe proper comparison is not with Android phones, it’s with iPhones before Apple introduced this feature. The news reported a global drop in iPhone thefts at the time [1].[1] https:&#x2F;&#x2F;archive.nytimes.com&#x2F;bits.blogs.nytimes.com&#x2F;2014&#x2F;06&#x2F;1... reply dotnet00 18 hours agorootparentI disagree that the point of comparison should be iPhones from before this functionality, the point is that the negative effects of locking all parts are not worth the amount of theft, not that they don&#x27;t reduce theft.After all, you could massively reduce burglaries too by allowing home security systems to have automated lethal turrets to shoot burglars, but that&#x27;s considered way too far in terms of social cost by pretty much every place. reply chongli 18 hours agorootparentThe point of my reply was to illustrate the true effect on iPhone theft from this change. Do you have a more accurate way to measure that?Whether you think the tradeoff is worth it or not is beside the point. I made no claim for or against the tradeoff, so you have nothing to disagree with there. reply realusername 21 hours agoparentprevIt limits the utility of all iphones, stolen or not. It&#x27;s not like you have a switch to deactivate it for yourself.And for the consumer choice, I don&#x27;t see Apple making any advertising about how anti repair they are, strange. I doubt most phone owners know about the pairing issues. reply 2OEH8eoCRo0 19 hours agoparentprevTheft is a boogeyman that allows Apple absolute control over their devices. Why is theft Apple&#x27;s problem rather than law enforcement? Should cars require a password too? Why don&#x27;t we make all consumer goods require a password so that theft can be a thing of the past! reply mwint 19 hours agorootparentLaw enforcement (and prosecutors) are increasingly unconcerned with theft of “small” amounts, and theft by groups of people they’ve decided to stop prosecuting.I’m happy that Apple isn’t just saying “meh, not our problem”, and it’s one reason I buy their stuff. reply pierat 20 hours agoparentprevThat&#x27;s exactly what I&#x27;ve been saying.This \"cloud controlled shit\" is a rental with no terms and unlimited claw-back. These aren&#x27;t sales.If I had a computer, installed remote controlling malware on it, sold it, and then started exerting remote control over it, I&#x27;d be arrested and likely sentenced to fraud or hacking.This is fraud for Apple etm to call this a \"sale\", and should be prosecuted as such. reply 2OEH8eoCRo0 11 hours agoparentWhy hasn&#x27;t someone done this? Say it&#x27;s for their protection via security&#x2F;virus scanning and hide it in the EULA. reply dmitrygr 13 hours agoparentprevYes. I am an adult. I paid for this exact experience and I don’t need an unrelated third party to get involved and “save” me from getting precisely what I sought and paid for! reply ubermonkey 21 hours agoparentprevYes. And that&#x27;s part of what I paid for. reply cabirum 20 hours agoparentThis is a case for post-purchase rationalization. Take an obviously negative trait and spin&#x2F;distort it in such a way it sounds like an advantage, reinforcing your delusion that you made the right choice.Same for a single, apple-controlled store, the inability to actually install apps without a store, even deciding what browser engine should everyone use. reply gentleman11 20 hours agorootparentAnd this I think is called gaslighting? Telling somebody they are wrong about what they think or feel? Or maybe not gaslighting. What is the term for this? Attack via psychology undermining? reply cabirum 19 hours agorootparentAre you saying there is no objective wrong? You cannot \"feel\" that 2×2 != 4. reply ubermonkey 13 hours agorootparentprevLOL.I want my phone to be locked down and curated. This isn&#x27;t post-purchase rationalization. I have actively chosen the iPhone over and over and over since its introduction, because the alternative is so obviously inferior from a security, privacy, and application selection POV.Obviously, I am making different choices than you are, but it&#x27;s a weak argument to dismiss them as \"rationalization\" in a transparent effort to crown your preferred platform king. reply jqpabc123 21 hours agoparentprevShow us where Apple advertises this and I might believe you. reply quadrifoliate 21 hours agorootparentThere is a form of explicit and implicit advertising.Apple advertised implicitly by consistently fulfilling the promise that if anything bad happens to your iPhone, in most cases an Apple Store can fix it.Control is a part of this implicit model. This is not a model I myself like (I prefer the more freewheeling Android ecosystem); but I can appreciate why people respond well to it. To your average person who doesn&#x27;t give a shit about unlocked bootloaders and just wants a way to regularly be in touch with their family and friends, the Apple model probably works better. reply eviks 20 hours agorootparentWhy did you pick bootloaders instead of the more obvious example of battery replacement that any average person can understand - it&#x27;s cheaper if it&#x27;s not locked&#x2F;less controlled by Apple via various means? Also don&#x27;t see the connection with Apple Store - their implied ability to fix it isn&#x27;t impugned in this case reply macNchz 20 hours agorootparentprevI’m not following as to what the Apple store being able to repair phones has to do with them restricting others from making repairs? They were certainly able to repair phones just fine prior to implementing parts pairing. reply jqpabc123 20 hours agorootparentprevControl is a part of this implicit model.And control is money. Apple obviously makes more money by controlling and limiting the consumer&#x27;s ability to repair the device. reply mplewis 21 hours agorootparentprevhttps:&#x2F;&#x2F;support.apple.com&#x2F;guide&#x2F;iphone&#x2F;use-built-in-privacy-... reply jqpabc123 21 hours agorootparentAbsolutely nothing there about how hardware repairs are restricted or about how this benefits the consumer. reply lcnPylGDnU4H9OF 20 hours agorootparentprevIs that an advertisement or a support page? reply kibwen 19 hours agoparentprevIf this is your mindset, you&#x27;re on the wrong website. The values of hackers are incompatible with the values of technological serfdom that you&#x27;re espousing. reply Terretta 19 hours agorootparentOn the contrary, most people are not hackers, and our job is to make tools usable, unbreakable, and since this tool is their digital twin: secure. reply lost_tourist 18 hours agoparentprevMeh, I use my iphone as a tool. Not saying I wouldn&#x27;t like more right to repair&#x2F;reuse&#x2F;recycle laws but I&#x27;m not panicking yet. And it&#x27;s not just iphones, my $50k car is not really mine either. reply nikanj 20 hours agoparentprevI paid hundreds of thousands for a home and the city still controls many aspects of it reply jqpabc123 18 hours agoparentThey control aspects that can adversely affect others in the community --- with disclosure and mutual consent.Restricting repairs to your iPhone only affects you and Apple&#x27;s profits --- and there was no disclosure or consent --- i.e. buyer&#x27;s weren&#x27;t told in advance. reply tinus_hn 19 hours agoparentprev [–] If only there were phones made by other manufacturers where the experience, which you know in advance, is different from the iPhone experience which you also know in advance! Then this wouldn’t be a monopoly! reply diffeomorphism 17 hours agoparent [–] As if having just two options were meaningful. Also, the phrase \"dominant market position\" or \"oligopoly\" is a mouthful so people just (incorrectly) say \"monopoly\" for short.Though since even \"literally\" nowadays often means \"figuratively\" instead, you might as well say this is what the word means now. reply tinus_hn 15 hours agorootparent [–] iPhone has a global market share of about 20%, and only a small majority market share in ‘premium smartphones’ in the US.Nobody is forcing you to use an iPhone, billions do fine with the alternatives.Apple does not have a dominant market position, an oligopoly or a monopoly and certainly is not illegally abusing any monopoly power. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Apple's software designed to detect unauthorized repairs has increased the difficulty of iPhone repairs, leading customers to rely on Apple or authorized repair centers, resulting in higher prices.",
      "Advocates are pushing for lower repair costs to promote sustainability and extend the lifespan of devices, but Apple claims safety concerns as a defense for their practices.",
      "State lawmakers and the Biden administration have taken steps to make repairs easier, however, regulations do not explicitly address parts pairing, fueling the ongoing debate over the right to repair. The article also covers various topics related to Apple, including product launches, tech industry trends, and the societal implications of technology use."
    ],
    "commentSummary": [
      "The article examines Apple's tight control over iPhones, including restrictions on application access, repair policies, and security measures.",
      "Debates over the pros and cons of Apple's control are discussed, with calls for greater user autonomy while maintaining device security.",
      "Transparency, regulations, and comparisons with other brands are also explored in relation to Apple's control over their products."
    ],
    "points": 165,
    "commentCount": 208,
    "retryCount": 0,
    "time": 1699793122
  },
  {
    "id": 38240333,
    "title": "Free Oberon: A Free, Cross-Platform IDE for Oberon Programming Language",
    "originLink": "https://free.oberon.org/en/",
    "originBody": "Free Oberon About Download Documentation Lessons РУ EN DOWNLOAD FREE OBERON for: WINDOWS / LINUX Updates November 8, 2023. A new edition of Documentation on Using the Free Oberon IDE and the Programming Language Oberon (ODT). January 26, 2023. New module documentation has been published. January 11, 2023. New Free Oberon 1.1.0-alpha.7 version is out. * Debug output and \"--debug\" key * Unicode support in modules In and Out on Windows * Automatic linking of external libraries * OS clipboard integration * Fix paste of large text * Fix compilation outside FreeOberon directory on Windows * Fix parser in project builder January 9, 2023. A lesson on Heapsort has been published. News Archive Video (voice is in Russian, with English subtitles) What is Free Oberon? Free Oberon is a cross-platform integrated development environment for development in Oberon programming language, made in the classical pseudo-graphic style. Compilation is done using the Ofront+ Oberon translator, the compiled console programs are executed independently or in the built-in cross-platform terminal emulator. Free Oberon uses the latest revision of the Oberon programing language (Oberon-07). The size of type CHAR is 2 bytes and it supports Unicode. The base modules were rewritten with this in mind: In, Out, Files, Texts, etc. The language extensions include pointers to arrays. The IDE includes a cross-platform module Graph for graphics programming. It is built on top of Allegro5 library. The interface of the IDE as well as the compiler error messages are translated in other languages. Anyone can add a language by editing a text file. Free Oberon is free software and is shipped under GNU General Public License version 3 with source code. It can be compiled under Windows, GNU/Linux and other operating systems. Windows version contains a precompiled Ofront+ compiler, and truncated MinGW bundle, necessary for its operation. The compiled programs are “native” Windows applications and do not require additional DLL files to work. Free Oberon is part of a larger project, which includes writing a series of textbooks on programming, creating educational materials, and the development of a native Oberon compiler and other programs with the aim of developing informatics as science and popularizing it as science among programmers and students. Installation To install on Windows, unpack the ZIP archive and run FreeOberon.exe. To install on Linux (Ubuntu, Debian, Mint), download ZIP-archive from GitHub or clone the repository and run install.sh with root privileges. Learn more in README. Game of Life with colors made in Free Oberon Additional Information The source code of the user programs are stored in the Programs directory, and the executable files are stored in the bin directory. To compile, a script file is used: data\\bin\\compile.bat (on Linux: data/bin/compile.sh), which you can edit if you like. Please read the documentation to get used to the interface of Free Oberon more quickly. The editor can be switched to windowed mode, using the combination of keys [Alt+Enter], copy and paste can be done using [Ctrl+C] and [Ctrl+V]. The program trapped in a livelock can be stopped by pressing the [Ctrl+Break] key combination. Among others, the following modules are available: In, Out, Strings, Files, Math, Graph. Feedback Please write your questions and wishes to freeoberon@yandex.com Write to freeoberon@yandex.com Last updated on January 26, 2023",
    "commentLink": "https://news.ycombinator.com/item?id=38240333",
    "commentBody": "Free Oberon: Cross-platform Oberon IDEHacker NewspastloginFree Oberon: Cross-platform Oberon IDE (oberon.org) 164 points by AlexeyBrin 20 hours ago| hidepastfavorite37 comments BaculumMeumEst 19 hours agoparentThis project is cool as hell. I really appreciate that it has very straightforward instructions and takes no time to get up and running, it&#x27;s just a git clone and an install command.The only quirk I ran into is that when I ran graphical programs, I would get a full-screen window with a blank prompt; I needed to move that window to another workspace in order for the running program to be displayed. The IDE seems to get smushed into the bottom corner of the screen in KDE and gnome for some reason (which I could work around by toggling windowed mode with alt+enter and then dragging the window to resize), but it works fine in i3.Between discovering this and finally getting around to trying the Factor language, I&#x27;m afraid I&#x27;m going to be very unproductive on my side projects for a while.. reply benj111 16 hours agoparent>I&#x27;m afraid I&#x27;m going to be very unproductive on my side projects for a whileI infer that your main project is discovering things that may one day help you be more productive in your side projects.It could be worse. Ben Eater was just trying to get his web browser working like he wanted... reply Qem 19 hours agoparentprevHow does FreeOberon compare to FreePascal, in terms of standard library and third party libraries available? Is it a practical development environment, in the sense of not needing to reinvent every wheel to use it? reply anta40 19 hours agoparenthttps:&#x2F;&#x2F;free.oberon.org&#x2F;docs&#x2F;en&#x2F;On a glance it looks pretty limited, I see no way to access OS API, no networking, etc (more or less like Turbo Pascal).Perhaps sufficient as educational tool. reply hnlmorg 18 hours agorootparentSyscalls were the OS APIs back in the Turbo Pascal days. DOS didn’t have an SDK like we now expect. But people still pulled off some pretty sophisticated stuff in Pascal (personally, I wrote a DOS GUI frontend (like pre-Win 3.x) in Turbo Pascal) reply fostware 8 hours agorootparentDamn, I miss the days Turbo Pascal was used for business logic, and the grunt work was TASM blocks and syscalls.Actually, that might just be the nostalgia talking. reply anta40 18 hours agorootparentprevAh, I still remember those DOS interrupts :)And of course, modern Pascal compiler like FPC provides OS specific units to do that. reply benj111 16 hours agorootparentprevint 0x80 was&#x2F;is the x86_32 way of doing syscalls in linux.im not sure if sysenter, used on 64bit systems is classed as an interrupt.the sdk is just a layer on top of that.ive never used c on dos, it woukdnt surprise me if they used a similar library to linux. theres certainly nothing preventing it. reply mikewarot 11 hours agorootparentMS-DOS used Int 21h with the function number in in the AH register. reply the_only_law 8 hours agorootparentprev> Perhaps sufficient as educational tool.Has Oberon ever been a thing outside academia? I’ve heard about some Modula2&#x2F;3 stuff out there in the wild, but not Oberon. reply pjmlp 3 hours agorootparentYes, when I was at CERN almost 20 years ago, Niklaus Wirth did a session on Oberon for scientific computing, and as part of that Oberon day, there was someone from Brasil talking about their use in production, controlling some hardware stuff.Additionally Astrobe sells Oberon-07 compilers for IoT (https:&#x2F;&#x2F;www.astrobe.com&#x2F;order.htm), for a while XDS also sold Oberon compilers alongside their Modula-2 compilers, and there was a spin-off from ETHZ which sold Component Pascal, basically yet another Oberon dialect. reply anta40 6 hours agorootparentprevFrom a quick Google search: \"Oberon includes low-level features that make it particularly suited to the development of real-time applications on ARM microcontrollers.\" https:&#x2F;&#x2F;www.astrobe.com&#x2F;Oberon.htmhttps:&#x2F;&#x2F;www.astrobe.com&#x2F;order.htmAh, very interesting. reply dengolius 5 hours agoparentprevIt is better to not use any software from russia now anyway. reply WillAdams 19 hours agoparentprevEvery time Oberon comes up, I wonder how it would have done if it had had a \"normal\" graphical interface, and some aesthetically minded person such as Keith Ohlfs or Susan Kare to make it attractive by the standards of the average user&#x2F;developer. reply pjmlp 19 hours agoparentIsn&#x27;t this normal enough?https:&#x2F;&#x2F;www.progtools.org&#x2F;article.php?name=oberon&section=co...Good enough when placed against many UNIX windows managers, or the developer beloved Plan 9 and Inferno GUIs.It failed because like Xerox, it stayed mostly inside ETHZ walls, a few European universities and zero industry interest, too much focused on building UNIX clones. reply pmontra 13 hours agorootparentI remember Oberon. My take is that it failed to become a mainstream language because we were using C to write system tools and browsers, Visual Basic and Visual C++ to write Windows apps and PHP and Java to write web apps. Those filled most niches.Delphi and the Pascal languages were on a downward spiral of popularity. C was the incumbent. PHP was easy to install and solved a problem that most developers had: write a web app quickly. Java and the Visual languages were backed by big companies. Oberon was not. It was a curiosity at best. I remember other languages from back then: Eiffel and Modula 3. They resurface sometimes in HN posts. reply cyberax 17 hours agorootparentprev> Isn&#x27;t this normal enough?It definitely is not normal enough. It&#x27;s a whole operating system, after all.> It failed because like Xerox, it stayed mostly inside ETHZ walls, a few European universities and zero industry interest, too much focused on building UNIX clones.Not really. It failed because Oberon was not a great language even in the 2000-s. Right now it&#x27;s not even good enough for teaching purposes. reply pjmlp 17 hours agorootparentApparently it was good enough to inspire Go authors, and everyone that enjoys its influences in Go, as the ultimate design in language simplicity. reply cyberax 16 hours agorootparentAs an inspiration for some of the ideas? Maybe. As a language in itself, Oberon was crappy even at that time.From the very start, Go was utterly practical, designed to be used for actual programming, and not PhD theses.So compared to Oberon, Go had hash maps from the start. It didn&#x27;t have the SCREAMING PROCEDURE&#x2F;RECORD&#x2F;VAR case-sensitive keywords, Go had multiple return values for error handling from the start, better namespacing support, variable declaration in-place, full support for UTF-8 for strings, etc.And of course, Go has lightweight threads and channels, making it a great language for servers. reply pjmlp 15 hours agorootparentIf you are stuck with a tunnel vision of the 1992&#x27;s version of Oberon, yeah.Except that Active Oberon from 1996, sorted out most of those cases.Hash maps don&#x27;t need to be built-ins, as proven in many languages.Active Objects take care of lightweight threads and channels.Oberon, the OS, was also good enough for Go&#x27;s hero Rob Pike to implement ACME and RIO on the same UX principles, re-use Oberon-2 (yet another version you ignored) method syntax, and Oberon&#x27;s SYSTEM package as unsafe.Screaming keywords, only an issue when someone doesn&#x27;t use an editor with automatic capitalization, only an issue for Notepad-like users. reply cyberax 13 hours agorootparentWe&#x27;re talking about Oberon here, not about its clones. And I based my reply on Oberon-2. It definitely sucked.> Hash maps don&#x27;t need to be built-ins, as proven in many languages.Except Oberon doesn&#x27;t have generics.From the very beginning, Go included very practical \"magic\" generic functions: append, len, cap, delete. Along with slices, they allowed Go to flourish without generics.Oberon only has LENGTH.> re-use Oberon-2 (yet another version you ignored) method syntaxHere&#x27;s Go: \"func (c Type) DoSomething(hello, world string) (int, error)\". Here&#x27;s Oberon: \"PROCEDURE (c: Type) DoSomething(hello, world: STRING): INTEGER;\" (error handling is for wimps).It is similar, but not the same. Go also has structural polymorphism, which Oberon lacks.> Screaming keywords, only an issue when someone doesn&#x27;t use an editor with automatic capitalization, only an issue for Notepad-like users.IT LOOKS UGLY, AND IT MATTERS A LOT, WHEN YOU MOSTLY READ THE CODE.So yep, I maintain that Oberon is a shitty language. It might be useful as a starting point for new language design, but that&#x27;s it.It has never been practical, and on its own it only ever \"succeeded\" in the ETH where professors just forced students to use it. reply pjmlp 2 hours agorootparentSo stuck in 1987, got it.What allowed Go to florish was being sponsored by Google, and being pushed alongside Docker and Kubernetes, without them, it would have had the same fate as Plan 9, Inferno and Limbo.All really widely successfull commercial projects from UNIX folks. &#x2F;sTurns out shitty languages only flourish with the right sponsors. reply jhgb 9 hours agorootparentprev> Except Oberon doesn&#x27;t have generics....which could plausibly be fairly easily fixed by Zig&#x27;s comptime feature, which would seem to fit the language very well. replyRochus 14 hours agorootparentprev> It&#x27;s a whole operating system, after all.You can use that one which easily starts on all platforms without taking control of the PC: https:&#x2F;&#x2F;github.com&#x2F;rochus-keller&#x2F;oberonsystem3 reply WillAdams 16 hours agorootparentprevMaybe, but that&#x27;s not what&#x27;s being shown on the linked website. reply pjmlp 15 hours agorootparentMaybe because the linked Website is not the original Oberon, and derived OSes done at ETHZ.The question of the parent naturally should be answered in regards to what was available during the 1990&#x27;s. reply WillAdams 14 hours agorootparentWorking from uncertain organic memory, but yes, the other screens look much better.I&#x27;ve actually always been quite fond of the concept of Oberon --- wondering if this implementation might work well for a potential future pet&#x2F;side project: making a graphical front-end for METAPOST&#x2F;METAFONT. reply troupo 19 hours agoparentprevThe graphical interface is the least of its problems. reply shrubble 11 hours agoparentprevThe great thing about Oberon now under Linux&#x2F;Windows&#x2F;Mac is that you can easily create CLI and related filter programs, like something that can be piped into perl or awk, or can receive output from a shell pipeline. This makes for a very gentle slope into using it more. reply anta40 3 hours agoparentWhich Oberon compiler do you use? reply andai 18 hours agoparentprevSee also: Oberon+: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35209102Code Examples: https:&#x2F;&#x2F;oberon-lang.github.io&#x2F;Context: https:&#x2F;&#x2F;github.com&#x2F;rochus-keller&#x2F;Oberon reply anta40 18 hours agoparentprevQuick look at https:&#x2F;&#x2F;github.com&#x2F;kekcleader&#x2F;FreeOberon&#x2F;blob&#x2F;main&#x2F;src&#x2F;make....:It uses ofront (Oberon-2 to C translator), and let GCC do the heavylifting. Let&#x27;s check if this thing can be easily built on macOS... reply zozbot234 16 hours agoparentprevThe TUI IDE is kinda interesting, looks a lot like QuickBasic, Turbo C and other old-style DOS apps. But otherwise, it would be a lot more sensible these days to just code an Oberon-specific language server, that you could use with any IDE. reply wenc 9 hours agoparentI love that TUI. Ncurses doesn’t even come close.I used to spend hours in Paradox for DOS, Turbo C etc. It felt so comfortable compared to Ncurses TUIs. reply bitwize 15 hours agoparentprevOberon is much more a language&#x2F;library&#x2F;IDE&#x2F;operating system, like a Pascal-flavored Lisp machine. This is a bit like saying \"Emacs Lisp is great but what I really want is a language server for it so I can write it in VS Code.\" reply zozbot234 15 hours agorootparentThis project just uses a C transpiler and creates plain binaries, though. It&#x27;s not running under any sort of bespoke environment. reply minroot 12 hours agoparentprev [–] Too much at 4:20 AM replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Free Oberon is a free cross-platform integrated development environment (IDE) for the Oberon programming language, which supports Unicode and graphics programming.",
      "It is part of a larger project focused on advancing informatics as a science.",
      "Users can download and install Free Oberon by accessing the ZIP archive and running the executable file. The IDE offers various modules and allows users to provide feedback to the developer via email."
    ],
    "commentSummary": [
      "Free Oberon is a cross-platform IDE that is user-friendly but may have compatibility issues with KDE and Gnome.",
      "It is primarily suited as an educational tool due to limited access to OS APIs and lack of networking capabilities.",
      "Oberon has limited popularity outside academia, with some usage in scientific computing and IoT development."
    ],
    "points": 164,
    "commentCount": 37,
    "retryCount": 0,
    "time": 1699799302
  }
]
