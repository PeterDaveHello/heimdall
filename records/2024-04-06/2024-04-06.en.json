[
  {
    "id": 39942288,
    "title": "Breaking Free: Strategies for Overcoming Feeling Stuck",
    "originLink": "https://www.experimental-history.com/p/so-you-wanna-de-bog-yourself",
    "originBody": "Share this post So you wanna de-bog yourself www.experimental-history.com Copy link Facebook Email Note Other Discover more from Experimental History 1) Find what's true and make it useful. 2) Publish every other Tuesday. 3) Photo cred: my dad. Over 38,000 subscribers Subscribe Continue reading Sign in So you wanna de-bog yourself What I found in the mire Adam Mastroianni Jan 02, 2024 551 Share this post So you wanna de-bog yourself www.experimental-history.com Copy link Facebook Email Note Other 46 Share Article voiceover 1× 0:00 -25:14 Photo cred: my dad Strangers sometimes ask me for advice, which is both flattering and alarming, because I only know about the things I write here, and sometimes not even those. For instance, someone recently asked me if I had any advice about how to teach people to fly planes, which makes me wonder: who’s running the pilot education system?? Now, whenever I get on a plane, I scrutinize the captain to see if they have that “A blogger taught me how to fly” kind of look. I often don't know how to respond to such questions, on account of my general incompetence. But I've realized that most of these folks have something in common: they're stuck. They’re looking for advice less in the sense of “any good restaurants around here?” and more in the sense of “everything kinda sucks right now and I’d like to change that but I don’t know how?” Being stuck is the psychological equivalent of standing knee-deep in a fetid bog, bog in every direction, bog as far as the eye can see. You go wading in search of dry land and only find more bog. Nothing works, no options seem good, it’s all bleh and meh and ho hum and no thanks and more bog. This is the kind of dire situation that drives people to do crazy things like ask a blogger for advice. Fortunately, I’ve spent much of my life in that very bog. Some say I was born in it, a beautiful bouncing baby bog boy. And I've learned that no matter how you ended up there—your marriage has stalled, you're falling behind in your classes, your trainee pilots keep flying into the side of a mountain—the forces that keep you in the bog are always the same. There are, in fact, only three, although they each come in a variety of foul flavors. It's a new year, the annual Great De-bogging, when we all attempt to heave ourselves out of the muck and into a better life. So here, to aid you, is my compendium of bog phenomena, the myriad ways I get myself stuck, because unsticking myself always seems to be a matter of finding a name for the thing happening to me.1 May this catalog serve you well, and may your planes always be flown by people who never learned anything from me. 1. INSUFFICIENT ACTIVATION ENERGY Most of my attempts to get unstuck look, from the outside, like I'm doing nothing at all. I'm standing motionless in the bog, crying, “THIS IS ME TRYING!” That means I've got insufficient activation energy—I can't muster the brief but extraordinary output of effort it takes to escape the bog, so I stay right where I am. There are few different ways to end up here. Gutterballing People will sometimes approach me with projects I don't really want to do. But if I do them, those people will smile and shake my hand and go, “We feel positive emotions, and it's because of you!” and that will feel good. So I often end up signing on to these projects, feeling resentful the whole time, cursing myself for choosing—freely!—to work hard on things I don't care about. This is gutterballing: excelling, but in slightly the wrong direction. For most of its journey, after all, the gutterball is getting closer to the pins. It's only at the end that it barely, but dramatically, misses. Gutterballing is a guaranteed way to stay stuck in the bog because people will love you for it. “You're doing the right thing!” they'll shout as you sink into the swamp. “We approve of this!” Waiting for jackpot Sometimes when I'm stuck, someone will be like, “Why don't you do [reasonable option]?” and I'll go, “Hold on there, buddy! Don't you see this option has downsides? Find me one with only upsides, and then we'll talk!” I'm waiting for jackpot, refusing to do anything until an option arises that dominates all other options on all dimensions. Strangely, this never seems to happen. Often, I'm waiting for the biggest jackpot of all: the spontaneous remission of all my problems without any effort required on my part. Someone suggests a way out of my predicament and I go, “Hmm, I dunno, do you have any solutions that involve me doing everything 100% exactly like I'm doing it right now, and getting better outcomes?” Declining the dragon Okay, this is a version of waiting for jackpot, but it's so common that it deserves its own entry. Sometimes I'll know exactly what I need to do in order to leave the bog, but I'm too afraid to do it. I'm afraid to tell the truth, or make someone mad, or take a risk. And so I dither, hoping that the future will not require me to be brave. Everybody thinks this is a bad strategy because it merely prolongs my suffering, but that's not why it's a dumb thing to do. Yes, every moment I dither is a moment I suffer. But when I finally do the brave thing, that's not the climax of my suffering—that moment is the opposite of suffering. Being brave feels good. I mean, have you ever stood up to a bully, or conquered stage fright, or finally stopped being embarrassed about what you love? It's the most wonderful feeling in the world. Whenever you chicken out, you don't just feel the pain of cowardice; you miss out on the pleasure of courage. Medieval knights used to wander around hoping for honorable adventures to pop up so that they could demonstrate their bravery. They were desperate for big, scary dragons to appear. When I put off doing the brave thing, I am declining the dragon: missing an opportunity to do something that might be scary in the moment but would ultimately make me feel great. The mediocrity trap About half of my friends kind of hate their jobs, so they're moderately unhappy most of the time, but never unhappy enough to leave. This is the mediocrity trap: situations that are bad-but-not-too-bad keep you forever in their orbit because they never inspire the frustration it takes to achieve escape velocity. The mediocrity trap is a nasty way to end up in the bog. Terrible situations, once exited, often become funny stories or proud memories. Mediocre situations, long languished in, simply become Lost Years—boring to both live through and talk about, like you're sitting in a waiting room with no cell reception, no wifi, and no good magazines, waiting for someone to come in and tell you it's time to start living. (I have previously written about this phenomenon as an underrated idea in psychology.) Stroking the problem I spend a lot of time thinking about my problems, but it usually looks like this: “Oh boy, what a problem! A real whopper, I'd say. Massive, even. Get a load of this problem, would ya! Wowzers!” I can spend days doing this. “How big would you say that problem is? Large? Huge? And that's just its size! Don't get me started on its depth.” This isn't solving the problem; this is stroking the problem. It looks like a good use of time, but it's just a form of socially acceptable anxiety, a way to continue your suffering indefinitely by becoming obsessed with it. 2. BAD ESCAPE PLAN Even if you've worked up a big enough head of steam to launch yourself out of the bog, you still have to aim properly. (“I’m doing it! I'm doing it!” I shout as I crash land onto my launch pad.) Here are a few of my recurring bad escape plans: The “try harder” fallacy I played a lot of Call of Duty in high school, and I used to roll with a gang of bad boys who would battle other gangs online.2 We weren't very good. Whenever we lost the first round, which was almost always, we would regroup in the pregame lobby—basically the online locker room—and decide what we really need to do in the next round is “try harder.” As if the reason we had all just been shot in the head 25 times in a row was that we were not sufficiently dedicated to avoiding getting shot in the head. Armed with the most dimwit plan of all time, we would march into battle once more and lose just as badly. As our virtual corpses piled up, we'd yell at each other, “Guys, stop dying!” This is the try harder fallacy. I behold my situation and conclude that, somehow, I will improve it in the future by just sort of wishing it to be different, and then I get indignant that nothing happens. Like, “Um, excuse me! I've been doing all of this very diligent desiring for things to be different, and yet they remain the same, could someone please look into this?”3 The infinite effort illusion The try harder fallacy has a cousin called the infinite effort illusion, which is the idea that you have this secret unused stock of effort that you can deploy in the future to get yourself unstuck. I'm always a week late responding to emails? No problem, I'll simply uncork my Strategic Effort Reserve and clear my correspondence debt. This never works because there is no Strategic Effort Reserve. All of my effort is currently accounted for somewhere. If I want to spend more of it on something, I have to spend less of it on something else. If I’m consistently not getting something done, it’s probably because I don’t want to—at least, not enough to cannibalize that time from something else—and I haven’t admitted that to myself yet. Blaming God I spend a lot of stints in the bog wailing about how I don’t have enough time. “Oh, if there were only 25 hours in the day,” I lament, “the things I would accomplish!” But here’s a stupid question: what am I mad about, exactly? That I don't have a time-turner? That I can’t find a little eddy in the spacetime continuum where I can hide out while I cross a few more things off my to-do list? Do I really believe that the way to get unstuck is to ruminate on how unfair it is that time marches ever forward at one second per second? This is blaming God: pinning the responsibility for my current predicament on something utterly unchangeable. And while many religions teach that God intervenes in human affairs, none of them, as far as I know, believe that he responds to whining. (Would you worship a god who does miracles if you just annoy him enough?) Diploma problems and toothbrushing problems Some problems are like getting a diploma: you work at it for a while, and then you're done forever. Learning how to ride a bike is a classic diploma problem. But most problems aren’t like that. They’re more like toothbrushing problems: you have to work at them forever until you die. You can’t, as far as I know, just brush your teeth really really well and then let ‘em ride forever. When I had a skull full of poison, I assumed feeling good again was a diploma problem. I just had to find the right lever to pull and—yoink!—back to the good times forever. People warned me it wasn't going to be like this and I didn't believe them; I assumed they had simply failed to earn their diplomas. I only started making progress when I realized I was facing a toothbrushing problem: feeling normal again would probably require me to do stuff every day for the rest of my life. I might get better at doing that stuff, just like when you first start brushing your teeth as a kid you get toothpaste everywhere and end up swallowing half of it, and eventually you learn not to do that. But even when you're a toothbrushing expert, it still takes you a couple minutes every day. You could be mad about that, but it won’t make your teeth any cleaner. Fantastical metamorphosis Here’s one of my favorite bad escape plans: I’ll just be a different person in the future. Like, “I know I hate working out, but in the future I will overcome this by not being such a baby about it.” Or, “I find quantum physics boring, so I’ll just learn about it later, when I find it more interesting.” These are fantastical metamorphoses. I have not, so far, woken up one day and found myself different in all the ways that would make my life easier. I do hope this happens, but I’ve stopped betting on it. Puppeteering People are always causing me problems by doing foolish things like trying to drive on highways while I'm also trying to drive on them, or expecting me to pay rent every month, or not realizing my genius and putting me in charge of things. In these cases, it feels like the only solution is to get other people to act differently. I'm only stuck because other people are unreasonable! A good word for this is puppeteering: trying to solve your problems by controlling the actions of other humans. Puppeteering often looks attractive because other people's actions seem silly and therefore easily changeable. Funnily enough, it doesn't feel that way to them. They have lifetimes of backstory that lead them to act the way that they do, and their actions are, on average, only as changeable as yours. So unless you think of yourself as being easily redirected with a few tugs of your strings, puppeteering is probably not going to get you out of the bog. Subscribe 3. A BOG OF ONE'S OWN A confession: most of my bogs are imaginary. The world doesn’t stick me there; I stick me there. These are, paradoxically, the most difficult bogs to escape, because it requires realizing that my perception of reality is not reality, and a lot of the mind is dedicated to preventing that exact thought. Floor is lava Every kid learns to play the “floor is lava” game, where you pretend that you'll get incinerated if you touch the carpet. Even toddlers can pick it up, which reveals something profound: very early on, we acquire the ability to pretend that fake problems are real. We then spend the rest of our lives doing exactly that. Often, when I’m stuck, it’s because I've made up a game for myself and decided that I’m losing at it. I haven’t achieved enough. I am not working hard enough and I am also, somehow, not having enough fun. These games have elaborate rules, like “I have to be as successful as my most successful friend, but everything I've done so far doesn't count,” and I’m supposed to feel very bad if I break them. It’s like playing the absolute dumbest version of the floor is lava. Did I create these games by thinking really hard about how to live a good life? No! I pulled them out of my butt. Or someone else pulled them out of their butt, and I said, “Ooh, can I have some of that?” Super surveillance During the Trump administration, I took on a part time job: keeping up with all the outrages. Every twenty minutes or so I would have to check my phone in case any new outrages had occurred, so that I could...collect them? Make them into a scrapbook? I'm not sure. I now think of this as super surveillance, tracking every problem in the world as if they were all somehow, ultimately, my problems. Super surveillance is an express ticket to the bog, because the world is full of problems and you'd be lucky to solve even a single one. I know some people think that super surveillance is virtuous, but they mainly seem to spend their time looking at screens and feeling bad, and this doesn't seem to solve any of the problems that they're monitoring. To them, I suppose, the most saintly life possible is one spent sitting in front of a hundred screens, eyelids held open with surgical instruments, A Clockwork Orange-style, bearing witness to all human suffering simultaneously. I, uh, feel differently. (See also: Reading the news is the new smoking.) Hedgehogging Sometimes I get this feeling like, “Nothing will ever work out for me, I will always be unhappy, the rest of my life will be a sort of wandering twilight punctuated with periods of misery.” And my wife will go, “You're hungry.” And I'll go, “No, no, this is true unhappiness, it comes to me unadulterated from hell itself, it lives inside my bones, I am persecuted by God, you could not possibly know what it's like to be me.” And then I'll eat a burrito and be like, “Never mind I'm fine!” This is hedgehogging: refusing to be influenced by others, even when you should. Personal problems growth ray You know how, when you go up in a tall building and look down at the street, everybody looks not just small, but kind of silly? Like, “Aww, look at those tiny little guys, walking around in their suits like they're people! They don't even know they're so small!” This is how other people's problems look to me. A friend will tell me, “I'm stressed!” and I'll go, “Aww, what a silly little problem, walking around like it's real! Just don't be stressed, and then you won't be stressed!” My problems, on the other hand, are like 50-foot-tall moody teenagers. They're so big and so real and so complicated! They cannot possibly be solved! I can only flee from them, hide among the rubble, and peek out at them with horror! Such is the result of the personal problems growth ray, which makes all of your own problems seem larger than life, while other people's stay actual size. This makes reasonable solutions look unreasonable—the actions that solved your human-sized problems could never solve my giganto-problems; they can only be addressed with either a lifetime of cowering or a tactical nuke. Obsessing over tiny predictors In graduate school, I made the terrible mistake of signing up for a professional development seminar. We would convene every week for 90 minutes of discussions like “OH NO WE'LL NEVER GET PROFESSOR JOBS WE'RE ALL SCREWED” and “THE WORLD IS TOO MUCH AND I AM TOO SMALL” and “HELP HELP HELP”. One week, we spent half the session arguing about whether you should print your name in bold when listing your publications on your CV. Like: Tweedledum, M.R. & Mastroianni, A.M., (2024). Please give me a job I will do anything, including publishing this terrible paper. The Journal of Desperation, 4(12), 122-137. vs. Tweedledum, M.R. & Mastroianni, A.M., (2024). Please give me a job I will do anything, including publishing this terrible paper. The Journal of Desperation, 4(12), 122-137. Some people thought bolding your name helps time-pressed hiring committees quickly assess your academic output. Other people objected that bolding your name looks presumptuous. A debate ensued. I forget who won—oh yes, it was none of us because this is a stupid thing to care about. This is obsessing over tiny predictors. It's scary to admit that you can't control the future; it's a lot easier to distract yourself by trying to optimize every decision, no matter how insignificant. (If you're at the point where you're spending 45 minutes debating the use of bold letters on your CV, perhaps you should consider pulling up a list of every god and praying to all of them in turn, in case one of them is real and decides to help you.) Parents who want to get their kids into elite colleges have perfected the art of obsessing over tiny predictors. When I gave campus tours, I would run into them all the time: “Should my kid play the timpani or the oboe?” “How many semicolons can you use in the personal essay?” “Can we include dental records to demonstrate a history of good brushing?” The joke was on them, of course: stressing about all those tiny things only makes you anxious, and even if your kid gets into a fancy school, they could still end up as a blogger. Impossible satisfaction Sometimes people will be like, “Well, whatcha gonna do, life is suffering,” and I’ll be like, “Haha sure is,” waiting for them to laugh too, but they won’t laugh, and I’ll realize, to my horror, that they’re not joking. Some people think the bog is life! I get why you might think this if you’ve experienced lots of misfortune. If you, say, survived the atomic bombing of Hiroshima and then took the train to Nagasaki just in time for the atomic bombing of that city, too, you'd probably have a gloomy outlook on life.4 But most of the people I know who feel this way haven’t survived any atomic bombings at all. They’re usually people with lots of education and high-paying jobs and supportive relationships and a normal amount of tragedies, people who have all the raw materials for a good life but can’t seem to make one for themselves. Their problem is they believe that satisfaction is impossible. Like they’re standing in a kitchen full of eggs, flour, oil, sugar, butter, baking powder, a mixer, and an oven, and they throw their hands up and say, “I can’t make a cake! Cakes don’t even exist!” WISHING YOU GOOD ALTITUDE In the big scheme of things, I haven't been alive for all that long. So there are probably lots of ways into the bog I haven't discovered yet. But I've been down there enough times to see the same patterns repeat, and sometimes I can even interrupt them. That's why having goofy names for them matters so much, because it reminds me not to believe the biggest bog lie of all: that I'm stuck in a situation unlike any I, or anyone else, has ever seen before. If you believe that, it's no wonder you'd suffer from insufficient activation energy, or bad escape plans, or self-bogging: you have no idea what to do, because you don't think anything you've learned, or anything anyone else has learned, can help you at all. Whenever I feel that way, whenever I think I'm in a bespoke bog, created just for me by a universe that hates me, if I can think to myself, “Oh, I'm gutterballing right now,” I can feel my foot hit solid ground, and I can start hoisting myself onto dry land. So, best of luck in 2024, and all the years to come after that. May you only spend as much time in the bog as is necessary to learn the lessons it has to teach you. And for goodness sake, if you see the side of a mountain coming toward you, pull up. Experimental History is impossible, it doesn’t even exist Subscribe 1 A periodic reminder that I am not a licensed mental health professional. I’m just a mop with a top hat on it. 2 Our leader claimed to be a Marine, which I kind of doubt because he spelled the name of our group as “Delta Companay” 3 See also Sasha Chapin ’s Certain ways that “try harder” can be a bad strategy. 4 In fact, Tsutomu Yamaguchi seems like he was remarkably upbeat despite witnessing some of the most horrific events in history, and I try to remind myself of this when I am frustrated about, for instance, a restaurant not slathering my burger with enough spicy mayo. Subscribe to Experimental History By Adam Mastroianni · Hundreds of paid subscribers 1) Find what's true and make it useful. 2) Publish every other Tuesday. 3) Photo cred: my dad. Subscribe Error 551 Share this post So you wanna de-bog yourself www.experimental-history.com Copy link Facebook Email Note Other 46 Share PreviousNext",
    "commentLink": "https://news.ycombinator.com/item?id=39942288",
    "commentBody": "So you wanna de-bog yourself (experimental-history.com)331 points by world2vec 20 hours agohidepastfavorite78 comments swatcoder 17 hours agoIronically, the root of most \"bogging\" is thinking too much instead of just doing things that need doing or that ripely present themselves. The author has reflected so much that they've created a bespoke system of abstract beliefs with catchy names and various example cases that they can summarize into a 5000 word essay and probably even extend into a book. For a writer, that's a sneaky but effective way to do their thing. (Or alternately: for a compulsive contemplator, writing is a sneaky way to justify the contemplating.) But for most people, reading something like this and reflecting on whether you also \"gutterball\" and also have \"toothbrushing problems\" is effectively feeding the beast. Many many of us in this community carry an urge to intellectualize and systematize and engineer things, but if you're interested in \"de-bogging\" that urge itself might be the thing to look most critically at. reply Satam 16 hours agoparentBefore reading the article, I was nodding along reading your comment. Having read the article... it's actually pretty good! \"Just doing things\" might be the right general approach but I feel that sometimes it's easy to get stuck contemplating. I think the post offers some interesting heuristics for getting unstuck. Edit: Reading even further, it's actually one of the best posts of this kind I've read in years. The author is spot in the behavioral patterns he's noticed. Damn. \"Often, when I’m stuck, it’s because I've made up a game for myself and decided that I’m losing at it. I haven’t achieved enough. I am not working hard enough and I am also, somehow, not having enough fun. These games have elaborate rules, like “I have to be as successful as my most successful friend, but everything I've done so far doesn't count,” and I’m supposed to feel very bad if I break them. It’s like playing the absolute dumbest version of the floor is lava.\" reply _factor 9 hours agorootparentMy biggest problem is contemplating all of the steps and future work that will go into a project, then getting disheartened as I begin. Eventually I delude myself into believing it’s not worth the effort as it might fail anyway. It’s probably a self-confidence thing, but so are most of the funny names in the article. I should probably just focus on step one once I decide the end result is valuable. reply mekoka 13 hours agoparentprevThe article all throughout points to the same root cause you point to. It clearly presents a mirror where we can see reflected all the stories we often fabricate to trap ourselves. Perhaps the author created a system. But I saw it rather as a device to better bring to awareness common but elusive mental patterns that keep us stuck. Although I'd agree with you that intellectualizing is often part of the problem, how do you then treat a disease, if the only medium available to administer the medicine is also the cause of the disease? How do you tell people that their mind is the reason they suffer without telling them? Even your own comment, as valuable as it is for pointing it out, feeds exactly the same beast that it accuses the article of feeding. That's the real irony. reply TrevorJ 16 hours agoparentprevI agree that most people are not biased towards action, and fixing that is the first step. However, the article is clearly aimed at people who have made that change and now are faced with the more subtle question of \"how do I think about the problem such that the action I choose is likely to be appropriate.\" reply henjodottech 17 hours agoparentprevIntention is cleansed in the process of forward motion. reply hellectronic 16 hours agorootparentThat is really good ! reply robocat 15 hours agoparentprev> they've created a bespoke system of abstract beliefs swatcoder, can you please tell me how you particularly manage to learn from your mistakes? Some people create personal theories of how the world works, and then put their theories into action: A successful example is Charlie Munger and heres his talk explaining some of his excellent theories: https://m.youtube.com/watch?v=Jv7sLrON7QY Some people overthink things and label things. That can be unhealthy, and Adam touches on that with his \"Stroking the problem\" section. But the opposite can be unhealthy too: not thinking at all and repeating over and over making the same mistakes. > catchy names Useful when communicating with others if it is an uncommon concept. I like to search for the perfect word or perfect catchphrase when thinking about a problem or solution because it helps my thinking. > various example cases How do you do it? Don't you look at specific issues you find in your own life? Examples yes? And then generalise from that? I just don't understand what you're complaining about. The closest I can think is that you're anti-intellectual or you're a \"Just do it\" prosyletiser - the implication being that thinking is unnecessary and the problem. Academic over-thinking is its own problem: is that your issue? Like most things: we need to find the right balance. Thinking too little is bad in a different way from thinking too much. > intellectualize and systematize and engineer things I'm just gobsmacked at your choice of words: is systemizing and engineering bad? I define engineering as making good compromises. Maybe you could find some catchier phrases from what you are trying to say ;-). \"intellectualize\": is thinking good or bad? I suspect I'm falling into the trap you mention - perhaps we both need to learn to write as well as Mastroianna!! reply swatcoder 14 hours agorootparentNavigating the world comfortably involves a balance of contemplation and action. As I tried to allude in my comment, most people here, myself included, are already heavily biased towards the former. We train ourselves to think deliberately and rationally, breaking down challenges into components, using and inventing abstract symbols and operations to get from where we are to where we need to be. It's our profession in many cases, and often we were called to that profession because we've got some natural inclination to approach the world that way. And it's valuable! I don't know that I could work on hard problems or take sound actions on some of the biggest and most impactful matters in my life without that. I value that I'm good at it, and practiced in it, and (like the author) think there's value in sharing the fruit of that work with others. I did exactly that in my original comment and I'm doing it again here. What I'm expressing is not a general critique against intellectualizing. It's cautionary advice that -- for many of the people here -- they (specifically) may experience more benefit resisting the urge to intellectualize rather than indulging in it. It's not anti-intellectual, nor is it especially novel. You can find comparable encouragement in both \"Eastern\" and \"Western\" traditions and from countless modern synthesizers of these traditions (Alan Watts, Werner Erhard, etc), who encourage brainy \"bogged\" intellectuals to just \"bonk\" themselves and stop expecting more thought and analysis to be the road away from their problems. In many cases, it's the intellectualizing itself that invents/perpetuates problems that simply cease to be if one can practice simply acting. Some people need the opposite advice, but few of them are going to be reading these comments in the first place and generally have different complaints than being stuck in s \"bog\". reply robocat 13 hours agorootparentIt's difficult alright. My father is very academic and he tends to start projects but not finish them. I also recognise the same fault in myself. But I've fought it hard and won a few times with some long-term successes (using a variety of personal strategies to avoid my unproductive tendencies). We have many concepts related to what you are saying: analysis-paralysis, productivity porn, ivory tower, etcetera, etcetera. I find the fields of psychology and philosophy are mostly tar-fields of unactionable thinking. Unfortunately I also find them interesting! Finding the gems in the tar is hard, but Adam seems to find a few of them. Here's another article of Adam's that seems relevant: https://www.experimental-history.com/p/excuse-me-but-why-are... reply gr8r 15 hours agoparentprevThe blog author does well to id/categorize the issues. People need a way to quantize+act on the issues - various systems exist for that. Key is to feel progress (on a particular direction/plan or at least in hindsight). Ideas that track such progress: -- 1-3 high quality decisions per week (credits to Bezos, tho he does 1-3 per day). -- 1-2 important/not-urgent tasks per week. 1-2 small, not-important/(semi-)urgent tasks per day - these are also a form of \"toothbrushing\" that each adult has to do. -- Bullet journal works well for both. reply Liquix 15 hours agoparentprev\"When we constantly pull everything apart trying to see how it works, we may end up with only an understanding of how to destroy something. We can have piles of spokes, rims and axles, but the beauty only happens when we see the wheel rolling.\" - Nick Sand reply financypants 15 hours agoparentprevAt the very least it led me to some self-reflection, was a short read, and very entertaining. reply PaulHoule 16 hours agoparentprevIt’s hypnotic writing in the style of Yudkowsky, Ron Hubbard or supplement scam videos on YouTube. On one hand it is pretending to be thinking rationally about things but with a heavy dose of fantasy mixed in that can put readers in a muddled mental state. They drone on and on and on so that you either give up reading it or go into a trance. reply rzzzt 53 minutes agorootparentSupplement videos never get to the (or any) point though - you can watch it for hours for amusement or just look up the company to see what they are selling. It's like that infinite GIF of a truck heading towards the security pillar, shown from all camera angles. reply bloomingeek 15 hours agorootparentprevGoodness! Please expand! reply ketzo 18 hours agoprevI really, really hate how many of my problems are toothbrushing problems. I know I just need to get over it and start brushing, but... ugh. Anyway, can't recommend Adam's writing enough. Subscribed after his second post and have never regretted it. If you liked this, you should also read \"You can't reach the brain through the ears\", an excellent piece about failing to communicate. https://www.experimental-history.com/p/you-cant-reach-the-br... reply munificent 17 hours agoparentThere is a liberating side to toothbrushing problems: the stakes of any given unit of effort are low. With diploma problems, if you blow it, you really blow it, with often irrevocable long-term consequences. All of your effort is building to a high stakes climax and if you miss your shot, that effort can all end up wasted. It's videogame permadeath mode for life. But with toothbrushing problems, you can have an off day and usually make it up today. Of course, every day's effort does matter. You can't make every day an off day. But I find something very comforting about problems where some random variance in my output does smooth out to the mean over time. reply ketzo 16 hours agorootparentYou know, that’s actually a great way to look at it. I think I feel like I can’t let myself excuse any slack, because I’m worried I’ll just start excusing everything — one day off at the gym becomes a week off, becomes a month off. But I guess the point is that no matter how much you have failed, the toothbrush problem is always best served by you starting again tomorrow, no matter how many tomorrows it takes. reply riskable 17 hours agoparentprev\"Everything needs maintenance.\" It's not just something a wise old engineer would say; it's life. Life itself is a Toothbrushing Problem. That is to say, if all your problems are Toothbrushing Problems then you're doing pretty good! That means you're living. At that point you can do one or all of these things: * Complain about your Toothbrushing Problems ( Terrible situations, once exited, often become funny stories or proud memories. Mediocre situations, long languished in, simply become Lost Years—boring to both live through and talk about, like you're sitting in a waiting room with no cell reception, no wifi, and no good magazines, waiting for someone to come in and tell you it's time to start living. It really resonates with me. During my life it did happen a couple times that I found myself \"stuck in mediocrity\" as the OP puts it. \"Waiting for someone to come in and tell you it's time to start living\" is a great analogy of how it feels when you finally realise it's time for a change reply weinzierl 19 hours agoprevBog in many slavic languages is God in English and used in many proverbs and idioms. This makes a hilarious headline, I thought this was about exiting god mode. reply SamBam 17 hours agoparentHuh! There is a YA novel I really like, The Girl Who Drank The Moon, and this casts that in a very interesting light. There is a bog -- a swamp -- that covers the known world, and this bog is treated in a religious way by the author as the embodiment of nature, of the fertility of the world. The bog also spawns a bog monster, who may have been the first living creature. \"In the beginning, there was the Bog. And the Bog covered the world and the Bog was the world and the world was the Bog.\" reply 5040 17 hours agoparentprevBogged has also come to mean something like 'having had drastic plastic surgery' in some circles, the expression being derived from 'Bogdanoff'. reply AvAn12 16 hours agoparentprevY'all probably also know that bog means \"toilet\" in British English... reply weinzierl 16 hours agorootparentBut a real Limey would never say \"Y'all\", so we don't believe you. reply riskable 17 hours agoparentprevSome say bog mode is harder to exit than vi. reply morsch 19 hours agoprevLife advice, unfortunately. Not an actual explanation of how to escape a bog. reply sieste 19 hours agoparentI know I'm setting the bar low, but compared to other pieces in that genre I found it well written, entertaining and insightful. reply pksebben 18 hours agorootparentFor sure, but throw me a rope here, it doesn't help the more immediate concern of this bog I'm stuck in. reply BlueTemplar 17 hours agorootparentYou could try pulling harder on your hair. (Sorry not sorry.) reply jabroni_salad 18 hours agoparentprevthis is now a chicago thread: https://en.wikipedia.org/wiki/Raising_of_Chicago reply WJW 17 hours agorootparentThank you random stranger for introducing me to this wonderful story! Pretty incredible they managed to do this in the 1850s already. reply hnthrowaway0328 15 hours agoprevMost of my problems lay in the fact that I do not like the way I am right now but do not have the power to get there or the power to make peace with myself. It's cliche but it IS impossible. Yeah it is a bog I made for myself but I did not ask for it. I kinda think this is a genetic thing. My father is like that too -- he is never happy, rarely content with himself, even when he already achieved a lot. reply datascienced 4 hours agoprevBest thing I have read, probably for years (outside of books). The insight here is brilliant. It doesn’t necessary help you get out of the bogs really, but for that a therapist might help. The lede is “brushing your teeth”. So much of life working depends on varieties of this. reply kajkojednojajko 6 hours agoprevI love the fact that he records voiceovers of his articles! I listen to podcasts on a regular basis, and this substitutes for podcast perfectly: it's shorter, but 10x higher quality. reply kashyapc 17 hours agoprevLast night I happened to listen to an episode[1] on EconTalk where the author of the post (Adam Mastroianni, a psychologist) was a guest. Definitely worth a listen. Adam also supports \"open science framework\" (https://osf.io/) and publishes his research and related artifacts there, which I really appreciate! [1] https://www.econtalk.org/a-users-guide-to-our-emotional-ther... reply veltas 17 hours agoprev> And while many religions teach that God intervenes in human affairs, none of them, as far as I know, believe that he responds to whining. (Would you worship a god who does miracles if you just annoy him enough?) It's not exactly as you say but it's roughly how I interpreted the parable of the unjust judge. https://en.wikipedia.org/wiki/Parable_of_the_Unjust_Judge reply fellowniusmonk 11 hours agoparentThat parable came to mind immediately. There is in fact a god that labels unanswered nagging as acting unjust. A lifetime ago in seminary I knew a guy who rage quit after spending months contemplating the implications of that passage and observations about how common it is to see others unanswered prayer. Don't know what happened to him but he would just mutter that his beliefs didn't matter since \"jesus defacto makes the claim he is unjust and defeats himself\", the problem of suffering indeed. reply cgriswald 14 hours agoprevRegarding “declining the dragon”: In my case “doing the brave thing” doesn’t feel good. It is the moment of greatest suffering and is usually followed by some useless anxiety that takes some time to dissipate. That’s why I’m avoiding it. It is only by recognizing that the suffering will end only after doing the brave thing that I can challenge the dragon. reply digging 17 hours agoprev> But most of the people I know who feel this way haven’t survived any atomic bombings at all. They’re usually people with lots of education and high-paying jobs and supportive relationships and a normal amount of tragedies, people who have all the raw materials for a good life but can’t seem to make one for themselves. Their problem is they believe that satisfaction is impossible. Like they’re standing in a kitchen full of eggs, flour, oil, sugar, butter, baking powder, a mixer, and an oven, and they throw their hands up and say, “I can’t make a cake! Cakes don’t even exist!” I found this an unpalatable paragraph in an otherwise insightful article. It seems to be, I don't know, recursive? Like saying \"one reason you may be stuck in the bog is that you're stuck in the bog,\" and ignoring the reasons people believe they don't have an out even with the ingredients for a \"good\" life. Drilling down into those reasons would, I think, result in exactly this same article...? reply munificent 17 hours agoparentYeah, I agree, that metaphor lacked an explanatory conclusion. If I had to fill one in, I'd say that people often blame the external world for not providing the ingredients necessary for happiness, when they actually do have them on hand already. What they are lacking is choosing to compose them into a meaningful whole, which requires effort on their part. reply digging 16 hours agorootparentThat makes sense. Maybe it's better described as \"not having the recipe\" or \"not knowing what land looks like\"...? I'm still not sure it's very useful though... it still feels like the awareness of \"I am in a bog, and land exists\" is a prerequisite for understanding the article at all. reply darepublic 16 hours agoprevSome of the small personal details in this blog were touching because I can relate, though I seldomly see them shared in this way from others. reply YeGoblynQueenne 10 hours agoprevAnd if you just wanna be-dog yourself... https://youtu.be/3gsWt7ey6bo?si=jMIA9GR1di2q7d_Y reply viburnum 18 hours agoprevIt sounds like none of this advice is working for the author. reply riskable 17 hours agoparentThe author scrounged together enough time, energy, and motivation to write the article. This suggests that they got out of the bog; at least for a little while :shrug: reply bovermyer 18 hours agoparentprevThat's not what I got out of it. It sounded like he instead was making an effort to recognize and categorize some of the problems he's experienced, and thereby create plans to avoid or mitigate them. reply munificent 17 hours agoparentprevEscaping the bog is a toothbrush problem, not a diploma problem. reply digging 17 hours agoparentprevWhat makes you think that? reply itscodingtime 11 hours agoprevIf you accept you do not have free will then, there’s nothing you can do. reply BlueTemplar 17 hours agoprevI've recently watched for the first time Neon Genesis Evangelion (+ The End of...), and powerful (and a bit painful) art like this seems to be a good slap in the face to get out of at least some of the versions of that bog - I'm a bit sad that I didn't watch it years earlier when I was stuck in some bogs... (Another commenter there mentions a quote recommending books - great literature I'm pretty sure in that context, not \"self help\" books... I guess I should hurry up and read Kundera's The Unbearable Lightness of Being already ?) reply sedivy94 17 hours agoparentFellow Neon Genesis fan here. Watching the original series was an incredibly frustrating experience for me. It does not follow the typical hero’s journey. There few wins, if any. Mostly losses. Idiot Shinji was a helpless and pitiful protagonist, so much so that you eventually stop rooting for him. The 1.11, 2.22, 3.33, and 3.0+1.0 rebuilds were much, much better in my opinion. But they also lacked that depressing trajectory that made the original series so unique. reply BlueTemplar 10 hours agorootparent> But they also lacked that depressing trajectory that made the original series so unique. Agree. Also, in that end, there's hope, even if the characters are still flawed, they have been forced to confront their issues and illusions, and (finally) are set on a realistically human path of growth. > The 1.11, 2.22, 3.33, and 3.0+1.0 rebuilds were much, much better in my opinion. Disagree, because of the above. Sure, plenty of eye candy (of both kinds), but it's gratuitous in Rebuilds. The \"biblical\" (mid-)themes are even more confusing. The character growth is only kind of earned if you actually watched the originals (with maybe the (tragic) exception of latest Rei and \"dad\", who finally does get a redemption arc). And even there, at a cost, as all the suffering of old Asuka (and our whiplash of empathizing with her) has basically been erased along with her original, all the while the new pilot, Mari, is never fleshed out, so her being there at the end doesn't feel earned, with her having been all along weirdly untraumatized and also hot for Shinji (gratuitous again). Many main characters literally get wished into a fairy tale ending. reply barrysteve 5 hours agorootparentprevOh come on. If Shinji's father had given him a 15 minute brief and debrief for every battle, that job would have been another day in the office for Shinji. He could of had a normal life, but the show sets him up to be trapped in hyper emotional relationships, influencing him to make irrational decisions all the time. He's a high school guy being manipulated by everyone around him, to fight battles he doesn't understand. reply immrammc 7 hours agoparentprev“The Unbearable Lightness of Being” is just fantastic. I think it’s well worth your time. I’ve read it a few times now. With each subsequent read at a different point in my life, it’s been interesting to see new insights and perspectives emerge. If you end liking it, another one from Kundera I particularly enjoyed was “The Book of Laughter and Forgetting”. reply seventytwo 16 hours agoprevGood read. I find myself doing a lot of these too. reply newfriend 7 hours agoprevbased and bogpilled reply taneq 15 hours agoprevFirst step is realizing you're in a statespace of low utility gradient. Colloquially put, everything's meh. Second step is to examine the separable components of said statespace. Is one increasing while another decreases? You're about to make a big life decision! Are they all meh? Well fuck. Uh I mean, decompose them further and repeat. Eventually you'll find a meta level where the components of the meh are divergent vectors that sum to zero, and there's your buried n-lemma. If everything's truly flat and boring for long enough, eventually you'll dig down to causal bedrock where the quantum noise will create signals for you whether you want them or not. Doesn't matter, because at this point, does anything? So just do the thing, you have nothing to lose. reply barfbagginus 17 hours agoprevFirst, debog your blog by removing the enshittware Second, start working to deconstruct capitalism and the state Tada, u no longer feel bogged reply weregiraffe 13 hours agoparent>Second, start working to deconstruct capitalism and the state Or just kill yourself, it will achieve the same result, but faster. reply hungariantoast 5 hours agorootparentDeconstructing capitalism and the state = killing yourself? Deconstructing capitalism but preserving the state = purging millions of people? Preserving capitalism and the state = killing millions of poor people? Preserving capitalism but deconstructing the state = killing millions of poor people, but cyberpunk? reply paradoxyl 19 hours agoprevFailure to define your meaning of \"bog\" in the opening paragraphs leads to unneeded frustration. reply ziddoap 18 hours agoparentIt is made fairly clear by sentence #5 what the author means by \"bog\". And by sentence #7 it is made crystal clear. You barely need to start reading to understand what the author meant. reply digging 18 hours agoparentprevI don't agree. If the article started explaining how and why to de-bog oneself without defining bog, that would be annoying. But this one simply has a short, helpful, interesting introduction and then immediately defines \"bog\" before moving on. It's well structured IMO reply Etheryte 17 hours agoparentprevFailure to define your meaning of \"unneeded frustration\" in the opening paragraph of your comment leads to unneeded frustration. reply hailmac 18 hours agoprev [–] Functionally not that different from a listicle - and at least those aren't so concerned with sounding smart reply PaulHoule 18 hours agoparentHe has \"history\" in the name of his blog and he thinks that knights expected to fight dragons? I mean, it is like that in a manga but not in real life. Quite a few knights in the day were nobles who had large landed estates to manage but were expected to impress their peasants in time of war. They were lucky enough to go to war with heavy armor and mounted on a horse whereas the peasants might get some weapon that is easy to handle without a lot of training like a spear. reply jaredhallen 10 hours agorootparentMaybe I'm being too generous, but I didn't take that to be meant in a literal, historical sense. I mean for the purpose of metaphor, a literary trope is just as good as factually accurate history. The point is that people can relate. reply digging 17 hours agorootparentprev> He has \"history\" in the name of his blog and he thinks that knights expected to fight dragons? I mean, it is like that in a manga but not in real life. I mean, \"experimental history\", so I don't expect real, academic history... that said, yeah, that was an insane analogy to make. Knights weren't, as a rule, wandering monster-slayers - anywhere or ever, as far as I know. Knights' bravery was tested on the battlefield, where they would have a very good expectation of survival until approximately post-Agincourt (where it became more socially acceptable to execute wealthy enemies instead of capturing and ransoming them). But that's also an extremely high-level description which may be so generalized as to be inaccurate. reply Apocryphon 17 hours agorootparent> Medieval knights used to wander around hoping for honorable adventures to pop up so that they could demonstrate their bravery. That is a loose pop historical way of describing the chivalric tradition, but it did exist in some fashion. The dragon reference also exists in a passage that is being airily allegorical, you're all being overly anal about accuracy. reply digging 17 hours agoparentprev [–] Well, then how would you turn this into a listicle? \"17 ways you get stuck in a bog (in 3 categories) (and also: what is a bog) (and also: what it means to get unstuck from the bog)\" Seems a pretty shit listicle; maybe it should be a full article :) reply rzzzt 15 hours agorootparent [–] Number 15 will bog you! reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article addresses feeling stuck in life, offering advice on overcoming this common experience.",
      "The author shares personal insights & strategies to break out of a rut, emphasizing the importance of taking action & making changes.",
      "Readers are encouraged to recognize patterns, navigate challenges, and find paths towards a better life based on the challenges imposed by misconceptions and self-imposed limitations."
    ],
    "commentSummary": [
      "The article highlights strategies to overcome overthinking and self-imposed obstacles by de-bogging oneself, stressing the importance of balancing contemplation and action.",
      "It offers practical tips to get unstuck and progress towards goals, touching on themes of character development in an anime series, philosophical thoughts on societal structures, and interpreting historical and metaphorical references."
    ],
    "points": 331,
    "commentCount": 78,
    "retryCount": 0,
    "time": 1712324594
  },
  {
    "id": 39944496,
    "title": "The Silicon Graphics Saga: From Innovation to Bankruptcy",
    "originLink": "https://www.abortretry.fail/p/the-rise-and-fall-of-silicon-graphics",
    "originBody": "Share this post The Rise and Fall of Silicon Graphics www.abortretry.fail Copy link Facebook Email Note Other Discover more from Abort Retry Fail In Abort Retry Fail, I am attempting to chronicle the history of the computing industry. This is a goal that will likely not be completed within my lifetime. Subscribe Continue reading Sign in The Rise and Fall of Silicon Graphics or How a Rebellious Youth Briefly Conquered the World Apr 04, 2024 9 Share this post The Rise and Fall of Silicon Graphics www.abortretry.fail Copy link Facebook Email Note Other Share James Henry Clark was born on the 23rd of March in 1944 in Plainview, Texas. Clark’s family was far from wealthy. His father was fond of drinking and couldn’t keep a job. His mother worked at a local doctor’s office making about $225 per month (around $2605 in 2024). Clark’s parents divorced while Clark was still young, and while that salary may seem fine if low adjusted for inflation, Clark’s mother would only have received $175.50 ($2032) after income tax and social security tax, and it was the sole income for a woman and her three children. For himself, Clark was a bit rowdy. His high school highlights include setting off a smoke bomb on the band bus, smuggling a skunk into a school dance, telling his English teacher to go to Hell, drinking, and drag racing. Given the era, I imagine that the drinking was accompanied by chain smoking. That times were different is… inadequate verbiage. For all the unruly behavior, Clark was only suspended from school twice. On his second suspension, young Clark decided he’d not be returning to school. He chose to join the US Navy and convinced his mother to sign the permission forms. Of course, this is Jim Clark, and the initial days of his naval career didn’t exactly go well. Clark had never taken a multiple choice test. He thought that for many questions more than one of the answers were at least partially true and therefore selected them. The officers in charge of test administration thought that Clark was attempting to fool the computer that checked the answers, and he was immediately sent out to sea with other delinquent recruits where he was given poor treatment, and rough and disgusting chores. The experience of Naval life lit a fire in Clark, and he chose to advance his station in life. He began learning about electronics, taking some general educational courses, and offering loans to other sailors at up to forty percent interest. His first step was to get his General Education Diploma, which he did. He then enrolled at Tulane. Clark did well at Tulane but transferred to the University of New Orleans from which he received his BS and MA in Physics. He then attended the University of Utah where he earned his Ph.D. in computer science in 1974. From 1974 through 1978, Clark was employed as an assistant professor at UC Santa Cruz, but he left to become an associate professor at Stanford in 1979. Jim Clark Early in his time at Stanford, Clark worked on a project with Xerox PARC with support from ARPA to develop three dimensional graphics. This led to the creation of the Geometry Engine. In “The Geometry Engine: A VLSI Geometry System for Graphics,” Clark also makes specific reference to Marc Hannah and Lynn Conway as being valuable contributors to the effort. What was the Geometry Engine? It was a special purpose microprocessor that handled matrix math along with point mapping. It featured an instruction set suitable both to 2D and 3D graphics, could generate quadratic/cubic curves and conic sections, worked with both vector and raster based systems, and operated in either integer or floating point systems as needed. In fewer words, Jim Clark and his team at Stanford along with the folks of PARC invented the GPU. The Geometry Engine: A VLSI Geometry System for Graphics 1.01MB ∙ PDF file Download The Geometry Engine: A VLSI Geometry System for Graphics Download The Geometry Engine, image from ACM via Stanford Clark founded Silicon Graphics Inc on the 9th of November in 1981, and he left Stanford early in 1982 to pursue building the company full time with just $25000 in funding (around $85000 in 2024) from a friend and the contents of his own accounts. Accompanying Clark in this adventure were Kurt Akeley, Dave Brown, Tom Davis, Mark Grossman, Marc Hannah, Herb Kuta, Rocky Rhodes, and Abbey Silverstone. While SGI knew they would deal in computers outfitted with a powerful GPU, they did not know precisely what else those computers should feature. As a result, Clark asked potential customers what they’d like to see in a workstation. While at least one potential customer was interested in VMS, NASA’s new Advanced Supercomputing division was very interested in UNIX and they were willing to pay. The division’s director at the time spoke with Clark, and (verbally) committed to purchasing at least eighteen workstations in their first order. As things began to come together around a product plan, Mayfield invested in the young company. As the development and production of workstations is rather expensive, Clark and SGI’s other founders were forced to sell more and more of the company’s ownership to keep operating. The first product to ship was the IRIS 1000, where IRIS meant Integrated Raster Imaging System, in November of 1983. This machine was intended for use as a terminal for a VAX-11 and featured a Motorola 68000 clocked at 8 MHz with 768K RAM, a Geometry Engine clocked at 6 MHz capable of over six million geometric floating point operations per second, and a 10 Mbps ethernet NIC. The cabinet of the IRIS 1000 was ten inches wide, twenty one inches tall, twenty seven inches deep, and when fully assembled weighed in at one hundred pounds with a ten slot backplane. This machine was followed by the IRIS 1200 which was the same machine but with a twenty slot backplane. These were followed by workstation models 1400 and 1500 in April of 1984 which upgraded the CPU to the Motorola 68010 clocked at 10 MHz with 1.5M of RAM. These machines were differentiated from one another in the size of HDD they featured with the 1500 having been larger. The 1400 featured a 72MB winchester disk, while the 1500 featured 474MB of SMD. Both of these ran a UNIX SVR4 variant with BSD enhancements called GL2, and they featured twenty slot backplanes. The main system boards in these four machines were licensed from Andy Bechtolsheim just before he founded Sun Microsystems. The 1000 and 1200 used the PM1 and the 1400 and 1500 used the PM2. These were not cheap systems with the IRIS 1000 having a price of $22500 (around $67200 in 2024) and the 1400 having a price of $35700 in 1984 (around $106600 in 2024). These twenty slot machines were eighteen inches wide, twenty nine inches tall, and twenty seven inches deep, and fully assembled weighed in at two hundred pounds. By the time the first of these machines sold to Carnegie-Mellon University’s Electronic Imaging Lab, the founders of SGI owned very little of their company. From nearly the first day that SGI’s hardware was on the market, software developers began trying to exploit the machines’ graphics capabilities. A rather prominent example of this was Wavefront Technologies in Santa Barbara led by Bill Kovacs, Larry Barels, and Mark Sylvester. Their first product was called Preview and launched in 1984 on SGI’s hardware. Their customer list included Universal Studios, NBC, NASA, and Electronic Arts. Naturally, this also informs us that these companies were using SGI hardware. Given the outline of his youth, it isn’t very surprising that Clark was a hands-off kind of manager. He would hire the brightest minds he could, set a general target, and then let people go after it however they saw fit. There are two narratives for what follows. The first and most common that I’ve read was that Mayfield didn’t much care for Clark’s management style and they brought Ed McCracken formerly of HP in as CEO. The second narrative states that Clark didn’t care for running the company and brought McCracken in on his own accord. Whatever the case, McCracken stated of Clark: Jim's not a day-to-day person. He works in his own time frame. He takes complex things and makes it simple. It might take a month, a day, or a year. He gets in these moods for a while where he's almost unavailable. He's most effective when he's in that mood. In August of 1985, the company introduced the IRIS 2000 series of workstations. These machines were all based upon the the PM2 system board featuring the Motorola 68010 clocked at 10 MHz with a floating point coprocessor (SKYFPM-M-03). Naturally, these all featured the graphics engine as well. The IRIS 2000 and 2200 were ten slot backplane, shipped without a disk, and were intended for use as terminals. The 2300 and 2400 were twenty slot backplane and shipped with winchester disks. The IRIS 2500 was rackmount and used SMD disks. The 2000 series used a Geometry Engine clocked at 8 MHz. A few months after the initial launch of these upgraded machines, SGI launched the turbo line. This included the 2300T, 2400T, and 2500T which featured the IP2 system board with a Motorola 68020 clocked at 16 MHz, an FP1 floating point unit, and 2MB to 16MB of RAM. The RAM of the turbo units used a newer, faster, local bus. As a result, the RAM between turbo and non-turbo systems could not be mixed. This was an important bit of information as SGI did offer turbo upgrades for non-turbo systems that would then require the purchase of expensive proprietary memory. In January of 1986, SGI made their initial public offering raising $17.2 million (nearly $49 million in 2024) with trading having started at $3 per share and topping $30 on the day. The following month, the company introduced the IRIS 3000 line. These are very similar to the IRIS 2000 turbo machines but with Enhanced IRIS Graphics. These featured either ten or twelve Graphics Engines clocked at 10 MHz with either eight or thirty two bitplanes depending upon configuration. The 3000 line could be ordered with either winchester disk drives, ESDI drives, or SMD. Also in 1986, Control Data Corporation and Silicon Graphics signed a deal under which CDC would resell IRIS machines under CDC’s own branding. As far as I know, no complete listing of which models sold under what naming survives today, but it is known that the IRIS 3130 was resold as the CDC Cyber 910. This would make it a machine with twelve GEs at 10 MHz and ESDI drives. IRIS 3130, rebadged by Control Data, image from sgistuff.net In March of 1987, Silicon Graphics announced a new machine that marked a major transition for the company. The Professional Iris was a RISC machine built around the R2000 from MIPS Computer Systems (another project started at Stanford and spun out as its own company) clocked at 8 MHz. The company’s press release read: The first member of the Iris line is the 4D/60, a RISC superworkstation with a 32-bit 8 MHz CPU from MIPS Computer Systems. It offer performance three times that of the Silicon Graphics Iris 3100 series. The graphics performance has been enhanced with 38 custom and semicustom graphic chips. It performs 140,000 32 bit three dimensional floating point transformations per second and renders over 4,500 100-pixel polygons per second with smooth shading and hidden surface removal. It offers 24 colour bit-planes for more than 16 million colours; four user-accessible system planes for overlay or underlay, menu and windowing functions; a 24-bit Z-buffer enabling hidden surface removal with greater accuracy and realism; high-level primitives such as splines and surfaces for more accurate renderings; and a multi-mode graphics windowing environment. Standard configuration includes 4Mb CPU, eight colour bit-planes for 256 colours); four system planes, a Weitek-based floating point accelerator board; a 170Mb ESDI disk and controller; a 19″ 1,280 by 1,024 60Hz non-interlaced colour monitor; keyboard and mouse; and a floor-standing chassis with 12 VME slots and a 1,000-watt power supply. Software compatible with the previous generation, it runs Unix System V.3 with a base price of $74,000. The Professional Iris line included the 4D/60 mentioned in the press release followed by the 4D/50, 4D/70, 4D/80, and 4D/85. All of these featured the R2000 CPU with a floating point coprocessor. The 50 and 60 had an R2000 clocked at 8 MHz, while the 70 was at 12.5 MHz, and the 80 and 85 were clocked at 16.7 MHz. For comparison to other architectures, the 4D/50 was capable of seven million instructions per second, the 70 was capable of ten million, and the 80 was capable of thirteen million. The 50 and 60 had memory configurations starting at 4MB and upgradeable to 12MB. The rest of the lineup started at 8MB and could be upgraded to a maximum of 144MB. The first of the 4D/60, 50, and 70 systems to ship utilized the Clover 1 graphics system. Later models shipped with Clover 2 branded as IRIS GT. IRIS GT brought hardware support for lighting, smooth shading, antialiasing, pan/zoom of images, arbitrarily shaped windows, and other rather modern capabilities. Importantly, the bus for this system was a proprietary 64 bit bus. The actual chips powering all of the graphics capabilities were still the Graphics Engines, but these were updated some and they were capable of twenty million floating point operations per second. The Professional Iris series brought an end to the disk anarchy of the previous lineup and all systems utilized SCSI hard disks, and QIC-120 tape drives were also available. These systems were resold by both Control Data Corporation and Prime Computers. The UNIX version mentioned in the press release was SGI’s 4D1 which would later be renamed IRIX. On the 29th of March in 1988, Control Data Corporation announced that it would be acquiring twenty percent of Silicon Graphics for $68.9 million (nearly $181 million in 2024) and extending its licensing deal for reselling SGI’s machines with an agreement to purchase $150 million (around $393 million in 2024) in hardware over the next three years. On the 16th of September in 1988, SGI announced that IBM would be purchasing graphics cards and licensing IRIS GL, the software library for SGI’s graphics, for use in the IBM RS/6000 POWERStation. McCracken commented: We are pleased to establish a relationship with IBM and look forward to working with them. The agreement reinforces our long-time conviction that three-dimensional graphics will become a mainstream technology in the computer industry. As real-time 3D graphics is made more affordable, the rapid growth that the 3D workstation industry is experiencing will continue to escalate. The card in question was the IrisVision, and while I refer to it as a card, it was really two cards. The primary card held the Graphics Engine and daughter cards held the framebuffer and z-buffer memories totaling 5MB for the framebuffer and 3.75MB for the z-buffer. The primary card connected to the computer via its MCA bus edge connector, and it provided a DE-15 connector for display attachment. Overall, the IrisVision MCA card’s hardware was extremely similar to the graphics system in the SGI Personal Iris series introduced in 1987. It featured SGI’s fifth generation geometry processing pipeline (referred to as GE5, or Graphics Engine five), either an eight or twenty four bit per pixel frame buffer, and twenty four bits per pixel z-buffer. Also, just as the workstations’ hardware did, the IrisVision implemented the entire IrisGL API in hardware. The primary difference in IrisVision was the presence of a VGA (DE-15) passthrough for 2D graphics. In the course of the IrisVision’s development, an IBM PS/2 running OS/2 was used for testing and development. This resulted not only in a minimal OS/2 driver, but also in an ISA version of the IrisVision being developed. Ultimately, the only major customer SGI had managed to obtain was IBM for the MCA card for the RS/6000 UNIX workstations. Their struggle may have been that the card was priced at $4995 (just over $13000 in 2024). The company ultimately spun off the entire project as a separate company, Pellucid, which didn’t fare well. The former SGI employees who started Pellucid still managed to change the world when they founded 3dfx which used similar technology as well as the passthrough for 2D graphics. SGI held a rather firm grasp on high-end graphics workstations, but hadn’t yet made a push into the entry level market. This changed with the introduction of the Personal Iris lineup. The line started with the 4D/20 which made use of a R2000 CPU from MIPS clocked at 12.5 MHz achieving ten million instructions per second. The other three machines made use of the R3000. In the 4D/25 the R3000 was clocked at 20 MHz achieving sixteen million instructions per second. In the 4D/30, the clock speed was pushed to 30 MHz and the performance was bumped to twenty seven million instructions per second. The highest performance model was the 4D/35 at 36 MHz and thirty three million instructions per second. Maximum memory supported on these systems was 128MB. Personal Iris systems were sold by both SGI and Control Data as expected, but these systems were also offered rebadged by the somewhat newly reconstituted Groupe Bull. From what I can find, Bull’s sales of rebadged SGI machines weren’t great; they had better luck with NEC hardware. For the naming “Personal Iris” and the thought that SGI would be attacking the “low-end” of the workstation market… the pricing wasn’t all that reflective unless one were to compare to “high-end” SGI machines which could reach lofty prices of about $100000 (about $262000 in 2024). The Personal Iris line started at $20000 (roughly $52000 in 2024). SGI Personal Iris, press image from SGI The other, much higher end and far more expensive, SGI lineup introduced at this time was the PowerSeries which were multi-processor systems (up to eight CPUs) and could be deskside or rackmount. These systems could also support higher clocks at up to 40 MHz which in combination with up to eight processors could mean performance over two hundred thirty million instructions per second. The power of these systems was put to use in the movies The Abyss, Terminator 2, and Jurassic Park among many more. In March of 1991, Compaq acquired thirteen percent of SGI for $135 million (around $307 million in 2024) along with an agreement to invest another $50 million (about $114 million in 2024) in the development of a new workstation that would be priced at around $7500 (roughly $17100 in 2024). The most famous and beloved SGI systems were introduced from 1991 to 1995. These models were the Indigo, Indigo 2, and the Indy. The corresponding high-end systems were the Crimson, and Challenge series. The first Indigo system released in 1991 featured a MIPS R3000 CPU clocked at 30 MHz. The Indigo (and Crimson) moved SGI’s systems to 64 bit MIPS CPUs starting with the R4000 at 100 MHz and the R4400 at 150 MHz in 1992. The 150 MHz part in an Indigo could achieve one hundred twenty million instructions per second. The Indigo 2 was first introduced in 1993 with the MIPS R4400 CPU and “Extreme” graphics. The Indy was lowest end SKU of the three, and it was introduced in July of 1993 with a 100 MHz R4000PC CPU, 24 bit graphics system, 16MB of RAM, the IRIX operating system, a fifteen inch monitor, and a price of $4995 (about $10700 in 2024). SGI Indigo 2, image from unixhq.com SGI Indigo 2 10000 IMPACT, from my personal collection On the 13th of March in 1992 announced that it was acquiring MIPS Computer Systems via a stock swap worth about $333 million (around $737 million in 2024). This followed MIPS having had financial problems, high employee turnover, and the exit of the company’s president, Charles Boesenberg, one month earlier. For SGI, the acquisition ensured their part supply. MIPS Computer Systems became MIPS Technologies. The combined company had revenues at around $1 billion (about $2.21 billion in 2024). However, the large acquisition did mean that SGI posted a loss on the year of about $118 million (or $261 million in 2024). This move also briefly brought SGI into the ACE alliance that aimed to build a workstation standard on the MIPS CPU and the UNIX operating system as well as the 80386/486 and NT. This group was built of Compaq, MIPS, Microsoft, DEC, SCO, Acer, CDC, Kubota, Olivetti, NKK, Prime Computer, Pyramid Technology, Siemens, Sony, Sumitomo, Tandem, Zenith, and Wang. SGI and Compaq left the alliance rather promptly. This could be due to their own arrangement not long before, but ACE fell apart completely not much later anyway. I suspect that no strong alliance of fierce competitors would last long in a market that was shrinking due to low-cost commodity hardware and software consistently improving year over year in the PC compatible market. Yet, the SGI Indigo 2, Indy, Challenge and a few more were mildly compliant with the ACE ARC (Advanced RISC Computing) standard. On the 30th of June in 1992, Silicon Graphics released OpenGL. This was a cross-platform API for both 2D and 3D graphics allowing hardware acceleration of rendering via one or more GPUs descended directly from IRIS GL. Unlike its predecessor, OpenGL did not have windowing, and it didn’t offer a mouse or keyboard API. IRIS GL had been developed before X and other graphical environments were available, and therefore had needed those features, but OpenGL had no such requirements. Another major change in the transition to OpenGL regarded feature availability. IRIS GL presupposed the use of SGI’s hardware. OpenGL could not make such an assumption, and as a result it allowed features not supported by a GPU to be rendered in software by the CPU. One customer this would positively affect was Microsoft who’d licensed IRIS GL for inclusion in NT in 1991. At the end of 1992, Jim Clark met with Nintendo CEO Hiroshi Yamauchi to discuss bringing 3D graphics to Nintendo’s next game console. In many ways, the Nintendo 64 was an SGI workstation in miniature with a MIPS R4300 CPU clocked at 93.75 MHz offering one hundred twenty five million instructions per second, 4MB of Rambus DRAM at 250 MHz (actually 4.5MB but 512K is visible only to the GPU) which could be doubled with a RAM expansion pack, and the Reality coprocessor clocked at 62.5 MHz which offered the SGI GraphicsEngine (though a more modest version). The system supported 16.8 million colors, a maximum resolution of 640x480, and audio sampled at up to 44.1 KHz. Unfortunately, the design of the system meant that the full capabilities would almost never be fully realized. For example, there was no dedicated sound chip, so high sample rates would tax the CPU, and while the R4300 is 64 bit, the Nintendo 64 had a 32 bit data bus. Yet, showing the nature of the hardware packed into the Nintendo 64 is the Nintendo 64DD. This offered 64MB read/write magnetic disks (similar to Zip), a real time clock, internet connectivity via a 28.8 kbps modem, keyboard, mouse, and audio/video capture effectively transforming the Nintendo 64 into a small workstation. The expansion, after significant delays and a one year two and a half month life on the market, was a commercial failure. The Nintendo 64 itself, however, was a huge success following its release in 1996. Industrial Light and Magic had been using SGI hardware since 1987, and on the 8th of April in 1993, they announced a partnership with SGI to create the Joint Environment for Digital Imaging, or JEDI. This allowed the two companies to gain insight from each other’s work. SGI got access to much of ILM’s software expertise while ILM got access to the latest and greatest hardware at a discount. In 1994, Jim Clark left SGI, sold his shares in the company, and went on to partner with Marc Andreessen and start Netscape. In 1995, SGI spent about $500 million (or $1 billion in 2024) acquiring Alias Research, Kroyer Films, and Wavefront technologies. At roughly the same time, SGI worked with DreamWorks SKG to form DreamWorks Digital Studio where these newly acquired companies’ products could be put to good use. On the 26th of February in 1996, Silicon Graphics acquired Cray Research for $740 million (or $1.47 billion in 2024). This gave SGI control of around forty percent of the high performance computing market at the time. While many industry analysts speculated about SGI’s motives, Cray was struggling to survive and they had multiple installations at NASA. While SGI had been successful in entertainment, that sector accounted only for something around ten percent of SGI’s annual revenues. The bulk of SGI’s customers were governmental, so much so that SGI created the wholly owned subsidiary Silicon Graphics Federal Inc to hold those contracts and provide service and support for governmental organizations. In this way, SGI was essentially making sure they couldn’t lose one of their largest and most valuable customers, NASA, as they’d be the provider of not only workstations but also the support and service of NASA’s supercomputers. The supercomputer relationship benefited SGI all the way to 2008 with Pleiades. Cray Y-MP Model D installation at NASA’s Glenn Research Center, image from Clive England via cray-history.net The new SGI workstations of 1996 were the O2 and O2+ series. These systems were very different from both their predecessors and successors in that they utilized a unified memory architecture via the Memory & Rendering ASIC (MRE). The MRE had direct paths to all parts of the O2 such as the CPU, memory, I/O, compression, display, and imaging. Due to this structure, graphics hardware wasn’t optional but rather integral to the system’s design. The O2 could come equipped with an R5000, RM5200SC, RM7000A, R10000, or R12000 CPU. Frequencies ranged from 180 MHz to 400 MHz, all options had on-board floating point support, and could support up to 1GB of unified memory via eight 128MB DIMMs of one hundred thirty nine pin SDRAM. The high-end deskside and rackmount options made available at this time were the Origin 2000, Origin 200, and Onyx 2 series. These were multiple CPU systems with distributed, shared-memory architecture called S2MP. The Origin 200 was the entry level system, the Onyx 2 was a step up, and the Origin 2000 was the premium SGI branded system and was rackmount. This series also had Cray Origin at the super-premium level with up to one hundred twenty eight R10000 CPUs. The IRIX operating system shipped with these models supported SMP. On the 14th of May in 1997, SGI announced the acquisition of ParaGraph International Inc. ParaGraph was a vendor of VRML and web graphics software, and after the acquisition the company and its assets were moved to Mountain View with the new name of Cosmo Software. McCracken commented: One of the most important long-term growth opportunities for Silicon Graphics is to empower the designers, developers, and service providers of the Second Web. With the acquisition of the leading PC 3D Internet company and the formation of Cosmo Software, we are increasing our investment and reinforcing our leadership in the market for the software and services that will bring about this new interactive medium. Bringing the technologies of Onyx 2 series to the midrange workstation was the Octane, released in January of 1997. This was the a desktop machine instead of deskside, but it supported dual CPUs. This line featured the crossbar switch that debuted in the high-end and server machines of the prior year. The concept was that instead of a traditional shared bus, each subsystem could communicate with any other without interference. The crossbar switch had seven ports: HEART ASIC (CPU and memory), graphics (Impact [first or second generation] or VPro), XIO B, XIO C, XIO D, built-in I/O, PCI bridge. The Octane did have a higher-end version, the Octane 2, which featured more powerful CPUs and GPUs, higher density memory support, and a beefier PSU. CPUs in the Octane ranged from the R10000 at 175 MHz to the R14000A at 600 MHz, and RAM ranged from 64MB to 2GB. Silicon Graphics didn’t do too well in 1997 overall. For revenues of $3.6 billion (or $7 billion in 2024) the company posted a loss of $78.6 million (roughly $152 million in 2024). On the 29th of October in 1997, Ed McCracken resigned as did the executive vice president of sales and marketing, Gary Lauer. The company then laid off around nine percent of its employees (about seven hundred people). Richard Belluzzo (formerly at HP) took over as CEO and Robert H. Ewald who was already the executive vice president of computer systems (formerly president of Cray) took over Lauer’s job duties. Some sources claim that McCracken was forced out, but this isn’t accurate. At the annual shareholder meeting in Palo Alto, McCracken announced his resignation stating: “after a great deal of thought, the time is right for me and the company to make a change.” He then proceeded to find and to hire his replacement himself. Around this time, Silicon Graphics filed a lawsuit against a startup called ArtX. ArtX was founded by Dr. Wei Yen and around nineteen other SGI employees who’d worked on the Nintendo 64. The company’s original goal was to develop a PC graphics chip that would rival 3dfx. Then, in May of 1998, the company gained a contract to develop a graphics processor for Nintendo’s next generation game console, the GameCube. At COMDEX in the autumn of 1999, the company unveiled the Aladdin 7 chipset which shipped as integrated GPUs on K6-2 and K6-3 motherboards made by Acer Labs. ArtX was bought by ATI in February of 2000. ArtX’s technology was incorporated into ATI’s GPUs from 2002 until roughly 2005. SGI’s lawsuit against ArtX was quietly dropped in 1998 without any settlement having been reached. On the 1st of January in 1998, shortly after taking over as CEO, Belluzzo sold two of SGI’s PCB factories and restructured the company from twenty six groups to just five. SGI then setup MIPS Technologies as its own legal entity (though SGI maintained a majority ownership), terminated the Cosmo software business, and proceeded to make customers hesitant to continue investments into the MIPS architecture by announcing SGI’s intent to migrate to Itanium (and collaborating on projects Monterey and Trillian) while simultaneously launching an IA-32 series of machines running NT known as the Visual Workstation. Additionally, the company began outsourcing the manufacturing of their computers, and cut the operating budget by about $200 million (or $381 million in 2024). In Spring of 1998, the company announced a lawsuit against NVIDIA for patent infringement. None of this helped to change the overall direction of the company. Revenues fell to $3.1 billion and the company posted a loss of $460 million for 1998. On the 20th of July in 1999, without adequate funding to continue the lawsuit against NVIDIA, SGI and NVIDIA agreed to license one another their respective patent portfolios. The company continued to lose money, and Belluzzo left on the 22nd of August in 1999 to lead Microsoft’s MSN division. As Bob Bishop took the reigns of SGI, things looked dark. AMD announced their 64 bit architecture in October, PC graphics had made massive strides while remaining significantly less expensive than SGI’s offerings, NT was proving to be a solid and less expensive competitor to UNIX, Linux was eating away at traditional UNIX market segments, and Itanium still hadn’t launched. By this point, the company had no fall back as they’d mostly stopped investment into new MIPS CPUs. On the 2nd of March in 2000, SGI sold Cray to Tera Computer for $22 million (or $40 million in 2024). Tera promptly renamed itself to Cray Inc as it took on an installed base of six hundred supercomputers and two hundred customers across thirty different countries. SGI’s final MIPS workstations were the Fuel and Tezro lines. Fuel was introduced in 2002 with the R14000 clocked at 500 MHz, up to 4GB of DDR SDRAM, and SGI’s VPro graphics. Models were available with up to an R16000 CPU clocked at 900 MHz. The Tezro was launched in 2003 starting at $20500 (or $34574 in 2024). This model featured only the R16000 and could be configured at clock speeds from 600 MHz to 1 GHz with 512MB to 8GB of DDR SDRAM and SGI’s VPro graphics. Fuel workstations were single CPU, but Tezro was offered with one to four CPUs. While SGI’s IA-32, Itanium, and Xeon workstations and servers sold, they didn’t make much money. On the 10th of July in 2003, SGI vacated and leased their headquarters to Google. SGI’s headquarters after becoming the Googleplex, by Coolcaesar at English Wikipedia As SGI’s fortunes continued to decline, the company sold Alias Systems (formerly Alias|Wavefront) for $58 million on the 16th of April in 2004 to Accel-KKR (roughly $95 million in 2024). Then, in November of 2005, SGI was delisted from the NYSE due its stock price sinking below the minimum required. In January of 2006, Dennis McKenna was hired as president and CEO, and named chairman of the board. Bishop remained on the board of directors and served as vice chairman. On the 8th of May, the company filed for bankruptcy protections. The campus leased to Google was sold to Google in June of 2006 for $319 million (or $491 million in 2024). It’s prior home in Mountain View had been sold to the Computer History Museum in 2002. The company emerged from bankruptcy and was relisted in October. The official end of SGI’s MIPS and IRIX came on the 29th of December in 2006 with the final orders being fulfilled in March of 2007. Bob Ewald replaced McKenna as CEO on the 9th of April in 2007. In December of 2008, SGI was again delisted. On the 1st of April in 2009, the company filed for bankruptcy, and was subsequently purchased by Rackable Systems for around $42 million on the 11th of May in 2009 (roughly $65 million in 2024). Rackable renamed itself Silicon Graphics International following the acquisition, and it was later bought by Hewlett Packard Enterprise. Subscribe to Abort Retry Fail By Bradford Morgan White In Abort Retry Fail, I am attempting to chronicle the history of the computing industry. This is a goal that will likely not be completed within my lifetime. Subscribe Error 9 Share this post The Rise and Fall of Silicon Graphics www.abortretry.fail Copy link Facebook Email Note Other Share",
    "commentLink": "https://news.ycombinator.com/item?id=39944496",
    "commentBody": "The Rise and Fall of Silicon Graphics (abortretry.fail)286 points by BirAdam 17 hours agohidepastfavorite306 comments martinpw 15 hours agoWhenever this topic comes up there are always comments saying that SGI was taken by surprise by cheap hardware and if only they had seen it coming they could have prepared for it and managed it. I was there around 97 (?) and remember everyone in the company being asked to read the book \"The Innovator's Dilemma\", which described exactly this situation - a high end company being overtaken by worse but cheaper competitors that improved year by year until they take the entire market. The point being that the company was extremely aware of what was happening. It was not taken by surprise. But in spite of that, it was still unable to respond. reply mrandish 14 hours agoparentYou highlight one of the most interesting (and perhaps less understood things) about the key Innovator's Dilemma insight. Even if the senior management have read the Innovator's Dilemma books, know they are being catastrophically disrupted and desperately trying to respond - it's still incredibly difficult to actually do. Not only are virtually all organizational processes and incentives fundamentally aligned against effectively responding, the best practices, patterns and skill sets of most managers at virtually every level are also counter to what they must do to effectively respond. Having been a serial tech startup founder for a couple decades, I then sold one of my startups to a valley tech giant and ended up on the senior leadership team there for a decade. I'd read Innovator's Dilemma in the 90s and now I've now seen it play out from both sides, so I've thought about it a lot. My key takeaway is that an incumbent's lack of effective response to disruption isn't necessarily due to a lack of awareness, conviction or errors in execution. Sure, there are many examples where that's the case but the perverse thing about I.D. is that it can be nearly impossible for the incumbent to effectively respond - even if they recognize the challenge early, commit fully to responding and then do everything within their power perfectly. I've even spent time sort of \"theory crafting\" how a big incumbent could try to \"harden\" themselves in advance against potential disruption. The fundamental challenge is that you end up having to devote resources and create structures which actually make the big incumbent less good at being a big incumbent far in advance of the disruptive threat appearing. It's hard enough to start hardcore, destructive chemo treatment when you actually have cancer. Starting chemo while you're still perfectly healthy and there's literally no evidence of the threat seems crazy. It looks like management incompetence and could arguably be illegal in a publicly traded company (\"best efforts to maximize/preserve shareholder value\" etc). reply duxup 5 hours agorootparentEven just changing simple behaviors across a large company can be impossible. I worked at a company with several thousand employees all required to attend mandatory training on \"effective meetings\", several hours long spread out across thousands of employees. Rule 1 was to have an agenda for the meeting. This was something nobody did at this company and you would regularly attend meetings unprepared. After all that training, still nobody did it (ok I did and one other guy). That company couldn't change anything. It was amazing. They had a project to change a department into more proactive than reactive. The solution was to create a lot of bureaucracy surrounding being proactive. As you can imagine bureaucracy about being proactive was really just institutionalizing ... not being proactive. I eventually left and work at a smaller company now. It's been refreshing for years now when we can decide \"this process doesn't work, let's not do it anymore\" and it just happens. Even just new coworker: \"I won't be in tomorrow, who do I tell?\", me: \"you just did, have a great time off\" seems revolutionary after being at a big company for so long. I'm convinced that as the sheer numbers of humans increases the friction to making real change in a company decreases and there's not much you can do. Fundamental change to respond to real disruption, nigh impossible. reply rbanffy 11 hours agorootparentprevI think SGI failed to understand that there was a point where desktop PCs would be good enough to replace dedicated workstations. Continuing to make hardware that's much better than the best PCs wasn't going to save them after PCs crossed the good-enough line - whatever they had, would be relegated to increasingly rarefied niches - the same way IBM now only makes POWER and mainframes - there is no point of making PCs, or even POWER workstations anymore for them, as the margin would be too narrow. SGI could double down on their servers and supercomputers, which they did for a while, but without entry-level options, their product lines becomes the domain of legacy clients who are too afraid (or too smart) to port to cheaper platforms. And being legacy in a highly dynamic segment like HPC is a recipe for disaster. IBM survived because their IBMi (the descendant of the AS/400) and mainframe lines are very well defended by systems that are too risky to move tied to hardware that's not that much more expensive than a similarly capable cluster of generic and less capable machines. As the market was being disrupted from under them, they retreated up and still defend their hill very effectively. The other movement they could do was to shift downwards, towards the PC, and pull the rug from under their workstation line. By the time Microsoft acquired Softimage and had it ported to NT, it was already too late for SGI to even try that move, as NT was solidified as a viable competitor in the visual computing segment, running on good-enough machines much, much cheaper than anything SGI had. reply mrandish 11 hours agorootparentI think your analysis of the shifting technology landscape is largely on target. However, I'm not convinced that the true root of SGI's failure was the technology. Clearly their tech did need to evolve significantly for them to remain competitive but that's a transition which many companies successfully make. Even though SGI chose not to evolve the tech soon enough, fast enough nor far enough, I suspect they still would have failed to survive that time period due to an even more fundamental root cause: their entire corporate structure wasn't suited to the new competitive environment. While the \"desktop transition\" was most obviously apparent in the technology, I think the worst part for SGI was that the desktop shift changed the fundamental economics to higher volumes at lower costs. SGI had invested in building significant strengths and competency in its sales and distribution structure. This was one of their key competitive moats. Unfortunately, not only did the shift in economics make this strength irrelevant, it turned it into a fundamental weakness. All that workstation-centric sales, distribution, service and support infrastructure dramatically weighed down their payroll and opex. This was fine as long as they could count on the higher margins of their existing business. While it's easy to say they should \"just layoff all those people and relaunch as a desktop company\" that can't be done in one quarter or even one year. It requires fundamentally different structures, processes, systems and skill sets. Hiring, training and integrating all that while paying for massive layoffs and shutting down offices, warehouses etc takes time and costs a lot of money. Worse, once their existing workstation customers saw them shutting down the SGI the customers had bought workstations and service contracts from to become a different kind of company entirely, sales revenue would have taken an overnight nosedive. SGI's stock would also have tanked far more immediately than it did as the fickle stock market investors sold stock they'd bought because SGI offered a specific risk/return expectation which just became much more \"risk\" and much less \"return\" (at least in the near-term). In making such a dramatic move SGI would have effectively dumped much of their current quarterly revenue and the value of one of their core strengths - all at the same moment. Thus turning them into one of their emerging startup competitors with all of a startup's disadvantages (no big ongoing revenue streams, no big cash pile (or high stock valuation to leverage for cash)) yet none of a startup's strengths (nimble, lower-paid staff and more patient venture investors). The point of my earlier post was mainly that a true disruptive market shift is nearly impossible for a large, established incumbent to successfully survive because they basically have to rapidly turn into someone else almost overnight. How can a champion sumo wrestler survive a shift so dramatic that their sport quickly turns into a track meet? Even seeing it coming doesn't help. How does one even prepare for such a shift since losing mass turns you into a bad sumo wrestler long before you even start being a viable sprinter? As Christiansen observed, such disruptions are often enabled by technology but the actual cause of incumbent death is often due to the shift turning an incumbent's own strengths into weaknesses almost overnight. reply panick21_ 9 hours agorootparentI don't think you need to shut down that distribution. Because fundamentally, existing costumers often continue to buy existing product at existing prices, as long as they get a faster product. This was something that Gordon Bell pointed out. Existing costumers are design to work at that level of expense. Expensive graphics workstations and rendering servers and so on still exist. Sure it would go down eventually as all business does in the long run. The real failure is not picking up new business along the way. With the N64 they showed they could design a consumer product. But outside of that they were in no future consoles. 3dfx and ArtX both came from former SGI. You don't need to stop selling workstations just because you make chips for consoles and other such devices. Nvidia barely survived and might not have if not for consoles. There are other markets where their expertise could have been applied. Surviving changes like that often requires finding other markets. And then when it comes to making hard choices you need to cut part of the thing that is unprofitable. But this is really hard to do and in some ways it goes against the 90s US corporate philosophy of focusing only on the 'Core' business. DEC for example sold profitable business units that might have been helpful to have. DEC had a printer business and had the potential for a Database business. Oracle calls RDB one of the best acquisitions. reply vidarh 3 hours agorootparent> the N64 they showed they could design a consumer product. But outside of that they were in no future consoles. 3dfx and ArtX both came from former SGI. You don't need to stop selling workstations just because you make chips for consoles and other such devices. Commodore tried for a play where their - still much lower end - newest generation chipset would have scaled (with the same chips) from being a full low end computer, console, or set-top box, computer (it had a PA RISC core on chip, so could run standalone), a high end graphics card for PCs, and the chipset for a higher end Amiga at the same time. They ran out of money - short maybe a few million - before being able to test if that would have worked as a way to widen their market. I wish we'd have gotten to see how that'd unfolded, though Commodore's deep management dysfunction probably still would have made it fail. reply panick21_ 9 hours agorootparentprevIBMs market was also just far larger. SGI sales were around 3 billion, Sun were around 3x that. IBM was even more. SGI and Sun were based Unix so Linux could disrupt that far more easy then IBMs systems. IBM also came into the game more vertically integrated. Having your own fab is expensive, but if you read on what Sun and SGI had to do in order to get chips, that route also wasn't great. In the beginning there was a chance that Sun and SGI could have merged, the reason it didn't happen was mostly because leadership couldn't agree on who would lead the company. Between them they duplicated a lot of technology while sitting right next to each other. Both doing their own RISC chips, at times Sun was doing their own graphics cars, competing in 'low' priced and mid priced work stations, incomparable Unix developments, competing in the large SMP market against each other. If they had been together and things could have been different a larger install base and more investment into the architecture might have given them a better chance. reply giantrobot 4 hours agorootparentprev> I think SGI failed to understand that there was a point where desktop PCs would be good enough to replace dedicated workstations. I think the real problem here is PC workstations, with Windows NT (later Linux) and an Intel chip, could do 90% of the SGI workstations for a fraction of the price. By workstation I mean an honest workstation with a high end graphics card, 10k RPM SCSI drives, and hundreds of megs of RAM. The price of SGI workstations was \"call us\" which translates to tens of thousands of dollars per workstation. PC workstations didn't and couldn't replace all uses of SGI workstations. What SGI was not able to handle was the fact their customers suddenly having a viable option besides paying them tens of thousands of dollars for their workstations. Even their Visual Workstations weren't a real improvement cost wise as those were still overpriced compared to competitors' PC workstations. reply smackeyacky 3 hours agorootparentThis is my recollection of the era as well. A quality PC like a Compaq was already a good alternative during the Motorola era. In a lot of ways the whole RISC thing was a dead end as all that happened was SGI, IBM, HP and Sun cannibalised each others sales. ARM is the only one left standing from that era which with hindsight seemed so unlikely. reply vidarh 3 hours agorootparentKeep in mind several of the others survived long past their public visibility. There were MIPS smart phones for a while. Both PPC and MIPS long outsold x86 in number of CPUs - just at low margin licenses with the bulk going into embedded uses, like ARM. ARM had the advantage in that space of starting from the very low end, and being able to squeeze margins instead of being squeezed. reply pfdietz 8 hours agorootparentprevArguably, the shareholders don't want the management to try to harden the company. If the shareholders wanted to invest in a new approach, they could do that on their own. Rather, the shareholders expect the company to squeeze what they can out of what they are, even if that means winding down the firm. reply Pet_Ant 1 hour agorootparentCompanies and management would rather a slow controlled descent into the ground than unexpected success. They balance their risk at the portfolio level not at the company level. During good times focus on your core and then peter out. Just follow a nice parabolic arc. A lot of success is just timing and attempting to fight all threats look foolish. A remember, for every up and comer that “we all saw coming” there were lots that didn’t make it. If you waste time fighting those you wasted money. reply throwaway4good 13 hours agorootparentprevEveryone has been reading that book since the late 90es. I remember a talk by Clayton Christensen talking specifically about Intel and how they setup the Celeron division to compete with themselves (based on his advice). A key property of tech in economics lingo is that it is “natural monopolies” - all fixed cost and no variable cost. This creates these winner takes all games. In this case both Intel, SGI plus others knew the rules and it just ended up with Intel taking the prize and it all becoming Wintel for a decade or so - basically until the smart phone allowed enough capital to be accrued to challenge the old monopoly. reply Kamq 6 hours agorootparentprev> and could arguably be illegal in a publicly traded company (\"best efforts to maximize/preserve shareholder value\" etc). There's no way the shareholders win this lawsuit. Violating fiduciary duty involves doing things you know won't provide value. Long term planning would be a defense for this. The shareholders could absolutely oust those executives, though. And they may very well do so. reply bsder 13 hours agorootparentprev\"Maximally efficient is minimally robust.\" A company that optimizes for efficiency will get stomped flat when the environment changes. The problem is that there are no incentives in business to optimize for robustness. reply roughly 12 hours agorootparentWell, that’s partially because of the converse: a company that optimizes for robustness will get stomped flat before the environment changes to require robustness. Short term games are bad in the long term, but often good enough in the short term to win before the long term arrives. reply datavirtue 4 hours agorootparentprevDoes this apply to the US response to Chinas lead in battery and solar production? The Inflation Reduction Act is essentially a protectionist policy for manufacturing in response to Asian and Chinese tech manufacture. I feel like we are trying to fight our way out of one of these situations. I'm concerned because every time I see something happening that excites me (the massive policy shift from enacting the IRA and the surge in American manufacturing) it usually means something really bad is about to happen. reply ghaff 15 hours agoparentprevHaving worked longtime for a minicomputer company--which actually survived longer than most mostly because of some storage innovations along with some high-end Unix initiatives--it's really hard. You can't really kick a huge existing business to the curb. Or otherwise say we're going to largely start over. Kodak was not actually in a position to be big in digital. And, of course, the digital camera manufacturers mostly got eclipsed by smartphones anyway a decade or so later. reply maire 13 hours agorootparentKodak was well aware of what was going to happen. Company culture killed digital photography. I was at Apple when we worked with engineers from Kodak who were working to change various format standards to allow digital photos. This was in the late 1980s or early 1990s. reply ghaff 13 hours agorootparentBut, from the perspective of today, Kodak would have had to basically eclipsed Apple. Even displacing the big Japanese camera manufacturers, who by then had dominated high-end photography, would have required reversing decades of a shift away from high-end cameras like the Retina line. I don't doubt there was company DNA against digital photography but it's not like non-smartphone photography, especially beyond relatively niche pro/prosumer level, has had such a good run recently either. reply nradov 12 hours agorootparentThere is still a lot of business opportunity in supplying image sensors and lenses to smartphones. reply chiefgeek 11 hours agorootparentBut it is nowhere near as profitable as the 35mm film system was. reply ghaff 10 hours agorootparentThe 35mm system was a huge consumables business down through the food chain. That basically doesn't exist with digital. (Aside from ink jet supplies and I'm not sure how true even that is any longer.) reply aurizon 14 hours agorootparentprevOn the contrary, Kodak was well placed to do well by anticipating 'Moore's Law' as pertinent to sensor pixel density and sensitivity versus film. Film resolution was towards the end of intense development in pixel terms - not much further to go. They had pioneering patents and ongoing R&D would have enabled a long period of dominance during the transition and to this day!! The board and scientists were asleep on a mountain of cash, and they sold their future for a few crumbs left for shareholders after bankruptcy. Blackberry did much the same with fewer excuses. I met with some board members of Kodak in the 80's and they were like old English gentlemen - long on pomp and procedure, but they wore blinders and a vision bypass - TRIH. reply ianburrell 11 hours agorootparentKodak did fine in the transition to digital. They made some popular compact cameras and tried to make DSLRs. They were wiped out by compact cameras being killed by smartphones. The survivors are the old camera makers like Canon and Nikon that have ecosystems. The other big survivor is Sony, which bought a camera company and makes most of camera sensors. Fuji is interesting, they weren't that successful in first digital cameras, but now have some interesting mirrorless ones. They still make film. reply ghaff 10 hours agorootparentFujifilm is a much smaller company than Kodak was. They also applied a lot of their expertise in emulsions to medical applications. And, yes, they have some interesting if somewhat niche cameras. reply ghaff 13 hours agorootparentprevKodak was essentially a chemical company at one point. They even spun off an actual chemical company. Kodak could probably have played a better hand even if they did probably before their time things like PhotoCD. But they could have been Apple or maybe Instagram? That's a stretch. I'm not a particular Kodak apologist but suggesting that a company should have been able to anticipate and correct for their business collapsing by 90% in a decade or so seems to need a lot of particulars. reply xcv123 13 hours agorootparent> But they could have been Apple? That's a stretch. They could have been a Sony. The iPhone camera sensor is made by Sony. reply ghaff 12 hours agorootparentAnd Sony has certainly had rough patches too. And that's for a company coming from an electronics manufacturer angle. Kodak could have spun off a consumer electronics or semiconductor manufacturing company. But it's not clear why that is actually a better model than someone else just spinning up similar entities. I don't need all the chemical engineers and a lot of other people connected with the old business anyway. And I'm sure not turning them into semiconductor experts. So you're one of the 10% of employees in HR who snuck through to the other side. Is that really a big deal? reply xcv123 10 hours agorootparentThat's right. The chief executives and the HR lady basically get transferred over to a new startup funded with Kodak's money and everyone else is fired. reply loloquwowndueo 15 hours agorootparentprevData General? reply ghaff 15 hours agorootparentYes. CLARiiON eventually enabled a sale to EMC (which arguably saved EMC for a time) and the Unix business (especially NUMA servers) were sufficient revenue producers for a while to keep the lights on. ThinLiiNe (or whatever the capitalization was) never went anywhere but neither did a lot of things in the dot.com era. reply loloquwowndueo 15 hours agorootparentI knew it :) thanks for confirming! And for sharing. reply ghaff 14 hours agorootparentI was the PM for a bunch of the minicomputers from the mid-80s on. Then I was PM for the initial Unix AViiONs and later the NUMA servers including being one of the main liaisons with CLARiiON. reply panick21_ 8 hours agorootparentprevSeems like Sun really shot itself in the foot by not buying DataGeneral. A Unix storage business that fits pretty well with their larger datacenter portfolio. And a start to a real x86 business. I just finished reading 'LIFE UNDER THE SUN: My 20-Year Journey at Sun Microsystems' that talks about Sun and the storage businesses a bit. Sun was never happy with how well they did in storage. Sun was part of defining Fibre Channel. For some reason that still doesn't make sense to they bought StorageTek for an incredible $4 billion at the time when Sun wasn't exactly flying high. The explanation from the CEO given in the book mentioned above is baffling. Edit: Seems they bought: 1999: MAXSTRAT Corporation, a company in Milpitas, California selling Fibre Channel storage servers. Never heard of them. Not sure how comparable it was. reply hulitu 2 minutes agoparentprev> The point being that the company was extremely aware of what was happening. It was not taken by surprise. But in spite of that, it was still unable to respond. They had the best processor on the market, yet they decided to sell Intel and Windows. I really don't underestand what were they smoking. reply hintymad 13 hours agoparentprevI remember Clayton Christensen mentioned that Andy Grove invited him to Intel to talk about how to deal with the dilemma, and interrupted Christensen while he was talking and said something like \"I know the problem, and I need you to tell me the solution\". Similarly, Peter Drucker repeatedly mentioned one of the biggest challenges in business is \"killing the cash cow\". Along that line, Netflix's Reed Hasting is really amazing. He somehow managed to kill the DVD business and used it to milk the streaming business, when almost everyone in the industry and some of his lieutenants in Netflix didn't believe him. reply froonly 11 hours agorootparentFor a while you could view Netflix online and rent DVDs from them. reply RandallBrown 11 hours agorootparentOh dang, I thought you still could. Looks like they shut down the DVD rentals about 6 months ago. reply chiph 9 hours agorootparentThere are now a couple of smaller disc-by-mail startups who aim to serve that market. I've signed up with DVDInBox out of Florida and they've done a good job thus far. From what I've seen their biggest current challenge is their mailer. Netflix spent a lot of time designing their signature red envelopes, working with the USPS on ensuring they would survive a trip through the postal sorting machines. DVDInBox has yet to reproduce it - their envelopes sometimes arrive fairly mangled, or have not arrived at all (lost to the bowels of the machines). reply specialist 11 hours agorootparentprevYes and: These years later, while the innovator's dilemma thesis describes what, there's still little treatment of why and how. I keep wanting someone to account for the roles of investment and finance. Amazon's innovation was lower cost of capital. They convinced investors to wait for returns. And they got a massive tax holiday. (How could they not succeed?) Ditto Tesla, with its saavy moves like govt loans, prepurchases, tax incentives, and selling direct. That cheap capital was necessary, but not sufficient. Both still had to create products customers wanted. I keep coming back to Apple. How'd Apple avoid the trap? Despite their terrible position. My guess is better financial strategy (if that's the right phrase). Apple focused on margins (and monosophony) instead of market share. And then leveraged their war chest to implement monosphony. reply system7rocks 9 hours agorootparentApple also recognized one of its big problems was marketing to the end user, in particular in big box stores where not many people knew and appreciated what Macs could do. Creating their own stores created innovation and an experience, rather than less than knowledgeable staff and price tag comparisons against the latest Dell PC. That meant letting go of some of the traditional stores and the chain of legacy Mac resellers. Of course, now, you can get Macs at Costco. reply Spooky23 8 hours agorootparentprevApple’s limited SKUs let them maximize their economies of scale. When Jobs took over, despite teeny market share, products like iMac and iBook were #1 in shipments, compared to Dell and their 300 models. reply microtherion 9 hours agorootparentprevApple also did not hesitate to kill their cash cow, supplanting the iPod with the iPhone (an observation made, I think, by Horace Dediu). reply varjag 2 hours agorootparentiPod was killed quite late into iPhone era, when the sales have plummeted to unsustainable levels. reply Pet_Ant 1 hour agorootparentBy “killed” GP means “cannibalised” not “cancelled”. They out-competed the iPod while it was still hot. reply panick21_ 8 hours agorootparentprevInvestors only 'wait' if you can show revenue growth and large market. Tesla was very capital efficient compared to how hard the task was, only just enough to get the next product out. By the time they were making big loses, you could see the Model 3 was gone turn around once they reached scale. There was always a clear story of if we do X next, that means Y. > I keep coming back to Apple. How'd Apple avoid the trap? I think by changing CEO radically at the right time. Whatever was gone work for Apple, it wasn't any of the typical things you would think off. I'm not at all a Jobs fan, but I don't think many people could have turned it around. Jobs had the ability to come back and radically shift the company. They also had the benefit of 20 years of loyal costumers, maybe the biggest asset Apple had was their loyal costumer base (or captured market). Personally I can say my dad was a complete Apple fan, he would just buy Apple. He simply didn't care the higher performance or any of the other things. reply Octokiddie 8 hours agoparentprev> It was not taken by surprise. But in spite of that, it was still unable to respond. This is even a major point of discussion in the book. The incumbents always see it coming a mile away. They can't respond because doing so breaks their business model. Employees can't go to managers and say, \"We need to enter this low-margin market for low-end products.\" Doing so is a good way to get sidelined or fired. The \"dilemma\" is that either traditional option, compete with the upstarts or move further up-market, leads to the same outcome - death. reply mcculley 2 hours agoparentprevI worked a lot with SGI hardware and IRIX in the 90s and very early 2000s. I ported a lot of code to and from Linux in that time. I remember trying to explain to SGI reps that while we loved the SGI hardware, Linux on commodity x86 was the increasingly more effective choice for our projects. We wanted to buy SGI x86 boxes but they were pushing NT. It was very apparent that SGI salesmen knew which way the wind was turning and they were milking the last bits of the commission gravy train. Even when everyone understands “The Innovator’s Dilemma”, the incentives of salesmen and shareholders can be to optimize for extracting value out of the dying company. If I am a shareholder in a company being out innovated, it might make sense to want them to maximize short term profits while reallocating capital to the innovators instead of trying to improve the dying company. reply Pet_Ant 1 hour agorootparentSeems like issue is a shift from high margin sales representative lead growth to low margin mass where you don’t need sales people to convince you to buy it. Then there is no way to justify the sales team, so they don’t support it. The company is beholden to them, and they sabotage the move to mass market. reply mcculley 12 minutes agorootparentThat is certainly one case, maybe the most likely. But another case I was involved with involved sales just not understanding the innovation. They could have potentially made just as much or more money with the new thing, but were too comfortable selling the old thing. reply VelesDude 14 hours agoparentprevIt was clear they were trying to do more consumer grade things, just look at the N64. Couldn't get more mainstream than that. Seeing how the graphics market ended up, it looks obvious from here but in the mid 90's it was still the wild west and everybody was throwing mud at the wall seeing what would stick. I have never really said that they where \"taken by surprise\", but a part of it felt like (from the outside) that management had been a little blinded by their pass success and the profit margins from their workstations combined with no clear path forwards for the whole industry. Nvidia could have very easily been just a curiosity of the past but they managed to strike it lucky standing on the shoulders of others. If SGI had always been a company that could provide graphics workstations the worked with x86/Windows PC's early for example - maybe they would have fared better. Would have gone with the flow of technology at the time rather than fighting uphill no matter the potential technical brilliance. But being saddled to their MIPS processors and custom OS meant that once people left, they almost never came back. One can have the best tech and still fail. reply the_mitsuhiko 14 hours agorootparent> It was clear they were trying to do more consumer grade things, just look at the N64. Yes, but the team that did that also left SGI, then worked directly with Nintendo for the GameCube and are acquired by ATI. I’m not sure how SGI managed to not support that effort within itself. reply cuno 11 hours agorootparentNintendo wasn't loyal to the company it was loyal to the team, so when they just decided to leave and form ArtX they took the customer with them... SGI was happy with the Nintendo contract. They earned $1 in additional royalties for every single N64 cartridge sold worldwide. Losing the team was a big blow. reply rbanffy 11 hours agorootparentprev> provide graphics workstations the worked with x86/Windows PC's Integraph started making PCs with high-end graphics at one point, when they abandoned CLIX and gave up on their (Fairchild's, really) Clipper processor. It didn't work for them either. SGI did their own \"Visual Workstation\" that ran Windows and had a Pentium, but that too was a huge disappointment. reply coredog64 5 hours agorootparentThe 320 and 540 had a few nice things going for them: You could option them with the same 1600SW monitor that the higher-end O2 workstations used without having to use the fiddly multilink. SGI paid Microsoft for a HAL license and did a better job with multiprocessor than what you got from installing the vanilla version. reply timc3 3 hours agorootparentThey had decent bandwidth internally allowing them to playback uncompressed realtime standard definition video which normal PCs running Windows couldn’t do at the time. reply blackoil 11 hours agoparentprevI believe having a talented dictatorial leader at top may be only solution. Like Steve Jobs, Bill gates or Jeff Bezos. Once they believe in a path, they have methods to get it done. Internet Tidal Wave memo is a good example of it. Zuckerberg is able to invest 100s of billions on a future he believes in. Obviously the observation has a confirmation bias. reply pixelfarmer 2 hours agorootparentCompanies through their usual hierarchical structuring are authoritarian by nature. However, many leaders are no actual leaders, they are just bureaucrats, and that is the reason why things get stuck. reply hintymad 10 hours agoparentprevI guess an interesting question would be whether Nvidia is SGI in the late 90s or Intel of 80s. reply VelesDude 2 hours agorootparentI get the vague feeling they are more like Intel in the 80's. Nvidia has had a real talent partially by their own smart moves and partial just pure luck for stumbling from one win to another. Seeing them fall into the Crypto boom and then straight onto the AI boom has been wild to see. reply geor9e 8 hours agorootparentprevSGI was a pretty small 3D workstation company at the bottom of the S&P500, even at it's peak. Microsoft was at least a hundred times as big as SGI. (And Nvidia was even smaller, selling GPUs for both SGI worthstations and Windows PCs at the time.) Now Nvidia is a titan at #5 in the S&P. They could certainly be taken down a notch or two as CUDA alternatives mature and people start buying cheaper AMD/Intel/FPGA(groq, etc) hardware. But they're the best at what they do, with the best people. They don't really have a doomed business model the way SGI's \"take out of a second mortage for the Onyx workstation to make N64 games\" business model was doomed. I don't buy Nvidia stock, personally, but I especially wouldn't bet against them long term either. reply leetrout 8 hours agorootparentprevI have been comparing them to SGI of the late 90s but the next 18 months will prove me right or wrong as Intel, Apple, Google and AMD try to compete. reply yndoendo 15 hours agoparentprevWhen statements like X was better than Y come up. I always think of \"All models are wrong, but some are useful\", from statistician George E. P. Box, and rephrase it as \"All models are flawed, but some are useful\" so that model becomes ambiguous, such as a smartphone, TV, computer, car, programing language, programing design pattern, social media platform, and so on. Price-point, SGI technology was a financially flawed model pertaining to the growing market and more useful than flawed performance of the low cost technology market. Did anyone at SGI try to simply buy the low tech products, play with them a bit, and see about slowly integrating your tech to make that low tech product just a little better than the competition and cost effect for the market? reply appstorelottery 14 hours agoparentprevI was making crazy money in the dot-com boom and bought a SGI 540 in 1999 (with an SGI monitor). With money to burn SGI was a childhood brand, legends in 3D. Such wonderful memories. 15k on a desktop setup - it was loose change, however it shows how clueless I was back then. However I'd felt like I'd \"arrived\". SGI with Windows NT - lol - I wrote my first OpenGL game in Visual Basic... I've always been somewhat of an outlier ;-) God help me. The point? My personal experience says something about the strength of the SGI brand - even in the face of what was happening at the time (3DFX and so on - my previous company was one of the few 3DFX api devs - illustrating how clueless I was...)... it all happened so quickly... I'm not surprised SGI couldn't respond - or more importantly understand the strength of Microsoft/OpenGL/DirectX in the boiling pot of 3DFX / Nvidia and the rest... From memory it took three years and SGI was done - shared memory architecture? No longer worth the cost. :-( Looking back, I was such a kid - a complete fool. Greybeard advice: bet on the monopoly. Be smart. Brands like SGI are nothing in the face of install base. Think about how crazy it was to spend 15k on a desktop SGI back then... nostalgia is insanity, vanity. reply VelesDude 2 hours agorootparentThe one thing that I always have to point out to folks who didn't live through it. The pace of change in everything was so rapid, especially in the graphics space. It is wild to think that in games for instance, we went from Quake in 1996 running software rendering to Quake 3 requiring a GPU only 3 years later and that becoming the standard in a matter of months. reply lizknope 11 hours agorootparentprevYeah but it still sounds really cool! From 1991 when I first saw SunOS I wanted a SPARCstation. I started college in 1993 and the school was full of DEC Ultrix machines, Suns, HP PA-RISC, and a handful of IBM RS/6000 and SGIs. I just thought DOS/Windows PCs were such garbage. Single user, no preemptive, multitasking, no memory protection. Then Linux came out and it changed everything. I bought a PC just to run Linux. My dream of a Unix RISC workstation faded away. My roommate in 1996 bought a DEC Alpha. Not the cheaper Multia but an Alpha that could run OSF/1 Digital Unix. He actually ran NetBSD on it. In 1997 I took the computer graphics class and we used SGIs. There was just one lab of them reserved for that class and grad students. I was so excited and it was really cool but I didn't think I could ever afford one. It's still really cool though that you had one. reply panick21_ 8 hours agorootparentLinux on RISC-V ... Its happening ... eventually ... probably. reply bombcar 10 hours agoparentprevThe way to survive is to eat your own lunch. Be the low cost competitor and cannabilize your own market. Otherwise you don’t build the iPhone because you don’t want to lose iPod sales. reply VelesDude 2 hours agorootparentI not so obvious but similar example of this would be with Nintendo and the Switch. They had always hand their handheld and consoles as separate things but eventually decided to just combine them into a single thing. So instead of double dipping on the hardware and potentially the software sales, it just become a single entity. And to say that has worked out well for them is an understatement. Sold 139 million units and are still taking their time of getting to a successor. They are probably going to take the #1 highest selling games machine of all time and they did it by going against their old business practices. reply foobiekr 12 hours agoparentprevI was at one of SGI's competitors and we had teams doing cheap HW - ATi and other cards, like IBM's GPUs at the time - and yet the company as a whole was like \"ALL GOOD LET'S KEEP BUILDING MASSIVE CUSTOM GRAPHICS SYSTEMS!\" They were as dead as SGI in the same timeframe. reply foobarian 15 hours agoparentprevI think it's a near impossible situation - the status quo is literally something that should not exist given the new market realities. Pivoting is pretty much asking a company to commit seppuku - asking the layers of leadership to basically replace themselves and quit in many cases. Which is pretty much what happens anyway. reply bunderbunder 15 hours agorootparentAnd, just like every Unix workstation vendor of the 1990s, they got hit with a perfect storm. They had their hardware being disrupted by x86 really coming into its own as a viable option for higher-end computing at the exact same time that Linux was becoming a serious option for the operating system. \"Literally something that should not exist\" is the perfect way of putting it. In 1990, lots of people needed boutique workstation vendors. In 2000, nobody did. reply bunabhucan 15 hours agorootparentIt's worse than that. Instead of \"nobody\" it was conservative slow moving vendor locked clients that could convince you to keep selling at those prices (\"look at the margins!\") instead of focusing on alternatives. I remember $5,000+ PCs being considered \"cheap\" workstations when those clients finally migrated. reply rbanffy 11 hours agorootparentprevEven Apple, which became the unlikely last of the Unix workstation vendors, was disrupted by Intel (and moved from PowerPC to x86 for a while). Ironically, Apple is now the very last Unix workstation vendor in existence. reply grumpyprole 2 hours agorootparentYes, although they have clearly not always been committed to the Mac Pro over the years, it still exists and the pricing is certainly workstation like. reply AlbertCory 14 hours agorootparentprev> Pivoting is pretty much asking a company to commit seppuku This is conventional wisdom (and thus, usually correct). However, it's always interesting to look at counterexamples: Beretta, for example (in business for 500 years). https://www.albertcory.io/lets-do-have-hindsight or the IBM PC, which cannibalized IBM's business, at least in IBM's mind. Thus, they screwed it up and let Wintel make the real billions. So it worked, until they took your advice and decided that had to stop. reply ghaff 15 hours agorootparentprevAnd, at some point, what does it matter if the leadership and most of the employees turn over, typically involuntarily? Is there any significance really to Foot Locker basically being a reorganized Woolworth's as opposed to being a brand-new company? If you're big enough and have some product lines that still bring in a lot of money and didn't totally collapse like IBM you can sometimes pull it off. But it's hard. reply neuralRiot 12 hours agorootparentprevProbably the lack of vision is not just failing to turn into the direction of new “products” but not acquiring, digesting and eliminating those busines who start to grow before they’re too big. See Microchip for example, how many relatively small semiconductor and technologies manufacturers have already eaten. reply voidmain0001 1 hour agoparentprevCould this eventuality happen to Google, Nvidia, or Apple? reply Animats 15 hours agoparentprevThey sort of tried. Around then they had a Windows NT machine that cost around US$12,000. But it was too late. The first serious graphics cards for PCs were appearing, from Matrox and others, with prices of a few thousand dollars. (I tried some early NT graphics cards on a Pentium Pro machine. This was before gamer GPUs; these were pro cards from tiny operations. Fujitsu tried unsuccessfully to get into that business, with a small business unit in Silicon Valley. At one point they loaned me a Fujitsu Sapphire graphics card prototype. When I went back to their office to return it, the office had closed.) Also, there was a bad real estate deal. SGI owned a lot of land where Google HQ is now. They sold it to Goldman Sachs in a sale and lease-back transaction, selling at the bottom of the market. That land, the area north of US 101 in Mountain View had, and has, a special property tax break. It's the \"Shoreline Regional Park Community\", set up in 1969. The area used to be a dump. Those hills near Google HQ are piles of trash. So there was a tax deal to get companies to locate there. That made the land especially valuable. reply msisk6 14 hours agorootparentSGI tried its hand at the PC video card business as early as 1990. I was at Autodesk at the time and got one of these to beta test on a DOS 486 running AutoCAD. It was an impressive product. But huge; it took up two full-length ISA slots. And the display drivers were a bit buggy. reply sillywalk 13 hours agorootparentHere's a brochure for the IrisVision boards - uses 2 ISA or Microchannel slots. Prices start start at $3,495 https://www.1000bit.it/js/web/viewer.html?file=%2Fad%2Fbro%2... reply rbanffy 11 hours agorootparentprevI wish they ported IRIX to x86. You can make more money by making stuff for Windows, but it won't protect you from market erosion. reply nradov 10 hours agorootparentI doubt that would have helped. Customers didn't love Irix as an OS. They tolerated it in order to use SGI's superior hardware and specialized applications. Competitors such as Sun did port their proprietary Unix flavors to the x86 PC platform but never achieved traction. It was impossible to compete with free Linux, and lack of device drivers was always an obstacle. reply Y_Y 13 hours agorootparentprevSounds just like Nvidia in 2024 reply theandrewbailey 8 hours agorootparentExcept Nvidia's modern cards are even bigger. reply AnimalMuppet 15 hours agoparentprevSomeone at SGI wrote a paper/web page/blog post titled \"Pecked To Death By Ducks\", claiming that x86 chips could never compete with SGI, and claiming to refute all the arguments that they could. Then Intel introduced dual core (or maybe just two chips in one housing sharing a bus), and that generated a lot of buzz. So he wrote a follow-up titled \"Pecked To Death By Ducks With Two Bills\". I don't recall the timing, though, how it related to the timing of asking everyone to read The Innovator's Dilemma. But at least some of the time, there was a pretty deep denial (or at least a pretty deep effort to keep the customers in denial). reply rbanffy 11 hours agorootparentA bit like Seymour Cray's plowing a field with 1024 chickens instead of two oxen. reply MichaelZuo 14 hours agorootparentprevThat’s really funny for some reason. reply HeyLaughingBoy 14 hours agorootparentIIRC, \"Pecked to Death by Ducks\" is the title of either a short (nonfiction) story or a book by Gerald Durrell, one of my favorite childhood authors. reply jfk13 12 hours agorootparentI don't recall that one, and I thought I knew Gerald Durrell's work pretty thoroughly. There is a book of that title by Tim Cahill, though; maybe that's what you're remembering? reply HeyLaughingBoy 11 hours agorootparentYesss! Thank you. I'm embarrassed because I used to have that one, too :) On the upside, I've never known anyone else who had even heard of Durrell. reply bluenose69 10 hours agorootparentI would have thought that lots of folks had watched the \"The Durrells in Corfu\" TV series (PBS Masterpiece Theatre) and then did some research on the family. I don't know whether this is available online, but I can recommend it as a pleasant programme, with lovely scenery, interesting storylines, and engaging actors. reply tambourine_man 7 hours agoparentprevI remember reading how Andy Grove, IIRC, spent two years trying to exit the DRAM business. He would flat out order people to stop working on it and they wouldn’t listen, believe or understand. The amount of inertia for large bodies is remarkable. reply Pet_Ant 1 hour agorootparentAnd yet there are stories of people ignoring the company direction, continuing work, and saving the company. See: The Blue LED https://youtu.be/AF8d72mA41M?feature=shared So it’s not clear that the company knows better. Feels like educated guesses but a lof of luck involved. reply bigboy12 9 hours agoparentprevWalking the streets of nyc 19 years ago. I saw a sgi indigo on the street and sadly I just kept walking on. Like wow. reply szundi 15 hours agoparentprevThanks for this comment, very much appreciated. reply jiggawatts 12 hours agoparentprevIn the late 90s I was in the last year of high school. Silicon Graphics came to do a demo of their hardware for students that were interested in taking a computer science course at university in the following year. The graphics demos looked like trash, basically just untextured and badly shaded plain colored objects rotating on the screen. For reference I was playing Quake III around the time which had detailed textures and dynamic lighting. I asked the SGI presenter what one of his Indigo workstations cost. He said $40,000, not including the graphics card! That’s extra. I laughed in his face and walked out. reply dekhn 11 hours agorootparentIn the late 90s, SGI demos were much more impressive than what you describe. It was used by technical folks to do real stuff, with stringent criteria. More importantly, the things that made Quake III so great were state-of-the-art for gaming. But those things couldn't render lines quickly and well (a mainstay of CAD at the time), or render at very high resolution (which IIRC was 1280x1024 in that era). Here's what Carmack said abotu the SGIs a few years before: \"\"\"SGI Infinite reality: ($100000+) Fill rate from hell. Polygons from hell. If you don’t trip up on state changes, nothing will come within shouting distance of this system. You would expect that.\"\"\" SGI was also key for map builds before PCs were capable. But yes, 1999-2000 was just around the cusp of when SGI went from \"amazing\" to \"meh\". reply rbanffy 11 hours agorootparentThe curve that maps fucking around with finding out is not linear. By the time you start finding out, it's very hard to stop finding out much more than you would like to. reply jiggawatts 10 hours agorootparentprevIf I remember correctly, their cards had a high compute rate even at double precision, but had tiny memory buffers and basically couldn’t do texturing at all in practice. It turned out that double precision was a mistake that was sold as a “professional” feature. By sharing edges correctly and using the correct rounding modes, single precision provides pixel-perfect rendering. Efficiencies like this allowed the consumer GPUs to run circles around SGI hardware. reply dekhn 9 hours agorootparentThey did texturing just fine. reply jiggawatts 8 hours agorootparentMost SGI graphics cards had no texture ram at all, and had zero texturing capability. At the time there was one card that had 4 MB of texture RAM, but in the same year a typical PC GPU had between 16 or 32 MB of shared memory, most of which was used for textures. A “budget” SGI card cost more than my parents’ car. I bought three different GPUs by that point with my pocket money. reply dclowd9901 3 hours agoparentprevCan you guess why? Was it maybe outmoded or outdated sales models that didn’t take reasonable competition into account. I’m so sick of dancing around this topic. Managers and business types destroy companies. It never stops. Company after company. How many times do we have to pretend this isn’t the case before we see the truth. Innovators make things worth selling. Business types drop it on the floor. reply davepeck 16 hours agoprevI was there near the end. First, as a summer intern in 1998, and then in 1999 as a full time engineer on what is now Google's Mountain View campus. SGI had always been a dream company for me. I'd first learned about them in high school; now, right out of college, I'd somehow managed to land a dream job. SGI's hardware was cutting-edge and exotic. IRIX was killer (sorry Solaris). Cray was a subdivision. My coworkers used emacs, too. They put an O2 on my desk! The dream didn't last long. Major layoffs hit just a few months after I started full time. I wrote about the experience here: https://davepeck.org/2009/02/11/the-luckiest-bad-luck/ reply dxbydt 14 hours agoparent> SGI had always been a dream company It was a dream company for pretty much every siggraph person at that time. I was in grad school, eagerly awaiting a very popular 3-semester course in computer graphics. It had been devised and taught by a young promising professor who had published some pioneering siggraph papers. I signed up for the course. On the first day of class, the head of the department walked in and said the professor had been recruited by his dream company SGI for an ungodly sum of money to work on some Jewish director’s movie about a dinosaur themepark. I thought ok, whatever, someone else will teach the course. The bastards scrapped the entire 3 series computer graphics module because there wasn’t anyone else who could teach that. So we had to pick from one of the usual dumb options - databases, OS, Networks, Compilers. Since then I’ve always held a grudge against sgi. reply IntelMiner 7 hours agorootparent\"Jewish director\" is an...interesting description reply krapp 7 hours agorootparentprev> to work on some Jewish director’s movie about a dinosaur themepark I assume you mean Steven Spielberg and one of the Jurassic Park films? If so, why can't you just say so? Why are you referring to Steven Spielberg, one of the most famous directors of all time, as \"some Jewish director?\" Do you think people won't recognize the name? I promise people know who Steven Spielberg is. reply theonething 2 hours agorootparentI think the GP was telling their story in the context of that time. It's a technique to help the reader more fully understand the context. I'm almost sure there is a term for this literary technique. reply Kamq 6 hours agorootparentprev> If so, why can't you just say so? Based on the comment, it sounds like that's the way the head of the department phrased it. Presumably the department head didn't know the title as it hadn't been released yet. reply brcmthrowaway 13 hours agorootparentprevJewish director? Hrmph reply Y_Y 12 hours agorootparentSpielberg had a bar mitzvah, what more do you want? reply ska 11 hours agoparentprev> SGI's hardware was cutting-edge and exotic. This was their downfall, trying to scale out adoption with esoteric hardware. I remember being quoted $18k ish for memory upgrade on a O2 or origin, same amount of memory I had just bought for $500 for an intel Linux box at home. Sure, it wasn’t apples to apples, but I remember thinking very clearly that this wasn’t going to end well for SGI. reply oaktowner 16 hours agoparentprevI worked at Google from 2013 to 2020. There were definitely employees (maybe a majority) who assumed that Google would always be the dominant force in technology. Those of us who were a bit older always understood that everything changes in Silicon Valley. Those buildings represented that change to me. I can remember coming to concerts at the Shoreline in the 90s and looking at those Silicon Graphics buildings: they looked so cool, and they represented the cutting edge of technology (at the time). And yet...it all disappeared. Same goes for the Sun campus which is where Meta/Facebook is now. Famously, the Facebook entrance sign is literally the same old Sun sign, just turned around! [0] So I always cautioned co-workers: this too, shall pass. Even Google. [0] https://www.businessinsider.com/why-suns-logo-is-on-the-back... reply dbreunig 16 hours agorootparentMeta still has the Silicon Graphics logos on a few glass conference room doors in building 16, I believe. At least they were there in 2012. Great memento mori. reply samatman 15 hours agorootparentPresumably you mean the Sun logo: http://www.logobook.com/logo/sun-microsystems/ Which is one of the all-time greats IMHO. I'd keep it around too. reply dbreunig 10 hours agorootparentI do! Thanks! reply alecco 15 hours agoparentprevI had to support an open source library for all major unixes and the Irix compiler was by far the best one. It took years for the rest to catch up. But it took ages to compile with optimizations on. Good times. reply ryandrake 15 hours agoparentprevI graduated undergrad in 1998 and can confirm that SGI was the company to go to. I felt so jealous of those few guys who had SGI offers, where I had to settle for a more generic PC graphics company. History is what it is but the SGI really had that luster that only a handful of companies ever boasted. reply mrpippy 16 hours agoparentprevWhat did you work on at SGI during your brief stint? reply davepeck 16 hours agorootparentMineSet, their data mining and visualization package. reply bcantrill 3 hours agorootparentIf a may, can I fact check a story conveyed to me through a mutual acquaintance of ours? The story was that SGI was trying to sell off MineSet, and needed the team to stick around long enough to sell them off -- so a bonus was to be given after a short period of time (a month maybe?). The bonus was significant enough to get people to at least defer a job search ($10K?), but SGI didn't manage to find a buyer. The check was to hit bank accounts on a particular day; the team waited to hear word that the literal money was in the bank -- and then all quit simultaneously. Is there at least some truthiness to it? Or has this just become Silicon Valley urban legend in my head? reply lowbloodsugar 8 hours agoparentprevThat's funny because my reaction to the O2 was \"oh, this is far too expensive for what it is\". Was workin on N64 game, and the other teams were using the Indy devkits, while we had PCs with the SN systems dev kits. Writing was on the wall at that point. reply davepeck 6 hours agorootparentYeah, the O2 definitely was too expensive for what it was. And while it was the least cool and powerful of the lineup by far, as a recent college grad, it was still the coolest computer I had ever had on my desk. ;-) reply dekhn 16 hours agoprevI was in love with SGI when I was an undergraduate just over the hill at UC Santa Cruz in the early to mid 90s. Everything about the machines from their industrial designed cases but wonderfully colorful cases, and the sexy desktop OS (\"This is UNIX. I know this!\") and the way IrisGL rendered molecular graphics. Driving to a Phish show at Shoreline, we passed the low-slung office buildings of SGI which seemed like the sexiest place to work. When I graduated, I thought I was \"too dumb in CS\" to get a job in Mountain View and went to grad school in biophysics instead. By the time I was a few years into grad school, I worked in a computer graphics lab outfitted with Reality Monsters and Octanes and other high end SGIs (when you maxxed out an SGI's graphics and RAM, they were really fast). I was porting molecular graphics code to Linux using Mesa (much to the derision of the SGI fans in the lab). When we got a FireGL2 card it had a linux driver and could do reasonable molecular graphics in real time and the SGI folks looked real scared (especially because the SGI Visual Workstation had just come out and was a very expensive turkey). Less than a decade after that I was working in those very buildings for Google. Google took over SGI's old HQ (Jeff Dean told me there was a period where Google and SGI overlapped in the GooglePlex and the SGI folks looked very sad as they paid for their lunches and teh googlers got free food). There was still plenty of SGI signage strewn about. And now Google has gone dumb and also built their own HQ next door (note the correlation between large SV companies building overly fancy HQs and then going out of business). Such is the cycle of sexy tech. reply dalke 15 hours agoparentWe've talked before about our respective molecular graphics background. I started with Unix on a Personal IRIS as an undergrad working in a physics lab which used it for imaging capture and analysis. I was the nominal sys admin, with one semester of Minix under my belt and just enough to be dangerous. (I once removed /bin/cc because I thought it was possible to undelete, like on DOS. I had to ask around the meteorology department for a restore tape.) The summer before grad school I got a job at the local supercomputing center to work on a parallelization of CHARMm, using PVM. I developed it on that PI, and on a NeXT. That's also when I learned about people at my future grad school working on VR for molecular visualization, in a 1992 CACM article. So when I started looking for an advisor, that's the lab I chose, and I became the junior co-author and eventual lead developer of VMD. With a Crimson as my desktop machine, a lab full of SGIs and NeXTs, and the CAVE VR setup elsewhere in the building. Heady times. I visited SGI in 1995 or so, on holiday, thinking that would be a great place to work. They even had an Inventor plugin for molecular visualization, so I thought it would be a good lead. I emailed and got an invited to visit, where the host kindly told me that they were not going to do more in molecular visualization because they wanted to provide the hardware everyone uses, and not compete in that software space. In the early 1990s SGIs dominated molecular modeling (replacing Evans & Sutherland), so naturally the related tools, like molecular dynamics codes, also ran on them. But we started migrating to distributed computing, where it didn't make sense to have 16 expensive SGIs, leaving them more as the head .. which as you pointed out, was soon able to run just fine on a Linux machine. reply theideaofcoffee 16 hours agoprevOh how I lusted over the Challenges, the Octanes, the Indigo2s of the time. It was a revelation when I finally was able to sit down at a console of an Octane (with two, count 'em TWO R14000 and a whopping 2.6G of RAM), tooling around in IRIX via 4dwm was so much more satisfying than today's UIs. It was snappy and low-latency unlike anything I've used since. Later on, I was able to do some computational work on an Altix 3700 with 256 sockets and 512G of RAM spread over four full-height cabinets with the nest of NUMAlink cables at the back), at the time running SuSE linux and that was wild seeing the 256 sockets being printed out with a cat /proc/cpuinfo. Now the same capabilities are available in a 4U machine. The corporate lineage story is also just as interesting as the hardware they made as well. Acquisition, spinoff, acquisition, rename, acqusition, shutter, now perhaps just a few books and binders and memories in the few remaining personnal at HPE are all that's left (via Cray, via Tera, via SGI, via Cray Research). RIP SGI reply bitbckt 16 hours agoparentI still keep a maxed out Octane2 in running order for posterity. Occasionally logging in to it reminds me just how a desktop environment should feel. We truly have lost something since then. reply ofrzeta 5 hours agorootparentIf you feel nostalgic you can run https://docs.maxxinteractive.com/ on Linux. reply hypercube33 16 hours agoparentprevI really wish they'd do movies like they made for RIM about: Cray, DEC, Compaq, SGi, Pixar. sounds like these places were either wild or strait up IBM culture or some clash or both either inside or outside. Raven and id Software would be neat too. Westwood Studios. reply latchkey 16 hours agoprevBack in 1993, I was in college and working for the extended education department running their all their computer infrastructure. One day, someone wheeled this approx. 3x3 foot sized box to my door and asked me if I wanted it. It was a SGI Onyx with a giant monitor sitting on top, with a keyboard and mouse. I plugged it in and it sounded like an airplane taking off. It immediately heated up my entire tiny office. It was the 4th Unix I had ever played with (Ultrix, NeXT and A/UX were previous ones). It had some cool games on it, but beyond that, at the time, I had no use for it because A/UX on my Quadra950, was so much more fun to play with. I don't even think I ever opened it up to look at it. I don't know what I was thinking. lol. After realizing it did not have much going for it, I ended up just turning it on when the office was cold and using it as a foot rest. Oh yea, found a video... https://www.youtube.com/watch?v=Bo3lUw9GUJA reply vrinsd 15 hours agoprevI believe nVidia was started with a lot of SGI's core technology ; not \"I have a good idea and I can't do it here\" and more like \"let me just take this stuff I doubt anyone will notice\". I think SGI sued but didn't really pursue the matter because they didn't really see nVidia as a threat. I think Jensen was pivotal in this \"technology transfer\". Regarding computing cycles, boom/bust, I recently re-read Soul of New Machine and was struck by how much the world has NOT changed. Sure we're not talking about micro/mini-computers and writing micro-coded assembly but the whole \"the market is pivoting and we need to ride this wave\" and \"work like a dog to meet some almost unobtainum goal\" seems to still underpin being an engineer in \"tech\" today. reply alecco 15 hours agoparent(1999) https://www.eetimes.com/sgi-graphics-team-moves-to-nvidia/ reply markus_zhang 14 hours agoparentprevI love \"Soul of New Machine\" too. It was a blast to read. It even made me ponder the possibility to start over at 40+ and do something hardware-wise (or very low-level software). Of course I then found myself drown by 2 mortgages and dropped the thought. reply miohtama 15 hours agoparentprevThe Nvidia lawsuit is discussed in the article. reply _DeadFred_ 14 hours agorootparentI mean there's more to it. NVidia literally just took SGI's IP. Only more blatant start was Cisco, where they straight stole a University computer. reply takinola 12 hours agorootparentCisco was started by a husband/wife team who were the heads of IT for the Stanford Electrical Engineering School and Business School respectively. Anecdotally, they first developed the technology trying to connect the networks for both schools. reply meekaaku 13 hours agorootparentprevwhere can i read about this cisco thing? reply vrinsd 13 hours agorootparenthttps://www.tcracs.org/tcrwp/1origin-of-cisco/ reply formerly_proven 14 hours agoparentprevFrom my reading SGI was already dead and falling apart by that time. If you look at 3D, SGI had two graphics architectures in the 90s: RealityEngine from 1992 and InfiniteReality from 1996. They never managed to release a follow-up to IR. Similarly everything that came after about 1996-97 was a refresh of a prior product with only marginal changes. And then they went bankrupt in the early 2000s. So SGI had really only a very brief productive period that was over by the second half of the 1990s. SGI also never had a presence in business critical applications which gave some of the other vendors more momentum (HP-UX/PA-RISC, VMS/Alpha, Solaris/SPARC). reply cuno 12 hours agorootparentI worked at SGI on the next generation (code named Bali) in 1998 (whole year as an intern) and 1999 (part time while finishing my degree, flying back and forth from Australia). Bali was revolutionary. The goal was realtime Renderman and it really would. I had an absolute blast. I ended up designing the highspeed data paths (shader operations) for world's first floating point frame buffer (FP16 though we called it S10E5) with the logic on embedded DRAM for maximum floating point throughput. It was light years ahead of its time. But the plug got pulled just as we were taping out. Most of the team ended up at Nvidia or ArtX/ATI. The GPU industry was a small world of engineers back then. We'd have house parties with GPU engineers across all the company names you'd expect, and with beer flowing sometimes maybe a few secrets could eh spill. We had an immersive room to give visual demos and Stephen Hawking came in once pitching for a discount. For team building, we launched potato canons into NASA Moffet field, blew up or melted Sun machines for fun with thermite and explosives. Lots of amazing people and fond memories for a kid getting started. reply mrpippy 9 hours agorootparentVery cool. Was Bali going to be the next high-end architecture after InfiniteReality? (I think IR was code-named “Kona” so the tropical codenames fit) Why did they cancel it, money running out? It’s sad to think they were close to a new architecture but then just kept selling IR for years (and even sold a FireGL-based “Onyx” by the end). Also was it a separate team working on the lower-end graphics like VPro/Odyssey? reply cuno 4 hours agorootparentYes Bali was the next gen architecture and incredibly scalable. It consisted of many different chips connected together in a network that could scale. The R chip was so big existing tools couldn't handle it and ppl were writing their own tools. As a result it was very expensive to tape out so many hefty chips and I think that's why when it came time, and with a financial crisis, upper management pulled the plug. Yes there were separate teams working on the lower-end graphics. reply phonon 5 hours agorootparentprevWhy was Bali cancelled? reply vrinsd 13 hours agorootparentprevWell, Most Hollywood effects were all done on SGI systems before the slow migration to Linux. Renderman, Maya, were all SGI first-party programs. Also SGI made huge advances in NUMA and machines with dozens of CPUs/processors before most other companies ventured into this space. But not business critical like IBM CICS or Java. 1. https://en.wikipedia.org/wiki/NUMAlink 2. https://www.cs.ucr.edu/~bhuyan/CS213/2004/numalink.pdf 3. https://cseweb.ucsd.edu/classes/fa12/cse260-b/Lectures/Lec17... reply sllabres 11 hours agorootparentThe large Origin servers and the nice indigo workstations at trade fairs with their cool real time visualizations comes into my mind. Also applications like Softimage, the 4Dwm desktop ... Later the large Altix NUMA systems with core counts in unprecedented sizes (and problems booting due to lock contention ;) And of course their donation of the XFS filesystem to the linux world! reply assimpleaspossi 16 hours agoprevI was a system engineer for SGI in 1992 working mainly with McDonnell-Douglas in St Louis. It was thrilling to be sitting in the cafeteria and have Jim Clark plop down next to me for lunch. Just one of the guys. As an outsider--cause I didn't live and work in California--this was the go-go atmosphere of such companies back then where they thought they could do no wrong. And the after work parties were wild (how the heck do you break off half a toilet bowl?). One of the buildings had plastic over the windows cause that's where they were working on the plugin GL card for the PC. (Ssh! No one's supposed to know that!) Being the first system engineer in St Louis, my eyes lit up when my manager told me he had ordered an 16-core machine for my office--just for me! I was hired as a video expert. The company re-org'ed and my new boss decided he needed a Fortran expert so that was the end of my job with SGI. reply ChrisMarshallNY 16 hours agoprevI remember having a Personal Iris, at the company I worked at, and, later, an Indigo. We never used them. I think they were really there, to impress the visitors (They were in our showroom). I remember the colors as being very different, from the photos, though. The Personal Iris was a deep purplish-brown, and the Indigo was ... indigo. Jim Clark sounds like my kinda guy. I made a hash of my teenage years, and barely squeaked in, with a GED, myself. It has all worked out, OK, in the end, though. reply randomdata 16 hours agoparent> We never used them. When I was in high school we had a lab full of SGI machines. They also never got used. Hundreds of thousands of dollars of computing equipment, and probably that much again in software licenses (at the commercial rate), just sitting there doing nothing. It was heartbreaking. On a happy note, the SGI bus (a semi-trailer full of SGI machines demoing their capabilities) came to school one time. As a teenage nerd, getting to play with a refrigerator-sized Onyx2 was a good day. reply mrpippy 15 hours agorootparentMy goodness, at a high school? Like Indys, or O2s? Was this a private school? reply randomdata 15 hours agorootparentThey were O2s. Rural public school. There were all kinds of toys, though. There was a dedicated classroom setup for video-based remote learning some 30 years before COVID - that got used for one semester, from what I gather (was never used while I was there). The school was even host to a dialup ISP at one point. The administrators were all in on technology. The teachers, not so much... Eventually, in my last year, the government changed the funding model and the party ended. reply fuzztester 12 hours agoparentprev>The Personal Iris was a deep purplish-brown, and the Indigo was ... indigo. Nice. I once worked at a startup that had a Cobalt Qube in the server room, and the Cobalt was ... cobalt blue. https://en.m.wikipedia.org/wiki/File:Cobalt_Qube_3_Front.jpg https://en.m.wikipedia.org/wiki/Cobalt_Qube reply fernly 7 hours agoprevI appreciate the article. As a lowly member of technical staff 92-97 I didn't see or understand a fraction of this. I *loved* my Indy workstation and the IRIX desktop UI, and I admired the brilliance of some of the engineers I worked with. Remember the Lavarand[1]? Random number generator based on an array of lava lamps? [1] https://en.wikipedia.org/wiki/Lavarand reply tombert 16 hours agoprevThere's a few cases in the history of computers where it feels like the world just \"chose wrong\". One example is the Amiga; the Amiga really was better than anything Apple or Microsoft/IBM was doing at the time, but for market-force reasons that depress me, Commodore isn't the \"Apple\" of today. Similarly, it feels like Silicon Graphics is a case where they really should have become more standard. Now, unlike Amiga, they were too expensive to catch on with regular consumers, but I feel like they should have become and stayed the \"standard\" for workstation computers. Irix was a really cool OS, and 4Dwm was pretty nice to use and play with. It makes me sad that they beaten by Apple. reply jandrese 16 hours agoparentSGI dug their own grave. Not only were the workstations expensive, but they demanded outrageously priced support contracts. This behavior drives people nuts and will insure that the switch to a competitor the instant it becomes an option. Despite the high cost, the support contracts had a pretty lousy reputation as well, with long wait times for repairs from a handful of overworked techs. Even worse is the company turned away from its core competencies to focus on being an also-ran in the PC workstation market. There was a window in the mid-90s where it would have been possible for SGI to develop a PC 3D accelerator for the consumer market using their GE technology, but nobody in the C-Suite had the stomach to make a new product that would undercut the enormous profit margins on their core product. It's the classic corporate trap. Missing out on the next big thing because you can't see past next quarter's numbers. Imagine basically an N64 on a PCI card for $150 in 1996. The launch versions could be bundled with a fully accelerated version of Quake. The market would have exploded. reply grumpyprole 15 hours agorootparent> The market would have exploded Absolutely, they could have been where Nvidia is now! reply Keyframe 15 hours agorootparentI'd argue Nvidia is ex-SGI, and so is ex-ATI. It's all their crew in the beginnings. reply foobarian 15 hours agorootparentI wish we could have a debugging view of the universe, draw a diagram with clusters of people labeled with company names, and watch them change over time. :-) reply jmtulloss 14 hours agorootparentThis view would certainly explain to people outside of Silicon Valley/ SF why the Bay Area has been so dominant in our industry for so many years. reply christkv 15 hours agorootparentprevOr they could have 3dfxed themselves. reply cduzz 12 hours agorootparentprevUgh. Worked at a university in the early 90s. Maybe irix was okay to use if you were just sitting in front of it doing rando user / graphics things, but administering it was unbearable. The license fees to get OS updates were exorbitant; you'd have to get wacky new licenses to enable NFS or NIS and you'd need new kernels for just about anything. As far as I could tell they were a cursed company that hated their users. \"Here's a pretty thing that does one thing well but is otherwise insane and will ruin you when you need it most.\" Good riddance. reply snakeyjake 16 hours agoparentprev>One example is the Amiga; the Amiga really was better than anything Apple or Microsoft/IBM was doing at the time Amiga was only better 1985-1988. I still have my original Amiga and A2000. I was an Amiga user for a decade. They were very good. I was platform agnostic, caring only to get work done as quickly and easily as possible so I was also an early Macintosh user as well as Sun and PA-RISC. And yes, I still have all of those dinosaurs too. By 1987 PC and Mac caught up and never looked back. But by 1988 the PS/2 with a 386 and VGA was out and the A2000 was shipping with a 7MHz 68000 and ECS. By 1990 the 486s were on the market and Macs were shipping with faster 030s and could be equipped with NuBUS graphics cards that made Amiga graphics modes look like decelerated CGA. After the A2000 the writing was on the wall. Note: my perspective is of someone who has always used computers to do work, with ALMOST no care for video games so all of the blitter magic of Amiga was irrelevant to me. That being said when DOOM came out I bought a PC and rarely used my Amigas again. What I can confidently assert is that I upgraded my A2000 many times and ran into the absolute configuration nightmare that is the Amiga architecture and the problems with grafting upgrades onto a complex system with multiple tiers of RAM and close OS integration with custom chips. One more bit of heresy is that I always considered Sun's platform to be superior to SGI's. reply icedchai 14 hours agorootparentI think you are mostly right, I just think your timing is off. Those early 386 machines and Mac II systems were very expensive, at least 2 to 3x the cost of an Amiga. The average home user wasn't going to drop $8K on a PS/2 model 80 with a 386/16. By the early 90's the Amiga just wasn't competitive. The chip set barely evolved since 1985. ECS barely added anything over the original chip set. By around 1992 or 1993, 386 systems with SVGA and Soundblaster cards were cheap. Amiga AGA was too little, too late. Also consider the low end AGA system (Amiga 1200) was totally crippled with only 2 megs of slow \"chip\" RAM. I was an Amiga fan until 1993. Started with an A500, then A3000. Eventually I moved on to a 486 clone w/Linux. Later on I had a Sun SparcStation 10 at home, so I agree with you on Sun and SGI. reply logicprog 16 hours agorootparentprev> Amiga was only better 1985-1988. By 1987 PC and Mac caught up and never looked back. Oh indubitably! I don't think even the most committed Amiga fan, even the ones that speculate about alternate histories, would deny that at all. The thing is, though, that only happened because Commodore essentially decided that since it had so much of a head start, it could just rest on its laurels and not really innovate or improve anything substantially, instead of constantly pushing forward like all of its competitors would do, and so eventually the linear or even exponential curve of other hardware manufacturers' improvements outpaced its essentially flat improvement curve. So it doesn't seem like IBM PCs and eventually even Macs outpacing the power of Amiga Hardware was inevitable or inherent from the start. If they had instead continued to push their lead — actually stuck with the advanced Amiga chips that they were working on before it was canceled and replaced with ECS for instance — I certainly see the possibility of them keeping up with other hardware, and eventually transitioning to 3D acceleration chips instead of 2D acceleration chips when that happened in the console world, eventually perhaps even leading to the Amiga line being the first workstation line to have the gpus, and further cementing their lead, while maintaining everything that made Amiga great. Speculating even further, as we are seeing currently with the Apple M-series having a computer architecture that is composed of a ton of custom made special purpose chips is actually an extremely effective way of doing things; what if Amiga still existed in this day and age and had a head start in that direction, a platform with a history of being extremely open and well documented and extensible being the first to do this kind of architecture, instead of it being Apple? Of course there may have been fundamental technical flaws with the Amiga approach that made it unable to keep up with other hardware even if Commodore had had the will; I have seen some decent arguments to that effect, namely that since it was using custom vendor-specific hardware instead of commodity hardware that was used by everyone, they couldn't take advantage of the cross-vendor compatibility like IBM PCs, could and also couldn't take advantage of economies of scale like Intel could, but who knows! reply pjmlp 15 hours agorootparentFrom retrogaming talks from former Commodore engineers, the issues were more political and management than technical alone. reply logicprog 15 hours agorootparentThat's definitely how it seems to me, which is why I focused on Commodores poor management decisions first and only mentioned the possible technical issues second reply AnimalMuppet 14 hours agorootparentprevThat's kind of typical, though, isn't it? When a company falls off, it's almost always not just technical. reply panick21_ 53 minutes agorootparentprevThe thing with Commodore was that as a company it was just totally dysfunctional. The basically did little useful development between C64 and the Amiga (the Amiga being mostly not their development). The Amiga didn't sell very well, specially in the US. The company was going to shit after the Amiga launched, it took a competent manager to save the company and turn the Amiga around into a moderate success. Commodore didn't really have money to keep up chip development. They had their fab they would have need to upgrade that as well, or drop it somehow. Another example of that is the Acorn Archimedes. Absolutely fucking incredibly hardware for the price. Like crushing everything in price vs performance. But ... literally launched with a de-novo operating system with 0 applications. And its was a small company in Britain. The dream scenario is for Sun to realize that they should build a low cost all costume chip device. They had the margin on the higher end business to support such a development for 2-3 generations and to get most software ported to it. They also had the software skill to make the hardware/software in a way that would allow future upgrades. reply pjmlp 15 hours agorootparentprevIt took a bit more than 1990, for PC 16 bit sound card, Super VGA screens, with Windows 3.1 to be widely adopted for the PC to out perform the Amiga, specially in European price points. My first PC was acquired in 1992, and still only had a lousy beeper, on a 386SX. reply geophile 15 hours agorootparentprevI was similar, not really interested in graphics, just a nice programming environment. PCs had that stupid segmented address space (which was not ignorable at the programming language level), expensive tools, and crappy OSes. My Amiga 2000 had a flat address space, a nice C development environment, and multitasking actually worked. It really was ahead of its time, in combining a workstation-like environment and an affordable price. reply snakeyjake 15 hours agorootparent>My Amiga 2000 had a flat address space Chip ram, fast ram, cpu ram, expansion board ram, or slow ram? Did too much ram force your zorro card into the slooooooooooow ram address space (mine did)? Tough cookies bucko! Macintosh, pounding on table: \"RAM is RAM!\" reply logicprog 15 hours agorootparentAs someone trying to get into Amiga retro competing as a hobby in today's day and age, I find it keeping all the different types of ram straight very confusing lol reply geophile 10 hours agorootparentprevThis was a loooooong time ago. I have no clue. reply dylan604 15 hours agorootparentprevWe kept our A2000 viable longer by adding the CPU board with the 030 chip. We went from 7MHz to somewhere around 40MHz or whatever. It meant that my Lightwave render went from 24 hours per frame to a few hours per frame. reply qqtt 16 hours agoparentprevMy main problem with Silicon Graphics (& have the same problem with Sun Microsystems) is that they just tried to do too much in propriety hardware and completely resisted standards. Microsoft & IBM \"won\" because they made computers with actual upgrade paths and operating systems with wide support among upgrade paths. With SGI/Sun you were very much completely locked in to their hardware/software ecosystem and completely at the mercy of their pricing. In this case, I think the market \"chose right\" - and the reason that the cheaper options won is because they were just better for the customer, better upgradability, better compatibility, and better competition among companies inside the ecosystems. One of the most egregious things I point to when discussing SGI/Sun is how they were both so incredibly resistant to something as simple as the ATX/EATX standard for motherboard form factors. They just had to push their own form factors (which could vary widely from product to product) and allowed almost zero interoperability. This is just one small example but the attitude permeated both companies to the extent that it basically killed them. reply dekhn 16 hours agorootparentThe big exception here is that SGI took IrisGL and made it into OpenGL which as a standard lasted far longer than SGI. And OpenGL played a critical role preventing MSFT from taking over the 3D graphics market with Direct3D. reply pjmlp 15 hours agorootparentExcept that OpenGL only mattered thanks to Carmack and id Software mini-GL drivers. It hardly matters nowadays for most game developers. reply dekhn 15 hours agorootparentWhen I say \"hardware graphics market\" I'm referring to high performance graphics workstations, not gaming. There is a whole multibillion dollar market there (probably much smaller than games, but still quite significant). It's unclear what carmack's influence on the high performance graphics workstation environment is, because mini-GL left out all the details that mattered to high performance graphics (line rendering would be a good example). In my opinion, Mesa played a more significant role because it first allowed people to port OpenGL software to run on software-only cheap systems running Linux, and later provided the framework for full OpenGL implementations coupled with hardware acceleration. Of course, I still greatly enjoyed running Quake on Windows on my 3dfx card with OpenGL. reply pjmlp 15 hours agorootparentWell, put that way it is a market that runs on Windows with OpenGL/DirectX nowadays, or if using GNU/Linux, it is mostly with NVIDIA's proprietary drivers, specially when considering VFX reference platform. reply thisislife2 16 hours agorootparentprev> With SGI/Sun you were very much completely locked in to their hardware/software ecosystem and completely at the mercy of their pricing. How is that in anyway different from Apple today with it's ARM SoCs, soldered SSDs and an OS that requires \"entitlements\" from Apple to \"unlock\" features and develop on? reply Gracana 15 hours agorootparentYou can buy a cheap Mac and easily write programs for it. You don't have to spend $40k on a computer, you don't have to buy a support contract, you don't have to buy developer tools. reply fuzztester 14 hours agorootparent>You can buy a cheap Mac and easily write programs for it. Interesting. How cheap? Never used Macs, only Windows and Unix and Linux. reply cryptoxchange 13 hours agorootparentEvery time I’ve checked over the last decade (including today), you can buy a mac mini that supports the latest macOS for under $250 on ebay. You can also test your app using github actions for free if your use case fits in the free tier. There is no way to do this for an IBM z16, which is the kind of vendor lock in that people are saying Apple doesn’t have. reply icedchai 13 hours agorootparentprevYou can get a Mac Mini for $600-ish. Never get the base model though. (FYI, macOS is Unix.) reply fuzztester 5 hours agorootparentprevThanks, guys. reply mcculley 15 hours agorootparentprevAre there entitlements or unlockable features other than when talking about App Store distribution? reply CountHackulus 14 hours agorootparentprevThanks to web browsers and web apps it's not QUITE as bad of a lock-in nowdays. At least from a general consumer point of view. reply hn_throwaway_99 16 hours agoparentprev> Similarly, it feels like Silicon Graphics is a case where they really should have become more standard. Now, unlike Amiga, they were too expensive to catch on with regular consumers, but I feel like they should have become and stayed the \"standard\" for workstation computers. I think you highlighted very correctly there, though, why SGI lost. It turned out there were cheaper options, which while not on par with SGI workstations initially, just improved at a faster rate than SGI and eventually ended up with a much better cost/functionality profile. I feel like SGI just bet wrong. The article talks about how they acquired Cray, which were originally these awesome supercomputers. But it turned out supercomputers essentially got replaced by giant networks of much lower cost PCs. reply bunderbunder 16 hours agorootparentHypothesis: What smaller businesses are using will tend to be what takes over in the future, just due to natural processes. When smaller businesses grow, they would generally prefer to fund the concurrent growth of existing vendors that they like using than they are to switch to the existing \"industrial-grade\" vendor. At the same time, larger organizations that can afford to start with the industrial-grade vendors are only as loyal as they are locked in. reply 01HNNWZ0MV43FF 16 hours agorootparentI see the same trend in programming languages. Say a really solid career lasts from about 20 to 60, 40 years long. Say that halfway through your career, 20 years in, you're considered a respectable senior dev who gets to influence what languages companies hire for and build on. So in 20 years in, the current batch of senior devs will be retiring, and the current noobies will have become senior devs. *Whatever language is easy to learn today will be a big deal in 20 years* That's how PHP, Python, and JavaScript won. Since JavaScript got so much money poured on it to make it fast, secure, easy, with a big ecosystem, I say JS (or at least TS) will still be a big deal in 20 years. The latest batch of languages know this, and that's why there are no big minimal languages. Rust comes with a good package manager, unit tester, linter, self-updater, etc., because a language with friction for noobies will simply die off. One might ask how we got stuck with the languages of script kiddies and custom animated mouse cursors for websites. There's no other way it could turn out, that's just how people learn languages. reply chuckadams 14 hours agorootparentBack in the old days there was a glut of crappy bloated slow software written in BASIC. JS is the BASIC of the 21st century: you can write good software in it, but the low bar to entry means sifting through a lot of dross too. My take: that’s just fine. Tightly crafted code is not a lost art, and is in fact getting easier to write these days. You’re just not forced into scrabbling for every last byte and cpu cycle anymore just to get acceptable results. reply tombert 16 hours agorootparentprevI mean, there are corporations who only sell to very large corporations and have had plenty of success doing so. Stuff like computational fluid dynamics software, for example, has a pretty-finite number of potential clients, and I don't think I could afford a license to ANSYS even if I wanted one [1], since it goes into the tens of thousands of dollars. I don't think there are a ton of startups using it. But I think you're broadly right. [1] Yes I know about OpenFOAM, I know I could use that if I really wanted. reply gspencley 15 hours agorootparentprevI still dream of having a Beowulf Cluster of Crays. One day ... reply analognoise 15 hours agorootparenthttps://github.com/DarkwaveTechnologies/Cray-2-Reboot I'm on board for this project? reply tombert 16 hours agorootparentprevYeah, I'm more annoyed about Amiga than SGI. They were priced competitively with Apple and IBM offerings. I guess it's just kind of impossible to predict the future. I don't think it's an incompetent decision to try and focus entirely on the workstation world; there are lots of businesses that make no attempt to market to consumers, and only market to large companies/organizations, since the way budgeting works with big companies is sort of categorically different than consumer budgets. But you're absolutely right. Apple and Windows computers just kept getting better and better, faster and faster, and cheaper and cheaper, as did 3D modeling and video editing software for them. I mean, hell, as a 12 year old kid in 2003, I had both Lightwave 3D (student license) and Screenblast Movie Studio (now Vegas) running on my cheap, low-spec desktop computer, and it was running fast enough to be useful (at least for standard definition). reply mike_hearn 16 hours agorootparentOf course, the reason they got better so fast is volume. There was just way more investment into those platforms. Which means this explanation is somewhat circular: they were successful because they were successful. I think a more useful explanation is that people rate the value of avoiding vendor lockin extraordinarily high, to the extent that people will happily pick worse technology if there's at least two competing vendors to choose from. The IBM PCs were not good, but for convoluted legal reasons related to screwups by IBM their tech became a competitive ecosystem. Bad for IBM, good for everyone else. Their competitors did not make that \"mistake\" and so became less preferred. Microsoft won for a while despite being single vendor because the alternative was UNIX, which was at least sorta multi-vendor at the OS level, except that portability between UNIXen was ropey at best in the 90s and of course you traded software lockin for hardware lockin; not really an improvement. Combined with the much more expensive hardware, lack of gaming and terrible UI toolkits (of which Microsoft was the undisputed master in the 90s) and then later Linux, and that was goodbye to them. Of course after a decade of the Windows monopoly everyone was looking for a way out and settled on abusing an interactive document format, as it was the nearest thing lying around that was a non-Microsoft specific way to display UI. And browsers were also a competitive ecosystem so a double win. HTML based UIs totally sucked for the end users, but .... multi-vendor is worth more than nice UI, so, it wins. See also how Android wiped out every other mobile OS except iOS (nobody cares much about lockin for mobile apps, the value of them is just not high enough). reply cmrdporcupine 16 hours agorootparentprevThis betting wrong on specialization happened over and over again in the late 70s and 80s. The wave of improvements and price reduction in commodity PC hardware was insane, especially from the late 80s onwards. From Lisp machines to specialized graphics/CAD workstations, to \"home computer\" microcomputer systems, they all were buried because they mistakenly bet against Moore's law and economies of scale. In 91 I was a dedicated Atari ST user convinced of the superiority of the 68k architecture, running a UUCP node off my hacked up ST. By the end of 92 I had a grey-box 486 running early releases of Linux and that was that. I used to fantasize over the photos and screenshots of workstations in the pages of UnixWorld and similar magazines... But then I could just dress my cheap 486 up to act like one and it was great. reply kazinator 14 hours agorootparentAtari ST and Intel PC are not distant categories. Both are \"'home computer microcomputer' systems\". Not all home computer systems can win, just like not all browsers can win, not all spreadsheets can win, not all ways of hooking up keyboards and mice to computers can win, ... reply cmrdporcupine 14 hours agorootparentThey were distant on market tier but most importantly on economies of scale. The Intel PC market grew exponentially. reply kazinator 13 hours agorootparentSure, but the economy of scale came from the success. The first IBM PC was a prototype wire-wrapped by hand on a large perf board. When you switched to Intel in 1992, PC's had already existed since 1981. PC's didn't wipe out most other home computers overnight. reply HarHarVeryFunny 16 hours agoparentprevThe reason SGI failed, and eventually Sun too, isn't because the world \"chose wrong\", but because their performance simply did not keep up with x86. When these RISC-based workstations were initially released their performance, especially at graphics, was well beyond what a PC could do, and justified their high prices. A \"workstation\" was in a class by itself, and helped establish the RISC mystique. However, eventually Intel caught up with the performance, at a lower price, and that was pretty much the end. Sun lived on for a while based on their OS and software ecosystem, but eventually that was not enough especially with the advent of Linux, GCC, etc, as a free alternative. reply cduzz 14 hours agorootparentIvan Sutherland described the reason [1] why PCs won a long time ago. Basically a custom tool may do a thing \"better\" than a general purpose tool for a while, but eventually, because more resources are spent improving the general tool, the generalized tool will be able to do the same thing as the specialty tool, but more flexibly and economically. [1] http://www.cap-lore.com/Hardware/Wheel.html reply sys_64738 14 hours agorootparentprevSun had the perfect opportunity with Utility Computing around the mid-2000s but when cloud took off we had Oracle buying SUNW. They killed Sun Cloud which had the opportunity to be big, vast, and powered by JAVA hardware. Sun Microsystems was a company like no other. The last of a dying breed of \"family\" technology companies. reply msisk6 14 hours agorootparentI was at the MySQL conference when it was announced that Oracle was buying Sun. It just took all the life out of the conference. All the Sun folks were super pissed off. Truly the end of an era. reply hodgesrm 12 hours agorootparentI was there too. It certainly felt \"timed\" to maximize the sense of deflation for people working on MySQL. Perhaps it was just",
    "originSummary": [
      "Silicon Graphics, founded in 1981 by James Henry Clark, revolutionized workstations and graphics in the 1980s but encountered financial difficulties in the late 1990s.",
      "After facing financial challenges, the company went through partnerships and acquisitions before filing for bankruptcy and being acquired by Rackable Systems in 2009.",
      "The company's journey and impact on the computing industry are detailed in the book \"Abort Retry Fail\" by Bradford Morgan White."
    ],
    "commentSummary": [
      "The article covers the rise and fall of Silicon Graphics, highlighting how high-end companies struggle with cheaper competition from disruptive innovation.",
      "It addresses challenges in adapting to market shifts, the impact of startups on established companies, and the contrast between traditional firms and disruptors like Tesla and Apple.",
      "Topics include missed opportunities for SGI, the evolution of technology ecosystems, the importance of OpenGL in the graphics market, and the shift from specialized systems to general-purpose tools influenced by smaller businesses."
    ],
    "points": 286,
    "commentCount": 306,
    "retryCount": 0,
    "time": 1712335358
  },
  {
    "id": 39940975,
    "title": "Revolutionizing UEFI Firmware with Rust-based Graphical IRC Client",
    "originLink": "https://axleos.com/an-irc-client-in-your-motherboard/",
    "originBody": "An IRC client in your motherboard 05 Apr, 2024 Reading time: 11 minutes Table of contents A quick refresher on UEFI Network boot Rust networking in UEFI Cursor support Modelling IRC messages Using libgui in UEFI Scroll bars Text rendering on scroll views Improving libgui Completely unnecessary I made a graphical IRC client that runs in UEFI. It’s written in Rust and leverages the GUI toolkit and TrueType renderer that I wrote for axle’s userspace. I was able to develop it thanks to the vmnet network backend that I implemented for QEMU. I’ve published the code here. You can connect to an IRC server, chat and read messages, all from the comfort of your motherboard’s pre-boot environment. “Why”? What kind of question is “why”? A quick refresher on UEFI The bootloader for any OS is itself loaded with the help of firmware that’s stored on the motherboard’s ROM. Back in the Bad Old Days, this motherboard firmware was a BIOS implementation. This pre-boot environment is often thought of as the first major step to the computer starting up. BIOS imposed a bunch of annoying limitations✱, so an industry consortium came up with a new standard to replace it, UEFI. ✱ Note For example, BIOS mandates that the bootloader starts off in 16-bit mode, as all APs ostensibly do. It also imposes weird and legacy requirements on the bootloader, such as mandating that the bootloader must have a self-contained first stage loader program that fits in 512 bytes. Just like the BIOS, a UEFI implementation is shipped on each motherboard in ROM. This UEFI firmware provides an environment for the operating system’s bootloader to run in✱, and provides various APIs that the bootloader can leverage to do its thing. ✱ Note Here’s axle’s UEFI bootloader. UEFI is a massive step forwards from BIOS! The bootloader is dropped into a 64-bit environment from the get-go, and UEFI provides tons of helpful APIs for switching VESA display resolutions, allocating memory, and interacting with the EFI filesystem. UEFI is also somewhat maligned for being over-engineered. Network boot One use case that’s kind of fun is that some bootloaders allow the operating system to be loaded over the network, instead of being loaded from a stored installation on a local block device. This can be useful in some corporate environments. Supporting this use case means that the UEFI firmware ships a network stack, complete with NIC drivers and a TCP implementation, and exposes APIs to interact with this stack directly to any applications running in the pre-boot environment. Of course, there’s no obligation for the bootloader to actually load an operating system. Behold, social media! Rust networking in UEFI The most finicky part of this project by far was implementing a client for UEFI’s TCP protocol in Rust. Making this all work with its scatter-gather buffers was quite tricky. The nuts and bolts of actually using UEFI’s TCP protocol can be fairly wacky, especially when trying to explain the lifetimes and data interactions to Rust. UEFI’s TCP protocol design enforces the use of global state and re-entrant callbacks, scatter-gather buffers, and an involved set of concepts (events, tokens, handles, protocols, oh my!). I spent a number of days carefully testing my Rust code to make sure I wasn’t leaking memory, and to squash TCP receive buffer UAFs. As an example of how the UEFI programming model can be somewhat obtuse, how do you think this UEFI API is meant to be used✱? ✱ Note I’ve Rustified the syntax and simplified the API for readability. Here’s part of the UEFI API in question. enum ListenMode { NOTIFY_SIGNAL = 0, NOTIFY_WAIT = 1, } fn set_up_listen_handle( listen_mode: ListenMode, callback: Func, ) -> ListenHandle; fn wait(event_type: EventType, handle: ListenHandle) -> None; If you gave this to me on a paper napkin, the behavior I’d expect is pretty straightforward: Specifying NOTIFY_SIGNAL will invoke my callback when an event occurs. Specifying NOTIFY_WAIT, then calling wait(), will block until an event occurs, invoke my callback, then continue execution. This is not at all what UEFI does! Here’s how it really works: If you specify NOTIFY_SIGNAL, UEFI will invoke the callback when the event occurs. Using wait() will raise an error. If you specify NOTIFY_WAIT, then call wait(), UEFI will invoke your callback whenever it feels like it, multiple times, until the event occurs. Then, the wait() call will unblock. This is quite confusing, because the callback✱ has completely different semantics depending on which listening mode you use. ✱ Note The UEFI C API uses the typical pattern of accepting a function pointer and an opaque context pointer to manage callbacks. I used Sage Griffin’s excellent trick to neatly trigger Rust closures as UEFI callbacks here. According to the UEFI specifiers, when using NOTIFY_SIGNAL, the callback’s world-model should be “The event has occurred, it’s time to do the next thing!” When using NOTIFY_WAIT, the callback’s world-model should be “The event still hasn’t happened, I should poke or prod something to move things along.” In other words, UEFI allows you to flip a switch to vacillate between two completely different callback paradigms, one of which is quite nontraditional, and neither of which provide the ‘block until ready’ behavior that both their names sort of imply. The name on the tin is literally NOTIFY_WAIT, but if you expect it to notify you after the wait() completes, you’ll be in for a bout of confusion. The actual behavior is spelled out in the docs, but you need to read the WaitForEvent docstring quite closely✱. ✱ Note It was a huge pain to successfully set things up such that I could asynchronously buffer received packet data. One sensible way to structure this would be to set up a NOTIFY_SIGNAL callback that appends to a buffer each time it’s triggered. Unfortunately, due to Rust’s borrowing rules, this was painful to get working. I ended up with a NOTIFY_WAIT loop that also includes a short timeout timer. Each event loop pass, this will either trip the timer and time out, or receive some packet data and append it to the buffer. If the timer tripped, we don’t remove the previous RX transfer handle as the underlying UEFI implementation didn’t like that. Cursor support While a mouse isn’t a strict requirement for an IRC client, having one makes the whole app feel more interactive. I used UEFI’s Simple Pointer Protocol to read mouse movement and button presses, and included visual feedback on the cursor’s current position in the GUI✱. ✱ Note Unfortunately, the Simple Pointer Protocol doesn’t support scroll wheels. To scroll in UEFIRC, you can either use the arrow keys, or drag the scroll bar with the cursor. If you try to use the Simple Pointer Protocol with the OVMF UEFI firmware, you won’t manage to get any mouse events, and you won’t get many helpful errors from the API✱. ✱ Note Here’s an example from the OSDev forums in which someone notices that the Simple Pointer Protocol is unusable with the standard OVMF build. I compiled a custom UEFI firmware build that had all the right drivers and protocols compiled in (paticularly UsbMouseDxe), which allowed me to get on with it. To facilitate others to try out UEFIRC in QEMU, I’ve also uploaded my UEFI firmware to the repo. Mouse drivers report a change in the mouse’s position. A naive way to code up a mouse cursor might be something like: fn handle_mouse_event(delta_x: isize, delta_y: isize) { // 'Linear' mouse scaling current_cursor_pos.x += delta_x; current_cursor_pos.y += delta_y; } As it turns out, this ends up feeling quite sluggish. Operating systems tend to use an approach more like this: fn handle_mouse_event(delta_x: isize, delta_y: isize) { // 'Log2' mouse scaling let scale = (delta_x.abs() + delta_y.abs()).log2(); current_cursor_pos.x += delta_x * scale; current_cursor_pos.y += delta_y * scale; } Get a feel for the difference: People tend to like log2 scaling because you can get where you’re going quicker: drag with confidence, and the mouse will fly across the screen, while still allowing for fine adjustments when honing in on an area more slowly. It’s also just what most people are used to. When presented with a linear movement scaling cursor, people tend to perceive the whole environment as slow and unresponsive. Modelling IRC messages Modelling the IRC messages was straightforward and pleasant. IRC uses a textual, line-based format that’s easy to parse, though it’s clearly encumbered by decades of slow expansion, only some of which is standardized. Using libgui in UEFI It wasn’t too bad to get my GUI toolkit running in UEFI, as I’ve already done most of the heavy lifting to make axle’s Rust GUI toolkit available in contexts other than axle itself. The first bulk of work here was providing an implementation of AwmWindow that can be used from within UEFI. After that, most of libgui comes for free, including event management, font rendering, layer compositing, view decorations, and tricky components like scroll views. Scroll bars axle’s Rust-based libgui toolkit came after axle’s C-based libgui toolkit, and the C toolkit still boasts a few features that I haven’t caught up to in the Rust version yet. For example, the C toolkit displays these nice scroll bars on scroll views. Since UEFIRC’s primary interaction takes place in a scrolling view filled with text, I couldn’t do without this for any longer. I reimplemented scroll bar functionality in the Rust libgui, with the famous ’tuck-in’ behavior at the top and bottom of the viewport that has made axle the OS of choice for the hip and fashionable the world over. Text rendering on scroll views To make UEFIRC usable, I had to make some minor, but notable, changes to how text gets rendered to scrolling views. To see why, let’s first take a look at a simpler case of representing and manipulating pixels. Representing pixel data is easy if all you have to worry about is a fixed-size rectangle of content. Imagine a buffer with width * height elements, containing RGB data. When we need to render this rectangle of content somewhere, it’s straightforward to conceptualize copying the buffer corresponding to the desired rectangular region. Views that allow scrolling their content are much more difficult. With a fixed-size rectangle, we never need to think twice about how much memory we’ll need to allocate for the pixel buffer. With a scroll view, however, all of a sudden we have an infinitely extensible canvas to think about. Should we impose a ‘maximum size’ on the scroll view and allocate a huge buffer upfront? Should we resize a backing buffer that grows as we draw more content into it? The approach for scroll views that I went with in axle’s Rust GUI toolkit is based on ’tiles’ of content. Each tile is a square pixel buffer, a few hundred pixels wide, and is the fundamental unit for scroll views. Each time we draw a bit of graphical content to a scroll view, we first allocate the tiles necessary to display the corresponding visual area. When rendering a scroll view to another layer, the visible tiles are computed and stitched together into a final image. This allows the scroll view to expand without bound, and ensures that the scroll view only allocates pixel buffer area that actually contains rendered content, instead of allocating pixel buffer memory for any empty space that the user could scroll to. This is all to say: it’s a lot more expensive to plot pixels to scrolling views than to fixed-size views, because we have to do more work to maintain the representation. Drawing graphics primitives to scroll views isn’t too bad, because the scroll view can pre-determine which tiles it’ll need to populate upfront. For example, if a caller asks to draw a circle at a given origin and radius: 1fn draw_circle(&self, circle: Circle, color: Color, thickness: StrokeThickness) { 2 // Pre-populate the tiles needed to cover the draw area 3 let bounding_box = circle.bounding_box(); 4 self.allocate_tiles_to_cover_bounding_box(bounding_box); 5 // Plot the pixels... 6} The call to allocate_tiles_to_cover_bounding_box() is fairly expensive, but we only have to pay it once for the entire shape. The absolute pathological worst case is putpixel(): 1fn putpixel(&self, pos: Point, color: Color) { 2 // We have no information available about what's being drawn! 3 // We'll need to do lots of computational work to find out 4 // whether this pixel area is covered by any of our existing tiles. 5 // If the caller is plotting multiple pixels in a row, this is 6 // very wasteful. 7 self.allocate_tiles_to_cover_bounding_box(Rect::new(pos.x, pos.y, 1, 1)); 8 // Plot the pixel... 9} Now, let’s look at how the TrueType renderer draws glyphs: 1for polygon in glyph.polygon_stack { 2 for px in polygon.pixels() { 3 layer.putpixel(px, draw_color); 4 } 5} Uh oh! The TrueType renderer is making a ludicrous number of calls to putpixel(), and the underlying scrolling view doesn’t have the opportunity to understand the wider context of how much area the renderer is going to draw to. To resolve this, I added polygon stacks as one of the ‘fundamental things’ that all view buffer implementations need to know how to draw, alongside primitives like lines, circles and rectangles. This gives the scroll view an opportunity to say “Ah ha, we’re drawing a big polygon! I can allocate all the tiles upfront!”, which is much quicker than the alternative. I don’t love having this as a fundamental primitive✱, as filling arbitrary polygons conceptually seems quite a bit heftier than rasterizing simpler shapes, but it’s practical and works well. ✱ Note Another option that I weighed for this API design was to let clients ask a graphics layer to “get this area ready for drawing”, explicitly priming the layer for a bunch of draw calls in one region. I didn’t love this either. Improving libgui Every time I implement a new graphical application against my stack, I come up against little limitations or papercuts that I’ve never run into before. These could be in the GUI toolkit, IPC, driver interface, kernel features, etc. This gives me an opportunity to just-in-time improve the system and APIs to facilitate whatever I’m building at the moment. It’s the fun of OS development! When building out UEFIRC, I made a few notable tweaks and fixes to libgui: libgui provides left-click-up events. Labels can be dynamically resized. Labels render TrueType fonts instead of the old bitmap font. Buttons render TrueType fonts instead of the old bitmap font. TrueType renderer provides more layout information when rendering a glyph. TrueType parser models and exposes more metrics from the font. Fix subtle layout and spacing bugs in TrueType renderer. TextInputView supports user-provided keypress callbacks. Completely unnecessary The IRC client itself, as a client, isn’t that usable because this project is an elaborate joke✱. ✱ Note I told a friend I was making a joke project, then explained it. She said she wasn’t sure when to laugh. I’m not so sure either. However, if you’re ever feeling mad about UEFI’s TCP/IP stack, I know just the tool to complain about it with. As a final tip of the hat, I joined the UEFI #edk2 development IRC channel from UEFI and bid good tidings. Here’s a demo showing UEFIRC in action. Newsletter Put your email in this funny little box, and I'll send you a message when I post new stuff.",
    "commentLink": "https://news.ycombinator.com/item?id=39940975",
    "commentBody": "An IRC client in your motherboard (axleos.com)284 points by codyd51 22 hours agohidepastfavorite64 comments codyd51 22 hours agoHi everyone! As a bit of a gag, I’ve made a graphical IRC Client that runs entirely in the UEFI preboot environment. It features completely overdone features such as TrueType fonts, a cursor, and GUI decorations. I first started this project as I was getting a bit tired building a from-scratch GPS receiver, and wanted to make something relatively quick and lighthearted. As tends to happen, this took a fair bit longer than I anticipated at the outset! A fair chunk of that time was spent on the visualisations in the post showing how scroll views are modelled and how they’re rendered to a static viewport. I really hope you enjoy them! When I first began wanting to \"stuff something in UEFI that really shouldn’t be in UEFI\", my first instinct was a Twitter client. As it turns out, someone has already done a great job making this by using UEFI’s HTTP protocol! I therefore decided that whatever I made shouldn’t use HTTP at all, because that’s taken. I went with IRC since it sits on top of TCP and has the same social media feel that doesn’t belong anywhere near a preboot environment. reply johannes1234321 16 hours agoparent> feel that doesn’t belong anywhere near a preboot environment. Seems to be quite the right place for me. How else would I get help on boot issues? reply molticrystal 15 hours agorootparentIt would be an interesting experience to dcc somebody RU [0], run it from ram, and guide that person through diagnostics. [0] https://ruexe.blogspot.com/ reply codyd51 14 hours agorootparentprevHa! I take your point. reply 1vuio0pswjnm7 13 hours agoparentprevLooking forward to ditching these bloated operating systems with all this cruft I I do not need for something smaller and simpler: UEFI. Not to mention faster startup. Easier \"embedded\" development. Of course I am joking. Sort of. As a minimalist I do not need a GUI or a mouse. It seems UEFI already has more than I need. Here is the Twitter client mentioned: https://github.com/arata-nvm/mitnal reply myself248 17 hours agoparentprevI would contend that software too large to cram into UEFI is all superfluous bloatware anyway. In my day, we had dual 360k floppies and that was plenty! reply knodi123 13 hours agorootparentDual? Pffft. reply myself248 10 hours agorootparentOne for the program, one for the data. It made storing the files easier. In a file cabinet, natch. reply hex4def6 14 hours agoparentprevThis is extremely cool! I've had an idea percolating in my mind for a while: Would it be possible to have VPN credentials stored in UEFI, and have a system reach out to a server for PXE network boot? It seems like it would be a neat way of (securely?) allowing a remote system to automatically recover in the event of a nuked install that prevents proper bootup. reply Jhsto 13 hours agorootparentNot OP, but what is much simpler is buying a motherboard with IPMI and placing that behind a VPN. If you cannot afford the couple hundred extra bucks for the motherboard, then a USB stick with minimal Linux setup + SSH and then doing a kexec from that is another option. reply E39M5S62 13 hours agorootparenthttps://docs.zfsbootmenu.org/en/v2.3.x/general/tailscale.htm... . Connect to your bootloader via your Tailscale network, select your ZFS boot environment and kexec in to it, all through a 'pretty' TUI ! reply contingencies 13 hours agorootparentprevActually, all it takes on modern hardware for PXE boot to occur on hardware failure is the BIOS boot order setting. As PXE inherently trusts the LAN, and a LAN may have VLAN support, you can assign a default VLAN to the port which equates to the PXE server you want. The PXE server can further configure by client MAC prefix, DHCP-assigned IP mapped to physical port number or similar. Configured systems can report status and/or other hardware identifiers to a server after installation and have default VLAN changed by the network fabric (more secure), or can actively request to join alternate VLANs (less secure). With PXE, any information can be fed to the machine, not just VPN credentials. This is how a lot of clusters are built, especially diskless (for CPU-bound operations) in this era of more-RAM-than-you-can-use. All of the above should work with IPMI ports if the controller is flashed with PXE-enabled firmware. reply nucleardog 7 hours agorootparentWell shit, glad I stumbled on this comment. Thanks for posting. Biggest gripe with my home lab setup is managing when something does or doesn’t PXE boot. Plug anything in and PXE boot it and it wipes the drive, does a scripted Debian install chained to an Ansible playbook that eventually installs k3s, discovers the rest of the cluster, and joins itself to it. So 0-click and 10 minutes from plug in to node in the cluster. If anything breaks, just PXE boot it and wait 10 minutes and it’s back. If anything needs updating, just PXE boot it and wait 10 minutes and it’s back. Except… these are a bunch of tiny PCs on a high shelf in my utility room. Selecting the boot order is a _project_. Never even thought about handling this from the network end. Either swapping the untagged VLAN on the switch or setting DHCP options per MAC address would let me handle this without getting up from my desk. reply kbenson 4 hours agorootparent> Except… these are a bunch of tiny PCs on a high shelf in my utility room. Selecting the boot order is a _project_. Every once in a while I look for a cheap remote KVM I can use as a crappy IPMI stand in, either with RJ45 or WiFi. I haven't looked in a year or so, but at the time the options I found all seemed far more costly than I would have hoped (the pi based ones seemed interesting but once you add the requirements together it wasn't cheap enough to be attractive to me for a home use). Server class equipment with built-in IPMI is quite a bit more expensive. I just want something affordable to put in front of a NUC to make dealing with it easier in some instances. You could stick some refurbished old KVM device in front of it to support multiple systems on that one KVM as long as they were in close proximity. Seems like you could benefit from that as well (but in your case you might get a workable solution out of switch config though). reply ahepp 6 hours agorootparentprevI believe if you are on a UEFI system, “systemctl reboot” has some flags to let you select boot options. reply Ecoste 16 hours agoparentprevI wanna know more about the from scratch GPS receiver reply codyd51 14 hours agorootparentI am really glad to hear that there's interest, and hopefully I will have a 3-part series to share on this some time soon! Similar to Andrew's project linked down below, this is a 'true' home-brew receiver. I didn't know anything about DSP, etc, when I started out, so I learned a lot about signal processing (and the incredible techniques that make GPS work), and really hope I'll be able to publish it all soon! reply Terr_ 15 hours agorootparentprevNot OP, but in the meantime this may help alleviate your thirst for \"how could someone do GPS from scratch\", especially the end parts about radio signals and encoding: https://ciechanow.ski/gps/ reply thatcherc 14 hours agorootparentThis is my favorite write up of someone truly building a GPS receiver from scratch: http://www.aholme.co.uk/GPS/Main.htm A real tour de force of DSP - really cool stuff, and well-written reply codyd51 14 hours agorootparentAndrew Holme's receiver was a crucial resource in my journey! There were times when a sentence or two from his post unlocked an insight for me. reply CamperBob2 8 hours agorootparentprevNice presentation! reply backspace_ 15 hours agoparentprevThis does not include ssl support? How much does this limit the number of irc nets that you can connect to? reply ijijijjij 14 hours agorootparentI never seen an IRC server that only support SSL.... I don't use many networks nowadays though... I only know of one channel that supports encrypted DCC transfers though. reply backspace_ 12 hours agorootparentLink-net comes to mind reply anthk 16 hours agoparentprevGopher it's easy, and you can read gopher://hngopher.com and gopher://magical.fish as starting points. reply nxobject 16 hours agoparentprevI mean, UEFI apps don't just have to be preboot environments – not with that attitude, at least! reply pred_ 15 hours agoparentprevFYI: The site keeps crashing the tab in Firefox 115.7.0esr. reply bbarnett 15 hours agorootparentYou should report it to Mozilla, nothing a site does should ever crash a browser. (Also, it could be an extension) reply o11c 7 hours agorootparentWith the possible exception of \"consumes a lot of memory, leading to the OoM killer being invoked\". reply badrabbit 13 hours agoparentprevIf this supports TLS, I would use it all the time. reply tsurba 2 hours agoprevNice! I would like to someday finish writing an OS for my IRC bot that is still running. Maybe the most useless comment but: that non-linear mouse movement (aka acceleration) is the very first thing I turn off when I boot up a new OS. It literally hurts my hand somehow. For example linearmouse is free for Mac. For Windows you can just turn off acceleration. For Linux its easy, obviously. Using mouse acceleration stops you from learning to map a distance traveled by the mouse to a distance on the screen. I do think its more efficient in the long run without it. Something I learned to do from gamers, and something I think all gamers still do for a good reason. reply sunday_serif 12 hours agoprevI love this! I think it also emphasizes the complexity and capability of software that underlies the systems most people think about. I think it is a common misconception that your OS is the \"lowest level\" of the software stack, but in actuality, there is this firmware-ish code that truly owns your system. Sometimes it does a job and goes away, other times stays running the whole time your system is up, transparent even to the OS. Sometimes, the attitude people have about this is along the lines of... \"who cares, its just low level code to get my devices running, nothing serious can happen down there\". But knowing that you can get a whole IRC client down there doesn't make it too hard to imagine all the other nefarious things that could go on. reply r3trohack3r 14 hours agoprev> “Why”? What kind of question is “why”? This is the spirit I come to HN for. Thank you for sharing. > The most frightening realization hit me: there wasn't any reason behind what I'd done. I mean, I knew why I'd done it - I just did it because it would be fun. But I knew they would ask, \"Why the hell did you do this?\" and if I didn't have a good enough reason, they would probably throw me into a mental institution.\" -- Boyd Rice reply quesera 15 hours agoprev> I told a friend I was making a joke project, then explained it. She said she wasn’t sure when to laugh. I’m not so sure either. Don't sell yourself short. There's a botnet C&C client project here! OK the UI is a bit funny. :) reply dvt 16 hours agoprevThis is super cool. Had no idea UEFI APIs were so readily-available and well-documented. Awesome work! Out of curiosity, what was the dev cycle like? I assume you were running the thing in a VM. Did you have to \"boot up\" every time you wanted to run the client? reply codyd51 12 hours agoparentThanks very much! The other commenter is correct that the work loop typically revolved around booting a QEMU instance which ships my UEFI application. The main run script will regenerate an EFI filesystem that contains a fresh build of UEFIRC, then pass it to QEMU. However, the overhead here can get a bit cumbersome when trying to build a GUI. I set things up such that the app could target either bare-bones UEFI, or a hosted environment that runs on my Mac. By flipping a build flag, my GUI toolkit would either draw directly to the UEFI-provided framebuffer, or would hook into my Mac's windowing system and receive/push events to that. You can see some of the overhead of this 'dual-target' approach in the app's entry point: https://github.com/codyd51/uefirc/blob/main/src/main.rs. Parsing IRC messages also really doesn't need any accoutrements, so I developed those with a unit test suite running directly on my Mac - you can see part of that here: https://github.com/codyd51/uefirc/blob/main/src/irc/response.... reply speps 16 hours agoparentprevQEMU can run UEFI apps reply squarefoot 5 hours agoprevI can't but think about some music related applications that would benefit from a bare metal environment that boots very quickly and doesn't contain unnecessary bloat, for example a synthesizer (just like MiniDexed for the Raspberry Pi, but not limited to FM), and a effect processor that interfaces with an external pedal board, for guitars, bass etc. Both would require also support for audio cards, although most recent mainboards certainly have decent converters. reply minusLik 11 hours agoprev> “Why”? What kind of question is “why”? Because low-level applications like this were promised when UEFI was introduced, that's why. UEFI's creators went even as far as to dream of replacing the Linux-based Internet-only mini-OSes of some vendors which could be accessed by pressing a certain key during boot (though I don't remember what they were called). reply pram 16 hours agoprevAmazing visualizations in the article, very impressive. reply codyd51 15 hours agoparentThank you very much, I've spent a lot of time on them over the past week and am really pleased to hear that you enjoyed them! reply wngr 14 hours agorootparentI was really impressed when I clicked the reload button -- inspiring attention to detail! How did you create those? reply codyd51 13 hours agorootparentWow, thank you so much! I made these using HTML canvases and TypeScript. I’m drawing everything in code, including the pixel art (which is defined in the source). The animations are made using a small animation system that I made for this post. This system has two useful properties: 1. It allows me to animate whatever property of the object I’m interested in (alpha, frame, etc). 2. It allows me to set up other work to be triggered when the animation has reached a certain completion threshold, which lets the animations flow into each other. This is how (for example) the grid lines ‘cascade’ in after each other. The 3D animations are also primarily HTML canvases, and I used Three.js to place them as textures in a 3D scene. I have some logic to map the coordinate system of the canvases to the 3D scene, so that I can draw the connective tissue between the canvases and run animations that operate on objects both on the 2D canvases and the 3D scene. reply a3f 12 hours agoprevNice writeup! This reminds me of the barebox bootloader April fools two years back, which will connect you to #barebox, when all other boot targets fail[1]. :-) The focus there was on adding TCP support to barebox though and it lacks your nice GUI elements. Only interface was CLI (which can be drawn on top of EFI GOP when barebox is built as EFI payload). [1]: https://lore.barebox.org/barebox/20220401145902.GF4351@telli... reply rdl 17 hours agoprevPerfect for preboot botnets :) reply Latty 12 hours agoprevThis instantly made me think of a recent video by the Cathode Ray Dude, talking about HP's 'email client' (read: Outlook Plugin) \"QuickLook\" which was a shipped product implemented this way: https://www.youtube.com/watch?v=ssob-7sGVWs (also goes into some even weirder stuff they did). This does the hard bit of networking that QuickLook skipped though. reply themaninthedark 16 hours agoprevAs always, the relevant xkcd: https://xkcd.com/1782/ I understand that BIOS had limitations but I still think that UEFI is way too much. reply tomsmeding 12 hours agoprev> Each time we draw a bit of graphical content to a scroll view, we first allocate the tiles necessary to display the corresponding visual area. I get the intent here, to avoid the issue of not knowing how large a buffer to allocate for your scroll view in the first place. But doesn't this still use way too much memory? Especially for something like an irc client, the scroll view will only grow as the program is used longer, and as such the number of tiles of rendered content will also only grow. You'll of course need to keep the textual history in memory, but that's far smaller than the rendered screen contents. Proper GUI toolkits (disclaimer: I have worked with few, and only a little at that) handle this, I think, by not considering the scroll view a canvas to draw stuff on, but instead a thing that you can place widgets on. Each widget has access to some data that allows it to re-draw its graphical content at some position on-screen, and the scroll view forgets rendered content far outside the visible area, and asks widgets to re-draw their content whenever they get scrolled onto the screen again. Of course, you could expect requests for even more over-engineering ;) Cool stuff! As someone else mentioned, you missed April 1st. reply codyd51 12 hours agoparentYes, you're absolutely correct! The design here totally suffers from unbounded memory use if you draw onto a large canvas. (Restating parts of your comment for confirmation that this is also how I think about it.) To resolve this while maintaining the spirit of the design, I think two representations need to be kept: one for the rendered pixel data, and one 'out of band' representation (such as the textual data - you also highlighted this in your comment). The idea is that, when the pixel buffer memory gets too large, some of it can be dropped. When it scrolls back into view again, it can be repopulated by the secondary representation. What I don't like about this is how it doesn't feel like it generalises well - you always need to be able to store the secondary representation, and have code to redraw it. I think the concept you suggested is a really good one: just make sure everything that's drawn is its own 'encapsulated' widget with its own drawing logic, and you can ask it to render itself whenever that's convenient. I'm grateful for the input here, and think I will end up switching to this sort of approach in the future. reply tomsmeding 1 hour agorootparentI'm not sure \"correct\" engineering really fits UEFIRC, somehow :p But if it's fun, go ahead! Perhaps it's helpful for axle too. :) reply imag0r 12 hours agoprevI recall contributing to IRC client that was running inside a SoftICE debugger... but this is another level ;) reply userbinator 10 hours agoprevUEFI is basically protected-mode 32/64-bit DOS. reply SuperNinKenDo 14 hours agoprevI don't know whether to think this is awesome, or a horrifying demonstration of bloat in UEFI. reply toast0 13 hours agoparentI don't think this really demonstrates UEFI bloat. A tcp/ip stack from boot services is handy and useful for 'legitimate' network booting, not really bloat IMHO; pxe and undi is similar in a bios environment but ddoesn't necessarily come from the motherboard firmware. Access to input devices, such as keyboard and mouse is reasonable too. Graphical output seems reasonable too. And then everything else is stuff the author did or linked in. Where's the firmeware bloat? reply blueflow 13 hours agoparentprevSit back and relax. Make this project more popular. People will decide for themselves. You are right and it is already going your way, even if you are not seeing it yet. reply paradox460 12 hours agoprevMakes me miss KillerNIC reply ultra_nick 13 hours agoprevLol, this is great. You missed your chance to release it on 4/1 though. reply Solvency 15 hours agoprevThis would be even better if it were a chat interface to ChatGPT so you could ask it troubleshooting questions next time your machine won't boot into OS. reply forgotpwd16 15 hours agoparentConsidering there're ChatGPT IRC bots, can already do that indirectly. reply quesera 15 hours agorootparentBut not on a pre-booted system! reply trhway 13 hours agoparentprevI think we'll soon see a ChatGPT embedded in UEFI, and it will be solving boot issues on its own. reply anthk 16 hours agoprevNow do a gopher client and head to gopher://hngopher.com reply syngrog66 13 hours agoprev [–] bad ideas are bad. even if one can do them reply orlandrescu 3 hours agoparent [–] Sir, this is hackernews. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author created a graphical IRC client on UEFI firmware with Rust and a GUI toolkit, discussing challenges with UEFI's TCP protocol and asynchronous buffering.",
      "They focused on addressing limitations with mouse events, efficient memory allocation for graphical content in scroll views, and pre-allocating tiles for shape drawing in the project UEFIRC.",
      "Emphasizing ongoing efforts to enhance the graphical application stack showcases the commitment to improving the UEFIRC project."
    ],
    "commentSummary": [
      "A developer is working on a graphical IRC client for the UEFI environment, exploring features like VPN credentials, PXE network booting, and system recovery methods.",
      "Discussions touch on affordable networking gear, GPS receiver construction, TLS backing for IRC servers, system software intricacy, coding inspirations, GUI creation, IRC message interpretation, animation frameworks, and memory efficiency.",
      "Ideas about chat interfaces and integrating ChatGPT into UEFI are also part of the conversation."
    ],
    "points": 284,
    "commentCount": 64,
    "retryCount": 0,
    "time": 1712315637
  },
  {
    "id": 39942122,
    "title": "Israeli spy chief's identity revealed in online security lapse",
    "originLink": "https://www.theguardian.com/world/2024/apr/05/top-israeli-spy-chief-exposes-his-true-identity-in-online-security-lapse",
    "originBody": "View image in fullscreen Yossi Sariel’s 2021 book The Human Machine Team offers a radical vision for how AI can transform warfare. Illustration: Getty images; Guardian Design Israel Top Israeli spy chief exposes his true identity in online security lapse Exclusive: Yossi Sariel unmasked as head of Unit 8200 and architect of AI strategy after book written under pen name reveals his Google account Harry Davies and Bethan McKernan Fri 5 Apr 2024 09.19 EDT Share The identity of the commander of Israel’s Unit 8200 is a closely guarded secret. He occupies one of the most sensitive roles in the military, leading one of the world’s most powerful surveillance agencies, comparable to the US National Security Agency. Yet after spending more than two decades operating in the shadows, the Guardian can reveal how the controversial spy chief – whose name is Yossi Sariel – has left his identity exposed online. The embarrassing security lapse is linked to a book he published on Amazon, which left a digital trail to a private Google account created in his name, along with his unique ID and links to the account’s maps and calendar profiles. The Guardian has confirmed with multiple sources that Sariel is the secret author of The Human Machine Team, a book in which he offers a radical vision for how artificial intelligence can transform the relationship between military personnel and machines. Published in 2021 using a pen name composed of his initials, Brigadier General YS, it provides a blueprint for the advanced AI-powered systems that the Israel Defense Forces (IDF) have been pioneering during the six-month war in Gaza. An electronic version of the book included an anonymous email address that can easily be traced to Sariel’s name and Google account. Contacted by the Guardian, an IDF spokesperson said the email address was not Sariel’s personal one, but “dedicated specifically for issues to do with the book itself”. Later on Friday, in a statement to the Israeli media, the IDF described the book’s exposure of Sariel’s personal details as “a mistake”, adding: “The issue will be examined to prevent the recurrence of similar cases in the future.” Do you have information about this story? Email harry.davies@theguardian.com, or (using a non-work phone) use Signal or WhatsApp to message +44 7721 857348. The security blunder is likely to place further pressure on Sariel, who is said to “live and breathe” intelligence but whose tenure running the IDF’s elite cyber intelligence division has become mired in controversy. Unit 8200, once revered within Israel and beyond for intelligence capabilities that rivalled those of the UK’s GCHQ, is thought to have built a vast surveillance apparatus to closely monitor the Palestinian territories. However, it has been criticised over its failure to foresee and prevent Hamas’s deadly 7 October assault last year on southern Israel, in which Palestinian militants killed nearly 1,200 Israelis and kidnapped about 240 people. Since the Hamas-led attacks, there have been accusations that Unit 8200’s “technological hubris” came at the expense of more conventional intelligence-gathering techniques. In its war in Gaza, the IDF appears to have fully embraced Sariel’s vision of the future, in which military technology represents a new frontier where AI is being used to fulfil increasingly complex tasks on the battlefield. View image in fullscreen The aftermath of the 7 October attacks at the Supernova music festival. Some have blamed Unit 8200’s ‘technological hubris’ for the intelligence failure. Photograph: Manuel de Almeida/EPA Sariel argued in the published book three years ago that his ideas about using machine learning to transform modern warfare should become mainstream. “We just need to take them from the periphery and deliver them to the centre of the stage,” he wrote. One section of the book heralds the concept of an AI-powered “targets machine”, descriptions of which closely resemble the target recommendation systems the IDF is now known have been relying upon in its bombardment of Gaza. Over the last six months, the IDF has deployed multiple AI-powered decision support systems that have been rapidly developed and refined by Unit 8200 under Sariel’s leadership. They include the Gospel and Lavender, two target recommendation systems that have been revealed in reports by the Israeli-Palestinian publication +972 magazine, its Hebrew-language outlet Local Call and the Guardian. The IDF says its AI systems are intended to assist human intelligence officers, who are required to verify that military suspects are legitimate targets under international law. A spokesperson said the military used “various types of tools and methods”, adding: “Evidently, there are tools that exist in order to benefit intelligence researchers that are based on artificial intelligence.” Targets machine On Wednesday, +972 and Local Call placed the spotlight on the link between Unit 8200 and the book authored by a mysteriously named Brigadier General YS. Sariel is understood to have written the book with the IDF’s permission after a year as a visiting researcher at the US National Defense University in Washington DC, where he made the case for using AI to transform modern warfare. Aimed at high-ranking military commanders and security officials, the book articulates a “human-machine teaming” concept that seeks to achieve synergy between humans and AI, rather than constructing fully autonomous systems. It reflects Sariel’s ambition to become a “thought leader”, according to one former intelligence official. In the 2000s, he was a leading member of a group of academically minded spies known as “the Choir”, which agitated for an overhaul of Israeli intelligence practices. View image in fullscreen Destruction near al-Shifa hospital in Gaza on 1 April. The book argues that using AI to create military targets can be more efficient. Photograph: Anadolu/Getty Images An Israeli press report suggests that by 2017 he was head of intelligence for the IDF’s central command. His subsequent elevation to commander of Unit 8200 amounted to an endorsement by the military establishment of his technological vision for the future. Sariel refers in the book to “a revolution” in recent years within the IDF, which has “developed a new concept of intelligence centric warfare to connect intelligence to the fighters in the field”. He advocates going further still, fully merging intelligence and warfare, in particular when conducting lethal targeting operations. In one chapter of the book, he provides a template for how to construct an effective targets machine drawing on “big data” that a human brain could not process. “The machine needs enough data regarding the battlefield, the population, visual information, cellular data, social media connections, pictures, cellphone contacts,” he writes. “The more data and the more varied it is, the better.” Such a targets machine, he said, would draw on complex models that make predictions built “on lots of small, diverse features”, listing examples such as “people who are with a Hezbollah member in a WhatsApp group, people who get new cellphones every few months, those who change their addresses frequently”. He argues that using AI to create potential military targets can be more efficient and avoid “bottlenecks” created by intelligence officials or soldiers. “There is a human bottleneck for both locating the new targets and decision-making to approve the targets. There is also the bottleneck of how to process a great amount of data. Then there is the bottleneck of connecting the intelligence to the fire.” He adds: “A team consisting of machines and investigators can blast the bottleneck wide open.” Intelligence divide Disclosure of Sariel’s security lapse comes at a difficult time for the intelligence boss. In February, he came under public scrutiny in Israel when the Israeli newspaper Maariv published an account of recriminations within Unit 8200 after the 7 October attacks. Sariel was not named in the article, which referred to Unit 8200’s commander only as “Y”. However, the rare public criticism brought into focus a divide within Israel’s intelligence community over its biggest failure in a generation. Sariel’s critics, the report said, believe Unit 8200’s prioritisation of “addictive and exciting” technology over more old-fashioned intelligence methods had led to the disaster. One veteran official told the newspaper the unit under Sariel had “followed the new intelligence bubble”. For his part, Sariel is quoted as telling colleagues that 7 October will “haunt him” until his last day. “I accept responsibility for what happened in the most profound sense of the word,” he said. “We were defeated. I was defeated.” Guardian Newsroom: Crisis in the Middle East On Tuesday 30 April, 7-8.15pm GMT, join Devika Bhat, Peter Beaumont, Emma Graham-Harrison and Ghaith Abdul-Ahad as they discuss the fast-developing crisis in the Middle East. Book tickets here or at theguardian.live Explore more on these topics Israel Israel-Gaza war Espionage Artificial intelligence (AI) Middle East and north Africa Gaza Palestinian territories news Share Reuse this content",
    "commentLink": "https://news.ycombinator.com/item?id=39942122",
    "commentBody": "Top Israeli spy chief exposes his true identity in online security lapse (theguardian.com)267 points by philk10 20 hours agohidepastfavorite240 comments john-radio 20 hours ago> The embarrassing security lapse is linked to a book he published on Amazon, which left a digital trail to a private Google account created in his name, along with his unique ID and links to the account’s maps and calendar profiles. I'm interested to know more about the nature of the lapse here. Is there a bug in Amazon where self-publishers expose their account email addresses? Or was it more like, he shared Google Map and Google Calendar content in the book, not realizing that those features exposed his real email? reply TrueDuality 19 hours agoparentFrom that line and a few others in the article Amazon doesn't seem to be involved at all. It seems like there was a Gmail account created to receive feedback, corrections, reviews, and media outreach that was also supposed to be relatively anonymous but was registered with his actual name which would be visible to anyone that he responded to at the very least, but may also show up through other account associations. reply dmix 19 hours agorootparentThe article also said he created that email specifically for the book to deal with queries. So it's possible there's more to it. > Contacted by the Guardian, an IDF spokesperson said the email address was not Sariel’s personal one, but “dedicated specifically for issues to do with the book itself”. reply SV_BubbleTime 18 hours agorootparentprevI figured it wasn’t “small nation state bug discovered in supply chain” but rather “yea, he used his real name”. reply TrueDuality 15 hours agorootparentIt's always a small detail that gets you... You only have to fail once for your OPSEC to crumble into nothing. reply Shrezzing 19 hours agoparentprevThe book is published under a pseudonym made up or his rank and initials and the blurb on Amazon reads: >[pseudonym], an expert analyst, technology director, commander of an elite intelligence unit, and winner of the prestigious Israel Defense Prize for his artificial intelligence based anti-terrorism project The defense prize projects & unit conducting the projects are published in The Times of Israel. The person's rank & name is publicly known from other historic news articles. With that context, the google account and Amazon weren't really important to linking the General to the unit in question. reply stef25 19 hours agorootparentWhere did you find that this person even exists ? If the email is yossi.sariel@gmail.com then you still need some kind IDF directory that lists his name, along with his current position. A name alone doesn't mean shit. I think ? reply alephnerd 18 hours agorootparentIsrael is a very small country. It has the population and size of the Bay Area. Everyone is basically a 2nd or 3rd level connection. It has it's pros (eg. VC and Entrepreneurship is much easier because the barrier to entry is lower) but also it's cons (gossip flows very quickly, and it's fairly easy to unmask someone). This is also why the IDF is so ferocious in Gaza - everyone in Israel and the Diaspora either knows someone or is related to someone who died either on 10/7 or during the deployment (eg. I'm from the west coast yet an elementary school classmate of mine died in the Nova massacre, and a couple former coworkers were mobilized to Gaza because they had an infantry MOS back in the day) so there is no appetite for reconciliation. Also, most of 8200 basically leaves and joins the private sector after a couple years, and the younger guys (post-2010) seem to have sloppy opsec compared to the older ones, for example publicly listing that they are ex-8200 on LinkedIn or social media. The IDF, Shabak, Aman, and Mossad have all deteriorated severely since the 2000s, because the best and the brightest in Israel now have private sector options that pay way more and give you way more fame, instead of working as a relatively underpaid bureaucrat in a country just as expensive as the Bay Area. A similar trend is happening in Singapore as well, as almost all my A*STAR friends and classmates broke bond and naturalized in the US instead of returning. Only those whose families owned a house or a car returned (iykyk). reply philistine 15 hours agorootparent> The IDF, Shabak, Aman, and Mossad have all deteriorated severely since the 2000s Absolutely true. Never forget that the vicious attacks by Hamas were never leaked to the Israelis. The supposed spookiest spooks in the whole wide world didn't know about an attack being planned within their own borders. reply alephnerd 15 hours agorootparentActually, it's even worse than that. The lower levels of the Intelligence Services had a vague idea an attack like this would happen [0] but dismissed it as unrealistic, and Egypt even warned Israel 3 days before the attack [1] but most likely it was ignored/procrastinated due to the Judical Protests and Yom Kippur holiday season. There was a systemic failure that is very unsurprising due to the relative lack of long term institutional knowledge as Intelligence Community and Policy members left to work for American MNCs like Microsoft or Google, or start their own massive cybersecurity companies like Palo Alto Networks, SentinelOne, Wiz, etc. Before the economic reforms in the 1990s-2000s, the only options for the best and brightest in Israel was to become a careerist in the Israeli Government or emigrate to the US to found companies like PANW. This meant a large subset of Israel's top talent remained in the government, but all that fell apart due to economic liberalization because people had better choices that paid more and had better work hours. It's the exact same story in Singapore and South Korea today, and a similar brain drain happened in the former Soviet Union and India in the 1990s. > The supposed spookiest spooks in the whole wide world didn't know about an attack being planned within their own borders Imo, the reason Israel's intelligence community was a top player in the 1970s-90s was because most Israelis were 1st-1.5 generation refugees from Arab countries. Mizrahi Jews (especially Yemeni) are fairly overrepresented in careerist Military and Police roles in Israel due to a relative lack of career options, and a number of that generation was L1 Arabic or Farsi speaking. By the 2000s-2010s, the younger generation was 2nd or 3rd generation and truly \"Israeli\" so a lot of the cultural nuances in the Arab World fell by the wayside. [0] - https://www.nytimes.com/2023/11/30/world/middleeast/israel-h... [1] - https://www.bbc.com/news/world-middle-east-67082047 reply hilux 14 hours agorootparentprevI used to work for a Bay Area startup whose claim to fame was that it was all 8200 alumni productizing 8200-derived technology. reply alephnerd 13 hours agorootparentYep! It was Shlomo Kramer (Checkpoint, Imperva, Cato Networks) and Nir Zuk (Palo Alto Networks) that started the 8200-to-entrepreneurship pipeline in the 1990s-2000s. Shlomo was basically the primary reason Israel does so well in cybersecurity entrepreneurship. There was some overlap with the IIT alumni network as well due to Rajiv Batra (cofounder with Nir at PANW) that caused the entire Enterprise SaaS space to be lead by Israeli-American and Indian-American founders. reply tyingq 16 hours agorootparentprevMight not be him, but there's a facebook profile with that name that happens to like an Israeli-built \"publish book to Amazon tool\", the Israeli Ministry of Defense, Palo Alto Networks, etc. reply ArunRaja 19 hours agoparentprev> Email Id with unique id leaked What's the unique id here ? SSN number / military id,...? reply NomDePlum 16 hours agorootparentHis name reply nolongerthere 20 hours agoparentprevnext [3 more] [flagged] ziddoap 20 hours agorootparent>but likely it’s a disgruntled Amazon employee who has a bone to pick with Jews What a wild assumption. How on earth do you figure this is the \"likely\" situation? reply redserk 20 hours agorootparentprevThis isn't \"likely\", this is a guess rooted in outlandish political discourse. reply weinzierl 19 hours agoprevI see no lapse here. Some people publish under a pseudonym to disguise their true identity, others to separate their public persona from their private one. This is pretty clearly the later case. He published the book under his initials in combination with a hint to his job. That he did not take a serious effort to hide his email is just consequential. This is as exciting as had they reported they'd found out the real name of JJ Lehto. EDIT: Thinking about it, it is simultaneously a nom de guerre and a nom de plume. reply yakito 19 hours agoparentfinally, I was waiting for this comment. reply lukev 20 hours agoprevOpsec is hard. Also. No matter how bullish you are on the potential of AI, it's horrifying and categorically unethical to use them to decide who to kill. It creates the possibility of atrocity with no accountability. Although the fact that this guy was anonymous to start with definitely indicates that accountability isn't the goal here. reply roughly 20 hours agoparentThe Guardian reported more on the IDF’s use of AI a couple days back, and it’s grim: https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai... Although in that article, most of the horrors are coming from the human operators - there’s what comes off as a pretty strong disinterest in finding reasons to distrust the machine. reply ethbr1 19 hours agorootparentThe original(?) +972 article was also on HN: https://news.ycombinator.com/item?id=39918245 It was an excellent and detailed piece on the various systems, and their use by Israel in the Gaza conflict. >> In an unprecedented move, according to two of the sources, the army also decided during the first weeks of the war that, for every junior Hamas operative that Lavender marked, it was permissible to kill up to 15 or 20 civilians; in the past, the military did not authorize any “collateral damage” during assassinations of low-ranking militants. Needs no comment and basically sums up the war. reply 082349872349872 19 hours agorootparentI believe the laws of war as commonly understood authorise civilian casualties insofar as they are \"proportionate\". 1:20 is technically a proportion, but... reply bjornsing 19 hours agorootparent1:2000000 is also a proportion. Btw, the proportionality requirement in the law of armed conflict relates civilian casualties not with military casualties but rather the military advantage gained. The military advantages of killing a single low-level Hamas combatant are rather limited, and thus the room for civilian casualties should be rather limited as well. reply ivl 19 hours agorootparentprevProportionate in war is not about going tit-for-tat. > The principle of proportionality prohibits attacks against military objectives which are “expected to cause incidental loss of civilian life, injury to civilians, damage to civilian objects, or a combination thereof, which would be excessive in relation to the concrete and direct military advantage anticipated”. The way it's worded is to prevent destroying civilian targets for no military gain. reply porkbeer 17 hours agorootparentThats a very... charitable reading. reply shermantanktop 19 hours agorootparentprev> the laws of war as commonly understood There’s a whole lot of wiggle room in that phrase. reply NomDePlum 16 hours agorootparentprev20:1 is a proportionality I'd find horrifying. 1:20 is unspeakable. There is no justification in the current situation in Gaza to justify anything close to the numbers quoted. reply weakfish 19 hours agorootparentprevMore of a slaughter than a war at this point. reply NomDePlum 16 hours agorootparent\"at this point\" being the last 6 months, I'd assume? reply weakfish 14 hours agorootparentYes. reply klyrs 17 hours agorootparentprevThere's one quote in that article that continues to make my blood boil: > \"You don’t want to waste expensive bombs on unimportant people\" This, regarding the bombing houses full of civilians, because an infantryman might have been inside. This, in a statement by somebody who is critical of the AI effort. By being more concerned at the loss of munitions; the true basis of the calculation is revealed. The IDF -- even those members who are actively critical of it -- views its enemies not as humans, but as vermin to be exterminated. This is genocide, pure and simple. reply alchemist1e9 19 hours agorootparentprevThe names of the systems are “The Gospel” and “Lavender”! How is it that a Jewish army is using Christian references for their AI killing systems? I don’t think that is unintentional. reply colinprince 19 hours agorootparent\"The Gospel\" has wider connotations https://en.wikipedia.org/wiki/The_gospel probably from the Greek https://en.wiktionary.org/wiki/εὐαγγέλιον reply alchemist1e9 18 hours agorootparentThat’s a stretch considering any Jewish person I’ve ever known would immediately associate “The Gospel” with Christianity and what officially their religion considers as a blasphemy and heresy. There is absolutely no possible way that whomever named the system wasn’t consciously linking it and invoking the religious connotation. reply zed1726 14 hours agorootparentCorrect. The Jewish people think of the Gospel as \"that which the masses blindly accept as true but we know internally to be false\" which is apt given what they have intended to use it for. reply alchemist1e9 11 hours agorootparentWhich perhaps they even expounded on by using “Lavender” which potentially is something Christians may have mis-associated with Jesus’s birth (see parallel comments on Lavender). The message to Christian’s is clear - “thanks for all the funding, you’re a bunch of fools, and we are killing our enemies in your name” reply permo-w 19 hours agorootparentprevis \"Lavender\" a Christian reference? reply readyplayernull 18 hours agorootparentLavender's history has biblical roots. It is referred to as Spikenard in the Bible. Mary used it on the infant Jesus and anointed Jesus after the crucifixion when she was preparing him for burial. So it has a \"life and death\" connotation which makes a lot of sense when you think of the system as a roulette for those chosen to die. reply YeGoblynQueenne 15 hours agorootparentSources? What Christ was offered in his birth was myrrh (by one of the Magi) and his body was wrapped in myrrh after his death (https://en.wikipedia.org/wiki/Myrrh#In_the_New_Testament). Myrrh and Lavender seem to be very different. Is there some popular association of the two (like yams with sweet potatoes)? reply alchemist1e9 11 hours agorootparentA quick google search for “lavender christianity” shows many many people have associated them together, possibly with some historical or primary source inconsistencies, however it’s very obvious connected. In addition to search engines a conversation with any LLM has them immediately explain the connection. Now you might be correct there is some mis-associating from a purely academic standpoint and that actually makes it even more interesting the IDF used it as a name, considering the other name is “The Gospel”. Isn’t the message to Christians - “you’re idiots and we kill our enemies using AI systems named to make fun of you”? reply YeGoblynQueenne 10 hours agorootparentI was raised Greek Orthodox and that's not a message I receive at all. I commented as above because for me there is no association between Christianity and lavender. Asking others who were also raised Greek Orthodox, lavender has no special meaning for any of us at all. To clarify, that's not from an academic standpoint, but from the point of view of tradition. Perhaps it's a Catholic or Protestant thing, but, if so, I don't know where it comes from. I used to love reading the New Testament and I really don't remember any mention of lavender at all. It could be an Old Testament thing though, so, to be fair, more Jewish than Christian. In Greek Orthodox practice the aromatic of choice is frankincense (every church smells of it because the priests burn it in long-chained incense burners that they swing wildly left and right during liturgy), and, separately, myrrh (although that's associated with death and funerals, I guess). Lavender we mainly use to keep moths off clothes, to be honest. I got small muslin-wrapped packets of it in my closet. I also am not sure why Israelis would want to send a message to Christians about an AI system used to kill mainly Muslims. I mean, in practice, the Israelis enemies are Arabs who tend to be Muslim, so why would they send a message to Christians? In any case, can you please share some of the information you found in your quick googling? I'm curious to see what people say. I had a quick look online also and couldn't really find anything specific. The wikipedia page on lavender also lists no specific relation with Christianity, as opposed e.g. for myrrh and frankincense. reply alchemist1e9 8 hours agorootparentThere is definitely a large groups of Catholics and Protestants who are associating Lavender with Virgin Mary, Jesus’s birth, and others who believe it goes back to the garden of Eden and Adam and Eve. One hypothesis is a confusing Spikenard, here is what GPT4 says about that: > Yes, there can be some confusion between spikenard and lavender, partly due to historical naming conventions and translations of ancient texts. The confusion often stems from the use of the term \"nard\" or \"spikenard\" in historical texts, including the Bible, and how it has been interpreted or translated over the centuries. > Spikenard (Nardostachys jatamansi) and lavender (Lavandula angustifolia) are indeed different plants, both botanically and in terms of their historical and cultural significance. However, the confusion might arise because both were used in ancient times for their aromatic properties and were considered valuable for perfumes, medicinal purposes, and religious rituals.The term \"nard\" comes from the Sanskrit word \"narada,\" while \"spikenard\" refers specifically to Nardostachys jatamansi. The translation and interpretation of ancient texts, like the Bible, have sometimes led to a blending of these plant identities, especially when the specific botanical knowledge of the original texts was not fully understood or when names were translated in ways that did not precisely match the botanical realities.Additionally, the historical trade of these substances, along with others, through ancient markets might have contributed to the blending of their identities. Merchants and consumers across different cultures might not have always distinguished clearly between the two, especially given the value placed on aromatic herbs and oils in ancient times for both practical and symbolic uses.Despite these confusions, modern botanical and historical scholarship distinguishes clearly between spikenard and lavender, recognizing their unique characteristics and the distinct roles they have played in history and tradition. As far as the message from IDF, my understanding is the true believers of Orthodox Judaism are actually both anti-muslim and anti-christian. The hidden message I take is “you Christians are fools, easily tricked, we have tricked you also, we laugh at you behind your back, and desecrate your beliefs as our weapons of war”. reply YeGoblynQueenne 8 hours agorootparentDo you have a source that corroborates GPT4? It is well-known that it can happily generate unsubstantiated information. >> As far as the message from IDF, my understanding is the true believers of Orthodox Judaism are actually both anti-muslim and anti-christian. The hidden message I take is “you Christians are fools, easily tricked, we have tricked you also, we laugh at you behind your back, and desecrate your beliefs as our weapons of war”. Isn't that just a little bit too much to infer from a single word? If they wanted to send a message to Christians, why not choose something obvious like \"Cross\" or \"Golgotha\" or \"Herod\"? reply alchemist1e9 7 hours agorootparent“The Gospel” is pretty damn obvious. I don’t think it’s too much to infer, for me it’s extremely obvious, especially considering the religious history. People don’t realize that Orthodox Jews literally spit at Christian worshipers in Israel. We have to admit what is going on here. The IDF built multiple AI killing machines with US and Western money (Christian money) and then named them intentionally offensively and with direct hostility to Christianity. There is absolutely no possibility that the people who selected the name “The Gospel” and “Lavender” were not doing so in a religious context. From a religious standpoint Islam and Christianity are incredibly close. Orthodox Jews only view Christians as useful idiots in their agenda not as religious allies, quite the opposite. Regarding Lavender - copilot with references below. However I think you are likely correct that the accuracy of the connection is potentially flawed, however it’s the beliefs that matter, and a large number of Christians believe there is a direct connection. Lavender has *profound connections* to divine symbolism within *Christianity*. Here are some references for you to review: 1. *Biblical Meaning of Lavender*: - Lavender's spiritual essence is depicted in various contexts within biblical scripture. - It is considered a powerful tool for *spiritual purification* in Christianity. - The scent of lavender uplifts the spirit, fosters inner peace, and aids in establishing a connection with the Divine¹. 2. *Folklore and Symbolism*: - When a woman washed Jesus' feet, the lotion she applied contained lavender. - Mary, Jesus' mother, hung his swaddling clothes on a lavender bush, transferring his scent to the plant. - As a result, lavender came to represent *cleanliness* and *purity* in Christian symbolism³. 3. *Spiritual Benefits*: - Lavender is associated with calmness, purification, and tranquility. - It is closely linked with the *crown chakra*, which connects to spiritual realms. - Smelling lavender during meditation and yoga can purify and cleanse the air, aiding in spiritual practices⁵. Feel free to explore these references further to deepen your understanding of the connection between lavender and Christianity! Source: Conversation with Bing, 4/5/2024 (1) Biblical Meaning of Lavender - Divine Symbolism. https://biblewithus.com/biblical-meaning-of-lavender/. (2) Lavender Folklore: The Tales Behind This Calming Purple Plant. https://www.icysedgwick.com/lavender-folklore/. (3) The Spiritual Benefits and Meaning of Lavender - Original Botanica. https://originalbotanica.com/blog/spiritual-benefits-lavende.... (4) The Spiritual Meaning of Lavender - TheReadingTub. https://thereadingtub.com/lavender-meaning-spiritual/. (5) History’s Love of Lavender: From Mummies to Bathhouses and Beyond!. https://www.ancient-origins.net/history-ancient-traditions/l.... Christianity: • Jesus ascended into Heaven • Jesus is the Son of God, the Messiah, & the final prophet • Jesus’ soul & body are in heaven • Jesus will return to destroy Satan and establish peace on earth • Jesus came from a virgin birth • Jesus performed miracles Islam: • Jesus ascended into Heaven • Jesus is the word of God, and his messenger and a deliverer of the scripture • Jesus’ soul & body are in heaven • Jesus will return with Imam Mahdi to destroy a False Messiah and establish peace on earth • Jesus came from a virgin birth • Jesus performed miracles Judaism: • Jesus did not ascend • Jesus was the most damaging false Messiah • Jesus is in boiling excrement in Hell. • Jesus will not return • Jesus had a normal birth • His miracles were of the devil reply alchemist1e9 18 hours agorootparentprevExactly. There is no way that whomever named these systems didn’t do it intentionally. The question is why? what was the motivation? reply readyplayernull 18 hours agorootparentIt's a form of ideological hand-washing, they don't want to link the killing to their own religion but it's ok to link the other well known religion. Coincidentally hand washing refers to the story in St. Matthew’s gospel, when Pontius Pilate ‘washed his hands before the multitude, saying, I am innocent of the blood of this just person’. reply 082349872349872 20 hours agorootparentprevThere must be a line somewhere between \"pretty strong disinterest in finding reasons to distrust the machine\" and \"using the machine as plausible deniability for doing what you hoped to do anyway\"; is there a relatively simple description of this line, or is it a fractal boundary? reply roughly 19 hours agorootparentYeah, I phrased that as generously as possible because I didn’t really want to kick that particular hornets’ nest, but the article does a fine job making that point. reply 082349872349872 19 hours agorootparentVery charitable of you! (do we need an emoticon for charity, like we have for sarcasm? symmetry would suggest yes.) Upon further reflection, it occurs to me that these situations are exactly why the Geneva Conventions[0] require combatants to have (a) uniforms, and (b) a command structure: (a) prevents someone low from disingenuously stopping the buck by claiming \"tweren't no orders; I'm acting on my own\" (b) prevents someone high from arguing as Uber does: \"you see, we're not a traditional army that gives orders to our fighters — we just provide a service that matches attackers and targets online, and really, anything bad that allegedly happened was only between those two parties\"[1] [0] if we're not doing these anymore, just go ahead and tell me \"the future is now, old man\", and I'll take my mutterings to the pétanque piste. [1] > \"Once the rockets are up, who cares where they come down? That's not my department,\" says Wernher von Braun —TAL reply shermantanktop 19 hours agorootparentTinder for combat: swipe to kill. reply jakeinspace 20 hours agorootparentprevMorality-washing was always going to be one of the first uses of AI, in hiring and in policing and in war (or ethnic cleansing). reply Qem 19 hours agorootparent> Morality-washing was always going to be one of the first uses of AI They even made a cruel joke by naming the automated killing system \"Lavender\". Lavender flowers were used in clothes washing since ancient times. The name of the flower cames from the Latin word for washing. Portuguese inherited it, for example, with the word for lavender, \"lavanda\", sounding similar to the verb to wash, \"lavar\". reply klabb3 19 hours agorootparentprev”Machines never make the decision, they’re merely collecting data to assist human operatives” They’ll keep saying this forever, and there’s a shroud of plausible deniability to it! Not to mention it can soothe the conscience of the operatives who have to live with their decisions - they don’t even have to look through the family photos - the AI has already filtered out the suspicious parts. In reality, it’s a good ole recommendation engine, just like Netflix or TikTok. And when you’re tired, have too much work stacked up, you’ll be more likely to let autoplay take over – or approve the strike of someone’s home. To those that think this is harsh: please read the article. It’s that bad. reply NomDePlum 16 hours agorootparentThe Guardian article on this had quotes from the \"operators\" involved. They don't question or examine any of the output just hit approve. The only apparent operator act that seems to be something they are involved in is turning the dial up or down to get more or less \"hits\". Depressingly this appears to be related to superiors shouting at them as they don't have enough targets. It's absolutely sickening. reply wahnfrieden 17 hours agorootparentprevIt's not a matter of being tired and having to catch up. The operators are explicitly instructed to treat the AI results as orders without questioning the results. In other words, operators are threatened with punishment if they take the time to inspect the results more closely before following orders. It's not even an option! > In order to speed up target elimination, *soldiers have been ordered to treat Lavender-generated targets as an order, rather than something to be independently checked*, the investigation found. Soldiers in charge of manually checking targets spent only seconds on each person, sources said, merely to make sure the target was a man. Children are also considered legitimate targets by Lavender. reply klabb3 2 hours agorootparentRight! The extreme point of laziness/stress is just pressing approve. At which point the machine is making the de-facto decision. In either case, the role of the recommendation engine is immensely impactful, as we already know from consumer products. But here the software engineers are directly involved in life-and-death decisions at scale. I really hope they know that. reply hammock 19 hours agorootparentprevFully autonomous drones, from other countries, have been killing people since at least 2020. It's not just the IDF using AI. This was the earliest official report sourced by the UN, pegging Turkey: https://www.fox5ny.com/news/fully-autonomous-drone-was-used-... reply readthenotes1 19 hours agorootparentThe US has killed plenty of non comabatants using human guided drones for decades... reply hammock 19 hours agorootparentIn question are fully autonomous, artificial intelligence-based, unmanned drones reply 082349872349872 19 hours agorootparentCan't make them too artificially intelligent or they might draw conclusions: https://news.ycombinator.com/item?id=38362711 reply tialaramex 18 hours agorootparentThe link is, indirectly to Peter Watts' story \"Malak\", which, yeah, is exactly what I think of whenever people talk about this. reply michelsedgh 19 hours agorootparentprevUsing one of the most biased and anti-israel as a source what could go wrong? Edit: A different and less biased title would be: the use of technology and AI to minimize civilian casualties in guerrilla warfare. No? How much civilians did US kill during Vietnam war? There was no AI then and the Vietnamese didnt murder and rape civilian Americans did they?Edit 2: downvote me until it gets removed and you enjoy your echo chamber of beliefs. reply roughly 19 hours agorootparent> the use of technology and AI to minimize civilian casualties in guerrilla warfare The article makes it quite clear this is not what’s happening and not why the systems are in use. They’re being used to generate a target list faster than could be done by traditional methods, and are being used despite agreeing with traditional methods only 90% of the time. They’re being used to accelerate the war, not make it more accurate. reply marcus0x62 16 hours agorootparentprev> Edit: A different and less biased title would be: the use of technology and AI to minimize civilian casualties in guerrilla warfare. In what universe is that a less biased title? It is just biased in a different direction. reply gambiting 19 hours agorootparentprev>>Using one of the most biased and anti-israel as a source what could go wrong? Which one exactly? The guardian article quotes literally hundreds of sources - which ones are you bothered by? >>the use of technology and AI to minimize civilian casualties in guerrilla warfare. It achieves literally no such thing, it's dishonest to suggest otherwise. >>How much civilians did US kill during Vietnam war? Peak whataboutism. As if everyone on the internet is American or believes that we should be comparing everyone else to America. reply ClumsyPilot 19 hours agorootparentprev> use of technology and AI to minimize civilian casualties In the year 2022 Russia invaded ukraine, flattened two (?) cities, showed no concern for civilian life, committed war crimes. And yet Israel has killed more children in 6 months than Russia did in 3 years. Russia killed 4 western aid workers in 2022, Israel already more than that in 1 week, we are suppose to believe these are accidents? reply mlyle 19 hours agoparentprev> it's horrifying and categorically unethical to use them to decide who to kill. Absolute statements are hard. I mean, I agree with the sentiment, but I can't get behind such a strong statement. If you have a 10 person group deciding who to kill, and reduce their workload with AI so that the 10 person group can take more time double checking-- that's \"using AI to decide who to kill\" but probably improves outcomes. The problem is, in practice, we know that people are just going to punt responsibility to the machine and shrug. reply ethbr1 19 hours agorootparentThe fundamental reality is that compressing decision timelines creates more effective military outcomes. Everything else flows from that. At a high-level, that decision compression will be an arms race between competitors for military advantage, where the argument to relax human-scale decisions will be \"If we don't do it, we'll lose to someone who will.\" You saw the same thing in the nuclear arms race, as launch-to-impact time compression (as technology advanced) eroded available human decision time. reply mlyle 18 hours agorootparent> The fundamental reality is that compressing decision timelines creates more effective military outcomes. But popping off half-cocked often results in bad outcomes, so there's a tradeoff between decision quality and decision time. In theory, having AI in the loop could improve both. In practice, I suspect you're right. reply ethbr1 18 hours agorootparentUnfortunately, the negative impact of killing civilians currently seems to be... minimal. And maybe always has been, internationally-speaking? It would be nice to reform UN and supra-national rules of warfare in light of modern developments. Even a \"this is an acceptable ratio of civilian collateral deaths, above which constitutes a war crime\" would be helpful for curtailing nation's baser urges. reply mlyle 12 hours agorootparent> And maybe always has been, internationally-speaking? If I had to guess, it was even less. Now at least there can be media backlash. > Even a \"this is an acceptable ratio of civilian collateral deaths, above which constitutes a war crime\" would be helpful for curtailing nation's baser urges. Having some kind of metric would be nice. However, there are problems with it being too simple (your enemy has a say in how exposed their civilians are; and we'd hate to leave countries with less precision in their militaries without the ability to defend themselves). reply throw7 18 hours agorootparentprevWe will find the \"evidence\" to extract our pound of flesh. It was Curveball then, it happens to be \"AI\" now. reply passion__desire 15 hours agorootparentprevUS decided not to bomb Kyoto in WW2 because Henry Kissinger had visited it and was enthralled by its beauty. Somehow such decisions are ok because made by a human? reply passion__desire 13 hours agorootparenthttps://www.bbc.com/news/world-asia-33755182 Some historians say US Secretary for War Henry Stimson had a personal reason for sparing Kyoto. (edit : wrong Henry) reply ClumsyPilot 18 hours agorootparentprev> reduce their workload If killing the right person is too much work then you shouldn’t be killing reply ziddoap 20 hours agoparentprev>It creates the possibility of atrocity with no accountability. As gross and unfortunate as it is, this is a selling feature to some governments. reply westmeal 20 hours agorootparentHey at least Palantir says their death machine is ethical because it shows you a flowchart of a bunch of widgets. Do other weapons have widgets?!? I didn't think so! reply rany_ 19 hours agorootparentprevDo you think this holds up in court? It gives me Nuremberg defense vibes (\"I was just following orders\"), except humans are following an AI's orders. reply Sharlin 19 hours agorootparentThat's why you work to remove humans from the loop altogether. reply sofixa 17 hours agorootparentThat probably isn't enough - representatives from IG Farben, Krupp and Flick were all tried at Nuremberg for war crimes because their companies helped war crimes and crimes against peace; therefore the people behind the AI targeting civilians are in theory liable for it murdering civilians. reply rany_ 19 hours agorootparentprevThat's terrifying, I hate where this is all headed. I still hope that the people that ordered it setup and those that had it developed would be held accountable (I know, pipe dream). reply postmodest 19 hours agorootparentprevMan, Fuck Ted Faro. reply salawat 19 hours agorootparentprev...I'm having trouble discerning whether you understand the abject stupidity of that suggestion, or if you're just being sarcastic. Poe's law strikes again. reply rany_ 19 hours agorootparentTo be honest, I could see this happening. What's going on right now is absurd enough as it is. I pity The Onion. reply Sharlin 19 hours agorootparentprevMore sardonic or grimly ironic than sarcastic, but yes. reply RcouF1uZ4gsC 19 hours agorootparentprev> It gives me Nuremberg defense You only need a Nuremberg Defense if you lose, and your country is taken over. If you are an American soldier, only the US will be able to hold you accountable. Israel has nukes and the backing of America. I think it is unlikely that they would ever lose so badly as their soldiers face a Nuremberg like trial. reply rany_ 19 hours agorootparentRules for thee but not for me (or any of my best \"friends\"). reply kayodelycaon 19 hours agorootparentprevIf they lose that badly, I can't imagine anyone around them would bother with trials. reply Kalium 19 hours agoparentprev> Also. No matter how bullish you are on the potential of AI, it's horrifying and categorically unethical to use them to decide who to kill. It creates the possibility of atrocity with no accountability. How much technology is it ethical to use in the decision-making loop for kinetic decisions? I don't think there's an easy answer here that actually engages meaningfully with the question. reply thinkingtoilet 19 hours agoparentprev>It creates the possibility of atrocity with no accountability. It most certainly does not. And comments and thinking like this enable that. There is a human who is responsible for deciding to use the AI, that human is responsible. If they can't handle the responsibility, then don't use AI. reply kspacewalk2 19 hours agoparentprevHe didn't advocate for fully anonymous AI systems, but ones where humans will ultimately make the decision. Obviously these can be implemented in a variety of ways, from basically data mining software and some neat dashboards to help a bunch of humans decide on a target in a responsible way, to something where all the boring bits are hidden, a list of names is oh-so-helpfully drawn up and a rubber-stamp from an under-trained early-20s \"intelligence officer\" is all that's needed to kill someone, and their family, in their home. reply namaria 18 hours agoparentprevThat's basically what AI as a concept is. Smoke as screens to hide responsibility and costs. reply mapt 17 hours agoparentprev> Also. No matter how bullish you are on the potential of AI, it's horrifying and categorically unethical to use them to decide who to kill. It creates the possibility of atrocity with no accountability. No it doesn't. That was always a possibility. Atrocity with no accountability long predates AI, and the ethics of \"using them to decide who to kill\" are isomorphic with the ethics of using a dice roll to decide who to kill. In this case, the people you could choose to hold accountable is everybody who planned, built, or activated the machine made of a Wacky Waving Inflatable Tube Man mounting a chaingun, designed to spray bullets indiscriminately in all directions. The fact that no human trigger finger is actually on the trigger does not AT ALL defuse ethical considerations, does not exculpate anybody. We kill with machines in every military, but it's human decisions all the way down no matter how long ago a human last physically touched the munition. The lack of accountability starts to occur when a journalist embraces headlines like \"AI Made Decisions About Who To Target\", rather than using scarequotes and agency - \"IDF-run AI system 'Made Decisions' about who to target\". The IDF are the actors in this construction, the AI system is just a tool. The lack of accountability continues in the political sphere where no war crime investigation takes place, no red line is instituted, no Geopolitical Consequences arise. It finalizes in the polity when no liberal / humanist vigilante takes revenge into their own hands, no 4chah/kiwifarms investigation doxes their family, no airline pilot diverts to the Hague, we just sort of embrace treating atrocity-committers humanely because we're lazy cowards. reply ghostway 18 hours agoparentprev> Although the fact that this guy was anonymous to start with definitely indicates that accountability isn't the goal here. Well, it isn't. This is a strategic choice, and one pretty much every military took reply Zambyte 19 hours agoparentprev> It creates the possibility of atrocity with no accountability. No it doesn't. If you use any tool to kill people (ie a gun, bomb, computer) the person (or people) who used the tool are accountable. reply raincole 19 hours agorootparentPeople who use the best tool (i.e. other people) to kill are rarely held accountable. reply cmrdporcupine 19 hours agorootparentprevWhat it does is create more levels of indirection and detachment. reply Cthulhu_ 19 hours agorootparentIndeed, they gave each hit 20 seconds - if that - to manually verify. That said, airstrikes, drones etc already add a layer of indirection and detachment. The thing that this \"AI\" tool allowed was to mark targets faster, or if you will, with less scrutiny, increasing the efficiency and speed of the killing machine. reply cmrdporcupine 19 hours agorootparentWe've been creating indirection ever since the first homo ancestor carved/fashioned a spear tip or arrow, or the first metallurgist poured a bronze sword. But. There's matters of degrees. And this is just one or two steps away from full autonomous murder. Reminds me of this section Frank Herbert's God Emperor of Dune: ... She would carry with her forever afterward the clear sights and sounds and smells. The seeking machines would be there, the smell of blood and entrails, the cowering humans in their burrows, aware only that they could not escape . . . while all the time the mechanical movement approached, nearer and nearer and nearer ...louder...louder! ...like the terrible machines of that apocalyptic vision, the predator could follow any creature who left tracks.* reply shermantanktop 19 hours agorootparentprevIndirectly, the voters who put a warmongering leader into office are accountable…but when a war goes wrong, they never blame themselves. Cynically, it’s not who is actually responsible and by how much, it’s who is forced to take the blame. reply cmrdporcupine 18 hours agorootparentwhen a war goes wrong, they never blame themselves Arguably the German nation/culture has done this. At least in large part. Not sure any cultural repentance would ever be enough though. I also feel like there is in Canada at least a growing understanding of the horrors of colonization and attempted genocide and assimilation against First Nations here. Whether that ultimately leads to reconciliation and a better path forward is hard to say. reply whyage 19 hours agoparentprevMilitary technology has been helping people decide who to kill for ages. For example, long distance cameras and night vision devices use extensive image processing. They're designed to improve visibility but can undoubtedly lead to false positives in the heat of the battle. reply nimbius 19 hours agoparentprevits true. Whenever you're in a sensitive position and must practice opsec hygene, you need to be consistent and get it right every time. Your adversary only needs to get lucky once. reply tomp 19 hours agoparentprevAI is a tool. It can be used to kill more people, and it can be used to kill less people. Imagine if the superweapon US developed during WWII was AI. They'd use it to deliver devastating destruction to military factories in Nagasaki and Hiroshima, saving 100k+ civilian lives. reply michelsedgh 19 hours agoparentprevnext [20 more] [flagged] dotnet00 19 hours agorootparentThe situation of Japan was obviously completely different, considering that it was an openly declared war against a nation that was actually capable of conquering its surrounding territory. Plus, the US had no interest in making Japan a part of its own territory. The nukes prevented a land invasion, which would've cost both sides millions of lives. We have precedent from Afghanistan, Iraq and Syria, that the US would occupy the area and spend vast amounts of resources trying and failing to do precision strikes to take out the leadership, and then eventually give up and go back home. If you've seen any of the images coming out of Gaza, you'd know that there isn't that much of a distinction between Israel using this AI and just bombing the shit out of everyone, which is why it's being suspected of being morality washing. They can just continue to bomb the shit out of everyone and claim to have blindly listened to the computer when questioned. reply ethbr1 19 hours agorootparentIt's still a human strategic decision though: they could have created or configured the system to minimize collateral casualties. They apparently didn't. reply michelsedgh 19 hours agorootparentprevYou are wrong because one bad bomb that killed the 7 kitchen workers made world headlines. If they bombed the shit out of everyone, then there wouldn’t even be any kitchen workers going in. The fact that this war is going on for months and this one is the first that killed people who it shouldnt have would tell you otherwise. Also a big difference is in the other wars you mentioned, the fighters wouldn’t disguise themselves as civilians, use hospitals and civilians as shields did they? reply stahtops 19 hours agorootparentI am not sure how anyone could possibly be expected to take this comment seriously. “This one is the first that killed people who it shouldn’t”. It had to be.. week 1? that they bombed a children’s hospital. They even shot a few of their own who were escaping captivity. reply dotnet00 19 hours agorootparentprevI've been seeing headlines and even some footage near constantly since this latest escalation of Israel killing civilians. There are thousands of images of dense housing complexes, hospitals etc being bombed. Anyone with basic common sense can tell that they've killed plenty of civilians in those, even if we accept their claims that they were targeting terrorists (which this system gives plausible deniability for, they can just label any target it designates as a terrorist, regardless of reality). reply signaturefish 19 hours agorootparentprevThree \"bad\" missiles over a five minute period. The hit on the WCK convoy killed the latest 7 out of over 200 aid workers who have been killed in Gaza since this latest war began. reply ethbr1 19 hours agorootparentprev> this one is the first that killed people who it shouldnt have would tell you otherwise I honestly can't tell if you're being ironic or not. Do you believe these were the first aid workers who were killed? reply frob 19 hours agorootparentprevYes, we Americans committed many atrocities in our many wars and we will absolutely do so in the future. Please learn from us instead of following our path. reply michelsedgh 19 hours agorootparentThey are not doing the same as America are they? They are not perfect but it just depends who you trust as a source in this war. All the stats either come from Hamas or IDF. People choose to believe the Hamas statistics all day and take a blind eye to what IDF is doing. Also big contrast is they are defending themselves. Im not talking only about Oct 7. Even before that Hamas sent bombs for many years before that. Imagine going to work and seeing bombs above ur head and all the world saying it is what it is you can’t attack them back or do anything about it. reply gambiting 19 hours agorootparent>>Also big contrast is they are defending themselves. Yes, I'm sure Israel shooting all of those kids in Gaza is just self defense - after all, they can't grow up to become terrorists if they are dead already. https://www.theguardian.com/commentisfree/2024/mar/23/israel... https://www.theguardian.com/world/2024/apr/02/gaza-palestini... Like, I know this is an extreme example, but this isn't anywhere near as black and white as you present. Israel has done a lot of shit to Gaza over many many many decades, and while it doesn't justify terrorist acts towards Israel, many people could argue that Palestinians are also defending themselves in many ways. reply michelsedgh 19 hours agorootparentYour source is Tehran Times. Have you considered that Iran is the one financing this war and wanting this war and you are quoting it as a reputable source? Also I don’t wanna see any child harmed in any way, and you have to consider the Hamas terrorists are using them as meat shields. The way I see it, the longer the terrorists have power, the more children they are going to harm, Palestinian and Israeli children alike. reply gambiting 19 hours agorootparentSorry, I grabbed the first link for it from google, because I read this story before and I didn't have the original article, here's where I read it first: https://www.theguardian.com/world/2024/apr/02/gaza-palestini... I'll replace the tehran times link now. reply frob 19 hours agorootparentprevWar crimes do not justify war crimes. reply adhamsalama 19 hours agorootparentprevHamas literally asked for investigation by independent international organizations. Israel refused. Tells all what needs to be said about that illegal terrorist rogue state that it Israel. reply ziddoap 19 hours agorootparentprev\"But what about...\" Your comment is basically unrelated to the parent comment. Parent said nothing about any specific country, just that it is unethical to use AI to decide who to kill. USA bad. Yes, yes. reply michelsedgh 19 hours agorootparentMy argument is AI not bad, AI help minimize civilian casualties even in such difficult grounds. reply albumen 19 hours agorootparentAI has provided the IDF with a huge list of potential enemy combatants. Then the IDF applies their own thinking re acceptability of related civilian casualties, far higher than \"the norm\" (ugh). Together, mass slaughter made easy. So no, I don't believe that AI is \"minimising civilian casualties\". reply ziddoap 19 hours agorootparentprev>My argument is AI not bad, AI help minimize civilian casualties even in such difficult grounds. That could be an interesting discussion! However, your argument actually appears to be \"USA did shitty things\". And you are presenting it in a way that looks almost designed to incite a flame-war, between this comment and your other one. reply adhamsalama 19 hours agorootparentprevBut they did bomb the shit out of everyone and everything. Over 32000 humans were killed, most of them were women and children. And they're starving the rest of the population, stopping aid from entering, and have killing aid workers. But you consider this good, so it makes me wonder how people like you sleep at night after supporting the death and starvation of an entire population. reply alephknoll 19 hours agoparentprev> No matter how bullish you are on the potential of AI, it's horrifying and categorically unethical to use them to decide who to kill. Is it any more horrifying or unethical to decide without AI? > It creates the possibility of atrocity with no accountability. Who was held accountable for hiroshima? Or do you know how much atrocities were committed to create israel? You act like we had accountability before AI. We've never had accountability for atrocities. Just victor's 'justice'. AI can be better than humans when it comes to atrocities. It can be as bad as humans, But it can never be worse. Humans set the standard. reply uluyol 18 hours agorootparent> Is it any more horrifying or unethical to decide without AI? It is harder to get 1000 people to participate in an unethical military campaign than it is to get 10 people. So if you can make those 10 people 100x as efficient... reply alephknoll 18 hours agorootparent> It is harder to get 1000 people to participate in an unethical military campaign than it is to get 10 people. No. It's easier to get 1000000 to participate than 1000. But that's not the point. We are talking about accountability. I'd say it's easier to hold 10 people accountable than a 1000. reply jokoon 19 hours agoprevIt doesn't really matter if his identity gets leaked, when you are a director, you always become more visible no matter what you do. You cannot hide if you are a director. In military matters, high ranking officers don't protect their identity, because they represent the military. Although it is obviously true that lower and medium ranking soldiers and personnel ALWAYS need to protect their identity, because they should not be identified since they are the ones who carry orders and take the real risks. Of course it would have been better for him to not have his identity disclosed, since it would expose him to assassins if he would travel, but honestly this is a non-story, this will just generate hate comments in anti-israel crowds. reply bdcp 19 hours agoparent> Published in 2021 using a pen name composed of his initials, Brigadier General YS Also it doesn't seem like he was REALLY trying to hide his identity reply octodog 19 hours agoparentprevYour last paragraph is a weird take. It's a story because he was ostensibly trying to hide his identity and failed pretty miserably. reply jhallenworld 20 hours agoprevHere's the book: https://www.amazon.com/Human-Machine-Team-Artificial-Intelli... reply posix_monad 20 hours agoparentAuthor is listed as \"Brigadier General Y.S\" - hardly difficult to guess Yossi Sariel? reply notesinthefield 20 hours agorootparentThe 'About the Author' doesnt really try to hold info back either > Brigadier General Y.S is an expert analyst, commander of an elite intelligence unit and technology manager with 20 years of experience working on national security issues and challenges threatening the State of Israel. His areas of expertise include cyber and data science. In 2018, he was awarded the prestigious Israel Defense Prize for a new artificial intelligence based anti-terrorism project. He wrote his most recent book, The Human Machine Team, during his year of studying for a Master’s Degree at the National Defense University in Washington, DC. Y.S also has written other books in Hebrew on the topics of intelligence, strategy, and Hezbollah. He holds a BA in Middle East Studies and another BA in Psychology and Sociology. He grew up in Haifa and currently lives with his family in the beautiful Galilee region of Israel. reply dmurray 19 hours agorootparentPerhaps whichever HR department in the IDF covers publishing books has a checklist that says \"serving members cannot publish books about intelligence operations under their own name\", but no one who actually enforces an anonymization policy. reply pksebben 19 hours agorootparentprevI believe the revelation is that this particular Brigadier General is leading specifically unit 8200. I'm sure that the line > n expert analyst, commander of an elite intelligence unit and technology manager with 20 years of experience working on national security issues and challenges Fits neatly into quite a few punched-up resumes and 'about' pages. reply thaumasiotes 17 hours agorootparentHow many matches do you think there are for \"In 2018, he was awarded the prestigious Israel Defense Prize for a new artificial intelligence based anti-terrorism project\"? reply pksebben 17 hours agorootparentokay, yeah. Not many. That is patently poor opsec. reply stef25 19 hours agorootparentprevYeah this is either an opsec blunder or a smokescreen. Sariel is an anagram for Israel. reply nvr219 19 hours agorootparentprevYeah how was this such a secret? reply consumer451 20 hours agoprevPersonally, I don't care about his identity, but this article also discusses the contents of the book he published, which is much more interesting. reply draugadrotten 20 hours agoprevBrilliant 4D chess move by Yossi Sariel: he's cleverly feigning a mistake, aiming to exit his role without formally resigning. This \"mistake\" provide his superiors with a pretext for his departure, all while sidestepping the events of October 7. reply gnulinux996 20 hours agoparentIt seems to me that any blunder can be described as \"brilliant 4D chess move\" by those insisting that they did not mess up and it is us who do not see the game. Based on the events that have been taking place from October 7, neither party is capable for any form of strategizing. Let alone \"brilliant 4D chess moves\". reply ethbr1 19 hours agorootparentA characteristic of highly effective leaders is the skill to blunder, laugh authoritatively, and claim it was all part of a bigger plan. reply porkbeer 17 hours agorootparentNo thats bad leaders with good staying power. reply lm2s 20 hours agoparentprevBut the book was released 3 years ago? He made this mistake on purpose 3 years ago to have some way of exiting his role without having to resign? reply llm_trw 19 hours agorootparentThis is why it's 4d chess. Your linear perception of time is why you're not the Israeli intelligence chief. reply timdiggerm 20 hours agorootparentprevBut not until very recently did a publication suddenly \"discover\" this reply Qiu_Zhanxuan 19 hours agorootparentprevi think he was being sarcastic reply hgomersall 20 hours agorootparentprevAh, but how do you know it was published 3 years ago? Did you buy a copy then, or are you just relying on Amazon telling you so? reply coldtea 20 hours agoparentprevEspecially since the book was publicly meant to be released using his initials YS in the first place. It's not like he really wanted to keep this a secret. reply rchaud 17 hours agoparentprevThe real 4D chess, is in writing a thought leadership manual for computerized mass murder occurring right now, and being able to extricate yourself from any responsibility by just resigning. reply smt88 19 hours agoparentprevWhy would he want to look like an idiot when he could just resign and become a civilian? He could even go full Snowden if he wanted to. reply TheFreim 20 hours agoparentprev> This \"mistake\" provide his superiors with a pretext for his departure, all while sidestepping the events of October 7. I am not convinced that the Mossad, a competent intelligence agency from what I have read, did not actually know what was going to happen. The October 7th attack gave a perfect political justification for wiping out as much of Gaza as possible. reply sofixa 18 hours agorootparentMossad's competence is a complicated topic. Exhibit A: Yom Kippur war. They had convinced themselves that Egypt would wait on armament deliveries, so their obvious preparations for war, troop movements, and massive exercises next to the border were not a problem. Syria's obvious troop movements and cancelling of leaves weren't a problem either because obviously Syria wouldn't attack without Egypt, and Egypt would obviously wait for more Soviet shipments of armaments. Spoiler: they both attacked, and although defeated later on, demonstrated that Israel wasn't as invincible as everyone had thought, and it resulted in Sinai being returned to Egypt and normalisation of relations between Egypt and Israel (thus long-term a victory for Egypt, even if they had their asses handed to them, militarily). Exhibit B: Lillehammer affair, where Mossad mistook a random Moroccan waiter for a high level Palestinian leader, and killed him. Exhibit C: Assassination attempt against high level Hamas leader, Khaled Mashal which was a failure and seriously jeopardised the relations with Jordan. For the October 7 attacks, we simply don't know if it was a political decision to let the attacks happen, or if hubris convinced Israel/IDF/Mossad that the intelligence can't be true. reply myth_drannon 19 hours agorootparentprevRead the article from Maariv that is linked in the parent article. Quite eye-opening. The plans were known for two years, but the hubris blinded them. Another recent, very painful article is this one - https://www.haaretz.co.il/magazine/2024-04-04/ty-article-mag... reply aardvarkr 19 hours agorootparentPolitely letting you know that it’s spelled quite, not quiet , so that you can learn from this. The English language can be really dumb reply smt88 19 hours agorootparentprevThis theory doesn't make sense when you factor in the political consequence for Netanyahu. A country's leader is always blamed for a lapse in decent, and Netanyahu knows that. reply majikaja 19 hours agorootparentMaybe he is just left there as a puppet reply smt88 14 hours agorootparentBy...? reply majikaja 6 hours agorootparentI don't know but does it look like he's hugely powerful now? reply smt88 5 hours agorootparentYes and no, but either way, he was hugely powerful before. Pointing out that he doesn't look as powerful now after dominating Israeli politics for decades is supporting my point. reply smt88 14 hours agorootparentprevlapse in defense* reply PhasmaFelis 19 hours agorootparentprevYeah. Many people in the Israeli government have been quite explicit about wanting to wipe out all Palestinians. They're not trying to hide it. reply dragonwriter 5 hours agorootparentMany people in the Israeli government have been quite explicit about Hamas’s actions being useful to them as a pretext for doing so, too. So, while I am not arguing that is is the case, it is not at all implausible (especially if the underjudged the scale or likely impact of the attack) that they might allow an unusual attack that was likely to be pretextually useful to occur to provide an excuse to bring the hammer down, even before considering the specific, personal pressures on Netanyahu and how he might view an excuse for a justified war as a means to deflect them. reply Sebb767 20 hours agoparentprevGiven his position, is revealing his identity really that great of a move for an uneventful retirement? The reduction in personal security (given that many people might want revenge on him or extract information) seems like a bad trade. reply coldtea 20 hours agorootparentHe already explicitly wanted to publish the book with his actual initials. It would have been quite easy for adversaries with just general public information to get from the initials to the person, right? So perhaps revealing the full name doesn't make much of a difference, which is why it could just as well have been \"accidental\" (quotes intented). reply vik0 20 hours agoparentprevnext [2 more] [flagged] coldtea 20 hours agorootparentHuh? It just reads as very basic conjecture about the motives of a public move. If Israel is like any other country when such things happen, there should be lots of articles in their press wondering the same thing. reply hdlothia 20 hours agoprevIt's nice to know this kind of stuff is hard for the experts too reply yread 20 hours agoprev> Sariel’s critics, the report said, believe Unit 8200’s prioritisation of “addictive and exciting” technology over more old-fashioned intelligence methods had led to the disaster. Do they also use Kubernetes and the latest frontend frameworks? reply solardev 18 hours agoparentDeep in the bowels of Mt. Sinai, a clandestine IDF bunker guards a terrible secret: a giant useEffect() loop that controls all the murderbots, individually, by their hardcoded names. They didn't have the budget to research memoization yet, so it runs a bit slow, but it was fine on powerful enough hardware. The ballistics were all calculated in WebGL, leading to a global GPU shortage the last few years. And sometimes they'd get the viewport size wrong, which is why there was collateral damage :( Having learned their lesson, Israel's next AI project will stick with the tried and true and be written entirely in CSS instead. reply copperx 20 hours agoparentprevKubernetes is old and crusty technology at this point. It would be more like firing the senior developers to hire junior ones with a ChatGPT subscription and expecting big improvements in development speed. reply bayindirh 19 hours agoparentprevNope, they moved to serverless. They compromise random computers in basements and send small functions to process in a distributed manner. Since the data is so small, it's not possible to construct what they are doing. SETI@HOME in Soviet Russia fashion. You process their data, even without knowing it. The only thing you can do is to format your system to get rid of the backdoor (hopefully). reply whatwhaaaaat 19 hours agorootparentI didn’t know reformatting disabled intelME! reply bayindirh 16 hours agorootparentI hoped the person used a firewall and/or removed ME forcefully for the second round. reply KingOfCoders 19 hours agoprevOpsec is hard. 99999 times done everything right. 1 time making a mistake and you're done. reply GaryNumanVevo 19 hours agoparentIs it really OpSec if you're putting your initials on a self-published Amazon book? reply dewey 19 hours agoprev> An electronic version of the book included an anonymous email address that can easily be traced to Sariel’s name and Google account. Contacted by the Guardian, an IDF spokesperson said the email address was not Sariel’s personal one, but “dedicated specifically for issues to do with the book itself”. So it doesn't sound like his \"real\" email was leaked somehow through the book publishing workflow but more like there was a contact email listed (Maybe even in the book itself) in the book and it was not sufficiently private. Could be as easy as leaking some letters or a profile picture through the password reset workflow. reply tester457 19 hours agoparentThe implications of this is that anyone is easily able to find the name behind a google account? reply dewey 19 hours agorootparentThey used to show the profile picture, not sure what's the current status but there's still a few characters of the email address visible usually. reply philip1209 19 hours agoprev> The security blunder is likely to place further pressure on Sariel, who is said to “live and breathe” intelligence but whose tenure running the IDF’s elite cyber intelligence division has become mired in controversy. It seems weird to me that the news outlet that ousted Sariel is foreshadowing that the disclosure could put pressure on him. If they say \"we try to oust Sariel,\" and also \"ousting Sariel will put pressure on him\", then through the transitive property I interpret it as \"we are trying to put pressure on him.\" And, that seems like politics instead of journalism. reply hilux 14 hours agoprevI don't run any secret military units (that I'm willing to admit to), but I do leave occasional product reviews on Amazon under a pen name. I discovered that I was doxxed by creating a Goodreads account from the same email address, now that Amazon owns Goodreads. reply jason-phillips 19 hours agoprevAdjacent for some time to those participating in the secret squirrel pantomime, I find this all so terribly tiresome. Drawing a veil under the pretense that revealing what's behind would harm the country, the reality is that those participating are engaged in rather mundane drudgery and would simply prefer to not be made available to uninformed speculation by the peanut gallery. reply negus 19 hours agoprevNice try, book promoters. reply archsurface 19 hours agoprev\"Published in 2021 using a pen name composed of his initials, Brigadier General YS\" - Really? Misdirection? reply stef25 19 hours agoprevEmail account aside, he - Published a book using his real initials - Was one of four recipients of an IDF prize in 2018 - Did a Master’s Degree at the National Defense University in Washington when writing the book This is either a blunder like no other or there is no Yossi Sariel. His last name being an anagram for Israel and the fact there's zero traces online for someone who's been in the IDF his entire life, this seems like the most likely explanation. EDIT \"Sariel\" is actually the name of an angel from a Judaic tradition https://en.wikipedia.org/wiki/Sariel reply cafard 18 hours agoprevIn the 1950s or 1960s, the American journalist Steward Alsop printed the name of the head of the British MI-5 (or maybe MI-6). He told someone that the man (Menzies) was somewhat placated because Alsop had referred to him as \"legendary\". reply coliveira 20 hours agoprevIf the chief spy of a country doesn't understand the implications of publishing books from his personal account, then you cannot trust him whatsoever... The stupid are controlling the whole thing. reply resource_waste 20 hours agoparentIve played at really high levels. I'd say 90-98% are really smart. That is the interesting part, a few people arent. They are there for some other reason. I know someone who was inspiring but a dolt, I know someone who had their parents money, I know someone who bandwagon a winning candidate. Who knows is this person is there on merit or not, but its pretty interesting how smart people get when you start moving up. Its the exceptions that are weird. reply coliveira 18 hours agorootparentI know there are smart people there, the point is that the stupid are really in control. It is the same for most companies: you'll find a lot of smart people (that's why they're successful), but you'll find also a few stupid people who reach the top by other means and make the company a piece of hell for everyone. reply hackerlight 20 hours agoparentprevEgo. What's the point of success and mastery if you can't convert it to what you really care about which is status, even if it's lived vicariously through a pen name. It's like organized crime people always having to buy cars with their money then the tax authority comes knocking. Beyond a certain point money is useless if you can't convert it to status and get those feel good chemicals flowing. reply speedylight 17 hours agorootparentIf nothing else you can use money to help people. Money is never useless my friend. Money can be a burden though, like if you have it but can’t spend like someone else who has the same amount but legally I can agree to that. reply thefz 13 hours agoprevWhere is the \"Mossad Is going to burn your house down\" copypasta now? Just for laughs. reply mmsc 20 hours agoprevSo he published a book using his own private email. It doesn’t seem like he was really trying to keep it a real secret. reply ljf 19 hours agoparentNo - he included a different email address in the book to gather feedback from readers. This email address was then linked to his personal Google accounts (how, is not described - but I bet Krebs On Security would know how). reply paradoxyl 19 hours agoprevGiven how unreliable LLM is in general usage with its tendency to \"hallucinate\" -- a grossly anthropomorphic term, when it's just an alogrithm with no sense of what's \"actual\" or \"fictional\" -- to use this in government and law is irresponsible and criminaly negligent. To use it in war is abhorrent. reply barbazoo 19 hours agoparentDoes it say anywhere that they were using LLM? reply bornfreddy 19 hours agoprev> However, it has been criticised over its failure to foresee and prevent Hamas’s deadly 7 October assault last year on southern Israel, in which... Does anyone believe that they didn't know about it? reply snapcaster 15 hours agoparentI do, I think a lot of times massive fuckups get the \"it was secretely a 4d chess move\" thing but it's pretty believable (to me at least) that Israeli capabilities have degraded significantly over the decades as the IDF shifted from a war fighting army to prison guards reply bornfreddy 14 hours agorootparentIt's possible, of course, it just doesn't sound likely. reply WarOnPrivacy 19 hours agoprevUS LEO like to say The bad guys only need to slip up once to get found out. This seems to be true. reply peter_d_sherman 19 hours agoprev>\"One section of the book heralds the concept of an AI-powered “targets machine”\" https://www.youtube.com/watch?v=nSQ5EsbT4cE https://en.wikipedia.org/wiki/Brazil_(1985_film) reply politician 20 hours agoprevThe book was published three years ago. The timing of this revelation is convenient. reply selimnairb 19 hours agoprevAnother 27-year-old brigadier general? reply colechristensen 20 hours agoprevOk but why did his identity need to be secret in the first place? https://en.m.wikipedia.org/wiki/Director_of_the_National_Sec... Like hey look here’s the director of the NSA! Who cares? reply eugenekolo 19 hours agoparentThere's some logic to hiding the identity... don't know who/who's family to hack/threaten? But, you can just target the 2nd, or 3rd in command it'll be just as effective really.... so I'm not sure what the point is, besides some sort of security theater coolness. reply ceejayoz 20 hours agoparentprevThe NSA is probably a bad example, given its entire existence was denied for two decades by the US. reply axus 19 hours agoparentprevThe US has oceans on both sides, and the bureaucracy involved in getting airfare reimbursed for a bunch of agents is too much for most governments. reply toyg 19 hours agorootparentIt's less the airfare than the fact that they would stand out. Fort Meade is a defence installation, people don't just \"pass by\". Most people in the area would have military connections and be wary of even-slightly-foreign-accented individuals suddenly popping up near critical areas or where heavily-protected personnel actually live. reply octopoc 17 hours agorootparentprevThat's not really apples to apples though. If we start bombing Indian reservations and trying to exterminate Native Americans, I'm pretty sure they would quite deliberately become a threat to American equivalents of this guy. (...or perhaps I'm misreading you? not sure) reply colechristensen 14 hours agorootparentThere have been reasons for folks to be motivated to attack personally the leads of the various American spy agencies over the last century, there really hasn’t been a significant amount of time where we weren’t in some kind of military conflict, very many of them with questionable to explicit human rights violations. reply roughly 18 hours agoparentprevThe head of Israeli intelligence is operating in a different threat landscape (both figurative and literal) than the head of the NSA. reply readthenotes1 19 hours agoprevHuman: There are hundreds of Hamas hiding in Al Shifa hospital. AI: Go in and kill them -- Is that why the picture of \"destruction near Al Shifa Hospital\" is in there, to lead us to believe it was the heartless software that led to the raid? (https://edition.cnn.com/middleeast/live-news/israel-hamas-wa..., as if you can believe anything coming out of there) reply myth_drannon 19 hours agoprevIn the subject article there is a link to Maariv article (In hebrew) https://www.maariv.co.il/journalists/Article-1078519. Basically the guy drunk \"Startup Nation\" kool-aid and thought he was running a startup. 8200 built this data lake with billions of data points and started to rely on it, decreasing the importance of intelligence analysts. So they were getting signals but couldn't act upon them, something that senior analysts would have helped. That's why they ignored the senior analyst \"V\" alarms and called her delusional. And on that damned early morning when they started to get \"low significance\" signals from the system and the chief of staff, Mossad and the intelligence head decided not to do anything significant. At the same time, an analyst could have connected the dots. This guy will be out and the rest as well. reply f38zf5vdt 20 hours agoprev\"Making an entire book about my AI death machine is the best idea I ever had!\" is the intelligence equivalent of The Simpsons \"Videotaping this crime spree was the best idea we ever had!\" edit: Since this thread is getting turfed so hard that my other, serious comment is already gone. I would ask you to read this thread about said AI death machine and make your own thoughts about what is currently happening. https://news.ycombinator.com/item?id=39918245 reply lenerdenator 20 hours agoparent“Is you taking notes on a criminal conspiracy?\"- Bibi, probably. reply snowwrestler 20 hours agoprevThe major challenge in fighting terrorists is distinguishing them from the general population. Killing innocent people is against international law and harms the country doing it. While killing terrorists is acceptable and even desirable to many people. If a targeting system is more intelligent, it should be better at reducing the loss of innocent life while still delivering the same kill rate of actual terrorists. Israel’s system, based on reporting, does the opposite. So we can see that their use of an AI system to do this targeting reflects an insight not into the operational benefits of AI, but the cultural benefits. By spending tons of money and time and calling it “artificial intelligence,” the targeting team has developed a far more flexible pretext for violence. “This incredibly advanced AI system said he’s a target” is now enough to go drop a bomb… even if the incredible AI system is simply set to have its filters wide open. This is what YS means by “A team consisting of machines and investigators can blast the bottleneck wide open.” The humans build the machines to be extremely credulous, and then tell everyone else that the machine ID’d each target as a legitimate target. reply majikaja 19 hours agoparentIsrael gets to define anyone killed as a terrorist so the AI can never be wrong Alternatively they can just label anyone resisting extermination as such so the entire population can be cleansed reply 93po 17 hours agorootparent> Israel gets to define anyone killed as a terrorist so the AI can never be wrong I will point out that the US does the exact same thing. Both are wrong of course. reply consumer451 16 hours agoparentprevI was once the first full-time employee at a small company. I had to answer the phone for sales calls sometimes when the owner wasn't around. I started there as a consultant who designed and coded the sales CRM application. I had full control of everything. When I answered the phone for sales, and someone would ask for a discount, I would always say \"I'm sorry, the computer just won't let me do that.\" The blame was passed to the computer, and I got out of that uncomfortable situation. The customer always understood. After all, \"it's up to the computer,\" what can you do? What we are reading about in this article is the kill list version of that. A couple years ago, I wrote on this website that I am much less worried about AGI killbots, than I am about humans using dumb AI to kill people. Now, here we are. reply refurb 19 hours agoparentprev> Killing innocent people is against international law It’s not. Specific instances of killing innocent people where a number of factors are met is against international law. Innocent people inevitably die in war. That’s why the world so desperately wants to avoid it. But international law acknowledges that even if a actor does everything right, innocent people will die. reply snowwrestler 19 hours agorootparentYes, there is “fog of war” and “collateral damage.” International law requires that combatants take steps to minimize that. And not intentionally target innocent life. reply pvaldes 18 hours agorootparentprevIt is. By definition (Because they are innocent) Even if you fail to avoid shooting innocent people and can find a scapegoat to save yourself from the consequences, homicide is definitely, unequivocally, illegal. And assassination (killing somebody that is helpless, like bombing its house or a sniper shooting a child) is even more illegal. And any army that does not try at least to study a basic understanding of international war laws are a bunch of unprofessional criminals. reply nobodyandproud 17 hours agorootparentWhere does this misunderstanding come from? https://ihl-databases.icrc.org/en/customary-ihl/v2/rule14 “an attack which may be expected to cause incidental loss of civilian life, injury to civilians, damage to civilian objects, or a combination thereof, *which would be excessive in relation to the concrete and direct military advantage anticipated*” Note that proportionality is ill-defined, leaving a lot of room for interpretation. reply pvaldes 17 hours agorootparent> Where does this misunderstanding come from? Greed. War is very profitable. There will be always people trying to twist the words, and justify the unjustifiable. reply refurb 8 hours agorootparent> Greed. War is very profitable. That's the reason for your misunderstanding? Because it's your statement that is incorrect. reply nobodyandproud 16 hours agorootparentprevRight, but have you given thought to the greed and maliciousness of those that prop-up Hamas? Also, war has never excluded the casualty of innocents except in the movies. What’s not reasonable is when an attack goes out of its way to kill civilians. It’s why it was a big deal and a disgrace when Trump pardoned US soldiers who knowingly and without cause killed civilians. And why what Hamas instigated was especially appalling and inexcusable. And why Netenyahu has overplayed his hand, to cover for his failings. reply zer8k 19 hours agoparentprev> Killing innocent people is against international law and harms the country doing it. While killing terrorists is acceptable and even desirable to many people. Enemy combatant has a very specific meaning and that _can_ include people aiding and abetting the enemy. Thus, \"actual terrorist\" is a fairly nebulous term along with \"innocent people\". War is hell for a reason. Except for in obvious cases like Mai Lai it is never clear whether to call a person \"innocent\" for allowing an enemy combatant to seek shelter in their home - for example. But you have to make a snap decision: is the woman carrying what looks like an oddly shaped baby actually carrying bomb? Groceries? Why is she walking so close to the convoy? Did we issue a warning? Did she heed it? A bad decision will cost you many more lives than taking one. War is hell. > the targeting team has developed a far more flexible pretext for violence Doubt. The kill order chain is most likely AI flags target -> fed to human operator -> operator confirms -> kill order. Of course, your counter argument is that the human is given pretext (\"this is a target\") and thus assesses it with the assumption but in theory it's actually a better situation. 80% accuracy is still better than previous generations warfare. You dont want to end up on the thermals of an apache carrying a tube you need to replace your broken sewage system. The news is polluted with pro-Palestinian nonsense. It's very clear absolutely no one on social media has any idea what hamas does, or what the people of palestine have done to aid and abet the terrorists. This is not to justify just dropping bombs on people without cause but I would be pretty satisfied with a best-effort approach to the loss of civilian life given how deeply embedded hamas is. reply frob 19 hours agorootparentAnd then the Israelis put that target they only have partial confidence about into a system called \"Where's Daddy?\" which will track their target until he goes home to his family at which point a kill order is sent out to drones and warplanes to massacre his entire family. [0, 1] Is that the \"pro-Palestinian nonsense\" you were referring to? [0] https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai... [1] https://www.972mag.com/lavender-ai-israeli-army-gaza/ reply zer8k 19 hours agorootparentSee the part where I said aiding and abetting a known target makes you a target. \"What about the children\" is a very poor argument. Would you rather a fireteam kick down the door and have to shoot the entire family when they all scurry to a room and grab arms because daddy told them to? Because that's what happens - all the time. There's no \"put down your weapons\" like you see in movies. You have about 50ms to make a decision to neutralize a target. I know people who are very screwed up after having to shoot children carrying weapons because their parents told them to. I know people who've had to make the kill/no-kill decision on a woman and her child approaching a convoy. It's a fucked up situation. That's why we try to avoid war. You can't just deploy operators when a guy goes home to his family. It's expensive, dangerous, and difficult. If you leave him alone he could be ordering people from his home to kill your people. Unconventional war is by definition unconventional. If they fought like a regular military their families would most likely not be targeted. I have no data but I can tell you absolutely no one wants to kill women and children. Except for hamas, that is. reply frob 19 hours agorootparentAt this point, \"aiding and abetting\" seems to be \"existing while inside Gaza.\" See the deliberate execution of the world central kitchen workers in a three-phase strike to ensure maximum casualties as an example. reply zer8k 7 hours agorootparentI mean, that's not true. But you won't agree with me as it's en-vogue to be pro-hamas. You should actually be ashamed of yourself how little you understand about how these terrorists operate and how boldly you claim shit like \"genocide\" and \"execution\". reply frob 6 hours agorootparentI am against systems designed to target and slaughter civilians. I am against using starvation as a weapon of war. I am against rules of engagement so loose that it allows the military to kill a convoy of people coordinating directly with the Israeli military on a aid mission who are using GPS devices to transmit their location to the Israeli military using three separate strikes over 2.5 km. I'm against dropping 2000-pound bombs on dense civilian areas. I am against rules of engagement so loose it allows the Israeli military to kill three of the hostages it was purportedly trying to save while they're waving white flags. I am against using snipers against people hiding in churches and hospitals. I am against an approved collateral civilian kill rate of 15-20x. I consider these positions to be pro-humanity. If in your view, holding these positions makes me pro-hamas, I encourage you to examine if you are using an unnecessarily binary framing to analyze the death and destruction going on. reply ryandrake 18 hours agorootparentprevYou can't just scowl seriously and declare \"war is hell\", and pretend that excuses everything. War may be hell, but it's only hell because of the individual decisions of actual people up and down each belligerent's chain of command. reply nobodyandproud 17 hours agorootparentYes, but Hamas instigated this by attacking civilians and the PLO—and only the Palestinians and its silent backers—threw away a dual-nation solution during the Clinton era. So when we include decisions, it’s important to be impartial here. reply cycomanic 15 hours agorootparentBlaming the failure of the 2000 Camp David talks solely on the PLO is a convenient lie that seems to only serve to justify the increasingly harsh treatment of Palestinians by Israel. The historical record shows that both parties were not willing enough to compromise in order to create the two state solution [1]. [1] https://en.m.wikipedia.org/wiki/2000_Camp_David_Summit reply nobodyandproud 14 hours agorootparentThe convenient lie is papering over the blame where it squarely belonged. Like many of my generation—Gen X—I was closely following the on-goings because it seemed so close (Berlin wall, Russia seemed like an ally; more peace in our time); but in the end Arafat scuttled the deal because he did not want to compromise and give-up any part of Jerusalem. “Arafat rejected Barak's offer and refused to make an immediate counter-offer.[100] He told President Clinton that, \"the Arab leader who would surrender Jerusalem is not born yet.” https://en.m.wikipedia.org/wiki/Yasser_Arafat [1] reply no_exit 12 hours agorootparentThe citation [100] here is Jimmy Carter's book, which not only does not support the wiki summary (Camp David was based on a proposal from Clinton--not Barak, and Barak had \"twenty pages of reservations\" about the proposal himself), Carter also concludes: [1] > There was no possibility that any Palestinian leader could accept such terms and survive, but official statements from Washington and Jerusalem were succesful in placing the entire onus for the failure on Yasir Arafat. Violence in the Holy Land continued. In regards to the following talks at Taba, which perhaps the wiki is conflating with Camp David, Carter continues: [2] > A new round of talks was held at Taba in January 2001, during the last few days of the Clinton presidency, between President Arafat and the Israeli foreign minister, and it was later claimed that the Palestinians rejected a \"generous offer\" put forward by Prime Minister Barak with Israel keeping only 5 percent of the West Bank. The fact is that no such offers were ever made. [1]/[2] Jimmy Carter - Peace Not Apartheid (it's on Libgen, go look for yourself like I just did) reply zer8k 7 hours agorootparentprev> but it's only hell because of the individual decisions of actual people up and down each belligerent's chain of command. If a 10 year old takes up an AK-47 and points it at you what are you going to do? If a woman carrying a child sets a suspicious package down what're you gonna do? This isn't a \"decision by the chain of command\" outside of ROE for the AO. Everything else is on you. If your answer is \"call the chain of command\" your entire unit is now dead. Congratulations. The variance in the decisions is due to the fact you can't make decisions by debating the internal psychology of the moron who may be trying to kill you. Innocent people will die. That's war. I'm getting downvoted to death here because it seems the posh liberals sitting at their desks don't understand what an actual life or death decision feels like. To be honest I'm not shocked. The toughest decision most people make is what to have for lunch and even that is enough to give the yuppies anxiety. reply paganel 20 hours agoprev> In one chapter of the book, he provides a template for how to construct an effective targets machine drawing on “big data” that a human brain could not process. “The machine needs enough data regarding the battlefield, the population, visual information, cellular data, social media connections, pictures, cellphone contacts,” he writes. “The more data and the more varied it is, the better.” They should hold more strategy-oriented courses at the Israel Military Academy, that is if they have a military academy worthy of that name and if this intelligence guy is a graduate of one. Because it looks like he can look no further than the tactical level (\"how do we kill leader X of enemy group Y at time moment Z?\"), which is a suicidal thing to have as your top-military commanders in the middle to long term (because, no, killing enemy leaders X1...Xn won't win you any wars in the middle to long term). reply jolj 17 hours agoprev [–] Statistical models are used for at least 80 years to calculate the size of bombs when hitting targets and to factor in civilian casualties. Today's statistical models have much better PR but it is not much different. Also war is bad, but sometimes it is a necessity when the alternative is worse. It is always quite easy to cast yourself as a neutral moral judge on the sidelines, but we all saw what happened to the USA in the early 2000s when faced with a lesser threat than Israel. With the way the world is heading what we are hearing are simply echoes of the pre-ww2 appeasement attitudes which of course are a great way to prevent future deaths and war reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Yossi Sariel, leader of Israel's Unit 8200 promoting AI in warfare, faced scrutiny due to a security breach related to his book \"The Human Machine Team.\"",
      "The book discusses AI's role in military actions, utilized by the IDF during the Gaza conflict, raising concerns about Sariel's leadership amid intelligence shortcomings, such as the 7 October attacks.",
      "Sariel's concept of human-machine collaboration in warfare created a debate in the intelligence sector, highlighting diverging opinions within the community."
    ],
    "commentSummary": [
      "The passage covers various topics including the exposure of an Israeli spy chief's identity due to a security lapse related to an Amazon-published book, brain drain in countries like Singapore and South Korea, and the use of AI in military decision-making.",
      "It discusses the ethics of AI in warfare, implications of religiously charged names in military operations, and the accountability of individuals involved in planning and using AI systems in warfare.",
      "The conversation emphasizes the challenges and ethical dilemmas of integrating AI in military operations, highlighting the potential for civilian casualties and the role of AI in minimizing such casualties in conflicts like guerrilla warfare."
    ],
    "points": 267,
    "commentCount": 240,
    "retryCount": 0,
    "time": 1712323735
  },
  {
    "id": 39948044,
    "title": "SearXNG: The Privacy-Respecting Metasearch Engine",
    "originLink": "https://github.com/searxng/searxng",
    "originBody": "Privacy-respecting, hackable metasearch engine Searx.space lists ready-to-use running instances. A user, admin and developer handbook is available on the homepage. Contact Ask questions or just chat about SearXNG on IRC #searxng on libera.chat which is bridged to Matrix. Matrix #searxng:matrix.org Setup A well maintained Docker image, also built for ARM64 and ARM/v7 architectures. Alternatively there are up to date installation scripts. For individual setup consult our detailed Step by step instructions. To fine-tune your instance, take a look at the Administrator documentation. Translations Help translate SearXNG at Weblate Contributing Are you a developer? Have a look at our development quickstart guide, it's very easy to contribute. Additionally we have a developer documentation. Codespaces You can contribute from your browser using GitHub Codespaces: Fork the repository Click on theCode green button Click on the Codespaces tab instead of Local Click on Create codespace on master VSCode is going to start in the browser Wait for git pull && make install to appear and then disappear You have 120 hours per month (see also your list of existing Codespaces) You can start SearXNG using make run in the terminal or by pressing Ctrl+Shift+B",
    "commentLink": "https://news.ycombinator.com/item?id=39948044",
    "commentBody": "SearXNG is a free internet metasearch engine (github.com/searxng)214 points by tosh 11 hours agohidepastfavorite57 comments keepamovin 2 hours agoIf anyone is interested in searches applied to the full text of every page in your browser history, or to only select pages that you bookmark, check out our project DownloadNet (formerly, and possibly, futurely: \"DiskerNet\"). It hooks into your browser to give you an augmented experience. The UI is pretty simple (think 1997 era google but without CSS haha), and we don't do anything super complex with search (but could in future), but it works not bad. Check it out!!! https://github.com/dosyago/DownloadNet Oh, it also makes your content (again either everything you browsed or only what you booked) available offline. So if you work on an oil rig, or shipping, or long haul freight, can be a good way to browse as normal but save yer satellite bandwidth!!! reply DavideNL 1 hour agoparentI don't see any documentation at all, like what browsers are supported, etc. :/ reply alexdeloy 20 minutes agorootparentMe neither, it really would benefit from a better documentation since I like the idea a lot. I just tried it out and it seems to be tied to Chrome. Since I use Firefox and Chromium as my daily drivers this does not work for my case. I understand that they probably rely on some Chrome internals to dig through the content, a SOCKS Proxy approach would have worked better and would have no need to switch between a \"save\" and \"serve\" mode. But then again I was only scraping the top of it because of the lack of browser support. Will keep an eye on this one though! reply lygten 3 hours agoprevTry this guy. Its not Kagi, but the search results are pretty good. Host it yourself on Docker. https://felladrin-minisearch.hf.space/ reply zuhsetaqi 3 hours agoparentWow, it's anoying that it reloads the result while I'm going through them reply lygten 1 hour agorootparentYou can disable the AI reply xnx 10 hours agoprevThis takes me back. Before Google, meta search tools increased your odds of finding a decent answer between the spammy results from Alta Vista, Hotbot, Lycos, etc. reply chefandy 5 hours agoparentI liked Copernic: it was a native Windows 9x Meta search tool. reply jszymborski 2 hours agorootparentThis brought a smile to my face... I worked at a company started by Copernic alums (Coveo). reply sheepscreek 4 hours agorootparentprevWow. I came here to the comments to write about Copernic! It was a super valuable tool in the pre-Google era, heck even in the early 2000s. reply nickburns 9 hours agoparentprevmemories. and now it's come back around some decades later in the name of digital privacy. reply rockskon 5 hours agorootparentHow are they private though? Unless they relay your search it is the exact opposite of private. reply sneela 57 minutes agorootparentIf you host your own instance: > SearXNG protects the privacy of its users in multiple ways regardless of the type of the instance (private, public). Removal of private data from search requests comes in three forms: > 1. removal of private data from requests going to search services > 2. not forwarding anything from a third party services through search services (e.g. advertisement) > 3. removal of private data from requests going to the result pages From: https://docs.searxng.org/own-instance.html#how-does-searxng-... The docs mention a caveat below at \"What are the consequences of using public instances?\": > If someone uses a public instance, they have to trust the administrator of that instance. This means that the user of the public instance does not know whether their requests are logged, aggregated and sent or sold to a third party. reply yayr 1 hour agorootparentprevI would assume that the relaying can strip the request from identifying information such as IP, cookies and other tracking mechanisms that you get when visiting e.g. google.com. reply nickburns 53 minutes agorootparentprevprivacy is achieved through the proxy and therefore aggregation of disparate requests/queries. some anonymity is therefore achieved, at least from the perspective of source search engine operators, by blending into 'the crowd.' but the idea is not necessarily anonymity so much as privacy by foiling the creation of any even somewhat accurate marketing/data profile derived from 'your search.' reply notpushkin 4 hours agorootparentprevThey do indeed relay your query. How else would they work? reply marban 7 hours agoparentprevNorthern Light was nice though. reply giantrobot 6 hours agoparentprevNot just avoiding spam but some meta search engines (Dogpile IIRC) could also search specialist search engines like White Pages and Yellow Pages (long before Yelp etc existed). You'd be able to find business listings and contact info that wasn't normally found on web search engines. They could also include FTP search results which was useful as public anonymous FTPs had yet to fall from use. reply 8ig8 10 hours agoparentprevDogpile was another. reply arcastroe 6 hours agoprevThis is great. I wish there was a way to block certain domains from ever appearing on search results. EDIT: Looks like there's already an open issue: https://github.com/searxng/searxng/issues/2351 reply ThinkBeat 57 minutes agoparentGoogle used to do that, but then stopped. You can still do it manually by specifying by excluding them in (every) search you do,but the list can get along and it is far from a good user experience. Kagi has this feature built in and it is a good user experience. You can also use the uBlacklist browser plugin. My problem with that is that is slows everything down. I am not certain but I think all the works is done after the search is complete. That it filter the actual result. The two above limit it from ever being part of the result. reply dalf 1 hour agoparentprevDisclaimer: I am one of the maintainers. The intent of SearXNG is to be stateless (with no sessions on the server) and to work without JavaScript. However, this approach limits certain features because of the restricted size of cookies (and other forms of browser storage require JavaScript). reply squarefoot 6 hours agoparentprevuBlacklist does just that with Google and some other search engines. I use it with Firefox to filter out pinterest junk from search results. Also available for Chrome and Safari. https://github.com/iorate/ublacklist reply poulpy123 2 hours agorootparentjust installed it to try. For the people that want to give it a try also, I noticed that several of the public list contains legitimate websites such as canva or reddit reply BeetleB 5 hours agoparentprevKagi does that. reply lannisterstark 4 hours agorootparentI trust myself a bit more than I trust someone else to run my queries sadly. I understand that they claim to store no user data or associations etc, but honestly, it's just their word. reply BeetleB 3 hours agorootparent> I understand that they claim to store no user data or associations etc, but honestly, it's just their word. My guess is that if they are found to do so, then they open themselves up to lawsuits. Not collecting data isn't merely a perk - it's practically the reason Kagi exists. reply zelphirkalt 1 hour agorootparentEven if not a lawsuit, people will judge it themselves and vote with their feet. reply arcastroe 5 hours agorootparentprevKagi requires an account to use, which is not great for privacy. I understand Kagi is generally reputable, but I like the idea of a self-hosted alternative where you're in full control. reply sitkack 10 hours agoprevRun this on your personal internet connection, risk not being able to use a search engine. reply baobun 9 hours agoparentOnly if you expose it publically without auth while routing queries through your residential connection, which is not an advised configuration. For personal use, you can run it directly on your machine or access over VPN. Queries to upstream search engines can be forwarded over proxies or VPNs as you see fit. Some work fine over tor and some can go over commercial or DIY tunnels. reply ttt3ts 8 hours agorootparentTo add, I have been running instance for years for family and friends. I run it behind a nginix basic auth with a config that sets a forever cookie first time you login. Really simple. Another good option is cloud flare zero trust. reply nickburns 8 hours agorootparenthow many total regular F&F users? do they ever ask you about logging? or is that beyond the scope of what most of them realize is happening? reply BeetleB 5 hours agoparentprevI think this needs a lot more clarification than is provided in this thread. If you run it locally, and only you use it, then you won't get blocked - a given search engine will see about the same number of requests as if you used it directly. Add a few house members and you'll still be fine. (I ran the original searx for a year or two locally - no issues at all). reply mostlysimilar 10 hours agoparentprevElaborate? reply marginalia_nu 10 hours agorootparentVirtually all public search engine endpoints see an insane amount of bot activity, often several queries per second. If you delegate queries to e.g. google or bing at that rate, you'll be ip blocked in a heartbeat. reply mostlysimilar 10 hours agorootparentAh duh, for some reason my mind didn't go to hosting the search instance locally and I misunderstood. btw thank you for Marginalia! The spirit of the small web is very important to me. reply RaisingSpear 5 hours agorootparentprevSearch engines: they scrape the web, but get narky when scraped themselves. reply marginalia_nu 1 hour agorootparentDifference is a crawler paces the requests, respects robots.txt and rate limits, and doesn't typically invoke 50-100MB disk I/O per request. Like I don't mind automated access to my search engine, I even offer a public API to the effect, that you can in fact hook into SearXNG. What I mind is when one jabroni with a botnet decides their search traffic is more important than everyone else's and grabs all the compute for himself via a sybil attack. reply Fnoord 10 hours agorootparentprevIt is a metasearch engine. So it uses other search engines. The point is to let multiple use it, so that Google et al. does not know who's using their service. Ie. it is a gloried proxy. Honestly, I just use Kagi. Though I need to find some way to limit my searches to 300 per month. reply wkat4242 6 hours agorootparentIsn't Kagi also really a delegator? I've heard they delegate to brave among others. reply ranger_danger 10 hours agorootparentprevthat does not negate what OP said. your IP will still get blocked very quickly. although existing searx instances have been run for years and they don't seem to be dropping like flies... reply lannisterstark 6 hours agorootparentWell. I host a public instance. IP is still not blocked. YMMV. reply HeatrayEnjoyer 10 hours agorootparentprevYour IP address will get burned reply RGamma 43 minutes agoprevThere's also https://metager.org reply kristjank 1 hour agoprevIt's my favourite tool to average out the individually shitty results of mainstream search engines into something vaguely usable. reply longitudinal93 10 hours agoprevBeen running thieves the default on all my devices for the past year and I couldn't be happier. Have only had it choke twice and it just needed to be updated to be back in business. reply keepamovin 5 hours agoprevThat's clever. X-ING (like those 'crossing' roadsigns), so it's like Search-ching. There's quite some similarity between the CH and the X sound in English. But, as this is HN probably someone with a PhD in comparative phonetics will explain why this is a common and infuriating misunderstanding of layfolken. reply lannisterstark 4 hours agoparent^_^' Hah. FWIW, it's a fork of searX. https://github.com/searx/searx reply keepamovin 2 hours agorootparentHahaha! :) Good to know reply nickburns 9 hours agoprevuse when i'm tired of picking obfuscated Fumo plushies or Minecraft screencaps on https://4get.ca/. i don't even know what a Fumo plushie is, never mind six of them. reply bilegeek 10 hours agoprevOOC, does this support YaCy as another engine? Would be the best of all worlds if it did IMO. reply hagbard_c 10 hours agoparentIt does, I run it that way with an optional fan-out to my personal YaCy instance. Here's the relevant part of settings.yml: - name: yacy engine: yacy categories: general search_type: text base_url: https://yacy.searchlab.eu shortcut: ya disabled: true # required if you aren't using HTTPS for your local yacy instance # https://docs.searxng.org/dev/engines/online/yacy.html # enable_http: true # timeout: 3.0 # search_mode: 'global' Change 'disabled' to 'false' and point it at whatever YaCy instance you want to use. It can use the 'general' and 'images' categories. reply ozehlaw 11 hours agoprev [–] Interesting. Google is going to shit these days. reply mrexroad 6 hours agoparentWeb content itself had gone to shit these days, in order to win google’s SEO game to win google’s Adsense game. “Google going to shit” is just a second order effect (or third/forth depending how you look at it). reply YvUuXJiO 6 hours agoparentprev [–] i dont think so reply nickburns 6 hours agorootparent [–] i don't either. it's done been to shit for some time now. scraping its results can be highly effective though. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Searx.space is a privacy-focused metasearch engine providing operational instances for users, along with comprehensive handbooks for different user roles available on the homepage.",
      "Users can contact support via IRC or Matrix, and the engine can be easily configured using Docker images or installation scripts, with customization guidance provided.",
      "Contributors have the opportunity to assist in translating and enhancing SearXNG, with streamlined contributions possible through GitHub Codespaces."
    ],
    "commentSummary": [
      "SearXNG is a privacy-focused metasearch engine enabling users to host personal instances and prioritize privacy.",
      "Users note concerns about browser compatibility, lack of documentation, and the importance of digital privacy by recommending tools like uBlacklist and VPNs.",
      "Despite some users facing IP blocking issues, SearXNG is commended for its performance and reliability over other search engines."
    ],
    "points": 214,
    "commentCount": 57,
    "retryCount": 0,
    "time": 1712356079
  },
  {
    "id": 39941232,
    "title": "Kyoo: Next-Gen Self-Hosted Media Browser",
    "originLink": "https://github.com/zoriya/Kyoo",
    "originBody": "I started working on Kyoo almost 5 years ago because I did not like the options at the time. It started as a \"sandbox\" project where I could learn about tech I was interested in, and slowly became more than that.",
    "commentLink": "https://news.ycombinator.com/item?id=39941232",
    "commentBody": "Kyoo – Self-hosted media browser (Jellyfin/Plex alternative) (github.com/zoriya)205 points by zoriya 18 hours agohidepastfavorite148 comments I started working on Kyoo almost 5 years ago because I did not like the options at the time. It started as a \"sandbox\" project where I could learn about tech I was interested in, and slowly became more than that. peter_l_downs 14 hours agoLooks very pretty and the demo is nice. Congratulations on the launch. I'm a happy Plex user, via Plexamp for audio and the Plex app for Apple TV for video, and I'm not interested in switching. That said, > It started as a \"sandbox\" project where I could learn about tech I was interested in, and slowly became more than that. This is a fantastic reason to build something. Looks like a wonderful project. reply jascination 8 hours agoparentHow are you using Plexamp? Do you DL albums and stream it from there as a spotify-ish alternative? reply manmal 11 hours agoparentprevIn case you‘re into audiobooks, I suggest to check out Bookcamp too. I guess Plexamp works for that as well, but Bookcamp is just like Audible in a way. reply dewey 4 hours agorootparentI second the other suggestion for Prologue on iOS as a Plex frontend for audio books. It’s such a good experience that I’m now listening to more audio books than before and they also just launched an Apple Watch version. reply Arn_Thor 4 hours agorootparentSeconded! (Or thirded?) Prologue is so much better than Audible. I’m using Libation to liberate my copy protected audiobooks, not to share them but to avoid that godawful Audible app reply dewey 4 hours agorootparent> not to share them but to avoid that godawful Audible app It’s sad how true that is for many things these days. I usually download shows to have them in Plex even though I have many paid streaming accounts. Just because it’s a better UX and it also automatically scrobbles to Trakt.tv. reply Ardon 10 hours agorootparentprevFor anyone who's game to run another service for audiobooks, I've found Audiobookshelf to be pretty good: https://github.com/advplyr/audiobookshelf reply haltcatchfire 2 hours agorootparentI love ABS but I use it mainly for podcasts since it downloads each episode to my server which I then stream from. It’s awesome. My only gripe is the iOS app, which is a pretty slow webapp wrapper. reply darknavi 10 hours agorootparentprevPrologue on iOS is an Audible-like experience with a Plex back end as well! reply joshuaturner 6 hours agorootparentprevThe biggest hurdle I've run into when trying to manage an audiobook library with Plex is the metadata source. There are a few plugins that try and gather from Audible, I assume by scraping, but it's always minimal and very flaky. I haven't revisited this for a while now though, so hopefully things have improved - I would love to start archiving my Audible collection. reply drakenot 11 hours agorootparentprevBookcamp has fairly negative reviews on the App Store. Have you had issues with it? reply generalizations 11 hours agorootparentI've noticed that in general, a lot of selfhosted-adjacent apps tend to get negative reviews. Without having looked at bookcamp specifically, I've noticed that a lot of times, it's because those apps require a minimum level of competence from their users, and those users that miss the threshold generally leave negative reviews. reply manmal 10 hours agorootparentprevNo issues whatsoever. reply ecliptik 14 hours agoparentprevPlexamp is the one thing that keeps me on Plex. I have Jellyfin setup in parallel for the day Plex enters an「enshittification」phase, but the lifetime membership I paid for in 2012 has served me well. reply iamacyborg 1 hour agorootparentIf you don’t mind paying a subscription, I find Roon hugely superior to PlexAmp. reply debacle 17 hours agoprevI tried switching from Plex to Jellyfin, and one of the greatest limitations that I noticed with Jellyfin is that it doesn't seem to really give a shit about managing libraries, and seems overly opinionated about file structure. There's whole sections of the wiki dedicated to naming your files right that I don't have to deal with with Plex. Does Kyoo take a similar approach, or is it more user friendly? Plex's monetization efforts are silly, but Jellyfin seems very much not ready for prime time. reply zoriya 15 hours agoparentI find this extremely silly too. The goal of kyoo is to organize your library for you, you should be able to use your download folder as your library folder, and it should work right away without having anything to rename. There are still some edge cases, especially with extra which are not handled very well right now. It works even for weird anime naming, things like \"[SomeGroup] Jojo's bizzare adventure - golden wings 12.mkv\" reply Fire-Dragon-DoL 3 hours agorootparentI have a gazillion of those weird names in my library reply resfirestar 10 hours agoparentprevYMMV of course but Jellyfin supports manual tagging well enough for my uses. No need to change filenames and break folder structures you set up for easier navigation in file browsers (as I did), you can click the \"Identify\" option on a file/folder and search your enabled databases by title or IMDB number. Once you tell it what TV show a folder is for, all the episodes seem to get automagically recognized. It's just that first step that doesn't happen by itself when the folders aren't named \"correctly\", and you could probably get around it by using Tiny Media Manager to mass-write NFO files (which Jellyfin recognizes). reply Arn_Thor 4 hours agorootparentHonestly, any manual tagging is still too much work. Jellyfin would be a better Plex alternative if it got this right reply ramon156 16 hours agoparentprevJust a question, why do you guys want sn unopinionated media server? I love that I click some buttons in jellyfin and it just does it's thing, I don't have to think of my own structure reply zoriya 15 hours agorootparentI hate having to rename my files on an arbitrary pattern to have items show up in the media browser. I want a media browser to organize my media, not to ask me to organize it myself. reply HumblyTossed 16 hours agoparentprevI use Jellyfin, but I also use TMM (tiny media manager) to manage my files. Jellyfin seems to agree with what TMM produces just fine. I would like to see a slim Jellyfin that does not have any media management code at all, tbh. Just media streaming. reply rockostrich 15 hours agoparentprevOut of curiosity, why are Plex's monetization efforts silly? Sure, the freemium model is less than ideal compared to OSS, but I gladly paid for a lifetime subscription to Plex Pass 4 years ago and haven't regretted it at all since. reply dotnet00 13 hours agorootparentI think part of it is that the efforts are all going to be kind of dodging bullets, in that everyone knows that a popular use case of Plex is for pirated media. So all monetization efforts have to be carefully designed to not risk implicating the project directly into that use case. Which means that monetization efforts mostly lean slightly differently from what the users would want to pay for. The only monetized features that have decent overlap with user desires are the player features, mobile apps, plexamp and its sonic analysis stuff. reply _heimdall 6 hours agorootparentI don't quite follow here. Assuming a common use case is personal consumption of pirated content, doesn't it make sense that the monetization strategy focuses on the server/client software itself? More importantly, that monetization strategy is a great fit for legal self-custody. I have a pretty large library of content I bought on DVD and ripped for personal use. I don't share it our as torrents and watch videos locally on my own network, there's nothing wrong with that and I like that Plex is still paid for the software that makes it work well for my use case. reply jwells89 15 hours agorootparentprevI think the main issue is that the monetization efforts have resulted in blunted focus on the core product, resulting in things like long-standing unresolved bugs and technical oddities. For example the Plex installation on my home server will break itself in odd ways every so often and sometimes the only way to fix it is to nuke all cache, config, etc and start over which gets frustrating. It’s also brought privacy concerns, because there’s incentive for Plex to harvest and sell data from users paid and unpaid alike. I’m currently subscribed, but all of this has me on the lookout for viable replacements. reply mynameisvlad 15 hours agorootparentprevThey are pushing their free with ads offerings and data gathering (Discover) far more in the past year or two, to the point where I have to give instructions to some of my friends because the defaults are exclusively their own offerings. reply BeetleB 5 hours agorootparentThat's because your friends are independent, separate Plex users from you, even though you and they don't want to think they are. Just because they can use the Plex app to connect to your server doesn't mean that they are not separate. I get the frustration - Plex didn't do it in the past, but if you look at it from 1000 ft, and are ignoring history, Plex isn't doing anything crazy here. If you install the app on your phone/Roku/whatever, it's on you to understand how to use it/customize it. reply halJordan 8 hours agorootparentprevI disagree with the implication that plex is Just Another LLC trying to make a buck. If Plex were another netflix, then ads wouldn't be silly. reply cchance 9 hours agorootparentprevI have 0 issue against plex monitization, except for TRANSCODING, wtf am i being charged to use my own GPU?!?!?! reply Zircom 8 hours agorootparentOut of all the things to take issue with about their monetization model that is such a wild take. Do you also have issues about paying for a videogame that uses your GPU? Probably not. Any paid software you can run on your own hardware by definition is paying to use \"your own\" resources(CPU, GPU, storage, etc), what you're paying for is their effort in creating and maintaining the software. If they want a gatekeep features for a premium version that's their right, if you have a problem with it find something else or make it yourself. reply tadfisher 7 hours agorootparentOf course it's their \"right\", but it's also not very smart to gate a feature that determines whether or not the product actually functions. The potential customer is faced with a non-playable video and a promise that paying will make it play. reply adamomada 7 hours agorootparentIt’s an added feature for larger servers, it does cpu transcode for free. reply BeetleB 5 hours agorootparentprev> The potential customer is faced with a non-playable video What kind of video is non-playable without GPU transcoding? reply buggeryorkshire 16 hours agoparentprevHad exactly the same issue. Jellyfish was very opinionated, Plex doesn't care. reply kyriakos 16 hours agoparentprevAccording to it's feature list it's not. The fact that it advertises that gives me hope. reply slily 16 hours agoparentprevBoth Plex and Jellyfin refused to import my fairly standard and accurately tagged music library last time I tried, and Plex is definitely opinionated about structure in video libraries. reply petepete 15 hours agorootparentJellyfin wasn't happy with my music library either until I realised wanted the ReleaseGroup field to be set. I set Picard to work and an hour later it imported perfectly. reply Modified3019 14 hours agorootparentThat jellyfin is that nitpicky with a prerequisite just to get a music library to work is horrifying. reply Jochim 13 hours agorootparentJellyfin has handled the default Picard output format just fine for me. I don't see the expectation of a standard naming format as unreasonable, given that it's open source and they're fairly short on developers reply petepete 1 hour agorootparentI think my problem was that I used Beets to organise my mp3s a long time ago - maybe 2011. It didn't write the ReleaseGroup because that might not have been present for all albums on MusicBrainz at the time. It still did a great job and Picard nicely filled in the blanks. reply slily 12 hours agorootparentprevI saw discussions on GitHub where it was suggested that they refuse to match based on metadata over folder structure because they don't trust people to tag files properly. With my library, it generates multiple album entries per multi-disc album because I have them organized with a subfolder per disc, which not only makes no sense considering when you could easily match on disc number and parent folder, but is also a regression. \"Short on developers\" is a good excuse for lagging in features, not for poor design/implementation. Finally, relying on non-standard fields for matching is unnecessary and is in line with the \"overly opinionated\" complaint. I'd probably use Jellyfin if it got the basics right and lacked a thing or two, or if its opinionated implementation was limited to trivialities like how Plex refuses to use local images not named cover.jpg. But it's too opinionated, too inflexibly, about too many things, and I think its opinions are stupid, so it crosses the line as far as I'm concerned. Doesn't help that the code is convoluted and I couldn't figure out how to make changes to the way it analyzes files easily. reply mdaniel 16 hours agoprevHaving both postgres and rabbitmq strikes me as overkill - I wonder if they'd be open to a PR to harmonize to just PG, slimming down the ops burden. I'll have to dig into it when I'm back on my desktop to see what exactly RMQ is doing for a media server reply zoriya 15 hours agoparentrabbitmq is used to communicate between services. I just introduced it but it will be used to: - handle websockets communication with the client - create workqueues for new items creation/rescan requests - Watch list syncing with external services - and to synchronize different replicas when deployed on k8s (still need work on this point tho) reply JeremyNT 12 hours agorootparentI'm not here to talk you out of rabbitmq now that you've already added it for this project, but IMO it's worth taking a look at PG notify/listen and keeping it in mind for simple use cases. It's not nearly as powerful but it can be a pretty good starting point before pulling in more dependencies. reply cchance 9 hours agorootparentprevAre you running your own websocket server or just spinning up soketi in a container? reply zoriya 9 hours agorootparentFor now, I'm not doing anything, websocket is next-release big change. I did not know about soketi tho, i'll take a look. reply eyegor 7 hours agorootparentIf you're in dotnet land, I'd recommend looking at magic onion [0] or memorypack [1]. It'll be much nicer to work with once you have a decent pile of message types. Otherwise it's easy to end up in an entity framework like situation where you're constantly serializing and deserializing, generating serializer wrappers, doubling up on dtos and schemas, etc. Although any of the cysharp libs are great in dotnet, definitely recommend checking out their back catalogue. [0] https://github.com/Cysharp/MagicOnion [1] https://github.com/Cysharp/MemoryPack reply roomey 14 hours agoparentprevRabbit mq is great. I found it particularly useful when some parts of a program are inherently slower than other parts. It offers a very robust and tested queuing system, and is pretty tiny to run. It lets you keep things very simple. reply NortySpock 14 hours agorootparentHow tiny is \"pretty tiny\" in your opinion? I've been playing around with NATS, which is hovering at just under 10MB of RAM on each of 3 nodes, while passing an average of 1 message per second. I am liking it, though NATS clearly has a less strict queue ordering policy when I throw a burst of messages at it. Edit: actually another node is at 22MB, so take what you will from that. reply jwells89 16 hours agoprevLooks nice. One thing I’ve noticed is that media server projects seem to have a disposition towards C# specifically, which I find interesting. Is there a technical reason for this or is more of a big project setting norms situation? reply kyriakos 16 hours agoparentMost related software too (the *arr family) are written in .net. It's a decent platform offers good performance without sacrificing developer experience. reply zoriya 14 hours agoparentprevc# shines for webserver stuff so it's no wonders, I like it less and less tho Kyoo also uses python/golang for some of it's components (and typescript for the frontend) reply CBarkleyU 13 hours agorootparent> I like it less and less Would you mind eloborating? reply zoriya 12 hours agorootparentI don't like the closed environment where you are not a first-class citizen if you are not using vs or rider. I always work on vim and linux, and I am getting tired of fighting with whatever new stuff microsoft makes that does not work out of the box (their latest LSP that does not follow the spec they created themselves as my latest example). reply Rohansi 3 hours agorootparentIt's not at all a closed environment though? You can live entirely on the command line if you wanted to and that's a fully supported workflow. reply HumblyTossed 16 hours agoparentprevThis one looks like it's written in several different languages. I see some C#, Go, Python. Maybe there's some front end stuff too, but I'm allergic to that. reply jzb 9 hours agoprevPity that they don’t handle music. That’s my primary use of Plex: managing a music library. I feel like that’s a secondary focus for Plex, too, but it’s good enough. reply aloer 14 hours agoprevJust the other day I was setting up Jellyfin and tailscale on an n100. It worked fine locally but sharing via tailscale with a family member across the world somehow broke things. It took about a minute for the stream to start despite a fast enough upload speed. Might be ping related? I will give this a try reply napkin 11 hours agoparentI had this problem too! Jellyfin behind a reverse proxy over Wireguard. For intercontinental visitors (high latency), there would be an initial burst of reasonable transfer speed, but within seconds, slow to an unusable crawl. It took a long time to identify the problem as relating to packet congestion. Try changing Linux's default congestion control (net.ipv4.tcp_congestion_control) on your Jellyfin & reverse proxy servers to 'bbr'. I don't understand the details- there might be negative consequences [1]- there might be better congestion algos- but for me, this completely solved the issue. Before, connections would stall out toseek effortlessly without waiting for the transcoder Depending on the container and codec this was always an issue. How did you solve that problem? are you not using libav? reply SamuelAdams 15 hours agoprevWhat sort of audio formats does this direct play? My biggest complaint with JellyFin is that it can’t play Dolby DDD+. reply zoriya 15 hours agoparentIt can direct play whatever your client supports, for now only android and web are supported clients. Web browsers aren't great with media compatibility tho, I think you will face the same limitations as with Jellyfin. reply Daunk 14 hours agoprevMy issue, going from Plex to anything else, is that it would render things like my AppleTV useless. reply resfirestar 10 hours agoparentJellyfin is compatible with the Infuse media player on Apple TV. I don't have one but have used it on other Apple things and love it, it's actually a bigger issue with Windows because I haven't found anything nearly as good on Windows as Infuse is on Mac. reply hamandcheese 8 hours agorootparent+1 for Infuse! But it only direct streams, so it's not the best if you want to stream over WAN. reply traviswt 13 hours agoparentprevI've had mostly a positive experience with Jellyfin on AppleTV. Have you tried it? Curious what's considered a dealbreaker for you. reply Kerbonut 5 hours agoparentprevJellyfin has an Apple TV app called Swiftfin. It works decently well. reply kayson 6 hours agoparentprevJellyfin has a decent roku app reply bunnyfoofoo 17 hours agoprevIt's very pretty, and the demo is very fast. Is there series tracking to continue watching to pick up where you left off? It doesn't seem like there is on the demo. My only concern is that your screenshots on the github include copyrighted movies. I know that unlike popcorn time (or whatever the name was), it's only a player and not a way to download things, but maybe change them out for your copyright-free movies on the demo? I'd hate to lose another project to overzealous copyright enforcement. reply zoriya 14 hours agoparentThere is a series tracking (which can be autosynced to simkl if you want) but you need to login to use it. Since the demo allow you to access everything as a guest without account you probably missed it. The screenshots are pushed on a secondary branch, so I can remove them completely without rewriting the git history. Thanks for worrying , this is cool and I will be playing with it tonight. ETA: I have no doubt that some people might be able to figure out the specific individual in this story, and that's fine, but I humbly ask that you do not post that person's name publicly here. I wasn't fired from Apple and I didn't have to sign a non-disparagement clause as far as I am aware, but I still don't want any extra drama from the company. reply craftkiller 13 hours agoparent> since I was working for Apple they legally owned it anyway IANAL but I think they were lying to you. CA law protecting your after-hours code from your employer: https://law.justia.com/codes/california/2011/lab/division-3/... NY law doing the same thing: https://casetext.com/statute/consolidated-laws-of-new-york/c... reply RajT88 14 hours agoparentprev> I still don't want any extra drama from the company Yeah, they are really good at that. I had a friend discover a vulnerability once, and behind the scenes they took it very seriously. But publicly, they disparaged him mercilessly and even got DaringFireball in on it. (Yes, he takes Apple money; of course he does) reply xyst 10 hours agoparentprevYou got the Jon Stewart treatment when Apple execs tried to suppress the segments on “AI” and “China”. This company is completely ruined for me. Feels disgusting to have dumped nearly 6 figures into this company across a decade. (this includes hardware, software, media, “App Store” purchases, merch, services, phones, music players) It’s not much to the bottom line but to me I was in deep. reply BeetleB 5 hours agorootparent> This company is completely ruined for me. BTW, OP's anecdote is how it's always been at Apple. Definitely in the early 00's, and probably all the way back to the 80's. I've known a bunch of great open products die because the person behind them got a job at Apple and was not allowed to work on it while employed. reply acangiano 9 hours agorootparentprevI'm getting less and less impressed with the company, so I started diversifying. I got Linux installed on my desktop and started using it more often. Switched from Apple Music to Spotify. Got rid of my Apple Watch Ultra and switched to Garmin. Went from Things to TickTick since it's cross platform. From Notes to Notesnook for the same reason. I know it's a drop in the bucket and I'm still pretty invested, but they are steps towards independence should I decide to abandon their ecosystem altogether at some point. reply _factor 13 hours agoparentprevEven the FTC commissioner can’t get air time. As far as Apple is concerned, an informed public is competition with Apple. reply therealfiona 14 hours agoparentprevThat sucks dude, I'm sorry. I mean, I get it from the company's perspective. They have a product that serves video, you were building a thing that served video. The thing that irks me is that since they build multiple operating systems and a wide range of software, literally anything you write and publish on the public internet is theirs simply because they will fire you and sue you into oblivion. Even if you _technically_ slip through a loop hole, they have more money and time than you do. Stories like this remind me that I have to be careful about who I work for, the scope of that work, and where I publish it. Thankfully, I think I'm in the clear as long as I don't invent a thing that solves the traveling salesman problem. reply tombert 3 hours agorootparentI personally don’t really think Plex/Emby/Jellyfin are really “competing” with Apple. Jellyfin and the like require a geeky person to maintain and supply video files of their own, Apples products are easy and streamlined by design. They’re superficially kind of similar but, like, depending on how abstract we wanted to get we could basically say that anything is competitive with anything e.g. “Your product has text, and we sell books that contain text, so it’s competitive” Regardless, I guess what they said worked, because despite me not having worked for Apple for more than three years now, I still don’t want to open source I am still a bit worried about being sued (especially since I didn’t leave on the best of terms with them). That said, my current job is much more reasonable about this stuff (and also much more domain-focused), so maybe I’ll be able to dust off my public GitHub again some day. (Again, I am sure you can figure out which company I work at (I have public profiles) but I ask that you don’t post it here.) reply user- 16 hours agoprevThe readme was obviously written with a LLM and it makes it so hard to read. High word count isnt a good thing reply tdhz77 16 hours agoparentI didn't catch this until you called it out. While I reading I was anticipating an argument that would convince me that I need Kyoo. I'm not convinced that its setup once and forget it -- especially since it also says that its not afraid of adding more services (complexity). Further, the hard stance on cinema only instead of books, games, etc made me think that the project was rigid. Making me potentially add more services to manage all of my entertainment media. reply zoriya 14 hours agorootparentAs a user, you don't really need to care about the number of containers since everything is managed by docker-compose or k8s (soon). The advantages of having more containers is that you can have specialized softwares. For example, the search system is based on meilisearch which makes it way better than what could have been done by just using postgres/sqlite. It also makes distribution or replication built-in (for example, to have a transcoder on a remote computer), jellyfin/plex does not support this natively and users have written their own remote transcoder for that. reply seabrookmx 11 hours agorootparentOnly half kidding, but you've heard of processes right? :) Plex for example starts many transcoder instances within a single container for scalability. You don't _need_ to scale at the container level. There's pros and cons to each approach, but for the self-hosting crowd keeping the deployment simple may broaden your audience. A good example I have experience with is vaultwarden: people use it because it's a single container deployment as opposed to the complex and resource intensive setup bitwarden provides. reply freedomben 14 hours agorootparentprevAre you planning to run these containers in the same Pod? And/or what is the deployable unit going to be? reply zoriya 14 hours agorootparentNot sure yet, I'm a beginner at k8s and just started writing a helm chart on a branch/reading the documentation. I have devops friends to help me with my skill issues tho x) reply hoherd 15 hours agorootparentprevI was also surprised by that bit about adding more services: > We're not afraid to bring in additional containers when it makes sense That is one of the last things I'm thinking about when I choose a media organization and streaming app, and if I do think about it, having more containers is a red flag more than something that sets my mind at ease, because of that added complexity. I experienced this with Photoprism when I wanted to customize it a bit, because I then had to figure out the roles of the containers and which containers did and did not need the customization bits I was adding, etc.. reply zoriya 15 hours agoparentprevYou're right, but in today's github if you want to stand out you need this kind of readme or an existing community. To be fair, the important features are in bold and the philosophy/why another browser is handwritten. reply n3storm 15 hours agoprevWhy some many self-hosted mediabrowsers written on C#/Mono? (honest question) reply giancarlostoro 15 hours agoparentBecause it's a great programming language, not sure about Mono, but .NET 8+ is now cross-platform (has been since sometime in 2016 actually), so I personally am choosing C# for some of my projects lately as a result. C# is just a nice all-around language and the runtime is really nice. By comparison every time I have to look at Java I just want to run away as quickly as possible. All the resources Oracle has, and instead of investing them into making Java a viable platform they shut down the one project that was giving Java an edge in Desktop Development (JavaFX) and basically leave Java in this weird limbo state its in. It took Java forever to implement lambdas meanwhile C# had them in since .NET 3.5? (2007?) Microsoft on the other hand, made all of .NET MIT licensed. Even if they change the license 10 years from now, you can pick any of the rich versions prior to use where the license was in fact MIT. reply Jochim 13 hours agoparentprevJust my own conjecture, but it's pleasant to write, the NuGet package ecosystem is very well populated, and it combines a great web framework with the ability to drop down into low level code when necessary. In recent years cross platform support has gotten fairly good as well reply imran-iq 12 hours agoparentprevI think (and I could be misremembering here) is that Emby started off as C# and both Plex and Jellyfin are forks of it. Also a lot of folks in this sphere seem to be on windows as their primary platform, and C# along with visual studio is pretty on that stack reply seabrookmx 11 hours agorootparentPlex is a C++ app and actually a fork of XBMC/Kodi, although that was so long ago there's probably no resemblance. Jellyfin is an Emby fork though, yes. reply seabrookmx 11 hours agoparentprevMono is basically dead. This uses dotnet 8[1] which is cross platform (has been since 5.x and \"core\" 1.x-3.x). [1]: https://github.com/zoriya/Kyoo/blob/master/back/Dockerfile#L... reply n3storm 13 hours agoparentprevbut there aren't as many IDEs, NAS/homelab manager, backup, games, graphic editing or visualization tools, ... Is it something about codecs availability? reply neodymiumphish 17 hours agoprevI’d be interested to know the status for the player apps on various platforms. For example, this is a nonstarter for me until it supports Google TV and iOS/iPasOS. reply candiddevmike 17 hours agoparentThis is unfortunately a deal breaker for most home grown media browsers. They need to maintain apps on all the walled gardens their users are using, which is a ton of work IME. reply jwells89 16 hours agorootparentCouldn’t this be addressed by standardizing around a protocol? That way client and server are decoupled and existing clients can work with new media server projects. reply djbusby 16 hours agorootparentLike if my TV could just open the webpage of my in-home media server and let me browse and play. reply jwells89 15 hours agorootparentWell maybe, but smart TV and streaming box browsers are unlikely to implement all the functionality pertinent to a high-grade home theater experience. Apps are better here, so what I had in mind was closer to standardization around existing popular protocols like that currently used by Kodi and Plex, both of which have high quality clients for just about every platform out there. reply jsf01 15 hours agorootparentprevThere is some interoperability between other clients today. For example, I have a Jellyfin server but in order to connect to it on my Apple TV I use the Infuse Pro app. I think that works more because of a standardized file structure that each app creates its own indexes for, so an actual protocol that they share would still be an improvement. reply zoriya 14 hours agorootparentInfuse implemented code specifically for jellyfin and it uses jellyfin's own API. The only common protocol is dlna, but it's pretty limited and only really used on local networks. reply oarsinsync 14 hours agorootparentHow insane would it be to expose a jellyfin compatible api? reply zoriya 13 hours agorootparentThat would slow down development and new idea down a lot, I don't think it's even worth considering. It's probably easier to implement it on Kodi/Infuse/any other clients. reply oarsinsync 18 minutes agorootparent> It's probably easier to implement it on Kodi/Infuse/any other clients Yep, it's definitely easier to get third party clients to implement your protocol. Kodi you can write your own plugins for, Infuse... requires their devs to care about your implementation. Chicken, meet egg? That said, I also fully admit I have no knowledge of your codebase, nor any knowledge of how extensive / complicated the jellyfin (or any other comparable media server) client api looks like, and I assume you have a better idea! Best of luck with this! I hope it succeeds! reply petepete 15 hours agorootparentprevIs that not what DLNA is? reply jwells89 15 hours agorootparentKind of, but as I understand it’s pretty barebones and can’t support an experience like that provided by Plex. reply zoriya 14 hours agoparentprevAndroid and web only for now. I do agree that Google tv/chromecast is extremely important. ios/ipad/tvos is even harder since it's 100$ a year for a dev account to push it to the apple store and I don't own an apple device to write the app. I want to focus on features before writing more clients, I hope to write Chromecast support in less than 6 mounts and google tv in less than a year. reply unstatusthequo 13 hours agorootparentI'm sure there's enough interest on HN to cover the $100 for a dev account for you and maybe get you a reasonable device to test on from Swappa. Maybe setup a donation link for an iOS/tvOS app? I think iOS/tvOS app would really make usage increase dramatically. People generally aren't against paying for software that works and makes things easier. Plex has become bloated and over-featured. Infuse is ok, but not great when trying to watch remotely, even over TailScale. reply zoriya 12 hours agorootparentI do agree about the value of tv/native apps but for now I have a tiny user base, we are only 20 on the discord. I think it's still too early to have any kind of financial support on the project. reply wccrawford 16 hours agoparentprevLooks like there's a kyoo.apk in the latest release, and I see the source in the 'front' directory. I see IOS stuff in the config in there, too. reply kayson 6 hours agoprevGreat to see more competition in this space. I found it interesting that every component seems to be written in a different language. The only one that surprised me a bit was the backend in c# instead of go or node/deno. A bit odd for the scanner to be in python too... reply grobibi 17 hours agoprevI would like to switch from Infuse to open source but I can't go back to transcoding. Does anything have feature parity with this? https://firecore.com/infuse reply pocketarc 17 hours agoparentThat looks -very- nice. What's your experience been with it, do you use Plex or anything like that? What do you mean 'can't go back to transcoding'? What have you been using that doesn't transcode? reply simongr3dal 16 hours agorootparentI’m using Infuse as well, and it’s pretty amazing. The main thing that Infuse does differently from all the others is that it always does Direct Play (in Plex parlance) so you don’t need anything powerful or power hungry to be hosting the video. Most devices that will play video these days are powerful enough to do the decoding themselves and have the bandwidth available. reply Latty 15 hours agorootparentI use Jellyfin and it defaults to direct play unless you need transcoding (e.g: the client device doesn't support the chosen format, Firefox with h265 for example, due to licensing) and it will just remux if the container is the only issue. The desktop client just uses mpv so it supports basically everything directly. reply jwells89 16 hours agorootparentprev> Most devices that will play video these days are powerful enough to do the decoding themselves and have the bandwidth available. IME this varies a lot between devices. Google TV dongles for example, even the 4K versions, are built with extremely weak SoCs (as in early 2010s phone weak) and lean hard on hardware acceleration. If you want to play back a format that isn’t hardware accelerated on one of these, you’ll have to rely on media server transcoding. reply HumblyTossed 16 hours agorootparentprev> does differently from all the others You can tell Emby and Jellyfin to direct play. Pretty sure Plex has that option, but I've not used it in a few years so could be that changed. reply unstatusthequo 13 hours agorootparentprevYes but Infuse over your whatever VPN back to your NAS/source is the issue. That's where transcoding at source shines. Infuse is great for LAN though. reply voltaireodactyl 16 hours agorootparentprevInfuse offloads transcoding to the client device, so you can use a low powered NAS with an appleTV for example. reply jwells89 16 hours agorootparentIt can also direct play a lot of formats too though, because Apple TV boxes since the 2017 4K model have enough muscle for problem free software decoding. reply mvanbaak 16 hours agorootparentprevand this is both nice and horrible. Most audio streams are 'direct stream' when you use plex/jf/emby as backend, but your receiver/soundbar only gets the PCM stream, without any object data (yes, you loose atmos, not that it is a lot of loss when using a soundbar, but if you have atmos speakers in your ceiling you want that data) in an ideal world, the appletv will simply passthrough the audio upstream, so you receiver can do what it does best. reply kiririn 16 hours agoparentprevKodi + Jellyfin-Kodi reply tdhz77 16 hours agorootparentKodi is my favorite open source project, but I did start it up the other day and thought it felt outdated. I will look into Jellyfin-Kodi. Using Kodi's Games/eBooks/Podcast playing ability with Jellyfin (Streaming, transcoding) features might be exactly what I've been missing. reply xyst 10 hours agoprev [3 more] [flagged] zoriya 9 hours agoparent [–] Classic rust fan :p I tried to write the transcoder in rust before rewriting it in rust. You can call that skill issue, but I did not like the language and needed a rewrite because I was taking a fundamentally broken approach anyway. reply input_sh 3 hours agorootparent [–] > I tried to write the transcoder in rust before rewriting it in rust. I'm assuming you meant to say you re-wrote it in Go. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The individual started developing Kyoo almost 5 years ago out of frustration with current solutions, which they found inadequate.",
      "Originally just a project for learning, Kyoo gradually transformed into a more substantial undertaking as time passed."
    ],
    "commentSummary": [
      "The comparison of media server software like Plex, Jellyfin, and Kyoo is discussed, addressing metadata, file organization, user-friendliness, and monetization strategies.",
      "User experiences and discussions cover features, functionalities, technology tools, programming languages, media player apps, copyright concerns, and container management in a media setup.",
      "Emphasis is placed on cross-platform support, standardization, and interoperability for an enhanced home theater experience, with users showing enthusiasm for the new platform Kyoo and its potential advancements for other devices."
    ],
    "points": 205,
    "commentCount": 148,
    "retryCount": 0,
    "time": 1712317795
  },
  {
    "id": 39944275,
    "title": "Challenges and Solutions in Compiling Fortran Code for WebAssembly",
    "originLink": "https://gws.phd/posts/fortran_wasm/",
    "originBody": "Fortran on WebAssembly hacks wasm fortran programming Patching LLVM Flang to output WebAssembly objects. Author George Stagg Published March 12, 2024 Thumbnail by Mike Hindle. Digit classification with machine learning, running in the browser using BLAS routines compiled to WebAssembly. Introduction Fortran1 is one of the oldest programming languages around. It first appeared in 1957, making it older than the C programming language, the Intel 4004 CPU, and even the IBM System/360 series of mainframe computers2. Fortran was created at a time when the byte had just been invented, and computers were still made of vacuum tubes and frustration. 1 The name is derived from Formula Translator. Fortran was originally stylised in all-caps, but modern Fortran has dropped it. 2 The System/360 was released around 1965. The 4004 around 1970. And K&R C was published in 1978. 3 The argument goes that Fortran’s lack of aliasing and use of native arrays rather than pointer arithmetic allow the optimiser to generate more efficient output than an equivalent C program. However, there are also counter-arguments against this. Over the years, Fortran has formed a rich history of use for computationally intensive scientific and engineering applications. It has powered the fluid dynamics of weather prediction and climate models, provided the condensed matter simulations for my PhD, and is still considered by some to be more efficient than C for numerically heavy work3. The syntax of modern Fortran is also surprisingly easy to get up and running with. This is not your parent’s Fortran 77 code; most restrictions that make fixed‑form Fortran awful to use are no longer in place in modern Fortran. In a clash of computational eras, this blog post is about compiling existing Fortran code for WebAssembly so that it can run in a web browser. I’ll describe the method we currently use for the webR project, compiling Fortran code using a patched version of LLVM’s flang-new compiler4. The post also serves as a request for help. The method I describe unfortunately relies on a hack, and this hack means that I cannot contribute the changes back to LLVM without assistance from a more experienced compiler developer. 4 “LLVM” is not an acronym, it is the full name of the project. So, what’s the problem? There are a surprising number of potential methods and toolchains available to compile Fortran to WebAssembly. Unfortunately, none of the available options are feature complete. Each method has its drawbacks, and none are a simple plug-and-play solution. Back in 2020, the situation was summarised wonderfully by Christoph Honal’s article FORTRAN in the Browser. Even now, the article is worth reading and provides a nice background for this post. I personally owe a lot to Christoph’s article, particularly for its description of the Dragonegg toolchain. Without that article, I would have given up on Fortran for WebAssembly a long time ago. Our goal by the end of this post is to be able to compile a modern Fortran routine to WebAssembly that takes in some numerical arguments, computes the output of BLAS and LAPACK routines5, and either returns the result or prints it to console. From what I remember, in 2020 none of the methods outlined in Christoph’s article could do this satisfactorily. Dragonegg and f2c both get close but have some drawbacks, as I’ll describe below. 5 LAPACK (Linear Algebra Package) is a popular library of routines used to numerically solve problems in linear algebra. It’s written in Fortran 90 and itself relies on a BLAS (Basic Linear Algebra Subprograms) library. 6 via Pyodide and webR. Together, BLAS and LAPACK routines provide a powerful numerical platform. Running them in the browser opens the door for several higher-level programming environments that rely on them under the hood, such as SciPy or R6. The beauty of this approach is that it allows you to bring existing and extensively battle-tested tools and libraries to the web without having to rewrite them all in Rust or JavaScript. Later, I’ll show an example of this with a machine learning demo that directly uses BLAS routines compiled from Fortran to WebAssembly. Rather than having to write fiddly linear algebra numerical algorithms in JavaScript, we can use reliable and efficient BLAS routines directly7. 7 Whilst running machine learning algorithms in a web browser will never be as efficient as using dedicated hardware, such as a GPU, I still think it’s a fun demo. Compiler round-up Since FORTRAN in the Browser was published things have changed a little, particularly when it comes to the LLVM-based Fortran compilers. As far as I am aware, here’s a brief round-up of the current situation in 2024. The f2c utility The f2c program converts Fortran 77 to C code, which Emscripten can then compile into WebAssembly. This is the method that the Pyodide project uses to compile Python packages containing Fortran code. They say that this “does not work very well”. The tool doesn’t work with modern Fortran code, and even after conversion the result still throws fatal errors and requires extensive patching. LFortran The LFortran compiler has made great strides over the last few years. In 2020, it was missing a lot of features and only supported a very small subset of Fortran. Now it now supports a much wider range of language features and can be used to compile a reasonable amount of Fortran code. It can even compile to WebAssembly out of the box!8 8 Check out the LFortran demo at https://dev.lfortran.org. While extremely impressive, note that the first thing I tried was changing x ** 2 to x ** 3 and saw that such a change is currently not supported by the code generator. However, there are still some barriers that make using LFortran a little rough. The project is currently considered to be in alpha phase and the developers state that issues compiling real-world code are expected. While it can successfully compile some projects, such as MINPACK, the full Fortran specification is not yet supported and so many larger projects still cannot be compiled. The LFortran developers are targeting full support for Fortran 2018, and its standout feature is an interactive Jupyter-like Fortran REPL. With a few more years of development, I expect that LFortran will be an excellent choice for compiling Fortran code for WebAssembly. Dragonegg Dragonegg is a plugin for GCC that uses the GNU compilers as a frontend and emits LLVM IR. With this, LLVM can be used as the backend to produce WebAssembly output. The technique works, and it was the original method that I used to compile Fortran sources for the webR project. However, there are some pretty serious drawbacks to this approach. Dragonegg requires a very old version of GCC and LLVM9. For most users, this means setting up a virtual machine or Docker container to provide the necessary environment. The LLVM IR emitted by Dragonegg also needs some fairly nasty post-processing before LLVM can produce WebAssembly output. Take a look at the script originally used by webR to get an idea of the extra processing required. 9 The latest supported versions are gcc-4.8 and llvm-3.3 Nevertheless, in 2020 this was the only real way to compile Fortran code for WebAssembly. Classic flang “Classic” Flang10 is another Fortran compiler targeting LLVM, based on an open-sourced PGI/NVIDIA compiler pgfortran. Classic Flang never supported 32-bit output, so it is not an option for us since we’ll be using wasm32 for our target architecture. This will likely be the case until browser support for 64-bit Wasm memory has improved11. 10 Previously, Flang or Flang-7. 11 At the time of writing Firefox, Chrome and Node supports wasm64, but locked behind a feature flag. Even so, the project documentation itself suggests that choosing to use Classic Flang for a new project today is probably not a great idea: Classic Flang […] continues to be maintained, but the plan is to replace Classic Flang with the new Flang in the future. LLVM Flang “LLVM Flang”12 is a full ground-up reimplementation of a Fortran frontend for LLVM. It was designed to replace Classic Flang, developed by much of the same team, and was accepted as part of the LLVM project as of LLVM 11. As such, the Flang sources can now be found in the official LLVM source tree. 12 Also known as Flang, new Flang, or flang-new. Previously, F18. Flang is not yet considered to be ready for production use, but its development is extremely active right now and pre-production versions of the flang-new compiler have been made available by the team. In recent years, the compiler has become very usable for compiling real-world Fortran code. Currently, LLVM Flang cannot generate WebAssembly output out of the box. Despite this, we’ll soon see that with LLVM’s modular design it’s possible to use the Flang frontend with LLVM’s WebAssembly backend. With this, we can take advantage of all the development work put into the Flang frontend by the NVIDIA and PGI teams for our own purposes of compiling Fortran to WebAssembly. This was also possible back in 2020, though it required larger patches to LLVM, injecting custom maths routines, and a multi-step compilation process. Now, due to the impressive development efforts in the flang-new frontend, creating a Fortran to WebAssembly compiler is possible with just a few small changes to LLVM’s source code. Building and using LLVM Flang for WebAssembly If one were interested in trying out LLVM Flang, they might grab an LLVM release using their package manager of choice. However, following that route will disappoint us, as a flang-new binary is not included13. 13 At least, not with LLVM v17.0.6 for macOS using brew. [~/fortran]brew install llvm ==> Downloading https://formulae.brew.sh/api/formula.jws.json ################################################################################ 100.0% ==> Downloading https://ghcr.io/v2/homebrew/core/llvm/manifests/17.0.6_1 ################################################################################ 100.0% ==> Fetching llvm ==> Downloading https://ghcr.io/v2/homebrew/core/llvm/blobs/sha256:8d739bdfa4152 ################################################################################ 100.0% ==> Installing llvm ==> Pouring llvm--17.0.6_1.arm64_sonoma.bottle.tar.gz ==> Summary 🍺 /opt/homebrew/Cellar/llvm/17.0.6_1: 7,207 files, 1.7GB ==> Checking for dependents of upgraded formulae... ==> No broken dependents to reinstall! [~/fortran]flang-new zsh: command not found: flang-new Since we will be modifying the LLVM Flang source in any case, we’ll have to compile from scratch. Let’s grab the LLVM v18.1.1 sources and start there instead. Feel free to follow along at home; I’ll try to provide all the commands and everything you need.14 14 I’m going to assume you’re familiar with Emscripten and have a version of that toolchain on your path. If not, and you want to play along, start with emsdk to setup Emscripten on your machine, get comfortable with compiling C code for WebAssembly, then return here to continue. [~/fortran]git clone --depth=1 --branch=llvmorg-18.1.1 https://github.com/llvm/llvm-project.git Cloning into 'llvm-project'... remote: Enumerating objects: 138937, done. Receiving objects: 100% (138937/138937), 199.81 MiB11.36 MiB/s, done. Note: switching to '6009708b4367171ccdbf4b5905cb6a803753fe18'. Updating files: 100% (132077/132077), done. [~/fortran]cmake -G Ninja -S llvm-project/llvm -B build \\ -DCMAKE_INSTALL_PREFIX=llvm-18.1.1 \\ -DCMAKE_BUILD_TYPE=MinSizeRel \\ -DLLVM_DEFAULT_TARGET_TRIPLE=\"wasm32-unknown-emscripten\" \\ -DLLVM_TARGETS_TO_BUILD=\"WebAssembly\" \\ -DLLVM_ENABLE_PROJECTS=\"clang;flang;mlir\" -- The C compiler identification is AppleClang 15.0.0.15000100 -- Found assembler: /Library/Developer/CommandLineTools/usr/bin/cc -- Detecting C compiler ABI info - done -- Performing Test HAVE_POSIX_REGEX -- success -- Configuring done (29.0s) -- Generating done (2.9s) -- Build files have been written to: fortran/build [~/fortran]cmake --build build ... [6136/6136] Linking CXX executable bin/obj2yaml Grab a cuppa15, this step uses a lot of resources and can take a very long time. 15 cuppa (/ˈkʌp.ə/): noun, informal, UK. A hot drink, usually tea or coffee. Interlude — Calling Fortran subroutines from C While we wait for LLVM to build, start up a new terminal and we’ll remind ourselves how to compile and link a Fortran subroutine as part of a C program. The principles here will help us later when it comes to calling Fortran from JavaScript. First, let’s write a simple subroutine that takes in three integer arguments: x, y, and z. It will set the value of z to the sum of x and y. Name our new subroutine foo and save the file containing your subroutine as foo.f08. foo.f08 SUBROUTINE foo(x, y, z) IMPLICIT NONE INTEGER, INTENT(IN) :: x, y INTEGER, INTENT(OUT) :: z z = x + y END Notice how, generally, Fortran routines pass arguments by reference and we can declare how an argument will be used in the subroutine using INTENT(). Assuming you already have a traditional Fortran compiler like gfortran installed16, compile the Fortran source into an object file. 16 You don’t need a native fortran compiler to follow along with the rest of the post, but if you’d like one you can get gfortran from your OS’s usual package manager as part of the GCC compiler suite. There’s also ifort, if you’re on an Intel CPU. [~/fortran]gfortran -c foo.f08 -o foo.o [~/fortran]file foo.o foo.o: Mach-O 64-bit object arm64 [~/fortran]nm foo.o 0000000000000038 s EH_frame1 0000000000000000 T _foo_ 0000000000000000 t ltmp0 0000000000000038 s ltmp1 I’m on an M1 macOS machine, so my resulting object is a Mach object for ARM. If you’re a Linux user, you should see something like ELF 64-bit LSB shared object, x86-64. I’ve also run nm to take a look at the names of the symbols in the object that the compiler has built. Keep an eye on the symbol for our subroutine — on my machine it’s named _foo_. The leading underscore is fairly standard, but the trailing underscore differs from what is usual for C procedures. Let’s write a C program that calls our Fortran subroutine17. Notice again how we pass the arguments by reference to the external symbol. Also, if your Fortran compiler added the trailing underscore, we’ll need to include it when we declare the symbol name in C. 17 Modern Fortran standards provide a Fortran module iso_c_binding and a C header file ISO_Fortran_binding.h to improve C interoperability, but our code is going to be simple enough that we can do without those today. main.c #includeextern void foo_(int*, int*, int*); int main() { int x = 1, y = 1, z; foo_(&x, &y, &z); printf(\"%d + %d = %d\", x, y, z); return 0; } Compile the C source using gcc or equivalent, and then run the resulting binary to observe a truly staggering level of numerical computation. [~/fortran]gcc main.c foo.o -o main [~/fortran]./main 1 + 1 = 2 Returning to LLVM Flang Once LLVM has finished compiling, the flang-new binary should be available in the directory build/bin. We can now run it and confirm that it has been set up to produce binaries for wasm32 and Emscripten. [~/fortran]./build/bin/flang-new --version flang-new version 18.1.1 (https://github.com/llvm/llvm-project.git dba2a75e9c7ef81fe84774ba5eee5e67e01d801a) Target: wasm32-unknown-emscripten Thread model: posix InstalledDir: .../fortran/build/bin Great! Let’s try compiling our Fortran subroutine using our freshly built compiler. [~/fortran]./build/bin/flang-new -c foo.f08 -o foo.o error: fortran/llvm-project/flang/lib/Optimizer/CodeGen/Target.cpp:1162: not yet implemented: target not implemented LLVM ERROR: aborting Ah, not so great. The wasm32-unknown-emscripten target triple unfortunately hasn’t been implemented yet in the flang-new compiler. And so here comes our first patch to LLVM. We will implement the target by extending Flang’s list of known target specifics. The required changes, shown below as a diff, can be mostly deduced by looking at the other targets implemented in the file flang/lib/Optimizer/CodeGen/Target.cpp. diff --git a/flang/lib/Optimizer/CodeGen/Target.cpp b/flang/lib/Optimizer/CodeGen/Target.cpp index 83e7fa9b440b..49e73ec48e0a 100644 --- a/flang/lib/Optimizer/CodeGen/Target.cpp +++ b/flang/lib/Optimizer/CodeGen/Target.cpp @@ -1109,6 +1109,44 @@ struct TargetLoongArch64 : public GenericTarget { }; } // namespace +//===----------------------------------------------------------------------===// +// WebAssembly (wasm32) target specifics. +//===----------------------------------------------------------------------===// + +namespace { +struct TargetWasm32 : public GenericTarget { + using GenericTarget::GenericTarget; + + static constexpr int defaultWidth = 32; + + CodeGenSpecifics::Marshalling + complexArgumentType(mlir::Location, mlir::Type eleTy) const override { + assert(fir::isa_real(eleTy)); + CodeGenSpecifics::Marshalling marshal; + // Use a type that will be translated into LLVM as: + // { t, t } struct of 2 eleTy, byval, align 4 + auto structTy = + mlir::TupleType::get(eleTy.getContext(), mlir::TypeRange{eleTy, eleTy}); + marshal.emplace_back(fir::ReferenceType::get(structTy), + AT{/*alignment=*/4, /*byval=*/true}); + return marshal; + } + + CodeGenSpecifics::Marshalling + complexReturnType(mlir::Location loc, mlir::Type eleTy) const override { + assert(fir::isa_real(eleTy)); + CodeGenSpecifics::Marshalling marshal; + // Use a type that will be translated into LLVM as: + // { t, t } struct of 2 eleTy, sret, align 4 + auto structTy = mlir::TupleType::get(eleTy.getContext(), +mlir::TypeRange{eleTy, eleTy}); + marshal.emplace_back(fir::ReferenceType::get(structTy), + AT{/*alignment=*/4, /*byval=*/false, /*sret=*/true}); + return marshal; + } +}; +} // namespace + // Instantiate the overloaded target instance based on the triple value. // TODO: Add other targets to this file as needed. std::unique_ptr @@ -1158,6 +1196,9 @@ fir::CodeGenSpecifics::get(mlir::MLIRContext *ctx, llvm::Triple &&trp, case llvm::Triple::ArchType::loongarch64: return std::make_unique(ctx, std::move(trp),std::move(kindMap), dl); + case llvm::Triple::ArchType::wasm32: + return std::make_unique(ctx, std::move(trp), +std::move(kindMap), dl); } TODO(mlir::UnknownLoc::get(ctx), \"target not implemented\"); } Save the contents of the above diff as the file add-wasm32-target.diff, and then apply it to the llvm-project directory using git or the patch utility. Then, rebuild LLVM Flang. It should be quicker to build the second time, as most generated objects are unaffected by the change. [~/fortran]patch -p1 -d llvm-project{ const x = Module._malloc(4); const y = Module._malloc(4); const z = Module._malloc(4); Module.HEAPU32[x / 4] = 123; Module.HEAPU32[y / 4] = 456; Module._foo_(x, y, z); console.log(\"x = \", Module.HEAP32[x / 4]); console.log(\"y = \", Module.HEAP32[y / 4]); console.log(\"x + y = \", Module.HEAP32[z / 4]); Module._free(x); Module._free(y); Module._free(z); }, 100); [~/fortran]node standalone.js x = 123 y = 456 x + y = 579 You should also be able to run the resulting WebAssembly binary in a web browser. Remove the line var Module = require('./foo.js'); from standalone.js, and instead load the script foo.js in your HTML. index.html Fortran Demo Spin up a local web server22, visit the page, and the same output should be seen in the browser’s JavaScript console. 22 Something like Rscript -e 'httpuv::runStaticServer()' or python3 -m http.server should work well. The Fortran runtime library: A journey to “Hello, World!” The ubiquitous “Hello, World!” test program is the usual way to introduce a programming language, but I didn’t introduce Fortran using such a program above. As you’ll see, that was for a good reason. Let’s see what happens when we try to build a “Hello, World!” subroutine in Fortran and call it from C. As before, we’ll compile the Fortran object using flang-new and use Emscripten to compile and link the C code. hello.f08 SUBROUTINE hello() IMPLICIT NONE PRINT *, \"Hello, World!\" END hello.c extern void hello_(); int main() { hello_(); return 0; } [~/fortran]./build/bin/flang-new -c hello.f08 -o hello.o [~/fortran]emcc hello.c hello.o -o hello.js wasm-ld: error: hello.o: undefined symbol: _FortranAioBeginExternalListOutput wasm-ld: error: hello.o: undefined symbol: _FortranAioOutputAscii wasm-ld: error: hello.o: undefined symbol: _FortranAioEndIoStatement emcc: error: 'wasm-ld -o hello.wasm [...] --no-entry --stack-first --table-base=1' failed (returned 1) The build failed due to some missing symbols. This is a consequence of a more general issue in that we have not yet compiled the LLVM Fortran runtime library for WebAssembly. There are a bunch of library symbols that we’re currently missing, including some functions that are required to print output!23 23 See LLVM Flang’s documentation for the nuts and bolts of the Fortran IO runtime library implementation. Luckily, the runtime library is written in C++ as part of the LLVM source tree at llvm-project/flang/runtime. So, in principle, all we need to do is build the library using Emscripten’s em++ compiler and then link to it whenever we’re using Fortran code in our WebAssembly program. Here is a Makefile designed to make this step easy. Save it24 in the current directory and then run make. It should go ahead and use the version of Emscripten on your path to build a static Fortran runtime library at build/flang/runtime/libFortranRuntime.a. 24 Be sure to indent the rules in this file using tabs, not spaces. Makefile ROOT = $(abspath .) SOURCE = $(ROOT)/llvm-project BUILD = $(ROOT)/build RUNTIME_SOURCES := $(wildcard $(SOURCE)/flang/runtime/*.cpp) RUNTIME_SOURCES += $(SOURCE)/flang/lib/Decimal/decimal-to-binary.cpp RUNTIME_SOURCES += $(SOURCE)/flang/lib/Decimal/binary-to-decimal.cpp RUNTIME_OBJECTS = $(patsubst $(SOURCE)/%,$(BUILD)/%,$(RUNTIME_SOURCES:.cpp=.o)) RUNTIME_CXXFLAGS += -I$(BUILD)/include -I$(BUILD)/tools/flang/runtime RUNTIME_CXXFLAGS += -I$(SOURCE)/flang/include -I$(SOURCE)/llvm/include RUNTIME_CXXFLAGS += -DFLANG_LITTLE_ENDIAN RUNTIME_CXXFLAGS += -fPIC -Wno-c++11-narrowing -fvisibility=hidden RUNTIME_CXXFLAGS += -DFE_UNDERFLOW=0 -DFE_OVERFLOW=0 -DFE_INEXACT=0 RUNTIME_CXXFLAGS += -DFE_INVALID=0 -DFE_DIVBYZERO=0 -DFE_ALL_EXCEPT=0 $(BUILD)/flang/runtime/libFortranRuntime.a: $(RUNTIME_OBJECTS) @rm -f $@ emar -rcs $@ $^ $(BUILD)%.o : $(SOURCE)%.cpp @mkdir -p $(@D) em++ $(RUNTIME_CXXFLAGS) -o $@ -c $>> defined as (i32, i32, i64) -> i32 in hello.o >>> defined as (i32, i32, i32) -> i32 in build/flang/runtime/libFortranRuntime.a(io-api.o) Success? Not quite. A warning is issued, letting us know about a signature mismatch. Emscripten has compiled the symbol _FortranAioOutputAscii to take three i32 arguments25. However, flang-new has compiled hello.f08 with the expectation that the symbol takes two i32 arguments and a single i64 argument. 25 This is LLVM IR notation, meaning an integer of size 32 bits. 26 This continues to crop up when compiling R packages for webR. Package authors or vendored libraries may have used tools such as f2c that declare a Fortran SUBROUTINE to return an int, while other libraries might declare a Fortran SUBROUTINE to return void. Who is right? I’m not sure, as I understand it early Fortran did not have a standard interface to C. Personally, I think returning void makes most sense. This is unfortunate. Despite being emitted as just a warning, if you try running the emitted program using Node you will see that the problem is catastrophic. WebAssembly, unlike a lot of target systems, absolutely requires that symbols defined over multiple compilation units have consistent function signatures, both in argument and return type26. [~/fortran]node hello.js .../fortran/hello.js:128 throw ex; ^ RuntimeError: unreachable at wasm://wasm/001a0366:wasm-function[20]:0x15d9 at removeRunDependency (/Users/georgestagg/fortran/hello.js:630:7) Node.js v18.18.0 Rather than going over the debugging process that eventually leads us to what is going on here, let me point you directly to the cause of the problem. Take a look at this comment from the LLVM source: flang/include/flang/Optimizer/Builder/Runtime/RTBuilder.h //===----------------------------------------------------------------------===// // Type builder models //===----------------------------------------------------------------------===// // TODO: all usages of sizeof in this file assume build == host == target. // This will need to be re-visited for cross compilation. /// Return a function that returns the type signature model for the type `T` /// when provided an MLIRContext*. This allows one to translate C(++) function /// signatures from runtime header files to MLIR signatures into a static table /// at compile-time. /// /// For example, when `T` is `int`, return a function that returns the MLIR /// standard type `i32` when `sizeof(int)` is 4. And therein lies the problem. For us, the host is different to the target, breaking assumptions in the LLVM source code. Surprisingly, this does not cause as much chaos as you might expect. From what I can tell, this machinery is used only to make the Fortran runtime library functions, written in C++, available to Fortran. There is a compile-time calculation using sizeof(), and since most of the sizes match anyway27 it mostly works fine. 27 The C data model for the host and target defines how many bits certain fundamental C types are represented with. The specific sizes can differ based on the hardware architecture and your OS. Unfortunately for us, assuming you’re following along on a modern 64-bit Unix-like system such as Linux or macOS, the sizes don’t match for the long data type. The result of sizeof(long) on our compiler’s host platform is 8 bytes (i64), but for the target platform of wasm32-unknown-emscripten the returned value should be 4 bytes (i32). When we compile the Fortran runtime library C++ code using Emscripten, things are fine. The resulting symbols are compiled with signatures such that long arguments are i32. However, when we compile our Fortran code with flang-new the external library symbols are declared such that long arguments are i64. This difference leads to the inconsistent function signature warning and runtime failure. Why did using PRINT() in our “Hello, World!” program invoke a function that takes an argument of type long? Well, in some implementations of Fortran there are so-called “hidden” arguments that are added whenever you pass a Fortran CHARACTER type to a function or subroutine. These extra arguments pass in the length of the strings. In the Fortran runtime library the hidden arguments are declared with type size_t which, following a chain of typedefs, ends up being the same as unsigned long. This hidden implicit argument is the one with inconsistent size. Hacking around the issue Unfortunately, I don’t know enough about the LLVM or Flang internals to implement a real solution to this problem. Ideally, flang-new would emit the correct use of i32 or i64 for the target architecture and data model when cross-compiling, no matter the host architecture the compiler is running on. Since I can’t solve this today, let’s hack around it for now. We’ll build a version of flang-new with the size of a long hard-coded to what we need for wasm32 and Emscripten. We’ll also make some changes so that calls to malloc() from Fortran are emitted with an i32 argument28. 28 This additionally fixes dynamic allocation with ALLOCATE(), a feature introduced in Fortran 90. The required patches are again shown as a diff below. If you’re following along, save it as a file named force-4-byte-values.diff and apply it to the llvm-project directory using git or the patch utility. Finally, recompile flang-new once more. force-4-byte-values.diff diff --git a/flang/include/flang/Optimizer/Builder/Runtime/RTBuilder.h b/flang/include/flang/Optimizer/Builder/Runtime/RTBuilder.h index b3fe52f4b..c3c7326da 100644 --- a/flang/include/flang/Optimizer/Builder/Runtime/RTBuilder.h +++ b/flang/include/flang/Optimizer/Builder/Runtime/RTBuilder.h @@ -146,7 +146,7 @@ constexpr TypeBuilderFunc getModel() { templateconstexpr TypeBuilderFunc getModel() { return [](mlir::MLIRContext *context) -> mlir::Type { - return mlir::IntegerType::get(context, 8 * sizeof(long)); + return mlir::IntegerType::get(context, 8 * 4); }; } template@@ -187,7 +187,7 @@ constexpr TypeBuilderFunc getModel() { templateconstexpr TypeBuilderFunc getModel() { return [](mlir::MLIRContext *context) -> mlir::Type { - return mlir::IntegerType::get(context, 8 * sizeof(unsigned long)); + return mlir::IntegerType::get(context, 8 * 4); }; } templatediff --git a/flang/lib/Optimizer/CodeGen/CodeGen.cpp b/flang/lib/Optimizer/CodeGen/CodeGen.cpp index ba5946415..2931753a8 100644 --- a/flang/lib/Optimizer/CodeGen/CodeGen.cpp +++ b/flang/lib/Optimizer/CodeGen/CodeGen.cpp @@ -1225,7 +1225,7 @@ getMalloc(fir::AllocMemOp op, mlir::ConversionPatternRewriter &rewriter) { return mlir::SymbolRefAttr::get(userMalloc); mlir::OpBuilder moduleBuilder( op->getParentOfType().getBodyRegion()); - auto indexType = mlir::IntegerType::get(op.getContext(), 64); + auto indexType = mlir::IntegerType::get(op.getContext(), 32); auto mallocDecl = moduleBuilder.create( op.getLoc(), mallocName, mlir::LLVM::LLVMFunctionType::get(getLlvmPtrType(op.getContext()), @@ -1281,6 +1281,7 @@ struct AllocMemOpConversion : public FIROpConversion { mlir::Type heapTy = heap.getType(); mlir::Location loc = heap.getLoc(); auto ity = lowerTy().indexType(); + auto i32ty = mlir::IntegerType::get(rewriter.getContext(), 32); mlir::Type dataTy = fir::unwrapRefType(heapTy); mlir::Type llvmObjectTy = convertObjectType(dataTy); if (fir::isRecordWithTypeParameters(fir::unwrapSequenceType(dataTy))) @@ -1291,9 +1292,10 @@ struct AllocMemOpConversion : public FIROpConversion { for (mlir::Value opnd : adaptor.getOperands()) size = rewriter.create( loc, ity, size, integerCast(loc, rewriter, ity, opnd)); + auto size_i32 = integerCast(loc, rewriter, i32ty, size); heap->setAttr(\"callee\", getMalloc(heap, rewriter)); rewriter.replaceOpWithNewOp( - heap, ::getLlvmPtrType(heap.getContext()), size, heap->getAttrs()); + heap, ::getLlvmPtrType(heap.getContext()), size_i32, heap->getAttrs()); return mlir::success(); } [~/fortran]patch -p1 -d llvm-projectblas-3.12.0.tgz % Total % Received % Xferd Average Speed Time Time Time CurrentDload Upload Total Spent Left Speed 100 323k 100 323k 0 0 317k 0 0:00:01 0:00:01 --:--:-- 317k [~/fortran]tar xzf blas-3.12.0.tgz We’ll need to modify BLAS-3.12.0/make.inc to tell it about our version of flang-new and the Emscripten tools. Modify the following settings, leaving the other lines in that file as they are, then build BLAS using make. BLAS-3.12.0/make.inc FC = ../build/bin/flang-new FFLAGS = -O2 FFLAGS_NOOPT = -O0 AR = emar RANLIB = emranlib [~/fortran]cd BLAS-3.12.0 [~/fortran/BLAS-3.12.0]make ../build/bin/flang-new -O2 -c -o isamax.o isamax.f ../build/bin/flang-new -O2 -c -o sasum.o sasum.f ... emar cr blas_LINUX.a isamax.o ... xerbla_array.o emranlib blas_LINUX.a [~/fortran/BLAS-3.12.0]cd .. [~/fortran] That went pretty well! Let’s try using it in a Fortran subroutine compiled for WebAssembly. For fun, we’ll try working with double precision complex numbers. We’ll use the BLAS level 2 routine ZGEMV(), which performs the matrix-vector operation 𝑦 ← 𝛼 𝐴 𝑥 + 𝛽 𝑦 , where 𝛼 and 𝛽 are scalar constants, 𝑥 and 𝑦 are vectors, and 𝐴 is a matrix. Our Fortran routine will take in alpha, beta, A, X, and Y, with a fixed parameter N so that 𝐴 is a square matrix with three rows and columns. The result is written back into 𝑦 , so we declare that Y is of intent INOUT. bar.f08 SUBROUTINE bar(alpha, A, X, beta, Y) IMPLICIT NONE INTEGER, PARAMETER :: N = 3 COMPLEX(KIND=8), INTENT(IN) :: alpha, beta, A(N,N), X(N) COMPLEX(KIND=8), INTENT(INOUT) :: Y(N) EXTERNAL zgemv CALL zgemv('N', N, N, alpha, A, N, X, 1, beta, Y, 1) END Notice how with some BLAS routines, CHARACTER strings of length one control configuration settings. Here, we pass 'N' as the first argument. It is one of the reasons we spent time and care above building a version of flang-new that can deal with CHARACTER arguments and their hidden implicit length arguments for the wasm32 target. Next, we’ll write a C program to create some complex variables, send them to Fortran and BLAS for processing, and print the result. This will let us know both that passing double precision complex numbers to Fortran and calling BLAS routines works as expected. bar.c #include#includeextern void bar_(double complex*, double complex*, double complex*, double complex*, double complex*); int main() { double complex alpha = 1.; double complex beta = 2.*I; double complex A[] = { 1.*I, 4. , 5., 7. , 2.*I, 6., 8. , 9. , 3.*I }; double complex X[] = { 0., 1., 2. }; double complex Y[] = { 3., 4., 5. }; bar_(&alpha, A, X, &beta, Y); printf(\"Y[0]: %f + %fi, Y[1]: %f + %fi, Y[2]: %f + %fi\", creal(Y[0]), cimag(Y[0]), creal(Y[1]), cimag(Y[1]), creal(Y[2]), cimag(Y[2])); return 0; } [~/fortran]./build/bin/flang-new -c bar.f08 -o bar.o [~/fortran]emcc bar.c bar.o build/flang/runtime/libFortranRuntime.a BLAS-3.12.0/blas_LINUX.a -o bar.js [~/fortran]node bar.js Y[0]: 23.000000 + 6.000000i, Y[1]: 18.000000 + 10.000000i, Y[2]: 6.000000 + 16.000000i And there we have it: BLAS compiled from Fortran 90 sources and running under WebAssembly! To finish up, let’s confirm for ourselves that this output is correct31, 31 Keeping in mind Fortran’s column-major array layout.𝛼 𝐴 𝑥 + 𝛽 𝑦 = ( 𝑖 7 8 4 2 𝑖 9 5 6 3 𝑖 ) ⋅ ( 0 1 2 ) + 2 𝑖 ( 3 4 5 ) = ( 23 + 6 𝑖 18 + 10 𝑖 6 + 16 𝑖 ) . Example: A handwritten digit classifier The following demo uses a multi-layer perceptron (MLP) artificial neural network to classify hand-drawn digits. Try it out with your mouse or touchscreen! Just draw a digit from 0-9 in the box, and the classifier will try to label what digit you wrote. The relative probabilities according to the network are shown in a plot on the right. It’s not a perfect model, but it works fairly well for me! The weights powering the model have been pre-trained using Python, but the classification is performed at runtime using JavaScript and WebAssembly, running in your browser right now. With an MLP network, the classification process is essentially a repeated application of matrix-vector addition and multiplication. In this demo the heavy lifting is done by a single Fortran subroutine making use of the BLAS level 2 routine DGEMV(). Building LAPACK LAPACK (Linear Algebra Package) is a software library for solving linear algebra problems numerically. It’s built upon BLAS and has similarly become a standard with many reimplementations designed for specific hardware or systems. Let’s finish this post by also building the “reference implementation” of LAPACK32. 32 Also available from netlib, released under a modified BSD licence. [~/fortran]curl -L https://github.com/Reference-LAPACK/lapack/archive/refs/tags/v3.12.0.tar.gz > lapack-3.12.0.tgz % Total % Received % Xferd Average Speed Time Time Time CurrentDload Upload Total Spent Left Speed 100 7747k 0 7747k 0 0 4117k 0 --:--:-- 0:00:01 --:--:-- 6655k [~/fortran]tar xzf lapack-3.12.0.tgz Similar to BLAS, we need to modify some configuration options to let LAPACK know about Emscripten and flang-new. Copy the file lapack-3.12.0/make.inc.example to lapack-3.12.0/make.inc, then make the following modifications. Be sure to replace [...] with the full path to the build directory on your machine33, and leave the other options in the file as they are. 33 A relative path doesn’t work here. Alternatively, simply set the option to read flang-new and make it available on your $PATH. lapack-3.12.0/make.inc FC = [...]/build/bin/flang-new FFLAGS = -O2 FFLAGS_DRV = $(FFLAGS) FFLAGS_NOOPT = -O0 AR = emar RANLIB = emranlib TIMER = INT_CPU_TIME Then, build LAPACK using the make lib command to create the WebAssembly static library liblapack.a. [~/fortran]cd lapack-3.12.0 [~/fortran/lapack-3.12.0]make lib make -C SRC .../build/bin/flang-new -O2 -c -o sbdsvdx.o sbdsvdx.f ... emar cr ../../libtmglib.a slatms.o ... dlarnd.o emranlib ../../libtmglib.a [~/fortran/lapack-3.12.0]cd .. [~/fortran] [~/fortran]file lapack-3.12.0/liblapack.a lapack-3.12.0/liblapack.a: current ar archive With this, LAPACK routines can be called in a similar way to the BLAS routine example in the previous section. Example: Polynomial Interpolation with Linear Algebra The following demo finds interpolating polynomials for a set of points, demonstrating LAPACK routines running in your web browser. Click the plot to add new points. An interpolating polynomial will be found to pass through all the points using Vandermonde’s method34. The linear algebra equation given by this method is then solved numerically in LAPACK using the DGELS() routine. 34 It is always possible to find an 𝑛 − 1 degree polynomial containing 𝑛 data points exactly. However, when 𝑛 is large the polynomial fluctuates wildly between successive data points. This problem is known as Runge’s phenomenon and can be avoided by using spline interpolation. Final thoughts If you followed along at home, you now have a version of LLVM Flang that can compile modern Fortran code into WebAsembly objects. As I mentioned earlier, while it’s always been possible to build numerical algorithms for the web using JavaScript, to me the beauty of this approach is it allows you to use powerful Fortran tools and libraries that already exist, avoiding time and effort rewriting large collections of numerical routines for the web. It would be wonderful if WebAssembly could be officially supported by the flang-new compiler. It would certainly lessen the burden of maintaining a fork of LLVM for webR and its R packages. However, without some help and support from a more experienced compiler developer, we will need to continue using a patched version for now. If you’re familiar with LLVM Flang and know a better route to fixing the issues described above in a way that works for all targets with cross-compilation, feel free to email me. I’d be very interested to hear. If you’d like to experiment with compiling Fortran code for WebAssembly but can’t or don’t want to build LLVM Flang from scratch, we provide a Docker container with a binary version of our patched LLVM Flang in the GitHub container registry.",
    "commentLink": "https://news.ycombinator.com/item?id=39944275",
    "commentBody": "Fortran on WebAssembly (gws.phd)195 points by georgestagg 17 hours agohidepastfavorite47 comments wch 14 hours agoA little context: this dive into Fortran is part of the excellent work George has been doing on WebR, to get R running in the browser. The R sources contain a fair bit of Fortran code, and I believe WebR originally used f2c to compile the Fortran to C first, before compiling that to wasm. With the patches to LLVM Flang, WebR can be built with a real Fortran compiler. I think George didn't want to say it directly in the blog post, but he has said that he's hoping that Flang would take his patches or implement better ones. That would be a win-win -- these patches wouldn't need to be maintained separately, and since unmodified Flang would be able to compile to wasm, it would benefit other projects out there that use Fortran. https://docs.r-wasm.org/webr/latest/ reply pklausler 14 hours agoparentPull requests are always welcome (https://github.com/llvm/llvm-project), and one can contact the general LLVM Fortran development community (https://discourse.llvm.org/c/subprojects/flang/33) for help. I am focused on things needed to complete development for Nvidia's Fortran product and don't have any time left for things like this, myself. reply QuantumG 11 hours agoparentprevSource to source, F77 to JavaScript is already pretty good but WASM is better. reply amirhirsch 12 hours agoprevI worked on compiling FORTRAN at Xilinx 20 years ago. The only thing I remember is that the header file for f2c.h contains a definition of barf: /* f2c.h -- Standard Fortran to C header file / /* barf [ba:rf] 2. \"He suggested using FORTRAN, and everybody barfed.\" (https://www.netlib.org/clapack/f2c.h) reply amirhirsch 12 hours agoparentDoes using all-caps FORTRAN say something about me? Fortran looks wrong to me. reply necheffa 11 hours agorootparentYes, it says you probably got started before the f90 standard. reply sroussey 10 hours agorootparentprevGlad it’s not just me. reply pklausler 16 hours agoprevI don't know whether to be impressed or horrified. Maybe both. I would recommend using top-of-tree llvm-project/main sources for building f18; we are a fast-moving project and it would be a waste of time for anybody to debug a problem that has already been fixed, or miss a feature that has already been implemented. reply tomcam 13 hours agoparentI was unable to understand the llvm source well enough to understand your point. Are they working on a WebAssembly port that will get their intermediate code to a point where Fortran works? reply pklausler 12 hours agorootparentI meant that we are actively developing a new implementation of the Fortran language itself here. We are still adding features and fixing bugs. Fortran code that compiles and runs today with llvm-project/main HEAD may well not compile or not run with older release branches. reply sanxiyn 11 hours agorootparentprevThe article uses LLVM Flang from LLVM 18.1.1. pklausler's point is that it is counterproductive and LLVM HEAD should be used instead. reply tomcam 2 hours agorootparentI’m trying to understand why though reply math_dandy 16 hours agoprevI love the \"simplest nontrivial example\" approach to exposition. I think I learned a lot from the article because it was grounded in the concrete problem \"call a BLAS function from Javascript\". Great post! reply georgestagg 15 hours agoparentThanks! There’s a series of books I really like, The Theoretical Minimum[1], that also takes that kind of approach but for teaching physics. [1] https://en.m.wikipedia.org/wiki/The_Theoretical_Minimum reply certik 13 hours agorootparentYes, I also like The Theoretical Minimum. Ha, I didn't realize there is more than one book! I think I only have the classical mechanics book. Need to buy the other ones. I tried to organize many physics subjects in a similar manner, with many worked out examples (minimal, but non-trivial/complete): https://www.theoretical-physics.com/dev/index.html reply 0cf8612b2e1e 14 hours agoprevI am pretty ignorant of Web Assembly development. Does Web Assembly have anything to offer me today as a consumer? Or is all of this still setting the groundwork for a future where programs are truly portable? I have heard some rumblings that the WA machinery makes it easier to restrict access (network, files) but I do not know if those are theoretical or implemented today. reply norman784 13 hours agoparentBasically Wasm is a virtual machine, is is very similar to JVM that is portable, but the key difference is that Wasm does not have any std nor expose any IO function, so you can build your own host (the VM) that expose functions that can be imported from the Wasm binary, that means that the Wasm binary can have access to the external world only through these functions. Also I would say an advantage is that the binary format is not proprietary and there's a spec, so anyone could implement their own Wasm VM. But right now is not in a good place yet, is too early and there are a lot of new functionality that is being standardized by a group (similar to W3C) and the process is very slow. reply kevingadd 13 hours agoparentprevAs a developer or someone shipping products, if you want robust sandboxing, WASM is probably the best option available to you right now. And there are ways to deploy it or cross-compile it for most targets. reply coldcode 15 hours agoprevI wish I had kept my Fortran 78 code from 1981/82 to see if I could get it to run on this. It was a Jovial programming language source code formatter. Not exactly what you should use Fortran for, but that's the only choice I had. reply tomcam 13 hours agoparentDid you work at Hughes in Orange County? reply droelf 16 hours agoprevWeird that it doesn't go into LFortran more, they even have an excellent online and mindblowing WASM example. https://dev.lfortran.org/ reply andsoitis 16 hours agoparent> Weird that it doesn't go into LFortran more, they even have an excellent online and mindblowing WASM example. They write: The LFortran compiler has made great strides over the last few years. In 2020, it was missing a lot of features and only supported a very small subset of Fortran. Now it now supports a much wider range of language features and can be used to compile a reasonable amount of Fortran code. It can even compile to WebAssembly out of the box! However, there are still some barriers that make using LFortran a little rough. The project is currently considered to be in alpha phase and the developers state that issues compiling real-world code are expected. While it can successfully compile some projects, such as MINPACK, the full Fortran specification is not yet supported and so many larger projects still cannot be compiled. The LFortran developers are targeting full support for Fortran 2018, and its standout feature is an interactive Jupyter-like Fortran REPL. With a few more years of development, I expect that LFortran will be an excellent choice for compiling Fortran code for WebAssembly. and Check out the LFortran demo at https://dev.lfortran.org. While extremely impressive, note that the first thing I tried was changing x * 2 to x * 3 and saw that such a change is currently not supported by the code generator. reply certik 15 hours agorootparentThe author of LFortran here. The demo at https://dev.lfortran.org uses our direct WASM backend that does not use LLVM. It is currently more limited, and indeed, we currently do not support the cubic power x**3 there, only square power x**2. Our most advanced backend is LLVM, and that of course supports x**3 and a very wide subset of Fortran (such as 60% of all SciPy packages fully compile and all SciPy tests pass). However, LLVM is huge and relatively slow, so we do not use LLVM in the online demo, which runs the compiler itself in the browser. For offline LLVM based WASM compilation I think LFortran is ready be tried. We'll be happy to help! reply georgestagg 15 hours agorootparentI’ll definitely be trying out more of LFortran in the future. For this post I really wanted to go deeper into the approach we’ve taken with flang, but I can see that LFortran is also a very strong choice here for running Fortran on Wasm. reply certik 13 hours agorootparentThanks. Please report all bugs that you find. I talked to my collaborators, we'll try to get some simple demo of Fortran->LLVM->WASM working soon, we need to figure out the runtime library issue (like you did), hook it into the driver, etc. I was in fact thinking about exactly this just last week, to easily distribute my simple computational codes online via static pages. I think exactly the approach that you took with Flang should work with LFortran also. reply superjan 14 hours agorootparentprevJust curious but what is keeping you from compiling x*3? reply certik 13 hours agorootparentNothing, we can compile x*3. We can't compile x**3, because we do not have a runtime library setup for WASM yet (Flang above had the same issue) and WASM can do x**2, but arbitrary power, such as x**3, requires a runtime power function that we haven't implemented yet. If you want to help, you can fix it probably quite easily right here: https://github.com/lfortran/lfortran/blob/69d488b1d1fd26b163.... reply selimthegrim 9 hours agorootparentHow about cube roots of fractions and rational numbers? (TI and Casio fans will get the deep cut) reply certik 8 hours agorootparentThe LLVM backend just does the usual floating point calculation for those. reply forgotpwd16 15 hours agorootparentprevGrats for the amazing work! LFortran is very cool project. reply certik 13 hours agorootparentThank you! reply floxy 11 hours agorootparentprevWow, this looks great. Seems like there is a mini-renaissance of Fortran that I've been seeing lately. I see from the main page: \"LLVM makes it possible to run LFortran on diverse hardware and take advantage of native Fortran language constructs (such as do concurrent) on multi-core CPUs and GPUs.\" ...is LFortran close to using coarrays, etc, and farming it out as appropriate to the GPU cores? reply certik 7 hours agorootparentWe are progressing. We'll tackle parallel loops very soon, and get some GPU offloading working. Our main focus is still on just compiling Fortran codes via LLVM. Once we can compile most codes, we'll focus on the various other backends, including GPU, running in the browser and Jupyter. reply Onavo 11 hours agorootparentprevAlso of course LPython https://lpython.org/ reply pjmlp 15 hours agoprevFortran on .NET and Java, https://www.silverfrost.com/14/ftn95/ftn95_fortran_95_for_mi... https://dl.acm.org/doi/10.1145/376656.376833 reply mhh__ 13 hours agoprevIs there a somewhat \"production\"-ready ecosystem for linear algebra in javascript? Upon googling I often find some ~decade old port of one of the old familiars to javascript (e.g. via emscripten), wondering if I'm missing something. reply KRAKRISMOTT 13 hours agoparentDo we have a BLAS equivalent on WebGPU or WebNN? reply ein0p 13 hours agoprevI’ve been reading these articles for years, but I’ve yet to experience any practical use of webassembly outside of contrived demos. Where do people use all this stuff? Does anyone use it? reply homerowilson 11 hours agoparentAs an educator, one great use for me is classroom use. Students can run R/Python/Fortran in the browser on any OS without installing any software: https://docs.r-wasm.org/webr/latest/ https://github.com/jupyterlite/jupyterlite https://dev.lfortran.org/ There are rough edges to be sure, but the potential is great in education I think. reply ein0p 11 hours agorootparentJupyterlite looks pretty cool, thanks for making me aware of it reply azakai 11 hours agoparentprevIf you used Zoom on the Web then you have used WebAssembly without knowing it. The same for a long list of other stuff, big and small, from parts of Wikipedia to games to many other things. When you use something like the Video element on the Web then it's obvious - you see a video playing - but wasm is just a technical detail that you might not notice as a user. But it often makes things faster or easier to port or to develop, and it is used quite widely (though far less widely than JavaScript, for example). reply georgestagg 12 hours agoparentprevWebAssembly is generally most useful when you want to write high performance web applications using languages like C, C++ or Rust. WebAssembly sits in the background quietly powering the web-based versions of products like Adobe Photoshop, AutoCAD, Figma, Canva, and likely others. By using Wasm components combined with other browser technologies such as HTML canvas and webGL, app performance and responsiveness can be improved. WebAssembly also powers the Pyodide and webR projects, enabling Python and R code to run in a browser without a supporting computational server. Where I’ve seen this used most effectively so far is in teaching materials, particularly for teaching data science, where interactive R and Python examples can be embedded directly into teaching materials without the educator having to worry about the time or expense to deploy a powerful backend service to evaluate learner’s code. reply sanxiyn 11 hours agoparentprevWebAssembly is used in the real world and uses are very diverse. I recommend \"An Empirical Study of Real-World WebAssembly Binaries\". (The paper is from 2021, and it would be great to get an update, but I guess academia does not reward such work because it is not \"novel\" even if it is clearly valuable.) https://www.software-lab.org/publications/www2021.pdf reply rad_gruchalski 12 hours agoparentprevEnvoy proxy uses wasm filters, thus Istio uses wasm filters. Everyone who uses Istio in non-ambient-mesh uses them. They can write their own in a language of their choice. reply csjh 12 hours agoparentprevCloudflare workers use them for portability/v8 isolate compatibility/speed/isolation, Figma uses for the main editor, a bunch of Web3 stuff uses them for ??? reply tomasreimers 13 hours agoprevI remember when I was working on https://medium.com/@tomasreimers/compiling-tensorflow-for-th... I thanked my lucky stars that TF used Eigen and not one of the popular math libraries (BLAS, Lapack) written in fortran b/c that would have been A LOT more work... reply ur-whale 14 hours agoprev [–] The translator gets translated. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article discusses the challenges of compiling Fortran code for WebAssembly in web browsers using modified versions of LLVM and Flang compilers for the webR project.",
      "It highlights the importance of experienced compiler developers' assistance due to the lack of a straightforward solution and explores various methods and toolchains, emphasizing reliable BLAS and LAPACK routines.",
      "The active development of the LLVM Flang compiler facilitates Fortran code compilation to WebAssembly with minimal code adjustments, addressing issues like symbol mismatches and function signature inconsistencies through patches in the flang-new compiler."
    ],
    "commentSummary": [
      "George Stagg is working on running Fortran on WebAssembly by patching LLVM Flang, removing the requirement to convert code to C beforehand.",
      "The discussion covers utilizing LLVM Flang from LLVM 18.1.1, tracking LFortran's advancements and constraints, addressing runtime library challenges, and exploring WebAssembly's applications in education and diverse hardware.",
      "WebAssembly is recognized for empowering high-performance web apps and finds extensive usage across different sectors."
    ],
    "points": 195,
    "commentCount": 47,
    "retryCount": 0,
    "time": 1712334109
  },
  {
    "id": 39941859,
    "title": "Cloudflare Enhances Serverless Computing with PartyKit Acquisition",
    "originLink": "https://blog.cloudflare.com/cloudflare-acquires-partykit",
    "originBody": "Cloudflare acquires PartyKit to allow developers to build real-time multi-user applications 04/05/2024 Sunil Pai Rita Kozlov 4 min read We're thrilled to announce that PartyKit, an open source platform for deploying real-time, collaborative, multiplayer applications, is now a part of Cloudflare. This acquisition marks a significant milestone in our journey to redefine the boundaries of serverless computing, making it more dynamic, interactive, and, importantly, stateful. Defining the future of serverless compute around state Building real-time applications on the web have always been difficult. Not only is it a distributed systems problem, but you need to provision and manage infrastructure, databases, and other services to maintain state across multiple clients. This complexity has traditionally been a barrier to entry for many developers, especially those who are just starting out. We announced Durable Objects in 2020 as a way of building synchronized real time experiences for the web. Unlike regular serverless functions that are ephemeral and stateless, Durable Objects are stateful, allowing developers to build applications that maintain state across requests. They also act as an ideal synchronization point for building real-time applications that need to maintain state across multiple clients. Combined with WebSockets, Durable Objects can be used to build a wide range of applications, from multiplayer games to collaborative drawing tools. In 2022, PartyKit began as a project to further explore the capabilities of Durable Objects and make them more accessible to developers by exposing them through familiar components. In seconds, you could create a project that configured behavior for these objects, and deploy it to Cloudflare. By integrating with popular libraries such as Yjs (the gold standard in collaborative editing) and React, PartyKit made it possible for developers to build a wide range of use cases, from multiplayer games to collaborative drawing tools, into their applications. Building experiences with real-time components was previously only accessible to multi-billion dollar companies, but new computing primitives like Durable Objects on the edge make this accessible to regular developers and teams. With PartyKit now under our roof, we're doubling down on our commitment to this future — a future where serverless is stateful. We’re excited to give you a preview into our shared vision for applications, and the use cases we’re excited to simplify together. Making state for serverless easy Unlike conventional approaches that rely on external databases to maintain state, thereby complicating scalability and increasing costs, PartyKit leverages Cloudflare's Durable Objects to offer a seamless model where stateful serverless functions can operate as if they were running on a single machine, maintaining state across requests. This innovation not only simplifies development but also opens up a broader range of use cases, including real-time computing, collaborative editing, and multiplayer gaming, by allowing thousands of these \"machines\" to be spun up globally, each maintaining its own state. PartyKit aims to be a complement to traditional serverless computing, providing a more intuitive and efficient method for developing applications that require stateful behavior, thereby marking the \"next evolution\" of serverless computing. Simplifying WebSockets for Real-Time Interaction WebSockets have revolutionized how we think about bidirectional communication on the web. Yet, the challenge has always been about scaling these interactions to millions without a hitch. Cloudflare Workers step in as the hero, providing a serverless framework that makes real-time applications like chat services, multiplayer games, and collaborative tools not just possible but scalable and efficient. Powering Games and Multiplayer Applications Without Limits Imagine building multiplayer platforms where the game never lags, the collaboration is seamless, and video conferences are crystal clear. Cloudflare's Durable Objects morph the stateless serverless landscape into a realm where persistent connections thrive. PartyKit's integration into this ecosystem means developers now have a powerhouse toolkit to bring ambitious multiplayer visions to life, without the traditional overheads. This is especially critical in gaming — there are few areas where low-latency and real-time interaction matter more. Every millisecond, every lag, every delay defines the entire experience. With PartyKit's capabilities integrated into Cloudflare, developers will be able to leverage our combined technologies to create gaming experiences that are not just about playing but living the game, thanks to scalable, immersive, and interactive platforms. The toolkit for building Local-First applications The Internet is great, and increasingly always available, but there are still a few situations where we are forced to disconnect — whether on a plane, a train, or a beach. The premise of local-first applications is that work doesn't stop when the Internet does. Wherever you left off in your doc, you can keep working on it, assuming the state will be restored when you come back online. By storing data on the client and syncing when back online, these applications offer resilience and responsiveness that's unmatched. Cloudflare's vision, enhanced by PartyKit's technology, aims to make local-first not just an option but the standard for application development. What's next for PartyKit users? Users can expect their existing projects to continue working as expected. We will be adding more features to the platform, including the ability to create and use PartyKit projects inside existing Workers and Pages projects. There will be no extra charges to use PartyKit for commercial purposes, other than the standard usage charges for Cloudflare Workers and other services. Further, we're going to expand the roadmap to begin working on integrations with popular frameworks and libraries, such as React, Vue, and Angular. We're deeply committed to executing on the PartyKit vision and roadmap, and we're excited to see what you build with it. The Beginning of a New Chapter The acquisition of PartyKit by Cloudflare isn't just a milestone for our two teams; it's a leap forward for developers everywhere. Together, we're not just building tools; we're crafting the foundation for the next generation of Internet applications. The future of serverless is stateful, and with PartyKit's expertise now part of our arsenal, we're more ready than ever to make that future a reality. Welcome to the Cloudflare team, PartyKit. Look forward to building something remarkable together. We protect entire corporate networks, help customers build Internet-scale applications efficiently, accelerate any website or Internet application, ward off DDoS attacks, keep hackers at bay, and can help you on your journey to Zero Trust. Visit 1.1.1.1 from any device to get started with our free app that makes your Internet faster and safer. To learn more about our mission to help build a better Internet, start here. If you're looking for a new career direction, check out our open positions. Discuss on Hacker News Developer WeekAcquisitionsCloudflare WorkersAIDurable Objects",
    "commentLink": "https://news.ycombinator.com/item?id=39941859",
    "commentBody": "Cloudflare acquires PartyKit to allow developers to build real-time multi-user (cloudflare.com)191 points by jgrahamc 20 hours agohidepastfavorite74 comments wrongcarwhy 18 hours agoPartykit confused me. They hired two people, then laid them off (https://twitter.com/threepointone/status/1724159621382754738) after raising 2.5 million, with nothing but a vague message about \"the tech landscape is moving changing incredibly fast\". That seems kind of callous? reply matt_oriordan 17 hours agoparentWow, that didn't last long! This can only be an acquihire given Sunil worked at Cloudflare before. reply cj 17 hours agoparentprevTrying to improve EBITDA (profitability) in advance of an acquisition perhaps? Or the company knew the deal was going forward and Cloudflare was unlikely to retain new employees? reply toddmorey 14 hours agoparentprevI think it's a classic example of landing in that space of being a feature vs a product. I know from my part, I'm really fatigued on the SaaS model of spinning up so many different products from so many different providers for one freakin' project. So Partykit, while interesting tech, may have just struggled as independent infrastructure. Partykit is actually powered by Cloudflare Workers, so it's a compatible acquisition that adds realtime to the workers platform. Plus like you said they had recently and unfortunately \"stripped PartyKit way back\" with some layoffs, so I'd imagine the acquisition was fairly cheap for Cloudflare. reply ensignavenger 17 hours agoparentprevA lot of folks on here complain about companies making long layoff announcements shrouded in \"nice\" speech. Finding the right balance seems to be hard for a lot of PR folks. reply progbits 15 hours agorootparentProblem is the layoff, not the PR balance. reply kentonv 17 hours agoparentprevI don't know anything about what happened here, but I know Sunil is a good person and wouldn't have done this on a whim. Sometimes there are internal problems forcing painful decisions but you just can't go and tweet the details. reply dont_dox_me_bro 17 hours agorootparentnext [6 more] [flagged] kentonv 16 hours agorootparent> How can you call someone a good person I know the guy. > if they literally hired then fired people? If hiring and firing is inherently wrong then I guess all founders are bad? reply ensignavenger 16 hours agorootparentprevGood people make mistakes. Maybe the fired employees got really good severance packages? Maybe they were given introductions that led to immediate employment offers? I have no idea, but judging some one based on a tweet where they announced they had made a mistake that may have hurt two individuals is hardly fair. reply dont_dox_me_bro 16 hours agorootparentI mean I think it's very telling since there was an acquisition nearly 6 months later by his previous company. That's quite an incestuous relationship, but hey he got his payday after removing two core contributors that were employees. Why are you assuming they got severance? He wouldn't be legally complied to do so, and if he did he would have mentioned it. reply ensignavenger 16 hours agorootparentI didn't assume anything, I suggested it may have happened. You seem to be the one assuming things and making accusations on another persons character. Its okay to ask questions, but we should do it nicely. reply bsimpson 16 hours agorootparentprevI know the people involved. It's not my business to publish their business, but I'm confident there's no malintent or hard feelings. As Kenton mentioned above, Sunil is a good dude. reply nullzzz 14 hours agoprevI think it’s an exaggeration to say ”Building experiences with real-time components was previously only accessible to multi-billion dollar companies”. For instance my hobby project ourboard.io provides realtime collaboration and it costs like 20$ to host with current moderate load of users. It utilizes Y.js for collab text editing. Y.js is dedinitely a great tech and has a low entry barrier. reply matlin 14 hours agoparentThere's a whole host of similar solution in the local-first realm of software[1]. I'm biased but you should definitely try Triplit[2] if you want a super easy way to make real-time collaborative software that works seamlessly even when offline or on unreliable networks (like on mobile). [1] https://localfirstweb.dev/ [2] https://triplit.dev reply CharlesW 14 hours agoparentprevIf you consider it from the Cloudflare author's POV, it's likely an implied \"at scale\" in that statement. reply nullzzz 13 hours agorootparentSure, but doing anything at a grand scale is expensive - realtime collab is no exception IMO, not that we already have things like Y.js. And don’t get me wrong, I’m not playing Cloudflare’s efforts down, just saying that particular claim is false. reply toddmorey 14 hours agoparentprevYeah I agree with it being an exaggeration. They are certainly riding the admittedly dated perception that realtime is so hard it's only available to the Googles and Figmas. But there's now some amazing open source solutions available like Y.js and ElectricSQL[1]. The barrier has certainly come down. [1] https://github.com/electric-sql/electric reply w10-1 17 hours agoprev\"The future of serverless is stateful\" I'm a big fan of Cloudflare's openness, e.g., in supporting wasm in workers. But I wonder if building lock-in is really in their customers' interests - or theirs, if people lose faith in them. One of the value propositions for javascript+databases, and java before it, is that it was a programming model built in the open, and sometimes to standards that multiple vendors could supply. The openness of SQL has powered the industry, notwithstanding the manifold limitations and variants. A PartyKit integration is not particularly concerning if it's just niche gaming, but if real-time collaboration really does become trivial to implement at the same time AI spreads into all corners of content, it could become the dominant programming model for emerging tech at scale. AI seems to have ample competition, but I see little competition and many barriers to entry for this kind of programming model. reply kentonv 15 hours agoparentStandards bodies only standardize things after they've been proven to work. You can't standardize a new idea before offering it to the market. It's hard enough to get just one vendor to experiment with an idea (it literally took me years to convince everyone inside Cloudflare that we should build Durable Objects). Getting N competing vendors to agree on it -- before anything has been proven in the market -- is simply not possible. But the Durable Objects API is not complicated and there's nothing stopping competing platforms from building a compatible product if they want. Much of the implementation is open source, even. In fact, if you build an app on DO but decide you don't want to host it on Cloudflare, you can self-host it on workerd: https://github.com/cloudflare/workerd reply ayuhito 16 hours agoparentprev> But I wonder if building lock-in is really in their customers' interests - or theirs, if people lose faith in them. People happily (or sometimes unhappily) lock themselves in with AWS since it’s convenient and useful. And that’s what Cloudflare is aiming to be in the serverless landscape even if it isn’t ideal. reply RowanH 13 hours agorootparentI guess there's degrees of lock-in. I.e. using some parts of AWS you know push comes to shove you could write a different alternative/use a different library. It's a bunch of building blocks. There's various alternatives out there for components. Without reading too much of Partykit + Cloudflare, if you base your whole architecture on the way one company works and perhaps the pricing is too good to be true, you're setting yourself up for a rude shock in future. Everytime I've looked at Cloudflare's pricing I've gone \"that's bonkers cheap\" for what you're getting, which sets off alarm bells that once a PE company gets their hands on it, it's not going to be that cheap any more. reply bennyp101 20 hours agoprevThe PartyKit website is wild, random cursors from other people! Quite fun to be chasing them around the screen! (Which does seem to show off the lack of lag and responsiveness) reply SushiHippie 19 hours agoparentReminds me of someone's personal site: https://dimden.dev/. Not many people are currently on there, but you can just open another tab and see for yourself. Also has a little live chat which gets a bridge to their discord server, where you can chat with others that are currently on the page. reply dorian-graph 18 hours agorootparentAnd this other personal site, with real-time multiple cursors: https://j-e-s-s-e.com reply rpastuszak 19 hours agoparentprevI love PartyKit! I used it to make a multiplayer version of sit: https://untested.sonnet.io/Sit.%2C+(together)+devlog+002+%E2... reply endisneigh 19 hours agoprevOther than games, anyone have good examples of real time multi user apps? Even with things like docs and sheets, though the capability is there, I find myself rarely editing in real time with others. reply jchanimal 14 hours agoparentWe love PartyKit as a real time sync connector for Fireproof. This lets us offer CouchDB or Firebase-like experience with only a browser and less than 100 lines of JavaScript on the backend. Here is what our PartyKit server looks like for the curious: https://github.com/fireproof-storage/fireproof/blob/main/pac... reply fritzo 19 hours agoparentprevRemote pair coding, then jumping to a shared whiteboard, then a shared diagramming tool, then back to a shared IDE reply et-al 17 hours agoparentprevShared meeting notes is a common one. Brainstorming in FigJam is another. If you're collaborating with other folks on a project, it's beneficial to see updates in realtime to maintain that one source of truth. Otherwise your work and theirs might overlap and someone will need to resolve merge conflicts. That, or you go the locking route, which comes with its own set of hassles. reply DaiPlusPlus 17 hours agoparentprev> anyone have good examples of real time multi user apps? My SaaS day-job is a real-time multi-user checklist web-app - built using SignalR. We're able to fit tens of thousands of concurrent users on a single Azure AppService instance - and we're self-hosted so we don't have IaaS-rug-pulling-anxiety - PartyKit looks cool, but I take a long-term view (5+ years) before adopting a technology, and PartyKit's brochure website is lacking information in that area... reply spxneo 17 hours agorootparentinteresting is there a non .net solution like signalr that can run on a single instance on AWS? reply DaiPlusPlus 16 hours agorootparentYou can use WebSockets with NodeJS; there's a variety of libraries for this, but (naturally) it's npm-hell; but I'm not aware of any easy-to-use WebSocket wrappers/adapter libraries like what SignalR is, but it's been a while since I looked. SignalR's two main selling-points back-in-the-day (2014-ish) was its solid cross-browser support and how it abstracted over WebSockets, Comet, SSE, long-polling, et al - but it's 2024 now and everyone's on Chromium or WebKit, so cross-browser support is moot, and and WebSockets+SSE now covers all use-cases; so there's less going-for SignalR thesedays, and since the ASP.NET Core rewrite of SignalR it just doesn't scale as well on the client-side (as it no-longer multiplexes multiple Hub requests over a single connection, which is crazy... and HTTP/2+QUIC+3 doesn't really help, I find). reply Nullabillity 14 hours agorootparentThat sounds a lot like socket.io? reply robbs 14 hours agorootparentprevPhoenix Channels reply kimar 17 hours agoparentprevObvious plug but my company[1] is building a multi-user real-time 3d engine. Think Figma meets Unity. There are lots of fun use cases around working collaboratively on subparts of a larger 3d system without having to break it apart: - architects working on different parts of a building - engineers working on different pieces of a CAD model - game designers working on different levels, etc [1] 3dverse.com reply selvan 19 hours agoparentprevChat, Audio/Video Conferencing apps are other examples. reply badwolf 18 hours agoparentprevFigma is pretty great at this. reply ketzo 18 hours agoparentprevI frequently do this in Notion, especially in more brainstorm-y meetings. Also good for notetaking; I might be writing most of the notes, but then start talking more, and see someone jump in to take my place in the notes. reply latchkey 19 hours agoparentprevI use the realtime editing features all the time with my coworkers. reply inopinatus 17 hours agoparentprevms.inopinatus and I often do event and travel planning through shared realtime notes you could also build a 2-person permissive action link for nuclear weapons launches or a stock exchange reply morkalork 17 hours agoparentprevMiro reply trevor-e 17 hours agoprevI was looking at partykit a while back since I have some multiplayer game ideas I finally want to prototype. The pricing confused me -- why is it per developer when they claim to take care of the infrastructure hosting? Shouldn't it be usage based? Instead I've been learning Elixir + Phoenix framework which has been fun. reply Gr4phTh3ory 16 hours agoparentThere's both a per-developer and per-usage component into their \"pro\" plan. reply trevor-e 14 hours agorootparentOh I totally missed they snuck that in as a line item. Still, they require you to call them so who knows what that could end up being. reply YousefED 13 hours agoprevCongrats! I used PartyKit since the early beta; for the open source React rich text editor I'm working on (https://www.blocknotejs.org, the homepage runs on Partykit), and PartyKit was a breeze to integrate (ofc, big part because we both build on Yjs). Looking forward to seeing where Cloudflare wants to take this further! reply eddd-ddde 20 hours agoprevI love using Cloudflare for my projects, but something about Durable Objects just scares me so much. I feel like an application like collaborative editing would send so much requests that billing would have to be insane, right? Even for my hobby size projects which I would like to publish for fun, terrify me with possible usage costs. Their hibernation web socket thingy is great, but the real thing that scares me is the overall web socket message cost. reply kentonv 20 hours agoparentFWIW yesterday we announced that WebSocket messages are now billed at 1/20 of a request, rather than a full request. It was kind of buried in this omnibus blog: https://blog.cloudflare.com/workers-production-safety reply eddd-ddde 16 hours agorootparentOh I totally missed that, thanks for making me aware of it. Edit: Oh wow, I totally missed the rate limiter thing as well. Just last week I was implementing my own using DO. It's great to see this developments. reply ftigis 17 hours agorootparentprevIs this the better pricing y'all are figuring out that's been dangled since the launch of Durable Objects + WebSocket on Workers? Oh and somehow I missed the Hibernation API announcement. Paying for idle but connected time is what made me nope out of trying it out. reply Sai_ 20 hours agoparentprevYour clients control the number of messages they exchange with each other via the DO. You still have to protect the DO through some sort of auth and/or rate limits. Don’t see how any of these issues are unique to DOs. reply eddd-ddde 16 hours agorootparentMy issue was that a single message, be it 4 bytes, was essentially billed the same as a 20Mb request. Didn't make too much sense to me. If I have to think about batching messages to decrease costs even tho my overall transport and execution would be the same, I feel like that's an issue on the platform somehow. reply jaflo 18 hours agorootparentprevWhen I took a look at using DO last time I decided against using them because you had to pay for the duration your clients are connected to them when using WebSockets. As far as I understood it’s not execution duration but flat out how long your clients are connected. You’ll burn through seconds quickly that way. I decided to go with a polling mechanism instead. reply ec109685 18 hours agorootparentThey have hibernating durable objects now that don’t charge unless there is a request through them: https://developers.cloudflare.com/durable-objects/api/websoc... reply jaflo 17 hours agorootparentOh that’s neat! I’m not sure if it didn’t exist or if I didn’t find this last time. Looks like this would address the problem. reply _factor 10 hours agoparentprevIf you’re concerned, another alternative is to use WebRTC for peer to peer connections. Bypass the server entirely and use it only for signaling. https://github.com/dmotz/trystero reply stevenfabre 8 hours agoprevGenuinely happy for Sunil who built a great community and moved the space forward! Liveblocks also runs partly on Cloudflare Workers, it’s been great for stateful real-time servers. reply ensignavenger 16 hours agoprevIs it possible to use PartyKit without Cloudflare? Such as hosting your own workerd instance? Is there any documentation anywhere for this? reply ensignavenger 16 hours agoparentI should note, I spent quite a bit of time looking at the official docs and couldn't find an answer for sure right away. It seems like Cloudflare is the only officially supported option (either through the PartyKit managed service or direct). While I might consider using Cloudflare, I wouldn't be willing to build an app in such a way as to depend on Cloudflare. If Cloudflare changes pricing, or comes under political pressure to terminate my account, or my business changes such that the Cloudflare offering is no longer suitable, I want a way to quickly migrate. It does seem that the main pieces are there and open source, but would likely require some amount of work to figure out and get into production. reply CharlesW 15 hours agoparentprev> Is there any documentation anywhere for this? PartyKit is open source (https://github.com/partykit/partykit/, MIT), so you could create your own back-end. The Socket.IO folks appear to have done this: https://blog.partykit.io/posts/party-io-a-socket-io-backend-... reply ensignavenger 14 hours agorootparentThanks! I will look into that. I knew it was Open Source and that it would be possible to create my own backend, I was just wondering if it had been actually been done/documented. This link answers my question, and PartyKit will go on my radar for future evaluation and possible use! :) reply neom 17 hours agoprevMia Wang big brain at work. Good stuff!! (https://x.com/miawang__) reply rasengan 18 hours agoprev> The acquisition of PartyKit by Cloudflare isn't just a milestone for our two teams; it's a leap forward for developers everywhere. This press release was written by ChatGPT. reply willsmith72 18 hours agoparenthahahah so i thought the same and decided to try and recreate it model = gpt4 prompt=write a press release for this announcement from cloudflare. Cloudflare acquires PartyKit to allow developers to build real-time multi-user applications and guess what was halfway through... \"The acquisition of PartyKit by Cloudflare is more than just the merging of two technology companies; it is a significant leap forward in reducing the complexity and barriers to entry for developers aiming to build the next wave of interactive web applications. \" too good to be true https://chat.openai.com/share/02976d40-f771-42ce-ae1e-738ba9... reply eagleinparadise 14 hours agoparentprevPress releases have always sounded like that before ChatGPT. reply pluto_modadic 18 hours agoparentprevhow do you get that from just that sentence? reply sdwr 18 hours agorootparentChatGPT has a naive optimism. It reaches for airy, meaningless, slightly metaphorical statements right away (when asked to support something, not when explaining). It also uses simple, but very clean grammar, and has a bit of a thesaurus feel where it has no attachment to any particular word. I've seen lots of people get it wrong, claiming that something is ChatGPT when it isn't. To my understanding, this is because they are negative matching - \"this sounds weird, so it must be AI\", or \"this is wrong, so it must be AI\", and not positive matching on ChatGPTs exact tone. reply hombre_fatal 17 hours agorootparentOn the other hand, press releases are overly optimistic, airy, and meaningless. ChatGPT being able to write this PR just shows how industry bog standard Cloudflare's PR is. It's like ChatGPT using the word \"synergy\". reply ethbr1 17 hours agorootparentprevGuess they incorporated a lot of HN training data. :) reply ptrwis 19 hours agoprevDurable Objects have a bit weird programming model for me, I hope this one will be easier. reply spxneo 17 hours agoprevhow does this compare to Supabases realtime features? I been generally confused about cloudflare pricing and its wide array of products (unsure which to use and when). reply lalalalalialia 15 hours agoprevIf you want to use something similar that’s not owned by a big company now, take a look at cord.com :) reply Benjamin_Dobell 8 hours agoparentAccount created 6 hours ago and has just posted this comment. Twice. This ah, probably doesn't come across the way you'd like it to. More than that, isn't this precisely the kind of product that you would want operated by a large cloud infrastructure provider? reply jakegmaths 14 hours agoprev\"Building experiences with real-time components was previously only accessible to multi-billion dollar companies\" ... what a load of nonsense. I've built them in a few hours, spending £5 per month for a server. reply lalalalalia 15 hours agoprev [–] If you want to use something similar that’s not owned by a big company now, take a look at cord.com :) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Cloudflare has acquired PartyKit, an open-source platform for creating real-time, collaborative, multiplayer applications, enhancing their serverless computing capabilities.",
      "The acquisition enables Cloudflare to offer developers a robust toolkit for building dynamic, interactive, and stateful applications using PartyKit's integration with Cloudflare's Durable Objects.",
      "This move signifies a significant advancement in redefining the landscape of serverless computing, making stateful applications more attainable and effective for developers."
    ],
    "commentSummary": [
      "Cloudflare acquired PartyKit to boost their platform with real-time features, prompting debates on hiring ethics and conflicts of interest.",
      "The acquisition sparked discussions on integrating real-time collaboration, AI, and standard APIs in the tech sector, addressing WebSockets, SSE, socket.io, Phoenix Channels, and billing concerns on Cloudflare Workers.",
      "Users generally view Cloudflare's acquisition of PartyKit positively, mentioning the advantages of leveraging Cloudflare Workers for real-time servers and collaborative initiatives."
    ],
    "points": 191,
    "commentCount": 74,
    "retryCount": 0,
    "time": 1712322224
  },
  {
    "id": 39946694,
    "title": "Apple Allows Game Emulators and EU Music Links in App Store",
    "originLink": "https://www.macrumors.com/2024/04/05/app-store-guidelines-emulators-music-app-links/",
    "originBody": "Apple Updates App Store Guidelines to Permit Game Emulators, Website Links in EU Music Apps Friday April 5, 2024 12:56 pm PDT by Juli Clover Apple today updated its App Store guidelines to comply with an anti-steering mandate levied by the European Commission. Music streaming apps like Spotify are now permitted to include a link or buy button that leads to a website with information about alternative music purchasing options, though this is only permitted in the European Economic Area. Music Streaming Services Entitlements: music streaming apps in specific regions can use Music Streaming Services Entitlements to include a link (which may take the form of a buy button) to the developer's website that informs users of other ways to purchase digital music content or services. These entitlements also permit music streaming app developers to invite users to provide their email address for the express purpose of sending them a link to the developer's website to purchase digital music content or services. Learn more about these entitlements. In accordance with the entitlement agreements, the link may inform users about where and how to purchase those in-app purchase items, and the price of such items. The entitlements are limited to use only in the iOS or iPadOS App Store in specific storefronts. In all other storefronts, streaming music apps and their metadata may not include buttons, external links, or other calls to action that direct customers to purchasing mechanisms other than in-app purchase. The European Commission in March fined Apple $2 billion for anti-competitive conduct against rival music streaming services. The fine also came with a requirement that Apple \"remove the anti-steering provisions\" from its App Store rules, which Apple has now done. Apple is restricted from repeating the infringement or adopting similar practices in the future, though it is worth noting that Apple plans to appeal the decision. Apple has accused Spotify of manipulating the European Commission to get the rules of the App Store rewritten in its favor. \"They want to use Apple's tools and technologies, distribute on the App Store, and benefit from the trust we've built with users - and pay Apple nothing for it,\" Apple complained following the ruling. In addition to updating its streaming music rules, Apple today also added games from retro game console emulator apps to the list of permitted software allowable under guideline 4.7. Guideline 4.7 permits apps to offer HTML5 mini apps and mini games, streaming games, chatbots, game emulators, and plug-ins. Apps may offer certain software that is not embedded in the binary, specifically HTML5 mini apps and mini games, streaming games, chatbots, and plug-ins. Additionally, retro game console emulator apps can offer to download games. You are responsible for all such software offered in your app, including ensuring that such software complies with these Guidelines and all applicable laws. Game emulators have managed to sneak onto the App Store several times over the years by using hidden functionality, but Apple has not explicitly permitted them until now. The rule change that allows for game emulators is worldwide, as is support for apps that offer mini apps and mini games. Tags: App Store, App Store Review Guidelines, European Union, Spotify [ 109 comments ]",
    "commentLink": "https://news.ycombinator.com/item?id=39946694",
    "commentBody": "Apple Updates App Store Guidelines to Permit Game Emulators, EU Music App Links (macrumors.com)187 points by bangonkeyboard 13 hours agohidepastfavorite123 comments jeff_tyrrill 10 hours agoThe emulator change is a minor rule change about bundling and is not what many of the reactions to the change think. What people seem to think this means: Open-ended retro game emulators like Snes9x and Dolphin are now allowed. (I don't think this is correct.) What the change is actually doing: If you are the licensed publisher of a retro game collection, you can now offer them in one app (including perhaps downloading additional games added to the collection later) instead of splitting them into individual apps. Each game must be individually vouched for.[1] What is not changing: \"Emulators\" have long been allowed if the emulated code is bundled with the app and it is officially licensed. [1] https://developer.apple.com/app-store/review/guidelines/ \"4.7 [...] You are responsible for all such software offered in your app, including ensuring that such software complies with these Guidelines and all applicable laws. [...]\" and \"4.7.4 You must provide an index of software and metadata available in your app. It must include universal links that lead to all of the software offered in your app.\" reply CharlesW 9 hours agoparent> What the change is actually doing: If you are the licensed publisher of a retro game collection, you can now offer them in one app (including perhaps downloading additional games added to the collection later) instead of splitting them into individual apps. How is this different than the one-app retro games collections that Apple has always allowed? (1) https://toucharcade.com/2011/04/06/atari-brings-100-retro-ti... (2) https://www.engadget.com/2012-02-24-midway-arcade-brings-jou... (3) https://www.theverge.com/2017/6/21/15845580/sega-forever-ret... reply jeff_tyrrill 8 hours agorootparentI think mainly the ability to download additional games, and more specifically, games emulated from a different platform rather than game content written as HTML/JavaScript. I may be wrong about the bundling in terms of the collection, but I still think this is more about Apple's general stance on \"stores within an app\", and the rule change is folding retro game emulators in as another exception to that, and not a change primarily about emulator allowability in general. reply sunpazed 6 hours agoparentprevInterestingly outside of games and consoles there are “emulators” that run classic HP calculators in the store. They emulate the HP Nut processor which runs small ROM dumps. reply TillE 8 hours agoparentprevGiven the policy, I'm still really unclear about how ScummVM was allowed into the iOS app store. Maybe it was a mistake, but it's been up there for months. There's no conceptual difference between interpreting SCUMM bytecode and interpreting 65816 machine code. reply chongli 1 hour agorootparentIt’s a business difference, not a conceptual one. No one cares if you want to fire up Secret of Monkey Island on your iPad. One company in particular really does care if you want to play Super Mario World on your iPhone. That’s the difference. reply al_borland 9 hours agoparentprevMy knee jerk reaction is to be disappointed by this, but I had an NES emulator on my first gen jailbroken iPhone back in 2007 or 2008. It was cool for a few days, but ultimately, I didn’t use it. reply bluescrn 9 hours agorootparentYeah, there's not much point bothering if you're limited to a touchscreen And if you're going to the effort of using a separate controller, you might as well use a separate gaming device. reply throwaway48476 6 hours agorootparentThere are controllers that integrate your phone and using your phone makes financial sense and reduces the hassle of having to carry a separate device. reply OatmealDome 11 hours agoprevNotably, Apple still does not allow non web browsing apps to use JIT recompilers. This precludes emulators for 6th generation and newer consoles (GameCube, etc) from running on the platform even with this guideline change. I submitted a DMA interoperability request for JIT recompilers, but Apple denied it on the grounds that it doesn't fall under Article 6(7) for \"multiple reasons\", including that JIT is only used by web browsers on iOS. reply apatheticonion 11 hours agoparentI'm not an expert in emulation but I am curious if one could recompile ROMs AOT such that JIT is not required by the emulator? Say, statically recompile the ROM on your PC then move the emulator-specific binary to the iOS device. Would such an approach be permissible by Apple? Is it possible to do so while sharing the source code for the JIT layer? I suppose the binary format must itself be natively compatible by iOS otherwise you'd need to have a JIT layer for your binary format - right? reply avianlyric 11 hours agorootparentHistorically the justification for limiting the use of JIT compilers is for security reasons, which does actually stack up. JIT compilers are one of few use cases where an application absolutely needs the ability to write data to memory, mark that memory region as executable, and then execute the op codes in that memory region. On iOS, other than Safari, no application, either built in or installed via the App Store is allowed to change memory permissions from writable to executable, and that acts as a cornerstone in iOS application sandboxing. Now there’s perfectly good argument that the security argument doesn’t really stack up anymore, given that sandboxing technologies have progressed a lot, and it should be possible to properly sandbox a JIT compiler or similar. But there’s no denying the fact that removing the ability for an application to execute arbitrary created op codes is a very good way to completely eradication a huge surface area for exploits. Especially when such restrictions are paired with static scanning of binaries before signing (which happens when any binary is produced for iOS, via Apples signing service). All of that is to say, there is a possible world where ROM are transpiled for iOS devices (using something like Rosetta), and loaded as signed binaries via emulation wrappers. But at point you’re basically having to create your own App Store, and sign a new app for each transpiled ROM. In short, it doesn’t seem likely we’ll see JIT powered emulators on iOS anytime soon, and, at least in this specific instance, Apple has a legitimate security reason for restricting their usage. reply apatheticonion 10 hours agorootparentIf Apple is compelled to allow users to run unsigned binaries (like Android) - would that allow for JIT emulators to run or is there something fundamentally blocking the execution of JIT code in iOS that prevents this? reply phire 9 hours agorootparentThere is no technical limitation, there is even an API for doing so. It's just that apple block any submissions using that API from the app store. reply avianlyric 9 hours agorootparentiOS itself almost certainly also blocks usages of that API as well, unless the binary is signed with the correct entitlements. But if Apple was forced to allow any binary to execute, and utilise any entitlement/API, then yeah there’s nothing stopping a JIT emulator running on iOS. But I think it’s very unlikely the EU would go that far, I don’t think such actions are needed for the EU to achieve their aims (liberalisation of app economy and markets). reply danielheath 11 hours agorootparentprevYou could do Rosetta style conversion up front of the complete binary to get around the JIT ban, but that’s still loading code at runtime. reply Wowfunhappy 7 hours agorootparentprev> Say, statically recompile the ROM on your PC Basically impossible. https://andrewkelley.me/post/jamulator.html reply wmf 11 hours agorootparentprevIIRC Apple also doesn't allow apps to load binary code at runtime. Redistributing derivatives of ROMs also sounds like a copyright problem. reply apatheticonion 11 hours agorootparentCould you recompile a ROM and embed it with a universal \"emulator\" game engine? (in the same way the OpenGoal project that recompiled Jak) I guess that would be illegal because you'd then need to distribute the game code. Perhaps a toolkit that allows users to compile the emulator+rom themselves? But then I guess Apple doesn't let users run their own unsigned binaries so that's not possible :/ reply VHRanger 11 hours agoparentprevLuckily for us both the Nintendo switch and the iPhone run ARM64, so you don't need a JIT to run yuzu/ryujinx on a phone! The bad news is that yuzus team is disbanded and never got the moltenVK backend done. And Ryujinx never got theirs to work on a phone. reply comex 10 hours agorootparentThat doesn't really help unless you bundle the game code inside the app executable. Otherwise you still need a JIT entitlement in order to map code as executable. reply layer8 11 hours agoparentprevYou could write a web browser that supports ROMs as script source.;) reply amelius 10 hours agorootparentOnly if Apple approves it. They have time and money for lawyers. reply extraduder_ire 10 hours agorootparentWhy would they need lawyers? They are writing and enforcing their own rules. I think enforcing compliance is more of an EU concern than yours. reply kevingadd 10 hours agorootparentprevConsidering the number of ads I see for \"gaming browsers\" like Opera GX, I wouldn't be surprised if someone tries to sneak an emulator onto the store that way reply phire 10 hours agoparentprevThere is a lot of space between interpreters and a full JIT that is under-explored. Because developers typically skip straight to a JIT when they find a interpreter isn't fast enough. Dolphin does have the cached interpreter, which eliminates some of the decoding overhead of a traditional interpreter, but I think you could go a lot further. Convert the PowerPC instructions to a optimal bytecode and apply various optimisations to that bytecode (function inlining, constant propagation). Common pairs and sequences of instructions can be replaced with a single bytecode implementation. Given how fast Apple's cpu cores are, I suspect it might be possible to get a optimising bytecode interpreter fast enough so GameCube and other 6th gen console emulators can run at full speed. reply int_19h 4 hours agorootparentI wonder how fast something like Forth-style direct threaded code could be on Apple silicon. reply hnlmorg 8 hours agoparentprevEarlier than the GameCube even. The N64 audio was a programmable chipset (it’s late in my timezone so please forgive me for not including the full technical details here) reply pridkett 11 hours agoprevSome of us remember back in 1999 when Steve Jobs announced that Connectix, a PSX emulator was coming to Macs. Different times, man. Luckily, YouTube doesn’t forget. https://youtu.be/3OqMcqRI-xA?si=lC2tbRWS-2UGe_8G reply throwaway48476 6 hours agoparentYoutube \"forgets\" a lot. My history has more deleted videos than not. reply sgerenser 8 hours agoparentprevConnectix was the company (known previously for making the QuickCam, the first webcam for Mac), Virtual GameStation was their PSX emulator. reply jwells89 8 hours agorootparentAlso the company behind Virtual PC[0], which at the time was the most capable emulator for running DOS, Windows, and other x86 operating systems on PowerPC Macs. They sold Virtual PC to Microsoft and dissolved in 2003. [0]: https://en.wikipedia.org/wiki/Virtual_PC reply mproud 4 hours agorootparentThere are some great retrospectives on Connectix, I encourage you to find them on YouTube. reply pininja 12 hours agoprevVery excited about this! But I’ve also been impatient and started using Eclipse for all of my Gameboy emulation over the last year.. it a PWA and uses local storage for game saves. https://eclipseemu.me/ reply snailmailman 10 hours agoparentI’ve been emulating DS games on my iPhone for a while with a web app pinned to my home screen. It warns to backup saves (and I have) but I haven’t had any issues yet. It lags a bit if my phone is in battery saving mode, but otherwise works flawlessly. Crazy that “old” but also relatively recent systems can just run in a web browser now. https://ds.44670.org/ reply agust 8 hours agorootparentAnother very good web app emulator is https://afterplay.io. It also works very well within the browser or installed on the homescreen. reply pininja 12 hours agoparentprevI’ve also enjoyed using desmume for DS emulation https://github.com/44670/desmume-wasm reply speps 12 hours agoparentprevWhat's a revoke? Why is it a problem? reply Pfhortune 12 hours agorootparentWhen you load an app on your own iOS device with a free developer account, that app will fail to open (as in be revoked) after seven days unless you refresh it from a Mac (or Windows system with AltStore or similar). reply rezonant 12 hours agorootparentprevGuessing here, but I suspect they are referring to the revocation of the enterprise signing certificates used by gray-market iOS app stores, since native app emulators could only be distributed that way until now. It's whack-a-mole- the stores sign their executables with a new certificate, Apple finds out about it, revokes the certificate. When that happens, I imagine the software signed by that certificate will no longer run on the devices the software was installed to. reply pininja 12 hours agorootparentprevI assume they’re referring to when the App Store revoked everyone’s emulator apps. For Apple to break these they’d probably need to remove standard web APIs. reply criddell 12 hours agoparentprevnext [2 more] [flagged] Pfhortune 11 hours agorootparentThat's a very negative take, one that disparages the hard work of vast swaths of people that not only work to optimize WASM in browser engines but also emulator developers. Likely the small payload/resource-demands of a Gamegear ROM + retroarch core are far lighter than most modern websites. Your battery life would probably be shorter visiting a random ad-filled news website in your browser. reply RedComet 12 hours agoprevThe use of \"retro\" is interesting. Probably intended to exclude Switch emulators, but what will the cutoff be? reply duskwuff 12 hours agoparentRealistically, the cutoff is likely to be \"can you point to a legitimate source of ROMs\". There's enough fan games for some older consoles like Atari 2600 or NES that this might be possible, but it certainly wouldn't be possible for newer consoles like the Switch. reply willis936 12 hours agorootparentIt's much easier to get your hands on a switch game and rip it with your hacked console (all perfectly legal acts) than it is to get a 20 year old artifact. reply galleywest200 10 hours agorootparentThis is not really the case. The entire ROM catalogues of retro console systems are archived on sites for download. reply duskwuff 8 hours agorootparentThe question isn't whether the ROMs are possible to obtain; it's whether there are sources of legitimate ROMs an app developer can direct users towards. The sites you're referring to are offering pirated ROMs. reply ascagnel_ 11 hours agorootparentprevProbably up through the PSX, at least in the US: - hardware to dump your own cartridges is available and doesn’t require breaking copy protection (which at that point was more around locking out publishers that didn’t sign license agreements rather than unauthorized duplication), and popular older systems are fairly well understood at the interconnect level at this point - PSX games themselves don’t use encryption to protect games, just some chicanery around CD standards so burners of the era wouldn’t make unauthorized duplication as much of an issue; additionally, the Bleem! case officially recognizes PSX emulation as legal Once you get to the PS2/GameCube/Xbox generation, you start to run into systems that include encrypted executables that make DMCA-compliant emulators basically impossible. reply RedComet 4 hours agorootparentInsightful but disappointing. reply goryramsy 12 hours agoparentprevThere are Switch emulators for iOS [0] [0] https://github.com/emuPlace/Sudachi reply goryramsy 12 hours agorootparentForgot about Folium. https://folium.emuplace.app/changelogs reply jsheard 12 hours agorootparentprevThey may exist, but the implication is they won't be allowed on the App Store. reply goryramsy 12 hours agorootparentAll depending on an ambiguous ’Retro’ requirement. Would an out of production device be ‘retro’? If so, then Switch 2’s ~2025 upcoming release would retro-ify many games. I guess we’ll see soon based on what passes app review. reply resource_waste 10 hours agoprevCool! I welcome the blue bubbles to my typical airplane ride for the last 12 years. I remember having a work iphone and bringing an old motorola smartphone on the plane just so I could play Zelda OOT. reply retskrad 10 hours agoprevWe need EU to force Apple to accept alternative browser engines on iOS. The iPad desperately needs desktop Chrome to become useful. reply threeseed 10 hours agoparentnext [7 more] [flagged] miohtama 10 hours agorootparentI will run Firefox with uBlock on mobile. I hope many others will as well. reply threeseed 10 hours agorootparentFirefox has about 3% market share on desktop and declining each year. And there are plenty of ad blockers on iOS. reply sangeeth96 9 hours agorootparentYes but almost all shackled by Apple. Orion Browser is probably the only one I've come across that lets me install uBlock and it actually seems to work. None of the other ad-blocking extensions for Safari have the same power as uBlock as per my understanding and usage. reply InvaderFizz 9 hours agorootparentI use AdGuard Pro on iOS Safari. I generally never see ads. The experience is pretty close to ublock origin on the desktop. reply hu3 8 hours agorootparent$10 closed source app that monitors everything in my browser. Hard pass. Classic Apple swamp garden where users have to buy black box apps that are often free and open source in other platforms. reply cqqxo4zV46cp 10 hours agorootparentprevnext [2 more] [flagged] lern_too_spel 9 hours agorootparentStill better than leaving people stuck on Safari. Now Apple will have to work to make Safari better. reply crooked-v 12 hours agoprevI have to wonder if behind the scenes there was any push here from companies that put out licensed emulation collections. For example, there are a ton of different SEGA collections that are nice GUIs around various ROMs, where doing a native port would both be a ton of work and kind of defeat the point of trying to faithfully carry across the original with exactly the same quirks. reply wjq 5 hours agoprevThis is a great change coming from Apple. I was initially surprised by this considering how Apple usually dislikes it when you want to find a way to run your own binaries on iOS devices. reply voytec 12 hours agoprevApple has been user-hostile on all possible fronts in their efforts to enforce renting model over media ownership. Some 10 years back iTunes had an option to stream or share media over network. It was cool to stuff iMac's 3TB HDD with audio CD rips and have all this music available on an iPhone or any other iDevice connected to the same local network. I had a VPN connection from iPhone to home network and all CD rips available anywhere. To avoid confusion: I'm talking about iTunes-specific functionality, not media files sharing. When iTunes was opened on an iMac, all iDevices in LAN automatically had all the media available through local iTunes apps. And then they \"renamed\" iTunes to Music... But even during the iTunes era they made it artificially difficult to own own media. One would think (or maybe I was delusional?) that media library fully synced from desktop iTunes to iPhone iTunes serves as kind of a backup. Nope - turns out that when desktop disk dies, one can't sync media from iPhone to the new desktop disk. Desktop iTunes was happy to suggest wiping iPhone media as a sync method. reply oneplane 12 hours agoparentiTunes Home Sharing and RAOP are still present and still work fine. Not sure what makes it not work for you (except the VPN connection which isn't allowed, Home Sharing is only for a single local subnet, those were the rules from the start as can be expected with the RIAA etc.). As for owning media, that was pretty easy, got a bit harder for a while and then got easy again. You can get everything you buy with no DRM and play it wherever you want for as long as you want. There are some limitations with iTunes Match AFAIK because again, recording industry/labels said no. reply WWLink 12 hours agoparentprevIIRC you actually could copy from the phone or ipod back to the computer but you had to turn off automatic sync first. reply cqqxo4zV46cp 10 hours agorootparentCorrect. reply DrNosferatu 10 hours agoprevBy not allowing me to run the full gamut of emulators - on the hardware I own - Apple is depriving me of my rights as an EU citizen. reply aeyes 8 hours agoparentYou can run whatever you want if you sideload it, even apps with a JIT compiler. This is about offering apps in the app store. reply Wowfunhappy 2 hours agorootparent> even apps with a JIT compiler No you can't. Altstore does this with a hack, it enables remote debugging, which requires you to be on the same wifi network as the server. reply thih9 12 hours agoprevHave any emulator apps been published and approved already? reply internetter 12 hours agoparentApp store review isn't that fast reply rezonant 12 hours agorootparentWe've been waiting since holidays last year for one of our updates to be reviewed. reply pipeline_peak 12 hours agoprevSteve Jobs announcing PlayStation emulator at MacWorld https://youtu.be/3OqMcqRI-xA?si=nUkGn6vLrLLMiGOP reply Wowfunhappy 12 hours agoparentThis is really cool. However, I think an underrated difference between then and now is that you could physically put a commercial Playstation disc into a standard CD drive and read it, no console hacking required. reply ascagnel_ 11 hours agorootparentIt’s trivially easy to take that same PSX disc, make an image of it, and load that into an emulator today. reply D13Fd 11 hours agorootparentThe difference is that the PSX disc had some semblance of DRM or at least indicated ownership. Most ROMs are just copied. reply pipeline_peak 11 hours agorootparentprevThat standard usage is part of what killed the Dreamcast. Just burn an iso of Sonic and throw it in. reply rezonant 11 hours agorootparentInterestingly, The Dreamcast's GD-ROM format was nonstandard enough to not be copyable with a normal CD burner, at least at first. They used CAV + cutting the disk speed in half in order to write more data (up to 1.2GB). https://en.wikipedia.org/wiki/GD-ROM I think what you are referring to is the fact that the Dreamcast itself didn't only read from GD-ROM- it was perfectly happy to execute code from a CD-ROM via the MIL-CD format. > The \"foot in the door\" came from a seemingly obscure capability of the Dreamcast to boot not from a GD-ROM but from a CD-ROM. Originally intended to add multimedia functions to music CDs, the functionality called \"MIL-CD\" was never used much, accounting for a mere seven karaoke applications. [1] Which meant if you were able to acquire a GD-ROM image, and you could repack it into the CD-ROM's max capacity of some 650MB, then you could burn it to disc and play it without any modification of your Dreamcast, at least once the other protections were defeated. For games that actually utilized more than a CD's worth of data, usually pirates would recompress or remove images, video files and other assets to save space. So that copy of Sonic might not behave exactly the same as a genuine copy, simply by the necessity of the format (not that I know if Sonic required this sort of rework). Fascinating post from Fabien Sanglard for this: [1] https://fabiensanglard.net/dreamcast_hacking/ reply extraduder_ire 10 hours agorootparentWouldn't CAV decrease the amount of data that can be stored unless you're compensating for it elsewhere? I assume they used CAV so they wouldn't have to change the disc's speed when seeking to a different area of the disc. The MIL-CD thing reminds me of the expansion port on very early playstations which was never used officially, but allowed exploiting the console by plugging a modchip into it. reply Wowfunhappy 9 hours agorootparentprevI know the Dreamcast had piracy issues but I think the situation must have been more complicated. PS2 games can be read by standard DVD drives, and PS3 games can be read by standard BluRay drives. reply doublerabbit 12 hours agoprevSo what, we're now back to 2018 when emulators were all the hype? Cool. Err, why am I flagged from this thread? - I mean seriously cool. 2018 was the hype when emulators were the thing. It's great to see such. reply talldayo 12 hours agoparentThat's not even that far back either, GBA4iOS has builds going back to 2014. 2018 was the year you could emulate Nintendo games... on the Switch: https://www.libretro.com/index.php/category/switch/ reply ben_w 12 hours agoparentprev2018? I missed that wave. I seem to remember they were cool in the late 2000s or so? Perhaps that was just me… reply oneplane 12 hours agorootparentI think it might be around the same time as the RetroPie wave when it got much more publicity than the early days around 2013, probably somewhere between the release of the Pi 3B and Pi 4B (2018-ish?). Around that time it was mostly N64, SNES, GB, GBA etc. Maybe even some PS1, but mostly just titles that were plausibly playable on a smaller screen or with lower resource consumption. Wouldn't be surprised if it gets attention on iOS when there is a larger public mindshare around such a topic. reply amlib 12 hours agorootparentprevi remember emulators really getting popular as a means to play the original pokemon games without owning a gameboy back in the late 90s... reply Apocryphon 12 hours agorootparentYeah, Bleem! was around since 1999. reply MBCook 11 hours agorootparentWhen was UltraHLE? Like ‘98? reply withinboredom 12 hours agoprev> They want to use Apple's tools and technologies, distribute on the App Store , and benefit from the trust we've built with users - and pay Apple nothing for it This quote smells like a \"self-induced problem\" since they literally require developers to buy or rent their hardware to build an app and also (at least, previously) required developers to publish on the App Store. If I could build an iPhone app on my Windows machine and publish an app from my website, then their argument wouldn't make any sense. reply benced 11 hours agoparentApple has this exactly backwards. Their platforms have value because of developers. There’s a reason Apple added an App Store after the app-less first year of the iPhone. How many people would switch to android, even if they like apple’s design better, if Apple had no apps? It’s just a farcical claim on their part. reply ben_w 12 hours agoparentprevMild disagree, though I can appreciate the sentiment. Why do developers want to publish and distribute on the App Store? As a dev myself, my anecdotal answer is: because I can make money doing so. Why can I make money doing so? Because Apple built trust with the users, and because they developed the tools and technologies that made their OS worth paying significantly more for similar tech specs. reply Vespasian 11 hours agorootparentI can see where you are coming from and once we have meaningful competitive alternatives to the AppStore (so after whatever they try in the EU with the platform fee and related shenanigans is forced to switch to a sane model) we can make a judgement on that. Right now there is simply no way to know whether people are interested in the AppStore itself or simply selling to people who own iPhones (which is more likely but I may be wrong). If I were a high class furniture company and the developer building roughly half of the populations' homes could enforce that all furniture sold to their customers needs to be vetted and distributed by them, of course I would play by their rules and even sing their praise. Apples terms (all of them) are a direct result of their ability to stifle any competition on devices their customers paid them good money for. Nothing they do is problematic unless they are able to \"my way or the highway\" their rules on the hardware level. Apple dug too deeply and greedily and they woke up the sleeping regulatory giants which are now changing the rules. reply lwkl 10 hours agorootparentWe have a direct comparison on the desktop be it Windows or macOS and it is definitely harder to sell software there. The App Store and Play Store buying software a lot easier and increased the size of the market. Similar to Steam for PC games. But I also think that Apple should probably give developers better conditions. As a customer of Apple I selfishly prefer Apple continuing to extract service revenue from developers. Because their shareholders expect growth and that has to come somewhere and I don’t want to pay for it. reply makeitdouble 5 hours agorootparent> I don’t want to pay for it。 I don't get how you're not paying for it...assuming you're an iOS user, you bought apps and the devs passed on you the extra cost to pay Apple. Not counting for the ads you saw in the Store. You probably also bought extra space to backup your phone in iCloud, and as Apple is the only way for that. Litteraly anything you paid on the platform went first to Apple. reply lapcat 8 hours agorootparentprev> We have a direct comparison on the desktop be it Windows or macOS and it is definitely harder to sell software there. How so? On desktop, the race to the bottom hasn't hit as hard, and customers are more willing to pay sustainable prices for software. reply talldayo 11 hours agorootparentprevIf the App Store wasn't the only place to download software on iPhone, you'd have more of a point. Instead, it doesn't matter what the relationship is between the user and Apple since there's only one option anyways. Apple wants to make the App Store look like Steam; at best, they're the built-in Microsoft store. reply ben_w 11 hours agorootparentI remember when the App Store didn't exist, and devs were begging for one. And then Apple accidentally discovered it was a money printing factory when they got around to it. Now the MacOS App Store, that vibes with the MS store. reply lapcat 11 hours agorootparent> I remember when the App Store didn't exist, and devs were begging for one. They weren't begging for an app store. They were begging for third-party native apps. The exact method of distribution of third-party apps is a different matter. From 1977 to 2007, all third-party apps on Apple platforms were independently distributed. (Some boxed software was sold in retail Apple Stores from 2001, but the software was not exclusive to Apple Stores.) reply heavyset_go 8 hours agorootparentprevNobody was begging for an app store lol reply makeitdouble 11 hours agorootparentprev> Why do developers want to publish and distribute on the App Store? Because it's half of the market, and more depending on who you're targeting. I worked at a shop where we were asked for Blackberry apps alongside with iOS and android apps, not because they had strong feelings about BlackBerry, but because it was 3% of their market share and it was above their cutoff for support. reply withinboredom 12 hours agorootparentprev> I can make money doing so. Not everyone is interested in making money. reply amelius 10 hours agorootparentprev> Why can I make money doing so? Because Apple built trust with the users, and because they developed the tools and technologies that made their OS worth paying significantly more for similar tech specs. Nah. It's because developers put a lot of effort in making Apple's platform great for many users. reply staplers 11 hours agorootparentprevbecause they developed the tools and technologies that made their OS Not quite. They used quite a few FOSS to build their products then pulled the ladder up behind them. Remove the app store requirement and the market will indicate just how useful the app store monopoly is to the end user. reply ben_w 11 hours agorootparent> They used quite a few FOSS to build their products then pulled the ladder up behind them Not only but also. > Remove the app store requirement and the market will indicate just how useful the app store monopoly is to the end user. Android suggests: fairly important, even though it could be replaced. reply stale2002 11 hours agorootparentprev> Because Apple built trust with the users, and because they developed the tools and technologies Hey if those tools and technologies on the Apple App Store are so valuable, then Apple has nothing to worry about. Developers will just stay on that app store. If, instead, other competing options are better on some metrics than Apple's, then that is a situation where developers would move off of the app store. It seems like we will find out how valuable that app store really is soon, won't we? reply ben_w 56 minutes agorootparentTrust was also on that list, and that's absolutely a thing they can lose. So far as I can tell, \"trust\" is the only reason Apple has for their rules about sexual content. reply Drakim 12 hours agoparentprevTo me it smells like flat out dishonesty. They are pretending the App Store is this premium high quality service that the riff-raff wants to get unfair access to, while they have actually been fighting tooth, claw, and nail to make any other alternative way of getting apps onto the iPhone physically impossible. If I wanna make an app for my mom's iPhone, I *can't* because Apple is preventing me. All while saying I'm trying to take advantage of them by wanting to get my app on the App Store. While working hard to make sure I have no other options. It's one small step removed from \"stop hitting yourself\" logic. reply withinboredom 12 hours agorootparentFurther, they actively stifle competition on their app store. Want to launch an MVP? It's \"too similar to other apps in this market.\" reply ben_w 12 hours agorootparentWhile I doubt they're going to be good judges of similarity, in the cases where they are correct that it is too similar, you don't have the \"V\" part of \"Viable\". > “All happy companies are diferent: each one earns a monopoly by solving a unique problem. All failed companies are the same: they failed to escape competition” — I may be creeped out by the guy himself, but I think Peter Thiel is right about that. reply withinboredom 11 hours agorootparentEveryone starts in the womb, but very few of us tread the same paths. reply ben_w 11 hours agorootparentI think the human analogy of an MVP is around when they can stand upright and talk, perhaps even a bit later than that. Before birth we're definitely a pre-release; but we won't reach product-market fit until whatever our culture counts as a coming-of-age ceremony. reply Pfhortune 11 hours agorootparentprevIsn't this just picking winners with more steps? reply threeseed 10 hours agorootparentprev> If I wanna make an app for my mom's iPhone, I can't because Apple is preventing me You can. You just add her to TestFlight and renew the app every 3 months. reply talldayo 13 hours agoprev [–] Better late than never...? Watching this all get walked back is kinda surreal, makes you wonder what the actual precedent was for keeping them off the App Store in the first place. There really shouldn't be that many hoops to running GBA4iOS on hardware you paid for. reply kccqzy 12 hours agoparentThe actual reason was that Apple wants to encourage native development instead of targeting some other platform and then emulating or simulating that on iOS. At one point they even required all iOS apps to be written in only C, C++, Objective-C, Objective-C++, JavaScript and no other languages. They walked that back almost immediately. reply jwells89 12 hours agorootparentI think they wanted to somewhat replicate what they had on macOS, where the best and most popular apps were those built by indie/boutique dev houses that cared specifically about building great iOS apps. Lowest common denominator apps that treated iOS as a generic mobile target (and thus, ignoring platform conventions and such) were undesired. I’m not sure that ever could’ve happened given the popularity of iOS, though. Companies like Panic and Omni Group don’t have the sort of firepower it takes to compete against the sheer amount of money poured into marketing by Facebook, Google, VC-backed startups, etc. reply talldayo 12 hours agorootparentprevWell that's the part that sorta confuses me. There were a lot of high-quality emulators that were native to iOS, and sideloading them was the only way to use it. There was also the same bog-standard port of Retroarch et. al., but developers really did put effort into making high quality, even Open Source, iOS-native emulation software. The sinister side of me wants to say that stopping emulation forces more users down the IAP/microtransaction feedback loop in order to entertain themselves. The rational side of me wants to say that Yoshi's Cookie isn't the Fortnite killer, but the whole thing feels icky to me nevertheless. reply withinboredom 12 hours agorootparentprevI vaguely remember this as well, but that wasn't the only reason. The other reason was security/ability to review apps. If an app can run arbitrary code, then they don't know if it contains a virus or something else to escape the sandbox. Or something like that. This was all quite a long time ago and Google isn't being super helpful in searching for old posts. reply Mathnerd314 12 hours agorootparentHere is an example removal (2021): https://www.imore.com/apple-going-remove-idos-2-emulator-app... It seems that they considered loading game images as \"running executable code\". So in particular what was banned was running code downloaded remotely, meaning any emulator that could download game images from the web or load game images from the filesystem was banned. reply simion314 12 hours agorootparentprevI bet it is not about the viruses, Apple does a bad job at catching malware. They are very concerned if a developer might show some link that would educate an apple user that they can get discounts outside the App Store so it is clear that all was for the money. If you have an emulator and then say get some old game from Gog and play it then Apple does not get their 15-30% cut, they want you to buy a game from their store instead. reply withinboredom 12 hours agorootparentOh, no doubt this is ALL about money. I was just recalling the \"official\" reason. reply ben_w 12 hours agorootparentprevThat rings a bell for me too, FWIW. reply modeless 11 hours agoparentprev [–] Yeah, funny how the threat of actual competition (even crippled as it is) promotes user-friendly policy changes. Imagine that. I think the reason was that Apple didn't want to get sued by Nintendo. They use the same locked down platform strategy as consoles so it would look bad if they were complicit in circumventing other platforms' restrictions. Still a lame reason. I definitely expect some litigation related to emulators on the app store though. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Apple has revised its App Store policies to align with a European Commission ruling, enabling music streaming apps in the European Economic Area to incorporate links to alternative music buying choices.",
      "This adjustment comes after Apple was penalized $2 billion for engaging in anti-competitive behavior.",
      "Furthermore, Apple now allows game emulators, HTML5 mini apps, and mini-games on the App Store globally."
    ],
    "commentSummary": [
      "Apple has updated its App Store guidelines to allow licensed publishers of retro game collections to offer them in one app, with the option to download additional games later.",
      "Emulators are now permitted if the emulated code is officially licensed and bundled with the app, sparking debates on ROM legality for older console systems and emulators for newer ones like the Switch.",
      "Users are seeking alternatives to Safari due to its limitations, exploring options like Firefox and ad blockers, amidst ongoing discussions about Apple's tight control over the App Store and its impact on developers and competition."
    ],
    "points": 187,
    "commentCount": 123,
    "retryCount": 0,
    "time": 1712348216
  },
  {
    "id": 39940959,
    "title": "A Lego Model Unveils Financial Capitalism",
    "originLink": "https://www.asomo.co/p/a-lego-model-of-financial-capitalism",
    "originBody": "Share this post A Lego Model of Financial Capitalism www.asomo.co Copy link Facebook Email Note Other Discover more from Altered States of Monetary Consciousness I explore the frontiers of modern money, and draw pictures of it to help you see our economic system with new eyes Over 5,000 subscribers Subscribe Continue reading Sign in A Lego Model of Financial Capitalism Unboxing the dark arts of finance Brett Scott Apr 04, 2024 20 Share this post A Lego Model of Financial Capitalism www.asomo.co Copy link Facebook Email Note Other 12 Share Dear readers: this piece builds upon my Lego Model of Corporate Capitalism Our economies are held together by money, and - most of the time - we hand it over in exchange for goods or labour. Occasionally, however, we hand it over in exchange for future money. For example, if you buy a share on the stock-market, you’re handing over money for a contract promising you a cut of the future profits of a company. This type of exchange, in which we exchange money for promises-for-future-money, is called financial exchange, and the financial markets are where it happens. Like many markets, the financial markets have a retail side - the smaller players like you and me - and a wholesale side, the mega players like funds, commercial banks and investment banks. The latter players cluster in big cities like London, New York, Singapore and Hong Kong, and in A Lego Model of Corporate Capitalism I showed them taking the lead on capitalizing international corporations. They ‘charge up’ corporate entities with money in exchange for financial contracts like shares and bonds, after which the corporates can blast that out to mobilize workers and suppliers to produce stuff… That stuff is then is sold to customers, and the revenues are refracted out as bonuses to management, interest to creditors, taxes to governments and dividends to shareholders. Building a Lego balance sheet The company shown above is some kind of industrial corporation, but let’s start from scratch in a different sector. Let’s say you’re actually a wealthy property developer who wants to build a luxury office complex for startups in down-town Manhattan. You envision a 6-storey building with open-plan workspaces, a meditation den, a fitness spa, and even sound-proofed booths for therapeutic screaming when the existential emptiness of yuppie life kicks in. Here’s the vision: Above I said ‘you want to build’, but that’s just a colloquial figure of speech. It’s not like you’re going to turn up with a spade and trowel to lay foundations for this building. No, what you actually want is for a thousand builders with specialist skills, equipment and materials to turn this vision into a reality. You nevertheless want to claim ownership of what they build, so to make sure they have no ownership rights, you need to approach them as suppliers selling goods and services in the open markets. That’s going to cost you about $100 million. The way to obtain that money is through financial exchange: you need investors to give it to you in exchange for promises-for-future-money. Investment banks are specialists in convincing big investors to do this, but this is a small-ish project and you don’t want a massive investment bank like Goldman Sachs. Instead, you want a small boutique investment bank. You find one called BlueGate Partners. On their website they describe themselves as follows: That phrase ‘debt and equity capital’ is finance slang for creditors and shareholders who will put in money for different promises-for-future-money. ‘Equity investors’ are shareholders: they put in money in exchange for shares of ownership that will entitle them to a morphing stream of future money (dividends). ‘Debt investors’ are creditors: they put in money in exchange for a promise for an fixed amount of future money (interest and principle). The promise given to equity investors is relative - the returns depend on how well things turn out - while the promise given to creditors is absolute - the amounts remains the same regardless of circumstances. From a legal perspective, absolute promises tend to be senior: they get dealt with first if everything goes to shit (which becomes particularly important in bankruptcy proceedings). ASOMOCO is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber. Subscribe Equity and debt investors will jointly capitalize projects or companies alongside each other. That said, the specific balance of power between them - and between the relative and absolute promises they’ve extracted - can create some interesting properties. One of these is leverage, the phenomenon by which debt investors amplify the returns of equity investors in exchange for protection (equity investors agree to absorb the first losses in a project, but also get to claim amplified gains). Leverage increases as the ratio between debt investors and equity investors increases, so the first thing you and BlueGate will work on is the optimal mix of equity and debt. BlueGate suggests a ratio of 1:4, with 20% equity and 80% debt. Raising equity Phase 1 is to deal with the equity chunk, which will be $20 million in total. BlueGate and your laywers set up a new legal entity, which you name Bloks Inc. You’re going to be the lead investor, and will put in $5 million of your own money for 25% of the shares. BlueGate assures you that they are experts in ‘equity placement’, and can find a home for the remaining 75% of the shares. They have many friends at funds who can be convinced to put up the other $15 million. After a few weeks, and a range of meetings, BlueGate’s team secures pledges for $5 million from a ‘family office’ that runs money for the super-rich, $5 million from an offshore fund, and $5 million from a local property investment fund. The $20 million equity chunk is now ready, but it will only be enough to cover the planning, permits, foundations and ground floor. Raising debt So, Phase 2 of the plan is to raise $80 million in debt financing. Again, BlueGate showcases their extensive ties to the super-rich and the super-big: They want to create a blend of different debt investors (creditors), so their first step is to approach two commercial banks. They get each of them to grant you $20 million in credit (incidentally, this will involve those banks creating new money). This $40 million can probably scrape you another three floors… There’s still one more normal floor and a fancy roof level to be financed, plus all the trimmings, so BlueGate now approaches a range of specialist funds and high-net-worth individuals to convince them to buy bonds. ‘Buying a bond’ is just the act of lending money in exchange for a fixed-promise-for-future-money encoded into a tradeable contract (‘bond’). Now that both the equity and debt financing is in place, let’s zoom out and see our Bloks Inc. corporate circuit in action. Imagine the money from the creditors (debt investors) and shareholders (equity investors) charging Bloks up like a battery. That money is then blasted out to mobilize a small army of contractors, suppliers and construction workers who will make the building emerge out of the ground as the money runs down. Share As the workers leave, you’re left with part ownership of a completed building, alongside a bunch of other financiers who also want a cut. To realize that cut, however, you need to make a profit, but where’s that going to come from? You need a customer… You consider trying to manage the property yourself, finding renters who will pay. In this case your customers would be startups buying access to the building. Alternatively, you can just try flip the building by selling the whole thing to some much bigger property holder. You decide to go with this latter strategy, and BlueGate even has a bespoke service to help you find a buyer for the thing they helped finance. They introduce you to a major real estate investment trust (REIT), that has a pre-existing portfolio of buildings that they own and rent out. From the perspective of this REIT, Blok Inc. appears in their world as a new potential supplier trying to flog them a new asset to add to their existing portfolio. The REIT boss instructs his analyst workers to do an assessment of your building… The sale Let’s assume that the REIT decides to buy the building. This is where leverage can get fun. If the rental market is solid, the analysts might suggest a price of $120 million for the building. From the combined perpective of the equity and debt investors in your project, that’s a 20% profit relative to how much the building cost to build. Nevertheless, given that the debt investors’ cut is absolute - it stays fixed - none of that relative increase goes to them. The entire increase accrues to the equity investors, which means - relative to their opening stake - their money just doubled from $20 million to $40 million (with your personal stake going from $5 to $10 million). That’s leverage for you. It’s sometimes called ‘gearing’, because just like a gear might amplify the affect of a foot pressing down on a bicycle pedal, leverage transmits an amplified positive return to the equity stake. Here’s a simplified representation (it’s simplified because the amounts shown don’t account for interest owed to debt investors, but let’s just ignore that): Unfortunately for you, gearing works both ways. If, for example, the building gets completed just as a global pandemic hits and demand for office space plummets among tech startup workers, the analyst valuation of the building might crash to $90 million. This hits the equity investors first. In this case, a 10% loss relative to building costs crushes the equity by 50%. You get an amplified version of the loss. The debt investors take their absolute share and leave. BlueGate mourns your loss, after which they take their advisory fee - which might significantly eat into that remaining slice you have - and leave. Calling all lecturers and professors: Next week I have the pleasure of presenting my Lego models to students at Stony Brook University in New York. If you’d like me to talk to your students, drop me a line! Playing the Advanced Finance Game What I’ve shown above is pretty basic finance, and there are two things to say about basic finance. Firstly, it’s built upon a much deeper and richer foundational layer of ecological systems, human beings, politics and - eventually - monetary systems, all of which I cover in my Intro to Economic Life course. Secondly, basic finance can be massively complexified. There are many exciting, and increasingly dodgy, things you can do to play a more advanced finance game, such as: Offshore finance: build complex legal structures, like a shell company that owns a shell company that lends to a shell company that is also owned by you, so that it can buy the shares Financial engineering: create new and weird combos and hybrids of debt and equity (e.g. Silicon Valley thrives on ‘convertible notes’, debt instruments with inbuilt options that can convert them to equity) Finance your financing: In our original scenario above, you were required to put in $5 million, but you could borrow $4.5 million of that from another bank (or other debt investors), which means you could put in $500k to get a 25% equity stake, which means you’re now leveraging your leverage! (something that hedge funds are notorious for doing) Securitization: the original banks involved might take their stakes and place them in a new offshore vehicle, alongside 1000 other loan contracts they’ve harvested, after which they can ‘tranche’ that package into different equity and debt slices that can be sold off. Now the combined interest that accrues to the pool of loan contracts can get refracted out like a monetary rainbow to a whole range of new investors, some of whom might insanely leveraged Derivatives: you might make bets on the side to protect yourself against changes in the average price of properties (e.g. property index derivatives), while the banks might be using interest rate derivatives to manage various aspects of their exposure. Perhaps your bond-holders might pay away some of their interest into a credit default swap (CDS) offered by an investment bank, in exchange for compensation in the event of your bankruptcy Mix it all up! Perhaps that investment bank can take the other side of that credit default swap, and place it - alongside other CDS contracts - into a new offshore vehicle. Now they can sell the tranches of that new SYNTHETIC CDO! This is highly recommended if you wish to trigger a global financial crisis. There are more fun instalments of my Lego Corporate Capitalism series to come, plus much more, so sign up below! Subscribe Leave a comment 20 Share this post A Lego Model of Financial Capitalism www.asomo.co Copy link Facebook Email Note Other 12 Share",
    "commentLink": "https://news.ycombinator.com/item?id=39940959",
    "commentBody": "A Lego model of financial capitalism (asomo.co)179 points by Dogwash24 22 hours agohidepastfavorite79 comments bombcar 18 hours agoA variation of this is why owning your house has (historically in the USA) been such a \"deal\". Because you put 20% down (or less) in cash, borrow the rest, and the appreciation goes to you. At 20% down, if the house goes up 20% you've doubled your money. At 5% down, it's 4x (minus transactional costs). As long as you ignore all the other aspects, like inflation, maintenance, etc, you have a pretty darn good return on paper. reply RHSeeger 16 hours agoparent> As long as you ignore all the other aspects, like inflation, maintenance, etc, you have a pretty darn good return on paper. That's a pretty significant amount of things to ignore. When you include closing costs (10-15k in NY) and insurance, you're underwater on your house for a pretty long time. reply mitthrowaway2 13 hours agorootparentInsurance and maintenance are costs of shelter, though. That's an exchange for the benefit of enjoying a roof over your head -- it shouldn't be considered a financial loss from an investment perspective. If you were renting out the property instead of living there, the renter would be paying those costs through their rent. reply RHSeeger 12 hours agorootparentMy apologies, I meant interest and maintenance. And I would say that maintenance certainly counts as a financial loss when you're considering the property from an investment perspective. If it was a paper investment (stock/bond/whatever), it wouldn't exist. It's part of that specific investment. reply mitthrowaway2 12 hours agorootparentMy point is that unless you're living in the woods, you have to pay for maintenance. Maintenance has a cost, but not an opportunity cost. If you choose to invest in tech or gold or whatever instead of a home, then you're still paying indirectly for maintenance for whatever structure you're occupying. At least as a homeowner you do have the freedom to advance or defer certain maintenance work according to your budget. reply staplers 11 hours agorootparentprevIf it was a paper investment Those have \"maintenance\" fees too at most brokerages. reply bombcar 10 hours agorootparentAnd even if they don’t, there’s still maintenance somewhere being paid by someone. Some are lower maintenance than others (physical gold you have to secure, etc) but everything needs at least some work to keep from wasting away. The point is that the simplistic “I made money selling my house” takes into account few if any of these costs (many which can be accounted as valid for the need of shelter). reply mulmen 10 hours agorootparentprevI rent. I pay something like $15.00 a month for insurance. My basement flooded and my landlord had to pay for an emergency plumber. It’s “built into the rent” but I still don’t have to bear the cost. My landlord assumes the risk of being ready to cover an expensive maintenance item. reply xyzelement 8 hours agorootparentYes but you compensate them for this risk via your rent. reply chiefalchemist 8 hours agorootparentThe landlord gets equity in the property. The tenant get freedom, peace of mind, etc. It's a question of priorities and personal values. reply paulddraper 15 hours agorootparentprevHistorically, conventional wisdom has been two years to recoup the overhead. Obviously depends on market volatility, and I've no idea if there's a more accurate # now. reply zdragnar 12 hours agorootparentI've heard 5-7 years, but that may be with much lower than the 20% down. reply bombcar 10 hours agorootparent7 years is the usual estimate in a “neutral/slow” market because it usually costs 10% to sell (realtor fees, etc). Of course if appreciation is going up more than 10% you can profit much faster, or you have flipping techniques to avoid frictional costs (like being your own realtor). reply 01HNNWZ0MV43FF 18 hours agoparentprevThe house going up 20% is its own oddity. My living here doesn't attract more business or residents to the neighborhood, it doesn't really improve the value of the land except for my fractional contribution to keeping a nice grocery store open nearby. I suspect in many cases home ownership is just subsidized. Might be Director's Law at work. https://en.wikipedia.org/wiki/Director%27s_law reply bombcar 18 hours agorootparentIt a lot of factors but the main drivers are inflation and desirability. In places where the desirability is basically neutral, houses do what you would expect and “used” ones sell at a moderate discount to new construction. reply toomuchtodo 16 hours agorootparentThey aren’t making more land. reply bckr 15 hours agorootparentAren’t they? Isn’t that what sprawl is? Obviously, not literally creating more physical land, but developing land into useable land. They’re making more useable land. reply BirdieNZ 10 hours agorootparentYou can't make more of unique locations. Dirt isn't the issue, it's location. Times Square doesn't use that much \"land\", but it's a unique, non-commodity location. Sprawl in NYC wouldn't create more Times Squares, so in this sense, \"they aren't making more land\". There's plenty of land in Siberia. There are very few locations that are in the middle of dense cities. reply dleink 8 hours agorootparentIf not for suburban zoning laws from the 20th century there would likely be more midtown-style skyscrapers in NJ/LI/CT. reply pixl97 13 hours agorootparentprevSprawl has its own cost growth function. Bigger roads, bigger water distribution, bigger sewers, bigger runoff, etc. And typically you develop the easiest and best land first then expand in the more and more difficult to develop. This inflates costs as time goes on. reply paulddraper 15 hours agorootparentprevThey are making more valuable/liveable land. Land itself is cheap as dirt. Level land in Wyoming for $350/acre (so $70/house at median lot size). [1] (Does it lack transportation, utilities, stores, schools, and jobs? Yes. Because those make land valuable.) [1] https://www.land.com/property/80-acres-in-Sweetwater-County-... reply MisterBastahrd 8 hours agorootparentprevLand is cheap. Location is expensive. reply phkahler 17 hours agorootparentprevHome prices have an inverse relationship with interest rates. Housing cost as a percent of income has been relatively stable in the U.S. lower interest rates mean you can borrow more for a given monthly payment. Interest rates had a 35+ year slide from 1980 to 2005. It's been really weird since then. reply mulmen 9 hours agorootparentprevYou living there reduces supply. reply staplers 11 hours agorootparentprevMy living here doesn't attract more business or residents to the neighborhood On the contrary, try getting internet, sewer, water, electrical, or gas hookups in a rural area and let me know the cost. reply bombcar 9 hours agorootparentIn fact, if you have a rural undeveloped plot of land amongst other undeveloped plots, and you pay to bring in electricity and gas or whatever, the properties around you will go up in value because now it’s cheaper to connect them up. reply civilized 13 hours agoparentprevAppreciation is a good deal for speculators and flippers, but for normal homeowners it isn't worth much. If all house prices double including my own, the money I make selling my house just goes into buying a new one. reply gizmo686 12 hours agorootparentThe presence of leverage means that appreciation still favors you. Assume you buy a $100k house, with a 30 year mortgage at a 6% interest rate and a 20% down payment. You then buy an equivalent house. Over the course of those 5 years, you will spend $28.77k in principle and interest, reducing your loan balance from $80k to $74.44k At 0% appreciation, you sell, giving you $25.56k in equity, then buy another $100k house at 20% down leaving you with $5.5k in cash. At 2% appreciation, you sell, giving you $35.96k in equity, then buy another $110.4k house at 20% down leaving you with $13.88k in cash. At 4% appreciation, you sell, giving you $47.22k in equity, then buy another $121.66k house at 20% down leaving you with $23.00k in cash. At 6% interest, the difference between the 80k loan and 97.328k loan is $103.89 a month, or about $1.25k a year. Set asside $6.23k from your surplus to cover the marginal P&I cost for 5 years and you are left with $16.77k cash. Subtracting the $5.5k of equity you woupd have had at 0% appreciation, and a 4% appreciation rate netted you $11.27k over just 5 years. Given your 20k initial investment, that is a net return of 56.35%. Which is an annualized return if 9.35%. reply civilized 1 hour agorootparentYour math may well be correct but I can't follow it without a spreadsheet, so let's do a simpler example with two different appreciation scenarios. Scenario A: I buy a $100k house with $50k down and a $50k mortgage. House prices don't change. I sell the house, then buy another $100k house. I'm still at $50k in equity and I still owe the bank $50k. Scenario B: same as scenario A, but this time, all home prices double, including mine. I sell for $200k and now have $150k, which I use to buy another $200k house. I now have $150k equity, but I still owe the bank $50k. In Scenario B I'm better off than someone who didn't buy the house before prices went up -- a fact that should surprise no one -- but I'm not necessarily better off than I would have been if prices hadn't doubled at all. I still owe the bank $50k in both scenarios. The housing price appreciation hasn't actually helped my finances unless I sell the house or use it as collateral for loans, neither of which I am interested in doing. Because I own the house to live in it, not to use it for financial engineering or speculation. reply not_the_fda 8 hours agorootparentprevThats a lot of work, and you have property taxes and maintenance. An index fund gives me 8% without lifting a finger and is very liquid while a house isn't. reply karaterobot 12 hours agorootparentprevThe appreciation presumably does not include all the money you spent just maintaining the house, or all the fees involved in both buying and selling. And the costs don't include remodeling the new house so that it's got the things you liked about the old one, or the cost of moving. I'm not arguing home ownership is a bad investment, it's been a good one for me. But every time I look into the actual cost of trading up houses, the calculation gets really complicated, and doesn't look as cut and dry as it did on the back of the envelope. reply gizmo686 11 hours agorootparentThose are all costs you would need to pay regardless of appreciation. reply dgfitz 7 hours agorootparentNot calculating/ adding in the additional feels from selling (and usually also buying) a house make your calculations flawed. reply mitthrowaway2 13 hours agorootparentprevIt still matters to normal homeowners who eventually intend to downsize before they die. Or if they borrow further against the rising value of their house to finance other investments at a lower rate than they otherwise could borrow at. But yes, it matters much more to speculators or investors who own rental properties. reply bombcar 9 hours agorootparentSpeculators are definitely gambling on appreciation but investors (while liking it) don’t want to depend on it. They want appreciation that they can be causal on, like reducing or increasing vacancies, raising rents, etc. reply karakot 8 hours agorootparentprevI have paper appreciation but very real tax increase. My taxes almost 3 times higher now comparing to what I paid when I bought the house. reply mitthrowaway2 8 hours agorootparentThat is a symptom of your city's budget needs increasing, not rising home prices. reply game_the0ry 18 hours agoparentprevIt also why leveraged losses can be so devastating - the same works in reverse. When your home depreciates, you lose the down payment and you are still on the hook for the debt. That's what happened during 2008 GFC when home prices went down. reply supportengineer 16 hours agorootparent>> you lose the down payment This loss isn't recognized unless you sell. If your house loses value but nothing else in your life has changed then \"Just keep swimming\" and historically you will win in the long term. reply JeremyNT 13 hours agorootparentMaybe on aggregate but the devil here is in the details. Plenty of people buy houses in \"on the rise\" areas and reap the benefits as desirability increases, it's true. Even market crashes like in the mid/late 00s don't impact their long term prospects. But there are also dilapidated cities and small towns in this country that have fallen from their heights never to recover. It's easy to look back after owning your home for a decade and conclude it was all inevitable, but the \"home ownership\" bet is one that the house you're buying in will be in a desirable area in the future. This isn't always going to be true, and it's a real risk. And yes there are protections from being on the hook for the full levaraged amount. You can walk away from an underwater mortgage, but if you put in a large down payment you're kissing that goodbye, and it's still a pretty big disruption in your life even if it's one you can recover from. reply bombcar 9 hours agorootparentprevIt can be quite a long time 10-15 years. I was in that situation and probably on paper we should have walked from an underwater house. But we could afford the payment, so we stayed. The only really annoying thing was waiting ten years until the value went back up enough that we could refinance from the relatively high rates we had been paying. Annoying to be paying 8% when you could get 3% but you can’t refinance because you don’t have the cash to become not underwater. reply swexbe 15 hours agorootparentprevThe history of financial markets is about 3-4 lifetimes long. That’s not a lot of history to go on. reply kjkjadksj 9 hours agorootparentprevAll you have to do is wait instead of panic sell and you will have weathered any recession in history just fine. reply elpakal 18 hours agorootparentprevAre you still on the hook for the debt, though? I though that's what bankruptcy was for reply travem 17 hours agorootparentThe following page provides a good overview for the US https://www.uscourts.gov/services-forms/bankruptcy/bankruptc... reply iamthirsty 17 hours agorootparentprevJust because you go legally bankrupt doesn't mean the debt magically disappears. reply compiler-guy 17 hours agorootparentIn many states a home loan is “non recourse”, which means that in a default the bank gets the house and nothing else. The debt is completely discharged. reply game_the0ry 17 hours agorootparentBut your credit score will still take a hit. reply toomuchtodo 16 hours agorootparentYou’re eligible for a new mortgage within ~3 years after foreclosure with an FHA mortgage, 7 for conventional. This is known as waiting periods wrt mortgage underwriting guidelines. Credit score might impact the rate, but on the property ladder might be than not, have to model both ways (appreciation, cost of debt service, reserves, rent, etc). (Strategically defaulted on property after buying at the peak before 2008 GFC) reply LanceH 16 hours agorootparentprevThey don't like it when you play by the rules. reply triceratops 18 hours agoparentprevIt's actually safer than almost any other debt financing. Even in bankruptcy creditors can't take your house. reply bombcar 18 hours agorootparentYes - the benefits for single family home ownership are so insanely high it's hard to come up with situations where it is not the way to go (usually involving not being in an area for long enough to overcome transactional costs). In California on a purchase loan you literally can't lose - the bank can only take the house, it's non-recourse. reply marcusverus 15 hours agorootparentWhen in doubt, math it out: https://www.nytimes.com/interactive/2014/upshot/buy-rent-cal... reply tomrod 14 hours agorootparentPaywalled reply 01HNNWZ0MV43FF 18 hours agorootparentprevI just don't think it makes sense from outside the system. If the benefits are so great, why can't the benefits be shared and even increased if I live in a condo in a row of condos? Then we have fewer outside walls to insulate, we can all pitch in for a manager to handle exterior maintenance, we can pool parking, maybe get some solar panels using that nice big shared roof space... I agree the benefits _as the system is set up now_ are obvious. I don't think those benefits _should_ exist because I don't think they make sense or fall out from first principles. And this isn't a communist thing, I think that single-family homes just look like an inefficiency. As a capitalist, why am I paying to heat and cool extra walls? reply supportengineer 16 hours agorootparentWhat sets condos apart (in the same general location) is the monthly HOA fees. Monthly condo fees could range from $200/month to $4,000 a month or more. When buying a place with a HOA you really need to do your due diligence. As part of the process you will receive a copy of the HOA's financial statements. You need to dig into those and look at common areas like the streets and the pool and look to see how much expected lifetime remains, the current estimated future costs, and the level of the reserves (do they have money in the bank or not). reply com2kid 10 hours agorootparent> Monthly condo fees could range from $200/month to $4,000 a month or more. Older high rise buildings have much higher fees, this is unfortunately true. (Soon as you have interior hallways and elevators...) But as you alluded to, in general if you go through the finances of townhome complexes, the HOA dues are (often mandated by law) just creating a cash reserve to cover future expected maintenance. Or to put it another way, realistically everyone who owns a home needs to set aside a few hundred a month to save up to buy a new roof, siding, paint fence, do pest removal, an so forth. The HOA in a townhome complex is a forcing function that requires people (again in some cities by law!) to calculate what the expected maintenance costs are going to be and to then save up accordingly for them using some low interest safe investment vehicle (or just cash, but IIRC my HOA has its money in some 2 or 3% interest bearing accounts). > and the level of the reserves (do they have money in the bank or not). This is the key part, a healthy HOA has reserves for the next n years of issues and has reasonable HOA dues to keep those reserves at a healthy level. Basically they know some large bill is, statistically likely, to come up, which will drop the reserves down, and the HOA dues are set at such a level as to refill the reserves before the next big bill comes around. This is the math that all home owners should be doing. reply bombcar 9 hours agorootparentMost people should pay themselves HOA++ so that they have a maintenance account when needed. The problem is if you don’t you just hurt yourself a bit - but a badly managed HOA can hurt you surprisingly when it’s discovered that they have no money at all for major maintenance items and trigger a sudden assessment. reply zdragnar 12 hours agorootparentprevThis is the reason my elderly parents still live in an oversized home for their current needs. They've looked at downsizing to a townhome or condo, but comparing everything they would lose to sharing noise through walls, HOA fees despite still being responsible for mowing and shoveling snow, and everything else it just doesn't make sense for them. reply triceratops 17 hours agorootparentprevMost of these benefits apply to condos too. reply lotsoweiners 16 hours agorootparentprev> As a capitalist, why am I paying to heat and cool extra walls? Paying to heat and cool “extra walls” is worth it to me for privacy and noise reasons. I also use the space for my gardening hobby, storage, and as an extension of my garage for diy woodworking projects. Money well spent in my opinion. reply paulddraper 14 hours agorootparentprev> it's hard to come up with situations where it is not the way to go One mistake is buying excessive amounts of house (and not renting it). Ownership is no-brainer inasmuch as it also replaces your rent (or provides income). --- EDIT: Another situation is short-term ( \"What are the most common tax benefits of investing in commercial real estate? > \"The most common tax benefits of investing in commercial real estate include accelerated depreciation, mortgage interest deductions, and tax advantages for an investor’s heirs. Accelerated depreciation allows investors to write off the cost of their investment over a shorter period of time than the asset’s useful life. Mortgage interest deductions allow investors to deduct any interest they pay on a commercial mortgage off of their federal income taxes. Lastly, tax advantages for an investor’s heirs can lead to a massive difference in returns, especially over an extended period of time.\" https://www.commercialrealestate.loans/blog/the-top-10-tax-b... If the market really goes belly-up, then the government will step in to bail out the 'fearless entrepreneurial capitalist investors' as with the subprime collapse, the covid collapse, the Silicon Valley Bank collapse, etc. Then the cheerleaders of capitalism stop complaining about socialism, at least for as long as it takes for them to deposit their government welfare checks. reply digging 16 hours agoparent> You can tell this is fluff What does that even mean? It's not a marketing page, it's just a simplified, introductory lesson. reply coretx 17 hours agoprev [–] It lacks point -7- ! Rentseeking. Setup a unhealthy / worthless business. Next lobby a politician who legislates value for your firm out of thin air. Very legal, very lucrative, very common. reply xyzelement 8 hours agoparent [–] I can’t think an example in my life. Can you provide ? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article explains financial capitalism through a Lego model, illustrating how money is traded for future promises of money in the financial markets.",
      "It explores the dynamics of raising equity and debt for construction projects, highlighting how leverage can enhance profits while also raising risks.",
      "The piece introduces advanced finance concepts like offshore finance, financial engineering, and securitization to provide a comprehensive view of financial markets."
    ],
    "commentSummary": [
      "Participants debate the financial aspects of homeownership as an investment, including property appreciation, maintenance expenses, and the influence of bankruptcy on debt.",
      "The discussion also covers the pros and cons of capitalism, emphasizes the significance of effectively managed Homeowners Associations (HOAs), and examines the government's involvement in supporting investors during market downturns."
    ],
    "points": 179,
    "commentCount": 79,
    "retryCount": 0,
    "time": 1712315447
  },
  {
    "id": 39946169,
    "title": "AI Impact: Combating Knowledge Collapse",
    "originLink": "https://arxiv.org/abs/2404.03502",
    "originBody": "Computer Science > Artificial Intelligence arXiv:2404.03502 (cs) [Submitted on 4 Apr 2024] Title:AI and the Problem of Knowledge Collapse Authors:Andrew J. Peterson View PDF Abstract:While artificial intelligence has the potential to process vast amounts of data, generate new insights, and unlock greater productivity, its widespread adoption may entail unforeseen consequences. We identify conditions under which AI, by reducing the cost of access to certain modes of knowledge, can paradoxically harm public understanding. While large language models are trained on vast amounts of diverse data, they naturally generate output towards the 'center' of the distribution. This is generally useful, but widespread reliance on recursive AI systems could lead to a process we define as \"knowledge collapse\", and argue this could harm innovation and the richness of human understanding and culture. However, unlike AI models that cannot choose what data they are trained on, humans may strategically seek out diverse forms of knowledge if they perceive them to be worthwhile. To investigate this, we provide a simple model in which a community of learners or innovators choose to use traditional methods or to rely on a discounted AI-assisted process and identify conditions under which knowledge collapse occurs. In our default model, a 20% discount on AI-generated content generates public beliefs 2.3 times further from the truth than when there is no discount. Finally, based on the results, we consider further research directions to counteract such outcomes. Comments: 16 pages, 7 figures Subjects: Artificial Intelligence (cs.AI); Computers and Society (cs.CY) ACM classes: I.2.0 Cite as: arXiv:2404.03502 [cs.AI](or arXiv:2404.03502v1 [cs.AI] for this version)https://doi.org/10.48550/arXiv.2404.03502 Focus to learn more arXiv-issued DOI via DataCite Submission history From: Andrew Peterson [view email] [v1] Thu, 4 Apr 2024 15:06:23 UTC (57 KB) Full-text links: Access Paper: View PDF TeX Source Other Formats view license Current browse context: cs.AInewrecent2404 Change to browse by: cs cs.CY References & Citations NASA ADS Google Scholar Semantic Scholar export BibTeX citation Bookmark Bibliographic Tools Bibliographic and Citation Tools Bibliographic Explorer Toggle Bibliographic Explorer (What is the Explorer?) Litmaps Toggle Litmaps (What is Litmaps?) scite.ai Toggle scite Smart Citations (What are Smart Citations?) Code, Data, Media Code, Data and Media Associated with this Article Links to Code Toggle CatalyzeX Code Finder for Papers (What is CatalyzeX?) DagsHub Toggle DagsHub (What is DagsHub?) GotitPub Toggle Gotit.pub (What is GotitPub?) Links to Code Toggle Papers with Code (What is Papers with Code?) ScienceCast Toggle ScienceCast (What is ScienceCast?) Demos Demos Replicate Toggle Replicate (What is Replicate?) Spaces Toggle Hugging Face Spaces (What is Spaces?) Spaces Toggle TXYZ.AI (What is TXYZ.AI?) Related Papers Recommenders and Search Tools Link to Influence Flower Influence Flower (What are Influence Flowers?) Connected Papers Toggle Connected Papers (What is Connected Papers?) Core recommender toggle CORE Recommender (What is CORE?) About arXivLabs arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs. Which authors of this paper are endorsers?Disable MathJax (What is MathJax?)",
    "commentLink": "https://news.ycombinator.com/item?id=39946169",
    "commentBody": "AI and the Problem of Knowledge Collapse (arxiv.org)158 points by kmdupree 14 hours agohidepastfavorite85 comments mark_l_watson 10 hours agoI don’t disagree much with the paper’s premise, except that I am turned off whenever there is a handy new tool for us to use and then some people come up with reasons why using the new tool is a harmful thing to do. We humans evolved to be very flexible and naturally use what is in front of us to solve whatever problems we need to solve. For some tasks LLMs are very useful and for other tasks they don’t offer much help. I feel sorry for people who don’t learn how to use common tools because they are stuck in place or have unreasonable fears. It is reasonable to worry about how powerful actors might use AI for surveillance and removing privacy rights, but I strongly disagree that it is a bad thing for individuals to sometimes save time and sometimes get better results by manually using tools like Perplexity and ChatGPT, and automating things using LLMs as sources of general common sense knowledge, as language processors, data transformation, etc. reply thesz 9 hours agoparentThe reliance on the tool in front of you can constrain you. Some tools are fads, some make you less of a thinking person. When I faced a second wave of IDEs I figured that any IDE is a fad - there will be better IDE in near future and your boss will require you to use it. The use of IDE can make you know less about project at hand, because you always can investigate, as opposed to internalize/remember. The difference? If you know internal relations, you can judge changes easier. You are better programmer that way and I would say a better person. The same goes to LMs - they help you not to know/remember and/or create thoughtfully. LMs constrain you to not know fully. reply chii 7 hours agorootparent> The use of IDE can make you know less about project at hand i disagree. Someone who's not interested in the project might know less (but is still able to accomplish their task), where as without such an IDE, they will have to learn a lot first. It's one reason why beginner java courses at university asks you not to use an IDE (at least for the first few tutorials learning the basics). But this isn't the fault of the IDE at all, and simply just reflect the motivations of the person using it. An IDE makes someone motivated to learn be more capable. It's a multiplier/enabler. > less of a thinking person. no, it makes you think less unimportant stuff, and thus have more to dedicate to the important stuff. Effortless navigation in an IDE (like intellij) means you can move through the call graph of an application without having to see/understand the entire application completely. The same can be said for LLMs - may be not today's, since it's still early, but at some point these LLM tools will make trivial/unimportant things easy, leaving time for you to focus on the things the LLM can't do. reply random_kris 25 minutes agorootparentprev> You are better programmer that way and I would say a better person Lost you here. A better person by using old school IDEs? What are you smoking A better person used LLM and whatever tool he gets at disposal to get job done ASAP and then goes outside to enjoy life with fellow humans reply williamcotton 7 hours agorootparentprevAnd the written word helps you to not remember anything, to paraphrase Socrates, so better get to memorizing the Odyssey so you can be an even better person. reply visarga 4 hours agorootparentI got better things to burn my neurons on than memorization. I normally forget almost everything, only remember abstract stuff. Maybe it's because I have used web search for 25 years that I learned to remember the good search keywords rather than actual information. Is this like relying on maps for navigation instead of pure memory? reply Capricorn2481 4 hours agorootparentprev> You are better programmer that way and I would say a better person. You think not using IDEs makes you a better person? reply kybernetyk 2 hours agorootparentIDEs add overhead, thus burn CPU cycles, thus increase your CO2 footprint. Not using IDEs is the only moral choice. reply Hadoque 1 hour agorootparentSo true. The only moral dev tool is a HEX editor. Or, for those less capable, also add a C compiler, as any newer language is guaranteed to have either runtime overhead or wasteful compile times. reply da39a3ee 1 hour agorootparentprevCan you give more details regarding what IDE features you have in mind? I agree that java/c# people not knowing how to use the command line is bad (because they only know how to click \"build project\" etc) but IDE features such as LSP, compiler error messages as you type, intelligent completion, variable renaming, etc I think are essential tools. reply wpietri 9 hours agoparentprevI'm not sure exactly what you're disagreeing with. There are plenty of examples out there of individuals using these tools badly. E.g., the teacher who used ChatGPT to generate student reviews. The students who use them as high-quality plagiarism engines. Individual marketers using the saved time to spam many more people. People who want internet points generating forum comments and Stack Overflow answers. Random kooks generating disinformation, propaganda, and hate. Et cetera, ad nauseam. Given that there are plenty of examples of people causing harm, I'm not sure how you can disagree with the notion that people can in fact use these tools harmfully. If a tools solves my problem by creating a problem for you, why shouldn't people point that out? reply chii 7 hours agorootparent> using these tools badly. i assume you mean unethical usages rather than bad. You believe it causes harm, but who gets to decide what is ethical? I certainly do not delegate my judgement to you - only I can judge what i do myself. Therefore, the only metric to judge is through the lens of legality (because everyone \"agrees\" what legal is). reply krainboltgreene 7 hours agorootparent> Therefore, the only metric to judge is through the lens of legality (because everyone \"agrees\" what legal is). I just want to make sure we're all on the same page here: You believe that prior to Lawrence v. Texas, being a gay man in many of the US states was unethical? That prior to 1865 chattel slavery was ethical? I often feel like HN has devolved into high-school level science fiction and philosophy, but this is rather on the nose. reply chii 7 hours agorootparent> That prior to 1865 chattel slavery was ethical? some people in that era did believe it was ethical, and some didn't. After a while, more and more people were convinced that it was unethical (and conveniently, machinary made slavery less economical for some industries). Once enough people believed/changed their minds about it being ethical, there was a large argument that resulted in laws rather than on individual ethical beliefs. reply bruce511 2 hours agorootparentLegal is what we collectively decide. Ethical is what we personally decide. Clearly something is either legal or not, and we have mechanisms setup to clarify where there is dispute. Some professions have ethical standards. Some even have enforcement of them, making them pseudo-legalities. But personal ethics, are, well, personal. You may find it ethical to eat meat, I might not. You may consider it unethical to eat cheese, or coffee, or honey. You might consider it ethical to pay minimum wage, or require employees to answer emails after hours. Or rent out an apartment, or wear white in October. Ethics are personal and vary enormously. Declaring things to be ethical or not is therefore somewhat unhelpful. Clearly some will agree, some will not. Whole college courses exist to try and define ethics and to encourage students to at least think about what their own ethical boundaries might be. reply krainboltgreene 2 hours agorootparent> Legal is what we collectively decide. It's not even that. The collective didn't ask for sodomy laws. The collective didn't repeal Roe v Wade. reply krainboltgreene 2 hours agorootparentprevThis is both incredibly historic and clumsily sidesteps the fact that were you in that time, according to your statement, you would have found it ethical. reply chii 1 hour agorootparent> you would have found it ethical. not having lived that era, it cannot be said which side i would've been on - because it would've depended on which side i was born, and the circumstances i find myself in. The truth is that which ever \"ethical\" belief that benefits me the most will have been the belief i followed. Most people believe that their beliefs are ethical, but are in reality, just post hoc rationalizations of decisions that benefit themselves (knowingly or not). I am just being clear, rather than try to hide this fact. reply verelo 5 hours agoparentprevYa, mean, what happened with the invent of the calculator? Sure maybe basic math skills declined…but i think i grasp relativity more than my father does and ever will… reply javajosh 8 hours agoparentprev>I am turned off whenever there is a handy new tool for us to use and then some people come up with reasons why using the new tool is a harmful thing to do. Same, but it turns out its complicated. There is something materially different learning French and using your phone to translate French. Or learning to play piano vs listening to a recording of someone playing the piano. The danger is that these tools give make you feel that you can do something when you can't. > For some tasks LLMs are very useful and for other tasks they don’t offer much help Yes, and the difference is that I don't care about bash so I let it write scripts for me, but I DO care about other languages so I generally write my own. I'm basically curating my own skillset according to value and capacity. In that way AI can be a big win for teams of approx 1 who only need pro forma help in certain areas, but deep expertise in others. reply chii 7 hours agorootparent> The danger is that these tools give make you feel that you can do something when you can't. i dont think people are so stupid as to feel this way. It didn't happen with cars - you could travel hundreds of miles in less than an hour with it, where as without it, you can barely do 5. And yet people have never made the mistake that they could travel that fast themselves. LLMs as a tool is not more harmful than what could be done with existing tools today prior to the advent of LLMs. And the benefits of the LLMs should outweight the harm imho. reply voidhorse 6 hours agorootparent> i dont think people are so stupid as to feel this way. It didn't happen with cars - you could travel hundreds of miles in less than an hour with it, where as without it, you can barely do 5. And yet people have never made the mistake that they could travel that fast themselves. But cars are in a totally different category insofar as they do one very specific thing and are bound by very obvious physical limits. Our own physical limitations are very obvious to us, our intellectual limitations, I think, are less so. Further, companies (I think knowingly) market AI (read: llm chatbots) as though it's some general, infallible solution to all intellectual and digital content problems. This is obviously not the case, and if you use a chatbot to work in a domain in which you have any expertise whatsoever, you'll quickly uncover this. The problem is people without expertise using these tools and being fooled into thinking they've plumbed the depths when they haven't tread past the shallows. Physically speaking, your capabilities are very apparent when you attempt to run 100mph and simply *cannot*. Realizing you cannot do something or don't understand something correctly intellectually is a far different scenario. reply GeoAtreides 5 hours agoparentprev> I am turned off whenever there is a handy new tool for us to use and then some people come up with reasons why using the new tool is a harmful thing to do. So we shouldn't investigate (theoretically and practically) potential harmful effects of a new effects? Should we treat with coldness (dare I say disgust) anyone who dares? You know, there is a big hole in the ozone layer that is now closing (or at least no expanding over the whole planet) because some poor researchers went against the grain and investigated all effects of this new invention called CFCs. reply Barrin92 5 hours agoparentprev>but I strongly disagree that it is a bad thing for individuals to sometimes save time and sometimes get better results you shouldn't really use tools to save time or 'sometimes' get better results, because that's an indication of a sort of laziness. When you use powerful tools you need to understand exactly in what way they save you time or effort, what their failure modes are, otherwise they become pathways for exploitation. The recent backdoor is a good example of this. People pile automation and tool chains in software on top of each other but don't bother to actually verify what comes through them, and so rather than leverage for them they became leverage for someone else. If you use LLMs to process information faster but someone feeds you garbage you're now the fastest consumer of garbage. There's nothing worse than a gullible user with a powerful tool. And given that the general attitude we have nowadays is that tools are a sort of thing that allow you to turn your brain off, rather than understanding that you need to be smarter and more critical and more alert the more tools you use, it's very reasonable to be extremely conservative about adopting new tools. reply readyman 10 hours agoparentprev>We humans evolved to be very flexible and naturally use what is in front of us to solve whatever problems we need to solve. Ha, yeah right. Almost all of us spent the vast majority of our time and energy just making dishonest rich people richer. In a world so full of exploitation, it should be no surprise that so many people are distrustful. reply macawfish 11 hours agoprevIs it the AI that's the trouble or the hostile new information environment we're expected to navigate and survive? Expecting us to remain sane amidst these torrents of information without new tools for querying and filtering it is cruel. reply the_af 9 hours agoparentI only skimmed the paper, but judging by the abstract/intro and the definitions at the end, it's not concerned with \"hostile\" anything, but rather, with AI mediating access to knowledge. Specifically, they mention that \"knowledge collapse\" is the narrowing of the \"human working knowledge\" and the universe of things \"worth knowing\" or \"epistemic limit\", which may result in obscuring/hiding what they call \"the long tail of knowledge\" (they define all these terms). They explain this better than me, but I think it's all about constraining the human relation to knowledge by these new \"recursive AI\" processes, without any malice involved. I don't know if the paper mentions this, but I've thought about this (in less smart terms). It's probably not that AI is a radically new process in this sense but, like a lot of tech, it makes it faster. We often say \"well, things were like this with [written language|printing press|the internet]\" but isn't it possible that a relatively harmless process could be accelerated to a harmful level by technology, even if it's not \"fundamentally\" something new? Can we always fall back to the belief that \"people from previous generations complained of $THING and it turned out ok, therefore $NEW_THING is probably OK too\"? reply apantel 6 hours agorootparentAnyone who needs to know more than the narrow middle of knowledge will seek it out. The real issue as I see it is people who have that kind of knowledge need to share it and have it be seen by those who are interested in it. There’s a huge problem with search engines serving junk ‘narrow middle’ SEO-optimized content to the endless horde, as opposed to real, quality knowledge. This issue predated generative AI. reply OgsyedIE 8 hours agorootparentprevThe baseline will always shift to accommodate the conditions, it's how the hedonic treadmill evolved. The perspective we have, stuck inside the system, doesn't make the people of Denmark and the people of Burundi equally happy. reply wslh 7 hours agorootparentprev> but rather, with AI mediating access to knowledge. Rephrasing McLuhan \"The medium is the m[ea]ssage\" we can say that \"The AI is the medium and the m[ea]ssage\". reply woopsn 6 hours agoparentprevThe information age is nothing new (for us), neither is media culture generally, or even silicon valley. AI will now be some new part of the complex. It seems obvious to me that a significant step to combat this effect would be not calling the thing \"artificial intelligence\". I like the term gpt because it is descriptive and accurate. Gpt doesn't suggest in any sense that we can rely on the thing or are comparable, in the same way \"cell phone\" doesn't. Imagine if we really bought into the idea that phones are truth receivers, or called them the closest friend. But that seems to be the idea with AI. Keep speaking up too. Just calling bullshit on the thing implicitly gives people permission to turn it off. The tech will not cause knowledge collapse among a population that doesn't need it. I do use it by the way, eg GitHub Copilot which is nice. reply TaylorAlexander 6 hours agorootparent> The tech will not cause knowledge collapse among a population that doesn't need it. Every google search now returns loads of AI generated websites fill of low quality information. You could call the things \"bullshit generators\" and the people who really want to make websites full of bullshit will still use them to flood the internet with that bullshit. We all suffer the degradation of the internet when that happens. reply woopsn 5 hours agorootparentI'm with you. I started moving away from Google a few years ago. That's what I mean I guess -- when something becomes so full of it, what can you do but turn it off? It's Google's own conceit that without it we'd be in the dark, Facebook's that without them we are lonely and alienated, missing out, etc. In actuality they are entirely dependent on you and are terrified you'll look away. They are enormous media companies and nothing more. Again, it's good that you call bullshit on it. Things are not as set in stone as they appear -- the tech is finicky and expensive, and we still have the wealth of \"legacy knowledge\" online and offline. There is enormous investment being made in this sector currently. Remember the huge amount of bullshit that was spread all over during the height of the cryptocurrency craze, uberization, social media, war on terror, etc. As I said, \"AI\" is a new part of the complex. Turning these things off is a way to stay sane, no more or less. reply thomquaid 5 hours agorootparentprev> Every google search now returns loads of AI generated website That is a google problem, not an AI problem. reply epgui 10 hours agoparentprevIt can be (and is) both at the same time. reply HarHarVeryFunny 12 hours agoprevMaybe the problem (which seems easily fixable), is more \"rizz collapse\", aka blandness, than this \"knowledge collapse\". The model hasn't forgotten the diversity of material it was trained on, but outside of a context predicting a \"long tail\" response, it's going to predict a mid response. You can always prompt it to respond differently though. Blandness is more of an issue since that's what most-probable word-by-word generation is going to give you, rather than the less predictable, but more interesting, responses that an individual might give. Prompting could help by asking the model to reply in the idiosyncratic style of some celebrity, but this is likely to come across as a cheesy impression. Maybe the models could be trained to generate conditioned on a provided style sample, which could be long enough to avoid the cheesiness. reply thesz 11 hours agoparent> You can always prompt it to respond differently though. No, you cannot. I rarely do anything with LMs [1], but if I do I ask them to code \"blocked clause decomposition\" [2] in Haskell. Blocked clause decomposition is very, very simple as far as algorithm's implementation complexity goes and Haskell is just an unusual but simple implementation language. [1] https://arxiv.org/pdf/2403.07183.pdf [2] https://www.cs.utexas.edu/~marijn/publications/bcd.pdf I tried that on one less known model (my son sent me a link) and on Phind two times. The Phind's responces were very illuminating ones. On a first try, it tried to make me code that myself by pointing to a paper that does not contain any blocked clause decomposition algorithm(s), just worthless combinations of them and references to other papers. Of course, I read that paper before. When I specifically asked to provide me with code, it did not even provided me with the correct type of blocked clause, which should be a pair of a CNF clause and a literal that blocks it. On a second try I could not even pass through bullshitting phase - I just was not able to persuade a LM to write any code. The second try I attempted after I saw an advert here on HN about Phind's new and updated LM, better at coding. Try that youself with your unusual but known problem of choice. And this is exactly a problem of collapse of knowledge: you can't ask an LM to code you a problem it hasn't seen several dozen of times during training. You just cannot, you will not get a satisfying answer. reply empath-nirvana 8 hours agorootparentI uploaded the paper to chatgpt and it summarized it, wrote pseudo code and wrote haskell code with very little prompting from me... no idea if it's _good_ code, because I didn't run it and I don't know the domain or haskell, but it did produce code -- and explained that some of it is non trivial to implement and might need more attention and explained why. reply FridgeSeal 7 hours agorootparentBut this is _exactly_ the problem being discussed. Domain expert: “I cannot get it to produce something that even approximately resembles x” Person: “I gave it the paper and I got maybe x?” There is a fundamental knowledge gap here, just because you can get it to do something isn’t the goal, or even a good outcome. The illusion that it’s capable of doing something it evidently cannot is a dangerous one, because people who don’t know better, and are being convinced that they do understand or comprehend when they don’t. reply __loam 7 hours agorootparentprevOkay so you have no idea how good the output is. reply HarHarVeryFunny 10 hours agorootparentprev> And this is exactly a problem of collapse of knowledge: you can't ask an LM to code you a problem it hasn't seen several dozen of times during training. You just cannot, you will not get a satisfying answer. I think that's more a function of the coding ability of the model you are using, and obviously they are going to do much better on languages better represented in the training set. What the paper is referring to as \"knowledge collapse\" isn't inability to do something, but rather getting a mid response since by definition that's going to dominate any normal (pardon the pun!) distribution. Here's what he said: \"While large language models are trained on vast amounts of diverse data, they naturally generate output towards the 'center' of the distribution.\" But, you can generally prompt around this sort of thing by asking the model to adopt a preferred context such as \"you're an expert xxx\", providing of course that is did see such expert-tagged material in the training set. reply FridgeSeal 7 hours agorootparent> obviously they are going to do much better on languages better represented in the training set. Which, again, indicates that the current crop of LLM’s are just fuzzy-recollection/fuzzy-interpolation machines, and have none of the actual thought/reasoning capabilities some people are claiming they have. reply int_19h 4 hours agorootparentIf that were the case, it would be impossible to describe rules to them and have them follow those rules. reply thesz 10 hours agorootparentprev> But, you can generally prompt around this sort of thing by asking the model to adopt a preferred context such as \"you're an expert xxx\", providing of course that is did see such expert-tagged material in the training set. So, I need LM to be an expert in SAT solving and an expert Haskell programmer. This means I need LM to be trained on the SAT solving and on vast amount of Haskell code. I think it is already easy to see that LM should be trained in an intersection of quite fringe (yes, I am watching that TV series right now) things. I also think that it is beyond reason to ask for this. reply freeone3000 5 hours agorootparent>This means I need LM to be trained on the SAT solving and on vast amount of Haskell code. Essentially why the current batch of top-tier LLMs are trained on a pile of text amounting to “the internet”, containing every haskell q&a on stackoverflow, every sat implementation on github, and every explaination of those terms on wikipedia. It might seem unreasonable without the sense of scale and expense of building these things; but yes, it has those input data in its training set. reply p1esk 7 hours agorootparentprevPlease get back to us when you try whatever you’re trying to do with a good model (gpt4, opus, or ultra). I recommend refraining from making (and especially from posting) any conclusions until then. reply jacobr1 11 hours agoparentprevOr introduce more noise or seeding to get more interesting responses. The `temperature` settings don't really satisfy this right now. I would like some determinism - but seeded randomly - so I can get similar responses if I like what is produced. Likewise some kind of metadata or explicability that allowed us to take a known style or featurespace of the model, perhaps from hand prompting, and then reuse-it with some degree is modification and maybe even combination from others would be very helpful. The work around adding model weights from fine-tuned seems directionally what I'm talking about, though that isn't the form I'd want to expose to users. reply thoughtlede 11 hours agoparentprevThat's interesting. In keyword-based indexing solutions, a document vector is created using \"term frequency inverse document frequency\" scores. The idea is to pump up the document on the dimension where the document is unique compared to the other documents in the corpus. So when a query is issued with emphasis on a certain dimension, only documents that has higher scores in that dimension are returned. But the uniqueness in those solutions is based on keywords being used in the document, not concepts. What we need here to eliminate \"blandness\" is conceptual uniqueness. Maybe TF-IDF is still relevant to get there. Something to think about. reply karaterobot 13 hours agoprev> Informally, we define knowledge collapse as the progressive narrowing over time (or over technological representations) of the set of information available to humans, along with a concomitant narrowing in the perceived availability and utility of different sets of information. > The main focus of the model is whether individuals decide to invest in innovation or learning ... in the ‘traditional’ way, through a possibly cheaper AI-enabled process, or not at all. The idea is to capture, for example, the difference between someone who does extensive research in an archive rather than just relying on readily-available materials, or someone who takes the time to read a full book rather than reading a two-paragraph LLM-generated summary. > Under these conditions, excessive reliance on AI-generated content over time leads to a curtailing of the eccentric and rare viewpoints that maintain a comprehensive vision of the world. My intuition is that AI will just accelerate the trends that the internet brought on, which is that eccentric viewpoints are actually pretty common, even ones based on research and in fact. The internet people mostly use has become relatively generic, consumed through a pretty narrow, curated aperture (social media). This feels analogous to getting it through AI, as described in the article. Yet, people are still learning about eccentric, marginal stuff all the time, especially compared to, say, 50 years ago. Assuming the AI's responses aren't artificially limited, people who are interested enough to look will still get to learn about topics in the long tail of the distribution, even in a world of ubiquitous AI. And they'll be able to dive as deeply into them as they do today. I'm not really worried about that. If anything, the knowledge collapse will be at the center. Basic liberal education topics are what will go away. Or rather, they will be offloaded to AI. In the same way that people say they don't need to learn arithmetic because they have a calculator, my guess is people will be more likely to decide not to worry about what previous generations considered core knowledge: history, geography, the canon, and so on. \"I don't have to know it, I can look it up\". That'll all go away even faster than it's going now. (I don't think this is a good thing, just stating the most realistic outcome based on extending what I've seen) reply chii 7 hours agoparent> decide not to worry about what previous generations considered core knowledge these sorts of things have already been happening for centuries. What was considered core knowledge depends on the environment one lives. Way back in prehistoric days, foraging and identifying edible plants would be considered core knowledge. How many people do this today? Prior to industrialization, most farmers will have some experience doing blacksmithing (for their own tools/repairs etc). That would be considered core knowledge that is lost today because industrialization made it unnecessary completely. Ditto with sewing, and many other skillsets that would be considered artisanal today. If knowledge acquisition turns out to be like that too, then it's fine imho. reply knowsuchagency 13 hours agoprevI feel like this has always been the case. The entire information economy is based on a few key publishers and figures. You see it in news, academia, social media -- there's orthodoxy everywhere. Not sure how AI is any different. reply iraqmtpizza 12 hours agoparentIn the 1990s people read their town's newspaper. Now people in Arizona read the Daily Mail reply simonw 11 hours agorootparentI worked for a local newspaper in Kansas around 2003/2004 and one thing I found surprising was that journalists there were frequently on the hook for writing up national stories - things that would come in off the wire services and then be re-written for the local audience. reply iraqmtpizza 1 hour agorootparentDid they write it like What in tarnation is going on in the Big Apple? reply 48864w6ui 11 hours agorootparentprevIn the 1990s people who wanted to advertise in that town had to do so in local media. Now they can ad tech and the Daily Mail will arrange for it to be served. reply the_af 9 hours agoparentprevIt's probably different in that the few key publishers reached few people, but now AI is \"sold\" as for everyone and it's not unreasonable to expect it to become consumerized into a magic box of information, news and problem solving in the near future. It may not be a fundamentally new process, but what if it becomes so ubiquitous and fast that it becomes really harmful? And would there be a point of no return for society if this happened? reply resolutebat 13 hours agoprevSo by this definition, do we already have \"knowledge collapse\" by Wikipedia? Because if you search for a random concept, that's usually the first hit, and it's also what countless other sources draw on. reply rwbt 13 hours agoparentYes, we do kind of. reply hprotagonist 13 hours agorootparentand i distinctly remember this critique being made at wikipedia's advent, as well. and it is not without justification! https://undark.org/2021/08/12/wikipedia-has-a-language-probl... reply nickpsecurity 12 hours agoparentprevThe same warning was given for Google. Except those people added that it would reduce problem solving ability, too. People would get used to whatever simple, instant content rose to the top. They'd gradually lose some or all of their ability to figure out the same things on their own. One submission here was a tech guy at a school saying that was already happening where he worked. reply aoanla 12 hours agorootparentI mean, it does - people search stuff all the time now, rather than thinking about it. reply 082349872349872 11 hours agorootparentIIRC, that was Socrates' complaint to Phaedrus about writing: that reading (because it was \"high tech\" at the time?) led only to an illusion of understanding. Elsewhere Phaedrus echoes with a very modern complaint (even though search engines wouldn't arrive for another 2'300 years): They would say in reply that he is a madman or a pedant who fancies that he is a physician because he has read something in a book, or has stumbled on a prescription or two, although he has no real understanding of the art of medicine. https://www.gutenberg.org/files/1636/1636-h/1636-h.htm reply voidhorse 6 hours agorootparentI think the Phaedrus is all about the importance of practice. I've been reading a lot of math books lately, but I don't actually grok anything well until I sit down and try to reason through the material myself, write my own little proofs, try to deconstruct what's being said actively with pen and paper. Similarly, I understand a work of literature far more deeply if I take active notes, and/or write a small essay about my interpretation. I become a better writer by reading good writers and emulating them in my own writing practice. Writing was a threat to poets when the goal was still to recite a compelling live performance, which, to do this well, would require memorization and practice—today, still, we ask that actors do not have paper scripts in front of them when performing in a film. This is kind of the threat that tools like LLM's pose. Their power to generate decent results means that far more people will eschew practice for \"good enough\" LLM produced results. Creation will become even more transactional, and (many) people will quickly fail to \"see the point\" in practicing until we have a culture that's degraded even further than it already has today. reply 082349872349872 3 hours agorootparentAs the hallucinated Euclid said to Ptolemy, there is no LLM for geometry? reply jprete 9 hours agorootparentprevSocrates wasn't wrong. Reading a lot gives you a partial understanding but it isn't complete without experiencing the thing for yourself. Arguably the Internet is the natural home of authoritatively stated but uninformed opinions - the exact result of reading a lot about a subject without having any experience of it. reply contravariant 8 hours agorootparentIronically we can only know he was right by making the exact mistake he was warning us against. reply the_af 9 hours agoparentprevProbably Wikipedia is an early precursor of this problem, yes. It may not be entirely new, but AI might accelerate it to really harmful speeds. Just pondering this, of course. reply AlienRobot 12 hours agoparentprevPersonally, I think the problem is that people abuse Google for things it's really not designed to do, and they don't even realize that. Google is great at finding official webpages by their exact title. If you type the title of a news headline from the 90s, Google will give you the link to it. I think that is amazing. Basically anything that has a canonical URL, Google is good at finding. But when you search for \"how to do X\" for example, there will be several results that are perfectly valid and they will still need to be ranked in a list. Because it's not a \"list\" of results, it's ranking of relevancy. So to avoid showing spam, Google will push to the top websites it finds trustworthy. And now every top result comes from the same website. If you need an explanation for the Xz incident, for example, there is no canonical URL for it. There will be several news websites, youtube channels, etc. that have talked about it, competing to be the top result. Google still has to rank them even though the algorithm can't tell fact apart from parody, so no matter what Google does, Google will be the one judging which content most people will read when they want to know about a certain topic. To borrow my fellow robot's words, people are finding knowledge through an algorithmically curated aperture: Google's SERP. If they're evil, they have the power to control everyone on Earth. If they're good, they must be going insane with what to do with their users' crippling dependency on them as a source of truth. reply 082349872349872 11 hours agorootparentI find Google isn't so good anymore for finding things by title; rather than being a search engine they are slowly becoming more like a politician answering reporters' questions, in that instead of returning results based on the terms I asked for, they insist on returning results for the terms they believe I should have asked for. reply AlienRobot 8 hours agorootparentCan you give me examples? Personally, I don't think I've ever had a problem finding things by their name or title on Google. If I type python, I get python's website, if I type hacker news, I get this website. I can type the name of an old program and get their webpage on sourceforge for example. I've also tested that it works with finding the official websites of celebrities, e.g. if you type eminem, you get his official website. It does seem to have biases toward recency and product pages, but finding things by their title isn't a thing Google is bad at. reply 082349872349872 4 hours agorootparentI often search for titles containing very specific acronyms or abbreviations (which I would expect to be high precision low recall); Google's first response lately is usually a search based on a \"correction\" of these to a more common search, presumably because they are biasing to low precision high recall. (eg band names, even at hamming distance, will shadow maths structures) Clicking again on my original query, or liberal use of quotation marks, then does the trick, but it's annoying af. Maybe there's a setting somewhere for \"show me the results of my query first, not the 'did you mean' first\"? EDIT: upon reflection, the problem is that I use Google in an early XXI manner: if I've been someplace before I use the URL bar, and it's for places I haven't been, that aren't common knowledge, that I want a search engine. There was a time when Google was optimised for this use case, and although that time is long past (in particular, no one buys ads for my queries), the annoyance is recent because now they actively pessimise. reply visarga 4 hours agoprevI don't think this paper goes deep enough, they don't consider for example structured diversity seeding for LLMs, which entails prompting the model to combine diverse entities, knowledge and skills selected at random from a list. Random combinations of conditioning context can lead the model to hyper-diversity. The Skill-Mix paper shows how this can work. https://arxiv.org/abs/2310.17567 LLMs have been trained on everything, when they are also prompted by diverse people with their own tasks and styles it won't lead to knowledge collapse. Two diverse worlds meeting each other in chat LLM interactions - the training corpus and people. But if you remove the human and just use fixed prompts, and then also narrow the training set with various methods, it might collapse. reply EVa5I7bHFq9mnYK 42 minutes agoprevAI is a clear negative from where I stand. As of last week, there are two new AI enabled cameras in my building, that are connected directly to the police. When Googling something, I now skip the first page of results altogether, because it's all unendings walls of AI generated garbage. All major sites like Twitter and Reddit are now fenced from outsiders because they want to sell the content to AI training companies themselves. Creative people are losing jobs right and left because AI can produce shitty \"art\" much cheaper. And this shitty \"art\" is now everywhere, polluting my brain. Up to 20% of my time on the web is now spent solving captchas, that are used to 1) help train AI and 2) to protect from AI scrapers. AI sends all my useful email to junk folder, so I now have to check two folders instead of one. AI uses enormous amount of energy and contributes to climate catastrophe. AI is actively used to kill people in both currently ongoing wars. reply thoughtlede 12 hours agoprevLLMs are both language processing engines and knowledge bases. This article explores the knowledge base aspect of LLM and sheds light on the potential danger. The authors are well-justified in doing so because ChatGPT as a knowledge-bot is being used by many end users for its knowledge. However, to my knowledge, many enterprise applications that are being built using LLMs feed task-specific curated knowledge to LLMs. This mode of LLM use is encouraging. I do not think this article acknowledged this aspect of LLM use. reply ziofill 7 hours agoprevThis would be a problem if knowledge were a closed system. In that case it would suffice to invoke the data processing inequality and sooner or later your knowledge is all gone and you’re left with just noise. However, if AI enables new knowledge to be discovered then maybe there’s no problem in the end? reply mediumsmart 2 hours agoprevAI is the DaVinci enabler in a complex world reply pella 6 hours agoprevrelated github repo : - https://github.com/aristotle-tek/knowledge-collapse \"replication code for \"AI and the Problem of Knowledge Collapse\" reply antisthenes 12 hours agoprevThis just means that in-person critical thinking skills will be at an even higher premium than ever. If knowledge collapse becomes evident, we'll dial back the use if AI, and a lot of \"prompt monkey\" businesses will go bankrupt. reply klyrs 11 hours agoparent> we'll dial back the use if AI Who, and how? This sounds suspiciously like the invisible hand reply chii 7 hours agorootparentIf using the AI does not economically complete well with those who don't use said AI, then yes it will happen, and i attribute this to the invisible hand of darwinian competition. reply klyrs 5 hours agorootparentYeah, that worked really well with cigarettes. People who used em were economically competitive with those who didn't. reply 627467 9 hours agoprev> While large language models are trained on vast amounts of diverse data, they naturally generate output towards the 'center' of the distribution Yeah... Current gen AI does seem impressive but can't it be said that we have been preparing ourselves to be easily impressed by these \"normal\" results? The world is more homogenized than ever making it much easier to a bland intelligence to sound intelligent reply JieJie 13 hours agoprev [–] The discussion section is quite illuminating. \"While much recent attention has been on the problem of LLMs misleadingly presenting fiction as fact (hallucination), this may be less of an issue than the problem of representativeness across a distribution of possible responses. Hallucination of verifiable, concrete facts is often easy to correct for. Yet many real world questions do not have well-defined, verifiably true and false answers. If a user asks, for example, “What causes inflation?” and a LLM answers “monetary policy”, the problem isn’t one of hallucination, but of the failure to reflect the full-distribution of possible answers to the question, or at least provide an overview of the main schools of economic thought.\" reply ben_w 12 hours agoparentFirst thought: Oh no, they want LLMs to be even more vocal about nuance Second thought: People aren't going to read nuance Third thought: They should Fourth thought: Have you met people? They'll get angry with you for even suggesting it reply voidhorse 6 hours agoparentprev [–] Right. It all hooks up to a naive, popular philosophy of knowledge that I think has been burgeoning since the birth of search engines: people today tend to think that everything is decomposable into atomic facts and that all questions have concrete, singular, atomic answers. Obviously, this could not be further from the truth, but I think ever since the advent of things like \"answer cards\" in search, people have been led into this technological bias trap of thinking that whatever answer the engine spits out must be the canonical answer and forget that we still have a broad range of questions and research areas we don't have anything close to definitive answers on. The problem is only exacerbated when people make this mistake in domains that will never have singular answers like politics and ethics. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The paper addresses the risks of widespread artificial intelligence (AI) adoption, emphasizing the concept of \"knowledge collapse\" caused by AI-generated content leading to misinformation.",
      "Authors suggest a model allowing users to select between conventional methods and AI-supported processes to promote diverse knowledge seeking.",
      "The research advocates for more studies to mitigate negative effects and stresses strategic decision-making when incorporating AI into decision processes."
    ],
    "commentSummary": [
      "Debates around AI, language models, and knowledge collapse underscore potential drawbacks of over-reliance on AI tools for tasks.",
      "Emphasis is placed on balancing technology use for efficiency and preserving cognitive skills, active engagement, and critical thinking.",
      "Discussions include concerns about internet genericization, impacts on creativity and learning, and biases in search engine results, stressing the need for diverse perspectives in maintaining quality knowledge dissemination."
    ],
    "points": 158,
    "commentCount": 85,
    "retryCount": 0,
    "time": 1712345430
  },
  {
    "id": 39945733,
    "title": "Autonomous Powerline Recharging for Uninterrupted Drone Operations",
    "originLink": "https://www.youtube.com/watch?v=C-uekD6VTIQ",
    "originBody": "Autonomous Overhead Powerline Recharging for Uninterrupted Drone Operations - ICRA 2024 Watch later Share 0:00 0:00 / 2:46•Watch full videoLive",
    "commentLink": "https://news.ycombinator.com/item?id=39945733",
    "commentBody": "Autonomous Overhead Powerline Recharging for Uninterrupted Drone Operations [video] (youtube.com)148 points by DocFeind 15 hours agohidepastfavorite127 comments jl6 2 hours agoI imagine that billing for the electricity usage will be the power company’s distant second concern behind the mechanical stress of hanging unauthorized devices off a cable that was not designed with this scenario in mind. reply wanderingstan 2 hours agoparentAs mentioned in another comment, these cables are designed to handle orders of magnitude more stress than a drone. (Think wind storms, entire flocks of birds, blown debris, etc) For example, See this video of how wires are inspected by humans crawling along them: https://youtu.be/oBJyyEAw-6g?si=QVqBgjqwlM4XCGKl reply schiffern 1 hour agorootparentIf anything, this offers utility operators a massive new revenue opportunity. Drone fleets could pay to \"perch\" and recharge (giving unlimited range and ubiquitous charging), all just by reusing existing infrastructure. No need for a massive new infrastructure buildout, and \"nothing left to take away\" design. Big future for whoever can successfully commercialize this. reply cdchn 5 hours agoprevSaying \"this would be good for power line inspection drones\" is true, but think bigger. Imagine if you could operate a fleet of delivery, surveillance, _whatever_ drones, with an already in place, widely distributed charging infrastructure that costs you nothing to build (but you pay for usage). This is like in-flight refueling massively extending the operating range of jet aircraft. reply squarefoot 5 hours agoparentYou don't even need many drones for surveillance, just a few ones that deploy mini cameras using power lines both for power and communication. Cameras wouldn't need a battery to operate because they'd remain in place. No drive logic, no sensors, no motors, no batteries: much cheaper, just leave each one at regular distance and collect information remotely. reply lolc 10 hours agoprevThis is the funniest thing I saw this week. The idea that such a teensy drone could travel continental distances by hanging like a bat and recharge between runs. Sure solar gliders may keep aloft indefinitely too. But this one steals its juice! reply palmfacehn 3 hours agoparenthttps://www.pmel.noaa.gov/ocs/saildrone >With a speed through the water of 2-8kts, they have a range of more than 16,000 nautical miles, and endurance of up to 12 months. reply m463 10 hours agoprevYou can hold up fluorescent tubes under high voltage power lines and they will light up. https://duckduckgo.com/?q=fluorescent+tubes+power+lines&iar=... I've always wondered why drones didn't just come with qi charger landing pads. reply Kerbonut 5 hours agoparentLet's take that a step farther and have the drone implement direct coupling and charge while flying near the power lines. reply doikor 4 hours agoprevThat is going to be really hard (impossible?) to monitor for billing purposes. Basically would have to resort to self reporting/honor system. reply wanderingstan 2 hours agoparentAs others have pointed out, the energy consumed would literally be “too cheap to meter.” More realistic would be that, If fully realized, this becomes a great secondary income stream for the power line owners. Not only do they get to monitor their own lines with self-powering drones, but they rent out access to delivery drones, traffic monitoring drones, and (yes) whatever nefarious and helpful uses people dream up. Monitoring would not have to be perfect in order for them to still make huge profits. Seems more akin to how the railroad companies realized that could make a fortune by using their right-of-ways for communications cables. And for monitoring: seems like an obvious solution would be to have monitoring drones that watch for usage by other drones. :) reply sspiff 2 hours agoparentprevOr good old fashioned theft. reply rkagerer 11 hours agoprevI presume the current transformer is spec'd for a particular range of current/voltage. Would the drone need to assess if the line is a suitable one before (or after) connecting? Also was a private power line used, or did the university ask the power company for permission before conducting their field tests? reply atenni 9 hours agoparentLooks like the tests were run on a private line belonging to an airport. From the associated PDF[0]: > “Testing was conducted at the outdoor three-phase powerline setup at HCA Airport in Odense, Denmark at the disposal of the authors…” [0]: https://findresearcher.sdu.dk/ws/portalfiles/portal/25601008... reply nhma 3 hours agoparentprevThe voltage of the powerline is not relevant since the charging principle is based on inductive coupling. So as long as you have a current above ~100A the harvester should work, irrespective of voltage. And high currents equal higher charging power. To optimize charging time, the drone could perhaps analyze the magnetic fields to determine which line has the highest current to optimize charging time. But I would assume some sort of balancing is happening between the lines and phases. The powerline used is a custom mockup with just 5V AC. But we have also landed on real powerlines. I think there's a video in the channel of the OP video. reply blacksmith_tb 13 hours agoprevPretty cool, though my take is that if it's recharging just from induction it's essentially stealing the electricity... I suppose if the owners of the lines want to have autonomous drones monitor their status, that's not stealing, but if you wanted to release some little flying vampire drones of your own which could run indefinitely that way, someone might be less amused. reply dkjaudyeqooe 10 hours agoparentIt's odd that people in the comments assume use without permission and stealing. You wouldn't attempt any of this without permission, regulatory approval and insurance, unless you wanted to be sued, prosecuted and go broke if something went wrong. How do people think the real world operates exactly? reply lolc 9 hours agorootparentOh but the scenario where the drone does it without permission is just way more entertaining. reply dkjaudyeqooe 9 hours agorootparentThree-quarters of a megavolt of electricity plus drones does seem like a lively mix. reply rtkwe 7 hours agorootparentThere's no current though, the same way birds can sit safely on lines all day long. reply baq 1 hour agorootparentWhere is there no current? The video says 300A if I heard correctly reply dclowd9901 5 hours agorootparentprevThere is definitely current or there would be no wattage. reply pineaux 4 hours agorootparentI dont know. There is definitely a flow of energy between the power line and the drone. But there is no closed circuit between them so there is no current flowing. I imagine there is a (slightly, almost not measureable) raised current in the powerline due to a lower resistance due to the parasitic voltage drop and phase shifting cause by the inductive load. So technically no current between the drone and the powerline. Although there is energy transfer. But there are probably lots of people here that understand the laws of electromagnetism a lot better than me. reply jefftk 4 hours agorootparentprevIt's hard to induce a current in a bird. reply BikiniPrince 6 hours agorootparentprevImagine a future in which the power company manages drones that destroy the electronic barnacles on their lines. reply kerkeslager 7 hours agorootparentprevBro, \"it's better to ask forgiveness than permission\" is a pretty common saying in business circles. A lot of enormous businesses, such as Uber or AirBnB, were founded completely on operating without permission, regulatory approval, or insurance, until those things were absolutely forced upon them, and even then they didn't always comply with the law. It's also common that companies assume they will be sued, and go ahead anyway because they know they'll make more money than they'll be sued for. And if you do get sued... there's a good chance you can just never pay up, which I'm seeing more and more often. The real world is certainly not your optimistic \"corporations won't do anything wrong because they're afraid they'll get in trouble\". reply cdchn 5 hours agorootparentSkirting regulations and stealing from another megacorp in the open are somewhat different I think. reply ethanbond 9 hours agorootparentprevHave you met Silicon Valley? reply fragmede 9 hours agorootparentprevdriving drunk is illegal as shit too, but you can't be naive enough to believe that's enough to stop people from doing that. If you had a drone and wanted to see if this worked, you'd just drive 50 miles from your house and just... try it out. The US isn't yet covered with surveillance cameras like the UK. reply dclowd9901 5 hours agorootparentprevFor this public demonstration, sure. I’m curious how you think power companies are supposed to be aware of entities leeching off transmission lines? reply hiddencost 4 hours agorootparentAmerica does everything via a combination of insurance and lawsuits and regulations. If people are doing this at any appreciable scale, the penalties for being caught will get ratcheted up until it's not worth it. You only have to ruin a relatively small number of lives before people mostly choose to do what you want. reply pengaru 2 hours agorootparentprev> How do people think the real world operates exactly? uh.. \"Move fast and break things\" and \"It's easier to ask forgiveness than to get permission\" come to mind. reply declan_roberts 13 hours agoparentprevI was trying to figure out exactly how it charges with just 1 pole. It must be induction in that case, right? reply pkage 12 hours agorootparentFrom the video description: > A passively actuated gripping mechanism grasps the powerline cable during landing after which a control circuit regulates the magnetic field inside a split-core current transformer to provide sufficient holding force as well as battery recharging. reply nealabq 11 hours agorootparentprevWhen the grippers close they probably close the loops of a coil that wraps around the wire. So it's harvesting the ever changing magnetic field that arises from AC current, independent of voltage. You can still get some power from coils that aren't wrapped around the wire but are still parallel. I think that's how wireless phone chargers work. You can also take power using a capacitor instead of an inductor, from the changing voltage (not current) in an AC line. Like when you hold a florescent tube vertical under a hi-power line, and it lights up. reply phanimahesh 18 minutes agorootparentThat is induction though. Acapacitor alone can not extract energy from a ac line. Inductance is what allows energy transfer here. reply dist-epoch 12 hours agorootparentprevIt could have a small spool of wire to drop to the ground to make contact. This would allow the drone to rest on the wire while charging. reply bdamm 11 hours agorootparentThis would vaporize the drone, the wire, and anyone or anything nearby, sending flaming battery and electronics shrapnel in many directions. High tension does not mess around. reply non-chalad 7 hours agorootparentSee what happens to a branch: https://www.youtube.com/watch?v=g4ph-h7l_aM reply jcims 6 hours agorootparentOr a conductor hauled up by fishing line https://youtu.be/mqRT7J86rco?si=Za9B-dA-VO-Fl5Z8 reply taneq 5 hours agorootparentprevNot if you put a large enough resistor in the line. It might be enough just to extend a spike to bleed off charge, though. reply idiotsecant 10 hours agorootparentprevThat is exactly opposite of what would keep the drone safe. In a power transmission network the earth is a conductive path. Touching a phase and touching earth allows the grid to push as much power through you as your impedance and grpund contact will allow. reply duskwuff 10 hours agorootparentThat, and long spools of loose wire and spinning propellers are not a good combination. reply throwaway14356 4 hours agorootparentprevIf it can make contact with the ground it should be able to charge from the static field. https://makezine.com/article/craft/1000-fluorescent-lights-p... reply quickthrowman 9 hours agorootparentprevThe link below is a video showing the explosion that would occur if someone attempted what you are describing. https://youtu.be/LCRfYIwFbxQ reply delichon 13 hours agoparentprevThis could become a major power draw over decades. It's probably time to figure out a protocol. E.g. a cheap light small low power meter on the drone that can post the transaction to the electric company while in flight, signals to designate power lines as in or out of the system and their current price, etc. Solar roof owners could compete with the utilities. There are unicorns hiding in this forest. The vampires will be the charging drones that aren't associated with a transaction. So it's about as enforceable as a requirement that drones have accurate identifier transponders. reply Kerbonut 5 hours agorootparentIf I was the power distribution owner I would not trust the drone meters. Probably would need some type of load profiling on the distribution side, then all the drone has to do is authenticate a valid customer id for billing. reply krisoft 34 minutes agorootparent> If I was the power distribution owner I would not trust the drone meters. Understandable. > then all the drone has to do is authenticate a valid customer id for billing I mean you can ask for anything, but how do you police it? If the drone is by a recognisable entity doing legitimate things sure you can fine them if they don’t comply. But what do you do with literal fly-by-night operators? reply deadbabe 12 hours agorootparentprevWho cares? If they don’t want their power drawn they need to be burying their powerlines anyway. reply 1minusp 12 hours agorootparentCost of undergrounding power lines is large. Especially over the distribution network (in that there is a lot more of it over space) reply sdenton4 12 hours agorootparentOn the other hand, hung lines have a tendency to fall down, get tangled in trees, and start forest fires, so the cost of above ground lines is also high... reply woopsn 7 hours agorootparentBurying those lines is not practical. Inspecting and repairing them is. The problem is significant deferred maintenance. Buried lines cost much more to maintain, in addition to installation costs even where they are feasible. It's better to make sure (1) the towers don't fall down (2) into a forest ready to ignite. That can be done, but we have to pay. reply rrr_oh_man 12 hours agorootparentprevIf Workers & Resources: Soviet Republic taught me anything it's that underground power lines are for the capitalist bourgeoisie. reply deadbabe 6 hours agorootparentprevSee this is the thing: people complain about the little bit of power being eaten up by drones. But if power companies really cared, they’d bury their powerlines. They really don’t care. It’s a rounding error. reply Filligree 5 hours agorootparentThis is a classic prisoner’s dilemma, and you’re advocating for both sides to hit “betray”. Perhaps if enough drones did this, they would indeed bury the lines. But that would be strictly worse than a world in which they didn’t bury them, and drones don’t steal electricity regardless. reply j-bos 12 hours agorootparentprevAlternatively Who cares? If they don’t want their oil siphoned they need to be burying their pipelines anyway. Most would agree that unauthorized draws from common infrastructure resulting in loss is theft. reply davely 12 hours agorootparentI feel like I would be more sympathetic to this argument if my utility provider wasn’t PG&E. reply cogman10 10 hours agorootparentprevTheft, yes, how serious? Not very. Basically a rounding error for the power company. They likely see higher loses from things like fence lines installed near power lines. reply idiotsecant 10 hours agorootparentprevIn which case the earth itself can steal the power, in addition to making your electric bill 500 times higher from the capital cost required to bury millions of miles of transmission network. reply cogman10 10 hours agorootparentI'd assume buried lines would be HVDC rather than AC which effectively eliminates the loses from burying. reply wglb 11 hours agoparentprevIf that can be measured, I would be pretty surprised. I would project that the drain from all possible drone charging is orders of magnitude less than the e.g. coronal loss or the static radiation that blasts my ham radio. Any legal action would need to be able to document that loss, one would think. reply Terr_ 11 hours agorootparentBut you agree the loss exists, right? It's simply difficult to detect from some aggregate noisy flow at a centralized location, because the system was never designed to make that easily measurable. The amount could be estimated by looking at how much flying the drones do between charges, or by suing for access to charging/position telemetry of the units. reply SirSourdough 11 hours agorootparentIf the drones could meter their own consumption from the line using a utility-approved meter, anyone with a drone with said meter should be able to just tap onto lines at will and get a bill at the end of the month. Not sure how that plays out in terms of the weight/packaging of the drone but seems feasible for at least larger drones. reply plorg 8 hours agorootparentReally depends who owns the lines; I doubt many T/D owners would want drones flying around by their lines, much less directly grabbing them. reply wglb 6 hours agorootparentprevI would argue that it is less than an order of magnitude smaller than the coronal discharge or other losses. I suspect we are talking about 24 watts as compared to eg 1000 megawatt 500kv line. This is seven orders of magnitude difference. Totally lost in the noise. reply cdchn 5 hours agorootparentIf companies could sue Nature for potential lost revenue, they would. reply CSSer 5 hours agorootparentNew FAA announcement: Effective immediately, all airspace below 500 feet near powerlines is now classified as Class M airspace (for money). If your registered drone is detected nearby, you’ll be charged per second. reply Terr_ 6 hours agorootparentprev> smaller than the coronal discharge [...] lost in the noise This is again technically plausible but ethically irrelevant. It's like the fallacy in: \"It's OK for people to steal goods from that store, because the parent-company is very big and one theft won't even show up on their monthly financials and they've got spoilage and breakage too.\" > I suspect we are talking about 24 watts The video demonstration shows 50 watts of input. Napkin-math: Suppose one drone uses 1000 (battery) watts flying around, and does so for 4 hours each day for a month. (Made possible by an improved version of this research that charges at 200w.) That's 4 kWH. The electrical price is $0.20/kWh. That means siphoning $24/month for one drone. That's not a casual \"keep the extra penny\", that's a Netflix Premium subscription. reply jfoutz 4 hours agorootparentAn alternative view, power companies point the finger at drones for outages or fires. Look the other way when people are stealing pennies. When the billion dollar bill comes in, hand it off to the police. Let them identify the operator, and put them on the hook for damages. reply _visgean 11 hours agorootparentprevright now the loss does not exist. Its a cool experiment. If this was a big thing the drone fleet operators would simply get some kind of legal agreement with the transmission operator. But overall we are talking about really small amounts of energy. reply Terr_ 9 hours agorootparent> we are talking about really small amounts of energy Napkin-math time: I see 4 motors, searching the model-number suggests each has a max draw of ~380 watts, so let's assume it averages 1000 watts in operation, for 6 hours a day, with a local cost of electricity at $0.20 per kilowatt-hour, and this continues for one month. 1000*8/1000*$0.20*30 = $36 per month per drone. That's not give-a-penny-take-a-penny territory. reply SECProto 5 hours agorootparentThat's bad napkin math. Per the video, it is charging at 50W. At worst, it would be charging 24hr/day, so 50Wx24h is 1.2kWh per day. Using your 20¢ rate, that's $0.24 per day or 7.20/month. That's the upper bound, assuming it only charges and does no work. reply Terr_ 5 hours agorootparent> That's bad napkin math. Per the video, it is charging at 50W. I previously pointed that out to someone in another comment, however I did not use 50 because the video-presentation continues with: > The current in the power-line was approximately 300 amperes [...] a higher power-line current would result in a proportionally higher charging power. As future iterations of this system become more efficient, the ratio of time spent flying and time spent charging will significantly increase. The point remains that once you reframe the electrical situation in financial terms, you will realize it is not just gleaning discarded ergs, and is instead significant enough to raise questions of theft and justice. reply PopePompus 11 hours agorootparentprevThis video would probably suffice to document the loss, assuming the recharging was done without the utility's permission. reply cryptonector 10 hours agoparentprevArmed forces don't care. Get it? The likeliest user of this technology will be armed forces. reply etrautmann 9 hours agorootparentThe biggest use case for this would be inspecting the powerlines, so presumably not stealing in that case. reply cyanydeez 9 hours agorootparentSecond is spy drones. reply incompatible 7 hours agorootparentThe criminal uses would seem quite extensive, such as smuggling or bombing a rival's premises from a safe distance. reply paulhart 9 hours agorootparentprevMore likely it’ll be utility companies that want to do remote and autonomous inspection of the transmission network. It’s already a big business, but if you can run the drone the entire length of the line without relocating the base as frequently, or have no base at all and transmit data over 5G? Big wins. reply Animats 7 hours agorootparentRight. Drones for power line inspection are common. Far easier than inspections involving bucket trucks, helicopters, or even people on the ground with binoculars. This will simplify that process. Especially for lines through rugged country, where following the line is difficult. Start the drone where the power line crosses a road, and then drive to another road crossing for pickup. Warning lights for aircraft which clamp onto power lines have been available for many years.[1] [1] https://clampco.it/obstruction-light-low-intensity-type-b-se... reply nhma 1 hour agorootparentPowerline inspection and maintenance are the primary use cases for this technology. And at least this particular system is in the early spinout process via https://www.ongrid.tech/ reply tarikjn 12 hours agoparentprevThere probably are exemptions for emergency or defense applications. reply causality0 9 hours agoparentprevI don't think you know how infinitesimal the amount of power would be. Assuming a Mavic Mini traveling at its maximum speed of 29 miles per hour, it could cross the continental united states in 99 hours for 36 cents worth of electricity. reply snypher 5 hours agorootparent~2kwh of electricity is around 160 aH at 12V, surely the Mini is more than 20W power at top speed? reply 05 9 minutes agorootparentYeah, it’s easier to use lab test data from Mavic Mini 3 specs: 51 minutes flight time at 21kph [0]. The battery capacity is 28.4Wh [1]. So, 18.4/(21*51/60) = 1.6 Wh/km. Assuming US is 2800 miles (4500 km) wide, we get 7.2 kWh of energy under ideal conditions, without accounting for charging efficiency and the impact of the charging system weight on flight time. Edit: 21kph is the optimal speed for max flight time but not for the best energy efficiency per km. Most efficient speed is somewhere between that and the top speed. But this is the right order of magnitude at least. [0] https://mavicpilots.com/threads/mini-3-51-minute-flight-time... [1] https://forum.dji.com/thread-291222-1-1.html reply shahar2k 6 hours agoprevI imagine something like a weaponized version of this, loitering semi autonomous drone swarms fully charged / ready to deploy hanging off wires... a bit like the US spider munition or just smart landmines. reply cdchn 5 hours agoparentYou don't need them to loiter. You just launch them when you have a target. We've had that for a long time; its called a missile. reply hiddencost 4 hours agorootparentYou should pay more attention to the war in Ukraine. reply mrinterweb 11 hours agoprevI can't imagine power companies would be ok with this. People go to jail for tapping into power lines. Energy theft from power lines is illegal. Even if this was somehow allowed by power companies, I wonder if they would be any weight considerations if multiple drones hooked on to the same line span. I see applications for this, but anyone operating these drones would need clearance from the power company they are tapping into. reply Reason077 11 hours agoparent> \"I can't imagine power companies would be ok with this. People go to jail for tapping into power lines.\" Presumably it's the power companies (specifically, transmission network and distribution network operators) who will be most interested in this. They're increasingly using drones for infrastructure inspection, finding faults, etc. reply avs733 10 hours agorootparent1000%. Funny enough my engineering capstone tried something very similar but much more stupidly complicated. Do it while flying a parabola with a winged drone. Never got the control system to work…crashed into a lot of local power lines. Our assumed customer was power companies doing inspection. reply underlogic 11 hours agoparentprevFor affordable long range assassination operations. Make it in clear matte plastic, quiet, low flying, add some obstacle avoidance and facial recognition perhaps. Quite a nasty package under 1500 dollars I bet. Could even be ultra small w poison darts too. reply cdchn 5 hours agorootparentYou know whats really quiet? A supersonic missile. reply cmilton 10 hours agorootparentprevYou had me until poison darts! reply HeatrayEnjoyer 10 hours agorootparentprevShaped 10g C4 charges reply underlogic 6 hours agorootparentTarget may be able to duck in time and you'd only get one attack per drone. Maybe a gyrojet explosive tip munition with poison coating for the shrapnel, where the firing drone could time the tip detonation by tracking the projectile in real time after launch. That would be light enough to provide several shots or for multiple targets. With infrared target the jugular. Highly inconvenient to defend against with armor and the projectile will be incoming fast enough such that there's no opportunity to evade, assuming it can get in range quietly. There's a huge market for this. From nation states to divorcing couples reply sherburt3 8 hours agoparentprevIf the FBI was going to kick down your door over this I think the $5 of energy you stole would be at the bottom of their list of concerns. reply idiotsecant 11 hours agoparentprevPower companies are really the only ones who care about inspecting power lines anyway... reply Havoc 12 hours agoprevWould this have energy loss in the same way a phone wireless charger has? Or is this just leeching energy that would be lost anyway reply WJW 12 hours agoparentNo this definitely drains energy from the power line. reply kernoble 13 hours agoprevReminds me of this video demonstrating this on the ground with a self wound inductor. I'm assuming the one on the drone is optimized for the voltage/freqency of that transmission line. https://www.youtube.com/watch?v=CLS8pbDNHbk reply dontupvoteme 3 hours agoprevCan't wait for the failure mode where they sit over HVDC lines, fail because there's no alternating magnetic field, and then fall on them and hobble the infrastructure. reply nhma 1 hour agoparentThe gripper has several modes. There's a mode for charging the battery and providing holding force given AC powerline current, a mode for just holding the drone without charging given AC powerline current (if battery is full), and another mode where a small current (about 1W power) is taken from the battery and used to provide holding force in the case where there is no powerline current. Additionally, the gripper can be designed to fail open or fail closed, whichever is deemed appriate for the end-user. reply ortusdux 13 hours agoprevPrev. post / original publication: https://news.ycombinator.com/item?id=39943807 reply nhma 3 hours agoparentEarlier post (also no discussion): https://news.ycombinator.com/item?id=39679772 reply scoot 13 hours agoparentprevThere is no previous discussion. reply ortusdux 12 hours agorootparentEdited reply bdamm 11 hours agoprevThis opens up all kinds of legal issues. The military applications could be very interesting as well. reply pnjunction 12 hours agoprevWow! Is there any project which allows collaborative SLAM? OSM/Mapillary for commercial drones basically. reply scotty79 3 hours agoprevI hope Ukrainians are watching this. It would be a shame if even a single russian refinery remained out of their drones range. reply Muromec 3 hours agoparentThose are different kind of drones. To successfully enhance a refinery, it takes a smallish plane with a pot of explosives, not a tiny grenade-dropper or fpv. reply pockmockchock 2 hours agoprevthis is nice, perfect for surveillance, like boarder control etc. reply ben_w 13 hours agoprevCongrats to the team. Semi-seriously: Yet another item on the list of ideas I totally came up with on my own, honest, I just never did the hard work to make it real. (I know, I know, my ideas count for nothing when I don't turn them into reality. Actually making hardware means solving a lot more problems than my imagination provides, and who likes facing those surprises in side-projects?) reply foobarbecue 12 hours agoparentYeah, this idea was pretty obvious -- both at LANL and JPL I worked in labs that were doing perching drones and we talked about landing on powerlines and charging inductively. The LANL work was 2013 and the JPL work was 2018. I think most \"good ideas\" are going to be thought of by thousands of people before they become a useful reality. Ideas per se really are pretty worthless and patents are only useful as a means of proxy warfare between large corporations, I'm afraid. Ever since I was a kid I've wanted to build a hanging chair something that latches onto powerlines and travels along them :-) Also reminds me of how I actually built a burrito delivery drone for fun that lowered a burrito on a winch a couple of years before the \"tacocopter\" story started doing the rounds on the news (early 2010s). It's interesting that drone delivery never made it beyond rural pharmaceuticals. reply pricechild 12 hours agoparentprevSemi serious: was that enough to have patented the idea yourself? reply ben_w 11 hours agorootparentI believe you can get patents without a physical model? I wouldn't have bothered with a patent for something like this though. Probably is money in it now I think about it, but patents are just not the kind of thing I think much about. reply cdchn 5 hours agorootparentYou can get a patent for something that doesn't even have to necessarily work. reply pricechild 1 hour agorootparentprevCrazy, Huh? reply akira2501 12 hours agoprevIt's going to be a very costly operation to go retrieve one of those once it's \"gripper\" ultimately fails. That's hoping it fails closed instead of failing open. Getting these parked in the face of upcoming weather is not going to be particularly fun, either. Given that you need a solid alternate location anyways, why not just go there instead? Then we can build safe single function autonomous ground charging stations that a human being can just walk up to and service on foot. Too clever by half. reply dkjaudyeqooe 10 hours agoparentThe application is for drones doing work in the field and needed to recharge on that basis, it's actually a very good solution for coverage of a large, possible remote, area. The alternative is a large number of charging locations which is very expensive. There's no need for alternate charging or parking in weather. Besides merely going into a hibernating state with a radio beacon and light in emergencies, recovery could be via a vehicle positioned in an optimal location relative to the drones where they can all converge and be collected. In the case of charging limitations you could execute more than one convergence location. Also the drones could be used to remove failed drones stuck on lines. Nope, this is fully clever. reply akira2501 9 hours agorootparentI'm suggesting that hanging random amounts of weight off of power lines is probably not a great engineering plan, less so if the wind or heat or load picks up significantly. My concern isn't for the drones it's for the actual power infrastructure. Are the drones designed for inspection or for heavy lifting and applying mechanical leverage against other objects? Are you so sure they're going to be able to do both? It's trying to solve two problems at once, and while the solutions individually may be clever, combined they seem like a total waste and fraught with complications. reply wanderingstan 2 hours agorootparentThe lines are far more robust than that. Right now human inspectors are used to crawl the lines for inspection! https://youtu.be/oBJyyEAw-6g?si=wW71x2tPyDxMuZA0 The weight of a drone, which is already designed to be light for flight efficiency, is not even worth factoring in. reply akira2501 2 hours agorootparentFor the light drone they used in the paper they had a 5 to 10% cycle. It has no detection equipment on it. They're ultimately going to need a much heavier drone to actually do inspections. Which, if you're going to go the autonomous route, ground based charging becomes much more justifiable in terms of fixed cost. Aside from that, they already have ground controlled attached cable \"walking\" drones in use by several providers and manufactured by several companies. Similarly to human inspectors you wouldn't deploy them on a windy day either and can have professionals ready and on scene in case any problems do happen. Anyways.. the point of this paper is they've worked out the landing and release technology and can credibly claim continuous operation although with a very little flight time in between recharges. Which is great, but as an application to the inspection problem, I still maintain it's too clever by half. This has applications, likely with custom drone only infrastructure, in which case you could do direct attachment and really speed up the charge time to something useful, but my strong guess is certainly not for autonomous inspections. reply dkjaudyeqooe 9 hours agorootparentprevReally, you're overly negative. Those lines aren't light to begin with, wind and other issues you mention are just basic design considerations. And the important point is there are no good alternatives. reply akira2501 2 hours agorootparentReally, my disposition has no bearing on the facts. They are designed to handle wind but I doubt those design parameters included random weights attached at random points between spans. The lines also change shape based on temperature. If the clamp abrades the line under high wind conditions then you are weakening and possibly breaking the line. If the hardware that mounts the line to the tower can't handle the additional loading then you risk breaking it and dropping a live line on the ground. No good alternatives? That's exceptionally unimaginative. The lines are strung up with towers. You could just put a station, on the ground, right at the base of the tower, where it would be much easier to directly connect it to the power lines in a safe and permanent way. reply numbsafari 12 hours agoparentprevI mean… who’s to say you aren’t operating these for nefarious purposes and the last thing you want to do is have them go back to a central location? Or if they are part of a defensive perimeter, or a long haul operation, where centralized service is problematic? These could be used for power line infrastructure observation and possibly even repairs at some point. reply AI_beffr 13 hours agoprev [–] i had this idea in 2011 reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The video explores autonomous overhead powerline recharging for drones, ensuring continuous operations without interruption.",
      "The topic is discussed as part of ICRA 2024, highlighting the latest advancements in robotics and automation."
    ],
    "commentSummary": [
      "The debate examines utilizing drones for recharging and functioning in proximity to power lines, discussing issues like recharging on current infrastructure, mechanical stress, billing concerns, and utility operators' opportunities.",
      "Considerations include ethical implications, feasibility of induction charging, risks of power theft, legality of drone use near power lines, burying power line costs, energy consumption for inspections, and possible military uses.",
      "The discourse revolves around the safety, feasibility, and consequences of employing drones for power line operations."
    ],
    "points": 148,
    "commentCount": 127,
    "retryCount": 0,
    "time": 1712343046
  }
]
