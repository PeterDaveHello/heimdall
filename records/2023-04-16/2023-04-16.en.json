[
    {
        "id": 35577895,
        "timestamp": 1681536908,
        "title": "Valve Restricts Accounts of 2500 Users Who Marked a Negative Game Review Useful",
        "url": "https://tech.slashdot.org/story/23/04/14/175246/valve-restricts-accounts-of-2500-users-who-marked-a-negative-game-review-useful",
        "hn_url": "http://news.ycombinator.com/item?id=35577895",
        "content": "'Valve Restricts Accounts of 2500 Users Who Marked a Negative Game Review Useful'122Posted by msmash on Friday April 14, 2023 @02:00PM from the how-about-that dept.New submitter jth1234567 reports:In late January, a Steam user posted a negative review for the game Warlander, warning potential buyers about the shady anti-cheat system the game was using, the apparent problems being intrusive data collection and difficult removal after the game itself had been uninstalled (the review text is no longer available). This review stayed on top as the most helpful review for nearly three months, which must have been a big thorn in the side for the developer and the publisher.Until yesterday, when they managed to get a Steam moderator to remove the negative review. In a perfect, consumer-friendly world it should have been another way around, and the game's sales page removed until the claims were investigated by Valve, but this is not a perfect world. However, things didn't end there.Apparently the Steam moderator categorized the negative review as \"attempting to scam users or other violations of Steam's Rules & Guidelines\", which meant that all those 2439 people (plus people who have it 437 awards) got their accounts restricted for 30 days, during this time none of them can up- or downvote any Steam reviews at all.Support tickets from affected users to Steam Support have received a default response saying Support will not help nor adjust the length of vote bans.The Steam review system was never perfect, but the impact of this kind of behavior from Valve will render the whole system completely pointless, as negative reviews can be culled by the developers/publishers at any time, and people will just stop marking any negative review as useful to avoid these kinds of repercussions.\u2190You may like to read:\u2192Can Intel Become the Chip Champion the US Needs?Elon Musk Buys Twitter For $44 BillionDespite EVs, People Are Buying Manual Transmission VehiclesHas Online Disinformation Splintered and Become More Intractable?Twitter Is Now an Elon Musk CompanyCan California's Power Grid Handle a 15x Increase in Electric Cars?28 State AGs Urge Congress To Pass Stalled 'Right To Repair' Bills",
        "summary": "Valve has restricted the accounts of 2500 users who marked a negative review for Warlander useful, leading to a 30-day ban on up- and downvoting for those affected. Steam moderators classified the review as \"attempting to scam users or other violations of Steam's Rules & Guidelines,\" resulting in the review's removal, and many believing the review system being \"completely pointless\" due to the impact of Valve's actions.",
        "hn_title": "Valve Restricts Accounts of 2500 Users Who Marked a Negative Game Review Useful",
        "original_title": "Valve Restricts Accounts of 2500 Users Who Marked a Negative Game Review Useful",
        "score": 624,
        "hn_content": "Valve has restricted the accounts of 2,500 users who marked a negative game review useful after the warlanders game installed anti-cheat software with suspicious behaviors on their machines. Hacker News users criticized Valve for allowing this \"malicious software\" on their platform, which makes it \"indistinguishable from malware.\" There is a debate about the effectiveness of anti-cheat software and a call to rely on reviewing game footage and behavior to catch cheaters. Sudden and consistent outliers above normal performance levels would flag players for review, and measuring inter-account variability in performance is insufficient when accounting for account-sharing scenarios.Anti-cheat malware is installed on every gamer's computer, causing more harm to innocent players than punishing cheaters, and often misidentifying them. Some users argue that intrusive corporate malware is not necessary and should not compromise individual freedom, while others propose viable alternatives such as the use of Vanguard, an anti-cheat system that uses an early mode kernel driver. Cheating in online games has become a lucrative industry with script kiddies subscribing to cheat makers for around $9.99/month to see through walls and auto shoot other players. While kernel drivers work effectively against cheat makers, allowing unsigned drivers has been complex and intrusive. Some users suggest limiting interactions to private servers for fair gaming.\u00a0A discussion on Hacker News centers around the potentially invasive nature of anti-cheat software in online gaming. One commenter points out that the intrusive nature of such software can lead to false positives, citing a personal example. However, another commenter suggests that the use of anti-cheat software is necessary to prevent cheating and protect the integrity of the game. Some commenters bring up past incidents of corporate-sponsored malware, such as Sony's rootkit, and express concern about the potential for anti-cheat software to similarly exploit users. While some acknowledge the need for anti-cheat measures, others argue that they fundamentally compromise user privacy and freedom.The comments refer to issues related to anti-cheat software and Valve, highlighting concerns over censorship and potential mishandling of moderation. Users suggest methods for fully uninstalling problematic software, and raise questions about the effectiveness of anti-cheat measures in addressing cheating in multiplayer games. The debate also touches upon the potential risks of running unverified software, with some users advocating caution when using private servers or third-party programs to remove unwanted software. There is no new technology being released, and the comments diverge significantly from the main point of the article.A discussion on anti-cheat measures for online multiplayer games revealed various opinions, with some users suggesting that anti-cheat is necessary to combat botting and cheating, while others feel that it is lazy and that game developers should implement better game design to minimize cheating. Some users criticized game management and suggested that security should be implemented at the hardware level, while others discussed pricing out cheaters or doing cheat detection entirely server-side. Ultimately, the issue of cheating in online gaming remains an important problem for fair interaction online.The article and comments explore potential solutions for cheating in gaming. Some suggest community policing and traditional community servers as effective measures. Others discuss the limitations of anti-cheat software and the challenges of sandboxing processes on Windows. There are calls for complete end-to-end sandboxes, as well as concerns about restricting personal computing freedom in the pursuit of better gaming security. Despite varying opinions, many agree that preventing cheating is important but challenging, and doing it right is tricky. One comment mentions a previous incident where rampant cheating led to unplayable multiplayer games.Comments on a Hacker News post discuss the ethics of Steam\u2019s monopoly on PC video game distribution and its use of anti-cheat software. Some users argue that Steam\u2019s monopoly is a lesser evil compared to having dozens of platforms, while others criticize their policies such as requiring games to be sold at a lower price outside of their platform. Additionally, concerns are raised about the privacy and data security of users on the platform. However, some users defend Steam\u2019s record, pointing out that they invest in wine development to run Windows games on Linux, and that DRM is optional on the platform.Gamers prefer Steam over GOG for Linux installers, with Steam offering better support and a more superior product. The benefit of offline installers is that it allows players to install games forever, which GOG is more committed to than Steam. However, some Steam games are DRM-free and can be played without an internet connection, but the platform still provides its storefront, authentication, distribution and updater, which is valuable to some players. GOG had been delisting game developers such as a Taiwanese game developer who made a joke about Xi Jinping, which led some players to stop making purchases from them.Developers have made integration optional for the user but included \"no multiplayer\" in their definition of optional, which is a reasonable compromise given that modern multiplayer games are architected to use centralized software. The Steam store has DRM-free games, but GOG goes the extra mile by ensuring that old games work on new Windows versions. Some users say that it's easier to run old Windows games on Linux via Wine/Proton than on the latest version of Windows. Steam is the most known and used storefront, but competition exists with Epic Game Store, which takes a 12% cut from developers, and GOG, which advocates for games without DRM. As a gamer, the experience with Steam is superior, but the company is not without fault, as demonstrated by its lack of support for macOS M1 binaries and a reliance on x86 frameworks. Valve has invested heavily in Linux support due to the need to diversify beyond Microsoft. This post covers a range of topics related to gaming and various storefronts.Valve has levers to pull to encourage ARM builds of their games, such as offering a lower commission rate for games that have ARM builds. Mac support is lackluster, and Apple has not maintained OpenGL support well, among other things. Supporting Linux was a hedge against an OS vendor using their power, and Steam cares about making money, as seen by their investment in Linux. Valve's investments in Linux are their future insurance policy from Microsoft, unlike Sony or Nintendo. As long as Valve and the reader's incentives are aligned, they will keep giving Valve their money and recommending their products to others.The article discusses Steam's effective monopoly in PC video game distribution, but HN users note that there are many other competitors in the market, even though they may not be as good. Some argue that monopolies are not inherently unethical but rather actions taken to maintain a monopoly. Convenience is seen as an ethical good, but externalized costs must be considered. The primary readers are industry experts who want unique insights and new information beyond what they already know.Valve released Steam 1.0, which was seen as a soft launch in preparation for HL2, as noted by an HN user. CS 1.6 required Steam when Valve shutdown the WON servers. A user mentioned that CS was a mod that Valve bought, which caused almost everyone to abandon PC gaming for consoles. Some users discussed the potential benefits of switching to the Xbox/MS store and Gamepass after the ActiBlizz Microsoft sale. However, others prefer Valve over Microsoft and appreciate the ability to download games purchased on Steam years ago. Despite other PC game distribution services, Steam remains the best by a significant margin.",
        "hn_summary": "Valve restricts accounts of users who marked a negative game review useful, leading to criticism from Hacker News users about Valve's allowance of \"malicious software\" on their platform. Some suggest alternatives to anti-cheat software, while others argue that it is necessary to prevent cheating in online gaming. The comments discuss the ethics of Steam's monopoly on PC video game distribution, with varying opinions on the need for monopolies and the effectiveness of anti-cheat software."
    },
    {
        "id": 35580847,
        "timestamp": 1681568400,
        "title": "Why does a plastic-wrapped turkey sandwich cost $15 at the NYC airport?",
        "url": "https://hellgatenyc.com/why-is-airport-turkey-sandwich-expensive",
        "hn_url": "http://news.ycombinator.com/item?id=35580847",
        "content": "Airport vendors are subject to strict price standards set by the Port Authority of New York and New Jersey; however, pre-packaged food at CIBO Express and other kiosks remains significantly more expensive than comparable products in the NYC metro area. Despite the efforts of the Port Authority's Office of the Inspector General to investigate airport pricing, a recent public records request has been denied, with individuals suggesting that the agency is withholding information either because it knows its process was flawed or simply to dodge public criticism. Jake Forken, an Excelsior Fellow at the state watchdog for public records access, suggests that the Port Authority is required to disclose factual data or final agency determinations regardless of whether there was action or not.No relevant tech news is present in the given raw text content. As an editor, no concise summary can be provided.",
        "summary": "N/A",
        "hn_title": "Why does a plastic-wrapped turkey sandwich cost $15 at the NYC airport?",
        "original_title": "Why does a plastic-wrapped turkey sandwich cost $15 at the NYC airport?",
        "score": 434,
        "hn_content": "An HN user discusses the reasons why a plastic-wrapped turkey sandwich cost $15 in the NYC airport, attributing high pricing to the extreme rents that airports charge vendors who are captive because of the TSA screening process which penalizes people for leaving the airport. HN users debate the limited competition inside airports and the lack of comparables for airports' F&B vendors, making it impossible to ensure fair pricing. Some users suggest that passengers should bring their own meals, which can be cheaper and taste better. Other aspects are also discussed, such as the failed effectiveness of post 9/11 TSA security measures or the possibility of deregulating and privatizing airlines.Airlines can form a consortium to operate ATC themselves, better than a government failing at modernizing; modernizing would help break away from the hub model that gives airports much power, and cheaper. Deregulating and privatizing wouldn't improve travel experience, as demonstrated by developments in Europe, and privatisation not being a panacea for improvement. The limited number of suppliers approach is almost always worse. At airports, an airport doesn't have to use the TSA: other private companies that operate under TSA specifications are feasible. But restoration of public services is preferable. High-level governments' improvements are also often out of reach compared to their private counterparts, leading to the preference for change at the latter. Security at high-security airports is not useful; however, airport security is necessary, given its unique potential for harm compared to other modes of transport.Opinions on airport security vary, with some finding it useless due to flaws in the system and others noting its importance in preventing hijacking. Major differences were found between US and non-US airports in terms of possible security inefficiencies. While some users believe it could be more efficient, others note that taking such measures could involve additional privacy and liberty violations. There are also comments about prohibited items and the arbitrary nature of TSA rules. Finally, a humorous comment about bringing sandwiches through security was made.The enforcement of the zip-top plastic bag rule in US airports for liquids, gels, and aerosols is next to non-existent. Anecdotal evidence suggests that it's rare for TSA to confiscate food that isn't liquid, such as sandwiches. Waiting times for TSA security tend to take two hours at the airport. Low-cost airlines tend to negotiate with airports about landing fees, as they generate less profit than traditional airlines. Often, food service places at airports operate on thin margins, and the money paid for food tends to go towards rent and other overhead costs. Finally, the article highlights the need for airports to feature well-known franchises that people are comfortable with and which price things appropriately.HN users discuss the cost of running airports and the pricing of food within them, with some arguing for more expensive airline tickets to account for carbon emissions. European airports tend to avoid airport-only chains due to large duty-free shopping areas, with Slavic tourists often being among the most avid buyers. Some HN users take issue with the privatization of airports in some countries, with profits raising questions over executive pay. Food pricing at airports is seen by some as a convenience tax, while others argue for a carbon tax on flights. Bringing food through airport security is allowed, but often restricted to sealed or new items.HN users discuss their experiences with bringing food through airport security. Some mention success with special, non-frozen items while others suggest creative solutions like dehydrated soup. The high prices of airport food and drink options are also a topic of conversation, with some attributing it to the rent charged by airports and others blaming the in-flight snack food companies. However, there seems to be agreement that the captive audience of travelers allows for gouging. One HN user offers insight into an unsuccessful attempt to regulate airport concession pricing.The lack of price protection policy enforcement and airport vendor staff has caused overpriced plastic-wrapped turkey sandwiches. The airport's monopoly on food contract and captive audience also allow for higher prices, despite regulations. Similar hospital shops face high rents and must charge more, regardless of competition. The government's involvement in contracts and potential corruption may explain why some airports have more competition than others. Movie theaters charge more for distinct candy offerings, but airports lack unique food. Customers are willing to pay more at both venues despite cheaper alternatives existing outside.Theaters offer a culturally significant, nostalgic experience with overpriced food; airports don't. Popcorn and candy combos can cost over $20. For some, sneaking food into theaters is a culturally meaningful experience. Cinema theater attendance is slimming due to the high cost of the authentic experience. There is no fair competition for airport food concessions as many are run by a single contractor. Airport food prices are driven by what the customer can pay. Some comparable sandwich stores charge less than the $15 sandwich at airports. Whole Foods sells a comparable sandwich for $7.99.A discussion on the price of sandwiches at convenience stores like 7-11, with some commenters noting the high prices in some cities while others claim reasonable prices in their own areas. Overall, there is a debate over what factors contribute to the high cost, with various expenses such as overhead, labor, and ingredient quality being brought up. Some commenters are critical of unclear pricing practices at certain stores. One commenter provides a link to a tutorial on making cheaper sandwiches at home. Qualifying statements are discouraged in the summary.Various comments talk about the restrictions on bringing fresh fruits and vegetables on a plane due to agricultural pests and disease prevention. The article also explains how American airports do not generally have international-to-international airside transfers where passengers do not have to pass through immigration, therefore, allowing them to visit the US instead of taking a connecting flight to their final destination. There are discussions on the difference in value and pricing of food at airports and how monopoly affects it, and the use of economic terms such as consumer surplus and surplus value. However, some comments also veer into discussions on Marxism and debunking theories.HN users discuss the monopolistic and inflated prices of food in airports based on the captive market situation. Some users point out the possibility of delivering food to airports, but others dismiss the idea due to logistical challenges and higher costs. The elasticity of demand of food in airports is debated as an indicator of the value to the buyers. The fact that travelers can bring their own food on planes is mentioned. The issue is attributed to the lack of competition and exclusivity tied to reasonable pricing in airports.",
        "hn_summary": "HN users debate the reasons why a plastic-wrapped turkey sandwich costs $15 in NYC airports; limited competition inside airports and the lack of comparables for F&B vendors make it impossible to ensure fair pricing. Users suggest passengers bring their own meals instead."
    },
    {
        "id": 35583228,
        "timestamp": 1681583303,
        "title": "Lofi air traffic control \u2013 LAX",
        "url": "https://www.lofiatc.com/?icao=KLAX",
        "hn_url": "http://news.ycombinator.com/item?id=35583228",
        "content": "133.900LOS ANGELES TOWER (NORTH) (1/2)KLAXLos Angeles International AirportGlimlip x Yasper - I'm sorryAirportSettings\ud83d\udcac Share feedback | \u2615 Buy me a coffee",
        "summary": "The post shares the frequency of the Los Angeles Tower (North) at KLAX, which is 133.900. The post includes a music video by Glimlip x Yasper and provides an option for feedback or donation.",
        "hn_title": "Lofi air traffic control \u2013 LAX",
        "original_title": "Lofi air traffic control \u2013 LAX",
        "score": 431,
        "hn_content": "Lofi air traffic control website is gaining attention amongst HN readers, which features air traffic control in a laid-back, chilled out style; some HN users request additional features and radio chatter. Some users recommend SomaFM and Blue Mars for similar ambient music, but the standout feature of lofiatc.com is its neat presentation. Some HN users return to the discussion of in-flight passenger entertainment in the form of listening to ATC comms, and whether or not passengers should be privy to them. Nonetheless, listening to ATC transmissions can create feelings of safety and comfort for some passengers.HN users discuss their preferences for ambient music while working, with some finding that instrumental music is less distracting, and others preferring music in languages they don't understand to avoid language processing. Some users recommend SomaFM's channels and the website mynoise.net for their ambient sounds. A few users note that they get easily distracted by any hint of human speech in the ambient sounds, but one suggests black metal as a suitable alternative as the lyrics are often unintelligible. There is no clear consensus on the best type of ambient music for concentration.Users on Hacker News are discussing a new web app that lets you listen to air traffic control (ATC) communications over lo-fi beats in the background, and it's gaining popularity. Despite some mixed feedback on the quality of music and the difficulty of finding particular airports, many users are finding the combination of calming ATC voices and background music strangely relaxing. There are suggestions for other similar services, including automated weather and radio broadcasts, and some users recommend live streaming the real-time Apollo missions. While most of the discussion is lighthearted, some users offer technical tips for altering the ATC audio to make it even more relaxing.",
        "hn_summary": "Hacker News users are discussing lofiatc.com, a new web app that combines ambient music with air traffic control communications in a soothing way, sparking interest; some users are requesting additional features and radio chatter. Users are also sharing their preferences for ambient music while working, with recommendations for SomaFM and mynoise.net, and a few suggesting black metal as a suitable alternative, although there is no clear consensus on the best type of ambient music for concentration."
    },
    {
        "id": 35576918,
        "timestamp": 1681523247,
        "title": "What are transformer models & how do they work?",
        "url": "https://txt.cohere.ai/what-are-transformer-models/",
        "hn_url": "http://news.ycombinator.com/item?id=35576918",
        "content": "Transformer models are a new development in machine learning that are great at keeping track of context and generating coherent text. They can be used for a variety of tasks such as writing stories, essays, poems, answering questions, translating between languages, and even passing exams. The architecture of transformer models is not complex, consisting of tokenization, embedding, positional encoding, transformer blocks, and softmax. The most complex part is the transformer block which contains the attention and feedforward components. Transformers are trained with a lot of data from the internet and build text word by word based on context.Transformers are neural networks that use tokenization, positional encoding, attention, feedforward blocks, and a softmax layer to generate text. The attention component is essential in dealing with context and enabling language models to understand different meanings of words. Multi-head attention is used to modify vectors and provide more context in transformer models. Post-training can be used to teach transformers to perform specific tasks, such as answering questions or functioning as chatbots. Transformers' success is due to their ability to capture many aspects of context through a large number of parameters.",
        "summary": "Transformer models are a new development in machine learning and are adept at generating coherent text by tracking context. With the ability to perform various tasks, such as translating between languages and answering questions, transformers consist of various components, including tokenization, embedding, positional encoding, transformer blocks, and softmax. The most complex transformer block employs attention and feedforward components, with multi-head attention used to modify vectors and provide more context. Post-training teaches transformers to perform specific tasks, and their ability to capture context has led to their success.",
        "hn_title": "What are transformer models and how do they work?",
        "original_title": "What are transformer models and how do they work?",
        "score": 396,
        "hn_content": "The Hacker News post discusses transformer models and their functionality; comments bring up discrepancies in the explanations and recommend resources for learning more. Some comments address specific points in the article, such as the use of \"command\" to describe input token sequence, the lack of discussion surrounding residual components, and the limitations of using a softmax layer. The post attracts attention from experts in the field interested in gaining a deeper understanding of transformers. Resources provided include Sebastian Raschka's \"Intro to deep learning and generative models\" course, videos, and papers.OpenAI has released their tokenizers publicly, which use byte pair encoding (BPE) to specify the vocabulary size rather than token size. Several alternative methods for tokenization exist, including ByT5. Users on Hacker News have questioned how the computational details of machine learning models connect to their high-level behavior, revealing that this is an active area of study called mechanistic interpretability. While we still cannot fully explain human consciousness, it is surprising how the simple models used in artificial intelligence can display emergent behavior. Efforts are ongoing to analyze and explain how and why these models learn.The comments on an article about GPT models discuss how neural nets are trained via error minimization and not evolution, how RLHF is used for Reinforcement Learning with Human Feedback, and how the predict-next-word feedback is more like \"learn to generate something like this,\" rather than direct control. Large transformers learn what responses get ranked highly by humans, not necessarily what is desirable or desirable speech. The emergent behavior that is much more powerful than what you\u2019d expect from the training data is still a mystery. Finally, neural networks start out as just random numbers and are gradually adjusted until outputs converge on the desired loss.HN users discuss the use and efficacy of transformers in machine learning. The article discusses the optimization benefits and end-to-end training of such models. Some users suggest resources for learning about the workings of transformers or their own experiences implementing them. However, opinions vary on their success rates and the comprehensiveness of promotional content from companies specializing in AI. Some users express confusion or doubt about how attention mechanisms actually operate within these models. Questions are raised about the reasons for masking over a sliding window, but it is suggested that the former enables more comprehensive training on variable-length context.Short: \nText embeddings send text to a vector list of numbers. Users asked for visual examples to better understand equations in terse language. Transformers are not a new development, but scaling to more compute power is. RLHF is a bigger jump than LLMs in NLP. Embeddings are leading to innovations such as more accuracy in KNN search and the potential to replace anthropomorphic computing concepts like files. Open AI is making strides in training large models with emergent intelligent behavior. It's not accurate to say that we develop sentences one word at a time.",
        "hn_summary": "Users engage in discussions about transformer models, questioning their efficacy and the comprehensiveness of promotional content. Alternative methods for tokenization are mentioned, and resources for learning more are recommended, including courses, videos, and papers. The emergent behavior shown by simple models in artificial intelligence and the connection between computational details and high-level behavior are explored, highlighting an active area of study called mechanistic interpretability."
    },
    {
        "id": 35579334,
        "timestamp": 1681555012,
        "title": "WebGPU Fundamentals",
        "url": "https://webgpufundamentals.org/",
        "hn_url": "http://news.ycombinator.com/item?id=35579334",
        "content": "English\u65e5\u672c\u8a9e\u0420\u0443\u0441\u0441\u043a\u0438\u0439\u7b80\u4f53\u4e2d\u6587WebGPU Fundamentals  English\u65e5\u672c\u8a9e\u0420\u0443\u0441\u0441\u043a\u0438\u0439\u7b80\u4f53\u4e2d\u6587A set of articles to help learn WebGPUBasicsFundamentalsInter-stage VariablesUniformsStorage BuffersVertex BuffersTexturesImporting ImagesConstantsData Memory LayoutWGSLHow It Works3D MathTranslationRotationScaleMatrix MathOrthographic ProjectionPerspective ProjectionCamerasMatrix StacksScene GraphsMiscWebGPU from WebGLResources / ReferencesWGSL Function ReferencegithubWGSL Offset ComputerTour of WGSLWebGPU API ReferenceWebGPU SpecWGSL SpecFix, Fork, ContributeThank you jrpricefor 1 contributions",
        "summary": "This post provides a set of articles for learning the fundamentals of WebGPU, including data memory layout, 3D math, and WebGPU from WebGL. The post also includes resources and references for further studying, as well as opportunities for contribution. Thank you to jrprice for their contributions.",
        "hn_title": "WebGPU Fundamentals",
        "original_title": "WebGPU Fundamentals",
        "score": 379,
        "hn_content": "WebGPU Fundamentals, a website dedicated to the WebGPU API, has been gaining attention on Hacker News. WebGPU is a successor to WebGL and brings new capabilities for graphics to web browsers. HN users discuss the potential for using WebGPU for in-browser simulation and physics, as well as the possibility of training deep learning models on the client side using federated learning. Some users express concern about browser feature-creep and the standardization of browsers as OS interfaces. However, others argue that the choice of which browser to use allows users to avoid features they don't want.Some users commented on government sites and websites that only work on specific browsers, while others discussed the potential risks and benefits of using browsers as a platform for various applications. There was also some discussion about the advantages of web-based MIDI sequencers, experimental instruments, and WebUSB for updating firmware. Overall, the conversation touched on the current state of the web as an application platform and the challenges of maintaining both cross-platform compatibility and security in this context.The potential risks of adding too many features to web browsers have been discussed by Hacker News users, with some arguing that native applications are better suited for many tasks. However, others defend the use of web browsers for a range of purposes and suggest that their increasing functionality is a positive development. The main driver for adding features to browsers is seen as the popularity of Chrome OS and the need to continually update the browser to keep it relevant. Native software can be cumbersome to install, and many users prefer the convenience of using web-based tools. While some concern exists over the security risks of a more extensive web browser, it is pointed out that all software has vulnerabilities, and open-source web browsers receive regular updates to address these issues.Various users on Hacker News discuss their opinions on utilizing new browser features such as WebGPU, WebUSB, or WebCPU to solve different issues, with a few pointing out potential limitations or compatibility issues that may arise. Some users inquire about how to render text with GPU, with others providing several methods, including prerendering and using HTML canvas element. One user points out the advantages of using WebGPU over WebGL since it can run compute shaders. Some comments also discuss Google's decision not to implement WebGL compute shaders due to the release of WebGPU.The Tech Times reports on WebGPU and how users can utilize Multi-Channel Signed Distance Fields and signed distance fields to render fonts and vector graphics using GPUs. HN users also shared their thoughts on utilizing WebGPU for crowdsourced LLM training and its current browser support, with some noting the limitations and need for breakthroughs in distributed training. Firefox users may encounter issues with a lack of support but can work around it by using \"bgra8unorm\" for now. Three.js users can currently access WebGPU through the engine's examples page.The article discusses the potential for running AI on home servers, pointing to indications that investing more resources in training small models can produce models that are easier to run. The comments touch on issues such as algorithm development, privacy concerns, and web-based application development. There is also discussion of the relative simplicity and usability of web apps compared to native apps, as well as criticism of Firefox's support for web technology. Firefox's WebGPU support lags behind Chrome's, and although Firefox has support, it is behind a flag as the spec is still a draft.Apple and Mozilla were the first to have prototypes for WebGPU, followed by Chrome, but all three parties had prototypes. Firefox's implementation is based on wgpu, which has great community and a lot of users within and outside the Rust ecosystem. WebGPU is not meant to be a high-level, beginner-accessible graphics API, but rather a low-level GPU API that expert users can use for tooling. Most of the concepts used in WebGPU tutorials are foundational to web programming, and most people wanting lower level access to the GPU aren't doing so just because of simple graphics work.",
        "hn_summary": "WebGPU Fundamentals gains attention on Hacker News as a successor to WebGL for graphics on web browsers. Users discuss potential applications for simulation, deep learning, and concerns about browser feature-creep. Comments also touch on web-based MIDI sequencers, experimental instruments, and WebUSB for firmware updates. Some argue the advantages of web-based tools, while others express concern over security risks and compatibility issues. WebGPU is not meant to be high-level or beginner-accessible but a low-level GPU API for expert users."
    },
    {
        "id": 35585174,
        "timestamp": 1681597166,
        "title": "Google CEO: \"can we change the setting of this group to history-off\" [pdf]",
        "url": "https://ia601707.us.archive.org/28/items/gov.uscourts.cand.364454/gov.uscourts.cand.364454.385.0.pdf",
        "hn_url": "http://news.ycombinator.com/item?id=35585174",
        "content": "WebGPU Fundamentals, a successor to WebGL, is being discussed on Hacker News for its potential for client-side deep learning without uploading data to the cloud. ONNX runtimes using WebGPU and its compute capabilities for in-browser simulations are also mentioned. However, comments also question the potential excess of browser feature-creep and the standardization of browsers becoming equivalent to operating systems. Nonetheless, many commenters find the development of WebGPU exciting and useful, and see it as an opportunity for novel applications.Users on Hacker News discuss the issue of websites requiring specific browsers like Chrome, instead of adhering to industry standards for the web. Some argue that using specific browsers caters to a single company's monopoly on the market and restricts competition. Others mention the convenience of using web technologies as an application platform and using cross-platform tools. Some cite specific use cases where web technology and access to system resources are beneficial, despite potential security risks. The conversation touches on the history of web browsers as applications versus document viewers, and their evolving capabilities over time.A discussion about the scope of web browsers occurred on Hacker News, with one user advocating for browsers to solely browse the web and native applications to be used for other purposes. Several users argued that the trend is towards browsers acting as a cross-platform VM, and therefore, the scope should be broadened to include running applications. Some users expressed concern over the increase in vulnerabilities with more features being included in browsers, while others argued that native OS features also have security vulnerabilities. Users also discussed the potential implications of WebGPU and its uses in browsers and native applications.Users discuss various ways to render text using GPU in WebGPU, including rasterizing fonts with stb_truetype and drawing quads, using a canvas element and uploading as a texture map, and rendering characters as sprite maps. Some users express concerns about feature creep in browsers and the possibility of breaking app store monopolies. One user suggests that WebGPU can help with text rendering using compute shaders, but others note that Google's decision not to implement WebGL compute shaders may have slowed down adoption.WebGPU allows for scalable multi-channel signed distance field rendering of characters, but it's not a great tool for rendering user-generated text with emojis. Workarounds include using sprites or layering. Mesh shaders could be used to approximate vectors with triangles. Mozilla lacks WebGPU support in its stable version, but it's expected to come by April 26th. WebGPU is not yet ready for Three.js either. A collection script with subresource integrity check and npm package will be added to web3dsurvey.com. WebGPU cannot support distributed training or internet-connected computer collaborations.An open-source AI project will allow people to run the state-of-the-art AI, but it may require more resources than a single server can handle. There is a need for models that use fewer resources, and collaborative model training could be a solution. WebGPU may allow for crowd-sourced model training, but concerns about browser complexity and user privacy exist. Operating systems could add browser-like features, but not all users prefer native apps. Firefox lags behind Chrome in WebGPU support, but Firefox still has support behind a flag.WebGPU teams for Chrome, Firefox, and Safari are working closely on the low-level graphics API. Apple and Mozilla were the first to have prototypes and informed the creation of the W3C community group to design the API. WebGPU is not for beginners, but low-level GPU API for expert users. For most people just wanting a triangle on the screen, they can use other higher-level tools that will do the \"dirty\" work of using WebGPU. Firefox's implementation is based on wgpu, which has a great community and a lot of users in and outside of Rust ecosystem.",
        "summary": "Hacker News is discussing WebGPU Fundamentals, the successor to WebGL, for its potential in client-side deep learning and browser simulations. Conversations also touch on browser feature-creep, its potential usefulness and convenience, and the scope of browsers as applications or viewers. Additionally, users discuss ways to render text using WebGPU, its compatibility with AI projects, and the ongoing collaboration among WebGPU teams.",
        "hn_title": "Google CEO: \u201ccan we change the setting of this group to history-off\u201d [pdf]",
        "original_title": "Google CEO: \u201ccan we change the setting of this group to history-off\u201d [pdf]",
        "score": 327,
        "hn_content": "Google CEO, Sundar Pichai, has been accused of requesting to change a group setting in Google Chat to \"history-off\" despite the potential legal implications. By default, Chats retain 24 hours worth of history, with users able to opt-in to 30 days of history, which would not be deleted even during a \"legal hold.\" Google has allegedly seen users intentionally deploy the feature to delete conversations subject to legal holds. Google has been accused of violating FRCP 37(e), with USA and State AGs filing for sanctions against Google adhering to the duty to preserve relevant evidence as an \"unqualified obligation in all cases.\"Google has been accused of falsely assuring the court that it had taken steps to preserve all evidence relevant to a court action without mentioning its decision not to pause the 24-hour default deletion of Chat. The company's decision to continue with a document (chat) deletion schedule without exception for those with data retention holds raised legal issues, according to one user. However, another respondent claimed that turning off chat history often doesn't stop it from being recorded at all. Courts tend to view all written conversions the same way, with both viewed very negatively when a court has specifically asked the company not to destroy any material.An HN user raises questions about the legality of Google's auto-delete practices, with a link to documentation of legal holds. The post highlights the legal topic of evidence spoliation, which could potentially apply to any means of electronic communication that deletes messages. Remote work is discussed and the advantage of making it harder for companies to hide misbehavior. The post emphasizes the importance of maintaining a discoverable record when an obligation to preserve it exists. Users question whether or not software platforms such as Google, Slack, and other video/chat programs truly respect deleted messages or if they secretly mark them as \"deleted\" but still store the data in the background.Google has been under a litigation hold order to preserve all written or recorded communications related to litigation. A former employee claimed that Google treats all records as being as ephemeral as possible. Finance firms follow SEC record-keeping rules that require the preservation of all internal written communications. Google has the power to design its own hardware and firmware without many of its own internal teams being aware of it. The article highlights a difference in attitudes towards document holds between finance firms and Google. The comments in the post contain examples of internal emails sent by Google employees discussing eliminating records and conducting conversations off the record.Financial firms forbid recording Zoom conversations because no one is using Zoom to make trades, and firms don't want to pay for storage to comply with discovery requests in case of lawsuits. Trading conversations have to be recorded, hence, corporates' Zoom policies say that Zooms are not recorded, therefore, trading is not allowed over Zoom. Conversations on written correspondence not part of the system of record is a big issue. Regulators specify industry legal requirements for a regulated manner. Compliance can monitor employee nonconformance with the rules.The article discusses the separation of concerns in the tech industry and how equity research is paid. The market now understands that credit rating agencies are barely worth the bytes they are recorded in. Comments suggest concerns over lack of legal standards in the tech industry and the cost of phone call recordings. Tech is compared to Wall Street as \"disruption\" often involves breaking laws they deem \"outdated.\" GDPR reasons are given for making documents ephemeral in some companies. The storing of live traffic is to have a model of it to test changes against.Google's legal policies advise employees to delete chat histories and emails after a certain time frame to avoid legal retention challenges, which means that only necessary documents are retained for the entire duration of the company. However, some HN users believe that Google operates like a criminal organization, engaging in illegal practices and racketeering that should land its executives in prison. The ongoing litigation against Google highlights the necessity of not explicitly discussing avoiding leading a paper trail with respect to subjects where litigation is imminent or already in progress. The judge's decision may not lead to major consequences, but the discussion among experts on HN could lead to real change in corporate culture.HN users discuss the optional duration for retaining security camera footage and other types of internal communications. While there is no law mandating a specific length of retention, companies vary in their practices. HN users suggest that companies consider adopting a default position of not creating records unless necessary, as excessive data retention can be a liability in the event of a breach or lawsuit. However, some caution against explicitly discussing avoiding a paper trail. Google's messaging settings default to history off and delete messages after 24 hours but this raises concerns about destroying evidence. Some users discuss the difficulties of conducting business in a medium where almost everything leaves a paper trail. The main point of the discussion is whether we want a functioning market economy or not, and how competition is limited by market segments.An HN user argues that Google's Android business should be regulated as it currently has zero competition in the mobile operating system market, and suggests that it needs to be separated from the company until there is serious competition again. The author notes that the situation is even worse in Europe, where the issue is not high on the agenda. Discussions on retaining emails related to a pending lawsuit at Google in 2006 are shared, as well as opinions on government regulation and monopolies worldwide.The Tech Times reports on a varied range of cutting-edge tech news without political or religious bias. Readers are typically experts in their field, and the editor must capture points of interest and avoid repeating well-known facts. Including key points stated by HN users is acceptable but secondary to the article's primary topic. The editor must write in a confident yet clear tone and avoid using potentially ambiguous phrasing. Currently, the site notes YC Summer 2023 applications are open.",
        "hn_summary": "Google CEO Sundar Pichai faces accusations of requesting a change in Google Chat group settings to \"history-off,\" despite potential legal implications and the violation of FRCP 37(e). HN users discuss the importance of preserving discoverable records and concerns over the legality of auto-delete practices, with examples of other electronic communication that deletes messages. Additionally, discussions on data retention, government regulations, and monopolies worldwide are shared, while concerns over Google's Android business and its lack of competition arise."
    },
    {
        "id": 35577285,
        "timestamp": 1681527951,
        "title": "Surviving Burnout (2015)",
        "url": "https://lifeofaudrey.com/essays/surviving_burnout.html",
        "hn_url": "http://news.ycombinator.com/item?id=35577285",
        "content": "Written in June 2015The first thing I know about burnout is this: burnout happens when we become locked in a cycle of caring about the results of our actions but having no meaningful control over those outcomes. I first learned this while reading about social workers, but the problem is abdundant in tech. I\u2019ve seen it play out in every company and volunteer organization I\u2019ve been a part of. When responsibility, authority, and resources are not aligned, burnout is inevitable.2013 was one of the absolute worst years of my adult life. I was depressed, burned out, at a job that seemed to have become stagnant, and struggling to decide how to move forward. Then one of my closest friends died by suicide, followed by another friend a month later. I spent the next few months in crisis mode, doing the next obvious step, whatever that was. As the dust settled I realized: if I keep doing things the way I have been, I am going to die.With the help of a therapist, I started to piece together what was wrong. Not only was my job stagnant and demoralizing, the things I did for \u201cfun\u201d constituted an entire unpaid second job\u2019s worth of work in open source and community organizing. My family relationships brought me all stress and no support. I didn\u2019t have the resources to make any of these situations better on my own, and through trying to fix things anyhow, I had no energy left to care for myself.I quit. First my job: I took a month off before starting at a larger company where I\u2019d be working alongside a friend. Then I resigned from the board of the nonprofit I was on, even though it made me feel like a complete and utter failure. I declared myself to be on sabbatical from anything that didn\u2019t feel fun. Not that I knew what fun would look like anymore. I was still depressed and anhedonic.I focused on keeping a steady pace at work, and trying to rediscover self-care and fun by treating it as a series of experiments. Do I feel well cared for if I stop for fancy coffee every morning? Can I rediscover my creativity by doing the same crafts as a grade-schooler? It seemed ridiculous at times, and often I could only keep it going by treating it like a role-playing exercise and making up a persona. \u201cI\u2019m a person with posh tastes and an incredible sense of style. Everything I want, I have. My favorite daily habit is to walk along the waterfront at lunch.\u201dFinally, in early 2014, I felt I was starting to turn the corner. At last! This was recovery. Saying no to things felt like a super power. No, I can\u2019t help you with that. No, I can\u2019t come to a meeting. You want to start a group for allies of women in tech? I can\u2019t help you, but that\u2019s awesome! Have fun!Work was finally going well, too, then suddenly it wasn\u2019t. I discovered that despite the verbal emphasis on health and work/life balance, hitting the end of a release cycle meant panic and crunch time. It was such a dramatic shift from the previous six months, I was in shock. I started asking questions and pushing back, which resulted in a round of negative feedback from my manager.Oh, burnout, I recognize you. Here we go again. Since talking to management wasn\u2019t working, I kept my rabble-rousing to conversations with peers. Morale in our department was so low. Everyone seemed to know what was wrong, but no one with the power or authority to change it was listening. That started to be the thing I looked for: who in our company had to speak up before anything we needed would happen?I went through a terrible dark month where I thought I was about to be fired. I didn\u2019t feel effective at all, I couldn\u2019t focus, and not being able to talk openly about what I was thinking was draining all my energy. On top of that, I started to felt marginalized in other ways. The company was growing, but the level of diversity was not. Increasingly I felt, as one of only a few women developers in the department, that I stuck out like a sore thumb, and doubly so because I had been told my communication style was too negative and overbearing.Tech feminists, followed by news outlets, started talking about the problem of mid-career dropout rates for women. I read all the research I could find, and nodded along. Lack of mentoring and support, no career advancement past a certain point, tone policing, it all fit. Suddenly, my work experiences seemed like they were part of an even bigger pattern. This was good and bad: even if I didn\u2019t get fired, how long could I last?They didn\u2019t fire me, and we started to see small improvements, but nothing that could restore my trust. I started to feel like I could escape the burnout of cycle again, if nothing else, by caring less. At the end of the year, when the teammate I\u2019d joined the company to work with left for another job, I reevaluated my options.A friend asked me, if you\u2019re looking for work, send me some requirements and I\u2019ll keep an eye out for anything that matches. I thought about it for weeks, completely stumped. It was like my earlier phase of burnout recovery: how could I know what would sound rewarding or fun? What am I even qualified to work on next? Finally, one evening on the bus home from work, I typed out an email.I said, I don\u2019t know how this is going to be a job, but I want to get back to the root of why I became involved in technology in the first place. It\u2019s because I discovered the Internet, which ended my teenage isolation and allowed me to connect with other people. I care deeply about the tools and infrastructure this is built on, and how they affect our ability to communicate.A few weeks later, a timely suggestion gave me the idea for a business built from those desires. I made a plan, and tried to balance the things inside my comfort zone with the things I would need to learn. It\u2019s still early days, but going to work for myself was the best decision I could have made, and it\u2019s only been possible because of last year\u2019s sabbatical from unpaid work, a really amazing therapist, and endless love and support from friends.This next phase, I think, is rebuilding. Running a business is exciting, and complicated, and hard. I have to learn something completely new every few weeks. I also don\u2019t have the level of funding that I really need to feel comfortable yet. A week or two in, though, I thought: the hardest day of working for myself is never going to be as bad as trying to survive in a company where I didn\u2019t fit. So far, that seems to be right.My story isn\u2019t a prescription for anyone but me. I pulled off a pretty great trick: creating space to recover from burnout in one area of my life, while coasting in others, then rotating until I finally had the mental and emotional space to plan my full escape. But it has changed how I think about burnout, and how I want to help other people if I can. Burnout is a structural issue, built into the dysfunctions of our industry. Burnout is made out of individualism, and meritocracy, and doing too much with too little. Burnout is built on the idea that if we skip a meal and work more hours, we might finally get ahead.Structural problems require structural solutions. Healthy organizations, healthy people. Someone I know who\u2019s in alcohol recovery told me, at the root of our problems is the belief that individuals can bear responsibility for personal failures caused by societal oppression. I want to see burnout recovery support, and burnout recovery funds. At its worst, people die while trying to earn enough money to escape this environment. How can any of us get better if we can\u2019t afford to extract ourselves from the environment that caused the harm?If you hear yourself in my story, remember that you\u2019re not alone. Getting better will take time, distance, and support. Burnout closes off our options, makes us feel like everything we do will fail. When you\u2019re finally in recovery, you\u2019ll start to be able to see what an environment that doesn\u2019t do that to you looks like. Then we can build it together.",
        "summary": "Burnout in the tech industry is caused by a misalignment of responsibility, authority, and resources. The author's experience with burnout pushed her to quit her job and enter a period of recovery, which led her to start her own business. Burnout is a structural issue that requires structural solutions, with recovery support and funds being necessary for those affected.",
        "hn_title": "Surviving Burnout (2015)",
        "original_title": "Surviving Burnout (2015)",
        "score": 291,
        "hn_content": "The article discusses surviving burnout and finding balance between caring and having control over outcomes through acquiring and matching resources to one's care. Several HN users shared personal experiences of struggling with burnout and depression, highlighting the difference in symptoms and impact on sleep. While depression led to hopelessness and a loss of self-worth, burnout resulted in permanent stress, anxiety, and doubt about the usefulness of one's work. Ultimately, the article aims to help readers find ways to align their caring with their available resources to avoid burnout and maintain balance.The post details users sharing experiences with burnout and depression caused by work while offering advice on how to handle it. Users suggest seeking therapy, quitting toxic jobs, and making time for fun activities. Additionally, experimenting with new activities and engaging in social hobbies can help reduce stress. The importance of finding a fulfilling work-life balance is highlighted, with a reminder to prioritize activities that make you happy.Physicist Richard Feynman discovered a new phenomenon while playing with a plate and later got a Nobel Prize for it. He expressed the importance of enjoying physics for the fun of it, without worrying about any significance. Burnout can occur when the job demands outweigh the resources, and it's a good idea to avoid such a situation. High resources-low task jobs lead to high motivation and low stress, low demand-not much motivation, high urgency-overwhelming demand and high significance-meaningful jobs. Priorities change as one moves up the business ladder. Good design is always important, but perfect design is an expensive approach. Finally, it's essential to distribute agency and accountability to everyone for the team's success.An article, originally from Hacker News, discusses the idea that caring too much about work, without having any control over the outcome, can lead to burnout. The article also notes that as a developer gains experience and maturity, they tend to care less about work. However, not keeping up with new technologies can limit job opportunities. Some comments illustrate examples of burnout-inducing workplaces, due to a lack of control over decisions made by higher-ups. The key takeaway is that one should care about their work, but not to the point where it affects their mental or physical health.An expert shares a personal experience of working at a company with a management philosophy of separating different functions, resulting in dissatisfaction for engineers. Many readers relate to this experience and some offer advice such as seeking professional help or quitting to start one's own business. Others note that this management philosophy is common in many companies and may be due to inexperienced managers or the desire to copy successful companies. Some comments suggest that this philosophy may be a recipe for disaster in startups. Finally, some readers link this philosophy to personality disorders and offer tips on how to deal with manipulative individuals in the workplace.An employee experiences burnout due to the company's pivot and product debt. They reflect and consider leaving for a new employer. Other HN users offer advice and recommend budgeting recovery time or having 'walk-away' money to escape abusive work environments. The users also recommend not basing self-worth on the opinion of others and understanding that solutions should consider people in the company. The importance of owning the problems in a company as a way to move up is also highlighted. Burnout recovery time is dependent on individuals, but one user suggests that taking a month might not be sufficient. Finally, starting a business is recommended by some as a potential solution to gain autonomy and overcome burnout, although others consider it a fast track to burnout.The topic of the article is how starting one's own business can lead to burnout. Some users in the comments point out that not all businesses are the same and the landscape has changed since the article was written. The idea of having a performance coach or therapist on the payroll to help employees with mental health is suggested, but there are mixed opinions on its effectiveness. The sentiment is that \"treating people well\" is difficult to scale, and not all employees will have the same idea of what that means. While having such coaches could help, it's important to focus on treating employees well first. Some are cynical about the idea and suggest that it can add pressure to employees and ultimately lead to burnout.An article featured on Hacker News discusses the efficacy of having a lifestyle coach or therapist to combat employee burnout. While some commenters recommend employers providing coaches for all employees, others express concerns about the coach being owned by the employer, reporting to them and the potential for conflict of interest. Commenters suggest that employers should give employees the funds to get a therapist rather than relying on companies who may have ulterior motives tied to 'maximum value' extraction. The article features a mix of opinions on the topic of employer-provided therapy and coaching, with some suggesting it has limited utility for engineers but could prevent employee burnout and therefore improve business performance. Many in the comments section discuss medical insurance being tied to work as a major problem that needs solving.Comments on Hacker News express the importance of self-care and recognizing burnout warning signs. One user noted that burnout happens when there is a cycle of caring about results but having no meaningful control over those results. However, another user shared their experience where they work harder and longer and take breaks when needed, with higher-quality output and no burnout. There is discussion about the difficulty of finding a healthy company structure for recovery from burnout, and the idea that companies may contribute to the problem. Suggestions are given for regular social activities and self-care, though caution is advised against doing too many activities at the expense of deeper connections.Audrey's experience with burnout is a common issue in the tech industry, caused by structural problems that require structural solutions. Healthy organizations can lead to healthier individuals, and support and recovery funds should be available to those affected by burnout. Some HN users offer solutions, including trying different activities before focusing on one or two passions, using megacorps for their wellness benefits, and rotating between areas of life to recover from burnout. Burnout can follow you, whether or not you run your own company. Finally, some HN users suggest using hate as an antidote to burnout, while others point out that burnout is just when you run out of fuel.",
        "hn_summary": "An article on Hacker News discusses the importance of finding balance to avoid burnout and maintain mental and physical health, while users share personal experiences and offer advice. Some HN users highlight the differences between depression and burnout, while others offer tips for dealing with burnout-inducing workplaces or starting a business as a potential solution. Several readers also discuss the efficacy of having a lifestyle coach or therapist to combat employee burnout, with mixed opinions. Ultimately, the key takeaway is that caring about work is important, but not at the cost of one's wellbeing."
    },
    {
        "id": 35578240,
        "timestamp": 1681541254,
        "title": "Low Code Software Development Is a Lie",
        "url": "https://jaylittle.com/post/view/2023/4/low-code-software-development-is-a-lie",
        "hn_url": "http://news.ycombinator.com/item?id=35578240",
        "content": "jay-fresh        jay-fresh-auto        jay-fresh-dark      LoginHomeResumeAboutFamilyGithubMastodonProjectRecipesLow Code Software Development Is A Lie2023/4/14 8:36 PMI've been writing custom software for a long time and one of the things that annoys me most is when a client adopts the position that there is a silver bullet which will reduce or remove the inherent complexity of this task. This happens more often than you'd think and guess what? They are almost always wrong.Perhaps I'm getting a bit too old and loose lipped for my own good, but the truth is that creating software for other people is exceedingly difficult. Contrary to the opinions of non-practitioners (aka non-coders), this difficulty is not the fault of coding languages, tools and paradigms. It is actually the result of clients and developers not taking the time to understand the root causes of the problems they want to solve and not designing a solution around the conclusions you'd draw from that process.It isn't enough to code the tool as specified by the client. The first step before you start coding is to validate the existence and the details of the problem itself. Most coding projects are initiated after the client realizes that they have a problem and decide to ask for code which they think will resolve it. The reality is that most clients are not professional problem solvers, whereas that is precisely what Software Developers do. It therefore falls upon our shoulders to validate the approach suggested by the client before we possibly waste both their time and money developing it.So let's be clear: I'm not disparaging clients. They know they have a problem, they just might not fully understand how to design and implement the most sensible and appropriate solution to that problem. Sometimes, it doesn't even make sense to write any code to solve some of the problems I have been presented with over the years. That's because in a lot of cases, the problem at hand is actually a process problem. But from the client's perspective, it's easier to pay somebody to code a tool to solve a problem than to attempt to change an entrenched process.I previously touched on this idea back in 2019 in my post \"Why I Can't STFU And Just Code A Solution To Your Problems\":The easiest way to explain my mindset is as follows. I'm a professional problem solver whose primary tool is code. People don't come to me and ask me to write code because everything is hunky dory. On the contrary they come to me and ask me to code a solution for whatever problem they are currently experiencing.In any event, if you get past all this, its time to write some code, right? Well usually. That's where this blog post comes in. Sometimes a client falls into the trap of believing that there is some kind of silver bullet they can employ which will negate the inherent complexity around coding custom solutions. Nowadays the most cliche form of this is to say, \"Well I'll just ask ChatGPT to code that for me\". I call bullshit. While ChatGPT can handle some simple coding tasks, anything beyond that causes it to rapidly devolve into an unmanageable mess.Beyond the in vogue AI Chatbot example, there are a wide variety of other snake oil tools lingering about. All of them sell prospective buyers on the premise of allowing them to cut through the cruft and quickly pump out custom software without going through the years of training that professional Software Developers tend to go through. The most relevant example of this syndrome are so-called low code tools. As it so happens, I work with one of these at my current job.This low-code tool is called OutSystems and my review of it is that its a steaming pile of shit. I won't go into the technical specifics of why as that probably deserves it's own post. While it has enabled some non-developers to produce custom logic and screens, it hasn't actually removed the inherent complexity around designing proper data structures, writing fault tolerant software and validating the quality of the resulting software. Because a lot of the coders in question don't have this expertise, the end result is a custom software system that is poorly thought through, is brittle and as a result will require constant fire fighting on the part of the future members of the team in an effort to keep it functional.I haven't even mentioned the best part: Tools like this aren't cheap and they tend to structure their licenses / billing so that you end up paying for as long as you use the software you produce with the tool. On top of which, all of these tools seem to involve accepting some level of vendor lock-in. So the more time you put into tools like these, the tighter their grip on your proverbial balls becomes.In both the AI Chatbot and the Low Code tool scenarios, the solutions each promise a shortcut around the complexity as perceived by a non-practitioner. That's the essence of the trap. Practitioners know that the writing of the code is merely the last step in a long process that involves a lot of thinking, discussion and planning. The code is generally the end result and producing it is relatively easy once you truly understand the problem at hand.TLDR: Designing a solution worth a damn is actually the most difficult part of the software development process. Low Code tools lie to customers by implying that the writing of code is the hardest part. The reality is that No Low Code tool can spare you from having to take the time to properly design your custom software or the consequences you will experience when you build solutions around a half-ass design.[ Back To Home ] [Previous Posts]Search: Find [Top] [Rss] [Email]",
        "summary": "An experienced software developer argues that creating software is difficult due to clients and developers not understanding the root causes of problems they want to solve, rather than the fault of coding languages and tools. The author critiques the idea of \"low code\" tools such as OutSystems, stating that they do not remove the inherent complexity and may lead to poorly thought-through software systems, as well as being expensive and involving vendor lock-in. Properly designing a solution is the most difficult part of the software development process, and no tool can replace the necessary thinking, discussion, and planning.",
        "hn_title": "Low Code Software Development Is a Lie",
        "original_title": "Low Code Software Development Is a Lie",
        "score": 253,
        "hn_content": "Low-code software development can be useful for tasks that require code as incidental complexity, but it's not a solution for complex problems that low-code tools cannot handle. Low-code tools are best for the first set of problems, but should not be used as replacements for developers. Some HN users shared experiences in using spreadsheets for decision-making processes in medical devices due to FDA regulations. Creating throwaway prototypes can lead to problems when they become the actual system. Code is just a precise expression of business logic, but it doesn't apply universally as some applications do not involve \"business logic\".An online debate occurred on Hacker News reflecting the lack of clarity in the definition of business logic in creative apps compared to UIs, and how it might be more of a domain and rule-based model than a coding problem. Some comments suggested that coding can help in refining thoughts and in figuring out the desired outcomes best. The discussion also touched on the benefits of using no-code or low-code platforms in certain situations, even for developers who know how to write code.Low-code tools like spreadsheets can help build large and complex things, but after a certain point, it's more trouble than it's worth. Low-code tools should focus on being rapid application development (RAD) platforms rather than just replacing code. Low-code solutions can save massive time and expense, but some users have gripes about poor testability, versioning, and debugging tools. There are two types of low-code environments: one is too complex and the other too simple. Low-code platforms are particularly useful in domain-specific applications, offering batteries-included solutions. The lift in efficiency is stunted if a low-code platform needs to handle too many use cases.Low-code solutions are pre-packaged fixes to common problems with trade-offs - you gain canned components but lose open development ecosystems. Low code makes sense for common business use cases that are not worth developer time. It's inappropriate for tasks where solutions are hacked into the tool or for delivering a core business competency. Low code is dominant in the data integration space, and low-code tools are useful in games/films. Some low code companies may promote bad coding practices and inexperienced salespeople. Low-code tools allow teams to separate into coding and non-coding teams. Bayesian software gets you quickly to 70% of what you want, but getting 100% is a game of diminishing returns.A recent HN thread discussed the trend towards low-code solutions in software engineering, particularly as a way for companies to sell B2B services. This approach allows engineers to configure tools provided via a B2B sale rather than developing solutions from scratch. However, some users believe that over-reliance on low code solutions could lead to a \"brain drain\" on new developers, who may not understand basic software architecture since they spent their careers configuring B2B tools. Additionally, some comments note that low-code solutions have been inaccurately marketed as \"no-code,\" and that these tools are only useful for certain situations, depending on the complexity of the project. There is a debate about whether or not all coding is programming. Some believe low- and no-code tools constitute programming since folks use them to control machines. Regardless, low-code tools are only useful for certain situations, depending on the complexity of the project. Finally, the comments stress the importance of a good tool-problem compatibility fit, to avoid making writing code unnecessarily difficult.Low-code and no-code tools may be useful but have limitations, as they constrain programming challenges, result in less flexibility and precision, lack good version control, and may lead to vendor lock-in. Low-code tools do have a place in the toolbox and may save time in making solutions that match user requirements faster. While low-code seems suitable mainly for small and low complexity software, it is valuable in tracking disease spread, pollution, and dashboard creation by non-engineers in the government sector. However, developers and clients must take time to understand the root causes of the problems they want to solve to avoid failures.The difficulty with software development lies in designing a solution that is of value, not in writing code, according to 'Closi'.\nHowever, 'rwalle' stated that Low Code tools are great for fast prototyping and often produce functional products.\nUsers of low-code tools are more willing to settle for what the tool can accomplish, regardless of their initial requirements, according to commenter 'ryanackley'.\n'Non-programmer' users can create custom reviews for Shopify stores by using low-code tools, as shared by \"gregjotau.\"\nFinally, \"sustainable\" software should be designed with security practices, version control, and unit testing, which is undermined by insufficiently precise low-code tools, according to \"siliconc0w.\"Experts on Hacker News discuss the usefulness of low-code development tools for creating a limited subset of software systems, with some users noting that low-code tools are helpful for prototyping and validating ideas while others argue that low-code solutions just give enough rope to hang oneself like any other kind of coding. Some argue that there are various use cases, including back office systems and operational tools, where low-code tools could be good options for building products. However, \"low code\" is a blurry definition, with Excel and shader graphs both potentially falling into this category.Experts on Hacker News discuss the viability of low-code tools, with some praising their usefulness for prototyping and early stages, while others warn of potential lock-ins and limitations for more complex applications. An HN user points out the importance of carefully choosing the appropriate tool depending on the type of application, with some suggesting that with the advent of LLM, low-code may become more prevalent again. However, some users caution against the potential downsides, while others criticize specific low-code tools like OutSystems for poor UI and functionality.",
        "hn_summary": "Low-code software development is useful for simpler problems but unsuitable for complex ones, and should not replace developers altogether. HN comments discuss the limitations and trade-offs of low-code platforms, including poor testability, versioning, and debugging tools that can lead to vendor lock-in. Some experts suggest that low-code tools can be valuable for prototyping and certain applications, but others caution against over-reliance on them and advise carefully selecting appropriate tools. While low-code has various use cases, the definition is blurry and potentially misleading, with Excel and shader graphs being examples."
    },
    {
        "id": 35581532,
        "timestamp": 1681572776,
        "title": "Remote code execution vulnerability in Google they are not willing to fix",
        "url": "https://giraffesecurity.dev/posts/google-remote-code-execution/",
        "hn_url": "http://news.ycombinator.com/item?id=35581532",
        "content": "A security vulnerability in Google allowed a security researcher to run arbitrary code on the computers of over 50 Google employees. The researcher found the vulnerability through security research into dependency confusion. The vulnerability involves Python's dependency management system and the use of the \"extra-index-url\" parameter. Google initially classified the bug as a severe vulnerability, but later changed their stance, calling it the intended behavior of their software. The researcher suspects that Google did not understand the problem, or they do not care about fixing it. The researcher has been receiving downloads from Google employees daily and fears the vulnerability could be exploited by someone with malicious intentions.An individual gained unauthorized access to Google's internal systems through \"dependency confusion\" and found multiple non-existent private packages that could have been used instead. The individual does not disclose the names of these packages. Google has since been notified of the breach and it remains to be seen if they will take additional action. The individual plans to write a follow-up piece detailing their methods for finding these package names from open-source data. Google has awarded the individual a $500 bounty for discovering the breach.",
        "summary": "A security researcher found a vulnerability in Google that allowed them to run arbitrary code on the computers of over 50 Google employees, caused by dependency confusion in Python's management system. Google initially classified it as severe but later changed it to intended behavior. The researcher fears the vulnerability could be exploited, as they have been receiving downloads from Google employees daily, and suspects Google does not understand the problem, or they do not care about fixing it.",
        "hn_title": "Remote code execution vulnerability in Google they are not willing to fix",
        "original_title": "Remote code execution vulnerability in Google they are not willing to fix",
        "score": 229,
        "hn_content": "A Remote Code Execution (RCE) vulnerability was found in Google's software, but the company is reportedly not interested in fixing it. Hacker News users discuss the issue, with some pointing out that Java's package management system has a more secure way of uploading packages than Rust's system. Others note that the problem lies with `pip install --extra-index-url` ignoring user-specified registries, which renders the concept of private registries useless. However, some also remind readers that all package management schemes eventually break and that Java's system simply shifts the problem, while naming conventions in Rust make it vulnerable.Comments on a post discuss the level of breach caused by an attacker gaining access to an engineer's workstation. Some argue that this can be the highest possible level of breach, while others contend that it depends on the company. One commenter offers a bet to security teams that they would be unable to prevent the deployment of malicious, unreviewed code. Some users argue that infiltrating a large organization involves multiple chains of vulnerability and that gaining access to an engineer's workstation is an initial entry point. However, some argue that technical measures are in place to prevent this.Google's security did not react strongly to a recent report that an attacker poisoned internal\u00a0packages with a malicious package because Google monitors to see what was leaked. An HN user also suggests that because an attacker with code execution on a lot of Google systems can circumvent many controls and protections, this potential attack is not unexpected. Meanwhile, there have been proposals for better defenses in other\u00a0registries against similar attacks such as adding namespacing.A vulnerability in the public open-source tool chain, pip, is not a Google vulnerability, but rather engineers inadvertently downloading untrusted packages. One user suggests that this blog is a desperate attempt to get Google to pay, and another argues that malicious code can be run on any employee's system. Google has zero-trust security measures to combat insider threats, and the company implements a security model that assumes devices may be compromised at any moment. While it is possible to mitigate package source confusion attacks, it is impossible to prevent them entirely. However, Google can create and enforce better security measures to prevent incidents like this.Google employees can download and run arbitrary code on their machines, which can be a security vulnerability, but Google accepts that risk. A misconfiguration can make package management problematic; however, whitelisting and sandboxing could help. Access to the monorepo is the primary risk, which would require additional authentication due to the zero trust model. An APT could use this vulnerability to get a foothold in the environment. This kind of breach affects many programming language package managers, so mitigation of the resulting damage is better than trying to prevent it. Google should have been prepared for this vulnerability, as it made global news two years ago.An HN user discusses the legality of opening a window on someone's computer to show that they are hacked; some jurisdictions may find it illegal. Other users debate the potential harm of this action and the security measures in place at Google. Users discuss how dependency confusion can be exploited, and the potential impact of a leaked list of not-found packages registered with PyPI. The need for better package management solutions and the role of zero-trust in preventing such attacks are also highlighted.An HN user discusses the vetting process for binary package inclusion in repositories like Debian, which differs from language repositories like pip where anyone can register. Some users question whether the demonstrated behavior in the Google vulnerability demo should be considered social engineering. Google's public IPv4 addresses for their dev machines raise questions about IP shortages. However, Google's large stockpile of IPs makes them less susceptible to this issue. The vulnerability exploits the Python package management tool's ease of accidentally pulling packages from pypi.org rather than a private repository.",
        "hn_summary": "A Remote Code Execution (RCE) vulnerability found in Google's software is reportedly not being fixed, with some users pointing out that Java's package management system has a more secure way of uploading packages than Rust's system, while others suggest that `pip install --extra-index-url` ignores user-specific registries, rendering private registries useless. Google has zero-trust security measures to combat insider threats, but an APT could use this vulnerability to gain a foothold in the environment. The need for better package management solutions and the role of zero-trust in preventing such attacks are also highlighted."
    },
    {
        "id": 35579876,
        "timestamp": 1681560679,
        "title": "Hypervisor Development in Rust",
        "url": "https://memn0ps.github.io/hypervisor-development-in-rust-part-1/",
        "hn_url": "http://news.ycombinator.com/item?id=35579876",
        "content": "The article describes the development of a Rust-based research hypervisor for Intel VT-x virtualization, leveraging existing blogs and code. It explains the key concepts of virtual machine architecture, VMX operation, virtual-machine control structure, and VMX activation. The author presents Rust code for checking the processor type and VMX support, and enabling virtual machine extensions (VMX) operation. The article aims to be a helpful resource for experts in the field who want to learn more about virtualization using Rust.This post discusses the implementation of Virtual Machine Extension (VMX) operation in Rust. The article focuses on setting specific bits in control registers for VMX operation, allocating the VMXON region, and enabling VMX operation. The article also mentions the use of a custom allocator for Rust's heap-allocated data types. The main contributor to the code being discussed is @not-matthias.The article explains the process of initializing a memory region to enable VMX operation for a virtual CPU in a hypervisor, with specific focus on logical/virtual CPUs. It also discusses the use of Rust programming language and provides a code example for virtualizing all available processors. The article provides a Hypervisor struct and a HypervisorBuilder struct, with the former having methods for virtualizing and devirtualizing processors using the Vcpu struct and the ProcessorExecutor struct. The code examples rely on Windows kernel functions and provide functionality for managing processor affinity. The article maintains a neutral tone and avoids religious or political statements.The article discusses the virtualization of processors using the hypervisor module, including the virtualize() function, driver_entry, and driver_unload functions. The article ends with the author's congratulations for completing the first part of the Intel VT-x Hypervisor Development in Rust series, and a list of references and credits. The text includes log messages and commands for testing the code, but does not provide much new or exciting information.",
        "summary": "This article describes the development of a Rust-based research hypervisor for Intel VT-x virtualization, providing Rust code examples for VMX operation and discussing the process of initializing memory regions for virtual CPUs. It aims to be a useful resource for experts in the field of virtualization using Rust. The article maintains neutrality and provides references and credits.",
        "hn_title": "Hypervisor Development in Rust",
        "original_title": "Hypervisor Development in Rust",
        "score": 205,
        "hn_content": "Hacker News new | past | comments | ask | show | jobs | submit loginHypervisor Development in Rust (memn0ps.github.io)205 points by ingve 17 hours ago | hide | past | favorite | 10 commentsdavemp 14 hours ago | next [\u2013]This is a pretty good article about CPU virtualization, which is a key starting point (as this seems to be the starting point of a series).What I'm interested in at the moment is device virtualization, which seems like a pretty hairy problem in the current KVM paradigm. IOMMU is a big step but it seems there's just a lot of grunt work left for getting the host/guest drivers working well.It almost feels like exokernel [0] path would have been preferable over having to write windows/linux/mac host drivers for virtualizing buses/devices. We already have a very awkward overlap with UEFI drivers. Maybe we just need new HW bus designs that are more of a switch than mux, I haven't gone deep enough into modern bus controller designs to know though.The reality of doing this kind of research/work is a special hell though, because you sit in a crossfire between hardware/firmware/os/application vendors.[0]: https://wiki.osdev.org/Exokernelreplybpye 12 hours ago | parent | next [\u2013]There are features that improve device virtualisation. Things like SR-IOV allowing for multiple virtual functions on a single device, and ATS which (among other things) means that device memory doesn\u2019t need to be pinned. The issue is that these features are at best supported on expensive data centre devices.replyLatticeAnimal 15 hours ago | prev | next [\u2013]This article seems to be targeting Windows. Does anyone know how different the process is on Linux? (Or if there are Linux-specific resources like this)replyrektide 14 hours ago | parent | next [\u2013]https://github.com/tandasat/Hypervisor-101-in-Rust is there to helphttps://github.com/cloud-hypervisor/cloud-hypervisor isn't educational necessarily but is one of the most technically progressive fastest developing highest funded vm projects ever, and there are oodles of tech talks on it. I am not qualified to make any specific recommendations, but there's tons of stuff here.replythe_duke 12 hours ago | root | parent | next [\u2013]> and there are oodles of tech talks on itCan you recommend a few good ones?Searching Youtube for cloud-hypervisor doesn't yield anything solid.replyanaisbetts 8 hours ago | parent | prev | next [\u2013]All of the NT functions used here have 1:1 Linux kernel equivalents, they are all very fundamental kernel operations that every kernel will havereplytraceroute66 15 hours ago | parent | prev | next [\u2013]AWS Firecracker[1] ?[1]https://firecracker-microvm.github.io/replyLatticeAnimal 15 hours ago | root | parent | next [\u2013]I mean in-depth guides like the one that was linked, not technologies, but thank youreplyghostpepper 14 hours ago | root | parent | next [\u2013]Not Linux but this is for UEFI https://tandasat.github.io/Hypervisor-101-in-Rust/replycarom 8 hours ago | prev [\u2013]Highly recommend the Gamozolabs streams for this type of work too. [1]1. https://m.youtube.com/@gamozolabs/playlistsreplyApplications are open for YC Summer 2023Guidelines | FAQ | Lists | API | Security | Legal | Apply to YC | ContactSearch:",
        "hn_summary": "A Hacker News user comments on the article about CPU virtualization and expresses interest in device virtualization, highlighting the challenges faced and proposing new solutions. Other users provide resources and alternatives for Linux users interested in this field."
    }
]