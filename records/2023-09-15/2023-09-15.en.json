[
  {
    "id": 37509507,
    "title": "The Tyranny of the Marginal User",
    "originLink": "https://nothinghuman.substack.com/p/the-tyranny-of-the-marginal-user",
    "originBody": "Nothing Human Subscribe Sign in Discover more from Nothing Human yet another attempt to weave together the threads of the human experience Subscribe Continue reading Sign in The Tyranny of the Marginal User why consumer software gets worse, not better, over time IVAN VENDROV SEP 14, 2023 71 21 Share A friend and I were recently lamenting the strange death of OKCupid. Seven years ago when I first tried online dating, the way it worked is that you wrote a long essay about yourself and what you were looking for. You answered hundreds of questions about your personality, your dreams, your desires for your partner, your hard nos. Then you saw who in your area was most compatible, with a “match score” between 0 and 100%. The match scores were eerily good. Pretty much every time I read the profile of someone with a 95% match score or higher, I fell a little bit in love. Every date I went on was fun; the chemistry wasn’t always there but I felt like we could at least be great friends. I’m now quite skeptical of quantification of romance and the idea that similarity makes for good relationships. I was somewhat skeptical then, too. What I did not expect, what would have absolutely boggled young naive techno-optimist Ivan, was that 2016-era OKCupid was the best that online dating would ever get. That the tools that people use to find the most important relationship in their lives would get worse, and worse, and worse. OKCupid, like the other acquisitions of Match.com, is now just another Tinder clone - see face, swipe left, see face, swipe right. A digital nightclub. And I just don’t expect to meet my wife in a nightclub. This isn’t just dating apps. Nearly all popular consumer software has been trending towards minimal user agency, infinitely scrolling feeds, and garbage content. Even that crown jewel of the Internet, Google Search itself, has decayed to the point of being unusable for complicated queries. Reddit and Craigslist remain incredibly useful and valuable precisely because their software remains frozen in time. Like old Victorian mansions in San Francisco they stand, shielded by a quirk of fate from the winds of capital, reminders of a more humane age. How is it possible that software gets worse, not better, over time, despite billions of dollars of R&D and rapid progress in tooling and AI? What evil force, more powerful than Innovation and Progress, is at work here? In my six years at Google, I got to observe this force up close, relentlessly killing features users loved and eroding the last vestiges of creativity and agency from our products. I know this force well, and I hate it, but I do not yet know how to fight it. I call this force the Tyranny of the Marginal User. Simply put, companies building apps have strong incentives to gain more users, even users that derive very little value from the app. Sometimes this is because you can monetize low value users by selling them ads. Often, it’s because your business relies on network effects and even low value users can help you build a moat. So the north star metric for designers and engineers is typically something like Daily Active Users, or DAUs for short: the number of users who log into your app in a 24 hour period. What’s wrong with such a metric? A product that many users want to use is a good product, right? Sort of. Since most software products charge a flat per-user fee (often zero, because ads), and economic incentives operate on the margin, a company with a billion-user product doesn’t actually care about its billion existing users. It cares about the marginal user - the billion-plus-first user - and it focuses all its energy on making sure that marginal user doesn’t stop using the app. Yes, if you neglect the existing users’ experience for long enough they will leave, but in practice apps are sticky and by the time your loyal users leave everyone on the team will have long been promoted. So in practice, the design of popular apps caters almost entirely to the marginal user. But who is this marginal user, anyway? Why does he have such bad taste in apps? A personality sketch of the marginal user Here’s what I’ve been able to piece together about the marginal user. Let’s call him Marl. The first thing you need to know about Marl is that he has the attention span of a goldfish on acid. Once Marl opens your app, you have about 1.3 seconds to catch his attention with a shiny image or triggering headline, otherwise he’ll swipe back to TikTok and never open your app again. Marl’s tolerance for user interface complexity is zero. As far as you can tell he only has one working thumb, and the only thing that thumb can do is flick upwards in a repetitive, zombielike scrolling motion. As a product designer concerned about the wellbeing of your users, you might wonder - does Marl really want to be hate-reading Trump articles for 6 hours every night? Is Marl okay? You might think to add a setting where Marl can enter his preferences about the content he sees: less politics, more sports, simple stuff like that. But Marl will never click through any of your hamburger menus, never change any setting to a non-default. You might think Marl just doesn’t know about the settings. You might think to make things more convenient for Marl, perhaps add a little “see less like this” button below a piece of content. Oh boy, are you ever wrong. This absolutely infuriates Marl. On the margin, the handful of pixels occupied by your well-intentioned little button replaced pixels that contained a triggering headline or a cute image of a puppy. Insufficiently stimulated, Marl throws a fit and swipes over to TikTok, never to return to your app. Your feature decreases DAUs in the A/B test. In the launch committee meeting, you mumble something about “user agency” as your VP looks at you with pity and scorn. Your button doesn’t get deployed. You don’t get your promotion. Your wife leaves you. Probably for Marl. all hail King Marl! Of course, “Marl” isn’t always a person. Marl can also be a state of mind. We’ve all been Marl at one time or another - half consciously scrolling in bed, in line at the airport with the announcements blaring, reflexively opening our phones to distract ourselves from a painful memory. We don’t usually think about Marl, or identify with him. But the structure of the digital economy means most of our digital lives are designed to take advantage of this state. A substantial fraction of the world’s most brilliant, competent, and empathetic people, armed with near-unlimited capital and increasingly god-like computers, spend their lives serving Marl. By contrast, consumer software tools that enhance human agency, that serve us when we are most creative and intentional, are often built by hobbyists and used by a handful of nerds. If such a tool ever gets too successful one of the Marl-serving companies, flush with cash from advertising or growth-hungry venture capital, will acquire it and kill it. So it goes. Thanks to Ernie French (fuseki.net) for many related conversations and comments on this essay. Subscribe to Nothing Human By Ivan Vendrov · Launched 3 months ago yet another attempt to weave together the threads of the human experience Subscribe 71 Likes · 5 Restacks 71 21 Share 21 Comments pleb.hodl 16 hrs ago Liked by Ivan Vendrov 1. Hobbyist builder doesn't have to sell out. 2. Hobbyist builder that do sell out (at a good price) can use the capital to build even more hobbyist tools, instead of becoming a VC or retire on an island somewhere. Hobbyist builder that fails both 1 & 2 is just another kind of Marl. LIKE (3) REPLY SHARE Nicolas Grilly Writes Nicolas Grilly 16 hrs ago Liked by Ivan Vendrov I think Apple did a pretty good job of developing and evolving their software while serving pretty much everyone, including the \"marginal user\". Maybe the article is more about social software than software in general? LIKE (2) REPLY SHARE 6 replies by Ivan Vendrov and others 19 more comments... Top New Community Against Positive-Sum Thinking why conflict is necessary JUN 26 • IVAN VENDROV 2 4 Ready for more? Subscribe © 2023 Ivan Vendrov Privacy ∙ Terms ∙ Collection notice Start Writing Get the app Substack is the home for great writing",
    "commentLink": "https://news.ycombinator.com/item?id=37509507",
    "commentBody": "The Tyranny of the Marginal UserHacker NewspastloginThe Tyranny of the Marginal User (nothinghuman.substack.com) 1150 points by ivee 19 hours ago| hidepastfavorite628 comments smukherjee19 1 minute agoI personally have a different name for the Marl-type of people: NPCs. Every time I get on the train I see them on their phones, mindlessly scrolling through TikTok and having the eyes of a dead fish. It&#x27;s almost as if their brains are turned off.It&#x27;s really sad that all software has become like the article states... reply wbobeirne 12 hours agoprevI worked at OkCupid from 2013-2017 and totally resonate with the author that mid-2010s OkCupid was a really special product, and that it took a steep decline as the decade went on. It&#x27;s not entirely fair to say that the Match acquisition immediately caused that decline; I started a couple years after Match got the company in its hands, and only two of the original founders were still focused on OkCupid full time. But the product continued to improve and grow for years after that. There was very little top-down directives about how to develop the product during that time.OkCupid had excellent growth in the first half of the 2010s, but as that growth started to plateau, it was pretty clear that the focus moved to following Tinder&#x27;s trends in an effort to match their level of growth. But OkCupid was a really healthy company with great profits and low burn, being only a team of 30-40 people. It could have stayed the way it was and continued to turn a profit. But Tinder had shown that the market size for mobile was way bigger than the desktop-focused product that OkCupid used to be. The focus towards acquiring more mobile users meant stripping down and simplifying a product that previously demanded hundreds of words of essay writing, and answering hundreds of questions. The essay prompts became simpler, multiple choice asymmetric questions got deprioritized over reciprocal yes &#x2F; no questions. And as a user, I felt the quality of conversations I had went down as most messages were sent on the go from people just trying to line up their weekend plans, instead of a deeply invested audience trying to form meaningful connections first.I really miss working on the product OkCupid was when I started, and often day-dream about starting another dating app closer to its original long-form vision. But the worst part of trying to do that is bootstrapping users, and seems like the only ways to do that are either have a lot of capital, or shadier methods like fake profiles or scraping data off of other sites. Not really interested in raising or setting my morals aside to do it. reply lr4444lr 12 hours agoparentI met my wife on OkCupid.The original format attracted a much smarter and more worldly crowd of women, to put it bluntly, than the other services. I exited the dating game before Tinder, but if OkCupid lost that quirky, artsy, college educated crowd in the chase to compete, that&#x27;s a real shame. reply sneak 10 hours agorootparentA big thing to consider is the fact that everyone got online all the time during the enshittification phase of OKC - it wasn&#x27;t just OKC&#x27;s userbase, but it was the median of the whole internet that got dumber and less sophisticated&#x2F;more basic.When OKC was great, the random median many-hours-on-the-internet-every-day user was a lot better than it is today. Now that&#x27;s just a median member of the general public, thanks to the ubiquity of social media. reply johntiger1 7 hours agorootparentThe internet really took a turn for the worse once they let people like me on to it.&#x2F;s reply User23 4 hours agorootparentprevWhen I first got online the average user’s IQ was no joke north of 120. Now of course it’s around 100.Someone needs to come up with a pithy term for how a subpopulation’s average value for any attribute approaches the population’s average value for same as the subpopulation’s size approaches that of the population. It’s conceptually a simple, even trivial, notion, but it’s cumbersome to talk about.That’s also why undergraduate degrees are no longer a particularly good signal. And I expect if it were easier to talk about many more cases would become apparent. reply lovich 3 hours agorootparentIsn’t that just Eternal September? At least in the internet reply opsimist 3 hours agorootparentCan we reverse Eternal Eptember? Can we create IQnet just for nerds? reply gwd 1 hour agorootparentSure, just make something that has a barrier to entry that will filter out non-nerds. From what I can tell Ham radio is basically just a chatroom with an entrance exam, for instance. Anything done in a constructed language like Esperanto would be another filter.There&#x27;s nothing stopping anyone from making a website duplicating the original OKCupid method. It&#x27;s just that it requires someone willing to say \"no\" to the Marginal User and stay niche.And from what I can tell, Mastodon is duplicating the original, pre-value-extraction Twitter experience. But the main filter it has at the moment is the network effects from Twitter and Facebook; as it grows that filter effect will be reduced. reply danielheath 1 hour agorootparentprevI think it’s called Gemini reply Jensson 3 hours agorootparentprevSmartphones was the final nail, after that close to 100% of young adults are active online participants.The good thing is that things aren&#x27;t getting worse at least, all the idiots are already online. reply sneak 3 hours agorootparentOnly about half the humans are on the internet. reply ebcode 1 hour agorootparentThen there&#x27;s still hope! reply Retric 4 hours agorootparentprevUndergraduate degrees are becoming a stronger signal just not in the same way.It’s even more obvious with high school degrees. Most people cross that threshold, so the people who didn’t now represent a usual group of under achievers. The threshold is far below what FAANG’s are looking for, but requiring a HS&#x2F;collage degree can effectively presort applicants for jobs with lower thresholds.Unfortunately, such methods consistently exclude many worthwhile applicants from a wide range of jobs the same way asking for a criminal background check. But that then sets up a stronger feedback loop as people have stronger incentives to cross that threshold. reply fingerlocks 2 hours agorootparentParadoxically, if you have an undergraduate degree but don’t have a high school degree, it can be even stronger signal than having both. “I actually dropped out of high school and went straight to college.”, sounds impressive.Of course you have to omit the part about taking a gap year and being a community college transfer student. reply jeffreygoesto 3 hours agorootparentprevJust imagine how high it must have been when there were only hundreds of users? =;-}Bitnet Relay in 1992 had some, not even all universities connected and I know of marriages that originated in the IRL(!) relay parties. We actually drove across Europe to meet our online friends. reply theresistor 4 hours agorootparentprevRegression to the mean reply switchbak 12 hours agorootparentprevAs did I! OkCupid was a shining star of a product that treated its users with respect and provided a really valuable service.I didn&#x27;t realize that it&#x27;s no longer. I feel old pining for the internet of yesteryear. As is obvious only in retrospect, you don&#x27;t realize when the golden years are! reply raisedbyninjas 11 hours agorootparentAnybody else remember the data blog posts? Those were interesting and satisfying. It was another confirmation that I&#x27;d found the right dating site and probably a like-minded userbase. reply lr4444lr 10 hours agorootparentI fondly remember the one that showed men&#x27;s rating of women approaching almost a perfect normal distribution, and then the men messaging mostly the hot ones anyway, whereas the women rated most men as ugly and then sloping downward toward very few as good looking, kind of like an exponential distribution, but that they also messaged the men almost exactly in tandem - uglier getting the most, with a steady drop as men&#x27;s ranking rose. reply throwaway2037 8 hours agorootparentThis is basically the foundation of modern, online dating -- aka red pill. Roughly, the top 20% of men get 80% of the attention from women. (I&#x27;m pretty sure that figure comes from Tinder data.) It makes sense from an evolutionary perspective, but is brutal in the real world. What do you do if you are average (or less) in looks and income (potential)? Prepare for a lonely existance. reply tspike 5 hours agorootparentIsn’t the parent comment saying the opposite of this? That despite rating most men as ugly, it didn’t affect their messaging behavior nearly as much? reply friendzis 4 hours agorootparentNo, they are saying a bit tangential things.Tinder&#x27;s data shows \"chance of approach\", which is brutal for men who are not too good looking.IIRC, OkCupid&#x27;s data shows a bit different thing. The distribution of ratings determines chance of messages&#x2F;likes - the larger stddev the better chances. IIRC, the most messaged men were ones with ratings characterized by bimodal distribution. Therefore, the most messaged men were not the ones with highest visual rating. I do not recall the distribution of messages, so can&#x27;t comment much on that. reply FearNotDaniel 4 hours agorootparentprevThere&#x27;s a lot about redpill culture that is inexcusably execrable, but it does offer a true and practical answer to the question you have posed: do everything in your power to make yourself more attractive. Work out, get a good haircut, improve your wardrobe, develop your career, improve your social&#x2F;conversation skills, have interesting hobbies. Become the best version of yourself and you will get more attention from others. reply slashdev 6 hours agorootparentprevYou’re being downvoted, but that’s pretty well supported with data. In fact it’s more skewed than 20&#x2F;80. Closer to 10&#x2F;90. reply deanCommie 4 hours agorootparentThey&#x27;re being downvoted because the very comment they&#x27;re replying to contradicts it: \"but that they also messaged the men almost exactly in tandem - uglier getting the most, with a steady drop as men&#x27;s ranking rose.OKCupid&#x27;s own data showed that women rate men is ugly but message them anyway. reply Roark66 4 hours agorootparentprev>What do you do if you are average (or less) in looks and income (potential)? Prepare for a lonely existance.You try to improve these things. Going to the gym etc, or focusing on one&#x27;s career is a start. reply flangola7 4 hours agorootparentprevThat data had poor epistemology, and was only really true if you&#x27;re only looking at cishet monogamous men and cishet monogamous women. reply dspillett 11 hours agorootparentprevParticularly the one that was a tare-down of why paid dating sites like match.com where a mug&#x27;s game for almost everyone. That somehow went AWOL fairly soon after the match.com take-over… reply lolinder 10 hours agorootparentThis one, Why You Should Never Pay For Online Dating:http:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20100725135309&#x2F;http:&#x2F;&#x2F;blog.okcupi... reply Noumenon72 6 hours agorootparentprevInformation has gotten harder and harder to come by as the Internet has matured. Think how much Tinder, Twitter, and Hinge know about human flirting and attraction. I believe it&#x27;s just too black pilled to see the light of day. reply astrange 10 hours agorootparentprevThe main effect of those data posts seems to have been to cause people to spread a lot of misinfo like \"women aren&#x27;t attracted to 80% of men\".(What they actually said was that women rate men much lower than men rate women, but the women still respond the same way despite rating them lower, so it doesn&#x27;t mean anything.) reply geraldwhen 11 hours agorootparentprevI also met my wife on okcupid. I wonder how many of us their are. reply dghughes 10 hours agorootparentI&#x27;d be curious if you&#x27;re all over 6&#x27; tall. I never had any luck on OKCupid. reply astrange 10 hours agorootparentThat height fetish stuff is the domain of 5&#x27;0\" white women. Basically message taller women and it doesn&#x27;t matter. reply seoulmetro 9 hours agorootparentNope. It&#x27;s not specific to their height and obviously not specific to their race.The same way men on average prefer big boobs, women on average will prefer taller men. Both can&#x27;t really be changed by the person but exist as attractiveness scores against a person.It matters to people who it matters to. Not many in the grand scheme and definitely not related to race. reply astrange 9 hours agorootparent> It&#x27;s not specific to their heightOf course it is because it&#x27;s relative to how tall they are. But taller women already don&#x27;t expect you to tower over them, because that&#x27;s hard to find, so it&#x27;s ok if you don&#x27;t.> and obviously not specific to their race.It is within a specific ethnicity and generation. If you&#x27;re in a country where the men in a specific age are short because food was scarce 2-3 decades ago, they&#x27;re not all single because their women aren&#x27;t attracted to them.And depending on culture and economic class, it matters more what impresses their parents, which is being a doctor-lawyer-astronaut who owns a house. reply geraldwhen 9 hours agorootparentprevYup reply semiquaver 9 hours agorootparentprevMe too! reply bbu 6 hours agorootparentprevme too :) reply crazygringo 10 hours agorootparentprevYup. It basically started as a dating site by Brooklyn grad students, for Brooklyn grad students.Grad students love writing essays. But if you want to expand, you have to face the fact that most people aren&#x27;t grad students and don&#x27;t love writing (or reading) essays.The trajectory to \"just another dating app\" was inevitable. reply garciasn 9 hours agorootparentThe great thing was that women saw men (and vv) who aren’t only a handful of Gram-worthy photos and a couple of stolen clever pickup lines.It allowed folks a direct avenue to those they found attractive and could use skills other than paying, stellar photography, and quotes from highly upvoted r&#x2F;Tinder comments as a way to convince others to go on dates.People have been either really successful with the way dating apps operate now (they’re incredibly attractive males or just about all females) or they’re incredibly frustrated because the algorithms have taken so much control away.It’s a sad reality. RIP OKC. reply DarknessFalls 5 hours agorootparentprevI think there was a happy medium somewhere along the way. The minimum word counts on the bios were just high enough to filter people that had no sincerity for the approach. You had to pantomime something of yourself to have a presence. What exists now is just a gallery of faces that could be the result of stable diffusion algorithms. reply carabiner 8 hours agorootparentprevWell they started off in Boston and were MIT&#x2F;Harvard grad students. And the backend was a DARPA project. So not really Brooklyn at heart, though some millennial New Yorkers pretended it was. They even had a personality trait for how much a user reminded them of Harvard girls. Like many \"only in New York!\" things it was really something that had mass appeal and gave a sense of quirkiness that was actually widespread in our generation.\"New Yorkers will say &#x27;only in New York!&#x27; and it&#x27;s the most normal shit ever.\" reply a-dub 5 hours agorootparent> And the backend was a DARPA project.the similarity&#x2F;CF stuff? what was the DARPA project? other than that it seemed a rather ordinary consumer webapp? reply tanepiper 3 hours agorootparentprevSame here (second wife) and the thing is once OKCupid did it&#x27;s job you didn&#x27;t need it anymore - and that was a good thing.The problem is that when you choose eternally needing customers you have to switch to the types of people who will never have a long term relationship - which Tinder style apps work better for.But those kind of people also drive away the ones looking for a long-term partner.Really sounds like poisoning the well. reply bboygravity 4 hours agorootparentprevThe best dates I ever had came from a language exchange site that doesn&#x27;t exist anymore.Seems to resonate with the \"filter for brainy people\" filter OKC seems to once have had. reply Roark66 4 hours agorootparentprevThese were different times... I met my partner of 25+ years on my town&#x27;s IRC channel. Imagine that happening now. reply kromem 10 hours agoparentprevI feel a twinge of guilt whenever I see things about how OKC got crappy.Not that long before the acquisition a certain jackass brought in as a consultant (ahem) happened to point to OkC as the leading competitor against the acquiring company&#x27;s properties specifically for mobile.Sorry everyone...If it makes it any better, I&#x27;ve had to use the product since then too, and suffered alongside all the rest of you. reply snerbles 9 hours agorootparentHey, at least you can say you had a direct role in how couples meet and their resulting progeny.Our personal misery and loneliness aside, the long-term societal effects as generations wear on will be fascinating. reply uoaei 4 hours agorootparentprevI appreciate your candor. Though I am upset, I realize this is the kind of thing that would be hard to see coming. reply sambazi 3 hours agorootparenthuh?the top point is that more users usually lead to a worse product, no? reply sirspacey 11 hours agoparentprevA somewhat natural conclusion is that mobile killed the thoughtful internet. Ouch. reply Karrot_Kream 11 hours agorootparentMobile onboarded a different demographic of user. Pre-mobile, not many people really used computers or the internet outside of work or gaming. I grew up in a poor part of the US and lots of people did not have desktop computers at home; most kids begged their parents for access to computers for gaming. Parents in our area could never figure me out. I liked using computers (I would dumpster dive for parts since as a poor kid, I had much more time than money) but I didn&#x27;t game much, and I&#x27;m a kid so I&#x27;m definitely not doing work. (I learned to code as a kid because I wanted to make games and then I found the coding part much more fun than the gaming part.) My parents were flummoxed how a kid who liked spending so much time reading was also so weird about wanting to use something as expensive as a computer.That&#x27;s the root of this blog post, the rise of Tinder, and the big shift to mobile in general. Nerds aren&#x27;t the only people on the internet anymore. The average person is now on the internet. OKCupid was very much the dating site of us thoughtful nerds, those who thought text and personality tests would help them find a better match. Most singles in the West at the time just went to the bar, got intoxicated, then made base conversation with whomever engaged their base interests. That demographic moved to Tinder.Unless you&#x27;re specifically targeting a nerd-heavy demographic (e.g. academics, devs, hackers, etc) with a high margin product, if the goal is to create a mass appeal product then making nerds happy just isn&#x27;t profitable. We&#x27;re too small in number and too picky. reply fiddlerwoaroof 11 hours agorootparentprevI find I comment and write much less on mobile than on a computer, because the writing experience on mobile is still very sub-par. reply wvenable 10 hours agorootparentThis is very true. And now think of all the people who&#x27;s only Internet experience is on mobile. They exist entirely within that sub-par writing universe. reply bigstrat2003 3 hours agorootparentI actually feel really bad for the younger generation, actually. There&#x27;s a whole bunch of teenagers who have no idea how good and useful computers can actually be, because all they ever have known is the shitty watered down mobile version of computing. Even desktops aren&#x27;t as good as they used to be (thanks, Electron), but they&#x27;re still a damn sight better than mobile. But if one grew up thinking that a phone&#x2F;tablet is the end-all of computing, they have no idea what they&#x27;re even missing. reply vore 2 hours agorootparentThis is a ridiculous out of touch take. Of course young people know what desktop computing is like: they use it at school for class and use it at home for gaming. Have you considered that people might prefer mobile is preferable because it’s, well, mobile and you don’t have to lug a big ol’ machine around? reply bigstrat2003 2 hours agorootparentI&#x27;m skeptical of your claim that young people are actually using desktops in those situations. As far as I&#x27;ve seen, young people are primarily gaming on consoles and are using stripped down devices like Chromebooks at school. It&#x27;s also been noted that computer skills have gotten markedly worse among young people in recent years, which suggests they are not in fact being exposed to desktops regularly.And I definitely think you&#x27;re off base about mobile devices being popular because they&#x27;re mobile. People will sit at home and use a phone that is an incredibly worse experience than using an actual computer, and think it&#x27;s an adequate substitute. They don&#x27;t need the mobility in that situation, but they really think there&#x27;s nothing wrong with the user experience. replyoxfordmale 10 hours agoparentprevAlmost all internet algorithms seem to converge around maximising time spend on the app in question. A dating website simply doesn&#x27;t want to be too effective, as you would lose two customers every successful match. Similar to the approach used in slot machines, you want to give the illusion of winning, but I&#x27;m reality only provide moderately succesful matches rather than perfect ones.Of course there is a human element too. Dating sites give the illusion of choice, and a result a lot of potential matches aren&#x27;t realised on, as the partner is good looking enough. reply wbobeirne 5 hours agorootparentI always push back on this argument, because it came up a lot. As someone higher up at the company once put it, if people are sufficiently convinced that you can find them what they&#x27;re looking for in a dating app, there&#x27;s almost no amount of money they wouldn&#x27;t spend. People churn after not getting what they want out of an app. And relationships end, and people will return to apps they felt they had success with. Word of mouth successes were the ultimate marketing tool, OkCupid didn&#x27;t have really any ad spend for the first year or two I was there (and apparently the hadn&#x27;t in the years past.) reply oasisaimlessly 3 hours agorootparent> people will return to apps they felt they had success withSo then the trick is to provide the illusion of successful relationships (but of course not ones that actually pan out in the long term). reply oxfordmale 1 hour agorootparentLong lasting relationships are based on common values. However, you can have succesful medium term relationships based on common interests and good looks.OkCupid, in its heydays, indeed managed to match people on common values by asking detailed questions. A lot of modern dating apps are far more focus on looks and common interests.Yes they look cute, and love rock climbing too, but hate children, and never want any. It will result in a good match in your mid twenties, but likely going to result in irreconcilable differences when you approach 30. Unless of course you both hate children :-) reply wvenable 10 hours agoparentprevI don&#x27;t understand why so many companies are against simply developing a new product with a new brand instead of lobotomizing their own product.It seems to have over and over where a product and brand that makes decent profit is utterly destroyed in an attempt to acquire a new market. reply bc11hn 8 hours agorootparentBecause creating a new product is harder and more expensive than changing an existing one, even if it does destroy it.Advertising, novel technical infrastructure, new branding, etc... all of this needs to be done for a new brand -- and then who knows if any one will come visit?Or, you can just make whatever short-term changes to your existing successful product, juice the metric you&#x27;re looking to juice, and (in theory) cashout before the long term repercussions take affect. reply wvenable 7 hours agorootparentNew branding isn&#x27;t necessarily bad; it can make a new product seem fresh. Technical infrastructure, both hardware and software, can be reused. You don&#x27;t have destroy one software product to make another.Take this OkCupid example; they had their website model. They could have just created \"OkCupid Nights\" as a separate Tinder-like product reusing as much of their tech as possible. reply OkayPhysicist 12 hours agoparentprevThe upside of dating app bootstrapping is that it&#x27;s an inherently local phenomenon. People want to meet people near them, which means you can gain traction one locale at a time. Maybe some kind of promotion where you cut deals with some local bars or restaurants to get some kind of discount &#x2F; freebie if you match with someone (with the implication being that they&#x27;ll use it for the date). Still takes capital, just not \"nation-wide aggressive advertising push\" levels of capital. reply JCharante 4 hours agorootparentNationwide is much easier in countries with a large primacy index, for example Thailand where Bangkok has 9x the population of Thailand’s second largest city, and Moscow where it has 4x the population of St Petersburg.Everybody is nearby when you have subway trains connecting half the people in your country together in under an hour. reply scoofy 11 hours agoparentprevOkCupid had the best damn blog on the internet. They were obviously extremely thoughtful folks. I was genuinely sad when it was discontinued. reply bunabhucan 8 hours agorootparentFounder wrote a book. Blog is still at archive.org reply Angostura 10 hours agoparentprevYou raise a really interesting point that I hadn&#x27;t really thought about before - the possibility that the move to mobile first is directly responsible for making things worse, dumber, simpler with less functionality. reply throwaway2037 8 hours agoparentprevThis post reads like Eternal September[1], and I write that without any cynicism or snark. It makes good sense that text-heavy web apps would fall prey to image-heavy mobile apps. I still think there is potential for dating apps that target higher intellect users. Most of the dominant apps today are mobile-first, largely visual, and disappointing for both sides. One idea: Could speech-to-text technology help to allow users to create OkCupid-style essays from a mobile phone? Maybe. Although, a few discussions here on HN said that speech-to-text is still a super hard problem in 2023.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Eternal_September reply pif 1 hour agorootparent> I still think there is potential for dating apps that target higher intellect users.Apps are not developed for the sake of the users. Apps are developed in order to make a profit.If your higher intellect users are not ready to pay good money for your product, it can only be one of two things: either they are cheap, or your product is not that great. Considering that there is no correlation between intellect and cheapness, I would exclude the first hypothesis.Then you end up with a crappy product (and it was your higher intellect users who voted it crappy) and a bunch of advertisers ready to pay you bread crumbs for your users&#x27; attention, and you suddenly realise that you need a lot of crumbles to get a sandwich. reply lelanthran 4 hours agorootparentprevI think that there is a reason that dating apps, dating sites and dating services all converge on a model which downranks intellect: the few humans who care about that characteristic are not enough to build a sustainable business.Literally everyone says that they are different and want a smart partner, but when they actually hook up they aren&#x27;t ranking high intellect.I liked okcupids blogs. The maintakeaway I had from reading all of them was:1. How much appearance played a role in being attractive.2. 90+% of women attempted to hook up with the same 10% of men, while men were much more open to women not in the top 10%.3. What people claimed they wanted in a partner had almost no relation to what they actually wanted, when looking at who they messaged, who they viewed, and who they responded to.All apps now are very aggressively tracking everything, so they have a much better idea of what makes people open their wallets, and intellect apparently isn&#x27;t one of those things. reply uoaei 4 hours agorootparenthttp:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20100725135317&#x2F;http:&#x2F;&#x2F;blog.okcupi...I don&#x27;t think you&#x27;re characterizing the results accurately, particularly point #2. I don&#x27;t think they really had a way to measure #3. #1 is just obviously true but doesn&#x27;t add much. reply lelanthran 3 hours agorootparent> I don&#x27;t think you&#x27;re characterizing the results accurately, particularly point #2. I don&#x27;t think they really had a way to measure #3. #1 is just obviously true but doesn&#x27;t add much.Maybe not, but #2 was from a blog that specifically looked at the data of messaging: how many men received messages, how many women received messages.IIRC, nearly all the women received messages and sent messages, while only about 10% of the men received messages while all of the men sent messages. I don&#x27;t really see any other way to interpret data showing that both men and women sent messages at about the same rate, but only about 10% of men received any messages.Now I don&#x27;t have the blog handy (and I rather wished I did), but my takeaway #3 was from reading all the blogs available, in basically one marathon sitting, not from one particular blog. reply strken 32 minutes agorootparentIt strikes me that if women and men sent messages in exactly the same long-tail shape of distribution, and you had a knob that controlled how frequently each sent messages, you&#x27;d be able to turn each knob until 100% of women and 10% of men received messages.This is not to say you&#x27;re wrong or right, but I don&#x27;t think the numbers tell us much without seeing the full distribution. replyBrajeshwar 6 hours agoparentprevThe best thing about OKCupid was the data-backed articles. It was our source of inspiration and data point to continue on a dating website we built. We started as a side project in 2006 but got shelved after my company was acquired. I returned to it in 2010-2011, and OKCupid was our constant fodder for data and inspiration. reply carabiner 11 hours agoparentprevI would pay $100&#x2F;month for a site like the original okcupid, but I want Max Krohn, Christian Rudder and the rest of the original team running it. reply genewitch 11 hours agorootparentyou&#x27;re in luck! OKCupid costs ~$44 a month, and you can add on \"read receipts\" for about $0.50 each, superboosts for $1-$3 each, the privacy (hidden) profile for $10&#x2F;month. with some creativity you can have 0 real matches for ~$100! reply webninja 5 hours agorootparentThe matches are real. It’s just that you have to get on an airplane and fly to a new country to meet them. I’ve met my matches in person. One of the girls paid for almost everything too. reply genewitch 1 hour agorootparentis that where you disappeared to for 3 years? reply pif 1 hour agorootparentprev> I would pay $100&#x2F;month for a site like the original okcupid, but ...That you would not pay $100&#x2F;month for a site like the original OkCupid. reply Iulioh 12 hours agoparentprevThanks for sharingAnother thing destroyed by the infinite growth model reply pif 1 hour agorootparentYou mean: another thing destroyed that a few people used to enjoy when the developers had no chance to have it economically better! reply Iulioh 1 hour agorootparentMan, you can have a profitable thing and just..have that?Like if you have the same let&#x27;s say 20% profit in the world of business is not enough, you want the RATE of your return to go higher even if the product allowed you to stay stupidity rich.Economically better is a good pair of words that leads to enshittification via greed reply pif 1 hour agorootparentEnshittification is only a problem from the point of view of the non-paying user. But the on-paying user has no say in what happens to the app.As they say, if you are not paying for the product, you are the product.Enjoying the generosity of other people is fine, but it gives you no right to expect it to last indefinitely. reply Iulioh 9 minutes agorootparentThat&#x27;s not even remotely the point.Have you read the post or seen how the things go?The paying user get fucked too, just give it time. reply pif 1 hour agorootparentprev> enshittification via greedYou are right. The greed of affectionate users who refuse to pay has destroyed many a service! reply talldatethrow 11 hours agoparentprevI remember being on SparkMatch when I was a 14-15 year old. A dating site meant for teens, from the makers of Spark Notes.I always had this weird vague hunch that spark match become OKCupid. Any info on this? reply martey 11 hours agorootparentfrom https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;OkCupid> SparkMatch debuted as a beta experiment of allowing registered users who had taken the Match Test to search for and contact each other based on their Match Test types. The popularity of SparkMatch took off and it was launched as its own site, later renamed OkCupid. reply qingcharles 7 hours agorootparentprevThe biggest online dating site in the 90s had a minimum age of 13 o_O. I thought that was weird, even back then.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Matchmaker.com reply talldatethrow 7 hours agorootparentI remember I was 14-15 on SparkMatch because I had to convince my mom to drive me 30 miles to a mall so I could meet a girl from SparkMatch. To this day I was the most out of my league girl I ever &#x27;dated&#x27; (only kissed a few times). I soon acted too sweet and too lame and lost her. But it taught me a lot to always be cooler and I cleaned up in the coming OkCupid&#x2F;PlentyofFish revolution, and doubly so by the time Tinder came around. I still think about that girl sometimes, which makes sense, because she was somewhat unique to be online constantly back in 1999-2000. reply doctorpangloss 10 hours agoparentprev> OkCupid had excellent growth in the first half of the 2010s, but as that growth started to plateau, it was pretty clear that the focus moved to following Tinder&#x27;s trends in an effort to match their level of growth.Okay... what was the ratio of active men to women on OkCupid each year? How about on Tinder? You worked there, and that&#x27;s an unfair assessment of Tinder.The fundamental trend in these dating apps is that ratio, and the relative growth (or decline!) of that gender&#x27;s active user base. And it&#x27;s not something Match, or for that matter Dataclysm ever discussed, even though it&#x27;s kind of the most important single metric for a dating app.I mean ask demographers, they talk about 3m:2f being a crisis ratio [1]. And on Tinder it&#x27;s probably closer to 10:1-20:1, I&#x27;m sure they pay AppAnnie (or whatever they&#x27;re called now) to push out some fake ass numbers here and there. If it wasn&#x27;t a horrible number - anything worse than 3m:2f is pretty horrible! - they would write about it, and they simply won&#x27;t.On the one hand I really liked Dataclysm, and I was bought into the ideas it put forward. There&#x27;s this post from 2018 by the author that used to say, oh well the reply rate to black women was 20 percentage points lower, which is the same in 2008. Well, trends showed about 18 percentage points more interracial marriages, the data was totally counter to trend: that indicated a problem in OkCupid, not in the user base as the author claimed. The Tinder PR team kind of put the kibosh on that kind of transparency for the wrong reasons, but it was the right idea.So this big essay prompt format that the app used to use, I don&#x27;t know if it was part of the problem where OkCupid was fundamentally against trend. In some respects, clearly, the essays versus swiping didn&#x27;t matter. It certainly seems intuitive that the essays matter, it appeals to a sense of superiority in a particular audience&#x27;s way of believing how online dating should work, but those guys are operating in the vacuum of the single most important data point (the actual ratio) and are forced to essentially generate fictions for why the apps work the way they do and why it worked for them.I appreciate that from your point of view, 2013-2017 was a focus on \"mobile\" and that in your opinion that was \"bad.\" But c&#x27;mon, show me a category of free app that didn&#x27;t have a focus on \"mobile.\" I personally think the apps are doing the best given the circumstances - the ratio! - and that everything else is dancing around this because, if people knew, you know, they&#x27;d stop using them.[1] https:&#x2F;&#x2F;www.google.com&#x2F;books&#x2F;edition&#x2F;Date_onomics&#x2F;7GDVBgAAQB... (page 22) reply munificent 17 hours agoprev> We’ve all been Marl at one time or anotherThis, to me, is the key line in this quite good article.It&#x27;s not that software companies are catering to those other people who are infinitely stupid and deserving of our scorn. It&#x27;s that they are catering to the worse impulses in all of us and encouraging us to become those people. reply spott 11 hours agoparentThis is a key point.If you look at people, each of them have multiple different “personas” throughout the day&#x2F;week&#x2F;etc.[0]Some of them, sometimes, are builders or content creators.Some of them, sometimes, are conscientious consumers, looking to stretch their understanding or themselves and think hard about something that they are consuming.But all of them, sometimes, are Marl.There will always be a way to find more Marls to add to your user pool because Marl is the basest human need for a steady effortless dopamine drip. Just about everyone has some amount of time that they spend as Marl, so there is an almost limitless pool of Marl time to pull new users from.I’m trying to find some way to say that this isn’t what you actually want, but I’m struggling. If you are making a product for everyone, Marl is the only persona that is in everyone, so you should probably target Marl.However, if you are trying to build a product for a more constrained persona, you should probably be careful of using metrics that measure Marls. Because there are so many of them (even your users with other personas are sometimes Marls!) if you aren’t really careful, you will enshitify your product as you continue your A&#x2F;B testing gradient descent into a user base of Marls, without anyone you were trying to get — even if you don’t loose your content creators and conscientious consumers, you have converted them into Marls, and lost what you were trying to achieve.Enshitification is the conversion of your target user from any other kind of persona, to Marls.[0] there are other personas, these were that the ones that immediately came to mind. reply somedude895 15 hours agoparentprevIt&#x27;s a very good point that I think some commenters here should take to heart. No matter how enlightened we think we are, we&#x27;re all part of the masses and behave this way at one point or another. reply telios 15 hours agorootparentThe reason it works is because they&#x27;ve done the research to make it work. It isn&#x27;t a coincidence DAUs increase. I think it is important to recognize that it can impact you, and take steps to account for that, even if - or especially if - you don&#x27;t want it to. You are not immune to propaganda, and all that. reply raxxorraxor 3 hours agorootparentIn German the DAU is the \"dumbest assumed user\", the worst case consideration when designing UI. My impression is that if you try to increase DAUs, you often increase both types. reply beefield 3 hours agorootparentprevThis is something important that people do not seem to grasp. Intelligence is a really high dimensional thing. Even the ones that are highly intelligent in some dimensions are dumb as rock in vast majority of other dimensions. So we all are basically morons with some occasional flashes of intelligence in some individuals. reply npsimons 13 hours agorootparentprev> No matter how enlightened we think we are, we&#x27;re all part of the masses and behave this way at one point or another.While this is true, it stands to question: why build systems to encourage this? Shouldn&#x27;t we be trying to do better?If nothing else, how can one avoid falling into these traps? reply RugnirViking 7 minutes agorootparent> While this is true, it stands to question: why build systems to encourage this? Shouldn&#x27;t we be trying to do better?until incentives change, people will continue to encourage this. The base instinct behaviors when one is stressed and tired and checked out are the most profitable, the most susceptible to adverts etc.The way to encourage conciencousness, taking pride in creation etc is to see a few (the right amount of) others (who are seen by the user as peers, not unnatainable far off creators) doing the same. Maybe stretched&#x2F;challenged a little - one or two at most people above their skill level, who appear approachable and humble.It&#x27;s the format of most true knowledge creation, be it classrooms, effective workplaces, sports programs, and others reply spott 11 hours agorootparentprevBecause there is an endless amount of human time spent like this, but we all have limited attention for other things.If you try to appeal to someone’s better parts, then there is a limit to the amount of attention that they can apply to your product.If you try to appeal to someone’s base need for dopamine, then the limit of attention is much higher. reply intended 13 hours agorootparentprevSpitballing -Perhaps due long tail effects.Tech (platforms) will always be advertising focused, because information systems scale with compute. marginal costs are so minor, that the limit becomes human attention.Which is also why apple may be able to focus on user centric design better. They are product + tech.Then again I can see other physical product firms delving into advertising - so its most likely corporate behavior&#x2F;values. reply tqi 12 hours agorootparentprevI think the problem is there isn&#x27;t a clear delineation between \"traps\" and \"meaningful improvement.\"Take Signal for example - early days they had a ton of success with a core group of users, in spite of a number of product warts. Ever since then, they&#x27;ve been making usability improvements to lower friction and appeal to more and more marginal users. Is that good or bad? Based on the hn threads I&#x27;ve seen, it seems like the jury is pretty mixed? reply rglullis 8 hours agorootparentprevWe have them, they exist for millennia. It&#x27;s just that most of them are considered too boring or are judged as a whole by looking at some of its members of questionable character - who ironically are there because they know they are not perfect but trying to be better. reply beefman 11 hours agoparentprevThere are stupid people. A large percentage of the population never regularly used PCs because keyboards and mice are too abstract. They only began regularly computing once they could touch things with their fingers. Today, Google search has more fuzzing and returns more Q&A results on mobile.A large percentage never used e-mail because e-mail addresses are too abstract. They only began using \"social media\" when they could address correspondence by photograph.There are a billion people who can speak but not read and write, and billions who can read and write but not well enough to earn karma on Hacker News.Though smart people are sometimes Marl, they are Marl less often, or in more sophisticated ways (like wasting time on Hacker News). reply andrewmg 12 hours agoparentprevAs Pogo put it, \"We have met the enemy, and he is us.\"[0][0]https:&#x2F;&#x2F;library.osu.edu&#x2F;site&#x2F;40stories&#x2F;2020&#x2F;01&#x2F;05&#x2F;we-have-me... reply waffletower 11 hours agorootparentTo Pogo: &#x27;What do you mean \"us\"? Do you have a mouse in your pocket?&#x27; reply uoaei 4 hours agorootparentIs it really so hard to consider? Do you believe that intentions and outcomes are always aligned? reply bcrosby95 9 hours agoparentprevIt&#x27;s a pretty interesting statement. I used to be fine with \"microboredoms\" and think about other things, such as a book I&#x27;m reading, a game I want to play, or even work.I noticed these days that I spend more time during those \"microboredoms\" on my phone. I have 10 seconds? Check out reddit!I&#x27;ve been trying to kick this habit, enjoy my surroundings more, or get lost in my head like I used to. reply MatthiasPortzel 7 hours agorootparentCarrying around a fidget toy has helped me with this. Part of the urge to scroll on my phone is just to do something with my fingers. If my fingers are occupied with a bit of string or a finger-trap, my mind is more free to wander. reply npsimons 13 hours agoparentprev> It&#x27;s that they are catering to the worse impulses in all of us and encouraging us to become those people.That is incredibly unsettling, and not just because it makes me uncomfortable. Dumbing down should never be a deliberate goal, especially of people. reply lifty 12 hours agorootparentIt’s not deliberate. It’s the tragedy of the commons. They are tapping into a shared resource (our well being) and everyone else is doing it. reply ChrisMarshallNY 10 hours agorootparentIf you listen to Frances Haugen&#x27;s testimony, you see that it is very much deliberate.There are probably thousands of psychology grads that went to school, hoping to help people, that are, instead, designing dark patterns.But they are probably making a lot more money than they would, helping people.Evil pays cash. reply Finnucane 12 hours agorootparentprevThere&#x27;s no commons on a commercial website. This is deliberate. reply sirspacey 9 hours agoparentprevYes and no98% of Spotify users never take any action other than “press play” on a radio station2% take some kind of agency (create a playlist, like a song)A vanishingly small amount create personal or public curated playlistsYes, that very small amount may also listen passively sometimes, but the difference matters. Imagine if Spotify was just a radio station. reply rconti 9 hours agorootparentIs this true, or just an invented number based on your intuition? reply webninja 5 hours agorootparentprevI hate that new Spotify radios play nearly the same songs from your existing playlists and listening history. Little variety and mostly an echo chamber. reply kmac_ 4 hours agorootparentIt works for me: Discover weekly + song radio + similar artists + genre and user playlists. I can listen to new songs until I&#x27;m tired. I love Spotify. reply srik 15 hours agoparentprevThat is the insight I’m surprised the author didn’t zero in on. reply doctorpangloss 10 hours agoparentprev> to the worse impulsesIn my experience, making stuff that provides no intrinsic value like video games, only value of meaning, my games have only gotten better by catering to those impulses, which are really not that negative or stupid.Really, who needs tutorials? Why make stuff that needs a tutorial? You can have complex games without tutorials and FTUEs. You don&#x27;t need so much UI. It&#x27;s not about scrolling so much as it is that so many apps obscure, rather than transmit, anything meaningful, through really obnoxious UI.This argument is the Malcolm Gladwell 140 character tweet complaint not being enough to have a deep conversation. Easy for him to say, he&#x27;s got his! reply rglullis 9 hours agoparentprevNow, let&#x27;s find any single company&#x2F;product that actually is successful by encouraging us to become better versions of ourselves. reply robotresearcher 4 hours agorootparentIn apps: Ten Percent Happier and Headspace?In meatspace: Nike, Adidas? reply rglullis 3 hours agorootparentSport gear companies? Just selling you a lifestyle and an identity. Meditation apps feel more like someone exploiting a fad than some with an actual interest in your wellbeing. reply whack 10 hours agoprevThis is a hilarious read but I think the author is too optimistic about the state of humanity. Marl isn&#x27;t the \"marginal\" user, Marl is the \"average\" user. If the average user actually cared about deep and meaningful content, then any A&#x2F;B test that throws her under the bus in order to please Marl will show bad data, and the proposed change would be killed.Yes, the author tries to hand-wave this away as \"product is sticky\", but I really doubt this is the main reason.No, the truth is far more scary. The average user doesn&#x27;t want deep and meaningful content. The average user is Marl. That is why every product, no matter how noble it starts off, eventually degenerate into Marl-fodder. Because that&#x27;s where the money is. The only way to escape this is to take on a huge pay cut and work at a company that doesn&#x27;t care about growing profits. Go ahead, you first.Finally, let&#x27;s be honest. Marl isn&#x27;t some obnoxious bozo. You and I are both Marl. That&#x27;s why we&#x27;re here in the HN comments. You are Marl, I am Marl, the world is Marl, and it&#x27;s getting Marlier every day. reply callalex 9 hours agoparentA&#x2F;B tests, as they are run by current software companies, are inherently flawed. I have never, in my entire career, ever heard of an A&#x2F;B test that ran for a year, let alone 3-5 years. That’s where the true power of statistics comes alive, and nobody is financially incentivized to even consider that fact. reply makeitdouble 5 hours agorootparentI&#x27;ve seen one A&#x2F;B test in the wild run for a full year.It was on a small part (test of a product name + description across the site), and the most interesting aspect was that it only made a small but measureable difference. Because of that there was no strong incentive to delete the AB test (not much harm to the user) nor make the B side permanent (too low of an effect).In that respect, AB Tests that end early aren&#x27;t a bad thing IMO: either there&#x27;s a clear improvement or it&#x27;s really bad, and the choice is obvious enough to not have to wait much longer. reply mlyle 4 hours agorootparentWhat I think the grandparent is getting at:You can measure the direct effect of a change now on something like conversions. But you can&#x27;t measure the second order effects: things like trust from your users, or the effects on community quality and composition, etc.This is a good part of why enshittification happens: lots of changes with immediate \"good\" impact that can be measured quantifiably, but there&#x27;s also readily foreseeable negative consequences to them.Of course, just running the test longer doesn&#x27;t really address this for most possible changes. reply disgruntledphd2 1 hour agorootparentGenerally you&#x27;ll have a quarterly holdout to measure total impacts but I agree that yearly would be better. reply eternal_braid 3 hours agorootparentprevHave you heard of long running holdbacks? Even if not, rest assured that for major features, they are very commonly run. reply bonniemuffin 7 hours agorootparentprevYou&#x27;re certainly correct that software companies should do a lot more year+ A&#x2F;B tests. You can learn really interesting things from it that a shorter test won&#x27;t capture. I know of this one: https:&#x2F;&#x2F;medium.com&#x2F;@AnalyticsAtMeta&#x2F;notifications-why-less-i... reply eru 7 hours agorootparentprevGwern runs tests that long. reply timdumol 9 hours agoparentprev\"Marginal\" in the blogpost is used in the economic sense, as in the next incremental user -- not \"marginal\" as in minority. reply thaumasiotes 8 hours agorootparentThat is the way whack is using it. whack is correct that if there is a negative effect on the average user, a test will show that negative effect. That&#x27;s what \"average\" means.To perceive an effect in new users without getting the same effect in existing users, you&#x27;d need to show different content to those two groups. reply lyjackal 7 hours agorootparentHmm, I think the authors point is more towards attention addiction, rather than specific average types of people. It’s more a matter of setting a low bar to encourage more people to be distracted by your app when they really shouldn’t be using it. Basically increasing the number of apps that people check in on, especially when those users are in their marginal time (before bed, while cooking, etc.). reply grishka 7 hours agoparentprev> The only way to escape this is to take on a huge pay cut and work at a company that doesn&#x27;t care about growing profits. Go ahead, you first.Gladly! Where do I sign up? reply zachthewf 6 hours agorootparentthere are lots of swe jobs with the government. reply grishka 6 hours agorootparentI would rather not involve myself with the government of my country. reply ivee 7 hours agoparentprevI completely disagree. If you walked up to Marl, built trust with him, and asked him whether he wanted more meaningful content in his life (for a definition of meaningful which made sense to him) I think he would say yes. So it&#x27;s not really about Marl&#x27;s preferences but about the way those preferences are collected and Marl&#x27;s (sadly mostly justified) lack of trust. reply wk_end 6 hours agorootparentIf you walked up to me, built trust with me, and asked me if I wanted more exercise in my life I’d say yes. And yet. reply mbwgh 2 hours agoparentprevI think you may both be right. Assume you start off with a small niche product and keep increasing your userbase.Then the characteristics of the users at the fringes will change the more you grow. That is to say, the former Marls in the middle are different (and likely not so shallow) from the next-generation Marls on the outside. Eventually, your notion of what is the average user, and OP&#x27;s notion of what is the Marl that finally kills the UX, will align. reply cwkoss 3 hours agoparentprevThe penultimate paragraph of the article says almost exactly this reply hackerlight 2 hours agoparentprevYou&#x27;re using a different definition of the world \"marginal\". Marginal in context doesn&#x27;t mean rare or unusual. It just means the next user. reply carlosjobim 7 hours agoparentprev> That is why every product, no matter how noble it starts off, eventually degenerate into Marl-fodder.The big reason for that is that people do not want to pay for quality content or services. Ask any HN commenter if you doubt me. So companies instead focus on growth to get the ad cents from the millions of impressions, or trick \"whales\" by manipulating their addiction in the same manner as casinos.As long as people call anybody a fool for paying for online services, don&#x27;t expect things to improve. reply bdcs 16 hours agoprevThe tyranny of the marginal user reminds me of population ethics&#x27; The Repugnant Conclusion.[0] This is the conclusion of utilitarianism, where if you have N people each with 10 happiness, well then, it would be better to have 10N people with 1.1 happiness, or 100N people with 0.111 happiness, until you have infinite people with barely any happiness. Substitute profit for happiness, and you get the tyranny of the marginal user.Perhaps the resolutions to the Repugnant Conclusion (Section 2, \"Eight Ways of Dealing with the Repugnant Conclusion\") can also be applied to the tyranny of the marginal user. Though to be honest, I find none of the resolutions wholly compelling.[0] https:&#x2F;&#x2F;plato.stanford.edu&#x2F;ARCHIVES&#x2F;WIN2009&#x2F;entries&#x2F;repugnan... reply feoren 15 hours agoparentThat conclusion is not repugnant at all, it&#x27;s just that its phrasing is so simplistic as to be nearly a straw-man. It&#x27;s a poisoned intuition pump, because it makes you imagine a situation that doesn&#x27;t follow at all from utilitarianism.First of all, you&#x27;re imagining dividing happiness among more people, but imagining them all with the same amount of suffering. You&#x27;re picturing a drudging life where people work all day and have barely any source of happiness. But if you can magically divide up some total amount of happiness, why not the same with suffering? This is the entire source of the word \"repugnant\", because it sounds like you get infinite suffering with finite happiness. That does not follow from anything utilitarianism stipulates; you&#x27;ve simply created an awful world and falsely called it utilitarianism. Try to imagine all these people living a nearly completely neutral life, erring a bit on the happier side, and it suddenly doesn&#x27;t sound so bad.Secondly, you&#x27;re ignoring the fact that people can create happiness for others. What fixed finite \"happiness\" resource are we divvying up here? Surely a world with 10 billion people has more great works of art for all to enjoy than a world with 10 people, not to mention far less loneliness. It&#x27;s crazy to think the total amount of happiness to distribute is independent of the world population.There are many more reasonable objections to even the existence of that so-called \"conclusion\" without even starting on the many ways of dealing with it. reply galaxyLogic 12 hours agorootparentYour post reminds me of xenophobes who lament the arrival of immigrants. The immigrants are taking their jobs they are saying. Such a viewpoint can be countered with the imaginary scenario where you live in a country with only 2 people. How well are they doing? There are no stores to buy goodies from because who would create such a store for just 2 people? Perhaps an immigrant, could open a deli!When there are more immigrants who are allowed to work, the immigrants will make some money for themselves. What do they do with that money? They spend it, which grows the economy. Our economy, not some other country&#x27;s economy.If you were the only living person on this planet you would be in trouble. Thank God for other people being there too. reply bluefirebrand 11 hours agorootparent> What do they do with that money? They spend it, which grows the economy. Our economy, not some other country&#x27;s economy.I&#x27;m going to guess you&#x27;ve never spoken to anyone who is sending money back to their family in their original country with every paycheck.Not really the point of this conversation I guess but... yeah. It does happen more than you probably think. To the point where malls in my area have kiosks for wiring money to other countries for cheap. reply Sai_ 11 hours agorootparentWouldn’t they be sending left-over money ie, money after spending locally, back to their home country?I can’t imagine a lot of people out there who send all their money back home without spending some of it locally for self sustenance. reply eru 7 hours agorootparentprev> I&#x27;m going to guess you&#x27;ve never spoken to anyone who is sending money back to their family in their original country with every paycheck.If that sent money ever comes back to the domestic economy, then you are back to the previous situation.If it doesn&#x27;t come back, that&#x27;s even better: because then your central bank can print more money to make up for the disappearance. Essentially, you got the foreigner to perform services in return for some ink and paper. reply soorya3 3 hours agorootparentprevThat&#x27;s not true, most of the money is spent here and very little to take care of the family that&#x27;s been left back home. Otherwise how can they survive here, think about immigrant kids education, housing, healthcare, retirement. reply anon84873628 10 hours agorootparentprevIt seems you completely misunderstood the parent comment. They are arguing against the existence of the repugnant conclusion, by pointing out that happiness -- like the economy -- is not actually a finite pie to divvy up. reply ThinkBeat 11 hours agorootparentprevYour scenario leaves a lot to be desired.Yeah two people only.Well Your scenario can easily be countered with the imaginary scenario that you have a town with 1 billion residents, far too little housing, no green space left due to trying to provide housing and the city only has natural resources for perhaps 300.000.000.Now 100.000.000 immigrants arrive. There is not enough food, water, hygiene. Hopefully, opening delis will solve the issue.Yes, it is absurd. But no more so than a world of 2.History though does prove your theory right. When proud and brave Europeans immigrated to what would become the United States.\"When they arrive there are no stores to buy goodies from because who would create such a store for just 2 people? Perhaps an immigrant, could open a deli!\"\"Thankfully for the native people&#x27;s immigrants came in to create a consumer capitalist culture.Can you imagine the utter horror if they native peoples were allowed to keep their versions of society going and develop it the way they wanted. They sure were blessed by the immigrants. A lot the natives&#x27; peoples also became xenophobes and we sure now what bastards&#x27; xenophobes are. reply astrange 10 hours agorootparentThis is silly because you don&#x27;t have to imagine any scenarios. Good economic models are based on empirical data, not on imagining things, and \"immigrants don&#x27;t increase unemployment or decrease wages\" is just about the strongest empirical result there is.The reason being that someone moving closer to you increases demand for labor more than supply, and immigrants generally have complimentary (slightly different) skills to natives. So the person whose labor the immigrant most competes with is another immigrant.https:&#x2F;&#x2F;www.noahpinion.blog&#x2F;p&#x2F;why-immigration-doesnt-reduce-...As for remittances&#x2F;brain drain, there are certainly theoretical issues but it seems to be okay in the end because it boosts investment in the originating country.https:&#x2F;&#x2F;www.noahpinion.blog&#x2F;p&#x2F;why-skilled-immigration-usuall... reply skybrian 14 hours agorootparentprevYes, more generally, I’m reminded of David Chapman’s essay, “No Cosmic Meaning” [1]. Thought experiments are a good way to depress yourself if you take them seriously.But I think that utilitarianism has a vague but somewhat related problem in treating “utility” as a one-dimensional quantity that you can add up? There are times when adding things together and doing comparisons makes a kind of sense, but it’s an abstraction. Nothing says you ought to quantify and add things up in a particular way, and utilitarianism doesn’t provide a way of resolving disputes about quantifying and adding. Not that it really tries, because it’s furthermore a metaphor about doing math, which isn’t the same thing as doing math.[1] https:&#x2F;&#x2F;meaningness.com&#x2F;no-cosmic-meaning reply greiskul 14 hours agorootparentThe big problem with utilitarinism, is that people think that a preference function for the utilitariam that is creating a given world is something simple. Then some people are like, no, it&#x27;s more complex, we need to take into account X, Y and Z. But the truth is, no human being is capable of defining a good utility function, even for ourselves. We don&#x27;t know all the parameters, and we don&#x27;t know how to combine those parameters to add them up. So I would say that formal, proper utilitarinism, is not a metaphor for math: it is math. But is right now in the area of non constructive math.Maybe our descedants will elevate it outside of that with computers someday. Cause the human brain with just pieces of papers and text, probably cannot do it. reply Gibbon1 13 hours agorootparentAlso utilitarinism was created by people who were utterly unaware that the world is fundamentally chaotic. Instead they thought it could be represented by a system of linear equations.It&#x27;s fundamentally broken in practice. reply pdonis 14 hours agorootparentprev> utilitarianism has a vague but somewhat related problem in treating “utility” as a one-dimensional quantity that you can add up?Yes, it does. This is one of the most common (and in my view, most compelling) criticisms of utilitarianism. reply at_a_remove 12 hours agorootparentOne of the very muddled thoughts I have in my head, along with Goodhart&#x27;s Law and AIs which blissfully attempt to convert the universe into paperclips, is that having a single function maximized as a goal seems to give rise to these bizarre scenarios if you begin to scan for their existence.I have started to think that you need at least two functions, in tension, to help forestall this kind of runaway behavior. reply pdonis 11 hours agorootparentEven \"two functions, in tension\" still assumes that you can capture values as functions at all. But the reason ethics and morality are hard in the first place is that there are no such functions. We humans have multiple incommensurable, and sometimes incompatible, values that we can&#x27;t capture with numbers. That means it&#x27;s not even a matter of not being able to compute the \"right\" answer; it&#x27;s that the very concept of there being a single \"right\" answer doesn&#x27;t seem to work. reply at_a_remove 10 hours agorootparentI think that&#x27;s what it will approach in the limit, yes, if you are talking about humans. For AIs, I think it will be somewhat less so, and that it would be preferable for the sake of predictability. replypdonis 14 hours agorootparentprev> a situation that doesn&#x27;t follow at all from utilitarianismExcept that it does according to many utilitarians. That&#x27;s why it has been a topic of discussion for so long.> you&#x27;re imagining dividing happiness among more people, but imagining them all with the same amount of sufferingNo. \"Utility\" includes both positive (happiness) and negative (suffering) contributions. The \"utility\" numbers that are quoted in the argument are the net utility numbers after all happiness and all suffering have been included.> You&#x27;re picturing a drudging life where people work all day and have barely any source of happiness.Or a life with a lot of happiness but also a lot of suffering, so the net utility is close to zero, because the suffering almost cancels out the happiness. (This is one of the key areas where many if not most people&#x27;s moral intuitions. including mine, do not match up with utilitarianism: happiness and suffering aren&#x27;t mere numbers and you can&#x27;t just blithely have them cancel each other that way.)> if you can magically divide up some total amount of happiness, why not the same with suffering?Nothing in the argument contradicts this. The argument is not assuming a specific scenario; it is considering all possible scenarios and finding comparisons between them that follow from utilitiarianism, but do not match up with most people&#x27;s moral intuitions. It is no answer to the argument to point out that there are other comparisons that don&#x27;t suffer from this problem; utilitarianism claims to be a universal theory of morality and ethics, so if any possible scenario is a problem for it, then it has a problem.> you&#x27;re ignoring the fact that people can create happiness for othersBut \"can\" isn&#x27;t the same as \"will\". The repugnant conclusion takes into account the possibility that adding more people might not have this consequence. The whole point is that utilitarianism (or more precisely the Total Utility version of utilitarianism, which is the most common version) says that a world with more people is better even if the happiness per person goes down, possibly way down (depending on how many more people you add), which is not what most people&#x27;s moral intuitions say.> It&#x27;s crazy to think the total amount of happiness to distribute is independent of the world population.The argument never makes this assumption. You are attacking a straw man. Indeed, in the comparisons cited in the argument, the worlds with more people have more total happiness--just less happiness per person. reply Murfalo 12 hours agorootparentprevThank you for this! I have very similar thoughts. Felt like I was going crazy each time I saw these types of conversations sparked by mention of the \"repugnant\" conclusion... reply shadowgovt 14 hours agorootparentprevAll of this having been said, replacing happiness with revenue makes chasing marginal users make a lot of sense.If you have a sure-fire way to get half the people on the planet to give you $1, you can afford a yacht. Even if it means the tool you make for them only induces them to ever give you that $1 and not more... Why do you care? You have a yacht now. You can contemplate whether you should have made them something more useful from the relative safety and comfort of your yacht. reply julianeon 14 hours agorootparentprevHere&#x27;s a simpler way to phrase the problem.The current world population is about 8 billion.By this argument, and also by your argument, it should actually be 999 billion. Or a number even higher than that.The conclusion boils down to:1. Find maximum population number earth can support.2. Hit that number.I do think that, when put this way, it seems simplistic. reply curiousllama 14 hours agorootparentTo be fair, boiling something down to a simple statement does indeed tend to produce simplistic statements reply olddustytrail 14 hours agorootparentprevHere&#x27;s an even simpler way to phrase the problem.The current world population is about 8 billion.By my argument it should be 2 billion.Your argument is therefore rather foolish. reply tyre 15 hours agoparentprevThe Repugnant Conclusion is one of those silly problems in philosophy that don’t make much sense outside of academics.Utilitarianism ought to be about maximizing the happiness (total and distribution) of an existing population. Merging it with natalism isn’t realistic or meaningful, so we end up with these population morality debates. The happiness of a unconceived possible human is null (not the same as zero!)Compare to Rawls’s Original Position, which uses an unborn person to make the hypothetical work but is ultimately about optimizing for happiness in an existing population.We really shouldn’t get ourselves tied into knots about the possibility of pumping out trillions of humans because an algorithm says they’ll be marginally net content. That’s not the end goal of any reasonable, practical, or sane system of ethics. reply chongli 12 hours agorootparentRawls&#x27;s original position and the veil-of-ignorance he uses to support it has a major weakness: it&#x27;s a time-slice theory. Your whole argument rests on it. You&#x27;re talking about the \"existing population\" at some particular moment in time.Here I am replying to you 3 hours later. In the mean time, close to 20,000 people have died around the world [1]. Thousands more have been born. So if we&#x27;re to move outside the realm of academics, as you put it, we force ourselves to contend with the fact that there is no \"existing population\" to maximize happiness for. The population is perhaps better thought of as a river of people, always flowing out to sea.The Repugnant Conclusion is relevant, perhaps now more than at any time in the past, because we&#x27;ve begun to grasp -- scientifically, if not politically -- the finitude of earth&#x27;s resources. By continuing the way we are, toward ever-increasing consumption of resources and ever-growing inequality, we are racing towards humanitarian disasters the likes of which have never been seen before.[1] https:&#x2F;&#x2F;www.medindia.net&#x2F;patients&#x2F;calculators&#x2F;world-death-cl... reply astrange 10 hours agorootparent> By continuing the way we are, toward ever-increasing consumption of resources and ever-growing inequality, we are racing towards humanitarian disasters the likes of which have never been seen before.We aren&#x27;t doing that. Increasing human populations don&#x27;t increase resource consumption because 1. resources aren&#x27;t always consumed per-capita 2. we have the spare human capital to invent new cleaner technology.It&#x27;s backwards actually - decreasing populations, making for a deflating economy, encourage consumption rather than productivity investment. That&#x27;s how so many countries managed to deforest themselves when wood fires were still state of the art.Also, \"resources are finite\" isn&#x27;t an argument against growth because if you don&#x27;t grow &#x2F;the resources are still finite&#x2F;. So all you&#x27;re saying is we&#x27;re going to die someday. We know that. reply eru 7 hours agorootparentI mostly agree. However:> That&#x27;s how so many countries managed to deforest themselves when wood fires were still state of the art.It was mostly ship building that deforested eg the countries around the Mediterranean and Britain. Firewood was mostly harvested reasonably sustainably from managed areas like coppices in many places. See https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Coppicing reply eru 7 hours agorootparentprev> By continuing the way we are, toward ever-increasing consumption of resources and ever-growing inequality, we are racing towards humanitarian disasters the likes of which have never been seen before.What do you mean by ever growing inequality? Global inequality has decreased in recent decades. (Thanks largely to China and to a lesser extent India moving from abject poverty to middle income status.)By some measures we are also using less resources than we used to. Eg peak resource usage in the US, as measured in total _mass_ of stuff flowing through the economy, peaked sometime in the 1930s.Have a look at the amount of energy used per dollar of GDP produced, too. Eg at https:&#x2F;&#x2F;yearbook.enerdata.net&#x2F;total-energy&#x2F;world-energy-inte... reply dragonwriter 14 hours agorootparentprev> Utilitarianism ought to be about maximizing the happiness (total and distribution) of an existing population.That&#x27;s a somewhat-similar alternative to utilitarianism. Which has its own kind of repugnant conclusions, in part as a result of the same flawed premises: that utililty experienced by different people is a quantity with common objective units that can meaningfully summed, and given that, morality is defined by maximizing that sum across some universe of analysis. It differs from by-the-book utilitarianism in changing the universe of analysis, which changes the precise problems the flawed premises produce, but doesn&#x27;t really solve anything fundamentally.> Compare to Rawls’s Original Position, which uses an unborn person to make the hypothetical work but is ultimately about optimizing for happiness in an existing population.No, its not; the Original Position neither deals with a fixed existing population nor is about optimizing for happiness in the summed-utility sense. Its more about optimizing the risk adjusted distribution of the opportunity for happiness. reply caturopath 15 hours agorootparentprevI think you might be missing a big part of what this sort of philosophy is really about.> Utilitarianism ought to be about maximizing the happiness (total and distribution) of an existing populationFor those who accept your claim above, lots of stuff follows, but your claim is a bold assertion that isn&#x27;t accepted by everyone involved, or even many people involved.The repugnant conclusion is a thought experiment where one starts with certain stripped-down claims not including yours here and follow it to its logical conclusion. This is worth doing because many people find it plausible that those axioms define a good ethical system, but the fact they require the repugnant conclusion causes people to say \"Something in here seems to be wrong or incomplete.\" People have proposed many alternate axioms, and your take is just one which isn&#x27;t popular.I suspect part of the reason yours isn&#x27;t popular is- People seek axiological answers from their ethical systems, so they wish to be able to answer \"Are these two unlike worlds better?\" -- even if they aren&#x27;t asking \"What action should I take?\" Many people want to know \"What is better?\" so they explore questions of what are better, period, and something they want is to always to have such questions be answerable. Some folks have explored a concept along the lines of yours, where sometimes there just isn&#x27;t a comparison available, but giving up on being able to compare every pair isn&#x27;t popular.- We actually make decisions or imagine the ability to make future real decisions that result in there being more or fewer persons. Is it right to have kids? Is it right to subsidize childbearing? Is it right to attempt to make a ton of virtual persons?> The happiness of a unconceived possible human is null (not the same as zero!)Okay, if you say \"Total utilitarianism (and all similar things) are wrong\", then of course you don&#x27;t reach the repugnant conclusion via Parfit&#x27;s argument. \"A, B, C implies D\", \"Well, not B\" is not a very interesting argument here.Your null posing also doesn&#x27;t really answer how we _should_ handle questions of what to do that result in persons being created or destroyed.> We really shouldn’t get ourselves tied into knots about the possibility of pumping out trillions of humans because an algorithm says they’ll be marginally net content. That’s not the end goal of any reasonable, practical, or sane system of ethics.Okay, what is the end goal? If you&#x27;ll enlighten us, then we can all know.Until then, folks are going to keep trying to figure it out. Parfit explored a system that many people might have thought sounded good on its premises, but proved it led to the repugnant conclusion. The normal reaction is, \"Okay, that wasn&#x27;t the right recipe. Let&#x27;s keep looking. I want to find a better recipe so I know what to do in hard, real cases.\" Since such folks rejected the ethical system because it led to the repugnant conclusion, they could be less confident in its prescriptions in more practical situations -- they know that the premises of the system don&#x27;t reflect what they want to adopt as their ethical system. reply salawat 15 hours agorootparentprev>We really shouldn’t get ourselves tied into knots about the possibility of pumping out trillions of humans because an algorithm says they’ll be marginally net content. That’s not the end goal of any reasonable, practical, or sane system of ethics.Are you sure you aren&#x27;t sharing the world with people who do not adhere to reasonable, practical, or sane system of ethics?Because, ngl, lately, I&#x27;m not so sure I can offer an affirmative on that one, making \"Getting tied into knots about the possibility of pumping out trillions of humans because an algorithm says they’ll be marginally net content\" a reasonable thing to be trying to cut a la the Gordian knot.After all, that very thing, \"pump out trillions of humans because some algorithm (genetics, instincts, & culture taken collectively) says they&#x27;ll be marginally more content\" is modus operandi for humanity, with shockingly little appreciation for the externalities therein involved. reply coldtea 14 hours agorootparentprev>The Repugnant Conclusion is one of those silly problems in philosophy that don’t make much sense outside of academics.Not even for academics. It&#x27;s something for \"rational\"-bros. reply caturopath 12 hours agorootparent(Real, academic philosophers actually care about the case, too.) reply coldtea 4 hours agorootparentOnly because the practice (in the US mostly) has been watered down a lot to include all kinds of rational-bros in the tradition of \"analytical philosophy\", usually also involved in the same circles and arguments with the wide rational-bro community.Then again the opposite side has also devolved into a parody of 20th century contintenal philosophical concerns with no saving grace. reply PaulDavisThe1st 15 hours agoparentprevMany versions of utilitarianism never specified the function to compute the sum for the many. Your example assumes that the function is simple addition, but others have been proposed that reflect some of the complexities of the human condition a little more explicitly (e.g. sad neighbors make neighbors sad). reply tasty_freeze 15 hours agorootparentReinforcing your point, Peter Singer, philosopher and noted utilitarian, has explicitly said that he weights misery far more than happiness in his own framework. From a personal level, he said he&#x27;d give up the 10 best days of his life to remove the one worst day of his life (or something like that).All of his work with effective altruism is aimed at reducing suffering of those worst off in the world and spends no time with how to make the well off even happier. reply frereubu 14 hours agorootparentI hadn’t heard that about Singer’s philosophy (unsurprisingly as I’ve read very little of his work). It’s interesting for me in that it lines up with Kahnemann & Tversky’s “losses loom larger than gains” heuristic in psychology. reply tasty_freeze 9 hours agorootparentSinger publishes his book, \"The Life You Can Save\" for free -- it was revised for the 10th anniversary. It is available in various formats, including an audio book. It is a short, easy read. It is also one of the most impactful books I&#x27;ve ever read.https:&#x2F;&#x2F;www.thelifeyoucansave.org&#x2F;Along the header there is an item \"free book\" if you want to get the book.In short, there are a few theses in the book that combine in a compelling way. This isn&#x27;t his summary, this is the summary I got out of reading it. (1) the suffering of someone you don&#x27;t know is just as real as the suffering of someone you do know. (2) there are many worthy causes, but we aren&#x27;t allocating enough resources to address them all, so it is best to allocate them such that they do the most good for the worst off (3) if you are reading hacker news, you are likely in the 1% (worldwide) and your primary needs are already being met and you can make meaningful contributions to help those most in need without affecting your lifestyle much.Each chapter tackles a topic. For instance, part of it brings up many the counter arguments about why someone might not want to donate and then debunks them. Eg, in a poll, most US citizens believe that 10-20% of their taxes are going to foreign, and say about half that, say 5%, would be reasonable. In fact it is well under 1%. Or people will say there have always been poor people and there will always be poor people (counter argument: to the people who are helped, aid makes a huge difference to them personally, and there have actually been great strides in the past 30 years at reducing global poverty).Another chapter talks about the typical feel good news item about someone in the community who has gone blind and so the community pitches in to pay for a seeing eye dog for the person (it costs up to $50K to train and vet such dogs). Yet that same $50K could have prevented river blindness for thousands of children, or been enough to perform cataract surgery on thousands of blind adults.People often say, why give to a charity in Africa? It will just end up in someone&#x27;s pocket before it helps anyway. The book talks about the effective altruism movement and describes how charities are vetted and monitored. The website above has links to many such vetted charities.Another chapter talks about where to draw the line? Sure, I can afford $700 to pay for corrective surgery for a woman suffering from fistula and feel good about myself. But in reality I could afford another $700, then another $700, etc. Do I need to keep donating to those worse off until I am one of the worse off people? (spoiler: no) reply pg_1234 13 hours agorootparentprevAs an aside, this is why buying insurance, despite being a financially bad bet (or the insurers would go out of business), actually is a sensible thing to do from a quality of life perspective. reply selectodude 12 hours agorootparentInsurance isn&#x27;t a financially bad bet. They&#x27;re providing a service (not needing to maintain the liquidity of replacement costs) in exchange for a fixed monthly fee. It&#x27;s cheaper for me to grow my own food but it&#x27;s not a \"bad bet\" to not be a subsistence farmer and buy my food at the grocery store even though many people are making money off my purchase up the chain. I get to use my money and time for something more productive. reply eru 7 hours agorootparentYou are right for catastrophic insurance, ie insurance that covers outlays that would financially ruin you, or at least be majorly inconvenient.Many people buy (or are forced to buy) insurance that covers minor outlays, too.Using that kind of insurance has pretty big (relative) overheads not just in terms of money but also in terms of annoying paperwork and bureaucracy.Some of the worst offenders are probably health insurance plans that include a fixed hundred bucks allowance towards new glasses every year. They might just as well charge you hundred bucks less in premiums and strike that allowance. (Unless in cases where that scheme is a tax dodge.) reply astrange 10 hours agorootparentprevInsurers are often mutually owned by their customers, so they don&#x27;t need to profit. reply eru 7 hours agorootparentThat doesn&#x27;t make much of a difference.Profit is only one part of the overhead. They also have to pay agents, adjusters, underwriters, managers, office stationary, postage, fraud investigators, lawyers, taxes, interest on bonds etc.Similar for hospitals etc. Profit, ie cost of equity capital, is usually (but not always) a relatively small part of an organisation&#x27;s overall cost structure. And the non-profit alternatives typically don&#x27;t have meaningfully lower costs. reply onlyrealcuzzo 15 hours agorootparentprevYeah, utilitarianism means you want to act in a way that&#x27;s beneficial to most people.There&#x27;s many ways you can interpret that, though.But I think if you say, before we had 1 apple per person, and now we have 2x as many apples, but they&#x27;re all owned by one person - that&#x27;s hard to argue it&#x27;s utilitarian.If before you had 100 apples, and everyone who wanted one had one, and now you have 10,000 apples distributed to people at random, but only 1 in 100 people who wants one has one - that also seems hard to argue as utilitarian.Businesses are value maximization functions. They&#x27;ll only be utilitarian if that happens to maximize value.In the case of software - if you go from 1m users to 10m users - that doesn&#x27;t imply utilitarianism. It implies that was good for gaming some metric - which more often than not these days is growth, not profit. reply tshaddox 15 hours agorootparentprevWhich conceivable method of summing is the least problematic? Depending on the summing method you might find yourself advocating creating as many people as possible with positive utility, or eliminate everyone with below-average utility, etc. reply Karrot_Kream 14 hours agorootparentUtility is very complicated and summing might not even be possible. Folks have argued for completely different utility systems, such as cardinal utility where utility is modeled purely as relations instead of something that is isomorphic to a real. Even going by the mainstream view of ordinal utility, utility tends to be a convex function (simplistically, having 1 food is much better than having no food, but having 1000 food isn&#x27;t that much better than having 500 food.) Modeling utility as something purely isomorphic to reals gives it all the fun paradoxes that we know the reals have and can be used to create some really wacky results. The \"repugnant conclusion\" is a direct consequence of that. reply fouronnes3 15 hours agorootparentprevAssuming linearity of utility either in individuals or in aggregation is a very common straw man of utilitarianism. reply polygamous_bat 6 hours agorootparentDoesn&#x27;t have to be linear, ANY strictly increasing function for aggregating the utility leads to the same conclusion. reply jancsika 15 hours agorootparentprev> (e.g. sad neighbors make neighbors sad)I much prefer, \"I&#x27;d rather have a bottle in front of me than a frontal lobotomy.\" At least in that case nobody will confuse a trucker hat slogan for a viable system of ethics. reply hammock 15 hours agoparentprevTyranny of the marginal user is a riff on the Nassim Taleb classic \"The Most Intolerant Wins: The Dictatorship of the Small Minority\":https:&#x2F;&#x2F;medium.com&#x2F;incerto&#x2F;the-most-intolerant-wins-the-dict... reply crabbone 14 hours agoparentprevOne way to deal with this problem is to ask why do we use the arithmetic sum to calculate the total happiness?. There are plenty of ways this can go. Say, if you believe that two very happy people are better than four half as happy people, then you can define this sum function as sum(happiness_per_person) &#x2F; number_of_people. Of course, this isn&#x27;t the only way.Utilitarianism opens a lot of questions about comparability of utility (or happiness) of different people as well as summation. Is it a totally ordered set? Is it a partially ordered set? Perhaps utility is incomparable (that&#x27;d be sad and kind of defeat the whole doctrine, but still).Also, can unhappiness be compensated by happiness? We unthinkingly rush to treat unhappiness as we would negative numbers and try to sum that with happiness, but what if it doesn&#x27;t work? What if the person who has no happiness or unhappiness isn&#x27;t in the same place as the person who is equally happy and unhappy (their dog died, but they found a million $ on the same day)?A more typical classroom question would be about chopping up a healthy person for organs to fix X unhealthy people -- is there a number of unhealthy people which would justify killing a healthy person for spare parts? reply wilg 15 hours agoparentprevI&#x27;ve never understood this problem. To me, it seems that since you&#x27;ve defined a minimum \"worth living\" amount of happiness and unbounded population, it makes complete sense that the answer would be that it is better to have lots of people whose life is worth living rather than fewer. Is it not tautological?Like it seems like you have to take \"worth living\" seriously, since that is the element that is doing all the work. If it&#x27;s worth living, you&#x27;ve factored in everything that matters already. reply mhb 15 hours agorootparentIf you pack the whole problem into a definition of \"worth living\", then you&#x27;re right. But the premise is that there is a range from extreme misery through neutral through extremely happy. The repugnant conclusion is that it is better to have many people in a state that is barely above neutral. reply wilg 15 hours agorootparentI&#x27;m not the one packing it, the setup of the problem does it. \"Barely above neutral\" means you&#x27;ve picked an acceptable state. And then we are supposed to consider that acceptable state \"repugnant\"? reply mhb 15 hours agorootparentThere&#x27;s a comparison. If the scale goes from -100 to +100, the conclusion is that if we have 8 billion people in the world with average happiness of +10, it is better to immiserate them in order to have 80 billion with average happiness +1.01.It&#x27;s not that the acceptable state of 1.01 is repugnant, it&#x27;s that the conclusion seems counterintuitive and ethically problematic to many people, as it suggests that we should prefer creating a massive population of people who are barely happy over a smaller population of people who are very happy. reply wilg 14 hours agorootparentI guess I just don&#x27;t understand how if your axioms are 1) X is an acceptable level of happiness and 2) more people are better than fewer it is in any way surprising or problematic to end up with infinite people at happiness X.Perhaps people don&#x27;t see that (2) is a part of the premise? reply zaphar 14 hours agorootparentIt&#x27;s more that after seeing that result of starting with those premises they don&#x27;t like the 2 premises anymore. It would be like me really liking the experience of eating potator chips all day right up until the point that I discovered it had a lot of adverse health effects. I might no long like eating them as much. reply mhb 14 hours agorootparentprevBecause 1 is not one of the axioms. The axioms are 1) There is a range of experience between worst possible misery and best possible happiness and 2) more people who are just barely happy is better than fewer people who are much happier.I don&#x27;t understand why you&#x27;re insisting on a binary distinction of acceptable vs. not acceptable. With that assumption there is no repugnant conclusion. reply wilg 11 hours agorootparent1 is one of the axioms because a binary cutoff is built into the premise. reply mhb 11 hours agorootparentI may have taken you a little too literally when you wrote that you didn&#x27;t understand the problem. Perhaps what you&#x27;re saying is that the conclusion is not repugnant to you and that the conclusion is neither counterintuitive nor ethically problematic.Consequently you believe that it is better for a large number of people to exist in a state barely better than misery than for a smaller number of people to experience a greater degree of happiness.Fair enough. reply wilg 10 hours agorootparentI suppose that is a fair characterization. I would say that I still think it&#x27;s tautological. Obviously it&#x27;s a synthetic situation that involves infinity, so real-world applications are difficult to evaluate.But I just don&#x27;t get why people see it as an ethical dilemma – the conclusion is a perfectly sensible outcome of the setup. The conclusion is just a restatement of the premise – a maximization of population over a maximization of happiness. Thats why it seems tautological to me, the math of it is perfunctory and reveals nothing. If you cared about maximizing happiness more than population you would have to modify the setup. The trade-off is built into the premise. replymvdtnz 15 hours agoparentprevWhy would anyone think that a large overall pool of happiness is somehow better than a high per capita happiness? This seems like the kind of thing that&#x27;s incredibly obvious to everyone but the academic philosopher. reply burnished 15 hours agorootparentThey do not, thats the point. If you start with a simple and reasonable sounding premise (&#x27;it is ethically correct to choose the option that maximizes happiness&#x27;) but it leads to obviously absurd or inhuman outcomes then you might not want to adopt those principles.Your second sentence rankles the hell out of me, you&#x27;re only able to make that snap judgement to this because of your exposure to academic philosophy (where do you think that example that demonstrates the problem so clearly comes from?), but are completely unaware of that.The bullshitters aren&#x27;t puzzling at seemingly simple things, they&#x27;re writing content free fluff. reply patmcc 15 hours agorootparentprevMaximizing for per-capita happiness just leads to the other end of the same problem - fewer and fewer people with the same \"happiness units\" spread among them. Thus we should strictly limit breeding and kill people at age X+5 (X always being my age, of course).It&#x27;s actually a hard problem to design a perfect moral system, that&#x27;s why people have been trying for literally thousands of years. reply wilg 15 hours agorootparentprevIt&#x27;s just a question of if you value other people existing or not. If you don&#x27;t, focus on per-capita happiness, if you do then you focus on meeting a minimum threshold of happiness for everyone.I don&#x27;t see how you couldn&#x27;t value other people existing – I think they have just as much of a right to experience the universe as I do. reply mvdtnz 14 hours agorootparentThere&#x27;s a vast chasm between \"other people deserve to exist\" and \"we should 100x our population in order to increase the marginal happiness pool\". reply wilg 14 hours agorootparentAlternately, there isn&#x27;t. reply mhb 12 hours agorootparentprevHas that belief led you to a lifestyle in which you are just barely happier than miserable so that you can lift as many others as you can out of misery? reply wilg 11 hours agorootparentNo, but doing so would be consistent with my beliefs and I think it would be considered admirable to most people. reply saint_fiasco 15 hours agorootparentprevIn this particular case, it&#x27;s because the success of an ad-funded service depends on the amount of users it has.If you don&#x27;t like the repugnant conclusion you have to change something in the conditions of the environment so that you make it not be true. Arguing against it and calling your refutation obvious doesn&#x27;t do anything. reply mvdtnz 14 hours agorootparentThat is an incredibly long bow to draw. Corporations are optimising for their own profits, not anyone&#x27;s happiness. reply saint_fiasco 14 hours agorootparentI agree. The math that applies to corporate profits is not the same that should apply for human happiness.But we have to acknowledge that the weird philosophical thought experiment that can&#x27;t possibly convince anyone except weird philosophers turned out to be convincing to other entities after all.Compare the trolley problem, a famous thought experiment that people used to laugh at, up until a couple of years when suddenly important people began to ask important questions like \"should we relax the safety standards for potentially life-saving vaccines\" and \"how much larger than Y does X need to be so that preventing X functionally illiterate children are worth the price of Y dead children\" reply oatmeal1 14 hours agorootparentprevFirst, the phrasing is confusing, because it&#x27;s not clear whether people with very low happiness measured in terms of N are what we consider unhappy&#x2F;sad, which is actually negative utility. I believe with this measure, positive N means someone is more happy than they are unhappy.Second, what&#x27;s \"obvious to everyone\" is just based on how you&#x27;re phrasing the question. If you suggested to people it would be better if the population were just one deliriously happy person with N=50, vs 5 happy people with N=10.1, people would say obviously it would be better to spread the wealth and increase overall happiness. reply didibus 13 hours agoparentprevI really don&#x27;t see the issue with your happiness split. You have 10 people, and they&#x27;re are equally unhappy.This is perfect, because now they are all equally incentivized to do something about it. They&#x27;re motivated to work together and collaborate for change.If you do any other split where some people will be very happy and others very unhappy, you&#x27;ve now created certain category of people who are incentivized to maintain the current system and repress any desire for change from the unhappy people. reply Ensorceled 13 hours agoparentprevEvery time I&#x27;ve engaged in debate over this, it always comes down to believing that the world is zero sum and there is a limited amount of \"happiness\" that can be distributed.That may be true for some things, but for many decisions it is not true.There is enough food to feed everyone if we choose to distribute it properly. There is enough housing to house everyone. etc. etc.There may not be enough cardiologists or Dali originals ... reply Terr_ 13 hours agoparentprev> infinite people with barely any happinessThat reminds me of",
    "originSummary": [
      "The article criticizes the decline in consumer software, exemplified by dating apps like OKCupid, due to a shift in focus towards attracting new users at the cost of improving the experience for existing ones.",
      "The concept of the \"marginal user,\" a user with a short attention span who prefers simple content, is introduced. The prioritization of this user type is seen as contributing to a decrease in software quality and user agency.",
      "The author notes that tools augmenting user agency are usually developed by hobbyists and often get acquired and discontinued by bigger corporations."
    ],
    "commentSummary": [
      "The article discusses OkCupid's shift towards a mobile-user-centric approach, which has reportedly resulted in declining conversation quality and the rise of more surface-level dating apps.",
      "It also highlights the negative impact of growth models in software development, criticizing their focus on economic success over user experience, and noting how catering to immediate gratification might lead to a product’s downfall.",
      "The article brings attention to the challenges in designing an optimal moral system, focusing on matters like impact of user interface design on content transmission, challenges of utilitarianism, and the increasing concern about resource consumption and inequality."
    ],
    "points": 1150,
    "commentCount": 628,
    "retryCount": 0,
    "time": 1694701686
  },
  {
    "id": 37516523,
    "title": "Unity has seemingly silently removed its GitHub repo that tracks ToS changes",
    "originLink": "https://www.gamerbraves.com/unity-silently-deletes-github-repo-that-tracks-terms-of-service-changes-and-updated-its-license/",
    "originBody": "NEWS REVIEWS INTERVIEWS SISTER SITES Unity Silently Deletes GitHub Repo that Tracks Terms of Service Changes and Updated Its License by Vincent L. 1 day ago in All, Industry, News Reading Time: 2 mins read 0 0 Unedited Image Credit: GitHub, Unity, Miramax Films, HoYoverse Share on Facebook Share on Twitter Share on Telegram Share on Whatsapp Share on Reddit Following the update to its pricing plan that charges developers for each game install, Unity has seemingly silently removed its GitHub repository that tracks any terms of service (ToS) changes the company made. As discovered by a Reddit user, Unity has removed its GitHub repository that allows the public to track any changes made to the license agreements and has updated the ToS to remove a clause that lets developers use the terms from older versions of the game engine that their product shipped with. Related Posts Konami Announces Super Crazy Rhythm Castle Release Date Crime Boss: Rockay City’s Dragon’s Gold Cup DLC Lets You Play As Danny Trejo Image Credit: Unity As a result of the repository deletion, the webpage is no longer accessible, resulting in an Error 404 unless users visit through a web archive. While visiting the page through a web archive, the web page’s last availability was on 16 July 2022, revealing that Unity might have silently deleted the repo sometime before that day. Follow us on Twitter and Tweet us The GitHub repository was first established in 2019 wherein an official blog post, Unity revealed that they are committed to being an open platform and that hosting on the software development cloud-based service will “give developers full transparency about what changes are happening, and when.” In the same blog post, Unity also revealed that they have updated the license agreement, saying “When you obtain a version of Unity, and don’t upgrade your project, we think you should be able to stick to that version of the ToS.” ToS Update In the term update from 10 March 2022, Unity added a clause to the Modification section of the ToS, stating the following: “If the Updated Terms adversely impact your rights, you may elect to continue to use any current-year versions of the Unity Software (e.g., 2018.x and 2018.y and any Long Term Supported (LTS) versions for that current-year release) according to the terms that applied just prior to the Updated Terms.” “The Updated Terms will then not apply to your use of those current-year versions unless and until you update to a subsequent year version of the Unity Software (e.g. from 2019.4 to 2020.1).” Image Credit: Unity However, on 3 April 2023, a few months before the supposed repository deletion date, Unity updated their ToS once again, removing the clause that was added on 10 March 2022, disabling developers from using the agreement from the version with which their game shipped. Now the clause is completely absent in any of the new ToS, which means that users are obligated to any changes Unity made to their services regardless of version numbers including pricing updates such as the recent fee that will charge developers per game install. Check This Out Next Tags: Unity Share Tweet Share Send Share Previous Post Mortal Kombat 1 PC System Requirements Revealed Next Post Global Version Of Reverse: 1999 Open For Pre-Registration Vincent L. Short Bio: A geek with a passionate love for games, arts and creativity. Graduated with a Bachelor's Degree in Game Design and always interested in all things within the game industries. Has an unhealthy obsession with Capcom games like Monster Hunter and Resident Evil. Related Posts NEWS Konami Announces Super Crazy Rhythm Castle Release Date SEPTEMBER 15, 2023 NEWS Crime Boss: Rockay City’s Dragon’s Gold Cup DLC Lets You Play As Danny Trejo SEPTEMBER 15, 2023 NEWS Ghostrunner 2 Demo is Now Available SEPTEMBER 15, 2023 Commmunity Join GamerBraves Discord Follow us on Facebook Follow our Youtube Channel Subscribe to our Newsletter FEATURES Why You Shouldn’t Sleep On The Pokemon Adventures Manga SEPTEMBER 13, 2023 0 The Lost World of The Forgotten Monster Hunter Mobile Games SEPTEMBER 8, 2023 0 Pokemon : Paldean Winds Episode 1 Is A Whimsical And Heartwarming Watch That I Can’t Wait For More Of SEPTEMBER 7, 2023 0 Armored Core 6 Fans Are Giving Ayre And Handler Walter A Face Because The Game Doesn’t SEPTEMBER 4, 2023 0 Checking Out The Shibuya Grand Line, An Ode To The Netflix One Piece Adaptation SEPTEMBER 2, 2023 0 How Daymare 1994 Sandcastle And Its New Features Step Up The Survival Horror Experience AUGUST 31, 2023 0 Total War Warhammer III : Shadows Of Change DLC Had Me Playing A Bizarro Version Of The Game AUGUST 30, 2023 0 About GamerBraves Contact Us Privacy Policy © 2016 - 2023 Digital Braves Media Group Sdn Bhd News Reviews Interviews Sister Sites © 2016 - 2023 Digital Braves Media Group Sdn Bhd",
    "commentLink": "https://news.ycombinator.com/item?id=37516523",
    "commentBody": "Unity has seemingly silently removed its GitHub repo that tracks ToS changesHacker NewspastloginUnity has seemingly silently removed its GitHub repo that tracks ToS changes (gamerbraves.com) 586 points by agluszak 9 hours ago| hidepastfavorite151 comments bhouston 8 hours agoThis could have been done in a much better fashion to achieve the long term desired outcome (more income) while also ensuring continued trust and transparency with their community.Simply, they could have not made this retroactive on existing released games. Rather just be clear that going forward, games build using the new Unity versions would have a per-installation fee. And they would slowly discontinue support for the older versions on a specific schedule.There are new devices coming out like the new Switch, the Apple Vision Pro, and then the new features Unity is adding like AI, just add those to the new versions that have the run-time fee. People will upgrade to it on their own terms!By making it retroactive and forcing it on everyone, they have basically screwed over their existing customers who shipped games expecting a certain cost structure and now it is higher.Deleting this GitHub license archive repo where they make it clear that their license changes are likely unenforceable is icing on the cake.EDIT: To remove the claim that Unreal Engine had a similar per-install fee, it doesn&#x27;t. reply umpalumpaaa 8 hours agoparentThe problem is that they did it retroactively and they also added a per install&#x2F;download fee. So if your game has 1mio installs you pad the install fee x 1 Million. Unreal has no install fee like this.“A 5% royalty is due only if you are distributing an off-the-shelf product that incorporates Unreal Engine code (such as a game). Provided that you notify us on time using the Release Form, you will only owe royalties once the lifetime gross revenue from that product exceeds $1 million USD; in other words, the first $1 million will be royalty-exempt.”Some mobile games have a ton of installs and a very small amount of revenue per user. Those 27cents per install are a lot of money for those type of games and will even make some business models no longer feasible. reply bhouston 8 hours agorootparent> Those 27cents per install are a lot of money for those type of games and will even make some business models no longer feasible.Exactly. So if they did this in an upfront way, they would have said that starting with Unity 2024 there is this new cost structure. Then game devs can make informed choices if they want to build those types of games on the platform.This retroactive stuff is insane and I cannot figure out how a company can make that type of move if they care about their users. Although I think I sort of answered my own question... reply bigstrat2003 7 hours agorootparent> This retroactive stuff is insane and I cannot figure out how a company can make that type of move if they care about their users.I can&#x27;t even understand how it can possibly be legal. How on earth is it even possible to say \"your game which was released before we updated this license is subject to the updated version\"? IANAL but that sure seems like something which would require both parties to agree to the updated terms for them to be binding. reply lolinder 5 hours agorootparentThe old Terms of Service have the usual clause that says that the company can change the terms at any time. However, the terms do provide that if you don&#x27;t update Unity then you can continue to use the old terms. Unity obviously doesn&#x27;t point that out in the blog or FAQ.> Unity may update these Unity Software Additional Terms at any time for any reason and without notice (the “Updated Terms”) and those Updated Terms will apply to the most recent current-year version of the Unity Software, provided that, if the Updated Terms adversely impact your rights, you may elect to continue to use any current-year versions of the Unity Software (e.g., 2018.x and 2018.y and any Long Term Supported (LTS) versions for that current-year release) according to the terms that applied just prior to the Updated Terms (the “Prior Terms”). The Updated Terms will then not apply to your use of those current-year versions unless and until you update to a subsequent year version of the Unity Software (e.g. from 2019.4 to 2020.1). If material modifications are made to these Terms, Unity will endeavor to notify you of the modification. If a modification is required to comply with applicable law, the modification will apply notwithstanding this section. Except as explicitly set forth in this paragraph, your use of any new version or release of the Unity Software will be subject to the Updated Terms applicable to that release or version. You understand that it is your responsibility to maintain complete records establishing your entitlement to Prior Terms.https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220716084623&#x2F;https:&#x2F;&#x2F;github.co... reply mwill 5 hours agorootparentWorth noting that this clause was removed early this year, whats interesting is you can see it under previous terms on the unity site, which indicate it was replace on October 13, 2022, linking to the new terms (that don&#x27;t have this clause), implying that this clause was removed nearly a year ago...However, the clause was still in the October 2022 terms, and was still there in March 2023 [2], and was actually removed in April this year...It&#x27;s likely just an oversight, but it does feel pretty dishonest in the face of removing the github repo, its the difference between \"that clause has been gone for a year\" and \"that clause was removed less than 6 months ago\"[1] https:&#x2F;&#x2F;unity.com&#x2F;legal&#x2F;terms-of-service&#x2F;software-legacy[2] https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20230303043022&#x2F;https:&#x2F;&#x2F;unity.com... reply wodenokoto 4 hours agorootparentprevWell, it depends on how you think of the license. Is it like you buy a license for a specific release or do you subscribe to a license to the software across all releases?I don’t know. I can see how it would be ridiculous if Amazon said “oh, by the way, starting next year you have to pay a cent every time you finish any of the books you bought on your kindle”But if Netflix went “starting next year, there’s a surcharge of 1 cent per episode you watch” nobody would go “surely it can only count for episodes released from next year!Which raises an interesting question to me: what if a developer wants out of the Unity contract? Does that mean they have to somehow break games consumers already purchased so as not to be liable to install fees? reply Nathanba 9 minutes agorootparentI think whether something can only run on the company&#x27;s service is the differentiating factor. So if Unity games all required to be played on unity3d.com or if they all required online communication with unity3d servers to function at all then people would accept that the contract for finished games could change anytime. reply j5155 4 hours agorootparentprevReminder that Amazon did something like that once: https:&#x2F;&#x2F;archive.nytimes.com&#x2F;www.nytimes.com&#x2F;2009&#x2F;07&#x2F;18&#x2F;techn... reply dotnet00 6 hours agorootparentprevMaybe their argument was going to be the malicious interpretation that continued use of the engine represents consent to the updated terms. Thus maliciously expecting that anyone who doesn&#x27;t agree should cease distribution and support of their game. reply perryizgr8 6 hours agorootparentprevYou can say whatever you want in a contract. If the other party thinks it is illegal they take you to court and the judge decides. reply TheRoque 6 hours agorootparentBut it means that their legal teams say that it&#x27;s legit already, so that&#x27;s why most people assume that this is legal. reply meheleventyone 4 hours agorootparentThis is an extremely bad way to view a contract. reply moron4hire 6 hours agorootparentprevA lawyer friend of mine once told me that most of his job as a contract lawyer was basically a game to see if the other company&#x27;s lawyers were paying attention and to take absolutely everything he could if they weren&#x27;t. reply semi-extrinsic 5 hours agorootparentBut in that case there is a meeting of the minds where one party is supposed to read the terms and object to any that are unreasonable.It&#x27;s very different from the situation where one party retroactively changes conditions. replyClubber 8 hours agorootparentprev>This retroactive stuff is insane and I cannot figure out how a company can make that type of move if they care about their users.If I understand you correctly (I haven&#x27;t really been following this), they changed the contract and are trying to retroactively collect license fees for installs done prior to the change in contract? I don&#x27;t think this is legal. When you change a contract, it&#x27;s on a go forward bases. It will be interesting to see how this plays out. It&#x27;s definitely a money grab. If it&#x27;s deemed illegal, i.e. fraud, I hope there is jail time. Gotta send a message.Did Unity recently get acquired, new investors or new management? reply jimkoen 7 hours agorootparent> Did Unity recently get acquired, new investors or new management?EA&#x27;s former CEO, John Riccitiello took over last year. He inaugurated himself with quite a few statements, one of which was discussed here:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=32097752 reply jskherman 7 hours agorootparentWhen it comes to games it&#x27;s always EA, isn&#x27;t it? Isn&#x27;t this CEO the one also responsible for some of EA&#x27;s notoriety? reply internet101010 6 hours agorootparentYes, he is the brain behind the 2013 SimCity disaster. reply riffraff 6 hours agorootparentForgive my ignorance, what disaster are you referring to? reply mikepurvis 5 hours agorootparentIt was a very dumbed down attempt to reboot the franchise, when what the fans wanted was what Cities Skylines would later deliver. reply Akronymus 54 minutes agorootparent> when what the fans wanted was what Cities Skylines would later deliver.For me personally, C:S goes in too much on building a nice looking city and not enough on the simulation aspect. reply Clubber 7 hours agorootparentprevEA and Activision&#x2F;Blizzard doesn&#x27;t have a great track record either. Megacorps are usually bad for everybody except ownership. reply thowfaraway 7 hours agorootparentprevRiccitiello has been CEO since 2014. There were some good times at the beginning, but things seem to be falling apart. reply callalex 5 hours agorootparentprevHow do these fuckers keep failing up? reply barkingcat 7 hours agorootparentprevUnity IPO&#x27;ed in 2020, which isn&#x27;t super recent, but is probably the reason behind these changes. IPO&#x27;ed means they gotta report some quarterly improvements, every quarter forever under the totally unsustainable growth model. reply gabereiser 6 hours agorootparentUnity went public. Bombed, and merged with IronSource, a notorious malware spam mobile ad company. It’s always about milking their install base.https:&#x2F;&#x2F;blog.unity.com&#x2F;news&#x2F;welcome-ironsource reply readyplayernull 7 hours agorootparentprev> Did Unity recently get acquired, new investors or new management?Nope. They bought Weta tools and the investment haven&#x27;t paid out and probably won&#x27;t be soon if ever, now they are desperate for money. reply marcosdumay 7 hours agorootparentprevIt&#x27;s not fraud. They are not misrepresenting anything, or getting any money that doesn&#x27;t belong to them.If it&#x27;s illegal, it will just be invalid. What means that people could just not pay them. There&#x27;s no jail time coming out of this. reply gmjosack 7 hours agorootparentprevThe terms have been changed so that all future installs can incur a fee even on older games that used unity even if the haven&#x27;t been updated recently. reply Clubber 7 hours agorootparent>The terms have been changed so that all future installs can incur a fee even on older games that used unity even if the haven&#x27;t been updated recently.They&#x27;ll be able to get away with that then, the weasels. Sounds like they are trying to make a golden goose and kill it in one fell swoop. The latest Unreal demos look mighty fine. Sounds like we will be seeing a bunch of games use it in the near future.I wonder if the older engines used by older games have any way to detect installs. I&#x27;d hate to see devs who abandoned their projects years ago but are still downloadable somewhere get caught up in this. reply whiddershins 7 hours agorootparentprevI have only been generally following this but I don’t think this is quite accurate.It seems more like, starting in 2024 when you get more downloads the fee would be applied.I see people talking here about apps that have a huge user base and a very low price per purchase. I admit that segment didn’t pop into my mind initially. And I see the problem there. I also imagine the Unity execs may have missed that scenario too.From reading all of their public communication, and with just a hint of principle of charity, I suspect they are trying to do this in the most fair minded and developer friendly manner possible.You have to meet both volume and revenue minimums to even be subject to this. All free apps are safe. All non-profits are safe.I think it is good Unity is receiving public feedback.I am sad so many people are jumping to the conclusion this is a corrupt money grab. reply Scramblejams 7 hours agorootparentA public company with veteran leadership does not upend their revenue model without first playing out, in great detail, how it will impact all of their largest users. The segment you mention may not have popped into your mind, but it&#x27;s certainly been on theirs. This was intentional.What category of game has \"a huge user base and a very low price per purchase?\" Mobile free-to-play, that&#x27;s what. How are those games monetized? Frequently with ads. And it&#x27;s been noted elsewhere that if you use Unity&#x27;s ad network, you will get a 100% discount on your per-install fees.They knew exactly what they were doing. They merged with an ad company -- they are now an ad company. Their strategy is to make F2P games untenable on Unity if you&#x27;re not getting advertisements from them. reply larusso 6 hours agorootparentprevI believe the whole point and plan is that you use the Unity ad network exclusively. My understanding is that you get exempted then. Unity makes the most money with its Ad provider and would love to kill other ad mediation frameworks to get a bigger slice of the pie. reply rossjudson 5 hours agorootparentI am pretty sure that they can&#x27;t actually just *say* that. I suspect you are right. reply Scramblejams 5 hours agorootparentMaybe. AWS had no problem saying \"Use our Lumberyard engine for free, but if you rent gameservers, you must rent them from us.\"I wonder how it&#x27;d have gone down if Unity had said, \"From Unity version 2024 and beyond, if you have ads in your game, you must get them from us,\" and let that be the end of it. replyheavyset_go 8 hours agorootparentprevThey don&#x27;t want developers choosing to target older Unity versions for their games, they want to milk cent they can out of their users. reply numpad0 7 hours agorootparentThat and&#x2F;or they wanted to set up existing games. Something like 1 in 5 of top 50 iOS games, free-to-play and majority Asian(Chinese or Japanese), are making banks and on Unity.Personally I’m wondering if Chinese gamedev industry would “buy Godot” or do something to that effect. Japanese publishers won’t be able to do that nor would be willing to pay, so I’m guessing they’ll migrate existing to UE or wind down Unity titles, just my speculations though. reply yAak 6 hours agorootparentThankfully Godot is safe from acquisition: https:&#x2F;&#x2F;godotengine.org&#x2F;governance&#x2F;(Or, at least they say they are.) reply jkaplowitz 3 hours agorootparentI just dug into the details. Yes, it looks pretty legitimate: copyright remains held by the individual contributors without a Contributor License Agreement, they are sponsored by a true non-profit foundation with robust non-profit policies and suitably non-profit legal status in the Netherlands, their money and important assets like the Godot trademark itself are held by a mixture of that non-profit foundation and (possibly as a transitional matter) the longstanding free software non-profit charity in the US which was their primary legal home for 7 years.I was formerly heavily involved in the leadership of the other major US non-profit charity that does this kind of fiscal sponsorship (and which maintained a friendly and collaborative relationship with the charity that Godot previously used). They’re not scamming you in the way of a lot of executives at VC-funded for-profit startups (and their acquirers) when they make entirely legally unenforceable statements about what will or won’t happen in the future which they don’t necessarily even believe themselves. reply tjpnz 6 hours agorootparentprevWhy couldn&#x27;t Japanese publishers buy Godot (assuming that they even could)? reply jkaplowitz 3 hours agorootparentThe seller that would be necessary is a legal non-profit foundation in the Netherlands, and currently for at least some important assets like the Godot trademark in the US, also a long-standing US 501(c)(3) public charity focused broadly on free software which is not controlled by the Godot team. These non-profits would usually not be legally allowed to subvert the purpose of the organization &#x2F; the project in this way, based on their approved non-profit mission, and the relevant non-profit regulators could slap them down in court if they do.Additionally the copyright isn’t even owned by those organizations but rather retained in full by all of the many individual contributors to Godot, without a Contributor License Agreement.So any for-profit corporate acquirer would not be able to get the Godot name, and if they didn’t want to have to comply with the Godot copyright license, they’d have to get the agreement of every individual contributor whose work they don’t want to rewrite.In short, they are safe from acquisition in the same way that Debian is, unlike most corporate-sponsored or small-team personally-owned “open source” projects that we see here on Hacker News. reply derefr 7 hours agorootparentprevThen just specify that new greenfield projects created after [date] won’t be licensed for previous versions of the engine, and that anyone with a project currently in development has until [date] to register their existing use. reply hedora 7 hours agorootparentprev> Some mobile games have a ton of installs and a very small amount of revenue per user. Those 27cents per install are a lot of money for those type of games and will even make some business models no longer feasible.When you put it that way, Unity could have come out of this price change looking like heroes with better messaging.Serious games pay the $0.27 fee moving forward, and (hopefully) that comes with some new value add for end users (such as contractually enforced no advertising, cross-platform something something).Ad-supported games use a different engine with different rules, and end users get the “free to play” benefit.(The retroactive thing is obviously bullshit; I wonder how many studios will simply refuse to pay and jump ship for future titles.) reply StopHammoTime 7 hours agorootparentThey have actually released something like this in the last day that says if you use their ad market there is no per device fee.It was on HN this morning. reply gnopgnip 7 hours agorootparentprevIf you pay $2k for unit pro it’s a max of 15 cents an install, actually less. And you pay nothing for installs until $1m in revenue and 1m installs in the previous 12 months reply AuryGlenz 3 hours agorootparentThat’s $2k, per seat, per year.Which you now need to pay to get rid of the Unity splash screen. Why they haven’t learned the lesson of only poor developers (and therefore, largely shovelware and bad games) showing their splash screen is a really bad idea I’ll never understand. I suppose this will technically help with that. reply ffhhttt 4 hours agorootparentprev> 27centsRealistically it’s closer to 3-5 cents per install. Where did you get 27? Even personal&#x2F;plus is cheaper than that in the worst case (ie. 100% of your users are in NA, the richer parts of Western Europe etc) reply jimkoen 8 hours agoparentprev> Simply, they could have not made this retroactiveHow can they make this apply retroactively though? For already shipped titles, if I&#x27;m no longer providing updates anymore, how can they force me to pay money?I&#x27;m aware that games no longer have a final shipping date, with early access and all, and as a dev I&#x27;d likely would want to offer continued support in such a scenario.But the way I understand it from the overall public reaction, is that they&#x27;re trying to charge customers for existing titles, retroactively, in perpetuity going onward. This would be a one sided ToS change which only benefits them, which they push the customer into agreeing. Such a practice is mostly unenforceable in a lot of jurisdictions around the world. reply dcow 7 hours agorootparentWell yeah, that’s what is so mind boggling about the whole thing. They are trying to do something that’s likely illegal in terms of contract law. It’s also just abundantly stupid given the social cost. There was a super clean way to do the whole transition where you announce the changes going forward starting 1 Jan 2024. You show examples of what costs will be and stress that that the pricing is an order of magnitude cheaper than Unreal, and everyone feels like it’s fair (though nobody loves price increases). Someone needs to fire their CEO. reply judge2020 7 hours agorootparentprevAre there perpetual unity licenses? If not, then surely the retroactivity comes as soon as you renew your license. reply jimkoen 1 hour agorootparentThis has nothing to do with whether there are perpetual licenses or not.The way the go about this makes it seem that you enter a contract that you can never reasonably exit out of, as in order for you to stop having to pay, you&#x27;d have to convincingly prove that you forced every customer to uninstall your app, i.e. that there isn&#x27;t at least one install left.This sounds absolutely bonkers to me. reply StopHammoTime 7 hours agorootparentprevThe problem is they now want to license the engine as a separate product which they didn’t do in the past. Previously, you paid your license fee for editor and any game you build off that is deployed and you could stop paying them.I guess they didn’t like the thought of not being able to perpetually milk their customers and wanted to increase their cut outside of the editor fee.From what I understand though, Unreal is just licensed based on revenue and all the editing tools are free. Unity had the opposite approach previously. They’ve decided they want a cut of both pies. reply thowfaraway 7 hours agorootparentprevThey can&#x27;t force you to pay. The only leverage or legal claim they have is if you want to update your title after Jan 2024, then they can ask you to get up to date on your account. reply glinkot 7 hours agoparentprevThis reminds me of the old Simpsons ep where Homer realises their pet elephant costs a lot and decides to retrospectively update pricing:https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=7uQNPS9v_VU reply StopHammoTime 7 hours agorootparent“Get out of my house.” reply CSSer 7 hours agorootparentprevWow, this should be higher. It’s perfect. I don’t think someone could even find an XKCD more relevant. reply white_dragon88 6 hours agorootparentXKCD is super overrated. Cringe at times, banal at others. reply Ylpertnodi 2 hours agorootparent....amd yet referenced so often. reply rapind 7 hours agoparentprevThis whole debacle is unreal (pun intended?). I don’t think they’ll be able to enforce this the way they hope to. For example they want to be paid for unity games in subscription services, like xbox gamepass. Meanwhile M$ lawyers are rubbing their hands together in anticipation.They’re going to (already have) damaged their reputation beyond repair. This isn’t typical consumer strong arm tactics. Their clients are businesses who already have alternatives. If one of my vendors abruptly changed our agreement like this, there’s no question I’d quietly phase them out ASAP. reply labster 5 hours agorootparentIf they think they can find a court that will actually enforce this change, then they’ll be waiting for Godot. reply coder543 8 hours agoparentprev> have a run-time fee, similar to Unreal EngineAnother comment already said this, but I feel it&#x27;s worth emphasizing: Unreal Engine does not have a runtime fee. You don&#x27;t pay per install. reply bhouston 8 hours agorootparentI edited the comment to fix that. :) reply gmerc 8 hours agoparentprev> Simply, they could have not made this retroactive on existing released games. Rather just be clear that going forward, games build using the new Unity versions would have a run-time fee, similar to Unreal Engine.No no, you don’t understand, that’s exactly what they want reply bhouston 8 hours agorootparentIt does appear to be what they want, but it is also very likely unenforcible retroactively. So it is likely that they are currently paying the steep repetitional costs of this move without making anywhere close to the additional income that they wanted from this move. reply gmerc 7 hours agorootparentYou are mistaking what the CEO and the VCs want with what a long term stable company would want.The incentives don’t work that way. The CEO gets his bonus and ability to sell shares if he pleases VCs and VCs are looking for bagholders for the company. So the CEO creates a revenue narrative to sell to institutional investors so they take an increasingly mediocre asset from the VCs at a premium.The pattern is all around, exactly the same as Reddit for example.As a game designer - there is zero built in incentives for the C level of a publicly listed company to do what’s good for the company long term. It’s much better to get rich quick and cash out.It’s just that the desperation is now now sky high and narratives for the next earnings call need to be generated quickly reply hn_throwaway_99 6 hours agorootparentThis comment makes no sense considering Unity is a publicly traded company. reply gmerc 2 hours agorootparentThey are heavily invested by VCs who need to find bagholders to buy their shares. That’s the point. reply ffhhttt 3 hours agorootparentprevWhy? IMHO it makes more sense for a public company. replyLammy 5 hours agoparentprev> Rather just be clear that going forward, games build using the new Unity versions would have a per-installation feeI would still oppose it because I don&#x27;t want every installer to spy on me as a user. I&#x27;m glad it happened in a way that spurred so much resistance instead of a slow frog-boil. reply dcow 7 hours agoparentprevI’ve been asking the exact same question. There is so clearly a better way to have handled this whole thing it makes you wonder whether the person in charge of this transition is simply incompetent, or actually negligent. If I were a shareholder, I might consider suing. reply zerocrates 8 hours agoparentprevI wonder just how much this change is geared at capturing value from what&#x27;s already out there, i.e. the retroactivity is the point. reply bhouston 8 hours agorootparentMost games on the Switch and Quest devices for sure. A lot of mobile games as well.Over 1B games sold on the switch: https:&#x2F;&#x2F;www.gamespot.com&#x2F;articles&#x2F;1-billion-switch-games-hav...We can assume at least one game per Quest was sold: https:&#x2F;&#x2F;www.roadtovr.com&#x2F;quest-sales-20-million-retention-st...Hard to figure out the mobile numbers. reply preommr 6 hours agorootparentThat list (which is at least half of switch game sales) are nintendo games that don&#x27;t use Unity. I&#x27;d be shocked if half of the remaining 500mn games sold used unity. But if they did, at .20c, that&#x27;s like 50mn dollars.As for the quest sales, that&#x27;s another 4mn.It seems extremely foolhardy to cause this much damage to their reputation and potential growth as a multi-billion dollar company (market cap of 13bn) for 50-100mn a year of additional revenue. reply ffhhttt 3 hours agorootparent> at .20cZero of them would be paying $0.2 per instal. Probably much closer to $0.03-0.05.Nobody could ship games in the Switch using the personal edition and nobody who understands basic math would be paying $0.2 even after these prices go into effect reply tomnipotent 7 hours agorootparentprev> geared at capturing value from what&#x27;s already out thereThis sounds like a plausible motive. There&#x27;s a handful of huge games using Unity that together generate upwards of 20bln annually, such as Pokemon GO, Honor of Kings, and Genshin Impact. I&#x27;m guessing their soundbite of \"developers being excited\" over the change is with those behemoths in mind, and not the other games that are barely making ends meet.These particular successful games are still going to save millions compared to Unreal, while the change means that everyone else would now be more profitable with Unreal. Pokemon GO alone would have made Unreal $100mln+ a year with the 5% royalty, while paying considerably less with Unity&#x27;s new scheme. Even at a billion downloads it&#x27;s only $10mln in comparison.It sounds like Unity is shifting their focus from the long tail where they were successful charging annual subscription fees (and ads), to the head that&#x27;s generating orders of magnitude more revenue. reply ffhhttt 3 hours agorootparent> everyone else would now be more profitable with UnrealTo be fair only F2P games that makes less than ~$2 per user might be more profitable. For almost everyone else above the 1 million threshold Unity would still be cheaper. reply gmjosack 7 hours agoprevThis video[1] talks a bit about this from a lawyer&#x27;s point of view and is a really good overview.For people who are not paying as much attention to this I&#x27;d like to summarize the main points of frustration.1. Unity has just shown they believe they are able, and they are willing, to change the terms on what you have to pay them. What are the bounds to terms like this? What if Unity is tight on money and decide to squeeze developers further? The risk to continuing business with Unity is very high as you have unknown future exposure.2. The monetization model they&#x27;ve chosen is tied to installs, not revenue. On the initial day of announcement they even claimed re-installs would count but they&#x27;ve since walked that back (or \"clarified a miscommunication\"). Unity has been extremely wishy-washy on how they even plan to track this mentioning proprietary systems they can&#x27;t elaborate on and your only recourse is to appeal if you think they got the numbers wrong. This is not a metric tied to your revenue and is difficult to plan around.There are a lot of people arguing against a strawman of people who don&#x27;t want to pay unity but that is not at all what this is about. Unity chose a terrible model they can&#x27;t even explain for how they want to bill people and apply it to all past games that use the engine for all future sales.This would be similar to if Microsoft said everyone who ever built anything on C# has to start paying a fee for every future install because it includes the .net runtime.[1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=rGMrebXypJo reply brundolf 6 hours agoparentIANAL but isn&#x27;t this what we have an FTC for? It feels like pretty blatantly unfair business dealings, particularly the fact that it&#x27;s retroactiveLiterally \"I am altering the deal, pray I do not alter it any further\" reply harles 6 hours agorootparentI hope so, but if it’s likely to get smacked down by the FTC, it’s unlikely Unity would try this path. I’m sure this has been in the works for a long time and all the backlash was anticipated - they just expect huge profits on the other side. reply brundolf 6 hours agorootparentWe&#x27;ll see I guess! But even if it&#x27;s not illegal the shortsightedness is staggering, which makes me question if leadership would have even foreseen legal problems reply harles 6 hours agorootparentI think this is called a single round game. They screw everyone over and will never be trusted again, but get a one time payout in the process. It just seems like a company of Unity’s scale must have a better plan than that. reply cezart 5 hours agorootparentSince the goal of management is to provide shareholder value, could the current management be sued by the shareholders for basically destroying the long term value of the company? reply danielbln 3 hours agorootparentprevWell, about that: https:&#x2F;&#x2F;finance.yahoo.com&#x2F;news&#x2F;unity-software-incs-president... reply hiddencost 6 hours agorootparentprevNaw bruh. They killed the regulatory state. It&#x27;s too late. reply readyplayernull 7 hours agoparentprevThey might have well devised the first of its kind \"ransom by installations\" in the history of software, by making it possible for attackers to fake mass installations and get gamedevs into fatal debts. And they are taking the executioner role. reply gmjosack 7 hours agorootparentWe&#x27;ve been calling it \"Install Bombing\" after the common abusive practice of review bombing. Unity claims they have anti-fraud systems in place and you can always appeal with their fraud team but I don&#x27;t have an reason to blindly trust a black box that when fails makes Unity more money and puts the burden on me to prove otherwise. reply johnfernow 2 hours agorootparentIt is completely impossible to keep track of DRM-free games being distributed illegally on private trackers that they are not members of, and there are surely tons of private trackers that are not mentioned on the public web that no one at Unity is aware of. Short of spying on the entire world (and processing all that info), it&#x27;s impossible to keep track of people sharing DRM-free games illegally on USB and hard drives with their friends, or on private folders through Google Drive, Dropbox, etc. accounts.So unless their anti-fraud system is asking Valve, Microsoft, Sony, Nintendo, Apple, Google, Epic, GOG, itch.io, etc. how many downloads have occurred (no chance that they&#x27;ll all agree to that), then their system is just going to make a guess, which they&#x27;ll charge you for, and hope that holds up in court. reply StopHammoTime 7 hours agorootparentprevBut even then they’re not going to proactively stop it, it’s up to devs to monitor their bill and go “wait we’re getting bombed”. Their whole approach is terribly sloppy and unprofessional. reply p1necone 2 hours agorootparentprevAll it takes is a few botnets over a decently distributed ip range to make this whole thing basically impossible. reply AceJohnny2 5 hours agorootparentprev> and you can always appeal with their fraud teamROFL reply lucb1e 7 hours agorootparentprevThis applies to any paid API and is something we check for when we do security audits, definitely not a \"first of its kind\". It&#x27;s just not common that APIs that cost 20 cents per invocation are exposed directly to the general public. reply brazzledazzle 7 hours agoparentprev>Unity has been extremely wishy-washy on how they even plan to track this mentioning proprietary systems they can&#x27;t elaborate on and your only recourse is to appeal if you think they got the numbers wrong.They must know that their methods will ultimately be revealed during discovery during the inevitable lawsuits. So I’m wondering if they haven’t actually figured out how they’re doing it yet. reply ahi 5 hours agorootparentAll I can think of is some poor dev trying and failing to explain to the mbas why this can&#x27;t be done with any precision. Two parallel lines that cross... reply d3w4s9 1 hour agoparentprevI am curious -- if you are a business and buy Google Ads, and they tell you how many impressions and clicks you got, are those numbers verifiable? How effective is it at filtering out \"bad\" clicks, like the ones from a competitor who wants to exhaust your ad money? Is the situation similar? reply lucb1e 5 hours agoparentprevNot sure why I watched the whole hour&#x27;s worth of content as I&#x27;m not involved tbh, but what I gather is that the whole speech amounts to, in essence, \"yes it&#x27;s legal (unless you want to appeal to empathy from a court); however, Unity is saying that they&#x27;ll tell you how much you owe them and you have no way of verifying it, so with these one-sided changes blemishing trust while simultaneously asking for your trust in their estimations on how much you owe them... tread carefully\" reply janalsncm 8 hours agoprevI posted this a few weeks ago, there’s already a project for tracking the TOS of many companies. This came up when people realized Zoom had done some funny business with their TOS as well. I see Unity isn’t there though, maybe someone should submit a PR.https:&#x2F;&#x2F;github.com&#x2F;OpenTermsArchive&#x2F;contrib-versions reply michaelteter 8 hours agoparentPerhaps you should repost this periodically. The worst case scenario is that your post is ignored. This idea could become something of a foundation for tracking companies. reply lolinder 5 hours agoprevIANAL, but I suspect part of what they&#x27;re trying to hide is that the old terms [0] specify that while they can change the terms at any time, you may opt to use the old terms as long as you don&#x27;t update the software beyond the current year (2023.x).That wording is changed in the new terms [1] to say \"If the modified Terms are not acceptable to you, your only recourse is to cease using the Services.\" Just in case you were wondering how one-sided this new agreement is intended to be.[0] Section 8, \"Modifications\": https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20201111183311&#x2F;https:&#x2F;&#x2F;github.co...[1] https:&#x2F;&#x2F;unity.com&#x2F;legal&#x2F;terms-of-service reply harles 5 hours agoparentThat was my understanding. They did it (or least claim to have made the change, maybe they left in a loop hole) in response to the Spatial OS debacle. They tried to crush competition in their ecosystem through retroactive TOS changes that time too. Some of the community got rightfully up in arms about it, so they reversed and added these long term licenses. But it seems like that was all just lip service, because here we are right back where we were.Overview of the Spatial OS stuff for those that didn’t follow it: https:&#x2F;&#x2F;www.engadget.com&#x2F;2019-01-10-unity-improbable-epic-ga... reply zmmmmm 7 hours agoprevWhat I hate most about this is that it puts unbounded liability onto developers. They can&#x27;t control how often their game will be installed in the future. The outcome will likely be that the minute a game falls below a certain rate of sales they will be forced to make it unavailable because they can&#x27;t risk the ongoing cost of the existing userbase continually reinstalling it. Every time a new platform or device is released, there will be a wave of people shifting their installs which will will generate cost for developers for no return, and windfall profits to Unity for doing absolutely nothing. They get the money even if the user never even opens the app, they just click the button saying \"install all my apps from my old device on my new one\". Which is what a lot of users will do. reply bhouston 6 hours agoparent> What I hate most about this is that it puts unbounded liability onto developers.And Unity can continue to raise the per-installation price as well. If they lose a bunch of customers but want to maintain their current income, why not raise it to $1 instead of just $0.27? reply labster 5 hours agorootparentI’m pretty sure that would be an unconscionable contract at $1, not a mere unethical contract. The latter is legal, the former is not. reply AuryGlenz 3 hours agorootparentWouldn’t that depend on the income of the developer vs. how many installs they get? Surely even $.20 for someone that has a hit mobile game that sells for $.99 would be unconscionable. After App Store fees and accounting for potential multiple installs it could halve their income. reply labster 1 hour agorootparentI didn’t actually make claim about the $0.20 case. Multiples of $1 is clearly too much for products that cost $0.99. But with America’s courts headed by an obviously illegitimate Supreme Court, who knows? The lesser amount could be pronounced legal. reply johnfernow 2 hours agoparentprevActually, making it unavailable wouldn&#x27;t even solve the problem, as once you purchase a game, even if it is no longer for sale on Steam, you can still redownload it, including to new devices.So if you&#x27;ve ever released a Unity game (even if it hasn&#x27;t been updated in years), even if you delist your game from the store today, presumably you could still get charged if people who already own your game reinstall it.I&#x27;m not a lawyer, but I really don&#x27;t see how that&#x27;d hold up in court — you created a product under different terms years ago, and now your product, which isn&#x27;t even for sale, can be charged for something that your business has no control over. Even if the ToS says Unity reserves the right to change their fees, I don&#x27;t see how that can apply to products that aren&#x27;t even being sold anymore. reply rolph 9 hours agoprevthis is something they want to hide.https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220716084623&#x2F;https:&#x2F;&#x2F;github.co... reply thaliaarchi 7 hours agoparentFor source code, I prefer the Software Heritage archive over the Internet Archive, because it archives the git history, instead of the HTML UI. This particular repo was saved there[0] and was most recently visited 24 Oct 2022, which has two more terms updates.I have created a mirror of this more up-to-date version at https:&#x2F;&#x2F;github.com&#x2F;thaliaarchi&#x2F;unity-termsofservice.Here&#x27;s how to “cook”[1] an archive from the vault, if you want to do it yourself: curl -X POST https:&#x2F;&#x2F;archive.softwareheritage.org&#x2F;api&#x2F;1&#x2F;vault&#x2F;git-bare&#x2F;swh:1:rev:28fdae008c61d98d0d9ec55b8cc016ce61809f58&#x2F; wget https:&#x2F;&#x2F;archive.softwareheritage.org&#x2F;api&#x2F;1&#x2F;vault&#x2F;git-bare&#x2F;swh:1:rev:28fdae008c61d98d0d9ec55b8cc016ce61809f58&#x2F;raw&#x2F; --content-disposition tar xf swh_1_rev_28fdae008c61d98d0d9ec55b8cc016ce61809f58.git.tar git clone swh:1:rev:28fdae008c61d98d0d9ec55b8cc016ce61809f58.git TermsOfService[0]: https:&#x2F;&#x2F;archive.softwareheritage.org&#x2F;browse&#x2F;origin&#x2F;directory...[1]: https:&#x2F;&#x2F;archive.softwareheritage.org&#x2F;api&#x2F;1&#x2F;vault&#x2F;git-bare&#x2F;do... reply ivanmontillam 8 hours agoparentprevI bet their lawyers are pulling their hairs right now on it reply w-ll 8 hours agorootparentthey are counting more than $0.25 per install reply EMCymatics 8 hours agoparentprevHaha yikes reply blendergeek 6 hours agoprevI&#x27;m a little confused here. If I released a game a couple years ago when the terms explicitly stated that Unity couldn&#x27;t retroactively update them but now they changed the no retroactive updates clause, how can they try to apply this when that violates the terms I agreed to?This seems extremely shady. reply zeroimpl 7 hours agoprevI&#x27;m surprised they even had such a repo public in the first place.Every year Apple releases a new version of their Apple Developer Program License Agreement and Paid Applications agreement. I always download both as TXT files and diff against the previous one to see what changed. I practically don&#x27;t even need to read any of the WWDC news to know what new things they are releasing. reply jamiek88 7 hours agoparentThat&#x27;s a great idea!It&#x27;d be awesome if someone automated that and threw it up on github but that&#x27;s just me being lazy. reply noduerme 5 hours agoprevAdobe put a silent kill switch into Flash player, rendering 10 years worth of casual games I&#x27;d written immediately unplayable. As a result of Adobe&#x27;s actions, a whole sector of lone devs and small teams turned to Unity to build games that would&#x27;ve otherwise been built in AS3. I&#x27;m glad I didn&#x27;t end up going that route, but I really feel for the folks who are now getting screwed again. reply hawkguy 4 hours agoparentI just got started learning about Flash so I could mod Starfield’s UI. The kill switch thing actually disgusted me, like I had to re-read the article explaining it because I couldn’t believe it was possible, let alone thinkable. All that history, just gone. I spent so many hours in the computer lab at school playing Flash games, man. Glad Ruffle exists. reply justinclift 5 hours agoparentprevWhat was the silent kill switch?Was it a time based thing that applies to everyone or something?Asking because a friend is playing a lot of ancient flash games recently using Ruffle (OSS flash player written in Rust), and doesn&#x27;t seem to be having problems like that. reply njsubedi 5 hours agoprevWe are making games in Unity, and paying per developer per month the highest subscription $180+ for any tool we use. The amount is already quite high and grants us license to use Unity.Their current move is either because they being extremely greedy, or because they&#x27;re burning a lot of cash. We make simple games, and we&#x27;re using Unity because of its community support and assets, not because we love Unity, the company. The community moves, we move.Now if they&#x27;re changing the terms arbitrarily, and hide that behind the \"I agree\" button, it proves that they have turned evil. We, along with several other fellow game companies don&#x27;t support evil, and already migrating our games to Godot. We were prepared for something like this, but didn&#x27;t anticipate Unity will flip their face this soon. This move only promotes Godot or Unreal; a far more different result than whatever they expected. reply cookiengineer 7 hours agoprevSource of the reddit post [1] with the web archive link [2].[1] https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;gamedev&#x2F;comments&#x2F;16hnibp&#x2F;unity_sile...[2] https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20220716084623&#x2F;https:&#x2F;&#x2F;github.co... reply sn41 8 hours agoprevJust a side thought related to this: can there be a community supported initiative to parse what TOS documents of different companies mean, and specifically, what to watch out for in each company&#x27;s TOS vis-a-vis what is the norm in a certain industry?Right now, the \"gotcha\" power is entirely one-sided. A wiki-like approach towards documenting TOS might make the user better aware of what to really watch out for when using a particular software. reply tagawa 8 hours agoparentI think what you&#x27;re looking for is TOSDR (Terms of Service, Didn&#x27;t Read): https:&#x2F;&#x2F;tosdr.orgIt&#x27;s been going for several years and has very thorough analyses of various ToS, done by volunteers who are often legal professionals. reply ekanes 8 hours agorootparentThat&#x27;s fantastic. Thank you.If anyone is interested in supporting them, here&#x27;s the link (so many clicks later!) https:&#x2F;&#x2F;opencollective.com&#x2F;tosdr&#x2F;donate reply snvzz 5 hours agorootparentprevLove how it shows Unity&#x27;s rating going down[0] with every change.They seem to have attempted the \"boiling the frog\" strategy.0. https:&#x2F;&#x2F;edit.tosdr.org&#x2F;services&#x2F;2768 reply xp84 8 hours agoparentprevThe main problem with “what to watch out for” is that it seems like every TOS is full of the same BS so your options when you spot something to “watch out for” are pretty slim. (Unless you want to live like the Amish, which tbh is looking pretty attractive sometimes!) reply janalsncm 8 hours agoparentprevTypically that’s what a newspaper is supposed to do. With userbases larger than some countries, it could make sense. reply komali2 7 hours agoparentprevI always thought it would be cool if Steam did that for their games. Kind of like the little feature tags they already use, \"local multiplayer,\" \"controller supported,\" etc, but for EULAs (technically they already track whether there is a third party EULA).So you could just look at a game and it&#x27;d have bubbles like \"phone homes > sends your data > IP, operating system, language,\" \"not responsible for online interactions,\" etc whatever other legal nonsense they stuff in those things. There&#x27;s tens of millions of them so I assume they can be compressed into some couple thousand of rote legal \"chunks\" that can be filtered and sorted on. reply lucb1e 6 hours agoparentprev(TL;DR: this describes an old project of mine which tried to do something similar, which may be useful as inspiration for such a project. More testing is needed to say whether simple string replacements work sufficiently well, but initial results were promising. These days, LLMs are probably even more promising.)I tried making this once for employment contracts, which would string-replace difficult phrases with a version that uncle Jack on his horse would understand. This was back when a computer&#x27;s understanding capabilities barely amounted to decompose a sentence into what the subject is you&#x27;re talking about in the first place. However, the simple string replacements worked so well that I figured we should just crowdsource a dozen contracts and that should be able to kill 90% of the difficult language in any employment contract.Example replacements: \"to come to a transfer of the concerning intellectual property rights\" with \"to transfer copyright\", or \"Employee shall henceforth\" with \"you will\" (I have trouble identifying \"employee\" versus \"employer\" in texts, so replacing it with &#x27;you&#x27; and &#x27;we&#x27; is a lot easier for me to read). It also just killed lesser-known words, like replacing \"forthwith\" with \"immediately\".Example paragraph: If and insofar as Employee as part of the execution of their work activities on behalf of Employer whether or not together with others produces a work or other type of something on which intellectual property rights rest or can rest, Employee transfers these intellectual property rights already now just in case, or alternatively Employee grants an unlimited and irrevocable license and Employee lends at the first request of Employer forthwith all required cooperation to achieve a transfer of the concerning intellectual property rights. (Translated from a Dutch work contract I once received.)Its replacement: If you make something during your work for us which can be copyrighted, you always transfer the copyright and grant a license and on request you immediately help transfer the copyright.The project never went anywhere because I didn&#x27;t pursue getting other contracts and seeing how well it works before marketing it as a useful tool for others. The main unknown is whether it would scale, or if the string replacements that work well in one contract start messing things up in others. Nowadays, though, I&#x27;d probably start by telling an LLM what kind of transformation it should make and then inputting the contract; that&#x27;s probably 99% of the result in 0.1% of the time spent. reply agar 5 hours agoprevAn under-discussed aspect of this pricing structure is the number of older games that will simply be pulled from the (virtual) shelves. I&#x27;ve already seen a few and I fear more devs will follow suit.The ripples and unintended consequences of this move could really be significant for years. reply matkoniecz 5 hours agoparentSee https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37518453they can continue using old terms of service if they do not upgradeUnity is trying to hide this. reply Animats 7 hours agoprev\"He who controls the present controls the past. He who controls the past controls the future.\" - Orwell. reply noobermin 5 hours agoprevSorry but I cannot help but blame developers again. Again you idiots put all your eggs into one basket, whilst forsaking alternatives, even open source ones because \"unity is better.\" Well close gardens locking you in (or out) is always a risk and instead of calling people like me tinfoil-hat wearing lunatics for sounding the alarm for years, may be you should have heeded it.Same goes for youtube, discord, zoom, aws. Invest in the alternarives you idiots, don&#x27;t wait until it&#x27;s too late. You won&#x27;t garner any sympathy when they tighten the strings. reply Gembobo 5 hours agoprevWhen I&#x27;ve made enough money, I would like to retire and just develop a free-2-play game. No intention of it making any money. I would happily pay a few thousand dollars for a good engine for that - like Unity. But I would not want to take the risk that my free game becomes wildly successful and suddenly costs me millions. It is very unfortunate, but I will now spend the weekend to learn Godot. reply sleepybrett 7 hours agoprevI got a bill from the guys that sold me my claw hammer. Apparently I have to pay a per nail charge on top of the $40 I paid for it. reply bee_rider 8 hours agoprevBit late to close the barn doors. reply accrual 8 hours agoparentThe cat is out of the bag, so to say. reply mkoubaa 7 hours agorootparentCan&#x27;t put the booger back in the nose reply CoastalCoder 7 hours agorootparentLet&#x27;s just hope that&#x27;s an... untested claim. reply matt3210 7 hours agoprevThe older versions should be subject to those original ToS, retroactive ToS changes are poor treatment. reply sharts 8 hours agoprevTypical corporate shenanigans. What company wouldn&#x27;t do this ever? Probably none. reply downWidOutaFite 7 hours agoprevGood use for git scraping https:&#x2F;&#x2F;simonwillison.net&#x2F;2020&#x2F;Oct&#x2F;9&#x2F;git-scraping&#x2F; reply jauntywundrkind 7 hours agoprevI struggle to think of a more well defined \"burn the ships\" moment in my lifetime. This company has lost all self respect. reply awinter-py 6 hours agoprevprobably not as silently as they wanted reply pipeline_peak 6 hours agoprev“Why leading development firms are leaving Unity for Godot”“Thinking of using Unity today? Think again!”“Unity hates puppies and babies” reply paxys 8 hours agoprev [–] I hate the word \"silently\" in headlines like these. How else are the supposed to do it? By throwing a press event? reply WarOnPrivacy 7 hours agoparent [–] > I hate the word \"silently\" in headlines like these.Why hate reporting that fairly represents what they did?> How else are the supposed to do it? By throwing a press event?Sure. That&#x27;s one way to uphold the standards of full transparency about what changes are happening and when - that Unity promised. reply zeroimpl 7 hours agorootparent [–] Deleting things never makes a sound. The word silently is added entirely for the connotation that it was meant to be secret. Since such an action would never go unnoticed, it&#x27;s obvious that it wasn&#x27;t meant to be secret, so that word is clearly misplaced. If the author wanted to imply it was bad, they should just come out and say it, with a word like despicably. reply akkartik 7 hours agorootparentHere&#x27;s the blog post where they announced they were creating a github repo: https:&#x2F;&#x2F;blog.unity.com&#x2F;community&#x2F;updated-terms-of-service-an...It&#x27;s the easiest thing in the world to write another blog post announcing they&#x27;re deleting the github repo. reply snvzz 5 hours agorootparenthttps:&#x2F;&#x2F;archive.ph&#x2F;LZRFz reply dotnet00 6 hours agorootparentprevSilently doesn&#x27;t have to literally mean without sound. When referring to written mediums it just means without notice. It implies that they hoped for it to go unnoticed because that&#x27;s exactly it, if they weren&#x27;t concerned about being secretive they&#x27;d take the time to announce it somewhere. reply jibe 6 hours agorootparentWe have a word for this: metaphor! It is building the imagery of a thief silently sneaking into the GitHub offices, and stealing the terms of service. reply ncallaway 6 hours agorootparentprev [–] Have they announced anywhere that this is being deleted?As you noted, deleting something doesn’t make a sound. So if they don’t voluntarily make a sound, then they have silently deleted it. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Unity, a game development platform, quietly removed a GitHub repository that kept track of changes to its terms of service (ToS) and a clause allowing developers to utilize older versions of the game engine.",
      "The repository's deletion makes the webpage no longer accessible, with the last availability being July 16, 2022.",
      "Key changes in Unity's ToS have included the removal of a clause (in April 2023) permitting developers to use software versions of the current year as per the terms at the time of the update; this compels users to comply with all Unity's service changes, such as the recent pricing plan update charging developers for each game installation."
    ],
    "commentSummary": [
      "Unity has erased its GitHub repository that tracked amendments to its terms of service (ToS), stirring worries about transparency and trust.",
      "These retroactive changes to the ToS have upset game developers basing their work on the previous cost structure.",
      "Unity's actions have drawn questions regarding their legality and ethics, and unfavourable comparisons have been drawn to Unreal Engine that doesn't impose a similar per-install fee."
    ],
    "points": 586,
    "commentCount": 151,
    "retryCount": 0,
    "time": 1694736607
  },
  {
    "id": 37510865,
    "title": "Chromebooks will get 10 years of automatic updates",
    "originLink": "https://blog.google/outreach-initiatives/education/automatic-update-extension-chromebook/",
    "originBody": "This site uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic. Learn more OK, got it Skip to main content The Keyword Latest stories Product updates Company news Subscribe CHROMEBOOKS Chromebooks will get 10 years of automatic updates Sep 14, 2023 5 min read P Prajakta Gudadhe Senior Director of Engineering, ChromeOS A Ashwini Varma Senior Director of Engineering, ChromeOS Share When Chromebooks debuted in 2012, their affordable price tags helped make personal computing more accessible. That also made them a great fit for the education world, providing schools with secure, simple and manageable devices while helping them save on their budgets. In fact, Chromebooks are the number one device used in K-12 education globally, according to Futuresource. Plus, they’re a sustainable choice, with recycled materials that reduce their environmental impact and repair programs that help them last longer. Today, we’re announcing new ways to keep your Chromebooks up and running even longer. All Chromebook platforms will get regular automatic updates for 10 years — more than any other operating system commits to today. We’re also working with partners to build Chromebooks with more post-consumer recycled materials (PCR), and rolling out new, power-efficient features and quicker processes to repair them. And at the end of their usefulness, we continue to help schools, businesses and everyday users find the right recycling option. Let’s take a closer look at what’s coming, and how we consider the entire lifecycle of a Chromebook — from manufacturing all the way to recycling. 10 years of automatic updates Security is our number one priority. Chromebooks get automatic updates every four weeks that make your laptop more secure and help it last longer. And starting next year, we’re extending those automatic updates so your Chromebook gets enhanced security, stability and features for 10 years after the platform was released. A platform is a series of components that are designed to work together — something a manufacturer selects for any given Chromebook. To ensure compatibility with our updates, we work with all the component manufacturers within a platform (for things like the processor and Wi-Fi) to develop and test the software on every single Chromebook. Starting in 2024, if you have Chromebooks that were released from 2021 onwards, you’ll automatically get 10 years of updates. For Chromebooks released before 2021 and already in use, users and IT admins will have the option to extend automatic updates to 10 years from the platform’s release (after they receive their last automatic update). 1 Even if a Chromebook no longer receives automatic updates, it still comes with strong, built-in security features. With Verified Boot, for example, your Chromebook does a self-check every time it starts up. If it detects that the system has been tampered with or corrupted in any way, it will typically repair itself, reverting back to its original state. You can find more information about the extended updates in our Help Center, Admin console or in Settings. Quicker repair processes Many schools extend their laptops’ lifespans by building in-school repair programs. In fact, more than 80% of U.S. schools that participated in a recent Google survey are repairing at least some of their Chromebooks in-house. The Chromebook Repair Program helps schools like Jenks Public Schools find parts and provides guides for repairing specific Chromebooks, either onsite or through partner programs. Many organizations even offer repair certifications for Chromebooks. We're rolling out updates that help make repairs even faster. Our new repair flows allow authorized repair centers and school technicians to repair Chromebooks without a physical USB key. This reduces the time required for software repairs by over 50% and limits time away from the classroom. A student at Jenks Public School repairing a Chromebook 1 2 3 More energy-efficient and sustainably manufactured Chromebooks We’re making sure Chromebooks are more sustainable when it comes to both hardware and software. In the coming months, we’ll roll out new, energy-efficient features to a majority of compatible platforms. Adaptive charging will help preserve battery health, while battery saver will reduce or turn off energy-intensive processes. Adaptive charging on Chromebook will help preserve battery health 1 2 3 And last year, we partnered with Acer, ASUS, Dell, HP and Lenovo to prioritize building more sustainable Chromebooks, including using ocean-bound plastics, PCR materials, recyclable packaging and low carbon emission manufacturing processes. This year alone, Chromebook manufacturers announced 12 new Chromebooks made with PCR and repairable parts. Recyclable devices All devices reach a time when they stop being useful, especially as hardware evolves. Schools can either sell or recycle Chromebooks via their reseller, who will often collect them onsite. (Before you turn them over to a remarketer or recycler, make sure all devices are removed from management first.) The reseller or refurbisher can then provide the school with monetary or service credits, and resell, use for parts or recycle the Chromebook completely. You can also search for drop-off recycling locations near you with our global recycling drop-off points feature in Google Maps. Lowest ownership costs In addition to reducing environmental impact, Chromebooks reduce expenses for school districts — allowing them to focus more of their limited budget on other benefits for teachers and students. Chromebooks include lower upfront costs than other devices: a 55% lower device cost and a 57% lower cost of operations. Over three years, Chromebooks save more than $800 in operating costs per device compared to others. And as a preventative cost-savings measure, automatic updates combined with existing layers of security have protected Chrome from having any reported ransomware attack. With all these updates, we’re committed to keeping Chromebooks universally accessible, helpful and secure — and helping you safely learn and work on them for years to come. POSTED IN: Chromebooks Sustainability More Information Related stories SUSTAINABILITY How we can accelerate advanced clean energy technologies By Devon Swezey Sep 14, 2023 SUSTAINABILITY Google’s clean energy progress in Ireland By Ainhoa Anda Sep 05, 2023 CHROME 5 Chrome tips for college students By Yana Yushkina Aug 31, 2023 CHROMEBOOKS Take a trip to the Forgotten Realms with your Chromebook and GeForce NOW By John Maletis Aug 31, 2023 MAPS New sustainability tools help businesses and cities map environmental information By Yael Maguire Aug 28, 2023 SUSTAINABILITY How do offices run on 24/7 clean energy? By Eric Jaffe Aug 22, 2023 Follow Us Privacy Terms About Google Google Products About the Keyword Help Deutsch English English (Africa) English (Australia) English (Canada) English (India) English (MENA) Español (Latinoamérica) Français (Canada) Français (France) Italiano Português (Brasil) اللغة العربية (MENA)",
    "commentLink": "https://news.ycombinator.com/item?id=37510865",
    "commentBody": "Chromebooks will get 10 years of automatic updatesHacker NewspastloginChromebooks will get 10 years of automatic updates (blog.google) 574 points by twapi 17 hours ago| hidepastfavorite326 comments lg_rocket 17 hours agoThis is a big victory for the parents, teachers, and students who wrote to Google asking them to make this change. https:&#x2F;&#x2F;pirg.org&#x2F;articles&#x2F;why-google-announced-chromebooks-w...Google and other tech companies should continue to find ways to stop the disposability treadmill that pressures us to replace our phones and laptops in favor of newer models. With e-waste the fastest growing waste-stream in the U.S., it’s not sustainable to consume technology at this rate. This is a meaningful step toward a tech industry making products designed to last. reply samtheprogram 15 hours agoparentIronically (because related to Google), I feel that the constant churn of web development is what makes these older devices unusable.I have several devices from early to mid 2010&#x27;s, and the real reason these devices are annoying to unbearable to impossible to use (assuming Linux or Windows for security updates) is that they become very slow while just browsing the web or simply playing a video with a newer codec that has no hardware support on these older machines.In my mind, this 10 years of updates is fantastic, but also not very practical towards the end of the support cycle. Better to have the option, though. reply jwells89 13 hours agorootparentEven going as far back as Core 2 Duo&#x2F;Core 2 Quad, while running Linux or even mildly debloated Win10, as long as it’s been outfitted with an SSD it’s not immediately obvious I’m using a 15+ year old machine until I have to open a web browser. These machines are perfectly usable outside of the boundlessly hungry entity that is the web. reply didntcheck 10 minutes agorootparentIt&#x27;s also very noticeable on smartphones. My phone is as snappy with native apps as when I first bought it, but every year the ridiculous amount of CPU time and memory it takes to render a basic news article increases. The last time I did upgrade phones it was specifically to get more RAM, as I was finding that modern web pages were so hungry that switching to tab n was almost always evicting tab n-1, necessitating lots of reloads if I was cross-referencing information. And that was on a Nexus 6, not a budget phone, and only a few years after its release reply mymac 44 minutes agorootparentprevIf you aggressively (and I mean really aggressively) block any and all ads you&#x27;ll find that you can use that 15+ year old machine just fine on the web. The bloat is mostly in the marketing and advertising part of the web, not in the content part. reply noirscape 14 hours agorootparentprevGenerally speaking I&#x27;d suggest installing Firefox on older devices.It&#x27;s usually at least slightly more usable as long as you don&#x27;t have too many tabs open.I&#x27;d also recommend Firefox in general but that&#x27;s neither here or there. reply skinkestek 6 hours agorootparentOn a slightly newer machine (3 years old, 32GB memory) Firefox (or rather LibreWolf) again runs nicely with a few hundred tabs.It would probably run fine with that amount of tabs also if it had 16 or maybe 8 GB, but not together with 2 or 3 IDE instancee, Teams, Slack and ome or more applications running in debug. reply pbmonster 2 hours agorootparentI have absolutely zero issues on 10 year old hardware with 16GByte of memory. Hundreds of tabs (Firefox is really good about moving them out of memory when they don&#x27;t get used for a while - which, lets be honest, are almost all of those tabs) and the normal everyday onslaught of office software, a fat IDE, and a CAD editor.This stuff is not rocket science. It&#x27;s not even performance gaming. We worked efficiently in 2013, and it still works today. All it takes is some memory and a halfway decent SSD. reply mymac 43 minutes agorootparentprevIt bloody well should though, 32G is massive. reply robocat 13 hours agorootparentprevSlowdown can also be due to the soldered NAND flash slowly wearing out - not necessarily because the device is underpowered.Certainly the Nexus 7 (2012) had that problem (became completely unusably slow after a few years) and I am sure I have seen the same issue with other devices (Android phones and one iPad I had). reply bcrosby95 11 hours agorootparentprevMy daily driver is a system76 from 2015 and it works perfectly fine. However, I plan to replace it with a 16\" framework so I can ditch my desktop and use the laptop for gaming. reply samtheprogram 11 hours agorootparent8 year old _desktop_ computers (that have anywhere from 3 to 6x more watts hitting the CPU) are one thing. Also consider whether your machine has a dedicated GPU. A Chromebook or other budget-to-mid-range laptop from 2015 would have a different experience, although I&#x27;m sure they&#x27;re still usable.I was daily driving a 2009 MacBook Pro for a while in 2018. It was... fine, especially as a Vim user, but if someone else used my computer, they would most certainly comment or complain with normal web browsing. reply KingOfCoders 4 hours agorootparentprev(Self plug)We senselessly use RIAs for everythinghttps:&#x2F;&#x2F;www.radicalsimpli.city&#x2F; reply froh 15 hours agoparentprevtil \"PIRG\"https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Public_Interest_Research_Gro... reply mrtesthah 16 hours agoparentprevGoogle&#x27;s per-user software subscription model works to their benefit here, as it lets schools and businesses trade the money saved from a less frequent hardware upgrade schedule for additional years of Google product usage. reply waynesonfire 6 hours agoparentprevThey should have written to the schools to ban these devices. reply Zambyte 15 hours agoparentprev> Google and other tech companies should continue to find ways to stop the disposability treadmill that pressures us to replace our phones and laptops in favor of newer models.The treadmill is powered by \"intellectual property\". Abolish \"owning\" ideas, and you abolish the treadmill. Capitalism would solve this issue if it were allowed to run its course. Unfortunately we&#x27;ve let artificial monopolies run rampant in the name of \"innovation\". All that we&#x27;ve innovated is screwing people over as much as possible. reply runeks 50 minutes agorootparent> The treadmill is powered by \"intellectual property\". Abolish \"owning\" ideas, and you abolish the treadmill.How so? reply noobermin 3 hours agorootparentprevIt would be nice if the solution wasn&#x27;t \"restructure society\" because if that&#x27;s true what will really happen is nothing changes. reply LordDragonfang 13 hours agorootparentprevIntellectual property is capital. Advocating for communal ownership for the intellectual means of production is more communist than it is capitalist.The market can then fix it once you&#x27;ve removed intellectual capitalism from the equation. reply teddyh 3 hours agorootparentBitcoin is commonly held to be worth something, i.e., an asset. But there are many who argue that its “true” value is 0. Something similar to that divergence is happening here. We, as a society, have a convention, a habit, where copyrighted works, trademarks, mining rights, etc. are restricted by law to be controlled by a single legal entity. This makes these a tradable commodity. But if the law did not apply to these, they would become worthless. It is, in fact, these laws which have created this tradable commodity from nothing. Other laws could be created to do the same to any number of currently freely available things; this does not prove that these things should be covered by such laws merely because it would create a kind of property which would have value. reply freedomben 11 hours agorootparentprevThere are plenty of capitalists who would disagree by arguing that \"intellectual property\" isn&#x27;t capital because such thing isn&#x27;t even possible. Many anarcho-capitalists hold this position. I&#x27;m not versed enough to argue it in depth, but the basic premise is that you can&#x27;t \"own\" an idea&#x2F;thought, and there&#x27;s no scarcity at play with ideas so it fails the basic test for property. reply squarefoot 5 hours agorootparentI guess the system worked around that limitation by hiring people with ideas and have them sign NDAs. reply avgcorrection 12 hours agoparentprev> Google and other tech companies should continue to find ways to stop the disposability treadmill that pressures us to replace our phones and laptops in favor of newer models. With e-waste the fastest growing waste-stream in the U.S., it’s not sustainable to consume technology at this rate. This is a meaningful step toward a tech industry making products designed to last.Uh-huh. Alternatively you could go back to books, pencil and paper. reply scbzzzzz 3 hours agorootparentI am really heartbroken by your response, I always feel the world&#x2F;society should fight planned obsolescence. people&#x2F;planet over profits. and then I see a person responding with a joke (I hope you don&#x27;t mean it) when we(society) have means to make products last but some corporation chose profits against it and then greenwash with 5min mother earth videos. I know you are aware&#x2F;heard of planned obsolescence. some people complain, these corporations have to maintain and it costs them, but those people don&#x27;t realise We are gifted with wonderful opensource community like (pixelexperience os maintainers). These corporation can design it to make it easy for opensource community to maintain it after EOL.Since you are here in HN, there is high probability you are one of the geeks in industry. I hope you fight for \"planet&#x2F;people over profits\". reply bryanrasmussen 3 hours agorootparent>I am really heartbroken by your response, I always feel the world&#x2F;society should fight planned obsolescence.alternative explanation - they feel there is overuse of computing devices and that one could really go back to pencil and paper for lots of tasks. reply oldnetguy 18 minutes agorootparentI have many of my old notebooks that I wrote in as a child. The amount of paper and ink I used was a lot. Multiply that times all the children and you see how much paper is used vs. typing on a computer.Sometimes the technology route is better, now what we need to do is make it more sustainable. reply _Algernon_ 12 minutes agorootparentThere&#x27;s a lot more resources that go into 1g of computing devices than 1g of paper and writing utensils. Several orders of magnitude more. reply scbzzzzz 37 minutes agorootparentprevyeah, that might be true, with all that&#x27;s going on the news,my first thought was that the commenter is linking planned obsolescence with technology progress (sarcastically). Thanks for the perspective. There are days when I felt the urge to forgo the computing and go back 5 years when world is hopeful and not overwhelmed with computing reply walteweiss 3 hours agorootparentprev‘Uh-huh’ changes that context and makes it sarcastic. reply avgcorrection 2 hours agorootparentUh-huh. That&#x27;s about twenty extra steps compared to going back to books, pencil and paper. reply pjmlp 3 hours agorootparentprevLike most schools around the world still do today. reply tgv 15 hours agoparentprev> This is a big victory for the parents, teachers, and studentsWho should never have been using computers in the first place. There&#x27;s really no point. Using gmail and gdocs doesn&#x27;t teach anything of value. A lot of the other software is pricey and sometimes even detrimental to the school result. reply greiskul 15 hours agorootparentMy mom sent me a photo of me when I was about 8 years old, playing on the home computer. It was very expensive to have a computer in Brazil at that age, and my parents used it for their work. I used it for games. I grew up using computers. Just getting the games to run, was something that needed knowledge back then. That lead me to at my teenage years, to try out programming, cause I wanted to make some changes to the open source version of a mmorpg my brother and I played. That lead me to choosing computer science. That lead me to being a FAANG engineer. I had a leg up agaisnt every single one of my peers during all my teenage and university years. When my peers were learning to use a computer, I was already programming. When they were learning to program, I was already good at it. You say that computer for young kids have no value? Useless? That computer usage was the single most valuable thing that has happened to me in all of my life! reply robrtsql 15 hours agorootparentWhich open source version of an MMORPG was that? If you don&#x27;t mind me asking. reply greiskul 2 hours agorootparentTibia. reply rTX5CMRXIfFG 15 hours agorootparentprevYeah keep scrolling down until you see that comment from a teacher who thinks it’s a distraction.In general Just because you had a clear purpose for and interest in computers doesn’t mean it’s gonna be the same for other kids reply nonameiguess 14 hours agorootparentprevNot to be antagonistic, but this story makes it sound like your advantage came from the fact you had a computer early and your peers didn&#x27;t. If everyone gets one, there is no advantage. You&#x27;ve just created a new necessity instead. reply NavinF 14 hours agorootparentThat&#x27;s an odd takeaway but even if you&#x27;re right, people who don&#x27;t use computers suffer a massive disadvantage. Even more so if all their peers used computers. Doesn&#x27;t change the fact that GP&#x27;s \"parents, teachers, and students [...] should never have been using computers in the first place\" is nonsensical flamebait reply pb7 14 hours agorootparentprevThe advantage came from being better at it sooner in life. That’s an advantage for a productive society. reply mongol 15 hours agorootparentprevYou don&#x27;t use gdocs to learn gdocs. You use it to write an essay or something. It is a tool, like a pen. reply doctor_eval 7 hours agorootparentprevI mean you can apply this kind of comment to literally any technology. Cars, carpentry, electricity… computing is part of the fabric of society and making it totally inaccessible won’t help anyone. Imagine this:> Who should never have been using electricity in the first place. There&#x27;s really no point. Using power tools and washing machines doesn&#x27;t teach anything of value. A lot of the other appliances are pricey and sometimes even detrimental to the school result. reply Klugistiono 15 hours agorootparentprevah yes of course why should a school teach kids not relevant knowledge like computer?Perhaps to make sure that poor kids can never learn it or what is your logic behind this? reply lostlogin 15 hours agorootparentI am married to a teacher who teaches 8-9 year olds. This is her perspective from many years with that age group.Computers and screens are introduced too early. The kids just use them to zone out and mess around.The kids all forget their passwords, so login is a pain. To solve this the school made the same password for all. Some brat sets all the girls avatars to boobs. The various ways kids look up porn is a continual frustration.It doesn’t add to the learning, it makes lazy teachers lives easier. Some classes play Minecraft - I’m unclear how that’s teaching. Some use iPads to take creative photos. It’s not creative and is a waste of time and lazy.Computers have a place in schools, and it’s with older kids than 8-9 and needs to be way more prescriptive when used withThe kids all forget their passwords, so login is a pain.I really wish Google would make fingerprint sensors standard for Chromebooks. reply autoexec 13 hours agorootparentI&#x27;m not sure collecting kids biometrics makes anything better. Fingerprints are easy to find, capture, and replicate using things students have readily available like glue or gummy bears (https:&#x2F;&#x2F;it.slashdot.org&#x2F;story&#x2F;10&#x2F;10&#x2F;28&#x2F;0124242&#x2F;aussie-kids-f...). Once a fingerprint is compromised the user is screwed forever because it can&#x27;t be reset. reply fragmede 10 hours agorootparentYou have a point, but I don&#x27;t think a thirteen year old slashdot post is the best way to illustrate it. Fingerprint authentication has to be implemented correctly, or else it does face the problem you mentioned, and other ones as well. Which Apple did. You can&#x27;t steal the fingerprint out of an Apple Secure Enclave and compromise it like you&#x27;re thinking. So it would need to be done right, which Google is capable of mandating for Chromebooks.As far as Gummy bears are involved, my read of the Cisco Talos Threat Intelligence group report*, vs the competency and resources available to 13-year olds (who are not to be underestimated, tbc), is that the gummy bear trick no longer works.* https:&#x2F;&#x2F;blog.talosintelligence.com&#x2F;fingerprint-research&#x2F; reply sebzim4500 15 hours agorootparentprev>Some classes play Minecraft - I’m unclear how that’s teachingThere are definitely ways to teach within Minecraft. Redstone springs to mind, but I imagine there are others. reply oidar 13 hours agorootparentprevI would love to here about how Waldorf education impacted your and your wife&#x27;s adult life compared to the average bear. I am so close to moving so that my child can go to a Steiner school... reply computer23 12 hours agorootparentWaldorf schools are dangerous anti-vax strongholds https:&#x2F;&#x2F;www.nytimes.com&#x2F;2019&#x2F;06&#x2F;13&#x2F;nyregion&#x2F;measles-outbreak... reply lostlogin 7 hours agorootparentIt’s certainly there but my experience is that it isn’t that different to what goes on at the school (non Waldorf) where my wife teaches.That said, I’m in New Zealand, which was quite highly vaccinated and also mandated vaccinations for teachers.I rate the system for getting kids to want to learn - not just at school, after finishing schooling too. reply butlike 12 hours agorootparentprevThey really should just print the password and tape it to the inside of the lid... reply lern_too_spel 15 hours agorootparentprevWriting papers in a word processor is a far different experience from writing papers on paper. reply vel0city 5 hours agorootparentMy boss always loves it when I write the documentation for my code on a wide-ruled paper in cursive instead of in our Wiki system. reply cududa 14 hours agorootparentprevOkay, and? Hand written papers haven&#x27;t been a thing in nearly 2 decades unless it was some form of punishment. Also, teachers don&#x27;t want to have to context switch between reading each paper, adjusting to each student&#x27;s handwriting reply LordDragonfang 13 hours agorootparentHandwritten essays are still widely used in testing environments (including those arguably most important to a student&#x27;s future, AP tests). reply NavinF 1 hour agorootparentYou listed the one exception to the rule. Most AP tests (physics, math, econ, etc) don&#x27;t have that. Even the SAT essay is gone. That one AP test the final stronghold for an obsolete medium reply lern_too_spel 10 hours agorootparentprev> Okay, and?You appear to be violently agreeing with me that there is a point to giving kids computers to use gdocs. reply kstrauser 15 hours agorootparentprevThankfully. Handwriting caused me massive hand cramping until much later in life when I re-trained myself to hold a pen differently. A lot of my school essays were optimized for the fewest number of words that met the base requirements.That in itself is a useful skill, but I don&#x27;t recommend it as a coping mechanism to avoid physical pain. reply nocman 14 hours agorootparentprevYeah, writing on a word processor is a million times better (at least it is for me).Don&#x27;t get me wrong, I do think it&#x27;s bad that writing things by hand is becoming more and more rare all the time. In particular, handwritten letters and notes have an extra bit of \"personal touch\" to them that can make them very valuable to the recipient.However, from the time I was in High School to today I would never want to be required to write a paper, well, strictly on paper (from the beginning). I want all of that ability to quickly edit at my fingertips. reply com2kid 3 hours agorootparentAs someone who has physical problems writing by hand, papers I wrote by hand in school where better. Being forced to slow down gave me mental time to edit before I committed to page, by the time my pencil made a mark I was already on the 2nd or 3rd revision of what I was going to write. reply Thedarkb 1 hour agorootparentI also have physical problems writing by hand, and it led to me handing in a lot of unfinished essays after running out of time in exams. If I hadn&#x27;t gotten a special dispensation to type my exams later on, I wouldn&#x27;t really have anything to show for my education. Before my issues were diagnosed, my teachers and parents felt that it was due to a lack of effort on my part and that they could punish me into writing properly, and I feel that having access to Chromebooks is worth it if it even spares one kid from having to deal with that. reply butlike 12 hours agorootparentprevFor me it&#x27;s the lack of context switching that would get to me. I&#x27;m many years out of school (for now) but I do remember having a blank page in front of me as being somewhat inspiring. It was a new, fresh invitation to write something. Ctrl + N in a word processor just opens up a new window, and for whatever reason, doesn&#x27;t carry that same weight of inspiration. reply nickthegreek 16 hours agoprev>Starting in 2024, if you have Chromebooks that were released from 2021 onwards, you’ll automatically get 10 years of updates.Nice of them to cover a few from the last few years as well. From a school standpoint, this is a big win. I doubt many chromebooks in active use by students would even last 10 years. reply jsnell 16 hours agoparentI don&#x27;t think it&#x27;s even covering just the last few years but goes back further than that:> For Chromebooks released before 2021 and already in use, users and IT admins will have the option to extend automatic updates to 10 years from the platform’s release (after they receive their last automatic update).I don&#x27;t entirely understand why the 2021 cutoff for it being opt-in vs. opt-out is there. Maybe it&#x27;s about the \"already in use\" bit somehow, and making sure that pre-2021 models don&#x27;t continue being manufactured and sold as as new. reply highwaylights 14 hours agorootparentMy guess is that they’ve received commitments since 2021 on parts and drivers for 10 years, and don’t have those commitments prior to that date, so they’re only offering opt-in OS updates that will be under subtly different terms for liability indemnity purposes. reply silvestrov 12 hours agorootparentMight also be a case of minimal RAM&#x2F;SSD requirement and OS build using reasonable new compiler.HW might also be more standarized today, e.g. using USB internally for webcam and keyboard. reply fma 9 hours agorootparentprevThere was an article from the WSJ that wrecks Google for e-waste due to not supporting Chromebooks past 5 years. A lot of chromebooks were purchased from 2020 due to the pandemic. It&#x27;s not the date of purchase that determines obsolescence, so many were coming up to be thrown away.It would be better if Google defaults to supporting 2020, 2019 (Many purchased in 2020 were manufactured in 2019). reply nolist_policy 2 hours agorootparentIf you where cheaping out an bought Windows 10 devices in 2020, you&#x27;d also only get 5 years of support. reply yencabulator 12 hours agorootparentprevThe footnote says> For devices prior to 2021 that will receive extended updates, some features and services may not be supported.So.. they might need to rip out some problematic drivers, maybe? Like, imagine the bluetooth chip vendor not being cooperative, you get to choose to continue updates but losing bluetooth as a feature.The footnote continues> See our Help Center for details.So kudos to first one dig out the exact page they&#x27;re referring to (there&#x27;s no link). reply Zenst 10 hours agorootparenthttps:&#x2F;&#x2F;support.google.com&#x2F;chrome&#x2F;a&#x2F;answer&#x2F;6220366?hl=en That one, had link for me. reply redeeman 8 hours agorootparentprev> imagine the bluetooth chip vendor not being cooperativeno, then you tell them that if they dont play ball, they will NEVER sell a single chip to anything google ever again, and then you hire some people to reverse engineer the shit, and make it work anyway. And then you publish all about how company X is being stupid and trying to work against efforts to save the environment, how they are trying very hard to make money on peoples hardware being obsoleted before time etc.But then we realize that google themselves have bummed out to large extents with what they have permitted on android and chromebooks, so anything like this would not happen reply saagarjha 2 hours agorootparentTell me you have never worked with hardware suppliers without telling me you have never worked with hardware suppliers.Imagine that the part you want (given the constraints, etc.) has maybe two suppliers. You pick one of them and use them in your product. Then they drop support and you pull this stunt. What do you think will happen? People will storm the company with pitchforks and they&#x27;ll quietly release their full source code and promise to never do that ever again?No, what&#x27;s actually going to happen is you&#x27;re going to write a blog post, Hacker News is going to be like \"yeah I worked with that supplier once, never again\" and the average consumer is going to be like \"who is this company?\" and it will be forgotten by next week. Your reverse engineered drivers, which you of course spent millions of dollars on hiring top-tier engineers to make, will ship and the company will immediately sue you for infringement. Maybe if you did a very careful job you might be able to claim some sort of interoperatability defense and win the case years from now. Before then the court will grant an injunction preventing the sale of your device.There&#x27;s no need to tell the supplier that you will never work with them again. You&#x27;ve ruined the relationship already. And the other supplier? They probably won&#x27;t work with you either, because they&#x27;re doing the same thing and would like to keep doing it, thank you very much. Oh, you think you&#x27;re Google so people will care about your business? They&#x27;re selling 10x the volume to Samsung for their smart fridges. And now you get to I guess create an entire division to create a Bluetooth chip from scratch. By the way leadership wants to ship Pixel 9 on time so can you please have it ready by December? And it needs to support all the latest features because it would truly suck if Apple shipped Bluetooth 6.5 support before we did. reply redeeman 24 minutes agorootparentperhaps if it was something mega complex, but we are talking a bluetooth chip, hardly an unwinnable scenario for google.are you saying for real that google isnt big enough to get its way with these things? they could buy these puny suppliers, piss on every desk in their offices, and close them down, just for fun if they so wanted.and how come this \"sued into oblivion\" doesnt happen when the community writes drivers for linux in the cases where vendors do not play ball? are you saying theres absolutely no way google could pay money to make this happen?get real reply eru 8 hours agorootparentprevGood luck with that, in case the company goes out of business? reply toast0 6 hours agorootparentIn that case, it&#x27;s easy for Google to never buy from them again. reply wrs 15 hours agorootparentprevI’m wondering if that will be a paid option. That’s how the last stage of support for commercial OSes often works. reply ewoodrich 15 hours agorootparentI have an original Pixelbook (late 2017 release date) and the auto update support page [1] has been updated from June 2024 to June 2027 (with an asterisk saying it is user opt in but that&#x27;s all I can see). So at first glance it doesn&#x27;t seem to be paid.My Pixelbook doesn&#x27;t get much use anymore vs my M1 MacBook but it&#x27;s nice to know it will still be supported. It can be a handy thin client and I don&#x27;t have to worry as much about it getting stolen&#x2F;abusing at this point in its life.[1] https:&#x2F;&#x2F;support.google.com&#x2F;chrome&#x2F;a&#x2F;answer&#x2F;6220366?visit_id=... reply mholm 15 hours agoparentprevI worked an inner city public school system&#x27;s well funded IT department about a decade ago. Chromebooks had just been distributed to all students with grant money. After the first year, about 1&#x2F;5 laptops needed major repair. None of them would make it to 5 years. reply fullstop 14 hours agorootparentI&#x27;ve seen some of the chromebooks at my daughter&#x27;s school and they are beyond abused by the kids. Missing keys, screens cracked, you name it. My daughter&#x27;s is in pristine condition, though! reply ugh123 12 hours agorootparentPretty soon we&#x27;ll see kids making their own covers and protective cases for Chromebooks like we did back in the day with our textbooks reply burkaman 14 hours agorootparentprevWas it an issue with Chromebooks specifically, or just a general consequence of heavily-used shared laptops? reply Scaevolus 14 hours agorootparentChromebooks are made out of plastic, children are not very careful, and people don&#x27;t value free things they&#x27;re given. reply makeitdouble 8 hours agorootparent> Chromebooks are made out of plasticWait to see what happens to devices made of glass !Jest aside, any device lasting even two or three years in a school environment is kinda of a big deal given the daily abuse it will get. reply Gigachad 9 hours agorootparentprevWe had macbook airs at school and they were similarly destroyed because people would just carelessly chuck them around. reply dheera 13 hours agorootparentprevPlastic isn&#x27;t necessarily a bad thing, metal tends to dent and deform while plastic has some elasticity. It depends on what plastic they use. reply singron 10 hours agorootparentE.g. thinkpads usually use a composite plastic (carbon&#x2F;glass fiber), which makes them lightweight, durable, and thermally insulated from your body. Chromebooks definitely use the cheap stuff though. reply fragmede 14 hours agorootparentprevPedagogically, it would seem the answer to that would be to have the classroom be a computer lab on the first day of school, and then make the kids work (running laps, taking quizzes on having done the reading) before they earn the laptop to take home. reply wholinator2 13 hours agorootparentBut then you can&#x27;t export the work of designing and implementing homework into some faceless corporation who&#x27;s only real goal is to appeal to administrators, not teachers or kids, certainly not to match course material or learn.I&#x27;ve seen an explosion of online homework recently and it&#x27;s all confusing and either way to easy or waaayyyy too hard with very little of the partial credit and recourse that an actual person grading a paper assignment has. reply fragmede 11 hours agorootparentWhich comes from the same place that Microsoft Teams craptacularity comes from. The people buying the product aren&#x27;t the ones using it. Computerized homework could auto adjust to be not too hard and not too easy, by changing the difficulty of the next problem, based on how the student did with the previous problem. But implementing that is beyond our capabilities, apparently. reply mholm 10 hours agorootparentprevTeachers were building lesson plans around everything being on the laptop, and that all students would have one available. A student couldn’t just be restricted to not taking laptops home, because that means that student either can’t do their homework, or has to do their homework afterschool, which would require parent involvement.The sorts of kids with laptop issues were not the children with high parent involvement. reply Cthulhu_ 13 hours agorootparentprevNah, that won&#x27;t work either, kids forget about that very fast. You don&#x27;t sound like you&#x27;ve got kids yourself either. reply ethbr1 13 hours agorootparentKids aren&#x27;t all or nothing. They remember, and they also forget.The only thing that really works are repeated reminders and attentive consequences, over a sustained period of time.Also, adults don&#x27;t typically have coworkers grab their laptop and smash it because they&#x27;re disliked. replynxobject 9 hours agorootparentprevHaving participated in a one-laptop-per-student pilot program ages ago, with Fujitsu tablet convertibles that were very much plastic painted to look like brushed metal, I had problems keeping my laptop intact too - since I was constantly running between classes, sandwiching my laptop between textbooks, the case plastics didn’t last the year. But laptops were much, much heavier then. reply makeitdouble 8 hours agorootparentprevI think an individual device not making it 5 year would be fine.A big issue with chromebooks in particular: there&#x27;s many discreet models of different sizes and builds, that all require different parts, and don&#x27;t get renewed every year.One school ordering 400 12\" HP chromebooks for instance will have no guarantee to be able to order another batch 2 years later, even of an equivalent machine that could be a straight replacement.Perhaps Dell has a more stable offering given they probably understand these problematics better ? reply greggsy 14 hours agorootparentprevThey’re much more robust today reply talldatethrow 7 hours agorootparentprevI&#x27;ve been dating a 6th grade teacher in a SV adjacent town, and hearing how she attempts to teach with these things is hard to imagine for me even though I was a computer nerds as a kid.They have like 5 different saas programs&#x2F;platforms they use. They also have video platforms. Reading, library checkout, digital media, quizzes, tests, who knows.If I was a kid without add, I would for sure have it having to use that stuff at 11 years old.I&#x27;m not sure who thought doing away with pen and paper and a simple book in front of you was a good idea.I assume it was an IT&#x2F;software salesperson with ability to give kickbacks. reply kernal 13 hours agorootparentprev>After the first year, about 1&#x2F;5 laptops needed major repair. None of them would make it to 5 yearsDo you believe a Mac or Windows laptop would have been more reliable given the abuse they were subjected to? reply butlike 12 hours agorootparentI think a simple fix would be a psychological, not technical one. Simply, it&#x27;s \"their\" laptop. They don&#x27;t return it at the end of the year and if they keep it in good form, then they have one. If they don&#x27;t; they don&#x27;t. reply firecall 8 hours agorootparentThat approach doesn&#x27;t really work with children.Removing student access to technology is overly punitive and does not support the intended learning and development outcomes of attending school.To ostracize a child because they damaged their laptop is psychological abuse.We can just help them take better care of it and reinforce the reasons why and train them to do so! :-) reply partdavid 9 hours agorootparentprevAnd when they don&#x27;t, what? The workhouse? reply blackoil 8 hours agorootparentThey&#x27;ll get a crappier bulky version. reply calgoo 1 hour agorootparentSo like the office then? Your 12\" light laptop that you use for travel breaks? No worries, here is a 17\" 8 year old machine that will break your back carrying around everywhere, and cant be used on a airplane. reply mholm 10 hours agorootparentprevMildly. Some classes had MacBook airs, which were a bit more durable to the sorts of abuse that would happen, but they costed 3x as much, and didn’t take 3x the punishment. I can’t imagine a solution beyond ‘give them the cheapest thing possible’ which happens to still be chromebooks. reply sangnoir 14 hours agorootparentprev> After the first year, about 1&#x2F;5 laptops needed major repair. None of them would make it to 5 years.The second sentenxe doesn&#x27;t follow the first - it&#x27;s a flavor of Zeno&#x27;s paradox, after 5 years, you&#x27;ll be left with 4&#x2F;5 x 4&#x2F;5 x 4&#x2F;5 x 4&#x2F;5 x 4&#x2F;5 of the original batch. reply nordsieck 14 hours agorootparent> The second sentenxe doesn&#x27;t follow the first - it&#x27;s a flavor of Zeno&#x27;s paradox, after 5 years, you&#x27;ll be left with 4&#x2F;5 x 4&#x2F;5 x 4&#x2F;5 x 4&#x2F;5 x 4&#x2F;5 of the original batch.You made a mistake: it&#x27;s not that 1&#x2F;5 of the computers spontaneously break every year. It&#x27;s that 1&#x2F;5 of the students treat their computers roughly.Assuming that laptops get collected over the summer and re-distributed each year, you should actually expect that 100% of each tranche of laptops would need to be replaced every 5 years. reply TJSomething 13 hours agorootparentI don&#x27;t understand how that math could work. Assuming random assignment, the probability that a given computer is given to a one of those students is identical from year to year. reply nordsieck 13 hours agorootparent> I don&#x27;t understand how that math could work. Assuming random assignment, the probability that a given computer is given to a one of those students is identical from year to year.That&#x27;s fair. I guess, it&#x27;s more accurate to say that you&#x27;d expect a number of laptops equal to the size of the initial tranche to be destroyed after the first 5 years.Although if I was running IT, it&#x27;d definitely keep track of the \"destructive\" students and issue them the oldest equipment, in which case, we&#x27;d be back to something closer to my original statement. reply yebyen 14 hours agorootparentprevYou&#x27;re assuming that 4&#x2F;5 of the laptops remained in pristine condition. I doubt that very much. You need to take account for the ordinary wear and tear compounded together with the impact of abusive 1&#x2F;5 of users that do an excessive amount of damage (requiring a total overhaul.)And anyway, if 1&#x2F;5 of laptops needed major repairs and some of them got it, those go back into circulation. Are they still original laptops? (Ask my grandfather&#x27;s axe...) reply lambda 13 hours agorootparentprevFailure doesn&#x27;t work that way.It&#x27;s not the case that there&#x27;s a constant 1&#x2F;5 probability of failure each year. Many failure modes are based on cumulative stress&#x2F;degradation; so the probability of failure can go up over time.Some failure modes go down over time; maybe there&#x27;s some manufacturing defect, and those that have the defect fail early, while those that survive past the first year will have lower chances of failure early on.But in this kind of environment, the cumulative stresses are much more likely than the early failures. reply mholm 10 hours agorootparentThis was the case. There were no pristine laptops. Some kids are gentle with them, but things happen outside their control, kids play destructive pranks, or are just clumsy. Theoretically possible to make it to 5 years? Sure. Practically? No. reply highwind 13 hours agorootparentprevColloquial comment doesn&#x27;t need to meet mathematical rigor. He&#x27;s just saying that these laptops do not last. reply Finn_ 14 hours agorootparentprevThis assumes that 1&#x2F;5 of them break every year which is probably not the case, older laptops will break more frequently. reply gabrielhidasy 12 hours agorootparentOn the other hand, considering we are talking about kids breaking laptops, this failures are much more random, a brand new laptop is not that much more likely to survive a fall than an old one. reply Cthulhu_ 13 hours agorootparentprevAll data you have from the author&#x27;s sentence is the first year, none about the following ones, then the conclusion that none last the full five years. But you assumed it&#x27;s 1&#x2F;5th per year, every year.Anyway, it doesn&#x27;t matter much either way, even if there&#x27;s a few that survive, they will be having wear and tear to the point you wouldn&#x27;t want another student to have them (or maybe as a replacement for a broken one); you wouldn&#x27;t want some year 1 students to get a new ones while others get the year 4&#x2F;5 leftovers, they&#x27;ll resent it for sure.Second, they&#x27;ll be paid off after a few years. reply michaelmrose 14 hours agorootparentprevFor things which are effectively integers there is no paradox when your division results in a number less than one you have nothing or perhaps more accurately a probability of having 1 but any given instance in actuality has either 1 or zero. Also equipment failure isn&#x27;t a linear thing its a curve as things reach expected lifespan. For instance a battery which is nontrivial to replace has an expected number of charge cycles until your battery is so shot you can&#x27;t really use it off a charger any longer. An increasing number of mechanical hard drives fail, charger sockets start failing. Heating and cooling cycles cause progressive degradation of electronics.You absolutely could design it to last 20 years with batteries that are easy to pop out and pop in as easy as changing a double aa but your customers won&#x27;t pay a premium over a more disposable machine and indeed if your customer has a good experience over the 3-5 they actually use it for you make MORE if your hardware is designed to need replacement. reply runjake 15 hours agoparentprevnext [–]> I doubt many chromebooks in active use by students would even last 10 years.Maybe not, but we&#x27;ve been surplussing tens of thousands of otherwise-usable Chromebooks regardless, because they could not be updated to current. reply xattt 11 hours agoparentprevI am also seeing all the easy educational access around Chromebook ecosystem as a long play to secure Google Suite as a de facto desktop publishing app for the next generation.Kind of like Adobe did with easy piracy of Photoshop during the early versions. reply jamiek88 10 hours agorootparentAs did Microsoft. They cared about businesses pirating office, teenagers and for home use, not so much.Ubiquity is it’s own reward. reply moneil971 13 hours agoparentprevUnlikely to last that long, but helpful that they&#x27;ll still be supported so they can be repaired, updated, etc. -- and so they can slowly upgrade throughout a school system, rather than having to do a wholesale update every few years. reply WarOnPrivacy 10 hours agorootparent> Unlikely to last that long,That&#x27;s what I keep coming back to. I&#x27;ve known two classes of Chromebook, shelved and about to be.Most of my customers tried them. It seemed reasonable their office could use them for light web app use. Every one was in the closet within 6 months.They&#x27;re commonly slow. Printer support is a crapshoot, MFP doubly so. Corporate plugin support is a crapshoot. Whatever unforeseen new computing experience arrives, they probably can&#x27;t do it.I was at my mechanic&#x27;s shop last month. He stopped mid sentence to say &#x27;I hate this thing; I&#x27;m about to throw it thru a wall&#x27; while he&#x27;s trying to lookup parts online. It&#x27;s an Acer Chromebook and will likely be gone by my next visit. reply icegreentea2 15 hours agoparentprevI agree, but at the same time, this is an extension from 8 to 10 years. While this will surely buy time for many schools to upgrade, we can all be prepared for a re-hash of this kerfuffle in 2 years. reply ChrisLTD 15 hours agorootparentWhat laptops are we seriously expecting to last more than 10 years? I wouldn&#x27;t expect that from a MacBook Pro or a Thinkpad, let alone a $300 Chromebook. reply Marvy_a 14 hours agorootparentMy father had been using a laptop he got in 2011 (I5-2410m) until a few months ago when I bought him a mini PC with an Intel N95, he didn&#x27;t even want to switch because for the most part everything worked pretty well and why wouldn&#x27;t it? The i5-2410m is faster than the Celeron N4020, which is commonly found in many ChromeBooks and budget laptops today, and the i5-2410m wasn&#x27;t even the best mobile processor back then. Many cheap laptops today are also limited to a soldered-on 4GB of RAM, but most older laptops can be upgraded to 8GB.I have several other laptops from 2011 which are even weaker (One with I5-560M (upgraded from 380M for 6$) and other with I3-2310M) and they are also mostly fine for web browsing and office, and capable of playing 1080p YouTube video even without hardware acceleration (they don&#x27;t have VP9 decoding),with H264ify CPU usage drops to 30-40 percents.With progress in semiconductors slowing down i would expect laptops to last even longer, but with manufactures soldering down RAM and sometimes even SSD maybe that won&#x27;t be the case. Cause if i wouldn&#x27;t be able to replaces HHD with SSD and upgrade RAM on these old laptops they would be garbage long time ago. reply phoyd 14 hours agorootparentprev2008 ThinkPad t400 user here, running Ubuntu. Most business class notebooks are incredibly durable and the market offers replacement parts for 10 of 15 year old devices. A t400 battery is less than 25€ on Amazon and there are dozens of vendors. reply WarOnPrivacy 11 hours agorootparentI still lug a T430 around. Runs Win 11, hyper-v and 1 bazillion tabs across multiple browsers. reply blagie 15 hours agorootparentprevMy experience is different. My experience is that the failures are pretty random.If you expect to lose 20% of laptops each year, after a decade, about 10% of laptops will still work after a decade. It&#x27;s more if you are willing to work around issues (e.g. epoxy a crack or replace a part).It&#x27;s crappy if you need to toss otherwise good computers purely due to a software issue. reply unregistereddev 13 hours agorootparentMy opinion about 10 years ago (most likely affected by inflation now) was that a laptop costs roughly $100&#x2F;year. When I had an inexpensive $300 laptop, it lasted about 3 years. In that time I opened the case multiple times to fix problems, usually involving overheating. Towards the end the laptop was unusably slow and unable to play full-screen video. When I bought a $1000 laptop, it so far has lasted 8 years and counting. I opened it once to upgrade the memory, and once again to simply tighten screws to reduce the chassis flex that had gotten worse over time.Failures are random and infrequent if you start with good hardware. Sadly, in my experience a lot of cheap laptops do not come with reliable hardware. reply theodric 12 hours agorootparentMy buddy will be delighted to know that his $4700 MacBook is good to go until 2069 reply jules22 1 hour agorootparentprevI am using a 12 year old Thinkpad as a secondary device. I don&#x27;t see why it won&#x27;t last me another 10. It runs a responsive and quite good looking modern Linux desktop environment from a HDD and I am not even using 40% of the RAM I have on it. I am obviously not encoding 4K video, running AI or AAA games on it, but for most things that people do on computers, it&#x27;s perfectly fine.This wasn&#x27;t the case in 20-25 years ago when stuff would outdate real fast. 90% of people don&#x27;t really need new computers. reply ryukafalz 15 hours agorootparentprev> I wouldn&#x27;t expect that from (...) a ThinkpadYou wouldn&#x27;t? I have an X230 and it still works fine&#x2F;is perfectly usable, and that&#x27;s over 10 years old at this point. Why would you not expect a laptop to last more than 10 years? reply toast0 14 hours agorootparentprevIf the hardware is still working, and the battery works enough to run off AC, even a 10 year old machine is still usable for a lot of stuff.I got an Acer Chromebook C720 in 2013ish, and the dual-core Celeron 2955U (Haswell) with 4GB of RAM is still ok. The touchpad stopped working in mine, and I dunno how bad the battery is, and I installed FreeBSD for fun after ChromeOS stopped updating, but I bet it&#x27;d run ChromeOS Flex no problem. It doesn&#x27;t have the virtualization extension needed to run Android apps (not part of ChromeOS Flex anyway), but I don&#x27;t think there&#x27;s anything else missing really.I&#x27;ll probably install ChromeOS Flex on my Lenovo ThinkPad 13 Chromebook after I let the final official OS update simmer a bit more (it&#x27;s a pain to get to the firmware write protect screw), it&#x27;s a much nicer case and a little bit newer processor, but otherwise pretty close to the Acer one; and the touch pad still works. OTOH, I don&#x27;t think I can change out the storage and as I mentioned the write protect screw is hard to access. reply bandrami 10 hours agorootparentprevOh Lord. There are lots of early teens&#x2F;late oughts laptops out there being used today. Non-power-user laptop specs haven&#x27;t really changed that much since then (4G of ram and 500G of storage) and normal people don&#x27;t actually care about their processor or graphics card.I was shift lead for a SIEM team when lockdown started and the number of 2009-2011 era machines that got pulled out of a closet and brought online when remote work started was staggering. reply acdha 15 hours agorootparentprevAny Apple laptop has a good chance? My 2011 MacBook Air still works fine (as does the 2013) - the main problem is software support. You’re not playing games on that but it’s fine for email &#x2F; web &#x2F; video chat &#x2F; office docs and light coding. Each of the earlier ones I had was replaced for performance reasons, not failure other than hard drives back when spinning metal was the norm. reply nextos 13 hours agorootparentSame here. My family uses my MacBook Pro from 2009 on a daily basis, the original unibody model.Zero issues, I just had to migrate to Linux to get OS updates. It has pretty damn good reliability.Hardware can last pretty long, it is wasteful not to bother releasing software updates. reply tonyedgecombe 15 hours agorootparentprev>the main problem is software supportHopefully this announcement will put some pressure on Apple to do the same. reply acdha 14 hours agorootparentAgreed. They have the lease excuse of any vendor to say drivers are hard to support. reply KennyBlanken 13 hours agorootparentprevApple has been top of the industry in terms of length of OS&#x2F;software support for their devices.My iPhone 8 is still supported by the current iOS (no longer by 17, womp womp.) It&#x27;s nearly seven years old, is still on its first battery with about 79% capacity left and it hasn&#x27;t gone into brownout-prevention mode yet. I&#x27;m figuring that with the new iOS release it probably won&#x27;t be supported, but who knows.A few whiz-bang features aren&#x27;t supported; fancy but kinda useless webcam stuff, and newer iPhones can do more extensive object recognition in photos like bugs and plants that I think my phone won&#x27;t do.I&#x27;m not missing much aside from better cellular band support, which is kind of a wash because my phone has a qualcomm modem and Apple&#x27;s switch to intel modems didn&#x27;t go well.Even the newer cameras aren&#x27;t tempting because a generation or two after the 8 and X, they all became inflicted with Apple&#x27;s horrifically bad \"AI\" image processing that makes everything look like a watercolor painting. reply tonyedgecombe 12 hours agorootparent>Apple has been top of the industry in terms of length of OS&#x2F;software support for their devices.They have for phones but I think they could do better when it comes to the computers.Also it would be nice to have a formal statement of what their intentions are.As an example I have no idea how long my four year old Mac Mini will continue to get updates for. reply KennyBlanken 5 hours agorootparentThe average lifespan of a desktop is five years, and for a laptop, 3-5. All of you bitching about how computers older than ten years old not being supported is some massive injustice are completely divorced from reality in the marketplace.Apple provides security updates for the prior two releases, which means that damn near any Mac made in the last ten years, even without Opencore Legacy, is still receiving security updates.My 2013 Macbook Pro will run the current MacOS release with Opencore Legacy. That&#x27;s a now-ten-year-old computer running the current OS release.Anyone who uses their computer for a significant period of time, and especially to make money, who does not upgrade more quickly than every ten years, isn&#x27;t very smart. It doesn&#x27;t take long, waiting for your computer every day, before it&#x27;s costing you more in lost productivity than it would be to replace it with something newer, especially if you buy used.Claiming that a ten year old laptop, Apple or otherwise, is \"perfectly usable\" is a joke by people who clearly haven&#x27;t spent any appreciable time using current hardware, which is by every single measure enormously better. reply ryukafalz 12 hours agorootparentprev> Apple has been top of the industry in terms of length of OS&#x2F;software support for their devices.For phones and tablets, sure. For desktops&#x2F;laptops, Linux outdoes them handily. My mid-2012 MacBook Pro can run Catalina at the latest, which has been outdated for several years and unsupported since last year. But I can still install a current Linux distro on a machine of that era just fine. reply sgerenser 8 hours agorootparentThis doesn’t absolve Apple of their lack of support for older Macs, but if you want to keep using that MacBook on a more modern MacOS, take a look at Open Core Legacy Patcher. Have Monterey on my 2012 Mac mini and it’s working great. reply KennyBlanken 5 hours agorootparentprevLinux, with 3% market share, is not \"part of the industry\" for personal computers like laptops and desktops.The only valid comparison is versus Windows, because only Windows has similar capabilities and user experience. replykccqzy 14 hours agorootparentprevSoftware should not be a limiting factor in the lifespan of a laptop. If the hardware breaks and you toss it, I think that&#x27;s much more acceptable than tossing it when the hardware still works but the software is out of date. reply dharmab 3 hours agorootparentprevI still have functioning Thinkpads from 2011. They run well with SATA SSDs and minimal Linux distros, and they&#x27;re handy in the garage or on a workbench where you might not your expensive devices lying around but need to reference technical data. reply twunde 15 hours agorootparentprevAs (The Verge&#x27;s article[https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;9&#x2F;14&#x2F;23873319&#x2F;google-chromeboo...]) about this points out``` The company currently guarantees eight years of automatic updates to Chromebooks. That period, however, begins at the time when the company certifies a Chromebook, not when it’s actually in the owner’s hands. Because of the time it takes schools and businesses to purchase, receive, set up, and deploy new fleets of computers, they commonly end up getting four to five years of use out of them in practice. ```so this is really about ensuring that the laptops actually get 5 years of use before needing to be replaced. reply devjab 13 hours agorootparentprevMy MacBook Pro 2015 still trundles along just fine, and while that isn’t exactly 10 years it’s getting there. I did replace it with an M1 air for my personal use but my wife is still quite happy with it. The only thing that has needed replacement despite its hefty usage has been the power cable which fell apart at one point. Maybe it had seen too much sun? Not sure exactly, but the plastic sure disintegrated.I’m not sure I’ll ever really need to replace my M1. I could technically still work on the pro, and I mostly got the M1 because of hype, but I really don’t see what is going to increase my systems requirements in the next 20 years to be beyond what the m1 is currently doing. Maybe if I start doing more compiling on it instead of in the cloud? But I really think we’re at the point where it’ll physically break before the spec become obsolete, or alternatively, that it’ll stop getting updates from Apple. At which point I guess it can just live on with Linux. reply TJSomething 13 hours agorootparentprevI run a small convention that just needs some easy to setup web kiosks to use for checkin. We bought a lot of 30 surplus Chromebooks at $15 each a few years ago, but we&#x27;re throwing them out because of lack of support. reply jsight 13 hours agorootparentWhy not just isolate their network and keep using them? I can&#x27;t imagine this being a big risk for a convention checkin system. reply icegreentea2 14 hours agorootparentprevAs I said, the previous window was 8 years. Presumably schools are able to get end up with enough 8 year EOL laptops to have caused a storm about it. If they were manage cause that miracle, then they can probably manage to get enough of them to 10 years as well.(And yes, I know what the real answer is - they bought bargain bin laptops like 4-6 years after RTM, so they only have like 2-4 years of actual wear and tear on them. Given their carelessness the first time, I wouldn&#x27;t rule out a repeat in 2 years). reply jefftk 12 hours agorootparentprevI bought an eeepc netbook in 2008. It was my main computer until 2012, spent several years sitting on a shelf, and now is my daughter&#x27;s. It&#x27;s still doing fine, as are the two other eeepcs people in my family bought around the same time.It&#x27;s not useful for very much, since it&#x27;s way underpowered for most things you might want to do today, but it still works for typing and basic networking. reply unregistereddev 13 hours agorootparentprevMy personal laptop is a Thinkpad x250 from 2015. That is \"only\" 8 years old at this point, but I have every intention of continuing to use it for the foreseeable future. reply prmoustache 13 hours agorootparentprevI have an HP Elitebook 8460p that was released in 2011 and is still working really well.It got ssd and battery replacements + memory upgrade though. reply runjake 15 hours agorootparentprevRugged Chromebooks? I still use Acer R11s (albeit these are non-rugged) that were released in 2015 -- almost 10 years ago. reply synergy20 10 hours agoparentprevtypically a school chromebook will break in 3-4 years though reply londons_explore 39 minutes agoprevI have a Gen 1 chromecast, which was supposedly still supported till April.I can tell you, that for the last~3 years of its life, it was pretty much useless. About half of youtube videos would stutter so badly it was unusable (ie. half the time they&#x27;d be paused).Third party apps were also about only about half functional - the loading time of the app frequently meant there was a comms timeout before the app had loaded.And the chromecast itself couldn&#x27;t stay connected to any wifi network for more than about 20 mins - which obviously isn&#x27;t great for something designed for TV watching.Basically - support is useless unless they actually put enough effort in to make sure the product remains usable. reply RistrettoMike 15 hours agoprevI&#x27;ve seen a few folks here doubting that Google would actually follow through with this (which I think is a valid concern with their track record), but I&#x27;m more curious about if the hardware would hold up to 10 years of updates.Granted, not all current Chromebooks are as low-specced as they used to be, but with the way the modern web has been gobbling up system resources the last few years I can&#x27;t imagine a Chromebook actually being usable through an entire decade of bloat (whether it&#x27;s technically supported via updates or not). reply dwiel 8 hours agoparentNot only this but my Chromebook wasn&#x27;t upgradable even though the parts weren&#x27;t soldered in. I tried upgrading the Wi-Fi&#x2F;Bluetooth module but it wouldn&#x27;t grab the latest drivers so I had to stick to the old Bluetooth that barely reaches across the room. reply nolist_policy 2 hours agorootparentYou haven&#x27;t worked a lot with laptops then. Many have a whitelist for Wi-Fi cards and will refuse to boot with anything else in the slot. reply creshal 14 hours agoparentprevFor the intended education market I&#x27;d hope there&#x27;s pressure to keep the used software reasonably well optimized for the sorts of hardware it gets used on. But the react zealots have swindled the whole world economy into funding their madness for years, so who knows. reply wakeupcall 15 hours agoparentprevThat&#x27;s a very good point. If I look at my android experience, two major updates is the limit I would _want_ to update to. On devices where I could push the limits with lineage&#x2F;cyanogenos, I could perhaps extend this to 3, being pretty apparent you&#x27;re sacrificing speed for security at that point.I hope they&#x27;re going for a different track record. reply segmondy 10 hours agoparentprevmy chromebook is a c720 released in 2013. Still holding up fine. reply ygjb 14 hours agoparentprevChromeOS and Google are super creepy because of how data hungry they are. That said, one of the advantages is that if they have committed to a 10 year lifecycle, and they have a new feature that is awful on an older device for performance reasons, they have an incentive to implement a feature that executes that slow function using cloud compute resources when the device is connected to maintain their lock on customers.It really depends on how Google assesses the value prop of supporting older devices. reply fzeindl 4 hours agoprevIs there anything, maybe a legal agreement, that can stop google from breaking this promise in three years?They are not famous for longterm project management. reply Thorrez 2 hours agoparentHas there been an instance of Google promising to support something for a certain number of years then failing to do so?Disclosure: I work at Google. reply agos 42 minutes agorootparentPixel Pass, which was supposed to give you a new phone after two years, was closed 22 months after being introduced. reply hu3 20 minutes agorootparent> Can I still upgrade my Pixel device after 24 months?> Yes, you can still upgrade your Pixel device after 24 months, you just won’t be able to renew your subscription to Pixel Pass. You can purchase or finance your next Pixel device directly from Google Store or Google Fi Wireless, and you have the option to trade-in your current Pixel device towards your next device. Current Pixel Pass subscribers received $100 towards their next Pixel purchase good for 2 years, which can also be used alongside available promotions.https:&#x2F;&#x2F;support.google.com&#x2F;pixelpass&#x2F;answer&#x2F;13968577?hl=en#z... reply davidw 15 hours agoprevI&#x27;m kind of amazed at the Chromebook I got for $250. I can do pretty much everything I need with it, it has good battery life. I can even do some coding with it. I bought it as a stopgap when the Dell I ran Ubuntu on died, but since I don&#x27;t do a lot of coding these days outside of work, haven&#x27;t replaced the Dell yet. reply mark_l_watson 15 hours agoparentSame experience, except all 4 of my Mac and Linux laptops still work fine.I bought a Lenovo Chromebook two years ago for $300: includes keyboard case and pen. Linux containers work well (but a little slowly). If I were poor, I could have a good digital life with just this one device.re Google: good for them doing this! reply pjmlp 15 hours agoparentprevMy 300 euro Asus 1215B netbook bought with Linux in 2009 is still going, without sharing everything I do with Google, and survived several Ubuntu upgrades. reply davidw 15 hours agorootparentI&#x27;ve had a number of these Dells over the years, and most have been great. This one developed a problem with the wifi system that I think must be in the HW. reply robocat 12 hours agorootparentWiFi failure is common on laptops.You can often easily replace the internal WiFi card - Intel cards were usually the best bet in my experience (especially on Linux - sometimes best to replace when you buy laptop if Linux is your main OS). I have done quite a few replacements for friends.if just the Bluetooth craps out and you have a spare USB-A port then you can get cheap Bluetooth dongles. reply gabrielhidasy 12 hours agorootparentIs WiFi failure something that happens? I&#x27;ve never seen one. I did upgrade a few cards (in one to go from B to G, in other from N to AC), and I replaced a few broadcom cards with intel ones to get better Linux support, but I don&#x27;t think I ever saw a broken card. reply robocat 12 hours agorootparentI think the theory is that cards go out of spec and start connecting less reliably. I replaced a friend’s WiFi card the other day when they were about to throw the laptop out because connectivity was poor (Windows, and it wasn’t a driver issue). Obviously you also need a reliable access-point (that’s a much more difficult topic to address!). And don’t forget some secondary means to connect to laptop to the internet or you can’t download the driver! replyhn_throwaway_99 15 hours agoprevI&#x27;m still a bit salty that Google discontinued the Pixelbook and shut down the team responsible for it. I could easily see that machine becoming the perfect developer laptop with its Linux container support, and the high-end version had pretty good specs.I would love a high end Chromebook, but sadly haven&#x27;t found anything that is even close to where the Pixelbook was. reply pa7ch 10 hours agoparentThe I had the last pixelbook and loved it as a dev laptop. Although, the hardware was lacking.I have a Framework running Fedora now.I like the default window manager and shortcuts on chromeOS better then any linux distro. I hate customizing linux distrubtions and I like a laptop where I can sync my backups and start new with little time configuring. I really love the linux container&#x2F;vm integration and would like to see further polish for running VMs and containers. For me the single remaining and sort of major downside is that I can&#x27;t just read a large variety of filesystems to access backups. I can&#x27;t DD a linux ISO to pen drives either. I&#x27;d like to play with bcachefs when its out for backups but currently I can&#x27;t on chrome OS. Its so close to being such a nice base secure OS with great out of box container&#x2F;primitives, but it just feels easier and more practical to run fedora these days and chromeOS develops pretty slowly. reply nolist_policy 2 hours agorootparentYou can write arbitary images to pen drives using the \"Chromebook Recovery\" Chrome extension. reply Arcuru 12 hours agoparentprevI agree, I used a high end Chromebook&#x2F;Chromebox for several years as my local dev machine (for corp work) and it worked flawlessly. It was one of the sleekest developer experiences I&#x27;ve ever had.I use an obnoxiously custom Linux setup for my personal devices, but I still try to push anyone who will listen to try a Chromebook. reply award_ 13 hours agoparentprevI&#x27;m not sure if it would suit you or not, but I&#x27;ve been very happy with my lenovo c13 chromebook. You can get a decently spec&#x27;d chromebook-version of a thinkpad for a pretty reasonable price I think. reply technofiend 13 hours agoparentprevIt really was a sleek and elegant system. I got a friend to switch to one after him twice say \"my computer is so slow, I need to buy a new one\" only for me to find each computer filled with every browser plugin and tracking app you can think of. Even though I&#x27;m sure there are still sketchy chrome plugins, the pixelbook cut down on that sort of thing enough it&#x27;s lasted him several times longer than a new computer does. Like you, I wish Google had continue to make them. reply newuser94303 9 hours agoparentprevI have been using an Intel samsumg chromebook for my dev machine and it is great.but are the manufacturers going to provide firmware updates for 10 years?Typically, yes, at least for severe, headline-generating issues. Most others tend to be able to be worked around in Linux kernel drivers anyway (and usually better than by most vendors…), so realistically the burden will be on Google to use a 10-year LTS kernel and meaningfully support it receiving backports for various issues.> Are Intel or Mediatek going to be providing 10 years of microcode updates for the CPUs used on these devices?Intel at least seems to be providing updates for 7+ years, going by their recent microcode releases. It&#x27;s not quite as out of the ordinary as it seems, at least for the big vendors. Mediatek is another question. reply mfrw 5 hours agoprevCan folks help me a little here, please. Sure this is an awesome announcement. I now am considering to buy a ChromeBook even more seriously.My reluctance is, can Google, tomorrow (before 10 years) feel that, ahh no we are bored of this so let&#x27;s not do it. Google has a history of introducing stuff that people start to rely on and then kill it; I still wish Inbox had not been killed by Google. reply ShinTakuya 5 hours agoparentHow often have they explicitly committed to support something for that long? Not disagreeing just curious. I think the main thing is whether or not they continue the product line. As long as they keep releasing Chromebooks they&#x27;ll want to keep this commitment or else they&#x27;ll risk reputational damage. reply nolist_policy 2 hours agorootparentWell, previously they supported Chromebooks for 8 years and adhered to that. They even prolonged support for some devices during the pandemic. reply perfect-blue 5 hours agoparentprevYou’re not wrong. Google does have a history of ending products. Honestly, someone should read the fine print and figure out if there is a clause in there that actually allows they to end support whenever they feel like it. I have an inkling that there is… reply cibyr 16 hours agoprevNow we just need every model to come with its expiry date clearly labelled. reply lasftew 13 hours agoparentThis has all the devices and dates: https:&#x2F;&#x2F;support.google.com&#x2F;chrome&#x2F;a&#x2F;answer&#x2F;6220366 reply izacus 4 hours agoparentprevThe Chromebooks show that prominently in \"About\" dialog reply tantalor 12 hours agoparentprevNot a good idea when the date can be extended later. reply jiofj 15 hours agoparentprevExpiry date? It&#x27;s not like after 10 years those laptops will simply shut down. reply breakingcups 15 hours agorootparentThey might as well, since they will be insecure. reply ChrisLTD 15 hours agorootparentOld Chromebooks can run Linux, or ChromeOS Flex reply modeless 14 hours agorootparentOr they can continue to get automatic browser updates after the platform updates stop with Lacros. reply hedora 15 hours agorootparentprevDo they require the hardware drivers to be upstreamed to the Linux kernel?If not, then there&#x27;s no way to patch security issues.Also, what about the binary blobs, such as the cell and wifi chipset operating systems? reply modeless 14 hours agorootparentI don&#x27;t know but the hardware drivers are not directly exposed to the web. The biggest security issue is the web facing attack surface and Google is in complete control of that. reply Moldoteck 14 hours agorootparentprevafaik you can&#x27;t install another OS on any chromebook, some are locked reply nolist_policy 14 hours agorootparentWrong, Chromebooks aren&#x27;t locked by default. But the owner&#x2F;institution can opt-in to lock them. reply fragmede 13 hours agorootparentprevhttps:&#x2F;&#x2F;MrChromebox.tech&#x2F; would like to have a word with you. reply mcbutterbunz 14 hours agorootparentprevHow about an “Officially Supported Until:” date? reply entropicgravity 7 hours agoprevI&#x27;m just in the middle of installing Linux Mint on my 2017 Asus c202 because the updates stopped this summer. The c202 is still a fine machine for my uses. I&#x27;ve take taken the screw out of the mother board now and just reading up on how to install Linux but now ... maybe I&#x27;ll wait and see if fresh updates restart coming my way. reply whompyjaw 7 hours agoparentim extremely biased, since its my daily driver for everything, but i think Linux is the better way to go. maybe a little awkward at first if you&#x27;re fully embedded in the Google eco, but can still use most google products via browser, anyway. reply Aissen 3 hours agoprevNice ! We were at a ridiculous situation where Google had released ChromeOS Flex, which would allow installing the latest OS on devices older that many Chromebooks that went out of support (and it was marketed as such). I joked that they should release ChromeOS Flex for out of support Chromebooks, but official support is much better of course. reply londons_explore 2 hours agoprev10 years of updates, sure. But will 10 year old hardware actually be usable on the web? Especially Chromebook hardware that tends to be low end. reply theshrike79 2 hours agoprevA serious question, what do people do with Chromebooks? Especially people who use their own money to get one, instead of getting one free from school.A decent Chromebook seems to be around 1000€, with prices going up to 2000€. You can get an _actual_ laptop with that. Why get a glorified hardware browser? reply mkjonesuk 1 hour agoparentVery low bloat. And if you use mainly Google cloud based Apps you can get pretty much everything done.The only problem is the lack of a &#x27;premium&#x27; model that isn&#x27;t cheap plastic. reply freedomben 11 hours agoprevThis is fantastic! I had kind of stopped buying Chromebooks because of how short the supported life was, even though they were great for my needs and very affordable. I&#x27;ll be buying Chromebooks again.With Pixel phones getting 5 years, and Chromebooks getting 10, I&#x27;m feeling good again about recommending them to people, particularly since they are unlockable so you can install alternative ROMs to get more life. I&#x27;d really love to see them match Apple by doing at least 7 years for Pixel phones, but I&#x27;m feeling really good about the direction we&#x27;re going! reply jimmar 14 hours agoprevLonger support is good. I hope schools don&#x27;t see that 10 years of support as meaning that the Chromebooks they buy will have 10 years of useful life. My daughter has a 3-year old Chromebook issued by her high school that struggles to load web pages. reply yjftsjthsd-h 14 hours agoparentAt least this means that the OS is less likely to be the constraint. reply Zuiii 16 hours agoprevThey should also guarantee that OEMs will not leave the Chromebook bootloader locked once those 10 years of automatic updates are over and they should release the source code for their drivers. My android is useless after 3 years because google doesn&#x27;t do what microsoft does with x86 OEMs. reply pgeorgi 15 hours agoparentThe only one who can lock the boot process is the device owner: school&#x2F;company laptops might be locked down and they might not bother resetting that.By default it&#x27;s locked-but-user-unlockable (presence test, user data removal), with various levels of trade-offs between \"degrees of freedom to replace stuff\" vs. \"ability to recover without external hardware tools\". When user and owner differ (e.g. schools or companies), the owner gets to decide.As for source code, go wild: https:&#x2F;&#x2F;review.coreboot.org&#x2F;plugins&#x2F;gitiles&#x2F;coreboot&#x2F;+&#x2F;refs&#x2F;... reply popchat 16 hours agoparentprevGoogle Pixel phones have unlocked bootloaders[0] (see the excellent projects GrapheneOS[1] and Calyx[2]), so if that&#x27;s something that is important to you (it&#x27;s good that it is), then you should purchase your next phone with that in mind.0. usually, but not always. Sometimes you need to install, for example, a T-mobile app for some previously GoogleFi phones in order for the phone to check with T-mobile&#x27;s servers and get unlocking approved, but the phone can be purchased unlocked directly from Google as well.1. https:&#x2F;&#x2F;grapheneos.org&#x2F;2. https:&#x2F;&#x2F;calyxos.org&#x2F; from https:&#x2F;&#x2F;www.calyxinstitute.org&#x2F; reply Projectiboga 13 hours agorootparentGraphene only supports the same time frame as Google, 3 years from launch for the #a series models. Calyx goes about an extra year. I really got hosed by not reading the fine print, I just bought Google 5a, and it runs out of support in a year now, its a 5G phone, I&#x27;ll have to use Calyx or Lineage OS to go beyond. I wish I had just gotten an LG V50 or V60 and gotten better audio quality and a nicer screen. reply p1mrx 15 hours agorootparentprevSometimes there is no known way to unlock a Pixel bootloader: https:&#x2F;&#x2F;jacobhall.net&#x2F;2022&#x2F;01&#x2F;29&#x2F;000177&#x2F; reply tonfa 16 hours agoparentprevAre chromebooks bootloader locked? reply londons_explore 16 hours agorootparentNo. Chromebooks have all open source drivers, and you can compile it yourself if you like. The only closed source bits are third party code (usually due to patent reasons - eg. mp3 codecs).If you want to run all your own stuff, you do need to have the machine in dev mode, which will warn you on every startup. reply colecut 15 hours agorootparentThat warning screen is the most awful thing...Not because of the warning, but because if you press Spacebar on that warning screen (which is the only key that the screen suggests you might want to press), it re-enables OS Verification, removing your ability to boot anything but ChromeOs until you run some more terminal commands do set it all up again..If at any point a child, or pretty much anyone else besides you turns on your laptop, this is guaranteed to happen.I hope they had good reason for making this design decision because for me it was one of the most frustrating aspects of trying boot outside of ChromeOS reply pgeorgi 15 hours agorootparentIt&#x27;s to ensure that you, the user, know when the boot process has changed substantially, and that you have a simple way to get back into familiar territory.If you want to get rid of Chrome OS and all its user protection measures entirely, that&#x27;s possible with official and relatively standardized means. The open source firmware community provides documentation and tested firmware images for that (of course: no warranty), most prominently https:&#x2F;&#x2F;mrchromebox.tech&#x2F; reply colecut 15 hours agorootparentBut I don&#x27;t want to get rid of it.ChromeOS tends to provide the best experience for anything that ChromeOS is able to do.I want to be able to choose at bootup, and not have that configuration be \"easily obliterated\" as someone else described. The warning is fine. The way back is a bit too simple... reply Steltek 15 hours agorootparentprevI went to a lot of trouble to set up my kid&#x27;s Chromebook in unlocked mode with Linux+Steam installed. It all got obliterated by one naive keypress after it ran out of battery and rebooted. That self-destruct button is ridiculously easy to push. reply colecut 15 hours agorootparentYes, I had nearly the same exact experience. reply hedora 15 hours agorootparentprevDo OEMs still release modified versions of their Chromebooks with a standard BIOS?I used to have an x86 Acer \"CloudBook\" that shipped with Windows and a nice EFI bios. It boots Linux well, and even has an option to disable the windows trusted boot keys, and to use user installed (i.e., grub) keys instead. The hardware seems to be designed to run chrome os, except that it has a standard keyboard.My only complaint is that I&#x27;d like a higher-end version of it. replysandGorgon 4 hours agoprevhow is Google doing this ? i mean as opposed to Apple, ChromeOS has to support a much wider variety of chipsets&#x2F;motherboards&#x2F;wifi drivers, etc.how is Google guaranteeing 10 years of updates on Linux while supporting newer and newer models every year.In 10 years - Google&#x27;s supported chromebook devices would exponentially blow up (versus Apple).How are they pulling this off ? reply nolist_policy 1 hour agoparentThere is a small selection base boards prescribed by Google, that a manufacturer can built a Chromebook around. That base board covers pretty much everything AFAIK, except for touchpad, touchscren, pen input, etc.I count around 40 base boards[1] that are still supported today, one year from now it&#x27;s 37, two years from now it&#x27;s 31. And you see much fewer variety in newer devices.The x86 boards are very similar, you&#x27;ll often have the same board just with a newer CPU&#x2F;SoC. It just means you have one more device in the regression test lab, it won&#x27;t necessarily create more work.[1] https:&#x2F;&#x2F;www.chromium.org&#x2F;chromium-os&#x2F;developer-information-f... reply bitigchi 12 hours agoprevWe are yet to see for how long Apple is going to support their Apple Silicon machines, but this definitely sets a precedent for Apple. It would be really shameful if they go the iPhone route and cut support after 6 years of updates.On the other hand, Apple is still selling the iMac with a 2020 chipset, so we could say that they look like they are committed to providing updates. I hope they wouldn&#x27;t just cut off support in 3 years time. reply JohnTHaller 12 hours agoparentApple has typically supported Mac hardware for about 7 years from introduction for a while now. That is provided you&#x27;re updating to the last supported version of macOS for it and then all security updates. I&#x27;d be surprised if they changed this much either way for Apple Silicon.One issue is that Apple never tells you when they end of life a given version of macOS officially, so you&#x27;re left guessing a bit. reply kramerger 16 hours agoprevSerious question:Is the chromebook division run by an entire different company? They are great exactly where Google has otherwise failed. reply crazygringo 16 hours agoparentI&#x27;m not sure what you mean. When Google shut down Stadia they refunded everybody everything, for instance.Google generally seems to treat its users pretty well. As long as you can accept that free accounts don&#x27;t come with any kind of customer service or recourse. And that it&#x27;s going to shut down products that don&#x27;t ultimately contribute to its bottom line, since it&#x27;s a business. reply ChicagoBoy11 15 hours agorootparentWait... if you got a stadia&#x2F;bought games, etc., all of it got refunded when they folded?! reply sangnoir 14 hours agorootparentYes - all Stadia purchases were fully refunded - software and hardware (Chromecast and controllers).Google also released a firmware update for the controllers allowing them to be used as generic Bluetooth controllers. It was the best Google product sunset I have experienced. reply AuthError 15 hours agorootparentprevYes also i think they sent out update for controllers so it can be used outside of stadia reply pgeorgi 16 hours agoparentprev\"Certain behaviors of a corporation look very different from how they usually seem to behave\" is most easily explained by:{Google, Microsoft, Apple, Intel} is big enough so that {insert product here} operates a lot like an independent company, just with lots of automatic mind share (although that can backfire when the parent brand is devolving), access to top-tier lawyers, marketing, sales, etc people and practically infinite runway (as long as the bosses like what you do). reply therealmarv 13 hours agoparentprevProbably they are close to Google Chrome. Google is very good with development with Chrome IMHO. reply jeffbee 12 hours agoparentprevChromeOS always seemed to me an expression of the main stem of Google culture. Android, if that is the distinction you were drawing, is from an alien planet. reply kweingar 2 hours agorootparentThat’s an interesting perspective. When I think of core Google culture, the first thing that comes to mind is the mission statement, “to organize the world&#x27;s information and make it universally accessible and useful”.If search is the root, then the branches would be maps, street view, books, earth, scholar, patents, etc. Just cataloguing and indexing everything there is. Truly mind-blowing projects, each one of these. Hardware (and some of the other PAs) seem somewhat tangential to this core idea.What comes to mind for you when you think of Google culture, and what parts of that do you see in ChromeOS? reply throwaway128128 10 hours agoprevI wonder what changed that allowed them to have a better update policy. AFAIK the time horizon was capped because SOC vendors fail to update drivers for legacy products. reply stewbrew 6 hours agoprevBut don&#x27;t expect them to check whether the Chromebooks are still useful after an update. E.g., the original Lenovo duet turned into an oversized paperweight after one of their later updates. reply mato 13 hours agoprevCool, can we get the same for Pixel4+?Ta. reply tedchs 10 hours agoprevThis is a big relief. I have a Samsung Chromebook Plus that still works fine and I like the form factor. I recently got notified that ChromeOS updates were EOL, so I reformatted it with PostmarketOS, an Alpine Linux derivative. Installing was easy, and I want to like it, but it almost works. It has no sound, won&#x27;t play videos, and the touchscreen behavior is janky. reply acyou 5 hours agoprev... And after 10 years, Google will intentionally structure their updates to force-sunset hardware, even if the hardware is still going strong. reply 76 more comments... Applications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google plans to automatically update all Chromebooks for a decade, making it the only OS to commit to such long-term updates, which will improve the security, stability, and device longevity.",
      "The tech giant is collaborating with its partners to construct Chromebooks using more recycled materials and is introducing power-efficient features and expedited repair methods.",
      "Google's strategy emphasizes the full lifecycle of a Chromebook, from its production to recycling, showcasing a commitment to sustainability and user convenience."
    ],
    "commentSummary": [
      "Google has decided that Chromebooks will automatically update for up to 10 years in a bid to minimize electronic waste.",
      "There has been debate on the online forum about the security of fingerprint authentication, the durability of Chromebooks in educational settings, and potential challenges Google might encounter with hardware suppliers.",
      "Despite appreciating the extended support for Chromebooks, users have expressed worries about hardware limitations and inadvertent Operating System (OS) Verification re-enablement."
    ],
    "points": 574,
    "commentCount": 326,
    "retryCount": 0,
    "time": 1694708057
  },
  {
    "id": 37508471,
    "title": "PostgreSQL 16",
    "originLink": "https://www.postgresql.org/about/news/postgresql-16-released-2715/",
    "originBody": "Home About Download Documentation Community Developers Support Donate Your account 14th September 2023: PostgreSQL 16 Released! Quick Links About Policies Feature Matrix Donate History Sponsors Servers Latest News Upcoming Events Past events Press Licence PostgreSQL 16 Released! Posted on 2023-09-14 by PostgreSQL Global Development Group PostgreSQL Project September 14, 2023 - The PostgreSQL Global Development Group today announced the release of PostgreSQL 16, the latest version of the world's most advanced open source database. PostgreSQL 16 raises its performance, with notable improvements to query parallelism, bulk data loading, and logical replication. There are many features in this release for developers and administrators alike, including more SQL/JSON syntax, new monitoring stats for your workloads, and greater flexibility in defining access control rules for management of policies across large fleets. \"As relational database patterns evolve, PostgreSQL continues to make performance gains in searching and managing data at scale,\" said Dave Page, a PostgreSQL Core Team member. \"PostgreSQL 16 gives users more methods to scale-up and scale-out their workloads, while giving them new ways to gain insights and optimize how they manage their data.\" PostgreSQL, an innovative data management system known for its reliability and robustness, benefits from over 25 years of open source development from a global developer community and has become the preferred open source relational database for organizations of all sizes. Performance Improvements PostgreSQL 16 improves the performance of existing PostgreSQL functionality through new query planner optimizations. In this latest release, the query planner can parallelize FULL and RIGHT joins, generate better optimized plans for queries that use aggregate functions with a DISTINCT or ORDER BY clause, utilize incremental sorts for SELECT DISTINCT queries, and optimize window functions so they execute more efficiently. It also improves RIGHT and OUTER \"anti-joins\", which enables users to identify rows not present in a joined table. This release includes improvements for bulk loading using COPY in both single and concurrent operations, with tests showing up to a 300% performance improvement in some cases. PostgreSQL 16 adds support for load balancing in clients that use libpq, and improvements to vacuum strategy that reduce the necessity of full-table freezes. Additionally, PostgreSQL 16 introduces CPU acceleration using SIMD in both x86 and ARM architectures, resulting in performance gains when processing ASCII and JSON strings, and performing array and subtransaction searches. Logical replication Logical replication lets users stream data to other PostgreSQL instances or subscribers that can interpret the PostgreSQL logical replication protocol. In PostgreSQL 16, users can perform logical replication from a standby instance, meaning a standby can publish logical changes to other servers. This provides developers with new workload distribution options, for example, using a standby rather than the busier primary to logically replicate changes to downstream systems. Additionally, there are several performance improvements in PostgreSQL 16 to logical replication. Subscribers can now apply large transactions using parallel workers. For tables that do not have a primary key, subscribers can use B-tree indexes instead of sequential scans to find rows. Under certain conditions, users can also speed up initial table synchronization using the binary format. There are several access control improvements to logical replication in PostgreSQL 16, including the new predefined role pg_create_subscription, which grants users the ability to create new logical subscriptions. Finally, this release begins adding support for bidirectional logical replication, introducing functionality to replicate data between two tables from different publishers. Developer Experience PostgreSQL 16 adds more syntax from the SQL/JSON standard, including constructors and predicates such as JSON_ARRAY(), JSON_ARRAYAGG(), and IS JSON. This release also introduces the ability to use underscores for thousands separators (e.g. 5_432_000) and non-decimal integer literals, such as 0x1538, 0o12470, and 0b1010100111000. Developers using PostgreSQL 16 also benefit from new commands in psql. This includes \\bind, which allows users to prepare parameterized queries and use \\bind to substitute the variables (e.g SELECT $1::int + $2::int \\bind 1 2 \\g). PostgreSQL 16 improves general support for text collations, which provide rules for how text is sorted. PostgreSQL 16 builds with ICU support by default, determines the default ICU locale from the environment, and allows users to define custom ICU collation rules. Monitoring A key aspect of tuning the performance of database workloads is understanding the impact of your I/O operations on your system. PostgreSQL 16 introduces pg_stat_io, a new source of key I/O metrics for granular analysis of I/O access patterns. Additionally, this release adds a new field to the pg_stat_all_tables view that records a timestamp representing when a table or index was last scanned. PostgreSQL 16 also makes auto_explain more readable by logging values passed into parameterized statements, and improves the accuracy of the query tracking algorithm used by pg_stat_statements and pg_stat_activity. Access Control & Security PostgreSQL 16 provides finer-grained options for access control and enhances other security features. The release improves management of pg_hba.conf and pg_ident.conf files, including allowing regular expression matching for user and database names and include directives for external configuration files. This release adds several security-oriented client connection parameters, including require_auth, which allows clients to specify which authentication parameters they are willing to accept from a server, and sslrootcert=\"system\", which indicates that PostgreSQL should use the trusted certificate authority (CA) store provided by the client's operating system. Additionally, the release adds support for Kerberos credential delegation, allowing extensions such as postgres_fdw and dblink to use authenticated credentials to connect to trusted services. About PostgreSQL PostgreSQL is the world's most advanced open source database, with a global community of thousands of users, contributors, companies and organizations. Built on over 35 years of engineering, starting at the University of California, Berkeley, PostgreSQL has continued with an unmatched pace of development. PostgreSQL's mature feature set not only matches top proprietary database systems, but exceeds them in advanced database features, extensibility, security, and stability. Links Download Release Notes Press Kit & Translations Security Page Versioning Policy Follow @postgresql Donate PoliciesCode of ConductAbout PostgreSQLContact Copyright © 1996-2023 The PostgreSQL Global Development Group",
    "commentLink": "https://news.ycombinator.com/item?id=37508471",
    "commentBody": "PostgreSQL 16Hacker NewspastloginPostgreSQL 16 (postgresql.org) 535 points by pella 20 hours ago| hidepastfavorite72 comments data_ders 20 hours agoanytime a huge multi-decades-old FOSS project lands a milestone, I can&#x27;t help but equate it to something like a moon landing.So much (unpaid) work and thought goes into stewarding open software. Kudos to the whole team. Software infra is just as important as bridges and roads -- here&#x27;s hoping we can fund it at least as well, for humanity&#x27;s sake. [1][1]: https:&#x2F;&#x2F;www.fordfoundation.org&#x2F;work&#x2F;learning&#x2F;research-report... reply simonw 18 hours agoparentPostgreSQL is also one of the most impressive projects out there in terms of being community maintained, as opposed to many large FOSS projects which have some kind of corporate backing employing the majority of the core team. reply dekobon 18 hours agorootparentIsn&#x27;t the good part of the core team part of EnterpriseDB? reply lfittl 16 hours agorootparentYou can see a break-down of the core team and major contributors here, as well as their current company affiliation: https:&#x2F;&#x2F;www.postgresql.org&#x2F;community&#x2F;contributors&#x2F;(and as noted in the other comment, whilst EDB certainly makes important contributions, they are one of many) reply h0l0cube 13 hours agorootparentTIL Julian Assange was a contributor to PostgreSQL reply brand 17 hours agorootparentprev3 of 7 work at EDB, and the core team doesn’t drive the project roadmap. And EDB hackers fail to get patches in all the time, just like everyone else :) reply bdcravens 16 hours agoparentprevIsn&#x27;t the work in large projects often done by those paid by their employers on \"company time\"? For instance Bruce Momjian by EDB. reply game_the0ry 15 hours agoparentprevAgreed - just think about the billions, possibly trillions of economic value (jobs, shareholder value, utility to society, etc) that a project like postgres or ruby on rails has created. reply brainzap 16 hours agoparentprev16 contains paid work reply riku_iki 18 hours agoparentprevThey significantly increased major versions frequency, transition from 9 to 10 took 7 years, and now they release major version every year. reply clarkdave 18 hours agorootparentThey just changed the versioning scheme; it used to be that e.g. 9.3 -> 9.4 was a major version (i.e. can&#x27;t be upgraded in-place). Starting with PG 10 major versions are now 10 -> 11, etc. I don&#x27;t believe the major release cadence itself changed that much reply eestrada 16 hours agorootparentIt seems like they fell more inline with Semantic Versioning when that format came in vogue. Semantic Versioning is what most devs expect now; it makes sense to communicate the version in a format that has a broadly understood meaning for devs. reply pella 17 hours agoprevRelease artworks : https:&#x2F;&#x2F;wiki.postgresql.org&#x2F;wiki&#x2F;Artwork#16_.282023-09-14.29 reply whalesalad 16 hours agoparentwoah til there is release art (did openbsd start this trend?) reply pella 20 hours agoprevRelease Notes: https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;16&#x2F;release-16.html reply pritambaral 20 hours agoprevPrevious discussion from Beta 1 announcement: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36070261 (154 points, 60 comments, 3 months ago) reply datadrivenangel 20 hours agoprev> Add SQL&#x2F;JSON constructors and identity functionsThis will be a nice quality of life addition! reply MuffinFlavored 19 hours agoparent> SQL&#x2F;JSON constructorsLike these?> Adds SQL&#x2F;JSON constructors, including JSON_ARRAY(), JSON_ARRAYAGG(), JSON_OBJECT(), and JSON_OBJECTAGG().Not sure what SQL&#x2F;JSON identity functions relate to reply zkomp 19 hours agorootparentidentity probably refers to the ’IS’:SELECT js, js IS JSON OBJECT \"object?\", js IS JSON ARRAY \"array?\", js IS JSON ARRAY WITH UNIQUE KEYS \"array w. UK?\", js IS JSON ARRAY WITHOUT UNIQUE KEYS \"array w&#x2F;o UK?\" FROM (VALUES (&#x27;[{\"a\":\"1\"}, {\"b\":\"2\",\"b\":\"3\"}]&#x27;)) foo(js); reply paulddraper 16 hours agoprevI am so glad psql got \\bind.What good does EXPLAIN do if you&#x27;re not running the same (parameterized) queries that your app does? Very cool. reply ptrwis 15 hours agoprevI can&#x27;t wait for direct I&#x2F;O (now behind debug_io_direct setting). reply esaym 14 hours agoparentCurious what your use case is for wanting direct_io? Every DBA I&#x27;ve ever worked with when setting up a new database, the first thing they want to do is enable direct io. My worst experience was with IBM DB2 mounted over NFS talking to netapp. Performance complaints would come from customers and land on the CEO&#x27;s desk. He&#x27;d go to the software team and tell them to fix it. They&#x27;d say the DB is slow. Then he&#x27;d go to the DBAs and tell them to tune the DB. They&#x27;d say there&#x27;s nothing more to do, we need faster disks. So he&#x27;d end up in front of me on the sysop team asking if we had any faster disks laying around (we didn&#x27;t and buying more wasn&#x27;t in the budget).Since it was NFS, you could just use tcpdump and watch what DB2 was doing on the wire. It was happily poking away sending and receiving packets all 1K in size (the current configured DB block size) with peak read and and write speeds of about 11MB&#x2F;s. Since the DBAs didn&#x27;t want to change settings on a production DB, I set up a testing environment, begged them to play with the direct io and block size settings on this new instance and figure out the best performance. When I checked back days later, it was set up exactly the same, \"we follow best practices, use 1K block size and force direct io\".I ended up creating a VM under the guise of \"we need a data warehouse\" with 1&#x2F;4 the cpus and ram as the DB2 machines and installed postgresql 9.2. Did a minimum amount of tuning, mostly just turning off fsync for WAL writes, then spent a week filling it up with 5TB of data and 15 billion rows from the production DB. Ran one of our analytic queries that had grown to taking 30 hours on DB2, it ran in 6 hours. The packet sizes over NFS were 32-64MB in size and getting peak speeds of 180-220MB&#x2F;s on the wire. reply mattashii 14 hours agorootparent> Did a minimum amount of tuning, mostly just turning off fsync for WAL writesThat is not something I would suggest to people on production systems, as that would give you a good chance of data loss when the system halts. So, out of interest, were there any circumstances why turning off WAL fsync was considered a good choice in your situation? reply esaym 13 hours agorootparentI probably meant to say \"synchronous_commit\", which is how data is written to disk from the WAL. If you want full data guarantees, with regular hard drives, you&#x27;d be looking at less than 200 transactions per second. You set synchronous_commit to off, and suddenly you can do 10k transactions per second. You can tune when the WAL gets flushed to disk based on time and&#x2F;or size. So you can set the amount of recent data loss you are comfortable with.From the docs: \"setting this parameter to off does not create any risk of database inconsistency: an operating system or database crash might result in some recent allegedly-committed transactions being lost, but the database state will be just the same as if those transactions had been aborted cleanly. So, turning synchronous_commit off can be a useful alternative when performance is more important than exact certainty\" reply guenthert 2 hours agorootparent> If you want full data guarantees, with regular hard drives, you&#x27;d be looking at less than 200 transactions per second.That sounds like an anecdote from the time before SSDs.> \"setting this parameter to off does not create any risk of database inconsistency: an operating system or database crash might result in some recent allegedly-committed transactions being lost, but the database state will be just the same as if those transactions had been aborted cleanly. \"If your application is told that the transactions were committed, but your DB actually hasn&#x27;t, you got a problem, methinks. reply Tostino 13 hours agorootparentprevRe-read their post. It was a secondary system setup to just run these analytics which were loaded from the production system. No issues if the whole machine had to be rebuilt. reply garenp 13 hours agorootparentprevThe 1k packets you saw probably correspond to the default block size being used for the DB, that is a vestige of using spinning disks. That you were using NFS or any kind of networked filesystem is what I&#x27;d say is a performance hostile environment. Did no one think of just not using NFS? reply esaym 13 hours agorootparentThis was before 2012, AWS did not exist. The company had to find rackspace in a data center. Which we couldn&#x27;t. One of the funding customers \"loaned\" us a couple of slots in their on premise data center which fit only a bladecenter and single netapp. NFS had advantages, you could dynamically resize live mount points, etc. Plus as I mentioned, using postgresql did away with our performance issues. reply ptrwis 14 hours agorootparentprevI&#x27;m thinking lower resource usage (no double caching of data), shorter path to data so I would expect fewer bad things might happen during commit, and better performance in terms of transactions per second. Otherwise, I can&#x27;t explain it any better than one of the lead developers himself: https:&#x2F;&#x2F;www.postgresql.org&#x2F;message-id&#x2F;20210223100344.llw5an2... reply mattashii 13 hours agorootparentThe new debug_io_direct flag only triggers direct IO in very limited cases, and is only tangentially related to the AIO patchset discussed in that thread.Note that the documentation on the config flag explicitly warns about not using it in production:> Currently this feature reduces performance, and is intended for developer testing only.Also note that very few things will actually do IO during commit - the only IO that I can think of are 1.) the WAL-logging of the commit (often small, a few 100 bytes at most), and 2.) replying to the COMMIT command (10s of bytes at most). It is quite unlikely that this will see much performance benefit from IO_DIRECT without further infrastructure inside PostgreSQL around io_uring and other async kernel IO apis. reply ptrwis 13 hours agorootparentI know, but it&#x27;s still nice to see progress in this area. Even PG17 would probably be too early to expect this work to be finished. reply esaym 13 hours agorootparentprevYes when direct io is brought up, it is usually followed with the \"double buffering\" argument. That is valid, but only if your disk speeds are well above 1,000MB&#x2F;s. Outside of hardware like that, you are always going to be waiting on disk.From Linus himself[0]\"The thing that has always disturbed me about O_DIRECT is that the whole interface is just stupid, and was probably designed by a deranged monkey on some serious mind-controlling substances\"[0] https:&#x2F;&#x2F;lkml.org&#x2F;lkml&#x2F;2002&#x2F;5&#x2F;11&#x2F;58 reply ptrwis 12 hours agorootparentHave you read the entire thread you linked? People explained to Linus why direct IO is important to them. Besides, it&#x27;s 20 years old and there were even no SSDs back then. The lack of direct IO in PG was one of (one of) the reasons why Uber moved to MySQL (https:&#x2F;&#x2F;www.uber.com&#x2F;en-PL&#x2F;blog&#x2F;postgres-to-mysql-migration&#x2F;, \"The Buffer Pool\" Section). With buffered IO you will likely store a lot of the same data in memory twice- once in DB&#x27;s memory and then in page cache. Now you can just give the memory used by page cache directly to DB, because it knows better what and when it needs. reply esaym 7 hours agorootparentThe thread is large, maybe I read the whole thing at one time, but the point of it is literally someone asking why using direct io is slower. That is the point I make, you can&#x27;t just enable direct io (which by passes all the logic to speed up reads and writes) and expect increased performance without a lot of extra up front work.But back to my first question, I am still curious what your workload is that you feel will benefit from direct io :) reply infamouscow 8 hours agorootparentprevI suspect Linus&#x27; position has radically changed with io-uring and proliferation of NVMe storage devices.I use io-uring with O_DIRECT at work and the performance graphs of TLB pressure are beautiful. replybrianwawok 17 hours agoprevAnyone know more about the \"vacuum\" improvements?To make my database fast, I often have to do a vacuum full on some key tables. Which is basically a freeze all access to the table, and copy byte by byte to a new physical file. So as your data size doubles, the vacuum full time doubles. Have a table that is so big I basically can&#x27;t vacuum full it anymore (in an acceptable amount of downtime). reply jskrablin 15 hours agoparentMaybe try pg_repack? reply ellisv 17 hours agoparentprevI’m not familiar with the VACUUM changes but the situation you’re describing suggests something is wrong with the table definition or database configuration. reply brianwawok 17 hours agorootparentHow do you figure?Postgres docs are quite clear. Table space is not reclaimed without a vacuum full. So delete a column in a big table? you are storing that data forever. reply _bohm 16 hours agorootparentNot quite true. Regular VACUUM marks dead tuples as available for re-use, so the system can overwrite the dead tuples with fresh ones after a VACUUM. VACUUM FULL completely rewrites and repacks the table.https:&#x2F;&#x2F;www.postgresql.org&#x2F;docs&#x2F;current&#x2F;sql-vacuum.html reply jeff-davis 14 hours agorootparentprevPostgres has a free space map, which allows it to reuse the space of deleted tuples for new or updated tuples created in the same table. If no new&#x2F;updated tuples are created in the table after the DELETE, you have fragmentation, which means the file remains large so the space can&#x27;t be used for other tables (or other unrelated data residing in the same filesystem).The nature of fragmentation means that you need to move a lot of data around to actually make that file smaller. In Postgres, that&#x27;s typically done with VACUUM FULL. The problem of fragmentation is not unique to Postgres, it&#x27;s a fundamental issue; but perhaps other systems are able to move the data around in a less disruptive way.If you just delete a column, that creates a different type of fragmentation within the tuples themselves (e.g. you delete the middle column, and the tuple itself doesn&#x27;t shrink, it just ignores that middle column). You are right that can be a problem. Postgres could be improved to rewrite tuples to eliminate the wasted space from deleted columns in the middle, which would probably be (computationally) worth it to do if it&#x27;s already performing cleanup on the page. reply ellisv 16 hours agorootparentprevIf rewriting the table is part of a regular workflow, then database configuration can play a significant role in its performance. However I still contend that rewriting tables regularly is an anti pattern.Are you able to partition any of your tables so that you can VACUUM FULL the partitions individually? reply adql 16 hours agorootparentprev...okay ? What&#x27;s the use case where data shrinks ?The data that will be \"not removed\" will just be used by new data.Only real use case is \"we&#x27;ve loaded way too many data, removed it, and want to recover that space because we will never need it\", and that is not enough to matter, as usually database have its own filesystem and most filesystems can&#x27;t be shrunk online so any shrinking needs downtime reply paulddraper 15 hours agorootparent> What&#x27;s the use case where data shrinks ?Parent literally provided one: deleting a column.Another is that it&#x27;s very easy in PostgreSQL to bloat indexes. Load a bunch of data. Update (or delete) that data and now your index is bloated.The only resolution is to REINDEX (or VACUUM FULL). reply efxhoy 12 hours agorootparentThe nice thing about index bloat is REINDEX has a CONCURRENTLY option, no need to block writes. reply paulddraper 6 hours agorootparentTrue, good point. reply salojoo 16 hours agorootparentprevHave you tried pg_repack? reply anarazel 14 hours agoparentprevWhy are you regularly doing vacuum full instead of just vacuuming more aggressively? reply dzolob 12 hours agoprevIs native transparent encryption somewhere on the radar? reply olavgg 20 hours agoprevDo I still have to use pg_upgrade when I&#x27;m just upgrading from RC-1? reply jkatz05 19 hours agoparentgit diff REL_16_RC1..REL_16_0 doesn&#x27;t show any changes that would require a pg_upgrade (at least from my read), so you should be able to upgrade without it. reply olavgg 17 hours agorootparentI just tested, I had to use pg_upgrade.Error message: The database cluster was initialized with CATALOG_VERSION_NO 202306141, but the server was compiled with CATALOG_VERSION_NO 202307071. reply yobert 17 hours agorootparentYou might just need to run: alter database mystuff refresh collation version; reply data_ders 20 hours agoprevcan anyone point to the COPY FROM improvements mentioned that can result in up to 300% performance improvements is it the line in the release notes about \"ASCII string detection\"? reply JelteF 20 hours agoparentThese are the two relevant patches that I know of (there might be more):1. https:&#x2F;&#x2F;github.com&#x2F;postgres&#x2F;postgres&#x2F;commit&#x2F;3838fa269c15706d...2. https:&#x2F;&#x2F;github.com&#x2F;postgres&#x2F;postgres&#x2F;commit&#x2F;121d2d3d70ecdb21...It causes much less CPU overhead on the receiving side of a copy when receiving big JSON blobs. reply anarazel 18 hours agoparentprevI think the 300% item is \"Allow more efficient addition of heap and index pages\". The source of the improvement is a number of related improvements around relation extension, see https:&#x2F;&#x2F;postgr.es&#x2F;m&#x2F;20221029025420.eplyow6k7tgu6he3@awork3.a... reply jfbaro 16 hours agoprevCongratulations to all PG community! reply jamesgresql 17 hours agoprevI&#x27;m really excited about the COPY FROM improvements!Can&#x27;t wait to test them with some big data. reply McGlockenshire 16 hours agoprev> bidirectional logical replicationJust to make sure, this is what we used to call multi-master, right?(This is not a \"why did they change it\" post. Do not make it into a \"why did they change it\" post.) reply mdaniel 15 hours agoparenthttps:&#x2F;&#x2F;www.crunchydata.com&#x2F;blog&#x2F;active-active-postgres-16 may interest you, also, which showed up recently https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37510260 reply paulddraper 16 hours agoparentprevYes reply theandrewbailey 17 hours agoprev [–] This is great!But I just installed the latest Debian with Postgres 15, haha. I don&#x27;t even think I&#x27;m using any features past 11 (websearch_to_tsquery), so I&#x27;ll need to research anything new that might be useful to me. reply CameronNemo 11 hours agoparentOur infra team decided to deploy v12 in the last year... But only for GitLab. We are still deploying with v9.6 for some other new projects. reply klysm 7 hours agorootparent9.6 for new projects is insane no? reply CameronNemo 3 hours agorootparentInertia is a helluva drug. reply bonif 13 hours agoparentprev [–] Performance replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The PostgreSQL Global Development Group announced the release of PostgreSQL 16 on September 14, 2023, the latest update of the open-source database.",
      "Enhancements include performance improvements in query parallelism, bulk data loading, and logical replication; extended SQL/JSON syntax; new monitoring stats; and improved access control for policy management.",
      "Noteworthy additions are support for client load balancing, CPU acceleration via SIMD, and bidirectional logical replication, beneficial for developers and organizations due to strengthened monitoring, access control, and security features."
    ],
    "commentSummary": [
      "PostgreSQL 16, an open-source software project, has been released with enhanced features and better version management.",
      "This project, renowned for its influential role in software infrastructure, is backed by a diverse group of contributors.",
      "Current discussions focus on areas such as performance optimization, index bloat, replication, and deployment options concerning PostgreSQL."
    ],
    "points": 534,
    "commentCount": 72,
    "retryCount": 0,
    "time": 1694696786
  },
  {
    "id": 37514940,
    "title": "Instead of collaborating or supporting me, Google stole my idea",
    "originLink": "https://github.com/google/project-gameface/issues/1",
    "originBody": "Skip to content Product Solutions Open Source Pricing Search or jump to... Sign in Sign up google / project-gameface Public Notifications Fork 50 Star 278 Code Issues 21 Pull requests 7 Actions Projects Security Insights New issue Instead of collaborating or supporting me, you guys stole my idea #1 Closed ozramos opened this issue · 3 comments Comments ozramos commented About a year or 2 ago Lawrence Maloney @lmoroney asked me about my project Handsfree.js (https://github.com/ozramos/handsfree) and if it could be used for accessibility. I showed him that not only could it, but that I've already open sourced a gesture mapper and desktop controller, that is itself handsfree, using a block based interface called Midiblocks: https://github.com/ozramos/midiblocks and https://midiblocks.firebaseapp.com. The worst part is that after I asked him for support, he didn't respond...he just took all my notes and ghosted me 2127463033.mp4 I'm very upset with this team right now, because I started working on these efforts while homeless in 2018 to help someone at the shelter recovering from a stroke. I didn't even have my own computer and was using a library computer to develop this, until Google PAIR gave me a computer. Here is proof of me at the shelter after hanging out with them (there's a local office) I have been living in poverty for all of these years, to the point of professors sending me food boxes at my lowest points. And still I've been obsessively pushing out dozens of projects, tutorials, and examples: https://oz.super.site/handsfreejs (unfortunately I burned out last year from extreme stress and deleted my entire body of work, this is just the stuff I have. My repos also had thousands of stars) My hands are shaking and I'm crying right now because for years and years and years I've lived in isolation and struggled severely, in and out of mental health hospitals, for no reason at all...you could have supported my work. You still can support my work and you don't...I don't understand why it's not like I haven't asked many of you directly for help I am so obsessively passionate about my research and work that I pursued it fully and blindly, instead of wasting time making other people money building things that don't ultimately matter. I could have been working with you, I prototyped these tools years ago! On the one hand I feel validated, on the other hand if I tell anyone outside of this repo any of this they'll put me back in the loony bin thinking I'm making all this up. I have literally had to have hospitals call a professor at Carnegie Mellon to verify my story because they thought I was making all this up (\"this\" being my journey in making this and they just thought I was \"manic\") In the recently leaked memo from Google about \"AI moats\", there was a bit saying something like open source is a huge competitor to you and OpenAI because so many quote \"regular people\" are contributing ideas...there's nothing regular about the efforts of people like myself who furiously and passionately contribute Despite my anger and disappointment, I do congratulate you on finally making progress on this. The video for the blog was genuinely beautiful and moving and I do have shame for having these negative emotions. I can't hold a job and will never make money for anything I have built, but I think seeing this project will ease my depression because now I know that my ideas are valid and it's just a matter of weathering the poverty 👍 42 ❤ 90 👀 30 Author ozramos commented I've closed the issue both literally and metaphorically, I think this and related projects are beautiful but I think you guys could be much more supportive and acknowledging of the open source community. Not simply liking a tweet or repo but really going hardcore and lifting people up I posted this out of frustration because Laurence reached out while I was homeless and ghosted me after I asked why not just support my efforts since I had already made so much progress, and open sourced it all This is one of the many examples and repos I showed him. Not only am I playing hands-free, I mapped the gestures handsfree and am controlling the desktop from the browser...it's handsfree end-to-end (except for literally turning the computer on) and this was in 2019-2020. DASH_1080.mp4 ❤ 29 ozramos closed this as completed golanlevin commented Oz has closed this issue. But on his behalf, here's a word of coda — so that his voice might not be diminished. I see some folks are praising Google for their high-mindedness in creating Project Gameface to help the disabled. It's a cruel tragedy that Google did this — factually — on the back of Oz Ramos, a homeless Iraq war veteran, who has PTSD, who created the working prototype on which the design of Project Gameface is based. Bluntly, Oz Ramos's Handsfree.js project, which he had been developing since 2018, was plagiarized by Google for its Project Gameface. Oz has a posse, you see. So, here are some receipts. I'm a Professor of electronic art and computer science at Carnegie Mellon University, and I can affirm that Oz's story and allegation are true. I supported Oz's work on Handsfree.js through residencies at my lab, the STUDIO for @CreativeInquiry at CMU, in February 2019 and February 2021. I'm the professor that Oz refers to, above. Oz was inspired to begin working on what became Handsfree.js in 2018, when he was staying at a homeless shelter. Oz met another resident at the shelter, who was recovering from a severe stroke that left them unable to communicate with their friends and family. From 2018 through 2023 — as a self-taught software developer with no college degree — Oz worked on Handsfree.js whenever his circumstances allowed. He tested it with other veterans. He made it work in the browser, and across multiple platforms. He connected it to toolkits for programming education, like p5.js from the @processing Foundation. He received support to continue developing the project from @glitchdotcom, @OpenSourceArts, and @PAIR-code (Google PAIR). He continued to work on it, even after his laptop was stolen. He did this while surviving on less than $12K per year, total, in Veteran Disability Benefits. Always, his vision was for Handsfree.js to build accessible interfaces for disabled people. Lawrence Maloney @lmoroney contacted Oz more than a year ago. Lawrence extracted a full rundown of how Handsfree.js worked; learned about Oz's ambitions for his passion project; and learned about Oz's sidecar MidiBlocks project, which allows people to design their own game-controlling macros and shortcuts for Handsfree.js. You can see some of this work in the GIF below. Oz summoned the courage to ask Lawrence for a job or funding to develop the project further...and Lawrence cold ghosted him. Let's just say Oz was at a pretty low point after that. I've seen corporations steal the work of individual creators more times than I can count, but this case truly takes the prize for its unnecessary and grievous cruelty. This could have so easily been a happy story. Oz was already using Google's MediaPipe as the tracking library in Handsfree.js! Google could have brought in Oz as a contributing consultant, uplifting him as a remarkable and exemplary MediaPipe developer, in a collaborative process to develop a solution for Lance. For pennies. Instead — you callously crushed the spirit of a homeless vet. What's done is done, the issue is closed. But I think an apology from the project team, and an official acknowledgement of Oz's contributions to the Gameface project, would still be very welcome. Here are some more receipts for those interested. https://oz.super.site/handsfreejs — Oz's documentation of Handsfree https://handsfreejs.netlify.app/ — An older Handsfree page, from 2021 https://clinicopensourcearts.com/index.php/portfolio/handsfreejs — Oz's residency at the Clinic for Open-Source Arts https://studioforcreativeinquiry.org/project/spring-2021-ossta-residencies — Oz's residency at CMU https://dev.to/goinghandsfree/introducing-handsfree-js-integrate-hand-face-and-pose-gestures-to-your-frontend-4g3p — Thorough article on Handsfree.js at Dev.to. https://vimeo.com/760693757 — Oz controlling a robot with Handsfree at CMU in 2019 ❤ 141 steeve commented I'm a complete stranger but what a great story about Handsfree.js came to be. Congratulations to Oz, very humbling, however sad the situation is. Google should absolutely respond. 👍 93 headllines bot mentioned this issue Hacker News Daily Top 10 @2023-09-15 headllines/hackernews-daily#1156 Open todaywasawesome added a commit to todaywasawesome/project-gameface that referenced this issue Add acknowledgements for @ozramos - closes google#1 … Verified 040d33d todaywasawesome mentioned this issue Add acknowledgements for @ozramos - closes #1 #38 Open Sign up for free to join this conversation on GitHub. Already have an account? Sign in to comment Assignees No one assigned Labels None yet Projects None yet Milestone No milestone Development No branches or pull requests 3 participants Footer © 2023 GitHub, Inc. Footer navigation Terms Privacy Security Status Docs Contact GitHub Pricing API Training Blog About",
    "commentLink": "https://news.ycombinator.com/item?id=37514940",
    "commentBody": "Instead of collaborating or supporting me, Google stole my ideaHacker NewspastloginInstead of collaborating or supporting me, Google stole my idea (github.com/google) 423 points by FloatArtifact 12 hours ago| hidepastfavorite72 comments dinkleberg 11 hours agoThis is depressing to read.This is so close to being the amazing story we all want to hear about.A veteran, suffering from PTSD, falls on hard times and ends up homeless. Despite his hard situation, he strives to help those who are even worse off. He learns how to program and uses these skills to build something to improve the lives of those are severely disadvantaged. He spends years working on this project and ends up building something really cool and useful.So useful in fact that his dedication pays off and one of the biggest software companies in the world is inspired and brings him on to scale up this technology to help improve the lives of millions.Except of course that doesn&#x27;t end up happening. Instead, we&#x27;re left reminded that life can be cruel. reply rootkea 5 hours agoparent> life can be cruel.We can be more specific here. \"Some people can be cruel\".(Of course, I&#x27;m talking about the one who took all the notes from Oz then instead of giving him the credits ghosted him completely and later co-authored the blog post announcing the \"inspired\" project. https:&#x2F;&#x2F;blog.google&#x2F;technology&#x2F;ai&#x2F;google-project-gameface) reply paul7986 13 minutes agorootparentUmmm it&#x27;s not the employee it&#x27;s Google and it&#x27;s culture of thievery as it ...- Copied iOS and created Android- Worked with Sonos then stole from Sonos; Sonos 10 years later wins a victory in court https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;5&#x2F;26&#x2F;23739273&#x2F;google-sonos-sma...- To inviting a MIT student out for an interview who demoed her tech & they patented it https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18566929To many other examples ... it&#x27;s not the employees it&#x27;s the company! reply ingenieroariel 12 hours agoprevI have a lot of respect for Oz&#x27;s ability to ship and skills &#x2F; imagination.Only thing I can think of is for people to think thoroughly the license they set. BSD in this case, 4 years ago. And to not take any contributions unless they sign a CLA so the license can be changed in the future.As for my own point of view, I screen apps&#x2F;libraries that are not MIT&#x2F;BSD&#x2F;Apache2 and I may want to link statically to or sell services for and try to sponsor on Github projects I rely heavily on.[1] https:&#x2F;&#x2F;github.com&#x2F;ozramos&#x2F;handsfree&#x2F;blob&#x2F;master&#x2F;LICENSE reply calrain 12 hours agoprevThis is a problem with specific people within Google, and Google&#x27;s inability to manage their staff.Google&#x27;s Legal department can definitely resolve this problem. reply solardev 4 hours agoparentThey&#x27;re probably just hoping it&#x27;d blow over if they ignore&#x2F;bury it. Google&#x27;s not exactly known for being good at responding to anyone... reply steeve 12 hours agoprevThat was a lot darker than I thought it would be. Google should absolutely respond.As for Oz, what an incredible story. reply metadat 12 hours agoparentAnd no reply from Elgoog since this was posted back in May, now more than 4 months ago. \"Disappointing\" would be an understatement. reply paul7986 11 hours agoparentprevGoogle is known for doing this as seen in this other HN post https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=18566929As well I met them and it wasn&#x27;t a pleasant experience. It was a decade ago around the same time Sonos met with them and they did similar to Sonos. Though Sonos recently won their case against them https:&#x2F;&#x2F;www.theverge.com&#x2F;2022&#x2F;1&#x2F;6&#x2F;22871121&#x2F;sonos-google-pate.... reply rmbyrro 11 hours agorootparent> Though Sonos recently won their case against themOuch. That one hurt. Google is looking worse every day. Is it going to be \"the Yahoo of tomorrow?\" reply solardev 4 hours agorootparentI think it&#x27;s more like the Yahoo of yesterday? They made a few key products and then... nothing... for decades, while sponsoring deals everywhere to try to maintain their monopoly. reply paul7986 3 hours agorootparentThey basically only created a better search engine which that possibly could have been stolen too. I mean Facebook was stolen as well and the public doesn&#x27;t care. I&#x27;m sure the public doesn&#x27;t care that 100s to 1000s of innovators have been ripped off by Google as they just see them as not the winners. Yet a lot of the winners are the no talent thieves and those who throw all their morals to win at all cost.I&#x27;ve talked about my experience (click thru my 1st link above ...my comment is the top of that thread as I met with that same R&D team, Google ATAP the MIT student did and Im betting so did Sonos who actually worked with Google) to warn those if and when Google comes knocking demand money deposited in your bank before taking a meeting! Blow their stardust back in their face and demand money! reply photon_lines 10 hours agorootparentprevYes reply theolivenbaum 5 hours agorootparentprevReminds me of something they mentioned on https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;The_Billion_Dollar_Code series: Google asking small startups for a sales offer, copying the startup instead, and using the offer as a shield against future lawsuits (look, they only thought it was worth X) reply klipklop 12 hours agoparentprevAgreed, the story is so wild it’s hard to believe at first. reply pedalpete 11 hours agoprevThe first things that come to mind are1) why would Google steal this instead of bringing Oz onto the team, which assumes he wanted to work for Google)2) what can we as a community do to support Oz .Oz, if you&#x27;re reading this, you&#x27;re obviously a very capable person, how do you think we can support you. Not just in relation to MidiBlocks, but beyond. That is just one project, I&#x27;m sure you&#x27;ve got more in you, if you want to pursue other things. reply romanhn 11 hours agoparentWith a big company like Google you can&#x27;t just randomly hire someone without putting them through the rigorous interview process that can be months long (been there, done that), accomplishments or not (see the Homebrew dude). reply rmbyrro 11 hours agorootparentThey have thousands of contractors and consultants that don&#x27;t go through this process. That&#x27;s not a valid reason. reply dappermanneke 11 hours agorootparentprevof course not, you have to acquire their LLC to let them skip the interview process. so building stuff does count, but only if done commercially reply romanhn 10 hours agorootparentFYI, it is incredibly common to subject acquihired employees to the same interviews, and extend offers only to those that pass. This is especially true at FAANG. reply 0cf8612b2e1e 10 hours agorootparentprevSo if John Carmack, Guido, Rich Hickey, Donald Knuth wanted a job, they would first have to leet code like everyone else?The reason the failure to invert a binary tree story was notable was because the dude invented Homebrew. He was supposed to enter though the back door, but someone screwed up and made him go through the regular mechanism. reply romanhn 10 hours agorootparentAt the extreme edges of course there are exceptions. I think we can agree that this is not the case here? reply chaps 9 hours agorootparentSorry bud, I strongly disagree. This feels like an exception&#x27;d be warranted. reply romanhn 8 hours agorootparentTo be clear, I am not passing judgment on Oz - I think his accomplishments are impressive, all the more so given his day-to-day challenges. And I&#x27;m not at all a fan of the Leetcode interviewing culture either. My point was that Oz is not Carmack, Knuth, etc, so wouldn&#x27;t fall into the exception bucket that Google cares about (unlike you or me). There are usually well-meaning reasons behind these processes, regardless how well they turn out. reply NalNezumi 6 hours agorootparent>There are usually well-meaning reasons behind these processes, regardless how well they turn out.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Argument_from_authority reply somsak2 4 hours agorootparentare you saying google is not an expert in software development? sorry, this fallacy doesn&#x27;t apply here reply no_wizard 7 hours agorootparentprevFor this piece of tech, he is Carmack. He is Knuth. He deserves respect for the work he’s done in this problem space, it actually is gaming changing the way it works.Why disrespect what’s been achieved here? replyexabrial 9 hours agorootparentprevGotta answer dem 1337 code questions.In a previous life on a job site, the term was called measuring dicks but I digress. reply midnitewarrior 6 hours agoparentprevIt&#x27;s not \"Google\", it&#x27;s people on project teams looking to elevate their careers. There&#x27;s greed, credit, ego, and notoriety at stake, and sharing it with others is not a priority for many.\"Google\" is only going to care if it affects Legal or PR. If you want Google to care, this is going to need a lot more exposure. It will also be really bad for the people at Google responsible for this situation if this gets too much attention. reply WesolyKubeczek 3 hours agorootparentIt is Google in that it enables, fosters, incentivizes, rewards culture exactly like that. reply chaps 11 hours agoprevOz, if you&#x27;re reading this -- is there anything we can do to support you and your work? reply athorax 12 hours agoprev\"be evil whenever possible\" - Google, maybe (probably) reply galaxyLogic 12 hours agoprevI don&#x27;t know what is the remedy here since it seems Google broke no laws, did it?Can you sue someone for \"stealing your idea\"? Unfortunately this is the world we live in. Only thing I can think of is that people vote into power parties who are willing to check the power of big corporations:https:&#x2F;&#x2F;subscriber.politicopro.com&#x2F;article&#x2F;2023&#x2F;09&#x2F;biden-doj... reply toyg 11 hours agoparentJust because something is legal, doesn&#x27;t mean that it isn&#x27;t utterly immoral.The Google guy should be ashamed of himself, apologize, and try to remedy the injustice he perpetrated - get Oz a job, and&#x2F;or credit him in their work. reply fallat 12 hours agoparentprevThe remedy is Google gives the guy a job or some damn payment. \"They don&#x27;t have to\" - well no shit, we don&#x27;t have to be nice to each other, yet most of us are. Why can&#x27;t Google be nice to people? reply pvorb 11 hours agorootparentThey don&#x27;t have to be nice to people, but it would be better if they (still) were not evil. reply msm_ 11 hours agorootparentprevBecause Google is a corporation, not a person. Even if Google decides to be \"nice\" in this case, this will be for purely selfish reasons (they decide good PR they get from paying this guy is worth more than whatever they pay). Expecting corporations to behave like people is a sure way to get disappointed. reply jjnoakes 11 hours agorootparentCorporations are made up of people, and people can influence the actions of the corporation, if they try. reply solardev 4 hours agorootparentThey&#x27;re made out of people subservient to the owners, whether that&#x27;s a rich dude or a bunch of shareholders largely shielded from the day to day operations and who just want their stocks to go up a little more. Google is THE poster child of a company whose employees rebelled, even unionized, but who still don&#x27;t really have much power.It&#x27;s a huge advertising company trying to make more money, not a scrappy search tech startup in a garage... reply Brian_K_White 5 hours agorootparentprevIt doesn&#x27;t matter what corporations are made of, they are their own different thing operating in a different context and according to other rules.It doesn&#x27;t matter if it&#x27;s made of people or ants. reply yoyohello13 11 hours agorootparentprevYeah good luck with that. The founding principal and mission of a corporation is to make money at all costs. Being \"Good\" will always come second to making money, the individuals who make it up are powerless to stop it. reply jordan_curve 11 hours agorootparentDo you have a source for this? As far as I know the purpose of corporations is to shield owners from losses and not a whole lot beyond that. reply doctor_eval 10 hours agorootparentUnclear why you were downvoted, it’s in the name: Limited Liability Company, PLC, Ltd etc. reply rmbyrro 11 hours agorootparentprevThe best way to shield owners is to not form a business in the first place. reply solardev 4 hours agorootparentThat&#x27;s even worse. You, the individual, will just have all the liabilities. reply jjnoakes 11 hours agorootparentprevI&#x27;ve effected positive change in the companies I&#x27;ve worked with in the past, so I guess I know firsthand of anecdotal counter-arguments. reply akomtu 7 hours agorootparentprevCorporations can&#x27;t be nice. They exist to multiply capital of the investors. Among those investors there is a big one - 401ks, index funds and other assets of small people managed by big firms. As an individual investor, do you want your 401k to grow? If you do, you&#x27;re among the many who force Google to promote efficient nihilists who bring money. If you don&#x27;t, why haven&#x27;t you invested your savings in a nonprofit fund helping the homeless? reply lol768 12 hours agoparentprevThe legal system isn&#x27;t the only means to a \"resolution\".Public shaming can work pretty well too, sometimes. reply happymellon 4 hours agoparentprevI completely disagree.Just because it is not illegal does not mean you want your employees acting this way. Google should at a minimum have in place a program to help these folks start a small company for the purposes of acquiring, with the implied benefit for the employee that it shows their leadership capabilities. Ripping off a disabled veteran should reflect badly on Google and therefore disciplinary actions can be taken.The fact that it isn&#x27;t a thing at Google speaks volumes. reply empiko 11 hours agoparentprevI really do not see what google did wrong here. There should be no flag-planting in the open source community. The fact that one person develops an idea does not mean that nobody else has a right to develop their own version. In this case the authors has even deleted all his repositories due to mental stress. It makes even more sense for Google to develop their own version so that they can be in the control of their project. reply throwmeout123 11 hours agorootparentOpen source is unsustainable if we act like this. A 100k grant costs a fraction of the latest leetcode wanker member of the blind church of tc. Add to it a couple of seniors to mentor the dude a couple afternoons a Week and you’re steering the project without too many problems at lower cost.“Give back to the community” used to be something I admired in the American culture as an European, but I guess most exchanged it for a L6 promo reply aaomidi 11 hours agorootparentprevThe wrong things is that they actually spent time talking to Oz.It wasn’t just a random repository they came across.Anyway this is why I GPL everything. At least it ensures that the changes to it remain free. reply madrox 11 hours agoprevI&#x27;m often skeptical of claims like the one I read here...not this time. This is is pretty egregious, and thanks to Professor Levin for providing lots of supporting material, making the offense even more obvious. reply lainga 12 hours agoprevI&#x27;d like to hear the other side of the story from the GOOG employee who has been mentioned in the issue [][] https:&#x2F;&#x2F;github.com&#x2F;lmoroneyed. not GOOG user, employee, but GH user, you know... reply gman83 11 hours agoparentIt seems like this guy has nothing to do with this project? I mean, he could have told other Googler&#x27;s about this idea, but maybe it&#x27;s just a coincidence? reply CSN3RD 9 hours agorootparentHe was one of two authors announcing the project on Google&#x27;s blog. https:&#x2F;&#x2F;blog.google&#x2F;technology&#x2F;ai&#x2F;google-project-gameface&#x2F; reply gman83 3 hours agorootparentOhh wow, that&#x27;s pretty damning then. reply lainga 11 hours agorootparentprevBased on a sibling comment I thought he might have merely collected information about Mr Oz&#x27;s project, in a DevRel role, and someone else gotten hold of it. But IANAL and IANAJ, I just thought that since he&#x27;s been mentioned he&#x27;d like to speak for himself. Esp. considering what some of the sibling comments are saying. reply dappermanneke 11 hours agoprevsounds like this dude got caught in someone’s promo packet assembly. i wouldn’t worry too much if i were him. this’ll be deprecated in three years or so once it served its purpose to signal how good of an engineer the person who made it as part of their promo package is reply solardev 12 hours agoprevDon&#x27;t be (caught being) evil. reply abrookewood 8 hours agoparentGoogle have fallen from a company I used to admire, to something grubby and untrustworthy. reply solardev 4 hours agorootparentThat&#x27;s just the nature of capitalism, isn&#x27;t it? I don&#x27;t think any company stays good once they get big enough.Maybe the B Corps and co-ops stand a chance... reply rg111 12 hours agoprevI am here to say something tangential.I found that deeplearning.ai and GoogleX in edX had some MOOCs where the person who is facing the allegation was an instructor.After some minutes, I found the person to be average, and not really up to my expectations as an instructor in AI. The rigor of those MOOCs were quite low, too.Digging up, I found that he was an \"AI Advocate\" at Google, which is just devrel. He is not a full-fledged developer or a scientist or research engineer.Of course, I didn&#x27;t finish or purchase those MOOCs. reply kristjansson 11 hours agoparentI think this is useful context and deserves fewer downvotes than it currently has. reply DiabloD3 12 hours agoprevSomebody at the DoJ should reach out to this guy and see if he&#x27;d be willing to testify. reply sneak 4 hours agoparentTestify for what? Ideas aren&#x27;t IP. His license is permissive. He literally gave his idea away to the world for free.How did anything Google did harm this guy in any way? reply pickingdinner 11 hours agoprevYa, F google. But that&#x27;s what corporations do. I wouldn&#x27;t expect otherwise. But that&#x27;s also why the PR department could get on this and make it right, and profitable (which is always the only motivation).The Honda \"random acts of helpfulness\" goes a bit too far to be tasteful to me, because their acts are so random.But if an individual could use help, and the situation is related to a companies service or product, the business should help, even just for PR, especially if they are selling to consumers, whom are all individuals. reply Kaibeezy 12 hours agoprevEvil. reply somsak2 4 hours agoprevwould highly recommend Oz look for some mental health resources. nowadays there&#x27;s plenty of self-study online, no insurance or expensive therapist needed. wishing him best of luck. reply swader999 12 hours agoprevThey should just be good about this but I guess that isn&#x27;t their motto. And I tend not to believe articles like this. reply matt3210 12 hours agoprev [3 more] [flagged] rmbyrro 12 hours agoparentSure, that&#x27;s why they should steal other people&#x27;s work without any credit or consideration to their morals. Because it&#x27;s a \"fiduciary responsibility\", this is totally fine. reply archgoon 12 hours agoparentprev [–] This is a fiction. I&#x27;m not sure if it is pushed by corporate apologists, or by people trying to convince others the system is completely broken and must be destroyed (and replaced with system X).An analysis of this claim:https:&#x2F;&#x2F;www.nytimes.com&#x2F;roomfordebate&#x2F;2015&#x2F;04&#x2F;16&#x2F;what-are-co...In general, corporations are given a large leeway as to what is &#x27;in the best interest of the coporation&#x27;. Fidiciuary duty basically means CEO&#x27;s just can&#x27;t run the company into the ground and spend all the cash on cocaine parties. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The individual, ozramos, alleges that their project, Handsfree.js, was plagiarised by Google for their Project Gameface, resulting in frustration and disappointment due to lack of support and recognition.",
      "A professor from Carnegie Mellon University vouched for the validity of ozramos's claims, expressing their own disappointment in Google's actions.",
      "The general response in the user comments was supportive towards ozramos, with calls for Google to respond and acknowledge ozramos's contributions."
    ],
    "commentSummary": [
      "A veteran suffering from PTSD and homelessness developed a helpful technology, which he accuses Google of plagiarizing due to lack of support from the company for his project.",
      "The situation sparked debates about corporate ethics, accountability, and the treatment of innovators, with legal actions and public shaming viewed as potential solutions.",
      "The incident underscores the complexities of corporate actions and discusses the necessity of addressing such conflicts for societal improvement."
    ],
    "points": 421,
    "commentCount": 72,
    "retryCount": 0,
    "time": 1694726070
  },
  {
    "id": 37507355,
    "title": "How to build a IP geolocation database from scratch?",
    "originLink": "https://ipapi.is/geolocation.html",
    "originBody": "About Blog Pricing Documentation Geolocation ASN Hosting Detection GitHub Log In Sign Up START Download Database Introduction Geolocation Accuracy DIRECT SOURCES Geolocation in WHOIS Data INDIRECT SOURCES Geolocation Interpolation DATA ENRICHMENT Open Source Projects Data Enrichment Geolocation Published on July 01, 2023 Modified on September 09, 2023 Author ipapi.is IP Geolocation Database IP Geolocation Accuracy WHOIS Geolocation Interpolation Download Geolocation Database Name Size in MB Num Networks Last Updated Description Download IPv4 Geolocation Database 262M 2,599,907 September 14, 2023The full geolocation database for all IPv4 addresses as CSV (Documentation) Download IPv6 Geolocation Database 50M 486,938 September 14, 2023 The full geolocation database for all IPv6 addresses as CSV (Documentation)Download Introduction Geolocation is the process of mapping IP addresses to a geographical location defined by latitude and longitude. There are many use-cases for geolocation intelligence that are demanded by online businesses and service providers: Targeted Advertising - Allows advertisers to serve ads that are geographically relevant to users. By knowing the approximate location of an IP address, advertisers can deliver targeted advertisements based on the user's location, such as promoting local events, services, or products. Fraud Detection and Prevention - By knowing the geolocation of an IP address, unusual login attempts or unusual financial transactions can be detected and blocked. For example, if a banking account is normally used by a IP address from country A and there is suddenly a login attempt from country B, the login attempt can be denied or the user can be asked for additional verification. Content Localization - Websites and apps often want to deliver localized content to users. Based on the user's location, websites can provide region-specific information, language preferences, or display prices in the local currency. Digital Rights Management and Compliance - Content providers use IP geolocation intelligence to enforce digital rights management (DRM) policies and regulations or restrictions. Those providers may restrict access to content based on the user's geographic location, ensuring compliance with licensing agreements and copyright restrictions. Network Security - IP geolocation plays a role in network security by providing insights into the origin of potential threats. Security systems can use IP geolocation data to identify and block suspicious IP addresses or implement access controls based on geographic regions. Analytics and Insights - IP geolocation data can be valuable for analyzing user behavior and trends. Businesses can gain insights into where their customers are located, which can inform marketing strategies, expansion plans, and product development. IP Geolocation Accuracy Why is IP geolocation sometimes not accurate in general? In some cases, allocated IPv4 and IPv6 networks are distributed geographically and thus one network can have multiple geographical locations. Furthermore, many networks are distributed geographically by design. Examples of such geographically disparate networks are mobile networks or satellite networks. For example, how exactly would you geolocate the IP ranges belonging to the satellite Internet from Starklink from SpaceX? Find out by yourself by inspecting Starlink's AS14593. In other cases, IP networks are reassigned or reallocated by Regional Internet Registries or IP leasing companies (such as IPXO or ipbroker.com) and the geolocation completely changes as soon as a IP address is assigned a new owner. It turns out that the process of geolocating IP addresses is a complicated endeavour. However, the accuracy that can be obtained is too good to be ignored in any IP address API. How to build a IP Geolocation Database from Scratch? The reminder of this page makes a deep dive into the technicalities of creating a geolocation database from scratch. If you are only interested in downloading the geolocation database, you can do so here. Each IP address in the Internet is owned or administered by an organization. Regional Internet Registries (RIR's) such as ARIN or APNIC store ownership information in their WHOIS databases. However, WHOIS records don't necessarily include geolocation information for allocated networks. Furthermore, organizations that own networks can use those networks in any geographical location they end up choosing. Even worse, those organizations can assign networks to any third-party organization or lease IP blocks to other entities. Therefore, it is inherently tricky to geolocate IP addresses and thus geolocation is often not accurate. Having said that, the task to find and collect geolocation information can be divided into three different sub-tasks: Extract Geolocation Data from WHOIS Records Directly - WHOIS records often include direct geolocation information about IP addresses. WHOIS attributes such as geoloc and geofeed can be used to derive self-published geolocation knowledge about IP addresses. Interpolate Geolocation Knowledge from WHOIS Records - Often it is possible to derive and interpolate geolocation information from WHOIS attributes indirectly. For example, organizations that are administratively responsible for a network have to provide their postal address in WHOIS records. Sometimes, this postal address is also the geographical location of the organization's networks. Consider Open Source Geolocation Projects - Many entities invested considerable resources into the geolocation problem and they provide their geolocation information for free. RIPE IPmap, geofeed-finder and OpenGeoFeed are good examples of such valuable open source projects. After compiling a raw geolocation database from the above sources, it may have incomplete or inconsistent records. The collected geolocation data may be incomplete since records with country and city information don't always include coordinates. Vice versa, sometimes raw records with coordinates don't have country and city information. If raw records only contain a country, the accuracy cannot be higher than on country level. Therefore, geolocation data needs to be enriched and transformed into a common format. This process is extremely important and is achieved by using open source geographical databases such as the ones from geonames.org or openstreetmap.org. Put differently, the data enrichment task is to either: Find the latitude and longitude from a given city and country pair. Example: What are the coordinates for US, San Francisco? And on the other hand, if only the latitude and longitude is given, the task is to obtain the closest city for those coordinates. Example: What is the city and country for the coordinates 52.524526 13.410037? The next sections describe all the major steps that need to be followed in order to build a geolocation database from scratch. Extract Geolocation Data from WHOIS Records Directly This section describes how the different WHOIS databases from the five major Regional Internet Registries (RIR's) provide direct geolocation support for IP networks in their WHOIS records. By analyzing and parsing WHOIS data from all five Regional Internet Registries, many IP addresses can be mapped to a geographical location. Since each RIR has their own WHOIS database format, each RIR needs to be treated distinctively. In the next sections, it will be discussed how geolocation information is provided in each of the five different WHOIS databases. Figure 1: The five different Regional Internet Registries (Source) Geolocation in RIPE NCC The RIPE NCC database has two different attributes that provide geolocation information for inetnum and inet6num objects. The inetnum and inet6num objects assign an IP network to an organization. It is suggested to read the RIPE documentation about inetnum and inet6num objects. As mentioned, there are two different attributes in inetnum and inet6num objects that allow to provide geolocation information to IP networks: The geoloc attribute The geofeed attribute The geoloc attribute The first attribute is the geoloc attribute. The geoloc attribute simply contains latitude and longitude coordinates in string format (Example: \"47.855374 12.132041\"). The geoloc attribute is defined in the RIPE Database Docs as follows: “geoloc:” - The geolocation coordinates for the resource in decimal degrees notation. Format is latitude followed by longitude, separated by a space. Latitude ranges from [-90,+90] and longitude from [-180,+180]. All more specific objects to the inetnum object containing this attribute inherit this data. For example, the inetnum object for the IP address 217.72.221.0 includes the geoloc attribute. The WHOIS record below can be obtained via any whois client with the terminal command whois 217.72.221.0: inetnum: 217.72.221.0 - 217.72.221.255 netname: KOMRO descr: komro GmbH country: DE admin-c: KIN65-RIPE tech-c: KIN65-RIPE status: ASSIGNED PA mnt-by: KOMRO-MNT mnt-lower: KOMRO-MNT mnt-routes: KOMRO-MNT created: 2003-08-29T12:22:59Z last-modified: 2017-07-31T05:45:34Z source: RIPE # Filtered geoloc: 47.855374 12.132041 language: DE So what does the above WHOIS record reveal? The responsible organization of the network 217.72.221.0 - 217.72.221.255 is komro GmbH and the geoloc attribute claims that the network is located at the coordinates 47.855374 12.132041. Those coordinates point to Rosenheim, a city close to Munich in Germany. What is the total coverage of the geoloc attribute for all inetnum and inet6num objects in the RIPE NCC database? At the time of writing in July 2023, there were 4,190,644 inetnum and 819,381 inet6num objects in the RIPE NCC database. But only 114,389 inetnum or inet6num objects contained the geoloc attribute. Therefore, the overall coverage of the geoloc attribute is only 2.3%. However, more and more organizations start using the geoloc attribute, therefore it is useful to start collecting it. The geofeed attribute Another method to provide geolocation information in the RIPE NCC database is the geofeed attribute. The geofeed attribute is defined in the RIPE Database Docs as follows: \"geofeed:\" - Contains a URL referencing a CSV file containing geolocation data for the resource. The geofeed format is defined in RFC 8805. The value of the geofeed attribute is a HTTPS url that points to a file that contains geolocation information. The format of such geofeed files is specified in RFC 8805. Currently, there are two different ways to provide such a geofeed url in WHOIS records: One way is to use a dedicated attribute geofeed with the geofeed url as value The other method is to use the remarks attribute to specify the geofeed property. An example of using the remarks attribute to specify a geofeed url would be: inetnum: 178.237.189.0 - 178.237.191.255 netname: OOOSET-NET descr: OOO SET remarks: INFRA-AW remarks: Geofeed https://github.com/is1581/geofeedset/blob/main/ip4set.csv country: RU Using the remarks attribute requires to specify the geofeed url in the format Geofeed {URL} in order to indicate that the url points to a RFC 8805 geofeed file. The next example illustrates how the geofeed attribute is used in the RIPE NCC database. The terminal command whois 193.56.36.0 returns a WHOIS record that follows the geofeed: attribute format: inetnum: 193.56.36.0 - 193.56.36.255 country: FR netname: FR-AERO-ME geofeed: https://ip-gfd.airbus.com/geofeed.csv descr: Airbus SAS descr: 110Bis Av. du G?n?ral Leclerc, 93500 Pantin, France descr: FR AI ICC as ISP geoloc: 48.902741962025644 2.422918799104585 language: FR org: ORG-EDG4-RIPE country: FR mnt-domains: EADS-MNT admin-c: CI1306-RIPE tech-c: LR1133-RIPE status: ASSIGNED PI mnt-by: RIPE-NCC-END-MNT mnt-by: EADS-MNT created: 2002-04-12T15:19:59Z last-modified: 2023-06-06T12:37:59Z source: RIPE As the WHOIS record above reveals, the geofeed url for the network 193.56.36.0 - 193.56.36.255 is https://ip-gfd.airbus.com/geofeed.csv. How does such a RFC 8805 geofeed CSV file look like? The first column is the IP Prefix. Often, Classless Inter-Domain Routing (CIDR) notation is used for the IP Prefix column, but it is not necessarily a requirement. Example: Singapore The second column is the country as Alpha2code. Example: SG The third column is the ISO region code conforming to ISO 3166-2. Example: SG-01 The fourth column is a city in free format. Example: Singapore The fifth column is a postal code in free format (deprecated). Example: 139964 185.187.244.0/24,FR,FR-IDF,Pantin,93500 185.187.245.0/24,DE,DE-HE,Frankfurt,65933 185.187.246.0/24,SG,SG-01,Singapore,139964 185.187.247.0/24,US,US-WV,Ashburn,20147 193.56.32.0/24,FR,FR-OCC,Toulouse,31400 193.56.33.0/24,FR,FR-IDF,Le Plessis-Robinson,92350 193.56.35.0/24,IN,IN-KA,Bengaluru,560001 193.56.36.0/24,FR,FR-IDF,Pantin,93500 193.56.37.0/24,FR,FR-IDF,Les Mureaux,78440 193.56.38.0/24,FR,FR-OCC,Toulouse,31060 193.56.39.0/24,FR,FR-IDF,Pantin,93500 193.56.40.0/24,AU,AU-NSW,Sydney,2000 193.56.43.0/24,FR,FR-PAC,Marignane,13700 193.56.45.0/24,DE,DE-HE,Frankfurt,65933 What is the total coverage of the geofeed attribute for all inetnum and inet6num objects in the RIPE NCC database? At the time of writing in July 2023, there were 6643 occurrences of geofeed urls in remarks attributes and 2035 WHOIS records had the geofeed attribute. Therefore, the overall coverage of geofeed urls is only 0.17%. However, geofeed files usually include more than one network, therefore, there are more networks with geolocation information than there are geofeed urls. Hence, the coverage number of 0.17% is misleading here. Geolocation in ARIN A not so recent article from 2018 discusses Geolocation in ARIN. The conclusion of this article is that geolocation is inherently difficult. It seems that ARIN does not provide much assistance to external entities that are looking to geolocate IP addresses. Geolocation in the ARIN database for NetRange objects is provided via geofeed urls in Comment attributes. There was a request to add a dedicated geofeed property, but it was denied since adding geofeeds over Comment or Remark attributes is deemed sufficient. For example, when looking up the IP address whois 96.43.200.0, the following WHOIS record is obtained from ARIN: NetRange: 96.43.192.0 - 96.43.223.255 CIDR: 96.43.192.0/19 NetName: OFL-62 NetHandle: NET-96-43-192-0-1 Parent: NET96 (NET-96-0-0-0-0) NetType: Direct Allocation OriginAS: Organization: Omni Fiber (OFL-62) RegDate: 2022-03-30 Updated: 2022-12-07 Comment: Geofeed https://omnifiber.com/geofeed.csv Ref: https://rdap.arin.net/registry/ip/96.43.192.0 Geofeed urls follow RFC 8805 and the format of those RFC 8805 files was already discussed in the section about RIPE NCC. The ARIN database currently doesn't make use of the geoloc attribute as it is the case in the RIPE NCC database. Geolocation in LACNIC LACNIC is much more supportive when it comes to geolocation compared to ARIN. LACNIC hosts a Geofeed Service that provides members the possibility to provide geolocation information for IP addresses they own. A good part of LACNIC members provided geolocation information which is publicly available at milacnic.lacnic.net/lacnic/geofeeds. Furthermore, the LACNIC WHOIS database already provides geolocation information (accurate to city level) by default. The LACNIC database can be downloaded from their FTP server: ftp.lacnic.net/lacnic/dbase/ As can be seen in the LACNIC database excerpt below, LANIC provides city and country information for all inetnum and inet6num objects: inetnum: 190.5.128/19 status: allocated city: Antiguo Cuscatlan country: SV created: 2006-06-16 changed: 2020-08-31 source: LACNIC inetnum: 190.5.160/19 status: allocated city: Buenos Aires country: AR created: 2014-05-22 changed: 2014-05-22 source: LACNIC inetnum: 190.5.192/20 status: allocated city: POPAYAN country: CO created: 2006-11-30 changed: 2006-11-30 source: LACNIC Geolocation in AFRINIC According to the AFRINIC support page, AFRNIC does not provide geolocation services and does not have any formal or operational relationship with any geolocation provider. Nevertheless, AFRINIC also supports the usage of geofeed urls in remarks attributes similar as in the RIPE NCC database. For example, when looking up the IP address with the command whois 102.222.84.0, the following WHOIS record is obtained: inetnum: 102.222.84.0 - 102.222.84.255 netname: TZ-DAR-CABLE descr: Wananchi Cable Tanzania country: TZ admin-c: WL8-AFRINIC tech-c: WL8-AFRINIC status: ASSIGNED PA remarks: Geofeed https://geofeed.zuku.co.tz/geofeed.txt mnt-by: WCL4-MNT source: AFRINIC # Filtered parent: 102.222.84.0 - 102.222.87.255 In conclusion, AFRINIC provides geolocation information with the same attributes as with RIPE. Geolocation in APNIC APNIC provides roughly the same support for geolocation as RIPE NCC. According to a APNIC article about geolocation, they support the geoloc attribute and the geofeed urls via the remarks attribute. Furthermore, APNIC seems to be quite open to improve the geolocation support as one of their publications suggests: \"Do we need a registry for IP geolocation information?\". For example, when looking up the IP address with the command whois 203.152.49.0, the following WHOIS record is obtained from APNIC: inetnum: 203.152.49.0 - 203.152.49.255 netname: PACIFICINTERNT-TH descr: Pacific Internet (Thailand) Ltd. country: TH admin-c: AP3-AP tech-c: NPT3-AP abuse-c: AP993-AP status: ALLOCATED NON-PORTABLE remarks: Geofeed https://intra.pacific.net.th/geofeed.csv mnt-by: MAINT-TH-PITH mnt-irt: IRT-PI-TH last-modified: 2021-01-19T07:37:32Z source: APNIC In conclusion, APNIC provides geolocation information with the same attributes as with RIPE. Interpolate Geolocation Knowledge from WHOIS Records This section describes how WHOIS attributes that were never directly intended for geolocation purposes can be used to derive geolocation intelligence. This process is inherently error prone, but the obtained results are too accurate to be ignored. WHOIS data from the five Regional Internet Registries is the most accurate data source for IP addresses. The main purpose of WHOIS is to provide registrant information for organizations that own Internet numbers such as IP addresses or AS numbers. As such, WHOIS databases also often include the postal addresses and countries of the organization's headquarter or administrative location. Often, the postal address of an organization is also the geographical location where their IP addresses are used. This is of course not always the case. The administrative postal address of large organizations often doesn't correspond with the location of all the organization's IP addresses. In the next sections, for each of the five RIR's, an IP address example where the WHOIS data can be used to derive geolocation information will be discussed (positive example). Additionally, a counterexample where WHOIS meta data is misleading will be provided (negative example). If applicable, a conclusion will be drawn from the examples. Geolocation Interpolation in RIPE NCC Positive Example - 185.212.53.138 When looking up the IP address 185.212.53.138 with a WHOIS client, the following WHOIS record is obtained: inetnum: 185.212.53.136 - 185.212.53.143 netname: PUMPENTECHNIK-ERKRATH-NET descr: Pumpentechnik Erkrath GmbH + Co. KG country: DE admin-c: CK5074-RIPE tech-c: CK5074-RIPE status: ASSIGNED PA mnt-by: KOMMITT-MNT created: 2018-09-25T12:33:17Z last-modified: 2018-09-25T12:33:17Z source: RIPE person: Christine Kessel address: Max-Planck-Str. 28 address: 40699 Erkrath phone: +49 211 925480 nic-hdl: CK5074-RIPE mnt-by: KOMMITT-MNT created: 2018-09-25T12:32:01Z last-modified: 2018-09-25T12:32:01Z source: RIPE # Filtered According to many different IP geolocation services, the IP address 185.212.53.138 is located in the city of Erkrath in Germany with coordinates 51.22235, 6.9083. When looking at the above WHOIS record, it becomes clear that there are many different attributes that could be used to extract the city name \"Erkrath\" or the country \"Germany\": The country can be extracted from the country attribute: DE The city can be extracted from the netname attribute: PUMPENTECHNIK-ERKRATH-NET The city can also be extracted from the descr attribute: Pumpentechnik Erkrath GmbH + Co. KG And the address attribute also reveals the city name: Max-Planck-Str. 28, 40699 Erkrath Certainly, it is very hard to extract the city name from the netname and descr attributes, since those names have a free format. However, the address attribute can be easily used to parse out the location, since postal adresses have a much stricter format. Positive Example - 139.98.0.0 Another positive example is provided to illustrate that the descr attribute can often be used for geolocation purposes. When looking up the IP address 139.98.0.0 with whois, the following WHOIS record is obtained: inetnum: 139.98.0.0 - 139.98.255.255 netname: FYLKOMOEST descr: Oestfold Fylkeskommunes Sentraladministrasjon descr: Bos 220, N-1701 descr: Sarpsborg country: NO admin-c: JT1367-RIPE tech-c: JT1367-RIPE status: LEGACY mnt-by: AS41572-MNT mnt-by: AS2116-MNT created: 2004-02-02T16:19:07Z last-modified: 2022-09-12T12:32:28Z source: RIPE According to most geolocation services, the IP address 139.98.0.0 is located in the city of Sarpsborg in Norway. This corresponds with what the descr attribute of the above WHOIS record states. Even better, the WHOIS record above provides a full address which allows for very accurate geolocation. This is an example that underlines the usablilty of the descr attribute for accurate geolocation. Negative Example - 109.134.237.140 When looking up the IP address 109.134.237.140 with a WHOIS client, the following WHOIS record is obtained: inetnum: 109.134.0.0 - 109.134.255.255 netname: BE-BELGACOM-ADSL1 descr: ADSL-GO-PLUS descr: Belgacom ISP SA/NV country: BE admin-c: SN2068-RIPE tech-c: SN2068-RIPE status: ASSIGNED PA mnt-by: SKYNETBE-MNT mnt-by: SKYNETBE-ROBOT-MNT created: 2011-11-25T10:16:24Z last-modified: 2011-11-25T10:29:00Z source: RIPE role: Proximus NOC administrators address: Proximus SA de droit public address: TEC/NEO/IPR/TDN/DTO/DSL Internet Networks address: Boulevard du Roi Albert II, 27 address: B-1030 Bruxelles address: Belgium phone: +32 2 202-4111 fax-no: +32 2 203-6593 abuse-mailbox: abuse@proximus.com admin-c: BIEC1-RIPE tech-c: BIEC1-RIPE nic-hdl: SN2068-RIPE mnt-by: SKYNETBE-MNT created: 1970-01-01T00:00:00Z last-modified: 2020-03-04T06:19:15Z source: RIPE # Filtered The address attribute from above shows that the administrative location of the organization \"Proximus\" is located at Boulevard du Roi Albert II, 27, B-1030 Bruxelles, Belgium. However, most geolocation providers place the IP address 109.134.237.140 in other Belgian cities such as Hasselt, Grimbergen or Wuustwezel. Therefore, if we would use the address attribute from this WHOIS record, we would obtain a sligthly wrong geolocation. However, using Bruxelles as geolocation is still better than picking the wrong country or even a wrong continent. This example shows why geolocation providers often have approximative accuracy. Conclusion Having seen the three examples from above, what attributes can be used from the RIPE NCC database to interpolate geolocation information from inetnum and inet6num objects? The inetnum and inet6num have at least three attributes that can potentially be used to derive geolocation information: The country attribute (Only yields country level accuracy) The descr attribute The netname attribute (Unreliable and hard to parse) The address attribute (Strictly speaking an attribute of the role object and not inetnum and inet6num) The country attribute is defined in the RIPE Database Docs as follows: “country:” - This identifies a country using the ISO 3166-2 letter country codes. It has never been specified what this country represents. It could be the location of the head office of a multi-national company or where the server centre is based or the home of the End User. Therefore, it cannot be used in any reliable way to map IP addresses to countries. The explanation above speaks for itself. It is somewhat safe to use the country attribute for geolocation, since the accuracy of country level information is rather coarse and thus the room of mistakes is reduced. Put differently: Since most multinational organizations have at least one postal address for each country, those organizations often use the postal address of the same country where the IP networks are actually used. The descr attribute is defined in the RIPE Database Docs as follows: “descr:” - A short description related to the object. Therefore the contents of the descr attribute could be anything, since RIPE NCC does not strictly define what this value represents. It turns out that the descr attribute is often used by organizations to provide location and address information for the network. In conclusion, the descr attribute is very useful in order to derive geolocation information from it. Additional information can be provided for inetnum and inet6num objects with the role object. Therefore, it is also interesting to discuss the role object. The address attribute of role objects is defined in the RIPE Database Docs as follows: “address:” - This is a full postal address for the role represented by this object. Even though address attributes can have high geolocation accuracy, the address attribute specifies the postal address of a role object. The inetnum and inet6num objects can have an address assigned via a role object, since the postal address of a company is not necessarily the location where the IP addresses are used. However, as the negative example from above proofs, it is a mistake to assume that IP addresses have the same geolocation as the postal address of a role object. Geolocation Interpolation in ARIN Positive Example - 192.42.152.0 When looking up the IP address 192.42.152.0 with a WHOIS client, the following WHOIS record is obtained: NetRange: 192.42.152.0 - 192.42.152.255 CIDR: 192.42.152.0/24 NetName: UMN-CC-NET NetHandle: NET-192-42-152-0-1 Parent: NET192 (NET-192-0-0-0-0) NetType: Direct Allocation OriginAS: AS57, AS217 Organization: University of Minnesota (UNIVER-233-Z) RegDate: 1988-10-12 Updated: 2021-12-14 Ref: https://rdap.arin.net/registry/ip/192.42.152.0 OrgName: University of Minnesota OrgId: UNIVER-233-Z Address: Office of Information Technology Address: 2218 Univ Ave SE City: Minneapolis StateProv: MN PostalCode: 55414 Country: US RegDate: 2009-10-13 Updated: 2019-09-30 Comment: http://www.umn.edu/ Ref: https://rdap.arin.net/registry/entity/UNIVER-233-Z Most IP geolocation providers locate the IP address 192.42.152.0 in the city of Minneapolis in the US. This corresponds with the City, StateProv, PostalCode and Country attributes of the above WHOIS record. Thus, the above example shows that those attributes can be used to geolocate the network 192.42.152.0 - 192.42.152.255. Negative Example - 136.50.220.162 When looking up the IP address 136.50.220.162 with a WHOIS client, the following WHOIS record is obtained: NetRange: 136.32.0.0 - 136.63.255.255 CIDR: 136.32.0.0/11 NetName: GOOGLE-FIBER NetHandle: NET-136-32-0-0-1 Parent: NET136 (NET-136-0-0-0-0) NetType: Direct Allocation OriginAS: Organization: Google Fiber Inc. (GF) RegDate: 2015-10-06 Updated: 2015-10-06 Ref: https://rdap.arin.net/registry/ip/136.32.0.0 OrgName: Google Fiber Inc. OrgId: GF Address: 1600 Amphitheatre Parkway City: Mountain View StateProv: CA PostalCode: 94043 Country: US RegDate: 2010-10-08 Updated: 2019-11-01 Ref: https://rdap.arin.net/registry/entity/GF Most IP geolocation providers locate the IP address 136.32.0.0 in San Antonio in Texas. However, if we would have used the above WHOIS record for geolocation, we would have taken the head office from Google in Mountain View, California for geolocation. This would obviously have been a mistake. Conclusion It seems that using the following ARIN WHOIS attributes is somewhat reliable if the organization is small or centered in only one location: Address attribute City attribute StateProv attribute PostalCode attribute Country attribute Examples for small organizations are universities, hospitals and governmental ministries. Those organizations use the IP addresses of NetRange objects the at the same location as their administrative postal address. This is not the case with larger businesses or nation wide organizations that own many NetRange objects. Geolocation Interpolation in LACNIC It is not necessary to derive geolocation information from LACNIC WHOIS records, since LACNIC provides full geolocation support in their WHOIS database as discussed earlier on this page. Geolocation Interpolation in AFRINIC AFRINIC has the same WHOIS database format as RIPE NCC, so the same principles apply as for RIPE NCC. In short, it is possible to use the country or descr attribute from inetnum or inet6num objects from the AFRINIC database to interpolate geolocation information. Furthermore, the address attribute from role objects can also be used to derive geolocation information. The address attribute specifies the postal address of a role, which is often used to specify ownership of a network. Geolocation Interpolation in APNIC APNIC uses the same WHOIS database format as RIPE NCC, so the same principles apply as for RIPE NCC. Open Source Geolocation Projects Several open source geolocation projects are explored in this section. Open source projects are often the basis for many commercial geolocation projects. Especially the contributions from RIPE NCC, APNIC and ARIN are reviewed, since those Regional Internet Registries provide the best support for geolocation. RIPE IPmap RIPE IPmap is (was - it seems that the it is not longer maintained) an API that provides geolocation data for core Internet infrastructure. RIPE IPmap uses several different engines to infer geolocation for IP addresses. RIPE IPmap is a system for active (live) IP geolocation, which means that each IP has to be geolocated actively, which can be a time consuming process. The most interesting engine from RIPE IPmap is called latency and single-radius engine. The latency engine uses measurements from RIPE Atlas to provide a latency radius for the geolocation of an IP address. Put differently, by using hundreds of geographically distributed latency measurement servers from RIPE Atlas, it is possible to estimate the location of an IP address by triangulating with minimum RTT measurements. The RIPE IPmap documentation provides a full description for the latency engine. It is quite straightforward to understand how the latency engine works in practice. If a certain IP address needs to be geolocated, latency measurements can be either obtained by actively pinging the IP address or by recording the RTT of incoming connections (passive). The minimum latency sets an upper threshold for the maximal possible distance due to the definition of the speed of light in fiber optic medium. reverse-dns is another RIPE IPmap engine that uses the hostnames from PTR records in order to geolocate IP addresses. The RIPE IPmap documentation explains how the reverse-dns engine works. Essentially, the idea is to extract city level geolocation from PTR records of hostnames. For example, the following traceroute output reveals how hostnames from routers indicate their geogrpahical location: ae59-300.edge9.frankfurt1.level3.net (62.67.4.229) 31.713 ms 29.638 ms 9 ae59-300.edge9.frankfurt1.level3.net (62.67.4.229) 31.189 ms * * 10 * att-level3-washington12.level3.net (4.68.62.30) 124.232 ms 120.208 ms 11 att-level3-washington12.level3.net (4.68.62.30) 119.936 ms 122.603 ms * In the traceroute dump from above, it can be seen how the IP 62.67.4.229 is located in Frankfurt (Germany) and the IP 4.68.62.30 in Washington (USA) according to their respective hostnames. The RIPE IPmap database can be downloaded from here: https://ftp.ripe.net/ripe/ipmap/ The database has the following CSV format: ip, geolocation_id, city_name, state_name, country_name, country_code_alpha2, country_code_alpha3, latitude, longitude, score Unfortunately, while the ideas of RIPE IPmap are certainly still good, the project's accuracy and coverage degraded considerably according to the former maintainers website. It seems like there are no new contributions to RIPE IPmap since 2019. geofeed-finder geofeed-finder is a open source project by Massimo Candela who was formerly employed by RIPE NCC. The purpose of the project is as follows: This utility discovers and retrieves geofeed files from whois data. Additionally, it validates the ownership of the prefixes, manages the cache, and validates the ISO codes. See RFC9092. This tool can be used to extract geofeeds from WHOIS data according to RFC 9092. As discussed on this page, the coverage of geofeed information in all networks is very low, therefore this tool has limited real life usablilty, but it is promising since geofeed coverage will likely increase in the coming years. LACNIC Geofeeds Service The LACNIC Geofeeds Service provides geolocation information for a good part of LACNIC's members. The data is publicly available for download at milacnic.lacnic.net/lacnic/geofeeds. This is a very important project, since it allows to access geolocation information where it should be collected: At the RIR level. OpenGeoFeed OpenGeoFeed is a open source project that compiles self-published geofeeds according to RFC 9092. OpenGeoFeed provides a single geofeed file that contains all known public geofeed files here: opengeofeed.org/feed/public.csv While OpenGeoFeed is a promising project, it seems that the geofeed coverage is not up to date and it is unlikely that the data sources are frequently updated. Geolocation Data Enrichment Often the raw geolocation information obtained from WHOIS data or geofeeds don't include all the meta data necessary to populate all geolocation fields that the database provides. In this section, it is explaind how raw geolocation data is enriched by considering third party sources. This data enrichment process is achieved by using open source geographical databases such as: geonames.org openstreetmap.org naturalearthdata.com The data enrichment process can be divided into two cases: For those raw records where only city and country geolocation information is given, there is a need to find the latitude and longitude (coordinates) from a given city and country. Example: What are the geographical coordinates for US, San Francisco? On the other side, if only the latitude and longitude is available in the raw data, the goal is to obtain the closest city and country for those coordinates. Example: What is the closest city and country for the coordinates 52.524526 13.410037 (if there is a city at all close to those coordinates) ? For example, ipapi.is uses the following databases to enrich geolocation information: GeoNames Postal Code Files - All known postal codes of all countries of the world (excluding some countries for legal reasons) cities500.zip - all cities with a population > 500 countryInfo.txt - country information such as Country Capital, Population, Continent and other country meta data ipapi.is is accurate and easy to understand Sign up for a free account. Our free plan (1,000 free daily requests) will always cover use-cases for most users. In case you need a large API volume, you can subscribe to a billing plan. Sign Up Get started for free by signing up Sign Up Sign In About Pricing Documentation Geolocation ASN Data Hosting Detection GitHub API Status ipapi.is - All rights reserved © 2021 - 2023 · Terms & Service · Privacy Policy · Contact We use cookies We use our own and third-party cookies to personalize content and to analyze web traffic. Read more about cookies Accept cookies Reject",
    "commentLink": "https://news.ycombinator.com/item?id=37507355",
    "commentBody": "How to build a IP geolocation database from scratch?Hacker NewspastloginHow to build a IP geolocation database from scratch? (ipapi.is) 402 points by incolumitas 23 hours ago| hidepastfavorite154 comments reincoder 20 hours agoFirst, I am big fan of your articles even before I joined IPinfo, where we provide IP geolocation data service.Our geolocation methodology expands on the methodology you described. We utilize some of the publicly available datasets that you are using. However, the core geolocation data comes from our ping-based operation.We ping an IP address from multiple servers across the world and identify the location of the IP address through a process called multilateration. Pinging an IP address from one server gives us one dimension of location information meaning that based on certain parameters the IP address could be in any place within a certain radius on the globe. Then as we ping that IP from our other servers, the location information becomes more precise. After enough pings, we have a very precise IP location information that almost reaches zip code level precision with a high degree of accuracy. Currently, we have more than 600 probe servers across the world and it is expanding.The publicly available information that you are referring to is sometimes not very reliable in providing IP location data as:- They are often stale and not frequently updated.- They are not precise enough to be generally useful.- They provide location context at an large IP range level or even at organization level scale.And last but not least, there is no verification process with these public datasets. With IPv4 trade and VPN services being more and more popular we have seen evidence that in some instances inaccurate information is being injected in these datasets. We are happy and grateful to anyone who submits IP location corrections to us but we do verify these correction submissions for that reason.From my experience with our probe network, I can definitely say that it is far easier and cheaper to buy a server in New York than in any country in the middle of Africa. Location of an IP address greatly influences the value it can provide.We have a free IP to Country ASN database that you can use in your project if you like.https:&#x2F;&#x2F;ipinfo.io&#x2F;developers&#x2F;ip-to-country-asn-database reply incolumitas 19 hours agoparentBig fan of what articles? On https:&#x2F;&#x2F;incolumitas.com&#x2F; or on https:&#x2F;&#x2F;ipapi.is&#x2F;?Great idea with latency triangulation, I used latency information for a lot of things, especially VPN and Proxy detection.But I didn&#x27;t assume you can obtain that accurate location. I am honestly impressed. But latency triangulation with 600 servers gives some very good approximation. Nice man!Some questions:- ICMP traffic is penalised&#x2F;degraded by some ISP&#x27;s. How do you deal with that?- In order to geolocate every IPv4 address, you need to constantly ping billions of IPv4&#x27;s, how do you do that? You only ping an arbitrary IP of each allocated inetnum&#x2F;NetRange?- Most IP addresses do not respond to ICMP packets. Only some servers do. How do you deal with that? Do you find the router in front of the target IP and you geolocate the closest router to the target IP (traceroute)? reply reincoder 19 hours agorootparenthttps:&#x2F;&#x2F;incolumitas.com&#x2F;This is my all-time favorite article: https:&#x2F;&#x2F;incolumitas.com&#x2F;2021&#x2F;11&#x2F;03&#x2F;so-you-want-to-scrape-lik...I used to do freelance web scraping, and that article felt like some kind of forbidden knowledge. After reading the article, I went down the rabbit hole and actually found a Discord server that provided carrier-grade traffic relay from a van which contained dozens of phones.For the questions..... we have to kinda wait a bit, someone from our engineering team might come here and reply.By the way, as I have you here have you considered converting the CSV files to MMDB format? I was planning to do that with our mmdbctl tool later today.https:&#x2F;&#x2F;github.com&#x2F;ipinfo&#x2F;mmdbctl reply withinboredom 19 hours agorootparentprevI&#x27;m very curious why you&#x27;d do VPN&#x2F;proxy detection...But at a previous company I worked at that ran a very large chunk of the internet, we did indexing of nearly the entire internet (even large portions of the dark web) approximately every two weeks. There were about 500 servers doing that non-stop. So, I think it is relatively reasonable if you have 600 servers to do that. reply meroje 18 hours agorootparentIn the business of media streaming, rightholder will require that you check for vpn and proxies in addition to countries when deciding if a given viewer will be able to stream a given media. reply withinboredom 18 hours agorootparentDoes that actually work? That could explain an issue with a particular streaming service I use. There are currently some ongoing routing issues in BGP land and my ISP. When trying to stream, it says I’m using a proxy, so due to the incredible route my packets are taking, that might be it. What’s funny is that the only way to watch this service is to use a vpn right now. reply meroje 1 hour agorootparentRouting should not impact the detection, it&#x27;s usually based on maxmind&#x27;s anonymous&#x2F;datacenter database using your IP. Accuracy won&#x27;t be 100% of course but you have to show compliance. reply vGPU 14 hours agorootparentprevThey probably just keep a list of known VPN server IP’s. reply sitzkrieg 16 hours agorootparentprevof course it doesnt work but they gotta try clutching pearls and applying whatever pressure they can think of on these fronts reply wpietri 15 hours agorootparentWhy is this getting downvoted? It seems to me that a lot of the media-focused anti-piracy tooling is essentially a performance of toughness to make rightsholder execs comfortable. Everybody accepts you can&#x27;t stop piracy entirely, and nobody&#x27;s willing to say, \"Fuck it, we&#x27;ll compete on convenience and strong consumer relationships,\" so we all put up with this weird middle ground of performative DRM and the like. With only the rare occasional bit of honesty, as from Weird Al: https:&#x2F;&#x2F;sfba.social&#x2F;@williampietri&#x2F;110906012997848549 reply fomine3 8 hours agorootparentI love that HLS+AES \"encryption\" is still in use, thanks to Apple. reply at_a_remove 14 hours agorootparentprevThis is correct. Imagine in the days of yore, some two decades and change ago, when I was charged with implementing putting some music reserves \"online\" for streaming ...[Harp music, progressive diagonal wave distortions through the viewport ...]We had two layers of passwords (one to get to the webpage for the class, one when actually streaming via the client, which was RealPlayer) as well as an IP range restriction to campus (you live off campus? So sorry) because our lawyers were worried about what the RIAA&#x27;s lawyers would find sufficient in the wake of a bunch of Napster-baited lawsuits launched at universities. The material itself was largely limited to snippets.I wanted to say, \"Calm down, have a martini or something. College students are just not going to go wild to download 128 kbps segments of old classical music,\" but alas I was not in charge. replycarlhjerpe 12 hours agorootparentprevYou can guess pretty well how IP&#x27;s are related by BGP announcements, so as long as a few per block and if small, ASN. You can use that logic. reply matsur 19 hours agoparentprevICMP response time not useful for “locating” an anycasted address, some of which have logical location associated with them. See https:&#x2F;&#x2F;blog.cloudflare.com&#x2F;icloud-private-relay&#x2F; for an example reply cuu508 15 hours agorootparentWell, at least you can detect it is an anycast address, and mark it as such. reply welder 15 hours agoparentprevGreat comment. I&#x27;m a big fan and customer of IPinfo, using your API in our login notification emails to say \"You just logged in from Berlin, Germany. If this wasn&#x27;t you click here.\" To provide country data for customers in their audit logs. And for anti-spam and fraud detection. reply reincoder 3 hours agorootparentI appreciate it, sir! If you have any questions or feedback, please let us know.The challenge of being a data provider is that you can use our data in a million ways, and we don&#x27;t have coverage of all. So, when you come up with questions or ideas, we can help you better.As you mentioned, audit logs. I highly recommend you look into the ASN field.The ASN identifies an organization that owns a block of IP addresses. In my experience, I have found that the combination of ASN+Country is the most valuable information you can use in spam and fraud detection. You can fake the IP geolocation information with a VPN. However, it is not as easy to fake the ASN information of the IP address. So, when you use a combination of country + ASN, you can have a robust cybersecurity system. reply welder 3 hours agorootparentCan you explain more how to use ASN to detect fraud and how it&#x27;s different from the country detected for the IP? I thought ASN was derived from the IP, basically the route to that IP? Here&#x27;s the ipinfo response for an IP used by a recent fraud signup attempt. The asn field matches country. { \"city\": \"Mumbai\", \"connection\": { \"asn\": 24560, \"isp\": \"Bharti Airtel Ltd.\" }, \"continent_code\": \"AS\", \"continent_name\": \"Asia\", \"country_code\": \"IN\", \"country_name\": \"India\", \"currency\": { \"code\": \"INR\", \"name\": \"Indian Rupee\", \"plural\": \"Indian rupees\", \"symbol\": \"Rs\", \"symbol_native\": \"\\u099f\\u0995\\u09be\" }, \"ip\": \"2401:4900:1f38:7402:5569:2e45:3bb:9c0d\", \"latitude\": 19.076000213623047, \"location\": { \"calling_code\": \"91\", \"capital\": \"New Delhi\", \"country_flag\": \"https:&#x2F;&#x2F;assets.ipstack.com&#x2F;flags&#x2F;in.svg\", \"country_flag_emoji\": \"\\ud83c\\uddee\\ud83c\\uddf3\", \"country_flag_emoji_unicode\": \"U+1F1EE U+1F1F3\", \"geoname_id\": 1275339, \"is_eu\": false, \"languages\": [ { \"code\": \"hi\", \"name\": \"Hindi\", \"native\": \"\\u0939\\u093f\\u0928\\u094d\\u0926\\u0940\" }, { \"code\": \"en\", \"name\": \"English\", \"native\": \"English\" } ] }, \"longitude\": 72.87770080566406, \"region_code\": \"MH\", \"region_name\": \"Maharashtra\", \"time_zone\": { \"code\": \"IST\", \"current_time\": \"2023-09-15T10:52:42+05:30\", \"gmt_offset\": 19800, \"id\": \"Asia&#x2F;Kolkata\", \"is_daylight_saving\": false }, \"type\": \"ipv6\", \"zip\": \"400203\" }Here&#x27;s the response from ipinfo.io which includes privacy fields. It&#x27;s technically a proxy but might be hard to detect because it&#x27;s probably a crowdsourced&#x2F;botnet proxy not a public one. We don&#x27;t pay for { \"ip\": \"2401:4900:1f38:7402:5569:2e45:3bb:9c0d\", \"city\": \"Najafgarh\", \"region\": \"Delhi\", \"country\": \"IN\", \"loc\": \"28.6114,77.2982\", \"org\": \"AS24560 Bharti Airtel Ltd., Telemedia Services\", \"postal\": \"110097\", \"timezone\": \"Asia&#x2F;Kolkata\", \"asn\": { \"asn\": \"AS24560\", \"name\": \"Bharti Airtel Ltd., Telemedia Services\", \"domain\": \"airtel.com\", \"route\": \"2401:4900:1f38::&#x2F;48\", \"type\": \"isp\" }, \"company\": { \"name\": \"ABTS (Karnataka),\", \"domain\": \"airtel.com\", \"type\": \"isp\" }, \"privacy\": { \"vpn\": false, \"proxy\": false, \"tor\": false, \"relay\": false, \"hosting\": false, \"service\": \"\" }, \"abuse\": { \"address\": \"Bharti Airtel Ltd., ISP Division - Transport Network Group, 234 , Okhla Industrial Estate,, Phase III, New Delhi-110020, INDIA\", \"country\": \"IN\", \"email\": \"ip.misuse@airtel.com\", \"name\": \"ABUSE BHARTIIN\", \"network\": \"2401:4900:1f30::&#x2F;44\", \"phone\": \"+000000000\" } }EDIT: Oops, I confused ipinfo with ipstack. I&#x27;m actually using ipstack. Their security field also doesn&#x27;t detect this IP as a proxy, which is why we only pay for Professional (no security field). { \"ip\": \"2401:4900:1f38:7402:5569:2e45:3bb:9c0d\", \"type\": \"ipv6\", \"continent_code\": \"AS\", \"continent_name\": \"Asia\", \"country_code\": \"IN\", \"country_name\": \"India\", \"region_code\": \"MH\", \"region_name\": \"Maharashtra\", \"city\": \"Mumbai\", \"zip\": \"400203\", \"latitude\": 19.076000213623047, \"longitude\": 72.87770080566406, \"location\": { \"geoname_id\": 1275339, \"capital\": \"New Delhi\", \"languages\": [ { \"code\": \"hi\", \"name\": \"Hindi\", \"native\": \"\\u0939\\u093f\\u0928\\u094d\\u0926\\u0940\" }, { \"code\": \"en\", \"name\": \"English\", \"native\": \"English\" } ], \"country_flag\": \"https:&#x2F;&#x2F;assets.ipstack.com&#x2F;flags&#x2F;in.svg\", \"country_flag_emoji\": \"\\ud83c\\uddee\\ud83c\\uddf3\", \"country_flag_emoji_unicode\": \"U+1F1EE U+1F1F3\", \"calling_code\": \"91\", \"is_eu\": false }, \"time_zone\": { \"id\": \"Asia&#x2F;Kolkata\", \"current_time\": \"2023-09-15T12:27:08+05:30\", \"gmt_offset\": 19800, \"code\": \"IST\", \"is_daylight_saving\": false }, \"currency\": { \"code\": \"INR\", \"name\": \"Indian Rupee\", \"plural\": \"Indian rupees\", \"symbol\": \"Rs\", \"symbol_native\": \"\\u099f\\u0995\\u09be\" }, \"connection\": { \"asn\": 24560, \"isp\": \"Bharti Airtel Ltd.\" }, \"security\": { \"is_proxy\": false, \"proxy_type\": null, \"is_crawler\": false, \"crawler_name\": null, \"crawler_type\": null, \"is_tor\": false, \"threat_level\": \"low\", \"threat_types\": null } } reply EwanToo 12 hours agoparentprevHave you considered making your database available for download as Parquet format so people could just copy the file to S3, Google Cloud, etc, and query it immediately with various tools?I know it can be done with CSV but it&#x27;s not as smooth. reply reincoder 4 hours agorootparentThank you for the feature request.We usually just send users the documentation of ingesting the data in CSV or NDJSON format (Newline Delimited JSON). We don&#x27;t actually get many requests for data downloads in Parquet format. I think we have a few customers where we deliver the data in parquet format directly to their cloud storage bucket.But keep an eye out for our emails if we announce the parquet data downloads. I will talk with the folks about this.BUT, there are some good news.At least for the free database, we deliver the data directly to data warehouse platforms. Not even storage buckets. And we supply a good amount of documentation.We have the free database in Snowflake, GCP, Kaggle, and Splitgraph, and we are working on a few more deals. For the free database, atleast, we are working on better things than parquet. Like literally one-click solution to bring the IP data to your data warehouse.Kaggle: https:&#x2F;&#x2F;www.kaggle.com&#x2F;code&#x2F;ipinfo&#x2F;ipinfo-ip-to-country-asn-...Snowflake: https:&#x2F;&#x2F;app.snowflake.com&#x2F;marketplace&#x2F;listing&#x2F;GZSTZSHKQ4QY&#x2F;i...If you want to use our free IP database on Google Cloud or BigQuery, please send us an email (support@ipinfo.io) and mention that the DevRel sent you from HN. I can easily set you up with the free IP database in GCP&#x2F;BQ. reply detourdog 18 hours agoparentprevI just noticed that my wifes iphone uses the same mycingular ip address while driving accross 3 states over 5 hours.l while checking mail. reply inemesitaffia 18 hours agorootparentThere&#x27;s several options&#x2F;techniques for doing it. But just imagine you have a permanent zero overhead VPN.I don&#x27;t know if that provider terminates long running calls, but the calls would stay up too regardless of tower. reply detourdog 17 hours agorootparentYes, I’m sure it is iOS anti-tracking and directly related to why firewall apps inside SIP my not know what is going on. reply Vendan 14 hours agorootparentMore likely to be just standard Mobile IP https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mobile_IP. Fairly standard stuff, can cause some false positives around traveling (I&#x27;ve seen people get freaked out about stuff like \"This person just logged in from their home state and then less then an hour later logged in from France!\" when it was just mobile IP treating their phone as still in the US while they were in France on a trip, but their laptop connected over normal internet was seen as coming from France) reply detourdog 13 hours agorootparentthis was a consistent ip address nothing to do with location and nobody was freaked out. replyDaviey 18 hours agoparentprevWould you consider no-signup inspection of the data you hold on the requesters IP address? I would love to see what you have on MY IP address, and if sufficiency accurate it feels that it would be a good incentive to sign up to use commerically.It feels like it couldn&#x27;t be abused by &#x27;freeloaders&#x27;, because i&#x27;d guess their use-case is viewing other peoples. reply reincoder 16 hours agorootparentWe have a very open approach to our data. In fact, our website is extremely accessible. It is quite useful for researching IP addresses and does not require signing up. The data is largely available to view on the website. Although we display all IP address meta data on the home page, if you intend to use our website frequently, I recommend utilizing the IP data pages.You can enter IP addresses on the right side to look up information here: https:&#x2F;&#x2F;ipinfo.io&#x2F;what-is-my-ipAdditionally, we offer some enjoyable tools that you can use here: https:&#x2F;&#x2F;ipinfo.io&#x2F;toolsThe CLI tool is particularly entertaining.You can also use our API service without signing up, with a limit of 1000 requests per day.If you do choose to sign up for a free account, you will receive 50,000 requests per month, free IP databases, a bulk lookup feature, and more. reply kam 18 hours agorootparentprevThis is literally the most prominent thing on the https:&#x2F;&#x2F;ipinfo.io home page. reply qingcharles 17 hours agorootparentHuh, that&#x27;s cool. It got my home IP about 15 miles from where I am, but still not bad.Wait - how does this work for cell IPs? A lot of cellphone v4 IPs are now shared between hundreds or thousands of devices, right? reply reincoder 16 hours agorootparentI work there, and I am supposed to know these things, but I don&#x27;t exactly :&#x2F;It probably has something to do with important routers. What tags do we show when you visit the IP data page? The IP data page can be accessed by visiting ipinfo.io&#x2F;.We use the generic term \"data experts,\" but it actually consists of about 2 dozen engineers, including data engineers, data scientists, infrastructure engineers, backend engineers, and a great technical CEO working on all that. All those folks have gone on a boating trip off the coast of Spain for a retreat.....except for me.I will ask them and try to circle back with some answers. reply Daviey 18 hours agorootparentprevThat&#x27;s embarrassing for me... I thought that was a static image of an example. And I did look through the site looking for a search. Oops. reply yrro 2 hours agoparentprevhm, ipinfo.io tells me that I&#x27;m using a VPN even though I&#x27;m not... reply reincoder 1 hour agorootparentOur VPN recognition is behavior-based. So, there is probably a chance that the IP address you are using is showing some of those behavior patterns.A behavior pattern could be that your IP address is being shuffled around random locations that go beyond the normal location shuffling of an ISP connection.Also, if your IP range is listed in some public datasets that belong to a VPN service, we could recognize your IP as a VPN.Please reach out to our support and let us know about this. Thanks reply theogravity 11 hours agoparentprevHow does that work with edge servers that use anycast to assume the same IP across different regions? reply SnorkelTan 11 hours agorootparentAren’t any cast addresses a specific subset of ips and thus knowable? Iirc, each autonomous system is allocated anycast ip space? reply sgjohnson 10 hours agorootparentNo. Any prefix can be anycasted. reply TheClassic 20 hours agoparentprevYour comment is extremely interesting and what I was hoping to learn from the article (without an existing source of information, how do we determine the location of an IP address). Thank you! reply reincoder 19 hours agorootparentI really appreciate. Thank you. We are very transparent about our process. If you have any questions, you can always reach out to us.We have a simplified explanation of our probe network here: https:&#x2F;&#x2F;ipinfo.io&#x2F;blog&#x2F;probe-network-how-we-make-sure-our-da...The only update is the number of servers is like 600+ now. The probe network is growing extremely rapidly.Our IP geolocation process is quite complicated, and we have a team of data engineers, infrastructure engineers, and data scientists working on various aspects of it. Therefore, our approach is users can ask us questions, and we will try our best to answer them. reply freedomben 18 hours agorootparentJust wanted to let you know, it&#x27;s this transparency that turned me into a customer!I love your company and service, but I hate your pricing. I work with a lot of small clients&#x2F;apps that paying for usage would be a no-brainer, but the defined monthly price buckets don&#x27;t make any economical sense at their scale. If you added a \"pay as you go\" tier that a small app could reasonably start by using dollars worth of API calls per month and grow from there, I&#x27;d be spreading your seed all over the place. I&#x27;m not saying this to rag on you, just trying to provide some constructive feedback as a thank you for your info sharing! reply reincoder 17 hours agorootparentThank you very much; I really appreciate your feedback. This is not the first time I have heard this. The solution is to try to take as much advantage as you can from the free tier.# Check out the free IP databaseshttps:&#x2F;&#x2F;ipinfo.io&#x2F;products&#x2F;free-ip-databaseThe free databases come with commercial usage permission, and because they are databases, you can make unlimited lookups from them. The databases provide full accuracy and are updated daily. They are just a subset of our IP geolocation database that only provides IP to Country information.# Complement the database with the API serviceIf you only want city-level information, switch to the API service. Use the database to look up IP-to-country information as many times as you want. However, use the API service only when necessary.Additionally, if you include a credit link to us, we will double your API limit to 100k&#x2F;month. Visit https:&#x2F;&#x2F;ipinfo.io&#x2F;contact&#x2F;creditlink.# Cache dataAll of our API libraries have native caching support. We strongly recommend that users reduce their number of requests by caching the response. I highly recommend you check out our libraries: https:&#x2F;&#x2F;github.com&#x2F;ipinfo---The only challenge with the free IP databases is that you need to host the database somewhere to lookup the IP to Country information. Having an API service with nearly unlimited lookups for IP to Country information will be fantastic.If you know someone who has an IP to Country as API service please, let me know. We only require an attribution for using our database. If you have a similar service that is popular but don&#x27;t want to maintain it let us know as well, we can takeover the site and host it ourselves with the IP to Country data. reply freedomben 11 hours agorootparentThank you, that&#x27;s super useful info. I didn&#x27;t realize you had an Erlang library! I&#x27;m definitely going to be putting that to use :-) replyvoltagex_ 20 hours agoparentprevCan your probes be identified and blocked? reply reincoder 19 hours agorootparentIt is just ping data. We ping an IP address, get the RTT, draw a radius on the globe, and say that the IP could be anywhere inside that radius. Then we do another ping and draw another radius, and at the cross-section of the two radii could be your IP address. Now, if we do it enough times, we can get an estimate of where the IP address is located.The data is not derived from the IP address itself, but rather from the process itself. And it&#x27;s just a ping. Moreover, the majority of the IP addresses are not pingable. So, we rely on other in house statistical and scientific models to estimate the location. The probe infrastructure is extremely complicated and there are billions and billions of IP addresses, which is why we do not have a robust range filter mechanism.You can implement a dynamic ping blocking mechanism or use our data to find hosting ASNs and block ranges of those ASNs. You can download the database for free: https:&#x2F;&#x2F;ipinfo.io&#x2F;developers&#x2F;ip-to-country-asn-database reply kube-system 19 hours agorootparentprevnext [–]iptables -A INPUT -p icmp -j DROP reply voltagex_ 19 hours agorootparenthttp:&#x2F;&#x2F;shouldiblockicmp.com&#x2F;(But the guy running the probes is making a good counter argument) reply j16sdiz 19 hours agorootparentprevThis breaks PMTU and is the source of many mystery download stalls reply chaps 19 hours agorootparentprevThis isn&#x27;t helpful. The comment was specifically asking about the probes, not ICMP traffic. reply kube-system 19 hours agorootparentAnybody can do this same thing, if you&#x27;re worried about this, you probably don&#x27;t want inbound ICMP. reply chaps 19 hours agorootparentCool. Thanks. But let&#x27;s say I do. reply kube-system 18 hours agorootparentThen there&#x27;s nothing you can do. If you respond to pings, then others can take note of the responses you send. reply sgjohnson 1 hour agorootparentAnd if you don&#x27;t respond to pings, a traceroute can still be used to find the hop before yours, which will almost certainly achieve the same result for geolocation purposes. reply chaps 18 hours agorootparentprevYou&#x27;re missing the point that the question is effectively asking for a list of hosts that they can block.Edit: they provided a method: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37510063 reply kube-system 18 hours agorootparentI understand that was the initial question. I am saying that is a fools errand. Anyone with a few VPSes, a calculator, and a map can do this. It isn&#x27;t just ipinfo.io doing this. There are a lot of ip geolocation services. replyeptyc1 19 hours agorootparentprevIndeed. Openwrt for some reason defaults to reply to pings. I see the value of ICMP for servers, but I don&#x27;t see the value for home ISP routers.I disabled ICMP reply on my home router. reply sambazi 17 hours agorootparent> Openwrt for some reason defaults to reply to pings.it&#x27;s a bit like greeting-back ppl on the street.not doing it will not make you invisible. it will break somebody&#x27;s assumption of decency, but most ppl don&#x27;t care either way. reply sgjohnson 1 hour agorootparentprev> I disabled ICMP reply on my home router.Doesn&#x27;t actually help at all because the BGP announced prefix of your IP can still be tracerouted. You won&#x27;t be physically far from it.Say if your ISP announces 125.15.18.0&#x2F;17 and you&#x27;re in 125.15.29.145, a traceroute will still yield a pretty good approximation of where you&#x27;re at. The last hop ping is really quite immaterial here. reply chankstein38 18 hours agoparentprevThat&#x27;s pretty neat! You&#x27;re basically using ping triangulation! reply sib 15 hours agorootparentTrilateration (same technique as used for mobile network location - in addition to the GPS on the phone) reply tmaly 8 hours agoparentprevAre there any historical sources for geo ip info? reply reincoder 5 hours agorootparentWe don&#x27;t have any free data for that. We have historical data that we sell as part of our custom enterprise deals. Historical data requests are rare, though.A time series IP database requires a substantial amount of storage and computational cost to query, as I imagine. The city level geolocation data we have is ~1.5 gb in size. IP range data is complicated to query efficiently as you need to understand data platform settings and good amount of computer network math and computer science stuff. Adding a layer of time series complexities on top of that, makes this process quite difficult.To give you some context of how IP metadata lookups work, you can check out this articlehttps:&#x2F;&#x2F;ipinfo.io&#x2F;blog&#x2F;ip-address-data-in-snowflake&#x2F;Even if you keep all your database in a binary format, the computational cost is still non-negligible. reply chaps 20 hours agoparentprevNot gonna lie, this creeps the heck out of me. reply reincoder 19 hours agorootparentThousands of people live in a zip code, while hundreds and thousands of people live in a city. We are literally giving away that data for free through our API and database. The creepiness of IP geolocation is mostly a meme.IP geolocation is mainly used in cybersecurity and marketing analytics. There are many ways to geolocate someone. I once came across a project that could estimate the country a user is from based on their writing style and grammar mistakes. For example, American people sometimes use \"should of\" instead of \"should have\". Knowing the geolocation of an IP address isn&#x27;t super creepy. It&#x27;s just how things work on the internet. reply chaps 18 hours agorootparentAnd you&#x27;re literally advertising this project as being helpful for targeted ads. So it&#x27;s pretty clear from the get go that what you consider creepy isn&#x27;t what I consider creepy. And having done enough reidentification work to scare myself, \"thousands of people\" might as well be a couple dozen or less. I get why you&#x27;re defensive and why you think it&#x27;s not creepy, but calling it a \"meme\" is insultingingly dismissive.Just because it&#x27;s \"how things work on the internet\" doesn&#x27;t make its mass collection right. Under the same logic, any side channel attack is just \"how it works\", and its abuse warrants no ethical question. reply reincoder 17 hours agorootparentI grok and understand your concern. I am not being defensive; I am just trying to provide an explanation. I really enjoy having conversations like this with developers as honestly and empathetically possible.I apologize if I was rude in any way by saying the word \"meme\". I saw a sister comment and thought you were being sarcastic. There is a popular meme about \"I have your IP address\", so I thought you were referencing that. I have had conversations with many young people who were concerned about their IP address being leaked through a game server. Therefore, I try to use humor to alleviate their stress. However, I now realize that this situation was different, and I am sorry for not understanding that.We provide a service that helps users keep their internet-connected services secure by providing IP metadata information. Are you being attacked by malicious actors? Use our free IP database to identify the location and ASN to block them. Do you want to restrict access to your service to certain regions? Do that for free with our services.We have the most accurate data available, and yet we offer the most generous free tier. We provide a full accuracy IP database for free, without any range aggregation, and with daily updates and a commercially permissible license. We have built a community forum solely dedicated to answering users&#x27; questions. We invest in website tools and open-source tools, all with the goal of helping users maintain the security and functionality of their services.We do have premium tier services, but if you use our free data as a foundation, you can always replicate those premium features to a reliable degree.Our IP metadata information is being used in marketing and sales intelligence. It is the same data that you use to protect your internet connected devices, used by our customers to sell you something.IP metadata information that we provide is a cornerstone of keeping the internet safe and accessible for everyone. That is how things just are. The deepweb is immune to IP meta data information, and that is why it is such a messy and chaotic place.That is just truth of the internet. We are essential and we prefer to be open about our process and listen to our stakeholders (users + customers + non-users). reply chaps 17 hours agorootparentThank you for the well thought out response. I disagree with just about everything you say, but I understand where you&#x27;re coming from and I appreciate the validation that the use of a VPN is more important than it&#x27;s ever been. As a professional courtesy: calling yourself \"essential\" is an enormous red flag and you might want to consider different phrasing. reply reincoder 16 hours agorootparentI should have used a different phrasing. :) I was reading an article about essential workers today, and that word popped up in my head when I wrote the comment.It&#x27;s good that you are using a VPN. I advocate for the usage of VPNs, and many VPN companies actually use our data to verify their server locations. In the VPN industry, VPN companies get their VPN servers from specialized hosting services that cater to dozens of VPN companies. You can check out the ASNs of the VPN IP addresses to find them.- https:&#x2F;&#x2F;ipinfo.io&#x2F;AS136787- https:&#x2F;&#x2F;ipinfo.io&#x2F;AS16247VPN companies use our IP geolocation data to confirm the actual location of their servers. Let me tell you a fun story. One VPN company claimed to have a server in the Bahamas, but upon investigation, we discovered that the server was actually located in New York. It was a surprising find. Getting a server in the Bahamas is more challenging than getting one in NY. Just imagine users thinking their internet activity is immune to US jurisdiction because they are using a VPN service based in Bahamas but in fact it is actually located in NY. So, we might not be essential, but we are certainly very useful!Thank you for the great conversation, dude. Appreciate it. reply wpietri 15 hours agorootparentprevFor sure. When people work in any industry long enough, it&#x27;s easy to stop thinking about the basics. E.g., a retail butcher thinks of his work very differently than a cow or a vegan does.When people work in advertising, they mostly forget that the core of their business is for-profit manipulation of people with little or no regard for truth or the people concerned. But I personally think that&#x27;s kinda creepy, and only getting more so as it goes from broad manipulation of millions via mass media down to thousands, hundreds, or single individuals. reply reincoder 5 hours agorootparentThat is a good point. I will try to add some additional points to your statement.In the context of a butcher and a vegan we are not either of them, we would be someone who sell salt. Salt as an ingredient is used by vegans, vegetarians, and meat eaters.Salt is useful, and it is a complimentary item that makes the food taste better. But it is not a main feature of any dish. Salt plays an important and somewhat universally required item in any dish, but this is not the main feature of the dish you eat.We are a data company. This IP metadata we sell is important to run a service that is connected to the internet. We are focused on serving cybersecurity as we are focused on other industries which includes adtech and sales intelligence.IP metadata is used in threat intelligence, building firewalls, and attack surface management. On the other hand, when you are running a business at scale, you need to invest into understanding your target demographics. That is where largely adtech companies use our data. They need data and context to understand who their users are.IP metadata helps to prevent cyberattacks to happen at a very early stage through firewall blocking. IP metadata, used through threat intelligence, can further strengthen firewalls to prevent future attacks. And IP metadata, can also be used in website personalization, adtech and sales intelligence etc.We believe that every internet connected services for profit and non-profit alike, should have access to some security resilience, that is why we offer so many good quality free data. reply wpietri 5 hours agorootparentHuh. Ignoring the somewhat strained metaphor, you seem to be suggesting that you don&#x27;t have moral responsibility for aiding the creepiness of professional manipulators because you also enable other things. I don&#x27;t think that&#x27;s true. But even if it were, it would only be so if it were a minimal, possibly negligible part of your business. What percentage of revenue would you say comes from adtech? reply reincoder 3 hours agorootparentI am happy to assist any business, organization or person to use our data. I enjoy talking with people and helping them with the technical and philosophical aspects of IP metadata.If you progressively remove the layers of metadata associated with internet-connected devices one by one from GPS data (user-permitted action) → IP geolocation (IPinfo.io)→ IP address (ISP), and come to a system that is completely anonymous, you have the dark web.The dark web represents an ecosystem that is completely devoid of ad tech because there is no identity, and the users are purely homogenous. The system itself is not widely adopted because internet participants need to feel secure from cyberattacks and harmful words. Traditional internet services do not exist there because they are getting bombarded with anonymous attacks, and they cannot provide any value to the customer because they don&#x27;t even know who&#x2F;what the user is.IP metadata helps with running a business and serves as a way to protect yourself. There are organizations and users who actively utilize our services to check email headers, find the IP address, and lookup the IP metadata of those IP addresses. The data is utilized for recognizing spam and phishing emails. Conversely, our service is also used in adtech-driven cold emails and newsletter services.IP metadata is required for a functioning and widely adopted internet. replyfragmede 19 hours agorootparentprevYour IP address is LEAKING! reply giantrobot 19 hours agorootparentprevYou might want to unplug your router then. A conceit of being connected to a network is you&#x27;re connected to the network. If you can see other nodes they can see you. reply goodpoint 17 hours agorootparentprevTogether with the tons of data leaked by browsers it makes it very easy to track people across places and devices. reply BonoboIO 6 hours agoparentprevHi, cool idea with the geolocation via latency.But I encountered 2 things using ipinfo: Hetzner Server that are in Germany in a fixed location that never moved are sometimes located in another country, for me it was once s Server placed into Moscow and once in South America.How does this happen? reply reincoder 3 hours agorootparentIf you can give me some information about the IP address or the IP range, I can take a closer look.I guess it is because of IPv4 trading or IP address shuffling.As far as I know, Hertzer, like many hosting companies, is buying IPv4 addresses around the world. Here is an article on the IPv4 trades:https:&#x2F;&#x2F;tech.marksblogg.com&#x2F;ipinfo-free-ip-address-location-...When a company buys an IP address block or relocates an IP block from one of its data centers to another, the location of those IP addresses changes.If your IP address is static, but we have made an error in geolocation, I would love to take a closer look. You can email our support (support@ipinfo.io) and send a link to the comment. We can discuss it further from there. reply louison11 21 hours agoprevIf you don&#x27;t want to do this yourself, you can actually just get Cloudflare to do it for you for free using a simple Worker since all Cloudflare requests contain approximate IP location information.You can also just send a request to my URL (Cloudflare Worker operated - so it should have global low latency): https:&#x2F;&#x2F;www.edenmaps.net&#x2F;iplocationUse it for small applications, I don&#x27;t mind. Just don&#x27;t start sending me 10M requests per day ;-) reply Aachen 20 hours agoparentOr you download an IP database rather than sharing with a third party which IP address is likely connecting to your service with a third party reply hotgeart 17 hours agoparentprevLocated 100km from the Somali coast... I&#x27;m in Brussels, Belgium, thx for protecting my privacy :D reply louison11 14 hours agorootparentThe result is [lon, lat]. You’ve most likely copied it onto Google maps, which works with [lat, lon]. Believe it or not, the industry still hasn’t come up with a standard order. reply emadda 19 hours agoparentprevDoes anyone know how accurate Cloudflare geolocation is (for workers requests)? reply banana_giraffe 19 hours agorootparentAs accurate as MaxMind[1], since that&#x27;s what they use [2]. In my experience, it&#x27;s reasonably accurate for the US, less so for other countries. MaxMind publishes some accuracy data which might be an interesting starting point [3]That said, for any analytics use cases of this data, be aware that MaxMind will group a lot of what should be unknowns in the middle of a country. Or, in the case the US now, I think they all end up in the middle of some lake, since some farm owners in Butler County, Kansas got tired of cops showing up and sued MaxMind. It can cause odd artifacts unless you filter the addresses out somehow.1 https:&#x2F;&#x2F;developers.cloudflare.com&#x2F;support&#x2F;network&#x2F;configurin...2 https:&#x2F;&#x2F;www.maxmind.com&#x2F;en&#x2F;geoip-demo3 https:&#x2F;&#x2F;www.maxmind.com&#x2F;en&#x2F;geoip2-city-accuracy-comparison reply matwood 11 hours agorootparentYeah, MaxMind is the best I have used with caveats. You need to update it frequently, and you need to allow for overrides. reply reincoder 18 hours agorootparentprevI work for IPinfo and we do ping based geolocation. The best thing you can do to verify geolocation accuracy is the following:- Download a few free IP databases - Generate a random list of IP addresses - Do the IP address lookups across all those databases - Identify the IP address that can be pinged - Visit a site that can ping an IP address from multiple server - Sort the results by lowest avg ping timeThen check where the geolocation provider is locating the IP address and what is the nearest server from there. reply noizejoy 8 hours agorootparentOn one hand, I love that there’s some good alternatives in the geolocation space, but misleading geolocation precision can lead to very undesirable side effects[0].[0] https:&#x2F;&#x2F;www.theguardian.com&#x2F;technology&#x2F;2016&#x2F;aug&#x2F;09&#x2F;maxmind-m... reply reincoder 4 hours agorootparentThat is part of the reason why I am here in HN. I am pretty down to earth and willing to talk with anyone about IP metadata.Our business approach is that we will come to you before you come to us. Whenever people complain about something related to IP data, I will just reach out to them and verify that we provide good data. Our support team is extremely responsive. We also have a community where we walk through users about IP metadata. I am super active on HN, Reddit and Twitter.The challenge for me is usually that we will tell people, \"We are providing good geolocation data for you, but the service that provides geolocation data to the service you are complaining about is not using our data. Our hands are tied.\" I have reached out to bigger corporations and streaming services to say, \"You are providing bad data to your customers. I am not even trying to sell you something. Even using our free database could lead you to better results.\" But I have not heard from them yet. It is frustrating to me as it is for the person with bad IP data.IP geolocation is never going to be absolutely accurate or precise. We understand that completely. Aside from continuously investing in improving our data from a product standpoint, we also take a very human approach of trying to fix every geolocation complaint one by one. reply carstenhag 11 hours agoparentprevI&#x27;m in Munich. Cloudflare tells a position that is 730km to the north in a random forest. reply louison11 4 hours agorootparentYou&#x27;ve inverted lat, lon. reply tiffanyh 20 hours agoparentprevThis is excellent!Would you mind open sourcing the code for that? reply louison11 17 hours agorootparentThis is the code running this endpoint: export function onRequest(context) { return new Response(JSON.stringify([parseFloat(context.request.cf.longitude), parseFloat(context.request.cf.latitude)]), {headers: {\"Content-Type\": \"application&#x2F;json;charset=UTF-8\"}}) }This is a function on Cloudflare Pages (which is just a different name for Cloudflare Workers). Minor adjustment needed for Workers (get rid of \"context\", I believe) reply junto 11 hours agoprevAs someone that lives in a country where the national language is not my first language, I hate websites that use IP location to make assumptions about my choice of language and it being forced on me based on a lazy assumption, when my browser is sending language headers quite clearly, and they are ignored. reply hedora 6 hours agoparentI live in the US, and IP geolocation points to the incorrect regions (plural) on all my devices.Few technologies manage to make my day-to-day internet experience than these sorts of databases.I wish they would just go away.Websites could just ask me my zipcode on first load instead of guessing it wrong every single time and then burying the flow to fix it behind multiple links and page loads.Also: There is no way to fix the database to produce the “correct” or “better” answer. I rarely want a website to use my current location.Instead, I check inventory for stores in places where I will be. This whole space is trying to solve an ill-posed problem. reply jedberg 17 hours agoprevIt all depends on what you want to use it for and how accurate it needs to be.The best way to build a geolocation service is to have a billion devices that report their location to you at the same time they report their IP to you. That&#x27;s basically Apple and Google. They have by far the best geolocation databases in the world, because they get constant updates of IP and location.The trick is basically to make an app where people willingly give you their location, and then get a lot of people to use it. That&#x27;s the best way to build an accurate geo-location database, and why every app in the world now asks for your location.4-square had the right idea, they were just ahead of their time. reply flounder3 16 hours agoparentEven 10 years ago, Apple internal privacy policies prevented itself from collecting precise lat&#x2F;long. We had to use HTTP session telemetry to determine which endpoints were best for a given IP (or subnet, but not ASN), which informed our own pseudo-geoIP database so we knew which endpoint to connect to based on real world conditions.Even still, it had to be as ephemeral as possible for the sake of privacy. We weren’t allowed to use or record results from Apple Maps’ reverse geo service outside of the context of a live user request (finding nearby restaurants, etc). reply jedberg 16 hours agorootparentYou don&#x27;t need precise lat&#x2F;lon to make a good database. Even a 1km circle would be more than enough.> but not ASNWhy wasn&#x27;t ASN allowed? That&#x27;s what Netflix used to make endpoint routing decisions and worked really well. reply flounder3 16 hours agorootparentYou’re not wrong, but privacy concerns were paramount.ASNs were allowed but too vague. We needed more granularity. Corporate proxies, subdelegations, many providers aggregating announcements below &#x2F;24, etc. replyhddqsb 19 hours agoprevSomewhat relevant: Google Maps can learn the location of your IP based on which locations you browse in the map. If you browse a specific location enough times, it will use that as the default location when you open Google Maps, even if you clear all cookies. (I discovered this just from using Google Maps, and I&#x27;m a little concerned by the privacy implications, considering that multiple people may share an IP address.) reply gniv 19 hours agoparentI suspect it&#x27;s the other way around. Google just has a very good IP geolocation db, so it uses that when you browse, absent any other info. reply hddqsb 18 hours agorootparentGoogle certainly uses its geolocation DB, but it also learns based on map browsing patterns.To clarify, the scenario I described is as follows: 1. Initially, when I open Google Maps in a clean browser it defaults to my real location. 2. I repeatedly browse some other location. 3. When I open Google Maps in a clean browser, it defaults to that other location. The only reason for Google Maps to pick that other location is my map browsing. reply gniv 18 hours agorootparentThanks for clarifying. That is indeed surprising and you are probably right. reply netsharc 18 hours agorootparentprevWell it has reporting beacons all over the world with GPS receivers, in the form of Android phones, and perhaps Google Maps users on iPhone too.. reply is_true 18 hours agoparentprevThat would explain why it sometimes it thinks I&#x27;m in a river I paddle often and other times where I have my summer house. reply dboreham 20 hours agoprevInteresting but this isn&#x27;t actually how geolocation is done, right? The ARIN&#x2F;RIPE data isn&#x27;t sufficiently accurate to be useful beyond country. Commercial geolocation involves correlating client IP vs known physical location e.g. from WiFi AP or mailing a package to the user. At least that&#x27;s what I have been told over the decades. reply shortrounddev2 20 hours agoparentI work in adtech and this is how we do geolocation. There&#x27;s also device geolocation but if the user doesn&#x27;t consent to sharing their GPS data with us, we just use IP address for targeting. Common provider for this is Maxmind; they ship a database that you host locally and query reply dawnerd 19 hours agorootparentEven the free maxmind db is accurate enough for most applications. reply tiffanyh 20 hours agorootparentprevDoes Cloudflare have the same data as Maxmind?Because Cloudflare and Maxmind geolocate me to the exact same longitude&#x2F;latitude. reply klaussilveira 20 hours agorootparentCloudFlare uses Maxmind: https:&#x2F;&#x2F;developers.cloudflare.com&#x2F;support&#x2F;network&#x2F;configurin... reply klaussilveira 20 hours agorootparentprevSince you are in adtech: do you buy MaxMind, or roll your own? Are there any providers for US-only data, and therefore, cheaper? reply shortrounddev2 20 hours agorootparentWe licensed Maxmind&#x27;s DB recently (it&#x27;s like $300 a year or something). idk if there are US-only databases. Our customers are all in the US, and we use geo IP to filter european users for compliance (GDPR and otherwise) reply nonethewiser 21 hours agoprevComments seem fairly dismissive but I actually found this really interesting. It reminds me of a task I had in my first position to add PostGIS to our database and a location based search. That was based off addresses and zipcodes. reply mannyv 16 hours agoparentThat&#x27;s relatively simple to do, even in mysql. One trick is to use a square instead of a circle, which avoids a lot of math. reply spacedcowboy 18 hours agoprevSo, at the risk of outing myself, I wrote http:&#x2F;&#x2F;www.hostip.info a long time ago* which used a community approach to get ip address location (\"is this guess wrong ? Fix it please\").The last time I checked (maybe a decade ago [grin]) it worked pretty much perfectly for a country, imperfectly for a region, and better-than-a-coin-toss for city resolution. All the data is free.I don&#x27;t think they have it on the site any more, but I used to have a rotating 3D-cube thing (x,y,z were the first 3 octets of the address) for things like known-addresses, recent lookups, etc. I used different colours for different groups (country, continent,...) It was so old it was written as a Java applet. Yeah. I guess if I were to do it again, it&#x27;d be WebGL.--*: I sold it a long time ago, with the proviso that the data must always remain free. I actually didn&#x27;t believe the offer at first (it came as an email, and looked like a scam) but it went through escrow.com just fine, and I think we both walked away happy. That was almost 2 decades ago now though. reply ipapi-co 6 hours agoprevGreat write-up ! Building a database from scratch is a good learning experience but the effort required for its daily upkeep and maintenance is no small feat.Shameless plug : We&#x27;ve faced these challenges head-on with our own solution over at https:&#x2F;&#x2F;ipapi.co . While it&#x27;s commendable to build from scratch, sometimes leveraging an established solution can be more beneficial, especially for businesses that need to hit the ground running. It might be a useful reference for comparison or for those seeking a SaaS solution.Regardless, appreciate the insights you&#x27;ve shared in this post. reply kiririn 20 hours agoprevA modern version of the ping-based geoip mentionedhttps:&#x2F;&#x2F;github.com&#x2F;Ne00n&#x2F;yammdb reply JoshGlazebrook 16 hours agoparentThis just links to a mmdb file that is already compiled, there isn&#x27;t anything relevant to show this is a \"modern\" implementation of anything if the implementation isn&#x27;t available. reply SirMaster 18 hours agoprevThese IP geolocation lookups never seen to work for me.They are always multiple states off, and checking multiple different services pretty much never even seem to agree. reply TZubiri 21 hours agoprev\"how to scrape an ip geolocation database\"You know you can just run a whois query per ip you want to analyze, no point in scraping the whole ipvN space. reply incolumitas 21 hours agoparentI have to scrape the whole IP address space since I offer location information as part of my API.Also I only need to scrape as many WHOIS records as there are different networks out there. So for example for the IPv4 address space, there are much less networks as there are IPv4 addresses (2^32).Also, most RIR&#x27;s provide their WHOIS databases for download.Therefore, \"scraping\" is not really the correct word, it&#x27;s an hybrid approach, but mostly based on publicly available data from the five RIR&#x27;s. reply notlukesky 21 hours agorootparentWhat was the easiest and the most frustrating part? reply incolumitas 10 hours agorootparentLACNIC is a fucking pain in the ass since they block after like 27 recordsARIN is awesome reply djbusby 21 hours agoparentprevThe whois data for IP is not accurate. reply gsich 12 hours agoparentprevwhois has no sane format. reply ggm 9 hours agorootparentRDAP is run by all the RIR and is Json and has all the whois data except IRR.And it does 302 redirect to best source. reply fabioyy 5 hours agopreva long time ago i build a project like that but instead of relying on whois. i did a traceroute to every ipv4 address avaliable. several router hops, have a reverse dns that uses some names that include city codes, (like airport codes ). most providers have a single hop for a city. so its easy to correlate the latest router hop to a city. reply fasteo 20 hours agoprev>>> Consider Open Source Geolocation ProjectsNot the definition of \"from scratch\" in my book reply overcast 21 hours agoprevStep 1: Download Geolocation Database reply Aachen 20 hours agoparentScroll down, the article is confusingly below that reply nonethewiser 21 hours agoparentprevStep 1: Download Geolocation DataUnless you think CSV is a database? reply debesyla 20 hours agorootparentMaybe a dumb question (I have no knowledge), but why wouldn&#x27;t we think of .CSV files as databases? It can have columns and rows filled with information and isn&#x27;t that what makes a thing a database? reply nobleach 20 hours agorootparentBest I can guess here, the reply is considering relational databases as \"real databases\" and flat files.... not real. reply nobleach 20 hours agorootparentprevAre we really going to do the mincing of words here? Did you need the word \"dump\" or \"export\" before you understood? Although I wasn&#x27;t wild about the original poster&#x27;s \"step 1\" terseness, it&#x27;s silly to think a normal person wouldn&#x27;t be able to parse the sentence well enough to understand \"download the database contents - perhaps stored in CSV format\". reply tmpX7dMeXU 20 hours agorootparentprevIf in your mind database implies a type of technology and not something conceptual, you’re really just outing yourself as someone that needs someone between you and the boardroom. Certainly not something to show off on Hacker News. reply mootothemax 21 hours agoprevAny suggestions for geolocating datacenter IPs, even very roughly? I&#x27;m analysing traceroute data, and while I have known start and end locations, it&#x27;s the bit in the middle I&#x27;m interested in.I can infer certain details from airport codes in node hostnames, for example.It would also be possible - I guess - to infer locations based on average RTT times, presuming a given node&#x27;s not having a bad day.Anyone have any other ideas?Edit: A couple of troublesome example IPs are 193.142.125.129, 129.250.6.113, and 129.250.3.250. They come up in a UK traceroute - and I believe they&#x27;re in London - but geolocate all over the world. reply toast0 13 hours agoparentThose IPs are owned by Google and NTT, who both run large international networks and can redeploy their IPs around the world when they feel like it. So lookup based geolocation is going to be iffy, as you&#x27;ve seen.Traceroute to those IPs certainly looks like the networking goes to London.The google IP doesn&#x27;t respond to ping, but the NTT&#x2F;Verio ones do. I&#x27;d bet if you ping from London based hosting, you&#x27;ll get single digit ms ping responses, which sets an upper bound on the distance from London. Ping from other hosting in the country and across the channel, and you can confirm the lowest ping you can get is from London hosting, and there you go. It could also be that its connectivity is through London, but it&#x27;s elsewhere --- you can&#x27;t really tell.Check from other vantage points, just to make sure it&#x27;s not anycast; if you ping 8.8.8.8 from most networks around the world, you&#x27;ll get something nearby; but these IPs give traceroutes to london from the Seattle area, so probably not anycast (at least at the moment, things can change).If you don&#x27;t have hosting around the world, search for public looking glasses at well connected network that you can use for pings like this from time to time. reply tyingq 20 hours agoparentprevThis looked promising:\"TULIP&#x27;s purpose is to geolocate a specified target host (identified by IP name or address) using ping RTT delay measurements to the target from reference landmark hosts whose positions are well known (see map or table).\"https:&#x2F;&#x2F;tulip.slac.stanford.edu&#x2F;But the endpoint it posts to seems dead. reply vinay_ys 20 hours agoparentprev> A couple of troublesome example IPs are 193.142.125.129, 129.250.6.113, and 129.250.3.250. They come up in a UK traceroute - and I believe they&#x27;re in London - but geolocate all over the world.If I&#x27;m running a popular app&#x2F;web service, I would have my own AS number and I will have purchased a few blocks of IP addresses under this AS and then I would advertize these addresses from multiple owned&#x2F;rented datacenters around the world.These BGP advertisements would be to my different upstream Internet service providers (ISPs) in different locations.For a given advertisement from a particular location, if you see a regional ISP as upstream, you can make an educated guess that this particular datacenter is in that region. If these are Tier 1 ISPs who provide direct connectivity around the world, then even that guess is not possible.You can see the BGP relationships in a looking glass tool like bgp.tools – https:&#x2F;&#x2F;bgp.tools&#x2F;prefix&#x2F;193.142.125.0&#x2F;24#connectivityIf you have ability to do traceroute from multiple probes sprinkled across the globe with known locations, then you could triangulate by looking at the fixed IPs of the intermediate router interfaces.Even this is is defeated if I were to use a CDN like Cloudflare to advertise my IP blocks to their 200+ PoPs and ride their private networks across the globe to my datacenters. reply sgjohnson 1 hour agorootparent> If you have ability to do traceroute from multiple probes sprinkled across the globe with known locationsEveryone who&#x27;s aware of RIPE Atlas has that ability.I have almost a billion RIPE Atlas credits. A single traceroute costs 60. I have enough credits to run several traceroutes on the entire IPv4 internet. (the smallest possible BGP announcement is &#x2F;24, so max of 2^24 traceroutes, but in reality it&#x27;s even less). reply dontdoxxme 20 hours agoparentprevhttps:&#x2F;&#x2F;ensa.fi&#x2F;papers&#x2F;geolocation_imc17.pdf has some ideas.Using RIPE atlas probes to get RTT to the IPs from known locations is close to your idea and probably the best anyway. reply ggm 9 hours agoprevrfc8805 https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;rfc8805&#x2F;rfc9092 https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;rfc9092&#x2F; reply johnklos 19 hours agoprevI think it&#x27;s interesting that the one IP range I decided to check has correct information on the ipapi.is web site, but unambiguously incorrect information in the downloadable geolocationDatabaseIPv4.csv. Somehow Bedford, New Hampshire (which came straight from WHOIS) became Bedford, Texas.How&#x27;d that happen? reply bjornsing 17 hours agoprevI expected traceroute to play a bigger part in this. If you know the route to an IP address and the location of routers, perhaps even from a few different servers, then you should be able to locate it fairly well. reply sneak 19 hours agoprevI feel like a more useful and accurate way would be to buy client ip and GPS location data in bulk from one of the mobile data brokers who have their spyware embedded in zillions of popular apps&#x2F;games and then group it by &#x2F;24 or something. reply ChopSticksPlz 20 hours agoprevThis is a very useful .csv, what is the license? Is it free for personal and commercial use? reply cstuder 21 hours agoprevQuestion: What’s the motivation to put coordinates in one’s own WHOIS record? (geoloc&#x2F;geofeed) reply incolumitas 21 hours agoparentMany service providers actually want their clients to be able to locate them. reply noizejoy 8 hours agorootparentI’m duplicating my comment elsewhere in this thread, so each serves as a direct reply to the different geolocation providers in this thread, in the hope that it will be recognized as a problem with data that implies that it’s more precise than it really is:> On one hand, I love that there’s some good alternatives in the geolocation space, but misleading geolocation precision can lead to very undesirable side effects[0].[0] https:&#x2F;&#x2F;www.theguardian.com&#x2F;technology&#x2F;2016&#x2F;aug&#x2F;09&#x2F;maxmind-m... reply dontdoxxme 20 hours agoparentprevgeofeed is used by big CDNs, it can actually help save money for the provider by meaning a CDN uses a more optimal network location. reply jl6 20 hours agoprevIs anybody maintaining a historical archive of “IP address metadata” (which would include geolocation)?If I have logs from 10 years ago, can I look up information about that IP as it was at the time? reply quectophoton 50 minutes agoparentMaybe not exactly what you&#x27;re looking for, but the ipfire project has a git repository[1] mapping address ranges to countries. It apparently going back to 2017 only.[1]: https:&#x2F;&#x2F;git.ipfire.org&#x2F;?p=location&#x2F;location-database.git;a=s... reply bullen 20 hours agoprevHere is a solution for those that care about speed:https:&#x2F;&#x2F;www.miyuru.lk&#x2F;geoiplegacy reply alberth 11 hours agoprevWhat are common use cases for needing IP geolocation? reply bagels 17 hours agoprevSurely someone is using online shopping shipping addresses for this? reply nanmu42 20 hours agoprevThanks for sharing.I have heard there is much effort to use BGP data to build GeoIP database. reply jwie 19 hours agoprevThe easiest way to get a geolocation is to ask the user. Maybe they’ll just tell you, and if that’s good enough for your application there’s no need for such solutions. reply n2dasun 16 hours agoprev [–] Step 1. Download Visual Basic replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "IP geolocation's application in targeted advertising, fraud detection, content localization, network security, and analytics is discussed, along with the challenges of geolocating IP addresses.",
      "The article lays out how to build a geolocation database using WHOIS records and open-source projects, and addresses the limited coverage of geolocation attributes in the RIPE NCC database.",
      "The limitations and alternatives of using geolocation data from IP addresses are explored, such as other geolocation projects and third-party sources for data enrichment, concluding with a mention of ipapi.is."
    ],
    "commentSummary": [
      "The text focuses on establishing an accurate IP geolocation database from scratch, emphasizing the significance of IP location accuracy, and discussing various methodologies like using MMDB format for CSV files.",
      "Attention is given to the detection of VPNs and proxies, the use of IPinfo's API for fraud detection, difficulties of detecting anycasted addresses, and privacy implications surrounding geolocation data.",
      "The reliability of geolocation services such as MaxMind and Cloudflare is questioned, with alternative methods like traceroute analysis and BGP advertisements proposed as replacements. The importance of these databases for companies like Google is also stressed."
    ],
    "points": 400,
    "commentCount": 154,
    "retryCount": 0,
    "time": 1694689246
  },
  {
    "id": 37507226,
    "title": "Calif. passes strongest right-to-repair bill yet, requiring 7 years of parts",
    "originLink": "https://arstechnica.com/gadgets/2023/09/calif-passes-strongest-right-to-repair-bill-yet-requiring-7-years-of-parts/",
    "originBody": "SKIP TO MAIN CONTENT BIZ & IT TECH SCIENCE POLICY CARS GAMING & CULTURE STORE FORUMS SUBSCRIBE SIGN IN REPAIR LEGISLATION — Calif. passes strongest right-to-repair bill yet, requiring 7 years of parts Repair shops must disclose if they're using \"non-authorized\" parts. KEVIN PURDY - 9/13/2023, 12:30 PM Enlarge iFixit 101 WITH California, the home to many of tech's biggest companies and the nation's most populous state, is pushing ahead with a right-to-repair bill for consumer electronics and appliances. After unanimous votes in the state Assembly and Senate, the bill passed yesterday is expected to move through a concurrence vote and be signed by Governor Gavin Newsom. \"Since Right to Repair can pass here, expect it to be on its way to a backyard near you,\" said iFixit CEO Kyle Wiens in a statement. iFixit, a seller of repair parts and tools and advocate for right-to-repair laws, based in San Luis Obispo, California, was joined in its support for the California repair law by another California company with a history of opposing repair laws: Apple. The consumer tech giant's letter urging passage of the bill was surprising, to say the least, though Apple said that the bill's stipulations for \"individual users' safety\" and \"product manufacturers' intellectual property\" were satisfactory. Enter your email to get the Ars Technica newsletter Join Ars Technica and Get Our Best Tech Stories DELIVERED STRAIGHT TO YOUR INBOX. SIGN ME UP By signing up, you agree to our user agreement (including the class action waiver and arbitration provisions), our privacy policy and cookie statement, and to receive marketing and account-related emails from Ars Technica. You can unsubscribe at any time. California's bill goes further than right-to-repair laws in other states. Rather than limiting its demand that companies provide parts, tools, repair manuals, and necessary software for devices that are still actively sold, California requires that vendors provide those items for products sold after July 1, 2021, starting in July 2024. Products costing $50 to $99.99 must be accompanied by those items for three years, and items $100 and more necessitate seven years. The bill also provides for stronger enforcement mechanisms, allowing for municipalities to bring superior court cases rather than contact the state attorney general. Advertisement There are some concessions and potential pitfalls, however. Pricing of parts and tools is left at \"fair and reasonable terms.\" The bill requires repair vendors that are \"not an authorized repair provider\" to \"provide a written notice of that fact\" to customers and to \"disclose if it uses replacement parts that are used\" or third-party. Apple specifically advocated for consumer notice of third-party parts and unauthorized repair in its letter supporting the bill. Along with repair laws going into effect in 2024 in California, New York, and Minnesota (along with bills focused on agriculture and powered wheel chairs in Colorado), there are repair laws underway in Europe involving repair services, removable batteries, USB-C standardization, and other aspects of repair and sustainability. With three large states and Europe as a whole moving to enforce repairable design and after-purchase care, manufacturers may choose to offer compliant products everywhere, rather than divide their offerings. Apple, notably, made a point of the increased repairability and durability of the titanium-framed iPhone 15 announced yesterday. Disclosure: Kevin Purdy previously worked for iFixit. He has no financial ties to the company. READER COMMENTS 101 WITH KEVIN PURDY Kevin is a senior technology reporter at Ars Technica, covering a variety of technology topics and reviewing products. He started his writing career as a newspaper reporter, covering business, crime, and other topics. He has written about technology and computing for more than 15 years. Advertisement Channel Ars Technica SITREP: F-16 replacement search a signal of F-35 fail? Footage courtesy of Dvids, Boeing, and The United States Navy. SITREP: F-16 replacement search a signal of F-35 fail? Sitrep: Boeing 707 Steve Burke of GamersNexus Reacts To Their Top 1000 Comments On YouTube Scott Manley Reacts To His Top 1000 YouTube Comments LGR's Clint Basinger Reacts To His Top 1000 YouTube Comments How Forza's Racing AI Uses Neural Networks To Evolve The F-35's next tech upgrade Fighter Pilot Breaks Down Every Button in an F-15 Cockpit Linus \"Tech Tips\" Sebastian Reacts to His Top 1000 YouTube Comments Customizing Mini 4WD Racers For High Speeds On A Small Scale MegaBots: Born to Smash Anything in Their Path First Look: Xbox Adaptive Controller Quantum Computing Expert Explains One Concept in 5 Levels of Difficulty Kids versus 80s tech: Game Boy, Vectrex and a stereo system Expert Explains One Concept in 5 Levels of Difficulty - Blockchain Best wearable tech of 2017 The Moov HR Sweat - heart rate monitor in a headbandArs Technica More videos ← PREVIOUS STORY NEXT STORY → Related Stories by Taboola Sponsored Links She Is One Of The Richest Heiresses In The World investing.com Today's Top 20 Amazon Prime Deals You May Not Know About Brad's Deals Shop Now 80s Legend Tommy Chong Says Stop Taking CBD Cruise Chews Learn More Here Are 7 Big Discounts Seniors Only Get If They Ask Senior Discounts By National Penny Learn More Expert Says This Drugstore Wrinkle Cream Is Actually Worth It BrunchesNCrunches Learn More Historic Figures Who Lived Long Enough To Be Photographed Livestly Today on Ars STORE SUBSCRIBE ABOUT US RSS FEEDS VIEW MOBILE SITE CONTACT US STAFF ADVERTISE WITH US REPRINTS NEWSLETTER SIGNUP Join the Ars Orbital Transmission mailing list to get weekly updates delivered to your inbox. Sign me up → CNMN Collection WIRED Media Group © 2023 Condé Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our User Agreement (updated 1/1/20) and Privacy Policy and Cookie Statement (updated 1/1/20) and Ars Technica Addendum (effective 8/21/2018). Ars may earn compensation on sales from links on this site. Read our affiliate link policy. Your California Privacy RightsCookies Settings The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast. Ad Choices",
    "commentLink": "https://news.ycombinator.com/item?id=37507226",
    "commentBody": "Calif. passes strongest right-to-repair bill yet, requiring 7 years of partsHacker NewspastloginCalif. passes strongest right-to-repair bill yet, requiring 7 years of parts (arstechnica.com) 391 points by thunderbong 23 hours ago| hidepastfavorite270 comments Woodi 12 minutes agoDo they included mandatory quality of the product ? At minimum quality that is equal to what they are selling. No car battery with half of advertised capacity or CrV pliers that become tattered on first plain nail. Or ever thinner cloths. All of them with relevant certificates and all needed papers. Usually straight from China. And no control from any TLA+ :> Producers or AliSellers dillute instantly on contact with troubles so the only way is to control quality @importers and clog them with what they voulountarilly push. reply skywal_l 22 hours agoprevI would rather force companies to release schematics, specifications and documentations after, say 3 years and let the market decide which part must be made. With competition it would lower the parts price and potentially these parts could remain available for ever and if the product is actually great could even become a standard. For example, those parts could be reused to make a new product. reply phh 21 hours agoparent> I would rather force companies to release schematics, specifications and documentations after, say 3 yearsOn top of that I would had that this documentation must have been released to an escrow before being releasing the product (many hardware companies come and go within few years. I wouldn&#x27;t mind an exception to the escrow for \"big enough\" companies). Also, the secure boot keys must also be released if a major security (~ local root privilege escalation without hardware access) issue hasn&#x27;t been fixed for one year. reply hedora 18 hours agorootparentI’d go further and dictate that a reference implementation of the software be required in source code form, and the instructions include a secure boot bypass (e.g., cut this trace on the board, pull a jumper, etc). reply JumpCrisscross 15 hours agorootparent> instructions include a secure boot bypassSo do NSO’s work for them. reply Zuiii 7 hours agorootparentYes, and that is irrelevant. If the owner can fully control his or her device then so should NSO. That&#x27;s why well-designed hardware tends to have hardware-enforced hardware input to override security settings. In the past they were simple dip switches on motherboards (some gaming motherboards still have them for overclocking), for modern phones it seems to be the secure boot&#x2F;hypervisor environment itself in conjunction with hardware keys like volume buttons. Physical hardware-validated input (or physical access to the device) is sufficient to spoil the schemes of NSO or any other group of remote coward criminals. No need to further encroach on owner rights.\"NSO\" should never be accepted as a valid argument against providing a secure boot bypass to device owners. Never. reply jwells89 21 hours agoparentprevThis would need to be paired with regulations regarding the quality of third party replacement parts, otherwise we’ll end up with a lot of near-ewaste quality parts flooding into the market and tripping up consumers who don’t know any better or simply don’t care (“why buy the $75 high quality part when there’s this $15 shoddy alternative on Amazon?”). reply maerF0x0 18 hours agorootparent> when there’s this $15 shoddy alternative on Amazon?smart consumers eventually learn. I don&#x27;t buy electronics from amazon anymore. I probably never will. Too many near fires. Too many things lasting just longer than the return window etc. reply red-iron-pine 14 hours agorootparentor any 3rd party marketplace, really. Newegg Marketplace is the same people who are on Amazon, so buy direct from them. If the stuff is fake then I can at least get @ them directly, and they can make changes to their supply chain. reply lloeki 17 hours agoparentprev> With competition it would lower the parts priceAround here repair shops with lower prices than first party get shitty parts. At best they&#x27;re not on par spec-wise on non-breaking things (e.g max nits or color reproduction on a display), at worst they either last way less than third party (e.g battery) or are outright dangerous (damaging other parts or outright fire hazard).I&#x27;ve been burned often enough that for me it&#x27;s first party or nothing, and get third party only as a last resort.People at large don&#x27;t care about&#x2F;understand these immaterial things so at scale competition is a race to the bottom. reply kdamica 22 hours agoparentprevI totally agree here. The bill is great in spirit but this could be onerous for small companies. reply ethbr1 22 hours agorootparentIt&#x27;d be nice to see an \"OR\" provision within the time window too.As in, provide spare parts OR release schematics and specifications that allow others to produce them. reply bombcar 21 hours agorootparentI’d go with “make parts available for two years after sale ends, and then release schematics. Schematics are not required to be released as long as the parts are still reasonably available.” reply ethbr1 19 hours agorootparentI was thinking of the schematics loophole from a small company perspective, for whom x years of parts availability might be impractical.But they could use the loophole to release schematics and relieve themselves of the burden. Win&#x2F;win! reply ImJamal 19 hours agorootparentprev>this could be onerous for small companiesProbably why Apple supports it. reply arcticbull 14 hours agoparentprevWell, there&#x27;s a trend now towards proprietary ASICs - and the market isn&#x27;t going to be doing custom ASIC runs of M1s are they? The cost would be astronomical. The manufacturing and assembly techniques for a lot of modern electronics are simply beyond the capacity of most manufacturers. reply contravariant 21 hours agoparentprevI think a responsibility to ensure parts are available gives a more pressing motivation to use parts that are already available.If they only need to publish schematics there&#x27;s no strong reason to avoid custom parts, other than cost but that&#x27;s the same as now. reply mortureb 17 hours agoparentprevSo ridiculous regulations and requirements before a small company can get a product out. This should only apply to companies above a certain cap. reply red-iron-pine 14 hours agorootparentalready a lot of regs that only apply to companies with 20+ employees, so it&#x27;s not crazy to assume this is the case, too. reply MatthiasPortzel 19 hours agoparentprevThis doesn’t make sense because most hardware with custom parts are actively manufactured and sold for longer than 3 years. If companies were forced to release all internal documentation, that only guarantees that competitors would begin manufacturing clones while the original product was still being sold. It wouldn’t accomplish the goal of getting replacement parts in the hands of consumers. reply JohnFen 12 hours agorootparentIt wasn&#x27;t really that long ago when you got schematics for pretty much any piece of electronics you bought, because it made repairs possible.That practice stopped because manufacturers wanted you to throw your broken things away and replace them rather than fix them. reply hedora 18 hours agorootparentprevPatent and copyright law already prevent that.Most devices are built on lines that also produce stuff for direct competitors (in places with traditionally-lax IP laws). reply nuancebydefault 14 hours agoparentprevI don&#x27;t think releasing schematics is a good idea. There is so much more to a production process than documentation. QA is a huge factor in fitniss for purpose and durability. Also, spare parts can&#x2F;should preferrably be the ouput of the same machinery and production lines as the original parts, which makes it better for the environment. reply JohnFen 12 hours agorootparentYour other points are well-taken, but don&#x27;t address why you don&#x27;t think releasing schematics is a good idea. Schematics make diagnosis and repair possible without having to engage in reverse-engineering. reply nuancebydefault 11 hours agorootparentGood point. I actually meant, releasing schematics for the sake of 3rd parties reproducing parts of probably inferior quality, would be not a great idea. Schematics for understanding, yes, but those can be more high level - black box if you want - schematics for the sake of understanding how the system works or interconnects. A repair manual. reply idiotsecant 10 hours agoparentprevThis works fine, except that apple can use xyz semiconductors widget Q and mandate to that supplier that they are the only ones allowed to buy that part.This is a thing they definitely do now. reply maerF0x0 18 hours agoparentprevAlso we&#x27;ve seen auto OEMs repeatedly raise their hands saying \"We make parts, but supply chain issues\" meaning you effectively cant. reply mortureb 17 hours agoparentprevSo ridiculous regulations and requirements before a small company can get a product out. Not to mention, ready to use blueprints for companies in China and India. This should only apply to companies above a certain cap. reply hedora 18 hours agoparentprevThe document says “necessary software”, so, presumably you’ll be able to do stuff like swap out components and jtag (or whatever) your design verification test suites, keys, firmware, etc., simply by following the steps in the software documentation.&#x2F;s reply user3939382 21 hours agoparentprevLet’s have both, with parts applying only if you’re a certain size. reply 1letterunixname 14 hours agoparentprev> after, say 3 yearsWhy the wait? Delay is bullshit. Release all the things on launch. reply anon____ 14 hours agorootparentExactly. That&#x27;s what patents are for. No need to be secretive. reply colechristensen 19 hours agoparentprevMinnesota&#x27;s right to repair law does require documentation and tools be available.It has too many carveouts, just the same. But things existing in the first place is progress.>In general, the Digital Fair Repair Act requires manufactures of certain electronic products to make documentation, parts, and tools for diagnosis, maintenance, or repair available to independent repair providers and product owners on fair and reasonable terms. Minnesota Statutes Section 325E.72, subd. 3(a). reply lettergram 21 hours agoparentprevEasier to force them to make parts available or release any IP related claims. reply ravenstine 20 hours agoprevThis just seems like a new moat the big companies have dug to discourage small companies from breaking into the hardware industry. If this was about the right to repair, then the bill would have been about releasing schematics and preventing anti-repair designs (like the Hall-effect sensor in Macbooks that includes a circuit with the sole purpose of preventing third-party replacement). In actuality, this is against the little guy in two ways; the purpose of forcing repair shops to disclose their use of \"unauthorized\" parts can only serve to try to discredit them in the eyes of the public. The public just wants their devices to work, but now California wants to scare them with this idea of \"unauthorized\" parts. reply jjtheblunt 14 hours agoparentwhy would a big company dig this moat?(they&#x27;re already big, which is _the_ moat, since they likely have excellent tech to have become big) reply red-iron-pine 14 hours agorootparentto discourage small companies from breaking into the hardware industry.said so right in the first sentence.make it hard for them to get off the ground and either copy it yourself, or buy them out when they&#x27;re still small. reply ecf 14 hours agoparentprevBig companies aren’t asking for this. Start pointing blame to the consumers who ask for something without realizing the consequences. reply nimos 21 hours agoprevAs much as I kind of like this it seems like this is basically another freebie for random offshore companies like BEEMOK and JOOBLE that are spamming stuff via amazon&#x2F;temu&#x2F;et all. There is basically 0% chance they even exist 7 years later and then another basically 0% chance you could actually get any remedy against them even if they did. reply PeterisP 14 hours agoparentThe general solution, at least as done by some other countries, is to hold the seller&#x2F;importer also wholly responsible for upholding all the regulations and warranties - so if the manufacturer is bankrupt, or not responding, or overseas, then that&#x27;s the problem of whoever sold you the lemon and took your money (i.e. Amazon, Temu, Walmart, etc); if they allow shady sellers on their marketplace, that&#x27;s their loss. reply red-iron-pine 14 hours agorootparentthe main point is that someone has to do the due diligence on the product, and it shouldn&#x27;t be the consumer, especially when there are few to no remedies. reply PeterisP 8 hours agorootparentMy point is that liability for consequences determines who (and if) does due diligence. If there are no remedies then customers are on their own, and either they do due diligence themselves or there is no due diligence at all; but as soon as the seller has to bear financial consequences for selling noncompliant product, suddenly they will become very capable of effective due diligence.It&#x27;s all about the incentives and motivation; companies which are permitted to offload risks to consumers will do so and ignore even trivial measures they can take to reduce these risks. reply aeternum 4 hours agoparentprevOften cheap is better than expensive and repairable reply BiteCode_dev 21 hours agoparentprevThe state could request proof of a stock of parts before allowing something to pass customs. reply anigbrowl 17 hours agorootparentAbsurd bureaucracy, and what are you gonna do when it ceases to exist after the paperwork is filed and hte aprts are just funneled back into manufacturing? Making manufacturers bank the schematics and auto-releasing them after manufacture ends is less work for the manufacturer and easier for the market. reply mcpackieh 21 hours agorootparentprevCustoms for a state? I don&#x27;t think that exists, or would even be legal to exist. reply ryanschaefer 20 hours agorootparentRelevant section of the constitution. Don’t know if this would fall under inspection:> No State shall, without the Consent of the Congress, lay any Imposts or Duties on Imports or Exports, except what may be absolutely necessary for executing it&#x27;s inspection Laws: and the net Produce of all Duties and Imposts, laid by any State on Imports or Exports, shall be for the Use of the Treasury of the United States; and all such Laws shall be subject to the Revision and Controul of the Congress. reply donatj 19 hours agorootparentI&#x27;ve always wondered about the constitutionality of California&#x27;s state-to-state border stations where they check every car for produce. Seems iffy. reply ncallaway 19 hours agorootparenthttps:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Maine_v._TaylorSCOTUS has ruled that, with specific and compelling reasons, states can implement these kinds of interstate restrictions. If Congress wanted to, they could pass a federal law that would pre-empt the state law, but has not done so. reply red-iron-pine 14 hours agorootparentit would also mean that the FedGov would have to evaluate or interact with every sort of intra-state interaction, which would get onerous and expensive quickly. reply ncallaway 13 hours agorootparent> FedGov would have to evaluate or interact with every sort of intra-state interactionI don&#x27;t think that&#x27;s the case. It would be up to Congress. They have the authority to pass a law that says: \"No state may put up any intra-state barriers to commerce at all\", and that would be that.Or they could choose to pass a law that&#x27;s a lot more specific, in which case they would need to deal with each intra-state interaction. reply strictnein 19 hours agorootparentprevYeah, just encountered those on a road trip and wondered how they were legal. Was right on the Cali&#x2F;Oregon border for a couple of days and those checkpoints were also only sporadicly staffed, so I don&#x27;t understand the point anyways. reply nonameiguess 14 hours agorootparentprevIt says right there they can do what is needed to execute inspection laws. They just can&#x27;t charge you to import. California had serious problems with Mediterranean fruit flies destroying crops from the 50s onward, which is why they started doing this. reply BiteCode_dev 20 hours agorootparentprevAh, right, it&#x27;s the US, states are not countries. reply reaperman 21 hours agoprevProgress is good to see, but I fear this will still result in only large expensive assembled “components” being made available. Like for a MacBook, instead of being able to buy a $0.02 capacitor replacement, Apple will probably sell the whole mainboard “part” for $2,000.Edit: I was a bit lazy in my writing and what I really meant were things like inexpensive proprietary power management ICs, NVMe storage modules, and&#x2F;or T2 security chips, USB controller ICs, etc. reply tzs 19 hours agoparentIf a capacitor fails there are two cases:1. The capacitor is part of a chip. There is no practical way for you to figure out that the capacitor has failed. You will just know at best that the chip is not working right. And even if you could somehow find out that a capacitor on the chip failed there is no practical way you could replace it.In short, if a capacitor on a chip fails you will need a new chip.2. It is a discrete capacitor. Probably surface mount soldered onto a PCB, possibly thru-hole soldered onto a PCB, or maybe some other kind of package with leads soldered across something else like the terminals of a switch or something like that.In this case it is a commodity part. You go to DigiKey or similar, find a capacitor that with the same capacitance, voltage rating, ESR, temperature range, etc,, which will be available from many manufacturers, and DigiKey will be happy to sell it to you for a few cents (plus $7 shipping).It would be nice if the device maker had to tell you the electrical parameters you need to match when buying a replacements capacitor, but it would be overkill to make all the device makers actually sell such readily available commodity parts. reply reaperman 19 hours agorootparentThese are all great points. I was a lazy in my writing and what I really meant were things like inexpensive proprietary power management ICs, NVMe storage modules, and&#x2F;or T2 security chips, USB controller ICs, etc. reply lotsofpulp 21 hours agoparentprevIs there a replaceable capacitor in a MacBook?https:&#x2F;&#x2F;www.ifixit.com&#x2F;News&#x2F;62674&#x2F;m2-macbook-air-teardown-ap...https:&#x2F;&#x2F;www.ifixit.com&#x2F;News&#x2F;54122&#x2F;macbook-pro-2021-teardown reply Tempest1981 20 hours agorootparentI see several here... is the issue the tight spacing makes it too hard?https:&#x2F;&#x2F;valkyrie.cdn.ifixit.com&#x2F;media&#x2F;2022&#x2F;07&#x2F;18205803&#x2F;MBA_M... reply lotsofpulp 20 hours agorootparentYes, at least I would not be able to do it with the household soldering iron I have. reply lacksconfidence 18 hours agorootparentYou would probably need a microscope and some appropriate tools. Looking at the 10&#x27;s of thousands of $$ my neighbor has in metalworking tools, there isn&#x27;t much of a problem asking home enthusiasts to buy some tools to do what they need. reply reaperman 19 hours agorootparentprevYou might not but you could pay a semi-affordable third party repair place like Louis Rossmann to do it for you. That still helps the general consumer, even if its not “DIY”. reply wongarsu 14 hours agorootparentprevThere are repair shops that will replace them for you. With good equipment and a steady hand it&#x27;s certainly possible.But if you go to an Apple-certified shop they&#x27;ll just swap out the entire board and call it a day. In Apple&#x27;s mind those are not replaceable. In their repair system Apple treats a MacBook as a collection of maybe 20 parts and a bunch of screws. reply datpiff 20 hours agorootparentprevAll of them are replaceable but Apple won&#x27;t provide the part numbers. reply lotsofpulp 20 hours agorootparentInteresting. I would have assumed anyone with the skill to work on something that tiny would be so expensive as to make repairs not worth it. reply reaperman 19 hours agorootparentThey are expensive labor but still less than half the cost of a whole new logic board with CPU, RAM, NVMe, etc. Looking at something like $600 instead of $1200+. Plus with Apple&#x27;s authorized solution you are guaranteed to lose all your data, whereas third-party repair shops that do board-level repairs may often be able to avoid data loss.My friend and I both sent our MacBooks into Louis Rossmann the same week. He spilled a cup of water on his, mine just killed itself for no reason. The repairs were expensive but they managed to not lose any data, and it still saved us many hundreds of dollars each vs. doing an Apple-authorized repair. replyFloatArtifact 20 hours agoprevI cannot emphasize this enough. It does not force manufacturers to provide individual parts. What does this mean? Considered the following scenarios.Key Currently: state of average repair Repairability: the ideal method to repair- Replace the keyboard on the laptop Reality: Purchase the keyboard&#x2F;top cover assembly Repairability: purchase keyboard only- Broken cable to usb daughter board Reality: purchase data board assembly to obtain cable. Repairability: purchase daughter board cable.- Motherboard no longer charges battery Current: replace motherboard Repairability: replace capacitors utilizing schematics- Faulty Mac magnetic sleep sensor Reality: Go through \"genius bar\" to replace assembly Repairability: purchase sleep sensor, pair&#x2F;calibrate with to macbook serial number because many of their parts are serialized.Summary do we have access to following?- Schematics and documentation - OEM software working with serialized parts and calibration - Individual parts and components not just assemblies. Cables are a great example.Not all of these scenarios the end user can do easily however, independence pair shops can with a proper support. reply j16sdiz 19 hours agoparent> - Motherboard no longer charges battery Current: replace motherboard Repairability: replace capacitors utilizing schematicsSome marginally related remarks:Most faulty capacitors were manufactured around 2000s ( see https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Capacitor_plague ). Those days are long gone. Most battery charging issue now are unrelated to capacitor .l reply FloatArtifact 15 hours agorootparent> > - Motherboard no longer charges battery Current: replace motherboard Repairability: replace capacitors utilizing schematics> Some marginally related remarks:> Most faulty capacitors were manufactured around 2000s ( see https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Capacitor_plague ). Those days are long gone. Most battery charging issue now are unrelated to capacitor .> lWhile that&#x27;s true the point still stands that we don&#x27;t have access to supply chain parts to fix reparable charging issues. reply rasz 10 hours agorootparentprevWhat you are thinking of is limited to electrolytic capacitors. There are different kinds of caps.Tons of dead Tantalums, those will explode in your face. Found in old gear from 1970-90.MLC ones will burn so hot as to turn surrounding PCB material into coal, sometimes even causing open flame fires.Small ceramic ones will dead short but not explode like tantalums, leaving you with dead weight of a product - this is the most common failure scenario in modern phones&#x2F;laptops. reply turtleyacht 20 hours agoprevMade me think of this in the accounting chapter of an aged textbook:---For decades companies that stockpile old goods have been \"writing down\" the value of their inventories. Using the accepted principle of evaluating inventory at the lower of two figures--current market price or the cost to produce--they sharply depreciate the stock to reflect the slow movement of dated parts that may never be sold. (...) the Supreme Court ruled... unless... actually scrapped or offered for sale at the reduced price, write-downs are... illegal.The Supreme Court Decision in the case of Thor Power Tool Co. vs. IRS meant that Thor had either to sell or scrap its devalued parts or to revalue its inventory and pay back taxes on the basis of new valuation... accountants advised clients to take no action, and the American Institute of Certified Public Accountants notified members that they need not advise clients to seek permission to conform to the Thor Power Tool decision.The IRS then shocked the accounting community... all improperly devalued inventory still on hand would need to be scrapped or revalued and back taxes paid.¹¹ Jerry Giesel, \"Product Liability Suits Jump in &#x27;80, Court Report Says,\" Business Insurance, October 6, 1980, p. 1.-- Business Today 3e (1982). Random House, Inc. reply smugma 20 hours agoparentThe IRS largely operates on a cash, not accounting&#x2F;accrual, basis.Companies still can and do write down inventories all the time. It’s just that it doesn’t help with the IRS. reply donatj 19 hours agoprevAre there lower limits on company size?My friend and I are working on a sort of synthesizer and we have trouble enough sourcing parts for our prototypes let alone having a stock of everything for 7 years!Our designs are on GitHub and are no secret, we encourage people to build their own. There&#x27;s no way we could provide parts for that long. The profit on each device after our labor is negligible. reply JumpCrisscross 15 hours agoparentSet up an entity, ideally non-Californian, and ignore the law. Obviously not legal advice. But if you’re still chugging along in a few years, you can afford to back comply. If you aren’t, there is nothing for a customer to sue. reply fredsmith219 20 hours agoprevThe seven-years provision seems a bit heavy handed. That may significantly raise the cost of doing business in California and result in companies not selling their products there. It will be interesting to see how this plays out. reply RankingMember 16 hours agoparentI would be very surprised if a company would consider leaving the world&#x27;s 5th largest economy due to a 7-year parts requirement. reply ZoomerCretin 19 hours agoparentprevCalifornia would not pass these laws if it meant companies would stop doing business in their state. They know that they are too big of a market to write off, which is why they feel comfortable passing these laws. As an example, all of the auto industry faces tougher emissions standards because of California&#x27;s stricter regulations. reply chroma 18 hours agorootparentI don’t think all manufacturers follow CARB for all the cars they build. When I lived in California I knew several people who bought their cars in Arizona because it meant they’d have more horsepower and fewer parts that could break. Also I removed the extra California emissions junk on my motorcycle because it caused the bike to leak fuel if it fell over. reply jppittma 18 hours agorootparentI had some hope we&#x27;d survive the climate crisis. We&#x27;re dead lmao. reply chroma 18 hours agorootparentThe device didn’t improve emissions. It was designed to try and prevent gas fumes from coming out of the tank. It technically did do that… but only if the bike was upright. reply mrguyorama 17 hours agorootparent>It technically did do that… but only if the bike was upright.Which is the expected and normal state of a motorcycle. reply chroma 17 hours agorootparentYeah and they also fall over all the time. And when that happened, it leaked gallons of gas. It increased the amount of pollution and created a fire hazard. reply red-iron-pine 13 hours agorootparentprevthere are a billion people in China, and another billion in India.only 40 mil in California, and most consumer use bikes &#x2F; cars &#x2F; whatever are a drop in the carbon bucket.we could, and should do better, but unless the rest of the world is onboard it&#x27;s moot. replycm2012 19 hours agoprevPrediction: the vast majority of people will be unhappy with the results of this bill in 5 years. reply pembrook 15 hours agoparentYou can always spot an emotionally-driven law (as opposed to one driven by logic) by the fact that it requires carve-outs for 75 different edge cases to be passable.Critics will call this the work of “special interests,” but this means the law itself was actually passed to please a special interest group.If we can agree that’s it’s a dumb law under that many different scenarios — then it’s not a good piece of legislation. reply racked 19 hours agoprevAs a consumer this makes me happy, but god, California must be an awful place to run a business. They keep piling on the most business-hostile laws. Another silly cookie consent law, unpoliced shoplifting in SF, where does it end? reply whartung 16 hours agoprevFrom the bill: above-described electronic or appliance product,So that means that this is just for electronics and appliances, not vehicles, or anything that&#x27;s not \"electronic or appliance product\".And that means that I will not be able to get a service manual from BMW for my motorcycle, just like I can&#x27;t today.Just want to point that detail out. reply penguin_booze 20 hours agoprevI&#x27;ve had a moment of reckoning the other day: my Android phone is rather old by recent cool-ness standards: it&#x27;s a Moto G5 plus, happily running Android 8.0. Just in the past week, two of the apps I use have dropped the support of Android 8.0. I don&#x27;t know what feature they decided take up on (the gain) by dropping support, or what load shed is, but I was not pleased that this has started happening.On the one hand, I&#x27;m rather relieved: I don&#x27;t have to keep downloading the endless stream of \"new\" features that I don&#x27;t want. More often than not, I&#x27;ve found the updates keep breaking something, or upset my established pattern of working. On the other hand, I&#x27;m facing the constant danger of some of the vital apps dropping support: for example, the work-related apps, without which I won&#x27;t be able to log in remotely.I suppose there&#x27;s the option of rooting and installing a custom ROM. But then, there&#x27;s no guarantee that it&#x27;ll continue to work as before, in all its full glory. It&#x27;s also the case that some apps (especially the work-related ones) refuse to work on a rooted device.So, no matter how strongly I&#x27;m determined to stay put, I&#x27;ll eventually be forced to get a new phone.I guess what I&#x27;m saying is that a modern devices are a complex ecosystem. Just having the right tools at hand, passing the right law, or having an open-source, DIY, path ahead doesn&#x27;t necessarily mean that things will be same as before. For some things, we are necessarily dependent on other people doing the right things--and some of those things, nobody can force them to do it. reply jwells89 20 hours agoparentSpeaking as a mobile dev, if OS versions are dropped in apps it’s usually to try to keep the scope of supported devices&#x2F;OSes within the realm of sanity, especially for smaller companies&#x2F;teams. Long-term support of older OSes is easier on Android than iOS but can still pose challenges. reply penguin_booze 19 hours agorootparentYeah, I&#x27;m sympathetic to that. If I were the developer, I don&#x27;t want an old version holding me hostage from moving on (for some definition of &#x27;moving on&#x27;). As a user, it&#x27;s sometimes that helplessness that turns into entitlement. reply hahn-kev 18 hours agorootparentprevYeah, they may have looked at the number of users on Android 8 and decided it was worth it for everyone else to stop spending time making sure they don&#x27;t break it. reply SoftTalker 18 hours agoprevRelated to the topic, it is commonly said&#x2F;claimed that there is federal law requiring automakers to have parts available for 10 years for any car they sell. As far as I can tell this is not true. If they offer a warranty, they must have parts available for the term of the warranty. And for emissions control parts, under some circumstances they are obligated to repair defects discovered within 8 years (this doesn&#x27;t necessarily mean they are obligated to stock the original parts).In reality, for any reasonably popular car, there will be OEM or aftermarket parts available for most things that commonly fail or wear out, for 10 years if not much longer. reply jiveturkey 13 hours agoparent> If they offer a warranty,Not even that. Tesla (most famously, but many others) have very long waiting lists for many parts, parts that are in no short supply for the purpose of building entire cars, but are not available at all as parts. reply throwaway914 20 hours agoprevI&#x27;m not a lawyer. Would this make it harder to invoke California&#x27;s Songs-Beverly Act for device replacement? (California&#x27;s Lemon Law)Previously, you could buy an appliance >$100 and if it broke in 5-7 years you could ask for service or parts to repair it. If the company cannot produce that, they would be required by law to replace the \"thing\" with an equivalent or newer product. This looks like the 7 year requirement is on things still being sold.If companies must retain 7 years of parts now, this kinda closes the loop on getting new stuff in a Planned Obsolescence world. :pI&#x27;ll happily take a win for Right to Repair. reply ZoomerCretin 19 hours agoparenthttps:&#x2F;&#x2F;leginfo.legislature.ca.gov&#x2F;faces&#x2F;billTextClient.xhtm...(k) This section shall not apply if the manufacturer provides an equivalent or better, readily available replacement electronic or appliance product at no charge to the customer. reply throwaway914 12 hours agorootparentBefore this, you could take advantage of their poor planning and not keeping parts or offering repair service. Now they&#x27;re required by law - as long as the product is still being sold.I liked getting new stuff freely :-) reply scarface_74 16 hours agoprevSo now phone makers have to supply parts for seven years. But most Android makers don’t supply OS upgrades for more than 3 if at all.Win? reply ugh123 16 hours agoparentWould love to see someone in the industry recognize this discrepancy and say \"we proudly say we match our OS upgrades with the strongest right-to-repair laws in the country\". Google Pixel?Edit:Well hey, at least Google is now doing 10 years of Chromebook updates (likely demanded by schools)https:&#x2F;&#x2F;blog.google&#x2F;outreach-initiatives&#x2F;education&#x2F;automatic... reply passwordoops 23 hours agoprevUsed to work in Europe for a CA based company. Every tender required at least 7 years of support, sometimes 10, including all parts. Good to see them catching up reply robertlagrant 17 hours agoparent> Used to work in Europe for a CA based company. Every tender required at least 7 years of support, sometimes 10, including all parts. Good to see them catching upThis is for consumer goods. It&#x27;s not the same. Consumers could always decide to only buy things with 7 years of support, like your tender process.The \"catching up\" nonsense isn&#x27;t great either. reply solardev 22 hours agoparentprevWhat&#x27;s a tender and why does it need 7 years of support? reply varjag 22 hours agorootparentA bidding process.In certain industries life cycle requirements are common (e.g. our customers expect 15 to 20 years of product lifetime) but it is far from universal and isn&#x27;t enforced by a EU wide law AFAIK. reply bombcar 21 hours agorootparentYep - if you’re a business wanting to buy a million dollar machine to do whatever, you want some assurance that it can be repaired and will be working until replacement time (at least the depreciation schedule, often many MANY years longer). reply solardev 21 hours agorootparentThat&#x27;s amazing. I&#x27;m happy when my npm packages last more than 2 months reply bombcar 20 hours agorootparentPhysical things have interesting support - there are actually companies whose entire business model is support equipment from companies that have been gone 40+ years. reply HeyLaughingBoy 17 hours agorootparentRight. My little cottage industry&#x2F;side gig used to build electronic boards that were used to interface 40+ year old machine tools to modern controls when the original controllers broke and replacements weren&#x27;t available. I sold to a small company that did nothing but retrofits like that.Really wish I could find more niches like this. It&#x27;s a boring but profitable domain to get into. reply HeyLaughingBoy 18 hours agorootparentprevYup. At my last job, we designed our products (medical instruments) for a service life of 15 years and a market lifetime of 25. i.e., from the time the product was released to the market, you could expect Service and Support and spare parts to be available for at least 25 years and the device itself was expected to last 15 years in the field.Of course, I&#x27;m talking about large machines that cost between $500k - $1M each, so... reply twoodfin 22 hours agoprevThe interesting dog-that-didn’t-bark on California’s most recent wave of consumer-focused regulation is the Supreme Court.The stereotypical view of the Court majority as a bunch of right-wing corporatists doesn’t hang together in this instance: They’ve rejected the so-called “dormant Commerce Clause” in a case centered around CA’s ethically raised pork standards, and generally seem unconcerned with arbitrary 50-state regulation of commerce so long as Congress has not chosen to intervene. reply j16sdiz 20 hours agoprevI hope it is equally enforced on imported gadgets listed on AliExpress or Amazon. reply pcdoodle 20 hours agoprevSomething I can chime in on. We&#x27;ve been doing Mac&#x2F;PC&#x2F;iPhone @ our B&M repair shop since 2009. We&#x27;ve delayed a few hundred thousand pounds of e-waste from hitting the dump before it&#x27;s truly EOL (doesn&#x27;t sound like much but we&#x27;re also retaining the customers familiar computing environment which is a huge value add).We&#x27;ve also enabled our customers to skip quite a few generations of upgrades due to extended operation of their existing hardware.To keep things simple: the parts used to achieve this were from computer recyclers across the US, not even once have we used parts from a manufacturer. There are quite a few reasons for this besides maintaining our profitability. We love high quality OEM parts.I have a feeling this will become a profit center for manufacturers and be priced just high enough that there&#x27;s no room to justify maintaining hardware when repair labor costs are added to the equation.My opinion is the \"Garbage by Design\" lockouts that happen due to hardware&#x2F;software&#x2F;firmware locks, are going to be the main culprits preventing companies like mine from performing the same extended use of these tools and thus causing more \"upgrades\" and trashing cycles.I think the most important thing is that parts remain swappable without manufacturer intervention and red tape. Louis Rossmann and Hugh Jefferys also make great videos about these issues.-Typed on my 2011 17\" Macbook Pro (16GB&#x2F;1TB) while pulling 20W from the wall. reply some_random 18 hours agoprevAnd as usual it has huge carve outs for whatever industries were able to apply enough money and or votes reply hanniabu 21 hours agoprevAs with most regulation, what matters most is what are the consequences if they don&#x27;t follow? If it&#x27;s just a slap on the wrist then it&#x27;ll be more cost effective for them to just eat the penalty than pay to have a surplus of supply manufactured then stored for years. reply system2 15 hours agoprevWhat&#x27;s the point of it if the manufacturer makes the parts extremely expensive? For example, Apple&#x27;s 4k screen for iPhone 11 Pro Max is $400 at apple. The phone itself is $150 on eBay. Aftermarket parts cause functional impairment (truetone gone if 3rd party screen used). This bill should be \"use any part without software limitations\". reply ZoomerCretin 19 hours agoprevhttps:&#x2F;&#x2F;leginfo.legislature.ca.gov&#x2F;faces&#x2F;billTextClient.xhtm...> 42488.2. (a) Notwithstanding any other law, every manufacturer of an electronic or appliance product with a wholesale price to the retailer, or to others outside of direct retail saleThis only affects manufacturers who sell wholesale. Is this intended as a proxy for a manufacturer&#x27;s ability to comply with this law? It seems that any large manufacturer who wishes to not comply simply has to stop using wholesale prices, though I&#x27;m not sure how feasible that is. reply HeyLaughingBoy 17 hours agoparentI think the rationale behind this statement is that it doesn&#x27;t apply to small specialty manufacturers. e.g., small manufacturers that sell direct to their customer are exempt.I build custom electronics (not consumer items), mostly with very small unit volumes. e.g., I just shipped 10 units of a device that monitors a controller and sends a message to an Android app when it turns on or off. The entire lifespan of this product will probably be under 100 units. Making someone like me have to comply with laws like this would probably be enough to rethink the whole thing. reply uconnectlol 21 hours agoprevthat could be great now how do i make it so i don&#x27;t need an OS and software in my laundry machineor any of the other elephants in the room reply hermannj314 22 hours agoprevSomeone got a nice re-election contribution to exempt \"video game consoles\" from the bill.No mention of what makes video game consoles so miraculously different than a video camera, television, etc.It seems like a good step for consumer rights aside from that. reply tzs 19 hours agoparentIt also looks like it doesn&#x27;t apply to all-terrain vehicles, or to machinery, equipment, implements, or attachments used for or in connection with:1. Lawn, garden, golf course, landscaping, or grounds maintenance,2. Planting, cultivating, irrigating, harvesting, and producing agricultural or forestry products,3. Raising, feeding, or tending to, or harvesting products from, livestock and any other activity in connection with those activities,4. Industrial, construction, maintenance, mining, or utility activities or applications, including, but not limited to, material handling equipment,although that exclusion does not apply to \"self-propelled vehicles designed primarily for the transportation of persons or property on a street or highway\" even if they are used for one of the above things.There is also an exclusion for alarm systems, which are \"an assembly of equipment and devices arranged to detect a hazard or signal the presence of an off-normal situation\". reply Sindisil 19 hours agorootparentAKA the John Deere exception.FFS, Deere&#x27;s egregious behavior is a large part of the push for RTR legislation.Disappointing, if not unsurprising. reply deelowe 19 hours agorootparentAnd as planned, were sitting here blaming Deere and not the politicians who allow this to happen. Deere is simply looking out for its best interests. The real scum are these so called \"representatives\" who place corporate interests over small businesses and citizens.Walk through your local Lowe&#x27;s and home Depot and take a close look at their lawn equipment. It&#x27;s all junk that will be thrown away in a decade. Plastic bushings, plastic spindles, flimsy exhaust mounts, etc. If you seriously take the time to look closely, you can see where you they are engineered to fail.Even contractor brands like Stihl are starting to do this stuff. Most of their trimmers now do not have a grease fill port on the head. To make matters worse, replacing a head costs almost as much as an entire trimmer... reply p_j_w 18 hours agorootparent>The real scum are these so called \"representatives\" who place corporate interests over small businesses and citizens.I don&#x27;t see why we can&#x27;t find both to be scum. reply robertlagrant 17 hours agorootparentBecause only one is being paid for by public funds to be impartial. reply AYBABTME 16 hours agorootparentThe corporation can also be scum by virtue of being an unpleasant actor in society. reply standardUser 15 hours agorootparentYou can call them \"scum\" if it makes you feel better. But even if the greatest shame campaign the world has ever seen was to miraculously convince John Deere to change their ways, other companies would just step in and take advantage of the system the same way John Deere has.The only solution is to change the rules. reply erulabs 16 hours agorootparentprevYes but it&#x27;s much harder calculus. What&#x27;s the net of a very large tractor manufacturer existing or not existing? If they lobby in a way you don&#x27;t like but they also cause cereals to be 15% cheaper, how can you calculate their \"unpleasant\"-ness?A public official taking a contribution in return for carving out an exception in a law is quite an easy one. reply mjburgess 16 hours agorootparentThe same calculus applies to the politician, you&#x27;re just imparting certain social duties on one and not the other.If you want to know why american society is prone to this sort of privitized corruption: this is it. Business is seen as a pure mechanism, but politics is a place of hyper-individualized duty.In europe, i think the reverse is more often true. Businesses are seen in personalized ways, as having explicit social duties compromised by greed; and politics is a pure mechanism. reply robertlagrant 15 hours agorootparentErm no - businesses can also be moral. In fact there&#x27;s an enormous social pressure to look good. That&#x27;s why people get fired for things that happen on Twitter.The only difference is businesses get money for doing something someone else wants, and they need to keep doing that. Politicians take your money and can&#x27;t even do the one thing they should be doing: be impartial and resistant to even more free money. reply mjburgess 15 hours agorootparent>Erm no - businesses can also be moral.That&#x27;s my point. We agree.> businesses get money for doing something someone else wants > Politicians take your money and can&#x27;t even do the one thing they should be doing^ Here is my issue. This is a cognitive-dissonance. You can equally say: businesses failing their social duty aren&#x27;t giving society what it wants; rather, they are sating the greed of their customers, shareholders and execs.Whereas politicians are balancing competing power interests into a compromise piece of legislation with a chance of being passed, and thereby improving the situation; if, very imperfectly.You see, under these reframings it is the biz failing, not the polician.to be clear, I do not agree with either framing. My point is only how quickly americans adopt this \"if someone&#x27;s buying, it&#x27;s excusable\" morality as applied to business. As-if politics were a place of heroic powerful individuals, and business merely a mechanism.The reality is both is true of both. Business can be held to much higher standards; and politicans can be more subtly understood. reply robertlagrant 15 hours agorootparent> My point is only how quickly americans adopt this \"if someone&#x27;s buying, it&#x27;s excusable\" morality as applied to business.I&#x27;m not sure why you&#x27;re talking about Americans, but my point is that the main thing a business does is create employment and useful goods or services.> As-if politics were a place of heroic powerful individuals, and business merely a mechanism.No, creating employment and useful goods or services is extremely important and heroic. It&#x27;s just different to being the person who takes money from others on the sole basis that he&#x2F;she will be impartial and not take bribes. reply AYBABTME 14 hours agorootparent> I&#x27;m not sure why you&#x27;re talking about AmericansAs a foreigner in America, I think America is culturally particularly business oriented and holds favorable views on business activities (until they get too large and obscure, then they become led by lizards or some such), and in particular I think the average person here is more prone to think that it&#x27;s ok for a business or person to seek to maximize their position in the market by almost any legal means. As in, if the player is good at the game, you can&#x27;t blame the player (up to a point). reply robertlagrant 13 hours agorootparentThey should maximise by legal means. That&#x27;s how you get better service, lower prices and better products. That&#x27;s why computers aren&#x27;t $1m each or still in the KHz CPU range. Or why every company is now making electric cars. Or... why most things are as good as they are. reply mjburgess 13 hours agorootparentBut that&#x27;s an naive ideological take on the virtues of business; whilst at the same time you offer a naive cynical take on the vices of politics.D&#x27;you not see this sort of double-think taking place?Exactly the same naive gloss can be given of policitians: their compromises are part of the democratic process by which competing power interests are balanced without oppression. There are no Company Stores, or Company Scrips because corporate power is given \"an inch\" but no more. And there are FDAs and the like because Society gets its two inches. And so on.Politicans are creatures of a mechanism as much as businesses.This \"reduce one to mere mechanism, but not the other\" is pure naive ideology.Business does not \"offer better prices\" etc. through this mechanism. It offers prices every bit as flawed as politics offers policies. reply robertlagrant 11 hours agorootparent> But that&#x27;s an naive ideological take on the virtues of business; whilst at the same time you offer a naive cynical take on the vices of politics.I don&#x27;t think that&#x27;s a virtue of businesses. It&#x27;s their primary function, and their primary good: producing useful stuff or services for their customers, and employment to their employees. The more useful their product&#x2F;service, the more money they get, and the better their customers&#x27; and employees&#x27; lives will be. If they campaign to make that easier by making regulation less onerous, that&#x27;s in pursuit of those primary goals.That&#x27;s different to a government job (e.g. in regulation-setting&#x2F;enforcing) where their sole job is to set and maintain good standards in their area. They provide no value other than that, and if they aren&#x27;t even doing that, then they&#x27;re worse than useless. They&#x27;re useless and they cost money we aren&#x27;t allowed to refuse to pay. reply mjburgess 4 hours agorootparent> It&#x27;s their primary function, and their primary good: producing useful stuff or services for their customersThis claim is a specific ideological interpretation of business, call it \"consumer capitalism\".You can reject than and believe say, \"social capitalism\" or \"democratic capitalism\". Where the purpose of business is to, on net, improve society -- and is given a licence to operate only insofar as, on net, it does so.> their sole job is to set and maintain good standards in their areaAgain, call this \"noble bureaucracy\". You could instead believe, \"resolution bureaucracy\" where the job of bureaucracy is to prevent conflict, not to resolve to an ideal. reply robertlagrant 52 minutes agorootparent> You can reject than and believe say, \"social capitalism\" or \"democratic capitalism\". Where the purpose of business is to, on net, improve society -- and is given a licence to operate only insofar as, on net, it does so.You could do, but then you have to invent a currency to award to people who you think improve society from your perspective. Or you could just use the existing one. mjburgess 16 minutes agorootparentThat&#x27;s the ideology of money = reward.Businesses routinely do not produce net benefits; routinely do not have efficient prices; routinely benefit their customers at the expense of society; and routinely distribute money away from net goods towards net bads. Indeed it is routine that an efficient market operating at marginal profits is a catastrophe for society: consider social media, climate change, and so on.This isnt a problem I need to solve for the observation to be true.The issue I have here is the black&#x2F;white false perceptions of politics&#x2F;business. AYBABTME 16 hours agorootparentprevIf the politician is scum as a result of having ought to judge the corporations&#x27; lobby as being scum, then it follows that the politician is able to come up with a calculus where the corporation is scum. And if the politician is able to, so am I. reply pengaru 16 hours agorootparentprevClearly one side is giving substantially more. reply maerF0x0 18 hours agorootparentprevAnd every time the citizenry tries to use regulation to reign in a megacorp it ends up creating more burden for that company&#x27;s competition. megacorps legal team can easily squeeze into the loop holes, but mom and pops (and entrepreneurs) get ground up like cheap meat. reply pc86 18 hours agorootparentThen exceptions (if any exist) should be based on company revenue (to include any and all holding companies), not what the tool or device does.Require Deere to make RTR easily available, let small upstarts focus on the product reply maerF0x0 18 hours agorootparentSo I definitely prefer this, and this is used to be a sort of unspoken rule in Canadian law. The law just had this bias built into for the \"little guy\" in the fight. Seems to have changed under the current Führer, at least from a non-resident&#x27;s perspective. IMO that&#x27;s the right bias to have to counter the matthew effect in Capitalism. reply HeyLaughingBoy 18 hours agorootparentprev> you can see where you they are engineered to failReally? Please give an example. I have been hearing this for at least the last 15 years and have yet to find someone who can offer an example of anything that was \"engineered to fail\" when challenged. Not saying it doesn&#x27;t exist, but I&#x27;d just like to see a single example of it happening.Sacrificial parts that are designed to fail in order to mitigate a more serious failure do not count for the purposes of this request -- that&#x27;s just Good Engineering Practice. reply deaddodo 18 hours agorootparentI think people should rephrase it to \"not engineered to last&#x2F;repair\". This is a much easier metric to point out and is about equivalent (though, less nefarious) to what they mean.If you use that metric, it&#x27;s insanely easy to quantify. Just look at the average refrigerator today, compared to one from the 50s-70s. It&#x27;s a fraction of the cost, but it&#x27;s built from cheaper&#x2F;less reliable parts in a repair-unfriendly (but quick to produce) manner. The idea being that you&#x27;ll buy a new fridge every 8-12 years and recycle (ideally) the old one, versus spending the cost of a car on one and keeping it for a generation or two. This is what planned obsolescence means, usually.The only nefariously intended to \"break\" items that I can think of are electronic devices that are unrootable and rely on third-party networked services. reply HeyLaughingBoy 17 hours agorootparentOh, I completely agree with you on that. Most consumer items are built to a price point. If you&#x27;re building to sell at a low price, you have to keep Bill of Materials cost low to make selling the thing worthwhile, so it&#x27;s not surprising that, e.g., a cheap riding mower is made from thin stamped steel chassis whereas a commercial one is mostly heavy weldments that hold up to being banged around for hours each day.I&#x27;m not being difficult. When I read \"engineered to fail\" that&#x27;s not the impression I get from the statement. reply deaddodo 16 hours agorootparent> I&#x27;m not being difficult. When I read \"engineered to fail\" that&#x27;s not the impression I get from the statement.I agree with you. I think people mean something else entirely, colloquially. Which is why I distinguished for clarity.I think the people who came up with the concept of \"planned obsolescence\" meant something entirely different to the zeitgeist meaning. That is, building something cheap with the intention of consistent replacements versus building something expensive with support&#x2F;operational costs ongoing. One guarantees you return to them, the other you&#x27;re just as likely to seek services elsewhere.The zeitgeist took that and morphed it into \"they actively engineer&#x2F;design parts that will fail after two years\". reply derefr 17 hours agorootparentprevHonestly seems to me that some BOMs (and therefore some practically-achievable price-points) should be illegal, then. You shouldn&#x27;t be allowed to market something as a mower, if it&#x27;s built such that the act of mowing gradually shakes the mower apart.Yes, a change like this would mean that, in the short term, there&#x27;d suddenly be no \"consumer\" version of many products. But that&#x27;d only be the short term. In the medium term, I&#x27;d expect heavy pressure for innovation in materials science, with all these companies that were fine with plastics before, suddenly investing money and labor into operationalization of e.g. scaling carbon-fiber production. reply ultrarunner 16 hours agorootparentThis sounds like me like an inquiry into \"quality\" and an attempt to make illegal those products lacking a certain quality.I generally call these products \" shaped objects\", e.g. a helmet shaped object that has all the outward appearance of an actual helmet, but does little to protect the wearer in the event of a crash. \"DOT standards!\" you might object, but DOT is generally known to be the worst standard in the world, often holding the industry back instead of moving it forward. If the department of transportation is unable to properly regulate safety equipment like helmets, I&#x27;m not sure I expect better results from a government committee intended to regulate the quality of nearly everything.This, of course, assumes that one can not only define \"quality\", but determine a threshold on a spectrum that delineates legality. Or maybe we&#x27;ll just accept Tsars that \"know it when they see it.\" reply derefr 15 hours agorootparentYes, there is no general definition of \"quality.\" But every industry and product has its own internal, domain-specific definition of quality. For hard drives, \"quality\" is MTBF. For batteries, \"quality\" is measured in loss of charge capacity per charge cycle.Or let me put it this way: the commercial&#x2F;industrial versions of these products do some things differently. Why do they do those things? To increase \"quality.\" If the industry didn&#x27;t know what its \"quality\" metric was, then it would be impossible for them to make the commercial&#x2F;industrial product \"better\" for long-term commercial&#x2F;industrial use than the consumer one.In any industry where the commercial&#x2F;industrial version of a product — one that lasts decades in heavy use — is already an existence proof for the possibility of \"quality\" in the product category, you can simply regulate that the consumer version must also be made to last at least N years of regular consumer-duty use. Doesn&#x27;t matter how they accomplish that. Maybe they can&#x27;t accomplish that, with positive margins, at a price point anyone is willing to buy, at first. Oh well. Keep trying.Compare&#x2F;contrast: FDA stage-3 drug trials — the trial phase that tests drug efficacy. It&#x27;s up to the drug&#x27;s manufacturer to declare to the FDA what effect the drug is supposed to have — it&#x27;s the very same effect the company is applying to the FDA to be able to market the drug as having. An efficacy trial, is simply the FDA demanding, from a drug&#x27;s manufacturer, proof positive of its own planned marketing claims about the drug. That efficacy proof uses metrics specific to the pathology that the drug treats — and likely metrics invented by the drug manufacturer themselves, while researching the problem. But crucially, the manufacturer, before even starting the trial, has to convince the FDA that these metrics are sensible ones to measure efficacy by; and also has to work with the FDA to reach a consensus on what would constitute a satisfactory level of efficacy for their drug (i.e. what metrics thresholds are meant by a marketing claim like \"relieves headaches.\") reply ultrarunner 15 hours agorootparentIf the industry is already able to determine quality, how do you propose to wrest that design process— enforceably, and without destroying value— and place it in the hands of aging politicians? The FDA example is a good one, with complaints like American sunscreen and toothpaste being subpar, and amid news that Phenylephrine is effectively a placebo (and was not the manufacturers&#x27; first choice).Would I enjoy high quality items? As someone shopping for a new toaster after ours simply stopped working (and after allowing my son to disassemble it both impressed and appalled at its design), in a word, yes! I suspect, however, that attempting to centrally plan quality would merely achieve a lower standard of living for most people. Telling the average person \"you&#x27;re not allowed to buy that because we deemed it to not be high enough quality (trust us)\" and following up with \"Oh well\" seems well meaning but, respectfully, out of touch. reply derefr 15 hours agorootparent> I suspect, however, that attempting to centrally plan quality would merely achieve a lower standard of living for most people.My feeling is different, and comes from an intuition about capitalism:• Companies will make money the easiest way that they can, with regard for any kind of unenforced \"code of ethics\" being a path-dependent rarity, rather than something common.• But companies do have the internal talent to solve problems in more challenging, constrained, and ultimately useful&#x2F;ethical ways, if they&#x27;re simply prevented (through regulation) from choosing the \"easy way out.\"If you allow a game studio to put slot machines in front of children, then that&#x27;s what they&#x27;re going to do to maximize ROI. If you don&#x27;t permit them to do that, then the market demand for \"games\" is still going to drive them — or at least, one of their competitors — to ship some actual video games that are fun-qua-fun rather than being addictive and money-sucking.If you allow a drug manufacturer to make an \"anti-colic\" baby formula that contains heroin, then that&#x27;s what they&#x27;re going to do. (And did! The early 1900s were wild!) If you prevent them from doing that, then the demand that still exists is going to force them [or one of their competitors] to put some research into how to actually address colic without just effectively putting the kids in a coma. And someone&#x27;s going to figure it out.If you let companies sell asbestos insulation, then that&#x27;d be what they&#x27;d do — it&#x27;s the cheapest insulation to manufacture, and so it&#x27;d also be the cheapest insulation to buy if it were on the market. If you prevent them from doing that, then they&#x27;ll have to get off their asses and innovate up a cheaper form of non-asbestosis-causing insulation.I don&#x27;t see why \"you can&#x27;t market this as a &#x27;lawnmower&#x27; if it shakes itself apart after eight months; try again\" is all that different from \"you can&#x27;t market this as &#x27;building insulation&#x27; if it destroys your lungs; try again.\" In both cases, I&#x27;d expect the continued market demand + supply-side talent-base to come together to solve the problem a better way. replynivenhuh 17 hours agorootparentprevKitchen aid stand mixers converted from using metal gearing to plastic gearing in their consumer stand mixers. After a certain amount of use, the gear wears out and costs $50 for a replacement.The commercial line still uses metal gears. The maintenance on it is to check grease&#x2F;lubricant after a certain amount of use.(We used the stand mixer daily. Our home edition lasted 6-9 months before needing a gear change. The commercial edition has been going strong for a few years now.)I’m sure there’s a reason why they moved to a fail-safe gear for consumer use — but as a consumer — I have no clue what that reason is. (We do ask a lot of our mixer tho!) reply HeyLaughingBoy 17 hours agorootparentI have one of those mixers and I&#x27;ve replaced the sacrificial gear at least 3 times, although I usually get the gears for far less than $50. I gotta learn to not overload it with bread dough :-)Based on what I see when I open up the unit, the reason they don&#x27;t have an all metal gear train is that doing that would impose the need for higher strength on everything in the transmission and the chassis up to the motor. That would increase the cost to the point where it would cut into sales.The larger consumer mixers (6qt?) are built more heavy duty since I know that they can take a larger vertical load, but I don&#x27;t know if they also have the nylon gear. reply kortex 17 hours agorootparentWhy not a shear pin? There&#x27;s no need to make the (more expensive) gears the shear point when you can use a pennies-each shear pin (or shaft, or similar). reply HeyLaughingBoy 16 hours agorootparentNo idea. I didn&#x27;t design the thing :-) reply winrid 17 hours agorootparentprevThey can use glass reinforced plastic instead, and powdered metal or nylon gears like the mid range $150 consumer drills... reply HeyLaughingBoy 13 hours agorootparentI think I may have misunderstood GP&#x27;s post. I thought they meant that one of the gears was changed to plastic (as in mine) with the rest remaining metal. But it&#x27;s more likely that they meant that the newer models are now using a fully plastic geartrain based on what I&#x27;ve read since. reply vineyardmike 16 hours agorootparentprev> I’m sure there’s a reason why they moved to a fail-safe gear for consumer use — but as a consumer — I have no clue what that reason is.As someone who just infrequently uses their gifted kitchen aid mixer let me offer a new perspective.I’d be ill-inclined to use it if I had to oil my kitchen equipment. That’s the reality. I use it once a month, and i would be turned off if I had to add lubricant. I’m an engineer, I get why it’s good, I get the purpose, but it’s just one more chore I wouldn’t do. reply aeyes 17 hours agorootparentprevDoes the plastic gear break if you attempt to recreate \"will it blend\" videos at home? They probably try to sell this as a safety feature. reply aubanel 17 hours agorootparentprevThe father of a friend worked at a high position at Canon. For a specific enterprise command, the client company wanted printers with a lifetime 20,000 copies instead of the base 10,000. Canon went \"no problem, we&#x27;ll see with our engineers\" and actually they only had to remove a small device which was basically a print counter and would artificially block the ink input at approx 10,000 copies. So nothing to do with good engineering, only bad business practices. reply deelowe 4 hours agorootparentprev> Really? Please give an example.I gave you one already. Newer stihl trimmers removed the grease plug. It&#x27;s impossible to lubricate the trimmer head and they predictably fail after so may hours. A replacement head costs nearly as much as a new trimmer. The head is the most common part that fails on trimmers. reply kortex 17 hours agorootparentprevI owned a treadmill (second-hand, details long forgotten, sorry) which had two long steel rails (running the length of the machine) for the main structure. The brackets which connected the rails on the front side were steel, but the ones on the back of the machine were inexplicably plastic. There were major load paths (cyclical loading from running) going straight through these brackets to the feet. Between the wear and plastic embrittlement, these parts were the first to fail, and the entire rest of the machine was in decent condition (easily years of life left).There was nothing particularly complex about that part, they could have easily used steel brackets. I can&#x27;t help but feel like it was designed for a specific lifespan. reply winrid 17 hours agorootparentprevUsually by using very cheap bearings which last just past the warranty period and cheaping out on reinforcement in critical areas. The AvE YouTube channel covers lots of this with his BOLTR teardowns. reply mrguyorama 17 hours agorootparentprev>Sacrificial parts that are designed to fail in order to mitigate a more serious failure do not count for the purposes of this request -- that&#x27;s just Good Engineering Practice.Except when that part breaks and the company does not make replacements available and the product was not meant to be taken apart to replace it. Mechanical fuses only work when you can easily buy and replace the mechanical fuse and ALSO fix whatever caused the failure in the first place. Otherwise it&#x27;s just a weak link. reply HeyLaughingBoy 17 hours agorootparentYes, but.That designed-in weak link that you can&#x27;t fix could be the difference between you being pissed off because your machine doesn&#x27;t work anymore and you losing a hand. reply winrid 16 hours agorootparentThat&#x27;s just not the thought process. A vacuum with a cheap motor isn&#x27;t going to have trouble hurting your fingers if you stick them in the brush at the right angle. But the bearings will wear out in 5 years.Another is drills with cheap housings or gears. The drill will happily rip a glove off and de-skin you. But it&#x27;ll still wear out faster than if it had metal gears or a tougher housing.Usually safety is an expense. Extra sensors, very carefully engineered weak links that suddenly break under load.Another counter example to your point is my automated litter box. It has a pinch sensor for safety reasons, which is made of two metal contacts. This sensor is directly above the pee&#x2F;poop so it corrodes and I have to take out like 20 screws in a machine filled with poop to fix it, like every year. They could just have added a plastic cover and one screw to protect the contacts, but no.Probably the only thing I can think of to support your argument is cars. The front end of a car is plastic and metal designed to absorb energy in an impact. But household stuff... reply JumpCrisscross 16 hours agorootparentprev> so called \"representatives\" who place corporate interests over small businesses and citizensCalifornia farmers have more influence in Sacramento than John Deere. Either they didn’t engage in this fight. Or there is a reason they would want this exempted. reply deelowe 4 hours agorootparent> Or there is a reason they would want this exemptedWell, I&#x27;m not in CA, but I do know a ton of farmers and not a single one is happy with the current situation. reply babypuncher 15 hours agorootparentprevThose representatives get elected because wealthy companies like John Deere spend lots of money to make sure that happens.Take the money out of politics. Pass strict campaign finance reform laws, kill super PACs, and put severe limitations on what qualifies as \"lobbying\", and a lot of these problems will go away. reply deelowe 4 hours agorootparentSure. And guess who needs to do that? The politicians. Again, all the blame sits on their shoulders. Expecting companies to have some sort of morale compass is just a result of the media hiding the truth from everyone. reply MetaWhirledPeas 18 hours agorootparentprev> Lawn, garden, golf course, landscaping, or grounds maintenanceTim Cook: And one more thing... iPhone 16 can control your lawn mower! reply lesuorac 17 hours agorootparentI mean iPhones (and other phones) have apps that help you identify weeds and the like.Don&#x27;t iPhones have that earthquake detection as well so they might as well be an alarm device. reply derefr 17 hours agorootparentprevTo me, it&#x27;d make sense in theory to carve out these exceptions even without a lobbyist asking for them: it&#x27;d make for a bill that gets immediately passed rather than endlessly argued about and shot down, because a bill with these exceptions has nobody on the other side of it pushing back. And that could just be the first step; you could then do a series of smaller bills (or better yet, riders to must-pass bills) that each try to knock out one of these exceptions.In practice, though, I feel like the exemptions here will be interpreted as part of the \"spirit of the bill\" rather than examples of realpolitik expediency... reply mdgrech23 17 hours agorootparentprevThis country has become such an effing joke. This story of exceptions for big companies and the rich repeats itself over and over. reply salawat 18 hours agorootparentprevSo, it applies to basically nothing at all important that wasn&#x27;t already covered in one way shape or form?Hell, the last paragraph on the alarm bits basically opens the door so damn wide, this moght as well have not even been drafted. reply tomhallett 20 hours agoparentprevI&#x27;m wondering if it was a carve out that was easy to give, doesn&#x27;t water it down too much and is helpful for other politics:* Sony produces semi-conductors and movies (Sony Pictures, Columbia, Tristar)* Microsoft is big in enterprise cloud (ie: government)* the impact of people being forced to upgrade their phone because they can&#x27;t fix it, is probably larger than people being forced to upgrade their game system because they can&#x27;t fix itNote: I 100% agree with you. I see video games as the same as all other consumer electronics which were included, but I can see if Sony&#x2F;Microsoft came complaining, it&#x27;s a good bargaining chip&#x2F;favor for other initiatives. reply bluejekyll 19 hours agorootparentI’m actually more surprised that they didn’t cave to Apple. In either direction. Apple should have been kicking and screaming to have no exemptions.Alternatively, the iPhone and AppleTV, and all their computers will now be redefined as gaming consoles (which honestly, what’s the technical difference) reply joking 19 hours agorootparentWhy would Apple complain? You can repair a phone screen as long as you pay 50% off the price of the original phone. As long as they control the supply of components and are able to price them as they wise, it’s a win win for them. The difference between Apple and any other phone, is that Apple has maybe 15 different models to support that each one has been sold by millions of units, meanwhile there are thousands of different android phone models. reply xethos 19 hours agorootparentprevThe trillion dollar behemoth famous for having few models can afford to stock parts for seven years. Can Motorola, or the smartphone or laptop arm of Lenovo (industries with famously low margins) justify staying in the space and competing with Apple? reply shaftway 18 hours agorootparentprev> which honestly, what’s the technical differenceAccording to the Tetris movie, it&#x27;s that they don&#x27;t have a keyboard and they are expected to stay in one spot. reply andjd 19 hours agoparentprevSo, there is a defensible reason for this carve-out.For generations now, video game consoles have had very aggressive cryptographic pairing of parts, done in the name of securing the hardware against hacking by the console owner. This is done to prevent mods to enable cheating and piracy. Given that consoles are often sold at a loss with profits recouped on game sales, there&#x27;s a justification for this.Providing replacement parts for game consoles would also require tools to re-pair the replacement parts. If these tools need to be provided to independent repair shops, there&#x27;s approximately a 100 % chance of them getting leaked and destroying the security of the console.I&#x27;m not going to say that this is a good or a bad thing. I&#x27;m just pointing out that there&#x27;s a real reason for lawmakers to treat game consoles different than phones or computers, and that it isn&#x27;t necessarily a sign of corruption. reply pjc50 19 hours agorootparentThis is also done for iPhones, which have not been exempted.The \"security\" of the console against \"unauthorized\" software is arguably against the public interest. Is it really to the customer&#x27;s benefit to exclude software providers from the market? Haven&#x27;t we been round this with app store discourse?> consoles are often sold at a loss with profits recouped on game salesThis used to be true, but is it still true? reply kube-system 19 hours agorootparentThe purpose of gaming consoles is to play games, and allowing cheating software on them ruins the experience for others. Consoles are not general purpose computers, they have a specific use which is gaming, and it is reasonable to protect the fairness required to have a good experience when using it in the way it was intended to be used. reply pjc50 18 hours agorootparentThere&#x27;s at least four different cases which are being conflated:- genuinely third party software, e.g. the short lived Playstation Linux => \"good\"- modified software (usually \"bad\" but we can find non-bad cases)- piracy. \"Private servers\" probably count under this- preservation (unfortunately indistinguishable from piracy, but covers what happens when required online services shut down) reply kube-system 18 hours agorootparentYes, but console makers don&#x27;t really get to choose how, or with what intent, downstream users will modify devices if given a window to do so. reply safety1st 17 hours agorootparentprevYou don&#x27;t need to lock down a console and prevent \"unauthorized software installs\" to prevent cheating. You do what game developers have been doing on PCs for years: validate all of the player&#x27;s actions on the server, look for players with suspicious patterns of activity then ban them. reply kube-system 13 hours agorootparentBehavior analysis is one approach used on PC games, and it has varying degrees of success. There are weaknesses to this approach and it tends to be a cat-and-mouse game of cheat developers adding fuzzing and anti-cheat developers adjusting their behavior analysis. Visit forums for games that use this kind of anti-cheat and you&#x27;ll see people complaining about cheaters.More popular games have shifted towards anti-cheat systems that run at ring zero and prevent you from playing the game unless it is happy with everything running on your system. reply sim7c00 18 hours agorootparentprevThis is correct to be honest. rooting your phone doesn&#x27;t ruin other peoples phone experience unless you perform actually illegal conduct perhaps (maybe some hacks or w&#x2F;e?). Cheating in a game is not illegal, so companies need to take it upon themselves to prevent it. This is honestly fairly logical. it does not at all compare to PC or Phones. reply kube-system 18 hours agorootparentAnd when people \"root their phone\" they are just modifying part of the device. The baseband is closed source and illegal&#x2F;impossible to modify in order to protect the network and spectrum. reply joecool1029 18 hours agorootparentSome of us do get pretty close and modify stuff like EFS to enable&#x2F;disable functions (voNR) and enable bands that were present but not legal at the time the device was certified. In US, band 77 was disabled on many devices but later became legal to use. The manufacturers didn&#x27;t want to pay for the recertification but the device is capable otherwise. We also sometimes add band combinations (for carrier aggregation) that the manufacturer missed. reply short_sells_poo 19 hours agorootparentprevPhones are not general purpose computers, they have a specific use which is to communicate with people over a distance.See?But you can in fact turn it around, because both phones and games consoles are in fact general purpose computers that are able to execute any program, before the arbitrary limitations are imposed on them by the manufacturers. reply kube-system 18 hours agorootparentMy point is that it is normal for special purpose devices to be regulated in such a way that prioritizes their primary purpose. And this is true for smartphones. The parts of your phone that must comply with telecom regulatory standards are locked down in black boxes separate from the main system. reply lukeschlather 18 hours agorootparentThe problem is this doesn&#x27;t prioritize their primary purpose. It ensures that the device will simply stop functioning within a relatively short time frame. This sort of crypto-locking of parts makes them impossible to fulfill their primary purpose when a part fails and the manufacturer won&#x27;t sell a replacement part. It&#x27;s unacceptable to brick devices in the name of cheat defense. reply kube-system 17 hours agorootparentI disagree. If it is not playable due to the manufacturing failing to prevent cheating, there is no need to replace parts on it, as it would be broken either way. A fair playing field is essential part of a functional game.If the immobilizer on your car fails, it will brick your car too. The solution isn&#x27;t to prohibit immobilizers and shrug our shoulders at car thieves, it is to require manufacturers to provide parts. Which we have long done for cars in the US.TL;DR: Don&#x27;t prohibits locks that protect consumers just because the lock could need maintenance. Require the manufacturer to provide parts for the lock. replyparineum 19 hours agorootparentprevAFAIK, it&#x27;s still true for Sony&#x2F;Microsoft but hasn&#x27;t been true with Nintendo for a while, I think since the Gamecube (when they stopped trying to play the performance game). reply bogwog 18 hours agorootparentprevWhy must the government pass laws to protect the specific business model of exactly 3 mega corporations, a business model which harms consumers and harms competition?The DMCA exception for consoles is the same thing. The government is just taking these companies word for it, and harming everyone else. If Playstation&#x2F;Xbox&#x2F;Nintendo can’t survive without these handouts from the government, then why should they? It’s not like game consoles are a necessity. The free market is what should decide whether a business model succeeds or not.And regarding privacy, that’s bs. If consoles somehow become overrun with piracy, then publishers can just move their games to other platforms. PC is much easier to pirate on, is in general used by more tech savvy people, and it doesn’t have a rampant piracy problem. Steam wouldn’t be as successful as it is otherwise. reply avar 19 hours agorootparentprevEven if we accept this argument, the parts you&#x27;re talking about are a tiny proportion of video game console parts.There&#x27;s no reason you shouldn&#x27;t be able to e.g. buy replacement analog stick parts. reply ndriscoll 19 hours agorootparentprevThe trend of \"securing\" (i.e. sabotaging) hardware against the owner is a large part of why these laws are needed in the first place. reply Aerroon 19 hours agorootparentprev>Given that consoles are often sold at a loss with profits recouped on game salesI&#x27;ve wondered about this before: how is this not anti-conpetitive pricing? Is it okay because Sony&#x2F;MS don&#x27;t raise prices? reply dmoy 19 hours agorootparentUS law in that area looks more at consumer harm, not incidental harm to other companies, IIRC. There&#x27;s a separate way to get in trouble here around predatory pricing, but I think that&#x27;s more complicated (you have to be doing it specifically to drive people out of business). It depends on what the rest of the market does. See https:&#x2F;&#x2F;www.ftc.gov&#x2F;advice-guidance&#x2F;competition-guidance&#x2F;gui...Specifically> Pricing below a competitor&#x27;s costs occurs in many competitive markets and generally does not violate the antitrust laws. Sometimes the low-pricing firm is simply more efficient. Pricing below your own costs is also not a violation of the law unless it is part of a strategy to eliminate competitors, and when that strategy has a dangerous probability of creating a monopoly for the discounting firm so that it can raise prices far into the future and recoup its losses.So> Is it okay because Sony&#x2F;MS don&#x27;t raise prices?Yes exactly this.See also:Printers sold below cost with expensive ink refills.E-readers, oftenRazors for shaving - the base or chassis or whatever you call it is often sold below cost. reply Aerroon 19 hours agorootparentThank you! reply dmoy 19 hours agorootparentNo problem, it&#x27;s a good question, and it only works that way because of the particulars of US law. It differs for other countries, or even within the same country over time (the US&#x27;s consumer focus was less strong in earlier years). reply criddell 19 hours agorootparentprevThe consoles-are-sold-at-a-loss explanation has always seemed like an extraordinarily week argument for giving Microsoft and Sony a pass on bad behavior.Their consoles may be sold at a loss at launch, but I don&#x27;t know of any console hardware that wasn&#x27;t net profitable over it&#x27;s lifetime with the possible exception of the XBox with the ring-of-death problem. reply hermannj314 19 hours agorootparentprev42488.2.f already mentions limitations in the bill to prevent overriding anti-theft.They could have extended that to include anti-piracy or anti-cheat or cryptographic pairing, but they didn&#x27;t. They created a specific carve out for video game consoles and not for those other things you mentioned.When the government uses words generically to define its compelling interest to regulate, they are usually sincere. When the government uses words to protect an industry explicitly, they usually have been bought. reply maerF0x0 18 hours agorootparentprev> at a loss with profits recouped on game salesand perhaps the FTC should be smashing down that practice as anticompetitive? reply fiddlerwoaroof 18 hours agorootparentI don’t see how it’s anticompetitive: any startup trying to get into the space is going to be making the case for product-market fit in terms of things like subscriptions and selling access to developers. I’d think a one-time per customer console sale at a loss would be one of the easier expenditures to justify to investors. reply LocalH 19 hours agorootparentprevThat heavy cryptography is why the Xbox One is shaping up to be the least preservable console we have ever seen. reply johnday 21 hours agoparentprevWithout trying to defend this particular carve-out, I would suggest that things like computers and video game consoles are improving in capability over a much faster time scale than TVs and video cameras. Hence there is much less of an expectation of longevity &#x2F; relevance than with other tech goods.That said, the same argument could be made for mobile phones as well, so it&#x27;s clearly spurious. reply InSteady 20 hours agorootparent>Hence there is much less of an expectation of longevity &#x2F; relevance than with other tech goods.These kinds of arguments are hollow. Especially in gaming, if you make a good console with good games, people will want to hang on to them and play them for literally decades. But even ignoring that specific aspect of gaming culture, it really should not be up to some top-down, self-serving analysis about what most consumers should expect. Otherwise it&#x27;s just a race to making the least consumer-friendly product so you can make legal&#x2F;political arguments about consumers obviously want to buy expensive garbage which they expect to break beyond repair in a few years at best. reply KptMarchewa 21 hours agorootparentprevThat argument made sense 10 years ago, but since then we&#x27;ve seen a lot of slowdown in computers, consoles and mobile phone progress, while TVs have overcome the LCD slump.The value difference between 10 year old console (PS4!) and new one, can be smaller than 10 year old LCD vs new OLED. reply inetknght 21 hours agorootparent> > Without trying to defend this particular carve-out, I would suggest that things like computers and video game consoles are improving in capability over a much faster time scale than TVs and video cameras. Hence there is much less of an expectation of longevity &#x2F; relevance than with other tech goods.I disagree with your point, but I&#x27;ll reply to this one:> That argument made sense 10 years ago, but since then we&#x27;ve seen a lot of slowdown in computers, consoles and mobile phone progressThat argument doesn&#x27;t made even less sense 10 years ago in my opinion. When things are moving fastest (eg, most profitable) is when parts must be made available for consumers to repair themselves. When things are moving slower, then the IP&#x2F;schematics should absolutely be provided if nobody is willing to make the parts. reply anonymousab 21 hours agorootparentVideo game console gens last longer and have continued software support for longer than Android phones. reply inetknght 17 hours agorootparentHonestly though: how long something lasts shouldn&#x27;t matter, companies should still be forced to provide support for things they sell, or else to provide their IP&#x2F;schematics so that other people can support the trash that was sold. reply mcpackieh 21 hours agorootparentprevThis is absolutely true when you look at hardware from today vs 10 years ago, then do the same comparison between the 90s and 80s or even 00s and 90s. People are playing basically the same manner of game now and 10 years ago, but between the 80s and 90s there was radical change in technology in a way that shaped the development of entirely new video game genres. Video game development since about the early to mid 00s has been mostly a matter of refinement, very little has been truly revolutionary. reply Kirby64 19 hours agorootparentprevIt makes less sense. Video game consoles typically run 5-10 year cycles. If anything, supporting repair on them should be easier, because you can play the same games on the console at very first release as you can on the console sold right before they discontinue them. PCs and phones get updates yearly, and a 10 year old PC certainly can&#x27;t play the same games as a brand new one. reply alpaca128 20 hours agoparentprevCan&#x27;t wait for a smartphone brand to argue their phone is a game console because you can play games on it. reply hermannj314 20 hours agorootparentThe statute&#x27;s definition of video game console specifically disallows computers, tablets and cell phones from being considered a video game console.Section J9 reply fulafel 19 hours agorootparentDoes this apply to general purpouse computers such as the PS3? (see https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;OtherOS) reply bathtub365 20 hours agorootparentprevApple has been making uncharacteristic strides in this area. At WWDC this year they announced that Death Stranding was coming to Macs, and at the Sept 12 event they had a fairly long piece about how the iPhone 15 Pro is capable of playing AAA games. I wouldn’t be surprised if this was actually a conscious strategy for this angle but that’s speculation. reply bombcar 21 hours agoparentprevSpeaking of video game consoles I remember finding out that Nintendo would still “repair” a GameCube without composite out into one with it for years and years after the GameCube was not sold new. reply hermannj314 20 hours agorootparentI dont want to start a war with any right-to-repair purists, but I do think in lieu of offering 7 years of parts a company that makes reasonable low-cost (or free) replacement a simple request for 7 years would also be meeting the needs of most consumers. And a lot of video game consoles have very liberal policies already toward this regard.Some products are significantly cheaper to replace than repair, even if they cost more than $99. reply bombcar 19 hours agorootparentA defined \"support period\" with relatively bounded costs is all we really need, I agree.Knowing that if I buy a technology product that is more than $100, it will either work for 5 years (or whatever) or be repairable for some fraction of the original cost, would make me satisfied. reply ncallaway 19 hours agorootparentprevmy only concern with this exception is it creates a monopoly, which then needs to be carefully regulated at multiple levels.Yes, we can regulate the price, but if only the original vendor can perform repairs we might also need to regulate quality and timeliness (similar to how lemon laws for cars often specificy a maximum number of repair attempts, or hours away from the owner for repairs, before the vehicle must be refunded).I think it’s an okay approach, but I also think it requires a heavier hand from the government, and from ongoing oversight, than letting the market figure out reasonable rates for a repair. reply bombcar 16 hours agorootparentALL of these various \"consumer protection\" laws can be gamed by the biggest players, so they have to carefully vetted before they go live.Basing them on the already-existing protections around the auto industry is probably a decent place to start. reply matheusmoreira 21 hours agoparentprevIt&#x27;s weird to me that video game companies apparently have this much lobbying power but all the other consumer electronics corporations don&#x27;t. Are they really much richer than all the others combined? reply paulmd 21 hours agorootparentthe regulation is much more about regulating a governmental solution to the android-iphone wars than regulating consumer freedoms or e-waste etc. those are convenient levers for the powers involved.tim sweeny does not care about unlocking your xbox. at no point was that a possible outcome or a consideration in his thoughts, no matter how much the android guys waved the flags.it&#x27;s about unreal and unity legislating higher gross margins, and about breaking the apple restrictions on facebook&#x27;s permission requests, and about safari resistance against google chrome browser monoculture. and y&#x27;all lost.is that crass? I guess, but it doesn&#x27;t matter, because we have to live with the google browser monoculture anyway. I had some people recently tell me \"EU will just regulate it if it becomes a problem!\". how long did it take to become a problem? didn&#x27;t google move pretty much right into the enhanced ad profile thing?https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36823031https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=33821820it is what it is, the laws are passed, but holy shit the arguments have been so transparently bad-faith, or incredibly blind.I’m just so tired of the fanboy wars and the “wow did you actually read someone advocating resale of stolen&#x2F;mugged parts to bring prices down”. Yes, on HN no less. The android fans are shameless. I’m so tired of the “wow iPhone fans are brainless” (earlier this week). Etc.It’s become so casually normalized for android fanboys to be toxic and gloat about anyone who calls it out. It’s so fucking weird. When did this happen. 2012? 2014?And no, there is no iPhone contingent going around calling android people brainless blue bubble sheeple or saying that their purchase melted their brains etc. it’s crazy. I am so tired of the way the android contingent casually misbehaves, everything is brainless this and brain-rotted that and sheeple this.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37491711 reply p_j_w 18 hours agorootparentThe people you&#x27;re trying to embarrass by linking here look pretty reasonable.>there is no iPhone contingent going around calling android people brainless blue bubble sheepleOn HN? Maybe not. Out in real life? Yes, there absolutely is. I recently got an iPhone, and the number of people who said something along the lines of \"OMG you finally got an iPhone, yay!\" was fucking obnoxious. reply JohnFen 16 hours agoparentprevI think it says a lot about the terrible state of things that such mild and inadequate legislation as this can be characterized as \"the strongest yet\".Don&#x27;t get me wrong, any progress is good, but this is, at best, a very tiny baby step. reply nobodyandproud 19 hours agoparentprevNot having these carve-outs would force some local manufacturing know-how.And solve some of the major garbage issues of our times.Of course the billwriters couldn’t push for a later timeframe for those “exceptions” rather than an outright pass. reply BLanen 20 hours agoparentprevCarving that exemption out afterwards seems easier now too. reply grecy 18 hours agoparentprev> got a nice re-election contributionIt&#x27;s bribery. They were paid a Bribe. Use the word. reply Joker_vD 20 hours agoprevnext [3 more] [flagged] rascul 20 hours agoparentCalif. is one way to abbreviate California. reply Joker_vD 20 hours agorootparentOops, I missed the dot after the \"f\". The title makes sense now, thank you.Edit: although that&#x27;s probably the first time I&#x27;ve seen this abbreviation, it&#x27;s always either \"Cal.\" or \"CA\". reply paulmd 22 hours agoprevnext [7 more] [flagged] throwaway48487 22 hours agoparentThat ship has now sailed for (almost?) all manufacturers, but I would like to remind that Apple was the pioneer in normalizing anti-consumer practices like non-removable batteries. reply causi 22 hours agoparentprevWho is \"them\"? Until Apple was strong-armed into launching the self-service program they didn&#x27;t sell first-party replacement parts at all, let alone for seven years after launch. reply paulmd 21 hours agorootparentdamn, so how long a lifecycle did sony do before they were forced? reply causi 14 hours agorootparentWhat does this have to do with Sony? As far as I know, every manufacturer including Sony and Apple do their utmost to extract as much revenue from consumers as possible. reply warning26 22 hours agoparentprevCan you elaborate? I’m not familiar with why android fans would make those particular arguments. reply paulmd 21 hours agorootparentsure, literal tech media whining about anti-theft being too good: https:&#x2F;&#x2F;www.macworld.com&#x2F;article&#x2F;1485237&#x2F;mac-security-t2-chi...https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=34545028literally and directly advocating resale of stolen goods, because \"who cares about theft, it&#x27;s cheaper\", on HN itself no less lmao.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35945110\"oh noooo it&#x27;s just one guy\" lmao no it&#x27;s not, do you want me to continue to mine?literal mass-theft rings: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=35475696 reply charcircuit 19 hours agoprevPhones don&#x27;t get security updates for 7 years. It&#x27;s irresponsible to repair such old phones, prolonging their use. reply Sindisil 19 hours agoparentYou&#x27;re holding it wrong.Phones should be required to get (at least) security updates for (at least) the same period as they are covered by repairability requirements. reply charcircuit 18 hours agorootparentLinux LTS is not even supported for 7 years, but only 4 years for the latest one. It&#x27;s not a linear function for how much it costs to add another year of support. reply Sindisil 18 hours agorootparentNothing says that they can&#x27;t ship a newer version of device software, if they find that less costly (as long as the newer sw fully supports the device, of course). reply gryzzly 21 hours agoprev7 years is nothing. This is the best we can do, people are doomed. reply mcpackieh 20 hours agoparentI agree, 7 years should be in the flat plateau of most product&#x27;s bathtub curves, before most things start failing and consequently need spare parts in the first place. 15 years would be a lot more meaningful, but it really depends on the type of product in question. reply djha-skin 21 hours agoprev [–] California: we&#x27;re rich and powerful and without us you compani",
    "originSummary": [
      "California has passed an extensive right-to-repair bill, obliging vendors to supply parts, tools, repair guides, and essential software for consumer electronics and appliances.",
      "The bill surpasses other state laws, demanding vendors offer such items for products sold from July 1, 2021, for a duration determined by the product's cost. The legislation includes enforcement provisions and mandates repair vendors to disclose the usage of \"non-authorized\" parts.",
      "Apple supported this bill, underlining its products’ increased repairability and durability. This legislation, along with similar laws in other states and Europe, may motivate manufacturers to provide globally repairable and sustainable products."
    ],
    "commentSummary": [
      "California has passed a right-to-repair bill obligating manufacturers to supply parts for their products for a minimum of seven years.",
      "This bill has sparked debate pertaining to issues such as the quality of third-party replacement parts, strain on small businesses, the disclosure of schematics with potential impact on competition and intellectual property rights.",
      "Discussions delve deeper into the capacity of repairing electronic devices, availability of individual parts, durability and duration of tech goods, with notable discourse on planned obsolescence and its influence on consumer rights, cost considerations, and overall impact on businesses and industries."
    ],
    "points": 391,
    "commentCount": 270,
    "retryCount": 0,
    "time": 1694688144
  },
  {
    "id": 37509560,
    "title": "Tails is a portable OS that protects against surveillance and censorship",
    "originLink": "https://tails.net/",
    "originBody": "Tails Donate Home How Tails works Install Tails Documentation Support Contribute News English DE ES FR IT PT RU Tails is a portable operating system that protects against surveillance and censorship. Avoid surveillance, censorship, advertising, and viruses Tails uses the Tor network to protect your privacy online and help you avoid censorship. Enjoy the Internet like it should be. Your secure computer anywhere Shut down the computer and start on your Tails USB stick instead of starting on Windows, macOS, or Linux. Tails leaves no trace on the computer when shut down. Digital security toolbox Tails includes a selection of applications to work on sensitive documents and communicate securely. Everything in Tails is ready-to-use and has safe defaults. Free Software You can download Tails for free and independent security researchers can verify our work. Tails is based on Debian GNU/Linux. How Tails works Install Tails News Tails 5.17 Posted 2023-09-05 Tails report for July 2023 Posted 2023-08-22 Tails 5.16.1 Posted 2023-08-15 Who uses Tails Activists use Tails to hide their identities, avoid censorship, and communicate securely. Journalists and their sources use Tails to publish sensitive information and access the Internet from unsafe places. Domestic violence survivors use Tails to escape surveillance at home. You whenever you need extra privacy in this digital world. Recommended by If you look at the way post-2013 whistleblowers have been caught, it is clear the absolute most important thing you can do to maintain your anonymity is reduce the number of places in your operational activity where you can make mistakes. Tor and Tails still do precisely that. — Edward Snowden, NSA whistleblower Tails expands Tor's protections to an entire operating system, and they do so with an unwavering commitment to their Social Contract. Tails is a favorite companion tool of Tor. — Roger Dingledine, co-founder of the Tor Project One of the most robust ways of using the Tor network is through a dedicated operating system that enforces strong privacy- and security-protective defaults. That operating system is Tails. — Electronic Frontier Foundation Sponsors Our work is funded by donations from people like you and organizations that support Internet freedom. Meet our sponsors. Tails Home How Tails works Install Tails Documentation Support Contribute News Support FAQs Known issues Warnings Accessibility Upgrade Contribute Report an error Translate Source code GitLab Donate About us Contact Mission and values Social contract Sponsors Code of conduct License Jobs News Subscribe to our newsletter: Subscribe",
    "commentLink": "https://news.ycombinator.com/item?id=37509560",
    "commentBody": "Tails is a portable OS that protects against surveillance and censorshipHacker NewspastloginTails is a portable OS that protects against surveillance and censorship (tails.net) 384 points by gslin 19 hours ago| hidepastfavorite170 comments dmwilcox 18 hours agoLove Tails, but I haven&#x27;t used it in ten years. I have had Tails and Qubes disposable VMs on my mind though.I switched off of Qubes last year to my own Alpine chroot with a hand crafted kernel and initrd that lives only in memory. I find turning off the computer when I&#x27;m finished and having it forget everything to be a very peaceful way to compute. I owe the internet a write up.I feel like ramfs for root filesystems is an underused pattern more broadly. \"Want to upgrade? Just reboot. Fallback? Pick a different root squashfs in the grub menu\" reply justin_oaks 18 hours agoparent> I owe the internet a write up.I would definitely be interested in reading more about this.I love the idea of being able to prevent an application from writing all over my disk to random places. If I can&#x27;t prevent it, I can at least remedy it by having all those changes go away with a reboot.One of the things I love about Docker containers is that they can be ephemeral or persistent, short or long term, have full network access or no access, allowed to write to the host system or stuck writing to its own file system only.I&#x27;m in control instead of the application. reply tlavoie 11 hours agorootparentAges ago, I tried out Puppy Linux, that ran from a burned CD. If I made updates, it wrote another filesystem extent to the disc, and I think the loading process just used those to over-write files as needed until the boot completed.I was thinking of it for a home firewall at the time, but in any case, it made for a very ephemeral system. reply mixmastamyk 16 hours agorootparentprevTypically they can only write to home and temp. That can be improved via sandboxing, and there’s Little&#x2F;Open Snitch as well. reply omani 18 hours agoparentprevSame here. Dont understand why not more ppl switched to alpine on the desktop. It is my daily driver. Plus LXD for stuff I must do (typically spawn ubuntu, etc.)my whole PDE (Personal Developer Environment) is within a container. Need python? Shell into (via dmenu) python container. All with complete neovim setup. Need a GUI? No problem. Spawn a container. My lxd profile is set up for this. Use chezmoi for heavy automated stuff.My base alpine system always stays clean. reply morjom 17 hours agorootparent>why not more ppl switched to alpineI think one reason might be musl and its compatibility. reply wkat4242 13 hours agorootparentWhat&#x27;s so bad about musl? Everything works fine for me on Alpine.My desktop is FreeBSD but I have a few alpine servers for docker and other Linux specific stuff.And FreeBSD is even less Gnu-Linux compatible than Alpine yet everything works fine. Thanks to an army of port maintainers of course. reply throwawayxxbv 9 hours agorootparentWorks fine after a lot of work. Sometimes. reply bsdnoob 18 hours agorootparentprevBy any chance can you share how you do this practically? reply coppsilgold 12 hours agorootparentI also use alpine as the main&#x2F;root environment. But I rarely use any applications from alpine. For that I have Arch, Fedora and Debian rootfs dirs into which I pivot_root with the help of bubblewrap (bwrap) in shell scripts. There is no overhead and the GPU can be easily attached. You can also dynamically attach ro&#x2F;rw CWD and target paths (`for arg in \"$@\"`).Everything that I care about just works and I get a separation of concerns. Use of network namespaces allows further flexibility. For example, I have a netns that is forced through a Tor gateway such that any traffic originating in it can only go through Tor.This type of setup is not hardened against kernel vulnerabilities, the kernel treats applications running in namespaces as if they are isolated from other namespaces but those applications can still interact with broad surfaces of the kernel and therefore potentially exploit it.For kernel safety applications must be denied direct access to the host kernel, this is usually achieved with virtual machines. reply palata 6 hours agorootparent> For kernel safety applications must be denied direct access to the host kernel, this is usually achieved with virtual machines.And that is what QubesOS does, if I understand correctly? reply yard2010 17 hours agorootparentprev+1 and from which IDE&#x2F;text processor did you migrate from to neovim? reply codethief 14 hours agorootparentprevDo you have a separate neovim instance (config and all) in every container? Or a single neovim instance on the host which can access all container volumes? What about shell instances? reply macinjosh 13 hours agorootparentI containerized my neovim setup and I share my projects&#x2F; directory with it. Containers get a shared volume like projects&#x2F;project&#x2F;.From my neomvim container I can use the local terminal or I can ssh to the host to run my other containers. reply PrimeMcFly 9 hours agorootparentprev> Dont understand why not more ppl switched to alpine on the desktop.Same. When I was looking for a minimalistic distro, while unorthodox it seemed better than the alternatives. My next choice would be Void but I ran into some issues with it, and Alpine worked much more flawlessly. reply Scarbutt 17 hours agorootparentprevHow do you run a GUI with a container? Xorg server running in the container? reply kspacewalk2 16 hours agorootparentHere&#x27;s how I do it using Docker Compose:https:&#x2F;&#x2F;gist.github.com&#x2F;kspacewalk&#x2F;52ea8f0c383f57a34042db2a0...Access via http:&#x2F;&#x2F;localhost:8080&#x2F;vnc.html reply samuell 17 hours agoparentprevHow do Tails and Qubes relate, any reuse of functionality?(Tried Qubes as written up in [1] but eventually gave up as it won&#x27;t allow me to create virtualbox images, and some other caveats, as well as being pretty resource hungry)[1] https:&#x2F;&#x2F;bionics.it&#x2F;posts&#x2F;installing-qubes-os reply paravirtualized 16 hours agorootparent> it won&#x27;t allow me to create virtualbox imagesWhat&#x27;s the use case[1] for VirtualBox images in an operating system designed around virtualization with Xen? You can simply create a Xen VM.[1]: Note that I&#x27;m asking a question here, not invalidating your experience. reply samuell 16 hours agorootparentI&#x27;ve been needing to create virtualbox images for use in some courses (teaching data science and the like) at my previous work. This usecase has popped up often enough that I feel O need to be able to do this on my main laptop. reply hedora 17 hours agoparentprevI treat my web browser like this, and similarly have a docker container for all my development stuff. I like the idea of making the computer (almost) completely stateless.How do you deal with stuff you want to store in &#x2F;home? (Like source code checkouts, ssh keys, etc.) reply analognoise 17 hours agoparentprevIn NixOs it&#x27;s called Impermanence:https:&#x2F;&#x2F;nixos.wiki&#x2F;wiki&#x2F;ImpermanenceAlso NixOs has absurd levels of control for upgrades, rollbacks, and control over the build and resulting files. reply smoldesu 17 hours agorootparentBe warned; your hard drive may file for a divorce after a few years of daily-driving NixOS. It is both a blessing and a curse: $ smol@computer ~> du -hcs &#x2F;nix&#x2F;store&#x2F; 257G &#x2F;nix&#x2F;store&#x2F; reply alex-robbins 15 hours agorootparentI&#x27;m so sick of this claim. Nix allows you to keep old versions of things installed, but you certainly don&#x27;t have to.When I switched from Debian to NixOS a few years ago, I installed it on a separate subvolume, and it ended up taking almost exactly as much space as Debian did (about 12 GiB with gnome and everything else). And really, what would you expect? It&#x27;s nearly all the same code, just organized differently in the filesystem.P.S., you can check the store usage of the current system profile with `nix path-info -Sh &#x2F;run&#x2F;current-system`. reply miniBill 17 hours agorootparentprevYou... do regular GC, right?I have 45G, and this computer is more than two years old reply smoldesu 17 hours agorootparentI have multiple flakes and a lotta CUDA drivers. In fairness though, this is after a few months of no manual GC. I think nix-collect-garbage could bring it down to ~120-150gb.It&#x27;s totally worth the stability, but maybe not the best choice for the storage-constrained.EDIT: According to nix-tree my current generation is only 45gb right now. replynostril 16 hours agoprevHi. We&#x27;re building The Nose (https:&#x2F;&#x2F;thenose.cc), a safe haven for training data that can&#x27;t be taken down with DMCA. Since this involves copyright infringement, strong anonymity is a requirement.I wrote up our security procedures here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37346620The reason Tails isn&#x27;t an option is because, as others have mentioned, there have been Tor browser exploits which reveal the IP address of the Tails user. While this is unlikely for our case, it&#x27;s important to approach security from first principles with threat modeling. An attack from the FBI may seem unlikely today, but both Silk Road and one of its successors were taken down by mistakes they made when setting up their site. Learning from history, if you&#x27;re not careful early, you&#x27;re in for a surprise later.Case in point: When I started Whonix Workstation to post this comment, the Whonix Gateway VM failed to boot. So when I tried to start Tor Browser and go to https:&#x2F;&#x2F;news.ycombinator.com, all I saw was a connection error. This kind of layered defense is essential if you&#x27;re serious about staying out of jail.Realistically, you&#x27;ll likely dox yourself through some other means: sending Bitcoin to your pseudonym from your real identity, admitting to someone you know that you control your pseudonym (this work gets lonely, so this is a real temptation), or even accidentally signing off an email with \"Thanks, [your real name]\". And once you make a single mistake, you can never recover. reply nostril 16 hours agoparentOther thoughts:Day to day browsing is a pain. I use a VNC client to remote into our server, which is running a desktop environment with a regular browser. That way you can use apps (gmail, discord, etc) from outside the Tor network. But since you&#x27;re tunneling through Tor, this is painfully slow. You&#x27;ll likely want to type out long messages in Whonix, then copy-paste into your remote session. Each keystroke can sometimes take a full second to appear when animations are heavy.Transferring large amounts of data is also painful. If you try to start Litecoin Core on Whonix, you&#x27;ll need to sync more than 30 GB, which can take a very long time.Patience is your weapon. You have all the time in the world not to make a mistake, and moments to make a fatal one. Think carefully about everything you do.Stylometry scares me. AI can help here: run an assistant locally, and ask it to reword everything you write. You won&#x27;t be able to use ChatGPT for this, obviously because OpenAI retains a history of everything you submit, but also because they require a real phone number to sign up. And you can&#x27;t get a real number through any means I&#x27;ve found so far.Payment is also a pain. I&#x27;m hoping to ask the community to donate Vanilla gift cards so that I can sign up for Tarsnap or spin up a droplet.By applying the discipline normally found in aeronautics, I think it&#x27;s possible to do this safely. But you&#x27;ll still be risking jail time, and the intersection of people who want to do something for altruistic reasons and willing to risk prison is pretty small. I&#x27;ll be documenting everything I do so that you can learn from my example, or perhaps from my mistakes. reply fmajid 22 minutes agorootparentllama.cpp runs LLaMa 2 7B on common hardware like a MacBook Pro. Haven&#x27;t tried it yet on my RTX 3070 (Mobile) but there&#x27;s no reason why it shouldn&#x27;t work. reply costco 7 hours agorootparentprevI like the way you describe your process. As the person who made the stylometry thing that made the rounds a while back, I would say the best thing you can do on that front is to either get a \"paraphraser\" like ChatGPT&#x2F;translators or just write less. Also, there&#x27;s a site called smspva.com and a lot of sites like it where you can rent \"real\" phone numbers and they take every payment method under the sun. Depending on the country a phone number to receive an OpenAI confirmation code is about $0.50, most less popular services are like $0.10-$0.20. reply WD40forRust 14 hours agorootparentprevYou sir are very based.I too am a fellow qube herder. After having discovered Qubes OS, I&#x27;ve never wanted to go back! reply artninja1988 14 hours agorootparentprevReally appreciate what you&#x27;re doing. Don&#x27;t let those danish bottom feeders get you! reply qingcharles 5 hours agoparentprevAre you currently hosted on Shinjiru now? I&#x27;m thinking about using them as a reverse proxy in front of a site that might suffer false DMCA attacks. I don&#x27;t want my web host to ban me just because they can&#x27;t deal with the hassle, so I&#x27;m thinking about proxying all the requests.What does Shinjiru do if they receive a DMCA notice?When I ran a huge private torrent tracker I paid a decent chunk to get a host that ignored every single request of any type that they received. reply paravirtualized 16 hours agoprevTails has a very specific use case, very few people need anti-forensics.I suggest looking into Whonix[1] if you want something that you can truly use for privacy. It is also much more secure than Tails by design, and does not have any limitations like locking down the root user account.Summary from GitHub:\"Whonix is an operating system focused on anonymity, privacy and security. It&#x27;s based on the Tor anonymity network, Debian GNU&#x2F;Linux and security by isolation. DNS leaks are impossible, and not even malware with root privileges can find out the user&#x27;s real IP.\"[1]: https:&#x2F;&#x2F;www.whonix.org&#x2F;wiki&#x2F;FAQ reply replwoacause 9 hours agoparentDoesn’t seem to work on ARM though? So if you have a M1&#x2F;M2 mac, even running a hypervisor, you are SOL… reply trw55 11 hours agoparentprevWhat isn&#x27;t secure about Tails? Its been recommended by so many InfoSec podcasts that I&#x27;ve been poking around in it on a USB stick reply paravirtualized 1 hour agorootparentTails uses a less secure model because it relies on the system firewall to block any non-Tor connections. This means that any user to root vulnerability will leave you naked, deanonymized. Additionally, protocol leaks, or unintentional leaks are more likely to happen. Both of which have happened in the past and are not mere speculation.I&#x27;ve commented in this thread that at one point, such a vulnerability was left unpatched in Tails for years despite being documented and a PoC existing.Whonix on the other uses two VMs, one of which runs Tor and the other applications, and connects via an internal network. This means that non-Tor connections are impossible, as the VM where you run software is completely unaware of the real, external IP.This raises the level of exploit needed substantially, from user to root, to remote kernel exploits or hypervisor escapes. reply Run_DOS_Run 18 hours agoprevTails is great. I am using it for several years now.Other related projects are whonix ( https:&#x2F;&#x2F;www.whonix.org ), which consists of two virtual machines:A workstation to work on and a gateway, which torifies all traffic from the workstation VM.Whonix is also integrated in Qubes OS ( https:&#x2F;&#x2F;www.qubes-os.org ), which allows you to easily work with multiple seperate whonix VMs. There is also the possibility to tunnel all internet traffic of your machine through Tor including system upgrades of the host OS itself. reply Syonyk 17 hours agoparentWhonix&#x2F;Qubes integration is excellent, and it&#x27;s certainly a nice perk of Qubes.To clarify the benefits of the \"two VM\" approach:Most of the unmasking exploits against Tor users (as distinguished from unmasking Tor hidden services) involve getting a browser to ignore the proxy settings, somehow. I believe WebRTC, Flash, and various other things have been used to cause the browser to beacon out to some endpoint - you exploit the kitty picture site, and put in code to exploit the browser, which then makes a direct request to http:&#x2F;&#x2F;someip&#x2F;unique_identifier - and, boom, you&#x27;ve got the user&#x27;s IP, probable cause, the works.This happens because a \"typical\" Tor install is the daemon running locally, but nothing prevents other binaries from making a direct connection out. You set the browser to use socks5:&#x2F;&#x2F;localhost:9050 or something as the proxy, but if you can either get some part of it to misbehave, or just spawn off a different process, it doesn&#x27;t obey the proxy settings and goes straight out.Whonix solves this problem by splitting the system into the workstation VM (what you interact with) and the gateway VM (that connects to Tor and \"torifies\" traffic). The only network port on the workstation VM is connected to the input port on the gateway VM - and everything coming in that port is routed through Tor, via the other (internet connected) port.So, if you manage to exploit the workstation VM, the attacker still doesn&#x27;t gain an IP - because they launch a shell that runs &#x27;wget http:&#x2F;&#x2F;someip&#x2F;unique_id&#x27;, but that goes out through the gateway VM, and gets encapsulated into Tor before going out, so it still pops out some Tor exit node, not your home IP address.It raises the bar rather substantially for using Tor, and avoids a lot of the various ways to get Tor to leak. Also, they ship a copy of the Tor Browser in Whonix, which disables a lot of high risk functionality and allows you to very easily disable automatic media parsing and Javascript and such.Qubes is awesome, and the integrated Whonix stuff is just a beautiful integration. reply paravirtualized 16 hours agoparentprev> Whonix is also integrated in Qubes OS ( https:&#x2F;&#x2F;www.qubes-os.org )Qubes-Whonix with fully ephemeral disposable VMs is the future. It would be a total killer for nearly every use case of Tails besides ease of use.Note that this is in the works, but not fully implemented by default yet. https:&#x2F;&#x2F;github.com&#x2F;anywaydense&#x2F;QubesEphemerize> The steps below outline how to make all PVH DispVM&#x27;s permanently fully ephemeral. All data written to the disk will be encrypted with an ephemeral encryption key only stored in RAM. The encryption and encryption key generation is handled by dom0 and is thus inaccessible to the VM. reply replwoacause 9 hours agoparentprevTried to use it on my M1 MBA but it barfed. So I guess it is only for x86&#x2F;64 architectures. reply woodruffw 15 hours agoprevCould any HN users speak about their experience and rationale for using Tails?My outsiders’ perspective is that the threat model for these kinds of surveillance resistant tools is somewhat perverse: they trade indistinguishability (being lost in the crowd) for a nominally more anonymous but extremely unusual datapoint (a host&#x2F;browser&#x2F;etc. that basically looks like no other normal machine.)Put another way: without a clear attacker in mind, my outsiders’ perspective is that Tails feels a bit like wearing a paper bag in public to foil public CCTV: it might work, but is far likely to provoke contact with the relevant authorities than just attempting to blend in. reply EVa5I7bHFq9mnYK 14 hours agoparentYou put the stick in, access forbidden web site (for example, Instagram). Take the stick out, police searches your computer, there are no traces. If you were using a regular OS, even through Tor, there are some incriminating traces left, in browser cache, in MFT, in pagefile etc. that can be recovered. reply PrimeMcFly 3 hours agorootparentMuch the same result can be achieved by using a portable browser stored on an encrypted volume run inside a sandbox. For example on Windows, you can use portable Librewolf stored on a veracrypt volume running iside a portable sandboxie-plus sandbox (also stored on the encrypted volume). reply EVa5I7bHFq9mnYK 2 hours agorootparentTails is stronger than this approach in respect of the following threats: the $5 wrench for the veracrypt, keylogger installed on the host OS, memory scanners, the pagefile reply PrimeMcFly 2 hours agorootparentOh, absolutely, but the approach I mentioned is a little more convenient in some instances and provides a good balance IMO. reply replwoacause 9 hours agorootparentprevHuh? This sounds like fear mongering… reply EVa5I7bHFq9mnYK 2 hours agorootparentthe instagram part?https:&#x2F;&#x2F;www.insider.com&#x2F;russian-influencer-veronika-loginova... reply jacknews 19 hours agoprevI might be wrong but I think this was a project originated by one of the branches of the US armed forces or security services?In which case, it should be pretty secure.Although, there&#x27;s the obvious &#x27;honeypot&#x27; concern.But maybe I&#x27;m thinking of another distro, that ran from RAM and didn&#x27;t write anything to disk. reply cf100clunk 18 hours agoparentDistrowatch is a good place to get a brief overview of pretty well every Linux distribution ever made, with links and a bit of background info on each:https:&#x2F;&#x2F;distrowatch.com&#x2F; reply Synaesthesia 19 hours agoparentprevI know the TOR project was started by the US navy, and that now I2Pnis the preferred method of browsing the darknet, because many people believe it has been compromised. reply paravirtualized 16 hours agorootparent> and that now I2Pnis the preferred method of browsing the darknetThis is not true by any means. A \"switch\" to I2P never happened, and just a few months ago an exploit[1] that could deanonymize eepsites was published. Tor is still the only \"method of browsing the darknet\"; by most definitions.[1]: https:&#x2F;&#x2F;xeiaso.net&#x2F;blog&#x2F;CVE-2023-36325 reply Synaesthesia 3 hours agorootparentOk, I haven’t tried it out in a while so thx reply beardog 18 hours agorootparentprevIn the same manner that parts of the NSA are interested in secure cryptography as opposed to breaking it, parts of the Navy were interested in anonymizing traffic as opposed to de-anonymizing. reply brightlancer 13 hours agorootparentprevThe TOR software is likely no more compromised than GNU&#x2F;Linux generally -- the TOR _network_ is likely compromised by flooding it with honeypot servers that can track users by monitoring origins and destinations. reply daqhris 18 hours agoparentprevI can&#x27;t validate if you are wrong or not. Just bring to your attention that one of their marketing slogan is \"Amnesia\" and \"Persistent Storage on a USB stick\". https:&#x2F;&#x2F;tails.net&#x2F;about&#x2F;index.en.htmlThe &#x27;honeypot&#x27; concern is somehow valid because full-on privacy on the internet is as hard to achieve as privacy in a public park. Only its user can determine if their online activities goes against the (legal&#x2F;moral&#x2F;financial) interests of the most technically-advanced nation on our planet. reply paravirtualized 16 hours agorootparentThe Tails team made the fantastic decision of modifying the Tor Browser, giving Tails users a unique fingerprint as opposed to regular Tor Browser users. reply kylebenzle 18 hours agoparentprevTails was \"FUNDED\" by the TOR project, which was started by the US Navy. So, not really... reply ranger_danger 18 hours agoparentprevThe Internet also originated from the US military, among many other things. So tired of this FUD. reply chickenpotpie 18 hours agorootparentThat&#x27;s a false equivalency. The military invented a network that inspired the Internet. We&#x27;re not all using ARPANET to send emails. reply selectodude 17 hours agorootparentThe DoD created TCP&#x2F;IP. reply wrs 18 hours agorootparentprevNot sure what you’re saying there…the Internet grew out of ARPANet, it’s not a separate thing. Is the oak tree “inspired” by the acorn? reply chickenpotpie 17 hours agorootparentI think that&#x27;s an incorrect oversimplification. The Internet didn&#x27;t grow from ARPANET like a seed grows into a tree. ARPANET didn&#x27;t become bigger and bigger until it became the Internet. The Internet was the merger of many networks and many of them never communicated with any computer in ARPANET and we&#x27;re developed with absolutely zero funding from the United States government. reply wrs 11 hours agorootparentI guess it’s a matter of interpretation. Of course every computer connected to the internet is not government-funded. But in this context we’re talking about the origin of the technology and protocols that allowed the network to exist at all. By the time the internet got bigger than ARPANet, CSNET, and NSFNET (all government funded), the protocols were pretty much settled, and that’s what everyone else’s network used to become part of the internet. If the government hadn’t gotten it to that point, there would be no internet. replypulse7 16 hours agoprevHow can I be sure this project isn&#x27;t sponsored by XYZ government secret agency and that more than 1GB of data does not contain any surveillance software? reply laurent123456 16 hours agoparentThey appear to support reproducible builds, which would make it a lot harder to sneak in surveillance software - https:&#x2F;&#x2F;tails.net&#x2F;contribute&#x2F;design&#x2F;reproducibility&#x2F; reply slim 16 hours agoparentprevyou can&#x27;t. but here are some reasons XYZ should not target Tails specifically : - People who use Tails are not interesting data collection targets - They have already access to people using Tails by other means - It&#x27;s just Linux. So their 0days could work with little effort in case they need it. - The main purpose of Tor being an opensource project is plausible deniability for CIA agents using it. The main purpose of Tails (which is really a UX focused project) is more plausible deniability. They wouldn&#x27;t ruin it by making a different \"clean\" version for their agents. reply londons_explore 18 hours agoprevThere have been quite a few exploits in tails.I suspect you&#x27;re better off with a more obscure project, because then your adversary is less likely to have a &#x27;ready to go&#x27; exploit. reply costco 6 hours agoparentThis has been argued before: https:&#x2F;&#x2F;medium.com&#x2F;@thegrugq&#x2F;tor-and-its-discontents-ef51648...I think this is somewhat sarcastic but the article goes as far as saying \"[Tor Browser Bundle] is the only reason that FireFox is a valuable target.\" Firefox has improved sandboxing now though I don&#x27;t think it&#x27;s as good as Chromium. reply fullstick 17 hours agoparentprevWouldn&#x27;t that be security through obscurity? Which is bad security and a good way to be exploited. I thought that having more eyes on a system made it more secure because people find the exploits. reply hedora 16 hours agorootparentIt depends. Monocultures are also bad for computer security, since the failure mode is catastrophic.Ideally, there would be a few tails-style projects competing with each other (there are; see sibling threads), and the internet would be more federated (for instance, if github is completely compromised right now, many people reading this will git pull malware in the next day or so). reply Airsinner 16 hours agorootparentprevAlso if you’re rolling your own, you’re way more likely to not keep updates perfectly and patch everything that comes up. reply yjftsjthsd-h 16 hours agorootparentDepends how you roll your own; something lightly modified from a \"normal\" distro can just take upstream package updates and so put you in a good spot. reply aqfamnzc 11 hours agorootparentprevAs always, depends on the threat model. reply matrix12 12 hours agorootparentprevSecurity through minority actually. reply Veserv 14 hours agorootparentprev\"Many eyes\" is a failed philosophy. Even if many people could, theoretically, look at the code few actually do as evidenced by the Heartbleed defect in OpenSSL. One of the most critical pieces of software, used by literally billions of consumers and basically every trillion dollar company, and they missed glaring coding errors that any basic static analyzer would automatically tag. Nobody was looking at even some of the most critical code. The first failure is that you need people actually looking, which basically requires being paid to do full-time work (as most work on Linux is these days).In addition, even if people are looking, finding defects is really hard. A random onlooker has basically a 0% chance to find most of the critical zero-days afflicting Linux. It takes weeks to months of dedicated effort by technical experts with domain knowledge to find most such bugs. \"Many eyes\" is worthless to security, what you need is many trained technical experts with domain knowledge using high quality techniques and processes derived from successful high security projects.This is not to say that \"security through obscurity\" is a good thing or that \"open source\" has no impact. Open source and development does have a large impact, it is just mostly on your ability to trust the auditing&#x2F;security process as a random third-party, not the security itself. The security itself demands focused technical ability. However, the ability to trust the security claims derives from a technical evaluation by a technically competent, trusted party. The easiest way to do that if you are technically competent is to do it yourself. However, few people have that sort of time, so you farm out the work. If you are a big company or the government, you can usually get access to the source code under appropriate contractual protection, then you have your own technical staff (technically competent, trusted party) do the evaluation. If you are a smaller company, you might not have any technical staff appropriate for the task so you farm it out to a testing body (technically competent) who can probably be trusted since you are paying them.However, if you are just some random person, you do not have the money to pay for a evaluation and you have no way of knowing if \"Totally Not the NSA Certification Company\" can be trusted. So, your best bet is inherent transparency and hoping that the unaffiliated lookers are, on average, not your enemy and technically competent. This is a okay option if you do not have access to better choices, and certainly better than nothing, but is a far cry from the other options where you have real control, incentive alignment, and insight into auditing processes. Only a organization incompetent at security would not use one of the better options for critical dependencys. Unfortunately, basically every large commercial IT organization, such as Google, Microsoft, Apple, Amazon, Crowdstrike, etc. is incompetent at security and none of them actually evaluate their dependencies or do any meaningful third-party certifications.Funnily enough, this means my advice is practically useless, because the security of everybody is completely untrustworthy. Your only hope is \"many eyes\" because that is the only way to get any trustable audit at all. In the physical industries you have standards and certification bodies worth more than the paper they are written on, but in software everything in security is total snake oil and you should only believe what you can see for yourself. Hope that helps. reply pcurve 18 hours agoprevFireship did a 2:40 minute video on this a few hours ago.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=mVKAyw0xqxwShort and informative :-) reply MR4D 18 hours agoparentJust watched it. Thanks for the recommendation. 100K views in 3 hours - not too shabby! reply pcurve 17 hours agorootparentnp! I love his humor. My favorite is \"10 programmer stereotypes\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=_k-F-MMvQV4 reply l0new0lf-G 16 hours agoprevI know it sounds weird, but unless you reviewed the source code AND built the binary from it, no open source software is to be trusted.The versions ready for download may be based on code slightly different than the one in the repo -either deliberetely, or because the NSA managed to redirect the download link to its&#x27; servers.There is always a probability that an anonymity product will be proved to be a honeypot. Even open source projects may either do as mentioned (provide a \"hacked\" version for downloading), or even include some code that downloads and runs a seemingly harmless module from an external source, that is not so harmless in reality.If the CIA gives enough money to the core developers or even just the website owner, what do they have to lose? Their reputation? Not everyone cares about that.I know these scenarios sound far-fetched and paranoid, but nothing should sound impossible after Snowden&#x27;s revelations. Even for open source software. reply MetaWhirledPeas 12 hours agoparent> I know it sounds weird, but unless you reviewed the source code AND built the binary from it, no open source software is to be trusted.That&#x27;s probably true, but if you want to be really paranoid you&#x27;d also want to be sure to compile it with a machine, operating system, and compiler that they are unlikely to have tampered with. Maybe something really old or esoteric or both? reply brightlancer 11 hours agoparentprev> I know it sounds weird, but unless you reviewed the source code AND built the binary from it, no open source software is to be trusted.Why specify \"open source software\"? Is it not true of ALL software?\"Unless you reviewed the source code AND built the binary from it, no software is to be trusted.\"That seems to be more accurate. Am I missing something? reply sneak 19 hours agoprevhttps:&#x2F;&#x2F;www.theregister.com&#x2F;2014&#x2F;07&#x2F;03&#x2F;nsa_xkeyscore_stasi_s...https:&#x2F;&#x2F;daserste.ndr.de&#x2F;panorama&#x2F;xkeyscorerules100.txt reply chimbosonic 18 hours agoprevTails is one of those tools I always keep on me physically. Added it to my key ring 6 years ago , and I get use out of it at least twice a month. Also started using it as a recovery ISO. But my main use case is when I have to use a computer but don’t have mine around . Just pop the USB in and voila all the access I need and my data stored in the persistent partition. reply mr_mitm 17 hours agoparentYour use-case sounds like you could be using any other live distribution. Why did you choose Tails over Knoppix, Mint, Ubuntu, Fedora, ... ? reply chimbosonic 18 hours agoparentprevI also spent most of my internship long ago researching secure operating systems for the analysts of the company I worked for and Tails was the best fit with Qubes being second due to how power hungry it is. Another was subgraph but at the time it wasn’t properly developed. Overall if you need a OS that guarantees that all your traffic is anonymised via Tor and that it is ephemeral Tails is superb. reply ShroudedNight 19 hours agoprevIt seems like a growing number of things once referred to as Linux distributions are now referring to themselves as operating systems. If the kernel is Linux, and the user-space is GNU, what makes this a distinct operating system from, say, SUSE, or Arch? reply stephen_g 19 hours agoparentThe userspace is so diluted now that it’s basically flat out wrong to say it’s just ‘GNU’, I mean Systemd is probably an even bigger a part than GNU is now, and we’ve long had things like OpenSSH from BSD as pretty core parts of the system, and we’re not going to start calling a distribution ‘Kubuntu Linux&#x2F;Systemd&#x2F;GNU&#x2F;BSD&#x2F;KDE’ or whatever…Basically about all something needs to be to be called an OS is a kernel and at least one userspace program that does something useful, so I’d definitely say every ‘Linux distribution’ has always counted as an operating system in itself (so ‘Linux distribution’ is just a specific subset of ‘operating systems’). reply WhyNotHugo 18 hours agorootparentI like to thing of GNU&#x2F;Linux as Linux with glibc. There’s software that only runs with glibc (eg: steam), and software that runs with various libc (eg: Firefox).I’m not sure that it’s a widely accepted definition, but it’s often useful to describe what a software depends on. Does it require _just_ Linux, or does it also require glibc? reply WhyNotHugo 18 hours agoparentprevA distribution focuses on the distribution part (eg: a package manager, repositories, etc).Some distributions are operating systems (eg: OpenBSD, ArchLinux, Debian). Some operating systems are not distributions (they don’t include a mechanism to pull packages. Eg: windows, macOS). Some distributions are not operating systems (eg: homebrew, Flatpak).Tails focuses on the operating system side of things. It’s focus isn’t on package distribution and letting you install things, but on downloading a usable OS image. It’s still a distribution, but that’s more of a technicality. reply npteljes 16 hours agoparentprevI&#x27;d say the reason for that is marketing, or branding, or positioning the product, which are, as you wrote, essentially Linux distributions.I find that even combinations that are supposed to be very similar (Linux kernel, same DE, same repos) can behave differently, and I guess this is because of how the distro maintainers set up the different parts and integrations in the system. So in this way, my MX Linux box is different from my Debian+KDE box. reply IE6 19 hours agoparentprevYou could make the argument that this is more of a GNU + Linux than an operating system unto itself. reply sleepybrett 19 hours agoprevThe fact that it still does not support an incredibly popular portable computer like the raspberry pi (or anything that ins&#x27;t intel) saddens me. reply hedora 16 hours agoparentI&#x27;d guess it is a matter of priorities (do you want the safest, best-tested environment, or something less tested?).However, assuming the source is easily bootstrappable, someone should try producing an unofficial port to Arm and Risc V. I&#x27;m sure it would reveal some security holes, even if it isn&#x27;t appropriate (yet) for tails&#x27; target audience. reply ipnon 18 hours agoparentprevI agree, and you have to make the PRs you want to see. I don’t think this project of free software has a big (or perhaps any) budget! reply tredre3 17 hours agorootparentI&#x27;m so tired of seeing this argument. Most \"big\" open-source projects are well funded. Usually the reason they don&#x27;t support > is poor leadership, not funding.Over the past two years Tails has received 500k USD in bitcoin alone:https:&#x2F;&#x2F;www.blockchain.com&#x2F;explorer&#x2F;addresses&#x2F;btc&#x2F;bc1qjg53lw...You can also surmise that they receive ~200k&#x2F;yr from official sponsors:https:&#x2F;&#x2F;tails.net&#x2F;sponsors&#x2F;index.en.htmlThen you have all the paypal, bank, cash donations.Is it enough to add support for a second arch that is fully supported upstream (they ship a customized Debian)? You decide. reply sillysaurusx 17 hours agorootparentThat’s a lot of donations. reply techlatest_net 17 hours agoprevFor those interested, we provide out of box setup of Tails on Google cloud for a quick setup. [1]https:&#x2F;&#x2F;console.cloud.google.com&#x2F;marketplace&#x2F;product&#x2F;techlat... reply great_psy 15 hours agoprevHow does Tails(or Qubes, or etc) provide security in a real use case full time OS system?Say I log into Facebook, obviously I expect my identity to be exposed to Facebook, but do any of those OS have the ability to keep me private after I logged into some website ? reply palata 6 hours agoparentThere are different things, for instance:- QubesOS provides security by isolating components. So if your browser VM is compromised, your password manager VM is not. That does not make you anonymous at all.- I don&#x27;t know Tails, but I think that it is just not persistent. Which means that when you reboot, you know that there are no traces of your previous session (as opposed to a \"normal\" system that would keep cookies, for instance). Which may help you not being tracked. That does not necessarily make you anonymous: you may leak your IP. I would guess that another thing is that if you get some malware in your Tails session and reboot, then the malware is supposedly gone (could it infect the hardware, e.g. a USB webcam? Not sure).There is no \"one\" security, it depends a lot on what you need (i.e. your thread model), and many tools provide many different features. reply jordanpg 19 hours agoprevWould be curious to hear criticisms of Tails, if anyone has opinions about it.To be clear, I&#x27;m a fan of the product -- just wondering what the other side of the story is. reply letmevoteplease 18 hours agoparentAll known law enforcement attacks against Tor have involved some kind of exploit (e.g., in Tor Browser) that creates a non-Tor connection to collect the user&#x27;s IP. Tails does not protect against this. Whonix provides much stronger protection against practical, real-world attacks, since the entire operating system is forced through a Tor connection. reply stephen_g 18 hours agorootparentIt’s probably important to note that as I understand it, these attacks have generally been Firefox zero-day exploits that have made its way in because the Tor Browser is based on Firefox ESR with patches. reply arboles 18 hours agorootparentDarknet sites should be on something with a much smaller attack surface like the pages from the Gopher or Gemini protocols. reply paravirtualized 16 hours agorootparentprevI left a comment in this thread of a non-root deanonymizing, Tails specific exploit that bizarrely went unpatched for multiple years. reply yieldcrv 18 hours agorootparentprevTails has the entire OS as Tor connections only, an escape from the Tor browser would still be stuck in a Tor only OS.What information do you have to the contrary? reply letmevoteplease 17 hours agorootparentTails includes an \"Unsafe Browser\" which connects in the clear. So on top of a Firefox exploit, you would need another exploit to launch that browser or an exploit to escalate to root and tamper with the firewall rules. At least one Tails user has been successfully targeted like this (\"an exploit taking advantage of a flaw in Tails’ video player to reveal the real IP address of the person viewing the video\").[1] With Whonix, even an attacker with root would not be able to make a non-Tor connection because the firewall runs on a separate virtual machine.[1] https:&#x2F;&#x2F;www.vice.com&#x2F;en&#x2F;article&#x2F;v7gd9b&#x2F;facebook-helped-fbi-h... reply yieldcrv 16 hours agorootparentwow! that story is wild I totally missed that during the pandemic. now I&#x27;m no longer annoyed at always having to update tails the few times I boot it up.but yeah probably going to prioritize Qubes and whonix again. reply vorticalbox 17 hours agorootparentprevI mean yes and no.Assuming there was an exploit that broke out of the Firefox sand box you are correct that any connection is via tor.Though tails isn&#x27;t 100% sure, you could chain a Firefox cve + user land to root and then turn off the to routing rules. reply yieldcrv 17 hours agorootparentadministrator&#x2F;root is turned off by default, and even if the user turned it on during boot, they would still have to be tricked into approving or putting in their password again, am I missing something about the veracity of possible exploits? reply vorticalbox 16 hours agorootparentThere are some exploits that allow for gaining root access.One that comes to mind is dirty sock[0]. It uses a vulnerability in the snap api to create a root user.https:&#x2F;&#x2F;github.com&#x2F;initstring&#x2F;dirty_sock&#x2F;blob&#x2F;master&#x2F;dirty_s... replygpcz 19 hours agoparentprevThere may be a security advantage to using a separate non-bypassable network appliance that puts your traffic on Tor, since then it would be much harder to break into a Tails machine and make it leak your location. However, given that it&#x27;s meant to be easy to use, I think they probably picked the right balance by having the Tor redirecting occur in the same address space as the computing environment. reply paravirtualized 16 hours agoparentprevTails didn&#x27;t patch a non-root exploit that could leak the users real IP by bypassing the firewall without them knowing it for 3 years. I do not understand why Tails is recommended over Whonix (specifically Qubes-Whonix, thus with a trusted TCB).> The Unsafe Browser allows to retrieve the public IP address by a compromised amnesia user with no user interactionhttps:&#x2F;&#x2F;gitlab.tails.boum.org&#x2F;tails&#x2F;tails&#x2F;-&#x2F;issues&#x2F;15635 reply cf100clunk 19 hours agoparentprevThe &#x27;&#x27;Heads&#x27;&#x27; distro was meant to address some of the criticisms of Tails. Sadly its development seemed to end in 2018:https:&#x2F;&#x2F;heads.dyne.org&#x2F;about.htmlhttps:&#x2F;&#x2F;distrowatch.com&#x2F;table.php?distribution=heads reply oneepic 17 hours agoparentprevI&#x27;m wary about even Googling it because I swear I heard you are tracked in the US for even Googling it, or downloading it, or even reading on Wikipedia. It sounds laughable when I type it to be honest, but hey. I feel I have better hills to die on. reply tonymet 18 hours agoprevI’d like to highlight the update process . I had a 2-3 year old installation and updated using the in-app updater. Update was a breeze and persistent storage was saved.I recently had to dust off tails to do some dark web research on a data breach.It’s a great “prophylactic” to protect your assets from possible malware while doing research. reply b8 16 hours agoprevThe Airforce Research Laboratory created a Tails like OS called TENS [0].0. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Lightweight_Portable_Security reply Jigsy 18 hours agoprevI&#x27;ve heard bad things about Tails over the last few years.What with the UK planning to pass that online safety bill, I decided to try out Whonix (which involved learning curves when it came to Linux), which I think is a better way of keeping safe online. reply NetOpWibby 18 hours agoparent> I&#x27;ve heard bad things about Tails over the last few years.Like what? reply Jigsy 18 hours agorootparentAs one of the comments mentioned below, easy for someone to get your IP with an attack on the Tor browser. (Which was actually utilized by law enforcement to catch somebody iirc.)Anecdotal evidence, but I&#x27;ve heard numerous complaints from other users about telemetry settings being enabled in the browser and locked.But worst of all, it uses GNOME. reply crtasm 17 hours agorootparentYou may be thinking of the case where a video file was specially crafted to cause the media player on Tails to make a direct connection?https:&#x2F;&#x2F;www.schneier.com&#x2F;blog&#x2F;archives&#x2F;2020&#x2F;06&#x2F;facebook_help... reply Jigsy 16 hours agorootparentI believe that is what I was thinking of. replyWhereIsTheTruth 17 hours agoprevTor servers were breached by the CIA&#x2F;NSA, I would be careful reply xyst 16 hours agoparentBy breaches you mean these agencies own a ton of exit nodes? reply paravirtualized 16 hours agoparentprevDo you suggest that we trust our ISP instead, and pretend that they aren&#x27;t compromised by default? reply trts 16 hours agoparentprevwhat&#x27;s the alternative to Tor? reply paravirtualized 16 hours agorootparentThere are no real \"alternatives\"; but see I2P, Lokinet and Freenet for some other options. reply xyst 16 hours agorootparentprevPhysical world. Lol reply 0cVlTeIATBs 15 hours agorootparentMore specifically, couriers to hand deliver your messages, like Al Qaeda had. reply londons_explore 17 hours agoprevIf I were wanting do do secure tor browsing, I would use a liveUSB of ubuntu, running virtualbox, running vmware, running tor. On the host ubuntu, I would run a 2nd instance of virtualbox, running vmware, running Chrome.Networking will be set up so the Chrome inner VM can ssh to the tor VM. The tor VM can access only some whitelisted tor nodes.Now an adversary that uses a Chrome exploit needs to break out of Windows and 2 layers of VM&#x27;s before they get to my host. Breaking out of a VM is fairly doable, but breaking out of two will require lots of zero-days chained together (expensive).Same if they find an exploit in tor. reply crimmin 17 hours agoparentIt&#x27;s a bit more secure if you use a proper write once DVD as well to read the live cd. It&#x27;s a bit slower to boot but the best way to prevent persistence is always to make it virtually physically impossible by not having any physical storage mediums connected reply londons_explore 17 hours agorootparentI think the main concern of most tor-users is that their real IP address (and hence location) is leaked.For that, just a run-of-the-mill firefox exploit is all that is needed, and suddenly exploit code can do a wifi scan and get a very precise location. reply nonameiguess 15 hours agorootparentHonestly, if this is a serious concern and you&#x27;re already willing to go to all the other trouble, you may as well do your most sensitive Internet browsing from your car, connecting only to public WiFi in parking lots, in cities you don&#x27;t actually live in, and never stay connected for more than a few hours at at time. Or take a hint from history&#x27;s most secure criminals and don&#x27;t do any of this yourself at all. Use paid underlings who fear you more than they fear prison and are willing to do time rather than rat you out. reply Syonyk 17 hours agoparentprevYou&#x27;ve just independently developed something almost identical to the Whonix system. :) May as well use the pre-built VMs that do it for you. reply londons_explore 17 hours agorootparentPre built VM&#x27;s mean an adversary probably has pre-built exploits... reply ra0x3 18 hours agoprevDoes anyone if&#x2F;when Tails will support Apple Silicon? reply SushiHippie 17 hours agoparenthttps:&#x2F;&#x2F;gitlab.tails.boum.org&#x2F;tails&#x2F;tails&#x2F;-&#x2F;issues&#x2F;10972This is the discussion regarding support for ARM, it&#x27;s currently not supported. reply BJxdr 18 hours agoprevI wish Tails ditched Gnome.. reply osigurdson 17 hours agoprevSounds like its users have something to hide (sarcasm). reply criddell 18 hours agoprevHow does Tails help you avoid censorship? reply diydsp 18 hours agoparentLegit question. IIUC: On the publishing side, it allows people to say things with less fear of bad guys knowing who said them. On the audience side, it allows people to consume media with less fear of bad guys knowing they read it. Unfortunately, I don&#x27;t believe it can ameliorate what most people think of as the censorship part, which is a guy with a black magic marker crossing out parts of things. reply criddell 17 hours agorootparent> it allows people to say things with less fear of bad guys knowing who said themI see what you are saying, but AFAIK, the technology is neutral as far as good or bad goes. One could say it lets a person say and do things with less fear of consequences in general. reply fluidcruft 18 hours agoparentprevIt&#x27;s a Tor client. Bypassing censorship is one of Tor&#x27;s design goals. reply criddell 14 hours agorootparentIs there anything Tails does to actively bypass censorship, or is it simply a result of the increased anonymity?To me, it seems like it can only have limited utility in this regard. For example, Tails (and Tor) isn&#x27;t going to help you avoid private sector censorship on services like X or Facebook or YouTube, right? It won&#x27;t help you get a book published or reach an audience with a video. reply fluidcruft 12 hours agorootparentI&#x27;m not really sure what you understand the word \"bypass\" to mean here?Tor&#x2F;Tails can certainly help someone who is experiencing censorship to publish a book or distribute a video in a different region where that censorship does not exist. That bypasses the censorship. For example someone experiencing censorship could contact a publisher or distributor in a different location and transmit the book or video to them.If censorship exists on Twitter, publishing items to Twitter isn&#x27;t bypassing Twitter&#x27;s censorship. You may be bypassing automated censorship or some mechanism but Twitter would still be censored.The same goes for books. There&#x27;s no tool that is going to keep a book on the shelves of a library that wants to burn the book. Bypassing the library&#x27;s censorship means getting the book to readers despite the library&#x27;s censorship. reply charcircuit 18 hours agorootparentprevIf you get canceled and ISPs refuse to give you service Tor is not able to somehow bypass that censorship. If the server your hidden service is hosted on is taken away in a raid. Tor doesn&#x27;t help you there.Providing limited protection from being deanonymized doesn&#x27;t mean that you can no longer be censored. reply lapinot 17 hours agorootparentObviously! Assassination or imprisonment could also be considered censorship and tor or tails won&#x27;t help. There are always edge cases. They are pretty explicit about their threat model and go into great lengths explaining it.https:&#x2F;&#x2F;tails.net&#x2F;doc&#x2F;about&#x2F;warnings&#x2F;index.en.html reply anthk 16 hours agoprevThe best code is the one not being run.- Set unbound with DNS over HTTP.- Use Links+ with Tor&#x2F;i2pd and enforcing all the connections to the proxy in the settings. Avoid the web for news sites and use Gemini with offpunk and gemini:&#x2F;&#x2F;gemi.dev for news sources Bookmark the news sites and sync. Then, reading the news offline it&#x27;s easy. Offpunk has a command for that, &#x27;offline&#x27;, and then run &#x27;list&#x27;, it will show up your cached bookmarks.- Use nncpgo and sneakernet (or any inet protocol on top) to share data between the machines you own.- News are better being fetched and read online with sfeed and lynx. Ditto with email with mbsync&#x2F;msmtp + Mutt. Also, Gopher and Gemini, to read all the nice sites offline. Fetch your news&#x2F;posts offline and forget.- Use keyboard locked (u)xterms with TMUX. Nsxiv and mpv for images&#x2F;videos. Better if you run them under the framebuffer.- Convert all the PDF&#x27;s you have to DJVU with the highest settings, then use gzip or xz on it, with DJView as the viewer. The less code you run, the better.- Avoid Brave, Chromium, or worse, Edge. reply toasted-subs 17 hours agoprevI like wearing my chainmail. Even if that means having to deal with some judgement. reply yieldcrv 18 hours agoprevwhere is darknet opsec and the current state of things discussed?I used to use Dread and various DNM forums to find people to talk with and read their threads. It was usually far more complex and nuanced than what I would find on clearnetbut its been like 2-3 years since any Tor services even worked reliably with this ongoing DDOS attack.dark.fail has been down tooI hear people moved to i2p but WHERE? reply shmde 18 hours agoprevTails OS is my daily driver for absolutely normal day usage and do legal stuff. (No tomfoolery involved) reply justin_oaks 18 hours agoparentI&#x27;m interested in why you chose this.What are the main benefits you get from using Tails OS?What downsides do you tolerate because of the benefits? reply yjftsjthsd-h 18 hours agorootparentIt would have to be pretty good at avoiding the usual privacy problems on the modern internet, right? reply mr_mitm 17 hours agoparentprevDoes it not become cumbersome to use the web for normal usage without persistent cookies, history, bookmarks, ...? If you save those to persistent storage (if that&#x27;s even possible, I imagine Tails has safeguards against shooting yourself in the foot), you lose one of the main reasons why people use Tails. reply paulpauper 16 hours agoprevjust be careful that is does not crash when using internet enabled mode. very common problem with tails given how much memory websites use . tails only has limited ram from the portable drive. reply mark_l_watson 17 hours agoprevI love the idea of Tails. It is unfortunate that it only runs on Intel macOS.I consider my personal setup to be pretty good, but not Tails grade privacy: 1. Avoid installing apps, use Safari with all possible privacy settings. 2. Run Lockdown mode iOS, iPadOS, and macOS. 3. Use duck duck go and ProtonMail. 4. Prefer to run in Safari private browsing tabs. 5. Become non-private when logging into Amazon to make a purchase, etc.I would love it if people more knowledgeable than I could critique my setup, make suggestions. Thanks in advance.I would like to mention Cory Doctorow’s excellent new book The Internet Con [1]. It carries on in the fine tradition of the books Surveillance Capitalism and Privacy is Power for the narrative that regular law abiding people also benefit from doubling down on privacy.[1] https:&#x2F;&#x2F;craphound.com&#x2F;internetcon&#x2F; reply throwitaway156 16 hours agoparentBeing blunt: your setup doesnt protect you from Apple. Websites will and does recognize you on every visit, both those done in private tabs and the usual ones. DDG and ProtonMail i cant comment on, but they are one of the better choices for the less tech-savvy&#x2F;i-want-to-spend-my-free-time-having-fun. You have a pretty nice setup in terms of security, however.If you want better protection for websites identifying you, you should consider researching on browser fingerprinting (which is extremely hard, if not impossible to do on Safari). If you want better protection overall, ditch Apple. reply mark_l_watson 15 hours agorootparentThanks, useful comment. reply mrb 17 hours agoparentprev\"It is unfortunate that it only runs on Intel macOS.\"Tails runs on most computers. It doesn&#x27;t have to be a \"macOS\" (you mean Apple?). macOS is an OS, tails replaces the OS. reply mark_l_watson 15 hours agorootparentI misspoke. I know that it works on any Intel computer that you can plug a USB flash drive into. reply boxed 17 hours agorootparentprevIt doesn&#x27;t run on ARM macs. Which is all new macs. reply mrb 17 hours agorootparentSure, but that&#x27;s not what parent said. He said it only runs on \"intel macOS\", which is false. It works on non-Apple computers as well.But I understand the miscommunication, parent meant to say \"of the Apple computers, it only runs on Intel ones\". There is a world outside of Apple, you know :-) reply boxed 15 hours agorootparentIt&#x27;s an emphasis thing. You can&#x27;t tell in text where the emphasis is. In this case it was super clear that it was \"intel macOS\", but yea, it should have been \"intel macs\". reply brightlancer 10 hours agorootparentThe conflation of \"MacOS\" with \"Apple computer\" is a problem that should be addressed.Tails works on Intel arch. It does not work on ARM arch.This has nothing to do with an Apple branded computer. replydwheeler 17 hours agoparentprevTails works fine on IBM-PC compatible laptops and desktops with Intel compatible chips, which is nearly all laptops. I presume you meant that Tails doesn&#x27;t run on ARM Macs?If you only have an ARM Mac, it&#x27;s easy to get an old IBM-compatible laptop and run Tails. What matters is a decent speed of USB stick, and today they&#x27;re generally decent. I find it helpful for testing some things, I can reboot and get to a known state. reply danielvaughn 19 hours agoprev [–] Is it new or something? This is the second time I&#x27;ve heard about it in 24 hours, and had never heard of it before. reply e_i_pi_2 19 hours agoparentIt&#x27;s been around for a while, but interesting to see this and a Fireship video on it the same day. I was wondering if they did some new release or something but doesn&#x27;t seem like it reply cuuupid 19 hours agoparentprevWas pretty popular circa 2012 for dissidents in some countries reply arbeiterz 19 hours agoparentprev [–] No, not new. If I recall correctly, Snowden approved of it back in roughly 2017(?) reply crtasm 19 hours agorootparent [–] Initial release 2009https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Tails_(operating_system) replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Tails is a portable operating system designed to safeguard against surveillance and censorship, utilizing the Tor network for online privacy and resistance to censorship.",
      "Designed to be installed on a USB stick, Tails provides a secure computing environment on any machine, equipped with applications for handling sensitive documents and secure communication.",
      "Tails, endorsed by Edward Snowden and funded by internet freedom organizations, is based on Debian GNU/Linux. It's freely available and often leveraged by journalists, activists, domestic violence survivors, and others requiring additional privacy."
    ],
    "commentSummary": [
      "The discussion focuses on Tails, a privacy-focused Operating System (OS) developed to guard against surveillance and censorship, with features like blocking traces of prior sessions and defending against malware.",
      "The conversation also points out certain limitations of the Tails OS, including the risk of IP address leakage, with alternatives like Whonix, Heads, and TENS being mentioned as secure browsing options.",
      "Other topics within the dialogue include the history and growth of the internet, the reliability of open-source software, and the financing of open-source initiatives."
    ],
    "points": 384,
    "commentCount": 170,
    "retryCount": 0,
    "time": 1694701994
  },
  {
    "id": 37515996,
    "title": "iNaturalist strikes out on its own",
    "originLink": "https://baynature.org/2023/09/12/inaturalist-strikes-out-on-its-own/",
    "originBody": "Close Search Search for: Bay Nature Understand everything better. Sign up to receive Bay Nature’s weekly newsletter! DONATE SUBSCRIBE Science & Nature Conservation Exploration Events BN Talks Local Heroes Search My Account 0 items Biodiversity iNaturalist Strikes Out on Its Own A new $10 million grant is helping the new nonprofit. by Lia Keener September 12, 2023 SHARE THIS: This summer, iNaturalist, the global social network for recording and collectively identifying the biodiversity around us, went independent. With the help of a $10 million startup grant, the organization that started as a UC Berkeley master’s project separated from the California Academy of Sciences and National Geographic Society and became its own 501(c)(3) nonprofit organization. “This is a necessary step in order for us to really reach our potential,” says Scott Loarie, co-director of iNaturalist. “We’re so grateful for them to give a home for the last nine years and help us through this process of finding our feet as an independent organization.” iNaturalist is both a social network and “the world’s most powerful biodiversity data set,” according to Alison Young, iNaturalist board member and co-director of California Academy of Sciences’s Center for Biodiversity and Community Science. It’s an online platform—as Bay Nature has written—where a backyard bee spotted by a four-year-old was identified by a bee expert living thousands of miles away; a place where two teenagers identified two new scorpion species. Its users have pitched headfirst into the world of plant galls, and tracked the impacts of the harmful algal blooms that took over San Francisco Bay in 2022 and 2023. And it is a place where people can find new friends, as Young has, among those who are interested in the same parts of the outside world. Teenagers Prakrit Jain and Harper Forbes described two new scorpion species (including the above Paruroctonus soda) after spotting two unidentified iNaturalist observations. Here and here are links to the iNaturalist observations that led to the new classifications. (Photo by Prakrit Jain) Bay Nature’s email newsletter delivers local nature stories, hikes, and events to your inbox each week. Sign up today! Data from iNaturalist have been used in more than 4,000 research publications, and users have identified new species through browsing its observations. “We have a better understanding of current biodiversity than we have ever had because of iNaturalist—hands down,” says Young. In total, more than 2.8 million observers have uploaded more than 150 million verifiable observations to iNaturalist, and in July, an average of 124 observations were uploaded per minute. Every month, around 350,000 people record observations. But Loarie recalls a time when he considered 50 regular iNaturalist users a triumph. Like any critter on its site, iNaturalist has gone through a number of life stages. In 2008, iNaturalist was born through its cofounder Ken-Ichi Ueda and fellow master’s students Nate Agrin and Jessica Kline’s joint final project. After Loarie joined in 2011, it grew into a limited liability company, and three years later, iNaturalist’s staff and office moved to the California Academy of Sciences as the two organizations joined forces. In 2017, the National Geographic Society came in as a partner, and iNaturalist became a joint initiative of these two nonprofits, funded by a combination of grants and small individual donations. iNaturalist current staff. Back row, left to right: Sylvain Morin, Patrick Leary, Tony Iwane, Scott Loarie, Yaron Budowski, Abhas Misraraj. Front row, left to right: Alex Shepard, Angie Ta, Amanda Bullington, Carrie Seltzer, Johannes Klein, and Ken-ichi Ueda. (Photo courtesy of iNaturalist) As the platform has grown in size and impact, its need for a more stable financial future has intensified. “It was making me personally feel a little uneasy that it felt so unstable as a project, not really knowing a couple months out what was going to happen,” says Loarie. Shifting toward independence allows iNaturalist to plan for longer-term goals. “I think iNaturalist has just barely, barely scratched the surface” of what it can do, Loarie says. On May 11, 2014, this New Zealand pigeon marked the 1 millionth observation uploaded to iNaturalist. Now, iNaturalist has more than 157 million uploaded observations. (Photo by Jon Sullivan, CC-BY) The Gordon and Betty Moore Foundation, a longtime iNaturalist donor with a $9.5 billion endowment, gave the newly independent iNaturalist a $10 million grant to help it achieve liftoff. Long term, iNaturalist aims to sustain itself through grants and individual donations. “Powered by the participation of its growing user community, iNaturalist has demonstrated its promise for connecting people to nature in ways that drive scientific and conservation insights on both local and global scales,” Janet Coffey of the Gordon and Betty Moore Foundation said in a statement. “We are delighted to support this stage of the organization’s growth.” As it takes this next step, Loarie reassures iNat users that the move toward independence isn’t a pivot. Its mission has stayed the same, as has its user interface. The platform’s leaders intend to double down on its goals to connect people with nature and produce good-quality ecological data. In particular, iNaturalist is interested in expanding its use in regions where biodiversity is high but access to iNaturalist is limited, such as parts of South America and Asia. iNaturalist is also interested in expanding its use of artificial intelligence, which the platform already uses to suggest identifications for observations based on image matching and geographic data. Its AI can currently identify 77,000 species, and it adds 1,000 to 2,000 new species each month. Already a pioneer in the use of AI for community-based science, iNaturalist hopes to use AI to guide predictions on species distributions, perhaps helping researchers and conservationists predict trends for invasive or threatened species. Managing the ever-growing iNaturalist presents unique challenges. Maintaining a safe and respectful social environment and avoiding online toxicity as the platform grows is a primary concern. And the platform’s leaders want to continue generating good-quality, scientifically useful data while keeping iNaturalist accessible for all. Moving forward, iNaturalist looks forward to collaborating with both of its former partner organizations. Many ongoing collaborations with Cal Academy—including the annual City Nature Challenge (the event that brings the most new users to iNaturalist each year), Snapshot Cal Coast (which we wrote about here), and California Biodiversity Day—are already in place, and plans for new projects are in the works. Though iNaturalist is now independent, it remains an inherently collaborative organization, built upon the efforts of millions of people observing the natural world. “What everybody wants is for them to fledge and become the best version of iNaturalist that they can be,” Young says. First seen on iNat Here are six of the more than 5,000 species whose first known photographs of live individuals were observations uploaded to iNaturalist. Rabbs’ Fringe-limbed Treefrog, by ramon_d via iNaturalist (CC-BY-NC). Taken in Panama. Eurhinus cupripes, by Gabriela Flor via iNaturalist (CC-BY-NC) Taken in Cuernavaca, Morelos, Mexico. Lindbergia pseudoillyrica, by Kaloust Paragamian via iNaturalist (CC-BY-NC). Taken in Rethymnon, Crete, Greece. Cloudy Andean Frog, by acatenazzi via iNaturalist (CC-BY-NC), Taken in Cusco, Peru. Cosmophasis ambonensis, Tiziano Hurni-Cranston via iNaturalist (CC-BY-NC). Taken in Maluku, Indonesia. Grey-cheeked Flying Squirrel, by jgrogers via iNaturalist (CC-BY-NC). Taken in Pandeglang, Indonesia. About the Author Lia Keener Lia Keener joined Bay Nature as an editorial assistant in June 2022. She graduated from UC Berkeley last year with a major in environmental biology and minors in journalism and Chinese language. She loved writing profiles of two of this year’s Bay Nature Local Heroes, and she is excited to continue learning about Bay Area nature and the people generating a more sustainable, equitable future. SHARE THIS: Every story from Bay Nature magazine is the product of a team dedicated to connecting our readers to the world around them and increasing environmental literacy. Please help us keep this unique regional magazine thriving, and support the ecosystem we’ve built around it, by subscribing today—you’ll get Bay Nature four times a year in your mailbox! SUBSCRIBE READ THIS NEXT How Your Beach Photos Are Helping CA Scientists: Snapshot Cal Coast 2022 August 11, 2022BAYNATURE.ORG An Update to the App to Identify (Almost) Anything (Almost) Anywhere June 24, 2019BAYNATURE.ORG Connect With Nature from Your Home March 18, 2020BAYNATURE.ORG Time Traveling With Clam Fossils June 22, 2023BAYNATURE.ORG Bay Nature connects the people of the San Francisco Bay Area to our natural world and motivates people to solve problems with nature in mind. Header illustrations by Jane Kim, InkDwell DONATE Bay Nature Institute 1328 6th St., #2 Berkeley, CA 94710 (510) 528-8550 Tax ID: 76-0744881 Magazine Archive Special Section Archive Bay Nature Talks About Staff and Board Pitch Us Stories, Photos or Art Advertise Submit an Event My Account Store Employment Opportunities SUBSCRIBE / RENEW Subscription Customer Service: 888-4-BAYNAT (888-422-9628) Monday – Thursday 5:30am – 2:30 pm PT Friday 5:30 am – 2 pm PT service@baynature.org SIGN UP FOR EMAIL Bay Nature’s email newsletter delivers local nature stories, hikes, and events to your inbox each week. Sign up today: SIGN UP! Bay Nature is a member of the INN Network. Crafted by Cornershop Creative",
    "commentLink": "https://news.ycombinator.com/item?id=37515996",
    "commentBody": "iNaturalist strikes out on its ownHacker NewspastloginiNaturalist strikes out on its own (baynature.org) 339 points by kscottz 11 hours ago| hidepastfavorite60 comments qz_kb 10 hours agoHow the hell does the Seek by iNaturalist app work so well and also be small&#x2F;performant enough to the job completely offline on a phone? You should really try it out for IDing animals and plants if you haven&#x27;t, it&#x27;s like a real life pokedex. Have they released any information (e.g. a whitepaper?) about how the model works or how it was trained? The ability to classify things incrementally and phylogenetically makes it helpful to narrow down your own search even when it doesn&#x27;t know the exact species. I&#x27;ve been surprised by it even IDing the insects that made specific galls on random leaves or plants. reply fogleman 9 hours agoparentI reverse engineered their stuff a bit. I downloaded their Android APK and found a tensorflow lite model inside. I found that it accepts 299x299px RGB input and spits out probabilities&#x2F;scores for about 25,000 species. The phylogenetic ranking is performed separately (outside of the model) based on thresholds (if it isn&#x27;t confident enough about any species, it seems to only provide genus, family, etc.) They just have a CSV file that defines the taxonomic ranks of each species.I use it to automatically tag pictures that I take. I took up bird photography a few years ago and it&#x27;s become a very serious hobby. I just run my Python script (which wraps their TF model) and it extracts JPG thumbnails from my RAW photos, automatically crops them based on EXIF data (regarding the focus point and the focus distance) and then feeds it into the model. This cropping was critical - I can&#x27;t just throw the model a downsampled 45 megapixel image straight from the camera, usually the subject is too small in the frame. I store the results in a sqlite database. So now I can quickly pull up all photos of a given species, and even sort them by other EXIF values like focus distance. I pipe the results of arbitrary sqlite queries into my own custom RAW photo viewer and I can quickly browse the photos. (e.g. \"Show me all Green Heron photos sorted by focus distance.\") The species identification results aren&#x27;t perfect, but they are very good. And I store the score in sql too, so I can know how confident the model was.One cool thing was that it revealed that I had photographed a Blackpoll Warbler in 2020 when I was a new and budding birder. I didn&#x27;t think I had ever seen one. But I saw it listed in the program results, and was able to confirm by revisiting the photo.I don&#x27;t know if they&#x27;ve changed anything recently. Judging by some of their code on GitHub, it looked like they were also working on considering location when determining species, but the model I found doesn&#x27;t seem to do that.I can&#x27;t tell you anything about how the model was actually trained, but this information may still be useful in understanding how the app operates.Of course, I haven&#x27;t published any of this code because the model isn&#x27;t my own work. reply murphyslab 3 hours agorootparentI don&#x27;t use Seek, but the iNaturalist website filters computer vision matches using a \"Seen Nearby\" feature:> The “Seen Nearby” label on the computer vision suggestions indicates that there is a Research Grade observation, or an observation that would be research grade if it wasn&#x27;t captive, of that taxon that is:> - within nine 1-degree grid cells in around the observation&#x27;s coordinates and> - observed around that time of year (in a three calendar month range, in any year).https:&#x2F;&#x2F;www.inaturalist.org&#x2F;pages&#x2F;help#computer-visionFor how the model was trained, it&#x27;s fairly well documented on the blog, including different platforms used as well as changes in training techniques. Previously the model was updated twice per year, as it required several months to train. For the past year they&#x27;ve been operating on a transfer learning method, so the model is trained on the images then updated, roughly once each month, to reflect changes in taxa. The v2.0 model was trained on 60,000 taxa and 30 million photos. There are far more taxa on iNaturalist, however there is a threshold of ~100 observations before a new species is included in the model.https:&#x2F;&#x2F;www.inaturalist.org&#x2F;blog&#x2F;83370-a-new-computer-vision...https:&#x2F;&#x2F;www.inaturalist.org&#x2F;blog&#x2F;75633-a-new-computer-vision... reply a_bonobo 9 hours agorootparentprev>It looked like they were also working on considering location when determining species, but the model I use doesn&#x27;t do that.I do this in fish for very different work and there&#x27;s a good chance the model for your species does not exist yet. For fish we have 6,000 distribution models based on sightings (aquamaps.org) but there are at least 20,000 species. These models have levels of certainty from &#x27;expert had a look and fixed it slightly manually&#x27; to &#x27;automatically made based on just three sightings&#x27; to &#x27;no model as we don&#x27;t have great sightings data&#x27;. So it may be that the model uses location, just not for the species you have? reply fogleman 9 hours agorootparentWell, there&#x27;s no way to feed lat&#x2F;lng or similar into this particular tensorflow model. reply a_bonobo 4 hours agorootparentyeah that&#x27;s true! You can&#x27;t really do that, these models are just polygons, all we do is doublecheck the other methods&#x27; predictions&#x27; overlap with these polygons as a second step. reply xigency 8 hours agorootparentprevSounds like a real-life Pokémon Snap. You should add a digital professor who gives you points based on how good your recent photos are. (Size of subject in photo, focus, in-frame, and if the animal is doing something interesting.) reply datadrivenangel 8 hours agorootparentprevThat sounds like an awesome setup! Would you be willing to share your script with another bird photography enthusiast? reply bombcar 7 hours agorootparentprevThis post fits the username perfectly. reply kooshball 6 hours agorootparentprevI would pay for this reply kubrickslair 9 hours agorootparentprevThanks for sharing - I was curious too but didn’t delve in myself. reply kooshball 6 hours agorootparentprevif you&#x27;re willing it&#x27;s totally fine to share your work with the model itself removed reply komali2 8 hours agorootparentprevYou wrote your own custom RAW photo viewer? Like, including parsing? That&#x27;s incredibly cool, do you share it anywhere?Also why not just darktable &#x2F; digikam? reply xipho 10 hours agoparentprevhttps:&#x2F;&#x2F;openaccess.thecvf.com&#x2F;content_cvpr_2018&#x2F;html&#x2F;Van_Hor...https:&#x2F;&#x2F;openaccess.thecvf.com&#x2F;content&#x2F;CVPR2021&#x2F;html&#x2F;Van_Horn...Etc. reply bandergirl 8 hours agoparentprevI wish I had the same experience as you. The vast majority of time I point at tree leaves in South East Asia it tells me it’s Dicots and it stops there. Only rarely I get the actual full classification; the last time it happened was for a common almond tree. reply burkaman 7 hours agorootparentIt&#x27;s very bad at trees for some reason. Also mushrooms, but I thought that might be intentional so they don&#x27;t get blamed for someone eating something poisonous that was misidentified.PlantNet often works better for trees. reply joshvm 2 hours agorootparentTrees are generally difficult to classify well with computer vision. It&#x27;s hard for the models to establish context because at a scale where you can see the whole tree you tend to include lots of background. If you include a bark photo, it&#x27;s often ambiguous if there&#x27;s growth&#x2F;stuff&#x2F;weathering on top. Flowers tend to be good inputs.The training imagery is also really inconsistent in inaturalist and again for plants it&#x27;s hard to establish context. These are mostly smartphone pictures that non experts have captured in the app. While someone might have verified that a plant is a particular species, because there isn&#x27;t any foreground&#x2F;background segmentation, there are often confounding objects in the frame. On top of that you only get a 300px input to classify from. With animals I&#x27;d say it&#x27;s much more common for photographers to isolate the subject. There&#x27;s also massive class imbalance in inat, a large number of the observations are things like mallards (ie common species in city parks).I guess the best solution would be to heavily incorporate geographic priors and expected species in the location (which I think is partly done already). reply alecst 6 hours agorootparentprevMy experience has been great with mushrooms, just to add another datapoint. I mean, it&#x27;s often about as good as you can get by eye without breaking out the lab equipment. reply s0rce 7 hours agorootparentprevIt seems to do well for trees for me in California. reply contingencies 6 hours agorootparentprevFor trees try to photograph the flowers, the seeds, the bark, the leaves (both sides), the trunk growth habit (especially bottom portion), and the upper branches growth habit. Often when asking it to suggest a species switching between these will create progress. reply rahimnathwani 9 hours agoparentprevI&#x27;d never heard of this app, but your description made me want to install it. When I googled it I was surprised at the app ratings:Apple: 4.8Google Play: 3.4The most common issue mentioned by negative Play store reviews is the camera not focusing on the right thing, and needing to try many different angles before something is recognized correctly. This is probably nothing to do with the underlying model, which I guess is the same on both platforms. reply Taek 6 hours agorootparentCamera zoom is definitely annoying, there&#x27;s no way to control how zoomed in it is.And yes, it often takes as much as a minute to identify a species, because you have to keep adjusting zoom and angle and trying to catch every important feature.That said, once you are used to it, it becomes less noticeable and just feels like part of the game. reply EGreg 10 hours agoparentprevProbably because many people around the world participated in classifying what was posted?I am guessing. Please tell me if that is correct. How do they prevent false labels ? reply nemo 10 hours agorootparentAny observations can be submitted, but the observation has to be verified by a different observer. Most identifiers are folks with more experience identifying things locally, and the data quality is high. There&#x27;s very little incentive to game the system and if something is misidentified other iNatters can also add identifications correcting mistakes which happens regularly - often various scientists&#x2F;specialists tend to sweep observations in their taxa of note and correct issues. There&#x27;s criteria for a \"high quality\" observation, including being verified. Only those observations that are high quality are used for training. reply xipho 10 hours agorootparentprevThere are hundreds of thousands of \"false&#x27; labels. Pictures can be classified many times. reply EGreg 10 hours agorootparentI always wondered how do you determine truth in such sites? reply phito 5 hours agorootparentYou ask actual experts for identification replytroymc 9 hours agoprevMost (or all?) of iNaturalist&#x27;s code is open source (typically MIT), see https:&#x2F;&#x2F;github.com&#x2F;inaturalistA lot of iNaturalist data is open data, see https:&#x2F;&#x2F;github.com&#x2F;inaturalist&#x2F;inaturalist-open-data(It&#x27;s up to each user to decide how they want to license their observations, photos, and sounds. The options are all-rights-reserved [no license], CC0, CC-BY, and various other CC license.) reply jw_cook 5 hours agoparentYou can also get all research-grade observation data from a DarwinCore archive[1] that&#x27;s updated monthly and exported to GBIF[2]. They also have a pretty good API[3], and if you happen to want to use that in a python application or script, I maintain a client library[4] for it.[1]: https:&#x2F;&#x2F;www.inaturalist.org&#x2F;pages&#x2F;developers[2]: https:&#x2F;&#x2F;www.gbif.org&#x2F;dataset&#x2F;50c9509d-22c7-4a22-a47d-8c48425...[3]: https:&#x2F;&#x2F;api.inaturalist.org&#x2F;v1&#x2F;docs&#x2F;[4]: https:&#x2F;&#x2F;github.com&#x2F;pyinat&#x2F;pyinaturalist reply geokon 8 hours agoparentprevIn case anyone else is wondering why it&#x27;s not on Fdroid: https:&#x2F;&#x2F;github.com&#x2F;inaturalist&#x2F;iNaturalistAndroid&#x2F;issues&#x2F;654(tldr: uses Google Maps and analytics) reply CameronNemo 7 hours agorootparentYou can download it from their github apparently.I just limp along with aurora, though. reply malermeister 1 hour agoparentprevDo you know if this includes the model this commenter was talking about? https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37516652Feels like that&#x27;d be useful for all sorts of stuff. reply bentcorner 10 hours agoprevI&#x27;m a big fan of their \"Seek\" app and have used it a bunch. It has a similar \"game\" loop like Pokemon Go, but without any mtx, plus you learn a lot about your local ecosystems.If you have kids I highly recommend pulling out the app during a nature walk. reply ronyeh 4 hours agoparentIn case others have the same question I did...Microtransactions, sometimes abbreviated as mtx, are a business model where users can purchase virtual goods with micropayments within a game. Microtransactions are often used in free-to-play games to provide a revenue source for the developers. reply tomrandle 35 minutes agoprevI love the app. Each week I discover a new to me species of insect in my garden. When the AI fails to work (relatively rarely) the community usually quickly manually identify it.I’ve had less success with trees but it’s still pretty good.The focus on images is a bit iffy. Usually I take the photo using the phones native camera app to overcome. reply manicennui 9 hours agoprevI&#x27;m so glad this happened and they weren&#x27;t acquired by some shitty tech company. reply singingfish 1 hour agoprevI&#x27;d never heard of iNaturalist until recently. Then it turned out one of my young adult family members had started developing quite a reputation on there - has found a few undescribed&#x2F;ambiguous&#x2F;out of range species of animal in quite a short period of time, and I think that it might have a strong influence on their coming career. reply cdepman 9 hours agoprevGreat news. Seek is the #1 app I recommend parents for their children if they’re going to be using a smart phone. A tool that helps us engage with and appreciate our natural environment with nice gamification. Helped me identify some of my favorite sages and other aromatic plants. reply llbeansandrice 10 hours agoprevI&#x27;m a huge fan of the Seek app. It does a much better job than the attempts Apple makes at IDing plants and animals in photos I&#x27;ve taken.I&#x27;m sure it&#x27;s an issue of the image not having enough data, but Apple seems to always try and pin down a species or two whereas Seek seems to only tell me what it knows. reply xipho 10 hours agoprevPerhaps the most successful \"natural\" social-network out there, well deserved. Now if we can just get citizen scientists cheap scopes and better camera lenses so we can actually make those photos of critters < 2mm useful (at scale) we&#x27;d see research potential rocket. reply nemo 9 hours agoparentWith the adoption of multi-lens phone cameras allowing better zooming the general quality of insect observation photos has improved (some, there&#x27;s still a lot of terrible photos). I actually started submitting a lot more insect observations in iNaturalist after I got an iPhone 12 and other folks on the forums have mentioned upgraded phone cameras have improved their observations and increased the range of what species they can submit. I&#x27;d love getting more zoom, there&#x27;s micro-moths, lot of small aquatic inverts and things I&#x27;d be happy to be able to observe. Individuals do have some incentive to find new species over time to increase species counts, I&#x27;m up to 590 identified insect species and am trying to top my bird species count at 632. Improved cameras over time help improve model training and add species that are harder to get photos of as tech improves. reply s0rce 7 hours agorootparentI submit most interesting insects I find, fun to learn about them. These are some of my favoriteshttps:&#x2F;&#x2F;www.inaturalist.org&#x2F;observations&#x2F;155914507https:&#x2F;&#x2F;www.inaturalist.org&#x2F;observations&#x2F;136708118https:&#x2F;&#x2F;www.inaturalist.org&#x2F;observations&#x2F;132443637https:&#x2F;&#x2F;www.inaturalist.org&#x2F;observations&#x2F;169121886https:&#x2F;&#x2F;www.inaturalist.org&#x2F;observations&#x2F;8443142https:&#x2F;&#x2F;www.inaturalist.org&#x2F;observations&#x2F;8445065https:&#x2F;&#x2F;www.inaturalist.org&#x2F;observations&#x2F;89986236. reply hetspookjee 5 hours agorootparentWhat camera do you use? This one is so nicely zoomed https:&#x2F;&#x2F;www.inaturalist.org&#x2F;observations&#x2F;132443637Almost looks like an image from an electron microscope the way the grass stands up. reply s0rce 2 hours agorootparentJust an iphone, grass isn&#x27;t real though. reply RaoulP 9 hours agoparentprevIf anyone has suggestions for a smartphone scope&#x2F;lens, I&#x27;d be happy to hear them. reply sphars 8 hours agorootparentThe Moment lenses and cases are probably the most well-received lenses for mobile devices. They have macro lenses as well: https:&#x2F;&#x2F;www.shopmoment.com&#x2F;mobile&#x2F;phone-lenses reply sphars 8 hours agoprevHas anyone used PlantNet&#x27;s app[0] and compared accuracy to iNaturalist? Been using the former and it seems to identify successfully, though I can&#x27;t say I&#x27;ve used to identify more \"exotic\" fauna. Might give iNaturalist a try.[0]: https:&#x2F;&#x2F;identify.plantnet.org&#x2F; reply nemo 8 hours agoparentI haven&#x27;t used PlantNet though I&#x27;ve been working on learning plant identification&#x2F;taxonomy and have been using iNaturalist. Their models are limited by inputs, if you&#x27;ve got a wild angiosperm that&#x27;s flowering it&#x27;s pretty good. With human cultivars, even with flowers it&#x27;s not always great, though no shade there, that&#x27;s what I&#x27;d expect for visually trained models that focus on plants in the wild. If you aim it at a leaf there&#x27;s not enough visual data to categorize, if you aim it at a full plant it&#x27;s so-so. I mostly stick to flowering plants and have an easy time. reply da39a3ee 2 hours agoparentprevI’ve been using PlantNet over iNaturalist. One reason is that PlantNet gives confidence scores for identification. In general PN seems very good for European plants. reply j7ake 5 hours agoprevWhat’s the model for them decide when to say a new species has been found, rather than just a variant of a known species?Or more generally, whats the generation of a species? It can’t be just whether they can produce offspring together because some different species has been shown to produce viable offspring. reply ry167 47 minutes agoparentLike a lot of biology, it’s complicated and often you need multiple forms of evidence to support a species classification if the viable offspring (biological species concept) doesn’t suit.So there are lots of different models for different types of organisms. And some reproduce asexually so reproductive compatibility would never be enough.Two simple options are evolutionary lineage (effectively genetic distance) or physical characteristics (morphology): https:&#x2F;&#x2F;bio.libretexts.org&#x2F;Courses&#x2F;University_of_California_... reply kej 10 hours agoprevAnecdotal, but I&#x27;ve gotten better results from iNaturalist than from the built in camera search on my phone, especially for insects. reply nemo 9 hours agoparentFor insects iNaturalist has the best trained models I know of, though of course not all insects are visually identifiable from a photo, especially beetles. It&#x27;s actually incredibly good with birds as well. I post observations to iNaturalist daily and use the AI all the time for identification, even when I know the species the models usually figure it out as well and it&#x27;s saves typing.I have used iNaturalist since 2014, the quality wasn&#x27;t great initially but with the continued observations adding high quality annotations to the data their training improved pretty quickly, by 2017-18 it was already really good. reply AndrewKemendo 8 hours agoprevThis is so beautiful! Congrats to everyone for pulling off a great project and now it has the ability to actually continue to do great things with a better future.Very positive to see reply chelmzy 9 hours agoprevIf they could drop their dependencies on Google Services for Seek I would be ecstatic. The identification works perfect but I would love to be able to view&#x2F;post locations. reply Evidlo 7 hours agoprevAre there any apks available outside of the Play store? reply Evidlo 7 hours agoparentSeems like there are apks on the Github repo: https:&#x2F;&#x2F;github.com&#x2F;inaturalist&#x2F;iNaturalistAndroid&#x2F;releases reply neilv 9 hours agoprevHopefully they&#x27;ll get the app into F-Droid. reply sphars 8 hours agoparentOld thread, but looks like due to non-FOSS dependencies, it&#x27;s not likely to happen: https:&#x2F;&#x2F;github.com&#x2F;inaturalist&#x2F;iNaturalistAndroid&#x2F;issues&#x2F;104... reply ChrisMarshallNY 8 hours agoprev [–] Good on ‘em!Great service, and great app. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "iNaturalist, a social network for logging biodiversity, has become an independent nonprofit entity, aided by a $10 million grant.",
      "The grant aims to support iNaturalist in continuing its mission of connecting people with nature and generating ecological data. The platform also hopes to increase its presence in areas with high biodiversity and limited access to their service.",
      "iNaturalist also plans to incorporate artificial intelligence to forecast species distributions and seeks to collaborate with its previous partner organizations."
    ],
    "commentSummary": [
      "iNaturalist app, employing a TensorFlow Lite model, has surmounted 50 million observations, aiding nature aficionados in identifying plants and animals.",
      "Despite shortcomings such as class imbalance and object confusion in photos, the app boosts its precision via user verification and inclusion of geographic priors.",
      "Future enhancements indicate the potential employment of improved camera technologies and app availability across various platforms."
    ],
    "points": 338,
    "commentCount": 60,
    "retryCount": 0,
    "time": 1694732836
  },
  {
    "id": 37512888,
    "title": "In a Git repository, where do your files live?",
    "originLink": "https://jvns.ca/blog/2023/09/14/in-a-git-repository--where-do-your-files-live-/",
    "originBody": "Julia Evans ABOUT TALKS PROJECTS TWITTER MASTODON GITHUB FAVORITES ZINES RSS In a git repository, where do your files live? Hello! I was talking to a friend about how git works today, and we got onto the topic – where does git store your files? We know that it’s in your .git directory, but where exactly in there are all the versions of your old files? For example, this blog is in a git repository, and it contains a file called content/post/2019-06-28-brag-doc.markdown. Where is that in my .git folder? And where are the old versions of that file? Let’s investigate by writing some very short Python programs. git stores files in .git/objects Every previous version of every file in your repository is in .git/objects. For example, for this blog, .git/objects contains 2700 files. $ find .git/objects/ -type fwc -l 2761 note: .git/objects actually has more information than “every previous version of every file in your repository”, but we’re not going to get into that just yet Here’s a very short Python program (find-git-object.py) that finds out where any given file is stored in .git/objects. import hashlib import sys def object_path(content): header = f\"blob {len(content)}\\0\" data = header.encode() + content digest = hashlib.sha1(data).hexdigest() return f\".git/objects/{digest[:2]}/{digest[2:]}\" with open(sys.argv[1], \"rb\") as f: print(object_path(f.read())) What this does is: read the contents of the file calculate a header (blob 16673\\0) and combine it with the contents calculate the sha1 sum (e33121a9af82dd99d6d706d037204251d41d54 in this case) translate that sha1 sum into a path (.git/objects/e3/3121a9af82dd99d6d706d037204251d41d54) We can run it like this: $ python3 find-git-object.py content/post/2019-06-28-brag-doc.markdown .git/objects/8a/e33121a9af82dd99d6d706d037204251d41d54 jargon: “content addressed storage” The term for this storage strategy (where the filename of an object in the database is the same as the hash of the file’s contents) is “content addressed storage”. One neat thing about content addressed storage is that if I have two files (or 50 files!) with the exact same contents, that doesn’t take up any extra space in Git’s database – if the hash of the contents is aabbbbbbbbbbbbbbbbbbbbbbbbb, they’ll both be stored in .git/objects/aa/bbbbbbbbbbbbbbbbbbbbb. how are those objects encoded? If I try to look at this file in .git/objects, it gets a bit weird: $ cat .git/objects/8a/e33121a9af82dd99d6d706d037204251d41d54 x^A}sƑo|^Qju\\*j^... What’s going on? Let’s run file on it: $ file .git/objects/8a/e33121a9af82dd99d6d706d037204251d41d54 .git/objects/8a/e33121a9af82dd99d6d706d037204251d41d54: zlib compressed data It’s just compressed! We can write another little Python program called decompress.py that uses the zlib module to decompress the data: import zlib import sys with open(sys.argv[1], \"rb\") as f: content = f.read() print(zlib.decompress(content).decode()) Now let’s decompress it: $ python3 decompress.py .git/objects/8a/e33121a9af82dd99d6d706d037204251d41d54 blob 16673--- title: \"Get your work recognized: write a brag document\" date: 2019-06-28T18:46:02Z url: /blog/brag-documents/ categories: [] --- ... the entire blog post ... So this data is encoded in a pretty simple way: there’s this blob 16673\\0 thing, and then the full contents of the file. there aren’t any diffs One thing that surprised me here is the first time I learned it: there aren’t any diffs here! That file is the 9th version of that blog post, but the version git stores in the .git/objects is the whole file, not the diff from the previous version. Git actually sometimes also does store files as diffs (when you run git gc it can combine multiple different files into a “packfile” for efficiency), but I have never needed to think about that in my life so we’re not going to get into it. Aditya Mukerjee has a great post called Unpacking Git packfiles about how the format works. what about older versions of the blog post? Now you might be wondering – if there are 8 previous versions of that blog post (before I fixed some typos), where are they in the .git/objects directory? How do we find them? First, let’s find every commit where that file changed with git log: $ git log --oneline content/post/2019-06-28-brag-doc.markdown c6d4db2d 423cd76a 7e91d7d0 f105905a b6d23643 998a46dd 67a26b04 d9999f17 026c0f52 72442b67 Now let’s pick a previous commit, let’s say 026c0f52. Commits are also stored in .git/objects, and we can try to look at it there. But the commit isn’t there! ls .git/objects/02/6c* doesn’t have any results! You know how we mentioned “sometimes git packs objects to save space but we don’t need to worry about it?“. I guess now is the time that we need to worry about it. So let’s take care of that. let’s unpack some objects So we need to unpack the objects from the pack files. I looked it up on Stack Overflow and apparently you can do it like this: $ mv .git/objects/pack/pack-adeb3c14576443e593a3161e7e1b202faba73f54.pack . $ git unpack-objects1561998673 -0400 committer Julia Evans1561998673 -0400 brag doc We can also do get same information with git cat-file -p 026c0f52, which does the same thing but does a better job of formatting the data. (the -p option means “format it nicely please”) commit step 2: look at the tree This commit has a tree. What’s that? Well let’s take a look. The tree’s ID is 01832a9109ab738dac78ee4e95024c74b9b71c27, and we can use our decompress.py script from earlier to look at that git object. (though I had to remove the .decode() to get the script to not crash) $ python3 decompress.py .git/objects/01/832a9109ab738dac78ee4e95024c74b9b71c27 b'tree 396\\x00100644 .gitignore\\x00\\xc3\\xf7`$8\\x9b\\x8dO\\x19/\\x18\\xb7}|\\xc7\\xce\\x8e:h\\xad100644 README.md\\x00~\\xba\\xec\\xb3\\x11\\xa0^\\x1c\\xa9\\xa4?\\x1e\\xb9\\x0f\\x1cfG\\x96\\x0b This is formatted in kind of an unreadable way. The main display issue here is that the commit hashes (\\xc3\\xf7$8\\x9b\\x8dO\\x19/\\x18\\xb7}|\\xc7\\xce\\…) are raw bytes instead of being encoded in hexadecimal. So we see \\xc3\\xf7$8\\x9b\\x8d instead of c3f76024389b8d. Let’s switch over to using git cat-file -p which formats the data in a friendlier way, because I don’t feel like writing a parser for that. $ git cat-file -p 01832a9109ab738dac78ee4e95024c74b9b71c27 100644 blob c3f76024389b8d4f192f18b77d7cc7ce8e3a68ad .gitignore 100644 blob 7ebaecb311a05e1ca9a43f1eb90f1c6647960bc1 README.md 100644 blob 0f21dc9bf1a73afc89634bac586271384e24b2c9 Rakefile 100644 blob 00b9d54abd71119737d33ee5d29d81ebdcea5a37 config.yaml 040000 tree 61ad34108a327a163cdd66fa1a86342dcef4518e content <-- this is where we're going next 040000 tree 6d8543e9eeba67748ded7b5f88b781016200db6f layouts 100644 blob 22a321a88157293c81e4ddcfef4844c6c698c26f mystery.rb 040000 tree 8157dc84a37fca4cb13e1257f37a7dd35cfe391e scripts 040000 tree 84fe9c4cb9cef83e78e90a7fbf33a9a799d7be60 static 040000 tree 34fd3aa2625ba784bced4a95db6154806ae1d9ee themes This is showing us all of the files I had in the root directory of the repository as of that commit. Looks like I accidentally committed some file called mystery.rb at some point which I later removed. Our file is in the content directory, so let’s look at that tree: 61ad34108a327a163cdd66fa1a86342dcef4518e commit step 3: yet another tree $ git cat-file -p 61ad34108a327a163cdd66fa1a86342dcef4518e 040000 tree 1168078878f9d500ea4e7462a9cd29cbdf4f9a56 about 100644 blob e06d03f28d58982a5b8282a61c4d3cd5ca793005 newsletter.markdown 040000 tree 1f94b8103ca9b6714614614ed79254feb1d9676c post <-- where we're going next! 100644 blob 2d7d22581e64ef9077455d834d18c209a8f05302 profiler-project.markdown 040000 tree 06bd3cee1ed46cf403d9d5a201232af5697527bb projects 040000 tree 65e9357973f0cc60bedaa511489a9c2eeab73c29 talks 040000 tree 8a9d561d536b955209def58f5255fc7fe9523efd zines Still not done… commit step 4: one more tree…. The file we’re looking for is in the post/ directory, so there’s one more tree: $ git cat-file -p 1f94b8103ca9b6714614614ed79254feb1d9676c.... MANY MANY lines omitted ... 100644 blob 170da7b0e607c4fd6fb4e921d76307397ab89c1e 2019-02-17-organizing-this-blog-into-categories.markdown 100644 blob 7d4f27e9804e3dc80ab3a3912b4f1c890c4d2432 2019-03-15-new-zine--bite-size-networking-.markdown 100644 blob 0d1b9fbc7896e47da6166e9386347f9ff58856aa 2019-03-26-what-are-monoidal-categories.markdown 100644 blob d6949755c3dadbc6fcbdd20cc0d919809d754e56 2019-06-23-a-few-debugging-resources.markdown 100644 blob 3105bdd067f7db16436d2ea85463755c8a772046 2019-06-28-brag-doc.markdown <-- found it!!!!! Here the 2019-06-28-brag-doc.markdown is the last file listed because it was the most recent blog post when it was published. commit step 5: we made it! Finally we have found the object file where a previous version of my blog post lives! Hooray! It has the hash 3105bdd067f7db16436d2ea85463755c8a772046, so it’s in git/objects/31/05bdd067f7db16436d2ea85463755c8a772046. We can look at it with decompress.py $ python3 decompress.py .git/objects/31/05bdd067f7db16436d2ea85463755c8a772046head blob 15924--- title: \"Get your work recognized: write a brag document\" date: 2019-06-28T18:46:02Z url: /blog/brag-documents/ categories: [] --- ... rest of the contents of the file here ... This is the old version of the post! If I ran git checkout 026c0f52 content/post/2019-06-28-brag-doc.markdown or git restore --source 026c0f52 content/post/2019-06-28-brag-doc.markdown, that’s what I’d get. this tree traversal is how git log works This whole process we just went through (find the commit, go through the various directory trees, search for the filename we wanted) seems kind of long and complicated but this is actually what’s happening behind the scenes when we run git log content/post/2019-06-28-brag-doc.markdown. It needs to go through every single commit in your history, check the version (for example 3105bdd067f7db16436d2ea85463755c8a772046 in this case) of content/post/2019-06-28-brag-doc.markdown, and see if it changed from the previous commit. That’s why git log FILENAME is a little slow sometimes – I have 3000 commits in this repository and it needs to do a bunch of work for every single commit to figure out if the file changed in that commit or not. how many previous versions of files do I have? Right now I have 1530 files tracked in my blog repository: $ git ls-fileswc -l 1530 But how many historical files are there? We can list everything in .git/objects to see how many object files there are: $ find .git/objects/ -type fgrep -v packawk -F/ '{print $3 $4}'wc -l 20135 Not all of these represent previous versions of files though – as we saw before, lots of them are commits and directory trees. But we can write another little Python script called find-blobs.py that goes through all of the objects and checks if it starts with blob or not: import zlib import sys for line in sys.stdin: line = line.strip() filename = f\".git/objects/{line[0:2]}/{line[2:]}\" with open(filename, \"rb\") as f: contents = zlib.decompress(f.read()) if contents.startswith(b\"blob\"): print(line) $ find .git/objects/ -type fgrep -v packawk -F/ '{print $3 $4}'python3 find-blobs.pywc -l 6713 So it looks like there are 6713 - 1530 = 5183 old versions of files lying around in my git repository that git is keeping around for me in case I ever want to get them back. How nice! that’s all! Here’s the gist with all the code for this post. There’s not very much. I thought I already knew how git worked, but I’d never really thought about pack files before so this was a fun exploration. I also don’t spend too much time thinking about how much work git log is actually doing when I ask it to track the history of a file, so that was fun to dig into. As a funny postscript: as soon as I committed this blog post, git got mad about how many objects I had in my repository (I guess 20,000 is too many!) and ran git gc to compress them all into packfiles. So now my .git/objects directory is very small: $ find .git/objects/ -type fwc -l 14 Want a weekly digest of this blog? Subscribe Notes on using a single-person Mastodon server ARCHIVES © Julia Evans. If you like this, you may like Ulia Ea or, more seriously, this list of blogs I love or some books I've read. You might also like the Recurse Center, my very favorite programming community (my posts about it)",
    "commentLink": "https://news.ycombinator.com/item?id=37512888",
    "commentBody": "In a Git repository, where do your files live?Hacker NewspastloginIn a Git repository, where do your files live? (jvns.ca) 333 points by todsacerdoti 15 hours ago| hidepastfavorite88 comments p4bl0 14 hours agoThanks for sharing this very interesting link (I actually knew it would be good before clicking simply because of the domain name)!If this sort of internal view of git interests you, I strongly suggest reading the \"DIY Git in Python\" series from here: https:&#x2F;&#x2F;www.leshenko.net&#x2F;p&#x2F;ugit&#x2F; reply js2 13 hours agoprevI realize the Python script is likely provided for didactic purposes, but you can use `git hash-object` to get the object ID:https:&#x2F;&#x2F;git-scm.com&#x2F;docs&#x2F;git-hash-objectWith a bit of sed, the python script in the blog post becomes: git hash-object sed -E &#x27;s|(..)(.*)|.git&#x2F;objects&#x2F;\\1&#x2F;\\2|&#x27;The inverse of `git hash-object` is `git cat-file`: git cat-file -p $(git hash-object )https:&#x2F;&#x2F;git-scm.com&#x2F;docs&#x2F;git-cat-fileAside, when I learn a new subject, I like to go to the index such that it is to get an idea of what I don&#x27;t know (first stage of learning: you don&#x27;t know what you don&#x27;t know). Then I can try to prioritize the order of learning about the topic. With git, I&#x27;d start with this page:https:&#x2F;&#x2F;git-scm.com&#x2F;docs&#x2F;git reply drewg123 13 hours agoparentI have a local clone of a git repo with many local branches. I lost an object file (and I&#x27;m not certain how). Now git gc always fails, complaining about the object:Counting objects: 100% (11785289&#x2F;11785289), done.Delta compression using up to 64 threadsCompressing objects: 100% (4116944&#x2F;4116944), done.fatal: unable to read 1cae71a9d5b24991c0d632b45186ca8a250e5d52fatal: failed to run repackI&#x27;ve cloned the repo again, and that object does not appear in the new clone, so I assume it must be from a commit to a local branch.The odd thing is that I think I locally cloned this repo, and saw no complaints about the missing object.Is there any way to tell what branch and&#x2F;or file(s) were referred to by the object? And, assuming its from a stale branch, just delete the branch and thereby fix my repo? reply Borg3 2 hours agorootparentThats interesting.. Did you had any system crash recently? Or maybe disk full? The only moment I think this is the only way to loose object like this.Anyway, If this is your only repo containing those branches then its gone. The only way you can try is to clone fresh repo from trusted source and then reconstruct every branch manually, basically squashing commits. And I bet, one of those branches will be broken. reply masklinn 13 hours agorootparentprevYou can try to git fsck in case that identifies the missing object. But I’m not sure there’s any ready made command to identify through which path a missing object is reached.It could actually be the reflog. Pruning the reflog then running “git gc —prune=now” might do the trick. reply drewg123 12 hours agorootparentThank you. I&#x27;ve tried git fsck in the past, and it complains about the missing object as well.And I just tried \"git gc —prune=now\", and sadly it still fails the same way.I&#x27;m afraid I&#x27;m going to have to bite the bullet and clean up my 30 or so worktrees and re-clone the repo, and re-create the worktrees. reply pcthrowaway 12 hours agorootparentYou might be able to recreate the git history without that object (or commit). Look into commands like filter-branch. I&#x27;d be surprised if there&#x27;s not a way to recover from this situation reply williamcotton 12 hours agorootparentprevTry a grep for that missing hash in the fatal message you posted and point it at a commit&#x2F;object that does exist or just delete that line&#x2F;file and see if that fixes it! reply drewg123 12 hours agorootparentThis is more or less what I&#x27;ve been trying to do for quite a while. How do I grep for it? And once I do that, how can I \"point it at a commit&#x2F;object that does exist ?\" reply williamcotton 11 hours agorootparentIf it&#x27;s a ref somewhere then it&#x27;ll just be a string of the hash deadbeef style. Just open the file up and change it to another commit hash or just delete the ref completely.Try something like: grep -r \"1cae71a9\" .&#x2F;.git&#x2F;And see if it comes up somewhere. My guess is that it&#x27;s a ref for some old branch pointing at a commit that isn&#x27;t around. reply Denvercoder9 1 hour agorootparentThat won&#x27;t work, as loose objects are stored zlib-compressed in .git, and packed objects can be stored in a delta format. You&#x27;d need something like this: git cat-file --unordered --batch-check=&#x27;%(objectname)&#x27; --batch-all-objectsxargs -n1 -- git cat-file -pgrep 1cae71a9d5b24991c0d632b45186ca8a250e5d52 replysmartmic 13 hours agoprevOh yeah, the Git internals... I tried to find my way through them using visualization but did not progress much: https:&#x2F;&#x2F;github.com&#x2F;smartmic&#x2F;git2pic reply sillysaurusx 12 hours agoparentI encourage everyone to read A Plumber&#x27;s Guide to Git: https:&#x2F;&#x2F;alexwlchan.net&#x2F;a-plumbers-guide-to-git&#x2F;It&#x27;s not a book, just a series of five short blog posts. Part 1 explains precisely where files live: https:&#x2F;&#x2F;alexwlchan.net&#x2F;a-plumbers-guide-to-git&#x2F;1-the-git-obj... $ mkdir animals $ cd animals $ git init $ echo \"Big blue basilisks bawl in the basement\" > animals.txt $ git hash-object -w animals.txt b13311e04762c322493e8562e6ce145a899ce570 $ find .git&#x2F;objects -type f .git&#x2F;objects&#x2F;b1&#x2F;3311e04762c322493e8562e6ce145a899ce570 $ rm animals.txt $ git cat-file -p b13311e04762c322493e8562e6ce145a899ce570 > animals.txtCongratulations, you just did a `git restore animals.txt` manually.Parts 2 through 5 are equally illuminating. reply bloopernova 10 hours agorootparentThank you a thousand times for sharing that. I just ran through the examples and they were very enlightening. reply metaltyphoon 13 hours agoparentprevThis was my aha! Momment https:&#x2F;&#x2F;youtu.be&#x2F;P6jD966jzlk?si=YNKrNf872IQqr1vj reply srathi 11 hours agoparentprevIt is fun to explore the Git internals! Some time back, I used it to learn Golang [1]. Two birds with one stone![1] https:&#x2F;&#x2F;github.com&#x2F;ssrathi&#x2F;gogit reply totetsu 7 hours agoparentprevI found this page had very easy to understand visualshttps:&#x2F;&#x2F;www.devopsschool.com&#x2F;blog&#x2F;git-tutorial-objects-refer... reply gjf 13 hours agoparentprevI tried to do something similar: https:&#x2F;&#x2F;articles.foletta.org&#x2F;post&#x2F;git-under-the-hood&#x2F; reply bloopernova 11 hours agoprevVery apropos, I&#x27;m trying to write a guide for my team called \"git beyond pull&#x2F;push and checkout\".I&#x27;m trying to write something that will demystify git for the developers in this team. So I want to show them the files in .git, and connect them to the concepts they know like branches, etc. I&#x27;m always on the lookout for new stuff to include.The more I can read, the better information I can put in this guide. reply grahamplace 11 hours agoparentI’d definitely read this if you’re able to share it publicly reply Vinnl 1 hour agorootparentHeh, \"git beyond pull&#x2F;push and checkout\" was also the idea behind my tutorial, though I figured visualising the commit graph would be more helpful than showing the hidden files. And also that a ~10 min guide would be more likely to be used than a very detailed book.Anyway, in case you&#x27;re interested: https:&#x2F;&#x2F;agripongit.vincenttunru.com reply tcoff91 11 hours agorootparentprevYou should read this: https:&#x2F;&#x2F;jwiegley.github.io&#x2F;git-from-the-bottom-up&#x2F; reply bloopernova 11 hours agorootparentprevI&#x27;ll probably announce it on HN when it&#x27;s finished :) reply globular-toast 13 hours agoprevYou don&#x27;t need to know this, by the way. You can totally just think of git as simply storing a copy of your entire repo every time you make a commit. This is one part of git that actually is a good abstraction.Of course it is fun to know this but it won&#x27;t help you understand git really, and please don&#x27;t tell people who are just learning git. Just say git makes a copy of the whole project every time you commit. reply solarkraft 2 hours agoparentYeah.I want to understand git. But by that I mean using it. I don&#x27;t need to know about the internals for that; I need to know common approaches to typical merge problems (where all of a sudden git loses a lot of its elegance). reply visarga 1 hour agorootparentI found out that GPT-4 is pretty good at helping me find&#x2F;format git commands and solve git issues. These are usually short responses, repeated in many places on the web, and easy to memorise for the LLM. GPT is really a game changer related to git anxiety. reply recursive 12 hours agoparentprev\"I don&#x27;t commit that often because I don&#x27;t have that much hard drive space.\" reply mostlylurks 11 hours agorootparentI wonder if anyone has built a system with the philosophy of the opposite extreme.\"Oh yeah, space is cheap, so I just let my automated system make 10,000 commits per second. It&#x27;ll be fine.\" reply quickthrower2 11 hours agorootparentI have been thinking about this. Why no record all keystrokes. Then checkpoint where you are whenever you desire. These days AI could describe any arbitrary span of code changes. reply mikewarot 23 minutes agorootparent>Why not record all keystrokes?That was Google Wave, it stored everything as an \"operational transform\". The presentation they used when showing it off to the world was brain damaged, they insisted as showing it off as a ton of separate blocks, instead of one continuous document, which gave people the wrong impression of it, and tanked it.In a similar way, the impression that Git stores deltas, got stuck in my head somehow at the beginning and made it an opaque mystery for me.It was only years later, when I somehow I managed to learn the truth, that Git stores full snapshots, and except for compression in extreme cases to save storage, it doesn&#x27;t do anything with deltas (except fake them to show diffs) reply jxy 11 hours agorootparentprevIt&#x27;s kind of true with git-lfs. reply glhaynes 11 hours agoparentprevI feel like git culture is one of the worst about these sorts of things. I&#x27;ve run into people that think you&#x27;re a loser if you don&#x27;t use it from the command line, but my commits using a GUI client are much cleaner and I seem to have much less trouble than they do. reply quickthrower2 11 hours agorootparentI use command line for pull&#x2F;push&#x2F;new branch, VSCode for commits and Tortoise for archeology and merges. I just use whatever seems easiest for the task. reply poorlyknit 6 hours agorootparentprevWhat GUI are you using and how do I make my commits cleaner? reply globular-toast 2 hours agorootparentI use magit. You want a UI that allows you to easily see the changes in your worktree and add those line by line to the index, if necessary. Of course, you also want it to be easy to add whole files or hunks too, as always going line by line would be insane.A good commit means a good version. That&#x27;s what we&#x27;re doing after all: version control. Every commit you produce should be a valid standalone version of the software. Commits can build on each other, e.g. you can add feature a then subsequently add feature b that depends on feature a, but a maintainer should always be able to only take feature a, there shouldn&#x27;t be bits of feature b in there, and there shouldn&#x27;t be fixes for feature a in feature b&#x27;s commit.With practice you can learn to make rough commits first then clean them up into proper commits later. For example, there are \"end of day\" commits and there are fixup commits. Those are both valid uses of git, but you shouldn&#x27;t be exposing those to your team. You need to rebase them before sending them. A good git user will sow the seeds for a smooth rebase early. reply offices 51 minutes agorootparentThe emacs user has feelings about annoying elitist cultures. reply Vinnl 1 hour agorootparentprevFor those who do prefer the command line (you do you), what you want is git add --patch reply globular-toast 1 hour agorootparentThat&#x27;s not really a CLI, though, it&#x27;s a really basic rudimentary text UI. Might as well spend the effort to learn it learning enough Emacs to use Magit. Can it even do line by line effectively? What about unstaging stuff you added accidentally? It&#x27;s not a patch on Magit or even any semi-decent GUI. reply globular-toast 2 hours agorootparentprevI&#x27;m the \"git guy\" in every job I&#x27;ve had. I never use the CLI! I use magit which is probably the very best git UI there is. A GUI is simply the best thing when you are in the process of building state. CLI is great for functional type stuff (ie. I type a command providing both input and output but is completely stateless). Building commits is one such example of working with state. Most CLI users I know just add everything every time. reply deepspace 11 hours agoprevThat was very informative, but I wondered if there is an easy-to-read reference somewhere about WHY git works the way it does?I am old enough to have used SCCS, RCS and CVS extensively. Each had their faults, but Git is the only VCS I have used where dealing with merge conflicts is unintuitive enough that I sometimes end up with the repository in an unusable state. I am sure I am doing something wrong, but I would like to understand why.The VCS that maps closes to the way my brain works is ClearCase. You essentially have a versioned file system, and you can set up a view to present any previous state of that file system. Of course, administration is a nightmare, it is not distributed, it is expensive, yada, yada. But when using it I always felt I knew exactly what was going on under the covers, which is not the case with Git at all. reply mabbo 10 hours agoparentIt&#x27;s definitely not a super intuitive model, but it is a powerful one.As I see it, git is a distributed database of snapshots of a directory of files. Every commit is a new snapshot. It&#x27;s designed the way it is to achieve that goal while minimizing the space used, yet keeping an entire history of the project. It also has tools like git-diff to better compare those snapshots.But distributed matters most because it was literally designed for managing the Linux kernel development- a large open source project with thousands of contributors working concurrently.Merge conflicts are hard in this model because you&#x27;re trying to put two snapshots together, not just two diffs. reply eru 8 hours agorootparent> It&#x27;s designed the way it is to achieve that goal while minimizing the space used, yet keeping an entire history of the projectMost of git&#x27;s design was done before they thought of &#x27;minimizing the space used&#x27;. Originally, they didn&#x27;t even do deltas and just stored complete snapshots for every object.> Merge conflicts are hard in this model because you&#x27;re trying to put two snapshots together, not just two diffs.I don&#x27;t think that&#x27;s the case at all. Thanks to three-way-merges git has just as much access to the diffs as any other version control system when merging. It&#x27;s just that in git diffs are a derived data structure, not a source of truth, but that doesn&#x27;t make a difference. reply hooper 3 hours agorootparentOne of the ideas behind Pijul is that implicit vs explicit diffs does make an important difference sometimes: https:&#x2F;&#x2F;pijul.org&#x2F;manual&#x2F;why_pijul.html reply ta8645 9 hours agoparentprev> ClearCase [...] it is not distributed [...]That&#x27;s the key reason Git can&#x27;t work the same way, and what makes it so powerful, and sometimes hard to grok.Git is based on a Directed Acyclic Graph (DAG) of committed changes. The DAG is shared by everyone. Each commit is immutable, and only extends the DAG with a new node. You do not alter any of the DAG that other people already possess, you are creating a NEW chain of nodes connected to the DAG.And that&#x27;s it, that&#x27;s how it allows anyone to make changes, at any time, on any number of systems. Because all operations are strictly additive to the DAG. Every time you commit changes, you add another immutable node onto the DAG. And at the very same moment, on another unrelated server, someone else is adding unrelated immutable nodes as well.Later, you may obtain some of those remote changes, they can be fetched into your local repository. You can fetch them without merging them. You will just have a copy of how someone else extended the DAG. But there will be no connection between the changes you made locally, and the changes the other person made in their repository.When you merge, you&#x27;re simply updating the DAG with a new node, it will point at two, previously disconnected chains of commits. Both sides of the merge represent immutable changes that extended the DAG starting from a single commit, the branching point.And that&#x27;s what you see in merge conflicts. The first block shows what a section of code looks like in the local branch. And the second block (after the equal signs) shows what that same section of code looks like in the remote branch you&#x27;re merging. >>>>>>> remoteThat&#x27;s it. reply jamie_ca 8 hours agoparentprevA lot of its design decisions are based around the data storage model, and tooling built to operate on those data structures. I recall a good write-up from a decade gone now, but no dice googling for it. The short version is probably:- Everything is a blob, a text file named after the SHA1 of its content.- Files are just themselves.- Directories list for their entries (file or subdirectory).- Commits list a Directory (the project root), and some metadata about the commit like the author, commit message, and the parent(s) of the commit.- A branch then is just an end-user-named reference to a commit&#x27;s hash.Everything flows from that - SHAs are reused, if you&#x27;re doing a diff and two directory entries have the same sha referencing a file, there&#x27;s no change. Switching a branch is modifying the special HEAD branch content, and recursively walking it to rehydrate the filesystem (and comparing to the previous checkout to optimize, skipping whole directories that don&#x27;t change). reply wayfinder 8 hours agoparentprevI think Git is conceptually simple... each commit is just conceptually a diff from a previous commit -- possibly from two commits. Branches and tags are just pointers to a commit.A merge is when you join two commits and thus may result in one merge conflict, while a rebase is resetting your branch to some other target commit and then &#x2F;re-applying&#x2F; _each_ of your commits on top, which may generate more than 1 merge conflict (due to each _one_ of your commits effectively being re-committed all over again) but hides the fact that you applying old changes to a newer base.But the tooling around Git is not great. I think showing merge conflicts properly so you don&#x27;t mess them up is also tooling issue more than anything.I&#x27;m going to plug this app called SmartGit which I have no relationship with that I don&#x27;t think a lot of people have tried but it&#x27;s awesome. Doesn&#x27;t obscure anything about Git and shows merge conflicts well IMO. Costs $ though. reply eru 8 hours agorootparent> I think Git is conceptually simple... each commit is just conceptually a diff from a previous commit -- possibly from two commits. Branches and tags are just pointers to a commit.That&#x27;s backwards. Git commits are complete snapshots of the state of your repository at the time. You can compute diffs between arbitrary commits, be that between child and parent commits, or completely unrelated commits.Have a look at https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;4129049&#x2F;why-is-a-3-way-m... reply wayfinder 5 hours agorootparentOh I know. I do that all that time. (And in SmartFGit, you can select any two commits.)But I said conceptually and that’s how I see them and it works for me. reply OskarS 1 hour agorootparentConceptually, though, that&#x27;s the wrong model. Pijul works like that, but git does not: commits are not diffs, they are full snapshots of the repository, including history. If you cherry-pick a commit from one branch to another, that&#x27;s an entire new commit, it&#x27;s not just \"this patch moved from one branch to another\". If your idea of a commit is \"it&#x27;s a diff to the previous commit\", you&#x27;ll get into trouble. reply globular-toast 25 minutes agorootparentYes and no.When you do a checkout or reset etc. you are indeed operating on snapshots. You&#x27;re just saying \"get me this version right here\".But when you do cherry-pick or rebase etc, git is operating on diffs. A cherry-pick doesn&#x27;t set your head or workdir to that version[0], it applies the changes to a new commit that sits on top of your current head. Similarly, a rebase walks through the changes and applies each one to the target.Commits and diffs are a duality and it matters not one bit how git stores them underneath. You can always calculate one from the other.[0] If you did want to do that for some reason then git reset will do it for you. That sets your current branch to that commit and with --hard it makes your workdir match. `git checkout.` makes your workdir match that older commit, but it doesn&#x27;t do deletes. If you want to make just your workdir match an older commit the only way I know is something like: `git reset --hard ; git reset --soft HEAD@{1}` which can be read as \"set my current branch to be at sha1 and make working directory match that snapshot exactly, then set my branch to be at where it was before that operation, leaving my workdir alone\". It&#x27;s not a very common thing to want to do. replyzadokshi 11 hours agoparentprevI used git for years now. I’m comfortable with all of the basic functions. It is my experience that I have had several times where merging&#x2F;branching has caused a repo to “break” It doesn’t happen often, but when it does it’s super frustrating and this I avoid the merging workflows where possible. I’m sure if I educate myself a bit more about git and pay more careful attention to the details, I wouldn’t occasionally have this problem, but Git really shouldn’t be like this. reply Yodel0914 10 hours agorootparentI&#x27;ve been using git for I guess 15 years, on a variety of server platforms (github, atlassian, MS devops, plain ssh) and branching models, with teams of various sizes, and I&#x27;ve never had a repo \"break\". Branching and merging is what git is amazing at.The worse thing I&#x27;ve had happen is that someone was lazy when merging and just did a \"take mine\" on 100s of files, thinking that they&#x27;d do a \"proper\" merge later. Of course git doesn&#x27;t work like that and their lazy merge had to unwound very carefully. reply jayshua 11 hours agorootparentprevWhat does a broken repo look like? What does broken mean here? reply nonethewiser 9 hours agorootparentprev> It is my experience that I have had several times where merging&#x2F;branching has caused a repo to “break”What do you mean? Like you resolve the conflict correctly and git stops working? Stops working how? That sounds very strange, and anything else just seems like PEBKAC. reply eru 8 hours agorootparentI wouldn&#x27;t go so far as the term PEBKAC.It&#x27;s true that git does not &#x27;break&#x27; from a merge; but merge conflicts (and rebase conflicts) can still be frustrating to resolve for ordinary users. And after things get too frustrating, they often do really random stuff that then might accidentally break the repo for real, or at least get it into a state where they don&#x27;t have enough knowledge to recover.Git&#x27;s underlying data model is fine, but the user interface can be quite lacking. For example, &#x27;git checkout&#x27; is a mess of almost unrelated functionality thrown together under one command.I think the idea behind &#x27;git switch&#x27; is a good one, and git could benefit from a complete overhaul of its user interface. Well, at least if you ignore the switching costs. Old farts like you and me have gotten used to the quirks of the bad old interface, and learned all the barely coherent options to &#x27;git reset&#x27;. reply appplication 11 hours agorootparentprevGit could be a lot better in a lot of ways, particularly from a developer experience perspective. I’m a little surprised we haven’t seen a meaningful successor.One example is how git will deceive you and tell you you’re up to date with your remote (e.g. origin&#x2F;main). What it means is that your local branch is up to date with its local concept of remote, and makes no statement guarantees about the actual state of the remote. Which is really a nonsense concept that does not need to exist.Similarly the whole concept of needing to specify “origin” at all is a bit bonkers and does no favors. Why is it that I can pull from a remote branch, commit some changes, run ‘git push’ and git has no idea what branch I want to push to. Another example: if main is a protected branch, don’t let me accidentally commit to it locally. I could keep going with the examples but I won’t.And yeah you can forgive all this by quibbling that git was written in a time when internet access was not ubiquitous, and of course all these decisions make sense because x, y, or z advanced edge case for advanced users only, and I’m a shitty engineer because all of this complexity secretly makes my life better and I’m just too simpleminded to appreciate it.Really though, if you rewrote git from a principles first approach (with developer experience being one of those principles), it certainly would not look like how it looks today. There is too much complexity, too many ways to do things, and too many bad decisions around defaults. Treat it like a proper distributed system, perhaps even backed by a real database. It’s not special because the data is code. The fact that it’s treated as such is the reason it feels so weird. reply OkayPhysicist 10 hours agorootparentYou&#x27;re confused because you&#x27;re treating the repo server as special.Git doesn&#x27;t do special. All branches, on all machines, are just branches. \"main\" on your device and \"origin&#x2F;main\" (main on the machine you called \"origin\"), are two different branches. They don&#x27;t need to share a name, you can just as easily set your local \"main\" to have \"origin&#x2F;Release\" as its upstream. The name \"main\" isn&#x27;t special. You can name your branches anything you desire. If you want to lock yourself out from controlling your own code, that&#x27;s a customization for you to make. To git, there&#x27;s no difference between committing to \"main\",\"feature111\", or anything else. \"origin\" isn&#x27;t special, either: you can have many different repo servers hosting different branches. Or maybe you don&#x27;t have a repo server at all, and you just have all your fellow devs machines and you coordinate via email.While being perhaps a bit un-opinionated, it also makes Git conceptually extremely consistent, and thus simple. reply appplication 10 hours agorootparentI certainly understand the abstraction and how to use git in this sense. The foundation of my above opinion is that I don’t think this is a great idea that’s well applied to modern development.Is it elegant that the same version control system can be used whether you have a remote server or you just coordinate over email? It certainly is! Is it necessary to have this level of generality and lack of opinions when 95% of users just want to do the same basic flow (and it does involve a server of some kind)? I don’t really think so, which is why I think there is so much confusion around really basic git functionality.We live in a world where git is philosophically more like Perl than python, and I think that it’s not unreasonable to think that it’s possible that if we flipped that, then that might actually be a good thing. reply ylyn 8 hours agorootparentThen write your own wrapper on top of Git. reply TeeMassive 7 hours agorootparentLazy Git ftw reply djur 9 hours agorootparentprev> Why is it that I can pull from a remote branch, commit some changes, run ‘git push’ and git has no idea what branch I want to push toGit has automatically tracked remote branches for years now. \"git switch foo\" will do exactly what you expect if \"origin&#x2F;foo\" exists.> if main is a protected branch, don’t let me accidentally commit to it locally\"Protected branches\" don&#x27;t exist in Git. They&#x27;re a GitHub concept. How would you be able to fork a repository if the permissions on a remote copy of the repository prevent you from making changes to your own copy? reply eru 8 hours agorootparentI can see the case for a local UI option (perhaps even on by default) that warns you when you make changes to a local branch that&#x27;s tracking a remote branch that&#x27;s marked as &#x27;protected&#x27; there. The option could also have a setting where it outright stops you from making that change.Of course, you could always opt out of that setting.Git doesn&#x27;t know what &#x27;protected&#x27; means, but you could teach it with a relatively small change to its code. Similarly, it might be useful to teach git about &#x27;volatile&#x27; branches (in the same sense as C&#x27;s volatile variables); a volatile branch is one where git would always checks for upstream changes first before any operation. Eg origin&#x2F;main would typically be marked as both protected and volatile.Again, volatile would be something you can override locally, but it might be useful as a default. reply djur 7 hours agorootparentThe logic you&#x27;re suggesting can easily be implemented with a Git hook:https:&#x2F;&#x2F;stackoverflow.com&#x2F;questions&#x2F;40462111&#x2F;prevent-commits...Alternately, you can simply not check out that branch locally at all, and then you&#x27;ll never have to worry about accidentally committing to it. reply WorldMaker 4 hours agorootparentAlso, many repo hosts have branch protection tools, and VS Code has a setting git.branchProtection to list branches which you want VS Code to remind you not to commit to, which can be handy. reply bloopernova 10 hours agorootparentprevGit separates its plumbing from its porcelain very well. That makes all the different front ends possible. Maybe there&#x27;s one that will help you to work with git?I differ from your opinion that the user experience is poor. I think it&#x27;s great, and I prefer using the command line interface. reply tmacam 9 hours agorootparentAs an example of a different frontend, have you tried \"jujutso\" [1]? Every time I ended seeing a comment about git vs Hg usability I am reminded of it. It uses git in the backend but its workflow&#x2F;frontend seems streamlined. Jujutsu is a Git-compatible DVCS. It combines features from Git (data model, speed), Mercurial (anonymous branching, simple CLI free from \"the index\", revsets, powerful history-rewriting), and Pijul&#x2F;Darcs (first-class conflicts), with features not found in most of them (working-copy-as-a-commit, undo functionality, automatic rebase, safe replication via rsync, Dropbox, or distributed file system).[1] https:&#x2F;&#x2F;github.com&#x2F;martinvonz&#x2F;jj reply appplication 5 hours agorootparentThis is pretty interesting. Maybe a missed opportunity to call it jugitsu reply eru 8 hours agorootparentprev> Similarly the whole concept of needing to specify “origin” at all is a bit bonkers and does no favors. Why is it that I can pull from a remote branch, commit some changes, run ‘git push’ and git has no idea what branch I want to push to.Git actually works like that. (Though you might have to set push.autoSetupRemote to true in the config?)However, when you have multiple remotes, it&#x27;s only natural that you will sometimes need to specify which one you want.> And yeah you can forgive all this by quibbling that git was written in a time when internet access was not ubiquitous, and of course all these decisions make sense because x, y, or z advanced edge case for advanced users only, and I’m a shitty engineer because all of this complexity secretly makes my life better and I’m just too simpleminded to appreciate it.Git was explicitly written for Linux kernel development.You are right that almost all other projects are simpler.> Really though, if you rewrote git from a principles first approach (with developer experience being one of those principles), it certainly would not look like how it looks today.I agree that git&#x27;s UI is lacking. You don&#x27;t need a from-scratch rewrite of whole system. You can just rewrite the UI only and think carefully about the defaults in the config.Eg &#x27;git checkout&#x27; is an incoherent mess of barely related features. &#x27;git switch&#x27; is a later addition, and goes in the right direction.> Treat it like a proper distributed system, perhaps even backed by a real database.Git is very much backed by a real database. That&#x27;s actually one of the stronger points of its design. You can see that the guy who started git, Linus Torvalds, has a lot of experience writing filesystems (which are also a kind of database).Git is also very much a distributed system with no trust between the nodes necessary, including no central trusted authority. How would you &#x27;treat&#x27; it even more &#x27;like a proper distributed system&#x27;?> It’s not special because the data is code. The fact that it’s treated as such is the reason it feels so weird.Where do you get that impression from?The main influence of being designed for code first comes in the form of the default merge driver being line oriented. But you can plug in your own merge drivers for your own data formats.But most everything else works the same, whether you stick C source code or funny cat pictures into your repository. reply zaphirplane 9 hours agorootparentprevHow would that work when someone is working on a feature&#x2F;bug and has to pause switch to a another bug, then return to the 1st feature&#x2F;bugSometimes you want to keep 2 different copies of Main with different names and state reply eru 8 hours agorootparent> Sometimes you want to keep 2 different copies of Main with different names and stateWouldn&#x27;t that just be two different branches? What does it have to do with &#x27;main&#x27;? reply TylerE 10 hours agorootparentprevBlame the Linus Torvalds personality cult. Only way that terrible UX got traction in the first place. If anyone OTHER than Linus had written it, it would have been mocked, and deservedly so. reply Yodel0914 10 hours agorootparentThat&#x27;s a pretty big claim. Git solved real problems at the time in a novel and extremely useful way. Coming from SVN (or god forbid VSS), the power and flexibility of git more than made up for its difficulty to grasp.Why it \"won\" over alternatives with cleaner UX (eg Hg) is a different question, and I think has a lot to do with github. reply TylerE 8 hours agorootparentMercurial came out essentially simultaneously, solved the same problems, with a much more coherent UX. reply Yodel0914 7 hours agorootparentEarly on, I was definitely a proponent for hg over git. I assumed it would at the very least remain a peer, given how much more sane the UX is. I was wrong though, and I don&#x27;t think it&#x27;s just because of github.Named branches being baked in turned out to actually be a real pain in mercurial. Sure, you can use bookmarks (and we did) but starts to quickly feel like you&#x27;re swimming against the current. reply spaniard89277 10 hours agorootparentprevGit may solve real problems but honestly, it&#x27;s a PITA to use. Just for basic tasks needs quite a lot time sink to understand what&#x27;s going on and what do you need to do.It gets in the way of the workflow IMO. reply KRAKRISMOTT 9 hours agorootparentprevIt&#x27;s bigger than him. GitHub built their SaaS on top of it. Had they chosen subversion or fossil, history would be very different.People use git because everybody else uses git and it started because GitHub provides easy code sharing and a better UI than the alternative — SourceForge and mailing lists. reply mr_toad 8 hours agorootparentPeople could have kept using SVN or whatever else. They jumped ship in droves, way before GitHub.At the time it was the only distributed and open source VCS. Fossil may have come quickly on its heels, but it was already too late. reply fragmede 8 hours agorootparentMercurial (hg) was released mere weeks after git saw the light of day, so it&#x27;s not that. reply eru 8 hours agorootparentAnd others were released before git:> The first open-source DVCS systems included Arch, Monotone, and Darcs. However, open source DVCSs were never very popular until the release of Git and Mercurial.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Distributed_version_control#Hi... reply appplication 10 hours agorootparentprevYeah, I originally had some Linus snark in there but deleted it. My above comment is being rapidly downvoted though, which is in some sense validating. reply WorldMaker 4 hours agorootparentprev> And yeah you can forgive all this by quibbling that git was written in a time when internet access was not ubiquitousI don&#x27;t think that&#x27;s right. Git&#x27;s remote concepts were built heavily on even more ubiquitous internet access than you are assuming, to some extent. Git was built where some upstreams were patches on email mailing lists. Git was built in environments where every contributor could relatively easily stand up a small server of their own (even as just a temporary server on a personal device with specified time windows) and you might have branch remotes tied to different colleagues&#x27; servers in a distributed fashion, the D in DVCS.At the time those weren&#x27;t advanced features for advanced users, those were simple features for flexible source control. There&#x27;s a sort of simplicity to pull requests in email flows. There&#x27;s a sort of simplicity in \"hey, can you check out my branch and make notes on it, I&#x27;ll serve it on my lab machine for a couple of hours so you can grab it, here&#x27;s the URL.\" In some of those cases you don&#x27;t even care to remember that remote URL after you&#x27;ve grabbed the branch because it will be a different IP address and port the next time they bring up that lab machine. (Git was a built in a world where there was no \"origin\" and multiple repos were valid representations of progress, some of them transient and as-needed, and \"origin\" was a name and concept that came later.)Some of that only exists in a world that assumes internet connectivity is ubiquitous, not just access, but service hosting and upload capabilities. The internet has some strange centralizing forces making access easier but anything other than raw consumption harder.There are certainly a lot of good reasons for some of that centralization. Whether or not is \"simpler\", there&#x27;s a convenience on everyone sharing big centralized hosts. There&#x27;s a lot of convenience of \"there is mostly only one remote that everyone shares and it has a high uptime SLA and a ton of extra collaboration features in one place\". There were certainly a lot of centralized version control systems before the DVCS was invented, and beyond convenience also a lot of familiarity that such centralizing operations benefited from.It&#x27;s interesting to me that in your last paragraph you think the solution is to make git a more \"proper\" distributed system, but one of the features you find too complex and don&#x27;t like exists so much because it was defined and built as a distributed system and just isn&#x27;t as convenient when working with centralized providers. git repos support multiple remotes because it was built to be distributed, git repos require to fetch remotes explicitly because it was built to be fault-tolerant in a distributed system and remotes may have very different SLAs from each other; losing access to one remote host shouldn&#x27;t stop you from fetching updates from a different one. The DX there was built for a distributed system. It is mostly where we see everything revolving around some super special \"origin\" remote that the DX feels overly-complicated and maybe missing better \"defaults\". It is mostly on the internet where running a simple CLI command to spin up a quick code server on a random port on a random machine with an accessible IP address is increasingly hard that it also becomes harder to imagine why people ever needed remotes beyond that special sauce \"origin\" idea. reply TeeMassive 7 hours agorootparentprevGit is much more data focused than all the other VCS. Sure, exposes details that complicates its usage for novices users, but it makes everything more maintainable and extensible in the long run. reply seesaw 9 hours agoparentprev+1 for clearcase. I enjoyed the time I used clearcase, and never found another one that was as pleasant to use as an end user. reply Borg3 2 hours agorootparentUgh. Ive been both using ClearCase and also were Admin of it. While as user it was pretty fine to use, as Admin I saw how complicated and fragile the whole thing was. They distributed model is absolutly terrible. You need powerfull box as a VOB server and probably be equal or even more powerfull box if you want to use dynamic views. We ended up using snapshot views.I would choose GIT every single time over ClearCase. reply temeya 9 hours agoprevWhile I&#x27;ve used Git a bit, and appreciate for what it is, I will admit that it&#x27;s syntax is what makes it a bit difficult. If the Git commands had kept to a single metaphor, then I think that would have helped tremendously. Even now, I&#x27;m still trying to figure out the best metaphor for using Git and it&#x27;s commands. So far the closest I have is a tree metaphor as follows:Git init = tree plantedGit add and Git merge = trunk growsGit branch = branch growsGit merge = branch intersectsAnd so on. But even this falls apart once I get to Git diff and Git checkout. reply brainbag 8 hours agoparentIf you haven&#x27;t watched the brilliant Git For Ages 4 and Up I can&#x27;t recommend it more highly. I make everyone watch it on my teams and my students. https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=3m7BgIvC-uQ Git is quite simple under the hood, it&#x27;s the convoluted user interface that makes it seem so difficult. Once you understand technically what the commands are doing, it&#x27;s a lot easier to know which one to reach for. reply valty 1 hour agoprev [–] Git has biggest moat of all software, and it is stifling innovation.On one side it&#x27;s good because everyone is using the same tool and we don&#x27;t have to learn many different intricacies of other tools.But on the other side, there&#x27;s probably a better way of doing things that could dramatically simplify everything.It was designed so long ago with such different computing and memory constraints, and the way we use repos today is very different - think monorepos.There are so many projects trying to bandaid solutions to its scaling issues, and so many projects are using monorepos today which are not well supported.I genuinely believe re-writing a VCS is actually a very simple task.If you look at the core use cases, or the commands people use, they are very few. reply offices 27 minutes agoparent [–] Discussions on improving git tend to be dominated by people who not only don&#x27;t grok git but don&#x27;t actually grok the problems inherent with distributed code development and want it to be little more than dropbox for github. Once you filter out these people, a good chunk of the remainders are people asking for UI changes that already exist but they didn&#x27;t bother to learn.Catering to these people means attempts at this problem usually punish power users by removing useful things like staging or a distinction between commit and push. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Git stores files as distinct objects in the .git/objects directory inside a repository, employing content-addressed storage, where filenames are the hash of the file's content.",
      "Git does not store diffs for individual versions; each version is saved as a complete file. To locate older versions, one can use 'git log' to find commit IDs associated with file changes.",
      "Git compresses objects using the zlib format. The author provides a practical example of retrieving an older version of a blog post using Git, accompanied by code snippets."
    ],
    "commentSummary": [
      "The article provides a comprehensive overview of Git, covering its unique functionality, troubleshooting methods, internal workings, and utilization of a Directed Acyclic Graph (DAG) for tracking changes.",
      "Criticisms of Git's user interface are explored alongside potential improvements, despite arguments supporting its flexibility and consistency in the realm of version control systems.",
      "The piece also discusses the complexity and usability of Git, compares its popularity against other options, and outlines potential for future innovation and scale-up."
    ],
    "points": 331,
    "commentCount": 88,
    "retryCount": 0,
    "time": 1694716454
  },
  {
    "id": 37516542,
    "title": "Godot Development Fund",
    "originLink": "https://fund.godotengine.org/",
    "originBody": "Features Blog Community About Assets Download Learn Contribute ❤︎ Donate Support the future of Godot Join the Development Fund and support Godot Foundation to work on core Godot development. € 31889 Per month 919 Members 9 Sponsors Choose Your Membership Level Your Name Link Logo Bronze €5 / month Silver €10 / month Gold €25 / month POPULAR Platinum €50 / month Titanium €100 / month Diamond €250 / month Sponsor Get in touch. * Displaying your name or company is opt-in. You control it being public or private. Credits Sponsor Platinum Sponsor Gold Sponsor Silver Diamond Anonymous Anonymous Anonymous Anonymous Anonymous Anonymous Titanium Game Dev Artisan Inventory System Course Kenney Koolala RPG in a Box Wilfred James You And 3 anonymous donors Platinum Andy Touch HP van Braam Justo Delgado Baudí Matthew Ekenstedt Ryan Heath Stephan Kessler Sylv Thx for #79697 And 11 anonymous donors Gold Asher Glick Ben Burbank Benjamin Sarsgard Benjo Kho Blake Farnsworth Brian Ernst Brian Levinsen David Chen Zhen David Coles Ends Eric Phy Faisal Al-Kubaisi (QatariGameDev) FeralBytes Frederick Ayala GlassBrick Guangzhou Lingchan Hendrik Mans Here's my 20 cents Iggy Zuk Jam José Canepa KAR Games KekLuck Kenneth Christensen Kristian Kriehl Logan Apple Luca Junge Luca Vazzano MHDante Malcolm Nixon Manuel Requena Mark Schramm Markus Hyvärinen Matheus Gritz Nicolas Gustafsson NotNet Obelisk Island Studios Piotr Siuszko Robin Ward Saltlight Studio Sofox Space Kraken Studios Vincent Foulon Weasel Games WuotanStudios.com endaye hiulit zikes And 151 anonymous donors FAQ How are monthly contributions calculated? How can I display my name in the credits? I just subscribed, why didn't the fund amount go up? Why not Patreon? How can I cancel my monthly contribution? Your donations will be received by the Godot Foundation, a non-profit organization that manages the funds for the Godot project. Thanks to your support we are able to: Hire developers to work part-time or full-time on Godot Engine. Create high quality demo artwork under a permissive license. Purchase hardware required to develop Godot. Pay for hosting of some web services. Cover travel costs to notable industry events. Produce merchandise for events. And much more! © 2007-2023 Juan Linietsky, Ariel Manzur and contributors Godot is a member of the Software Freedom Conservancy. Kindly hosted by TuxFamily.org. Website source code on GitHub. Get Godot Download Web Editor Public Relations Blog Communities and Events Press Kit About Godot Features Showcase Education License Code of Conduct Privacy Policy Donate Project Team Governance Teams Extra Resources Asset Library Documentation Code Repository Contact us",
    "commentLink": "https://news.ycombinator.com/item?id=37516542",
    "commentBody": "Godot Development FundHacker Newspastlogin [dupe] Godot Development Fund (godotengine.org) 291 points by bilsbie 10 hours ago| hidepastfavorite1 comment dang 4 hours ago [–] Comments moved to https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37481872. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Godot Development Fund is a program enabling individuals and businesses to financially assist in developing the Godot game engine by contributing varying amounts per their chosen membership levels.",
      "The funds are managed by the Godot Foundation and used for purposes such as hiring developers, creating artwork, acquiring hardware, and covering other project-related costs.",
      "Godot is a part of the Software Freedom Conservancy, and its website is hosted by TuxFamily.org, adding a layer of legitimacy to this open-source project."
    ],
    "commentSummary": [
      "The Godot Development Fund is the subject of discussion in a Hacker News post, but related comments have been relocated to another site.",
      "Applications have been announced open for Y Combinator (YC) Winter 2024 batch.",
      "The post provides links to several resources like application guidelines, FAQs, APIs, security, legal information, and details on how to apply and reach out to YC."
    ],
    "points": 291,
    "commentCount": 1,
    "retryCount": 0,
    "time": 1694736744
  },
  {
    "id": 37509624,
    "title": "Googlers told to avoid words like ‘share’ and ‘bundle,’ US says",
    "originLink": "https://www.bloomberg.com/news/newsletters/2023-09-14/googlers-told-to-avoid-words-like-share-and-bundle-us-says-lmj27bhl",
    "originBody": "Skip to content Bloomberg the Company & Its ProductsBloomberg Terminal Demo RequestBloomberg Anywhere Remote LoginBloomberg Customer Support Think Bigger:See how we drive impact, create opportunities and power decisions US Edition UK Europe US Asia Middle East Africa 日本 Sign In Subscribe Live Now Markets Economics Industries Tech AI Politics Wealth Pursuits Opinion Businessweek Equality Green CityLab Crypto More Newsletter Googlers Told to Avoid Words Like ‘Share’ and ‘Bundle,’ US Says The Google logo. Photographer: Nathan Laine/Bloomberg Gift this article Have a confidential tip for our reporters? Get in Touch Before it’s here, it’s on the Bloomberg Terminal LEARN MORE By Tom Giles and Davey Alba September 14, 2023 at 4:00 AM PDT You're reading Tech Daily. Get exclusive reporting and industry-leading access from Bloomberg reporters around the world. Email Sign Up By submitting my information, I agree to the Privacy Policy and Terms of Service and to receive offers and promotions from Bloomberg. Hi all, it’s Tom Giles in San Francisco and Davey Alba in Washington. Like Fight Club inductees, Googlers must never say certain things about Google. But first... Three things you need to know today: • Elon Musk called AI a double-edged sword • US said China’s iPhone ban is retaliation • Lawmakers probed big tech’s use of AI “ghost” staff Chatting without records Alphabet Inc.’s Google is on trial in Washington DC over US allegations that it illegally maintained a monopoly in the online search business. Executives of the Mountain View, California-based behemoth have known for years that the company’s practices are under a microscope, and have encouraged its employees to avoid creating lasting records of potential problematic conduct, government lawyers allege. Googlers often communicate with one another internally using the company’s Google Chat product. Under a policy called “Communicate with Care,” the Justice Department asserts, Googlers receive training that instructs them to have sensitive conversations over chat with history off — meaning the conversation is auto-deleted after 24 hours. Justice Department attorney Kenneth Dintzer presented a trial exhibit Monday with an October 2021 chat from Alphabet CEO Sundar Pichai. “Need the link for my leaders circle tomorrow,” the executive said. And in the next line: “Also can we change the setting of this group to history off… thanks.” This and other evidence at the trial would show Google “hid and destroyed documents because they knew they were violating the antitrust laws,” Dintzer said in his opening statement. Google declined to comment. As far back as 2003, Google managers circulated unambiguous instructions on phrases to avoid to ensure they don’t come across like monopolists. We “have to be sensitive about antitrust considerations,” Google Chief Economist Hal Varian wrote in a July 2003 memo, unearthed by government lawyers who are suing Alphabet. “We should be careful about what we say in both public and private.” One phrase to avoid, Varian said: “Cutting off their air supply.” He was referring to a quip used years earlier by then-Microsoft Corp Chief Executive Officer Steve Ballmer, when his company was under federal antitrust scrutiny. Another no-no, according to a 2009 Varian missive: “Market share.” Instead, when referring to Google’s portion of the search market, use the term “query share.” Penny Chu, the recipient of Varian’s email, responded in the affirmative. “Yes, absolutely.” Such instructions constitute “the one big thing I remember from all that Legal training,” Chu wrote, ending the sentence with a sideways smiley. The term “share” is a sensitive topic inside the ‘Plex. Google commands close to 90% of the market for search queries, and, as a result, it collects the majority of the revenue raised from ads situated alongside those results, data show. The Justice Department and a smattering of state attorneys general allege that Google struck unlawful agreements with other big tech companies, including Apple Inc., to give Google’s search tools prime real estate on the electronics, like smartphones, that people use every day. Those pacts prevented competitors including Microsoft and DuckDuckGo from gaining traction in search, government attorneys allege. Google’s attorneys deny that it has hampered competition, saying that consumers choose its search engine because its technology is superior. For decades, companies have urged workers to eschew phrases that could get them into hot water with authorities, create public relations embarrassments or otherwise reflect poorly on products. General Motors Co. employees, in a training session, were instructed to avoid terms including “decapitating,” “inferno” and “powder keg,” Time reported in 2014. References to “Challenger,” “Hindenburg” or the “Titanic,” were disallowed too, according to the presentation. Early on, Apple retail employees discussing customers' tech problems were discouraged from using terms “unfortunately,” “bug,” “crash,” or “hot,” according to reports in the Wall Street Journal and Gizmodo. Even if growing a search empire is perfectly legal, Googlers are instructed to avoid taking chances in any communications that might be saved, government lawyers say. Another internal presentation from March 2011, titled “Antitrust Basics for Search Team,” tells employees: Avoid discussions of “scale” and “network effects” We do not “leverage” anything We don’t “lock up” or “lock in” our users/partners We don’t “bundle” or “tie” products together Avoid metaphors involving wars or sports, winning or losing During the trial, Dintzer pressed Varian on the question of “antitrust training” at Google. When Varian said he couldn’t remember whether he’d taken it, Dintzer tried to jog his memory. “Avoid references to markets or market shares or dominance,” Dintzer said, citing an internal document. Varian was unmoved. “I may have had informal communication with lawyers about matters of law of this nature,” Varian said. “But I don’t specifically recall having a class in this subject.” —Tom Giles and Davey Alba The big story A hack of MGM casinos forced the company to take down some systems and throttled the betting world. Often, these cases go unreported. Caesars Entertainment paid millions to hackers in a recent attack. Get fully charged Adobe will undercut OpenAI on price for its image-generation tool. Microsoft’s tweaked army goggles worked well in a recent test, the US said. NSO spyware was used to hack an independent Russian journalist, researchers said. Intel rode a made-in-America stock wave to a big gain. Amazon put up $40 million through nonprofit partners to create affordable housing. A depression-treatment startup said it has implanted its device in two human skulls. More from Bloomberg Live event: The Bloomberg Technology Summit in London will host top technology leaders, business executives, innovators and entrepreneurs on Oct. 24. The event will explore the rapid advance of AI, green technology, the escalation of cyber warfare and more. Register here. Get Bloomberg Tech newsletters in your inbox: Cyber Bulletin for coverage of the shadow world of hackers and cyber-espionage Game On for reporting on the video game business Power On for Apple scoops, consumer tech news and more Screentime for a front-row seat to the collision of Hollywood and Silicon Valley Soundbite for reporting on podcasting, the music industry and audio trends Hyperdrive for expert insight into the future of cars — With assistance by Leah Nylen Get Alerts for: Tom Giles Davey Alba Most Read Chip Designer Arm Jumps 25% in Debut Win for Owner SoftBank Byron Allen Makes $10 Billion Bid for ABC, Other Disney Networks Ray Dalio Says He Doesn’t Want to Hold Bonds, Cash ‘Is Good’ ECB Delivers 10th Hike as Lagarde Won’t Quite Confirm Rate Peak China’s Property Market Crisis Is Trouble for the Whole World Terms of Service Do Not Sell or Share My Personal Information Trademarks Privacy Policy ©2023 Bloomberg L.P. All Rights Reserved Careers Made in NYC Advertise Ad Choices Help",
    "commentLink": "https://news.ycombinator.com/item?id=37509624",
    "commentBody": "Googlers told to avoid words like ‘share’ and ‘bundle,’ US saysHacker NewspastloginGooglers told to avoid words like ‘share’ and ‘bundle,’ US says (bloomberg.com) 261 points by mfiguiere 15 hours ago| hidepastfavorite324 comments archo 14 hours agohttps:&#x2F;&#x2F;archive.is&#x2F;XsDSf jsheller 14 hours agoprevFor things like this, Matt Levine is insightful:https:&#x2F;&#x2F;news.bloomberglaw.com&#x2F;securities-law&#x2F;matt-levines-mo...Summary is that not only can you not say things like \"lock up\" or \"market share\", you also can&#x27;t tell employees not to say those things or you&#x27;ll see headlines like the posted article and have the government claiming at trial that you&#x27;re trying to hide evidence. This feels kind of odd and kind of unfair. reply steveBK123 12 hours agoparentWell put another way - It&#x27;s one thing to tell your employees not to break the law. That&#x27;s good!It&#x27;s another thing to tell your employees not to use a bunch of words while doing their job which implicate the firm in breaking laws they&#x27;ve been accused of breaking. It&#x27;s almost like an admission of guilt or attempt to obfuscate.From a bank&#x2F;fund perspective - we get tons and tons of training about how we should not insider trade, money launder, etc. They have people who have gone to jail come give talks about how it&#x27;s not worth it, it was the biggest mistake of their lives, etc. Never ever, across half a dozen firms and 20 years, have I had training that was like \"so hey don&#x27;t use these terms that are used by insider traders because that would give the wrong impression when you are um.. doing your job and stuff..\".It&#x27;s stupid and hubristic. Just like the other stuff that came out of GOOG execs sending emails telling people not to put stuff in emails, lol. Cmon guys. reply caturopath 10 hours agorootparent> From a bank&#x2F;fund perspective - we get tons and tons of training about how we should not insider trade, money launder, etc. They have people who have gone to jail come give talks about how it&#x27;s not worth it, it was the biggest mistake of their lives, etc. Never ever, across half a dozen firms and 20 years, have I had training that was like \"so hey don&#x27;t use these terms that are used by insider traders because that would give the wrong impression when you are um.. doing your job and stuff..\".I got the same takeaway when I was at Google as when I was in the hedge fund space: be careful what you say, regulators and judges might not be very charitable. In both cases, the concept of something you say being in the New York Times was present for me.The Googlewide training and messaging when I was there did focus on not using anti-trust-triggering _language_ over the specific acts, but I don&#x27;t think it&#x27;s fair to interpret this as \"Violate anti-trust regulations\" but rather a recognition that the common fuck-up some random employee can make isn&#x27;t to commit a material anti-trust violation, but to provide nasty evidence by writing a puffy email about \"crushing the competition\". Telling people to write emails about \"making users happy\" rather than \"owning the market\" is not telling people to behave badly.I don&#x27;t know what you&#x27;re doing in finance, but it&#x27;s my understanding that folks who are actually involved in stuff where their job could look like insider trading probably do get subtler lines drawn than I ever sought (I was in systematic&#x2F;program trading.) Places where doing my job well could be confused for something bad, e.g., tax optimization, we did discuss how to properly communicate in order to avoid misunderstanding if a regulator, court, or journalist ever read our communication. reply steveBK123 8 hours agorootparentMy experience is that funds & staff that do have exposure to opportunities for insider info because they talk to outsiders like (brokers, company execs & IR, research providers, etc) actually get even brighter lines & rigid boxes around them.For example - all emails to above go through compliance first & include a disclaimer that you are a market participant and do not wish to receive MNPI. Meetings with above have compliance sit in, etc. People are urged to self report if someone does volunteer something stupid to you that they shouldn&#x27;t have, and then you sit out from trading it for some period, etc.They make it very clear that the upside&#x2F;downside risk is asymmetric. Hey maybe you can cheat and make 10% more this year. Or you can go to prison for 10 years, lose your home, have your wife leave you, and never work in the industry again. reply throwaway2037 3 hours agorootparentnext [–]you can go to prison for 10 yearsReally? I doubt it. Most insiders never get caught, and those that do get relatively small fines and sentences. Many sentences are suspended or deferred. Remember: To clawback (fine) insider trading, you need to clearly prove specific profits were gained via insider trading. It is insanely hard. Even when caught, it is a tiny fraction of their wealth.Raj Rajaratnam is one of the most notorious in the current generation. He only did 7.5 years. And Stephen Cohen had so many layers in his onion legal strategy that SEC could never nail him down. reply paganel 5 hours agorootparentprevIf you worked at Google and you weren’t aware that the whole thing (including your and your colleagues’ big comps) was built on capturing the online ad market then I don’t know how else people like you can be made to see that they worked for something at the limit of breaking the law.It’s like an investment banker back in 2006 saying that he was doing everything by the book, which he might of well have done, but the whole thing was crooked nevertheless. reply blindriver 11 hours agorootparentprev> Never ever, across half a dozen firms and 20 years, have I had training that was like \"so hey don&#x27;t use these terms that are used by insider traders because that would give the wrong impression when you are um.. doing your job and stuff..\".Well, I have.At a large well known tech company I used to work for, we were told not to use terms like \"killing our competitors\", \"smoking them\", etc. or any words that implied we had any dominance or monopoly in our industry. We even had a \"War Room\" undergo a name change. The reason is exactly the same as Google&#x27;s, where they were worried about reporters using it to twist narratives or in discovery by lawyers who came across emails. reply prepend 10 hours agorootparentWere you given training not to kill your competitors? Were you?I think my concern is that the important thing is not to do illegal things. If training focuses on just not sounding like you do illegal things instead of just not doing illegal things, that’s the problem. reply derefr 9 hours agorootparentI think the issue here is a corporate kind of mens rea. It’s seemingly fine under capitalism to incidentally kill your competitors in the process of making your customers happy. It’s not fine to set out with the explicit goal of killing your competitors. And so, any mention of your being aware that you’re killing your competitors, hints that you might be intentionally killing them while just feigning ignorance. reply blindriver 9 hours agorootparentExactly this. Even though we were engaging in regular competition, us simply mentioning that we wanted to \"kill them\" or \"wipe them out\" could be falsely construed as us trying to use illegal means to do so, which we weren&#x27;t.And that&#x27;s the point. Lawyers can twist things written in emails to be whatever they want. People who say \"if you&#x27;re not doing anything illegal, then you have nothing to hide\" has never been at the hands of a witch hunt. I have a friend who lived in the US on F1 and H1B for over 10 years and was banned from entering the US over jokes with her ex-bf about marrying for a green card. reply kuhaku22 1 hour agorootparent> I have a friend who lived in the US on F1 and H1B for over 10 years and was banned from entering the US over jokes with her ex-bf about marrying for a green card.That&#x27;s insane, especially after her being in the US for 10+ years and having established a life there. Sorry to go off-topic, but I have a friend whose SO is on a work visa and they have joked about the marrying for a green card thing before (a very common joke it seems). How did the government find out about the joke? (in-person, through texts, etc.) I ask because I wouldn&#x27;t want the same to happen to them and to caution them. reply eep_social 8 hours agorootparentprevYes. And discovery in these trials is performed via keyword matching so you have to assume that every email is going to end up on a giant projector screen in front of a jury who might not understand that Bob’s enthusiasm for destroying the competition is Bob’s quirky bombastic communication style rather than a business strategy. reply lstamour 4 hours agorootparent> And discovery in these trials is performed via keyword matchingDon’t worry, soon it’ll get done by AI instead and it’ll match on “acceptable” language too. reply thaumasiotes 9 hours agorootparentprev> It’s not fine to set out with the explicit goal of killing your competitors.What? That&#x27;s also fine. reply derefr 7 hours agorootparentI meant “in the implicit context of having successfully destroyed all your competitors [potentially by doing things other than just selling a better product, harder], and then being put on trial for anti-trust allegations.” reply thaumasiotes 9 hours agorootparentprev> If training focuses on just not sounding like you do illegal things instead of just not doing illegal things, that’s the problem.No, that isn&#x27;t the problem.The problem is that the difference between violating the law and not violating the law is whether you used what the court&#x2F;jury felt to be inappropriate language. \"Not sounding like you do illegal things\" is how you avoid violating the law. Your actions are less relevant than your commentary on those actions directed to your friends.That&#x27;s why the training focuses on using the right magic words and tabooing the wrong ones. The training is there to help you follow the law, no matter how stupid the law might be. reply naikrovek 7 hours agorootparent> \"Not sounding like you do illegal things\" is how you avoid violating the law.only if the regulators investigating you are complete morons, which may be the case once in a while, but I doubt it is for any large case like this one.regulators see straight through doublespeak and careful wording. buzzwords and corporate lingo are completely transparent to anyone who spends a single moment thinking about the message that the words are conveying, and regulators have far more experience cutting through that stuff than just about anyone else. reply twoodfin 8 minutes agorootparentIf you’re interested in this topic, I highly recommend watching David Boies interview Bill Gates for his deposition in Microsoft’s antitrust trial. The whole thing is on YouTube and it’s fascinating.They spend a lot of time parsing just what Gates and others on his executive team meant by things like “cut off [Netscape’s] air supply”.Regardless of who you think “wins” these exchanges, the government thought that putting Gates in a position where he had to explain this kind of language would be embarrassing and discrediting.It worked. Jensson 7 hours agorootparentprev> regulators see straight through doublespeak and careful wordingNo they don&#x27;t, Microsoft didn&#x27;t do this training and got nailed for bundling internet explorer with windows. Then Microsoft and all other big tech companies started to police words and look, no big anti trust like that has happened in US since. As long as Microsoft says \"we always open edge no matter the settings when you click links in our products to ensure the best customer experience\", instead of \"we always open edge to increase edge market share\", they wont get nailed in USA. reply jeffbee 7 hours agorootparentprevYou are not really engaging with these training materials in context. The entire point of the training is to not draw conclusions in areas in which you are not an expert, in discoverable media. For example, you are a software developer. Writing to your colleague that this change-list reduces an algorithm from quadratic to linear time complexity is within your wheelhouse. Posting on a mailing list that you think some other team&#x27;s product will crush the competition is not really within your domain, because you are not an economist. Drawing conclusions of law is the worst of all things to do because even though you&#x27;re just some idiot, those conclusions become discoverable and opposing council will put them on the record out of context even though you are just a Junior Associate Moron, not a person in a position to draw that conclusion. reply ffhhttt 31 minutes agorootparentSo executives, marketing people etc. can say that their products “will crush the competition” and that would be fine?> MoronNot so much because they might making some incorrect conclusions but because they don’t know when to keep their mouths shut. reply salawat 5 hours agorootparentprevNo one ever got busted for anti-trust violations by doing things that help support the competition.Describing something in terms of helping the competition while actually doing the opposite, will get you dunked on doubly so. If you think equivocation is they to doing illegal things, my dear poster, snap out of it and feel the Terra firma, because you&#x27;re so high, the FAA can do an airspeed check. replydataflow 10 hours agorootparentprevI can&#x27;t speak to this particular situation, but your argument has \"if you&#x27;ll had nothing to hide then you would have nothing to fear\" vibes. You don&#x27;t seem to account for the possibility of a situation where an entity is not guilty, but gets in trouble anyway because of someone&#x27;s words. reply steveBK123 9 hours agorootparentNo that&#x27;s not it at all. If they are concerned about monopoly allegations, they should give anti-monopolistic-practices training to staff. Instead they are giving anti-monopolistic-language training to staff.You may not believe it, but no financial firm I&#x27;ve ever worked for gave me training on \"don&#x27;t use insider training language\". All the training was emphatically that they did not want us to do it, it would destroy the company and destroy our lives explicitly. It was drilled into our heads with live talks, videos, handbooks, attestations, etc.This GOOG training seems to be like \"how to pass a sobriety test\" rather than \"don&#x27;t drunk drive\". reply jasonfarnon 8 hours agorootparentInsider trading and anti-trust violations aren&#x27;t comparable. It&#x27;s pretty easy to tell someone not to trade on insider knowledge, and it&#x27;s pretty easy for an employee with a little experience to tell when they are doing so. How do you tell employees not to engage in monopolistic behavior? Be less competitive? Don&#x27;t push out products that too many people will like? I would say the basic issue is that anti-trust laws are entirely subjective, enforcement is usually politically motivated. Given this subjectivity, it makes more sense to care about appearances rather than some ill-defined \"substance\". reply steveBK123 8 hours agorootparentAnti trust isn&#x27;t that opaque, it just hasn&#x27;t been actively prosecuted for the last few decades.There&#x27;s a ton of stuff that has been allowed to happen via consolidation, merger, or pure homegrown that simply hasn&#x27;t been prosecuted because recent administrations had an alternate theory that monopolies are OK if it benefits consumers via lower prices. Tech gives out a lot of stuff free or where its cost is hard to directly measure.Tech also enjoyed bipartisan support for the last 20 years or so, but that has completely flipped over the last 4 years or so. We will likely see a lot of this stuff is no longer ignored. reply AnthonyMouse 2 hours agorootparent> There&#x27;s a ton of stuff that has been allowed to happen via consolidation, merger, or pure homegrown that simply hasn&#x27;t been prosecuted because recent administrations had an alternate theory that monopolies are OK if it benefits consumers via lower prices.That&#x27;s not incompatible with violations in other circumstances. For example, Google releases Android for free, resulting in low prices for mobile operating systems. Competing operating systems may be put out of business, but customers benefit from lower prices and this should be fine if anyone can still choose to use a competing OS -- or fork of Android -- should they prefer it.Whereas, Google uses tying to its dominant services to ensure that Google Play is the only viable app store on Android, then takes a 30% cut. High margins don&#x27;t result in lower prices and neither does excluding competitors who might take a smaller cut, so they should be slapped down for this.Google adds remote attestation and encourages third parties to rely on it even though it makes third party apps dependent on Google&#x27;s version of the system, creating a barrier to entry for forks or competitors. This kind of thing should be prohibited, because otherwise people are not choosing Google&#x27;s offering because it provides the best value for money, they&#x27;re choosing it because Google manufactured a way to shut out competitors who might do better.The theory isn&#x27;t the problem. Taking a competitor&#x27;s market share because customers choose your product for having a better price is not bad. The bad is making it harder for customers to choose competing alternatives they might actually prefer.The problem is the application. The company comes up with some claim that their anti-competitive moat is there to benefit customers by providing security etc. and get away with it even though it doesn&#x27;t really provide security or there are viable alternatives that provide security without restricting competition. reply jasonfarnon 8 hours agorootparentprevIn saying that different administration priorities and changes in political support for tech drive anti-trust actions you are making my point (which I maybe didn&#x27;t make clear). That kind of arbitrariness means firm&#x27;s counsel can&#x27;t say \"don&#x27;t do X\" like you want them to. Because \"X\" shifts. It also means counsel sensibly focuses on appearances, since appearances can be the main driver of political support. reply AnthonyMouse 2 hours agorootparentprev> How do you tell employees not to engage in monopolistic behavior? Be less competitive? Don&#x27;t push out products that too many people will like?A good start would be don&#x27;t do things that create friction for a customer who wants to choose a competitor&#x27;s product instead of yours. reply dataflow 8 hours agorootparentprevAgain, this isn&#x27;t a comment on the merits of Google&#x27;s case in particular. I&#x27;m not supporting what they&#x27;re alleged to have done here, nor claiming they&#x27;ve been angels all around. What I&#x27;m saying is \"they told people to not use risky language\" isn&#x27;t necessarily a sign that they were guilty or doing something illegal, just like it isn&#x27;t with everyday folks. Because prudent people will care about language either way, because they know it can get them in trouble regardless.With that said...> You may not believe it, but no financial firm I&#x27;ve ever worked for gave me training on \"don&#x27;t use insider training language\"These are apples and oranges. You may not believe it either, but I don&#x27;t think Google tells anyone \"don&#x27;t use insider trading language\" either. That&#x27;s the apples-to-apples comparison.AFAIK being a monopoly is a corporate civil matter, not a (strictly personal?) criminal one like insider trading. Expecting people to treat them the same way and claiming they&#x27;re guilty if they don&#x27;t makes no sense. reply ffhhttt 27 minutes agorootparentprevThere is very little non-executive level employees can do to engage or not engage in monopolistic practices. All the decisions that lead to that are generally taken way above so such training would be pretty useless. Insider trading is very different in that regard because it’s something individuals can engage in and (usually) not the outcome of corporate strategy. reply Affric 4 hours agorootparentprevThis is a cultural issue in tech:“Politicians and regulators are always playing catch up. They are so dumb. We are creating the future” - some tech broThey don’t take society seriously. They don’t take the law seriously. At best they aren’t thinking about what they are saying. At worst they feel they are justified.Treat the law seriously. Don’t break the law. If you do those two things you will not need to send memos around to get people to use phrases which regulators will grep your comms and transcripts for. reply 1vuio0pswjnm7 8 hours agorootparentprev\"First, Google wants to withhold from the public internal emails from more than 10 and up to 15 years ago. See Sept. 1, 2023 Hrg Tr. at 62-63, 65. DCN is highly skeptical that communications over a decade old could possibly interfere with Googles competitive business today and in the future. These emails would instead inform the public and press about practices that led to the government filing suit.Second, Google wants to withhold from the public certain provisions of its standard agreements, including definitions contained in such agreements, many of which were signed more than ten years ago. Id. at 56, 65-69. These agreements and definitions are foundational to the publics understanding of how Google established its dominant market position.Third, Google wants to clear the courtroom during the overwhelming majority of Googles examination of Apple witnesses, which could span several days. Id. at 69-70. There is substantial public interest in Googles deal with Apple and the termination of the agreement. There does not appear to be any good reason to close the trial completely for this testimony other than to shield Google and Apple from potential embarrassment.\"https:&#x2F;&#x2F;ia902501.us.archive.org&#x2F;21&#x2F;items&#x2F;gov.uscourts.dcd.22... reply bryanrasmussen 4 hours agorootparentprev>From a bank&#x2F;fund perspectiveFrom a consulted a bank perspective - I noticed that the examples were pretty darn intuitive that hey this is obviously illegal but for some reason they wanted to have people sit through a multiple choice form and 45 minute tutorial on banking ethics to make sure nobody did it, and also that one of the negative outcomes that was mentioned in breaking the code of ethics was that the bank would experience problems in the media that would make the whole thing which seemed like a good idea not worth it. reply marcosdumay 7 hours agorootparentprevOn the other hand, the Law should care only if your actions broke it, and not what kind of things you told somebody. (And if you exploited your monopoly completely by chance and got a couple of billions out of it, too bad, you are guilty anyway.)But until we have that, people will keep studying what they can and can&#x27;t say. reply Closi 11 hours agorootparentprevReally good comparison! Imagine…“Rather than use words like ‘insider trading’ we should say ‘based on market research’” reply shadowgovt 11 hours agorootparentprevThat&#x27;s certainly the legal theory that the DOJ is going to push.The counter argument that I&#x27;m sure Google will bring to the table is that (a) that advice was given in the context of helping engineers understand that legal definitions and vernacular definitions are different, and it is the nature of adversarial court systems that words they think they&#x27;re using with one meeting can be taken out of context by an opponent in a court case, so think about what they are saying, and (b) all of the above is just facts and the government suppressing a corporation&#x27;s right to state facts would be a clear and obvious violation of the First Amendment.But these are two legal arguments and it&#x27;s hard to predict how the court will decide. reply sdwr 7 hours agorootparentprev> From a bank&#x2F;fund perspective - we get tons and tons of training about how we should not insider trade, money launder, etc. They have people who have gone to jail come give talks about how it&#x27;s not worth it, it was the biggest mistake of their lives, etc.Not to be paranoid, but that&#x27;s also how a bank that wanted people to insider trade would act. The idea is, you see the people who got caught, learn what they get caught for, and carve the apple just a little bit less than they did.A principled (naive) person imbibes the meaning \"Don&#x27;t do bad stuff\", and an ambitious (sociopathic) person learns how to do it and what gets caught. reply fnordpiglet 12 hours agoparentprevI was a senior person at a company best remaining nameless that trained all new executives to never use the words “monopoly,” “fix prices,” “dictate prices,” despite the fact we had a required pricing schedule for retailers, bought back all excess inventory at cost to prevent a grey market, and dropped retailers that ran promotions. Their products were never on sale and accounted for 80% of retailers revenues, and they controlled 75% of their market segment. Whenever a new upstart brand came along they simply acquired them. Everyone sold their brands because it was known unless you were owned by this company you had no long term future in the market.These sorts of market controlling companies are weird to work for. On the one hand they have a certain excellence that keeps their market lock year over year. On the other there’s a strangulating incestuous monoculture that self perpetuates a view of brilliance. You see this internally at other companies with these locks - google for one, googlers, especially hey day googlers, walk out with an ego the size of their market share. I’ve scrupulously avoided working there despite many chances over the years because of the smugness - not that I couldn’t work with that environment, I’m afraid I would adopt it as well. reply throw__away7391 9 hours agorootparent> an ego the size of their market shareOh man, I worked for a long time on the east coast in industries that didn&#x27;t give me much exposure to startups during the 90s-00s, so one day I met an ex-Google developer at a meetup who dropped into the conversation that he once worked for Google and then waited for me to be impressed. It was a long awkward wait because I didn&#x27;t realize at the time that that was supposed to impress me, and instead just said something like \"oh cool\" and the conversation just abruptly stopped in the weirdest way you can imagine. reply throwmeout123 12 hours agorootparentprevWould it be possible to identify those companies and then build new companies just to be acquired? Nice chunk of change every 3 years… reply fnordpiglet 1 hour agorootparentIt’s not obvious to me. “Make a compelling product that speaks to an unfulfilled desire with pitch perfect marketing, relentless quality, and flawless execution” seems to be what differentiates who we acquired. There were a lot of startup brands and only a few were acquired in my time. Most just died. reply discodave 6 hours agorootparentprevThis is what many &#x27;serial entrepeneurs&#x27; already do. reply throwmeout123 3 hours agorootparentAnd what is their algorithm? How to identify those industries? reply ars 12 hours agorootparentprevResMed and Luxottica are like that. Luxottica is a straight up abusive monopoly - they actually sell the insurance that they themselves take!ResMed simply has better technology than others, and is a de-facto monopoly. reply deepsun 12 hours agorootparentYes, but there&#x27;s also a problem is customers really believe it&#x27;s worth paying $300 for the simplest type of near-vision glasses in 2023. And they&#x27;re ready to pay for that, so why not take their money? reply Firmwarrior 12 hours agorootparentIt&#x27;s so nuts that Facebook was able to put a computer and cameras into sunglasses without increasing the pricePrescription glasses are basically just chunks of not-too-special plastic that you can buy online for $20 or less, but people refuse to believe that the whole industry is a scam when I try to tell them about it reply nostromo 11 hours agorootparentIt&#x27;s because of insurance.Anything insurance touches becomes expensive, because insured individuals are no longer price sensitive, so there is no incentive to lower costs by providers.My employer pays for my vision insurance, whether I want it or not, so I may as well maximize the benefit with the \"best\" hardware I can get for \"free.\" reply lotsofpulp 11 hours agorootparentYour employer offers it, and you use it, because the government specifically carved out a tax exemption for it. Without the tax benefit, there would not be much reason for an employer to provide you vision insurance rather than the equivalent cash. reply deepsun 10 hours agorootparentprevI set up the vision health plan for my company, and you can certainly waive that (and save some out-of-pocket $$ as well, as employer cannot pay 100% of the insurance, ot at least I couldn&#x27;t find a 100% option).And buy the glasses at Zenni et al. reply waynesonfire 9 hours agorootparentprevWhat about thr crop insurance program? reply pyuser583 10 hours agorootparentprevThe $20 glasses increase in price sharply when you add vague “nice-to-haves” like blue light filtering.Likewise, store bought lenses are available with $20 out of pocket expenses. reply NavinF 12 hours agorootparentprevThat&#x27;s because those $20 glasses are objectively worse than $200 Costco glasses. You might not think that the latter is worth the increased price, but for the vast majority of Americans it is.Btw Zeiss (known to HNers for making EUV lithography hardware) also makes glasses and you can buy them online. Some of their lenses are $700. Not worth it for me, but I can definitely see how someone would be willing to pay even more for those optical specs reply Xamayon 9 hours agorootparentThe $30-50 zenni glasses&#x2F;lenses in my experience are actually substantially clearer than the (absolute ripoff) $400-500 rayban ones. Same prescription, and the zenni ones even arrived quicker! Frame consistency is a bit of an issue though, I bought a few more cheap pairs with the &#x27;same&#x27; frame a few years later and they changed the design subtly which made them fit worse. reply throwmeout123 12 hours agorootparentprevI have zeiss lenses on my glasses, they’re terrible. Full of scratches in 1.5 years. Worst money I’ve ever spent, my last no name €80 lenses went for years without a single scratch! Anecdata obviously reply Firmwarrior 9 hours agorootparentI&#x27;ve been wearing nothing but Zenni glasses for a decade, and they&#x27;ve been excellent the whole timeYou can choose the material you put into them. Ray-Ban Scamglasses from the Scam Shop are definitely NOT better. Even Costco glasses aren&#x27;t better. reply zx8080 10 hours agorootparentprevThey probably did not come with scratches, did they?Don&#x27;t scratch them. It&#x27;s simple as that. Wash lens with soap. It&#x27;s as simple as that. reply Dylan16807 8 hours agorootparentWhat, do you think they scratched them on purpose? Avoiding scratching for thousands of hours isn&#x27;t actually simple, and if some brand is less scratchable then that&#x27;s a real benefit. reply jjgreen 1 hour agorootparentprevOr get glasses made with ... glass? reply NavinF 11 hours agorootparentprevWhat model? High index or polycarbonate? reply throwmeout123 11 hours agorootparentI have no idea, but i can copy some data from the package:One is SV AS +2.5 sphere 0 cyl duravision platinum uv 1.60 index (guess this is what you’re talking about) uvprotectThe other is the same but 1.25 sphereHope it helps reply dharmab 3 hours agorootparentprevZenni&#x27;s men&#x27;s glasses are much higher quality than any of the expensive glasses I&#x27;ve tried. I don&#x27;t know if it&#x27;s different for women&#x27;s glasses. reply deepsun 10 hours agorootparentprevI bought mine for $50 years ago and they are perfect. \"Objectively\" better I would say. reply lotsofpulp 12 hours agorootparentprev> Luxottica is a straight up abusive monopoly - they actually sell the insurance that they themselves take!What is wrong with this? Apple does it, lots of managed healthcare organizations like Kaiser Permanente and UnitedHealth and CVS do it, auto manufacturers do it, etc. reply ars 11 hours agorootparentIt&#x27;s not actually insurance, it&#x27;s a payment plan. Insurance is meant to cover unexpected events, with this you pay a monthly fee for \"insurance\" which gives you the right to buy the glasses later for a normal price.The other companies you mention are actual insurance: They cover rare, and unexpected events. As opposed to covering once every two year glasses, on a schedule. reply lotsofpulp 11 hours agorootparentThen what is wrong with a business offering a payment plan? reply Retric 10 hours agorootparentThe deception. False advertising is a crime for good reason. reply lotsofpulp 10 hours agorootparentWhat is the deception? reply Retric 7 hours agorootparentCalling it insurance rather than a payment plan or something.Further it’s got some serious conflict of interest going on with how the benefits are structured. So a plan may cover 1 300$ par of glasses, but not 2 pairs of 150$ glasses specifically to minimize the risk of a race to the bottom etc. reply ars 7 hours agorootparentprevThe deception is that glasses cost a lot, and you need insurance to help with the cost.In truth the insurance is just a scam because glasses cost 1&#x2F;10th what they say.Now that would be OK if there was actual competition, but there isn&#x27;t, they are basically a monopoly - as soon as a competitor arises they buy them.Online glasses are not the same market as a physical store where you can try them on. reply lotsofpulp 7 hours agorootparentEveryone who goes to Walmart (majority of the US?) sees this section at the front of the store when they walk in or out:https:&#x2F;&#x2F;www.walmart.com&#x2F;browse&#x2F;health-medicine&#x2F;prescription-...I see lots of $30 and $60 options.The insurance is only a thing because the tax code allows it as a way for employers to pay people with untaxable money in the form of insurance, so it is not a real insurance market. reply ars 10 hours agorootparentprevBecause you end up paying around 50 times as much as what the glasses actually cost.But because of how they do it they hide that. $40&#x2F;month for 2 years = $960 \"for insurance\" which gives you the right to buy glasses worth around $20 or so.All the number are inflated leaving people with the impression that glasses cost $400 - they don&#x27;t. reply lotsofpulp 10 hours agorootparentSo now we are talking about profit margins being bad?We have the internet now, with plenty of other vendors willing to sell eyeglass frames and lenses for cheaper. reply Dylan16807 8 hours agorootparentProfit margins that make a price more than double are pretty bad, yeah.High profit margins are also bad when it&#x27;s something people need.The competition isn&#x27;t working right, for a variety of reasons, and so the mere existence of competition does not make those problems disappear. reply lotsofpulp 8 hours agorootparentHow is the competition not working right?https:&#x2F;&#x2F;www.zennioptical.com&#x2F;Pretty sure you can go to most Walmarts and find much cheaper corrective eyewear than Luxxotica too.https:&#x2F;&#x2F;www.walmart.com&#x2F;browse&#x2F;health-medicine&#x2F;prescription-... reply Dylan16807 8 hours agorootparentThe average person doesn&#x27;t consider them to be a viable option. Don&#x27;t ask me why, but it&#x27;s true. And them being considered a viable option is a prerequisite to competition working right. reply lotsofpulp 7 hours agorootparentThe average person (at least in the US) does not consider the world’s largest retailer, with a well known reputation for being the cheapest, an option? I don’t buy that. reply ars 7 hours agorootparentThat WalMart link is to decorative glasses, not prescription glasses.So here&#x27;s the thing with WalMart and Luxottica - their insurance does not fully cover WalMart! They give you a significantly reduced amount with WalMart (or Costco), that&#x27;s how you know it&#x27;s fraudulent - they only want to cover their own stores, that&#x27;s not a normal behavior for \"insurance\". reply Clubber 12 hours agorootparentprev>On the one hand they have a certain excellence that keeps their market lock year over year.Would it be unreasonable to say a lot of potential excellence isn&#x27;t actualized because:>Whenever a new upstart brand came along they simply acquired them.and they don&#x27;t ever actually compete with a near peer? reply fnordpiglet 12 hours agorootparentI’d say they do a good job of acquiring and learning and teaching. When they take on a brand they don’t subsume them but let them be fairly autonomous, but take on certain commoditized aspects such as supply chain, distribution, and marketing placement. The core of the brand stays independent and some of the learning of that brand comes back into the core company. They also are very self critical and internally striving. But, yes, they could certainly be better and healthy competition would help. reply lazide 13 hours agoparentprev“Anything you say can and will be used against you.”It’s not just a warning, it’s reality, as you’re seeing play out here.Legal opponents will use whatever they can get ahold of. At a certain scale, it’s guaranteed you’ll have legal opponents - often constantly! - no matter what you do. Though some courses of action will certainly result in more of them!The question is, is it better or worse than the alternative? And how likely is it to actually cause you harm?Because I’m pretty sure a bunch of emails saying “We’re going to crush x by locking up the market.” would be worse. We’ll see how this plays out though! reply onlyrealcuzzo 14 hours agorootparentI suspect if you&#x27;re under investigation for abusing monopoly power and you tell your employees not to use phrases like \"We&#x27;ll crush the competition\" and instead talk about how \"You&#x27;ll try to maintain a competitive environment while doing your best to excel\" it&#x27;s probably better than your legal opponents finding evidence that people in your company are constantly talking about abusing their power to \"crush the competition\".I guess we&#x27;ll get an idea by the result of this lawsuit. reply roenxi 12 hours agorootparentI&#x27;m still suspicious of the idea that Google can have a monopoly anywhere except maybe in the Android ecosystem. It is too easy to move away from their products and go use something else. Nobody is under any pressure to use Google&#x27;s search. Literally Google \"alternatives to google search\" and get a list of reasonable alternatives. If they have outstanding market share it is because they are just better, not because they have a monopoly [0].But the problem I&#x27;m looking at here is the phrase \"...you&#x27;re under investigation for abusing monopoly power...\" anticipates the result to some degree. This is a an exhaustive list of the guidance lawyers can provide. Both seem to anticipate that some wrongdoing has been done. It leads to shallow thinking:... you&#x27;re under investigation for abusing monopoly power and lawyers tell employees not to use phrases like \"We&#x27;ll crush the competition\".... you&#x27;re under investigation for abusing monopoly power and lawyers provide no guidance, then employees use phrases like \"We&#x27;ll crush the competition\".Most of the work is actually being done by the initial frame, not what the employees are told.[0] I wouldn&#x27;t know, I don&#x27;t use Google search. reply AlphaSite 12 hours agorootparentGoogle used the search monopoly to grow chrome into another monopoly, placing it on their front page, a place where absolutely no one else can ever get advertising. reply roenxi 12 hours agorootparentChrome&#x27;s engine is open source, and there is literally nothing stopping someone from installing Brave, Firefox or Opera. They all render the same pages and are all standards compliant enough.Did Google give Chrome a boost? Yes. Was that a good thing? Also yes. Chrome was the better browser at the time they did that - still arguably is. But that doesn&#x27;t mean monopolies are involved. Apple gives privileged advertising to the iPhone, iPod and iPad on their website and they aren&#x27;t a monopoly in any sense.Google is arguably less of a monopoly in pushing Chrome because they sell advertising to other people. I&#x27;m sure Samsung would pay an absurd amount of money to get an ad on apple.com with any URL path. In theory Google could be a monopoly and put a chrome ad on google.com but the fact is that they aren&#x27;t a monopoly and pushing chrome did good for the world, not harm. They&#x27;re just providing exceptional products and people trust the brand [0].[0] Trusting brands in software is silly. reply Cheezewheel 10 hours agorootparentNothing that you said addressed what the person above you wrote. reply roenxi 9 hours agorootparentroenxi: \"Google doesn&#x27;t have a monopoly. [argument]\"AlphaSite: \"Google has a monopoly and used it to build a second monopoly [argument]\"There isn&#x27;t much there to address. But I did directly address it.(1) He claimed that Google had a monopoly, I ignored that because I&#x27;d addressed that in my original comment.(2) He claimed that Chrome had a monopoly. I provided an argument that it wasn&#x27;t (it is really easy not to use Chrome. You give up literally nothing switching to Brave for example).(3) He claimed that Googe used monopoly tactics to build Chrome&#x27;s market share. I provided a counterexample that the tactics used aren&#x27;t monopoly tactics because other companies do more or less the same thing. Advertising your own products on your own site isn&#x27;t monopoly behaviour. And even if Google was a monopoly and that is monopoly behavior - both of which I don&#x27;t think are true - that isn&#x27;t exactly an abuse of monopoly power, it is pretty tame.It&#x27;d be helpful for me if you pointed out why you don&#x27;t think that is addressing the comment. It seemed pretty direct to me. reply jasonfarnon 8 hours agorootparentprevWhy wasn&#x27;t it OK for MS to give Explorer a boost? reply roenxi 1 hour agorootparent* Internet Explorer came bundled with the OS and therefore had a leg up on the competition. They made it impossible to remove that browser, so people targeting Windows would likely also automatically target IE in the knowledge that it would be available on the system.* Microsoft controlled the Windows API and appeared to be sabotaging attempts to build cross-platform applications. And they seemed to think it was substantial interference. Take this for example:\"Microsoft&#x27;s videotape showed the process as being quick and easy, resulting in the Netscape icon appearing on the user&#x27;s desktop. The government produced its own videotape of the same process, revealing that Microsoft&#x27;s videotape had conveniently removed a long and complex part of the procedure and that the Netscape icon was not placed on the desktop, requiring a user to search for it. Brad Chase, a Microsoft vice president, verified the government&#x27;s tape and conceded that Microsoft&#x27;s own tape was falsified.\" [0]If MS had restricted itself to a banner on their website saying \"Download and Install IE!\" they&#x27;d have been fine; the issue was that they were creating an environment to destroy Netscape for no good technical reason, they just wanted to destroy Netscape. And that was part of a pattern of behaviour where they were employing consistent tactics against anyone trying to create cross-platform software.[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;United_States_v._Microsoft_Cor.... reply ffhhttt 16 minutes agorootparent> Internet Explorer came bundled with the OS and therefore had a leg up on the competition.Isn’t Google doing the same by making their search engine default on Chrome, Android and even by paying Apple billions to make the default on Safari?paulddraper 12 hours agorootparentprevChrome defaults to Google Search.ChromeOS comes with a bundled browser, the big no-no that cost Microsoft. reply roenxi 12 hours agorootparentAre you suggesting that ChromeOS of all things has a monopoly position in the market?I&#x27;m happy to be proven wrong if the year of the Linux desktop has finally come! reply q7xvh97o2pDhNrh 10 hours agorootparent> if the year of the Linux desktop has finally comeNo, I think that&#x27;s next year. ;) reply TylerE 12 hours agorootparentprevWindows had about 90% consumer market share at that point. ChromeOS… doesn’t. reply scarface_74 11 hours agorootparentprevChromeOS is like 3% of the market. reply peyton 12 hours agorootparentprevIt’s an ad company. Good luck running a local plumbing business without forking over 10% to the big GOOG. reply jrockway 13 hours agorootparentprevThis is kind of what&#x27;s sad at working at a big company. If the same team was doing the same work at a startup, every one of their meetings can be \"this feature will kill the competition\". Personally I think it&#x27;s a great attitude; if your technology is better than everyone else, you deserve to put them out of business. And you&#x27;re certainly entitled to try. (And, sometimes ideas do kill their industry. Called someone on your landline recently? Bought a DVD at the store? Listened to music on a Walkman? It happens.)The devil is always in the details. If you kill the US steel industry by being a government that pays people to buy steel from your country, that&#x27;s problematic. If you just make shit and people like it, though, that should never be illegal. reply pyrale 13 hours agorootparent> if your technology is better than everyone else, you deserve to put them out of business.The issue is that, once you reach Google scale, you have so many tools to put the competition out of business that are unrelated to product fit. And, in the case of Google, they&#x27;ve been known to do just that.So yeah, you can&#x27;t really compare an incumbent with monopoly power to an underdog, just like some sentences from young kids are hilarious, that would be chilling if adults said them. reply spywaregorilla 13 hours agorootparentprevIt is not problematic to put people out of business by having a superior product. It is problematic to abuse the fact that you have more money, connections, lawyers, political power, market control, customer interaction control, etc. reply GauntletWizard 12 hours agorootparentAbsolutely, and the fact that our lawmakers cannot distinguish the two, and rely on fighting the last war with dumb heuristics based on phraseology is a real social problem. reply ryandrake 13 hours agorootparentprev> Personally I think it&#x27;s a great attitude; if your technology is better than everyone else, you deserve to put them out of business.I think this \"Others must lose so that I win\" attitude is one of the more toxic attributes of this Thunderdome Capitalism so many industries have somehow ended up in. Wouldn&#x27;t it be great if we could have dozens of businesses all successful, all doing \"somewhat good\" rather than having to always have a small number of winners that take everything?If I&#x27;m going to open a laundromat a block away from Paul&#x27;s competing laundromat, I&#x27;m not doing it to try to put Paul out of business. I&#x27;m just trying to capture enough business so that we can coexist comfortably. Some entrepreneurs just don&#x27;t know the meaning of the word \"enough\". reply jrockway 12 hours agorootparentI&#x27;m not sure how applicable this is to software. If you&#x27;re making nails or something, then sure, your factory can only turn so many tons of coiled steel into nails per day. So other companies can exist that also make nails. In software, it&#x27;s a little different; you moving a billion copies doesn&#x27;t necessarily take any more work than selling one copy, so even if you \"want to leave enough for everyone\", you might not be able to. I doubt the Chrome team was saying things like \"we shouldn&#x27;t add tabs, that would be so bad for Internet Explorer\". reply lazide 9 hours agorootparentUh, Standard Oil?Antitrust has a long history and it has nothing to do with tech. reply thegrimmest 11 hours agorootparentprevBut if your laundromat is better in some way (service, cost, marketing), why wouldn&#x27;t you want to grow? And if the market is a fixed size, (which just about every market is) doesn&#x27;t that inevitably result in Paul adapting to keep up or closing down? When did it become immoral to realize this and strive for it? In this scenario everyone besides Paul benefits. And so it will be when you become the incumbent and face a competitor with a similar edge.In Google&#x27;s case, I suspect \"search\" will die to AI like Blackberries died to iPhones. Google is already proving that its size and bureaucratic unwieldiness are major obstacles to its competing in the AI space. Would we really hold back the vast social benefits of this progress because we object to some people becoming obscenely wealthy? reply tyg13 8 hours agorootparentI feel like this comment exists in a capitalist fairy tale where the only way a business could grow to overtake its competitors is by being better for consumers. Or where a business that has done so will always continue to do so once it has achieved market dominance.> But if your laundromat is better in some way (service, cost, marketing), why wouldn&#x27;t you want to grow?Maybe you just want to run a laundromat? Is that not enough these days? reply thegrimmest 8 hours agorootparentI mean, in the medium term, isn&#x27;t this exactly how it goes? Aren&#x27;t current incumbents relatively recent, and didn&#x27;t they get there by being substantially better than their competition (Amazon, Google, Apple, Uber) or creating an entirely new business model (Facebook, Twitter). Isn&#x27;t the dominant position that these companies enjoy only as fragile as the continued use of their product? If everyone switches to OpenAI for their search needs, Google will have a hard time surviving.> Maybe you just want to run a laundromat? Is that not enough these days?It&#x27;s enough, until someone comes up with something that disrupts the industry. In a fast-evolving world, standing still is a doomed strategy. Do you really want to be the bookseller when Amazon comes along? Or the taxi driver competing with Uber? or on the board of RIM watching the Apple keynote in 2007?Edit: Come to think of it, this rather parallels the natural world. Very few creatures have been able to stay relatively unchanged for tens of millions of years. They have been able to do so because the niche the evolved to optimally fill has remained unchanged and undisrupted. The rest of the natural world undergoes constant churn as new species emerge and others go extinct. It&#x27;s the same in business. The less likely your niche is to be disrupted the more insulated you&#x27;ll be from the necessity to change (assuming you&#x27;ve optimally adapted). Prime examples are best-in-class restaurants, whose proprietors often do just about the same thing their entire lives very successfully. reply fiddlerwoaroof 13 hours agorootparentprevI think the “winner takes all” attitude is the problem. It’s perfectly fine to run a tech company with a limited market but it doesn’t generate the spectacular returns current investors are looking for. reply lazide 13 hours agorootparentprevThat depends entirely on the details of how it is said.If it is said in a way clearly making it obvious that not just the words, but the intent is bad, and to instead do the other thing? Seems likely to not be an issue.If it is saying the intent is fine, just use the other words? Then yeah.If it gets to the press, chances are it’s being spun the opposite way that context would show it was being used, because that’s how it usually works to get clicks. reply AnonymousC123 14 hours agorootparentprevI suspect in the future all employee education on law will have a lawyer present who marks the discussion as client attorney priviledged.It is weird that the legal system has developed where absolutely all communication except that which has lawyers can be discovered in court. Almost like a guild support it&#x27;s members. But if that&#x27;s the way it is so be it.Everything will now be feature more lawyers and education on law will be client attorney privileged. reply woodruffw 13 hours agorootparentThat sounds weird because it isn’t how it works. The courts take a dim view of clients who attempt to abuse attorney-client privilege by putting all communications under it.(A good heuristic for legal reasoning is that anything that sounds like a “one weird trick to avoid getting prosecuted” listicle item has already been picked clean by the courts.) reply majormajor 13 hours agorootparentprev\"Facts can&#x27;t be privileged\" is how one lawyer at a place I worked with put it, regarding attempted tricks like this. Only specific discussions asking for counsel can be. So as far as I understand what could be protected in something like this training case: questions about how to make the training? Sure. The training itself? Nope. reply esrauch 10 hours agorootparentIt&#x27;s hard to see the line here: if a lawyer has a 1:1 meeting with someone and tells them that using certain terms can be legally risky that&#x27;s protected? If he has a group meeting with 10 execs to advise the same? One lawyer gives the same advice to 100 people, 1000 people, 10000 people what is the number of people receiving the information where verbatim the exact same conversation isn&#x27;t legally protected anymore? reply lazide 6 hours agorootparentAre the people having direct conversations with the lawyer, where they ask for legal advice on an issue?Then it’s covered.If they aren’t, it’s not.10 execs? Maybe. If they’re all involved in the same thing and all asking for advice. Seems unlikely to actually be the case though. So probably not.100 folks listening to a presentation? Definitely not covered. reply abduhl 2 hours agorootparentThis is a weird way to view the test. The conversation is privileged if the conversation includes the provision (or seeking) of legal advice from the lawyer to (by) their client. That means that the contents of the conversation cannot be forced to be divulged; however, if the conversation is about a specific event and the legal impacts of that it doesn’t bring the facts of that event under the privilege.“Joey said that we can kill the competition with this new feature, is that going to be a problem for us from an antitrust perspective?”Privileged: whether or not that is going to be a problem from an antitrust perspectiveNon-privileged: Joey said that we can kill the competition with this new featureThe number of people is irrelevant except as a gauge for whether or not legal advice is actually being provided. If you were to cc an entire department on an email to your counsel with the above question it wouldn’t change the analysis. Recall that in the corporate context the corporation is the client and employees are the corporation’s agents. Whether 1 or 100 employees, it’s the same corporation.What should be the “correct” answer legally is that, if the lawyer is providing the training, it should be privileged regardless of how often it occurs or how many people are trained. The potential catch here is that you can’t use privilege to protect conversations where you’re telling people how to commit a crime, and teaching hundreds of people how not to lose antitrust buzzword bingo starts to look suspiciously like telling (or even helping) your client (the corporation) how to get away with a crime. reply lazide 14 hours agorootparentprevClient &#x2F;attorney privilege doesn’t work that way. :(But frankly, all the G stuff was with attorney guidance and well vetted. It already had what you’re trying to get to the best of the very well paid attorney’s ability. reply dudus 13 hours agorootparentprevNot only that but someone once told me to write the following before any email communications: \"-- ATTORNEY CLIENT PRIVILEGED --\"They explained to me this allowed us to communicate without fear our discussion can be misquoted and miscategorized in the future.EDIT: To clarify that was something I needed to add when talking with legal. Not something magic that works for everyone.So besides being in good standing with a member of their guild you also have to preface your communication with their religious texts. \\s reply jstarfish 13 hours agorootparent> Not only that but someone once told me to write the following before any email communications:That only applies when corresponding with counsel, and even there in limited circumstances (not everything can be privileged). If no attorney is addressed, it cannot be privileged.IIRC, applying the label arbitrarily risks all correspondence being made discoverable. reply checkyoursudo 13 hours agorootparentprevThis does not grant privilege to communications, just so people are aware. reply morelisp 12 hours agorootparentprevTo be legally binding it needs to be -----BEGIN ATTORNEY&#x2F;CLIENT PRIVILEGED BLOCK----- reply ketralnis 12 hours agorootparentand if you never end the block everything you do is safe from now on. Judges don&#x27;t want you to know this one weird trick reply gowld 12 hours agorootparentprevNever write the END block. Infinite privilege glitch! reply dekhn 9 hours agorootparentprevThis doesn&#x27;t work if you&#x27;re discussing something that&#x27;s illegal. reply happytiger 13 hours agorootparentprevIt’s much more insidious. It will necessitate a surveillance AI on all interactions to eliminate legal liability. That is absolutely inevitable. reply AnonymousC123 13 hours agorootparentOhh that&#x27;s a good idea.If I&#x27;m understanding this correctly you proactively filter comms through an AI. If it detects you said something that could be interpreted a certain way the communication isn&#x27;t sent and the user is told to be more careful in their phrasing?That&#x27;s pretty brilliant to be honest. Except maybe the discovery will then be on what the AI filter was instructed to prevent as if that&#x27;s an admission of guilt. reply happytiger 11 hours agorootparentThere’s always a double jeopardy in legal monitoring. You have to adjudicate the risk of appearance in discovery and trial against the original risk you sought to moderate.I absolutely think this is a good startup idea, and have been pondering building out a prototype.I don’t love it, but in so many ways when you sit down and look at the alternative to it that isn’t tearing down or radically altering the existing legal system, it’s actually the better platform for the future.Unfortunately there is a plethora of social control (and behavioral modification) issues intrinsic in this technology area, and like medical it requires some serious and open ethical exploration.Thanks for the good comment. reply mikestew 13 hours agorootparentprevGoogle has already tried something similar:https:&#x2F;&#x2F;arstechnica.com&#x2F;tech-policy&#x2F;2022&#x2F;03&#x2F;google-routinely... reply lowbloodsugar 14 hours agorootparentprevIANAL but you don’t get attorney client privilege just by having a lawyer in the room. You actually have to be quite careful to make sure the privilege can be asserted. reply checkyoursudo 13 hours agorootparentI was a lawyer (still am, just don&#x27;t practice anymore), and this is true.Not only that, but if you have the wrong people in the room, then you can lose what would otherwise have been attorney-client privilege. reply belval 13 hours agorootparentNot seeking legal advice, just curious. Where is the line drawn with regard to attorney-client privilege in corporation with various communication tools?I was once told by a lawyer that emails were privileged (assuming you are communicating with your corporate counsel) but Slack messages with the same person were not. Is this just a lack of precedent with Slack? reply lazide 13 hours agorootparentNot a lawyer, but my understanding is:- you have to have a reasonable expectation of privacy for the communication (yelling it across a crowded room, or using a line you know is recorded by someone else means no privilege)- it needs to be a legitimate attempt to receive counsel from said attorney.- the only other folks who are in the communication are also related to the matter and also clients of the attorney (or attorneys for you).So asking your attorney ‘hey, I ran over someone - am I in trouble?’ over direct private email (or other channel) that is private? That’s privileged.CC’ng your attorney on a thread where you’re conspiring between 3-4 other people so that ‘it’s attorney client priviledged’, but the thread isn’t about you getting legal advice about the legality of the endeavor?Not privileged.Think of it this way:- the courts want to be sure that you can have direct conversations with your attorney on legal matters. That includes asking questions about the law, defending yourself, etc. and they don’t want you to have to worry about putting your foot in your mouth in the process. Because a big reason attorneys exist is because people will put their foot in their mouth constantly without help.- the courts also want to be sure that the truth of any legal matter (with the assistance of your attorney) is found in a speedy, accurate, and expeditious manner.So if you aren’t legitimately trying to get legal advice or help? Pound sand. reply checkyoursudo 13 hours agorootparentprevI have never used Slack and don&#x27;t know anything about it, so it is hard for me to say. Are Slack messages accessible by third parties? If so, that can break A&#x2F;C privilege. That is probably the main way it happens.You still need to be careful with email too. Just because you are emailing a lawyer doesn&#x27;t make it automatically privileged, though there is a much stronger presumption and argument for privilege. But, like, your plans to go to the bar with your lawyer buddy after work are not privileged, even if they are also your corporate counsel. It still needs to be related to legal advice, or in anticipation of litigation (which itself is a very large umbrella that gets you a lot of privilege for otherwise mundane corporate communications).At any rate, a good counsellor will tell you what is safe and not safe. Be sure to take it seriously. reply esrauch 10 hours agorootparentSlack is accessible by third parties in the same way that phone calls and emails are, namely that many employees of the companies that own the infrastructure can observe all of the communication but are told only to do so under very specific circumstances. reply TylerE 12 hours agorootparentprevIs the whole “pay me a dollar retainer so you’re my client” trope an actual thing? reply zerocrates 12 hours agorootparentNot really.One obvious reason: there are pro-bono and state-provided attorneys, but they still retain the privilege with clients that don&#x27;t pay.There&#x27;s no requirement for money to change hands, and the mere act of doing so doesn&#x27;t create an attorney-client relationship where one doesn&#x27;t otherwise exist. reply k12sosse 11 hours agorootparentprevSimple answer.. only hire attorneys in all positions &#x2F;s replytshaddox 13 hours agoparentprevIs it really that odd? The point isn&#x27;t that you can&#x27;t say those things and you can&#x27;t tell employees to not say those things. The point is that you can&#x27;t do those things, and separately, you can&#x27;t tell employees to not say those things.Your characteristic made it sound like the government&#x27;s end goal is for the company to simply not say those things, in which case it would be silly for them to also not allow you to tell employees to not say them. But of course the government&#x27;s end goal is for the company to not do those things, and separately, they don&#x27;t want the company to instruct its employees to refrain from discussing those things because that indeed looks a lot like trying to hide evidence. reply kibwen 13 hours agorootparentRight, there&#x27;s nothing odd or unfair here unless you&#x27;re an anticompetitive company trying to get away with anticompetitive practices.It&#x27;s like saying that it&#x27;s odd or unfair for someone to have \"how to hide a dead body\" in their search history as evidence against them while they&#x27;re on trial for murder. But your honor, if I&#x27;m being penalized for researching how to hide the body, it&#x27;s unfair because it makes it more likely that my murder will be discovered! Think of the chilling effect this will have on murderers, and the devastating economic repurcussions on manufacturers of bone saws and rubber hose! reply singron 10 hours agorootparentprevInstructions to not _do_ things are conspicuously lacking from these trainings. We were instructed not to consider the legality of what we were doing, avoid using all the above language, and let the lawyers clean up afterwards if it&#x27;s necessary. I think the only exceptions might have been export controls, copyright (loosely), and HR training (discrimination, etc.). reply summerlight 13 hours agorootparentprevYes, that&#x27;s very odd. Because without such corporate policy being allowed, competitors can easily bribe some employees to loudly speak it out and use it as evidence of bad acts&#x2F;intention. It&#x27;s almost impossible to counter it as long as they&#x27;re careful enough to hide such collusion. reply Prickle 10 hours agorootparentThat claim seems incredibly unfair.That is just regular corporate espionage. The reverse is possible as well.What next? Governments are not allowed to police corpY because rival corpZ will violate the laws that corpY follows; thereby stealing marketshare? reply dekhn 13 hours agoparentprevMy favorite part is the core guidance Google always told us was: \"how would you feel if an email wrote showed up negatively on the front page of the New York Times\".I lost count of the number of times that Google execs (and senior directors) emails showed up on the front page of the Times after that; one time I opened the Times to see my own manager&#x27;s email advising the android team that it was fine to reverse engineer Java code from Sun into Android. reply TX81Z 12 hours agorootparentWith the *really* sensitive stuff you aren’t even allowed to write a single thing down, everything is done verbally, totally off the books. reply TylerE 12 hours agorootparenthttps:&#x2F;&#x2F;youtu.be&#x2F;7R3fqjCL4XY?si=0uOcKDgWZhuvlZbQ (NSFW language warning) reply recursivecaveat 5 hours agorootparentI thought for sure this would be a link to the end of this scene: https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Ly82nabRRYc reply andy_ppp 2 hours agoparentprevI was just listening to Scott Galloway&#x27;s podcast where he suggests if you&#x27;re a big enough percentage of any market you should be regulated as if you are a monopoly. My opinion is you should not be able to have both sides of the same business (search and ads in the case) in the same company and certainly bundling a flipping ad network&#x2F;surveillance system in your \"free\" browser is an astonishing situation. The power Google exert over the Internet is enormous.Policing words that imply criminality is not a way to not be guilty of abusing your market position. reply ffhhttt 10 minutes agorootparentHow would the search business be monetized? reply dllthomas 11 hours agoparentprevI think there are three things worth distinguishing.1. \"Don&#x27;t do these bad things.\"2. \"Don&#x27;t talk about it when you do these bad things.\"3. \"For chrissake don&#x27;t talk like you&#x27;re doing these things when you&#x27;re not even doing them.\"1 and 3 are appropriate, 2 isn&#x27;t. I agree that the lines are not always obvious. reply hotnfresh 13 hours agoparentprev“Don’t say ‘murder’; say ‘liquidate’ or ‘take care of’”I mean, that sure looks like evidence to me, and not in an unfair way.Calling it unfair is like “how can you possibly expect me to not get in trouble if I can’t conspire to avoid getting caught breaking the law!” reply JumpCrisscross 14 hours agoparentprev> you also can&#x27;t tell employees not to say those thingsYou and I can’t. Our lawyers can. There shouldn’t be that many people at your firm who can make anticompetitive decisions. Ensure they meet 1:1 with corporate counsel to be advised on what the law is, and how the law responds to certain language. That’s not only kosher, it’s protected by privilege. reply birdyrooster 13 hours agorootparentLegal privilege will not apply if your conversations with your attorney are for planning or furthering an ongoing crime or fraud, or one that hasn&#x27;t happened yet. reply JumpCrisscross 12 hours agorootparent> if your conversations with your attorney are for planning or furthering an ongoing crime or fraudSure. But that isn’t what’s going on here.Every regulated industry has blackballed terms. Communicating that to ensure employees don’t accidentally trip up, as well as informing them of the laws they are meant to follow, is totally legitimate. reply sidewndr46 14 hours agorootparentprevbased on the discovery from this and other cases, everyone at Google believed they were entitled to meet with legal counsel and that all conversations were privileged reply esrauch 9 hours agorootparentI&#x27;ve been a swe at big cos for 10 years and I believe this because that&#x27;s literally what the lawyers repeatedly informed me was the case. Every significant launch involves a moment where a senior engineer meets with legal counsel and explains the launch and counsel says if they see legal risks with the launch. It&#x27;s also routine to meet with them early and discuss possible future directions or explain the business value in revisiting a standing policy to see if the benefit to risk is worth it or not.If you&#x27;re saying that random engineers aren&#x27;t actually entitled to meet with legal counsel and have a privileged conversation where they privately ask for directed legal advice, that would be surprising news to me. reply JumpCrisscross 13 hours agorootparentprev> everyone at Google believed they were entitled to meet with legal counsel and that all conversations were privilegedIt sounds like a lot of senior people at Google don’t understand how privilege works. reply Cheezewheel 10 hours agorootparentprevAs someone who is ignorant of this matter, why aren&#x27;t the conversations privileged? Is it because the lawyer&#x27;s represent the company and not the individual personally? reply oceanplexian 12 hours agoparentprevI worked at another FAANG and they did exactly the same thing.There were official docs saying not to say the word monopoly, or something to that effect (It&#x27;s been a few years). It felt dirty, glad to see that I was right and no, there isn&#x27;t some magic legal loophole of using special phraseology to imply things that are illegal. reply OkayPhysicist 12 hours agoparentprevThe issue isn&#x27;t the phrasing. It&#x27;s the conspiring to violate antitrust law. If you do conspire to violate antitrust law, then telling people to hide the evidence is furthering that conspiracy. That&#x27;s not unfair, it&#x27;s a misunderstanding of what the illegal part is. reply UtopiaPunk 14 hours agoparentprevWhat seems unfair? Government agencies are actively try to identify forming monopolies and stop them, or break them up. If a company doesn&#x27;t want to face consequences for acting like a monopoly, the best way to do that is to not approach becoming a monopoly. reply gnicholas 12 hours agoparentprevI remember when I was a corporate lawyer, it was common practice to search for emails that just said \"call me\" — an indication that there was something that they didn&#x27;t want to put in writing.This wasn&#x27;t a smoking gun, but it could help prove you were on the right track. Also, if you depose someone and ask them about a specific phone conversation they had, they&#x27;re probably less likely to lie than if you just generally ask them if they ever talked about XYZ. reply senkora 13 hours agoparentprev> you also can&#x27;t tell employees not to say those thingsYou can, but only in an regularly scheduled unrecorded meeting that is described euphemistically as “compliance training”. reply tetrep 13 hours agoparentprev> This feels kind of odd and kind of unfair.Why? It&#x27;s not a crime in and of itself. You&#x27;re also free to make sure all your banking transactions are you also can&#x27;t tell employees not to say those things or you&#x27;ll see headlines like the posted article and have the government claiming at trial that you&#x27;re trying to hide evidence. This feels kind of odd and kind of unfair.The point is to not do anti-competitive things. Doing them and not talking about them isn&#x27;t better than doing them and talking about them. Clearly it&#x27;s worse because you know you&#x27;re doing something wrong and trying to get away with it. reply aaomidi 13 hours agoparentprev> This feels kind of odd and kind of unfair.Legitimately a hilarious notion to be honest. reply TX81Z 12 hours agoparentprevIt’s utterly uncontroversial to state that Google search has gone to shit in the last few years.Now, the question to ask is if Google wasn’t paying off other companies to make them the default would they have been more incentivized to make a better search experience?At this point I don’t get any better results from Google than DuckDuckGo&#x2F;Bing. A few years ago Google was better, now they are increasingly useless and no better than competitors.If iOS users got a prompt to choose a search engine the first time they open Safari, and the order of choices was random, how many would even notice the results were different in any way? reply BitwiseFool 11 hours agorootparentThere are folks in my life who aren&#x27;t comfortable with computers and either wouldn&#x27;t know that changing the default search engine was even possible, or wouldn&#x27;t feel comfortable with going into the settings because they would be afraid of breaking something. reply TX81Z 8 hours agorootparentAnd Google has them hook line and sinker by virtue of paying off some competitors. reply eep_social 8 hours agorootparentprevKind of doesn’t sound like much of a monopoly if you’ve got two alternatives you know and are familiar with off the top. reply TX81Z 8 hours agorootparentI think you’re missing the point about antitrust and competition. It’s about abusing your power to prevent potential competitors from competing on the merits. Paying to be a default means hardly anybody will ever see your competitors product.If everybody was able to easily see Google’s results vs competitors it’s likely they would try harder and wouldn’t have just spent all their effort on cramming more ads above the results. reply eep_social 6 hours agorootparentUnfortunately not trying hard isn’t illegal. Paying for placement is not illegal either, that’s pretty much what advertising is. And what Google will argue, in the case of websearch, is that the problem is hard which is what drives your perception that they have failed to maintain quality and switching is trivially easy, but no one does because.. the competition is worse. I daily drive Bing and in aggregate it’s approximately the same level of bad as google.If you were to address the online advertising market, we would have a lot more to agree on. But you didn’t, and the article seems a bit confused about the ongoing cases (search filed in 2021 vs ads filed recently) and IMO is mostly written to rile the proles. reply happytiger 13 hours agoparentprevTraining employees to avoid terms that legally insinuate “market dominance” (aka, monopolies) is the smoking gun of someone trying to hide a monopoly though. How is that in any way unfair?Unfortunately that article is under lock and key login so forgive me if the comment is off point. reply HDThoreaun 13 hours agorootparentI don&#x27;t think it&#x27;s unreasonable to fear that your employees will say something stupid that shows up in court even if you haven&#x27;t done anything illegal. reply happytiger 11 hours agorootparentThere is always a balance of risk between what appears in discovery and trial to be active management of risk, the original risk of monopolistic accusations and prosecution, and the risk of false accusation due to imprudent or unconscious behavior of employees and associates of the business, irrespective of legality.I’m simply saying the smoking gun of managers managing the risk needs to be seriously considered as a possible smoking gun and not simply dismissed because of its potential as a false indicator. reply salawat 5 hours agoparentprevNo. It&#x27;s really simple. Don&#x27;t do those things. It&#x27;s really that easy. It isn&#x27;t hard. If you don&#x27;t go out of your to make it so a competitor cannot emerge, you&#x27;re fine.The only time employees will even utter that type of language is when that language accurately conveys what you&#x27;re doing. In which case, it&#x27;s time to dial back. Not double down by kindly reminding them not to use terms because golly gee, thems monopolists words and we&#x27;re not that golly gee, no sir. reply Jiro 4 hours agorootparent>The only time employees will even utter that type of language is when that language accurately conveys what you&#x27;re doing.You are describing robots, not human beings.Actual people speak imprecisely all the time. reply salawat 1 hour agorootparentI&#x27;m really not. The only time in my life I ever read through any corporate material and was left with the words \"wow, that&#x27;s anti-competitive af\" is pretty much only when dealing with companies that within 5 years, had anti-trust actions started against them.It is not difficult to avoid unless you set out to do it in the first place. reply yieldcrv 12 hours agoparentprevand just because I used snapchat to message (which has ephemeral messaging by default, at least client side) doesnt mean I’m a hiding antitrust violations!or whatever procedurally generated idea you think I’m hidingjust cocaine shipments. reply naikrovek 14 hours agoparentprevI&#x27;ll tell ya, having watched the MS antitrust stuff happen vs. this, Google has a hell of a lot more apologists participating in posts like this one than Microsoft had employees at the time.Google learned a lot from prior big antitrust cases, clearly. reply seanmcdirmid 12 hours agorootparentHaving worked at MS post anti trust, we weren&#x27;t allowed to say things like \"murder the competition\", but I just assumed that was because they didn&#x27;t want us going to jail for attempted homicide when we were just using hyperbole. reply naikrovek 7 hours agorootparentwell, believe it or not, hyperbole can&#x27;t put you in jail for long, of at all. 1st Amendment.if hate speech is protected (it is) then hyperbole is protected (it is).you weren&#x27;t allowed to say those things because you needed to change your corporate culture. changing how you speak at work is very effective at that.Google somehow believe that if they also dodge the phrases of the past that they will escape the scrutiny of the past, implying that they think government regulators are stupid and won&#x27;t be able to see what is really happening.Google have been very, very foolish in thinking in that way. reply seanmcdirmid 7 hours agorootparentWait. How is Microsoft banning phrases to change corporate culture but google banning phrases isn’t to change corporate culture? Or is google just consider evil in intent by default while Microsoft isn’t? reply aaomidi 13 hours agorootparentprevI work at Google and the comments like the one OP had is so deeply confusing to me?If the judicial system finds that there was monopolistic behavior, then they should deal with it. People apologizing that \"oh poor companies have a hard time with words\" are wild to me. reply stefan_ 13 hours agoparentprevOdd and unfair?! Companies are just an abstraction we invented purely to facilitate capitalism, a simple organizational unit in the market. If they try to monopolize and manipulate the market to defeat competition, there is no reason to keep them around. reply gipp 13 hours agorootparent? Their culpability on that count has nothing to do with whether this particular argument is a fair one or not. If you do something unfair to a guilty person it was still an unfair thing reply compiler-guy 12 hours agorootparentprevErr, companies go back before the invention of capitalism. Ignoring government chartered companies (which date back to the earliest governments, and therefore served monarchical economic systems), the first common-stock company was the Dutch East India Company (sometimes known as VOC) and was founded under a mercantilist economic system.And the VOC was hard-core manipulative and monopolistic.If you want to claim that companies were invented to serve the rapacious profiteer, then all good--that&#x27;s mostly true. But as a factual matter, they are not the invention of capitalism and long predate it. reply bemusedthrow75 12 hours agorootparentprev> Companies are just an abstraction we invented purely to facilitate capitalism, a simple organizational unit in the market.No. The earliest companies in various cultures go back more than a thousand years and they have emerged for a variety of reasons -- pooled risks and resources, family businesses needing to hire non-relatives, tradesmen needing to hand their businesses on to their apprentices, etc.Capitalism is actually pretty new. It&#x27;s not much older as a practice than its definition.Kongo Gumi alone existed for more than a thousand years before capitalism became a meaningful economic model.The livery companies in the UK date back 600 years before the UK was a capitalist system.And we could still have various forms of companies in a non-capitalist system, which in turn does not automatically mean communism. reply danaris 14 hours agoparentprevOr—and hear me out here—you could just not conduct your business in such a way that you end up on trial for abusing a dominant market position.It&#x27;s not like this is something that loads of companies have faced—this isn&#x27;t the kind of situation where you can say \"but the DoJ brings companies up on trial for this all the time, whether they&#x27;ve clearly got a dominant market position or not!\"The rules are byzantine and complex, but the principle is simple: Compete fairly, rather than trying to eliminate your competition. If you do end up with a dominant market position, by whatever means, don&#x27;t try to abuse it to keep others out of the market or small within the market.\"But Wall Street\" \"But muh infinite growth\" \"But repeatedly-debunked-fiction about fiduciary duty to stockholders\" No. You don&#x27;t have to be a greedy, selfish, narcissistic asshole just to get by. reply nonethewiser 13 hours agoprevDoesnt the title imply using words monopolists use is evidence of something? Surely thats not what defines a monopoly. You’d have to look at actual actions.Communications like this could arguably be about building culture, not evading antitrust allegations:> \"We don&#x27;t &#x27;lock up&#x27; or &#x27;lock in&#x27; our customers,\" and \"we do not &#x27;leverage&#x27; anything,\" Google told employees.But regardless, are they trapping customers and abusing some unique power that makes them a monopoly or not? reply marricks 14 hours agoparentI imagine a murder trial would be a lot easier if the person charged was quoted saying:\"I&#x27;m going to murder this person\"Compared to\"I hope something bad happens to this person\" reply pawelmurias 13 hours agorootparentIf you are saying things like \"This would be a perfect murder weapon\" and \"I wish John Smith was dead\" it will make you more likely to get convicted even if you are innocent. reply henry2023 12 hours agorootparent- It was a joke bro.. sorry, your honor. reply k12sosse 11 hours agorootparentLike robbing stores and saying \"twas merely a YT prank!\" reply nonethewiser 13 hours agorootparentprevBut are you guilty of murder if you say “Im going to murder this person?” reply drdaeman 14 hours agorootparent(IANAL) AFAIK, intent matters a lot in the criminal law, and if the statement is unambiguous it&#x27;s significantly easier to prove the intent. reply qingcharles 7 hours agorootparentMany criminal trials have no direct evidence and are totally reliant on circumstantial evidence, so the statement above would be very detrimental to the defense. reply nonethewiser 12 hours agorootparentprevBut the point is you would also have to actually kill them. reply quickthrower2 11 hours agorootparentNot really. You can’t know if someone you never met killed someone after the fact so you rely on evidence. Some of which is what you say. The jury are regular people, not logicians.In addition killing is not always a crime. reply Aachen 12 hours agorootparentprevI agree with the sibling comment about what the point was, though of course you are technically correct as well, but in addition it might be relevant to mention that attempts at someone&#x27;s life are also punishable. Whether the analogy continues to work for anti-monopoly law, I don&#x27;t know reply qup 12 hours agorootparentprevno, the point is once they&#x27;re dead, it matters greatly whether you intended to kill them or not reply leereeves 14 hours agorootparentprevYeah, killing with intent is the very definition of murder. (Edit: Unlawfully) Killing someone without intent is manslaughter, with (generally) a much lighter punishment.But to answer GP&#x27;s question, AIUI, merely saying \"Im going to murder this person?\" does not make someone guilty of murder or attempted murder, or (perhaps surprisingly) even conspiracy to commit murder. Conspiracy usually requires an overt act, like buying a weapon, in addition to the statement of intent.https:&#x2F;&#x2F;www.law.cornell.edu&#x2F;wex&#x2F;conspiracy reply weaksauce 14 hours agorootparentthere&#x27;s more nuance to the manslaughter than just killing without intent. you generally have to be doing something wrong in the first place to have it rise to criminality. ianal though and different localities judge it differently. reply l33t7332273 14 hours agorootparentprevGenerally it’s only manslaughter if you were reckless or negligent when you killed the person. reply IvyMike 13 hours agorootparentprevAs your lawyer I strongly advise you to not say \"I&#x27;m going to murder this person\". reply Hamuko 13 hours agorootparentHow should I phrase my intent to squeeze the life out of someone then? reply quickthrower2 11 hours agorootparentI will reduce their market share reply ForHackernews 12 hours agorootparentprevI&#x27;m planning to excel in the extremely competitive air-breathing segment this quarter. reply dotnet00 14 hours agorootparentprevIt&#x27;s more like, if you intentionally started avoiding a murder spot specifically before a murder ended up happening there, you&#x27;d look a lot more likely to have had some inkling that something wrong was going to happen there than if you had just always been taking the alternative route.Similarly, if Google was intentionally avoiding using anticompetitive language, it&#x27;s reasonable to think that they felt they might be facing some anticompetitive behavior related action. reply lsaferite 12 hours agorootparentI&#x27;d say it&#x27;s more like:A lot of people are murdered in location A, we walk past location A frequently, let&#x27;s not walk by location A anymore because the police are looking at us funny. Then they get pulled into the interrogation room and they use the fact that you stopped going by location A as evidence that you were involved in the murders (that kept happening even after you stopped walking by that location). reply lmm 9 hours agorootparentWalking past a place perfectly is legal and moral. Abuse of a dominant market position is neither. Google employees weren&#x27;t being warned against talking about something innocuous that happened to be associated with crime. They were being warned against talking about doing crimes! reply Aunche 8 hours agorootparentprevFrom Google&#x27;s perspective, it would be like be charged with murder because you told them to \"go to hell\", which proves your intent, even though in context, it was obviously a mundane argument. reply jeremyjh 7 hours agorootparentIt would be more like being charged with murder after murdering 4 billion people and then whispering \"don&#x27;t say &#x27;murder&#x27; guys\". reply Aunche 7 hours agorootparent\"I know that you did it, so who cares that the evidence provided is questionable.\"If you&#x27;re 100% confident that they&#x27;re guilty, you should have no problem with providing better evidence than, \"an employee said a nono word\" or \"Google told their employees not to say a nono word.\" reply 2OEH8eoCRo0 12 hours agorootparentprevInstead of drugs, call them onions. Instead of money, call it flowers. Establishing euphemisms. reply runeks 51 minutes agoparentprev> Doesnt the title imply using words monopolists use is evidence of something? Surely thats not what defines a monopoly. You’d have to look at actual actions.Who says they&#x27;re not both looking at what Google says and what it does?Proving that Google both has questionable practices and tries to hide them is an argument that Google not only does questionable things but also that Google is aware it&#x27;s doing questionable things. reply klabb3 11 hours agoparentprev100% agree. This speaking-in-code game is testament to the complete ineffectiveness of antitrust laws. I went through this training as well and it’s explicitly just about avoiding certain words and phrases. Meanwhile we have an industry where the norm is anti-competitive behavior and myopic dominance games. These rent-seeking monopolies aren’t created by accident. reply thomastjeffery 13 hours agoparentprevThe crime is not saying something, the crime is meaning it.Why would you tell you employees to use careful language? So they can say something without being obvious.The intent here is very clear. reply RyanHamilton 13 hours agoparentprevCulture is based on what you actually do, not what you say. Volkswagen said they wanted to make cleaner cars, instead there was the emissions scandal. Most governments say they want to build new homes, not many houses get built. reply anticensor 12 hours agorootparentOr worse, earthquake-fragile houses get built. reply lmm 7 hours agorootparentIt&#x27;s not worse, and the attitude that says it is is exactly why we end up with nothing getting built. reply 2OEH8eoCRo0 14 hours agoparentprevCombined with other evidence, it could show that they knew what they were doing was wrong. reply wnoise 13 hours agoprevThis strongly reminds me of a scene from season 3 of The Wire. A bunch of gang leaders are making plans together -- by way of a meeting trying to be run by Robert&#x27;s Rules of Order. A subordinate is taking notes -- have to have minutes according to the rules. Eventually the leader notices and asks \"is you takin&#x27; notes on a criminal fuckin&#x27; conspiracy?\"https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=Ly82nabRRYc reply Graziano_M 13 hours agoparentOne of the all-time best quotes from the series. reply rg111 13 hours agoparentprevIt was a nice cooooop for as long as it was operational.Bi&#x27;ness was abooming without any bloodshed.---On a more serious note, it is quite baffling to me that even after the tech sector embracing the corporate culture fully, and tons of documents generated every hour, prosecutors still have to scrape for such documents. reply Mechanical9 10 hours agoprevI feel like the single words referenced in the title are taken way out of context. The actual texts of these trainings unambiguously tell workers to not break the law, why the law is important, and what Google&#x27;s philosophy is instead. That that includes not miscommunicating those intentions isn&#x27;t a bad thing. None of this is ambiguous to anyone who has taken the actual trainings. reply bartwr 7 hours agoparentI worked at Google and I didn&#x27;t get that impression. At no training I was told to not try to overtake the market, at many meetings PMs and directors were strategizing how to overtake the market, but the trainings were all about avoiding words (especially in writing) that could be seen as trying to establish the market dominance. reply chmod600 14 hours agoprevWe&#x27;ve shifted too much in the direction of punishing based on words rather than actions.Punishments should be driven primarily from actions and harms, and words should just be used to show intent and involvement.It seems weird to me that the question of whether company X did something wrong is answered by its own employees&#x27; statements (based on their narrow perspective) rather than some objective criteria that something bad happened. reply freeAgent 11 hours agoparentThe reason they don’t want employees to use these words (and why they go OTR occasionally) is, at least as alleged by the government, to make discovery more difficult&#x2F;impossible and also to hide&#x2F;destroy evidence of their activity. It’s not about being word police, it’s about the reason why they’re policing language. reply chmod600 10 hours agorootparentIf you observe an action that&#x27;s wrong, you can work backwards from there to discover what you need.If you have to use dragnet searches, that means you don&#x27;t have any clear bad action to work from, and you&#x27;re trying to construct it from statements. reply Cheezewheel 10 hours agorootparentDo you not understand the basic principle of law that intention actually does matter? Or do you not understand that it may be difficult to prove that there was intention to commit a bad act even if it is trivial to establish that the bad act was made? reply droopyEyelids 6 hours agorootparentThat&#x27;s not a joke or something to take for granted. A lot of people in tech want law to be like a formal mathematics, and sort of pretend that&#x27;s how it works, rather than acknowledge that fuzzy human things like \"intention\" are valid factors in legal matters. reply nonethewiser 10 hours agorootparentprevYeah but this is reasonable with or without antitrust violations. Its the same principle as the 5th amendment and not incriminating yourself. reply freeAgent 8 hours agorootparentThey aren’t being charged with policing the language used by their employees. reply turquoisevar 9 hours agoparentprevThis is great in theory, but in practice a lot of illegal acts (whether criminal or civilly illegal) hinges on intent, state of mind and the benchmark of the illusive “reasonable person”.A simple criminal example is would be the difference between negligent homicide, manslaughter and murder. Which can be summed up respectively as lack of intent, lack of intent for outcome and intentional.To suss this out you’d have to figure out the state of mind of the person in question and going over their communications is one of many ways to do this.In the context of anti-trust this gets a bit more complicated but in a nutshell that is severely lacking the necessary nuance the difference comes down to getting ahead by legal pro-competitive means and getting ahead by illegal means.To figure out if a company got ahead just because they had a great product (or got lucky) and based on that they had an organic market growth v. them getting ahead because they had access to means and methods they only derived from their size and market share in other markets, it’s important to look at communications to see what the intent behind decisions was. This becomes increasingly more important when you’re dealing with a behemoth of a company where the lines between different departments and projects are blurred.All of that is not even touching upon the fact that pretty much everything is an action, or act, even the choice of inaction. Speaking, making a decision, not acting on knowledge, etc. They can all be considered acts.To sum it up, intent is often a deciding element of an illegal act. But if Google ends up being punished, it isn&#x27;t because of these communications, it is because of what these communications prove in terms of the acts they are being prosecuted for. reply thomastjeffery 13 hours agoparentprevOn the contrary: this case it&#x27;s punishing the very behavior you are complaining about.People who tried to defend themselves with vain word choice now have that very act of defence used as a tool for their prosecution. reply csb6 12 hours agoparentprevThe instructions and training given to employees is definitely relevant when determining intent, i.e. the question of whether Google systematically or accidentally destroyed evidence. No one is saying that the case is about words only. It is about anticompetitive behavior and the act of destroying evidence of it. reply mattigames 11 hours agoparentprevCan you imagine saying that with any other charge \"It seems weird that Tom is being charged with murder just because the sister&#x27;s victim claims that she discussed his death treats with her and not because we have objective proof of the murder\" reply chmod600 10 hours agorootparentIn your analogy, you assume that you already know a murder happened, and it&#x27;s a question of who did it. Obviously words matter there.But for antitrust it&#x27;s using words to try to show that a crime even happened at all.That&#x27;s definitely weirder -- more like if Tom said he killed Fred, but we don&#x27;t really know who Fred is or whether he is alive or not, and we still put Tom on trial using a series of his statements. reply corethree 13 hours agoparentprevI get where your coming from especially with this whole pronoun fiasco.But on the other side of the coin very real bullying can come from just words.Unfortunately what is real bullying and just harmless talk exists actually exists on a gradient so we can&#x27;t really codify it into anything that seems reasonable. Most good judgements are arrived at by just intuition. reply chmod600 13 hours agorootparentThat would be interesting to discuss but it&#x27;s not where I was going and it&#x27;s a bit off topic.Investigations should start with the crime and work backwards to find the criminal. If you have to find incriminating statements to tell if a crime has even happened, that is really a different thing. reply johnnyanmac 13 hours agorootparent>If you have to find incriminating statements to tell if a crime has even happened, that is really a different thing.That&#x27;s what it sounds like:>Alphabet Inc.’s Google is on trial in Washington DC over US allegations that it illegally maintained a monopoly in the online search business.They aren&#x27;t 100% sure so they are finding statements and actions to prove that Google is engaging in anti-competitive behavior. reply MAGZine 14 hours agoprevIs anyone surpri",
    "originSummary": [
      "Google employees, or \"Googlers,\" have been instructed to refrain from using particular words and phrases potentially implying anti-competitive behavior, as per documents presented in an ongoing trial.",
      "These instructions are part of a larger case where Google is being accused of maintaining a monopoly in the online search market. Google, however, denies these allegations.",
      "The documents also reveal that employees are encouraged to have sensitive chats with their history turned off and to avoid phrases like \"cutting off their air supply\" and \"market share.\""
    ],
    "commentSummary": [
      "The discussion focuses on Google and its antitrust issues, emphasizing the importance of language in legal matters and the potential abuse of monopoly power.",
      "Topics include Google's instruction to its employees to bypass certain words and a conversation surrounding attorney-client privilege, demonstrating the complexity of legal aspects in the tech industry.",
      "Another theme covered is Google's dominant role in the software industry, discussing factors such as the quality and pricing of its products and their impact on competition."
    ],
    "points": 261,
    "commentCount": 322,
    "retryCount": 0,
    "time": 1694702304
  },
  {
    "id": 37509533,
    "title": "So You've Decided to Move from Unity to Unreal Engine",
    "originLink": "https://impromptugames.com/movingtounreal.html",
    "originBody": "So You've Decided To Move From Unity To Unreal Engine Ugh, something bad probably happened and now you're here. This sucks! Let's get you started on the right foot though. I'm Joe Wintergreen, I'm an Unreal Engine generalist. If you want you can look at all my stuff. Here is a bunch of helpful information for people new to Unreal whose experience is in Unity. \"Where do I start?\" Read the documentation on the Gameplay Framework. All of it! Unreal has a Gameplay Framework. Read the docs and get to grips with it. It's the right choice for every type of game. Don't skim it. Keep it on hand to read it again.Get in a community of helpful folks. This will quadruple your Learn Speed. There's Alex Rose's Discord For Former Unity Devs and there's also my discord, which you are welcome in if you don't be a jerk.Hit up the Epic Online Learning Library. Here it is. Focus on the ones by Epic Games. Download the latest Unreal Engine through the Epic Games Launcher. Right now it's 5.3. In general, you always want to start a project on the newest version. There's also no reason to use UE4 anymore - UE5 is better and has everything from UE4.Check out Epic's \"Unreal Engine for Unity Developers\" doc. It's a pretty good initial \"oh god what am I looking at\". Here it is.Read this whole page. I know there's a lot of text here, but don't skim it! This stuff is important and accurate! There's a lot of bad info about Unreal on the internet, but not here. This is all gold. \"Just give me tips!\" Alright fine! Here's 20 minutes of rapid fire tips and a video about the Class Viewer (turn on the Class Viewer). And Chris Murphy's Video about Features You Probably Don't Know About. I suggest watching these through immediately, even though it's a bit overwhelming, just to get a sense of what sorts of things are there, and then coming back and looking again later when you're more equipped to directly utilise the scoops. \"I have so many questions!\" Here are answers to some questions that are asked frequently. I'm worried about this whole situation! What's conceptually different about Unreal? I heard a rumour! Isn't Epic going to end up screwing me over in some way? You should never trust a big corporation, but probably not. Epic's EULA stipulates that if the EULA changes, you don't have to agree to the new terms; as long as you stay on the version of Unreal you're on. Combined with full access to the source code, this probably means you're pretty safe. Anecdotally and as of right now, Epic tend to be chill. For instance, when they changed their Unreal Marketplace rev share from 30% to 12%, they made it retroactive and refunded every Marketplace creator the difference on every sale they'd made. Anything can change, so keep an eye on 'em, but you should be alright.Unreal and Unity are not game engines in the same sense. Unreal, idTech, Cryengine, Source, Snowdrop, etc are game engines that emerged from the process of game development. Unity and Godot didn't, which is fine, but not the same thing, and using them is fundamentally different. If you use the Half-Life Engine, you benefit from using the tools that shipped Half-Life; you don't go in and write your own weapon system and networking and savegame system. It's the same way with Unreal, except you're not getting \"whatever Epic ended up with when making Gears of War\" - Epic spent 25 years supporting AAA licensees and building systems that would pretty much work for any and all of them, so that's what you're getting. It's overpowered for what you need as an indie, but that's good. You want to be overpowered. I heard it's hard to learn! It can be! It's huge and empowering, but it doesn't do a good job of teaching itself. The UI is kept \"simple\" in a way that means there are huge features you just won't discover unless someone tells you about them. The forums are not great, and the entire internet is filled with very confidently-stated misinformation. Googling worked well until this year, and now it doesn't. If you can help it, you shouldn't try to learn it alone. You should put yourself in some sort of Unreal learning community, like Alex Rose's Discord For Former Unity Devs, and ask a lot of questions. I've seen people go from zero to extremely capable (and hired) in a year, from being in my discord. What's the payment situation? 5% gross doesn't sound great! It's free until you make a million bucks USD, and only after that is it 5% gross, and only in quarters where you made more than $10,000 USD. So most folks never end up paying anything. There are no subscription fees or anything. To clarify, if you make a million bucks, and then one dollar, you only owe them five cents. If this still sucks to you, you can talk to them about a custom license with custom terms. There's an email link on their website somewhere. Make sure you fill out the Release Form when you release your game. Otherwise you might have to pay royalties sooner than $1M, apparently. Take you five minutes. If you're making \"linear content\", like movies, TV, etc, Unreal is literally just free.Don't roll-your-own everything. Check the system you want to make doesn't exist already. If it does exist, but seems bad, you probably haven't looked hard enough at it yet. They aren't banging rocks together at Epic. You think you can make a better animation system or whatever, you're wrong. Quit it, you're gonna hurt your team. That said, not everything in Unreal rules. I don't like Unreal's Behaviour Trees, I think they're really bad. I built my own AI system instead of that which I think is real good. Maybe you can too!I heard C++ sucks! Maybe, but Unreal's C++ is pretty different to C++ elsewhere. It's easier. Give it a shot even though you dread it. Most games, though, don't need much, if any, C++ - you can build and ship an entire solid, maintainable, performant, complex game in Blueprint. Check out Tom Looman's Complete Guide to Unreal C++, that guy knows what he's doing. The most important thing is not to be dogmatic. C++ and Blueprint both have their place. If you find yourself insisting that someone move all their Blueprint to C++ \"for performance\", you have become the villain. Nativisation and optimisation are not the same thing. What's the deal with platforms? Consoles? Epic Launcher? You can put your games on any platform or console, they're all well supported, and nothing is mandatory. If you sell on EGS, which you don't have to, those sales don't contribute to the revenue thresholds above. Porting to consoles is easier here than on other engines. Porting to consoles isn't an outsource job here. It can be, of course, but Unreal is built to target every platform from one project. Fortnite is on Switch, Android, iOS, Xbox, Playstation, PC, and maybe something else, and that is all built out of one project. You can do this too. For the most part it \"just works\". Stuff like \"make the textures lower res on the Switch, depending on the asset\" is all built-in and easy. I did the Switch port of Adios in a week. Bear in mind you'll have to go through the console's signing process to get the secret source code you need to compile the engine for it. It tends not to be difficult. Whole engine's on Github by the way. I heard Blueprint sucks! Blueprint actually rules. Look, I get it - why would a visual scripting thing be good? They're all shit! I agree. Blueprint is the only one that's any good. It's amazing. It will also help you learn the engine. Everything you do there will be applicable to C++. No matter who you are, you should start in Blueprint. It's 100% true that you can build an entire game in Blueprint. Yeah, with multiplayer. Yeah, performantly. Yeah, maintainably. It's not just for rapid prototyping. Be a snob about Blueprint at your peril. I've helped a lot of people get good at Unreal and get hired for it, and Blueprint-related recalcitrance is the number one way people screw themselves - without realising, they sentence themselves to months of wasted time and frustration only to mould themselves into the type of Unreal user who sabotages any team they're on. Swallow your pride and look at some nodes. Do I have to put the Unreal logo on my stuff? No, in fact if you want to use it, you have to fill out a form and they can reject you. You do still have to put a \"this uses Unreal Engine, copyright yada yada\", etc in your credits.You won't use the Asset Store as much. It's called the Unreal Engine Marketplace, and there's a lot of good stuff and a lot of bad stuff on there. In general, you need it less than you do on Unity. Like you don't need Rewired; Unreal's input systems are solid and work on every platform. There'll be a lot of stuff like that.I heard Unreal is geared towards first person shooters and it's a struggle to make something in my genre! This isn't true. It was sort of true in the first half of UE3. By UE4 it wasn't true in any sense. Somebody's lyin'. You can make anything in any genre with equal ease. If in doubt, look up the Wiki list of Unreal Engine games. Nobody there had to go out of their way (or outside the Gameplay Framework) to do their thing. Doesn't Tencent own Epic or something? They have some non-controlling amount of shares. The way I've had this explained to me is Tim Sweeney owns the majority and nobody else gets any real say in anything. Tencent did invest though and do own part of it.Upgrading to the latest version is not a big deal. Most times you upgrade to the next version of Unreal you won't run into any issues. Some folks like to hold off a little just to be sure. Psychonauts 2 started on 4.11 and shipped on 4.26. Staying up to date is good here.What if I don't want fancy graphical bells and whistles? What if I'm not making something in a realistic style? That's all fine. The fancy graphics in Unreal are easy to disable, and you still get the benefit of their fancy tooling. Unreal also doesn't limit the types of styles you can go for. You can do anything. \"Physically based rendering\" doesn't mean you have to work in a realistic style. Does Unreal pay you to be this helpful? I fuckin' wish. I don't know what compels me to be honest. You could send me money though if you wanted, or there's a patreon.Unreal doesn't suddenly remove important features. When Epic deprecates a massive feature, it tends to stick around for a long time before actually being removed, and then you'll have an upgrade path provided. For instance, the current particle editor is Niagara. Before Niagara, for many years, there was Cascade. Cascade is still in the engine, but you should use Niagara, and there's an automatic converter of your Cascade particle systems to Niagara. Similarly, the animation tool Matinee (responsible for the cutscenes in Gears of War, Mirror's Edge, Batman, Xcom, etc) was removed from the engine years after being deprecated and replaced with Sequencer, and to this day if you open a level that contains a Matinee it gets perfectly converted to Sequencer.Can I make a 2D game? Yeah, totally. Just make a game as usual but with an orthographic camera. If you want sprites instead of animated meshes, there's a system called Paper2D for dealing with sprites, and it doesn't get a lot of updates or do much with animation, but there's also a system called PaperZD (on the marketplace) that does a lot more. As of 5.3, all the latest lighting features work with orthographic - lumen, virtual shadowmaps, etc. Unreal introduces new systems carefully. If something new comes into Unreal, usually it's initially marked Experimental. This means Epic don't recommend relying on it for production. Eventually it will lose that label, and then it's safe to use in a shipping game. Presumably out of an abundance of caution, some features stay Experimental for a lot longer, even though they're good to go and are used in many shipped games. Ask around if you're unsure how safe an \"experimental\" feature is. Also, all the new stuff is optional, it doesn't replace old features. Lumen and Nanite are new and cool, but still optional. You can still bake lighting and everything's still compatible with that. Can I make a game that's playable in the browser? Not really! There used to be HTML5 support, but it got deprecated a few years ago. Other than Pixel Streaming, you don't have much recourse here unless you want to implement it yourself. So that sucks. Unreal doesn't have multiple rendering pipelines with their own asset requirements. You do have access to multiple renderers in Unreal, with different features - there are Deferred and Forward renderers for both Desktop and Mobile with various quirks (eg, you only get MSAA on Forward). But your assets don't care about this - the renderers all look the same, and you can switch between them at will to figure out what best fits your project.I heard you can't make a build that's less than a billion megs! Out of the box in UE5.3, if you disable all unnecessary plugins and package a nearly-empty project, it's like 120mb. On UE4 that was more like 75mb. There's a lot more you can do to reduce file size - this is just what I've done personally. If you search, you should find some good tips for this. This is the engine that made that game you like. You know how in Batman Arkham Asylum you sometimes have to wait in front of a door while it security-scans you, but actually it's loading the next chunk of level while you stand there throwing batarangs and it'll take longer to scan you on a slower machine? That's not something Rocksteady did, that's just Unreal's level streaming system they used for Gears of War. You can just use that. If some game on Unreal ever did a thing you liked, there's a good chance you literally have the code.I heard the level design tools are bad! You probably heard that from me. There's a way to go, but things have gotten a hell of a lot better, especially in 5.3. Check out that link for some scoops on the tools CubeGrid and MeshTool, which are both excellent and work well together. I heard it's a hassle to develop on/for Linux and Mac! Not really! There were some Mac CPUs that weren't properly supported until recently, but they are now. You can download the editor for Mac through the Epic Launcher just like PC, or for Linux, go here.",
    "commentLink": "https://news.ycombinator.com/item?id=37509533",
    "commentBody": "So You&#x27;ve Decided to Move from Unity to Unreal EngineHacker NewspastloginSo You&#x27;ve Decided to Move from Unity to Unreal Engine (impromptugames.com) 261 points by Kye 19 hours ago| hidepastfavorite138 comments spywaregorilla 17 hours ago> I heard Blueprint sucks!> Blueprint actually rules. Look, I get it - why would a visual scripting thing be good? They&#x27;re all shit! I agree.> Blueprint is the only one that&#x27;s any good. It&#x27;s amazing. It will also help you learn the engine. Everything you do there will be applicable to C++. No matter who you are, you should start in Blueprint. It&#x27;s 100% true that you can build an entire game in Blueprint. Yeah, with multiplayer. Yeah, performantly. Yeah, maintainably. It&#x27;s not just for rapid prototyping.> Be a snob about Blueprint at your peril. I&#x27;ve helped a lot of people get good at Unreal and get hired for it, and Blueprint-related recalcitrance is the number one way people screw themselves - without realising, they sentence themselves to months of wasted time and frustration only to mould themselves into the type of Unreal user who sabotages any team they&#x27;re on. Swallow your pride and look at some nodes.Best advice in this page. Blueprints are excellent. They make the engine API extremely discoverable. You naturally gain a deep understanding of the classes and components and how they interact. They are performant. They can do 95% of what you want.The C++ engine API is fine but it doesn&#x27;t lend itself to learning the engine. I don&#x27;t recommend using it unless you identify a specific need. reply aschearer 17 hours agoparentHow do people using Blueprints deal with:- Find and replace a variable- Change a variables type- Merging changes from multiple commits- Refactoring- Finding all referencesI&#x27;m a fan of visual coding and use it extensively in YWDHT but have found the above challenging. I&#x27;m curious how Blueprints solves these issues, especially for larger teams. reply dbrueck 16 hours agorootparentEarlier this year we completed a huge refactor that involved, among other things, getting us almost 100% off blueprints (now we use them just for little bits of presentation logic in UIs).BPs are amazing for discovering how to use the engine - they provide a sort of guided exploration of things, especially when you don&#x27;t know what you don&#x27;t know.For us they really, really, really broke down when it came to version control, multiple people working on the same BP, code reuse, and refactoring. Arguably, at least some of this was our fault - I think you&#x27;re \"supposed\" to do the major coding not in BP and then use BP mostly for really high level stuff, and we didn&#x27;t always do that.Anyway, it&#x27;s been wonderful not having those issues anymore. Gone are the days of changing one thing and then git saying that 100 files have uncommitted changes! reply exogen 13 hours agorootparentHey, I&#x27;ve been working on something I think is pretty cool to address some of the shortcomings mentioned here. If you&#x27;re up for chatting about your experience and offering some feedback, mind hitting my profile and shooting me an email (on my homepage)? reply doctorpangloss 15 hours agorootparentprevIt&#x27;s nice to hear from someone with real experience.Blueprints clearly delivered negative ROI. In general they probably do. This is the worst time to be advocating for visual programming, considering the first truly groundbreaking application of AI is going to be in writing code.The real question is, did C++ give you any real ROI either? Probably not, it probably only got in the way compared to the way Unity is architected.> Gone are the days of changing one thing and then git saying that 100 files have uncommitted changes!You&#x27;re using Unreal, but not with Perforce? Get back into the time machine buddy!People&#x27;s expectations about this extremely clunky engine are way too high. reply dbrueck 15 hours agorootparent> The real question is, did C++ give you any real ROI either?We actually moved most of everything that was in BP (and a good bit of what was in C++) to Python, so it addressed all of our issues while also speeding up development and, somewhat surprisingly, giving us a decent performance boost too.> You&#x27;re using Unreal, but not with Perforce?Yeah, definitely not going to use Perforce, haha - might as well be using SourceSafe!> People&#x27;s expectations about this extremely clunky engine are way too high.Unreal absolutely does have its warts, an almost overwhelming amount of complexity, and we&#x27;ve run into our share of issues. Sometimes you&#x27;re amazed at how quickly a feature can be implemented, and then other times you spend days on something you thought was going to be trivial. We replaced the replication system with something better suited to our needs, for example. That said, on the whole we&#x27;re pretty happy with Unreal (both the renderer and the materials system are very impressive). reply bradleyishungry 15 hours agorootparentprevBlueprints are extremely useful in prototyping at the very least, not just in the initial stages of development but for adding new systems. There is nothing wrong with them and the idea that LLM’s are going to replace blueprints is ridiculous. Sure, you will be able to have them write a block of collision code, but gamedev is one of the most complicated fields in terms of having an understanding of what your state is and what references what.LLM’s can spit out code without understanding the problem, but understanding the problem is 99% of gamedev reply crustaceansoup 16 hours agorootparentprevI&#x27;ve only been on medium-small teams, but I&#x27;ll give it a shot:Merging is essentially as banned as we can make it; we use Perforce, and set all .uasset files (Blueprints and other UE assets) as Exclusive Checkout so only one person can edit them at a time. This is recommended by Epic. When we do need to merge things, it&#x27;s mostly a manual process of opening the Editor on two branches and duplicating all of the changes.All of the refactoring-related questions, again, mostly manual effort. There are some constructs that can help keep things DRY which reduces the problem, like BP function and macro libraries. You also get inheritance and interfaces. UE also lets you redirect property, class, and function names to new names using \"Core Redirects\"; you can do that and then resave all packages to effect a bulk change.Finding all references: Search All in UE will find a string anywhere; that means in property details, BP function calls, variable names, comments, anything. There&#x27;s not exactly a \"find references\" as you might expect from a normal IDE though.Really, the ultimate solution to dealing with these and the general \"visual scripting spaghetti\" problem if they&#x27;re on the verge of becoming acute is to stop using Blueprint. We try not to use Blueprint for any complicated systems. It&#x27;s nice for simple presentation-related things (e.g. \"play x sound when y happens\"), or places where we want designers to have some control for tuning or prototyping, but even for something that seems \"straight-forward\" like GUI code it can very easily end up spiraling out of control.Blueprint also has a performance cost and it&#x27;s hard to profile. UE5 dropped UE4&#x27;s main attempt to fix this with \"nativized\" Blueprints, i.e. Blueprints that got compiled into C++. There are ways to improve Blueprint performance, but you really shouldn&#x27;t even get yourself into a place where you&#x27;re leaning on it so heavily that you can even worry about that. reply yAak 16 hours agorootparentSounds very similar to the problems of using XIBs&#x2F;Storyboards in iOS dev. (aside from the perf. cost you mention) reply spywaregorilla 16 hours agorootparentprevNot sure why this is downvoted.> - Find and replace a variable > - Finding all referencesI think the basic search tools are pretty good. I can&#x27;t say I expect find and replace to be super common. I would prefer to do such things one at a time.> - Change a variables typeI would say you really shouldn&#x27;t be doing this too often. It&#x27;s compiling to statically typed code under the hood so this will frequently cause a lot of breaks. You can do it, and it will highlight all the areas where this breaks things (maybe more easily than c++ might tbh). And if the types are compatible, that might mean you have to do the annoying step of redrawing lines to the same var with a new \"node\" representing the proper type.> - Merging changes from multiple commitsThis is hard and not good. The most difficult part about blueprints.> - RefactoringI tend to think this is pretty easy. Maybe easier than in code. I&#x27;m a big fan of collapsing all nodes into subnodes. So every individual step becomes one high level node. You can also \"collapse nodes\" into a function itself. You want to minimize the number of nodes you&#x27;re looking at any given time so it kind of encourages good practices on itself if you&#x27;re competent. reply andybak 16 hours agorootparent> I can&#x27;t say I expect find and replace to be super common. I would prefer to do such things one at a time.This seems like a very strange thing to say. I presume you do text-based coding as well? Multiple cursors, search&#x2F;replace, bulk refactors and other semi-global operations are a huge part of my normal workflow and I can&#x27;t quite fathom how visual coding would change the need for that.Regarding refactoring - I&#x27;m not sure what you describe really is \"refactoring\". reply spywaregorilla 15 hours agorootparentI&#x27;m a data scientist day to day, which is a very different feel from coding up game systems. The latter is a lot more intricate and intertwined. The text coding I do in c++ for unreal is probably more involved.I can&#x27;t say what you&#x27;re saying resonates with me as familiar. I&#x27;ve always been confused at why people ever feel multiple cursors is useful if not just begging for disaster. You can, for example, rename a property in a blueprint class, and that will flow through to all references to that property in other blueprints, if that&#x27;s closer to what you mean.When I think about refactoring I think about taking some logic and making it into a more reusable function; or abstracting it into a shared component. I would say the former is what I was saying, and the latter is more of a capability offered by the engine than the tooling. Reparenting classes to compatible alternative parents and moving properties and logic to component classes is relatively comfortable in my opinion. reply exogen 13 hours agorootparentprevWould you be down to chat a little about your Blueprint experience and take a look at a tool I&#x27;ve been working on? Check my homepage (on my profile) for contact info if so, I&#x27;d be very thankful :) reply spywaregorilla 13 hours agorootparentI&#x27;d prefer to just reply to comments but I&#x27;d take a look. You might find better perspectives asking the folks who sound like they&#x27;ve finished shipping a complete game though. reply andybak 17 hours agorootparentprevThis is an extremely good list of the potential issues with most current node-based tools and Is be very keen to see a detailed reply. reply timeagain 16 hours agorootparentprevI think you missed the point. Yeah it isn’t code and it has downsides, but it is a GUI for discovering and learning to intuit the API. To not use it would be tantamount to refusing to read the documentation.When entire teams are using visual programming tools through the entire dev lifecycle (incl. refactoring and maintenance), wake me from my cryogenic freezer! reply andybak 15 hours agorootparentBut the original article and the post we&#x27;re all replying to isn&#x27;t arguing for using it for \"discovering and learning to intuit the API\" - they are arguing for using it for the bulk of coding tasks. reply spywaregorilla 15 hours agorootparentNo I don&#x27;t think so. You can. I do about 80&#x2F;20 bp, gradually shifting some content to cpp as I need more specific network replication capabilities.But they&#x27;re definitely referring to learning by doing stuff in blueprints. I would agree with this. Figuring out how something ought to be done with the engine in blueprint and then re-implementing it in cpp is the more pleasant experience imo. reply russdpale 17 hours agorootparentprevA colleague and myself were just discussing similar issues with SSIS packages compared to just running the queries in a stored procedure on the server. reply Pxtl 13 hours agorootparentYes but the difference is that Blueprint is actually a good language while SSIS is a dumpster-fire. reply andersa 14 hours agoparentprevBlueprints are not performant, they are potentially the slowest scripting language to ever be used in a significant way, worse than python even. If you don&#x27;t believe this, try implementing some basic number crunching routines in pure blueprints and see how long they take to execute. Though if you&#x27;re just using them to configure and glue together C++ classes, like most gameplay code is doing, then it&#x27;s usually fine.Reading other people&#x27;s blueprints and understanding them is much harder than doing this with the equivalent code - having to follow the wires everywhere is a nightmare with all visual noise. I often jokingly call it a write-only language. Not to mention the part where you must have compiled the project and be running Unreal Editor with all the assets loaded to do this in the first place.And then you can&#x27;t even properly diff or merge them without using some special tool that doesn&#x27;t properly integrate with your version control and only works reliably half the time.Blueprints are fantastic for familiarizing yourself with the engine, since you can quickly discover all the things to do from the context sensitive search. They&#x27;re also great for people to get started with their projects and prototyping. They&#x27;re not at all suited for production work in a large team.I really wish Unreal Engine supported a proper scripting language so the choice isn&#x27;t between noisy node graphs hidden in binary asset files and raw C++ code. People keep shooting themselves in the foot with both of these. reply johnnyanmac 14 hours agorootparent>I really wish Unreal Engine supported a proper scripting language so the choice isn&#x27;t between noisy node graphs hidden in binary asset files and raw C++ code. People keep shooting themselves in the foot with both of these.That&#x27;s apparently what UE&#x27;s new Scheme based language, Verse[0], is aiming to do. But this is very new tech and currently used in the Fortnite editor part of UE. It&#x27;s not quite something to use in the main engine yet.[0]: https:&#x2F;&#x2F;dev.epicgames.com&#x2F;documentation&#x2F;en-us&#x2F;uefn&#x2F;verse-lan... reply brundolf 12 hours agorootparentOh I didn&#x27;t know about this, this sounds greatHave they said explicitly that it has ambitions beyond fortnite? reply brundolf 16 hours agoparentprevMy hangup with blueprints has always just literally been: I&#x27;d like to type them out with my keyboard instead of using a mouseI wish they offered like a \"Bluescript\" language or something, that just maps 1:1 with blueprints but lets you write them out as code reply andybak 15 hours agorootparentI think lossless roundtripping with a textual representation is essential if node-based tools want to escape the local minima they all seem to get trapped in.Either that or the ability to use 3rd party editors so competion and innovation can happen in the same way it has for textual code editors. reply johnnyanmac 14 hours agoparentprev>They make the engine API extremely discoverable.yeah, because the UE documentation is absolutely horrid (and it&#x27;s not like Unity is better at this). I have lots of gripes, but I think the meta issues involve how BPs cause so much community knowledge about the c++ API to be buried. Absolutely fatal if your game cares about performance.>They are performantThey are performant... IF you know how to weave between them and c++. Shame that courses don&#x27;t really seem to emphasize that and you simply hit that wall once you&#x27;re working on a project. reply LanceH 17 hours agoparentprevI had this same scepticism but kept seeing tutorials doing real with with it until I was convinced. reply pfisch 15 hours agoparentprevBlueprints have terrible performance. They just do. Even trying to compile them into c++ doesn&#x27;t work well.Blueprints run at least 100x-1000x slower than equivalent c++.This isn&#x27;t even discussing working with multiple coders and version control, which is also a disaster.If you are making a simple game then they can work. If you aren&#x27;t then they are not great. reply johnnyanmac 14 hours agorootparent>Blueprints run at least 100x-1000x slower than equivalent c++.they are slower but unless you are doing literal math in the blueprints this is a huge exaggeration... which is exactly what one AAA game I worked on did. sigh. And they wondered why we couldn&#x27;t hit 60fps (tho, that wasn&#x27;t even the biggest detractor to performance).Now, BP&#x27;s in general usage when you&#x27;re not doing literally everything in them is about 10x slower. But when you properly use blueprints, you can mitigate this a lot. BP&#x27;s in a large project work best when you expose existing c++ code to BP and make sure any designer code is piped through c++ first. The main exception tends to be UI code, but UI is rarely a performance bottleneck in large 3D games to begin with.>This isn&#x27;t even discussing working with multiple coders and version control, which is also a disaster.yup, that&#x27;s my 2nd biggest gripe. Nothing worse than trying to submit code and the BP you changed one node in is locked, with the owner of the lock being out for the day. reply jarsin 15 hours agoparentprevDon&#x27;t forget to use base classes in c++ though. It&#x27;s massive performance hit to cast to bp only classes. The base class will help you move nasty bp stuff like complex calculations once you run into them. reply somenameforme 18 hours agoprevA course that finally made Unreal \"click\" for me, after years of toying with it, was Tom Looman&#x27;s &#x27;Professional Game Development in C++ and Unreal Engine&#x27; course. The source for what you build (with the chapters available in the git history) is here. [1] It was based on a class he taught and so also includes homework, which I found infinitely more valuable than just following along in a &#x27;Here&#x27;s how to [x].&#x27; type lesson.[1] - https:&#x2F;&#x2F;github.com&#x2F;tomlooman&#x2F;ActionRoguelike reply compacct27 16 hours agoparentI agree, that course was fantastic. Unreal C++ was way less intimidating after. reply jaimehrubiks 17 hours agoprev> It&#x27;s free until you make a million bucks USD, and only after that is it 5% gross, and only in quarters where you made more than $10,000 USD. So most folks never end up paying anything. There are no subscription fees or anything. To clarify, if you make a million bucks, and then one dollar, you only owe them five cents.It sounds very fair to me, what are the general thoughts here? reply owenpalmer 17 hours agoparentI&#x27;m surprised they can sustain such low pricing reply danudey 17 hours agorootparentThe arrival of Fortnite Money has meant that Epic can afford to spend a lot more and charge a lot less for everything they do. They opened a studio in Vancouver and started hiring whoever they wanted from other companies, e.g. The Coalition, with starting salaries that made jumping ship a no-brainer for the engineers they were picking up.For Unreal, I think it fundamentally comes down to:1. We want to be the biggest and best game engine out there2. We want everyone to use our technology if at all possible3. The vast majority of our money is going to come from the top 1% of the huge players in game dev (CD Projekt Red, The Coalition) and not from anyone else4. The more people who use Unreal to make games, the more Unreal devs there are in the world, and the more Unreal devs there, the more likely those huge companies (or potentially blockbuster indies) are to choose Unreal for their projects because talent is readily available (see point #3)Edit: Per their court case with Apple:https:&#x2F;&#x2F;www.theverge.com&#x2F;2021&#x2F;5&#x2F;3&#x2F;22417447&#x2F;fortnite-revenue-...They made over $5bn in profit from 2018 to 2019 from Fortnite, and $5.1bn in revenue in 2020. reply NetOpWibby 16 hours agorootparentI spend money on Fortnite roughly every month. Extrapolate that to an insane amount of players and it&#x27;s not hard to see that they&#x27;re in an excellent position.Creator payouts from building games and experiences within Fortnite builds loyalty and encourages further development from kids going, \"Ooh, I have an idea for something.\"It&#x27;s incredible. reply boppo1 8 hours agorootparentprevBut how long will Fortnite money last? Gamers are fickle. It wasn&#x27;t too long ago that no one could imagine a &#x27;halo-killer&#x27;. reply PeterisP 14 hours agorootparentprevJust as in game microtransactions, it doesn&#x27;t matter how much or little the median person is paying, because all the profit is in the minority of very big payers &#x2F; &#x27;whales&#x27;, so you optimize the payment structure of the small payments to ensure that they don&#x27;t prevent you from capturing the whales.If your game doesn&#x27;t earn a million dollars, it doesn&#x27;t matter to Epic, because all those (many!) tiny games in total don&#x27;t earn enough that even a much higher pricing would move the needle.However, if the low-end pricing structure means that one more (or one less) blockbuster chooses this engine, that makes all the difference, because they are going to pay the full rate out of the billion dollars they earn. reply csdreamer7 17 hours agorootparentprevTake a quick look at how much fortnite is making per day in 2018.https:&#x2F;&#x2F;www.cinemablend.com&#x2F;games&#x2F;2454545&#x2F;the-insane-amount-... reply Ekaros 17 hours agorootparentprevJust remember how many AAA or big name titles use Unreal as engine. Those can sell millions of copies at 60 per copy. And even if they have much better rate it is still probably half a million to millions a game. reply danudey 17 hours agorootparentEpic made more than $5bn in profit from 2018 to 2019, according to documentation from Epic&#x27;s court case with Apple, and $5.1bn in revenue in 2020.https:&#x2F;&#x2F;www.theverge.com&#x2F;2021&#x2F;5&#x2F;3&#x2F;22417447&#x2F;fortnite-revenue-...With numbers like that, collecting a half-million dollars from even ten blockbuster games per year is probably not even worth the time and energy it would take; that would be 0.1% of their revenue, which, relatively speaking, is basically nothing. That whole business wouldn&#x27;t even show up on the balance sheet. reply enragedcacti 17 hours agorootparent> collecting a half-million dollars from even ten blockbuster games per yearI don&#x27;t think that&#x27;s in the right ballpark. PUBG has generated about $15 billion in revenue over 6 years or $125 million per year in revenue for Epic.Jedi: Fallen Order sold 10 million copies at full price in its first four months, netting Epic ~$20 million.Even an indie game like Stray netted Epic ~$2 million in one month of Steam sales.https:&#x2F;&#x2F;vgsales.fandom.com&#x2F;wiki&#x2F;PUBGhttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Star_Wars_Jedi:_Fallen_Order#S...https:&#x2F;&#x2F;www.gamesensor.info&#x2F;news&#x2F;stray* assuming all these devs have the standard 5% deal and chopping 30% off for marketplace fees where only sales*price data was available reply akhosravian 14 hours agorootparentFWIW basically no established game developer is using the standard terms epic provides. If you’re in a situation where you have a high degree of confidence you will owe Epic money it is worth reaching out in advance. reply johnnyanmac 14 hours agorootparentTrue, but I also imagine that Epic isn&#x27;t bargaining down the rev share too low. Or, companies are fine paying 8 or even 9 figures upfront in anticipation of such success in a custom contract.I can&#x27;t imagine it being chump change. reply ffhhttt 16 hours agorootparentprevIsn’t most of that from Fortnite and not the engine business? reply readyplayernull 17 hours agorootparentprevThat&#x27;s mostly a contribution fee, game engines don&#x27;t make a lot of money from their software, in their case the real revenue comes from Fortnite. reply nottorp 16 hours agorootparentprevThey’re financed by blood diamonds. I.e. tencent making their initial funds from gacha on the Asian market and now trying to buy legitmity with it. reply johnnyanmac 14 hours agorootparentTencent purchased a stake in Epic in 2012, years before the f2p mobile market took off.Tencent isn&#x27;t just a mobile game company, they are basiaclly Chinese Microsoft for how many parts of the industry they are entwined in in their home country. reply nottorp 1 hour agorootparentIn 2012 I already had trouble finding any mobile games that aren’t f2p and basically gave up on playing any. (I’m too poor to afford free games.)Also, they made their blood money on Asian markets not here. reply brucethemoose2 16 hours agorootparentprevThe side benefits are enormous. Its not like Unity where Unity fees are the bread and butter for the company. reply WeylandYutani 14 hours agorootparentAnd with respect for indie games the vast majority of them barely make money.Unity was trying to squeeze water from a rock. reply brucethemoose2 13 hours agorootparentUnity makes its money from mobile gaming, and that is a juicy rock to squeeze. reply ffhhttt 16 hours agorootparentprevTechnically if your game is not F2P Unity will still be much if your revenue i a couple if millions (even with their bizarre and convoluted per install pricing).Also I don’t think they have that many people working on the engine (they have less than half the employee count of Unity) and it’s probably subsidized by Fortnite revenue to some extent. reply corysama 14 hours agorootparentGames that expect a large revenue are expected to negotiate a custom contract with Epic. That has been their practice going back to Unreal Engine 1. reply johnnyanmac 14 hours agorootparentin that regard I&#x27;m sure they will do the same with Unity. But Unity for the little guys that just a little bit too big suffer the most in this deal. At least Epic handles that edge case by letting those edge case devs keep the first million. reply beanaroo 14 hours agoparentprevWhat happens when your business has a portfolio of products&#x2F;services over multiple departments, spanning various platforms, and only one consumer mobile app uses Unity for an augmented reality component that&#x27;s not a core offering (premium feature)?Should Unity still be entitled to the same cut? reply ricardobeat 11 hours agorootparentThose are the Unreal fees, not Unity.But to answer your question, they are royalties on top of that one mobile app, not your entire revenue. If you distribute it for free, you might pay no royalties; if it somehow is tightly related to your main revenue-generating product then you’d sign a custom licensing agreement with them. reply r053bud 17 hours agoparentprevIt&#x27;s fair until they change it without warning. It&#x27;s not a matter of if, it&#x27;s a matter of when. I love Unreal, but I know it&#x27;s coming. reply throw16180339 15 hours agorootparentEpic is a highly profitable private company controlled by the founder. They have no incentive to mess with a business model that works; their margins are higher than Unity.Unity has over 3x as many employees as Epic, much lower margins, is publicly traded, and they&#x27;ve been losing money hand over fist. Everything is subject to change until they make money, shut down, or are acquired. reply WhiteOwlEd 17 hours agoprevData scientist here who spent a couple of years working with Unreal (to produce high end data visualizations). Here are my thoughts> Blueprints suck! Not really. Think of Blueprints like python. Its good for routing and keeping track of things at a high level. Think of C++ as handling things at a lower level.> I heard you need to start with blueprints. Not really. After going through the basic tutorial that Unreal Sensei has on YouTube (https:&#x2F;&#x2F;youtu.be&#x2F;gQmiqmxJMtA?si=TqBiiIe12M5hiCda) , it is better to do a mix of blueprints and C++ if you have any programming background.> I don&#x27;t know what to use for the IDE. I used Rider for Unreal Engine and it has good integration into Unreal Engine.> So when do you use C++? When I was doing data vis of census data, I needed a way to load in 10,000 data points into memory. The \"out of the box\" tools for Unreal didn&#x27;t support this, so custom C++ was the way to go.> But really, if I just want to get started with Unreal and want official tutorials, where do I go?After going through Unreal Sensei, I looked at at https:&#x2F;&#x2F;dev.epicgames.com&#x2F;community&#x2F;unreal-engine&#x2F;getting-st..., there are a ton of tutorials there for game developers.Also, a year ago I put together an online course that looked at how to ramp up on Unreal Engine. The course (\"Data Visualization in the Metaverse\") is ideal if you already have a programming background. I put the course out on YouTube for free (https:&#x2F;&#x2F;www.youtube.com&#x2F;playlist?list=PLKH3Xg62luIgPaB4fiFuT...) and happy to answer any questions about it. reply azan_ 17 hours agoparent>Data scientist here who spent a couple of years working with Unreal (to produce high end data visualizations) That sounds amazing, could you share some of your visualizations? reply vintagedave 16 hours agoparentprev> I don&#x27;t know what to use for the IDE. I used Rider for Unreal Engine and it has good integration into Unreal Engine.Don&#x27;t forget Visual Assist! It&#x27;s more flexible, is faster, uses less memory, works on uncompilable code, etc. (I work on it.) reply caniszczyk 16 hours agoprevAlso check out https:&#x2F;&#x2F;o3d.foundation and Godot as options... open source gaming engines should be at the heart of modern game development imho, just like Linux is the heart of many infrastructure things we do reply blinding-streak 16 hours agoprevUnity offices are closing due to death threats. Things going smoothly after their pricing change.https:&#x2F;&#x2F;www.bloomberg.com&#x2F;news&#x2F;articles&#x2F;2023-09-14&#x2F;video-gam... reply mrtksn 15 hours agoparentWhat up with the gaming community? I get the the players being carried away or be from a special demographics but aren&#x27;t the game professionals aware that they are doing business? Underpaid developers, death treats after some pricing changes. Wow. reply skeaker 15 hours agorootparent\"The gaming community\" consists of an insanely large number of people. Some percentage of people on Earth are willing&#x2F;crazy enough to use death threats to get their way. The gaming community is large enough that that percentage manifests itself in the form of death threats being used. The question isn&#x27;t so much \"what&#x27;s up with the gaming community\" as it is \"what&#x27;s up with this small percentage of humanity.\" reply saurik 13 hours agorootparentThere is something interesting though that while the audience of superhero movies is super large and while there are a lot of overly toxic complaints and clearly a number of people who are super angry about various things, I haven&#x27;t seen news reports of any offices at Warner Brothers or Disney being closed due to credible threats of violence. reply skeaker 12 hours agorootparentI suppose you haven&#x27;t looked hard enough, then: A 5 second google search for \"marvel movies death threats\" turns up multiple articles about threats against directors for killing off Marvel characters. To your point I&#x27;m not sure that they closed their offices over it, but how they react isn&#x27;t really up to the people making death threats. reply mardifoufs 14 hours agorootparentprevThis is not necessarily the gaming community. If anything, the devs who are currently revolting are usually pretty critical of said community reply musicale 15 hours agorootparentprevThe developers are revolting. reply pixl97 14 hours agorootparentRent goes up 200%: [we sleep]Unity changes pricing: [ we riot ] reply johnnyanmac 13 hours agorootparentlet&#x27;s be real: there&#x27;s good odds that the people doing this hail from countries where they feel they can be safe from legal avenues of (the US-headquarter) Unity.Also, these are children or the privileged who are complaining about video games on thee internet. They have no issues with rent. replyTacoRabbit 15 hours agoprevIt&#x27;s also worth noting that if you&#x27;re concerned about Epic Changing the Deal and doing a rugpull like Unity, they&#x27;ve said you can simply not accept the changes and continue operating under your existing terms you agreed to:\"If we make changes to this Agreement, you are not required to accept the amended Agreement, and this Agreement will continue to govern your use of any Licensed Technology you already have access to.\"You potentially lose access to epic services of various sorts, but it&#x27;s a far cry from the Unity situation.https:&#x2F;&#x2F;www.unrealengine.com&#x2F;en-US&#x2F;eula&#x2F;unreal (Section 7) reply interestica 15 hours agoparentI think Unity had that same provision? Until they changed it:\"Unity silently removed their Github repo to track license changes, then updated their license to remove the clause that lets you use the TOS from the version you shipped with, then insists games already shipped need to pay the new fees.\"https:&#x2F;&#x2F;old.reddit.com&#x2F;r&#x2F;gamedev&#x2F;comments&#x2F;16hnibp&#x2F;unity_sile... reply jimmaswell 18 hours agoprev> Read the documentation on the Gameplay Framework. All of it!Is it just me or is this an unviable learning strategy? My approach for learning anything has always been to follow small tutorials, build an intuition, and only consult docs when I need some specifics. reply adamkittelson 18 hours agoparentI think it&#x27;s just different learning styles. My preference for learning e.g. a new programming language has always been to read a book cover to cover as the first step (if it&#x27;s a language established enough to have a book anyway). Note that it&#x27;s not important that I actually understand everything on this first pass. The cover to cover is mostly about getting the lay of the land so I know what exists, then, even years later when I have a problem that could be solved by using some bit of the language that I read about but didn&#x27;t really understand but vaguely recall is a thing it springs to mind and I can do my deep dive on that aspect then. reply pxc 17 hours agorootparentI&#x27;m currently doing this with a few programming language books, and the strategy for me is basically to read the book in two passes. On the first pass, the goal is just to get through the whole thing and get a feel for everything it covers. If I don&#x27;t understand it, that&#x27;s okay— I just let it wash over me.It&#x27;s only on the second pass that I am trying to go through each section carefully and make sure I really understand before moving on, including seeking outside help or resources if I feel confused or stuck.This feels fun for me, and the casual first pass makes it easy to figure out if a book or language truly appeals to me.I also feel, strange as it sounds, like for me it save time compared to learning in small increments through tutorials. It lets me more quickly absorb the basics for things that are already more or less familiar, and then I can focus on exercises and examples only for the tricky stuff.When I first started studying computer science, in high school, the biggest productivity gap was between the students who tried to work only with what they were directly taught in class by the teacher and the students who decided to go explore the language&#x2F;stdlib API docs on their own. There was a lot of &#x27;wow, how did you do that!?&#x27; from the former group and a lot of &#x27;it&#x27;s built in, check out this part of the manual&#x27; in response from the latter. But somehow no amount of exchanges like that could convince the former group to take some time to RTFM in a comprehensive or unguided way, so it stayed that way. reply janosdebugs 18 hours agoparentprevAs someone who recently learned UE: yes, this is completely unviable. The UE API docs are almost useless. Use Rider and its code navigation instead, you&#x27;ll get much better results.The docs about the concepts are better, those are worth reading. reply blt 16 hours agoparentprevYour style will get you through a project, but you&#x27;ll miss out on useful but nonessential features.For example, a lot of C++ programmers miss the full spectrum of std::algorithm. A lot of Python+NumPy programmers miss out on some useful indexing tricks.I&#x27;m still suffering from not taking a rigorous approach to unix shell. reply freedomben 18 hours agoparentprevEverybody is different. It&#x27;s certainly unviable for some people.For me, the ideal thing is a book, and great docs can feel like this. Something well thought out, comprehensive, deep, and importantly error checked&#x2F;reviewed. The downside is books are increasingly rare and get outdated really quickly. reply atomicnumber3 18 hours agoparentprevYeah I agree. For me personally the best combination seems to be a quick start guide to get me bootstrapped and let me get the gun poinTed at my feet, and then solid normal documentation for me to mend my feet each time after I shoot myself.Some of it is a matter of it being hard to even have the language to know how to ask the questions you have, so a bootstrap or quick start to let you just get in there and start looking around helps a ton and makes the full documentation a lot more accessible. reply david422 17 hours agoparentprev> follow small tutorials, build an intuition, and only consult docs when I need some specificsWhile I basically tend to learn like this - (solve my current problem and move on, since I have limited time to spend on things) - I find that this type of learning can miss some things. Like when the documentation says this is important etc and you never know about it&#x2F;find out about it the hard way when your stuff doesn&#x27;t work properly. reply johnnyanmac 13 hours agoparentprevdepends. IME I tend to go through at least 3 passes of- read high level architecture docs, - try to do some small coding - get confused and google until I get my goal done - go back to reading high level architecture docsYou&#x27;re (or at least, I will) never absorb and become productive in all that material in a first pass. But at the same time reading the intro for the mentality of how the big picture works helps a lot to scope into what to focus on. reply andersa 13 hours agoparentprevIt sounds more like an intermediate strategy, if you&#x27;re eager to discover some tricks you missed. First do some small projects to familiarize yourself with the basics. Reading the API before really knowing the context of anything you&#x27;re looking at seems fairly pointless to me. reply Maschinesky 17 hours agoparentprevI read the kubernetes API and I did not regret it.Nonetheless for just getting to your goal and not becoming really good in something this is not necessary or can be done later reply hypeatei 15 hours agoprevUnity never seemed like a good engine. It&#x27;s CPU bound which is extremely aggravating for a GAME engine.A popular game made with Unity, called Rust, always gets a lot of shit from players because GPUs don&#x27;t do anything except give a couple FPS. I&#x27;d be glad to see Unity die with these pricing changes. reply kibwen 13 hours agoparentQuoting a post from the lead dev of Rust-the-game entitled \"Unity can get fucked\": https:&#x2F;&#x2F;garry.net&#x2F;posts&#x2F;unity-can-get-fucked\"Let me be clear.. the cost isn&#x27;t a big issue to us. If everything worked out, the tracking was flawless and it was 10p per sale, no biggy really. If that&#x27;s what it costs, then that&#x27;s what it costs. But that&#x27;s not why we&#x27;re furious. It hurts because we didn&#x27;t agree to this. We used the engine because you pay up front and then ship your product. We weren&#x27;t told this was going to happen. We weren&#x27;t warned. We weren&#x27;t consulted. We have spent 10 years making Rust on Unity&#x27;s engine. We&#x27;ve paid them every year. And now they changed the rules. [...] Let&#x27;s not make the same mistake again, Rust 2 definitely won&#x27;t be a Unity game.\" reply bluescrn 14 hours agoparentprevC# support is&#x2F;was its killer feature. Game dev without the pain of C++, and without being limited to non-standard scripting languages (or worse, visual scripting spaghetti)With Unity, you can use C# for everything, from the simplest &#x27;spin this object around&#x27; script to customised rendering pipelines and complex in-editor tools.Performance was clearly good enough for the engine to become wildly successful, particularly amongst indie&#x2F;mobile developers making smaller games, and experienced users learn to avoid the main performance pitfalls. reply andersa 13 hours agoparentprevUnreal is similar. All of the gameplay code runs on a single thread. The game framework tricks you into building slow OOP stuff by default with far too much pointer chasing. You can easily make an Unreal project that performs worse than the equivalent Unity project. In fact, many do!It takes effort to release a well performing game using either engine if you have a non-trivial amount of \"stuff\" going on. Luckily Unreal comes with fairly advanced profiling tools so you can find where the problems are. reply boppo1 14 hours agoprevFor any Unreal experts:I&#x27;m an aspiring graphics&#x2F;engine programmer. I don&#x27;t really care about making games, I&#x27;m more excited about improving the tools available. My feet are wet enough with C++ that I think it would be good to start digging around in&#x2F; modifying&#x2F; contributing (likely merely attempting &#x27;small&#x27; stuff like bugfixes) to the Unreal codebase. I&#x27;ve been doing so lately with Blender&#x27;s codebase lately with some success, so large software isn&#x27;t totally new to me. Blender is mostly C though, hence my interest in seeing how things are done in Unreal.Any tips&#x2F; resources&#x2F; advice&#x2F; quirks I should know that you can share would be greatly appreciated! reply johnnyanmac 13 hours agoparentIf you were working in Blender, Godot may hit up your alley a bit more as an open source community driven engine.But wrt UE, it depends on if by \"contributing\" you mean \"making plugins\" or \"contributing to the codebase at large\". From the sound of things you want to do the latter. Unreal is \"viewable source\" but you first need to sign up with an Epic Games account: https:&#x2F;&#x2F;www.unrealengine.com&#x2F;en-US&#x2F;ue-on-githubFrom there, there are instructions on how to contribute (the contribution documentation is actually on a public page: https:&#x2F;&#x2F;docs.unrealengine.com&#x2F;5.3&#x2F;en-US&#x2F;contributing-to-the-...)There is probably some official Unreal Engine community as well (probably on the UE forums), so that can be a place to ask for any specific pieces where devs need help. Best of luck. reply boppo1 7 hours agorootparent> depends on if by \"contributing\" you mean \"making plugins\" or \"contributing to the codebase at large\". From the sound of things you want to do the latter.Yep, I just want to cut my teeth on bugfixes for now, maybe a plugin down the road. I&#x27;m running into some trouble finding much in the way of a bug tracker. The official issues page:https:&#x2F;&#x2F;issues.unrealengine.com&#x2F;only lists the last 5 bugs. I&#x27;d love it if I could browse them all, & perhaps filter by module. Unfortunately I&#x27;m not sure that listing exists publically. reply crustaceansoup 15 hours agoprevSome disagreements based on my experience working with UE for the past 11 odd years. Mind if this all sounds negative that I really like working in the engine and would recommend it for most game projects. I just think you should be aware of what you&#x27;re getting into.> Unreal and Unity are not game engines in the same sense.This is mostly a true description, but> It&#x27;s the same way with Unreal, except you&#x27;re not getting \"whatever Epic ended up with when making Gears of War\"No, a lot of what you&#x27;re getting is \"whatever Epic ended up with when making UT, Gears of War, Paragon, and Fortnite\". You can very much feel their previous games in it. This is good and bad; good in that the tools you need to ship a real game are all there and the engine is actually battle-tested; bad in that the tools you need to ship a game that doesn&#x27;t fit that mold might not be and there could be a lot of stuff that will get in your way if you decide the Epic Way doesn&#x27;t suit your project. UE4&#x2F;5&#x27;s adoption does help a lot, things were rougher earlier in UE4 and in the UE3 days.> Porting to consoles isn&#x27;t an outsource job here.Nah, we needed help to ship Chivalry 2 on console and WinGDK. Many smaller teams do outsource or contract for assistance. It was months of multiple programmers and tech artists, it really wasn&#x27;t one person x one week.> Upgrading to the latest version is not a big deal.If you&#x27;re a tiny, Blueprint-only indie &#x2F; side project I guess this is probably true. It takes us weeks though.> Unreal introduces new systems carefully.We and other teams I&#x27;ve talked to had a policy of waiting for the first hotfix revision of a major UE4 update before attempting an upgrade, though.> I heard Blueprint sucks!See my comment https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37512356> I heard Unreal is geared towards first person shooters and it&#x27;s a struggle to make something in my genre!As above I don&#x27;t totally buy the rebuttal. If you&#x27;re doing something way out of left field you can do it in UE, you might have to bypass a lot of Epic&#x27;s way of doing things though.> What if I don&#x27;t want fancy graphical bells and whistles? What if I&#x27;m not making something in a realistic style?I&#x27;ve not worked on VR or mobile but I&#x27;ve heard that Unity scales down better. Some of UE5&#x27;s nice stuff (nanite, lumen) also doesn&#x27;t scale down well. reply pjmlp 18 hours agoprevGet ready to throw away everything that was written in C# to start with. reply starburst 17 hours agoparentTechnically there is UnrealCLR, so if you made a game with mostly Unity-agnostics code it&#x27;s possible to keep a bunch of it.One of my game is multiplayer, the whole gameplay code is completely Unity-agnostics to run server-side without any Unity code. reply pjmlp 17 hours agorootparentWhich is a proof of concept and doesn&#x27;t do mobiles, game consoles and VR&#x2F;AR headsets, mostly useless. reply starburst 17 hours agorootparentVery true, for now, but the amount of tools &#x2F; libraries &#x2F; projects that will spawn &#x2F; funded &#x2F; contributions to move projects out of Unity is gonna make that more realistic eventually. reply pjmlp 16 hours agorootparentI seriously doubt it, as it requires embracing the game development culture that most FOSS folks are against to, and most commercial engines rather stay with compiled languages instead of having a R&D department in compilers. reply zerr 15 hours agoparentprevOr move to Godot&#x2F;C#. reply pjmlp 15 hours agorootparentDoesn&#x27;t do game consoles. reply madacol 15 hours agorootparentGODOT developers are trying to do it via https:&#x2F;&#x2F;w4games.com&#x2F;. But not sure if it&#x27;s ready reply pjmlp 15 hours agorootparentC++ part, not AOT compilation for .NET. replyhnthrowaway0315 18 hours agoprevI&#x27;m curiously to see whether a big player switches side. Likely not as all big players were probably consulted. reply mediaman 18 hours agoparentI get the impression that Unity did not do a lot of homework before rolling this out. Several aspects of the policy they’ve waffled on, and when asked about who would pay the fee for GamePass games, they said the distributor would, but it appears the distributors were not consulted on this.Not to say they didn’t consult with the major Unity players, but it seems plausible that they didn’t based on the carelessness of the rest of the rollout. reply Ekaros 17 hours agoparentprevBig big players probably don&#x27;t care the Pro and Enterprise tier isn&#x27;t too horrid. Or they have negotiate their own deals. For them 0.01 per install is probably magnitudes less than they pay on advertising per player. reply ffhhttt 16 hours agorootparent> re the Pro and Enterprise tier isn&#x27;t too horrid.Technically you couldn’t even use Personal or Plus if you made over 200k a year. It doesn’t really make much sense to stay on the personal tier now anyway, as long as you manage to make at least over $10k per developer in a year. reply amiga386 17 hours agoprevThis may well be marketing, but it&#x27;s good marketing. It leads with being open and honest that not everything is great with Unreal or Epic either. That&#x27;s much more convincing than something which claims to be sunshine and rainbows. reply gigatexal 17 hours agoprevBut Unreal is doing the same nickel-and-diming though no? reply starburst 17 hours agoparentThey didn&#x27;t retroactively changed the TOS of their engine so that a game you made years ago means you now potentially receive monthly invoices from Unity (and what about ridiculous new fees they will think in the coming years).If Unity would&#x27;ve said that now any games built using whatever the most recent version of their engine is subject to a new TOS that means a fees per installs it wouldn&#x27;t have nearly generated the amount of backlash it has received (no one is going to use Unity for a future project regardless of the fact that the fees per install is for the most majority a much better deal than 5% revenue). reply gigatexal 17 hours agorootparentYeah that too. My initial take is clearly wrong to link the two of them. Shame Apple is partnering with Unity when Unreal seems to be the more popular&#x2F;better looking engine. reply starburst 17 hours agorootparentYeah I wonder if that will impact their partnership they have with their VisionOS... reply dave_sullivan 17 hours agoparentprev5% after your first million in game sales and only in quarters when you sell at least $50k of product? reply samspenc 16 hours agorootparentAlso, as other comments have pointed out, Epic makes most of its money from Fortnite, their revenue from UE licensing fees are tiny in comparison. reply gigatexal 17 hours agorootparentprevYeah that seems far more reasonable never mind. reply ffhhttt 16 hours agorootparentBecause it’s predictable and and you can trust Epic to not start pulling the rug from under you.Even with the new pricing model Unity should still stay way cheaper for anyone who make more than $2-3 per user. reply bastardoperator 16 hours agoprevOr you can wait for Source 2 which is rumored to be dropping on September 23rd with CS:2 reply tapoxi 16 hours agoparentSource 2 has been out since 2015, with tooling, but so far I think the only third-party licensee is S&ndbox. It&#x27;s not so much a modern game creation platform as it is a collection of Valve&#x27;s internal tools.Also from a technology standpoint it is miles behind Unreal Engine. reply sosodev 15 hours agorootparentIt seems a goal of S&box is to allow more developers to ship games that are built using Source 2. I&#x27;m curious if we&#x27;ll see much of that in the future. reply babypuncher 16 hours agoparentprevI&#x27;m not convinced Valve is all that interested in pushing Source 2 as an alternative to Unreal or Unity, and their organizational structure would probably make them a pain to work with. reply ThatPlayer 12 hours agorootparentI think they did when they first announced it, and that it was going to be free (like Unreal&#x2F;Unity). But that was also in 2015 and we&#x27;ve seen no public release of Source 2 since. reply ryanwaggoner 18 hours agoprevI have no personal interest in this topic, but I like this site and the way the FAQs are organized. I&#x27;d love to have this for more topics. reply xkcd-sucks 18 hours agoprevIs anyone aware of unofficial (and maybe illegal in some jurisdictions) releases of Unreal toolchain that strips off the Epic Launcher and can be downloaded without making an account? reply spywaregorilla 17 hours agoparentYou can just grab the repo off of github to use it without the epic launcher but you do at the minimum need an epic account to get access. I&#x27;m not sure why you would want it to be unofficial or be so stubborn against making an account of any sort. reply MikusR 17 hours agoparentprevhttps:&#x2F;&#x2F;godotengine.org&#x2F; reply zengid 18 hours agoprevwow, great resource even if you just like to know more about both. reply koromak 14 hours agoprevfor really small teams, does godot make more sense? I&#x27;ve always heard Unreal is too much to chew on reply johnnyanmac 13 hours agoparentfor 2D or simple 3D games, sure. Godot should be able to do enough to enable a small team to launch a game. You just have to keep in mind that console support won&#x27;t be as robust and smooth as UE. reply Pxtl 18 hours agoprevI can&#x27;t help but be reminded of the people who jumped from Twitter to Threads.Ultimately, the recent wave of enshittifications of major products - Unity, Twitter and Reddit off the top of my head - It&#x27;s a hard reminder that lock-in and governance matters. Software is a long investment, so it&#x27;s time to start thinking very hard about how the software you use is run, and how much control you have if it all goes sideways.I realize that OSS options like Godot aren&#x27;t really comparable, but since Unreal&#x27;s main competitor is Unity, it feels likely that Unreal could do something similar since they don&#x27;t have a competitor keeping the pressure on about price anymore. reply ainiriand 18 hours agoparentDo not fool yourself here, Unreal&#x27;s main competitor was never Unity, it was the different myriad of proprietary engines that exist in powerful studios, there is were the millions are.Unity could never get into that piece of business and Unreal Engine is barely scratching it. reply karim79 17 hours agorootparentThat was always the impression I had, engines such as id tech X, Frostbite, Fox Engine, etc, in my view are some examples of more \"direct\" competition. reply Pxtl 17 hours agorootparentprevYes, but Unity targeted the Indie market with \"free for small unsuccessful projects and we take a small cut of sales if it takes off\" first and then Unreal jumped into that market.While Unreal entered that market from the opposite direction (offering a proper, supported high-end gaming engine to replace in-house engines of AAA gaming companies) they both converged into the same market when it came to selling to small players. reply ainiriand 2 hours agorootparentThat is also true. Not sure how much revenue any of that can generate, though. reply Ekaros 17 hours agoparentprevAlso the models these companies pull are so weird, tone-deaf and impenetrable that it boggles mind. But maybe that is point.Like Unity pricing model. And then Hashicorp and what ever does competing product or offering mean... reply stuckinhell 18 hours agoparentprevGame development is a very different space due to the extreme amount of middleware used and the fact porting between engines has been done since the 90&#x27;s. reply babypuncher 16 hours agoparentprevTwitter usage is down 30% and probably still declining, so I wouldn&#x27;t say their enshittification saw no consequences.When something has momentum it takes a lot to slow it down, but that does not mean doing so is impossible.Unity is a different case though. Unity is retroactively applying these new terms to existing licensees, even if their game already shipped years ago. Unlike Twitter, they are directly hitting their customers wallets in a very nasty way. And unlike Twitter, Unity isn&#x27;t the only well established player in its market. Already in-development projects might not switch, but this is sure to give studios pause when evaluating potential stacks for future games. reply jarsin 15 hours agoprevThat is until round 2 of Epic vs Apple. Where Apple officially kicks the Unreal Runtime off it&#x27;s store this time. [1]Amazes me the short memory of the dev community. So many studios and publishers could not take the risk of Unreal being kicked off and had to switch to Unity.Unity is still cheaper for vast majority of cases too.[1] https:&#x2F;&#x2F;www.macrumors.com&#x2F;2020&#x2F;08&#x2F;17&#x2F;apple-terminate-epic-de... reply Nexxxeh 17 hours agoprev [–] Did Unity have the same reputation for shader cache compilation stutter on PC as UE4 games do? reply sovietmudkipz 13 hours agoparent [–] Tell me more. I’ve recently (past two weeks) gotten more into shaders and I’d like to hear more about this story. What was the shader cache compilation stutter? replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "This summary offers guidance and resources to help transition from Unity to Unreal Engine, emphasising the importance of understanding documentation, joining relevant communities, and using educational resources like the Epic Online Learning Library.",
      "It addresses concerns about payment structures, platform support and emphasizes Unreal's benefits like versatility, extensive marketplace, efficient input systems, and compatibility with both 2D and 3D game development.",
      "The article mentions the use of Unreal Engine in popular games, enhancements of level design tools, and notes the feasibility of developing games on Linux and Mac platforms."
    ],
    "commentSummary": [
      "The discussions primarily focus on topics related to game engines, notably the transition from Unity to Unreal Engine and the application of 'Blueprints' within Unreal.",
      "Other points of interest include concerns about version control and merging changes when utilising Blueprints, its performance and constraints compared to C++, and comparisons with other game engines like Godot.",
      "Further topics discussed comprise the revenue generation by game engine companies, policy and pricing shifts by Unity, threats directed at directors, and the reduction in Twitter utilization."
    ],
    "points": 261,
    "commentCount": 138,
    "retryCount": 0,
    "time": 1694701840
  },
  {
    "id": 37517329,
    "title": "Linear code is more readable",
    "originLink": "https://blog.separateconcerns.com/2023-09-11-linear-code.html",
    "originBody": "Linear code is more readable published 2023-09-11 [ home ] You can only claim to be contrarian if people actually defend the opposite viewpoint. Well, one of the “best practices” I disagree with was recently featured in the Google Testing Blog — usually a very good resource, there is a reason that post appeared in my newsreader! The authors present two versions of a function and ask which one is the most readable. At first glance, we can already notice the presentation is a bit partisan :) In addition to the obvious background color bias, the authors ellipsed some code on the right-hand side, making both implementations appear roughly the same size when the right one is really much longer. The authors argue that the function on the right is more readable because it does not mix levels of abstraction, and that makes it more “top-down”. Well, OK, but the function of the left reads linearly from the top of the screen to the bottom, whereas if you want to understand everything that happens on the right-hand side you need to jump back and forth. You may tell me, sure, but you never need to look at the whole code, that is what abstraction is for! OK. Quick, tell me this: does the function that bakes the pizza also heat the oven, or do you need to preheat it first? Hint: there are two functions. One is called bake and takes a Pizza, and the other is called bakePizza… Also, what happens if you pass a pizza to those functions twice? Are they idempotent or do you end up eating cinder? So, you may have guessed that I do not like the code style on the right. But I have to admit something: it is somehow easier to understand than the code on the left. Is that because of the structure that separates the levels of abstraction? Let us see. What about that version? func createPizza(order *Order) *Pizza { // Prepare pizza pizza := &Pizza{Base: order.Size, Sauce: order.Sauce, Cheese: “Mozzarella”} // Add toppings if order.kind == “Veg” { pizza.Toppings = vegToppings } else if order.kind == “Meat” { pizza.Toppings = meatToppings } oven := oven.New() if oven.Temp != cookingTemp { // Heat oven for (oven.Temp < cookingTemp) { time.Sleep(checkOvenInterval) oven.Temp = getOvenTemp(oven) } } if !pizza.Baked { // Bake pizza oven.Insert(pizza) time.Sleep(cookTime) oven.Remove(pizza) pizza.Baked = true } // Box and slice box := box.New() pizza.Boxed = box.PutIn(pizza) pizza.Sliced = box.SlicePizza(order.Size) pizza.Ready = box.Close() return pizza } Do you recognize it? This is just the left-hand side function code, with function names from the right-hand side added as comments. I don’t know about you, but this is my favorite. And it looks like the readability just came from explaining what we did properly here, not from extra abstraction layers and indirection. In conclusion, I stand by what I said earlier: do not extract small functions from linear code, especially if you only use them once. None of the benefits offsets the loss in linearity. One more thing I wasn’t sure if I wanted to mention this or not, but I ended up editing the post because there is something that bothers me with this function, and it is that business with the oven. First, pre-heating the oven is self-contained and should probably be a method of the oven itself. But beyond that, this code makes no sense: why would you create a whole new oven to make a pizza? In real life, you get an oven once, and then you bake a whole lot of pizzas with it, without going through the whole heating cycle. I know this is a synthetic example but this kind of issue actually occurs in real code and sometimes causes performance issues. It is likely that this code should take the oven as a parameter. Providing it is the job of the caller. (And since you put the pizza in the box, you probably want an interface where you return the box, not the pizza. Oh well.) [ home ]",
    "commentLink": "https://news.ycombinator.com/item?id=37517329",
    "commentBody": "Linear code is more readableHacker NewspastloginLinear code is more readable (separateconcerns.com) 248 points by dmarto 8 hours ago| hidepastfavorite213 comments theptip 4 hours agoIt’s a matter of style, and like cooking, either too much or too little salt will ruin a dish.In this case I hope nobody is proposing a single 1000-line god function. Nor is a maximum of 5 lines per function going to read well. So where do we split things?This requires judgment, and yes, good taste. Also iteration. Just because the first place you tried to carve an abstraction didn’t work well, doesn’t mean you give up on abstractions; after refactoring a few times you’ll get an API that makes sense, hopefully with classes that match the business domain clearly.But at the same time, don’t be over-eager to abstract, or mortally offended by a few lines of duplication. Premature abstraction often ends up coupling code that should not have to evolve together.As a stylistic device, extracting a function which will only be called in one place to abstract away a unit of work can really clean up an algorithm; especially if you can hide boilerplate or prevent mixing of infra and domain concerns like business logic and DB connection handling. But again I’d recommend using this judiciously, and avoiding breaking up steps that should really be at the same level of abstraction. reply ncann 3 hours agoparent> In this case I hope nobody is proposing a single 1000-line god function. Nor is a maximum of 5 lines per function going to read well.This is the key. Novice devs tend to write giant functions. Zealot devs who read books like Clean Code for the first time tend to split things to a million functions, each one a few lines long (pretty sure the book itself says no more than 5 lines for each function). I worked with a guy who extracted each and every boolean condition to a function because \"it&#x27;s easier to read\", while never writing any comments because \"comments are bad\" (according to the book). I hate that book, it creates these zealots that mindlessly follow its bad advices. reply usrbinbash 3 hours agorootparentThe problem with any good idea: As soon as it becomes dogma, it doesn&#x27;t matter how good the original idea was, it will turn itself bad. reply rightbyte 1 hour agorootparentAnd programmers are way worse than people in general when it comes to being dogmatic. reply jamil7 2 hours agorootparentprev> I worked with a guy who extracted each and every boolean condition to a function because \"it&#x27;s easier to read\"Obviously, readability is important, but I&#x27;ve also seen things like this so often in my career where it&#x27;s used as an excuse for anything. Most recently, trying to stop a teammate turning nearly every class into a singleton for the sake of \"simplicity\" and \"readability\", which I thought was a real stretch. reply livrem 3 hours agorootparentprevClean Code says \"Functions should not be 100 lines long. Functions should hardly ever be 20 lines long\".I think both 100 and 20 are a bit low, but much better than 5. As I mentioned in a comment a few days ago when I also corrected someone that misremembered a detail from the book, I am not a huge fan. But I also think it is mostly correct about most things, and not as terribly bad as some say. Listening to fans of the book is more annoying than to actually read the book.(And that other comment when I corrected someone was about bad comments. Clean Code definitely does not say that you shall never comment anything.) reply mcv 56 minutes agorootparentI think I completely agree with that line. 5 is a nice goal to aim for. Sometimes you hit 1, some things really do take 20. 100 lines is almost always a bad idea (unless it&#x27;s a 100 really boring and obvious lines).I haven&#x27;t read the book, and I can see how people can go overboard and can turn good advice into a caricature of it, but short, well-named functions that focus on a single thing are generally better than long ones that do dozens of different things. Separate those concerns. reply ahoka 1 hour agorootparentprevA classic criticism of CC: https:&#x2F;&#x2F;qntm.org&#x2F;clean reply raincole 2 hours agorootparentprevIt&#x27;s not from Clean Code, but Refactoring. reply coldtea 2 hours agoparentprev>In this case I hope nobody is proposing a single 1000-line god function.Why not? Who said it&#x27;s worse? What study settles the issue?Some times a \"1000-line god function\" is just what the domain needs, and can be way more readable, with the logic and operations consolidated, than 20 50 line functions, that you still have to read to understand the whole thing (and which then someone will be tempted to reuse a few, adjust them for 2-3 different needs not had by your original operation, and tie parts of the functions implementing your specific logic to irrelevant to it use cases).And if it&#x27;s a pure 1000-line function, it could even be 10,000 lines for all I care, and it would still be fine. reply visarga 1 hour agorootparentYeah, when code gets spread out across too many classes and functions, it&#x27;s like you&#x27;re trying to navigate a maze without a map. You hit a breakpoint, and you&#x27;re left scratching your head, trying to figure out what the heck each class is supposed to do. Names can be deceptive, and before you know it, the whole architecture feels like a jigsaw puzzle. It&#x27;s a cognitive load, having to keep track of all these quirks. Maybe it was easier for the author to do it that way when they started from scratch, but after they finished, it&#x27;s another deal. reply orwin 29 minutes agorootparentprevI think the only good use case I have for 50+ lines functions are finite state machines and renderers, whatever the form.Do you have other examples of 50+ lines functions where you thought it was the best to not separate issues? reply wiseowise 3 hours agoparentprev> In this case I hope nobody is proposing a single 1000-line god function.I’ll take well-structured 1000-lines function over bad spaghetti of hundreds small functions any day. reply npteljes 2 hours agorootparentGoing further, I&#x27;ll take a 1000-line shitty code, over split-to-small-functions shitty code. In the long code, all I have to think about is the code. With the functions, I have to pay attention to what calls what, also also because the code is shitty, surely the function names also are, adding two things at the same time to the confusion mix. reply Gibbon1 1 hour agorootparentEven better instead of a interrupt driven state machine implemented as a switch statement that linearly progresses. Do it using 20-25 small chained callbacks spread over a couple of files.Bonus: Uncle Bob teaches us not to use comments. reply leoedin 3 hours agorootparentprevHave you ever seen a well structured 1000 line function?I&#x27;m sure they exist - maybe some sort of exceedingly complicated data transform or something. But in almost every situation I&#x27;ve seen, a 1000 line function has countless side effects, probably sets a few globals, takes loads of poorly named arguments, each of which is a nested data structure which it reaches deeply into and often has the same for loop copied and pasted 10 times with one character changed.Often a 1000 line function is actually 5 or 6 20 line functions. I&#x27;m sure there are legitimate exceptions, but I&#x27;ve never seen them. reply Thorrez 2 hours agorootparenthttps:&#x2F;&#x2F;github.com&#x2F;github&#x2F;putty&#x2F;blob&#x2F;master&#x2F;terminal.c#L3281This function is 1830 lines long. It&#x27;s reasonably well structured I think. Although the #if 0 are maybe not so good. reply mattlondon 2 hours agorootparentA lot of those if-&#x2F;case-blocks are precisely where I&#x27;d put functions :)If you changed a bunch of those to separate, pure (i.e. side-effect-free) functions it would if nothing else make unit testing a breeze, and then you&#x27;d be free to fix bugs in the logic without fear. As it is, if I had a bug in that huge function I&#x27;d be really worried about breaking some edge-condition or implied-state 500 lines up etc. reply bombela 1 hour agorootparentprevOh my God. The sneaky `else` at line 3400.edit: another one at 3826 with a preprocessor define interleaved. reply pjc50 1 hour agorootparentprevWell that&#x27;s horrendous. Sorry, Simon. Each of those big \"switch\" statements should be broken out. reply deelly 3 hours agorootparentprevI`m not OP, but yes, I saw.Thats my personal opinion, and nothing more:Something like complex one time financial&#x2F;workflow&#x2F;maintenance operation that includes calling dozens of different smaller functions, but very well structured.It does not make sense to separate it more into different functions, because execution is generally linear and having to deal with tree of calls where some calls is depends on state of the previous is become cumbersome and makes reading and making changes more complex.Again, thats my personal feeling, and nothing more. reply atoav 3 hours agoparentprevIf we go with the cooking analogy, if you have to describe to someone how to cook a meal, and at one part of the meal you have to put the fond in, it is reasonable to explain how to make the fond in a seperate section. The fond is it&#x27;s own thing and it has one touching point with the food,therefore it is okay (or even benefitial) to move it out.Also: cooking recipes are also very abstracted. When they say you need to lightly fry onions they assume you know a way to cut onions and a lightly frying algorithm already. If they would inline everything it would become unreadable.Code is very similar. If you want it strictly without abstractions it will be as low level as your language allows you, and that is definitely not readable code.If you e.g. instead of using pythons \"decode\" method tries to do unicode decoding yourself it would become very hard to understand what your program is actually about. Now there are probably zero people who would do that, because the language provides a simple and well tested abstraction — but what makes that different from you creating your own simple and well tested abstraction and using that throughout the actual business logic of your code?The hard part is creating abstractions that are so well chosen that nobody will have to ever touch them again. reply wouldbecouldbe 1 hour agoparentprevMy biggest pain is Javascript developers who get to high on Java concepts, most often after using NestJS. Providers, Models, Services and what not.Remember an import script I wrote in ExpressJs. Was like 50 lines. Did things like copy databases, clean up config etc. There were hardly any layered ifs, just steps, I didn&#x27;t see much use in breaking it up, was easy to read.Another developer, who was smart but liked abstract concepts, overenginered the hell out of it, moving it to 20 places, a bunch of provider, and I could never find & make sense out of it after that, was very hard to read was going on. Was such a pain always to update it. reply ed_blackburn 1 hour agoparentprevAs soon as conversations stray into lines of code etc. I think we&#x27;ve veered directly into Goodhart&#x27;s Law. reply dsego 3 hours agoparentprev> Also iteration. Just because the first place you tried to carve an abstraction didn’t work well, doesn’t mean you give up on abstractions;C. Muratori calls this method \"semantic compression\" . https:&#x2F;&#x2F;caseymuratori.com&#x2F;blog_0015 reply djur 2 hours agorootparentWhat&#x27;s described there is what I understand DRY (\"don&#x27;t repeat yourself\") and the associated \"rule of three\" to mean. reply nevir 1 minute agoprevIt really all boils down to cognitive load:Can the average dev keep all of the variable states & side effects of the function in your head as they read through it? Great! Linear may be a good fit.Or does one need to jump up and down in the function to &#x2F;really&#x2F; understand it? Probably time to consider abstracting it. reply bsuvc 7 hours agoprevThe example code is vey simplistic, so of course that linear code is more readable, but the idea doesn’t scale.I think you have to consider things like reusability and unit-test-ability as well, and having all your code in a single function can make reasoning about it more difficult due to all the local variables in scope that you need to consider as possibly (maybe or maybe not) relevant to the block of code you’re reading.That being said, when I look back on my younger, less experienced days, I often fell into the trap of over-refactoring perfectly fine linear code into something more modular, yet less maintainable due to all the jumping around. There is something to be said for leaving the code as you initially wrote it, because it is closer to how your mind was thinking at the time, and how a readers mind will also probably be interpreting the code as well. When you over-refactor, that can be lost.So I guess in summary, this is one of those “programming is a craft” things, where experience helps you determine what is right in a situation. reply laserbeam 6 hours agoparent> The example code is vey simplistic, so of course that linear code is more readable, but the idea doesn’t scale.One of the best reviewed functions I wrote at work is a 2000 line monster with 9 separate variable scopes (stages) written in a linear style. It had one purpose and one purpose only. It was supposed to convert from some individual html pages used in one corner of our app on one platform into a carousell that faked the native feel of another platform. We only needed that in one place and the whole process was incredibly specific to that platform and that corner of the app.You could argue that every one of those 9 scopes could be a separate function, but then devs would be tempted to reuse them. Yet, each step had subtle assumptions about what happened before. The moment we would have spent effort to make them distinct functions we would have had to recheck our assumptions, generalize, verify that methods work on their own... For code that&#x27;s barely ever needed elsewhere. We even had some code that was similar to some of the middle parta of the process... But just slightly didn&#x27;t fit here. Changing that code caused other aspects of our software to fail.The method was not any less debuggable, it still had end to end tests, none of the intermediate steps leaked state outside of the function. In fact 2 other devs contributed fixes over time. It worked really well. Not to mention that it was fast to write.Linear code scales well and solves problems. You don&#x27;t always want that but it sure as hell makes life easier in more contexts than you&#x27;d expect.Note. Initial reactions to the 2000 line monster were not positive. But, spend 5 minutes with the function, and yeah... You couldn&#x27;t really find practical flaws, just fears that didn&#x27;t really manifest once you had a couple tests for it. reply saurik 6 hours agorootparentI don&#x27;t know if it is still like this, but the code for dpkg used to be like this, and it was amazing: if you ever needed to know in exactly what order various side effects of installing a package happened in, you could just scroll through the one function and it was obvious.To this end, I&#x27;d say it is important to be working in a language that avoids messing up the logic with boiler plate, or building some kind of mechanism (as dpkg did) to ease error handling and shove it out of the main flow; this is where the happy path shines: when it reads like a specification. reply realrains 6 hours agorootparentprevI don&#x27;t think the fact that a function works well is a good enough reason to write a 2000 line function. Sometimes there are long pieces of code that implement complex algorithms that are difficult to break into smaller pieces of code, but those cases are limited to the few you mentioned. reply BigJono 4 hours agorootparentComputers execute code in a linear fashion, why on earth would you \"need a reason\" to NOT abstract something? Just because abstraction is often the right thing to do doesn&#x27;t make it the base case.It&#x27;s like saying you need a reason not to add 4000 random jumps in your assembly code just to make it more difficult to read... reply ahtihn 4 hours agorootparentSource code isn&#x27;t written to be executed by computers, it&#x27;s written to be read by other humans.Source code tends to be very far removed from how computers execute anything, so I wouldn&#x27;t use that as a justification for any sort of code style. reply amoss 3 hours agorootparent> Source code isn&#x27;t written to be executed by computers, it&#x27;s written to be read by other humans.It is pronounced \"documentation\". reply nomel 3 hours agorootparentprev> that implement complex algorithms that are difficult to break into smaller pieces of codeMy longest code is always image processing. It&#x27;s usually too hard to break up for the sake of breaking up. There&#x27;s nothing to reuse between the calls to filters&#x2F;whatever. reply flohofwoe 3 hours agorootparentprevThe default should be reversed, don&#x27;t break into smaller pieces unless there&#x27;s a really good reason. reply coldtea 2 hours agorootparentprev>I don&#x27;t think the fact that a function works well is a good enough reason to write a 2000 line function.The fact that it works well and reads well (when it does, as in the parent&#x27;s case), is.Aside from those factors what else would be against it? Dogma? reply nevir 3 minutes agorootparentThe cognitive load can be a consideration:Can you keep all of the side effects of the function in your head as you read through it? Or do you need to jump up and down in the function to &#x2F;really&#x2F; understand it? reply osigurdson 4 hours agorootparentprevI guess all we know is there were 2K lines of code and the commenter thinks that was the right way to do it. It would be necessary to see the code to appropriately critique it. reply goatlover 3 hours agorootparentNot just the commenter, but his team as well. It passed code review with flying colors, apparently. The moral of the story is that there always exceptions and developers should not be ideologically committed to one approach above all else. reply RHSeeger 5 hours agorootparentprev>The moment we would have spent effort to make them distinct functions we would have had to recheck our assumptions, generalize, verify that methods work on their ownWhy? Why can&#x27;t the functions say \"to be used by , makes assumptions based on that function, do not use externally\"? Breaking out code into a function so that the place it came from is easier to maintain... does not mandate that the code broken out needs to be \"general purpose\". reply laserbeam 5 hours agorootparentSpecifically, in that place, there was no need. And prematurely splitting it would have caused us to overthink and over generalize. Having a long, linear and tested function was a better choice. reply auggierose 4 hours agorootparentI understand your point, but perhaps that would have simply been an opportunity to refine your approach to code design. If such a situation leads to excessive deliberation and overgeneralisation, your code base must be riddled with unnecessary overthinking and overgeneralisation. reply wiseowise 3 hours agorootparentGlad you can see that without even looking at the code. reply auggierose 2 hours agorootparentSome things you don&#x27;t have to see to know whats going on. Function with 2000 lines of code? Have fun rationalising this. reply goatlover 3 hours agorootparentprevOr maybe it was just a long, sequential algorithm where breaking it up wouldn&#x27;t have been an improvement. reply auggierose 2 hours agorootparentI have been programming for more than 30 years. Except for code generated explicitly to be only consumed by machine, I&#x27;ve never come across a function consisting of 2000 lines of code that should not have been broken up. Something is wrong there, and if you show me the code, I&#x27;ll tell you what&#x27;s wrong with it. replykoonsolo 4 hours agorootparentprevAt first I thought how horrible, but basically you have sort of 9 functions within the same scope, each having a docstring. So I guess not too different from splitting them up.I read you have \"end to end\" tests.One question though: Wouldn&#x27;t each part benefit for having their own unit tests? reply laserbeam 4 hours agorootparentMaybe, maybe not. For our particular case it would have been mostly wasted effort.I found that I like to write tests at the level of abstraction I want to keep an implementation stable. I&#x27;d be totally fine if someone went in and changed the implementation details of that long process if needed. We cared that stuff got cleaned up at the end of the process, that the output matched certain criteria, that certain user interaction was triggered and so on... In that case it made more sense to test all our expectations for a larger scope of code, rather than \"fix\" the implementation details.Tests usually \"fix\" expectations so they don&#x27;t change from build to build. Tests don&#x27;t ensure correctness, they ensure stuff doesn&#x27;t alter unexpectedly. reply coldtea 2 hours agorootparentprev>One question though: Wouldn&#x27;t each part benefit for having their own unit tests?Not necessarily better, especially since this allows for the case where individual unit tests pass fine, but the combined logic fails. reply osigurdson 4 hours agorootparentprevYou don&#x27;t have to write tests to prove that private methods work on their own. Just test the public behaviour. reply waynesonfire 6 hours agorootparentprevI worked with an engineer that wrote the most clear and elegant linear code. It was remarkable, never seen anything like it since. I can&#x27;t reproduce it but I do have an idea of what a well designed linear function looks like.. a story. reply eep_social 3 hours agorootparentI was just thinking that if I _needed_ to refactor this I might structure the stages as chapters in a book. One might be able to write an inner class or some such that had a “table of contents” function that called each stage in sequence as a void function with data managed out of line, maybe via cleverly designed singleton structs. Then the code itself can be written in order with minimal boilerplate between stage boundaries.I think I’ve worked with some Python that looked and worked this way. I can’t place the details but probably in a processor pipeline running over a particularly hairy data format. Consider ancient specifications written by engineers talking on the phone encapsulated in relatively “modern” but still vintage specifications, sometimes involving screen-scraping a green screen mainframe terminal, wrapped in XML and sent over the internet. Anyway, point is I couldn’t agree more about stories. reply laserbeam 5 hours agorootparentprevI will agree that it takes some skill, not that I am great at it. It&#x27;s a different kind of skill than abstraction. Reading error handling in c code offered good insights for me to learn linearity better (c code that uses goto to jump to the end of a function for cleanup when an error occurs, for example).However, if you screw up linear code, you screw up locally. If you write poor small functions, the rest of the team screws up because they barely ever read the contents of your functions that call other functions that call other functions. I&#x27;ve had way more problems with stuff being called slightly out of order, than with large functions. reply yxhuvud 5 hours agorootparentprevThat is true of well designed nonlinear code as well.The code needs to tell a story or it will be a mess. reply emodendroket 4 hours agorootparentprev> You could argue that every one of those 9 scopes could be a separate function, but then devs would be tempted to reuse them.Good thinking. Now they’ll just add 50 flags and ten levels of nested ifs instead which is much simpler. reply patrulek 4 hours agorootparentprev2000 lines is like a small project. I cant imagine putting that all in one function. reply gabereiser 6 hours agorootparentprev>”but then devs would be tempted to reuse them”Isn’t that the fucking point? Having a 2000 line function is a code smell so bad, I don’t care how well the function works. It’s an automatic review fail in my book. Abstractions, closures, scope, and most importantly - docs to make sure others use your functions the way you intended them. Jesus. reply laserbeam 5 hours agorootparentSome devs did find it a code smell... But each scope had a clear short high level comment describing what it did, there were end to end tests for the method, and very little state flowed from scope to scope (some did) - because that&#x27;s what scoprs do... Prevent variables from leaking.My point is the code smell isn&#x27;t always accurate, and there are times and even for 2000 line monsters other devs agreed that it was the best way to hide complexity away from the rest of the codebase in that case. If we ever needed to factor things out (we never did), we could spend some effort and do it. reply okaleniuk 4 hours agorootparentprevHave you tried reading code instead of smelling it? reply MrPatan 4 hours agorootparentprevA code smell means you should look into it, not that it&#x27;s wrong.Some things are genuinely 2kloc-complex. Maybe not that many. Do check! But some are. reply laserbeam 3 hours agorootparentDefinitely not that many. Even for me this was an outlier, but it made me more comfortable with functions most people would consider long.I&#x27;d like to clarify this was not necessarily 2kloc-complex, this was just 2kloc-long-and-not-really-meant-to-be-reused. It was a fairly long but linear process that was out of the ordinary for the rest of the codebase. It could easily have been split (hell, I had 9 fairly separate stages), but calling any of the intermediate stages out of order or without the context of the rest of the execution flow... would have been a foot gun for someone else. And, as time showed, we never needed those stages for anything else. reply turdprincess 5 hours agorootparentprevAgreed. I’ve written plenty of software of all kinds and have never had to write a 2000 line long methods (although I have had the joy of refactoring such messeses a time or two).Just don’t do that. Your code doesn’t have to have abstractions out the wazzo, but if your class (or method) is getting bigger than 1000 lines that’s a great sign that it’s doing too much and abstractions can be teased out. Your future self will thank you, as well as your team. reply crabmusket 4 hours agorootparentI like this from Sandi Metz:> You can&#x27;t create the right abstraction until you fully understand the code, but the existence of the wrong abstraction may prevent you from ever doing so. This suggests that you should not reach for abstractions, but instead, you should resist them until they absolutely insist upon being created. reply whywhywouldyou 6 hours agoparentprevSo where&#x27;s the proof that the function&#x27;d code scales? As the complexity of the overall code grows, so would something that gets chopped into dozens of functions to the point of being unreadable.Suddenly, you realize that the dozens of functions __need to be called in specific orders__, and they are each only ever used once. So really what you&#x27;re doing is forcing someone to know the magic order these functions are composed in order for them to be of any use. reply harpiaharpyja 6 hours agorootparentThe truth is that either one can be done wrong.Unfortunately organizing your code along the right lines of abstraction is something that just takes skill and can&#x27;t easily be summarized in the form of \"just always do this and your code will be better\"If you organize your code into units that are easy to recompose and remix, well you get huge benefits when you want recompose and remix things.If you organize your code into units that can&#x27;t be easily recomposed, then yes you&#x27;ve added complexity for no benefit. But why make units that can&#x27;t be treated individually?\"As the complexity of the overall code grows, so would something that gets chopped into dozens of functions to the point of being unreadable.\"So the answer to this is, \"don&#x27;t chop it into functions in a way that leaves it unreadable, instead chop it into functions in a way that leaves it more readable.\"That may be unsatisfying, but it gets to the point that blindly applying rules is not always going to lead to better code. But it doesn&#x27;t mean that an approach has no value. reply erhaetherth 5 hours agorootparentThere&#x27;s an easier approach that will also aid you in telling you how to precisely chop up your function.Simply don&#x27;t chop up your function until you need a slice of it somewhere else. Then refactor out the bit you need. You&#x27;ll find out exactly which bits need to be replaced with variables and exactly where the slice needs to happen. reply atq2119 5 hours agorootparentThis is the correct answer right here if you have a good enough team. It is still the way I want to work. Unfortunately, I find that there are too many developers who haven&#x27;t learned that you should always be considering to \"refactor as you go\". I&#x27;m trying to teach by example, but it&#x27;s an uphill battle. reply pstuart 4 hours agorootparentprevExactly. Start with the straight-ahead linear approach and factor out once it&#x27;s unwieldy.Same thing for copy pasta funcs -- the first copy is fine, the second one may be too, but after that consider extracting to a parameterized func (a permutation of the Go Proverb \"A little copying is better than a little dependency.\") reply lelanthran 5 hours agorootparentprev> Suddenly, you realize that the dozens of functions __need to be called in specific orders__, and they are each only ever used once. So really what you&#x27;re doing is forcing someone to know the magic order these functions are composed in order for them to be of any use.That&#x27;s where nested functions show their true utility. You get short linear logic because everything is in functions, but the functions are all local scope so you get to modify local scope with them, and because the functions are all named, it is easy to determine what is going on. reply Guvante 6 hours agorootparentprevThe API shouldn&#x27;t be that. Expose something easy to use. That is the point of abstractions. It doesn&#x27;t matter if there are a dozen methods called in order if those dozen methods are called by a helper method, beyond maybe some implementation details.Really the question should always come up when there are more than say two ways to do things. If I can make a pizza from scratch, reheat a chilled pizza, create a pizza and chill it, reheat a half dozen pizzas, or make three pizzas of the same kind and chill them suddenly the useful abstractions are probably something you can figure out between those helper methods.Honestly that is the real fear of the left way of thinking. If you add a quantity, whether to cook and whether to chill parameters you end up with a hard API where certain combinations of parameters don&#x27;t make sense.Have a clean API and make the implementation as simple as is feasible. Reuse via functions when it makes sense but don&#x27;t add them willy nilly.Aka \"it is a craft and you figure things out\" as someone said in the comments here reply lenkite 3 hours agorootparentprevIf you have dozens of functions that need to be called in specific orders, design and use a state machine and then use a dispatch function that orchestrates the state machine. reply professoretc 6 hours agorootparentprevIn a decent programming language you can nest functions, so all the little functions that make up some larger unit of the program are contained within (and can only be called within) that outer function. They serve less as functions to be called and more just as names attached to bits of code. And since they can&#x27;t be called anywhere else, other people don&#x27;t need to worry about them unless they&#x27;re working on that specific part of the program. reply dfee 6 hours agorootparentprevDozens of functions need to be called in a specific order?Oh my God. reply rramadass 6 hours agoparentprev> but the idea doesn’t scale.You are wrong here.> this is one of those “programming is a craft” things, where experience helps you determine what is right in a situation.You are right here.The key insight on why giant linear functions are often more readable (and desirable) is because they allow you to keep more concepts&#x2F;relationships simultaneously together as a single chunk without context switching which seems to aid our comprehension. An extreme proponent is Arthur Whitney (inventor of the K language) who writes very terse (almost incomprehensible to others) code so as to accommodate as much as possible in a single screen.Two examples from my own experience;1) I found reading&#x2F;understanding&#x2F;debugging a very large Windows message handler function (i.e. a WndProc with a giant switch statement containing all the business logic) far easier than the same application rewritten in Visual C++ where the message handlers were broken out into separate functions.2) The sample code for a microcontroller showed an ADC usage example in two different ways; One with everything in the same file and another where the code was distributed across files eg. main.c&#x2F;config.c&#x2F;interrupts.c&#x2F;timer.c&#x2F;etc. Even though the LOC wasan extreme proponent is Arthur Whitney (inventor of the K language) who writes very terse (almost incomprehensible to others) codeBut k has a small set of built-in commands and a built-in database; it was made for fast analysis of stock information, so with that you have everything you need and you use the same semantics. The only thing you need to know is the data structure and you can build whatever you need.So in this way, it&#x27;s very likely that, given two tables A + B and &#x27;bunch of operations&#x27; X on A and &#x27;bunch of operations Y&#x27; on B where Y depends on the result of X, and given the tasks to;- create X&#x27; = X- create XY&#x27; = X + Yto implement XY without knowing X already exists rather than figure out X exists and reuse it.The problem with not k (or programs written in similar style; it doesn&#x27;t really matter what the programming language is), that we have learned to use the second style from the article, and, more extreme, to separate everything out in layers. You cannot even reach the data model without going through a layer (or more) of abstractions which makes it necessary not only to know the datamodel in detail but also find the matching findXinAandApplyWithYToB(). Where X & Y & A & B are often some kind of ambiguous and badly named entities. And then there is of course badly designed databases which is also quite the norm as far as we see, so there is a much lower data integrity which means that if you create something without checking all the code that touches it, that you might change something and the data becomes inconsistent.I notice the same when working on systems built with stored procedures on MSSQL&#x2F;Postgres; it is far quicker to oversee and (at least basically) understand the datamodel (even with 1000+ tables, which is rather normal for systems we work with) than it is to understand even a fraction of a, let&#x27;s say Go, codebase. So when asked to do do a task XY&#x27;, you are usually just not searching for X&#x27;; you are simply reading the data used in X & Y and whop up a procedure&#x2F;query&#x2F;whatever yourself. It&#x27;s simply much faster as you have a restricted work surface; the model and sql (I know, you can use almost any language in postgres, but let&#x27;s not here) and you can reason about them and the tasks at hand when you shut off internet and just use your sql workbench. reply RHSeeger 5 hours agorootparentprevYEAH, but the moral that should be taken from that is not \"it&#x27;s always better to write huge, linear functions\". Rather, \"there are cases where huge, linear functions make sense because of the way the code needs to interact with things\". Along the same lines, there are cases where breaking the code up into smaller functions, and calling them from the main function, makes more sense\".> Linear code is more readable^ Wrong> Linear code is sometimes more readable^ Better reply starbugs 4 hours agoparentprevI have seen many instances where people just out of habbit factor out a lot of linear code that will never be reused into separate functions.These pieces of code then often end up being private functions of a class. With state. Since they are private functions now, they are not really testable.So now we got a lot of private functions that are only called once and typically modify side effect state. When these functions are grouped together with the caller, it is actually still a bit readable in simple cases.But then after a while someone adds other functions in between the calling function and the factored out ones.Now we have bits and pieces modifying different side effect state that no one knows if they are called from different places without getting a call graph or doing a search in the class file.If you insist on making the code non-linear, I&#x27;d beg you to at least consider making these factored out private funcs inner funcs of the calling function if your language supports that. This makes it clear that these functions won&#x27;t be called from anywhere else.As with so many things in life, in a real codebase this is not an either&#x2F;or, but an art of combining the two into something that stays readable and maintainable. reply flohofwoe 3 hours agoparentprev> The example code is vey simplistic, so of course that linear code is more readable, but the idea doesn’t scale....that&#x27;s basically why common sense and taste in programming is still required, it&#x27;s not a purely mechanical task. That&#x27;s also why I&#x27;m not entirely a fan of automatic code formatting tools, they don&#x27;t understand the concept of nuance. reply matsemann 4 hours agoparentprevIf the function was truly linear having a long function wouldn&#x27;t be so bad. But it actually isn&#x27;t, the example contains multiple branches!Will people bother testing all of them? Or will they write a single test, pass in a pizza and just glance at it actually working? My guess is the latter, as testing multiple branches from outside is often tedious, vs testing smaller specialized functions. reply s17n 6 hours agoprevEveryone saying \"linear code doesn&#x27;t scale\" actually has it backwards - it&#x27;s concise functions with a deeply nested call stack that really becomes a nightmare in large codebases. It&#x27;s never obvious where new code should be added, the difficulty of understanding what the effects of your changes will be increases exponentially since you have to trace all the possible ways code can get called, you end up with duplicated subroutines, etc etc.99% of the time, you haven&#x27;t actually come up with a good abstraction, so just write some linear code. Prefer copy&#x2F;pasting to dubious function semantics. reply gorgoiler 5 hours agoparentAnother risk is if you add print_table() then someone else is going to find it and use it in their code, but also add a little flag to adjust the output for their use case.12 months later you have: print_table( rows, headers = None, is_unicode = False, left_align = False, align = [], remove_emoji = None, max_width = 80, potato_mode = 7, _debug_frontend = not FLAGS.dont_debug, ellipsis_for = 0, no_print = False, ) reply tonyedgecombe 16 minutes agorootparentI just had to implement potato_mode in a report, what a rabbit hole that turned out to be. reply ncann 3 hours agorootparentprevI think we all know at least some functions like this in a code base. All it takes is for a newcomer to come across a complex function that they need to update some logics for but also don&#x27;t understand it enough to refactor, so they just added some parameters with default values and call it a day.> no_print = Falselove this reply reedf1 2 hours agorootparentprevTo play devil&#x27;s advocate - what&#x27;s the issue with this?Is print_table() + print_table_without_emoji() better than print_table(remove_emoji= False)? reply krembo 1 hour agorootparentprevThis example looks totally legit to me as long as it preserves backward compatibility and doesnt add unnecessary junk flags reply corethree 5 hours agoparentprevWell you&#x27;re describing a readability problem. And you&#x27;re essentially saying readability is what causes it not to scale.If we consider the concepts orthogonally meaning we don&#x27;t consider the fact that readability can influence scalability then \"everyone\" is fully correct. Linear code doesn&#x27;t scale as well as modular code. The dichotomy is worth knowing and worth considering depending on the situation.That being said I STILL disagree with you. Small functions do not cause readability issues if those functions are PURE. Meaning they don&#x27;t touch state. That and you don&#x27;t inject logic into your code, so explicitly minimize all dependency injection and passing functions to other functions.Form a pipeline of pure functions passing only data to other functions then it all becomes readable and scalable. You&#x27;ll much more rarely hit an issue where you have to rewrite your logic because of a design flaw. More often then not by composing pure functions your code becomes like legos. Every refactoring becomes more like re-configuring and recomposing existing primitives. reply bcrosby95 3 hours agorootparentI disagree. It&#x27;s not the purity of the functions, its having to know the details of them. The details, which could have existed here, are now in two other places. If you need to figure out how a value is calculated, and you use a half dozen functions to come to that value, you now have a half dozen places you need to jump to within the codebase.Small functions increase the chances of you having to do this. Larger ones decrease it, but can cause other issues.Also, many small functions doesn&#x27;t make code modular. Having well defined, focused interfaces (I don&#x27;t mean in the OO sense) for people to use makes it modular. Small functions don&#x27;t necessarily harm it, but if you&#x27;re not really good at organizing things they definitely can obscure it. reply tonyedgecombe 12 minutes agorootparentI find how easy it is to name something is a pretty good indicator. If I&#x27;m struggling to name a function then it probably needs some more attention. reply tlarkworthy 1 hour agoprevJohn carmack said much the same and I have been following it ever since. Of course linear code is easier to read, if follows the order of execution. It minimizes eye saccades.Some code needs to be non-linear for reuse. Then execution is a graph. If you code does not exploit code reuse from a graph structure, do not bother introducing vertexes where a single edge suffices.http:&#x2F;&#x2F;number-none.com&#x2F;blow&#x2F;blog&#x2F;programming&#x2F;2014&#x2F;09&#x2F;26&#x2F;carm... reply devjab 5 hours agoprevI actually sort of agree that linear code is more readable, but that’s not what makes good code practices alone. So while good linear code is more readable, at least in my opinion, it’s also a lot less maintainable and testable. I have a few decades of experience now, I even work a side gig as an external examiner for CS students, and the only real world good practices I’ve seen over the years is keeping functions small. I know, I know, I grade students on a lot of things I don’t believe in. I’m not particularly fond of abstraction, or even avoiding code-duplication at all costs and so on, but “as close to single purpose” functions as you can get, do that, and the future will thank you for it.Because what is going to happen when the code in those examples run in production over a decade is that each segment is going to change. If you’re lucky the comments will be updated as that happens, but they more than likely won’t. The unit test will also get more and more clunky as changes happen because it’s big and unwieldy, and maybe someone is going to forget to alter the part of it that wasn’t obviously tied to a change. The code will probably also become a lot less readable as time goes by, not by intend or even incompetence but mostly due to time pressure or other human things. So yes, it’s more readable, and in the perfect world you probably wouldn’t need to separate your concerns, but we live in a very imperfect world and the smaller and less responsibility you give your functions the easier it’ll be to deal with that imperfection as time goes on. reply mtreis86 5 hours agoparentI recently started reading Sussman&#x27;s Software Design for Flexibility and what you write is directly in line with that book https:&#x2F;&#x2F;mitpress.mit.edu&#x2F;9780262045490&#x2F; reply Shoop 6 hours agoprevRelated email by John Carmack: http:&#x2F;&#x2F;number-none.com&#x2F;blow&#x2F;blog&#x2F;programming&#x2F;2014&#x2F;09&#x2F;26&#x2F;carm...Discussion: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=12120752 reply munro 52 minutes agoprevI have to agree that the code on the left is far more readable (one function). I&#x27;ve worked with developers that have written code on the right (lots of functions), and it&#x27;s always the worst to iterate on.The problem in the second approach is the functions aren&#x27;t clean abstractions, they often hide logic&state transformations that only make sense in the calling context. So the dear reader is forced to jump back and forth between the multiple functions to understand the entire process.And just to throw a bit of shade, I encountered this type of programming more in webdev, and especially devops communities-- than with data scientists, ml, or data engineers. ;) And also when the director of eng wanted to get their feet wet every now and then. reply latchkey 6 hours agoprevThe code that is more easily unit testable, is the code I care about.Neither example is easily tested.Neither support injecting the dependencies, which make mocking really difficult.On the left, you&#x27;re testing one big method with a whole bunch of conditionals, which leaves you with a whole ton of tests for that one big method.On the right, there is a bake() method and it does oven.New(), but where does oven come from? Is it some global somewhere? reply jpc0 6 hours agoparentHere is an idea for a unit test for this code.Pass in an order, assert the pizza that comes out is correct.The entire function is a unit which can fit on my phone screen and has no external dependencies other than possibly oven, which was discussed in the article, it should probably have been passed in, aka dependency injection. reply latchkey 6 hours agorootparentSince the example was golang, I personally love uberFX to define modules and dependencies between modules. When you do it that way, unit tests become really easy.It isn&#x27;t necessary with golang to do this at all, but it really helps build consistent structure throughout the entire app, so I do it.Speaking from personal experience. I built a small golang process that ran on around 25k worker machines. It had to be bug free cause if it crashed and stopped running, it meant updating a whole lot of computers across multiple data centers, by hand.We unit tested everything and the project worked out really well because of that. reply anon-3988 5 hours agoparentprevunit test is overrated because most of the problems can be solved via correct by construction methods. Like, do you really need to check if this \"kind\" variable is equal to \"Veg\"? This could have easily been solved by using Enum. Similarly, global or not can be solved by using classes&#x2F;structs that don&#x27;t have any constructors or something like that.Functions should exist at the level of concepts:1. arrflatmapcollect as HashMap makes sense.2. CreateFlattenMappedHashMapFromArr does not. reply skybrian 6 hours agoprevThey both read linearly. In the version with smaller functions taken out, there&#x27;s a table of contents at the top of the page and it summarizes the dataflow between the steps. It seems like an appealing read order, assuming you&#x27;re going to read the whole thing.For it to stay this readable, though, you&#x27;d need to move the functions around if you change the order of the steps. And that&#x27;s fine if they&#x27;re private functions, called only from the table of contents. Only, nothing forces you to keep them in order, or even to think about how it reads overall.It often happens that functions start being reused in a way that can&#x27;t be linearized anymore. Sometimes people give up and sort them alphabetically, or it&#x27;s just random. reply fjfaase 28 minutes agoprevWhen you grow older, and become lazier, you only create function&#x2F;methods when they need to be called more than once. Some languages, like C# and JavaScript, also allow you to define them local (inside a method). When these are used to perform some checks, I usually just place them before they are used, and when the perform some operation, I usually place them just below where they are called. The latter usually involves async of parallel execution. I just realize that this helps to keep the code more linear. So, I think I have a strong preference for linear code. reply jonahx 6 hours agoprevHard agree. And I used to belong to the other camp.The basic tension here is between locality [0], on the one hand, and the desire to clearly show the high-level \"table of contents\" view on the other. Locality is more important for readable code. As the article notes, the TOC view can be made clear enough with section comments.There is another, even more important, reason to prefer the linear code: It is much easier to navigate a codebase writ large when the \"chunks\" (functions &#x2F; classes &#x2F; whatever your language mandates) roughly correspond to business use-cases. Otherwise your search space gets too big, and you have to \"reconstruct\" the whole from the pieces yourself. The code&#x27;s structure should do that for you.If a bunch of \"stuff\" is all related to one thing (signup, or purchase, or whatever), let it be one thing in the code. It will be much easier to find and change things. Only break it down into sub-functions when re-use requires it. Don&#x27;t do it solely for the sake of organization.[0] https:&#x2F;&#x2F;htmx.org&#x2F;essays&#x2F;locality-of-behaviour&#x2F; reply haberman 4 hours agoparentI went the opposite direction: I used to be in the linear code camp, and now I&#x27;m in the \"more functions\" camp.For me the biggest reason is state. The longer the function, the wider the scope of the local variables. Any code anywhere in the function can mutate any of the variables, and it&#x27;s not immediately clear what the data flow is. More functions help scopes stay small, and data flow is more explicit.A side benefit is that \"more functions\" helps keep indentation down.At the same time, I don&#x27;t like functions that are too small, otherwise it&#x27;s hard to find out where any actual work gets done. reply jonahx 3 hours agorootparentSome important context re: my style...> Any code anywhere in the function can mutate any of the variablesRegardless of the language I&#x27;m using, I never mutate values. Counters in loops or some other hyper-local variables (for performance) might be the inconsequential exceptions to this rule.> More functions help scopes stay small, and data flow is more explicit.Just write your big function with local scope sections, if needed (another local exception to the rule above). Eg, in JS: let sectionReturnVal { &#x2F;&#x2F; stuff that sets sectionReturnVal }or even use IIFE to return the value and then you can use a const. \"A function, you&#x27;re cheating!\" you might say, but my goal is not to avoid a particular language construct, but to maintain locality, and avoid unnecessary names and jumping around.> A side benefit is that \"more functions\" helps keep indentation down.This is important and I maintain it.See \"Align the happy path to the left\" (https:&#x2F;&#x2F;medium.com&#x2F;@matryer&#x2F;line-of-sight-in-code-186dd7cdea...)It is also worth noting that solving this problem with function extraction can often be a merely aesthetic improvement. That is, you will still need to keep hold the surrounding context (if not the state) in your head when reading the function to understand the whole picture, and the extraction makes that harder.Using early returns correctly, by contrast, can actually alleviate working memory issues, since you can dismiss everything above as \"handling validation and errors\". That is, even though technically, no matter what you do, you are spidering down the branches of control flow, and therefore in some very specific context, the code organization can affect how much attention you need to pay to that context.> I don&#x27;t like functions that are too small, otherwise it&#x27;s hard to find out where any actual work gets done.Precisely, just take this thinking to its logical conclusion. You can (mostly) have your cake and eat it too. reply _dain_ 3 hours agorootparentprevThe better solution to this is to use nested functions that are immediately called, rather than top level functions. That lets you cordon off chunks of state while still keeping a linear order of definition and execution. And you don&#x27;t have to worry about inadvertently increasing your API maintenance burden because people started to depend on those top level functions later. reply jonahx 3 hours agorootparentHa, I started writing my reply before seeing yours, and suggested almost the same thing. reply ryanjshaw 6 hours agoparentprev> Only break it down into sub-functions when re-use requires it. Don&#x27;t do it solely for the sake of organizationWhat about for testing? What about for reducing state you need to keep in mind? What about releasing resources? What about understanding the impact of a change? Etc.Consider an end of day process with 10 non-reusable steps that must run in order and each step is 100 lines. Each step uses similar data to the step before it so variables are similar but not the same. You would really choose a 1000 line single function? reply jonahx 6 hours agorootparent> What about for testing?For \"use-case\" code like this with many steps, you are typically testing how things wire together, and so will either be injecting mocks to unit test, in which case it is not a problem, or wanting to integration or e2e test, in which case it is also not a problem.If complex, purely logical computation is part of the larger function, and you can pull that part out into a pure function which can be easily unit tested without mocks, that is indeed a valid factoring which I support, and an exception to the general rule.> What about for reducing state you need to keep in mind?Typically not a problem because if the function corresponds to a business use-case, you and everybody else is already thinking about it as \"one thing\".> What about releasing resources?Not a problem I have ever once run into with backend programming in garbage collected languages. Obviously if you are in a different situation, YMMV.> Consider an end of day process with 30 non-reusable steps that must run in order and each step is 100 lines.I would use my judgement and might break it down. Again, I have never encountered such a situation in many years of programming.You seem to be trying to find the (ime) rare exceptions as if those disprove the general rule. But in practice the \"explode your holistic function unnecessarily into 10 parts\" is a much more common error than taking \"don&#x27;t break it down\" too far. reply syntheweave 6 hours agorootparentprevnext [–]let DebugFlags = {StepOne=false, StepTwo=false, StepThree=true}; if (DebugFlags.StepOne) { ... } if (DebugFlags.StepTwo) { ... } if (DebugFlags.StepThree) { ... }Your training in structured, DRY and OOP will recoil at this: More branches! Impossible. But your spec says \"must run in order\". It does this by design. Every resource can be tracked by reading it top to bottom, and the only way in which you can miss it is through a loop, which you can also aim to minimize usage of. The spec also says \"uses similar data to the step before it\". If variables are similar-not-same, enclose them in curly braces so that you get some scope guarding. The debug flags contain the information needed to generate whatever test data is necessary. They can alternately be organized as enumerated state instead of booleans: {All, TestOne, TestTwo, TestThree}.Long, bespoke linear sequences can be hairy, but the tools to deal with them are present in current production languages without atomizing the code into tiny functions. Occasionally you can find a useful pattern that does call for a new function, and do a \"harvest\" on the code and get its size down. But you have to be patient with it before you have a good sense of where a new parameterized function gets the right effect, and where inlining and flagging an existing one will do better. reply js8 4 hours agoprevI think the fundamental problem is that, despite our wishes, there are programs which are inherently complex, and cannot be refactored into a simple, by-pieces testable, form. And if we try to do that anyway, all we end up with is just more fluff (mocking, I am mocking you) that hides the complexity.The internal complexity doesn&#x27;t necessarily come from complex abstractions. Take for example some implementation of a tax code, i.e. code calculating taxes. There is probably gonna be a lot of interdependencies, dealing with special cases. That&#x27;s your typical \"business logic\". This code is not inherently complex because the primitives are complex, but because there is a lot of dependencies in the calculation. That fact in itself makes it difficult to unit test.On the other end of the spectrum, we have something like a library of functions, for example, mathematical functions. The inner workings of how to calculate, say, a gamma function, can be very complex to understand, but the surface (API) of each of the function is very small, and that makes the library itself simple and easy to unit test.We can make an analogy with books instead of programs. On one end, you have a novel, which despite being written in a plain language, has many interdependencies of the characters interacting. You cannot \"unit test\" a novel by reading a single chapter, you have to read it all. You can have a summary of the novel (like the top function in exhibit B in the OP&#x27;s example), but the summary of the novel is not exactly the novel, you&#x27;re not really testing the novel if you read just the summary.On the other end, there are reference works like dictionary or encyclopedia. We can unit test these easily, since each entry should stand on its own (if you want to evaluate quality of a reference work, you can pick a few entries and test that, and it&#x27;s gonna be pretty representative). They are not emergently complex like a novel is, despite the fact that entries might use specialized jargon and be harder to read. reply andrewjl 3 hours agoparent> That fact in itself makes it difficult to unit test.Verifying a tax code implementation is a good place to make use of property based testing. reply js8 3 hours agorootparentI agree, and that&#x27;s why I favor it to unit testing (although to be fair, they are pretty complementary, because each addresses different end of the spectrum). To properly unit test, you need to have a different implementation, which you can compare with, you cannot IMHO unit test under the same assumptions that the code makes. reply mcv 1 hour agoprevI completely disagree with the article. The right hand side is far better. Not perfect; there are definitely a couple of things to improve, but it&#x27;s better than just a big long meandering god function like on the left. It feels like the author is arguing to go back to the coding style of the 1980s.Big advantage of the right-hand style: the various steps are laid out in a simple 5-line function. You immediately see what making a pizza involves. Want to know more about it (like whether baking involves the creation of a completely new oven), you can zoom in on the details, but you never have to look at details that are irrelevant to you, unlike on the left side, where you have to dig through a page of code to figure out which part is relevant to you.Mind you, there are a lot of ways in which the right hand style could go wrong: if you don&#x27;t separate your concerns, and have global or member variables manipulated by different functions in ways that are not immediately obvious, then superficially clean code could be hiding some terrible spaghetti. But at least the right-hand style punishes you for that and encourages you to do better (in fact, I&#x27;m currently refactoring a bit of code that did exactly that). The left hand side would allow terribly messy code with complex interactions between different parts of the code without making it obvious that those interactions are there, and will make it more intimidating to refactor them. Small functions are easier to test and easier to refactor. reply lucumo 6 minutes agoparentI agree. The right hand side also makes it very easy to zoom in on the problem details. If the pizza is not properly boxed, I don&#x27;t want to worry about whether the salami was sliced the right way. I can skip over that, and immediately zoom in on the boxing process.Pretending that a comment header is the same as a function is a bit silly. We can navigate to functions, not to comments. reply dgunay 4 hours agoprevThe example code would be less distracting if it at least attempted to stick to the pizza metaphor in a meaningful way and weren&#x27;t subpar Go code.`prepare` is a horrible name for a function. I would expect a seasoned Gopher to call it something like `NewPizzaFromOrder`.I don&#x27;t see any reason for putting `addToppings` in its own function. If you have to have it, I personally would have made it a method on Pizza something like `func (p *Pizza) WithToppings(topping ...Topping) *Pizza { &#x2F;* ... *&#x2F; }`. Real pizza is mutable, so the method mutates the receiver.Why is a new oven instantiated every time you want to bake a pizza? You should start with an oven you already have, then do `oven.Preheat()`, and then call call `oven.Bake(pizza)`. You can take this further by having `oven.Preheat()` return a newtype of Oven which exposes `.Bake()` so that you can&#x27;t accidentally bake something without preheating the oven first. Maybe elsewhere `Baker` is an interface, and you have a `ToasterOven` implementation that does not require you to preheat before baking because it&#x27;s just not as important.Without changing the code, I&#x27;d also reorder the declarations to be more what you&#x27;d expect (so you don&#x27;t have to jump up and down the page as you scan through functions that call each other).IDK I have to leave now but there are just so, so many ways in which the code is already a deeply horrible example to even start picking apart the \"which is more readable\" debate. reply jvans 5 hours agoprevIn my experience the more familiar that someone is with the code, the more they think pushing code into smaller functions is the correct path. They have already built up a mental model of the code at hand, so the cleanest implementation to them is one with very few lines.But the next person to come along has to bounce back and forth, performing mental stack push&#x2F;pop operations to create the same mental model which is much harder to do when you don&#x27;t have any of the original context reply mcv 40 minutes agoparentI disagree, but maybe there&#x27;s a difference between people who read&#x2F;think bottom-up and those who think top-down.My son struggled in school despite easily being smart enough for it, and one of the many people we spoke to about his needs explained to him that schools tend to teach bottom-up, whereas he was very much a top-down learner. He first needs an overview before he dives into the details, whereas others first need to grasp the details before they can assemble an overview. And schools tend to teach to the second group.It&#x27;s possible we&#x27;ve got something similar with programmers here. reply pif 1 hour agoparentprev> But the next person to come along has to bounce back and forthOnly if they can&#x27;t read code! Code is meant to be read as written, at least the first time; if you try to read it as executed, you are in the wrong.If the previous developer wrote a function BakePizza, just assume that the pizza will be properly backed and move to the next line. If you start dwelling in details like oven temperature while trying to understand how to run the restaurant, you will not understand how the restaurant works, and you will forget the correct oven temperature. reply sfn42 2 hours agoparentprevNot if the code makes sense. If the code is well written with elegant abstractions, slim interfaces and decent documentation, you often don&#x27;t need to bounce around that much. For example how often do you read source code of your language&#x27;s standard library? I almost never do, I mostly just look at method signatures and maybe read some docs if it&#x27;s a bit complex or new.The whole point of interfaces is that you&#x27;re not supposed to care how a method is implemented, only what it does which is explained by a combination of context, naming and documentation. But a lot of devs don&#x27;t understand(or care about) this, so they write code that doesn&#x27;t make sense and then it doesn&#x27;t matter whether they made it linear or modular. They do things like make a service class where you have to call one method to get some data and then you have to call another to get some other data and then you have to call a third method to get some data that needs to be consolidated with the other two and now what the hell is the point of your service? It exposes all the internal complexity to the outside.You aren&#x27;t supposed to force small methods, there&#x27;s no point having 20 ~5-line functions that are all only called once and do super specific stuff and have to be called in the right order etc. That&#x27;s not clean code, that&#x27;s more like cargo cult programming. You are supposed to abstract things appropriately so that they make sense both to new and seasoned team members, are easy to reason about and hide complexity in places where the complexity makes sense.This is not easy to do but it is possible. reply okaleniuk 4 hours agoprevThis \"level of abstraction\" euphemism actually means \"the level at which I&#x27;m not reading code anymore even and especially if I should\". Of course, linear code is more readable! Linear everything is more readable. Have you ever seen a novel with \"levels of abstraction\" in it?But nobody reads the code anymore. Why bother? You&#x27;re not going to stay on a single project for long enough for the attention investment to pay off. So the common best practice at the moment is to pretend that you read the code without actually reading it. For this purpose, the green code is much much better. reply mrkeen 53 minutes agoparent> Linear everything is more readable. Have you ever seen a novel with \"levels of abstraction\" in it?Not if you&#x27;re in the business of writing novels. What happens if you decide to edit out a scene - do you re-read the entire book to double-check that the deleted scene wasn&#x27;t referenced anywhere? reply japanuspus 3 hours agoparentprevI realize this is tongue in cheek, but really: Read code!If you ever start plateauing in your code skills, start digging into the code of your favorite open source project. Accept that things have been done in another way than you would for a reason and try to understand that reason.Try joining advent of code[0], and make sure to spend half you time block on reading and understanding alternative solutions.[0]: https:&#x2F;&#x2F;adventofcode.com&#x2F; reply realrains 6 hours agoprevMixing different levels of abstraction makes the code harder to understand. Linear code is probably good because the examples in the body are simple. It&#x27;s one thing to separate code into separate files, but it&#x27;s another to break up code snippets in one file. reply agigao 2 hours agoprevPerhaps we can try to do it in a proper functional language? (ns restaurant.pizza (:require [restaurant.oven :as oven] [restaurant.package :as pack])) (defn make-order [size sauce cheese kind] {:size size :sauce sauce :cheese cheese :kind kind}) (def toppings-map {\"Veg\" \"Veg toppings\" \"Meat\" \"Meat toppings\"}) (defn prepare [order] (assoc order :toppings (:kind order))) (defn bake [prepared-order] (oven&#x2F;bake prepared-order :pizza)) (defn box [baked-pizza] (pack&#x2F;box baked-pizza :pizza)) (defn pizza [order] (-> order prepare bake box)) (comment (def order (make-order 26 \"Tomato\" \"Mozzarella\" \"Meat\")) (pizza order))It&#x27;s short and overwhelmingly granular, but for the sake of illustration. Large and complex codebases sliced up this way has not alternative in terms of ease of testing and reasoning about the code. reply christophilus 7 hours agoprevI agree. I really hate having to jump all over a file (or multiple files!) for something that could fit into a single page of linear code. reply Jeff_Brown 7 hours agoparentSomeone smart said, \"When you&#x27;ve lost something, and finally find it, don&#x27;t put it there again. Instead put it the first place you looked.\"I think that applies to code. When I read something I wrote, if I&#x27;m annoyed at how it reads, I try to refactor it to be what I wanted to read, and remember to do it that way in the future.But sometimes what the reader wants is too much work for the writer, so I don&#x27;t push that effort beyond what it&#x27;s worth. reply gabereiser 6 hours agorootparentThere’s a whole style of coding dedicated to that very notion. It’s called test driven development. reply BigJ1211 4 hours agorootparentI don’t agree that’s what TDD does. You spent inordinate amounts thinking about how you should want it to be, when you could just write it, find where and what about it you dislike, write it again and have actual good code. Also called WET. You spend less time with better results that way and you gain what OP was talking about in the process. reply meitham 7 hours agoparentprevI agree too. Another example: I find early returns in functions easier to read than “else” with one “return” at the end. Basically vertically linear code as opposed to unnecessary branches and too much indentation, keeping the code slimmer is healthier! reply corethree 5 hours agoparentprevIt&#x27;s also a naming issue. A good name means I don&#x27;t have to jump. reply faizshah 1 hour agoprevWhats not shown is the 10 other functions calling createPizza and bakePizza that can be tested by mocking that routine centrally.In the basic case, the linear version is better until the code is duplicated. Adding constants and function aliases before the code has duplicated is generally a bad idea. reply kristjank 4 hours agoprevI have been working on a system for programming some specialty hardware on customer premises for a while, and most of it was written in a pseudo-language implemented by another backend programmer. Think BASIC-like implements in a YAML file, with arbitrary python inserts here and there.Despite the code being not very visually attractive (long corridors of imperative statements reading and writing from SMBus addresses), I was always surprised how easy it was to maintain the code, and how quickly I could get back \"in the zone\" after not working on it for months.There is something painfully trivial about old clunky languages that makes them somewhat easier to get back into. The cost in abstraction capabilities is obvious though. The only reason I can afford to write concise, linear, imperative code for this project is its narrow, specialized scope that most of modern programs cannot afford to limit themselves to anymore. reply olav 1 hour agoprevI wonder if there is some programming language that supports combining both styles:- A linear control flow - Named Blocks with explicit, named, typed parameters and return valuesI understand that one can use anonymous functions, immediately called to simulate this style. reply pushfoo 1 hour agoparentIf I understood you correctly, the ML family seems to come closest, especially Elm and F#&#x27;s use of |> syntax. reply js8 6 hours agoprevI find Linear B more readable than Linear A, but I agree with the OP, if there were additional explanatory comments in Linear A code, then it would be probably more readable than Linear B. reply vulcan01 6 hours agoparentThis is not a constructive comment. I just want to say that I appreciate this joke, it&#x27;s pretty funny. reply siddharthgoel88 4 hours agoprevI noticed that people have already contributed great insights on readability and testability aspects which were my first thoughts as well on reading this blog.However, I do believe that there is no one right answer to this argument. And the right answer is with that team who in the end have to read, write and maintain that code. The metrics that I collect with my co-workers who work on same code base as me are * What is the cognitive load to grasp the code for members in the team? * How easy is it to onboard a new member to this team? * Are we able to move fast and have confidence in the code changes we make?In my opinion, metrics like these are usually the ones most of us care about in the end. reply sns989 6 hours agoprevthis is anecdotal of course, but as someone who has never written a line of production Go code (but can tell at a visual glance this is in fact, Go), small functions (green) made sense to me as soon as I started reading it. The single function code (red) became hard to follow at some point. It felt like the function was doing 10 different things with a lot of branching and no particular single purpose. Maybe it&#x27;s the Python background in me, but I am not seeing how the single function is better to read than small, self-contained functions. reply Jtsummers 6 hours agoparentIt&#x27;s not a Go thing. I&#x27;ve inherited a number of large linear functions of the author&#x27;s favored style in several C-syntax family languages, they all become increasingly incomprehensible as they grow longer and older. For any advocate of that style, the only way to maintain them (and retain their supposed clarity) is to extract functions and then re-inline those functions after a comprehensive refactoring. Otherwise, they accrue so much cruft over time that their legibility is completely lost.Your only other option is to freeze them and never make changes, that doesn&#x27;t happen much in real-world code (though it probably should). reply atq2119 5 hours agorootparentLiterally extracting the functions and then re-inlining them makes no sense. Having that as a sort of mental model while you&#x27;re working on the code does make sense. reply Jtsummers 4 hours agorootparentIt’s to enable refactoring when it grows large. Most effective way I have found for 1k SLOC or larger functions. I usually don’t re-inline because the result after refactoring is almost always clearer.Trying to in-place refactor those things is an exercise in frustration. That’s part of why they grow so large, from observing their proponents in action. They don’t actually know what the functions do, only where to add a new path and repeat themselves. reply al05 2 hours agoprevI still prefer the one the right. I&#x27;m able to skip entire sections of code, and assume what the function does. Only if I require details do I go deeper.The comments are metadata, and where function names are tied into the code. One is going to stay up to date. The other isn&#x27;t. reply zelphirkalt 1 hour agoprevMutation everywhere, no thank you.This approach requires one to keep the state in mind while manually \"evaluating\" the mutations along the way, forming a picture, or whatever one uses, in mind about the created artifact. reply mrkeen 43 minutes agoparentCorrect.Especially when there&#x27;s mixing of in-place mutation and return-values.The first function in the green: func createPizza(order) { pizza = prepare(order) bake (pizza) box (pizza) return pizza }`prepare` transforms an order into a pizza, but `bake` and `box` mutates one in-place. reply raggi 7 hours agoprevIf you never have to write any tests, perhaps this is ok. reply yCombLinks 6 hours agoparentWhat do you mean never write any tests? The api should be the same. Order goes in, pizza comes out. The rest is implementation details that should not be exposed to a test. reply mrkeen 40 minutes agorootparent> The rest is implementation details that should not be exposed to a test.But it&#x27;s always implementation details all the way down!If `prepare` is not worth testing, why would `createPizza` be worth testing? `createPizza` is someone else&#x27;s implementation detail. reply raggi 6 hours agorootparentprevyou&#x27;re right, the api for ordering a pizza will probably stay the same.the cooking process won&#x27;t though. stuffed crust? add some stuff in the middle. square? add some stuff in the middle. deep dish? add some stuff in the middle.iterate a while and your \"one golden test\" is what falls down. reply jpc0 5 hours agorootparentYAGNIRefactor when those things are needed, right now the cooking process is stick it in a warm over for x minutes.What are you testing there?The oven was preheated? Put in an assert, that doesn&#x27;t need a test.That it stayed in for x minutes? You assuming the builtin sleep function is broken? Don&#x27;t test library code, that&#x27;s not your job.That the oven actually preheated correctly, that was discussed in the article, the oven and it&#x27;s preheat method should be a dependency that gets passed in, again not needed to be tested here.Also in your example you are testing whether an if condition was evaluated as true.Give me an example of a stuffed crust pizza cooking process that has a unit test which cannot be checked by looking at the resulting pizza. reply yCombLinks 5 hours agorootparentprevThose items are all testable through the createPizza method. There should be lots of tests! You&#x27;ve made up the one golden test scenario as a strawman. Every scenario you listed changes the expected output(the pizza). If you are testing internal methods, your tests are going to tell you you have broken, even if the pizzas created are 100% correct. So people won&#x27;t clean the code, because the tests break, and they don&#x27;t know if they are actually broken. reply al_be_back 1 hour agoprev>> this code makes no sense: why would you create a whole new oven to make a pizza? in real life...one can rationalize all sorts, but certain real-life metaphors don&#x27;t have to map closely to the digital realm.if my CreatePizza function relies on remote&#x2F;dynamic code&#x2F;features (realtime functionality), then it&#x27;s simpler and possibly safer to re-create than re-use. Depends on the use-case. reply Nevermark 1 hour agoprevI can imagine a new control statement with this type of syntax: code code uses (a, b, c, d) { &#x2F;&#x2F; Step 5: Foo the bar code code } more code more codeIt&#x27;s a block that defines the variables it uses, with no other access to the outer scope. It would help break up a linear function into blocks with clearer dependencies. reply bcoughlan 1 hour agoprevThis was always my interpretation of \"Flat is better than nested.\" from \"The Zen of Python\".I often run into conflict with developers who believe in the single return statement. This is flatter but irks a lot of devs:if (!condition) { return}more codereturn reply bogdan 3 hours agoprevThere is absolutely no doubt in my mind that that right variant is significantly better. I prefer it because of the smaller lexical scopes, because it&#x27;s easier to test and most importantly to me it&#x27;s easier to extend and to understand what the workflow intends to do. If I had to maintain code like this, I imagine in my day to day, I&#x27;ll likely only have to extend it by only touching the `addToppings` function, the rest can stay the same. If I have someone new joining my team I can easily guide them to this `addToppings` function and ask them to add support for pineapple and ham, nobody needs to be overwhelmed by the entire system and their task would be done in no time. I do acknowledge the question is about readability but I don&#x27;t think it&#x27;s possible to ignore testability, manageability and extensibility. I think the inlined approach simply does not strike a good balance of the aforementioned. reply BoorishBears 3 hours agoparentAs someone who prefers the underlying of the non-linear right side example, it&#x27;s written terribly code (which is puzzling since it was supposed to be the halo case)The prepare function is the main issue: it creates the pizza and adds toppings. If the pizza had been constructed at the top of createPizza, then `addToppings` `bake` and `box` were called, it&#x27;d be strictly clearer than it is now.Now obviously this is all from a contrived example, but I think the underlying lesson is: bad linear code is less tedious to deal with than bad non-linear code. With bad overly long linear code, at least the whole mess is in front of you. With bad non-linear code stuff is hiding stage-left, there&#x27;s side effects that names are hiding, you&#x27;re at the mercy of tooling for navigation, etc.Maybe if you know what you&#x27;re making is doomed to be bad code (think convoluted business logic driven by the real world), maybe prefer linear? reply jpc0 5 hours agoprevI feel like there a happy medium between the two, the left can easily be made more simple by factoring out one or two functions however the right went too far.The prepare and addtoppings functions should be one function, prepare effectively just fills in a struct and calls add toppings, its pointless to seperare them.The Bake function simply prepares the over for cooking, which the author mentioned should be a dependency with a method and then factors 4 lines of code into a new function for no reason. The bake and bake pizza function should be one function.You can then keep the box function as is.That would be both easier to maintain and easier to read. reply erhaetherth 5 hours agoparent> You can then keep the box function as is.The box function is broken too. You box the pizza and then return the pizza...but the box is logically a wrapper for the pizza. `box(pizza)` should return a boxed pizza. A box with contents=[pizza]. Maybe some sauce and pepperoncini in there too.Plus all these functions are impure. Which isn&#x27;t always bad but if you can prevent things like boxing it before baking it, you should.And what even... this entire example is just horrendous. You box the pizza and then slice the pizza? Ready = box.Close()? Can the Close() operation fail? And then the pizza is not ready? Why not throw an error, now the caller has to check if the pizza that got returned to them is even ready...? And that fact is even more hidden on the right side. Same for Sliced and Boxed. reply jpc0 5 hours agorootparentThis entire function is clearly a factory for a boxed pizza with toppings which is baked.I&#x27;d argue the entire box.Close() method is slideware and wouldn&#x27;t exist since it likely is just a return true. You can just as easily just say pizza.Ready = true. Reading this code afterwards I would think there was some stupid requirement somewhere for a pizza.Ready property so someone added it and would check a commit log to see if it can just be removed.Decent catch there though, the box can also be a dependency that get&#x27;s passed in. reply exitb 3 hours agoprevThe straw man has been shot with silver bullets. Can we also linearise calls like box.PutIn(pizza)? What if it&#x27;s a complex external API call that takes the pizza serialised to ProtoBuf and needs credentials that you&#x27;ll retrieve from a configuration provider? reply justanotherjoe 3 hours agoprevSure, you can put A, B, C, D side by side. But next time if you need to find D, you have to navigate A > B > C > D, with no other recourse. Often, you don&#x27;t care about A, B, or C. Only D. And the benefit of A, B, C, and D being close together becomes immaterial.In real systems where things are spread, A, B, C, and D can be very far apart indeed. And it&#x27;s totally fine! What matters is that from the starting position,let&#x27;s say X, I can &#x27;navigate&#x27; to A, B, C, or D, in an equal and speedy manner.Plus human brains love to navigate things in a &#x27;spatial&#x27; way like this. It&#x27;s natural. Really when you think about it, the perceived loss here is not that big compared to the benefits. reply d-us-vb 6 hours agoprevThis post presents why object oriented programming is harder than it looks.“I’m gonna return a pizza because I want a pizza”When of course, what one really wants is a pizza in a box. And the oven objection is also kind of funny. It leads to a “but computers are so fast, why can’t they build me a new oven for each pizza?”People think they want real-world analogies, which they hope will make code easier to reuse and maintain when what they really want are deep modules with clean interfaces, for which object orientation is not necessary in the least. reply jraph 3 hours agoparent> When of course, what one really wants is a pizza in a boxThat&#x27;s what Boxed is for, but this is more costly than a Pizza directly. reply gabereiser 6 hours agoprevI wholeheartedly disagree. Linear functions like this promote laziness in variable naming (var a1, c_tfr, bvf, etc). This also leads to buggy side effects such as having multiple nested if statements performing a plenko-machine determination of code branching. It’s horrid. It’s unmaintainable. It guarantees that someone will have to rewrite it after your gone, because you will be gone.This is the same as someone arguing for scrolls when books with table of contents and appendices are far superior. reply rramadass 5 hours agoparentYour rant is misplaced; it is the spirit rather than the letter of the thing that matters. Linear giant code is often easier to comprehend for structures like state machines where you can follow the business logic from one stage to another easily.See my other comment here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37518275 reply garbanzoPDX 4 hours agoprevMuch prefer the right-side version. It&#x27;s still \"linear\" at the top level and cognitive load is greatly reduced into small, single-responsibility, bite-sized functions. Plus—and sure, this might be a premature optimization—but future devs will thank you when it comes time to implement the \"bake a calzone\" feature. reply Roark66 4 hours agoprevI too find the code on the left&#x2F;red (linear) more readable. However the version with all the functions is quite extreme. When I&#x27;m splitting my code into functions I decide if something should be it&#x27;s own function on the basis of: is this chunk of functionality required to be reusable? Am I repeating code, only slightly changed?If the answer is yes, a function gets created. I never do what I assume authors did here, find the smallest logical units code can split into and generate a bajillion functions. I&#x27;m not paid by the line of code after all.The same reason makes me like object programming (especially inheritance, abstract functions, operator overloading). IMO with a good IDE such code is much more succinct(within the constraints of the language) and more readable, but taking it to extreme is a mistake. reply pif 2 hours agoprevThe problem with code styles is that most developers can only reason about information systems, where the only thing your code has to do is dispatch the right data to the right place.As soon as you try and write a function that actually uses the data, you find out that every book has been written for CRUD application programmers. reply nyanpasu64 6 hours agoprevI agree that placing sequentially executed code in order of execution often improves readability over abstracted code (especially dynamic dispatch and static&#x2F;dynamic traits). A similar article is at http:&#x2F;&#x2F;number-none.com&#x2F;blow&#x2F;john_carmack_on_inlined_code.htm..., but linear code has its own failure modes, if code is not factored into blocks with identifiable functionality and constrained&#x2F;documented side effects (for example 500-line functions twiddling hardware registers and reading&#x2F;writing global variables). Carmack later wrote an article in support of small-f functional programming and avoiding side effects and global state when practical (https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20190123060017&#x2F;http:&#x2F;&#x2F;gamasutra...., the article lost all line breaks during migration to gamedeveloper.com)Another article that touches on this idea (among others) is https:&#x2F;&#x2F;loup-vaillant.fr&#x2F;articles&#x2F;source-of-readability which advocates that \"code that is read together should be written together\" (reading it made me confused until I realized it meant \"placed together\"), specifically \"Consider inlining functions that are used only once\". reply dwb 3 hours agoprevI know it’s (usually, mostly) implied, but one of my dearest wishes for programming discourse is for people to say that something is more&#x2F;less readable for them rather than declaring it a universal. reply nevertoolate 5 hours agoprevThe right side version has extracted functions from an arguably worrisome implementation on the left, then someone inlined it and left comments to explain the purpose of ?some lines? of upcoming code. Author wants to optimize readability, Carmack and others want to reduce complexity by eliminating local optima introduced by abstractions. Other people want to make a fashion style out of it. I’m thinking: how does oven work? Does it mutate the parameter, is it heating up at a constant pace? If oven mutates pizza why not the Box methods? Also if inline person likes inline why they don’t inline Box and Oven. Because they are called from some other places? Why not inline those as well? So many questions to ask. I’m not sure this is a clear win for either styles. Maybe we should ask chatgpt :) reply Mizoguchi 3 hours agoparent\"The right side version has extracted functions from an arguably worrisome implementation on the left\"Not amount of linearity and abstractions, or silly comments, can make bad code readable. I see this stuff at work all the time. To my team&#x27;s defense I deal with a lot of chemists and physicists who like to write their own algorithms. reply jraph 3 hours agoprev> I know this is a synthetic example but this kind of issue actually occurs in real code and sometimes causes performance issues. It is likely that this code should take the oven as a parameter. Providing it is the job of the caller.The caller might not care about the oven, does not know the processes needs a oven, or does not even have a oven.The injection pattern could be used. reply dzikimarian 3 hours agoprevWrong thing is discussed in this post.Code on the right isn&#x27;t good because it&#x27;s non-linear. It&#x27;s good because it outlains business processe clearly, making it easy to get a grasp on it, if you never baked pizza before and aren&#x27;t an author of the original piece.It&#x27;s possible to write non-linear code using for eg unnecessary events or to much levels of abstraction and have the same issues for completely opposite reason. reply molly0 3 hours agoprevTestability matters more than readability - please separate different parts into different functions! reply DrDroop 6 hours agoprevIt is also super powerful technique when using the closure of a function as a way to encapsulate logic and state. A good example is this implementation of a json parser in js[1]. Attempt at lifting the lexer functions or state out of the function would result in every function needing to be wrapped with a factory function. Parser have always been tricky and before I knew this technique I would have reached for a parser combinator&#x2F;generator but this is a very sensible way of doing it.[1] https:&#x2F;&#x2F;lihautan.com&#x2F;json-parser-with-javascript&#x2F; reply skinkestek 6 hours agoprevI am currently working in some \"best practice\" (according to its author) code with hardly an if statement.And after half a year of halving to always step into a method (or out of it) to continue reading or debugging, this resonates with me very much. reply userbinator 5 hours agoprevIt&#x27;s more readable to the CPU too.Deeply nested code, especially with many functions that are called once, is really horrible to debug.Extract functions when you see obvious repetition, not just to appease some dogmatic abstraction goal. Incidentally, this also helps the CPU (cache locality).Along the same lines, I&#x27;d rather have a directory with several dozen source files than several dozen nested directories that may contain only one or two files each. reply realrains 2 hours agoparentI don&#x27;t think the issue is about which code is more readable, but whether it&#x27;s efficient for the CPU or the computer. Modern compilers optimize more than we think in production builds. reply FrustratedMonky 25 minutes agoprevSeems like the key takeaway was adding comments. reply patrulek 3 hours agoprevGood luck with finding proper line to make change or find a bug with single long linear function that is always a mess, because theres never time to refactor. I would rather not want to work with such code. reply afandian 4 hours agoprev> Also, what happens if you pass a pizza to those functions twice? Are they idempotent or do you end up eating cinder?That is surely about state and mutable data, not code structure. And factored code makes it _easier_ to write more stateless code. reply mrkeen 31 minutes agoparentYeah, that&#x27;s the most frustrating part of the debate here.Arguing about the difference between: number := prepareZero addOne(number) addTwo(number) addThree(number) return numberand number = 0 number += 1 number += 2 number += 3 return numberWhen either of the following would be far better: addThree (addTwo (addOne prepareZero))or return 0 + 1 + 2 + 3; reply urbandw311er 3 hours agoprevI’d like to also see the Rx example of this code. In my experience it would be vastly less readable but probably half the length. reply anoy8888 5 hours agoprevFor me , if a function is bigger than one page and I have to scroll , it means it is probably too long . If it’s length is less than one page , I don’t bother to break it down into smaller functions unless it makes sense reply erfgh 4 hours agoprevPro tip: Use an editor that doesn&#x27;t allow you to quickly jump to the definition of a function. You will make your code more readable because you will prefer to write linear code. reply osigurdson 4 hours agoprevThe one on the right is more readable, but takes things too far seemingly to prove a point. For example, \"addToppings\" clearly doesn&#x27;t need to be a separate method. reply Ultimatt 2 hours agoprevMaybe more readable but less testable and less maintainable longer term. reply meindnoch 6 hours agoprevI hate asking the question \"is this function called from different places, or was it extracted only for aesthetic reasons?\". reply al05 2 hours agoparentFunctions have never been about simply being called different places.So you entire premise is wrong. reply dllthomas 4 hours agoparentprevWould you hate it if it was really, really easy to answer? reply corethree 5 hours agoparentprevThe function will&#x2F;may get called from different places in the future. I am coding for the future. reply mrkeen 28 minutes agorootparent>> The function will&#x2F;may get called from different places in the future. I am coding for the future.> Ah, the good old premature abstraction.The function will get called from different places. Once from its caller, and a second time from its unit test. reply kaoD 5 hours agorootparentprevAh, the good old premature abstraction.You&#x27;re coding for a future that might not exist. You might be coding for the wrong future and you painted yourself into a corner.Been there, done that. reply corethree 4 hours agorootparentBut what if I&#x27;m coding for the correct future?Maybe there&#x27;s a way where I can code for every possible future with minimal effort. I&#x27;m talking about a pattern that isn&#x27;t a form of premature optimization. Just a rule.Your way of coding is, coding for the most probable future. Distinctly different of coding for every possible future. reply emodendroket 4 hours agoprevYeah, when it’s trivial code like this and doesn’t go on for ten pages that might be true. reply pechay 5 hours agoprevI don&#x27;t like the side effects of the second addToppings. I&#x27;d much preferpizza.Toppings = getToppings(kind string) reply mrkeen 28 minutes agoparent> pizza.Toppings = getToppings(kind string)That&#x27;s a side effect. reply agumonkey 3 hours agoprevI wonder if modularization is not a form of parametrization. reply gorgoiler 6 hours agoprevEnd to end tests only, for you! They’ll find your bug in 30 minutes or you get your money back! reply deafpolygon 1 hour agoprevI&#x27;m only a novice at programming, but my usual rule is if the indentation gets too far in, then it&#x27;s time to put it in its own function. When it becomes hard to follow, I will put it in its own function doing The Thing(tm). But I won&#x27;t break down every small logic into its own function - it&#x27;s just too much. reply t3rra 6 hours agoprevhaving a poor taste is nothing to have confident with. The author sounds like he has never coded anything large and complex. reply wiseowise 3 hours agoparent> having a poor taste is nothing to have confident with.Huh, I can say the same about you by the reaction to this post. reply jimbob45 6 hours agoprevHow about this: most code has hard chunks or even sections that can be nearly impossible to figure out without a significant time investment. We can skip the intermediate steps and just move straight to a document that explains the architecture so that we may stop trying to jump through hoops to avoid writing non-comment documentation.The amount of places I’ve worked at that don’t even have accessible DB schemas is mind-boggling. reply orblivion 6 hours agoprevAll of this \"why your favorite best practice is wrong, actually\" stuff gives me whiplash. reply imtringued 3 hours agoprevPrepare, addToppings and bake are meaningless functions that serve no purpose. Meanwhile heatOven, bakePizza and box do have very good reasons to exist. reply readthenotes1 7 hours agoprevThose comments won&#x27;t match the code in 6 months.Edit to add: and in 6 months, instead of being one short page of code, it&#x27;ll be 600 lines long and impossible to understand or modify safely reply Supermancho 7 hours agoparentDo other people not consider comments in PRs anymore? Would someone ok a PR [for a function] with 600 lines? Probably not. Let&#x27;s not be absurd here, but I fundamentally agree that it&#x27;s too long already.Yes, maybe it&#x27;s the wrong abstraction or it won&#x27;t match in 6 months because people will start calling Hats Pizzas and the logic will be different. Maybe I&#x27;ll be dead tomorrow. I don&#x27;t concern",
    "originSummary": [
      "The author is advocating against abstracting code for the sake of readability, contending that linear code is intrinsically more understandable.",
      "The writer substantiates their stance by offering an example of a function that criticizes the use of abstraction in the code.",
      "They address a possible code issue involving an appliance, recommending that the code should treat the oven as a parameter, reinforcing the idea that small functions should not be extracted from linear code."
    ],
    "commentSummary": [
      "The central theme of the discussion is the readability and maintainability of code with divergent opinions promoting larger linear functions and smaller modular functions.",
      "The discourse underlines the significance of writing code with other developers' readability in mind and striking a balance through careful use of abstraction.",
      "It emphasizes the importance of taking into consideration the specific requirements of the codebase while prioritizing between readability and efficiency. Various viewpoints on code structure, testing, and scalability are also examined."
    ],
    "points": 242,
    "commentCount": 208,
    "retryCount": 0,
    "time": 1694743384
  },
  {
    "id": 37515645,
    "title": "Programming Language Inventor or Serial Killer? (2003)",
    "originLink": "https://vole.wtf/coder-serial-killer-quiz/",
    "originBody": "PROGRAMMING LANGUAGE INVENTOR or Serial KilLer ? Can you tell a coder from a cannibal? A mathematician from a murderer? Try to spot who liked hacking away at corpses rather than computers Start More GamEs Home About TwitTer MastodOn VOLE.wtf Sound v o l e",
    "commentLink": "https://news.ycombinator.com/item?id=37515645",
    "commentBody": "Programming Language Inventor or Serial Killer? (2003)Hacker NewspastloginProgramming Language Inventor or Serial Killer? (2003) (vole.wtf) 243 points by bagpuss 11 hours ago| hidepastfavorite110 comments gorgoiler 7 hours agoRob Pike, Canadian inventor of Golang, an imperative language with a focus on channel based concurrency…aka a “serial” killer.Sorry. reply isaacfung 4 hours agoparentWhen ProgrammerHumor mixed with DadJokes reply BerislavLopac 3 hours agoprevI just chose \"serial killer\" for everyone. In my experience, when programming language inventors encounter all the comments and requests and criticisms from the users of their languages, there is a very thin line separating them from becoming serial killers... reply deelly 2 hours agoparentWe need additional button, thats appears after wrong choice. \"I wish...\".And resulting statistics, of course.Or is it too dark? reply pteraspidomorph 10 hours agoprev9&#x2F;10. Sorry, Guido, I knew those were the dead eyes of a programming language inventor but I still decided to go with serial killer. reply lukeinator42 9 hours agoparentI got the same score for the same reason, haha reply cutemonster 23 minutes agorootparentI got 8, ... The old lady, was 50-50? How could one know if she was one of the spaceship programmers but at old age? But now I realize, the photo looked old too, so then logically she couldn&#x27;t have been one of them after all :-) reply pharrington 10 hours agoprev\"Established much of the design of COBOL in two weeks\"that still doesn&#x27;t answer the question?? reply visarga 2 hours agoparentThat answers the question why is COBOL so weird. Just like JS, invented in a week, fixed for the next 3 decades. reply keyle 15 minutes agorootparentI&#x27;d take COBOL over JS back in 1997! reply dang 5 hours agoprevRelated:Programming Language Creator or Serial Killer? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25878602 - Jan 2021 (139 comments)Can you tell a programmer&#x2F;language inventor from a killer? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=1455383 - June 2010 (12 comments)Programming Language Inventor or Serial Killer? - https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=135299 - March 2008 (1 comment)(I put 2003 on it because of https:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20031008105832&#x2F;http:&#x2F;&#x2F;www.malevo... but I didn&#x27;t have the patience to wait for it to load. How different can it be though, with that url...) reply muzani 2 hours agoparentInteresting how it became more popular recently reply debesyla 1 hour agorootparentMaybe it&#x27;s because HN is more popular (has more users) over all? Just a guess, I have no idea if there&#x27;s correlation. reply yowzadave 10 hours agoprevI like this because I like to flatter myself that I have a good intuition about people after seeing them, and this shows that I’m completely wrong about that—barely better than random. reply Macha 9 hours agoparentIt turns out with the trappings of how serial killers are presented in media (bad black and white photos from odd angles), everyone looks like a serial killer. reply jeffparsons 2 hours agorootparentThere&#x27;s a security camera monitor displayed prominently in one store near where I live that makes everyone look dodgy — something about the frame rate and fuzzy image just looks like shoplifting footage you&#x27;d see on the news.I see myself on the screen as I enter and think \"yeah, that guy&#x27;s going to hold up the shop or something\". reply hutzlibu 1 hour agoparentprevWell, I think so, too. But only after seeing them in real and not just on some blurry, distorted picture.But I also think, most people have the potential to become serial killers. Hunting and killing is deep in our genes after all and society can mess up people pretty bad, so some turn their animal instinct against society, while maintaining the facade on the outside. reply tux3 32 minutes agorootparentI don&#x27;t think that&#x27;s right.In psychiatry, you reach the coveted status of Antisocial Personality Disorder (the remorseless manipulative sociopath with a charming personality, but no compassion) by starting out with Conduct Disorder (the kids that hurt animals, lie, cheat, and steal) and not snapping out of it by adulthoodHumans are social animals. If your animal instinct is hunting and killing, and you feel like you&#x27;re just maintaining a facade... good! You don&#x27;t choose the instincts you&#x27;re born with, but please keep maintening the facade thank you! :) reply hutzlibu 5 minutes agorootparentModern civilized society tries hard to negate and channel all violent impulses from early on and only unleash it in ritualistic scenarios like sports.(Or after a 180 degree turn - for real in the military.)And this is mostly successful, but push someone hard enough and violence will be the result. Otherwise there would not be so many murders and violent crimes.Most people will just explode violently (and then regret) and the path of the silent serial killer is (luckily) rare.But if you look at other (savage) societys where violence is still baked in, there simply are no pacifists there, so pacifism is not something we were born with, but a learned trait. And one that makes sense, to keep society stable, but I don&#x27;t think it makes sense to fool ourself about what humans are capable of. Just look at Ukraine to see what ordinary civilized people are capable of, if put in a different environment. reply quickthrower2 4 hours agoparentprevSerial killers. By definition have aptitude to get away with murder for some period of time. Probably good at concealing their madness. reply sn41 8 hours agoparentprevProbably you are still right. Seeing a photograph is different from seeing a person in real animated life. I guess there are micro expressions, the way people laugh, and the exact point at which people laugh and such that some people are really good at reading, but it is hard to articulate what exactly the process of interpretation is. reply muzani 2 hours agorootparentLike Chris Watts was investigated and arrested for behaving a little off about his family&#x27;s disappearance. reply bryanrasmussen 3 hours agorootparentprevI think you&#x27;re right, if someone is laughing while chopping up a corpse there&#x27;s a good chance they&#x27;re a serial killer. reply eru 9 hours agoparentprevI was way worse than random. Make of that what you will. reply eterm 7 hours agorootparentUnless you scored 0 or 1, then you might not be \"way worse than random\", or at least, there is a lack evidence that you are \"way worse than random\":2&#x2F;10 has a p-value of p = .057.Or put another way, the 95% confidence interval of scoring 2 out of 10 covers 0.5. reply dclowd9901 3 hours agorootparentprevIn a binary result you almost can’t be worse than random. If you’re worse, then invert your result and you’re good again.Or as in Seinfeld, when George just decides to do the opposite thing he would normally do and things start going well for him. reply neilv 10 hours agoprevI know it&#x27;s a silly game, but I&#x27;m slightly uneasy with it.If you remember a time when programming computers was considered nerdy, in a socially discouraged and mocked kind of way (until it became big money)... a game of guessing whether a photo is of a serial killer or a computer programming nerd... might seem a little abusive. reply joelegner 9 hours agoparentAnother interpretation is that the portraits communicate essentially zero information about the subject. No information means no way to differentiate beyond the absolute basic facts: male, age such and such, seems to be wearing western clothes, things like that. No information means no way to shade probabilities. You might as well flip a coin.Or this way: Serial killers look like random people, just as programming language inventors look like random people. reply neilv 9 hours agorootparentIf that were the goal, wouldn&#x27;t a diversity of obviously nigh-saintly people in the mix... be better than focusing on a historically maligned group? reply TylerLives 8 hours agorootparentprevFacial asymmetry, testosterone (thick eyebrows, baldness), weight, piercings, tattoos, unnatural hair colors etc. surely have some correlation with being a serial killer? reply Jensson 8 hours agorootparentAlso to being a coder. Coders and serial killers are both very male groups, so likely share many of the same signals. reply psychoslave 3 hours agorootparentprevAny measurable characteristic will allow to establish some correlation, but it doesn’t necessarily will be a high correlation. reply an_aparallel 9 hours agoparentprevkind of agree - its the same \"humour\" which devolved TV like big bang theory into canned laughter shit-shows - poking fun of \"virgin nerds\" (which make bank). reply neilv 9 hours agorootparentAnd worse. When, say, GvR was a kid, it was normal in many schools for nerds to be bullied.Imagine someone doing this game back then, in that context, passing it around school (before cyberbullying), and it&#x27;d be pretty nasty.We can say \"but computer programming is OK, now that it&#x27;s a status career that rich kids have blessed as cool, and kids don&#x27;t get bullied like that in school so much, so now it&#x27;s funny in a non-bullying way\", I guess.Still feels like punching-down, to me, but not everyone knows the earlier context. reply lo_zamoyski 8 hours agorootparentIt sounds like you&#x27;re the one doing the punching down by tacitly assuming that who write software are or were wimpy, creepy nerds. If that&#x27;s not a stereotype, than I don&#x27;t know what is.And trust me, there are plenty of bullies in tech.Don&#x27;t worry. There&#x27;s no one needing to be rescued here. reply wiseowise 3 hours agorootparentStopping calling people “wimpy, creepy nerds” would be a good start. reply PheonixPharts 8 hours agoparentprevI&#x27;m just glad the game isn&#x27;t \"File system creator or killer\" reply Stratoscope 3 hours agorootparentThat was my first thought too!OTOH, wouldn&#x27;t it be \"File system creator and killer\"? :-( reply psychoslave 3 hours agorootparenthttps:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Hans_Reiser for those who might wonder reply emfax 2 hours agoparentprevI agree with this sentiment, but I’ve always wondered about a person’s face or appearance and how that might correlate to other traits.I think we could all agree that a person’s face might indicate ‘shiftiness’ or ‘meanness’ and that there is a decent probability that you’d be right in your assessment.Has there ever been studies that correlate face types with personality traits? reply jhbadger 8 hours agoparentprevParticularly since some of the photos of programming language designers seem to be particularly unflattering ones. reply mongol 6 hours agoparentprevI agree. I don&#x27;t think it is good taste to use people&#x27;s photos in a game and let players guess if they have killed someone. reply dclowd9901 3 hours agoparentprevYeah I had this exact tinge of unease when the game started but I couldn’t really identify where it emerged from. I think you nailed it on the head. reply michael_leachim 19 minutes agoprev10&#x2F;10 but the difference is obvious, you just have to look into their eyes. PL designers are a bit weird and not of this world.Serial killers have this spark in their eyes that is really difficult to hide. reply armchairhacker 10 hours agoprevCorrection: programming language inventor or convicted serial killer reply avodonosov 7 hours agoparentknown programmer language inventor(some of the maniacs could have secretly designed prograrming languages too) reply seanmcdirmid 8 hours agoparentprevOr doesn’t exclude and. reply atleastoptimal 10 hours agoprevMaking a programming language prone to bugs&#x2F;frustrating to work with makes one possibly a stochastic serial killer reply Waterluvian 10 hours agoparentI mean instead of killing entire people, what if you kill a small fraction of thousands of people? reply arthurcolle 10 hours agorootparentThat&#x27;s how SaaS pricing was invented! reply elteto 9 hours agorootparentMaaS reply gorgoiler 7 hours agorootparentMaaS murderer reply fud101 9 hours agorootparentprevdo you really mean it bro? reply 1letterunixname 10 hours agoparentprevLiveness data flow analysis is just a phase a compiler and JITs go through. They&#x27;ll eventually cease murdering heap and stack values once they&#x27;ve decided to halt. Unfortunately, they use a disposable Erlang distribution Schrödinger cat box to make each decision. Not sure what they do with all the no-longer-cats or what sort of sensor detects ex-cats.Schrödinger couldn&#x27;t just invent a cyanide sensor. He was definitely a psychopathic serial killer in addition to being a serial pedophile (this bit is true). reply casion 10 hours agoprevHeh, I knew all the names by the photo... maybe I should leave the house one day. reply swader999 10 hours agoprevDon&#x27;t ever pick me for jury duty. reply FireInsight 36 minutes agoprevEasy, serial killers always looks more handsome. reply wpietri 9 hours agoprevI only got 3 of 10 right, substantially worse than random chance. Sorry, coders! Although I don&#x27;t feel bad about thinking that the COBOL inventor was a serial killer. reply el_toast 9 hours agoprevThis reminds me of a game me and a buddy started playing called &#x27;homeless or math professor?&#x27;. Fun times. reply skrebbel 3 hours agoprevI got 6&#x2F;10 and it told me better not to work in IT recruitment but joke’s on them cause all our interviews are text based reply muzani 3 hours agoparentthis is why we tell people not to put their photos on resumes reply pmontra 2 hours agoprevI got 6 out of 10, a poor result according to the site. I picked inventor on the first entry, killer on the second one and kept alternating.Great site, BTW. Plenty of other games and with an unusual twist they are selling them (the sub sites for the games) reply derefr 10 hours agoprevDeeper question: why is Sussman wearing a fez in that photo? reply ufo 9 hours agoparent\"We&#x27;re getting really close to the spirit of the computer at this point, so I have to show a certain amount of reverence and respect\"https:&#x2F;&#x2F;youtu.be&#x2F;aAlR3cezPJg?list=PLE18841CABEA24090&t=234 reply spott 8 hours agoprevRelated: https:&#x2F;&#x2F;www.proforhobo.com reply einpoklum 23 minutes agoprevI guessed \"programming language inventor\" for all of the images I saw, and I would do so again if I had to replay this \"game\", because I don&#x27;t think it&#x27;s reasonable to assume someone is a serial killer, while guessing they&#x27;ve invented a programming language is harmless speculation. reply nneonneo 10 hours agoprevAka, hacker or ‘hacker’.I feel like with enough photos of just about anyone, you’ll eventually get one that makes them look sinister… reply meekaaku 1 hour agoprevJust found out i know more serial killers than programming language inventors reply daxvena 7 hours agoprevI feel like I gamed this somehow. Instead of looking for serial killers, I looked for anyone who didn&#x27;t look like a programming language inventor and got 10&#x2F;10. reply eru 9 hours agoprevI got 2&#x2F;10. And one of them only because I recognised Guido van Rossum. I&#x27;m honestly impressed that I did so much worse than chance. That must require some special kind of (inverse) skill. reply temeya 7 hours agoprev7&#x2F;10, so a pass. But as others have pointed out, everything in the photographs (from lighting to the angle of the subject) tells nothing about the subject. Unless you&#x27;ve seen pictures before, you wouldn&#x27;t know, and even then you wouldn&#x27;t know. People don&#x27;t matter. Your perception of them DOES matter and that can change from things such as a single photograph. reply glandium 4 hours agoparentSome of the pictures are clearly mugshots, though, and those are all from serial killers. reply al_be_back 2 hours agoprevso that&#x27;s where Zuckerberg got his idea for hot-or-not reply ithkuil 4 hours agoprev9 out of 10 You&#x27;d spot Hannibal Lecter in seconds at a hack day. Your liver&#x27;s safe reply ericls 10 hours agoprevAt least I got guido right… reply Nevermark 10 hours agoprevIsn’t a shotgun murderer a … parallel killer? reply gabereiser 10 hours agoparentNot if you await the first shot… reply secf4ult 9 hours agorootparentYou cannot await in top level, unless... reply nomaxx117 11 hours agoprevThis is great fun. Even if it&#x27;s mostly a 50&#x2F;50 guessing game it&#x27;s still quite humorous. reply anigbrowl 11 hours agoparentI scored 9&#x2F;10 and &#x27;true crime&#x27; is not an especial interest of mine, I didn&#x27;t recognize anyone&#x27;s photos.* HMU if you want to screen new hires&#x2F;potential business partners, no refunds reply Wowfunhappy 10 hours agorootparent> no refundsIf you get it wrong and they hire a serial killer... well, I don&#x27;t think this policy will be necessary. reply smsm42 10 hours agorootparent\"I know you hired me to murder the competing gang, but I thought designing a new multi-paradigm type-safe VM-driven LISP-like automatically verifyable programming language would be much better use of the money\". reply naniwaduni 10 hours agorootparentprevWhat? No, you&#x27;d be worried about getting a programming language inventor for your serial killing startup, right? reply quickthrower2 4 hours agorootparentprevSelf selected p-hack reply mabbo 10 hours agoprevI got 9&#x2F;10 (sorry Sussman!).In a previous version of this game on another site, Phil Wadler was one of the computer scientists and I was able to say \"I&#x27;ve met that one! I hope he&#x27;s not a serial killer...\" reply avodonosov 7 hours agoprev8&#x2F;10I thought one photo was of Larry Wall, but that was a similary looking murderer (and a programmer, but not known to invent any language) reply ganglandfee 9 hours agoprevWell, all I learned is that I’m a judgmental piece of shit. reply karaokeyoga 8 hours agoprev\"why not both?\" reply dhosek 8 hours agoprevI thought this was going to be about how uncaught null errors kill people. reply Jigsy 10 hours agoprev2&#x2F;10.Surprised that Hans Reiser wasn&#x27;t on the list. (Or I didn&#x27;t see him.) reply naniwaduni 8 hours agoparentAs far as we&#x27;re aware, he doesn&#x27;t belong to either category (yet). reply Jigsy 7 hours agorootparentOh yeah, that makes sense.I keep forgetting he killed just his wife, not his kids as well. reply quickthrower2 4 hours agorootparentAnd I think spree and serial killings are different things. reply bagels 10 hours agoparentprevThat one is a trick question if sorts. reply sneak 9 hours agorootparentNope; he wrote a file system, not a programming language. reply Jigsy 9 hours agorootparentprevPersonally I think of him as a murderer first and a programmer second. reply djmips 9 hours agoparentprevwow you are almost exactly backwards. do you hate language inventors? reply Jigsy 7 hours agorootparentNot really. I just assumed nearly everyone was a programmer.\"Wow, what a sweet old lady. I&#x27;m guessing she invented Fortra-- oh, she, murdered people for their social security checks.\" reply icpmacdo 8 hours agoprevFunny seeing this I&#x27;ve have the identical idea before reply RajT88 10 hours agoprevIs there one with file system inventors or murderers? reply gabereiser 10 hours agoparentDouble Bonus Points for ReiserFS right? reply kasperset 7 hours agoprevI scored 8 out of 10! Was fun reply jp57 10 hours agoprevWhy not both? reply LaurenSerino 6 hours agoprevWhy not both? reply Ericson2314 7 hours agoprevRieser FS Reiser, did he make any PLs? reply benj111 1 hour agoprevI got 3 out of 10, and one I recogised.Does that mean: A. I&#x27;m a sociopath because I&#x27;m unable to detect the cuesB. An inherently good &#x2F; naive person that has never needed to differentiate between a programmer and a serial killer?Til: keep away from people I think look like programming language designers. reply kunley 10 hours agoprevGvR !! ;))) reply jdjdjdjdjduuuu 10 hours agoprev7&#x2F;10 reply debtless4080 10 hours agoprev10&#x2F;10 reply arianvanp 5 hours agoprev [–] This is gross replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The text indicates the concept of a game where the challenge is to distinguish between a programming language inventor and a serial killer.",
      "This game might involve examining the individuals' interests, which could potentially involve topics such as hacking and murder.",
      "The post is unique in its suggestion of combining technology and true crime into an interactive format."
    ],
    "commentSummary": [
      "The article covers a game that involves guessing whether a person in a picture is a serial killer or a developer of programming languages.",
      "There's a debate within the discussion thread around the validity of linking facial features to someone's nature, along with the stereotypes connected to programmers and serial killers.",
      "The game has garnered mixed responses, with some participants enjoying it while others express concerns about potential discrimination and are surprised at certain exclusions."
    ],
    "points": 239,
    "commentCount": 107,
    "retryCount": 0,
    "time": 1694730488
  },
  {
    "id": 37511036,
    "title": "Intermediate sci knowledge associated with overconfidence and negative attitudes",
    "originLink": "https://www.nature.com/articles/s41562-023-01677-8",
    "originBody": "Your Privacy We use cookies to make sure that our website works properly, as well as some optional cookies to personalise content and advertising, provide social media features and analyse how people use our site. By accepting some or all optional cookies you give consent to the processing of your personal data, including transfer to third parties, some in countries outside of the European Economic Area that do not offer the same data protection standards as the country where you live. You can decide which optional cookies to accept by clicking on \"Manage preferences\", where you can also find more information about how your personal data is processed. Further information can be found in our privacy policy. Accept all cookies Manage preferences Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Subscribe Sign up for alerts RSS feed nature nature human behaviour articles article Article Published: 14 September 2023 Intermediate levels of scientific knowledge are associated with overconfidence and negative attitudes towards science Simone Lackner, Frederico Francisco, Cristina Mendonça, André Mata & Joana Gonçalves-Sá Nature Human Behaviour (2023)Cite this article 99 Altmetric Metrics details Abstract Overconfidence is a prevalent problem and it is particularly consequential in its relation with scientific knowledge: being unaware of one’s own ignorance can affect behaviours and threaten public policies and health. However, it is not clear how confidence varies with knowledge. Here, we examine four large surveys, spanning 30 years in Europe and the United States and propose a new confidence metric. This metric does not rely on self-reporting or peer comparison, operationalizing (over)confidence as the tendency to give incorrect answers rather than ‘don’t know’ responses to questions on scientific facts. We find a nonlinear relationship between knowledge and confidence, with overconfidence (the confidence gap) peaking at intermediate levels of actual scientific knowledge. These high-confidence/intermediate-knowledge groups also display the least positive attitudes towards science. These results differ from current models and, by identifying specific audiences, can help inform science communication strategies. This is a preview of subscription content, access via your institution Access options Access through your institution Access Nature and 54 other Nature Portfolio journals Get Nature+, our best-value online-access subscription 24,99 € / 30 days cancel any time Learn more Subscribe to this journal Receive 12 digital issues and online access to articles 111,21 € per year only 9,27 € per issue Learn more Rent or buy this article Prices vary by article type from$1.95 to$39.95 Learn more Prices may be subject to local taxes which are calculated during checkout Additional access options: Log in Learn about institutional subscriptions Read our FAQs Contact customer support Data availability Surveys EB, Pew and GSS are publicly available and data and details can be found in refs. 27,28,29, respectively. The Fernbach study was published in ref. 9 and the authors made the data available. Lackner survey data are available at: https://doi.org/10.5281/zenodo.7920776. Code availability All code used for the analysis is available at: https://doi.org/10.5281/zenodo.7920750. References Plous, S. The Psychology of Judgment and Decision Making (McGraw-Hill, 1993). Lichtenstein, S. & Fischhoff, B. Do those who know more also know more about how much they know? Organ. Behav. Hum. Perf. 20, 159–183 (1977). Article Google Scholar Johnson, D. D. P. & Levin, S. A. The tragedy of cognition: psychological biases and environmental inaction. Curr. Sci. 97, 1593–1603 (2009). Google Scholar Tuchman, B. W. The March of Folly: From Troy to Vietnam (Alfred A. Knopf, 1984). Johnson, D. D. P. & Tierney, D. R. The Rubicon theory of war: how the path to conflict reaches the point of no return. Int. Secur. 36, 7–40 (2011). Article Google Scholar Akerlof, G. A. & Shiller, R. J. Animal Spirits: How Human Psychology Drives the Economy and Why it Matters for Global Capitalism (Princeton Univ. Press, 2009). Kruger, J. & Dunning, D. Unskilled and unaware of it: how difficulties in recognizing one’s own incompetence lead to inflated self-assessments. J. Pers. Soc. Psychol. 77, 1121–1134 (1999). Article CAS PubMed Google Scholar Motta, M., Callaghan, T. & Sylvester, S. Knowing less but presuming more: Dunning–Kruger effects and the endorsement of anti-vaccine policy attitudes. Soc. Sci. Med. 211, 274–281 (2018). Article PubMed Google Scholar Fernbach, P. M., Light, N., Scott, S. E., Inbar, Y. & Rozin, P. Extreme opponents of genetically modified foods know the least but think they know the most. Nat. Hum. Behav. 3, 251–256 (2019). Article PubMed Google Scholar Al-Harthy, I. S., Was, C. A. & Hassan, A. S. Poor performers are poor predictors of performance and they know it: can they improve their prediction accuracy. J. Glob. Res. Educ. Soc. Sci. 4, 93–100 (2015). Google Scholar Händel, M. & Fritzsche, E. S. Unskilled but subjectively aware: metacognitive monitoring ability and respective awareness in low-performing students. Mem. Cognit. 44, 229–241 (2016). Article PubMed Google Scholar Miller, T. M. & Geraci, L. Unskilled but aware: reinterpreting overconfidence in low-performing students. J. Exp. Psychol. Learn. 37, 502–506 (2011). Article Google Scholar Urban, M. & Urban, K. Unskilled but aware of it? Cluster analysis of creative metacognition from preschool age to early adulthood. J. Creat. Behav. 55, 937–945 (2021). Article Google Scholar Sanchez, C. & Dunning, D. Cultural patterns explain the worldwide perception/performance paradox in student self-assessments of math and science skill. Soc. Psychol. Pers. Sci. 10, 935–945 (2019). Article Google Scholar McIntosh, R. D., Fowler, E. A., Lyu, T. & Della Sala, S. Wise up: clarifying the role of metacognition in the Dunning–Kruger effect. J. Exp. Psychol. Gen. 148, 1882–1897 (2019). Article PubMed Google Scholar Gignac, G. E. & Zajenkowski, M. The Dunning–Kruger effect is (mostly) a statistical artefact: valid approaches to testing the hypothesis with individual differences data. Intelligence 80, 101449 (2020). Article Google Scholar Jansen, R. A., Rafferty, A. N. & Griffiths, T. L. A rational model of the Dunning–Kruger effect supports insensitivity to evidence in low performers. Nat. Hum. Behav. 5, 756–763 (2021). Article PubMed Google Scholar Nederhof, A. J. Methods of coping with social desirability bias: a review. Eur. J. Soc. Psychol. 15, 263–280 (1985). Article Google Scholar Larson, R. B. Controlling social desirability bias. Int. J. Mark. Res. 61, 534–547 (2019). Article Google Scholar Cole, J. S. & Gonyea, R. M. Accuracy of self-reported SAT and ACT test scores: implications for research. Res. High. Educ. 51, 305–319 (2010). Article Google Scholar Greenwald, A. G., Poehlman, T. A., Uhlmann, E. L. & Banaji, M. R. Understanding and using the Implicit Association Test: III. Meta-analysis of predictive validity. J. Pers. Soc. Psychol. 97, 17–41 (2009). Article PubMed Google Scholar Bishop, G. F., Tuchfarber, A. J. & Oldendick, R. W. Opinions on fictitious issues: the pressure to answer survey questions. Public Opin. Quart. 50, 240–250 (1986). Article Google Scholar Sedikides, C. & Alicke, M. D. in The Oxford Handbook of Human Motivation (ed. Ryan, R. M.) Ch. 17 (Oxford Univ. Press, 2012). De Neys, W. Bias and conflict: a case for logical intuitions. Perspect. Psychol. Sci. 7, 28–38 (2012). Article PubMed Google Scholar Williams, E. F., Dunning, D. & Kruger, J. The hobgoblin of consistency: algorithmic judgment strategies underlie inflated self-assessments of performance. J. Pers. Soc. Psychol. 104, 976–994 (2013). Article PubMed Google Scholar Light, N., Fernbach, P. M., Rabb, N., Geana, M. V. & Sloman, S. A. Knowledge overconfidence is associated with anti-consensus views on controversial scientific issues. Sci. Adv. 8, eabo0038 (2022). Article CAS PubMed PubMed Central Google Scholar Bauer, M. W., Shukla, R. & Kakkar, P. Public Understanding of Science in Europe 1989–2005—A Eurobarometer Trend File (GESIS, 2012); https://www.gesis.org/en/eurobarometer-data-service/search-data-access/eb-trends-trend-files/eb-pus-1989-2005 Smith, T. W., Davern, M., Freese, J. & Morgan, S. L. General Social Surveys, 1972–2018 (NORC, 2019); https://gss.norc.org/get-the-data Funk, C., Kennedy, B., Johnson, C., Hefferon, M. & Thigpen, C. L. American Trends Panel Wave 42 (Pew Research Center, 2019); https://www.pewresearch.org/science/dataset/american-trends-panel-wave-42/ Maki, R. H. in Metacognition in Educational Theory and Practice (eds Hacker, D. J. et al.) Ch. 6 (Routledge, 1998). Bauer, M. Socio-demographic correlates of DK-responses in knowledge surveys: self-attributed ignorance of science. Soc. Sci. Inform. 35, 39–68 (1996). Article Google Scholar Hamilton, L. C. Self-assessed understanding of climate change. Clim. Change 151, 349–362 (2018). Article Google Scholar Durant, J. R., Evans, G. A. & Thomas, G. P. The public understanding of science. Nature 340, 11–14 (1989). Article CAS PubMed Google Scholar Bauer, M. W., Allum, N. & Miller, S. What can we learn from 25 years of PUS survey research? Liberating and expanding the agenda. Public Understand. Sci. 16, 79–95 (2007). Article Google Scholar Wynne, B. Knowledges in context. Sci., Technol. Hum. Values 16, 111–121 (1991). Article Google Scholar Evans, G. & Durant, J. The relationship between knowledge and attitudes in the public understanding of science in Britain. Public Understand. Sci. 4, 57–74 (1995). Article Google Scholar Pardo, R. & Calvo, F. Attitudes toward science among the European public: a methodological analysis. Public Understand. Sci. 11, 155–195 (2002). Article Google Scholar Hamilton, L. C. Education, politics and opinions about climate change evidence for interaction effects. Clim. Change 104, 231–242 (2011). Article Google Scholar McCright, A. M. Political orientation moderates Americans’ beliefs and concern about climate change. Clim. Change 104, 243–253 (2011). Article Google Scholar Drummond, C. & Fischhoff, B. Individuals with greater science literacy and education have more polarized beliefs on controversial science topics. Proc. Natl Acad. Sci. USA 114, 9587–9592 (2017). Article CAS PubMed PubMed Central Google Scholar Oskamp, S. Overconfidence in case-study judgments. J. Couns. Psychol. 29, 261–265 (1965). Article CAS Google Scholar Sanchez, C. & Dunning, D. Overconfidence among beginners: is a little learning a dangerous thing? J. Pers. Soc. Psychol. 114, 10–28 (2018). Article PubMed Google Scholar Quattrociocchi, W., Scala, A. & Sunstein, C. R. Echo Chambers on Facebook (SSRN, 2016); https://doi.org/10.2139/ssrn.2795110 Science and Engineering Indicators 2014 Ch. 7 (National Science Foundation, 2014). Iyengar, S. & Krupenkin, M. The strengthening of partisan affect. Polit. Psychol. 39, 201–218 (2018). Article Google Scholar Klein, E. Why We’re Polarized (Profile Books, 2020). Bauer, M. in Handbook of Public Communication of Science and Technology (eds Bucchi, M. & Trench, B.) Ch. 8 (Routledge, 2008). Nickerson, R. S. Confirmation bias: a ubiquitous phenomenon in many guises. Rev. Gen. Psychol. 2, 175–220 (1998). Article Google Scholar Fernbach, P. M., Rogers, T., Fox, C. R. & Sloman, S. A. Political extremism is supported by an illusion of understanding. Psychol. Sci. 24, 939–946 (2013). Article PubMed Google Scholar Meyers, E. A., Turpin, M. H., Białek, M., Fugelsang, J. A. & Koehler, D. J. Inducing feelings of ignorance makes people more receptive to expert (economist) opinion. Judgm. Decis. Mak. 15, 909–925 (2020). Article Google Scholar Rozenblit, L. & Keil, F. The misunderstood limits of folk science: an illusion of explanatory depth. Cogn. Sci. 26, 521–562 (2002). Article PubMed PubMed Central Google Scholar Walters, D. J., Fernbach, P. M., Fox, C. R. & Sloman, S. A. Known unknowns: a critical determinant of confidence and calibration. Manag. Sci. 63, 4298–4307 (2017). Article Google Scholar Campbell, T. H. & Kay, A. C. Solution aversion: on the relation between ideology and motivated disbelief. J. Pers. Soc. Psychol. 107, 809–824 (2014). Article PubMed Google Scholar Feinberg, M. & Willer, R. The moral roots of environmental attitudes. Psychol. Sci. 24, 56–62 (2013). Article PubMed Google Scholar Feinberg, M. & Willer, R. From gulf to bridge: when do moral arguments facilitate political influence? Pers. Soc. Psychol. B. 41, 1665–1681 (2015). Article Google Scholar Hornsey, M. J. Why facts are not enough: understanding and managing the motivated rejection of science. Curr. Dir. Psychol. Sci. 29, 583–591 (2020). Article Google Scholar Campbell, W. K., Goodie, A. S. & Foster, J. D. Narcissism, confidence and risk attitude. J. Behav. Decis. Mak. 17, 297–311 (2004). Article Google Scholar Littrell, S., Fugelsang, J. & Risko, E. F. Overconfidently underthinking: narcissism negatively predicts cognitive reflection. Think. Reason. 26, 352–380 (2020). Article Google Scholar Macenczak, L. A., Campbell, S., Henley, A. B. & Campbell, W. K. Direct and interactive effects of narcissism and power on overconfidence. Pers. Indiv. Differ. 91, 113–122 (2016). Article Google Scholar Sukenik, S., Reizer, A. & Koslovsky, M. Direct and indirect effects of agreeableness on overconfidence. J. Individ. Differ. 39, 174–181 (2018). Article Google Scholar Rodríguez-Ferreiro, J. & Barberia, I. Believers in pseudoscience present lower evidential criteria. Sci. Rep. 11, 24352 (2021). Sanchez, C. & Dunning, D. Jumping to conclusions: implications for reasoning errors, false belief, knowledge corruption and impeded learning. J. Pers. Soc. Psychol. 120, 789–815 (2021). Article PubMed Google Scholar Kuhn, S. A. K., Lieb, R., Freeman, D. andreou, C. & Zander-Schellenberg, T. Coronavirus conspiracy beliefs in the German-speaking general population: endorsement rates and links to reasoning biases and paranoia. Psychol. Med. 52, 4162–4176 (2022). Pytlik, N., Soll, D. & Mehl, S. Thinking preferences and conspiracy belief: intuitive thinking and the jumping to conclusions-bias as a basis for the belief in conspiracy theories. Front. Psychiatry 11, 568942 (2020). Article PubMed PubMed Central Google Scholar Beyer, S. Gender differences in the accuracy of self-evaluations of performance. J. Pers. Soc. Psychol. 59, 960–970 (1990). Article Google Scholar Hill, P. W. H. et al. Science possible selves and the desire to be a scientist: mindsets, gender bias and confidence curing early adolescence. Soc. Sci. 6, 55 (2017). Article Google Scholar Johns, R. Likert Items and Scales Survey Question Bank: Methods Fact Sheet 1 (UK Data Service, 2010). Download references Acknowledgements We thank C. Souto-Mayor, M. West and J. Nolasco for initial extraction and analysis of the EB dataset, members of the SPAC group for valuable discussions, Fernbach et al.9 for making their survey data available and M. Bauer, T. Paixão, M. Entradas and J. Lobo Antunes for critical reading of the manuscript. We also thank L. Hamilton for independently testing the robustness of our metric and confirming some of our findings. This project was partially funded by Welcome DFRH WIIA 60 2011 and ERC-Starting Grant FARE-853566, both to J.G.S. The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript. Author information Author notes These authors contributed equally: Simone Lackner, Frederico Francisco, Cristina Mendonça. Authors and Affiliations LIP - Laboratório de Instrumentação e Física Experimental de Partículas, Lisboa, Portugal Simone Lackner, Cristina Mendonça & Joana Gonçalves-Sá Departamento de Física e Astronomia, Faculdade de Ciências, Universidade do Porto, Porto, Portugal Frederico Francisco CICPSI, Faculdade de Psicologia, Universidade de Lisboa, Lisboa, Portugal André Mata Nova School of Business and Economics, Carcavelos, Portugal Joana Gonçalves-Sá Contributions J.G.S. conceived of this work. All authors contributed to the methodology. S.L., F.F., C.M. and J.G.S were involved in investigation. A.M. and J.G.S. undertook supervision. All authors wrote the manuscript. Corresponding author Correspondence to Joana Gonçalves-Sá. Ethics declarations Competing interests The authors declare no competing interests. Peer review Peer review information Nature Human Behaviour thanks Ian Brunton-Smith, Lawrence Hamilton and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available. Additional information Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Extended data Extended Data Fig. 1 Model comparison. Different expectations of the proportions of correct (yellow), incorrect (purple) and ‘Don’t Know’ (green) answers, per knowledge bin (a, c, e, g, i) or proportion of incorrect (purple) and ‘Don’t Know’ (green) within non-correct answers only, per knowledge bin (b, d, f, h, j) depending on different expectations of the relationship between confidence and knowledge (k). Perfect metacognition (a, b, yellow solid line in k) expects all non-correct answers to be of the ‘Don’t Know’ type. Random answering (c, d, dotted blue line in k) expects a constant and even proportion of ‘Don’t Know’ and incorrect answers regardless of knowledge bin. If overconfidence decreases with knowledge (e,f, green lines in k), the proportion of incorrect answers should decrease as knowledge increases. If overconfidence increases with knowledge (i, j, solid purple line in k), the proportion of incorrect answers should increase as knowledge increases. If respondents only ‘guess’ when they do not know the answer, the distribution of incorrect may vary depending on the baseline knowledge and the fraction of incorrect should grow nonlinearly with knowledge (g, h, large-dash grey line in k). Extended Data Fig. 2 Knowledge distributions. Knowledge distributions for EB (a), GSS (b), Pew (c), Lackner (d) and Fernbach (e). Absolute frequencies for the first bin in each dataset were: 1179, 107, 165, 2, 42, respectively. Absolute frequencies for the last bin in each dataset were: 2753, 556, 685, 64, 48, respectively. Extended Data Fig. 3 Alternative calibration models. Alternative representation of calibration errors, with different null models. Left axis show the answer proportion with green bars representing observed proportion of ‘Don’t Know’ answers per knowledge bin and purple bars representing observed proportion of incorrect answers per knowledge bin, out of all non-correct answers, for EB (a–d), GSS (e–h), Pew (i–l) and Lackner (m–p). In all plots, solid lines show the expected proportion of incorrect answers (null model) and the dashed line the calibration error calculated as the difference between the observed and the corresponding null. As different null models allow for different expectations please note that the right axis, can vary between 0 and 1 or between -1 and 1. In (a, e, i, m), the null model represents the perfect metacognitive model (yellow lines), in which any incorrect answer represent a calibration error. In (b, f, j, n), the null model represents random guessing (blue lines), such that an equal proportion of incorrect and ‘Don’t Know’ answers is expected, regardless of knowledge level. In (c, g, k, o), the null model expects confidence to increase in tandem with knowledge (purple lines). In (d, h, l, p), the null model is the result of the simulations with 25% guessers (dark-grey lines). Extended Data Fig. 4 Demographic analyses for the EB and Lackner surveys. (a–d) EB data, (e–g) Lackner data. (a, e) Box plot shows the fraction of female (orange) and male (blue) respondents that never say ‘Don’t know’ across (a) 31 territories or (e) 3 countries. Data was negatively tested for normality using scipy’s stats module’s normaltest function (α = 0.001) and for similarity (two-tailed Mann-Whitney U test) in both datasets. Three black asterisks indicate statistical significance with p < 0.001 in (a) and in (e) no significant difference was found. (b, f) Box plot shows the fraction of different age group bins that never say ‘Don’t know’ across all (b) 31 territories or (f) 3 Lackner-surveyed countries. Diamond indicates an outlier (values in the panel). A two-tailed Kruskal-Wallis H-test and all pairwise comparisons were found to be significant with post hoc Tukey’s tests except for (b) 25-39 vs. 40-49 and 40-49 vs. 55+ and no evidence of significance in (f) (p = 0.042). (c, g) Box plot shows the fractions of different bins of age at time of completing their education that never say ‘Don’t know’ across all (c) 31 territories or (g) 3 Lackner-surveyed countries. Diamonds mark outliers (values in the panel). A two-tailed Kruskal-Wallis H-test and all pairwise comparisons were found to be significant with post hoc Tukey’s tests, except for ‘Up to 15’ vs. ‘Still studying’ and ‘16-19’ vs. ‘20 + ’, in (c) and no evidence of significance in (g) (p = 0.036). (d) Scatter plot shows for each territory the fraction of respondents that never say ‘Don’t know’ sorted according to latitude of the territory. Black line shows the linear regression with low correlation represented R2 = 0.21. (h). Table with values for all whiskers (low, 3rd column and high, 7th column) and quartiles (Q1, Median and Q3). Extended Data Fig. 5 Answer distributions to the ‘How Informed’ questions and calibration errors. (a, c, e, g, i) Stacked bar plots showing fraction of respondents who answered ‘Poorly’ (yellow), ‘Moderately well’ (light blue) and ‘Very well’ (dark green) when questioned how informed they were about (a) new inventions and technologies, (c) new medical discoveries, (e) new scientific discoveries, (g) politics and (i) sports news, per knowledge level. In all panels, black solid lines with squares indicate mean fraction of respondents who answered ‘Moderately well’ or ‘Very well’ per quartile, while solid grey line shows average knowledge rank per quartile. (b, d, f, h, j) Plot showing the difference between average fraction of respondents who answered ‘Moderately well’ or ‘Very well’ per quartile and average knowledge rank per quartile, each represented by a circle marking the average and a vertical line marking the variation in average between bins of the same quartile. Extended Data Fig. 6 EB attitudinal data. (a, c, e, g, i, k, m) show stacked bar plots with fractions of Agree (orange), Neutral (yellow) and Disagree (red) answers in response to 7 EB attitude questions. Order of stacked bars is inverted in (e, k) as, in those two items, a negative attitude could be revealed by the Agree answer, while the reverse might be true for (a, g, m). (c) and (i) show a more nuanced response. Figures in (b, d, f, h, j, l, n) show the mean fractions across 34 EU territories with standard error of the mean. Extended Data Table 1 Knowledge questions Full size table Extended Data Table 2 Attitude questions Full size table Supplementary information Supplementary Information Supplementary Methods, Tables 1–5, Figs. 1–9 and Annex. Reporting Summary Peer Review File Rights and permissions Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law. Reprints and Permissions About this article Cite this article Lackner, S., Francisco, F., Mendonça, C. et al. Intermediate levels of scientific knowledge are associated with overconfidence and negative attitudes towards science. Nat Hum Behav (2023). https://doi.org/10.1038/s41562-023-01677-8 Download citation Received 19 September 2022 Accepted 11 July 2023 Published 14 September 2023 DOI https://doi.org/10.1038/s41562-023-01677-8 Subjects Human behaviour Science, technology and society Access through your institution Buy or subscribe Associated Content With some knowledge comes great confidence (and negative attitudes toward science) Nature Human Behaviour Research Briefing 14 Sept 2023 Sections Figures References Abstract Data availability Code availability References Acknowledgements Author information Ethics declarations Peer review Additional information Extended data Supplementary information Rights and permissions About this article Advertisement Nature Human Behaviour (Nat Hum Behav) ISSN 2397-3374 (online) nature.com sitemap About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Nano Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Live Expert Trainer-led workshops Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Career development Nature Careers Nature Conferences Nature events Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights © 2023 Springer Nature Limited",
    "commentLink": "https://news.ycombinator.com/item?id=37511036",
    "commentBody": "Intermediate sci knowledge associated with overconfidence and negative attitudesHacker NewspastloginIntermediate sci knowledge associated with overconfidence and negative attitudes (nature.com) 239 points by taylorbuley 18 hours ago| hidepastfavorite196 comments biomcgary 17 hours agoAs a scientist, I&#x27;ve seen lots of people who are overconfident in both themselves and overconfident in science. IMO, a good PhD science program helps students master a discipline, but also to recognize the limits of the discipline.For example, 23andMe thought they would revolutionize drug development with a huge genetics dataset. In practice, genetic information alone is not sufficient to treat the majority of diseases that affect individuals and society. There is too much environmental variation affecting human biology for purely genetic approaches.Understanding the real limits of knowledge is vital to pushing knowledge forward where we can. As a biologist, one of the things I most appreciate about Sabine Hossenfelder (a physicist) is that she highlights the limits of knowledge in her (and adjacent) fields. She gets a lot of push back (and is sometimes wrong), but having the discussion is vital to science.Acknowledging the limits of science is not a negative attitude about science, but a positive one. A clear idea of the current limits of science (both theoretically and practically) is instrumental to pushing through them. For example, the scholarly papers highlighting the replication crisis (https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Replication_crisis) are actually very useful to maintaining the health of science as a human endeavor, not a critique of science. Scientists need a clear understanding of the scientific foundations that they are building on. reply NikolaNovak 16 hours agoparentI find that coloquially we use the term \"science\" in several distinct meanings, two of which are:1. Science as the body of knowledge2. Science as a method &#x2F; approachI also find that mixing the meanings&#x2F;perspectives&#x2F;intent up in a single conversation is common, sometimes accidentally sometimes intentionally.In my ignorance (ComSci major, so not a real science :), I would describe myself as extremely positive &#x2F; confident to \"Science, the approach&#x2F;method\" and, through that approach, pragmatic about the \"Science the current body of knowledge\".In other words:Yes, there are very much limits to what we currently know, and some of what we think we know will turn out to be wrong, subtly or catastrophically. There are definitely huge limits and uncertainties to Science the body of knowledge!But, acknowledging it is kinda the point, and the best way to figure it out that we are currently aware of is through scientific approach. (I&#x27;ve just realized I might even have become a zealot that you describe, because I can&#x27;t even figure out what a plausible & feasible alternative method is, if your goals are to actually figure things out. To that point, I find humility and skepticism about your current science body of knowledge a crucial part of science the method, something which most other methods lack).I find distinction is crucial especially in political and religious discussion frameworks. Otherwise, I never know if I agree or disagree with statements regarding \"limits of science\" etc.(This is all further mixed up by zillion of daily popular articles where \"Science says that [...]!!!\" or \"[...], scientists find\", which... ugh, oversimplify at best and deceive more likely)What are your thoughts? reply Sharlin 16 hours agorootparentI think there is a third definition of \"science\":3. What is actually happening in academiaI think most people exposed to science#3 from the inside can agree that science#2 works – and indeed works surprisingly well – despite science#3, not because of it. reply tivert 15 hours agorootparent> I think there is a third definition of \"science\":> 3. What is actually happening in academiaWhile we&#x27;re enumerating, I think there&#x27;s a fourth definition:4. \"Science\" as a belief system rather than as a tool&#x2F;technology. I think in this respect, there&#x27;s often an unacknowledged (or denied) blurring between science and science fiction (the more traditional \"spaceship books\" kind, as well as overconfident speculation). There&#x27;s also a tendency to claim the prestige and authority of science for one&#x27;s own personal opinions and preferences. reply BlueTemplar 13 hours agorootparentI think the word \"Scientism\" (also) covers that one ? reply mcpackieh 13 hours agorootparentAccording to wiktionary, &#x27;scientism&#x27; has these meanings:1. The belief that the scientific method and the assumptions and research methods of the physical sciences are applicable to all other disciplines (such as the humanities and social sciences), or that those other disciplines are not as valuable. 2. The belief that all truth is exclusively discovered through science.Maybe the second definition kind of fits if you stretch it. I think &#x27;futurism&#x27;, not in the sense of the artistic movement, is a closer fit; &#x27;2. The study and prediction of possible futures.&#x27; reply ramblenode 6 hours agorootparentI think scientism runs deeper than just a set of philosophical beliefs. It is more like a modern religion, or even an aesthetic.A key feature of scientism is that science itself is never well defined or understood by its adherents, so science is a floating signifier that can mean whatever its proponents want it to mean. Typically, these are not people with firsthand experience doing science, but consumers of second and thirdhand science media and science culture (TED Talks, \"I fucking love science\", NASA t-shirt, \"I believe in science\" bumper sticker, etc.). Lack of scientific literacy results in science taking on a ritual status, where following the ritual (scientific method, peer review, etc.) produces truth, and failure to find truth is always the fault of the mislead individual scientist. Because science is the ultimate source of truth, it is also the organizing principle for society, and those \"anti-science\" people who would question science are dangerous and stand in the way of progress--basically a religion. reply NikolaNovak 8 hours agorootparentprevI find personally that \"scientism\", unlike many other ism-s, is an external label. I.e. I don&#x27;t think people call themselves that. It&#x27;s a negative label ascribed to people one philosophically disagrees with. As such, I am skeptical of its value and use. reply mistermann 12 hours agorootparentprevBelieve it or not, I have had more than one person tell me with sincerity that observing the contents of a box is \"doing science\", I imagine because they believe that science is actually the only way to acquire knowledge.Meanwhile, these people mock the religious [in their imagination] for \"being\" insular&#x2F;fundamentalist. reply T-A 11 hours agorootparent“When you break an egg and scramble it you are doing cosmology,” said Sean Carroll, a cosmologist at the California Institute of Technology.[1] https:&#x2F;&#x2F;www.nytimes.com&#x2F;2008&#x2F;01&#x2F;15&#x2F;science&#x2F;15brain.html reply NikolaNovak 8 hours agorootparentprevWhat are the other ways? reply Muromec 2 hours agorootparentMaking things up reply 1letterunixname 10 hours agorootparentprevThe word you&#x27;re looking for is probably \"anti-intellectualism\". The tribal flavoring of the white supremacism-religious fundamentalism far-right spectrum in the US is against undisputed knowledge, history, learning, and facts in addition to STEM. reply ronjobber 10 hours agorootparentOr they could be referring to the opposite - the unquestioning adherence to all things Science, as long as those things fall within the progressive orthodoxy that has a stranglehold on academia. reply DiggyJohnson 9 hours agorootparentprevThis comment doesn’t make sense at all in this context. It seems like you’re rushing to put down the “white supremacism-religious fundamentalism far-right” before understanding if that’s relevant to this thread.That’s too many hyphens. reply NikolaNovak 15 hours agorootparentprevAgreed; I have a few friends who quit academia, and few who stayed. Some of their experiences are hope-inspiring, some are depressing. Same for those in government employ.But I don&#x27;t think as academia as the only, or even necessarily the most important place that science is happening in the world today. reply jltsiren 12 hours agorootparentprevI often trust science as a social process more than the scientific method.The scientific method works best in fields such as physics and chemistry, where you have an established model of reality. The model has been extensively tested and validated, and you can use it to design experiments that will likely test what they are supposed to, taking all relevant factors into account.Other fields, particularly those that are most affected by the replication crisis, study phenomena that are too complex for such comprehensive models. Instead of testing established mechanisms, such fields often use the scientific method to investigate black boxes. Designing experiments is harder, because it&#x27;s not clear if you are measuring the right things in the right way, or which factors could plausibly affect the results. You may not even be sure if the mechanisms the experiments rely on actually exist and if they are properly understood.I like to think that the replication crisis is the social process trying to deal with the issues resulting from overreliance on the scientific method. When you can&#x27;t rely on an established body of knowledge, a focus on the method takes your attention away from questioning your assumptions and understanding them. reply wolverine876 6 hours agorootparent> I like to think that the replication crisis is the social process trying to deal with the issues resulting from overreliance on the scientific method. When you can&#x27;t rely on an established body of knowledge, a focus on the method takes your attention away from questioning your assumptions and understanding them.Which particular research are you thinking of? reply wolverine876 6 hours agorootparentprevIs that the negative attitude the OP refers to? reply mathematicaster 16 hours agorootparentprevTop comment.My adjacent refrain is \"Science is not the same as people trying to do science\". reply biomcgary 16 hours agorootparentThe work of philosophers and sociologists of science, Kuhn and Feyerabend in particular, support this perspective. reply mistermann 12 hours agorootparentprevScientists trying to do science is a component of broad science, is it not? reply mike_hearn 37 minutes agorootparentOnly if they succeed at doing science. If they just engage in pseudo-science then it&#x27;s not. reply ThinkBeat 14 hours agorootparentprev\"\" > I would describe myself as extremely positive &#x2F; confident to \"Science, the >approach&#x2F;method \"\"But what does that actually mean? How do you manifest this in your daily life and in your decisions?My grandmother told me God told me I heard on the newsWell, that does not seem scientific nor following the tenants of science. But how can you evaluate information you receive that is called science and in so far as you know from a source of a scientist. Esp. these days in the US everything is incredibly politicized.There is no way to dig deep enough into every tidbit of knowledge we are exposed to. A lot of scientific fields these days are so complicated that you need a degree to start understanding what is going on or to evaluate data.If we are lucky we know a few people in different fields whom we trust. We trust the people to we trust what the say, since they are scientists. We all walk around and -believe- in various things we hear and elect not to believe in others. Then we claim that we believe in this or that \"because of science\". and because of the scientific method. But we dont know that for a fact because we dont know and probably could not understand all the steps from beginning to end needed to ensure that the scientific model had been applied appropriately at all stages.I dont think real science should state \"THIS IS TRUTH BECAUSE THIS IS SCIENCE\" it should be \"This is our best understanding right now, and there are some other theories out there that may also be valid.\" reply cowpig 14 hours agorootparentI think the parent comment specifically means coming up with a falsifiable hypothesis and testing it, as opposed to the \"body of knowledge\" part you are talking about. reply biomcgary 16 hours agorootparentprevI think your distinction between 1 and 2 is very important (but, as a computational biologist, I disagree about CompSci not being science :-).Along these lines, I think the role of consensus in science has been overly dramatized by those with various policies to push. Max Planck&#x27;s principle is famous in the short form \"Science progresses one funeral at a time\". One of the professors I worked with as a graduate student had a sign on his desk, \"First They Ignore You, Then They Laugh at You, Then They Attack You, Then You Win\".These two quotes captures an important tension in the practice of science: consensus both retards the progress of science and captures it for others to build on. reply mcguire 15 hours agorootparentRetarding the progress of science is sometimes (often?) a good thing.Many people regard Einstein&#x27;s later career as fruitless, but by attacking quantum mechanics, he improved its foundations as well as making it much more acceptable. reply nonrandomstring 15 hours agorootparentprevThere is also:3. Science the institution.As in \"What Science says about X\" as if there was a single authoritative, coherent entity we could call Science. reply NikolaNovak 15 hours agorootparentIt is frequently used that way, and I suppose I didn&#x27;t include it because I feel it&#x27;s an incorrect usage... but I&#x27;d have to agree with you that it might even be the most common :-&#x2F; reply Ensorceled 15 hours agorootparentprevThis is often what is meant when the lay person uses \"science\" or \"scientists\" in a (usually) derogatory way. reply austin-cheney 16 hours agorootparentprevWhat’s important is not what you think. More important is what other people think, even though their observations are at fault no differently than your own. What’s most important is how you measure compared to other people, as everything else is a biased faulty guess.Younger people are more at risk of getting this wrong because their scope of knowledge and experience are shallower. Introspection grows with age, but when introspection is not deliberate older people are more catastrophically at risk of getting this wrong. reply mistermann 14 hours agorootparentprevI would add:3. Science, the mass psychological phenomenenon.Like many ideologies it behaves a lot like a religion, and online discussions are chock full of artifacts.In my case, I have a negative view of \"science\" because of this phenomenological aspect of it, which I consider dangerous because it results in irrational, tribal thinking (see: covid, climate change, etc)...and it ain&#x27;t only the \"deniers\" who are guilty.> Yes, there are very much limits to what we currently know, and some of what we think we know will turn out to be wrong, subtly or catastrophically. There are definitely huge limits and uncertainties to Science the body of knowledge!> But, acknowledging it is kinda the point, and the best way to figure it out that we are currently aware of is through scientific approach.Pro-science people absolutely love this meme, I encounter it several times a day in the online spaces I frequent. reply trimethylpurine 2 hours agorootparentThis goes back to the comments on definition. Much of the misinformation on covid was largely due to the general public having a misunderstanding of what can NOT be called science. For example; when a research paper is peer reviewed by its author (e.g. Pfizer reviewing its own drug research) that&#x27;s clearly not science. Conversely, when the heads of multiple top university epidemiology departments come together to speak out about it, that should be regarded as science. What happened with COVID is that the media declared itself the authority on science, most of the public believed them, and most scientists were pushed aside or stuffed with a sock and labeled \"deniers.\" This altogether framed science as the bad guy. That is; what you described as science in your comment is actually not describing science at all. It&#x27;s describing the media. reply mike_hearn 29 minutes agorootparentIronically you&#x27;re presenting textbook mis-definitions of science, the exact problem being discussed in this thread.> when a research paper is peer reviewed by its author .. that&#x27;s clearly not sciencePeer review is something academia evolved only relatively recently. Science long pre-dates peer review, and you can do science without peer review (or with useless peer review) just like you can write programs without code review. As recently as Einstein, peer review was being seen as some offensive newfangled thing which he had no time for.The goal of peer review is to try and ensure that claims that are presented as being scientific actually are. It frequently fails at that task but even when it works it&#x27;s still just a safety check, not an actual required component of true science.> when the heads of multiple top university epidemiology departments come together to speak out about it, that should be regarded as scienceA bunch of academics making an announcement is definitely not science. The whole point of science is that it doesn&#x27;t rely on People With Titles deciding by fiat what&#x27;s true. That&#x27;s what religion is!> What happened with COVID is that ... most scientists were pushed asideWe have very different memories of these events. reply trimethylpurine 6 minutes agorootparentYou&#x27;re right. I should have said, good science. You&#x27;re welcome to dabble as deep into whatever mental hole you like without taking any criticism. But in and of itself, such a take on science is deserving of criticism, and has been criticized by scientific philosophers for centuries. reply theGnuMe 16 hours agorootparentprevThe science of computing is a real science. reply seanr88 15 hours agorootparentI&#x27;d agree with this although I understand where the idea comes from. It is difficult for people to understand what is and is not a science and it is easy to think that computer science is not a science even when you study it.The way we learn and study topics is divorced from the original method of discovering those topics. The way people learn Computer Science is generally by absorbing the information, not by doing the experiments. So it is difficult for people to understand that the way we have this knowledge is through hypothesis forming and experimentation i.e. Science. reply eh_why_not 15 hours agoparentprev> As a scientist, I&#x27;ve seen lots of people who are overconfident in both themselves and overconfident in science.I feel that I&#x27;ve never had the first problem, but have definitely had the second.On one hand, there is the natural limitation of Science itself in terms of the type of questions (that are amenable to the scientific method) it can answer. On the other hand, it is still the best way of generating knowledge that we have.My overconfidence was that scientists, as individuals and as a community, would always do the right thing, driven by, and honestly following, the scientific method. But in the past few years I&#x27;ve had to revisit this assumption several times and be reminded to always retain some healthy skepticism.Most recent example is this climate scientist who just published in Nature, and then went ahead afterwards and penned an op-ed [0] saying he actually misrepresented the actual factors in order to get published.[0] https:&#x2F;&#x2F;www.thefp.com&#x2F;p&#x2F;i-overhyped-climate-change-to-get-pu... reply perfect-blue 14 hours agorootparent> My overconfidence was that scientists, as individuals and as a community, would always do the right thing...This is a great point. I&#x27;m shocked by how often I end up working on a project with a colleague who is taking the path of least resistance. In my field, this usually results in using decades old statistical methods than have been proven time and time again to be unsatisfactory. They just don&#x27;t want to learn new methods or their technical expertise aren&#x27;t good enough to learn how to implement the new approaches. So they just coast. I&#x27;m not sure what to do in these situations other than just try and set a positive example. reply dekhn 15 hours agoparentprev23&Me failed in drug development because they started from a mistaken premise- that the data they collected (very specifically, genotype arrays) would produce data that was correlated with human health closely enough to identify targets (proteins or pathways to disrupt&#x2F;modify). They have a huge genetics dataset, they don&#x27;t have a huge genomics dataset, and the underlying relationship between the genome and phenotypes (especially complex disease phenotypes) is a highly nonlinear function.Environment is important but we could still have huge improvements in medical care using genomics. It&#x27;s easy to obtain and still has a very strong relationship to disease, and is a problem best solved by deep learning. I&#x27;ve watched people tilt against this windmill for 25+ years and it&#x27;s kind of funny just how bad our labelling of diseases is. reply dahinds 10 hours agorootparentThis is an inaccurate view of what 23andMe is doing.First we did not \"fail\" in drug development, our collaboration with GSK yielded substantially more programs than we had anticipated when we started. The verdict on whether the strategy is successful or not will not be clear for another 5-10 years because being better at picking targets doesn&#x27;t shorten the timeline for bringing a drug to market, it mostly means that you should have a modestly higher proportion of programs that end up being successful.Second we did not start with a premise that we could or needed to do a great job of predicting disease from genetics alone, that is not required to identify good targets. You&#x27;re correct we don&#x27;t have huge genomics datasets, we largely use the same genomics datasets others use. Identifying targets with genetics in the simplest sense requires using genetics to identify an association at a genomic location, and then using genomics for functional interpretation of that association. And having the largest database of genetic associations enables the first step of that.I&#x27;m not sure what you mean by \"the underlying relationship between the genome and phenotypes... is a highly nonlinear function\". Simple additive models account for most of the heritability of complex phenotypes. reply dekhn 9 hours agorootparentThe only thing 23&Me has done really well in stat gen is IBD (which IIRC you worked on).I was a team from Google that evaluated 23&Me&#x27;s data and technology many years ago for a business deal. We already talked about this with Anne and she confirmed what I said above. It might have been before you were hired- but I&#x27;m pretty sure we talked about building a variant store and a transpose service? I stand by my statements (note: I work at a competitor of GSK and I know all about these deals). It&#x27;s not correct that being better at picking targets doesn&#x27;t shorten the timeline, either- at least in the opinion of the scientists at my company.Additive models don&#x27;t really account for most of the heritability of complex phenotypes. They&#x27;re what have worked best and been published so far. Complex phenotypes are nonlinear because the generative processes in biology have feedback, homeostasis, enormous numbers of individual elements... etc...By the way, does 23&Me still put tongue-twisting as a heritable trait on its reports? https:&#x2F;&#x2F;blog.23andme.com&#x2F;articles&#x2F;tackling-tongue-curling-th... It&#x27;s not. reply dahinds 8 hours agorootparentI did not work on IBD but have been doing stat gen at 23andMe for 13 years. I&#x27;d say that anything you evaluated many years ago is pretty irrelevant today as the 23andMe database (and our research effort) didn&#x27;t reach an interesting size until maybe 2016 and has grown rapidly since then. Our research group has >100 peer reviewed publications, I think some of them are decent, and that&#x27;s just what we publish. Most of those are genome-wide association studies so a lot might hinge on whether you find those interesting&#x2F;valuable. I would not say these are methodologically innovative, but I think we do them well.You may be correct that better targets may be faster to market. We would also hope so: better targets might be more straightforward to validate in the lab and may enable smaller trial sizes, for instance. Timelines are still long and this doesn&#x27;t alter my statement that the success or failure of our target selection strategy won&#x27;t be known for some years.Do you have any evidence for additivity not accounting for most heritability? I&#x27;ll give one cite (https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC2265475&#x2F;). The fact that biology is very complex and non-linear is not inconsistent with most genetic effects being small and approximately additive.We have never had a trait report on tongue curl, the 15-year-old blog post you linked to says it isn&#x27;t a Mendelian trait, so I&#x27;m not sure where you were going with that. I can tell you that it is somewhat heritable but complex. reply biomcgary 15 hours agorootparentprevExcellent point. I work at a biotech startup where one major focus is \"how do we fix the disease labels?\". I call it the pyrite problem (your gold standard data contains fools gold), but it is known more prosaically as the mislabeling problem. reply GoblinSlayer 4 hours agoparentprev>As a biologist, one of the things I most appreciate about Sabine Hossenfelder (a physicist) is that she highlights the limits of knowledge in her (and adjacent) fields.I only heard her arguing others are wrong because she&#x27;s right. That&#x27;s not a demonstration of the limits of knowledge. reply XTHK 11 hours agoparentprev>one of the things I most appreciate about Sabine Hossenfelder (a physicist) is that she highlights the limits of knowledge in her (and adjacent) fields.I suppose you missed her recent video about economics? Her content is getting more and more clickbaitey by the day. Some really half-baked data creeping into her videos. reply ramraj07 9 hours agorootparentIt really is sad indeed. You die a hero (stop posting videos once you’ve exhausted your expertise) or live long enough to become a villain indeed. reply crabmusket 11 hours agoparentprev> Acknowledging the limits of science is not a negative attitude about science, but a positive one. A clear idea of the current limits of science (both theoretically and practically) is instrumental to pushing through them.\"The gods did not reveal, from the beginning, all things to us, but in the course of time through seeking we may learn and know things better. But as for certain truth, no man has known it, nor shall he know it, neither of the gods Nor yet of all the things of which I speak. For even if by chance he were to utter the final truth, he would himself not know it: for all is but a woven web of guesses\"Xenophanes via Karl Popper reply f1shy 15 hours agoparentprevThe most over confident in theirselves and science people I know are PhD. With egos and arrogance greater than the solar system. People that go early to the industry and see the “real world” tend to have a more tamed expectative of what they could achieve and science can offer. reply brigadier132 12 hours agoparentprevIronically, you are taking this study at face value. This study reminds me of the \"Republicans tend to be sociopaths more often\" study. That ended up being completely refuted. reply lusus_naturae 17 hours agoprevThe study has an interesting approach to avoiding self-reporting level of confidence.> We propose and use in the paper, an indirect measure of confidence in knowledge, defined as the ratio of incorrect to ‘don’t know’ answers in any knowledge questionnaire, as long as it had the format true&#x2F;false&#x2F;don’t know (or similar). The rationale is that an incorrect answer corresponds to an overestimation of one’s knowledge (more details in the main text).On face value it seems like a good way to avoid the pitfalls of self-report surveys, perhaps also useful in affective modeling. reply svnt 16 hours agoparentHow do they&#x2F;you remove the confound of becoming more conservative vs less confident, or do they assume that overconfidence and being conservative are opposites?I might be motivated to be more conservative because I have a reputation to protect, but not actually be less confident. This may have an effect just as much as because I am more experienced.I may also have just learned not to express my overconfidence interpersonally, while still exhibiting it in practice. Expressing appropriate levels of confidence is a skill, not just the absence of overconfidence.I can’t access the paper currently. reply lusus_naturae 9 hours agorootparentPer my understanding of their method, the participants were just asked to do the survey without mentioning what was being measured. It&#x27;s like you said, someone can manage their expression of confidence to a degree (or not, maybe), but privately they may not do that, i.e. when just doing some surveys for a study. One thing I remember from running my own studies like this: usually the participant is subjected to a series of such tests (called a battery, sometimes) in succession so they&#x27;re likely to get fatigued. I think that&#x27;s a tougher effect that can possibly confound studies. Though I am not sure mental fatigue matters so much for this study.Edit: I&#x27;d share the article but have no idea where to host it. reply subw00f 14 hours agorootparentprev> learned not to express my overconfidence interpersonally, while still exhibiting it in practiceWhat does that mean? If you&#x27;re overconfident in the forest and nobody hears it, it doesn&#x27;t really matter, right? reply svnt 12 hours agorootparentIf you still act on your confidence, but learn to give the right answers understating it in conversation, it could be that you gave those same right answers on the test reactively and then their interpretation is probably flawed.In this case, additional knowledge wouldn’t actually represent a diminishment of your confidence in a functional sense, but a learned compensation to social feedback. reply cutemonster 14 hours agorootparentprevIsn&#x27;t participating in such research usually fairly anonymous? And I&#x27;m guessing the researchers didn&#x27;t tell the participants how they were going to interpret \"I don&#x27;t know\" vs wrong answers?> Expressing appropriate levels of confidence is a skill,That&#x27;s interesting, confidence can be gamed, just like other traits in personality tests reply mistermann 12 hours agoparentprevOne issue though is that in realtime cognition under non-laboratory conditions, \"I don&#x27;t know\" often isn&#x27;t available, unlike when it is explicitly given as an answer.The number of science fans I&#x27;ve met who sincerely proclaim they possess knowledge of the unknowable is scary. reply karaterobot 13 hours agoprevI&#x27;m 100% guilty of this. I try not to be, but hey.There&#x27;s different levels:1. The guy who reads the title of the journal article.2. The guy who reads the abstract of the journal article.3. The guy who reads the text of the article.4. The guy who&#x27;s read all the other significant research in the field and can put it in context alongside their own personal experience as a practitioner.I&#x27;m #2, and I strive to be #3. It&#x27;s really hard to be #4, especially for more than one domain. reply shostack 6 hours agoparentI&#x27;m not a scientist, I&#x27;m in digital media and ads, but I&#x27;ve been doing this for almost 20 years and feel confident in my level of technical and business knowledge of the space.I never realized how wrong papers could be until I read some from my industry and dug into their methodology of which I&#x27;m sufficiently knowledgeable to spot issues. I don&#x27;t recall specifics as it was a while ago but I do recall the district impression I was left with which amounted to \"holy crap, I wouldn&#x27;t let this person pull reports on my ad account let alone run campaigns\" due to the buy side 101 mistakes they made.Since then I read all scientific papers with a huge heaping of salt. reply naniwaduni 11 hours agoparentprev0.5. The guy who reads the press release for the journal article!(0.2. The guy who reads the title of the news article for the journal article on HN and proceeds straight to the comment section...) reply moffkalast 11 minutes agorootparent0.1. Guy who reads the edited HN title and makes an offhand joke in the comments without even reading any other comments. reply not_enoch_wise 13 hours agoparentprevThat’s why I skip even reading the title, and get right to mocking other commenters. reply jrflowers 11 hours agorootparentA true Posting Elemental needs no context to ply their trade reply wolverine876 6 hours agorootparent> Posting ElementalIs that a thing or did you make it up? reply jrflowers 1 hour agorootparentMade it up reply jrflowers 12 hours agoparentprev#3.5: The guy who skims the text of the article with just enough effort and time to be proven correct about their opinion of the article’s titleThis is an incredibly common guy reply riccardomc 12 hours agoparentprevYou claim you&#x27;re a #2.5 which is intermediate. So according to the article you might very well be an overconfident #1, instead...You should probably add a \"5. don&#x27;t know\" option and check that one... reply gus_massa 10 hours agoparentprevI read the title, skim the abstract and jump directly to the tables&#x2F;graphics. There is a lot of bullshit in the introduction and conclusions. reply ramblenode 6 hours agoparentprev2.5. The guy who reads the abstract then skips to the figures. reply quickthrower2 12 hours agoparentprev#2.5 someone who lets Karpathy explain it all :-) reply antisthenes 12 hours agoparentprev#3 is pretty orthogonal.There&#x27;s a reason abstracts exist, and they usually provide enough information as to whether the paper discovered any significant findings, so whether it&#x27;s worth reading at all.If you are #1, #2 and in #2 you include reading not just the paper but the meta-analysis papers of the field, that already puts you ahead of 95% of the general public.Not even scientists themselves are full #3 people. It&#x27;s just impossible, considering the amount of work that exists in the field, and considering that most studies just confirm existing findings from 10-20-50 years ago. reply hnthrowaway0328 14 hours agoprevFrom my personal experience (thus does not have statistical significance), it&#x27;s not the amount of knowledge, but the position. Teachers&#x2F;professors are a group of people that I interact frequently with (both my parents and parents of my friends are university professors&#x2F;lecturers), and it just happens that the ones that I know the most are all overconfidence.Basically they think they know everything, to the point of educating the doctors about medicines when they are in the hospital (as patients). I don&#x27;t know what got them into this but I found the arrogance distasteful.Maybe it&#x27;s in the culture though. Back in the day teachers were respected and the relationship between teachers and students are somewhat closer to father-children than customer-merchant. Now time changes but old habits stay hard. reply FactualOrion 14 hours agoparentWhat do you mean by educating the doctors about medicines? I&#x27;ve seen people without degrees advocate for themselves as patients and be more knowledgeable about certain medications and treatments than doctors or nurses were. reply Workaccount2 13 hours agorootparentThis is something that always kind of gets me, because when I have something wrong with me I will do a deep dive on it and read whatever studies, publications, and fellow patient accounts I can find.This often puts me in a position where I feel pretty confident that I have more fresh knowledge about it than the doctor before me. Someone who in all likely hood has a mild familiarity with it, and is filling in the blanks with rote medical intuition.What I really wish is that I could get doctors to drop the veil, and just openly admit what there depth of knowledge on the illness is. I would love it if they googled stuff right in front of me. I absolutely do not expect them to have a full medical encyclopedia in their head, and I am smart enough to be able to not be put off by \"I don&#x27;t know&#x2F;I&#x27;m not sure\". reply quickthrower2 13 hours agorootparentThe flip side is imagine a project manager did this to a programmer or architect. The programmer would constantly need to explain why the blog post they read dated 2013 about how hadoop makes everything faster is wrong, or how that AI paper is bullshit and designed to get someone grant money. Or how someone else’s experience with Azure was great because they just shifted all their Windows stuff to it. So that could kind of stuff get frustrating for the expert. reply abecedarius 9 hours agorootparentIt&#x27;s interesting to imagine doctors understanding humans and their pathologies nearly as well as programmers understand the systems they work on. My guess is that&#x27;d amount to an incredible upgrade.(Yes that level of understanding is often quite poor in absolute terms.) reply SkyMarshal 12 hours agorootparentprevThat’s the promise of AI in medical care, that it can synthesize all known data relevant to observed symptoms and, on average, make a more accurate diagnosis than human doctors.https:&#x2F;&#x2F;towardsdatascience.com&#x2F;ai-diagnoses-disease-better-t... reply CrazyPyroLinux 12 hours agorootparentprevThe old joke: \"The difference between doctors and programmers is that programmers actually admit to finding all their answers on the internet!&#x27; reply hnthrowaway0328 13 hours agorootparentprevLike \"you don&#x27;t know as much as I do, I Googled a page and it says...\" type. No they definitely know very little about the stuffs. And I personally heard and saw they tried to persuade OTHER patients, of different symptoms to listen to their \"theories\". reply ramraj07 9 hours agorootparentFor every 5 “type” People you mention there’s 1 common person who really does spend the time doing their research and likely knows more about the drug than the doctor in some ways (typically they just lack the context of interactions and side effects). A good doctor will listen to what the patient says and then discuss with them what they think with an open mind. Good doctors are rare. Especially nowadays with all this arrogance that they know everything as you say. reply slt2021 13 hours agorootparentprevALL patients with access to Internet are like that.now with chatGPT there will be more people like that reply SkyMarshal 12 hours agorootparentprevIndeed, given the PE-driven profit motive of most (US) hospitals these days, people are increasingly less trusting of their diagnoses and prognoses, and more likely to take an active role in their own care and treatment. reply HPsquared 13 hours agoparentprevI think with teachers and professors it can be a case of \"habit\".They&#x27;re used to being the smartest person in the room and telling the people around them what&#x27;s what. This can sometimes rub off on interactions outside work. Same kind of thing can happen with other professions, of course. reply wolverine876 6 hours agoparentprevDo you disagree with the OP, that it&#x27;s the people with intermediate knowledge that are most overconfident? reply next_xibalba 15 hours agoprevI am 100% guilty of this. I try to consistently remind myself that having read mostly pop-sci and the occasional abstract of a scientific paper does not in any way qualify me as either a scientist or even a knowledgeable non-scientist. reply koromak 14 hours agoparent\"They don&#x27;t know I watched a 20 minute video on relativity\" reply quickthrower2 12 hours agorootparentMeanwhile… everyone else aged 10000 years. reply xamuel 14 hours agoprevI feel like this has been part of the latent background memetic knowledgebase for many years now: https:&#x2F;&#x2F;knowyourmeme.com&#x2F;memes&#x2F;iq-bell-curve-midwit&#x2F;photos&#x2F; reply ObservingFuture 15 hours agoprevI only glanced at the paper, but I wonder how much of this is explained by just random chance?It looks like they used multiple choice quizzes to determine both knowledge in science and a propensity to respond \"don&#x27;t know\" indicating confidence. Any \"don&#x27;t know\" response was counted as an incorrect response, while a correct guess increased the participants \"science knowledge\".Thus, a willingness to guess something at random in the multiple choice test would both increase \"science knowledge\" as well as make the participant appear overconfident. reply moffkalast 15 hours agoparentSounds like your intermediate knowledge of the paper is resulting in an overconfident negative attitude :P reply cududa 15 hours agoparentprevWell yeah but that&#x27;s where data modelling comes in. reply ObservingFuture 14 hours agorootparentI mean, the data modeling assumed people guessing were doing so completely at random without eliminating any options (In the section \"Simulation\").If I&#x27;m looking at the right document, one question was about which city out of Chicago, New York, and LA have the greatest annual temperature range (accompanied with a plot). Almost all respondents said New York or Chicago, rather than LA or \"All equal\". reply read_if_gay_ 15 hours agoparentprevoh irony reply nonrandomstring 15 hours agoprevI think lifespan plays an important part in this. I know a few aging scientists, some with extraordinary achievements, who having accumulated a lifetime of wisdom are finally entering the \"We don&#x27;t really know\" phase about every question. reply mathisfun123 17 hours agoprevto wit:reply not_enoch_wise 13 hours agoparentFucking fantastic reply itronitron 15 hours agoprevIf they want the research to \"help inform science communication strategies\" then make the article freely available. reply dav_Oz 12 hours agoprevOnce the activation energy can be maintained (basic skill and consistency) the learning curve is the steepest at the beginning of any given field; the setbacks are still rare and surmountable (and just mostly add to the confidence). But the human mind is only able to suffer a finite amount of beating and at one point your perceived competence level will collapse dramatically, overcorrecting in the opposite direction.However, the reward structure of overconfidence can be used to maintain the momentum and once you hit the hard wall of insurmountable incompetence congratulate yourself that you actually walked the path of knowing practically nothing.It&#x27;s the hardest thing to fully admit one&#x27;s own ignorance and easy to see all around you, it&#x27;s only when the giant rationalization machine buzzing inside is finally fully exhausted; for a brief moment the crushing vastness of the unknown pours in.So in a way overconfidence is just unused fuel. Use it wisely. reply threeseed 14 hours agoprevI can imagine it&#x27;s not just restricted to scientific knowledge.And having met many of these types of people they all seem to share one trait: definitiveness.Everything is black&#x2F;white and there is always a \"right\" answer or approach where as people with little knowledge and those who are experts tend to be nuanced and flexible. reply emodendroket 17 hours agoprevI feel like we&#x27;ve all encountered this guy. reply not_enoch_wise 13 hours agoparentHacker News is this reply neilv 12 hours agorootparentOne of my favorite parts of n-gate.com&#x27;s &#x27;summaries&#x27; of HN posts was the phrase \"incorrecting each other\". reply malfist 15 hours agoparentprevSome of us have been that guy. reply gumby 13 hours agoprevI think this is also a root of science denialism (e.g. anti-vaxxers). I have some antivax family, and the root of their opinion is that the scientists changed their advice as the pandemic developed!My theory is that in primary and high schools, science is taught as a series of immutable \"facts\". You get tested on remembering them, and when you do an \"experiment\" you get marked down if your reading of the litmus paper isn&#x27;t 4. No sense of doubt, and no exposure to the epistemic boundaries to controleld trials, measurements, etc.If your takeaway is that scientists uncover and explain immutable facts, hearing them say one thing in January and another in June can in fact shake your beliefs in these scientists. reply enjeyw 13 hours agoparentIn highschool I was lucky enough to join a program run by the CSIRO (Australia&#x27;s Government funded scientific research body), where students would assist scientists on experiments they were conducting.I was tasked with measuring the water resistance of a proposed environmentally friendly paper coating.I asked my supervising scientist what numbers I should expect to get back from the experiment. I distinctly remember my surprise and thrill when he looked at me and said \"I have no idea, that&#x27;s why you&#x27;re running the experiment\".It was such a new concept to me! A scientific experiment where the correct answer wasn&#x27;t written in a teacher&#x27;s lesson guide, or even known to anyone! reply ignorethefacts 8 hours agoparentprevThat&#x27;s a bad take.The science mouthpieces (aka media and government speaking on behalf of scientists) were insisting they knew the immutable facts and any questions or doubt in those immutable facts were heretical. Anyone who has an appreciation of the evolving nature of scientific research should immediately see the red flags in that.\"Antivax\" is not a position of anti-science, it&#x27;s a slanderous label for an alternative theory with its own compelling evidence. reply bratgpttamer 12 hours agoparentprevThis has been my experience, too, as well as people who understood The Science perfectly and that the authorities were just taking a best guess early on, which set them further against any kind of mandate. (Mostly older, conservative physicians with an \"it&#x27;ll be fine\" attitude)The Science didn&#x27;t change that much (viz: masks in healthcare since forever), but the flip-flopping with messages (\"don&#x27;t horde masks; they won&#x27;t save you!\", \"wait, no - everyone needs a mask!\"), which was really less about The Science than about different concerns (mask effectiveness, availability) were just the \"I told you so\" they were looking for. reply CrazyPyroLinux 12 hours agorootparent> scientists changed their advice as the pandemic developed\"Changing advice\" is to be expected, but it was the outright lying, as proven by FOIA&#x27;d emails, which understandably shook faith. reply dboreham 13 hours agoparentprevDoubtful it was anything so logical. Humans like to believe magic, and are very easy to manipulate. reply p0w3n3d 12 hours agoprevI&#x27;ve met both overconfident PhD holders and intermediate sci knowledge \"flat-earthers\" (conspiracy theory propagationists). Both are really hard to talk to, and both one couldn&#x27;t convince they are wrong. I observed both being wrong. And meanwhile some of conspiracy theories became true...It&#x27;s really hard to by sure of anything these days reply gobdovan 11 hours agoparentCould you provide examples of conspiracies you knew were wrong and became true? reply archarios 17 hours agoprevWhat does \"intermediate knowledge\" mean in this context? reply Jensson 8 hours agoparentIntermediate knowledge of what&#x27;s being tested, everyone is the most overconfident on subjects they have intermediate knowledge about.If you test high school concepts then if you are shaky about high school concepts that applies to you. People who have no clue about high school and people who understand high school well will be less overconfident on that test.Or if you talk about college algorithms, then that is the basis for intermediate knowledge. An average comp sci grad will be the most overconfident, a person who never studied algorithms and a person who teaches algorithms for years will be less overconfident on that test. reply smcin 14 hours agoparentprevLike high-school level, a very basic familiarity with terms, experiment design, inference. The authors cite and link to the five surveys used in the &#x27;Data availability&#x27; section: https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41562-023-01677-8#data-avai...* Surveys EB, Pew and GSS are publicly available and data and details can be found in refs. [27],[28],[29], respectively. \\* take the interactive Pew survey (11 questions) here: https:&#x2F;&#x2F;www.pewresearch.org&#x2F;science&#x2F;quiz&#x2F;science-knowledge-quiz&#x2F;* The Fernbach study was published in ref. [9] and the authors made the data available.* Lackner survey data are available at: https:&#x2F;&#x2F;doi.org&#x2F;10.5281&#x2F;zenodo.7920776[27]: Bauer, M. W., Shukla, R. & Kakkar, P. Public Understanding of Science in Europe 1989–2005—A Eurobarometer Trend File (GESIS, 2012); https:&#x2F;&#x2F;www.gesis.org&#x2F;en&#x2F;eurobarometer-data-service&#x2F;search-d...[28]: Smith, T. W., Davern, M., Freese, J. & Morgan, S. L. General Social Surveys, 1972–2018 (NORC, 2019); https:&#x2F;&#x2F;gss.norc.org&#x2F;get-the-data[29]: Funk, C., Kennedy, B., Johnson, C., Hefferon, M. & Thigpen, C. L. American Trends Panel Wave 42 (Pew Research Center, 2019); https:&#x2F;&#x2F;www.pewresearch.org&#x2F;science&#x2F;dataset&#x2F;american-trends-...[9]: Fernbach, P. M., Light, N., Scott, S. E., Inbar, Y. & Rozin, P. Extreme opponents of genetically modified foods know the least but think they know the most. Nat. Hum. Behav. 3, 251–256 (2019). https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41562-018-0520-3 reply smcin 14 hours agorootparent(useful to note all those surveys are 2019 pre-pandemic, before there was severe partisanization of the phrase \"trust in science\". I wonder how hard it would be to construct a neutral methodology post-pandemic, now that even the basic vocabulary itself is loaded with associations.)Even then, the 2019 Pew article is depressing reading: https:&#x2F;&#x2F;www.pewresearch.org&#x2F;science&#x2F;2019&#x2F;08&#x2F;02&#x2F;partisanship-... reply calf 11 hours agorootparentprevIf the abstract actually defined intermediate we wouldn&#x27;t have comments talking so much about advanced education like PhDs and STEM majors... reply archarios 16 hours agoparentprevLike I have a bachelors degree in engineering. Is that intermediate or advanced? I feel like saying my science knowledge is anything beyond intermediate is a bit of an overstatement personally. reply wongarsu 16 hours agorootparent> I feel like saying my science knowledge is anything beyond intermediate is a bit of an overstatement personallyThat&#x27;s not overconfident, I&#x27;m lead to conclude that you have advanced science knowledge. reply f1shy 15 hours agorootparentAbsolutely advance. No question. At least in this context. reply threeseed 13 hours agorootparentprev> Like I have a bachelors degree in engineeringI do to and unquestionably I am beginner level.Each scientific field has specialised and become so dense with knowledge that even new graduates in that field would barely be classed as intermediate. reply xormapmap 7 hours agorootparentprevIn my view, bachelor&#x27;s degree is beginner, especially if you haven&#x27;t got any further knowledge than that from work experience or anything. reply burnished 15 hours agorootparentprevI didnt find out what standard they use, but personally I&#x27;d say intermediate sounds about right. I also have an engineering degree and while I know more than the average bear in many scientific disciplines I couldn&#x27;t say that any of it is advanced.I&#x27;m thinking of times where I went to the library to dig deeper on a topic and discovered a huge and complex topic just laying in wait. reply at_a_remove 14 hours agorootparentprevI have one in physics, but I have also taken a rather a lot (given the degree) in biology, chemistry, civil engineering, and electrical engineering. Went some places also not usual in math. And I&#x27;ve worked in IT since forever. There&#x27;s a lot of stuff where I take a glance at it and realize I&#x27;m just looking at a single hull plate on a battleship.What I am getting at is that if you have just intermediate knowledge in a bunch of places, I think it lends itself to sensing that you&#x27;re just a paramecium stuck to the side of some N-dimensional construct. There&#x27;s so much. I had a professor who was the expert in the second excited state of Helium-3. That was his thing. Just a single needle in the whale-sized blowfish of physics. reply not_enoch_wise 13 hours agoprevExactly why I developed advanced sci knowledge, so my narcissistic confidence and anti-social attitude can be defended! reply gobdovan 12 hours agoprevMaybe that&#x27;s why all the major materials on climate change I find are sociological, focusing on people&#x27;s perception on it and on agreement between experts rather than the actual subject -It&#x27;s so I don&#x27;t get intermediate knowledge and become skeptical to my own dismay. reply pickingdinner 12 hours agoprevOr maybe those overconfident with negative attitudes resort to intermediate scientific knowledge?And aren&#x27;t there humble optimists with intermediate sci knowledge?Maybe there just aren&#x27;t enough humble optimists? reply cycomanic 14 hours agoprevI am not sure why we have all these comments about confidence&#x2F;overconfidence of scientists and the limits of science.The article has some very different findings. The crucial paragraph from the abstract is:>We find a nonlinear relationship between knowledge and confidence, with overconfidence (the confidence gap) peaking at intermediate levels of actual scientific knowledge. These high-confidence&#x2F;intermediate-knowledge groups also display the least positive attitudes towards science.It seems to that it is essentially a refinement of the Dunning-Kruger effect. It also matches some previous study I remember which found that science sceptisim and many conspiracy theories around science are most prevalent with certain engineering disciplines (I can&#x27;t find the study right now, but will update with a link once I do).It is interesting that someone mentioned Sabine Hossenfelder as a positive example, because I find much of her recent content peddles to exactly the crowd who has intermediate knowledge of and very negative attitude toward science. In particular she often comments on topics where she herself has very little understanding (I know because I have seen it for topics where I am an expert) and just pushes a scepticism opinion without much understanding, but acting like she is an authority. reply mxmlnkn 13 hours agoparent> The article has some very different findings. The crucial paragraph from the abstract is:It&#x27;s kinda funny how only the abstract is referred to when trying to paraphrase the findings of the paper. I would say that the abstract by itself is more like an opinion. The real hard data backing up the abstract, should be in the article. But, it can&#x27;t even be faulted because this \"science\" is behind a pretty hefty paywall with 40$ for the full PDF and 10$ for a 48h rent. It&#x27;s basically the same price as a full movie. reply cycomanic 13 hours agorootparentThe abstract is not an opinion, it is a summary of the key methods and findings written by the authors. It is the perfect place to get a short quote to outline the main results of the paper.Now if we wanted to investigate the methods and results in detail, we certainly would have to read the full paper, however the main findings will not differ from what is in the abstract. You might find that the methods (and hence results) are not valid, and can come up with a detailed rebuttal, for that you certainly would need to read the full paper. However, I assumed here that the findings are valid, because even though I have access to the paper, this is well outside my area of expertise so I am not well placed to investigate the claims in detail and rather refrain from that. reply mxmlnkn 3 hours agorootparentYou are right. \"Opinion\" was also the wrong word. I just felt that the shortness of the abstract yields some similar dangers of details and context being lost as you have when reading only a headline. For example, one wouldn&#x27;t use the valuable abstract space to reiterate shortcomings of one&#x27;s method even if they are listed in the paper. reply cassac 13 hours agoprevIntermediate [insert topic here] knowledge associated with overconfidence and negative attitudes.Topics: Science, Sports, Cooking, Driving, Programming… literally anything.I didn’t need a study to know this. reply quickthrower2 13 hours agoparentIt this the B swimming lane thing again? reply cassac 12 hours agorootparentI do not know the reference. Is it that people claim the middle lanes are faster?But I do know that a lot of people across a lot of topics over estimate their ability because they don’t know what they don’t know. Science as a topic isn’t special in this regard.Jr devs are great examples. Your code is garbage and I am brilliant, just let me change this thing here and OH MY THE SYSTEM IS BROKE PLEASE HELP ME! Intermediate knowledge and negative attitudes. reply quickthrower2 11 hours agorootparenthttps:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37359250B lane swimmers are less friendly than A,C, and D at least anecdotally reply photochemsyn 16 hours agoprevThe article is paywalled but the research group has a 2021 arxiv publication on the same topic: \"A little knowledge is a dangerous thing: excess confidence explains negative attitudes towards science\"https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;1903.11193.pdfIt&#x27;s a survey-based study but the obvious thing to consider is, what do they mean by &#x27;negative attitudes towards science&#x27;? Are they talking about the scientific process itself, i.e. experiment and observation coupled to theoretical modeling as the basis of discovering how our universe functions? Or are they talking about negative attitudes towards the &#x27;science-based&#x27; pronouncements of governmental and academic institutions?Certainly the modern scientific process takes place at such a level of specialization that even working scientists in one field are usually unable to judge the quality of results obtained in another field without doing a lot of time-consuming research, but if a long record of failure of peer review exists (and it does) then it shouldn&#x27;t be surprising when people lose faith in academic and governmental institutions - but I&#x27;d guess they still believe that the scientific process itself is valid, it&#x27;s just that the received wisdom of the white-robed annoited priesthood is no longer taken at face value.There are many reasons for this - e.g. while science may have been viewed by all as wonderful in the 1950s, many discoveries (environmental carcinogens, fossil fueled global warming, etc.) have upset major economic and institutional powers leading to coordinated attacks on the reliability of science in major media outlets. Then there&#x27;s the long record of pharmaceutical skullduggery (the push to prescribe opiates for just about any condition, leading to an addiction epidemic, the failure of a wide variety of science-approved medications to live up to claims and&#x2F;or the production of negative side effects (Vioxx etc.)) - and as far as the vaccine controversy, yes it was a terrible idea to put organometallic preservatives in multi-use bottles of vaccines, and yes it was done to cut costs, but the claim it led to an epidemic of autism isn&#x27;t well-supported, there are many more plausible industrial sources of heavy metals to blame for high childhood exposures, but that&#x27;s not as convenient for class-action lawsuits due to vaccination records, etc.This doesn&#x27;t mean that most science isn&#x27;t fairly reliable, but the glaring failures are what make the headlines, and there have been quite a few of them.If we really want to regain public trust in academic institutions, divorce proceedings aimed at kicking the corporate interests out of the academic sphere will have to be initiated, meaning for example no more exclusive private rights to NIH-financed inventions and no more revolving doors between academic institutions and pharmaceutical executive boards. Don&#x27;t hold your breath, we live in an era of systematic insitutional corruption that Trofim Lysenko would have fit right into. reply frankreyes 2 hours agoprevDunning Kruger Effect, one more time. reply bratgpttamer 12 hours agoprev> We find a nonlinear relationship between knowledge and confidence, with overconfidence (the confidence gap) peaking at intermediate levels of actual scientific knowledge.Dunning-Kruger isn&#x27;t real.Dunning-Kruger isn&#x27;t real.Dunning-Kruger isn&#x27;t real. reply Jensson 8 hours agoparentIt is the same result, just that they added the \"unskilled\" category. People who never drove a car will rank themselves as the worst drivers, and people who are experts rank themselves highly, so the most overconfident are those who can drive, but drives poorly, ie \"intermediate skilled\" relative the whole population. reply mcpackieh 9 hours agoparentprevIs that a mantra? reply slackfan 9 hours agoprevMay we all remember that the we can only know that we know nothing. reply scotty79 12 hours agoprevInteresting. I think I&#x27;ve seen a research that when it came to covid, both uneducated and highly educated were making the wrong decisions more often. Sweet spot was around master&#x27;s degree. Those people knew enough to know that they don&#x27;t know enough to wing it themselves and deferred to expert opinion. Both under and overeducated thought they know better. reply izzydata 17 hours agoprevIs this similar to the dunning-kruger effect? reply xeonmc 17 hours agoparentmore like the \"midwit distribution\" memes. reply stanford_labrat 17 hours agorootparenthttps:&#x2F;&#x2F;knowyourmeme.com&#x2F;memes&#x2F;iq-bell-curve-midwithard to find a good example that is funny while also not crass&#x2F;political, but they generally go something like this: https:&#x2F;&#x2F;i.imgflip.com&#x2F;5dh26p.jpg reply mrbungie 16 hours agorootparentSome good examples:- Related to the post at hand and some of its comments: https:&#x2F;&#x2F;images.hive.blog&#x2F;0x0&#x2F;https:&#x2F;&#x2F;files.peakd.com&#x2F;file&#x2F;pe...- Meta 1: https:&#x2F;&#x2F;programmerhumor.io&#x2F;wp-content&#x2F;uploads&#x2F;2023&#x2F;07&#x2F;progra...- Meta 2: https:&#x2F;&#x2F;assets.website-files.com&#x2F;611cc49abc685aa7e3817103&#x2F;64...- The one I hope most people would follow in Data Science&#x2F;Engineering: https:&#x2F;&#x2F;i.redd.it&#x2F;s7olw2f01ra81.jpg reply giraffe_lady 16 hours agorootparentprevA good web-dev one I&#x27;ve seen has \"use bootstrap\" at the ends and \"create standardized design system\" in the middle. reply lo_zamoyski 15 hours agorootparentprevOr \"Ackchyually guy\"[0].[0] https:&#x2F;&#x2F;knowyourmeme.com&#x2F;memes&#x2F;ackchyually-actually-guy reply oldandtired 15 hours agoparentprevIt&#x27;s obvious from the Abstract that they are not referring to the Dunning-Kruger Effect as it is NOT mentioned in the Abstract, which is the highlight of the paper.Actually who the hell knows when the paper is essentially behind a paywall. The Abstract gives nothing away about what they have found. reply maxwell 17 hours agoprevAlexander Pope was right. reply 1letterunixname 10 hours agoprevThis shall be henceforth known as \"The Dunning-Kruger paper\". ;)Certainly, overconfidence and negative attitudes cloud public debate and popularization of conclusions. I&#x27;ve unfortunately come across narcissistic CEO&#x2F;VC types who believe they have \"all\" of the answers, when instead they may have a corner of the Rosetta stone or a piece of lint.STEM knowledge must be tempered with data and supported conclusions over non-experimental biases. The larger issues are behavioral pathologies when people appear to believe they have a superior special monopoly on knowledge, experience, or being. Another pathology is anti-intellectualism, which runs deep in America. reply GMoromisato 16 hours agoprevI blame Carl Sagan[1]. Carl Sagan was the Martin Luther of science communication. He showed us how you could figure out the size of the Earth just by measuring shadows at noon. He showed a vessel full of gases creating the precursors of life with just a little electricity. He reduced the history of the universe to a 1 hour PBS show. In short, he made science understandable to anyone.But just as the Reformation led to faith-healing and megachurch preachers, Sagan&#x27;s teachings made it seem as if anyone could be a scientist. As long as a chain of reasoning made sense to you, then it was true!Take something like whether the earth goes around the sun. Sagan showed how Mars sometimes moves backwards in the sky, and he implies that this can only happen in a heliocentric model. In reality, of course, you need much more evidence to come up with the correct model. It wasn&#x27;t until Newton could predict orbits from simple equations that there was no longer any doubt.But watching Sagan you get the idea that if you can just come up with ONE piece of evidence for whatever you believe, then that&#x27;s enough to prove it! This is why flat-earthers rely on meme-like \"evidence\" that takes effort to refute.In the end, it&#x27;s a trade-off. Do you want people to just trust authority or do you want people to think for themselves? If we want the latter (which I think we do) then we have to put up with those who are wrong.-----[1] I love Carl Sagan. He was a huge influence on me, and I think he benefited society, even if I think his teachings also (ironically) stoked some pseudoscience. reply nonethewiser 16 hours agoparentIt makes me think of the Its Always Sunny in Philadelphia episode where Dennis hypocritically appeals to authority in an effort to disprove creationism. The valuable point the skit makes is that there is a sort of “cult of science” where people mistake faith for reason and you have a bunch of science “believers” who dont realize it. Of course this is not what science really is.Personally, I have always been irked by phrases like “Science say” as if science itself is a centralized institution rather than a collection of people applying the scientific method.In a similar vein, I sometimes see posts of some natural phenomena (like ants changing colors after drinking dyed water) with captions like “Isnt science cool?” Im still trying to figure out why this irks me but its weird to imply science somehow caused this. reply nerpderp82 13 hours agorootparentI was just mentioning to a friend of mine, a lady in her late 60s early 70s about spiders using electrostatics to travel.https:&#x2F;&#x2F;journals.aps.org&#x2F;pre&#x2F;abstract&#x2F;10.1103&#x2F;PhysRevE.102.0...And she remarked, \"isn&#x27;t evolution amazing! It figured out so many things\"When someone says \"Isn&#x27;t science cool?\", they are saying lots of things* I appreciate facts&#x2F;truth* Knowing things is fun* Figuring things out is fun* There is so much we don&#x27;t know about the universeI think you are putting to much semantic meaning into the grammar they are using to express their sentiments. Same goes for, \"science says\". It isn&#x27;t enjoyable to discuss things and at the same time qualify every single statement. reply nonethewiser 12 hours agorootparentIts non sensical. Not minor. Electrostatics exists without science. The point is science is a tool for learning the truth, not the cause, nor the phenomena itself. It would make more sense to say “nature is cool.”Its like looking at a painting and saying “vision is so cool.” Except worse because at least in that example you are actually using the lens (vision) to look at the phenomena. reply nerpderp82 11 hours agorootparentScience is the tool that allowed us to know these truths.Your comment is damn rude. reply ramblenode 5 hours agorootparentprevEverything you just described is what I call \"Scientism.\" reply GMoromisato 15 hours agorootparentprevLol--that&#x27;s a great reference. reply mistermann 12 hours agorootparentprev> The valuable point the skit makes is that there is a sort of “cult of science” where people mistake faith for reason and you have a bunch of science “believers” who dont realize it. Of course this is not what science really is.Whereas with religions, the shortcomings of it&#x27;s delusional followers are attributed to it.Science has got to have the shrewdest marketing department in the history of religion. reply passion__desire 15 hours agoparentprevPeople trust \"authority\" because they don&#x27;t have time, resources, training to build the body of knowledge themselves. It is not feasable neither desirable for everyone to know about everything. Societies build chain of trust and that&#x27;s why institutions are important. Think of authority as a function call in a big framework which provides an answer with reasoning for that answer. In my previous function calls, the authority provided answers properly. If I get a wrong answer, there is a \"bug\" somewhere in the system. reply itronitron 15 hours agoparentprevWhy call it pseudoscience? It&#x27;s just science done poorly by someone doing science. We don&#x27;t call a bad haircut a pseudo-haircut. reply paulddraper 15 hours agorootparentSame as psuedostatistics. There are fundamental, objective principals. [1]Violate those, and it&#x27;s not what it claims to be.A bad haircut doesn&#x27;t claim to be something that it&#x27;s not, and its goodness is subjective.[1] https:&#x2F;&#x2F;en.wiktionary.org&#x2F;wiki&#x2F;pseudostatistical reply itronitron 14 hours agorootparentDude, the reference you provide does not support your claim that \"There are fundamental, objective principals.\" Not sure if you are trying to be subversive or just lazy (or both). reply paulddraper 14 hours agorootparentNeither. Reference should have followed the word pseudostatistics reply aschearer 16 hours agoparentprev> But just as the Reformation led to faith-healing and megachurch preachersQuite a leap. Break that one down...> Sagan&#x27;s teachings made it seem as if anyone could be a scientist. As long as a chain of reasoning made sense to you, then it was true!How does Sagan give this impression? Namely that \"as long as it makes sense to you, then it must be true.\"And why is this analogous to the Reformation? Seems like a non-sequiter. reply paulddraper 15 hours agorootparent>> But just as the Reformation led to faith-healing and megachurch preachers> Quite a leap. Break that one down...Prior to the Reformation, you needed not just Truth but Authority as well. There was an actual hierarchy, and you respected that hierarchy.Luther said that any man could connect to God, be a spiritual leader, assemble a congregation. And so the number of religious sects increased from 1 to much more than 1, including for example faith healers and megachurches. reply mcpackieh 12 hours agorootparentThere&#x27;s no doubt that the Reformation resulted in a proliferation of Christian sects, but attributing megachurchs and faith healing to that seems bizarre to somebody who is not a Christian. The Christian bible says that Jesus himself was a faith healer. Innumerable Catholic saints have been faith healers, and faith healing in the form of Exorcism is still taught as real by the Roman Catholic Church to this day. And megachurchs? No Christian church is more &#x27;mega&#x27; than the RCC. They share all the defining characteristics: Huge gaudy megastructures? Yes, Cathedrals. Money flowing up through the organization? The Vatican is decked in gold. Hierarchical with the preacher at top living opulently? This describes the Roman Catholic Church to a T. And Jesus himself is said to have preached to crowds of hundreds or thousands.The Reformation certainly lead to a splintering of Christian sects, but did not introduce faith healing and megachurches. These were already ancient, arguably originating characteristics of Christianity. reply santiagobasulto 16 hours agoparentprevLol, this is a great comment. reply bedobi 16 hours agoprevThis study basically describes 99% of people here, lol. Because you know how to write code, you&#x27;re suddenly an expert not only at that but also at economics, medicine, international relations etc etc. Every field is ready for you to disrupt it. The hubris is astonishing. reply paulddraper 16 hours agoparentWhy doesn&#x27;t _____ just ______? I&#x27;ve thought about this for only 2 minutes and it&#x27;s already obvious. reply svnt 16 hours agorootparentClearly you’re not in the field or you’d know that ______ is actually better understood as _______, which means your question doesn’t even make sense. reply cutemonster 14 hours agorootparentprevAt the same time, with \"just\" removed, those questions are often pretty good I think.It seems I would just remove just, and make the question great again reply nyc_data_geek1 16 hours agorootparentprevI would simply _____. reply tekla 16 hours agorootparentI as an coder would ____ reply mcguire 15 hours agorootparent_____, _____, land value tax. reply paulddraper 15 hours agorootparentUBI, _____, _____ reply meepmorp 16 hours agorootparentprevAnd the closely related I could write _______ in _______ days. reply simpleuser27 15 hours agoparentprevSeriously. Folks in tech like to complain about MBAs, but it&#x27;s a toss up in my book for \"most egregiously overconfident\".Doctors get a good shout as well. reply ignorethefacts 7 hours agoparentprevNot everyone who posts here is a coder but I do agree with you the narcissism and astro-turfing on HN is high.I suspect the high-confidence&#x2F;narcissist combination is especially high here due to this being an industry&#x2F;entrepreneurial forum where being confidently wrong is a positive trait.The astro-turfers appealing to the confidently wrong go by unnoticed to the majority.The abstract of the study states the metric for over-confidence they developed is \"the tendency to give incorrect answers rather than ‘don’t know’ responses to questions on scientific facts\". I think that&#x27;s true. I maintain that being confidently skeptical of confident claims and research is not the same thing. reply passion__desire 15 hours agoparentprevIs economics really a science?Economics is generally regarded as a social science, although some critics of the field argue that economics falls short of the definition of a science for a number of reasons, including a lack of testable hypotheses, lack of consensus, and inherent political overtones. Despite these arguments, economics shares the combination of qualitative and quantitative elements common to all social sciences [0][0] https:&#x2F;&#x2F;www.investopedia.com&#x2F;ask&#x2F;answers&#x2F;030315&#x2F;economics-sc... reply DiggyJohnson 15 hours agorootparentWhether it&#x27;s a science or social science or research domain or discipline, how is that relevant to this discussion? It doesn&#x27;t change GPs point. reply passion__desire 15 hours agorootparentWell is it possible that an Alan Sokal kind of trick be pulled off in economics if it is a social science.Relevant : https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=d0nERTFo-Skhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=GTQnarzmTOc reply bedobi 12 hours agorootparentYes, economics is science, and the people who don&#x27;t understand that and love to point out how economists are never right in their predictions about the economy fundamentally have no idea what the field is even about.Economics is not about predicting the stock market or economy as a whole, nor is it about coming up with excuses for free market capitalism and neoliberal agendas. It&#x27;s about studying things like market failures, tax incidence, deadweight losses etc etc etc and coming up with solutions. reply cududa 14 hours agoparentprevOne thing I&#x27;ve realized about this site are the insane amount of software engineers that have a disdain for the medical field. It comes up all the time deeper into comment threads where people say medical school entrance exams being so hard is a form of \"gatekeeping\" - which it is, on purpose, but they&#x27;re using it as a pejorative to tell themselves \"I could&#x27;ve been a doctor too if they didn&#x27;t make it so purposefully hard.\"The other very very disturbing trend are the \"makers\" who denigrate medical devices as overly complex. One thread I&#x27;ll never get over was on old pacemakers. The prevailing sentiment was they&#x27;re designed for failure because \"evil medical industry profit\", not that, you know, they wear out.The other part felt like watching the theory of memetics demonstrate itself in real-time. One person commented that the single small mechanical component is rated to actuate 5,000,000 times or something like that. Someone dismissively said \"Well yeah but Adafruit keyboard switches are rated at 2-3 million presses, they mass-produce them, thus it can&#x27;t be that hard\" (adafruit&#x27;s data sheet says 1,000,000 btw). Very quickly, people picked up that line and repeated that the actuator in a pacemaker isn&#x27;t \"actually that complicated\", citing the 2-3 million keycap example. I still see that keycap \"argument\" pop up all the time.BTW: Pacemakers are actually rated for about 100,000,000 stimuli cycles. reply mr_mitm 14 hours agorootparentI wanted to write a very similar comment, except about cosmology instead of medicine. The amount of people with high school level physics knowledge who think they know better than almost all luminaries of the field combined just because their gut feeling is telling them something about dark matter is astonishing. reply cududa 14 hours agorootparentI mean I barely know about pacemakers. Just that I have a congenital heart condition and will need one in a decade or so, and have taken a hobbyists interest in learning about them&#x2F; following the field. Just the level of arrogance and just completely wrong \"facts\" astonished me. The bit that moves is a few strands of hair thick. In what world does \"I built my own keyboard\" translate to \"I built my own keyboard so how much different could a pacemaker be?\" reply Jensson 8 hours agorootparentprev> the insane amount of software engineers that have a disdain for the medical fieldWhat field doesn&#x27;t they have insane disdain for? Software engineers even have insane disdain for software engineers! reply tivert 15 hours agoparentprev> This study basically describes 99% of people here, lol. Because you know how to write code, you&#x27;re suddenly an expert not only at that but also at economics, medicine, international relations etc etc. Every field is ready for you to disrupt it. The hubris is astonishing.Aka \"Engineer&#x27;s disease.\" There&#x27;s an overestimation of one&#x27;s personal competence and the effectiveness of the tools and mental models you&#x27;re most familiar with. Basically think asshole software engineer who tells everyone they&#x27;re dumb and should just solve the problem like they&#x27;re writing software. reply adasdasdas 14 hours agoparentprevCross field contamination a fantastic product of our interconnected world, but it&#x27;s more fun to shit on people when they fail. I&#x27;m sure some folks here would&#x27;ve loved to tell davinci to stay in his lane. reply nologic01 16 hours agoparentprevIndeed. Intelligence is just I&#x2F;O and gradient descent. The Universe is code. etc.Coupled with an asocial, greed-driven and essentially anti-humanist agenda its just the worst possible moment (severe environmental stresses across the planet) to hijack whatever potential digital tech offers...Sigh. reply nyrikki 15 hours agorootparentUnfortunately the lack of a definition of intelligence makes all claims unfalsifiable too.But Western reductionism&#x2F;Laplacian determinism is still taught even at the PHD level as cannon and not as a target for practical models.Perhaps the rise of research into indecomposable continua and the discovery of Strange non-chaotic attractors in nature may help.Obviously math and computer science as taught today is insufficient.I particularly blame the way we teach things as absolute truth and then pull the rug out from under those previous supposed hard facts.But I am showing my own ignorance here because we do learn about the computable set etc...It doesn&#x27;t seem to help with people making claims about universal quantifiers being a few quarters away. reply bratgpttamer 12 hours agoparentprevWell, at least we&#x27;re not physicists, amirite?https:&#x2F;&#x2F;xkcd.com&#x2F;793&#x2F; reply colordrops 17 hours agoprevVery meta study. reply davidktr 16 hours agoprev [–] full paper here: &#x2F;&#x2F; deleted. Looks like my choice of an anonymous file hoster was inappropriate. reply bagels 15 hours agoparentresearchgate has it: https:&#x2F;&#x2F;www.researchgate.net&#x2F;publication&#x2F;362183387_Knowledge...You can click on \"Read Full Text\"Also here: https:&#x2F;&#x2F;www.science.org&#x2F;doi&#x2F;10.1126&#x2F;sciadv.abo0038 reply malf 16 hours agoparentprevThis page tries to send expensive SMS messages. reply bagels 16 hours agoparentprev [–] Site doesn&#x27;t look legitimate. Risky click. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The study discovers a link between scientific knowledge, self-assurance, and attitudes towards science, specifically noting an overconfidence and negative bias in individuals with mid-level scientific knowledge.",
      "The findings question existing models and highlight the necessity to address this overconfidence and encourage a more in-depth understanding of science.",
      "The article also offers details about the academic publication and its publisher."
    ],
    "commentSummary": [
      "The discussion focuses on understanding the limitations of science, the challenges in defining it, and the dangers of putting too much faith in scientific claims.",
      "It sheds light on how overconfidence impacts various fields and how media and politics shape the public's perception of science.",
      "Emphasis is placed on the necessity for humility, critical thinking, and acknowledgment of the uncertainties in scientific understanding to counter overconfidence and science denialism."
    ],
    "points": 239,
    "commentCount": 194,
    "retryCount": 0,
    "time": 1694708692
  },
  {
    "id": 37509427,
    "title": "Arm IPO to kick off today",
    "originLink": "https://www.theregister.com/2023/09/14/arm_ipo/",
    "originBody": "SIGN IN / UP SYSTEMS Arm IPO kicks off today with CPU slinger valued at $54.5B 15 British chip designer to trade on Nasdaq only Dan Robinson Thu 14 Sep 2023 // 13:28 UTC The long anticipated Arm flotation is set to kick off today with shares being offered to the public at $51 apiece, putting a value on the company of $54.5 billion. Britain's chip design and licensing outfit said in a statement that its shares are expected to begin trading on the Nasdaq Global Select Market in New York on September 14 under the symbol ARM. There has already been huge interest in this IPO, which resulted in Arm closing orders for shares a day earlier than planned this week due to its stock being more than five times oversubscribed, according to the Financial Times. This interest could push the share price higher than the initial $51 once trading begins. Post-IPO, Arm to push purpose-built almost-processors COMMENT At this price, the IPO is reportedly set to raise about $4.9 billion for Arm’s parent company, Softbank, which is less than the $8-$10 billion the Japanese investment outfit had previously said it hoped to generate. Softbank itself posted a record $39 billion loss earlier this year. Arm will continue to remain under the control of Softbank after the stock sell off, however, as reported by The Register earlier this year when the chip designer first filed for its public listing. Softbank issued a statement saying that: \"SBG (Softbank) intends that Arm will continue to be a consolidated subsidiary of SBG following the completion of the proposed initial public offering.\" The valuation of Arm at $54.5 billion is also lower than the $60-$70 billion that Softbank was said to be aiming for, a figure based on the estimated value of the proposed sale of Arm to GPU maker Nvidia at the time the deal fell through last year. It is still likely to make it the largest IPO in the US this year, however. That proposed sale fell through due to the \"significant regulatory challenges\" it faced from authorities in various countries, as well as opposition from other tech companies who feared that Nvidia might limit access to Arm technology for other licensees. The IPO has instead generally met with broad approval, with many big names in the industry such as Apple, Samsung, and Intel stepping up to take a sizable stake in the Brit chip company. Financial red tape blamed for London losing Arm IPO Arm files for IPO – and SoftBank will retain control Lightning struck: Apple switches to USB-C for iPhone 15 lineup Linux on the Arm-based Thinkpad X13S: It's getting there This is one reason why the UK government was hopeful that the IPO might be a dual-listing, with Arm shares going up for sale on the London stock exchange as well as New York. Those hopes were dashed earlier this year, when the company confirmed it would list only in the US, blamed by some on financial red tape. According to Nikkei Asia, the IPO has four lead underwriters, comprising Barclays, Goldman Sachs, JP Morgan, and Mizuho USA. There is also a second tier of banks, including Bank of America and Citigroup. ® Sponsored: Reach for the clouds in London More about Arm Semiconductor More like these 15 COMMENTS TIP US OFF Send us news Other stories you might like Post-IPO, Arm to push purpose-built almost-processors COMMENT British chip design biz plans to satisfy investors by seeking new customers, while RISC-V and China are already challenges SYSTEMS 9 hrs3 Arm's lawyers want to check assembly expert's book for trademark missteps IPO-hungry chip biz promises to donate copies to universities – may also demand a reprint SOFTWARE 3 days49 Arm wrestles assembly language guru's domains away citing trademark issues Maria Markstedter spent years writing about chip biz's ISA, is a tad miffed by heavy-handed takedown tactics SOFTWARE 15 days106 Paving an intentional road to a sustainable IT future For businesses that want to stay competitive, e-waste is an infelicitous fact of life – so what to do about it? SPONSORED FEATURE TSMC gobbles up $430M slice of Intel's IMS Nanofab unit Taiwanese also plot $100M investment in Arm IPO, x86 giant gets real about Thunderbolt 5 SYSTEMS 3 daysThe future of the cloud sure looks like it'll be paved in even more custom silicon You're probably using cloud providers bespoke chips already and not even know it CLOUD INFRASTRUCTURE WEEK 3 days6 Need a datacenter processor? Try our take-and-bake Neoverse N2 cores, says Arm HOT CHIPS Just bring your own accelerator SYSTEMS 17 days6 Arm reveals just how vulnerable it is to trade war with China COMMENT 你那里的生意不错，如果出了什么事就太可惜了 SYSTEMS 23 days19 Arm execs to cash in on IPO, but clouds gather over prospects Critics wondering if SoftBank's being realistic SYSTEMS 23 days1 It's official! Arm files for IPO on Nasdaq Paperwork confirms parent paid $16B for 25% stake held by Vision Fund ON-PREM 24 days9 Linux on the Arm-based Thinkpad X13S: It's getting there REVIEW Armbian 23.08 is out, and adds preliminary support for this ultralight Snapdragon laptop PERSONAL TECH 7 days40 After failed takeover, Intel and Tower Semi aren't giving up on the relationship Meanwhile, Arm suffers IPO financial muscle loss with low valuation ON-PREM 10 days1 The Register Biting the hand that feeds IT About Us Contact us Advertise with us Who we are Our Websites The Next Platform DevClass Blocks and Files Your Privacy Cookies Policy Privacy Policy T's & C's Do not sell my personal information Copyright. All rights reserved © 1998–2023",
    "commentLink": "https://news.ycombinator.com/item?id=37509427",
    "commentBody": "Arm IPO to kick off todayHacker NewspastloginArm IPO to kick off today (theregister.com) 235 points by LinuxBender 20 hours ago| hidepastfavorite157 comments bhouston 19 hours agoThe strategy they are using to establish a revenue stream that justifies this valuation is to continue to raise prices on their customers. I think this works in the near term (next 5 to 10 years), and generate a ton of money for ARM, but it will drive additional momentum to RISC-V.The legendary Jim Keller is going all in on RISC-V, if you don&#x27;t know Google him. His company has many core designs coming as well chiplets: https:&#x2F;&#x2F;tenstorrent.com&#x2F;risc-v&#x2F;Because of Jim Keller and similar efforts I wouldn&#x27;t be surprised for RISC-V to see both core count as well as per core performance meet ARM over the next few years. Maybe even exceed if Jim can push the chiplet approach faster than ARM can roll theirs out.Hopefully this drives a lot of innovation and we all benefit as a result.I think that using ARM is going to be viewed as being locked into ARM&#x27;s ever increasing licensing fees, where as if you go RISC-V, you are free to switch CPU providers. reply packetlost 19 hours agoparent> where as if you go RISC-V, you are free to switch CPU providers.Idk, this really isn&#x27;t as true as you&#x27;d think. Yes RISC-V is an open and free ISA which will cut out some fees, but you&#x27;d still have to license IP&#x2F;chip designs (if you can&#x27;t make your own) and they could only undercut ARM by a little bit. Further, the lack of mobility across chips&#x2F;boards&#x2F;whatever is not usually from the ISA, but from the BSP, SDK, etc. so you still would have substantial lockin unless we somehow standardize on that (lol) reply AnthonyMouse 18 hours agorootparentPart of the issue here is that nobody is going to build something free on top of someone else&#x27;s property. What good is a \"free\" design if you still have to pay ARM?Whereas once you have a free ISA which is actually in widespread use, you could get some designs out of universities or major corporations which intend to use them rather than sell them as their primary business and then release the design for the same reason they do for Linux code, potentially under a copyleft-style license.Those designs aren&#x27;t going to be competitive with the state of the art, at least in the beginning, but they don&#x27;t have to be. All they have to be is low power enough to stick in an embedded device and fast enough to run the display on a refrigerator and the lack of a license fee would cause them to replace a zillion ARM chips that currently go into every IoS device andWhereas once you have a free ISA which is actually in widespread use, you could get some designs out of universities or major corporations which intend to use them rather than sell them as their primary business and then release the design for the same reason they do for Linux code, potentially under a copyleft-style license.We&#x27;ve had open ISAs for decades. The problem isn&#x27;t with ISA licensing, the problem is cost-of-entry.Most people have a computer...it costs nothing to install Linux and GCC&#x2F;rustc&#x2F;Python&#x2F;etc and start contributing to open source software. For open hardware, you need (at minimum) a decent FPGA for testing&#x2F;development; but access to fabrication resources to be in anyway competitive.Don&#x27;t get me wrong, I&#x27;m generally pro on RISC-V; I just don&#x27;t think it&#x27;s the revolution everyone is making it out to be. reply AnthonyMouse 11 hours agorootparent> Most people have a computer...it costs nothing to install Linux and GCC&#x2F;rustc&#x2F;Python&#x2F;etc and start contributing to open source software. For open hardware, you need (at minimum) a decent FPGA for testing&#x2F;development;That wasn&#x27;t even true when open source got started. Typical access was to expensive mainframes and VAXen available only in universities and major corporations. PCs were only starting to become a thing and most people didn&#x27;t have one.That model still works if you need something expensive. Get your university to buy one, or your company if it will save them $0.05&#x2F;unit on the millions of devices they sell. Or you rent one in the cloud.You also might not need your own. A project gets started by someone who does have access to a decent FPGA, you want to contribute to it, great. They give you remote access to the FPGA.Meanwhile FPGA prices keep going down.> but access to fabrication resources to be in anyway competitive.Which is available to anyone, if you have customer demand. They&#x27;ve made millions of Raspberry Pis. reply deaddodo 11 hours agorootparent> That wasn&#x27;t even true when open source got started.Which is why it took off when computers became accessible; and continued growing with even further ubiquity.> You also might not need your own. A project gets started by someone who does have access to a decent FPGA, you want to contribute to it, great. They give you remote access to the FPGA.Cool, so we&#x27;re back to bottlenecked accessibility.> Which is available to anyone, if you have customer demand.Not hobbyists. To reiterate, open hardware (including ISAs) is as old as open software.You&#x27;re delusional if you think either are anywhere equivalent. reply AnthonyMouse 11 hours agorootparent> Which is why it took off when computers became accessible; and continued growing with even further ubiquity.So things like FPGA prices going down over time or being available to hobbyists via cloud providers.> Cool, so we&#x27;re back to bottlenecked accessibility.Anyone with a computer and an internet connection can contribute, all they have to do is send an email to the project maintainers. It&#x27;s obviously not as good as everybody already having the hardware, but it could be good enough to actually make it happen.> Not hobbyists.The model would be that there is a public repository with a design in it, anyone can contribute, and then every year or two they do a freeze and a production run which anyone can buy including the hobbyists who made contributions.It feels like your argument is that Debian can&#x27;t exist because a hobbyist doesn&#x27;t have the resources to build a whole operating system. One doesn&#x27;t, but a million of them do, especially if they can start with a basic design released by a major corporation or university or government. reply doctorpangloss 18 hours agorootparentprevAs a layperson though, how would I be able to tell whether any of this is true? When I have to target platforms as a software developer, the truth is, I’ll do whatever Microsoft and Apple tell me to. By the time Apple is shipping a RISC-V phone I hope to be retired! reply AnthonyMouse 18 hours agorootparentFor any kind of high-level code, \"platform\" is something like win32 or Android or Qt. The underlying hardware architecture is the compiler&#x2F;interpreter&#x27;s problem.The people dealing with assembly know who they are, but much of that is the sort of work that cares a lot about shaving off a few cents worth of license fee for an embedded device. reply WanderPanda 7 hours agorootparentUntil it becomes the users problem (e.g. PowerPC -> Intel -> ARM transitions) reply AnthonyMouse 5 hours agorootparentFor users of general purpose computers this is caused almost entirely by closed-source software. Most of the architecture-specific code is part of the operating system, and by the time you&#x27;re doing an architecture transition the OS itself runs on the new architecture. The third party applications largely aren&#x27;t dependent on a specific architecture but they&#x27;re compiled for one.With open source you could just recompile for the new architecture. Linux has always run on just about every one under the sun and the user largely can&#x27;t even tell the difference. But if you don&#x27;t have the source code you can&#x27;t do that.Closed-source systems could avoid this by compiling to bytecode, which is essentially what Android does, so transitioning to RISC-V would be much less trouble there than it would be for e.g. Windows. reply smoldesu 18 hours agorootparentprev> As a layperson though, how would I be able to tell whether any of this is true?You probably won&#x27;t ever know. Do you know the architecture of the microcontroller on your first computer&#x27;s hard drive? I don&#x27;t.The stuff that RISC-V will replace first is the low-margin hardware that can be mass-produced by China et. al and exported without license violation. ARM&#x27;s goose was already cooked in this sense, and even ARM China won&#x27;t fix it. For IO controllers, ICs and network switches, it&#x27;s hard to see why manufacturers would stick with higher-margin ARM hardware. If RISC-V cores are cheap, stable and available, you could replace them without the user ever noticing.> By the time Apple is shipping a RISC-V phone I hope to be retired!Apple is reportedly looking to replace some of their A-series ICs with RISC-V ones: https:&#x2F;&#x2F;www.techpowerup.com&#x2F;298936&#x2F;report-apple-to-move-a-pa...Hopefully you don&#x27;t intend to retire this soon :p reply AprilArcus 15 hours agorootparentApple holds a rare Architecture license to the ARM ISA due to their role as a founding partner, and can make original implementations without incurring licensing dues, as they do with the A and M series CPUs. I understand why they would want to switch to homegrown designs instead of licensing ARM reference designs (which they do have to pay for), but why migrate instruction sets too when RISC-V doesn&#x27;t save them any marginal cost over novel ARM designs that would be binary compatible with the existing firmware? reply zie 12 hours agorootparent\"We have entered into a new long-term agreement with Apple that extends beyond 2040, continuing our longstanding relationship of collaboration with Apple and Apple&#x27;s access to the Arm architecture,\" - ARM&#x27;s IPO Document.I assume they paid something for it, but who knows how much, ARM and Apple have not decided to tell us.Source: https:&#x2F;&#x2F;www.sec.gov&#x2F;Archives&#x2F;edgar&#x2F;data&#x2F;1973239&#x2F;000119312523... reply klelatti 15 hours agorootparentprev> Apple holds a rare Architecture license to the ARM ISA due to their role as a founding partner, and can make original implementations without incurring licensing duesSorry, the architecture license wasn’t a thing when Arm was founded and there is no way that Arm would hand out free licenses at a later date. It’s just a myth. reply NortySpock 15 hours agorootparentprevWestern Digital announced an open source core (\"SweRV\") in 2019, so I assume they already use them now that we are a few years on from that announcement.https:&#x2F;&#x2F;github.com&#x2F;westerndigitalcorporation&#x2F;swerv_eh1https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=25002448 reply packetlost 18 hours agorootparentprevHonestly, this is conjecture at best, there have been other open ISAs that didn&#x27;t manage to capture the market like this. That isn&#x27;t to say I don&#x27;t think RISC-V will capture a lot of market share, but I&#x27;m not going to make specific predictions about how much and where. reply AnthonyMouse 18 hours agorootparentOf course it&#x27;s conjecture. If you know anyone who can reliably predict the future I&#x27;d like to meet them.But previous open ISAs were in the wrong market segment. Okay, SPARC is open, but it&#x27;s also Oracle and no one trusts them, and the existing SPARC ecosystem is the enterprise market which expects big, hot hundred-thread systems and has no use for a simple dual-core CPU at 800 milliwatts. But that&#x27;s the thing you can produce with a low budget, so it never goes anywhere or no one even makes one.People are starting to use RISC-V for the thing where that actually works. reply xorcist 17 hours agorootparentMIPS? PowerPC?They&#x27;re all open, albeit with somewhat varying definitions of the term. reply AnthonyMouse 17 hours agorootparentMIPS wasn&#x27;t opened up until they were already dead, and then almost immediately threw in the towel and joined up with RISC-V.PowerPC basically the same, not opened until after it was irrelevant. OpenPOWER is in the same enterprise market as SPARC and IBM is not far from Oracle on the \"do not engage litigious bureaucracy\" chart. reply monocasa 17 hours agorootparentprevMIPS didn&#x27;t really open. They made a big deal about it, but it turned out to mean something to the effect of &#x27;we&#x27;ll open more of our build system to partners who pay for a traditional MIPS license. No third party MIPS cores. No general release of MIPS RTL.&#x27; replypclmulqdq 18 hours agorootparentprevARM actually has a pretty good story for how they can undercut RISC-V prices in that they can design the ISA rather than accepting the decisions of a committee. That committee used to make good choices, but things like the vector ISA seem more suspect. reply packetlost 18 hours agorootparentThe general consensus I&#x27;ve heard is the vector extension is good? I do agree the design by committee is less than ideal, but the ability to add vendor extensions at all is nice for certain markets. reply monocasa 18 hours agorootparentprevThe vector ISA seems alright to me. Particularly compared to Neon, but even compared to SVE. reply aristus 18 hours agorootparentprevYou&#x27;re not wrong, but having two choices of supply does wonders for squeezing profit margins from both back to the customer. Duopolies are terrible but better than monopolies. reply devnullbrain 19 hours agoparentprevSoftbank has spent 7 years and a CEO finding out how difficult just raising prices is. reply boringg 18 hours agorootparentEspecially when your lifeline is tied to Apple. No way are they going to negotiate to raise prices in a meaningful way against their largest client.Actually> \"Apple (AAPL.O) has signed a new deal with Arm for chip technology that \"extends beyond 2040,\" according to Arm&#x27;s initial public offering documents filed on Tuesday.\" reply scrlk 18 hours agorootparentApple was one of the founding investors of ARM back in 1990 - it&#x27;s likely they have an extremely generous licence and pricing terms as a result. reply xadhominemx 18 hours agorootparentApple’s involvement with ARM’s founding has zero impact on their negotiations or pricing. reply fomine3 9 hours agorootparentSoftBank has&#x2F;invests so many business related to Apple (like mobile career), that may affected to negotiation. reply devnullbrain 18 hours agorootparentprevIt does when that involvement means they&#x27;re one of the few architecture licensees. Allegedly. reply klelatti 17 hours agorootparentThey have an architectural license (for Arm v8&#x2F;9) because they are a huge customer with deep pockets not because of a shareholding they sold a decade before that architecture was announced! reply monocasa 17 hours agorootparentIt&#x27;s not the deep pockets per se, but the hand Apple had in designing AArch64. Apparently their relationship with ARM is more like the Intel&#x2F;AMD relationship, ie. cross-licensing. replylondons_explore 15 hours agorootparentprevThe deal with apple is probably 0.1% of revenue from all hardware sales that contain ARM IP or something similar.Which means that if Apple decide to switch to RISC-V to save money, the deal is still in effect, but no money will be paid, so there might as well be no deal. reply boringg 13 hours agorootparentYou think it&#x27;s that low? reply sapiogram 17 hours agorootparentprev> No way are they going to negotiate to raise prices in a meaningful way against their largest client.Why not? It&#x27;s not like Apple will have anywhere else to go for the next 8 years. x86 cores are too slow and power-hungry for the foreseeable future, and building their own risc-V core will take... at least 8 years. reply wtallis 12 hours agorootparent8 years sounds like an absurdly long time to retrofit a different instruction set onto an existing CPU core design. reply apatheticonion 2 hours agoparentprevI like the idea of an open platform centered around an open standard - I don&#x27;t know enough about the subject but I wonder if RISC-V is viable as a complete product?Like, if we ignore the chip design aspects - is it guaranteed software compiled on one RISC-V chip will run on another RISC-V chip? (in the same way it does on ARM and amd64&#x2F;x86?What about hardware interoperability? PCI? UEFI&#x2F;Boot semantics? Power management?Who enforces that stuff for arm and x86 platforms? reply snvzz 9 minutes agorootparent> What about hardware interoperability? PCI? UEFI&#x2F;Boot semantics? Power management?Refer to the RISC-V platform spec (ongoing).It depends on other specs, some of which (like those related to the boot process) have already been ratified. reply varjag 2 hours agorootparentprev> What about hardware interoperability? PCI? UEFI&#x2F;Boot semantics? Power management?Afraid I have bad news about ARM right there. reply demondemidi 7 hours agoparentprevAn open source ISA isn&#x27;t the same as a design. They are radically different, in order to use an ISA you need IP design. The companies that are gaining ground with RISC-V are all largely IP vendors, which is exactly what Arm is. It&#x27;s just shifting where the dollars go. reply miohtama 16 hours agoparentprevUnity IPO’ed three years ago. Their stock is down 80%, common among tech stock since money printer stopped. However now their plan to turn the tech company to cash cow and milk existing customers seem to have backfired. reply bhouston 16 hours agorootparentA lot of games can not just drop Unity quickly. So a bunch will be forced into paying Unity. Also remember Apple just made Unity \"the way\" for making full screen VR apps on their new VR device. Don&#x27;t underestimate how much Unity can make this way... while a lot will drop Unity many games simply can not in the medium term. reply miohtama 13 hours agorootparentExactly. Milk the cow until its dead and preferably little longer. reply hunson_abadeer 11 hours agoparentprev> if you go RISC-V, you are free to switch CPU providers.That&#x27;s not even true within the ARM ecosystem itself. The chips from Infineon are not source-code compatible with STM, STM is not compatible with Microchip, Microchip is not compatible with TI...The problem is that the ARM core is just a portion of the architecture. Everything on top of that - GPIO, memory interfaces, timing, etc - is vendor specific, and will stay that way for RISC-V. RISC-V is just an instruction set architecture (with some appendages), not a blueprint for a complete CPU &#x2F; MCU &#x2F; SoC.Not to mention, the chips also won&#x27;t be electrically-compatible. Your hardware architecture can be as daunting to redesign as the code, if not more so. There&#x27;s a reason why we try to do as much as possible in software, after all... reply snvzz 8 minutes agorootparent>Everything on top of that - GPIO, memory interfaces, timing, etc - is vendor specific, and will stay that way for RISC-V.Not as true for RISC-V, as there&#x27;s efforts (some of them complete) to standardize interfaces to standard peripherals.E.g. timers, gpios and watchdogs. reply azinman2 17 hours agoparentprevBuilding out tooling and even chips based on RISC-V is handing the future to China. They’re going all in because it’s an ISA that the west generated and builds support for but is free to use, which plays into their strengths of lowest cost and their ambition to own the future chips of the world. reply bhouston 16 hours agorootparentYou are right that China is going on in on RISC-V in part because of Western sanctions. It is yet another reason why RISC-V has so much momentum. It is in China&#x27;s interest to destroy Intel&#x27;s and ARM&#x27;s competitive advantages and it is pouring money and people into it. reply azinman2 14 hours agorootparentThey wouldn’t be producing ARM or x86 even if no sanctions. They want to own an entire ecosystem. reply lmm 11 hours agorootparentAn architecture that&#x27;s developed in public that anyone can implement is a funny way to achieve that. Particularly given that western firms do largely follow the IP rules, if China wanted an ecosystem they controlled, surely they&#x27;d develop their own proprietary one (or worst case, buy out one of the western also-rans). reply RC_ITR 17 hours agoparentprevI think everyone in this thread underestimates this part of ARM&#x27;s business (from the F-1):* Expand our System IP and SoC Offerings. To enable further improvements in performance and efficiency, we continue to develop a broader set of configurable systems IP offerings, including proven on-chip interconnect, security IP, memory controllers, and other design IP to be used with our processors, including the integration of multiple IP technologies into a subsystem and additional information to assist in fabrication. More recently, we have invested in a holistic, solution-focused approach to design, expanding beyond individual design IP elements to providing a more complete system. By delivering SoC solutions optimized for specific use cases, we can ensure that the entire system works together seamlessly to provide maximum performance and efficiency. At the same time, by designing an increasingly greater portion of the overall chip design, we are further reducing incremental development investment and risk borne by our customers while also enabling us to capture more value per device.*ARM doesn&#x27;t just give you the architecture, they give you a reference design that already works and then lets you customize it however you want.Companies like Apple don&#x27;t care about that, but MediaTek, NXP, etc. use it to speed the design process meaningfully. reply monocasa 16 hours agorootparentARM already does that though. Their dev systems like the Juno boards are ARM designed chips with ARM IP through and through covering just about every accelerator and integration niche. CPUs, NoC fabrics, GPIO, sound, just about every hardware interface master and slave, AI inference, display scanout, etc.Integrators don&#x27;t typically go all in on ARM IP though for a couple major reasons. 1) They want to provide some value add beyond the standard offerings or else why pick them over a competitor? 3) They have massive collections of IP blocks already that they don&#x27;t have pay ARM for. Maybe it takes some engineering to convert to the next chip, but that&#x27;s probably cheaper than what ARM is asking for. reply RC_ITR 16 hours agorootparentSure, I&#x27;m not saying that ARM is in a good position per se, but that RISC-V has way more catching up to do than people realize. reply monocasa 15 hours agorootparentIt&#x27;s less than you would think. Despite having offerings in about every IP block segment about the only ARM IP blocks that get heavy use are the pieces that have some other ecosystem thing going on. PL011 uarts are de facto required for some initial consoles. Mali GPUs were being sold in what was frankly a move that needed some anti-trust scrutiny (ARM saw Apple taking the piss out of IMG and decided to go in for the kill by offering CPUs+GPU for cheaper than CPUs on their own, overnight destroying IMG&#x27;s market). Beyond that it&#x27;s easier to not pay ARM for their IP. NoC fabrics and IP blocks that touch pads are better coming relatively straight from the foundry. Simple serial controllers are essentially commodities at this point. Etc.So RISC-V really only needs to focus on CPU cores to be an existential threat to ARM.At this point their biggest most is probably the patents on AMBA specs, but if they tried hard to enforce those the industry would switch to something like TileLink in a relative heartbeat. reply bhouston 16 hours agorootparentprevI am giving RISC-V 5 to 10 years to catch up in my estimates. I think that is fair. The momentum behind RISC-V is massive and even then I am not saying it is fast. reply RC_ITR 15 hours agorootparent5 years is a flash in chip design. Initial design to tape-out is 3 years at the leading edge if you&#x27;re really good.Maybe in 5-10 years, RISC-V gains share in initial designs, but the semiconductor design process is loooong.And if you&#x27;re going to talk about Microcontrollers and simpler chips, keep in mind we had a bunch of other RISC architectures a decade ago that all lost to Cortex-M for simplicity&#x2F;cost reasons (RIP MIPS). reply bhouston 15 hours agorootparentI think RISC-V eats ARM&#x27;s lunch at the low end across the board over the next 5 years. Financially that is okay in the near term for ARM as the major profits are all in the high end designs.But all that will be left in a few years is the high end areas and where there is a lot of lock in to the ISA.It isn&#x27;t yet clear when RISC-V will be ready to compete at the highest end of things, but that is where Jim Keller comes in.RISC-V is a classic market disruptor for ARM, just as ARM was a disruptor to Intel. replysamwillis 19 hours agoprevOur first family computer was an Acorn Archimedes, we had it for maybe a year before it was replaced by a PC with an Intel.Now here we are 30 years later and I&#x27;m typing on a laptop running on a ARM (née Acorn RISC Machines, then Advanced RISC Machines), I have an ARM in my pocket, another in a tablet in my bag. My wife is next to me on an ARM laptop, she&#x27;s also got an ARM on her arm... we&#x27;re listening to music on a wifi speaker running on an ARM. There are probably 30-40 ARMs in one way or another around our house. Amazing really. reply deepspace 18 hours agoparent> Acorn ArchimedesNewb &#x2F;sI cut my teeth on an Acron Atom in 1982, and upgraded to a BBC Micro (a renamed Acorn Electron) the next year.But, yes, I never would have thought that, 40 years later, most of the CPUs in my house would still be derived from that scrappy British&#x27;s company&#x27;s designs. reply TX81Z 18 hours agorootparentOne of my favorite examples of the benefits of public interest spending and investment. There very likely wouldn’t be an ARM today if it weren’t for the Micro. reply klelatti 18 hours agorootparentprev> renamed Acorn ElectronActually renamed Acorn Proton. Electron came later. reply acomjean 13 hours agoparentprevAbout 10 years ago, my partner turned to me and said, there is an ARM core for every person on the planet. Her company was designing printer chips and using ARM cores. They bought the reference design to use. \"Arm and a Leg\" they nicknamed it due to high fees even back then.I bought some \"Armh\" (ARM&#x27;s old ticker symbol) which did really well before they got bought by softbank. Oddly hard to find any info about historical stocks on the interwebs. reply downrightmike 17 hours agoparentprevApple bought out Acorn and used them to design their chips. reply monocasa 15 hours agorootparentI wouldn&#x27;t go that far. Apple&#x27;s strategy in a lot of cases is more like that of automobile manufacturers where they invest heavily in a company as sort of a king maker, but then hold them over a barrel on later margins with the threat that they can make another king. That&#x27;s what they did with TSMC, pre purchasing chips to the tune of ~$15B which allowed TSMC to go ahead and buy a bunch of the first EUV steppers. reply FredPret 13 hours agoprevHere&#x27;s a list of companies that can be bought for $50b:Valero Energy. Profit: $10b. [valustox.com&#x2F;VLO]DR Horton home builders. Profit: $5b. [valustox.com&#x2F;DHI]General Motors (!). Profit: $10b. [valustox.com&#x2F;GM]Aflac Insurance. Profit: $5b. [valustox.com&#x2F;AFL]Nucor steel. This one is selling for only $40b. Profit: $5.6B. [valustox.com&#x2F;NUE]Microchip Technology Inc. Also $40b. Profit: $2.4b. [valustox.com&#x2F;MCHP]Arm has it&#x27;s work cut out to raise their profits from the rumored $1b. I&#x27;m not sure why an investor would consider them without a strong plan to 10x-100x their profits when there are companies selling at a similar rate but making much more money in boring product categories. Hope they can do it while staying true to their mission. reply alberth 12 hours agoparentWhy are Arm&#x27;s expenses so high?They don&#x27;t manufacturer anything, correct? reply FredPret 3 hours agorootparentThose big-brain chip architects aren’t free!I don’t know anything about Arm’s business interals, but I think they have more of a low-revenue problem than a low-margin problem.According to [0] they had 2.5b in revenue and 0.5b in profit. A healthy margin, and much lower revenue than the other companies I mentioned.[0] https:&#x2F;&#x2F;www.barrons.com&#x2F;articles&#x2F;arm-stock-price-ipo-caf090b... reply jamesblonde 19 hours agoprevIt was disappointing for the UK not to get a dual listing, despite Rishi Sunak&#x27;s best attempts. I guess Europe is just not attractive enough for capital from the rest of the world for IT investments.https:&#x2F;&#x2F;www.theguardian.com&#x2F;business&#x2F;2023&#x2F;mar&#x2F;03&#x2F;uk-chip-des... reply dom96 19 hours agoparentWhat would be the point in a dual-listing? How does one actually work? reply jamesblonde 16 hours agorootparentIt would mean you can buy and sell ARM shares on more one stock exchange.One basic rule for making money as a country is to ensure capital flows through your country (e.g., services, manufactured goods, FDI, etc). Then skim off some of the captial that flows.If ARM were listed in the UK and say, $30b of shares is traded anually, of which say $10b is in the UK, then some of that will go to UK ltd. reply pc86 16 hours agorootparentWhat incentive would ARM have to do that, though? Just so the UK can \"skim off some of the capital\" (which is a very generous way of describing what&#x27;s actually occurring). reply pm90 15 hours agorootparentAccess to more investors. Probably they could tap into some kind of nationalist sentiment since they are HQd in the UK. reply MichaelZuo 13 hours agorootparentAre there more than 0 serious investors in the UK that can&#x27;t access the US capital markets? reply globular-toast 12 hours agorootparentprevThey&#x27;re a UK company based in the UK. It&#x27;s preferable that any skimmings stay within your own country isn&#x27;t it? But obviously the top people would decide on whatever would personally benefit them the most. reply binarymax 19 hours agoparentprevIs LSE Europe though? Perhaps pre-Brexit it would have been a more obvious choice. reply steve1977 17 hours agorootparentIt is Europe, but not EU reply sneak 19 hours agoprevTechnical question: why do people need ARM licenses? Surely you don&#x27;t need anything from them to design a chip from scratch that implements the same instruction set, as Cyrix and AMD famously did to the ia32.Are the licensees using parts of the actual chip design? Are their own designs too far down the \"derivative work\" rabbit hole due to not being cleanroomed that they have no hope of ever not licensing?What are the specifics? reply dragontamer 19 hours agoparentThe ISA isn&#x27;t very useful IMO, outside of the compiler framework.The crux of modern chip design is the tradeoff in MHz, peculiarities of Tomasulo&#x27;s Algorithm (out of order buffers, tuning sizes and number of pipelines, etc. etc.).Lets take an example: should you have 200 64-bit words in the reorder buffer, or should you have 800 (Apple M2). What&#x27;s the tradeoffs? How much slower does accessing the reorder buffer get when you need to go from 8-bits to 10-bits to address the various locations?How many multiplication units should you have? I know Intel has 3 of them per core, is that enough? Or do you go IBM Power route and go for like 20 pipelines wide?Etc. etc. etc.ARM Neoverse N2 makes a lot of these decisions, packages them up into an easy moniker (\"General Purpose\"), and also has customizations towards V-cores (higher performance but bigger) vs E-cores (lower-performance but smaller and more power-efficient).You then make decisions based off of the core as a whole, rather than designing a core. Ex: do you use 128kB of L1 cache? Or 64kB? Do you do L1 &#x2F; L2 &#x2F; L3 cache like Intel? Or do you do L1 &#x2F; L2 cache like Apple?You still need to make these \"uncore\" decisions, including the important MESI (core-to-core communications: Modified data vs Exclusive data vs Shared data vs Invalid data). Even _IF_ you buy an off-the-shelf core like Neoverse N2, you&#x27;re no where close to finishing an actual chip yet cause the darn thing can&#x27;t even talk to RAM yet. reply uxp8u61q 19 hours agoparentprevYou also don&#x27;t need anything from your architect to design a building from scratch. But unless you&#x27;re an architect yourself, it&#x27;s going to be prohibitively difficult, or even impossible. So people hire architects. reply ip26 19 hours agoparentprevOnly a few licensees are capable of designing their own core from scratch. Most customers are licensing some form of reference design. reply actionfromafar 19 hours agoparentprevCyrix and AMD licensed tech from Intel back then. reply papercrane 18 hours agorootparentOriginally Cyrix did not license from Intel. Intel sued for patent infringement and lost badly enough they had to give Cyrix a few million to settle their counter claims.Cyrix has also sued Intel over their Pentium chips. In the end the results of all the lawsuits are cross-licensing deals. reply sneak 19 hours agorootparentprevInteresting, I didn&#x27;t know that. Why would Intel do that?What is the legal interpretation of IP law that says you need permission to design a chip that implements an ISA? reply papercrane 18 hours agorootparentFor AMD the primary driver was IBM.In order to get the contract for the IBM PC, Intel had to agree to have a second-source manufacturer for their CPUs. Intel already had a relationship with AMD so it made sense to use them. reply ip26 19 hours agorootparentprevIntel licensed x86 to provide a credible second source, which they needed for some of their early business deals. reply monocasa 15 hours agoparentprev> Surely you don&#x27;t need anything from them to design a chip from scratch that implements the same instruction set, as Cyrix and AMD famously did to the ia32.Cyrix and AMD had licenses to do so, ultimately deriving from a time when Intel needed second sources of their CPUs in order to win defense contracts. reply throw0101c 19 hours agoparentprev> Surely you don&#x27;t need anything from them to design a chip from scratch that implements the same instruction set, as Cyrix and AMD famously did to the ia32.Cyrix and AMD got (cross-)licenses from Intel:* https:&#x2F;&#x2F;www.sec.gov&#x2F;Archives&#x2F;edgar&#x2F;data&#x2F;2488&#x2F;000119312509236...* https:&#x2F;&#x2F;www.kitguru.net&#x2F;components&#x2F;cpu&#x2F;anton-shilov&#x2F;amd-clar...This has been true since the very beginning:> Early 1980s--IBM chooses Intel&#x27;s so-called x86 chip architecture and the DOS software operating system built by Microsoft. To avoid overdependence on Intel as its sole source of chips, IBM demands that Intel finds it a second supplier.* https:&#x2F;&#x2F;www.cnet.com&#x2F;tech&#x2F;tech-industry&#x2F;intel-and-amd-a-long...* https:&#x2F;&#x2F;jolt.law.harvard.edu&#x2F;digest&#x2F;intel-and-the-x86-archit...The reverse engineering happened with Compaq doing the BIOS:* https:&#x2F;&#x2F;www.allaboutcircuits.com&#x2F;news&#x2F;how-compaqs-clone-comp...This was a major plot point in AMC&#x27;s (very good) show Halt and Catch Fire:* https:&#x2F;&#x2F;www.internethistorypodcast.com&#x2F;2014&#x2F;05&#x2F;the-incredibl...* https:&#x2F;&#x2F;arstechnica.com&#x2F;gaming&#x2F;2014&#x2F;05&#x2F;review-halt-and-catch...* https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Halt_and_Catch_Fire_(TV_series... reply delfinom 19 hours agoparentprevARM uses a mix patents, copyright and trade secret protections for their ISA. The give you the RTL&#x2F;vhdl&#x2F;verilog for the core when you license it and they forbid you from changing the core in the license agreement to use it.You can clean room implement the trade secret part, but the patents would be an issue and ARM could still sue and drag things out.You also could never legally call it ARM because it&#x27;s trademarked. This makes it harder for semiconductor vendors to sell chips.See the Qualcomm lawsuit shitshow which is now causing Qualcomm to invest big in RISCV. reply pclmulqdq 18 hours agorootparentChip IP is usually encrypted verilog. Your EDA tools compile it in a secure enclave, basically. You have no real options to modify it. reply monocasa 15 hours agorootparentWell, encrypted OASIS these days for something like a higher perf CPU core, but close enough for the point you were making. reply pclmulqdq 11 hours agorootparentYeah, for hard layouts that the vendor has already done, that is true. Either way, it&#x27;s transferred encrypted and protected so you can&#x27;t screw with it. reply pid-1 15 hours agoparentprevPeople don&#x27;t want to design chips from scratch. ARM gives you a lot of working stuff to bootstrap a product. reply foobiekr 18 hours agoparentprevMaking and more importantly verifying a high performance CPU is extremely hard. AMD has taken a lifetime to get where it is. reply pkcsecurity 18 hours agoprevComment on the timing of this IPO: for a company to IPO \"unfavorably\" compared to previous valuations likely means ARM&#x27;s hand was forced by timing considerations, unless they are running out of cash, which I don&#x27;t think is the case.My interpretation of this is that their investors suspect that whatever boost ARM is getting from AI optimism will likely peak soon, so the timing has to be now.I know that&#x27;s not fully rational because they&#x27;re mostly unrelated, but certainly the optimism because of AI has to be good for them. Curious to see if this \"signal\" plays out - investors tend to be pretty savvy about timing. reply jsnell 17 hours agoparent> I know that&#x27;s not fully rational because they&#x27;re mostly unrelated, but certainly the optimism because of AI has to be good for them. Curious to see if this \"signal\" plays out - investors tend to be pretty savvy about timing.The \"investors\" are SoftBank; they&#x27;ve been pretty much the stupidest money in the world for years.While it&#x27;s possible that they&#x27;re being more savvy about the timing of this sale than about their investment decisions, I don&#x27;t know that it should be the default assumption. reply zzbn00 13 hours agoparentprevThere is one timing-related disclosure in the F-1: The Kronos guarantee reply dilyevsky 18 hours agoparentprevArm itself may not be running out of cash but their major investor might be looking to cash out reply lotsofpulp 18 hours agorootparentARM was wholly owned by SoftBank. They did not have their own cash, it was all Softbank’s cash. And obviously SoftBank selling ARM means SoftBank wants to cash out, for whatever reason. reply pokerhobo 16 hours agorootparentSoftBank made a ton of stupid investments like WeWork and was bleeding money. They needed to cash out their ARM investment to recoup major losses. reply monocasa 15 hours agorootparentIn fact, SoftBank is known for being the one of the stupidest big investors there is. They got lucky being an early investor in Alibaba, but have managed to piss most of that money away on getting left holding the bag on the peak. replySilverBirch 14 hours agoprevI&#x27;ve said it before, and I&#x27;ll say it again: the weird self-dealing and tiny float that softbank are going for indicate a strong chance that this is going to fall through the floor. Softbank should&#x27;ve learned by now, you can bully the market when you&#x27;re buying, but you can&#x27;t bully the market when you&#x27;re selling. I&#x27;d be surprised if this stock weren&#x27;t down 50% within 12 months. There&#x27;s too much sell pressure from Softbank and there&#x27;s no buy pressure. reply lvl102 11 hours agoparentBut they have strong support from the likes of Apple to keep ARM independent. reply incognition 9 hours agoparentprevBuy pressure from the ibanks on the tombstone reply Keyframe 18 hours agoprevWould it be possible now for Nvidia to move onto a hostile takeover? Or any form of takeover is done due to regulatory decisions? reply SilverBirch 14 hours agoparentEven if Nvidia wanted to go that route, they still wouldn&#x27;t get through regulators, and no one else will try for the same reason. reply pianoben 18 hours agoparentprevSoftbank still controls what, 90% of the stock? It would seem mathematically impossible for anyone to execute a hostile takeover. reply Keyframe 15 hours agorootparentIf Softbanks starts releasing stock. reply idontwantthis 18 hours agoparentprevNot as long as SoftBank owns 90% of the shares. reply lotsofpulp 18 hours agorootparentWhy would that be relevant? SoftBank wanted to sell to Nvidia, but the government did not stop the sale just because SoftBank owned it. reply idontwantthis 17 hours agorootparentBecause they would need to sell those shares for there to be a takeover. reply lotsofpulp 17 hours agorootparentBut they already wanted to sell their shares to Nvidia before, what would have changed now? They want to reduce their ownership of ARM, hence them doing an IPO in the first place. reply disgruntledphd2 16 hours agorootparentThe regulators would stop it like they did last time. reply pc86 16 hours agorootparentRegulators stopped a coordinated purchase, which they are totally within their right to do. And if Softbank and NVIDIA try to coordinate a purchase another way, they&#x27;ll stop that too.It&#x27;s not as cut-and-dry if Softbank just puts the shares on the open market, and NVIDIA pays market value for them. Are there reporting requirements around NVIDIA buying stock on the open market? Freeze-out periods? Regulatory delays? If there&#x27;s collusion it might be a crime but even if you&#x27;re cynical and refuse to believe that there might not be, you still have to prove it. reply therealcamino 10 hours agorootparentThe antitrust laws and regulations don&#x27;t change. replygoodmachine 15 hours agoprev\"With the financial world anxiously awaiting the start of Arm’s roadshow in the hopes that Son can reignite the flaccid IPO market, Son has decided that his chip-maker is worth $64 billion because Son agreed to buy a chunk of it from Son for that price.In so doing, Son agreed to pay Son twice what Son sold it to Son for six years earlier.\"https:&#x2F;&#x2F;doomberg.substack.com&#x2F;p&#x2F;arms-length reply incognition 9 hours agoparentLike they say, cash is king reply itsoktocry 19 hours agoprev50 terrible investments by Softbank possibly recouped in a single IPO. Crazy world. reply boringg 19 hours agoparentI don&#x27;t think that&#x27;s the case here.\"At this price, the IPO is reportedly set to raise about $4.9 billion for Arm’s parent company, Softbank, which is less than the $8-$10 billion the Japanese investment outfit had previously said it hoped to generate. Softbank itself posted a record $39 billion loss earlier this year.\" reply anonymousiam 18 hours agoprevBought some earlier and it&#x27;s already up 20% today. reply intrasight 19 hours agoprevI&#x27;ve read that some big tech names are anchoring this IPO: Apple, Google, NVidia. What&#x27;s in it for them? Or are they getting a sweetheart deal on their shares of Arm? reply SkyMarshal 18 hours agoparentThey don’t appear to be saying, but the investment makes sense for Apple and Google even without a sweetheart deal. It ensures a successful IPO and continuing viability of their primary chip supplier, and protects it from a takeover by some entity hostile to Apple or Google. Nvidia I’m not sure about though. reply coder543 15 hours agorootparentNvidia has been selling ARM chips for years (the Nintendo Switch’s SoC, for example), and they’re currently in the process of massively growing their ARM business with the new Nvidia “Grace Superchips”. Not to mention the expected sales boom of the new Switch 2 SoC that should happen within about a year. reply 01100011 18 hours agoparentprevProbably a pump-n-dump onto retail investors to make a quick buck... or they&#x27;re paranoid and want to retain enough ownership to have some say in the future direction of the architecture... or both. reply therealcamino 10 hours agoparentprevThey don&#x27;t want a competitor to control ARM. reply seabass-labrax 17 hours agoprevWhat I would like to know is why ARM - or its owners - needs the cash. Are there any major projects they are undertaking that justifies this flotation? reply dukeyukey 17 hours agoparentSoftbank is in a bit of financial trouble - https:&#x2F;&#x2F;techcrunch.com&#x2F;2023&#x2F;05&#x2F;11&#x2F;softbank-vision-fund-loses... reply bdcravens 17 hours agoparentprevInvestors demand exits. reply 1-6 19 hours agoprevARM IPO will make it another patent house like Qualcomm. reply throwaw12 19 hours agoprevisn&#x27;t it slightly high for ARM? what is fair value for them? reply psychlops 19 hours agoparentHave you seen Nvidia&#x27;s stock price? reply 01100011 18 hours agorootparentIrrelevant given they have completely different business models. reply xorcist 17 hours agorootparentThis is literally how ARM is being sold by stock analysts. It is supposedly the \"primary competitor\" to nVidia in \"AI\". reply relativ575 13 hours agorootparentThat&#x27;s new to me. Who are those analysts? reply ta988 19 hours agoparentprevI heard that&#x27;s what market exchanges are supposed to be doing. &#x2F;s reply robertlagrant 19 hours agoparentprevCan you define fair? reply ravenstine 18 hours agorootparentYou can&#x27;t. Valuations are based on opinion and feelings. reply lotsofpulp 18 hours agorootparentYou can certainly try to define it.https:&#x2F;&#x2F;www.ifrs.org&#x2F;content&#x2F;dam&#x2F;ifrs&#x2F;publications&#x2F;pdf-stand... reply wredue 19 hours agoparentprevTech valuations are all fairies and unicorns right now. I don’t know what their “actual fundamentals” valuation should be, but actual fundamentals haven’t dictated tech stock pricing for at least a decade. reply ShroudedNight 19 hours agorootparentI thought the substantial increase in interest rates mostly pissed away the fairies and unicorns, and people needed to prove they made real money now. reply wredue 19 hours agorootparentNVDA is up 200% YTD and was already massively overvalued at the start of the year.Others do seem to be backing off, but there is still definitely a lot of way overvalued tech out there. reply linuxftw 19 hours agorootparentNVDA forward PE is 42.48, which isn&#x27;t super crazy relative to other big tech companies (MSFT over 30). I suspect ARM&#x27;s forward PE is double that ratio (>80).If NVDA&#x27;s forward projections are correct, and they can maintain that same growth, then there is still room for upside. Personally, I&#x27;m not playing this game of musical chairs because I don&#x27;t think these valuations are sustainable, but as they say, the market can stay irrational longer than you can stay solvent, so shorting is a terrible idea. reply wredue 18 hours agorootparentPricing stocks today at what a company might be worth in 10 years is pretty much fairies and unicorns.Other sectors do not price in the way tech does. reply sapiogram 17 hours agorootparentprevAnyone who is able to reliably predict which stock valuations are actually fairies and unicorns can become insanely rich doing so. With this great insight, surely you&#x27;ll be a billionaire in 10 years through short selling? reply sharedbeans 15 hours agoprevI remember reading that ARM makes more money from embedded than they do from mobile, but I can’t find this source any more. Does anyone know anything about this? Was this true in the (recent) past but no longer true? reply mise_en_place 15 hours agoprevI wonder how well SoftBank did with this IPO. If it was a decent enough return, I’d say it’s good news for new SoCs and chipmakers that want to innovate. reply xyst 15 hours agoprevAnybody buying ARM stonk at IPO price will be bag holding. $54B valuation is insane reply varjag 15 hours agoparentThat&#x27;s two LinkedIns reply als0 1 hour agorootparentARM probably provides 10x world impact&#x2F;value compared to LinkedIn. reply varjag 1 hour agorootparentExactly my point. One could have maybe one LinkedIn profile but easily dozens of ARM devices. reply adolph 19 hours agoprev [–] As an IP holding company for an ISA, how is Arm Limited different from any other patent troll?https:&#x2F;&#x2F;www.arm.com&#x2F;glossary&#x2F;isahttps:&#x2F;&#x2F;www.theregister.com&#x2F;2023&#x2F;08&#x2F;31&#x2F;a_star_star_domains&#x2F;https:&#x2F;&#x2F;www.theregister.com&#x2F;2023&#x2F;09&#x2F;12&#x2F;arm_markstedter_domai... reply deelowe 19 hours agoparentPatent trolls patent things that already exist in some form and then seek to extract revenue through the legal system.You can&#x27;t call a company that literally developed the IP they patented \"trolls.\" reply uxp8u61q 19 hours agoparentprevBoth cases you link to are about trademarks. Patents and trademarks are unrelated.\"Patent troll\" has the connotation of an organization or individual who buys cheap patents and sue other organizations on mostly bogus claims related to these patents, hoping that the other side won&#x27;t want to bother and just settle the matter. That&#x27;s not Arm&#x27;s business model. reply The_Colonel 19 hours agoparentprevThey don&#x27;t just hold the patents, but actively develop the ISA &#x2F; designs too.ARM doesn&#x27;t have a big enough moat to stay static and just troll. There are competing ISAs, some free, and there isn&#x27;t as big of an lock-in as for e.g. x86. reply codazoda 19 hours agoparentprevThis feels different to me because Arm is designing these chips. It feels a bit more like a drafting company who draws plans but doesn’t build anything. They don’t just have some loosely defined patent.The linked articles are about the brand name, Arm, used in a domain. You wouldn’t put “intel” or “nvidia” in your domain name without drawing attention. Maybe we need a moniker similar to x86 to define the arm architecture more generally. reply deelowe 19 hours agorootparentI would add to this that people who make statements like the parent did are woefully ignorant of how the industry really works. Board producers rarely design the entire PCB. PCB designers rarely produce the board. Chip designers rarely produce their chips. Chip producers often do some portion of the design process. And on and on.Computing is a complex business and few companies do everything in house. ARM&#x27;s business model of focusing solely on the IP seems to have worked well for them. From the engineering side, it&#x27;s certainly nice to have the ability to pick and choose which IP blocks we&#x27;d like to use and then shop around the design ourselves versus having to battle with Intel to get what we need while trying to poke through the various layers of obfuscation they tend to put in place. reply devnullbrain 19 hours agoparentprevIf anyone replying to this needs you to define ISA for them, their input isn&#x27;t very useful. reply chmod600 19 hours agoparentprev [–] The links you provided are about copyright and trademark law, not patents. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Arm, a British chip designer, is initiating its IPO with a stock price of $51 each, setting the company valuation at $54.5 billion.",
      "The IPO is set to generate about $4.9 billion for Softbank, Arm's parent company, and post-IPO, Arm will continue as a Softbank subsidiary.",
      "The IPO received widespread approval, attracting investments from tech heavyweights such as Apple, Samsung, and Intel, but will only be listed in the US, following dashed hopes for a dual-listing in London earlier this year."
    ],
    "commentSummary": [
      "ARM's Initial Public Offering (IPO) has started, with speculation suggesting that a potential increase in prices might push customers towards the open-source RISC-V architecture.",
      "Discussions are ongoing concerning a possible transition from ARM to RISC-V, with key considerations being software compatibility and hardware interoperability.",
      "The IPO is strategically positioned to maintain ARM's success, with SoftBank selling a 21% stake. Tech giants such as Apple, Google, and Nvidia potentially back the IPO to prevent a hostile takeover."
    ],
    "points": 235,
    "commentCount": 155,
    "retryCount": 0,
    "time": 1694701076
  },
  {
    "id": 37510885,
    "title": "Stolen van Gogh painting returned in an IKEA bag",
    "originLink": "https://www.smithsonianmag.com/smart-news/dutch-art-detective-recovers-a-van-gogh-stolen-in-2020-180982896/",
    "originBody": "SECTIONS SUBSCRIBE RENEW SHOP SUBSCRIBE GIVE A GIFT RENEW SMART NEWS History Science Innovation Arts & Culture Travel HISTORY Archaeology U.S. History World History Video Newsletter SCIENCE Human Behavior Mind & Body Our Planet Space Wildlife Newsletter INNOVATION Innovation for Good Education Energy Health & Medicine Sustainability Technology Video Newsletter ARTS & CULTURE Museum Day Art Books Design Food Music & Film Video Newsletter TRAVEL Africa & the Middle East Asia Pacific Europe Central and South America U.S. & Canada Journeys Newsletter AT THE SMITHSONIAN Visit Exhibitions New Research Artifacts Curators' Corner Ask Smithsonian Podcasts Voices Newsletter PODCAST PHOTOS Photo Contest Instagram VIDEO Ingenuity Awards Ask Smithsonian Smithsonian Channel NEWSLETTERS SHOP SMART NEWS Cool Finds Stolen van Gogh Painting Worth Millions Returned in an Ikea Bag Arthur Brand, the “Indiana Jones of the art world,” negotiated the recovery of an 1884 canvas taken from a Dutch museum in March 2020 Christopher Parker Daily Correspondent September 14, 2023 11:38 a.m. Arthur Brand poses with The Parsonage Garden at Nuenen in Spring, painted by Vincent van Gogh in 1884. Courtesy of Arthur Brand via Twitter Thanks to a world-renowned art detective, an early Vincent van Gogh painting is back at home three and a half years after it was stolen from a Dutch museum. Arthur Brand announced the recovery of The Parsonage Garden at Nuenen in Spring, an 1884 canvas estimated to be worth between $3.2 and $6.4 million, on September 12. The day before, an anonymous tipster delivered the bubble-wrapped painting to Brand’s Amsterdam apartment in an Ikea bag. The individual who returned the painting is not believed to be involved in the theft, which took place before dawn on March 30, 2020—van Gogh’s birthday—at the Singer Laren museum in the Netherlands. At the time, the Singer Laren was closed due to Covid-19 restrictions. The artwork was on loan from the Groninger Museum, also in the Netherlands. Authorities arrested the culprit behind the heist in April 2021, using DNA evidence left on a broken picture frame to link a man identified only as Nils M. to the thefts of both the van Gogh and a Frans Hal painting stolen in August 2020. A Dutch court sentenced Nils to eight years in prison and ordered him to pay nearly $9 million in compensation to the owner of the Hals. Prosecutors believe Nils stole the van Gogh on the orders of Peter Roy K., a Dutch shipping mogul involved in drug smuggling, who hoped to use the artwork as leverage for negotiating a reduced prison sentence, reported Marco Willemse for Dutch newspaper AD in 2021. “The perpetrator is in custody and the painting is back,” Richard Bronswijk, a member of the Dutch Police’s Art Crime Unit, tells ABC News’ Emma Ogao. “We are very happy with that result.” After Nils’ arrest, the painting circulated in the criminal underworld, where it was used a down payment. But nobody was willing to buy it, as “the thieves had been convicted, and anybody possessing it would risk a hefty fine,” writes Claire Moses for the New York Times. “We knew that the painting would go from one hand to another hand in the criminal world, but that nobody really wanted to touch it,” Brand tells the Guardian’s Senay Boztas. “You could only get in trouble. So it was a little bit cursed.” An anonymous tipster delivered the bubble-wrapped painting to Brand’s Amsterdam apartment in an Ikea bag. © Groninger Museum Brand is most famous for recovering two horse statues created by Adolf Hitler’s favorite sculptor, Josef Thorak. The bronze horses once stood outside of the New Reich Chancellery in Berlin, but they went missing after the fall of the Berlin Wall in 1989. Brand helped authorities track the sculptures through the underbelly of the art world, ensuring their return in 2015. Since then, the so-called “Indiana Jones of the art world” has helped authorities recover stolen paintings by Pablo Picasso and Salvador Dalí, in addition to a 15th-century manuscript of Persian poetry, a gold ring gifted to a friend by Oscar Wilde and more than 200 other artworks. Brand tells the Guardian that the tipster who returned the painting contacted him, saying, “Mr. Brand, I could turn in the van Gogh, but I don’t want to get in trouble.” The art detective “had to gain his confidence” before the man agreed to drop off the canvas in a meeting sanctioned by authorities. In a statement, the Groninger Museum says the oil on paper on panel painting “has suffered” due to poor storage conditions over the past few years but “is—at first glance—still in good condition.” A formal examination and restoration work must be completed before the painting goes back on view, which could take “weeks, if not months,” according to the museum. Get the latest stories in your inbox every weekday. Christopher ParkerREAD MORE Christopher Parker is a journalist covering history, conservation, education and other topics. His work has been featured in America magazine, Notre Dame magazine, the Los Angeles Times and the Berkshire Eagle. RECOMMENDED VIDEOS Why This 1933 Double Eagle Coin Will be Worth Millions Years after all double eagles were supposedly destroyed, the Secret Service traces the reappearance of two of the rare coins back to a deal between jeweler Israel Switt and Mint cashier George McCann. 0 seconds of 3 minutes, 0Volume 0% Filed Under: Adolf Hitler, Art, Art Crimes, Art History, Cool Finds, Crime, Impressionism, Mysteries, Netherlands, Pablo Picasso, Painters, Painting, Vincent Van Gogh MOST POPULAR The Asteroid Hit by NASA Seems to Be Moving Strangely, High School Students Find Alleged Alien Corpses Displayed to Mexican Congress Did Not Convince Scientists Stolen van Gogh Painting Worth Millions Returned in an Ikea Bag The Quest to Save the World’s Most Coveted Chocolate Amateur Metal Detectorist Makes 'Gold Find of the Century' in Norway EXPLORE Smart News History Science Innovation Arts & Culture Travel At The Smithsonian Podcast Photos Video SUBSCRIBE Subscribe Give a gift Renew NEWSLETTERS Sign Up OUR PARTNERS Smithsonian Institution Smithsonian.com Smithsonian Store Smithsonian Journeys Smithsonian Channel Smithsonian Books Smithsonian Membership TERMS OF USE About Smithsonian Contact Us Advertising RSS Member Services Sustainability Terms of Use Privacy Statement Cookie Policy Advertising Notice © 2023 Smithsonian Magazine Privacy Statement Cookie Policy Terms of Use Advertising Notice Your Privacy Rights Do Not Sell My Personal Information Get our best stories each day for free by email. By checking this box, I agree to receive other information from the Smithsonian, including relevant content and programming, news about Smithsonian events, trips and offers, and museum updates. Click to visit our Privacy Statement. Easy unsubscribe links are provided in every email.",
    "commentLink": "https://news.ycombinator.com/item?id=37510885",
    "commentBody": "Stolen van Gogh painting returned in an IKEA bagHacker NewspastloginStolen van Gogh painting returned in an IKEA bag (smithsonianmag.com) 229 points by Brajeshwar 18 hours ago| hidepastfavorite76 comments zamalek 15 hours agoAfter watching way too much Baumgartner Restoration, do paintings with such status receive much conservatorship? The varnish on that painting is obnoxiously aged. reply toyg 15 hours agoparentThey do, but I expect it becomes a big political issue - can you imagine how much it must cost in insurance alone, as soon as you mention the painting might have to be touched...? And then you&#x27;ll need a committee to agree on how much varnish should be stripped, etc etc. reply greggsy 15 hours agorootparentAn experienced conservationist would know exactly what to do, and scope the work accordingly. It would go on show for a short period to capitalise on the current interest and attract foot traffic to the gallery, before being treated. reply londons_explore 14 hours agorootparentConservator &#x27;best practice &#x27; changes pretty much every decade, with each generation of conservators dismayed at all the damage done by their predecessors... reply krisoft 11 hours agorootparentThat is true, but![1] This is well understood by modern conservators, so they use reversible materials as much as possible. For example paints which can be any time cleaned up with a weak solvent specifically selected such that it doesn&#x27;t attack the base painting at all. The any time is a very important property here. Normal paints \"set\" after a while. You might clean them off the canvas a day later easily, with some difficulty a year later, and 30 years later it becomes basically impossible. But conservation paints don&#x27;t do this. They can be cleaned up a day after the work is done, or 200 years after.The other important property is that these materials are often designed to show up visibly under UV light. That way they can perfectly blend in the base paint under normal gallery lights (if desired, this is not always desired) but they will always show up for someone who investigates the painting in the future.1: All my knowledge about the topic comes from the aforementioned Baumgartner Restoration YouTube channel: https:&#x2F;&#x2F;www.youtube.com&#x2F;c&#x2F;BaumgartnerRestoration reply AdamJacobMuller 8 hours agorootparentIf you watch Baumgartner&#x27;s channel (as you do) this is a topic he is probably most careful about. He knows his first duty is to do nothing which can not be undone. Conservation paints and isolation layers are critical. reply londons_explore 1 hour agorootparentprevTrue... But what when the conservators work itself becomes a historic artifact? In the 25th century, there may be no way to separate and keep both the 15th century artwork and the 21st century conservators work. reply hinkley 13 hours agorootparentprevConservators: the dentists of the art world. reply ndiddy 11 hours agorootparentprevSounds like software development reply ChrisRR 2 hours agorootparentprevThey wouldn&#x27;t know \"exactly\" what to do. Just like every discipline there&#x27;s many different ways to skin a cat, pros&#x2F;cons, aims. reply AdamJacobMuller 8 hours agorootparentprevAn experienced conservator (such as Baumgartner) would know how little he knows and would proceed with extraordinary caution if faced with the prospect of restoring a Van Gogh.I suspect, if given the job, he would only do it in incredibly small steps with deep collaboration with his peers.I&#x27;ve watched how cautiously he approaches paintings which (while admittedly beautiful) don&#x27;t have 1% of the historical significance of a Van Gogh. reply internet101010 13 hours agorootparentprevThey&#x27;ll just have someone do it for free in exchange for IP rights so that nobody can ever take a photo of it. reply Aunche 9 hours agoparentprevAs the name implies Baumgartner is a restorer, not a conservator. Conservators tend to consider his methods rather aggressive, though I imagine part of it is being envious of his popularity. If you just want to spend a moderate sum of money to make your family heirloom look nice, you probably don&#x27;t care about the .01% of original paint that gets lost. reply AdamJacobMuller 8 hours agorootparentIf you watch his channel, he absolutely considers himself a conservator. reply AdamJacobMuller 8 hours agoparentprevI&#x27;m not the only technical person who likes his channel!His channel hits this incredible niche between science (his knowledge of how the various cleaning methods, glues, paints and varnishes he uses interact with each other is amazing), the technical (one of the first videos of his I saw was the vacuum table build and the rigs he&#x27;s built to save some of the wood panel paintings are amazing), and the meditative (as he would say, sometimes there is no better way to clean a painting than sitting there for 12, 24, 72 hours with cotton balls).I&#x27;m a bit sad that they don&#x27;t allow someone like him to work on paintings of this vintage. I know a Van Gogh is extraordinarily perhaps incalculably valuable but I would absolutely love to see paintings as they were when the artist first painted them (or at least closer), especially Van Gogh. The transformations on some the paintings Baumgartner has done are astonishing and can completely change the tone or meaning of a painting. reply zamalek 10 hours agoparentprevAfter further research, can Gogh might have used paints with ingredients that brown over time. What a pity! reply rasz 11 hours agoparentprevSimilar dilemmas in vintage car collecting circles. Some like them fully restored to pristine condition, others leave patina and every imperfection as is. For example this “King Leopold” Bugatti 59 https:&#x2F;&#x2F;youtu.be&#x2F;MzZIk05pAJ8?feature=shared&t=1017 sold for $12mil few years back https:&#x2F;&#x2F;luxurylaunches.com&#x2F;auctions&#x2F;a-vintage-bugatti-type-5... reply lamplovin 17 hours agoprevIt&#x27;s like a real life adaptation of the book, Goldfinch reply unreal6 15 hours agoparentOne of my favorite novels of all time reply munificent 14 hours agorootparentCan you give me some thoughts on what you enjoyed about the book? I read it several years ago after reading many many glowing reviews but I just couldn&#x27;t get much out of the book at all. What did I miss? reply bmelton 14 hours agorootparentI think everything in it is fairly subtle (relative to modern television at least) and there are a lot of them. It&#x27;d be reductive for me to refer to it as a coming of age story, but I often do that despite knowing it&#x27;s wrong, but coming of age stories generally have to hit me over the head with their point before I stop seeing it as a character piece.For me, the themes in Goldfinch are about art (and the power it can hold over us,) how messy relationships can be despite good intentions (and how much care they require,) the role of beauty in the world, and the search for identity. reply cgio 9 hours agorootparentprevIn the book. That start… the writing had me feel stress and despair in a way that no other book has managed. I think the technique it used was giving you a heads up on what will happen but then glimpses of hope that would make the hopelessness even more evident. I am not a writer, so cannot distill it fully, but the experience was palpable. reply UberFly 12 hours agoprevAnyone who enjoys these kind of stories should check out the series \"Raiders of the Lost Art\". They are on Curiosity Stream and maybe elsewhere. Good stuff. reply londons_explore 14 hours agoprevSomeone who is really good at finding lost artworks hey....?Is there good evidence that this guy or his friends didn&#x27;t steal the artworks in the first place? reply deepsun 13 hours agoparentSame thoughts. It&#x27;s hard to navigate the criminal underworld having clean clothes yourself.But the painting is back. reply muzani 3 hours agorootparentHe did literally write a book on infiltrating the Nazi underground to get artwork back.https:&#x2F;&#x2F;www.amazon.com&#x2F;Hitlers-Horses&#x2F;dp&#x2F;1529106109 reply civilitty 11 hours agoparentprevThe thief left DNA evidence at the scene and eventually pleaded guilty. The person in TFA didn&#x27;t \"find\" the artwork, someone came to him with it in order to arrange a handover without getting into legal trouble themselves. reply rasz 11 hours agorootparent>without getting into legal trouble themselves.How would that work? Police: Hey thanks for returning stolen property, since it was in your possession we will charge you now, that is unless we learn who gave it to you. reply 8bitsrule 9 hours agorootparentI wonder how that tactic would work for fentanyl? Jailing the ultimate source (or at least highest-level distributor) would seem ideal. Making the charge stick might be harder; does it fall back down then? (Warden Isaac Newton spent years on one counterfeiter.) reply vermilingua 6 hours agorootparentCounterfieiting currency is a high-skill activity, distributing fentanyl is not. As soon as they cut the head off of a distribution network, another one will pop up to fill the vacuum; so it isn&#x27;t worth huge investments to take down any given individual. reply _jal 11 hours agorootparentprevI don&#x27;t see any indication in the story that the police were involved in the return.The hard part, as with most transactions of this sort, is trust. I&#x27;m curious how Brand convinced the returner he wouldn&#x27;t double-cross them. reply sourcecodeplz 4 hours agorootparent>> The art detective “had to gain his confidence” before the man agreed to drop off the canvas in a meeting sanctioned by authorities. replystateoff 9 hours agoprevIf it came in a yellow and not a blue bag, we should have known. reply EA 16 hours agoprevBTW: those durable plastic carry bags from IKEA are a bit of a lifehack for me. They are just a few USD each and they carry a lot of volume and weight. I keep a couple folded up in my vehicle and in the garage. They are great for carrying lots of groceries, firewood, and other items...such as valuable pieces of art. reply jetrink 15 hours agoparentAlso dogs! New York banned dogs on the subway unless they fit in a bag or other container, so New Yorkers have been dressing their dogs in Ikea bags with four holes cut in the bottom.https:&#x2F;&#x2F;www.reddit.com&#x2F;r&#x2F;pics&#x2F;comments&#x2F;10yzyq6&#x2F;nycs_answer_t... reply victorbjorklund 12 hours agoparentprevAnd laundry! That is what we use them for in sweden! reply wkat4242 14 hours agoparentprevA few USD?? Wow here they&#x27;re 50 euro cents reply blamazon 11 hours agorootparentThere&#x27;s different kinds of those bags. My favorite is a rectangular prism, has a zipper and backpack straps and sells for like $4.99. I think it may have been discontinued in my area, or it is of sporadic availability? reply TylerE 12 hours agorootparentprev$0.99. Probably .9 euro or something. reply sva_ 15 hours agoparentprevSome even make backpacks out of them. https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=13013868 reply neilv 15 hours agorootparenthttps:&#x2F;&#x2F;web.archive.org&#x2F;web&#x2F;20200301084451&#x2F;http:&#x2F;&#x2F;sandiegomi... reply kzrdude 15 hours agorootparentAlso syndicated on https:&#x2F;&#x2F;ikeahackers.net&#x2F;2016&#x2F;12&#x2F;ikea-ultralight-backpacking-... reply swader999 14 hours agoparentprevThey work well for bullion too. reply throwaway161718 4 hours agoprevI was hoping to see the IKEA bag as well when I clicked on the link. Slightly disappointed :( reply tanepiper 4 hours agoparentWe have lovely page where you can see themhttps:&#x2F;&#x2F;www.ikea.com&#x2F;gb&#x2F;en&#x2F;p&#x2F;frakta-carrier-bag-large-blue-1... reply chaxor 9 hours agoprevThat top image looks like a generated image.Those hands. Man those hands are wildly big.Camera angles are powerful. reply jjoonathan 9 hours agoparentYeah but there are 8 visible fingers, not 18. reply glouwbug 8 hours agoprevThere’s nothing you can do with a stolen famous painting. It’s essentially worthless as your clientele know it’s worth and that it’s stolen. Stolen art only gains to make the art more famous reply gnulinux 7 hours agoparentWhat? Aren&#x27;t stolen high art pieces used as their own currency in the dark web for \"priceless\" services. I was told that criminals use stolen art for payment and it just goes around one criminal to another. Is this just an urban legend, is it inaccurate? reply fastball 8 hours agoparentprevWhat do you mean? There are absolutely people willing to buy stolen art. reply lmm 3 hours agoparentprevYou can do the only thing you should be buying a painting for: look at it and enjoy it. reply WeylandYutani 2 hours agoparentprevTrue. There was an infamous case in the Netherlands were the Bulgarian thieves realised their mistake and burned a million euro painting in their mother&#x27;s stove to get rid of the evidence.Criminals contrary to Batman cartoons aren&#x27;t geniuses. reply laxatives 6 hours agoprevSort of like a Goya in a Harrod&#x27;s handbag? reply sourcecodeplz 4 hours agoprevHot potato indeed reply moffkalast 15 hours agoprevReminds me of that Rembrandt&#x2F;Renoir heist, a classic documentary by the Internet Historian.https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=iPlFdIpgioI reply User23 10 hours agoprevI wonder if an ethical collector was viewing to buy and said something like “the only way it’s leaving here with you is with the police. Are you staying or leaving it?” reply adolph 16 hours agoprevI wonder if Nils will get his $9M back?Authorities arrested the culprit behind the heist in April 2021. . . . A Dutch court sentenced Nils to eight years in prison and ordered him to pay nearly $9 million in compensation to the owner of the Hals.After Nils’ arrest, the painting circulated in the criminal underworld, where it was used a down payment. But nobody was willing to buy it, as “the thieves had been convicted, and anybody possessing it would risk a hefty fine,” writes Claire Moses for the New York Times. reply mikey_p 15 hours agoparentTha Hals is a different painting than the van Gogh. reply paulpauper 14 hours agoprevhard, if not impossible to sell it. that is the problem with stolen artwork from the perspective of thief reply wkat4242 14 hours agoprevThey bought the wrong VÅNGØGH and wanted to return it reply tomcam 5 hours agoprev> Prosecutors believe Nils stole the van Gogh on the orders of Peter Roy K., a Dutch shipping mogul involved in drug smuggling, who hoped to use the artwork as leverage for negotiating a reduced prison sentenceThat could be the plot of a Tarantino comedy reply 1MachineElf 15 hours agoprevIf this was all an elaborate ruse to make us want to go shopping at IKEA, then I&#x27;ll concede that it worked. reply here4U 16 hours agoprevI guess the IKEA bag was stolen too reply 2-718-281-828 15 hours agoparentStolen IKEA bag returned with van Gogh painting in it. reply petre 16 hours agoprev> Prosecutors believe Nils stole the van Gogh on the orders of Peter Roy K., a Dutch shipping mogul involved in drug smuggling, who hoped to use the artwork as leverage for negotiating a reduced prison sentenceRoy K: \"Two years for the stolen van Gogh?\"Prosecutor: \"Right. On top of what you got for dealing drugs?\" reply onlyrealcuzzo 16 hours agoparentWait. Am I reading this right?Did he commit a crime to get less jail time?Wouldn&#x27;t this be like kidnapping the police chief&#x27;s child to try to get less prison time?Someone please tell me it didn&#x27;t work. reply cherrycherry98 15 hours agorootparentI was shocked to learn that this is a thing but it does happen. Organized crime groups steal art that they can use to negotiate lighter sentences.It is believed that the Mafia stole Rembrandt&#x27;s \"Storm in the Sea of Galilee\", among other works from the Gardner Museum for this reason. The documentary series \"This Is a Robbery\" goes into this heist and is a good watch.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;This_Is_a_Robbery https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;Isabella_Stewart_Gardner_Mus... reply saikatsg 16 hours agorootparentprevMeet Gerald Blanchard, who did something similar https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Gerald_Blanchard reply jadbox 15 hours agorootparentIt&#x27;s kinda amusing that his last great crime after prison was stealing PlayStations from Best Buy... reply awb 15 hours agorootparentprevSounds like he successfully bargained after this arrest, but didn’t necessarily pre-meditate the theft in order to reduce a future prison sentence. reply mschuster91 11 hours agorootparentprevAn ages old tactic, take someone or in this case something hostage to be ransomed for letting someone get out of jail. The most well-known cases in Germany involved the RAF (the left-wing terrorists, not the British Air Force), but it also works with nation states such as China taking two Canadians hostage to exchange them against a Huawei executive, or in war times with spy and prisoner-of-war exchanges.The thing is, the stakes for something like that are super high, at least as a criminal as you need someone&#x2F;something that is immeasurably valuable, stuff like the Crown Jewels or a masterpiece worth many millions of dollars, as a starter for negotiations - and that is usually just as well protected.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Detention_of_Michael_Spavor_an... reply WeylandYutani 15 hours agorootparentprevIn the Dutch system the judge has the last word not the prosecution so no it doesn&#x27;t work. reply petre 14 hours agorootparentOf course the judge has the last word. It was just a hypothetic prosecutor joke. I found it quite stupid that Roy K allegedly comissioned another crime, holding a painting hostage to get a reduced sentence. What?! That only put a different person in prison and potentially damaged the painting. I don&#x27;t understand these people (drug dealers, nazis, climate activists) who keep stealing, looting and defacing Vincent van Gogh&#x27;s legacy. His life was quite miserable as it is, why tarnish his legacy as well? reply iamnotsure 15 hours agoprev [–] Stolen attention returned in a HN comment. reply CobrastanJorji 15 hours agoparent [–] Wait a second, can attention be returned?Like, I can take attention with billboards and pop-up ads and flashy lights and loud noises, but is there some way I could do something that would do the opposite?I suppose I could destroy other people&#x27;s advertising, but that&#x27;s more reducing the theft. I suppose some organizational tools might count? What&#x27;s the opposite of taking attention? reply tspike 14 hours agorootparent [–] Giving attention? Actively investing your attention in someone else’s wellbeing? replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "An early work of Vincent van Gogh, The Parsonage Garden at Nuenen in Spring, has been retrieved three and a half years post-theft from a Dutch museum.",
      "The painting, valued between $3.2 and $6.4 million, was returned anonymously in an Ikea bag to art detective Arthur Brand with no implication of the returner in the theft.",
      "The original thief was arrested in 2021 and sentenced to eight years in prison. The restored artwork will be displayed again after necessary examination and restoration."
    ],
    "commentSummary": [
      "The stolen van Gogh painting was recovered and returned in an IKEA bag, facilitated through an underground network run by art detective Arthur Brand.",
      "This painting, stolen in 2002, had been circulating in the criminal underworld and its return illustrates the legal issues related to possession of stolen artwork.",
      "Also discussed in the post are themes about the conservation of paintings, art restoration, and recommendations for books and series concerning art theft narratives."
    ],
    "points": 228,
    "commentCount": 76,
    "retryCount": 0,
    "time": 1694708140
  },
  {
    "id": 37507419,
    "title": "Nue – A React/Vue/Vite/Astro Alternative",
    "originLink": "https://nuejs.org",
    "originBody": "Author here. I&#x27;ve been working on this for the past ~12 months, lately full-time.I&#x27;m releasing two things today:1. Nue JS: https:&#x2F;&#x2F;nuejs.org&#x2F;docs&#x2F;nuejs&#x2F; — A tiny (2.3kb minzipped) JavaScript library for building user interfaces. It&#x27;s like React&#x2F;Vue core, but there are no hooks, effects, props, or other unusual abstractions on your way. Know the basics of HTML, CSS, and JavaScript and you are good to go. Nue JS supports server-side rendering (SSR), reactive components, and \"isomorphic\" combinations. It takes inspiration from Vue 2.0 and Riot.js. (I&#x27;m actually the original author of Riot).2. Nue ecosystem: https:&#x2F;&#x2F;nuejs.org&#x2F;ecosystem&#x2F; — This is the ultimate goal and once all the sub-projects are finished, Nue will be a serious alternative to things like Vite, Next.js, and Astro.The thing is that I&#x27;m not happy with the current state of web development, so I want to write a completely new ecosystem from scratch. I&#x27;m taking advantage of the \"old\" innovations like progressive enhancement, separation of concerns, and semantic web design. Benefits highlighted here: https:&#x2F;&#x2F;nuejs.org&#x2F;why&#x2F;All projects will be released under the MIT license.Happy to answer any questions.",
    "commentLink": "https://news.ycombinator.com/item?id=37507419",
    "commentBody": "Nue – A React&#x2F;Vue&#x2F;Vite&#x2F;Astro AlternativeHacker NewspastloginNue – A React&#x2F;Vue&#x2F;Vite&#x2F;Astro Alternative (nuejs.org) 213 points by tipiirai 9 hours ago| hidepastfavorite158 comments Author here. I&#x27;ve been working on this for the past ~12 months, lately full-time.I&#x27;m releasing two things today:1. Nue JS: https:&#x2F;&#x2F;nuejs.org&#x2F;docs&#x2F;nuejs&#x2F; — A tiny (2.3kb minzipped) JavaScript library for building user interfaces. It&#x27;s like React&#x2F;Vue core, but there are no hooks, effects, props, or other unusual abstractions on your way. Know the basics of HTML, CSS, and JavaScript and you are good to go. Nue JS supports server-side rendering (SSR), reactive components, and \"isomorphic\" combinations. It takes inspiration from Vue 2.0 and Riot.js. (I&#x27;m actually the original author of Riot).2. Nue ecosystem: https:&#x2F;&#x2F;nuejs.org&#x2F;ecosystem&#x2F; — This is the ultimate goal and once all the sub-projects are finished, Nue will be a serious alternative to things like Vite, Next.js, and Astro.The thing is that I&#x27;m not happy with the current state of web development, so I want to write a completely new ecosystem from scratch. I&#x27;m taking advantage of the \"old\" innovations like progressive enhancement, separation of concerns, and semantic web design. Benefits highlighted here: https:&#x2F;&#x2F;nuejs.org&#x2F;why&#x2F;All projects will be released under the MIT license.Happy to answer any questions. Dave3of5 2 hours agoI think you want the getting started to be the first thing people see on your homepage. Like instead of that thing which is showing you size difference put a snippet to show how easy it is to make a hello world app then a link to click to take them to a TODO style app.I know some devs do care about bundle size but most f&#x2F;e devs I&#x27;ve worked with don&#x27;t really care about that. They care more about their Dev Experience so you should be showing them how it&#x27;s the same or better with your new tool. reply ivan_gammel 1 hour agoparentAs important as a simple „getting started“ is a more complex showcase with modularity, some integrations etc. Many frameworks on FE and BE die on that hill, being easy to start, but hard to scale. reply progx 1 hour agoparentprevThat is true, the first thing i ask myself when i read \"Frontend Troublesolver - Nue is a powerful React, Vue, Next.js, Vite, and Astro alternative. It might change the way you develop for the web forever.\" ... was, how?And then came a code size comparison, this example is ok, but display it later, show first a simple example in which way it change it, e.g. a small code snippet? How does Nue look? reply hahn-kev 5 minutes agorootparentIt looks like Svelte honestly. I&#x27;m really trying to figure out how it&#x27;s all that much different reply niutech 8 hours agoprevNice project, well done!However, it is more like an alternative to Petite-Vue or Riot.js rather than full-blown Vue or React. Therefore your comparison vs headlessui-react&#x2F;vue is like apple vs orange&#x2F;banana: headless UI listbox is much more complicated than your implementation. You can easily make a listbox in Vue using a similar amount of code as Nue.One thing which is lacking in your Getting Started (https:&#x2F;&#x2F;nuejs.org&#x2F;docs&#x2F;nuejs&#x2F;getting-started.html) is how to use Nue without a build step, in order to progressively enhance existing HTML websites like Petite Vue: `` or Alpine.js: ``?How is Nue performance compared to other JS frameworks? Could you add it to https:&#x2F;&#x2F;krausest.github.io&#x2F;js-framework-benchmark&#x2F;current.ht...? reply tipiirai 8 hours agoparentThank you!You are right: Nue takes inspiration from Vue 2.0, petite-vue and Riot.I&#x27;ll make the comparison more fair, but it doesn&#x27;t take out the fact that React&#x2F;Vue promote use of \"spaghetti\" code where logic&#x2F;layout&#x2F;styling are mixed together making the code hard to read and causes the size to grow. Everywhere I look the projects are unnecessarily big. Very often in the factor of 10x too big.Pretty sure Nue JS will always need a build step. I don&#x27;t like the idea to load the compiler and run JS exec() on the client side. Heavy and unsecure.Haven&#x27;t checked performance yet. I want to see this project getting more traction before deep diving to benchmarking reply hackerman_fi 3 hours agorootparentI jumped straight to comparison (as it’s listed first) and was let down because the comparison seemed borderline deceiving. The other examples had hundreds of lines of logic and types for example. reply niutech 1 hour agorootparentprevHaving a zero-build-step bundle is a quick & easy way to experiment with a library and add simple interactions to existing static HTML websites, which is a big plus.However, according to BundleJS, only nuejs-core&#x27;s compile() method is 36.2KB minified gzipped: https:&#x2F;&#x2F;deno.bundlejs.com&#x2F;badge?q=nuejs-core@0.1.0&treeshake... - it is nowhere close to 2.3KB as on your website. Compare it to petite-vue&#x27;s bundle, which is only 7.3KB: https:&#x2F;&#x2F;deno.bundlejs.com&#x2F;badge?q=petite-vue@0.4.1 reply ilrwbwrkhv 6 hours agoprevThis is fantastic. As much as the web changes and people complain about \"new frameworks\" everyday, all the major frameworks are surprisingly similar.Rethinking things from the ground up and making it smaller and more RAM efficient, is absolutely brilliant.More frontend devs needs to stop following the herd and think for themselves and look back at how hackers used to work back in the day to use as little memory as possible.These days I look at apps like Slack and feel such terrible sadness and despair.Projects like Nue at least have the right spirit and attitude. reply tipiirai 6 hours agoparentThis. So glad to see there are still people who care about minimalism! I asked here on HN the other day that \"why your login screen loads 6.4MB of resources\" and they said that VSCode is ~200MB and gdocs is ~30MB so it&#x27;s not that bad. That&#x27;s the spirit these days.I want to make things very, very differently. Not just because of the size, but maintaining a codebase with 5k lines is so much easier than maintaining 500k lines. reply davedx 3 hours agorootparentThe problem is more in the ecosystem side than the core libraries side. Many front end devs build UIs for a day job and when they’re developing some new product requirement they don’t think twice before pulling in react-widget, react-ui-this, react-router, react-accordian. This is the main issue that creates bundle bloat and maintenance pain down the line.I don’t know what the solution is there. reply zelphirkalt 3 hours agorootparentBetter education or being more informed would help. Knowing the basics well, like HTML and CSS, to already avoid some of the JS. Then knowing a backend language can help with actually considering simply rendering templates on the server using some template engine, like done for decades. Some knowledge about setting up a HTTP server would probably also help. Knowledge would help being able to take a step back when needed and think: \"Do I actually need much interactivity here?\"Question is how we get web developers to learn those, instead of the next (ha) hyped JS frontend frameword. reply gcau 5 hours agoprevHere is what some of it looks like.```{ title } { desc } { desc }Thatshould be a , I think. reply tipiirai 5 hours agoparentprevYes. Nue is indeed HTML-based and takes inspiration from Vue. It is designed for UX developers who prefer to use HTML&#x2F;CSS and minimal JavaScript to communicate with the business model layer, that the JS developers are building. That is: separation of concerns.I can understand that this syntax is not a preference for JavaScript&#x2F;TypeScript developers who opt to JSX and want to write everything (logic, layout, styling) in JavaScript. reply orangepanda 1 hour agoparentprevMy problem with these :ifs and v-ifs and {#ifs} is I cant place a breakpoint and step through _my_ code with a debugger. reply zarzavat 2 hours agoprevThank for for sticking up for external stylesheets.When I was starting out with HTML, inline styles were considered to be a hack, and the goal of writing good HTML was to separate the data from the presentation as completely as possible. It seems that nowadays people place more emphasis on encapsulation rather than separation, they want their style to live with the component. Separation and encapsulation are in opposition: vertical vs horizontal architecture of code.Personally I prefer separation. While components are a good way to divide up functionality, when it comes to presentation users are perceiving the UI of your entire website, not the individual UIs of each component. Separating the style into a stylesheet gives you global control over presentation and makes you more aligned with how the user is perceiving things. reply jacobsimon 41 minutes agoparentThis is a really good observation. If I can add on, I feel like a lot of the disagreements in modern front end development boil down to this: Some people actually like developing with HTML&#x2F;CSS, and other people see it as an implementation detail and would rather abstract it away with JavaScript.People in the first camp tend to like Vue, CSS&#x2F;Sass, Htmx, server rendering, etc.People in the second camp like React and React Native, CSS-in-JS, Tailwind, etc. reply moritzwarhier 32 minutes agorootparentI don&#x27;t agree with that separation. I feel that e.g. Tailwind appeals a lot to developers of templates for e.g. Laravel.And I like to be an expert in HTML+CSS (at least I try), and still prefer JSX to e.g. Vue&#x27;s template syntax. reply shrimpx 53 minutes agoparentprevSeparation also has drawbacks. You have to go to open a different file and search for things by ID or class name. It’s like aspect oriented programming. reply niutech 45 minutes agorootparentIn almost every IDE you can open two files in a split view and you can ctrl-click on an ID to go to the definition. reply Kiro 14 minutes agorootparentThat&#x27;s not good enough. I want to look at a tag and immediately see how it&#x27;s styled. No cascading or hidden&#x2F;indirect styling. It should be all there, completely isolated from the rest. In fact, I should be able to copy&#x2F;paste just the HTML (or component) into a completely different application and it should remain exactly the same. reply tipiirai 3 hours agoprevHey fellow devs. I&#x27;m heading to Finnish forrest to practise disc golf. Will answer to all the critical questions later this evening. I&#x27;m so happy this launch went well and I&#x27;m super motivated to build a great, minimalistic frontend toolchain that is closer to web standards. reply kunley 2 hours agoparentAs a non-Suomi guy who ended up living in Finland part-time, I can relate so much. Enjoy the forest! reply benatkin 7 hours agoprevSvelte is mentioned on the site but not in here. Is it harder to put Nue, or another framework, forward as an alternative to Svelte&#x2F;SvelteKit? I think SvelteKit is batteries-included while still being fairly small and easy to understand. reply tipiirai 6 hours agoparentSvelte is indeed a bit different to how the internals are implemented and what kind of compilation results are created. However it is a component-based UI framework and they also compare themselves to React a lot. When Nue ecosystem is completed, it can be compared to Nuekit. reply benatkin 5 hours agorootparentWell, I like Svelte, and so far I don&#x27;t want to write code in Nue, based on the examples. The last I looked on HN there were 67 upvotes and 34 comments. That&#x27;s less than double the number of upvotes to comments. I think it&#x27;s being ratioed not because people dislike the attempt at writing a web framework with a different syntax, but because the site and the text claim it&#x27;s competitive with all these frameworks. reply robertlagrant 1 hour agorootparentI think \"ratioed\" is a pretty weak signal in general, and especially here. At least compared upvotes to commenters, not comments. reply tipiirai 5 hours agorootparentprevIt&#x27;s me replying to everything in here :) reply rk06 4 hours agoprevI get why you want to replace vue&#x2F;react&#x2F;next&#x2F;nuxt, but why vite?Are you really planning to create a new build tool? reply tipiirai 4 hours agoparentNot a build tool, but rather a web application builder with support for multi-page applications (aka. websites) and single-page applications. Vite is (mostly) a SPA application builder so that&#x27;s why it is mentioned. reply josephernest 3 hours agoprevVery promising!Would it be possible to use your framework with any server of my choice (Python or Node or even PHP), and use Nue only for the frontend?In this case, since it&#x27;s just JS + HTML + CSS, can we have an \"Option #3\" in https:&#x2F;&#x2F;nuejs.org&#x2F;docs&#x2F;nuejs&#x2F;getting-started.html with no command-line, no `npm install`, no `npm run start`, no use of `npm` at all?It would be nice to have a Hello world example with just a HTM file + import of Nue from your CDN (or from local). Is that possible?I&#x27;d like to totally avoid npm, etc, just write JS + HTML + CSS, and use my own server. reply niutech 1 hour agoparent+1 for a zero-build-step bundle. As an alternative you can use Petite Vue, which is even smaller. reply omnimus 2 hours agoparentprevNot possible without buildstep. Use something like alpinejs reply CSSer 7 hours agoprevWould you mind sharing some details about how you made this? https:&#x2F;&#x2F;nuejs.org&#x2F;compare&#x2F;component.htmlIt’s very cool. I’m on my phone, but I’d like to investigate more later. reply cornedor 3 hours agoparentThis is done using css columns. The slider controls the font sizes, and the column width is set to 30em, which increases when the font size increases. reply tipiirai 7 hours agoparentprevThanks! It&#x27;s a custom made script to generate a HTML page with `pre` blocks to render the source code on a file. Then a Nue-based zooming app on top of it. The images on the site are screenshots from this app. reply wruza 4 hours agoprevListBox&#x2F;PopupButton … The React version is 2500 lines of JavaScriptIs this idiomatic? I refused to use React for years, but if this is normal-ish, it basically cements the decision. An implementation of a ListBox in VGA 0xA0000 framebuffer could be only a little bigger (if even bigger). GtkTreeView, which draws a complete tree&#x2F;table with columns, resizing, dynamic rows and all the interactions, was 10kloc, afair (now 14). GtkCombobox.c is 5kloc, almost half of that is comments or doxygen. reply Loeffelmann 2 hours agoparentThe listbox does a lot like searching, multiselect, is completely accessible and includes a lot of types. It&#x27;s a really unfair comparison. reply xigoi 18 minutes agorootparentEven with all those features, 2500 lines sounds like way too much. reply wruza 23 minutes agorootparentprevDo you mean my comparison to gtk, or on-site comparison to nue? reply cornedor 3 hours agoprevThe comparison on the homepage is not even close to fair. They compare a React component from a headless UI library that has a lot of (accessibility) features and full TypeScript typing to a basic version without any typing.> The amount of code required to build a basic listbox UI componentThat is not what is being compared.The speed graph shows the amount of HTML&#x2F;CSS&#x2F;JS on the project home page. Again not even close to a fair comparison, they have completely different content. I can create a sluggish library, with a homepage that is just a plain text link to a GitHub repo and that would rank way higher. reply jampekka 38 minutes agoparentIsn&#x27;t basic version without any typing being shorter and clearer a fair comparison of JS against TS? reply aziis98 2 hours agoprevAwesome project, feels very refreshing even for me being a great fan of Vite and Astro.Just curious, how do you handle the client side reactivity? Does it use something like virtual dom with diffing or do you compile everything like Svelte (or even some other strategy)? reply canadiantim 53 minutes agoprevAs someone who wants to use the minimal amount of JavaScript, are there graceful fallbacks for when JavaScript is disabled? reply KRAKRISMOTT 2 hours agoprevDoes your SSR support component level network and caching optimization (i.e. streaming in an island architecture configuration)? That is the current state of the art for JavaScript single page app server side rendering. reply amilner42 3 hours agoprevCool ideas, took a brief look but I’ll need to dig in when I’m at my computer.On a sidenote, I was startled by the tailwind mention. Am I out of the loop? Is it not just some css classes? Why is it being compared to React? I’ve used tailwind casually a few times and dont remember it increasing my build size very much at all. reply tipiirai 3 hours agoparentPlease check the original post. This is a launch of the first item (Nue JS) in a new, uccoming frontend development ecosystem. One part of the ecosystem is a project called \"Nue CSS\", which aims to bring developers back to more standards based CSS development and it emphasizes that separation of concerns is a good thing (and not a bad thing as TW states). reply pier25 7 hours agoprevCongrats looks great. Can&#x27;t wait to see the whole vision with Nuekit.Not a fan of the Vue template syntax but it&#x27;s not a deal breaker.I really love that you don&#x27;t need a bundler. reply tipiirai 7 hours agoparentThank you! I&#x27;m glad this initial launch got some traction so I&#x27;m absolutely going to cross the finishing line. The ecosystem code is actually done and the website is made with Nuekit. Need to polish the code, rewrite some pieces, and document everything — which is the time consuming part. reply meowtimemania 4 hours agoparentprev+1 on not requiring a bundler. It makes it so much easier to try out on just 1 or 2 pages when you don’t have to also add a compiler. reply tipiirai 4 hours agorootparentExactly. And bundlers are quite big monsters. Vite, for example is 32MB on disk. reply Kiro 3 hours agoprevI&#x27;m missing the classic example where you click a button to increment a value. In fact, I fail to find any example handling state at all. Any pointers? reply niyaven 1 hour agoparentThe closest I could find was a carousel[1], since clicking on a button will increment&#x2F;decrement an index. I agree that the classic examples are missing. I would have like a simple counter and a TodoMVC.[1] https:&#x2F;&#x2F;nuejs.org&#x2F;docs&#x2F;nuejs&#x2F;reactive-components.html reply quickthrower2 1 hour agoprevWhen do I reach for this instead of AlpineJS or HTMX? When the team is bigger? reply niutech 49 minutes agoparentHTMX is for AJAX-driven web apps, rather _hyperscript is closer to Nue. There is also Petite Vue which is similar to Nue and does not require a build step. reply theogravity 6 hours agoprevCongrats on the launch! Looks really interesting. I&#x27;m looking through the documentation and am having trouble understanding the slots example:https:&#x2F;&#x2F;nuejs.org&#x2F;docs&#x2F;nuejs&#x2F;component-basics.html#slotsI&#x27;m unable to see the relationship between thetag and the looped content in the 2nd code snippet. Can you clarify that in the documentation?Edit: I think it would have made more sense if you included the @name=\"media-object\" attribute in the first snippet. reply tipiirai 6 hours agoparentThank you! The slot syntax is borrowed from Vue. The difference is that there can be only one slot, and not multiple named slots.I can see that the slots example needs improvement and more detail. I&#x27;ll make it shine because slot is such an important feature and helps you build reusable code.I&#x27;ll work on the docs as a whole, now that I&#x27;m getting this valuable feedback from here. reply tinco 3 hours agorootparentEvery slot system I&#x27;ve ever seen eventually implemented multiple named slots. Often after first only supporting one slot, then multiple unnamed slot and then finally the whole shebang.Why go through that whole progress again with Nue? Or do you foresee some other way of doing highly customizable components? reply SparkyMcUnicorn 6 hours agoparentprevIt appears to be similar to Vue. The first snippet is thecomponent, and the second snippet is using the component. Everything inside the component tag goes into the slot. reply theogravity 6 hours agorootparentI&#x27;m from a non-vue audience, so the context would be lost on someone like me. reply tipiirai 5 hours agorootparentCan you clarify? Not sure I understand what you mean. reply eh8 3 hours agoprevIt&#x27;s really awesome to see this recent counter-revolution of developer tools emphasizing simplicity. Nue gives me the same optimistic, feel-good vibe that htmx and Alpine.js gave me when I first read about them.Best of luck, wishing the author all the best! reply tipiirai 3 hours agoparentThank you!! This means a lot actually and gives me motivation to implement everything on the roadmap. reply beefman 4 hours agoprevKudos for the emphasis on code size – this is something I always liked about Riot. But the comparison faq currently returns a 404https:&#x2F;&#x2F;nuejs.org&#x2F;compare&#x2F;faq&#x2F; reply tipiirai 4 hours agoparentThanks! I fixed the links. Here is the correct one: https:&#x2F;&#x2F;nuejs.org&#x2F;compare&#x2F;faq.html reply beefman 1 hour agorootparentDo you have a RealWorld implementation?https:&#x2F;&#x2F;codebase.show&#x2F;projects&#x2F;realworldhttps:&#x2F;&#x2F;medium.com&#x2F;dailyjs&#x2F;a-realworld-comparison-of-front-e... reply Alifatisk 43 minutes agoprevHow does it perform compare to Qwikjs and Vue? reply siduck 3 hours agoprevare there any plans for making the state management exportable? in react state&#x27;s bound to the component, but in solid-js we can define it outside the component and export it, and components from other files can easily use it :Dlikeexport const [counter, setCounter] = createSignal(0)you can probably look at js proxies reply siduck 3 hours agoprevwhat would be nue-css? i really like unocss currently as its syntax&#x27;s pretty cleanlike instead of tailwind&#x27;s alsotoo, it supports value-less attributes and one can use a single class name as tag name too, likesomethingreply tipiirai 3 hours agoparentNue CSS is like SASS, but more minimal and more in line with the current standards. Think CSS variables instead of template variables. It&#x27;s pretty vocal about semantic CSS and separation of concerns once it&#x27;s public. The main thing is to give a strong alternative to the current css-in-js movement. Haven&#x27;t checked Uno CSS in detail, but looks like it&#x27;s a close companion to Tailwind. Nue is a big step away from tight coupling. reply kunley 3 hours agoprevMoi Tero!At a first glance I like it a lot. With regard to the \"Why\" section and the FAQ - kudos for the bold claims, that was needed. Typical frontend ecosystem went insane long time ago. Thanks for your effort to bring back the sanity. reply madmod 7 hours agoprevThis looks great! Reminds me of crank.js in that it leverages native language features (generators) to greatly simplify interactive html.Please add a mailing list to the homepage so I can keep up to date with your progress. A blog with smaller updates would be nice also. reply tipiirai 7 hours agoparentThank you! Good idea. I&#x27;ll add blog + mailing list. I have a lot on my mind! (lol) Before that you can follow Nue on Github and notifications from there: https:&#x2F;&#x2F;github.com&#x2F;nuejs reply oooyay 7 hours agoprevHow does cross-component state work? I&#x27;m thinking something like Pinia in the Vue ecosystem. You might&#x27;ve mentioned it on the site but I couldn&#x27;t find anything about it. reply tipiirai 5 hours agoparentState manager &#x2F; Router is on the roadmap. Check \"Nue MVC\" from https:&#x2F;&#x2F;nuejs.org&#x2F;ecosystem&#x2F; reply MrJohz 3 hours agoprevI really like the idea of a framework designed from first principles around the idea of islands and progressive enhancement. That said, this feels like a lot of potential misleading marketing.Firstly, I don&#x27;t think the comparisons with React&#x2F;Vue are hugely helpful for Nue. React and Vue do a lot. You&#x27;re right that most people probably don&#x27;t need all of that stuff, but it is in the frameworks for a reason - those who need it really do need the complexity.Some better points of comparison in terms of compile-to-JS frameworks might be Svelte and SolidJS, both of which have some similar goals to this, and specifically focus on producing small, fast code. Alternatively, if you want the \"it&#x27;s just Javascript\" approach, Mithril is another great framework oriented around minimising complexity, albeit with a reactivity model more like React&#x27;s.I also think the specific code comparisons scattered around the site are similarly unhelpful. For example, you typically use Typescript-based examples for other frameworks, and JS-based examples for your own. This is obviously going to make Nue look smaller, but typically people use Typescript for good reason, and understand the trade-off around code size. More egregiously, many of the comparisons seem very much apples-to-oranges comparisons. For example, the React listbox on the homepage is a part of Headless UI - it meant to be as unopinionated as possible and allow the user of the component to bring their own components, styles, etc. This makes it more complex but more powerful - a trade-off that isn&#x27;t always worth making, but can be very useful for these sorts of components where 90% of the complexity is getting the UI interactions right. Your example is not headless, I don&#x27;t think it&#x27;s even styleable, and while it includes keyboard navigation, the lack of aria tags makes me doubt its accessibility. That doesn&#x27;t mean it&#x27;s bad - it looks like the sort of component I&#x27;d write as a custom component for a particular project - but it makes the comparison somewhat meaningless. I would imagine any component I wrote in most frameworks I use would be a similar order of magnitude in size.(In fairness, I&#x27;ve just seen you call both of these points out in your compare FAQ. I disagree with your answers though - a framework&#x27;s choice to use Typescript internally does not affect the choices of users to write components in Typescript, so \"embracing dynamic typing\" feels meaningless in this context. Moreover, it&#x27;s not apples-to-apples if the components themselves are designed with different purposes - a quick React listbox could look a lot simpler if it needed to.)More practically, I think it would be really helpful if you talked about rendering model more clearly. As a frontend developer, this is one of the first questions I have when looking at a new framework. Is reactivity sound, or am I going to have to spend a week trying to figure out why some variable isn&#x27;t updating when I think it should be? It looks like the Svelte-style compile-to-DOM-mutations approach, is that right?I have some other more philosophical quibbles with some of the claims in the documentation and FAQ, but I don&#x27;t think those are so important. But I do think they you could improve the sales pitch a lot by making the underlying technologies clearer, and by having more useful points of comparison.As an aside, do you have an entry on the Krausest framework benchmark yet? It may be worth submitting a PR there. Obviously pure framework speed isn&#x27;t everything, but it&#x27;s a useful point of comparison to see how one might approach the same problem in different frameworks, particularly a fairly intensive problem. reply theN00t 3 hours agoprevI was an avid user of Riot back in the days and loved the small library. I will take a look at this when I have the time :) reply demondemidi 6 hours agoprevDo you plan to support this for 5 years or more? Because that&#x27;s the kind of LTS I need to take this seriously. reply abdellah123 6 hours agoparentRead the source, it&#x27;s a few hundred lines of code. It&#x27;s very much possible to treat is as your own app code and \"maintain\" it.Kudos to the author, the best thing about this is that the source is concise!! reply da39a3ee 2 hours agorootparentI disagree that vendoring &#x2F; forking a 3rd party library is a good idea. reply tipiirai 5 hours agoparentprevI plan to develop this as long as there are people using it. If the world changes and a new jQuery comes around, then I have to see how to adapt. But the goal is to stabilize the code and make it production ready. Same for all project on the Ecosystem. By looking at todays traction, I&#x27;m highly motivated to continue with this project. I&#x27;m working full-time actually because I don&#x27;t have a day job atm. I like it. reply ash 9 hours agoprevHello Tero! Do you have project example using Nue (however small)? reply tipiirai 9 hours agoparentHey! You can clone and play with this: https:&#x2F;&#x2F;github.com&#x2F;nuejs&#x2F;create-nue — it showcases Nue JS, which is currently the only thing completed from the Nue Ecosystem. The only real Nue project atm is the nuejs.org website. reply _d3Xt3r_ 7 hours agorootparentNoob here, but also a former web dev from the Web 1.0 days, looking to get back into the game.Like you, I dislike much of the modern web frameworks and all the bloat and unnecessary complexities that come with it. I roughly tuned out of this stuff when JQuery became mainstream and everyone and everything started using it, and I couldn&#x27;t be bothered to keep up any more, nor did I feel inclined to invest my time in such a bloated framework. I did come back to webdev every now and then for casual projects, but every time I did, the world moved from one fad framework to the other, which made me dislike this messy ecosystem even more.In particular, one environment&#x2F;toolset that I really disliked was Node.js. Every time I did anything with Node, it always turned into pulling down a gazillion dependencies, and eventually down the line, that led to stuff breaking because some random dependency of a dependency was no longer compatible a with newer version of node or something. It basically put me off modern webdev for good, to the extent that I web back to using plain ol&#x27; php for the backend, and since then I&#x27;ve been exploring using pure HTML5+CSS3 without any Javascript for the frontend, but I&#x27;ve been seeing limitations like not being able to do stuff like real-time form validation etc.Which brings me to your example: # install dependencies npm installMay I enquire why you&#x27;re using npm here? Exactly what dependences are you pulling down? I thought the whole point of Nue was to avoid bloat like Node.js and dependency hell? Isn&#x27;t Nue supposed to be a self-contained library&#x2F;ecosystem?Can I use Nue without touching any Node stuff at all? reply tipiirai 6 hours agorootparentI hear you! I went all-in to jQuery- scene. Even wrote a semi-famous library called \"jQuery Tools\" (oldies know). Then came React and I wrote Riot to simplify the syntax. Then I sidetracked to a startup world for (too) many years and watched aside how the frontend ecosystem grew to it&#x27;s current dimensions.Node uses a single dependency, htmlparser2 [1], in the package.json [2]. The HTML parser is used to traverse the HTML that is written on the Nue files. I quickly _thought_ of writing my own parser, but right now I&#x27;m having my eyes staring at Bun&#x27;s native HTML parsing capabilities. Instead of Node, I&#x27;m using Bun to develop everything. I need less dependencies with it, because things like JS minification or .env file parsing are biult in.Avoiding NPM dependencies is a high priority![1]: https:&#x2F;&#x2F;github.com&#x2F;fb55&#x2F;htmlparser2[2]: https:&#x2F;&#x2F;github.com&#x2F;nuejs&#x2F;nuejs&#x2F;blob&#x2F;master&#x2F;package.json#L12[3]: https:&#x2F;&#x2F;github.com&#x2F;oven-sh&#x2F;bun&#x2F;discussions&#x2F;1522 reply naasking 6 hours agorootparentprevSounds like you might be interested in htmx. Lots of client dynamism, easy integration with backends and you don&#x27;t need to write any JavaScript. reply tipiirai 5 hours agorootparentI&#x27;ve been looking at HTMX. It&#x27;s good for HTML&#x2F;CSS&#x2F;UX developers to add dynamic pieces to a multi-page application. However, It&#x27;s quite different from what Nue attempts to be. Nue is meant for building both dynamic islands and full blown web applications. It&#x27;s just targeted for UX developers and the JS developers can shift their focus more to the \"back of the frontend\" [1]. Ultimately Nue is going to be a complete frontend ecosystem and alternative to tools like Vite and Next.[1]: https:&#x2F;&#x2F;bradfrost.com&#x2F;blog&#x2F;post&#x2F;front-of-the-front-end-and-b... replyhknmtt 5 hours agoprevNew day, new JavaScript framework...what&#x27;s new? Anyway, I highly recommend Quasar if anyone&#x27;s looking for something new to use. Been using it for two years now and after 20 years of coding I felt happy using JS. Not that Vue is not good but quasar just has it all and is built on top of Vue. reply tipiirai 4 hours agoparentThanks for the pointer. Quasar seems more like an UI library. Like Material UI or Chakra. Not directly comparable with Nue JS. It&#x27;s comparable with the upcoming Nue UI though: https:&#x2F;&#x2F;nuejs.org&#x2F;ecosystem&#x2F; reply thatxliner 6 hours agoprevHow does it compare to Svelte? reply tipiirai 6 hours agoparentThe syntax is HTML- based, strong preference to separate styling&#x2F;logic from the UI code, and keep it familiar with UX developers [1] (not JS developers), there is no need for Bundlers like Webpack or Vite, and it&#x27;s written in more minimalistic fashion. Your app is probably smaller too if it&#x27;s anything more complex than a TODO- app, because Nue is only 2.3gzipped and the compiled files are very small too.[1]: https:&#x2F;&#x2F;css-tricks.com&#x2F;the-great-divide&#x2F; reply todotask 1 hour agoprevCurious if you are targeting at an extreme performance, your site still need to inline CSS on every page? reply jwmoz 1 hour agoprevAnother day another js framework. reply quickthrower2 1 hour agoparentFeels like a welcome relief from a new LLM adjacent thing. reply nsonha 52 minutes agorootparentno, the LLM is breaking new grounds everyday. FE frameworks are... doing templating in another syntax? Cool!!! reply sfc32 1 hour agoprevAnother FE framework (sigh) reply Aleksdev 5 hours agoprevLooks neat! Will keep an eye on it. reply xyst 5 hours agoprevhttps:&#x2F;&#x2F;xkcd.com&#x2F;927&#x2F; reply tipiirai 5 hours agoparentNue does not try to be a new starndard. It tries to bring web developers closer to web standards: HTML, CSS, DOM, and plain JavaScript. New developers today start with React, learn hooks, adopt Tailwind, and writes TypeScript and distance themselves from the basics. reply Aeolun 2 hours agorootparent> distance themselves from the basicsIt’s almost as if there’s a reason for this.Classic HTML is pretty good for building static websites, but it sucks for building interactive applications. reply siduck 4 hours agoprevwould be great to use bun with this! reply tipiirai 3 hours agoparentBun is really awesome! I&#x27;m using it to develop Nue. It runs the minimalistic code in instant. Everything is sooo fast and pleasant. Test suites finish as soon as I release the Enter key. reply lolinder 6 hours agoprevYour comparison of the various ListBox implementations[0] feels disingenuous. I know Vue best, so I looked at that implementation in detail, and it&#x27;s got a lot going on that you don&#x27;t attempt to replicate in your version. A few key features that are missing:* Search—in the Headless UI version there are several hundred lines dedicated to making typing work for jumping to specific list items.* Multiselect—Headless UI supports multiple selections, yours does not appear to. Again, this accounts for a large number of extra lines in the Vue implementation.* Focus management—Headless UI has a lot of code dedicated to smoothing out the focus management. In my testing, your implementation has pretty buggy support for using tab to navigate.* The Headless UI version dedicates a lot of lines to types, where your Nue implementation is dynamically typed. This may be a feature for you, but in my mind those type declarations are doing important work.* In general, the Headless UI implementation tries to be flexible for many use cases [1], while yours only needs to support the one demo list.These kinds of comparisons are most persuasive if you can write all the implementations from the ground up, using idiomatic patterns for each framework and identical feature sets for each implementation. When you do that, it&#x27;s easy to compare and contrast the frameworks. As it is, it&#x27;s like comparing a house to a garden shed: yes, you&#x27;ve used fewer lines of code, but it&#x27;s not obvious to me that that&#x27;s a feature of Nue and not just a byproduct of a less ambitious component.[0] https:&#x2F;&#x2F;nuejs.org&#x2F;compare&#x2F;component.html[1] https:&#x2F;&#x2F;headlessui.com&#x2F;vue&#x2F;listbox#component-api reply SebastianKra 3 hours agoparentI wouldn&#x27;t just call this disingenuous, I would call it lying. He&#x27;s claiming that his barely usable, non aria-compliant listbox with a fraction of the functionality, is equivalent to the work of the headless-ui team.If the reader wonders where these lines were saved, they will only find broad, general statements about (IMO questionable) values. Compare this to some other frameworks, where the changes from the status quo are clear on the landing page:- Svelte -> compile step, templating, common features included- Solid -> signals, constructor functions- Lit -> web-components, fewer featuresIt is unfortunately common for new frontend solutions to not be as up-front about their trade-offs as I would like. But this takes the cake for most requirements swept under the rug. reply tipiirai 6 hours agoparentprevI agree it&#x27;s unfair at the moment. I&#x27;ll change the example to be more apples-in-apples. I&#x27;m going to write a more detailed comparison articles for each framework. Point taken! Thanks.Ultimately Nue will come out with a UI library with a high feature parity with Headless UI. I can imagine the current listbox (demo) doubling it&#x27;s size with all the above features. Definitely not 10x! reply ilrwbwrkhv 6 hours agorootparent> Ultimately Nue will come out with a UI library with a high feature parity with Headless UI.This will actually be a killer addition. I was actually complaining about this the other day: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37448914#37449926 reply tipiirai 5 hours agorootparentNice. Thanks for the encouragement! reply chrismorgan 3 hours agoparentprevIn my opinion it’s far worse than this: it’s not just a considerably less ambitious component, it’s a component currently completely unfit for any purpose. Most significantly, it’s inaccessible due to semantic abuse and missing ARIA support (role=listbox, aria-controls, aria-expanded, aria-selected, &c. &c.). Even as a sighted user that doesn’t need to use accessibility tech (AT; screen readers are the best known example), I would hate to encounter a page using this, because it misses valuable functionality like type-ahead. Users that depend on AT will be left high and dry, presented with just a read-only text box and no idea what to do with it.All up, it’s just like so many others, a bad reimplementation of half of what the browser already provides with . About the only thing it adds to that is support for an image per option, and perhaps some more exotic styling aspects (which you hopefully don’t want anyway).Mind you, I do find Headless UI generally bloated, mostly just suffering from being overly flexible, and it does end up with a moderate amount of code bloat attributable to the particular frameworks’ designs (though not as much as some I’ve seen), but the comparison is just unreasonable. If they think it’s fair to say “With React: 2.5k lines; with Nue: 200 lines”, then I respond: “With HTML: 0 lines”, and insist thatis better than the result of those 200 lines.There are more problems with it, too, whereas I suppose Headless UI will be a pretty high-quality implementation. Examples of problems I found immediately, without having tried to actually run it, but which I presume Headless UI will be free of: it usesfor the options and wraps each option’s label with , which are both semantic sins; some of the code sharing with combo boxes leads to obvious minor inefficiency (filtering, which can’t actually happen); Escape detection happens on keyup instead of keydown; clicking outside the listbox popup won’t close it if the target or an ancestor matches .open, which is very plausible, e.g. when within a modal dialog (and because it’s ad hoc, it’s certain to interact badly with things like clicking outside modals—any concept of potentially-nestable modality needs to be managed more than that, in one of a few ways but I’ve already rambled enough); after pressing Escape to close the popup, pressing Tab will reopen it as well as moving to the next focusable.Hopefully the problems with this will be sorted out, but at present I think it’d be best to just remove the comparison, because it portrays a false picture, and suggests that the listbox is ready for use, whereas I hope that the author would agree it’s not. reply tipiirai 3 hours agorootparentTotally agree with \"HTML: 0 lines\" is the best pick in most, if not all situations. For example the Headless UI radio group component [1], can be implemented with just HTML and CSS — and they made it a huge JS component.[1]: https:&#x2F;&#x2F;headlessui.com&#x2F;react&#x2F;radio-group reply 420official 6 hours agoparentprevIt also seems a little disingenuous to suggest tailwindcss requires 800kb to build a webpage reply tipiirai 6 hours agorootparentIs there such suggestion? I merely counted the amount of HTML&#x2F;CSS&#x2F;JS tailwindcss.com has on their frontpage and put it in a comparison chart. They key take there is that inlining styles to markup and loadinng the utility CSS makes it hard to keep the initial TCP packet below 14kb, which is a limit for extremely fast loading performance. reply 420official 5 hours agorootparentThe nuance you provide here is missing from the site. Your chart says only this (maybe I&#x27;m missing your explanation somewhere?):> Amount of code needed for a rich, interactive web page.And lists \"Tailwind CSS\" as 804k.As a reminder, Tailwind CSS doesn&#x27;t require or use JS in the browser at all and the majority of tailwind gets removed during build so the vast majority of the code you&#x27;re attributing to Tailwind CSS is unrelated to the task of using Tailwind to build a rich interactive webpage.To your point about inlining styles, using Tailwind out of the box I struggle to see how you&#x27;re forced above 14kb, and if you really had kilobytes of classes in your markup you can switch to composing your own rules with @apply.I recognize you are making a tool and not trying to do ecosystem wide benchmarks, but still suggesting you need 804kb to use Tailwind still seems disingenuous, or at least misinformed, to me. reply tipiirai 5 hours agorootparentI changed the wording to \"Amount of HTML&#x2F;CSS&#x2F;JS on the project home page\" on the front page. Thanks for the heads up. reply 420official 3 hours agorootparentThat makes it a lot more clear, thank you! reply PennRobotics 2 hours agorootparentprevIt seems to me---and maybe my intuition is wrong---you WILL have more bandwidth usage loading ... ... ... ... ... ......... ...... vs:... ... ... ... ... Sure, the CSS in the second case will be larger, but that one file gets cached for the remainder of the visit, whereas every asynchronously loadedin the first case is gonna be 3.8 KB. An inventory with 3,176 items will take 12.2 MB to fully load WITHOUT product descriptions e.g. user decides to search empty string and scroll all the way to the bottom. (These numbers are rather exact because I picked a random, well-known, segment-specific shop---not cherry-picked, just the first one I thought of.)Maybe someone at this large, segment leading company carefully considered that they should have 12 different srcset pictures because \"responsive\" and \"bandwidth\", but I doubt it because the URLs violate DRY and have escaped characters in the query part and the URL indicates this brand doesn&#x27;t host static content on their own server (as in, they&#x27;ve hired someone else and have non-technical employees log in to a CMS and upload&#x2F;update everything).More realistically, the company that creates these websites imports a framework that has already considered that 2.3% of users are using Edge, 3.8% are using Safari, 0.4% are using Opera on Mobile, 0.2% are using Kiwi on Mobile, 0.8% have disabled Javascript, etc. and then decide they absolutely MUST have everything display as-desired on all platforms rather than excluding the most unusual or ancient user agents that represent far less than one percent of sales. I mean, who&#x27;s going to leave if your site loads a little slow (but like all the others)? Who leaves if it loads \"not at all\"?I see everyone from blogs to clothing stores slapping in a dozen minimized JS frameworks, fonts, reams of generated CSS, ElasticSearch, jQuery, images scaled or loaded improperly, cookie cutter UI elements and giant rounded corners and then some having the nerve to link to a \"How awesome is our site?\" survey (aka another nugget of JS) where I feel obliged to reply \"Your front page takes 8.5 seconds to load on current stable Firefox, has 30 warnings and an error... How do YOU think you did?\"While I&#x27;m no web specialist, it seems you could even have a lightweight front page that has a small or even inline stylesheet while the sitewide CSS is loaded asynchronously (cached) after the front page is presented, so the first thing visitor sees is a quick loading page, the 2 to 4 second load happens in the background, they click a link, BOOM next page loads in its full-featured, one-or-two-human-readable-class-per-element glory with the Sneaky Load Giant CSS as an already-cached dependency.I&#x27;ve also seen much worse violations than my example: divs within divs 20 deep, 15+ clvrly-abrvd-cls per div, because someone decided it&#x27;s easier as a dev to have \"flex flex-col-reverse lg:flex-row items-center justify-center mt-20 mb-32 md:mb-40\" outside of every paragraph (instead of a single, well-defined paragraph class that could even inherit common custom properties) or better yet, (I&#x27;m sorry if you see that I called out a snippet of your blog here, but that last example belongs to a Next.JS&#x2F;TailwindCSS advocate, and it&#x27;s like he took the ideas of the coinventors of CSS and then went full Second City improv, \"yes, AND!\") replymontroser 1 hour agoprevIt&#x27;s a little bit of a stretch to call this \"reactive\":> The component re-renders itself automatically after calling an event handler, but you need to call this manually if there is no clear interaction to be detected.It is a creative approach to shed reactivity and just re-render after calling an event handler, and in some applications it can even be preferable to manage your own updates. But generally this seems like it will be rough and not enough in practice.For very simple apps it might just work, but in rich interactive settings, it happens all the time that the whole point of interacting with one component is to affect the content in other components on the page. In those cases it can be a slog with this approach for the developer to have to manually keep track of which components need to be updated and traverse through and call update() in all the right places. reply nine_k 1 hour agoparentA truly reactive Preact [1] is merely 3 kb of JS.OTOH the need for really simple bits of interactivity does occur in real life. If the htmx [2] approach does not cu it, a micro-library like this could.[1]: https:&#x2F;&#x2F;preactjs.com&#x2F;[2]: https:&#x2F;&#x2F;htmx.org&#x2F; reply idkwhoiam 1 hour agoprevIt&#x27;s an interesting project but the website is full of statements that range from strange to downright false. 1. The comparison to React&#x27;s ListBox is unfair until you reach feature parity. 2. The \"nue levels of speed\" makes it look like Nue the tool beats the hell out of the competition but then in small text it says it&#x27;s a comparison of the project home pages. Why would anyone care about the size of the project home page? 3. The whole section on Tailwind in the FAQ is just false. reply iainmerrick 1 hour agoprevI don&#x27;t like everything about this but the website is really good and clear. From the FAQ (https:&#x2F;&#x2F;nuejs.org&#x2F;compare&#x2F;faq.html):How is Nue 10 – 100× smaller? [...] No TypeScript: Nue embraces the dynamic typing in JavaScriptI see the TypeScript backlash is in full swing!I personally think TypeScript is (mostly) great and is the only thing that makes JS development bearable. But it&#x27;s always good to see alternatives. reply gloosx 2 hours agoprev>It&#x27;s like React&#x2F;Vue core, but there are no hooks, effects, props, or other unusual abstractions on your wayI have almost a decade of React experience and to my ear this sounds very weird (starting from React&#x2F;Vue put together casually). For me – React is really 7 hooks that provide usual abstractions and nothing more.EDIT: I just looked through their listbox \"code volume\" comparison and it seems like a bad joke. Obviously meticulously type-scripting anything and exaggerating the code to the absolute will make it look BIGGER when compared to plain js file crafted to make it as thin as possible. I don&#x27;t think it can stand a fair comparison though. reply gloosx 1 hour agoparentFor the author @tipiirai here. A fair and functional challenge: what will be Nue solution for making this beautiful triangle?https:&#x2F;&#x2F;codesandbox.io&#x2F;s&#x2F;pedantic-mclaren-nqpjl5?file=&#x2F;src&#x2F;A...As you can see it is 20 lines of code and zero hooks for React. It also takes a finite time to compute a limit > 2^10 without code sandbox complaining.I wonder how much time Nue needs to render for limit=2^10? 2^100? Then we can compare. reply jamesfisher 2 hours agoprevAfter reading the homepage and the docs homepage, I still don&#x27;t know what it is. What&#x27;s the key API difference that lets you write only 10% compared to React? What&#x27;s the \"hello world\"? reply zooFox 1 hour agoprevHonest question from a back end developer.I have been using Java for a good decade now, and it solves all the business problems. Yes, we had an occasional Go&#x2F;React threat (along JVM-based languages), but I have not seen it coming to a fruition. Java is mature, well supported and understood language that gets regular updates now. Some people don&#x27;t like it, and that&#x27;s okay.What makes JS frameworks so quick to change? Angular, AngularJS, Next, Vue, React, Nue to name the few... What&#x27;s the urge to reinvent rather than evolve? reply peoplefromibiza 1 hour agoparent> What&#x27;s the urge to reinvent rather than evolve?young age of developers (average 25-34 years old.), who usually (not always of course) reinvent the wheel because they don&#x27;t know the past and don&#x27;t understand the tradeoffs.Also, it&#x27;s a way to get attention in this economy of virtue signaling, nobody gives a sh*t if you write a new C++ library that sends rockets into space, it&#x27;s C++, it&#x27;s insecure, you should have used Rust. reply bashtoni 5 hours agoprevI wonder what the rise in AI assistants like Github Copilot will mean for new projects like this?Will people avoid adopting them because code won&#x27;t be auto-generated efficiently?It wouldn&#x27;t be a barrier for me or many people that read hacker news, but I suspect there is a growing subset of the developer community for who this would be an issue. reply professoretc 5 hours agoparentThat&#x27;s what I&#x27;m a bit afraid of. Will software engineering get \"stuck\" with just the tools we have right now, because LLMs won&#x27;t be able to help with anything newer?If you&#x27;re thinking, all we have to do is wait for OpenAI to re-scrape the web and re-train GPT on the new material, well... LLMs don&#x27;t \"learn\" so much by looking at documentation, as by looking at examples. And a new tool is not going to have a lot of examples out there, simply by virtue of being new. reply smokel 3 hours agorootparentAlso, people are already misusing LLMs to generate blog spam, which regurgitates existing knowledge. Future LLMs will have to train on that as well.The \"Selfish Gene\" strikes again. reply imiric 3 hours agoparentprevI can&#x27;t believe I have to say this, but there are still developers who don&#x27;t use AI assistants to program. They write code \"manually\" by reading documentation and reference material, as our ancestors (mostly) did. They might be a dying breed, but they&#x27;re out there.Personally, I&#x27;m waiting for the space to settle, and for an offline, self-hosted and OSS version to reach feature parity with the proprietary SaaS offerings. Those might exist already, I&#x27;m not evaluating the options frequently, but I&#x27;m in no hurry.On-topic: NueJS looks interesting. I&#x27;m very worn out and weary of shiny new JS frameworks, but I like the simplicity here. Will keep an eye on the project and consider it again once it matures, but for now Svelte is my best friend. reply gloosx 42 minutes agorootparentThere are also developers who are better programmers than AI itself, so for them writing code straight away is much easier than thinking about the natural language prompt needed to generate the same code from a non-deterministic statistic machinery. reply m4tthumphrey 2 hours agorootparentprevI haven’t even considered using AI to “help” me code! Is this really that widespread in dev land? Surely not. reply PennRobotics 2 hours agorootparentFor a long time, you&#x27;ve had dropdowns while typing that list possible matches.If you introduce a feature where someone writes int i=0;and the IDE goes, \"Hey dude, probably writing a loop, should I manage that for you?\" and it&#x27;s C++ 17&#x2F;20&#x2F;23 or Rust or Go best practice and looks back a little bit in your code and in its compendium of great project examples to see what the loop logic should&#x2F;could be...I would probably let the IDE write the loop header for me. And the string formatting. And modify the function I&#x27;m writing to support multithreading. And tell me it looks like I was trying to change each instance of pxX to pxY and graphX to graphY but also forgot to change one rotX to rotY.Hell, if the IDE could read a PDF datasheet and automatically import addresses and bitfields and assign them to variable names, much of my current career workflow would be automated and I could focus mental effort on more creative work. reply imiric 1 hour agorootparentNo thanks to all of that. Following that train of thought, most programming could be considered a chore. And to me, it&#x27;s not. I like my tools to get out of my way, and not guess what I&#x27;m _trying_ to do, but let me do what I _want_ to do.Autocomplete is far less intrusive, and doesn&#x27;t fall into this category. I can quickly refine the results since the scope is greatly reduced, and I don&#x27;t have to read a large chunk of code to understand whether it does what I want it to do, or whether it introduces subtle bugs I&#x27;ll have to hunt down later. Besides, we&#x27;ve had code snippets, macros and refactoring tools for decades to help with writing code quickly, so AI tools are not groundbreaking in that sense.Even once AI tools are absolutely correct in guessing my intention, and write entirely bug-free code, I think I&#x27;ll still prefer typing code out manually. By that point, AI will be capable of writing complex programs from prose prompts, so that creative work you mention will also be automated away. Yet human programmers will still exist in some form, if nothing for the joy of it. We&#x27;ll probably value programs written by humans in the same way we value handcrafted tools that are not mass produced today. reply satvikpendem 4 hours agoparentprevYou are assuming the level of LLMs is static. An alternative future is one where LLMs get so good that they can generalize over new patterns and learn Nue themselves to then help you code in it. reply awb 4 hours agoparentprevWhen it becomes easier to have an LLM read website content on the fly, this will hopefully become less of an issue. reply tipiirai 5 hours agoparentprevDepends on whether Nue becomes relevant. New projects are obviously unknown to AI, but they learn as the world starts adopting them. reply Aeolun 2 hours agoprev> The best results are gained when UX developers and JavaScript developers work in parallel without blocking each other.In my experience the best results are gained when they’re the same people. Splitting them up sounds like a recipe for disaster to me. reply mattlondon 2 hours agoprevNice to see that the react approach of mixing html and JavaScript in one file is missing. Hurrah!Please now provide a way avoid the need for npm and we can really start to move away from the dumpster fire that is react + npm. reply 9 hours agoprev[deleted] coldblues 2 hours agoprevThere&#x27;s no VSCode extension. How am I supposed to use this??? :) reply al_be_back 2 hours agoparent>> You can use whatever extension you wish on the component file, but .nue extension is recommended. You can also use .htm to have your editor (and GitHub) automatically color highlight the code and to distinguish them from static .html files[1] https:&#x2F;&#x2F;nuejs.org&#x2F;docs&#x2F;nuejs&#x2F;component-basics.html reply caesil 5 hours agoprev>Nue CSS>Bring back the power of cascaded stylingWelp, I&#x27;m out. reply progx 1 hour agoparentThe problem in the past with css was the inconsistent browser implementation, this should be solved since some years.And now we have native nesting, wich was in old times a reason for use things like sass&#x2F;scss&#x2F;... CSS-Variables too, so theming is not a pain in the a.. anymore.You can use overbloated frameworks, but i did not see a reason anymore for that. Especially when you develop component based. Tailwind on a top level is ok, but not within a component and child items, unnecessary complicated. reply tipiirai 5 hours agoparentprevYes. Nue is probably not a good pick for people who really like things like React and Tailwind. It&#x27;s more like going backwards in time when standard HTML, CSS, and vanilla JavaScript was a thing. reply PennRobotics 3 hours agorootparentWelp, I&#x27;m in! reply timeon 3 hours agorootparentprevTailwind is maybe good for people that do not want to learn CSS but creates bloat for user to download. reply sensanaty 2 hours agorootparentHow exactly do you use Tailwind without knowing how to use regular CSS first? Pretty much everyone I known uses Tailwind BECAUSE dealing with CSS is a fucking nightmare, even in component-based frameworks. reply progx 1 hour agorootparentI know CSS and have to look always into the Tailwind documentation to find the corresponding settings. As long as you use tailwind 0815 settings everything is ok, but not easier as css (if you know css). reply ceesharp 1 hour agorootparentprevYou do know that unused styles get removed and Tailwind gets converted to plain CSS? reply tonyoconnell 2 hours agorootparentprevYou can use DaisyUI to clean things up reply gigatexal 1 hour agoprevhow do you plan to monetize? reply nsonha 8 hours agoprev [4 more] [flagged] lolinder 7 hours agoparent [–] Can you clarify why you believe this, rather than just posting a shallow dismissal? \"Horseshit\" does nothing to help me understand your point of view other than make it clear you feel something very strongly. reply Semaphor 7 hours agorootparent [–] While their wording takes some work, it’s simply not \"just HTML\". Even less so than react is \"just JS\". It’s a DSL applied on top of HTML. reply lolinder 6 hours agorootparent [–] Agreed, the distinction matters and it&#x27;s worth respectfully pointing out. Thanks! replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author has developed Nue JS, a JavaScript library for building user interfaces, influenced by Vue 2.0 and Riot.js.",
      "An ecosystem is in the works to complement Nue JS, designed to be an alternative to tools like Vite, Next.js, and Astro. The aim is to emphasize progressive enhancement, separation of concerns, and semantic web design.",
      "All products under the Nue brand will be released under the MIT license, which confirms the author's commitment to open-source tooling."
    ],
    "commentSummary": [
      "The article announces the launch of Nue JS, a lightweight alternative to renowned front-end frameworks, and discusses potential expansions to related projects.",
      "It showcases debate around front-end development encapsulation issues and provides user feedback while drawing comparisons with other similar frameworks.",
      "The post also explores varying audience sentiment towards Nue JS and brings into conversation the potential influence of artificial intelligence on coding norms."
    ],
    "points": 207,
    "commentCount": 151,
    "retryCount": 0,
    "time": 1694689877
  },
  {
    "id": 37513030,
    "title": "A clever “perpetual motion” device [video]",
    "originLink": "https://www.youtube.com/watch?v=r_LG8FDt51U",
    "originBody": "- This is a \"perpetual motion\" device. That's the first time I've ever used a green screen in one of my videos. But it's important to put perpetual motion in inverted commas because perpetual motion doesn't exist. Actually, the designer of this device calls it a perpetual motion simulator. I quite like that. Actually, I quite like perpetual motion simulators in general because we know that perpetual motion isn't possible, so it's fun to try and figure out like where's the trick? And in this particular case, the trick is some really lovely engineering. To be clear, I don't like perpetual motion simulators that are designed to scam people. The list of those is endless, but the creator of this device is very clear that it needs batteries. In fact, I did some bookkeeping after buying all the stuff for this video, and I chuckled at these two entries, perpetual motion machine followed immediately by batteries for perpetual motion machine. To figure out how this works, we really need to look inside, and thankfully through the magic of buying two of them, I already have a taken apart one right here. And that's the second time I've ever used green screen in one of my videos. The idea was to remove the wooden base and replace it with a transparent one, because, you know, I like to make transparent versions of things. The problem was when we put all the gubbins back in, we couldn't get it working again. So while this is good for showing you what's going on, it's a bit unsatisfying because it doesn't actually work. And then I thought, \"Wait a second, why don't I try and contact the person who made this thing?\" William Le was very helpful giving advice on how to get this thing working, but we never could. So eventually I asked if he would make one for me. And so here is my third perpetual motion simulator. Isn't it beautiful? I'm hugely grateful to William for making this for me. He took the time to figure out how to work with unfamiliar materials, and the result is fantastic. By the way, William is the creator of this design. There've been hundreds of knockoffs since, but if you're planning to get one of these, I really hope that you'll go to the original creator. The link to William's Etsy page is in the description. So let's figure out how this thing works. Well, even without looking inside, we can make some educated guesses. Without the device turned on, you can see the losses due to friction. Gravitational potential energy is turned into kinetic energy and that kinetic energy is turned back into gravitational potential energy. But look how much less gravitational potential energy there is after that process. So when the device is turned on, the ball must be given some additional kinetic energy at some point. And the only thing I can think of is electromagnets. And in this transparent version, that's what you see here. But that's not enough on its own. If you simply turn on the electromagnet, well, the steel ball will accelerate towards it, but once it reaches the electromagnet, it'll be harder to leave. This is what happens when I put a permanent magnet in place of the electromagnet. So the electromagnet needs to be on during the approach, and then off once the ball reaches the magnet. That's where this component comes in. This is an inductive proximity sensor. Actually, no. This is an inductive proximity sensor. This is one of these that's been deconstructed by William so that it'll fit inside his sneaky device. The way it works is when you supply power on these two wires an oscillating current passes through the coil inside which induces an oscillating magnetic field. You might know that a changing magnetic field induces a current in nearby metals. Well, an oscillating magnetic field is changing all the time. So when the steel ball approaches, an oscillating current is induced inside it. Now that oscillating electric current inside the ball has an oscillating magnetic field of its own. And the way the physics works out, that induced magnetic field actually opposes the magnetic field of the coil. So as the ball approaches, the total magnetic field goes down. That's detected by the sensor and this little LED light up. But for the purposes of this circuit, it also sends a signal voltage down this third wire. So now we can have the electromagnet turn on when the ball gets to a certain position. We can then decide like how long do we want the magnet to be turned on for? I've attached a voltmeter across the electromagnet so you can see a voltage is supplied to the electromagnet for about 10 milliseconds. Final couple of things I wanna look at. What are these things? Well, these are capacitors. You really need to give that electromagnet some juice. So instead of powering it directly from the battery, you charge up these capacitors and then power it from them. I'm not sure how long it takes to charge up these capacitors, but if you send two balls down at the same time, the second ball doesn't make it. But if you leave a little gap between the two, then they both come back to the top. And actually looking at the voltage graph from earlier, the capacitors don't discharge very much at all. So you can imagine it wouldn't take much time to get them back where you want them before the next ball arrives. These two blue components are important. They allow you to adjust a couple of the parameters of the device. You tweak the top one if you want to adjust the strength of the electromagnet, and you tweak the bottom one if you want to adjust how long the electromagnet is on for. And these are important because each one of these devices is handmade. There's gonna be a slight variation in the distance between the rails and the sensor, the length of the track and so on. So you need to be able to fine tune these things after it's all put together. I mean, you don't have to. William does it before he sends it. The final thing is the power button. You know, you really don't want your perpetual motion machine to have a power button. It kind of spoils the illusion a little bit. So here under the acrylic, you can see a capacitive sensor. When you touch it, you're adding the capacitance of your body to that little bit of acrylic there. That sensor can detect the change in capacitance, and the circuitry interprets that as a button press. And so in the wooden version, it's as if there is no power button. On the subject of perpetual motion, actually, occasionally I'll make a video that demonstrates some physical principle typically involving magnets, and there'll be a discussion in the comments of like, \"Would it be possible to slightly adjust the setup so that the thing keeps spinning forever or the thing keeps bouncing up and down forever?\" Things like that. A good example is my video about the spinning ballerina toy. What if you had two magnets or a ring of magnets so that the ballerina just constantly moved round in a circle? But actually you'll notice in that video, I'm always moving my hand. The magnet is always getting closer and closer to the ballerina, and the ballerina is getting further and further away. And of course, the ballerina is pushing back against my hand, so I'm doing work. My hand is moving some distance in the direction of an applied force, so there's no free energy to be had here. And of course, there's no free energy here either, unless you don't pay for your electricity. ♫ painfully smooth jazz ♫ And thankfully through the magic of buying two of them... And thankfully through the magic of buying two of them, I already have a taken apart one right here. I picked up the wrong one. I used to get these phone calls where they'd be like, \"Hello, am I speaking to Steven Mould of such and such address?\" \"Yes, that's me, that's my address.\" And they say, \"I'm calling from insurance department.\" Okay, they know my details. They must be calling from the insurance department of my insurers. But then you carry on the conversation, it turns out they're just trying to sell you life insurance or something like that. It's really interesting to know how these annoying practices came about. It's also interesting to know how you can stop this kind of phone call and other intrusions into your life thanks to the sponsor of this video, Incogni. Basically, it comes down to these intermediary companies called data brokers. There's hundreds of them, and they all collect data about you and then sell that data to companies like insurance department. And then those people call you, send you emails, send you mail in the post. You can contact these data brokers and tell them to stop, but they want to be contacted in a specific way. Maybe it's an email, maybe it's a web form, and it has to include specific information. And there's hundreds of them. It's almost impossible for one person to do it on their own. So wouldn't it be great if there existed a company that did all the legwork in advance, figuring out how all these companies want to be contacted, and then automated it so that you could contact that company and say, \"Can you do that thing that you do?\" And that's how Incogni works. You sign up, you give them permission to act on your behalf, and then they contact all of these companies and it just happens in the background. If you want, you can log in and you can see the progress. Look, these are all the companies that no longer have my data, and it feels good. Like I don't get those creepy phone calls anymore, and I don't get the kind of spam that seems weirdly specific to me and my data. If you're interested in the service, the promo on this one's really good. The first 100 people to go to incogni.com/science and use promo code science at checkout will get 60% off. The link is also in the description. So check out Incogni today. I hope you enjoyed this video. If you did, don't forget to hit subscribe, and the algorithm thinks you'll enjoy this video next. (lively music)",
    "commentLink": "https://news.ycombinator.com/item?id=37513030",
    "commentBody": "A clever “perpetual motion” device [video]Hacker NewspastloginA clever “perpetual motion” device [video] (youtube.com) 205 points by ed_westin 15 hours ago| hidepastfavorite106 comments rendall 13 hours agoHow delightful. I was 99% sure even before I clicked that it would be Steve Mould.Loved his parody of the fixed grin of Technology Connections. reply stouset 10 hours agoparentThrough the magic of buying two of them… reply MikusR 2 hours agoparentprevEven the outtakes. reply thefourthchime 12 hours agoparentprevMe too! reply londons_explore 14 hours agoprevThis circuit is awfully complex.... it&#x27;s possible to do the same with a far simpler circuit if you use the same coil for sensing and accelerating the ball.A small microcontroller could do both - perhaps even with low enough power that the whole circuit could stay turned on for years on a charge (when not flinging the ball).Looking at the total energy you need to impart on the ball, you should be able to do that with a far smaller coil and many fewer capacitors as long as you have a suitably shaped steel core to keep the flux path low. I suspect you might be able to do it with no capacitors at all, since modern lithium cells are perfectly happy to deliver 100 amps for a few milliseconds. reply lolinder 9 hours agoparent> This circuit is awfully complex ... A small microcontroller could do bothAdding a microcontroller might reduce the number of components used, but it&#x27;s a bit disingenuous to claim the result is \"simpler\". reply djmips 1 hour agoparentprevI&#x27;d like to see the videos of your version! reply amelius 11 hours agoparentprevYou say that the circuit is complex, but it&#x27;s the other way around.Its simplicity is the cause of the high component count. reply ape4 13 hours agoparentprevAn entire microcontroller to run an approx 3-line program? reply mutatio 3 hours agorootparentThrow in a node.js implementation with 100 dependencies and we&#x27;re cooking, simple as. reply londons_explore 13 hours agorootparentprevUsing a single coil, the microcontroller program is pretty complicated. It needs to pulse the coil very briefly on a regular basis and measure the resonant frequency.If you do the capacitor-less design, you might want to have a steel core with sawtooth top, and then use software to measure the position of the ball relative to each tooth and turn the coil on while the ball is heading towards a tooth and off when the ball is heading away. That allows the energy to be extracted from the battery slower.You might also choose to have your coil driven by an h-bridge. That means you can put the energy from the magnetic field that builds up in the steel core back into the battery between each &#x27;tooth&#x27;. That should dramatically increase energy efficiency, allowing you to use a smaller (cheaper, lighter, more eco friendly) cell or have the battery last longer. To do that, you&#x27;ll need current sensing too. reply NavinF 12 hours agorootparentprevThat&#x27;s very common. Look at all the $0.03 microcontrollers on LCSC. They save time, money, and board space. reply polishdude20 13 hours agorootparentprevCheaper than to have a microcontroller that results in a smaller PCB vs discrete components that make the PCB bigger. reply mcpackieh 9 hours agoparentprevI think you could drop coil sensing of the ball entirely and simply switch the electromagnet using the metal ball contacting the two metal rails. A dialectic gap in the rails near the bottom of the track could turn the electromagnet off at the right moment. reply bagels 1 hour agoparentprevRailgun instead. reply p1mrx 13 hours agoprevBe aware that most of the cheap knockoffs just use a motorized wheel. For example, see the videos on https:&#x2F;&#x2F;www.amazon.com&#x2F;dp&#x2F;B09VTJ4LZ8&#x2F;#ive-videos-for-this-pr... reply BugsJustFindMe 12 hours agoparentThey also use diagrams showing the ball traveling the wrong way. https:&#x2F;&#x2F;imgur.com&#x2F;a&#x2F;o3sHFhX reply dylan604 9 hours agorootparentThe art on most of Amazon&#x27;s listings is just a thing of beauty, if you&#x27;re into really bad photoshopping. Some of them are really eyebrow raising, while others are more WAT. I use it as a litmus test as clearly a knock off item, and move away from that listing. reply wingworks 6 hours agorootparentThe other day I came across the first use of stable diffusion in a listings product in use photos. To me it was obvious, knowing what to look for, but to the average user they&#x27;d never know, unless they really paid attention. reply crazygringo 10 hours agoparentprevIt makes a horrible sound in the videos, but it&#x27;s not obvious to me what you mean by \"motorized wheel\".None of the mechanism is visible at all, certainly no wheel, motorized or not. How does a motorized wheel accomplish this? reply flutas 10 hours agorootparent> None of the mechanism is visible at all, certainly no wheel, motorized or not. How does a motorized wheel accomplish this?Probably a simple spinning wheel inside of the ball collection area.Spinning rubber wheel in the hole the ball drops through before getting on the track. Notice how the ball doesn&#x27;t differ in speed at all after it&#x27;s fallen, vs the original feels natural (gaining momentum) until it gets close to the bottom.Edit: In one of the Amazon review images[0] you can see a black spot in the ball drop hole, maybe there.[0]: https:&#x2F;&#x2F;i.imgur.com&#x2F;xb65ljL.png reply crazygringo 10 hours agorootparentOh I see what you mean.On the Amazon one (as opposed to the YouTube video) the balls come shooting down out of the upper collection area at high speed. And the upper collection area is much thicker. So it&#x27;s hiding some kind of mechanism. reply KRAKRISMOTT 10 hours agorootparentprevYou can also accelerate it from the ball collection area using a coil gun mechanism. A motor adds too much cost and moving parts. reply slig 10 hours agorootparentprevJust guessing, but maybe there&#x27;s some magnets attached to the wheel and they accelerate the ball as it gets near the bottom. reply harles 11 hours agoparentprevGotta love the description on theses:> No need for power, just press on the battery and use it. reply dylan604 9 hours agorootparentwell, duh, you don&#x27;t need power when it&#x27;s got batteries. That&#x27;s like emergency kit 101 reply yantrams 15 hours agoprevBrings back childhood memories. Enjoyed reading about these and the accompanying illustrations as a kid from the excellent book Physics for Entertainment by Yakov Perelman. Nirantara Chalana Yantralu they were called in Telugu translation. reply mdp2021 2 hours agoparentThank you for the suggestion!Yakov Perelman - Physics for Entertainment - https:&#x2F;&#x2F;archive.org&#x2F;details&#x2F;PhysicsForEntertainment-Eng-Yako...I see that Astronomy for Entertainment, Algebra for Entertainment, Figures for Entertainment also exist. reply tantony 14 hours agoparentprev> Physics for Entertainment by Yakov PerelmanI read the same in Malayalam! That book was one of my earliest introductions to practical physics. He deconstructs pretty much all the early \"perpetual machine\" designs in the book.I also particularly remember the chapter with the experiments with soap bubbles as being very interesting as a kid. reply facu17y 14 hours agoparentprevI had the Arabic translated edition of that book! same fond memories! reply comicjk 15 hours agoprevWas anyone else hoping it would detect the ball by simply completing a circuit (since the rails are metal and so is the ball)? Then it could give a magnetic tug after an appropriate time. Maybe this would be flaky because of the poor contact between rails and a rolling ball, but an inductive proximity sensor feels like overkill. reply angry_moose 14 hours agoparentIt probably wouldn&#x27;t work nearly as well.It looks like the rails are already a complete circuit - I think they&#x27;re a single piece of wire that is bent at the end to make a loop, and there are a couple lateral braces soldered on to keep them properly spaced.You&#x27;d have to split the rails into two pieces and replace the lateral braces with something nonconductive (plastic) which wouldn&#x27;t look nearly as nice; and the device would be a lot more prone to going out of calibration if the spacing drifted.Its probably possible but there&#x27;s a lot of downsides to save $2 on a sensor, some of which will be eaten up elsewhere as it will add some additional parts.Edit: It would also somewhat spoil the magic, as that&#x27;s the first thing most of us would think of (I certainly did). reply djmips 1 hour agoparentprevYes flaky, it&#x27;s going to corrode and get dirty so the connections won&#x27;t be reliable reply bibelo 3 hours agoprevI like the idea that the laws of physics allow us to draw conclusions with certainty, despite what our eyes observe: we are sure it&#x27;s no perpetual device, since science says it&#x27;s impossible.Exactly with the Sun: our eyes observe that Sun goes around Earth, but science tells us otherwise.Reminds me of the definition of Faith in the Holy Scriptures: \"the evident demonstration of realities that are not seen.\" (Hebrews 11:1) Yes, there are realities that exist beyond what we can see, that we can deduce with reasoning.Edit: typo reply marginalia_nu 3 hours agoparent> Exactly with the Sun: our eyes observe that Sun goes around Earth, but science tells us otherwise.These are just two different reference frame. Both are equivalent. reply OskarS 1 hour agorootparentTell that to the 16th century Catholic church... reply marginalia_nu 1 hour agorootparentThat&#x27;s the irony though, both them and the high school teacher telling you they were wrong is making the same category of error.It&#x27;s a debate over where to put the origin of the coordinate system, which is an arbitrary choice. reply moonchild 3 hours agoparentprevThe whole reason science works is that we start by assuming what our eyes tell us is true, and then come up with models to explain that.Edit: plato believed the nature of reality could be discerned with pure reason. He was wrong.Science also works only because it always assumes that its models may be wrong. reply owenpalmer 14 hours agoprevSteve Mould is top-notch reply martinmunk 14 hours agoparentThis one is pretty good, but I usually steer clear of his videos. Topics are pretty on point for my interests, be he just seem... Too full of himself? I don&#x27;t want to be mean in any way, but if someone agrees maybe they can put a finger on what it is reply cycomanic 13 hours agorootparentWhat is your background? I know that many Americans perceive a British accent as snobbish&#x2F;arrogant (this is often used in Hollywood movies as well). So maybe it&#x27;s just that? reply Retr0id 14 hours agorootparentprevThere are a few youtubers that come to mind who fit this description, but Steve Mould is not one of them. reply legohead 13 hours agorootparentprevI feel like your mind must have confused two people. Steve is very down to Earth.Maybe his youtube-battle with ElectroBOOM turned you off? Where he was pretty convinced he was right about the chain fountain. reply masklinn 13 hours agorootparentNah I always have the same impression, even though I’ve been watching for years (long before the chain thing), and I can see the janky setups trying to figure things out.I think it’s mostly the voice &#x2F; accent, to me it… sounds sneery? reply cameronh90 6 hours agorootparentI find him very down to earth with a healthy dose of humour and self deprecation.Maybe it could be a British thing? Perhaps there&#x27;s some culture-specific signalling that can be read in a different way in a different culture? reply masklinn 5 hours agorootparentThat is what I assume yes, but I don’t know where I picked it up. reply Bellend 12 hours agorootparentprevI don&#x27;t know him but I feel he is a bit tongue-in-cheek with humour. As far as I remember, he did comedy and was also good with education with kids. I don&#x27;t imagine meeting him and him coming across as full of himself though. I feel I could approach him in a pub and he would have good banter. reply dylan604 9 hours agorootparentsome people just don&#x27;t get there&#x27;s a joke unless there&#x27;s a laugh track reply masklinn 13 hours agorootparentprevHis voice and presentation style do give me the same feeling. I don’t know why. Same with Mark Rober.But the actual content is the opposite. It’s really quite strange. reply djmips 58 minutes agorootparentI like Steve Mould and dislike Mark Rober. hmmm. I feel a pretty good judge of character, Steve Mould is quite often humble and self effacing but he does mug and talk in a very intimate way - some people might dislike that from someone they don&#x27;t really know. reply martinmunk 12 hours agorootparentprevYeah, I think I can see the link to Mark Rober. Although not at all to the same degree. Maybe it&#x27;s the way of \"acting dumb\" in order to progress the discovery process, but a face that they know full well (obviously) that he knows what&#x27;s going on? Essentially talking down to the audience?Not sure. My first attempt at phrasing it did not get my feeling across well. reply phailhaus 14 hours agorootparentprevThis one is pretty representative of what his videos are like. Could be that you got a skewed first impression? Once you watch a few of them, you can see he&#x27;s pretty genuine. reply Cthulhu_ 14 hours agorootparentprevI didn&#x27;t get the impression he&#x27;s too full of himself, but he was confident for sure. That&#x27;s not being full of oneself though, that&#x27;s making a video interesting, confidence, and not filling the space with caveats or self-deprecation. reply owenpalmer 14 hours agorootparentprevToo full of himself? I&#x27;m not sure I understand, can you give an example? reply flavius29663 10 hours agorootparentprevFull of himself? He literally dresses in a tutu and spins in the mirror in this video. reply bawolff 10 hours agoprevIts cool, but it seems kind of obvious how it would work. Uou can tell the ball is speeding up at the wrong times. It&#x27;d be cooler if they could make the motion look more natural. reply at_a_remove 6 hours agoparentThat would be definitely interesting. Myself, I could see the following developments:1) More caps and work in it being powered by ambient light. 2) Taller, perhaps multi-stage. 3) Multiple paths that were somewhat random.Really, I think I am inventing a cat toy. When I was small, I had a racetrack game with just enough randomness to keep my cat completely fascinated. reply divbzero 13 hours agoprevI wonder if the creator of this device William Le [1] has managed to make this his full-time endeavor.[1]: https:&#x2F;&#x2F;www.etsy.com&#x2F;shop&#x2F;backtonaturedecor reply rootusrootus 11 hours agoparentHe is selling a lot of them today. Another one every minute or so right now. reply djmips 49 minutes agorootparentHmm I wonder if he has enough already made or if it becomes a long backorder situation. 152 sold recently and it they are hand made it could take a while! reply tempestn 14 hours agoprevHuh, I&#x27;d always assumed the ball simply closed a circuit when it rode on the rails, and that&#x27;s how it knew when to turn the magnet on and off, with suitable delays. It does seem to me you could still do it that way, but it&#x27;d probably be more difficult. reply johnyzee 14 hours agoprevThis got me wondering if it could be made to be entirely mechanical. Like, the approaching ball triggers something to move in front of the magnet &#x27;switching it off&#x27;, then slides away again when the ball has passed, ready for the next run.I think I just invented perpetual motion... reply MetallicDragon 11 hours agoparentAny mechanism that could switch the magnet on and off would require energy. E.g. you could put a magnet next to it with opposite poles, which would mostly cancel out the magnetic field, but would require a lot of force to push them together, which is work, and thus requires energy. reply tempestn 14 hours agoparentprevNo reason you couldn&#x27;t do that as long as you just mean the actuation is purely mechanical. You&#x27;d still need an electromagnet and power source though, as it only works if you can turn the magnet on and off. reply quickthrower2 8 hours agoparentprevThe easiest perpetual motion is just drop a tennis ball. It is just that the perpetually moving thing is no longer the ball :-) reply p1mrx 13 hours agoparentprevWhat do you propose to use as an energy source? reply djmips 43 minutes agorootparentclockwork wind-up. It would be bulky but maybe you could put a permanent magnet on a sled or wheel that would impart the necessary force on the metal ball as it approached but then and flipped repelled it. Would be difficult to make work smoothly or at all... reply austinjp 11 hours agorootparentprevJust build a second machine to power the first! reply srijanj 3 hours agoprevThe circuit is awfully complex reply _a_a_a_ 14 hours agoprevExcellent presentation, no dumb graphics, witticism, silly voices or stupid faces pulled etc, just nice clean explanation.Nice toy too. I&#x27;d get one but I&#x27;d turn it on 3 times then get bored and give it away. reply Cthulhu_ 14 hours agoparentI like it as a desk toy, like the row of balls or things like that. reply zht 14 hours agoparentprevit&#x27;s funny because there&#x27;s another comment saying they really enjoy the stupid face at 1:07 reply ozay 3 hours agorootparentThat&#x27;s him imitating another YouTuber who does this stupid face all the time. reply phelm 14 hours agoprevI thought it was going to be a railgun reply Cthulhu_ 14 hours agoparentIt can be if the magnet&#x27;s strong enough! reply maerF0x0 15 hours agoprevCould this work as a magnetic rail with earth magnets? Would that not require any batteries then? reply ugh123 14 hours agoparentHow would you \"switch off\" the magnets as the train approaches so as to allow it to pass with its newly gotten energy? reply gus_massa 14 hours agorootparentI&#x27;m not sure if the GP is proposing a railgun. In any case, I propose a railgun version. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Railgun reply p1mrx 13 hours agoparentprevWhat do you propose to use as an energy source? reply stavros 14 hours agoprevOoh, I&#x27;d love to find one of these on Ali, but their search is betraying me currently. reply koromak 14 hours agoprevDamn I kinda want to build little doohickeys and sell them on etsy instead of going to work every morning reply Workaccount2 13 hours agoparentI can tell you that this has two possible outcomes:1. You don&#x27;t sell enough to get by.2. You sell enough for Chinese knock-offs to come in and offer a good-enough clone product for 1&#x2F;3 your raw material cost.Being a first world tiny shop in hardware is near impossible. reply masklinn 13 hours agorootparent(3) you make good looking gizmos which are not really worth copying seems to be the niche of “William”. Apparently the slides were about 150, and they’re externally simple but good looking. They’re out of stock but the shop has neat kinetic sculpture for high hundreds.Could you get plastic versions for a third the price? Absolutely. Would you? Hell nah. I could see kits of spare parts to print and build your own, maybe, but not ready made. reply itigtohft 13 hours agorootparentIf you search for \"perpetual motion machine\" you can find a ton of cheap knockoffs of this device. You can get a badly made wooden knockoff for $50 or quite a bit less? reply newaccount74 13 hours agorootparentprevThere are a bunch of tiny hardware shops in the audio community that seem to be doing fine, for example https:&#x2F;&#x2F;neurochrome.com&#x2F;Of course, running a small business like this is not easy, but it&#x27;s not impossible either. reply MalcolmDwyer 7 hours agorootparentWhen it comes to pricing products at absolutely outrageous multiples of material cost, the \"audio community\" seems to be in its own league. I don&#x27;t think the desktop toy market is quite there. reply quickthrower2 8 hours agorootparentprevYou are then no longer selling the toy, but the “My one is OG” status. And the certainty that it will work. Once you reach a certain age fucking about returning stuff to save a few bucks seems silly. reply luma 13 hours agoparentprevNothing stopping you! I have git and printables etc accounts full of stuff I&#x27;ve designed and shared, but some folks might just want the finished thing so awhile back I hung out my hat and started a small shop selling the widgets I design and share for free.Turns out a lot of people just want the thing, I can give the plans away and still make some extra on the side by making a few to sell.I&#x27;m incredibly far away from being able to quit my job over this, but it has turned a few of my hobbies into slightly net-profitable ventures instead of money holes and the result is a well appointed shop to spend my free time playing around with new ideas.My advice: give it a shot. There&#x27;s nearly zero up front cost and if nothing else, you&#x27;ll probably learn a bit. reply tnecniv 14 hours agoparentprevWell then building doohickeys would be your new “going to work” reply semireg 13 hours agorootparentBusiness is a great way to ruin a hobby. reply Try1275 15 hours agoprevThe video is worth just for his expression at 1:07. Highly recommended. Have no interest in the topic and watched the whole thing! reply iamjackg 15 hours agoparentFor those who don&#x27;t know, it&#x27;s a reference to Technology Connections[0], another incredible YouTube channel. Alec, the host, is very fond of that bit[1].[0] https:&#x2F;&#x2F;youtube.com&#x2F;@TechnologyConnections [1] https:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=CZs-YcmxyUw reply em-bee 12 hours agorootparenti have only seen a few of alec&#x27;s videos, but i immediately recognized this as familiar, wondering \"hey, that&#x27;s a different guy\" reply russdill 14 hours agorootparentprevOh my gosh, the green screen reply ChrisClark 14 hours agorootparentprevHah yeah, for some reason that line never gets old for me. reply masklinn 13 hours agorootparentIt’s short, it’s snappy, and it’s only deployed appropriately (by Alec, and by Steve here), so it stays fresh and not overdone.And other similarly nice recurring gag is Tasting History’s hardtack. reply pxndx 15 hours agoprevLost it at the \"through the magic of buying two of them\" bit! reply debesyla 15 hours agoparentThat, by the way, is a reference to another great channel - Technology Connections: https:&#x2F;&#x2F;youtube.com&#x2F;@TechnologyConnections reply dageshi 15 hours agoparentprevhttps:&#x2F;&#x2F;www.youtube.com&#x2F;watch?v=CZs-YcmxyUw reply oldandtired 14 hours agoprev [–] Steve makes an interesting statement when he says \"we know that perpetual motion is not possible\". Yet we have a modification to the general cosmological view with the theoretical entity \"dark energy\" which if you consider what is said about it properties, it provides a means of creating a \"perpetual motion\" environment.So what can we say: Does perpetual motion exist or not? reply helpfulContrib 1 hour agoparentThe universe is in perpetual motion. This is a process that has been being refined since the very beginning.Our ability to harness it and use it for our own intentions, not so much.We don&#x27;t have an energy problem.We have an energy management problem - we are harvesting only the coarsest of it all, when we could be harvesting the finest, most refined of it, that is all around us .. reply mr_mitm 14 hours agoparentprevEnergy is not globally conserved in an expanding universe, dark energy existing or not.https:&#x2F;&#x2F;www.preposterousuniverse.com&#x2F;blog&#x2F;2010&#x2F;02&#x2F;22&#x2F;energy-...https:&#x2F;&#x2F;physics.stackexchange.com&#x2F;questions&#x2F;259759&#x2F;conservat...https:&#x2F;&#x2F;twitter.com&#x2F;WKCosmo&#x2F;status&#x2F;1303134701180325890?t=pv5...Obviously the guy in the video was making the implicit assumption that we are talking about local experiments. reply n2d4 12 hours agorootparentThe accepted solution in the second link claims your other two links are wrong:> Some people claim incorrectly that energy is not conserved in an expanding universe because space-time is not static. The law of Energy conservation is derived from Noether&#x27;s theorem when the dynamical equations are unchanged with time. These people confuse the invariance of the equations with the invariance of the solution. Space-time changes but the equations obeyed by the expanding universe do not change. Space-time cannot be treated as a background, its dynamics must be included when deriving the enrgy equations via Noether&#x27;s theorem. This leads to the equations given above which show that energy is indeed conserved. reply raattgift 25 minutes agorootparent[tl;dr momentum loss is a generic feature of a spacetime which has a metric expansion of space. Informally, every future direction is uphill, so everything has to roll uphill[*]. If the expansion is accelerated by a cosmological constant the hill steepens with the expansion. The author of the accepted answer at the phys SE link seems to want to argue that the slowdown while rolling uphill is what generates the hill. It&#x27;s not. The hill is generated by the initial impulse that kicks off the expansion and driver of the expansion-acceleration if any.]So, uhhm, let&#x27;s look at the> accepted solution in the second linkwhich was authored by the hagiographic https:&#x2F;&#x2F;www.vixrapedia.org&#x2F;wiki&#x2F;Philip_Gibbs (in which there&#x27;s a whole section \"Energy Conservation in General Relativity\": \"... Gibbs is the leader of a small minority of commentators who dispute [that energy conservation only works in special cases]\".In the comments below the answer he links to a 2010 article in the \"Prespacetime Journal\" of which he is one of the editors and more prolific contributors. That article, written by Gibbs (which some editing pass managed to leave in a state where one finds both Einstein-Hilbert and Hilbert-Einstein and similar) finds the right problem -- energy is very hard to define in a general curved spacetime . It does not imho find the right solution. His is ultimately an attempt to define a quasilocal quantity and then extend it to some cosmologically large volume. His method requires a closed cosmology, and he had the decency to say so in the second paragraph. Consequently most people could simply stop reading at that point and spare themselves pp 906-907 where he admits that he&#x27;s forced into considering coordinate-dependent quantities like everyone else (none of which he cited, more below), and misses the opportunity to back a quasilocal view with an ultralocal (if averaged) one. If he had done that he might have confronted the problem that in the far future of an accelerating expanding spacetime dark energy and horizon radiation are all that&#x27;s left at a typical point in spacetime.I agree with mr_mitm that dark energy doesn&#x27;t make much qualitative difference with respect to energy losses from matter that just don&#x27;t go anywhere (pace Gibbs). In an inertially expanding non-closed spacetime&#x27;s far future you find no energy at all at a typical point, so vast vast regions appear to be flat vacuum. If the expansion is accelerated by dark energy, you get vacuum which isn&#x27;t flat. It&#x27;s best to consider this by comparing parallel trajectories, Raychaudhuri-style.Consider two test (massless, non-interacting) particles having an initially-parallel trajectory at an adjacent pair of points in each version. These particles will stay parallel in the inertially expanding case, but will diverge in the accelerated expansion (cosmological constant) case.Both of these cases conflict with Gibbs&#x27;s stack exchange answer in the following way. Make our test particles massless, and apply the Blau-Frank-Weiss adaptation of Fermi coordinates to their worldlines; the affine parameter x+ along the null geodesics generates a pair of momenta k^\\mu = \\dot{x+}^\\mu and orthogonal \"transverse\" accelerations a^mu = k^nu \\nabla_nu k^mu = 0. The particles lose momentum in their direction of travel but feel no acceleration; they are simply in zero-force constant free fall. The cosmologies themselves pick out solutions of the geodesic equation, and the momentum-loss along null geodesics is because of the expansion of space. The test particles on their worldlines do not know whether the worldlines are parallel or divergent.Since we can solve the geodesic equations for the entire spacetime (as a \"block universe\") it is hard to imagine what one even means by an energy of the gravitational field, unless one slices up the spacetime into time-ordered spaces. But once you do that you have to guard against slicing-dependent quantities like those Gibbs contemplates. He starts, uncontroversially, with a slicing that contains the vast majority of actually-occupied timelike geodesics (the centres of masses of inertially drifting galaxy clusters, represented by the FLRW homogeneous fluids), but does not contemplate other slicings -- do the conclusions hold up for our pair of massless observers? No, his plan only works for for a family of timelike geodesics which were parallel at the termination of the inertial impulse or early in the the accelerated-expansion history. His conclusions also don&#x27;t hold up in general for slicing along any accelerated massive observer&#x27;s proper time either, and are super-awkward if we slice along a high-energy cosmic ray propagating from one galaxy cluster to another (e.g. if we wanted to think about its mean free path).Gibbs&#x27;s paper, dated 2010, cites work only up to the early 1990s, with 6&#x2F;9 of his references dated before 1970. Any peer-review would demand he expand his list of references with the expectation he is or should be aware of work done in the fifteen year gap. I&#x27;ll quote from the publication&#x27;s editorial polcies page: \"PSTJ employs a three-tier due diligence process in selecting submissions for publication. First, all submissions are screened by the Editor to determine whether the contents and&#x2F;or forms are suitable for publication in PSTJ; and unsuitable submissions will be declined without reviews. Second, the remaining submissions will be reviewed by the Editor; and submissions passes Editor&#x27;s review will be accepted for publications\". Well, Gibbs is an Editor so maybe this paper didn&#x27;t take the \"Third, the still remaining articles ...\" route. Who knows?Honestly, I expected worse; he only fell into traps that were already in the academic literature and dealt with in grad-level GR textbooks.is well-known and \"fringe\" is polite\". That said, this paper was fairly conventionally wrong.[*] \"Uphill\" means against a gravitational potential. It is seductive in cosmology to think about gravitational potential and kinetic energy, especially if we drop dark energy. Early in the expanding universe masses like galaxy clusters are all relatively close and flying apart at high speed; at later times the masses are all relatively distant and flying apart at lower speed. The early kinetic energy has been converted into late gravitational potential. (Under time reversal, that gravitational potential energy crunches everything back together at high speed).If we add dark energy then in the resulting accelerated expansion both the gravitational potential and kinetic energy increase with time. If the dark energy is the cosmological constant (CC), where is the extra kinetic energy coming from? The CC is constant at every place and every time. So there&#x27;s an awfully big hint that energy isn&#x27;t conserved, and digging into this one learns that the seductive idea doesn&#x27;t work. reply Cthulhu_ 14 hours agoparentprevWhat makes you think dark energy is \"a means of creating a perpetual motion envrionment\" though? I&#x27;ve never heard that claim made.I mean personally I think the theory of dark matter &#x2F; energy is a patch for the perceptions not matching up with the theories, but that&#x27;s besides the point. reply dist-epoch 14 hours agoparentprev [–] You are being pedantic.If you want to consider dark energy perpetual motion, sure, but then it&#x27;s excluded from the \"we know that perpetual motion is not possible\" rule.\"we know that perpetual motion is not possible\" is based on the fact that you can&#x27;t break the laws of physics, which perpetual motion is doing, but if dark energy is part of physics, it can&#x27;t break those laws by definition. replyApplications are open for YC Winter 2024 GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The video involves the presentation of a 'perpetual motion' device that essentially operates as a perpetual motion simulator, using electromagnets and an inductive proximity sensor to keep a ball in a constant motion.",
      "The creator gives a comprehensive demonstration of the device's functionality and walks through its various components, such as capacitors and adjustable parameters.",
      "The concept of perpetual motion is discussed during the video, intertwined with aspects of the device's operation. A sponsor, Incogni, is mentioned as a service that aids in protection of personal data and prevention of unwanted phone calls."
    ],
    "commentSummary": [
      "The featured video shows a \"perpetual motion\" device, sparking discussions on potential improvements, such as plastic rails, microcontrollers, motorized wheels, and new power sources.",
      "The conversations also cover philosophical and scientific topics, like the nature of reality, the role of science, energy conservation, and defining energy within a curved space-time context.",
      "Skepticism around dark matter and energy theories and the credibility of certain arguments is also prevalent among the discussions. The article ends by mentioning applications for YC Winter 2024."
    ],
    "points": 205,
    "commentCount": 105,
    "retryCount": 0,
    "time": 1694717042
  }
]
