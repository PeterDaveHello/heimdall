[
  {
    "id": 37248494,
    "title": "Code Llama, a state-of-the-art large language model for coding",
    "originLink": "https://ai.meta.com/blog/code-llama-large-language-model-coding/",
    "originBody": "Research Blog Resources About FEATURED Large Language Model Introducing Code Llama, a state-of-the-art large language model for coding August 24, 2023 Takeaways Code Llama is a state-of-the-art LLM capable of generating code, and natural language about code, from both code and natural language prompts. Code Llama is free for research and commercial use. Code Llama is built on top of Llama 2 and is available in three models: Code Llama, the foundational code model; Codel Llama - Python specialized for Python; and Code Llama - Instruct, which is fine-tuned for understanding natural language instructions. In our own benchmark testing, Code Llama outperformed state-of-the-art publicly available LLMs on code tasks RECOMMENDED READS Code Llama research paper Code Llama GitHub Download the Code Llama model Today, we are releasing Code Llama, a large language model (LLM) that can use text prompts to generate code. Code Llama is state-of-the-art for publicly available LLMs on code tasks, and has the potential to make workflows faster and more efficient for current developers and lower the barrier to entry for people who are learning to code. Code Llama has the potential to be used as a productivity and educational tool to help programmers write more robust, well-documented software. The generative AI space is evolving rapidly, and we believe an open approach to today’s AI is the best one for developing new AI tools that are innovative, safe, and responsible. We are releasing Code Llama under the same community license as Llama 2. How Code Llama works Code Llama is a code-specialized version of Llama 2 that was created by further training Llama 2 on its code-specific datasets, sampling more data from that same dataset for longer. Essentially, Code Llama features enhanced coding capabilities, built on top of Llama 2. It can generate code, and natural language about code, from both code and natural language prompts (e.g., “Write me a function that outputs the fibonacci sequence.”) It can also be used for code completion and debugging. It supports many of the most popular languages being used today, including Python, C++, Java, PHP, Typescript (Javascript), C#, and Bash. We are releasing three sizes of Code Llama with 7B, 13B, and 34B parameters respectively. Each of these models is trained with 500B tokens of code and code-related data. The 7B and 13B base and instruct models have also been trained with fill-in-the-middle (FIM) capability, allowing them to insert code into existing code, meaning they can support tasks like code completion right out of the box. The three models address different serving and latency requirements. The 7B model, for example, can be served on a single GPU. The 34B model returns the best results and allows for better coding assistance, but the smaller 7B and 13B models are faster and more suitable for tasks that require low latency, like real-time code completion. The Code Llama models provide stable generations with up to 100,000 tokens of context. All models are trained on sequences of 16,000 tokens and show improvements on inputs with up to 100,000 tokens. Aside from being a prerequisite for generating longer programs, having longer input sequences unlocks exciting new use cases for a code LLM. For example, users can provide the model with more context from their codebase to make the generations more relevant. It also helps in debugging scenarios in larger codebases, where staying on top of all code related to a concrete issue can be challenging for developers. When developers are faced with debugging a large chunk of code they can pass the entire length of the code into the model. Additionally, we have further fine-tuned two additional variations of Code Llama: Code Llama - Python and Code Llama - Instruct. Code Llama - Python is a language-specialized variation of Code Llama, further fine-tuned on 100B tokens of Python code. Because Python is the most benchmarked language for code generation – and because Python and PyTorch play an important role in the AI community – we believe a specialized model provides additional utility. Code Llama - Instruct is an instruction fine-tuned and aligned variation of Code Llama. Instruction tuning continues the training process, but with a different objective. The model is fed a “natural language instruction” input and the expected output. This makes it better at understanding what humans expect out of their prompts. We recommend using Code Llama - Instruct variants whenever using Code Llama for code generation since Code Llama - Instruct has been fine-tuned to generate helpful and safe answers in natural language. We do not recommend using Code Llama or Code Llama - Python to perform general natural language tasks since neither of these models are designed to follow natural language instructions. Code Llama is specialized for code-specific tasks and isn’t appropriate as a foundation model for other tasks. When using the Code Llama models, users must abide by our license and acceptable use policy. Evaluating Code Llama’s performance To test Code Llama’s performance against existing solutions, we used two popular coding benchmarks: HumanEval and Mostly Basic Python Programming (MBPP). HumanEval tests the model’s ability to complete code based on docstrings and MBPP tests the model’s ability to write code based on a description. Our benchmark testing showed that Code Llama performed better than open-source, code-specific LLMs and outperformed Llama 2. Code Llama 34B, for example, scored 53.7% on HumanEval and 56.2% on MBPP, the highest compared with other state-of-the-art open solutions, and on par with ChatGPT. As with all cutting edge technology, Code Llama comes with risks. Building AI models responsibly is crucial, and we undertook numerous safety measures before releasing Code Llama. As part of our red teaming efforts, we ran a quantitative evaluation of Code Llama’s risk of generating malicious code. We created prompts that attempted to solicit malicious code with clear intent and scored Code Llama’s responses to those prompts against ChatGPT’s (GPT3.5 Turbo). Our results found that Code Llama answered with safer responses. Details about our red teaming efforts from domain experts in responsible AI, offensive security engineering, malware development, and software engineering are available in our research paper. Releasing Code Llama Programmers are already using LLMs to assist in a variety of tasks, ranging from writing new software to debugging existing code. The goal is to make developer workflows more efficient, so they can focus on the most human centric aspects of their job, rather than repetitive tasks. At Meta, we believe that AI models, but LLMs for coding in particular, benefit most from an open approach, both in terms of innovation and safety. Publicly available, code-specific models can facilitate the development of new technologies that improve peoples' lives. By releasing code models like Code Llama, the entire community can evaluate their capabilities, identify issues, and fix vulnerabilities. Code Llama’s training recipes are available on our Github repository. Model weights are also available. Responsible use Our research paper discloses details of Code Llama’s development as well as how we conducted our benchmarking tests. It also provides more information into the model’s limitations, known challenges we encountered, mitigations we’ve taken, and future challenges we intend to investigate. We’ve also updated our Responsible Use Guide and it includes guidance on developing downstream models responsibly, including: Defining content policies and mitigations. Preparing data. Fine-tuning the model. Evaluating and improving performance. Addressing input- and output-level risks. Building transparency and reporting mechanisms in user interactions. Developers should evaluate their models using code-specific evaluation benchmarks and perform safety studies on code-specific use cases such as generating malware, computer viruses, or malicious code. We also recommend leveraging safety datasets for automatic and human evaluations, and red teaming on adversarial prompts. The future of generative AI for coding Code Llama is designed to support software engineers in all sectors – including research, industry, open source projects, NGOs, and businesses. But there are still many more use cases to support than what our base and instruct models can serve. We hope that Code Llama will inspire others to leverage Llama 2 to create new innovative tools for research and commercial products. Try Code Llama today Code Llama GitHub repository Download the Code Llama Model Read the research paper Code Llama: Open foundation models for code Share: Our latest updates delivered to your inbox Subscribe to our newsletter to keep up with Meta AI news, events, research breakthroughs, and more. Join us in the pursuit of what’s possible with AI. See all open positions Related Posts FEATURED Research Meta and Microsoft Introduce the Next Generation of Llama July 18, 2023 Read post FEATURED Research Introducing CM3leon, a more efficient, state-of-the-art generative model for text and images July 14, 2023 Read post Large Language Model Community-driven AI innovation comes alive with Llama 2 July 28, 2023 Read post Who We Are About Meta AI People Careers Events Latest Work Research Infrastructure Blog Resources Our Actions Responsibilities Newsletter Sign Up Privacy Policy Terms Cookies Meta © 2023",
    "commentLink": "https://news.ycombinator.com/item?id=37248494",
    "commentBody": "Code Llama, a state-of-the-art large language model for codingHacker NewspastloginCode Llama, a state-of-the-art large language model for coding (meta.com) 756 points by marcopicentini 19 hours ago| hidepastfavorite445 comments daemonologist 16 hours agoWorks nearly out of the box with llama.cpp, which makes it easy to try locally: https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp&#x2F;issues&#x2F;2766Here&#x27;s some output from q4_0 quantization of CodeLlama-7b-Python (first four lines are the prompt): # prints the first ten prime numbers def print_primes(): i = 2 num_printed = 0 # end of prompt while num_printed2 3 5 7 11 13 17 19 23 29 reply someplaceguy 12 hours agorootparentYeah, but yours was generated by the \"post unoptimized code to HN and wait for someone to optimize it\" model, which, although free and doesn&#x27;t require a GPU, is a much slower model. reply saurik 12 hours agorootparentBut, unless you are trying to find a prime number low enough that you might as well look it up in a pre-generated table, it might still be end-to-end more efficient? reply someplaceguy 12 hours agorootparentAh, good point :) Touché! reply turnsout 11 hours agorootparentprevSomeone should turn this into a product! You highlight the code you want to optimize, and it posts it to hn as a semi-contextually-appropriate comment to invite code golfing, and the highest rated reply gets posted back to your repo as a PR. reply easygenes 2 hours agorootparentWhat are some existing data source that are somewhat analogous to this? e.g., Project Euler. reply badloginagain 8 hours agorootparentprevWe then train the LLM on all code optimized like this. reply FrozenSynapse 1 hour agoparentprevhow much VRAM do you need to run quantised 7b model? reply RossBencina 52 minutes agorootparentRough calculation: typical quantization is 4 bit, so 7b weights fit in in 3.6GB, then my rule of thumb would be 2GB for the activations and attention cache (not usually quantized). So 6 or 8 GB VRAM would probably do it. llama.cpp will let you offload your choice of layers to GPU, so you could probably get quite a way with 4GB. reply quickthrower2 11 hours agoparentprevFunny watching HN be nerd sniped by a machine :-) reply blibble 15 hours agoparentprevI&#x27;d fail an interview candidate that suggested adding 1 each time for subsequent prime testing reply csmpltn 13 hours agorootparent> \"I&#x27;d fail an interview candidate that suggested adding 1 each time for subsequent prime testing\"Congratulations! You must be that arrogant guy everybody hates interviewing with, the one with the superiority complex.How about instead of just failing people over literally nothing (wasting everybody&#x27;s time and money) - just ask the candidate whether they could somehow reduce the search space by utilizing the properties of a prime number? reply hyperbovine 9 hours agorootparentHow many even numbers are prime? reply wavemode 8 hours agorootparentOne. reply awwaiid 5 hours agorootparentTwo when you include -2, which I certainly think we should in this circumstance. reply chaboud 5 hours agorootparentAre we including it just to poke the bear? Prime numbers are typically defined as numbers with no positive divisors other than one and the number in question. reply squeaky-clean 4 hours agorootparentprevNegatives are not prime. reply lynx23 4 hours agorootparentprevDownvoting this is not enough. I&#x27;d pay $5 (reddit style) to have this properly killfiled if HN allowed for that. Besides, not \"everybody hates them, only those inmature enough to still need intellectual babysitting. reply tasubotadas 13 hours agorootparentprevFinally we meet the lifeless drone that everybody complains about in the interviews.My suggestion for your next interview: decide to hire them just based on their leetcode score, but invite to the interview just to flex that you&#x27;re still better at puzzle solving :-DPerfect reply internet101010 3 hours agorootparent\"Useand optimize for runtime.\"\"solution begins with \".Copy solution from gpt, paste in leetcode, run, submit.\"faster\"Repeat.Repeat.Next question. reply jckahn 8 hours agorootparentprevSo I take it you typically produce fully optimized, thoughtful, and correct code on the first iteration while being actively judged by a stranger, yes? reply maleldil 13 hours agorootparentprevI assume you meant that you should add 2? If yes, that&#x27;s such a mind boggling basic thing to do that I agree with you, and it makes no sense that you&#x27;re being crucified. reply warent 9 hours agorootparentnext [–]it makes no sense that you&#x27;re being crucified.Probably because there&#x27;s significant overlap in the Venn diagram of people with years experience who professionally develop products that generate $millions in wealth&#x2F;value, and people who would fail that interview.Or we have worked with junior developers who have really grown and flourished under our care, who would never have gotten that chance with such insane Draconian judgements.It&#x27;s such an obvious \"GOTCHA!!\" setting someone up for failure.The way it&#x27;s framed is very cringy because it signals that they don&#x27;t care in their interviews about determining how objectively effective a software developer is. reply maleldil 1 hour agorootparentI don&#x27;t get it. This is an extremely basic fact that most people can figure out after thinking about primes for a minute. Maybe if you ask for \"what&#x27;s an easy optimisation here?\" This would make the candidate think more closely about invariants that their code should hold, which in itself is a very valuable skill. reply NhanH 24 minutes agorootparentBecause I know enough not to write prime testing code that resemble anything like that loop to have to care about reducing its search space. If you actually want to test my knowledge about prime number, you can ask and I will tell you about using some probabilistic choice instead, and that I know fast deterministic one might exist, but I am not up to date on the state of the art.If I have to write the loop above, I am assuming it is the Fizzbuzz equivalent of your company to show that I know how to write a while loop. I am not thinking about reducing the search space because I am writing the code semi-unconscious and frankly just want to get to the next question. reply blibble 13 hours agorootparentprevyes reply throwuxiytayq 13 hours agorootparentprevi’d walk out from an interview that asked me to write a prime number generator reply belenos46 12 hours agorootparentI&#x27;ve done that (maybe it was fizzbuzz, now that I&#x27;m thinking about it) and boy howdy does that get the people you&#x27;re interviewing with agitated. Saying \"I&#x27;m interviewing for a architect level container orchestration position. If I&#x27;m reinventing the wheel writing algorithms, something is terribly wrong\" shuts them up, but doesn&#x27;t make them any happier. reply zaphirplane 9 hours agorootparentIs the job role just a for example ?what does and container orchestration architect do ? Something like this cluster should use envoy and Prometheus. The new clusters rate isn’t usually high enough for the stack to change.Real question I love these non conventional (swe, sre, pm, manager ) roles in tech reply squeaky-clean 4 hours agorootparentprevYou&#x27;d reject a candidate that is willing and legally able to work for free while also cloning themselves so they can pair program with every one of your employees at once? reply dontupvoteme 12 hours agorootparentprevSimply prompting the output with \"Optimize \" prepended adds your suggestion, and some others. reply beanjuiceII 6 hours agorootparentprevAlso don&#x27;t these only ever need to be computed once reply droopyEyelids 15 hours agorootparentprevThe simple-to-understand, greedy algorithm is always the correct first choice till you have to deal with a constraint. reply blibble 15 hours agorootparentit&#x27;s not that though, there&#x27;s several other typical optimisations in therejust not the super obvious one that demonstrates extremely basic understanding of what a prime number is reply jpeterson 13 hours agorootparentHaving \"extremely basic understanding\" of prime numbers immediately at one&#x27;s command is important for approximately 0% of software engineering jobs. If you instant-fail a candidate for this, it says a lot more about you and your organization than the candidate. reply SideQuark 10 hours agorootparentApprox 0% of devs need to know what the earth is, but from lots of interviews I&#x27;ve given I&#x27;ve found consistent correlation between lack of basic knowledge and lack of ability to solve many things. It was so strong we found it much more cost effective to cut people early that didn&#x27;t know at least a few of some standard knowledge items. reply chaxor 8 hours agorootparentThis is some really good advice here. It&#x27;s always a good idea to throw out all candidates that can&#x27;t immediately recall what the first theoretical result of the rest mass of a Higgs boson was in the first paper describing was. Basic knowledge like this just correlates so well with ability to make proper decisions in API architecture. reply blibble 13 hours agorootparentprev> If you instant-fail a candidate for this, it says a lot more about you and your organization than the candidate.yes, we expect professional software developers to have basic maths skills\"what is a prime number\" is taught to 7 year olds, it&#x27;s not vector calculuswhat else would you consider to be an unreasonable thing for an employer to require?reading and writing skills of a typical 7 year old? reply daok 12 hours agorootparentYou probably do not have a child of 7 years old because they do not know at that age what is a prime number.Second, basic math still that you never or rarely use or with very large time between usage might get rusty. You may understand the concept but not find the optimal solution. The way you are responding here shows quite a lot about how you are short sighted by instant-failing someone with a single question instead of trying to asses the whole person as much as you can. On you side, you are wasting opportunity to have a great person that could be a key player in your team by bringing other set of skill on the table. reply blibble 11 hours agorootparent> You probably do not have a child of 7 years old because they do not know at that age what is a prime number.it&#x27;s part of the curriculum for children of this age where I grew up (I did check)> The way you are responding here shows quite a lot about how you are short sighted by instant-failing someone with a single question instead of trying to asses the whole person as much as you can. On you side, you are wasting opportunity to have a great person that could be a key player in your team by bringing other set of skill on the table.it may also be the case that I have more in depth knowledge about the roles that I&#x27;ve interviewed candidates formost recently: hiring people to work for quantsnot instantly knowing that even numbers (other than 2) are not prime is a very strong signal reply hyperbovine 9 hours agorootparentprev> You probably do not have a child of 7 years old because they do not know at that age what is a prime number.A few do. And in 20 years you&#x27;re reallyreally going to want to hire them. reply jpeterson 8 hours agorootparentprevYou&#x27;re not testing for \"basic math skills\" here. What you&#x27;re testing for is more like \"immediately retrieves an irrelevant math fact after many years of having no need to think about it.\"Look, if you think this sort of thing allows you to identify great candidates, good for you. But in my experience, not only is this kind of practice stupid on its face, but it leads to engineering orgs packed with people who are good at memorizing trivia but terrible at solving real problems. reply ungruntled 12 hours agorootparentprevI think the key problem here is that is is a bad programming question. If you know anything about prime numbers then coming up with an answer is trivial. If you expect a more optimized solution, then you are really only gauging the interviewee’s understanding of prime numbers. So effectively the interview is more about mathematics than it is about programming or problem solving. replynoduerme 13 hours agorootparentprevI&#x27;m mad at myself now that it has eaten 15 minutes of my time trying to come up with the right optimization. What&#x27;s the trick? 2, +1, and then +2 from there on seems obvious but once you get to 9 is it worth building a list of nonprimes to skip? reply thewataccount 13 hours agorootparentI think they&#x27;re suggesting simply doing +2+1 is not a good idea since ~half of all numbers are effectively non-prime simply by being even numbers.You can double the speed by using +2 without using any fancy tricks, just changing a single character. reply nojs 9 hours agorootparentWell it doesn’t double the speed, since anything with a factor of 2 undergoes only one loop iteration inside is_prime. It basically just saves a function call reply dahfizz 10 hours agorootparentprevThere&#x27;s lots of more advanced optimizations, which would be an interesting avenue for discussion in an interview, but the drain dead algorithm would just use +2 instead of +1 reply Our_Benefactors 13 hours agorootparentprevhttps:&#x2F;&#x2F;stackoverflow.com&#x2F;a&#x2F;54544012&#x2F;1336678Common approach is to use square roots, this reduces the runtime. Recommend checking out project euler if you like solving hard math-code-o(n)-puzzles. reply noduerme 12 hours agorootparentI didn&#x27;t want to cheat by looking on S.O. but thanks ;)Yes it makes sense (in the GPT code) that you&#x27;d only go up to i * i ... although looking at pythonic while: statements is just gross to me in this context, it would feel a lot more readable to say, e.g. in PHP:for ($i=2;$i The Code Llama models provide stable generations with up to 100,000 tokens of context. All models are trained on sequences of 16,000 tokens and show improvements on inputs with up to 100,000 tokens.Edit: Reading the paper, key retrieval accuracy really deteriorates after 16k tokens, so it remains to be seen how useful the 100k context is. reply nabakin 18 hours agoparentLooks like they aren&#x27;t releasing a pretty interesting model too. In the paper they mention a \"Unnatural Code Llama\" which wipes the floor with every other model&#x2F;finetune on every benchmark except for slightly losing to Code Llama Python on MBPP pass@100 and slightly losing to GPT-4 on HumanEval pass@1 which is insane.Meta says later on that they aren&#x27;t releasing it and give no explanation. I wonder why given how incredible it seems to be. reply EvgeniyZh 17 hours agorootparentNote that current GPT-4 pass@1 for HumanEval is closer to 90% than to 67% reported in GPT-4 technical report, as reported, e.g., in [1][1] https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2305.01210 reply nabakin 17 hours agorootparentGood point, I guess Meta should be using that number in their chart reply jonchurch_ 17 hours agorootparentprevThe paper states it was instruction fine tuned with synthetic data (LLM generated instructions) ala another paper (“Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor”).The github repo associated with that paper is linked below. It links to the paper on arxiv, but also has some data in the repo.https:&#x2F;&#x2F;github.com&#x2F;orhonovich&#x2F;unnatural-instructions reply ilaksh 17 hours agorootparentMaybe they used GPT-4 to train it. OpenAI terms of use don&#x27;t allow that to be released commercially. reply nabakin 17 hours agorootparentI&#x27;ve seen this argued a lot but is it fact? OpenAI was able to train on data from other platforms and surely, those platforms weren&#x27;t letting their data go if they could help it. Unless some new laws have been passed, I don&#x27;t think OpenAI can legally prevent others from using their data to train models. OpenAI can&#x27;t have their cake and eat it too. After all, any content generated by AI can&#x27;t be copyrighted. reply lhl 16 hours agorootparentIt is indeed a fact that OpenAI&#x27;s Terms of Use do state that you can&#x27;t use their service to develop competing models: Section 2.c.iii - https:&#x2F;&#x2F;openai.com&#x2F;policies&#x2F;terms-of-useNow of course, the terms are not the law (so don&#x27;t govern the use of the generated data by any third party), they are an agreement between two parties. If you did click \"agree\" then that&#x27;s a binding agreement and there could be legal&#x2F;contractual repercussions (some of which are outlined in the terms). reply haldujai 14 hours agorootparentThat seems like a likely explanation, probably won&#x27;t get into legal trouble for using an OpenAI model for a research paper but redistributing said model may be upsetting enough for OpenAI trigger a legal challenge.Unnatural language used davinci-002 although that was a while ago, they only say \"similarly\" in this paper and don&#x27;t specify what they used. I can&#x27;t see a reason why they wouldn&#x27;t be releasing it if the unnatural prompts were generated by LLaMA2-family.In any case, replicating this training seems trivial and very cheap compute-wise for anyone who wanted to do it. reply nkohari 17 hours agorootparentprevThis is the most likely explanation for both why they wouldn&#x27;t release it and wouldn&#x27;t explain why. reply kapp_in_life 17 hours agorootparentprevLikely trained on internal code. reply mediaman 16 hours agorootparentThat model is trained on synthetically AI-generated code, not internal code.It suggests that synthetic training could be the future in increasing capability of smaller models (and perhaps bigger ones too). AI will train AI. reply haldujai 14 hours agorootparentI thought this specific model was referring to self-instruction using both synthetic prompts (generated from few-shot in-context prompting of presumably some OpenAI model, the original paper used text-davinci-002) as well as synthetic code (presumably Code Llama 7 like for self-instruct) subsequently validated with execution?The differences being it&#x27;s not just training on unvalidated synthetic data and this specific method (per the unnatural questions paper) results in increased instruction diversity which confers some added advantage and I&#x27;m assuming explains the performance gain over the also synthetic self-instruct code?I may be misunderstanding but this seems more nuanced than just training on synthetically AI-generated code and is more validating of synthetic instructions (i.e. low resource setting) rather than synthetic code (i.e. high resource setting). reply sroussey 15 hours agorootparentprevThat is the basis for https:&#x2F;&#x2F;synthesis.ai&#x2F; reply SubiculumCode 15 hours agorootparentI&#x27;m an amateur, but it seems to me that methods to synthesize will have to be distinct from methods of the generative model. replybrucethemoose2 19 hours agoparentprevDid Meta add scalable rope to the official implementation? reply snippyhollow 18 hours agorootparentWe changed RoPE&#x27;s theta from 10k to 1m and fine-tuned with 16k tokens long sequences. reply malwrar 18 hours agorootparentCurious, what led you to adjusting the parameters this way? Also, have you guys experimented with ALiBi[1] which claims better extrapolative results than rotary positional encoding?[1]: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2108.12409 (charts on page two if you’re skimming) reply ttul 18 hours agorootparentUndoubtedly, they have tried ALiBi… reply riku_iki 17 hours agoparentprev> The Code Llama models provide stable generations with up to 100,000 tokens of context.what is the trick to achieve 100k context? They can&#x27;t just use 100k wide transformer layer, it is cost prohibitive, right?.. reply littlestymaar 16 hours agorootparentI&#x27;m pretty sure they don&#x27;t do that, but for code the relevant relationship between two tokens is easy to determine with the semantics of the language alone (for instance you can say that tokens related to a local variable have no relationship with tokens outside), so it would lead to a sparse matrix in the transformer, reducing the cost of big contexts by a lot. But it would require language specific preprocessing, and whether you can make it fast is also dubious. I don&#x27;t think it&#x27;s been tried so far. reply up6w6 19 hours agoprevEven the 7B model of code llama seems to be competitive with Codex, the model behind copilothttps:&#x2F;&#x2F;ai.meta.com&#x2F;blog&#x2F;code-llama-large-language-model-cod... reply SparkyMcUnicorn 17 hours agoparentI&#x27;m not sure copilot is using codex anymore[0]. They&#x27;ve also been talking about a shift towards GPT-4 with \"Copilot X\" a few times now[1][2].[0] https:&#x2F;&#x2F;github.blog&#x2F;2023-07-28-smarter-more-efficient-coding...[1] https:&#x2F;&#x2F;github.com&#x2F;features&#x2F;preview&#x2F;copilot-x[2] https:&#x2F;&#x2F;github.blog&#x2F;2023-07-20-github-copilot-chat-beta-now-... reply zarzavat 8 hours agorootparentCopilot X is just their name for their project to bring AI to more areas of VSCode. I don’t believe they can use GPT-4 for completions because it’s a chat-optimized model. It seems that they are using something else, that blog post seems to imply it’s a custom-trained model. reply up6w6 9 hours agorootparentprevTrue. The results from codex are actually from code-cushman-001 (Chen et al. 2021), which is an older model that Copilot was based on. reply ramesh31 19 hours agoparentprev>Even the 7B model of code llama seems to be competitive with Codex, the model behind copilotIt&#x27;s extremely good. I keep a terminal tab open with 7b running for all of my \"how do I do this random thing\" questions while coding. It&#x27;s pretty much replaced Google&#x2F;SO for me. reply coder543 19 hours agorootparentYou&#x27;ve already downloaded and thoroughly tested the 7B parameter model of \"code llama\"? I&#x27;m skeptical. reply Eddygandr 19 hours agorootparentMaybe confused Code Llama with Llama 2? reply realce 19 hours agorootparentprevJust sign up at meta and you&#x27;ll get an email link in like 5 minutes reply coder543 19 hours agorootparentYes, that&#x27;s not a response to my comment.No one who has been using any model for just the past 30 minutes would say that it has \"pretty much replaced Google&#x2F;SO\" for them, unless they were being facetious. reply tyre 19 hours agorootparentThey said 7b llama which I read as the base LLaMa model, not this one specifically. All of these LLMs are trained on Stack Overflow so it makes sense that they’d be good out of the box. reply brandall10 18 hours agorootparentThe top level comment is specifically citing performance of code llama against codex. reply dataangel 19 hours agorootparentprevGPT4 has replaced SO for me and I&#x27;ve been using it for months. reply bbor 18 hours agorootparentprevIt was made available internally, I believe. So this is one of the many Meta engineers on this site —- after all, Facebook is now less hated than Google here ;) reply lddemi 19 hours agorootparentprevLikely meta employee? reply MertsA 18 hours agorootparentI&#x27;ve been using this or something similar internally for months and love it. The thing that gets downright spooky is the comments believe it or not. I&#x27;ll have some method with a short variable name in a larger program and not only does it often suggest a pretty good snippet of code the comments will be correct and explain what the intent behind the code is. It&#x27;s just a LLM but you really start to get the feeling the whole is greater than the sum of the parts. reply coder543 17 hours agorootparentI just don’t understand how anyone is making practical use of local code completion models. Is there a VS Code extension that I’ve been unable to find? HuggingFace released one that is meant to use their service for inference, not your local GPU.The instruct version of code llama could certainly be run locally without trouble, and that’s interesting too, but I keep wanting to test out a local CoPilot alternative that uses these nice, new completion models. reply fredoliveira 14 hours agorootparentThere are a bunch of VSCode extensions that make use of local models. Tabby seems to be the most friendly right now, but I admittedly haven&#x27;t tried it myself: https:&#x2F;&#x2F;tabbyml.github.io&#x2F;tabby&#x2F; replyohyes 18 hours agorootparentprevWhat hardware do you have that lets you run 7b and do other stuff at the same time? reply brucethemoose2 18 hours agorootparentPretty much any PC with 16GB+ of fast RAM can do this, any PC with a dGPU can do it well. reply selfhoster11 3 hours agorootparentprevA 7B model at 8-bit quantization takes up 7 GB of RAM. Less if you use a 6-bit quantization, which is nearly as good. Otherwise it&#x27;s just a question of having enough system RAM and CPU cores, plus maybe a small discrete GPU. reply woadwarrior01 39 minutes agorootparentYou’ll need a bit more than 7GB (~1 GB or so), even at 8 bit quantization, because of the KV-cache. LLM inference is notoriously inefficient without it, because it’s autoregressive. reply FrozenSynapse 1 hour agorootparentprevhow&#x27;s the generation speed on CPU? reply hmottestad 18 hours agorootparentprevMaybe a MacBook Pro. The Apple silicon chops can offload a special AI inference engine, and all ram is accessible by all parts of the chip. reply gzer0 13 hours agorootparentprevAn M1 Max with 64GB of RAM allows me to run multiple models simultaneously, on top of stable diffusion generating images non-stop + normal chrome, vscode, etc. Definitely feeling the heat, but it&#x27;s working. Well worth the investment. reply _joel 17 hours agorootparentprevIf you&#x27;re willing to sacrifice token&#x2F;s you can even run these on your phone. reply solarkraft 19 hours agorootparentprevHuh? Do you perhaps mean standard Llama? reply Palmik 17 hours agoprevThe best model, Unnatural Code Llama, is not released. Likely because it&#x27;s trained on GPT4 based data, and might violate OpenAI TOS, because as per the \"Unnatural\" paper [1], the \"unnatural\" data is generated with the help of some LLM -- and you would want to use as good of an LLM as possible.[1] https:&#x2F;&#x2F;arxiv.org&#x2F;pdf&#x2F;2212.09689.pdf reply redox99 17 hours agoparentThe good thing is that if it&#x27;s only finetuned on 15k instructions, we should see a community made model like that very soon. reply syntaxing 17 hours agoprevTheBloke doesn’t joke around [1]. I’m guessing we’ll have the quantized ones by the end of the day. I’m super excited to use the 34B Python 4 bit quantized one that should just fit on a 3090.[1] https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;CodeLlama-13B-Python-fp16 reply mchiang 16 hours agoparentOllama supports it already:`ollama run codellama:7b-instruct`https:&#x2F;&#x2F;ollama.ai&#x2F;blog&#x2F;run-code-llama-locallyMore models uploaded as we speak:https:&#x2F;&#x2F;ollama.ai&#x2F;library&#x2F;codellama reply jerrysievert 16 hours agorootparentwhile it supports it, so far I&#x27;ve only managed to get infinite streams of near nonsense from the ollama models (codellama:7b-q4_0 and codellama:latest)my questions were asking how to construct an indexam for postgres in c, how to write an r-tree in javascript, and how to write a binary tree in javascript. reply jmorgan 15 hours agorootparent> managed to get infinite streams of near nonsenseThis should be fixed now! To update you&#x27;ll have to run: ollama pull codellama:7b-instruct reply mchiang 16 hours agorootparentprevstill modifying the code completion (foundation &#x2F; python models) to see what&#x27;s causing the behavior.Have had some good success with the instruct model:codellama:7b-instruct reply jerrysievert 16 hours agorootparentthanks! this give me some results, but I&#x27;ve had to use a specific construct to get anything meaningful:usingwrite me a it&#x27;s managed to spit out code, rather than \"write a traversal function\". reply syntaxing 16 hours agorootparentprevSame, just tried it and it would give me infinite amount of blank lines reply jmorgan 15 hours agorootparentSorry, this should be fixed now! To update you&#x27;ll have to run: ollama pull codellama:7b-instruct reply pmayrgundter 6 hours agorootparentThis is amazing!I was up and running from clone&#x2F;build-from-scratch&#x2F;download in ~5m.It&#x27;s running on my M1.. it knows WebGL JS APIs better than I do, makes a passable attempt at VT100 ascii art, and well, should read more about Wolfram Automata, but does seem to know Game of Life!Thank you so much! reply carbocation 16 hours agorootparentprevSimilarly, I had it emit hundreds of blank lines before cancelling it. reply kordlessagain 16 hours agorootparentWhat fortune, I so happen to need hundreds of blank lines. reply justinsaccount 15 hours agorootparentprevMaybe it&#x27;s outputting https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Whitespace_(programming_langua... :-) reply syntaxing 16 hours agorootparentprevWhoa, it’s absolutely astounding how fast the community is reacting to these model release! reply Pesthuf 16 hours agorootparentprevIsn&#x27;t ollama terminal only? For code, that wouldn&#x27;t be good. reply natrys 16 hours agorootparentThey have a server&#x2F;client model. The binary comes with a basic terminal front-end but you can just create your own self-hosted GUI or editor integration against the API[1]:[1] https:&#x2F;&#x2F;github.com&#x2F;jmorganca&#x2F;ollama&#x2F;blob&#x2F;main&#x2F;docs&#x2F;api.md reply jmorgan 15 hours agorootparentIndeed! After pulling a model with \"ollama pull codellama\" you can access it via the REST API: curl -X POST http:&#x2F;&#x2F;localhost:11434&#x2F;api&#x2F;generate -d &#x27;{ \"model\": \"codellama\", \"prompt\":\"write a python script to add two numbers\" }&#x27; reply comechao 14 hours agorootparentprevI&#x27;m testing it on my M2 Air (16GB). Quite fast! reply stuckinhell 17 hours agoparentprevWhat kind of cpu&#x2F;gpu power do you need for quantization or these new gguf formats ? reply syntaxing 16 hours agorootparentI haven’t quantized these myself since TheBloke has been the main provider for all the quantized models. But when I did a 8 bit quantization to see how it compares to the transformers library load_in_8bit 4 months ago(?), it didn’t use my GPU but loaded each shard into the RAM during the conversion. I had an old 4C&#x2F;8T CPU and the conversion took like 30 mins for a 13B. reply selfhoster11 2 hours agorootparentprevI can quantize models up to 70B just fine with around 40-50 GB of system RAM, using the GGMLv3 format.GGUF seems not optimised yet, since quantizing with a newer version of llama.cpp supporting the format fails on the same hardware. I expect that to be fixed shortly.For inference, I understand that the hardware requirements will be identical as before. reply SubiculumCode 15 hours agorootparentprevi run llama2 13B models with 4-6 k-quantized oin a 3060 with 12Gb VRam reply UncleOxidant 16 hours agoparentprevIf I don&#x27;t want to run this locally is it runnable somewhere on huggingface? reply emporas 14 hours agorootparentReplicate has already hosted Llama2 13B, the chat version. My guess is, in a short span of days or weeks they will host the code version too. They charge a dollar for 2000 generations if i am not mistaken.https:&#x2F;&#x2F;replicate.com&#x2F;a16z-infra&#x2F;llama-2-13b-chat reply suyash 17 hours agoparentprevcan it be quantised further so it can run locally on a normal laptop of a developer? reply syntaxing 17 hours agorootparent“Normal laptop” is kind of hard to gauge but if you have a M series MacBook with 16GB+ RAM, you will be able to run 7B comfortably and 13B but stretching your RAM (cause of the unified RAM) at 4 bit quantization. These go all the way down to 2 bit but I personally I find the model noticeably deteriorate anything below 4 bit. You can see how much (V)RAM you need here [1].[1] https:&#x2F;&#x2F;github.com&#x2F;ggerganov&#x2F;llama.cpp#quantization reply totallywrong 5 hours agorootparentprevJust started playing with this, there&#x27;s a tool called ollama that runs Llama2 13B on my 16GB M1 Pro really smoothly with zero config. reply reacharavindh 19 hours agoprevCode llama Python is very interesting. Specifically tuned for Python.I wonder if we could make such specific LLMs (one that is proficient in all things Rust, another- all things Linux, all things genomics, all things physics modeling etc) and have them talk to each other to collaboratively solve problems.That would be a crazy future thing! Putting machines truly to work.. reply esperent 19 hours agoparentI think this is called \"mixture of experts\" and also there&#x27;s a lot of speculation that it&#x27;s how GPT-4 works, although probably with just a few large models rather than many small ones. reply jmiskovic 17 hours agorootparentIt&#x27;s been confirmed by multiple (unofficial) sources that GPT-4 is 8 models, each 220B parameters. Another rumor is GPT-4 being 16x111B models.There&#x27;s a quite fresh and active project replicating something similar with herd of llamas: https:&#x2F;&#x2F;github.com&#x2F;jondurbin&#x2F;airoboros reply brucethemoose2 19 hours agoparentprevIf you can find a large body of good, permissively licensed example code, you can finetune an LLM on it!There was a similar attempt for Godot script trained a few months ago, and its reportedly pretty good:https:&#x2F;&#x2F;github.com&#x2F;minosvasilias&#x2F;godot-dodoI think more attempts havent been made because base llama is not that great at coding in general, relative to its other strengths, and stuff like Starcoder has flown under the radar. reply seydor 13 hours agoparentprevStart with a CodeLlama for C, and start treating these systems as natural language compilers. C is low level enough and still readable for those rare moments reply bbor 18 hours agoparentprevMark my words: you’ve caught a glimpse of the near future :). Google “Society of Mind” if you’re not yet familiar reply benvolio 19 hours agoprev>The Code Llama models provide stable generations with up to 100,000 tokens of context.Not a bad context window, but makes me wonder how embedded code models would pick that context when dealing with a codebase larger than 100K tokens.And this makes me further wonder if, when coding with such a tool (or at least a knowledge that they’re becoming more widely used and leaned on), are there some new considerations that we should be applying (or at least starting to think about) when programming? Perhaps having more or fewer comments, perhaps more terse and less readable code that would consume fewer tokens, perhaps different file structures, or even more deliberate naming conventions (like Hungarian notation but for code models) to facilitate searching or token pattern matching of some kind. Ultimately, in what ways could (or should) we adapt to make the most of these tools? reply wokwokwok 18 hours agoparentThat seems daft.You can, I suppose, contract your code so that it’s context free and uses less tokens, but that makes it more confusing for humans and language models.Taken to the extreme, you can see obviously with one letter functions and variables like i, j, k the model will be able to infer literally nothing and, thus, produce arbitrary nonsense.Clearly the solution is to do what we already do to manage complexity which is to decompose large tasks into smaller black box modules with an api where the (large number of tokens) implementation is hidden and not known or relevant to using it.If you give an LLM a function signature and good description, maybe some usage examples, it doesn’t need the implementation to use it.Terseness decreases the ability of LLMs to process code; it doesn’t solve context length, and even at best it doesn’t scale.100k tokens is plenty.You don’t need to do anything like that. reply sicariusnoctis 6 hours agorootparent64k tokens ought to be enough for anybody. reply emporas 14 hours agorootparentprevThe process of decomposing the task into smaller steps and generate each step independently seems to be the correct way in my experience too. It works very well with GPT (chatGPT or GPT4).>100k tokens is plenty.The context window can be really helpful, in case there is a release of a new library and the user wants to generate code targeting the API of the library. When the training date stops at August 2023, any library released after that date is not known to the engine.My general opinion in regards to context window, is that 1 trillion tokens context window still may not be enough for all use cases. reply ttul 18 hours agoparentprevYour developer tool already maps out the entire code base in useful ways, such as knowing all the symbols available in the current context and the structure of classes. This information can be distilled for presentation to the LLM. For instance, if you’re wanting to generate a method implementation inside a C++ class, the LLM can be given a condensed version of the header files that the compiler would have access to on compiling that specific class. Removing white space and comments and boiling macros down saves a lot of tokens.You can also probably skip including standard library headers since those will be well known to the LLM through its fine tuning.Either way, consider that a typical preprocessed C++ file would push against the 100K limit even with some optimizations. You will definitely want to have some middleware doing additional refinement before presenting that file to the LLM. reply roughly 18 hours agoparentprevI’ve found the utility of the coding LLMs gets a lot higher when you’ve got code comments and descriptive variable and function names - the LLM makes better inferences and suggestions. We’ve seen similar on data - properly tagged data and descriptive field names helps the LLM to produce much more useful responses. I’m secretly hoping the spread of these tools will finally lead my fellow developers to comment their code and stop using three character variable names. reply GreedClarifies 18 hours agorootparentCommenting the code in this manner sounds like a job for an LLM, maybe with human assistance in the short run. reply bbor 18 hours agorootparentThis is my ultimate (short term) AI fear - letting it get into a feedback loop with itself, leading to perverse and incorrect results.To state my position more clearly: I don’t think an AI could comment code from scratch very well - how would it know all the decisions made, business logic considerations, historical conventions, micro-industry standards, etc?A good benchmark I was told once was “if a human expert couldn’t do it, an AI probably can’t either”. And commenting code I didn’t write would certainly test the bounds of my abilities reply gonzan 15 hours agoparentprevI built a VS code extension a while back that I still use that wraps GPT-4 and writes code directly in my editor.The method I used to choose which files to feed GPT-4 was embeddings-based. I got an embedding for each file and then an embedding from the instruction + some simple processing to pick the files more likely to be relevant. It isn&#x27;t perfect but good enough most of the time in medium-sized codebases (not very large ones).The one thing I started doing because of how I implemented this is make files shorter and move stuff into different files. Having a 1k+ LOC file is prohibitive because it eats up all the context window (although with 100k context window maybe less so). I think it&#x27;s a good idea to keep files short anyways.There&#x27;s other smarter things that can be done (like embed and pass individual functions&#x2F;classes instead of entire files) so I have no doubt someone will build something smarter soon. You&#x27;ll likely not have to change your coding patterns at all to make use of AI. reply brucethemoose2 19 hours agoparentprevThis sounds like a job for middleware. Condensing split code into a single huge file, shortening comments, removing whitespace and such can be done by a preprocessor for the llm. reply gabereiser 18 hours agorootparentSo now we need an llmpack like we did webpack? Could it be smart enough to truncate comments, white space, etc? reply brucethemoose2 18 hours agorootparentYou dont even need an llm for trimming whitespace, just a smart parser with language rules like ide code checkers already use. Existing llms are fine at summarizing comments, especially with language specific grammar constraints. reply gabereiser 16 hours agorootparentMy point. We don’t need the middleware. reply visarga 17 hours agoparentprevA good practice is to have a prompt file where you keep the information you want the model to have at its disposal. Then you put it in the start of your conversations with GPT-4. It&#x27;s also good documentation for people.You start a project by defining the task. Then as you iterate, you can add new information to the prompt. But it can be also partially automated - the model can have a view of the file structure, classes, routes, assets and latest errors.I was really hoping that the one year update of Codex would be that - a LLM that can see deep into the project, not just code, but runtime execution, debugging, inspecting and monitoring. Something that can iterate like autoGPT. Unfortunately it didn&#x27;t improve much and has weird conflicts with the native code completion in VSCode, you get freezes or doubled brackets. reply rawrawrawrr 3 hours agoparentprev> Not a bad contextA little understated, this is state of the art. GPT-4 only offers 32k. reply adamgordonbell 18 hours agoparentprevSolutions exist that feed LLMS ctags, and seem to work well. The function signatures and symbols names for a code base are much smaller than the actual code. reply sean_flanigan 7 hours agorootparentI know about https:&#x2F;&#x2F;github.com&#x2F;paul-gauthier&#x2F;aider. Have you got a link to any others? reply smcleod 2 hours agorootparentI&#x27;m using this right now, but it&#x27;s noted that \"ctags only work with GPT4\" so I&#x27;m yet to get them working with llama locally. reply jmorgan 17 hours agoprevTo run Code Llama locally, the 7B parameter quantized version can be downloaded and run with the open-source tool Ollama: https:&#x2F;&#x2F;github.com&#x2F;jmorganca&#x2F;ollama ollama run codellama \"write a python function to add two numbers\"More models coming soon (completion, python and more parameter counts) reply lordnacho 18 hours agoprevCopilot has been working great for me thus far, but it&#x27;s limited by its interface. It seems like it only knows how to make predictions for the next bit of text.Is anyone working on a code AI that can suggest refactorings?\"You should pull these lines into a function, it&#x27;s repetitive\"\"You should change this structure so it is easier to use\"Etc reply adocomplete 17 hours agoparentGive Cody a try! (Cody.dev)With Cody you can create embeddings for your entire repo, so Cody will have much greater context about your code base and the problems you&#x27;re trying to solve.Disclaimer: I just joined Sourcegraph a few weeks ago. reply stuzenz 13 hours agorootparentCody is great, it had become my go-to (and I pay for Github Co-pilot).With that said, they have recently changed the architecture, with the local install required, and I have not managed (yet) to get it working with NixOS. Once I have some more time, I will try again - it looks like there will be some hoops to go through. https:&#x2F;&#x2F;nixos.org&#x2F;manual&#x2F;nixpkgs&#x2F;stable&#x2F;#ssec-pkgs-appimageT...Kudos to the Source Graph team, Source Graph&#x27;s original product was nicely thought out and ahead of it&#x27;s time. Nice to see how the original product gave a nice basis for building out Cody. reply phillipcarter 18 hours agoparentprevSourceGraph Cody is going in that direction, as is Copilot Chat. But it&#x27;s still early days. I don&#x27;t think there&#x27;s anything robust here yet. reply nvm0n2 14 hours agoparentprevNeither of those tasks require AI. IntelliJ IDEA will happily suggest both for you today, locally. It can find large chunks of duplicated code and automatically refactor them out to functions for you. And it has many inspections that suggest refactorings to make code clearer. reply sestinj 16 hours agoparentprevYou can use Continue for all of this, as easy as highlighting code and making the request. We also support using Code Llama: https:&#x2F;&#x2F;continue.dev&#x2F;docs&#x2F;walkthroughs&#x2F;codellama reply thewataccount 16 hours agorootparentAny plans to support IntelliJ? reply vunderba 11 hours agorootparentYeah this would be a crucial feature - interoperability with Jetbrains IDEs. reply GordonS 14 hours agorootparentprevI&#x27;d also be really keen on this. reply armchairhacker 17 hours agoparentprevCopilot calls these \"Code Brushes\" https:&#x2F;&#x2F;githubnext.com&#x2F;projects&#x2F;code-brushes&#x2F;Last I heard they are in beta and don&#x27;t work very well (even on the examples page: the \"add types\" brush is too strict, since `a` and `b` are checked for `null`, and the \"fix simple bug\" is a typo) reply claytongrassick 16 hours agoparentprevI&#x27;ve been using Cursor (https:&#x2F;&#x2F;www.cursor.so&#x2F;) and it can do embeddings of the entire codebase, refactoring entire classes, etc. I had it rewrite a UI to add state to show one item at a time and have a selection list to the left and it executed it perfectly in MUI controls, first try. reply fpgaminer 14 hours agoparentprevhttps:&#x2F;&#x2F;docs.github.com&#x2F;en&#x2F;copilot&#x2F;github-copilot-chat&#x2F;using... can basically do that if you&#x27;re in the beta. reply make3 18 hours agoparentprevThere&#x27;s an instruct model in there, you can definitely use it for this, that&#x27;s one of the objectives.An instruct model means that you can ask it to do what you want, including asking it to give you refactoring ideas from the code you will give it. reply regularfry 17 hours agorootparentSounds like what&#x27;s needed is a bit of tooling in the background consistently asking the LLM \"How would you improve this code?\" so you don&#x27;t need to actually ask it. reply lordnacho 17 hours agorootparentprevHow do I access it from my IDE? Jetbrains&#x2F;VSCode? reply artificialLimbs 18 hours agoparentprevI let mine generate whatever it likes, then add a comment below such as \"# Refactor the above to foo..\" Works fairly well at times. reply lordnacho 17 hours agorootparentCan it suggest deletions? Just seems like I don&#x27;t know how to use it. reply Draiken 17 hours agoprevAs a complete noob at actually running these models, what kind of hardware are we talking here? Couldn&#x27;t pick that up from the README.I absolutely love the idea of using one of these models without having to upload my source code to a tech giant. reply dangelov 17 hours agoparentI&#x27;ve used Ollama to run Llama 2 (all variants) on my 2020 Intel MacBook Pro - it&#x27;s incredibly easy. You just install the app and run a couple of shell commands. I&#x27;m guessing soon-ish this model will be available too and then you&#x27;d be able to use it with the Continue VS Code extension.Edited to add: Though somewhat slow, swap seems to have been a good enough replacement for not having the loads of RAM required. Ollama says \"32 GB to run the 13B models\", but I&#x27;m running the llama2:13b model on a 16 GB MBP. reply j45 17 hours agorootparentApple Silicon, especially an M1 Max Studio seems to be an interesting machine to hang on to as the models become more and more efficient with using less and less.If there&#x27;s nay other opinions or thoughts on this, I&#x27;d be very happy to learn as well. I have considered the eGPU route connected to a 1L PC such as a thinkcentre m80&#x2F;90. reply BoorishBears 13 hours agorootparentI have a 64 GB M1 Max MBP, and I&#x27;d say unless you really have some academic interest towards messing with open models, for now accessing SOTA models via a REST API has better latency for a given quality.Claude 1.2 instant is as fast as 3.5, follows instructions at a quality closer to 4, and has a 100k context window. Hard to compete with that with an open source model right now. reply jkeisling 12 hours agorootparentHow does open source compete with the Claude API? Easy: actually let you use the model. From the signup page:> Anthropic is rolling out Claude slowly and incrementally, as we work to ensure the safety and scalability of it, in alignment with our company values.> We&#x27;re working with select partners to roll out Claude in their products. If you&#x27;re interested in becoming one of those partners, we are accepting applications. Keep in mind that, due to the overwhelming interest we&#x27;ve received so far, we may take a while to reply.No thanks, I&#x27;d much rather not wait months to see if my app deserves their oh-so-limited attention, or \"aligns with the values\" of a company taking $400m from Sam Bankman-Fried.To be more charitable to your underlying point, Claude 2 is free to chat with via Anthropic&#x27;s website, Poe, or Slack, and the GPT-4 API is open to use. If you&#x27;re building a prototype or just need a chatbot, these do have better results and dev experience, at least for now. But I don&#x27;t think picking on your Claude API example is unfair. These companies could randomly refuse your prompts via some opaque \"moderation API\" (that all GPT fine-tuning data goes through!), train on your company&#x27;s proprietary data, spy on your most intimate questions, or just not find you worth the trouble and cut you off, at any time. THAT is why open source beats proprietary hands down: My device, my data, my weights, my own business. reply BoorishBears 7 hours agorootparentPerfect example of why I said academic interest.Awkward tie-ins between SBF and value systems (?) have no effect on practical usage.A theoretical concern they might train on my API data after saying they won&#x27;t doesn&#x27;t either. Amazon might be training on everything not bolted down in S3, not worth wasting brain power on that.The moderation API isn&#x27;t some magic gotcha, it&#x27;s documented. They don&#x27;t want to deal with people fine tuning for porn. Maybe you have some ideological disagreement on that but it&#x27;s not of practical relevance when trying to write code.At the end of the day you&#x27;re not alone in these opinions. But some of us prefer pragmatism over hype. Until someone catches OpenAI or Anthropic trying to kill their golden goose by breaking their GDPR, HIPPA, and SOC2 certifications, I&#x27;m going to take delivered value over theoretical harm. reply kordlessagain 7 hours agorootparentIn my opinion the risk is coupling accelerated intelligence to competitive business models. reply BoorishBears 5 hours agorootparentThe accelerated intelligence wouldn&#x27;t exist without competitive business models. replyliuliu 17 hours agoparentprev34B should be able to run on 24GiB consumer graphics card, or 32GiB Mac (M1 &#x2F; M2 chips) with quantization (5~6bit) (and 7B should be able to run on your smart toaster). reply epolanski 17 hours agorootparentAre there cloud offerings to run those models on somebody&#x27;s else computer?Any \"eli5\" tutorial on how to do so, if so?I want to give these models a run but I have no powerful GPU to run them on so don&#x27;t know where to start. reply RossBencina 22 minutes agorootparentrunpod, togethercomputer, replicate.Matthew Berman has a tutorial on YT showing how to use TheBloke&#x27;s docker containers on runpod. Sam Witteveen has done videos on together and replicate, they both offer cloud-hosted LLM inference as a service. reply kordlessagain 7 hours agorootparentprevI started something here about this: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37121384 reply redox99 16 hours agorootparentprevOn runpod there is a TheBloke template with everything set up for you. An A6000 is good enough to run 70b 4bit. reply redox99 17 hours agoparentprevIf you want to run them fast, a 12GB GPU (e.g 3060) for the 13B and a 24GB GPU for the 34B (e.g 3090). Otherwise llama.cpp CPU inference would work on most machines. reply scriptsmith 18 hours agoprevHow are people using these local code models? I would much prefer using these in-context in an editor, but most of them seem to be deployed just in an instruction context. There&#x27;s a lot of value to not having to context switch, or have a conversation.I see the GitHub copilot extensions gets a new release one every few days, so is it just that the way they&#x27;re integrated is more complicated so not worth the effort? reply sestinj 16 hours agoparentYou can use Continue as a drop-in replacement for Copilot Chat with Code Llama. We&#x27;ve released a short tutorial here: https:&#x2F;&#x2F;continue.dev&#x2F;docs&#x2F;walkthroughs&#x2F;codellama. It should save you a lot of time context-switching; you can just highlight code and ask questions or make edits, all with keyboard shortcuts reply modeless 18 hours agoparentprevhttp:&#x2F;&#x2F;cursor.sh integrates GPT-4 into vscode in a sensible way. Just swapping this in place of GPT-4 would likely work perfectly. Has anyone cloned the OpenAI HTTP API yet? reply lhl 15 hours agorootparentLocalAI https:&#x2F;&#x2F;localai.io&#x2F; and LMStudio https:&#x2F;&#x2F;lmstudio.ai&#x2F; both have fairly complete OpenAI compatibility layers. llama-cpp-python has a FastAPI server as well: https:&#x2F;&#x2F;github.com&#x2F;abetlen&#x2F;llama-cpp-python&#x2F;blob&#x2F;main&#x2F;llama_... (as of this moment it hasn&#x27;t merged GGUF update yet though) reply fudged71 18 hours agorootparentprevI was tasked with a massive project over the last month and I&#x27;m not sure I could have done it as fast as I have without Cursor. Also check out the Warp terminal replacement. Together it&#x27;s a winning combo! reply thewataccount 18 hours agoparentprevFor in-editor like copilot you can try this locally - https:&#x2F;&#x2F;github.com&#x2F;smallcloudai&#x2F;refactThis works well for me except the 15B+ don&#x27;t run fast enough on a 4090 - hopefully exllama supports non-llama models, or maybe it&#x27;ll support CodeLLaMa already I&#x27;m not sure.For general chat testing&#x2F;usage this works pretty well with lots of options - https:&#x2F;&#x2F;github.com&#x2F;oobabooga&#x2F;text-generation-webui&#x2F; reply msp26 17 hours agorootparent>This works well for me except the 15B+ don&#x27;t run fast enough on a 4090I assume quantized models will run a lot better. TheBloke already seems like he&#x27;s on it.https:&#x2F;&#x2F;huggingface.co&#x2F;TheBloke&#x2F;CodeLlama-13B-fp16 reply thewataccount 16 hours agorootparentUnfortunately what I tested was StarCoder 4bit. We really need exllama which should make even 30b viable from what I can tell.Because codellama is llama based it may just work possibly? reply modeless 19 hours agoprevInteresting that there&#x27;s a 34B model. That was missing from the original Llama 2 release. I wonder if it&#x27;s still usable for general non-code chat tasks or if the code fine tuning destroyed that. It should be the best model that would still fit on 24GB gaming GPUs with quantization, because 70B doesn&#x27;t fit. reply brucethemoose2 19 hours agoparentSomeone \"grafted\" llama 33B onto llama v2 13B to make \"llama 22B\"https:&#x2F;&#x2F;huggingface.co&#x2F;chargoddard&#x2F;llama2-22bTheoretically this is an even better size, as it would fit on a 20GB-24GB GPU with more relaxed quantization and much longer context.Metrics are slightly below 13B, but the theory is that the higher parameter count is more amenable to finetuning. If you search for 22B on huggingface, you can see that frankenllama experiments are ongoing:https:&#x2F;&#x2F;huggingface.co&#x2F;models?sort=modified&search=22b reply nabakin 18 hours agoparentprevLooks like they left out another model though. In the paper they mention a \"Unnatural Code Llama\" which wipes the floor with every other model&#x2F;finetune on every benchmark except for slightly losing to Code Llama Python on MBPP pass@100 and slightly losing to GPT-4 on HumanEval pass@1 which is insane.Meta says later on that they aren&#x27;t releasing it and give no explanation. I wonder why given how incredible it seems to be. reply ImprobableTruth 17 hours agorootparentIt&#x27;s \"unnatural\" because it was finetuned on generated data using another model, almost certainly gpt-4 (whose TOS forbid this). reply redox99 18 hours agoparentprevI can&#x27;t imagine it being better than Llama1 33B, after all this code finetuning. reply modeless 18 hours agorootparentBut the license for llama 2 is a whole lot better. reply redox99 18 hours agorootparentMeh.If you&#x27;re using it commercially you&#x27;re probably deploying it on a server where you&#x27;re not limited by the 24GB and you can just run llama 2 70b.The majority of people who want to run it locally on 24GB either want roleplay (so non commercial) or code (you have codellama) reply mymac 18 hours agoprevNever before in the history of mankind was a group so absolutely besotted with the idea of putting themselves out of a job. reply ttul 18 hours agoparentThat’s just one perspective… Another perspective is that LLMs enable programmers to skip a lot of the routine and boring aspects of coding - looking up stuff, essentially - so they can focus on the fun parts that engage creativity. reply KingOfCoders 1 hour agorootparentOne coachman to the other: \"Another perspective about this car thing, you can skip all the routine and boring trips - they are done with cars. You can focus on the nice trips that make you feel good\". reply mymac 18 hours agorootparentprevBut it won&#x27;t stop there. Why would it stop at some arbitrarily defined boundary? The savings associated with no longer having to pay programmers the amounts of money that they believe they are worth (high enough to result in collusion between employers) are just too tempting. reply ilaksh 17 hours agorootparentSome form of AI will eventually take over almost all existing jobs. Whether those jobs evolve or not somehow and new jobs replace them, we will see.But it&#x27;s definitely not just programmers. And it will take time.Society needs to adjust. Stopping progress would not be a solution and is not possible.However, hopefully we can pause before we create digital animals with hyperspeed reasoning and typical animal instincts like self-preservation. Researchers like LeCun are already moving on from things like LLMs and working on approaches that really imitate animal cognition (like humans) and will eventually blow all existing techniques out of the water.The path that we are on seems to make humans obsolete within three generations or so.So the long term concern is not jobs, but for humans to lose control of the planet in less than a century.On the way there we might be able to manage a new golden age -- a crescendo for human civilization. reply lsmeducation 17 hours agorootparentContinuing your aside…Humans don’t become obsolete, we become bored. This tech will make us bored. When humans get too bored and need shit to stir up, we’ll start a war. Take US and China, global prosperity is not enough right? We need to stoke the flames of war over Taiwan.In the next 300 years we’ll wipe out most of each other in some ridiculous war, and then rebuild. reply ilaksh 17 hours agorootparentI agree that WWIII is a concern but I don&#x27;t think it will be brought about by boredom.\"Global prosperity\" might be true in a very long-term historical sense, but it&#x27;s misleading to apply it to the immediate situation.Taiwan is not just a talking point. Control over Taiwan is critical for maintaining hegemony. When that is no longer assured, there will likely be a bloody battle before China is given the free reign that it desires.WWIII is likely to fully break out within the next 3-30 years. We don&#x27;t really have the facilities to imagine what 300 years from now will look like, but it will likely be posthuman. reply lsmeducation 16 hours agorootparentI’ll go with the 30 year mark. Countries like Russia or China don’t get humbled in a loss (like Germany didn’t in WW1). Russia will negotiate some terms for Ukraine (or maintain perpetual war), but I believe it will become a military state that will funnel all money into the defense sector. The same with Iran, and the same with China.Iran supplies Russia with drones. I can promise you Russia will help Iran enrich their uranium. They are both pariah states, what do they have to lose? Nuclear Iran, here enters Israel.Everyone’s arming up, there’s a gun fight coming. reply lsmeducation 17 hours agorootparentprevOkay, think about it this way. This thing helps generate tons and tons of code. The more code people (or this thing) writes, the more shit there is to debug. More and more code, each calling each other means more and more insane bugs.We’re going to move from debugging some crap the last developer wrote to debugging an order of magnitude more code the last developer generated.It’s going to be wonderful for job prospects really. reply Sakthimm 3 hours agorootparentUntil AI figures out debugging reply swader999 14 hours agorootparentprevThe answer to AI stealing your job is to go ahead and start a company, solve a hard problem, sell the solution and leverage AI to do this. reply astrange 5 hours agorootparentThe only thing that takes anyone&#x27;s job is demand shortfalls. Productivity increases certainly don&#x27;t do it. It&#x27;s like saying getting a raise makes you poorer. reply drcongo 14 minutes agoparentprevWell, since Brexit anyway. reply quickthrower2 11 hours agoparentprevThe best interpretation of this is you mean eventually ML&#x2F;AI will put programmers out of a job, and not Code LLama specifically.However it is hard to tell how that might pan out. Can such an ML&#x2F;AI do all the parts of the job effectively? A lot of non-coding skill bleed into the coder&#x27;s job. For example talking to people who need an input to the task and finding out what they are really asking for, and beyond that, what the best solution is that solves the underlying problem of what they ask for, while meeting nonfunctional requirements such as performance, reliability, code complexity, and is a good fit for the business.On the other hand eventually the end users of a lot of services might be bots. You are more likely to have a pricing.json than a pricing.html page, and bots discover the services they need from searches, negotiate deals, read contracts and sue each other etc.Once the programming job (which is really a \"technical problem solver\" job) is replaced either it will just be same-but-different (like how most programmers use high level languages not C) or we have invented AGI that will take many other jobs.In which case the \"job\" aspect of it is almost moot. Since we will be living in post-scarcity and you would need to figure out the \"power\" aspect and what it means to even be sentient&#x2F;human. reply thewataccount 16 hours agoparentprevIs automation not what every engineer strives for when possible? Especially software developers.From my experience with github copilot and GPT4 - developers are NOT going anywhere anytime soon. You&#x27;ll certainly be faster though. reply 037 15 hours agoparentprevI understand the fear of losing your job or becoming less relevant, but many of us love this work because we&#x27;re passionate about technology, programming, science, and the whole world of possibilities that this makes... possible.That&#x27;s why we&#x27;re so excited to see these extraordinary advances that I personally didn&#x27;t think I&#x27;d see in my lifetime.The fear is legitimate and I respect the opinions of those who oppose these advances because they have children to provide for and have worked a lifetime to get where they are. But at least in my case, the curiosity and excitement to see what will happen is far greater than my little personal garden. Damn, we are living what we used to read in the most entertaining sci-fi literature!(And that&#x27;s not to say that I don&#x27;t see the risks in all of this... in fact, I think there will be consequences far more serious than just \"losing a job,\" but I could be wrong) reply kbrannigan 15 hours agoparentprevDo you really want to spend you days writing REDUX accumulators? reply vunderba 11 hours agoparentprevIf we get to the point where these large language models can create complete applications and software solutions from design specs alone, then there&#x27;s no reason to believe that this would be limited to merely replacing software devs.It would likely impact a far larger swath of the engineering &#x2F; design industry. reply astrange 5 hours agoparentprevYou can&#x27;t get promoted unless you put yourself out of a job. reply PUSH_AX 15 hours agoparentprevWe&#x27;re not looking at a product that&#x27;s putting anyone out of a job though, we&#x27;re looking at a product that frees up a lot of time, and time is great. reply worksonmine 14 hours agoparentprevThis should be the only goal of mankind so we can smell the flowers instead of wasting our years in some cubicle. Some people will always want to work, but it shouldn&#x27;t be the norm. What&#x27;s the point really unless we&#x27;re doing something we&#x27;re passionate about? The economy? reply yborg 17 hours agoparentprevWhen mechanized textile machinery was invented, the weavers that had jobs after their introduction were those that learned how to use them. reply ilaksh 19 hours agoprevBetween this, ideogram.ai (image generator which can spell, from former Google Imagen team member and others), and ChatGPT fine-tuning, this has been a truly epic week.I would argue that many teams will have to reevaluate their LLM strategy _again_ for the second time in a week. reply astrange 5 hours agoparentSDXL and DeepFloyd can spell. It&#x27;s more or less just a matter of having a good enough text encoder.I tried Ideogram yesterday and it felt too much like existing generators (base SD and Midjourney). DALLE2 actually has some interestingly different outputs, the problem is they never update it or fix the bad image quality. reply ShamelessC 14 hours agoparentprevDid ideogram release a checkpoint? reply ilaksh 13 hours agorootparentI can&#x27;t find any info or Discord or forum or anything. I think it&#x27;s a closed service that they plan to sell to make money. reply WhitneyLand 13 hours agoprevHow much am I’m missing out on with tools like this or code pilot, compared to using GPT-4?I guess since Xcode doesn’t have a good plug-in architecture for this I began experimenting more with a chat interface.So far gpt-4 has seemed quite useful for generating code, reviewing code for certain problems, etc. reply citruscomputing 10 hours agoparentEditor plugins are fantastic about completing based on a pattern. That&#x27;s the main thing you&#x27;re missing out on imo - it&#x27;s worth it to hit tab, but not to copy&#x2F;paste and say \"finish this line for me, it looks almost like the one above.\"There&#x27;s also the real-time aspect where you can see that it&#x27;s wrong via the virtual text, type a few characters, then it gets what you&#x27;re doing and you can tab complete the rest of the line.It&#x27;s faster to converse with when you don&#x27;t have to actually have a conversation, if that makes sense? The feedback loop is much shorter and doesn&#x27;t require natural language, or nearly as much context switching. reply 1024core 14 hours agoprevIf GPT-4&#x27;s accuracy is 67% and this is 54%, how can these guys claim to be SOTA? reply rgbrgb 10 hours agoparentThis runs locally on a MacBook. reply binreaper 11 hours agoparentprevSeriously, I was expecting to read the article and them be on a level on-par with GPT-4 or higher. For all this chat of how long Google&#x2F;Facebook have been in the AI space longer than OpenAI, their products don&#x27;t speak to that.. reply KingOfCoders 1 hour agoprevAny performance tests? (e.G. tokens&#x2F;s on a 4090?) reply m00nsome 2 hours agoprevWhy do they not release the unnatural Variant of the model? According to the paper it beats all of the other variants and seems to be close to GPT-4. reply awwaiid 5 hours agoprevI want to see (more) code models trained on git diffs reply KaiserPro 12 hours agoprevThis is great for asking questions like \"how do I do x with y\" and this code > isn&#x27;t working, whats wrong? Much faster that googling, or a great basis for forming a more accurate google search.Where its a bit shit is when its used to provide auto suggest. It hallucinates plausible sounding functions&#x2F;names, which for me personally are hard to stop if they are wrong (I suspect that&#x27;s a function of the plugin) reply SubiculumCode 5 hours agoparenthallucinations can be resuces by incorporating &#x27;retrieval automated generation&#x27; , RAG, on the front end. likely function library defs could be automagically entered as prompt&#x2F;memory inputs. reply TheRealClay 8 hours agoprevAnyone know of a docker image that provides an HTTP API interface to Llama? I&#x27;m looking for a super simple sort of &#x27;drop-in&#x27; solution like that which I can add to my web stack, to enable LLM in my web app. reply nodja 7 hours agoparenthttps:&#x2F;&#x2F;github.com&#x2F;abetlen&#x2F;llama-cpp-python has a web server mode that replicates openai&#x27;s API iirc and the readme shows it has docker builds already. reply TheRealClay 7 hours agorootparentThanks! As someone just getting started, I really appreciate the tip! reply natch 18 hours agoprevWhy wouldn’t they provide a hosted version? Seems like a no brainer… they have the money, the hardware, the bandwidth, the people to build support for it, and they could design the experience and gather more learning data about usage in the initial stages, while putting a dent in ChatGPT commercial prospects, and all while still letting others host and use it elsewhere. I don’t get it. Maybe it was just the fastest option? reply redox99 17 hours agoparentProbably the researchers at meta are only interested in research, and productionizing this would be up to other teams. reply natch 14 hours agorootparentBut Yann LeCun seems to think the safety problems of eventual AGI will be solved somehow.Nobody is saying this model is AGI obviously.But this would be an entry point into researching one small sliver of the alignment problem. If you follow my thinking, it’s odd that he professes confidence that AI safety is a non issue, yet from this he seems to want no part in understanding it.I realize their research interest may just be the optimization &#x2F; mathy research… that’s their prerogative but it’s odd imho. reply ShamelessC 14 hours agorootparentIt’s not that odd and I think you’re overestimating the importance of user submitted data for the purposes of alignment research. In particular because it’s more liability for them to try to be responsible for outputs. Really though, this way they get a bunch of free work from volunteers in open source&#x2F;ML communities. reply jasfi 19 hours agoprevNow we need code quality benchmarks comparing this against GPT-4 and other contenders. reply nick0garvey 17 hours agoparentThey show the benchmarks in the original post, a few pages down reply jasfi 17 hours agorootparentThanks, I missed that somehow. reply andrewjl 18 hours agoprevWhat I found interesting in Meta&#x27;s paper is the mention of HumanEval[1] and MBPP[2] as benchmarks for code quality. (Admittedly maybe they&#x27;re well-known to those working in the field.)I haven&#x27;t yet read the whole paper (nor have I looked at the benchmark docs which might very well cover this) but curious how these are designed to avoid issues with overfitting. My thinking here is that canned algorithm type problems common in software engineering interviews are probably over represented in the training data used for these models. Which might point to artificially better performance by LLMs versus their performance on more domain-specific type tasks they might be used for in day-to-day work.[1] https:&#x2F;&#x2F;github.com&#x2F;openai&#x2F;human-eval[2] https:&#x2F;&#x2F;github.com&#x2F;google-research&#x2F;google-research&#x2F;tree&#x2F;mast... reply e12e 17 hours agoprevCurious if there are projects to enable working with these things self-hosted, tuned to a git repo as context on the cli, like a Unix filter - or with editors like vim? (I&#x27;d love to use this with Helix)I see both vscode and netbeans have a concept of \"inference URL\" - are there any efforts like language server (lsp) - but for inference? reply ilaksh 13 hours agoparenthttps:&#x2F;&#x2F;github.com&#x2F;runvnc&#x2F;smartcat reply ingridpan 13 hours agoparentprevnot quite self-hosted but gradient.ai gives you access to llama2 via CLI reply 194 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Code Llama is a new large language model (LLM) specifically designed for coding tasks.",
      "It is capable of generating code and natural language about code from code or natural language prompts.",
      "Code Llama is available in three models: Code Llama, Codel Llama - Python, and Code Llama - Instruct.",
      "It has outperformed other publicly available LLMs on coding tasks.",
      "The models are built on top of Llama 2 and are free for research and commercial use.",
      "Code Llama has the potential to improve developer workflows and make coding more accessible.",
      "It supports popular programming languages and can be used for code completion and debugging.",
      "Safe and responsible use of Code Llama is emphasized, and the models have undergone safety evaluations.",
      "The release of Code Llama encourages innovation and collaboration in the AI community."
    ],
    "commentSummary": [
      "Code Llama is a highly advanced language model for coding that can generate optimized code, sparking discussions about its potential applications and implications for code optimization and generating pull requests.",
      "The importance of understanding prime numbers in software engineering jobs is debated, while speculation arises about the training methods and context size of Code Llama.",
      "Discussions cover using GPUs for running Code Llama locally, hardware requirements, tools, and models for optimizing and improving code. There is also a debate between using open-source models versus accessing state-of-the-art models through a REST API.",
      "The performance and licensing of a model called \"Unnatural Code Llama\" are debated, alongside the potential impacts of AI advancements, such as job security and human control.",
      "Participants express excitement about language models revolutionizing the industry but acknowledge limitations, including concerns about potentially inflating performance through training data."
    ],
    "points": 756,
    "commentCount": 445,
    "retryCount": 0,
    "time": 1692883605
  },
  {
    "id": 37248844,
    "title": "Code Llama, a state-of-the-art large language model for coding",
    "originLink": "https://ai.meta.com/blog/code-llama-large-language-model-coding/",
    "originBody": "Research Blog Resources About FEATURED Large Language Model Introducing Code Llama, a state-of-the-art large language model for coding August 24, 2023 Takeaways Code Llama is a state-of-the-art LLM capable of generating code, and natural language about code, from both code and natural language prompts. Code Llama is free for research and commercial use. Code Llama is built on top of Llama 2 and is available in three models: Code Llama, the foundational code model; Codel Llama - Python specialized for Python; and Code Llama - Instruct, which is fine-tuned for understanding natural language instructions. In our own benchmark testing, Code Llama outperformed state-of-the-art publicly available LLMs on code tasks RECOMMENDED READS Code Llama research paper Code Llama GitHub Download the Code Llama model Today, we are releasing Code Llama, a large language model (LLM) that can use text prompts to generate code. Code Llama is state-of-the-art for publicly available LLMs on code tasks, and has the potential to make workflows faster and more efficient for current developers and lower the barrier to entry for people who are learning to code. Code Llama has the potential to be used as a productivity and educational tool to help programmers write more robust, well-documented software. The generative AI space is evolving rapidly, and we believe an open approach to today’s AI is the best one for developing new AI tools that are innovative, safe, and responsible. We are releasing Code Llama under the same community license as Llama 2. How Code Llama works Code Llama is a code-specialized version of Llama 2 that was created by further training Llama 2 on its code-specific datasets, sampling more data from that same dataset for longer. Essentially, Code Llama features enhanced coding capabilities, built on top of Llama 2. It can generate code, and natural language about code, from both code and natural language prompts (e.g., “Write me a function that outputs the fibonacci sequence.”) It can also be used for code completion and debugging. It supports many of the most popular languages being used today, including Python, C++, Java, PHP, Typescript (Javascript), C#, and Bash. We are releasing three sizes of Code Llama with 7B, 13B, and 34B parameters respectively. Each of these models is trained with 500B tokens of code and code-related data. The 7B and 13B base and instruct models have also been trained with fill-in-the-middle (FIM) capability, allowing them to insert code into existing code, meaning they can support tasks like code completion right out of the box. The three models address different serving and latency requirements. The 7B model, for example, can be served on a single GPU. The 34B model returns the best results and allows for better coding assistance, but the smaller 7B and 13B models are faster and more suitable for tasks that require low latency, like real-time code completion. The Code Llama models provide stable generations with up to 100,000 tokens of context. All models are trained on sequences of 16,000 tokens and show improvements on inputs with up to 100,000 tokens. Aside from being a prerequisite for generating longer programs, having longer input sequences unlocks exciting new use cases for a code LLM. For example, users can provide the model with more context from their codebase to make the generations more relevant. It also helps in debugging scenarios in larger codebases, where staying on top of all code related to a concrete issue can be challenging for developers. When developers are faced with debugging a large chunk of code they can pass the entire length of the code into the model. Additionally, we have further fine-tuned two additional variations of Code Llama: Code Llama - Python and Code Llama - Instruct. Code Llama - Python is a language-specialized variation of Code Llama, further fine-tuned on 100B tokens of Python code. Because Python is the most benchmarked language for code generation – and because Python and PyTorch play an important role in the AI community – we believe a specialized model provides additional utility. Code Llama - Instruct is an instruction fine-tuned and aligned variation of Code Llama. Instruction tuning continues the training process, but with a different objective. The model is fed a “natural language instruction” input and the expected output. This makes it better at understanding what humans expect out of their prompts. We recommend using Code Llama - Instruct variants whenever using Code Llama for code generation since Code Llama - Instruct has been fine-tuned to generate helpful and safe answers in natural language. We do not recommend using Code Llama or Code Llama - Python to perform general natural language tasks since neither of these models are designed to follow natural language instructions. Code Llama is specialized for code-specific tasks and isn’t appropriate as a foundation model for other tasks. When using the Code Llama models, users must abide by our license and acceptable use policy. Evaluating Code Llama’s performance To test Code Llama’s performance against existing solutions, we used two popular coding benchmarks: HumanEval and Mostly Basic Python Programming (MBPP). HumanEval tests the model’s ability to complete code based on docstrings and MBPP tests the model’s ability to write code based on a description. Our benchmark testing showed that Code Llama performed better than open-source, code-specific LLMs and outperformed Llama 2. Code Llama 34B, for example, scored 53.7% on HumanEval and 56.2% on MBPP, the highest compared with other state-of-the-art open solutions, and on par with ChatGPT. As with all cutting edge technology, Code Llama comes with risks. Building AI models responsibly is crucial, and we undertook numerous safety measures before releasing Code Llama. As part of our red teaming efforts, we ran a quantitative evaluation of Code Llama’s risk of generating malicious code. We created prompts that attempted to solicit malicious code with clear intent and scored Code Llama’s responses to those prompts against ChatGPT’s (GPT3.5 Turbo). Our results found that Code Llama answered with safer responses. Details about our red teaming efforts from domain experts in responsible AI, offensive security engineering, malware development, and software engineering are available in our research paper. Releasing Code Llama Programmers are already using LLMs to assist in a variety of tasks, ranging from writing new software to debugging existing code. The goal is to make developer workflows more efficient, so they can focus on the most human centric aspects of their job, rather than repetitive tasks. At Meta, we believe that AI models, but LLMs for coding in particular, benefit most from an open approach, both in terms of innovation and safety. Publicly available, code-specific models can facilitate the development of new technologies that improve peoples' lives. By releasing code models like Code Llama, the entire community can evaluate their capabilities, identify issues, and fix vulnerabilities. Code Llama’s training recipes are available on our Github repository. Model weights are also available. Responsible use Our research paper discloses details of Code Llama’s development as well as how we conducted our benchmarking tests. It also provides more information into the model’s limitations, known challenges we encountered, mitigations we’ve taken, and future challenges we intend to investigate. We’ve also updated our Responsible Use Guide and it includes guidance on developing downstream models responsibly, including: Defining content policies and mitigations. Preparing data. Fine-tuning the model. Evaluating and improving performance. Addressing input- and output-level risks. Building transparency and reporting mechanisms in user interactions. Developers should evaluate their models using code-specific evaluation benchmarks and perform safety studies on code-specific use cases such as generating malware, computer viruses, or malicious code. We also recommend leveraging safety datasets for automatic and human evaluations, and red teaming on adversarial prompts. The future of generative AI for coding Code Llama is designed to support software engineers in all sectors – including research, industry, open source projects, NGOs, and businesses. But there are still many more use cases to support than what our base and instruct models can serve. We hope that Code Llama will inspire others to leverage Llama 2 to create new innovative tools for research and commercial products. Try Code Llama today Code Llama GitHub repository Download the Code Llama Model Read the research paper Code Llama: Open foundation models for code Share: Our latest updates delivered to your inbox Subscribe to our newsletter to keep up with Meta AI news, events, research breakthroughs, and more. Join us in the pursuit of what’s possible with AI. See all open positions Related Posts FEATURED Research Meta and Microsoft Introduce the Next Generation of Llama July 18, 2023 Read post FEATURED Research Introducing CM3leon, a more efficient, state-of-the-art generative model for text and images July 14, 2023 Read post Large Language Model Community-driven AI innovation comes alive with Llama 2 July 28, 2023 Read post Who We Are About Meta AI People Careers Events Latest Work Research Infrastructure Blog Resources Our Actions Responsibilities Newsletter Sign Up Privacy Policy Terms Cookies Meta © 2023",
    "commentLink": "https://news.ycombinator.com/item?id=37248844",
    "commentBody": "Code Llama, a state-of-the-art large language model for codingHacker NewspastloginCode Llama, a state-of-the-art large language model for coding (meta.com) 654 points by nickthegreek 20 hours ago| hidepastfavorite2 comments dang 16 hours ago [–] Comments moved to https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37248494, which was posted a bit earlier. reply runeks 2 hours agoparent [–] Maybe delete this post then :-)There&#x27;s two copies of it on the front page.Thank you for your effort! replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Code Llama is a cutting-edge large language model (LLM) specifically designed for coding tasks.",
      "It can generate code and natural language about code based on prompts.",
      "Code Llama has three models: Code Llama (the foundational code model), Code Llama - Python (specialized for Python), and Code Llama - Instruct (fine-tuned for natural language instructions).",
      "In benchmark testing, Code Llama outperformed other publicly available LLMs on code tasks.",
      "It supports popular programming languages and can be used for code completion and debugging.",
      "Code Llama has different model sizes to cater to specific latency requirements.",
      "It has the potential to improve coding workflows and make coding more accessible for beginners.",
      "Code Llama is released under a community license, and users must adhere to the acceptable use policy.",
      "The model has undergone safety evaluations and precautions have been taken to mitigate risks.",
      "Developers are encouraged to evaluate the model using code-specific evaluation benchmarks and perform safety studies.",
      "The goal is to continue developing generative AI for coding by leveraging Llama 2 and inspiring others to create innovative tools."
    ],
    "commentSummary": [
      "Code Llama is a leading language model for coding, renowned for its advanced capabilities.",
      "The Hacker News forum is currently discussing the deletion of duplicate posts.",
      "More details about the context of the duplicate posts and their deletion are not available."
    ],
    "points": 654,
    "commentCount": 2,
    "retryCount": 0,
    "time": 1692885477
  },
  {
    "id": 37250834,
    "title": "Hacker News Guidelines",
    "originLink": "https://news.ycombinator.com/newsguidelines.html",
    "originBody": "Hacker News Guidelines Hacker News GuidelinesWhat to SubmitOn-Topic: Anything that good hackers would find interesting. That includes more than hacking and startups. If you had to reduce it to a sentence, the answer might be: anything that gratifies one's intellectual curiosity.Off-Topic: Most stories about politics, or crime, or sports, or celebrities, unless they're evidence of some interesting new phenomenon. Videos of pratfalls or disasters, or cute animal pictures. If they'd cover it on TV news, it's probably off-topic.In SubmissionsPlease don't do things to make titles stand out, like using uppercase or exclamation points, or saying how great an article is. It's implicit in submitting something that you think it's important.Please submit the original source. If a post reports on something found on another site, submit the latter.Please don't use HN primarily for promotion. It's ok to post your own stuff part of the time, but the primary use of the site should be for curiosity.If the title includes the name of the site, please take it out, because the site name will be displayed after the link.If the title contains a gratuitous number or number + adjective, we'd appreciate it if you'd crop it. E.g. translate \"10 Ways To Do X\" to \"How To Do X,\" and \"14 Amazing Ys\" to \"Ys.\" Exception: when the number is meaningful, e.g. \"The 5 Platonic Solids.\"Otherwise please use the original title, unless it is misleading or linkbait; don't editorialize.If you submit a video or pdf, please warn us by appending [video] or [pdf] to the title.Please don't post on HN to ask or tell us something. Send it to hn@ycombinator.com.Please don't delete and repost. Deletion is for things that shouldn't have been submitted in the first place.Don't solicit upvotes, comments, or submissions. Users should vote and comment when they run across something they personally find interesting—not for promotion.In CommentsBe kind. Don't be snarky. Converse curiously; don't cross-examine. Edit out swipes.Comments should get more thoughtful and substantive, not less, as a topic gets more divisive.When disagreeing, please reply to the argument instead of calling names. \"That is idiotic; 1 + 1 is 2, not 3\" can be shortened to \"1 + 1 is 2, not 3.\"Please don't fulminate. Please don't sneer, including at the rest of the community.Please respond to the strongest plausible interpretation of what someone says, not a weaker one that's easier to criticize. Assume good faith.Eschew flamebait. Avoid generic tangents. Omit internet tropes.Please don't post shallow dismissals, especially of other people's work. A good critical comment teaches us something.Please don't use Hacker News for political or ideological battle. That tramples curiosity.Please don't comment on whether someone read an article. \"Did you even read the article? It mentions that\" can be shortened to \"The article mentions that\".Please don't pick the most provocative thing in an article or post to complain about in the thread. Find something interesting to respond to instead.Throwaway accounts are ok for sensitive information, but please don't create accounts routinely. HN is a community—users should have an identity that others can relate to.Please don't use uppercase for emphasis. If you want to emphasize a word or phrase, put *asterisks* around it and it will get italicized.Please don't post insinuations about astroturfing, shilling, brigading, foreign agents, and the like. It degrades discussion and is usually mistaken. If you're worried about abuse, email hn@ycombinator.com and we'll look at the data.Please don't complain that a submission is inappropriate. If a story is spam or off-topic, flag it. Don't feed egregious comments by replying; flag them instead. If you flag, please don't also comment that you did.Please don't complain about tangential annoyances—e.g. article or website formats, name collisions, or back-button breakage. They're too common to be interesting.Please don't comment about the voting on comments. It never does any good, and it makes boring reading.Please don't post comments saying that HN is turning into Reddit. It's a semi-noob illusion, as old as the hills.",
    "commentLink": "https://news.ycombinator.com/item?id=37250834",
    "commentBody": "Hacker News GuidelinesHacker NewspastloginHacker News Guidelines (news.ycombinator.com) 382 points by tonmoy 17 hours ago| hidepastfavorite355 comments nologic01 16 hours ago> Please don&#x27;t post shallow dismissals, especially of other people&#x27;s work. A good critical comment teaches us something.This is one of the more serious pain points I notice (thankfully only occasionally).Obviously getting some visibility is important for people launching new projects. Sometimes adversarial comments seem to be motivated by commercial rather than technical reasons. reply InSteady 10 hours agoparent>Please don&#x27;t post insinuations about astroturfing, shilling, brigading, foreign agents, and the like. It degrades discussion and is usually mistaken. If you&#x27;re worried about abuse, email hn@ycombinator.com and we&#x27;ll look at the data. reply nextaccountic 8 hours agorootparentWell at least this doesn&#x27;t insinuate a specific comment is astroturfing but rather that this practice exists (and I think that the existence of this practice is a reasonable topic to talk about, at least in this thread) reply noduerme 12 hours agoparentprev>> Sometimes adversarial comments seem to be motivated by commercial rather than technical reasons.Do you mean like, Alice shows her project and Bob gets on and becomes adversarial to get attention for his competing project? Or are you saying that Alice creates adversarial sock puppets just to increase the comment count and visibility? reply iLoveOncall 1 hour agoparentprev> Sometimes adversarial comments seem to be motivated by commercial rather than technical reasons.No kidding.On most Launch &#x2F; Show HN posts half of the comments are \"CEO of yourdirectcompetitor.com here, cool project, good job, here are some irrelevant questions so that my obvious self-plug doesn&#x27;t get deleted.\" reply antisthenes 13 hours agoparentprevA shallow article written in bad faith only deserves a shallow dismissal.Don&#x27;t force me to fight an asymmetric warfare battle against malicious authors to participate. reply skeaker 13 hours agorootparentThat&#x27;s what flagging is for. Or just ignore the post. Participation here is never \"forced\" reply gingerbread-man 13 hours agorootparentprevDoes a ‘shallow article’ even merit a dismissive comment? Wouldn’t it be better simply to ignore it and find another thread on which to engage? reply thecosas 13 hours agorootparentThis makes sense to me since leaving a comment (even a negative one) would be a signal of engagement that would likely boost the likelihood of a given article being&#x2F;remaining on the front page. reply kbenson 8 hours agorootparentI agree, it&#x27;s the same principal as spam. You don&#x27;t reply calling them out as a spammer, as that only signals that they have access to your attention. You blackhole the spam or sender or submit to authorities of services that can help you block it in the future, but you do not engage with the originator. reply DisgracePlacard 8 hours agorootparentprevIIRC, submissions are downranked as the commment to vote ration gets higher and higher.https:&#x2F;&#x2F;github.com&#x2F;minimaxir&#x2F;hacker-news-undocumented#flame-... reply antisthenes 13 hours agorootparentprevIgnoring&#x2F;Flagging it is akin to shallow dismissal.I make no distinction between the 2. reply kbenson 8 hours agorootparentThe rule is not to force you to be a better person by making you consider all comments you see, it&#x27;s to keep discussion useful and help the site continue to provide a high level of usefulness for all users, including yourself.In that respect, ignoring, flagging, and shallow dismissals replies are three distinctly different outcomes with different utility to the users of this site. reply post-it 13 hours agorootparentprevBut the guidelines do.> Please don&#x27;t post shallow dismissals, reply dang 6 hours agorootparentprevThe issue isn&#x27;t justice, it&#x27;s thread quality. reply dredmorbius 4 hours agorootparentI&#x27;m coming to appreciate this view increasingly, why HN chooses to align itself this way, and the difficulty and precariousness with which that balance is attained.I&#x27;ll still say that the instances of HN moderation with which I have the greatest reservations tend to resemble what antisthenes describes above: poorly-conceived articles which would themselves be legitimately flagged and admonished if posted as HN comments to which the rather understandably heated or snippy response instead draws moderator action.And yes, HN mods can&#x27;t read everything or be everywhere,[1] so moderation is inconsistent, though I know what it strives toward.And I can often identify how a response might have been improved or what elements run aground on HN&#x27;s policies. I&#x27;m not convinced that the occasional exception or leniency would utterly wreck the ship (though having seen what, in dang&#x27;s words things that strongly encourage that a \"thread will lose its mind\"[2] there&#x27;s some reason for caution). But in a world where, to borrow from Tim Minchin, there&#x27;s frequently a contingent which \"keeps firing off clichés with startling precision like a sniper using bollocks for ammunition\", diplomacy dikes do on occasion break.[3]And tone-policing that, particularly unilaterally, strikes me as a greater wrong.________________________________Notes:1. Which you&#x27;ve noted, 2 days agoand eight years ago: . Another HN perennial...2.and .3. Tim Minchin, \"Storm\" (2009), . Animated video:and live performance: . reply ineedasername 10 hours agorootparentprevIgnoring those articles is quite nearly the definition of “easy” reply Cpoll 10 hours agorootparentprevA shallow dismissal just makes your position look weak, and theirs stronger by comparison. reply wilg 9 hours agorootparent“look” is the operative word here reply Cpoll 9 hours agorootparentI suppose it depends whether your goal is communicating your position or just winning a moral victory.\"Weak\" is the operative word. Being right doesn&#x27;t do you much favors if you can&#x27;t communicate it. In this context, \"looking\" weak is being weak. reply antisthenes 8 hours agorootparent> Being right doesn&#x27;t do you much favors if you can&#x27;t communicate it. In this context, \"looking\" weak is being weak.No. Function over form. reply antisthenes 9 hours agorootparentprevYou&#x27;re welcome to think so, but position strength is tied to facts, not posts. reply Cpoll 8 hours agorootparentIn that case, \"strength\" is the wrong metric. If you&#x27;re posting a shallow response just because the facts align with your position, you&#x27;re still just wasting people&#x27;s time.The people who already agree that the article is shallow learn nothing, and the people who don&#x27;t know the article is shallow also learn nothing.And I agree with you, position strength is tied to facts, which is why writing a shallow dismissal instead of listing some facts leads to a weak position.Incidentally, why are you responding to me and not just saying \"you&#x27;re wrong, I&#x27;m done talking to you.\" replynaillo 16 hours agoprevThe only one I subtly disagree with is \"comments should be substantive\". What it discourages I think is comments like \"thanks\" or other really &#x27;unsubstantive&#x27; comments. It&#x27;s true that maybe it adds noise, and in many cases are maybe supposed to be inferred without explicitly saying. But I think discouraging this slightly leans behaviour towards snark vs not. (If you see comments like \"thanks\" you&#x27;re less likely to be snarky than if you see &#x27;substantive&#x27; but maybe too harsh critiques in the comments that appear because \"cool project!\" isn&#x27;t allowed.)Personally I like to make it a point to break this rule from time to time to reduce this pattern. reply dang 15 hours agoparentSushiHippie already said it (https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37252326), but pg made this point way back in https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newswelcome.html (2009):Empty comments can be ok if they&#x27;re positive. There&#x27;s nothing wrong with submitting a comment saying just \"Thanks.\" What we especially discourage are comments that are empty and negative—comments that are mere name-calling. reply EA-3167 15 hours agorootparentWhole subs on Reddit are essentially rendered worthless because the comments are all low-effort, meme responses. This is one of the only places I&#x27;ve been online where the discussion of Prigozhin&#x27;s death wasn&#x27;t just 500+ \"Fell out of a window\" comments.THANK YOU reply vunderba 10 hours agorootparent100%. Whenever I read somebody&#x27;s response on an article, the first thing that lights up for me cognitively - \"is this a reddit-level comment?\".How many times have you seen a deeply nested Reddit thread where each reply is maybe a single sentence long, and they&#x27;re all low hanging word puns? Just completely worthless threads that are all noise. reply lostlogin 9 hours agorootparentprev> Whole subs on Reddit are essentially rendered worthless because the comments are all low-effortThis might be a feature - some events are ripe for ridicule and jokes, and Reddit having has areas where this is completely the norm provides a forum.But when you want to know what chainsaw to buy, how to make a specific ESP chip work or some other random thing, Reddit also provides.You have to avoid getting sucked into its cesspits. reply kbenson 7 hours agorootparentThe problem is that since reddit has places for both where it&#x27;s entirely appropriate to act in specific ways, them both being on the same site often leads to it leaking from one area to another to poor effect.Useful and&#x2F;or somewhat serious subreddit can have submissions derailed and useful content buried by meme comments, and meme subreddit can have someone be too serious and upset or disheartened when people don&#x27;t engage on what they see as an important or cool thing (or not even that people don&#x27;t engage, but that any discussion is derailed by the community as a norm).It&#x27;s great that I can go to one place for almost anything (kind of, they&#x27;re getting a little pushy and scummy with the monetization), but sometimes the community is also a downside. reply EA-3167 8 hours agorootparentprevYou&#x27;re right about that, it&#x27;s honestly unfair for me to refer to Reddit as though it&#x27;s a monolith. r&#x2F;AskHistory is as good as it&#x27;s ever been, r&#x2F;WhatsThisBug is always fun, and lots of little niche subs are just vibrant communities.Unfortunately when it comes to the major news subs, the big issue isn&#x27;t polarizing politics, it&#x27;s just people using the headline to spout memes. reply yreg 11 hours agorootparentprevI would really like an &#x2F;r&#x2F;worldnews clone with joke comments forbidden. reply 93po 11 hours agorootparentprevYou have my updoots good sir reply anotherevan 9 hours agorootparentprevThanks. reply burnished 16 hours agoparentprevYou can be substantive in your thanks making or praises. And if you cannot then maybe its OK that it doesn&#x27;t get expressed as a one word &#x27;thanks&#x27; post.I personally don&#x27;t think this causes the community as a whole to lean snarky - that one might be a pre existing condition rather than the format.I also think the occasional rule breaking is good, &#x27;I don&#x27;t have anything substantial to say but your project means a lot to me and I&#x27;m grateful&#x27; is substantial in a way that default &#x27;thanks&#x27; is not anyway. reply vunderba 10 hours agoparentprevI disagree, there is an upload button which delivers the equivalent of thanks. I don&#x27;t think it&#x27;s too much to ask that an expression of gratitude also take the time to include something meaningful.This is one of the biggest differentiators from Reddit. reply JNRowe 16 hours agoparentprevIn the specific instance of a \"thanks\" message, I&#x27;ll somewhat regularly send an out of band message to say thanks for helpful replies(or general comments). It doesn&#x27;t pollute the threads for others, and I&#x27;d like to think the added cost of a personal note gives the reader a sense of the value I found in their writing.I&#x27;m yet to have any pushback on sending a thank you note, but who knows maybe it will upset some people in the future ;)Which - I guess - also deserves a \"add some contact details to profile\" note. reply zogrodea 13 hours agorootparentThat sounds like a wonderful idea. Thank you for suggesting it, and for doing it as well. reply 1123581321 16 hours agoparentprevSame. I think it&#x27;s especially important to thank someone when they might otherwise assume you&#x27;ll want to pick apart with their response to you, after you&#x27;ve asked them to write it.One feature I&#x27;ve thought of would be for someone in a conversation thread to know if the other participant upvoted their last comment. Giving someone an upvote and not replying would send a strong positive signal without taking up more space. reply SushiHippie 16 hours agorootparentThat is okay Comment from dang: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37030249 reply permo-w 27 minutes agorootparentwhether it&#x27;s allowed or not is probably less pertinent than whether it&#x27;ll get downvoted. I&#x27;ve never seen a flagged comment that was just \"thanks\", but I suspect I probably have seen a heavily downvoted one, although I can&#x27;t think of a specific example reply zogrodea 13 hours agorootparentprevThat suggestion about upvoting might work. It has less of a human element than a typed&#x2F;written reply though (instead of someone typing text to express positive intent, it&#x27;s someone incrementing a number to express positive intent), and it does sound more desolate&#x2F;lonely from that perspective. Although I don&#x27;t know how much it matters.Here&#x27;s an exchange from a book I thought of while typing this comment, to illustrate my meaning.`But he could not resist the temptation to speak and to awaken a little human warmth around him. “A pity for the car,” he said. “Foreign cars cost quite a bit of gold, and after half a year on our roads they are finished.” “There you are quite right. Our roads are very backward,” said the old official. By his tone Rubashov realized that he had understood his helplessness. He felt like a dog to whom one had just thrown a bone; he decided not to speak again.` reply mook 6 hours agorootparentA lone \"thanks\" doesn&#x27;t seem to contain very much human element in it either, though; that just feels like somebody wanted to make a comment but couldn&#x27;t be bothered to provide detail. What specifically are they thanking? Does the link make their life a little better (and if yes, how, so that others could emulate making more people&#x27;s lives better)? If it was in reply to a comment, did they just read it or actually try whatever it was?I think I dislike it because it reminds me of the busy exec replying with a single word, and that is definitely lacking in humanity. reply zogrodea 4 hours agorootparentThat&#x27;s true. Curtness does often sound negative. That&#x27;s a good point I hadn&#x27;t considered. reply sanderjd 16 hours agorootparentprevI&#x27;d really love a separate \"thanks\" interface element that only the person you replied to can use. reply noduerme 12 hours agorootparentThis. Perhaps even with a very short note attached, visible to the person you&#x27;re thanking but not visible in the main thread. reply pkulak 4 hours agoparentprevI almost always have something more than “thanks” to say. Like, “Good point about the enfabulator, I hadn’t thought of that. Thanks.” Or, “Oh yeah, I will have to try that way. Seems very promising. Thank you.” reply johnnyanmac 11 hours agoparentprev> But I think discouraging this slightly leans behaviour towards snark vs not.who are you thanking? the mechanics of HN means that a uesr would have to actively search around for a response, so odds are your thanks simply goes the ether. reply suddenclarity 9 hours agorootparentI partially \"solved\" this by bookmarking the page showing my most recent comments and their replies so I can skim it before going to the front-page. I understand the reasoning behind the functionality but there is a lot of knowledge in replies so I wouldn&#x27;t want to be without it. reply jacquesm 4 hours agorootparentprevThere is the &#x27;threads&#x27; link at the top of the page, which shows you all your recent comments and their replies. reply freedomben 16 hours agoparentprevI agree, though I think for posts deserving a \"thanks\" it&#x27;s not too hard to make it substantive. For example, if I wanted to thank you for this comment, I might say something like this:Thanks, that&#x27;s very helpful. You make a good point about comments like \"cool project!\" not being allowed, which could cause the overall sentiment to feel skewed negative when it might actually be well received. That said, it can feel noisy and unhelpful to see a thread full of empty comments, so what if we had a thumbs up button or something that people could use to register \"cool project\" ? Maybe not practical, but just thinking through the problem a bit. reply bombcar 15 hours agorootparentI like to do a simple “thank you because X” where X is an encouragement for others to read the link (usually that’s what’s thanked, anyway). reply krapp 15 hours agorootparentprevI think the idea is that if you can&#x27;t make a substantive comment, you refrain from commenting at all.It&#x27;s a weird dynamic to have in a web forum, where people are essentially engaging in text-based conversations, but casual, emotive speech is discouraged because that&#x27;s what Redditors do, and every keystroke brings us closer to Eternal September. reply toofy 7 hours agorootparent> I think the idea is that if you can&#x27;t make a substantive comment, you refrain from commenting at all.me too. how many of our grandmothers repeatedly said, “if you have nothing nice to say, don’t say anything at all.”it’s wild to me to see how much The Internet has tried to pretend it can escape from things humans figured out were important a century ago. in a lot of ways we’ve collectively fooled ourselves into believing the people who came before us were all stupid.i mean, so many of the failures we’re seeing from companies or large communities have turned out to be our own hubris pretending as if The Internet wouldn’t have super basic, reaaaaally basic human problems like, “if you’re not nice, 1) people will be rude back and 2) a community full of assholes will _shockingly_ be a shitty place.”this is basic shit that even a social halfwit knows when they go out in public, but we (myself included) are hilariously relearning and pretending like it’s a deep revelation.if we can’t post anything nice, don’t post anything at all. we act liek this is complicated. reply blackpill0w 14 hours agoparentprevIsn&#x27;t that (partly) the point of the upvote button? reply bdcravens 16 hours agoparentprevYes, but it also discourages \"cool story bro\", \"ok boomer\", \"no cap\" etc reply jasonlotito 14 hours agoparentprevGood news, you can! \"Thanks\" is 100% substantive!From dang: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37030249 reply ateng 17 hours agoprevThe world of internet would be a _much_ better place if everyone at least have read this. I tried my best to adhere to these rules in any social network. reply Tao3300 16 hours agoparentWherever you go, always do unto others as you would do when dang is watching. reply 93po 11 hours agorootparentLeave everywhere slightly better than you found it reply bombcar 15 hours agorootparentprevMeaning that about 14 hours out of the day you can do whatever you want muahauahhaUp that to 25 hours a day if on IPv6! reply DonHopkins 13 hours agorootparentFonebone is watching you the other 14 hours.https:&#x2F;&#x2F;www.madmagazine.com&#x2F;blog&#x2F;2014&#x2F;08&#x2F;22&#x2F;don-martin-foneb... reply roflyear 15 hours agoparentprevIt is unfortunate that the rules are so vague&#x2F;up for interpretation, and when you break them, it isn&#x27;t explained to you that you broke them. The rule just gets cited and there you go. reply dredmorbius 4 hours agorootparentThat&#x27;s in many ways deliberate, and I&#x27;d argue to positive effect. reply langsoul-com 9 hours agorootparentprevRules have to be vague to some extent no? Because language and people are vague.If it was precise then that&#x27;d be a 500 page legal document for site guidelines. reply roflyear 8 hours agorootparentYes, but if the goal is to help people participate, explaining what they did wrong rather than \"we don&#x27;t do that here\" helps.If the goal is \"we only want people like us here\" then keeping the status quo is good. reply kelnos 13 hours agorootparentprevI&#x27;ve found that dang is very open to discussion about these sorts of things. He&#x27;s only an email away, and usually responds quickly. reply lazyasciiart 10 hours agorootparentI&#x27;ve found the complete opposite: it took years to even get a dismissive response, and longer to get him to actually bother looking into what I wrote. Depends whether you pass his initial guess at whether you have a real issue or are trolling him, apparently. reply dredmorbius 4 hours agorootparentIf you don&#x27;t get a timely response, try sending a follow-up or reminder message.I&#x27;ve sent a lot of HN mod mail over the years, and usually get a response within a few hours. Occasionally a few days, during busy times, and on a very small handful of instances, an apology for missing or overlooking an email. I think all of those have occurred within 1--2 weeks tops.I try to keep most correspondence short, sweet, single-focused, and direct. (Most of that concerns submissions: titles, URLs, or nominations to the 2nd chance pool.)Occasionally I address more complex or difficult issues. Dang emailed me a few days ago noting that he&#x27;s still meaning to reply to series on one topic (not pressing, though interesting). I&#x27;m aware that he&#x27;s pressed and that there are more urgent priorities. But he does go out of his way to stay on top of things.(I also owe him a reminder on another issue, also fairly minor, I&#x27;d raised a couple of months back.)Keep in mind that mods are ingesting a firehose and that complicated or poorly-scoped questions or issues might be difficult to respond to. (This is a general principle to keep in mind when corresponding, not just for HN mods.) reply dang 6 hours agorootparentprevI&#x27;d be interested in what took years—can you explain? My worst case in terms of responding to emails is a few months—which is terrible, but happens when (a) the inbox is backed up and (b) the request requires more than a little time.It doesn&#x27;t really depend on whether I think someone&#x27;s trolling, because the response is usually much the same in either case and anyhow genuine trolling (i.e. totally bad-faith action to provoke or waste time) is relatively rare. reply tptacek 9 hours agorootparentprevI imagine he gets a lot of trolling emails. It can&#x27;t be easy keeping up with it; I barely keep up with my own email, and I rarely get email. reply roflyear 8 hours agorootparentWell, yes, I sympathize, but it is his job. reply tptacek 8 hours agorootparentSince he doesn&#x27;t work for us, I don&#x27;t find that fact as persuasive as you do. reply roflyear 8 hours agorootparentprevDang responds, but he won&#x27;t say what you did wrong. I kind of understand, but also not really. reply dang 6 hours agorootparentI spend half my day (or what feels like it) telling people what they did \"wrong\", i.e. what they did that led to whatever they experienced that they didn&#x27;t like. The trouble is that these explanations are expensive: it takes time and energy to track the specifics, deliver the information in a clear enough form that, proof it against possible misunderstanding or unintended offensiveness, and then go back-and-forth with the user when the information isn&#x27;t clear enough or lands the wrong way. It&#x27;s impossible to do a satisfactory job of this in every case, even though one wants to—the only option is to approximate.Since you&#x27;ve mentioned twice that you didn&#x27;t get an explanation, I&#x27;d be curious to see the case that you didn&#x27;t get an explanation about. Is there a link? Usually when people remain upset about something long after the fact, it&#x27;s for good reason. replysgarman 16 hours agoprev> Please don&#x27;t post comments saying that HN is turning into Reddit.As internet communities evolve over the years I have seen some changes in HN posts and comments but I suspect HN not trying to grow at any cost has done a good job of keeping it from becoming reddit. reply minimaxir 16 hours agoparentThat line is more than a decade old where the comparisons were more obvious, especially given Reddit&#x27;s YC origins. reply Tao3300 15 hours agoparentprevThe real issue with Reddit is the capricious insanity of the mods. I got banned from enough subs over total nonsense that I just quit the whole thing.It makes sense though, the mods are unpaid volunteers doing work that people generally don&#x27;t appreciate and often criticize. You&#x27;d have to be a crazed zealot to sign up for that.All that to say HN is nothing like that. reply egithinji 10 hours agoprevInteresting how having intellectual curiosity as the goal, rather than the ubiquitous &#x27;an inclusive space where everyone can feel safe&#x27;, has ended up in a forum that&#x27;s much &#x27;safer&#x27; and less toxic than most places on the Internet. reply abraae 10 hours agoparentAnd how the HN code of conduct (well, these guidelines being the nearest thing to) doesn&#x27;t describe or even mention \"hurtful or harmful conduct\", nor \"gender\" or \"behaviour\".Unlike more turgid efforts: https:&#x2F;&#x2F;www.mozilla.org&#x2F;en-US&#x2F;about&#x2F;governance&#x2F;policies&#x2F;part... reply altairprime 8 hours agorootparentOne point of view is that it does, by requiring the opposite:> Be kind.It also lists specific hurtful or harmful behaviors that the community tends to use, which is often just as effective. Certainly I have had no trouble reporting harmful conduct, because it’s covered by the collection of guidelines addressing it — and when a new kind of harm becomes prevalent, they’re updated to reflect that.Gender is an interesting problem for HN, because with explicit misbehavior prohibited by the guidelines, the tech-male gender biases in the community are primarily expressed through voting, flagging, and starting “plausible” flamewars. I don’t think altering the guidelines would have any effect on those behaviors, and would probably encourage them. It’s definitely possible to witness ‘probable’ bias effects and report your perceptions of them as such; the mods have a lot of flexibility to evaluate a concern in context of a potential bias. I really encourage speaking up to them when concerned.I wish more community guidelines were just this block:> Be kind. Don&#x27;t be snarky. Edit out swipes.> Comments should get more thoughtful and substantive, not less, as a topic gets more divisive.> When disagreeing, please reply to the argument instead of calling names.> Please don&#x27;t fulminate. Please don&#x27;t sneer> Please respond to the strongest plausible interpretation of what someone says> Avoid generic tangents.> Please don&#x27;t post shallow dismissals> Please don&#x27;t use Hacker News for political or ideological battle.And one modification of my own:> Avoid generic tangents. Generic negative comments that can be copy-pasted into other posts are noisy and uninteresting. Be substantive and relevant when sharing your concerns. reply tptacek 8 hours agorootparentMoreover, pretty much all the turgid clauses of Mozilla&#x27;s conduct code apply here as well; they&#x27;re just not written in the guidelines, but rather in mod comments. That&#x27;s deliberate; if you write them in the guidelines, people make a game of coming as close to the line as possible without crossing it, and there are huge meta squabbles over what the guidelines mean. reply abraae 6 hours agorootparentI don&#x27;t think this is so, as demonstrated by people usually quoting the guidelines themselves, almost biblically, when chastising someone else on HN. I don&#x27;t often see people quoting Dang&#x27;s comments.I prefer to think instead that HN has crystallised down the lofty goals of civilised dialogue into a handful of wonderfully tangible rules - but unfortunately, rules that can only be followed by somewhat thoughtful people.This works on HN because HN content (stuff that gratifies one&#x27;s intellectual curiosity) naturally drives away non-thoughtful people.For example:> Please don&#x27;t fulminate. Please don&#x27;t sneer, including at the rest of the community.At this risk of sounding elitist, if you don&#x27;t know what fulminating means, or you actively seek out conflict online where you can sneer at others, then you are not the kind of person who will be able to follow the guidelines, and you will quickly be downvoted, which on HN carries a very visible stigma as your comments literally fade into obscurity.Instead, you will be quickjly driven back to the safe echo chambers of Facebook or wherever, where you can find like minded-people who will sneer alongside you. reply mdwalters 4 hours agorootparentprev+1 to your modification. It wasn&#x27;t obvious what the word tangents meant, so that modification may do well as it explains it a bit. reply delecti 10 hours agoparentprevYes, but&#x2F;because many subjects are off-topic here. It&#x27;s easy to avoid lots of kinds of internet drama if you blanket prohibit the topics.I&#x27;m glad this place exists how it is, but it can also be a bit stuffy. reply tptacek 9 hours agoparentprevMost of the norms of spaces that are deliberately inclusive are norms here too, but they&#x27;re common law norms: they&#x27;re stated very generally in the guidelines, but the real binding norms are in Dan&#x27;s comments. reply SalmoShalazar 6 hours agoparentprevThis is a website for people in the tech industry, with additional focus on business. There are also subjects that simply cannot be discussed here (which is good). It’s those limits that constrain the conversation which makes this place “less toxic”. If it was a free for all where you could post anything, well, the place would go to shit immediately.I feel like you’re attacking attempts at inclusivity in general with your comment, which seems misguided. Inclusivity and trying to accommodate people is not what causes toxicity. reply ajonit 17 hours agoprevWhile you are there, go through dang’s comments timeline https:&#x2F;&#x2F;news.ycombinator.com&#x2F;threads?id=dangModerating something like HN is a very hard job. Gratitude . reply solardev 16 hours agoparentYeah. In 30 years of being on the Internet, dang is probably the single best moderator I&#x27;ve ever met.Thank you SO much for what you do.We should all get together and throw him a virtual party... reply pknerd 15 hours agorootparentdoes SO means Stackoverflow here? kidding reply zerojames 15 hours agoparentprevYes indeed! Dan, we sincerely appreciate the work you do nurture, moderate, and maintain the HN community! reply dontupvoteme 3 hours agoparentprevWould be cool to see how a SOTA summary from an LLM of this looks like. reply chrisan 16 hours agoparentprevno pun intended.. but dang, I had no idea reply xwdv 16 hours agoparentprevI’ve had a few run-ins with dang. Every post I write nowadays I have to reread carefully to soften any sharp edges and avoid getting into trouble, but I don’t always have time to double check a comment if I’m in a hurry. I wonder if there is a hidden reputation score or if it’s all just based off of dang’s memory. Public karma scores are mostly useless except as a vanity metric. reply bowsamic 16 hours agoparentprevI understand why but I don’t like how people are individually rate limited silently without their knowledge. It is certainly immoralEDIT: unfortunately I cannot defend my point in the comments, as I am now rate limited :)EDIT 2: &#x2F;u&#x2F;Dylan16807 yes I&#x27;m seeing that. When I try and post it says \"you are posting too quickly, please slow down\" reply sneak 16 hours agorootparentI don&#x27;t think it&#x27;s immoral - it&#x27;s their site, after all. Our being able to post here at all is a privilege afforded to us, and their choosing to revoke that privilege for any reason is fully within their rights. No cause or explanation is even required, though they are frequently provided out of the abundant courtesy that the moderators seem to have a natural talent for. If you think about it, even rate limiting is a slightly more courteous alternative to outright banning someone.I think shadowbanning is a bit unethical as it technically involves lying, but afaik HN doesn&#x27;t do such things. reply zacharycohn 15 hours agorootparentWhile shadowbanning has been made political, it is a key tool in managing a community. If you ban a troublemaker, they just make a new account. So if you can isolate a troublemaker without them understanding what&#x27;s happening, you improve the community and reduce the whack-a-mole game.And ultimately, \"freedom of speech\" refers to the government silencing speech, not private companies&#x2F;private websites. We are all guests here, and if someone isn&#x27;t upholding the standards the people who run this website want people to uphold, then they&#x27;re free to do whatever they want. reply DisgracePlacard 8 hours agorootparent\"Freedom of speech\" does not simply refer to the 1st amendment - the concept has existed much longer than the USA has. I don&#x27;t think GP is arguing that shadowbanned users have a \"right\" to use HN, instead they&#x27;re saying that it is somewhat unethical because it is a form of lying.As for shadowbanning being a key tool in managing a community - In HN&#x27;s case, I imagine any shadowbanning system could be easily defeated, as a malicious actor could create a new account for every comment. reply latency-guy2 9 hours agorootparentprev> And ultimately, \"freedom of speech\" refers to the government silencing speech, not private companies&#x2F;private websites. We are all guests here, and if someone isn&#x27;t upholding the standards the people who run this website want people to uphold, then they&#x27;re free to do whatever they want.If you hold this opinion then you can never say water, food, shelter, internet, etc. are human rights either. reply bowsamic 15 hours agorootparentprev> I don&#x27;t think it&#x27;s immoral - it&#x27;s their site, after all.> I think shadowbanning is a bit unethical as it technically involves lyingThese two points contradict, and also HN does do shadowbanning (\"marking as dead\") reply xdennis 10 hours agorootparentprev> Our being able to post here at all is a privilege afforded to us, and their choosing to revoke that privilege for any reason is fully within their rights.I really hate it when discourse about anything devolves into rights.If I have a genius or terrible take like \"Chairs are pointless. Nobody should use chairs because ...\" you can&#x27;t just say \"Well actually The Constitution allows people to use chairs and you can&#x27;t ban the private use of chairs.\" That doesn&#x27;t bring anything to the discussion.Nobody is saying here that HN isn&#x27;t legally allowed to control the content on its website, but different people have different opinions about what&#x27;s right and wrong for websites to do which doesn&#x27;t involve having to bring the government in to settle things. reply pb7 15 hours agorootparentprev>I think shadowbanning is a bit unethical as it technically involves lying, but afaik HN doesn&#x27;t do such things.It does. A ban on HN is a shadowban. You can still post but only those who have \"show dead\" on will see it (greyed out and marked dead). reply dang 15 hours agorootparentShadowbanning is when you don&#x27;t tell the user that they&#x27;re banned. When an account has an established history on HN, we tell them we&#x27;re banning them and why: https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&page=0&prefix=true&que....Shadowbanning is something we only do for either (1) spammers or (2) new accounts that are showing signs of being repeat abusers. This seems to be roughly the correct tradeoff. reply nonomoreplease 11 hours agorootparentnext [2 more] This post has been deleted and the user has left. reply LordDragonfang 11 hours agorootparentI can confirm for you that you&#x27;re not shadowbanned. Flagging comes from users, not moderators. It simply means that multiple members of the community in good standing indicated that your comments are not a good fit for HN.I suspect your \"other comment\" got flagged for being political polemic from a new account, which fits the pattern of, as dang phrased it, \"repeat abusers\". reply pb7 13 hours agorootparentprevResponding to an offending user’s comment on a site with no notifications barely qualifies as telling them. If you truly wanted to inform them, you would either put a banner next to their name in the header or simply prevent them from being able to post. You and I both know what the intention is here, just like the rate limit you have placed on my account. reply dang 12 hours agorootparentIt&#x27;s telling them in the same way that anybody tells anybody anything here.Obviously the intention is to inform—otherwise why bother? Those comments take a lot of time to write. replywhimsicalism 16 hours agorootparentprevWhen I was rate-limited, I found it quite easy to find out what happened after a little bit of googling and get it reversed with a nicely worded email. It doesn&#x27;t take a genius to figure out why you can&#x27;t really post after a reply from dang.Nonetheless, I agree they could be a bit more explicit about this. reply bowsamic 16 hours agorootparent> It doesn&#x27;t take a genius to figure out why you can&#x27;t really post after a reply from dang.Well actually it does because you&#x27;re wrong about this, it isn&#x27;t about him replying to you, he manually sets a flag on your account. reply whimsicalism 16 hours agorootparent> Well actually it does because you&#x27;re wrong about this, it isn&#x27;t about him replying to you, he manually sets a flag on your account.Right, but in my experience, this usually occurs after a reply. reply bowsamic 16 hours agorootparentYou said it doesn&#x27;t take a genius to work it out but you haven&#x27;t worked it out. It&#x27;s opaque other than that we know it&#x27;s a flag that can be manually set on the user without their knowledge reply whimsicalism 16 hours agorootparentI worked out that I had been flagged. I was not saying that dang replying was the mechanism, you are just (intentionally?) misinterpreting what I am saying. That dang replies to you is an indicator that he has flagged you.Not going to keep replying, as I suspect that a conversation between two people flagged in this manner is one of the likeliest to turn flame-y :) reply krapp 16 hours agorootparentprevUnfortunately, that reply can sometimes be days, weeks or who knows how old, and HN doesn&#x27;t inform you of replies to your comments, so unless you happen to see it when it happens you&#x27;re stuck with having to intuit that \"you&#x27;re replying too fast\" is an extremely passive aggressive flag on your account and not just a general site-wide rate limiter. Or notice that your flags no longer work, or your vouches no longer work, or any number of even more subtle effects. reply dabluecaboose 15 hours agorootparent>Or notice that your flags no longer work, or your vouches no longer work, or any number of even more subtle effects.Wait, I&#x27;m now wondering if I&#x27;ve been limited. I&#x27;ve never once seen the \"Vouch\" button and I&#x27;ve flagged some blatant stuff that nothing happened to, but figured there was somewhat of a vote (or multiple flags) before it took any effect. Can anyone confirm this behavior? reply dang 15 hours agorootparentYour account is fine. reply dabluecaboose 15 hours agorootparentThank you for the confirmation, dang! Big fan of the job you do around here. replyDylan16807 15 hours agorootparentprev> EDIT: unfortunately I cannot defend my point in the comments, as I am now rate limited :)All comments get rate limited as they start to nest, by hiding the reply link. Are you seeing that? reply shadowgovt 15 hours agorootparentThere&#x27;s also an (account-specific) \"You&#x27;re posting too quickly. Please Slow Down. Thanks\" that specific users get if they have a flag set on their account. reply lazyasciiart 10 hours agorootparentprevThat was done to me as well. I still have no idea why and when I finally got it lifted dang didn&#x27;t know why either. One of the most infuriating experiences I&#x27;ve had in a forum, and actively made worse by the sycophantic adoring articles going around at the time citing their \"personal human touch\". dang explained that they can&#x27;t possibly have time to give everyone that personal human touch! But not to the reporters, apparently. reply ryandrake 5 hours agorootparentSame experience here. I was rate limited a few times, and when I got around to emailing dang, I don’t recall him figuring out why for any of the cases. Kind of annoying but obviously not the end of the world. Not remotely worth complaining about. Would more transparency be nice? Sure but I doubt it scales.You can always abuse the “Edit” function for a somewhat limited way to reply and have a conversation, but it’s simpler to just drop an email note. reply tptacek 9 hours agorootparentprevHave you considered asking for a refund? reply bowsamic 9 hours agorootparentHN is free. If you paid for it, you have been scammed reply lazyasciiart 8 hours agorootparentHe knows that. I suspect he is implying that I have nothing to complain about because it is a free service, which is a pretty vacuous argument. reply tptacek 8 hours agorootparentIt&#x27;s a response to your expectation of personalized service. reply bowsamic 3 hours agorootparentI think you need to take a basic class in ethics if you think ethics are determined entirely by rights and law reply pvg 29 minutes agorootparentA stranger providing you a service for free doesn&#x27;t have an ethical obligation to answer your emails. replyTao3300 16 hours agorootparentprev> immoralThat&#x27;s really not the word you&#x27;re looking for. reply bowsamic 3 hours agorootparentHow is it not? I think it’s wrong, ie immoral reply Vicinity9635 16 hours agorootparentprevIt&#x27;s precisely correct. reply LordDragonfang 11 hours agorootparentprevAs someone who personally has been rate-limited, it&#x27;s a little annoying but justified in basically every occasion I&#x27;ve seen someone complain about it. It&#x27;s also not hard to figure out what&#x27;s happening if you&#x27;re the kind of person willing to put in enough effort to be a good member of the hacker community.Avoid getting into flame wars, and send an email to dang saying you&#x27;ll do so in the future, and you&#x27;re fine. If you can&#x27;t do that, or can&#x27;t be bothered to use Google to figure that out, there&#x27;s a good reason for your account to be rate limited. reply shadowgovt 16 hours agorootparentprevWhat principal of morality does rate-limiting a commenter on one&#x27;s site violate? reply pessimizer 15 hours agorootparentI don&#x27;t have a problem with it, but it&#x27;s obviously (for the person you&#x27;re replying to) the secrecy. reply shadowgovt 15 hours agorootparentThank you; that makes sense. I can see that viewpoint, but I&#x27;m torn on whether I agree with it.On the one hand, it&#x27;s at the very least considered good UX to inform users of information regarding their account status that impacts their experience.On the other hand, it&#x27;s probably acceptable for a place called \"Hacker News\" to hide some community features behind \"You have to demonstrate some willingness to do some computer sleuthing to learn this detail.\" reply bowsamic 3 hours agorootparentprevHonesty reply PCMcGee1 3 hours agoprevWhat good does it do to have upvotes and downvotes on a site, if you have no tools available to discriminate between them. When most comments turn out to be obvious, redundant or repetitive, a tool that identifies the pertinent portions of a discussion seems not only in good order, but becomes an imperative for growth at some point. Asking every participant to make these discernments is a giant waste of valuable people&#x27;s time. reply thecosas 15 hours agoprevGlad to see digging in a bit more on HN! While we&#x27;re at it, if you&#x27;re not aware of the \"second chance pool\", you should be: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;poolMore discussions&#x2F;description from dang here: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=26998308 reply NaOH 15 hours agoprevHere or elsewhere I’ve long followed these rules for commenting:1. Be respectful.2. Stay on topic.3. Move the conversation forward. This sounds like a repetition of #2 but there is often a distinction in that, say, a discussion about a new product feature is likely not the time to discuss the company’s history with features. Going in that direction is moving the conversation sideways.4. Provide supporting evidence for what is said. Claiming something like, “I’d never buy this from Company X” is a baseless statement compared to “I’d never buy this from Company X because A, B, and C are an indication I won’t get much support beyond the 90-day warranty and that’s not enough at that price point.” The trick I use for this is to include a word like because since it compels an explanation.5. Avoid attempts at humor. For one, text mediums like HN can easily lead to misinterpretations; there are many people reading for whom English is a second language, so being clever can cause confusion for those readers; if my humor were so good to be worthwhile for the amount of readers a place like HN has then I should be a comedian. I&#x27;m not a comedian. reply Uehreka 15 hours agoparentMy most upvoted comment on HN by a mile was a joke about Siri. A lot of my other most upvoted comments are either jokes or humorous exaggerations or other silly stuff.The guidelines may say that humor should be avoided, but the readership (the people who, in the end, decide what HN is) seems to disagree. reply tptacek 14 hours agorootparentThe canonical answer to this issue, which comes up over and over and over again on HN:https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=36219385It&#x27;s worth remembering that HN is a common law system. If you want to nerd out about what the real, fine-grained guidelines are, follow Dan&#x27;s comments; they&#x27;re the site jurisprudence.A corollary to the humor thing: insubstantial comments are problematic when they&#x27;re negative and less problematic when they&#x27;re positive or encouraging. That&#x27;s a principle that goes all the way back to Graham. So you&#x27;re generally going to be fine attempting a cheerful joke than you are trying for a sly dunk. reply Gibbon1 13 hours agorootparentHumor is often a wrapper around something.Malign people wrap antisocial stuff in order to get people to eat of it.A joke with nothing inside it is just annoying and derailing. See the guy who always interrupts the conversation with a pun.It is possible to wrap decent stuff with humor. reply vlz 14 hours agorootparentprevDisfavoring humor is one of the things that keeps HN from becoming like reddit where the top answers often seem to be empty witticisms.While it might have worked for you karma-wise, many bad&#x2F;average attempts at humor seem to get downvoted a lot and I am glad for it.When I click on a topic that I&#x27;m deeply interested in, the last thing I want to see is someone&#x27;s attempt at being witty to collect internet points. reply gspencley 14 hours agorootparentThis is going to be a divisive issue.Personally there&#x27;s nothing I can&#x27;t stand more than people who take life too seriously and can&#x27;t find the absurdity in every day matters. If someone manages to make me spit out my coffee, give a chuckle or even just a smile then I am eternally grateful. After all, I&#x27;m usually on HN because I need a temporary mental break from work.Value comes in many shapes and forms. But is also in the eye of the beholder. I just ask that you and others don&#x27;t assume for a second that someone trying to make others laugh is doing it for \"internet points.\" Some people genuinely like trying to bring a smile to the faces of others. Those who succeed are my heroes. reply kelnos 13 hours agorootparentThe problem with that is the response varies a lot by individual.There have certainly been occasions -- albeit rare -- when a humorous HN comment has made me laugh out loud, or at least grin.But most of the time I find attempts at humor here to be annoying and distracting. Especially when it devolves into a deep thread of few-word or one-line responses that reminds me very much of things I dislike about Reddit.Put another way: I don&#x27;t come here for humor. That doesn&#x27;t mean I won&#x27;t appreciate it sometimes, but that&#x27;s not what I&#x27;m here for, and the majority of the time I find it to be an unwelcome distraction from what I actually come here for. I come here for discussion, whether just to read it, or to participate in it. Short, humorous comments almost never lead to discussion. reply tamimio 13 hours agorootparentprev> I just ask that you and others don&#x27;t assume for a second that someone trying to make others laugh is doing it for \"internet points.\" Some people genuinely like trying to bring a smile to the faces of others.Spot on!! I personally couldn’t care less about these brownie points, my whole life been (and still) using alt&#x2F;nicknames accounts and mostly in sites&#x2F;chats where the whole upvote system isn’t there, when I help someone in something or make a joke, because it makes me feel better to know I helped someone or brought some smile, I don’t care about your fake coins or whatever, but some people are so fixated about it for some reason, and that’s why I don’t like “influencers” culture in general, they are usually slaves to these thumbs up! reply throw10920 8 hours agorootparentprevHN doesn&#x27;t ban humor. HN disfavors it - you can still be humorous, but you have to not just be humorous, but actually provide substance. Solid discussion written in an entertaining style tends to be highly upvoted. Allowing \"mere jokes\" with no substantial content leads to Reddit. If you want that - go there. reply gretch 14 hours agorootparentprev> the people who, in the end, decide what HN isI don’t agree with this position. There is a place for administrators to shape the place they want to build for the world and have it be differentiated from other places.As a thought experiment: HN could turn into a TikTok clone and it would be wildly popular. It will be decided by the users, but the user base will be 100% different. And the world would have lost a unique place for yet another clone.So I appreciate it when the site owners are opinionated and proactive about maintaining this space. reply jjav 14 hours agorootparent> HN could turn into a TikTok clone and it would be wildly popular.As a strictly text-only medium that would be difficult.That&#x27;s why I vastly prefer text-only media. Email lists (without attachments), Usenet, or even forums that only do text. The written word requires more effort than just posting pics so quality is almost inevitably better. reply another-dave 12 hours agorootparentprevBut there&#x27;s a healthy tension between \"moderator and moderated\" — people come to a place because it&#x27;s being shaped in a certain way, but bring their own expectations.And in tandem, the guidelines grow with the community to reinforce behaviour that&#x27;s seen to be fruitful and disincentivise behaviour that&#x27;s derailing. reply mindcrime 14 hours agorootparentprevThe guidelines may say that humor should be avoided, but the readership (the people who, in the end, decide what HN is) seems to disagree.In my experience here (and I have been around a while), the actual case is that some humor is welcome here. But the subset of what is welcomed on HN, versus the set of \"all things someone finds humorous\", is pretty small. I&#x27;ve had humorous comments upvoted before, even highly so. But there&#x27;s a pretty particular brand of humor that seems to work here. And you can&#x27;t always predict how something will be received.I will say this: some of my most highly upvoted comments are among some of my lowest effort ones (eg, something like \"Fuck these guys. The NSA can go go hell\" or similar) while I&#x27;ve had tons of comments that I spent half an hour or more working on, doing researching, finding citations, etc.... and they either got zero votes, or got downvoted.My point is that it&#x27;s really hard to guess how people will react to any particular comment here, humorous or otherwise, on any particular day. reply kej 14 hours agorootparentprevIt had its own moderation problems, but I liked the Slashdot rule that funny upvotes didn&#x27;t count for karma with the explanation that \"you have to be smart, not just a smartass\". It made it so that people could still post jokes, but they weren&#x27;t rewarded in the same way that meaningful contributions were. reply mulmen 14 hours agorootparentprevClassic survivor bias. Jokes are fine when they are funny but they aren’t worth the price of encouraging unfunny posts. Ultimately they don’t contribute. reply sofal 8 hours agorootparentExactly. Actually funny jokes from amateurs tend to have risen out of an order of magnitude more failed attempts. You can&#x27;t encourage the funny one without inviting a ton of bad ones. reply dontupvoteme 3 hours agorootparentprevSlashdot fixed this way back in the day by identifying which category the comment was in (Informative, Funny, etc)Would make great training data these days! reply adamredwoods 14 hours agorootparentprevSimilar to sarcasm, I don&#x27;t always \"read\" the sarcasm or humor as intended. My internal voice may read something differently, depending on the mood I&#x27;m in.I don&#x27;t mind it when someone calls it out with a \"&#x2F;s\" or \"&#x2F;jk\" (&#x2F;sarcasm, &#x2F;joking).Related: humor at work: https:&#x2F;&#x2F;hbr.org&#x2F;2020&#x2F;07&#x2F;sarcasm-self-deprecation-and-inside-... reply wrboyce 13 hours agorootparentprevI had the same thought reading the parent comment. My most upvoted comment on HN is a single word joke (that blurs the lines between English and Spanish) and if I’m completely honest I’m still quite proud of it, especially being someone who, at best, fumbles their way through speaking Spanish.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23842179#23845200 reply doctor_eval 12 hours agorootparentprevMine was a story about cockatoos that had a funny twist ending.I think humour on HN is one of those things that’s, let’s say, “a little bit naughty” - but you can get away with it sometimes if it’s genuine. reply krapp 14 hours agorootparentprevThe guidelines don&#x27;t actually say humor should be avoided. Hacker News is just weirdly priggish because it associates humor with Reddit and Reddit with everything it fears, hates and stands against. So unless it&#x27;s particularly smart and clever humor (which negates its \"Redditness\") it&#x27;ll get stamped out like a cockroach. reply samstave 13 hours agorootparentprevI try as often as possible to add a meaningful comment after I make my pun or jokes.I don&#x27;t always remember to do it, but I do try. reply 1letterunixname 14 hours agorootparentprevNotes on this: We&#x27;re not fucking robots and data is cold and boring. If people can&#x27;t be free to be themselves, I don&#x27;t see the value and suspect egotistical&#x2F;protofascist-esque attempts to control others. The best conversations include stories and have a sense of humor. People lacking a sense of humor tend to be the most dramatic and problematic. reply mulmen 14 hours agorootparentI don’t lack a sense of humor, it’s just not why I come to HN. I also don’t discuss my political views with my manager. reply tamimio 13 hours agorootparentprevI will take humor or even cheesy jokes over some of the condescending, egotistic, and patronizing comments in here any day any time. Obviously all in moderation, but listing humor as a bad thing in general gives an you idea the type of person&#x2F;company&#x2F;etc. is, taking life too seriously is not a healthy thing, not for you, not for everyone around you. reply kelnos 13 hours agorootparentPersonally I&#x27;d be fine if the humor and the condescending, egotistic, patronizing comments all went away.I don&#x27;t think humor in general is a bad thing (my friends would likely in part describe me as a wise-cracking, sarcastic jokester at times), but I just don&#x27;t think HN -- or any sort of textual medium where participants don&#x27;t know each other that well or at all -- is a great place for it.Obviously we&#x27;re all free to disagree on this (and we obviously are, given the size of this subthread), but I think overall the community agrees (through up&#x2F;downvoting) that humor on HN should be fairly rare. reply tamimio 3 hours agorootparentIt might be, but a light hearted joke shouldn’t be looked at as a bad&#x2F;offensive behavior, if you don’t like it, ignore it, someone else might like it, we are not the same, something for you maybe is a no no to joke about, for someone else it isn’t so why gatekeeping the conversation? I do agree on not overdoing it since after all that’s not what I’m here for.>but I think overall the community agrees (through up&#x2F;downvoting) that humor on HN should be fairly rare.I disagree with that from two perspectives, for one, the majority of the site’s users are lurkers (I’ve been lurking since 2007ish, first account I made in 2014 and barely used it to comment, and made this mainly to engage a month ago), and these up&#x2F;down votes only account the users who engage in the comments. The second side is, I believe it’s a different personalities, the ones who engage in comments up&#x2F;down votes are mostly the intense ones who comes out usually as condescending, since being that after all might get them some of these kudos, and the ones who don’t engage in up&#x2F;down voting are the relaxed personalities who don’t mind to have some humor from time to time, hence the comments in here saying they don’t favor humor will get more votes than the others, because they are the ones who engage and care about these votes to start with, but that’s my personal observation only. reply janalsncm 15 hours agoparentprevOn 5, I will avoid humor directed at a user and usually humor related to the ambiguity in headlines, however poorly written. I won’t shy away from mocking soulless PR statements or silly public figures. reply 0xdeadbeefbabe 14 hours agorootparent5 oughta have a caveat like only pg can attempt humor reply the_arun 14 hours agorootparent@0xdeadbeefbabe Good sense of humor! reply AlbertCory 11 hours agoparentprev> Avoid attempts at humor. For one, text mediums like HN can easily lead to misinterpretations; there are many people reading for whom English is a second language, so being clever can cause confusion for those readers;On behalf of ESL people, you&#x27;re offended? Maybe you should let them speak for themselves.Humor is a big part of what makes life worth living. I love it when someone makes me LOL.Maybe the non-native English speakers just think, \"Well, I don&#x27;t get that, but whatever.\" In their other reading, they&#x27;ll run across idiomatic English sooner or later, too.Don&#x27;t take life too seriously. You&#x27;ll never get out of it alive. reply lazyasciiart 10 hours agorootparentIf you read that line as \"someone is offended\", you might be over-estimating when people are offended. reply aequitas 15 hours agoparentprevAs a personal rule I only upvote humor on fridays, which I sometimes break if a joke is really really good. reply Savely 15 hours agoparentprevBut humour is half the reason I read HN and 3&#x2F;4 the reason I comment! reply 1letterunixname 14 hours agorootparentMade with 125% organic love and infotainment value. (By weight, not by volume. Some contents may have settled during transport.)Edit: Maybe we need an overlay meta HumorNews to channel all of our distracting banter lest the people who yell at you for daring to ask a question in a source repository issue declare \"you are wrong, stop being you, stay in your lane, and follow the rules precisely\". reply TurkishPoptart 13 hours agoparentprevAll attempts at humor should be made. If they fail, a simple apology or explanation should be fine. Otherwise, offended parties should kindly exfiltrate themselves back to Reddit. reply canvascritic 16 hours agoprevA mentor once said to me something to the effect of \"don&#x27;t optimize for the noise - optimize for signal\"These guidelines, in many ways, embody that sentiment. While some might complain they are restrictive and harsh (I think, for example, of new commenters being met with a swift downvote to oblivion when they comment \"me too!\" or \"cool!\" on a thread), I view them as a way to elevate discourse, prioritizing the depth and quality of conversation over fleeting internet trends, a beacon of light in this sorry internet that mostly devalues thoughtful discourse and inquiry.Understanding the dynamics of a community and its shared norms can be as important, if not more so, than the actual content. in nurturing a thoughtful environment, in particular an environment that nurtures curiosity and civil discourse, we&#x27;re not just preserving the present, but serving as role models for tomorrow&#x27;s communities. personally I&#x27;m glad that HN emphasizes intellectual curiosity and mutual respect. this is truly a special place reply gweinberg 14 hours agoprev\"How do I flag a comment?Click on its timestamp to go to its page, then click the &#x27;flag&#x27; link at the top. There&#x27;s a small karma threshold before flag links appear.\" This could be more clear. I was able to figure out what they meant, but \"25 minutes ago\" is not a timestamp. If you hover over the link it will display the timestamp, but I never even noticed that until today.I think it would be clearer if the text said \"click on the reply link\". Yeah, I know the link doesn&#x27;t say \"reply\", but \"reply link\" is what it is, and \"timestamp\" is something it isn&#x27;t. reply ChrisArchitect 16 hours agoprevMaybe OP can comment on why they submitted this reply minimaxir 15 hours agoparent> Please don&#x27;t complain that a submission is inappropriate. If a story is spam or off-topic, flag it. reply Tao3300 15 hours agorootparentCute, but I think you read it wrong. It would be very relevant to know why someone wanted to talk about this and how it got to the front. There has to be some context, and I suspect GP is intrigued to know what it is. reply minimaxir 15 hours agorootparentThe only requirement to submit something to HN is \"it&#x27;s interesting\". Random evergreen content with no contemporary relevance gets submitted all the time, hence the (YEAR) rule. My 8 year old GitHub repo which hasn&#x27;t ever been significantly updated gets submitted to HN atleast once a year: https:&#x2F;&#x2F;hn.algolia.com&#x2F;?q=https%3A%2F%2Fgithub.com%2Fminimax...If other users didn&#x27;t think this submission about HN rules was interesting, it wouldn&#x27;t be upvoted. reply throw_m239339 13 hours agorootparentprevI think it&#x27;s more like a question, what prompted the author of the thread to submit the rules? Did they change or something? reply lapcat 16 hours agoprevIMO the guidelines could use some updates. For example, there are some unwritten conventions that could be formalized:1) Search for duplicates before you submit a link.2) If the submission is not from the current year, append (YEAR) at the end of the title.3) It should be clarified that the guidelines about comments apply to linked article authors too. \"Be kind. Don&#x27;t be snarky.\" \"Please respond to the strongest plausible interpretation of what someone says, not a weaker one that&#x27;s easier to criticize. Assume good faith.\" \"Please don&#x27;t post shallow dismissals, especially of other people&#x27;s work.\"4) There&#x27;s dang&#x27;s own idiosyncratic, controversial, unwritten exception to \"Please submit the original source\", i.e., unless it&#x27;s a corporate PR.[EDIT:] Three different replies have said to append [pdf] and [video] to submissions, but that&#x27;s already in the guidelines. \"If you submit a video or pdf, please warn us by appending [video] or [pdf] to the title.\" reply tomashubelbauer 16 hours agoparentAFAIK (I saw dang state this a few times in his comments) it is fine to submit duplicates to HN assuming enough time has passed (a year?). He&#x27;ll even reach into the second change pool and re-submit submissions that did not gain much traction the first time around, I think. So I think your first rule isn&#x27;t really something that is much enforced on HN. (Which I think is a good thing.) reply lapcat 16 hours agorootparentThat&#x27;s in the FAQ: \"If a story has not had significant attention in the last year or so, a small number of reposts is ok. Otherwise we bury reposts as duplicates.\" https:&#x2F;&#x2F;news.ycombinator.com&#x2F;newsfaq.html reply kergonath 16 hours agorootparentIt’s more of a guideline than an ironclad rule, though. Two different sources might have different takes on the same thing and it is not rare to have more than one story about the same subject on the front page, for good reasons. The community (and the mods) seem to be very effective at filtering real duplicates. reply dredmorbius 4 hours agorootparentAnother case where looking through dang&#x27;s moderation comments is helpful.The duplicates-detection code is deliberately porous: But overwhelming the front page with multiple takes on a story (e.g., the Tver aircraft downing yesterday) would be tiresome, and even multiple takes on what&#x27;s essentially the same story over a span of a few days or weeks can get tedious.The critical qualifying exception is \"significant new information\":reply DavidPeiffer 16 hours agorootparentprevI hadn&#x27;t heard about the 2nd chance pool until I submitted an article and he emailed me to say he was going to 2nd chance it.That was a really neat mod intervention I wasn&#x27;t expecting but really appreciated. reply brudgers 16 hours agoparentprevTo me, those all seem more like places where the community usually intervenes to the degree it matters. [1]While the guidelines seem more there to help the community as a whole stay out of potholes, sinkholes, and black holes.But that’s me and I can see why people might have a different point of view on this. This is a model I use, not an argument.[1] editing headlines being an exception. reply weinzierl 16 hours agoparentprevBesides (YEAR) there also seems to be the convention of [pdf] and less strongly [video]. The latter two use square brackets instead of parentheses. reply lapcat 16 hours agorootparentThat&#x27;s actually in the guidelines already: \"If you submit a video or pdf, please warn us by appending [video] or [pdf] to the title.\" reply weinzierl 16 hours agorootparentOh, indeed, it&#x27;s been a while since I read it. Then I would like to add the guideline \"Read the posting, before you comment.\" reply styfle 16 hours agoparentprevI&#x27;m pretty sure that submitting a duplicate link is automatically turned into an upvote on the original reply dang 15 hours agorootparentYes but only if (1) the previous post got significant attention and (2) it was within the last year or so. Otherwise we let reposts through, because we want good stories to get multiple chances at attention, and because it&#x27;s good for the culture when classic articles cycle through once in a while. Just not too often. reply em-bee 16 hours agorootparentprevonly if the url is an exact match, which often it isn&#x27;t. reply Hamuko 16 hours agorootparentprevI&#x27;m pretty sure that it isn&#x27;t.https:&#x2F;&#x2F;hn.algolia.com&#x2F;?q=https%3A%2F%2Fwww.backblaze.com%2F... reply Tao3300 15 hours agoparentprevUsually I see the dupe and not the original.Comments pointing out dupes are irrelevant noise. reply jasonpeacock 16 hours agoparentprevEvery dupe I&#x27;ve submitted has automatically de-duped to an existing post that someone already submitted - probably because it&#x27;s the same URL? reply dang 15 hours agorootparentSame URL plus (1) the previous post got significant attention and (2) it was within the last year or so. reply redbell 16 hours agoparentprevAs a complementary to 2), if the submission is a video or a PDF append [video], [pdf] respectively at the end of the title. reply gumby 16 hours agoparentprevand add warnings for non-text posts [pdf] [video] etc reply jwr 16 hours agoparentprevI also wish there was a guideline that only content available on the Internet can be submitted. We are too often being used for promotion by sites with pay walls. Nothing wrong with a paywall, but it should be either-or: you should not be able to get HN to promote you, unless your content is accessible. reply osigurdson 14 hours agoparentprevA lot of stuff also gets posted which is behind a paywall. I&#x27;ve learned to tune these out for the most part just from the domain name but I still don&#x27;t see the point. reply tptacek 12 hours agorootparentPaywalled stories are OK if there are straightforward workarounds, which are almost always surfaced on the thread. Stories that people simply can&#x27;t read without subscribing are off-topic here.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=10178989 reply dredmorbius 4 hours agorootparentThis has been somewhat increasingly problematic over the past month or so as well-known existing workarounds seem to be increasingly problematic or failing.Around 15% or more of HN front-page submissions are to paywalled and&#x2F;or general news sites.(I&#x27;ve classified the latter in my analysis of historic HN front-page activity, I haven&#x27;t gone through to specifically note paywalled sites.)And tightening paywalls can have a large impact on submissions. After the New York Times strengthened its paywall in 2019, HN front-page submissions fell to about 25% of their previous level. reply osigurdson 4 hours agorootparentprevInteresting, I&#x27;d always thought the paywall workarounds were a terms of use violation. reply pb7 16 hours agoparentprev>There&#x27;s dang&#x27;s own idiosyncratic, controversial, unwritten exception to \"Please submit the original source\", i.e., unless it&#x27;s a corporate PR.I said it before and I&#x27;ll say it again: this is a bad rule. People can read through the corporate bullshit themselves instead of having some \"journalist\" tell them what to think of it. reply wolverine876 13 hours agorootparentThe news reporter doesn&#x27;t tell you what to think, they do the research - talk to competitors&#x27; CEOs, talk to independent experts, bring up that lawsuit and interview leading attorneys in the field, research prior comments and actions, ask followup questions to the CEO of the corporation who issued the press release, etc etc - and then share it with you.No one has time to do that themself, and the CEOs, attorneys, experts, etc. won&#x27;t return your calls anyway (they can&#x27;t return everyone&#x27;s calls).Opinion writers are the one who tell you what to think. IMHO, few of them are better than blogger. reply fullshark 17 hours agoprev> Off-Topic: Most stories about politicsI&#x27;d welcome a firmer hand on eliminating these submissions. reply dang 15 hours agoparentThe solution space for this is pretty small, meaning that most things that feel like they might work (e.g. just ban politics) don&#x27;t actually work. But the answer we&#x27;ve converged on over the years is pretty stable: some political overlap is inevitable and ok, but the articles should be ones that can support an intellectually curious conversation rather than just garden-variety flamewar.Here are some past explanations of how we approach this. If anyone reads those and still has a question that isn&#x27;t answered there, I&#x27;d be happy to take a crack at it.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=23959679 (July 2020)https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=22902490 (April 2020)https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=21607844 (Nov 2019)https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=17014869 (May 2018)https:&#x2F;&#x2F;hn.algolia.com&#x2F;?dateRange=all&page=0&prefix=false&so... reply phpnode 15 hours agorootparentusers tend to be quite good at flagging most highly political stories, so they disappear off the front page pretty quickly but can still be found by those who really want to engage. The status quo is good imo reply fragmede 15 hours agorootparentCertain high profile stories get flag protection, which seems controversial to me, especially when used silently and only admitted to after the fact. I can&#x27;t remember the specific one but it was one in the wake of Elon Musk&#x27;s purchase of Twitter. It ranked highly despite the flags it was getting, according to dang. reply dang 15 hours agorootparentSure, we sometimes turn off user flags when the article contains significant new information and the topic seems intellectually interesting.Most of what we do is \"done silently and only admitted to after the fact\". HN is a curated&#x2F;moderated site; it always has been. We don&#x27;t publish a moderation log but it&#x27;s always possible to get an answer to a question—you just have to ask. reply fragmede 15 hours agorootparentI welcome the curation and moderating of this site! I&#x27;m more imagining that those stories got posted to https:&#x2F;&#x2F;news.ycombinator.com&#x2F;favorites?id=dang, with some time delay, so years from now, amateur historians can see what articles were deemed noteworthy in such a fashion. reply bombcar 15 hours agorootparentprevThe “climate change” ones are becoming boring. Recent penguins for example. reply joshmanders 14 hours agorootparentYou know you can skip those right? Just because it&#x27;s posted and upvoted to the front page doesn&#x27;t mean you have to read it.I read like 2-3 links max on my visits here. reply kelnos 13 hours agorootparentOn top of that, it&#x27;s easy to click the \"hide\" link under a story title, and that leaves more room on the front page for stories I might actually want to read, without having to dig deep into successive pages of stories. reply fragmede 15 hours agorootparentprevGiven the advancements of LLMS, have you given thought to automating some moderation to tell the user they&#x27;re about to leave a predictable repetitive flamewar comment? Ie, a cleverer version of https:&#x2F;&#x2F;blog.xkcd.com&#x2F;2008&#x2F;01&#x2F;14&#x2F;robot9000-and-xkcd-signal-a... reply dang 15 hours agorootparentNot yet, but the relevant data for doing this is mostly public, and if anyone wanted to work on it, we&#x27;d certainly be interested in what they came up with. reply suddenclarity 9 hours agorootparentprevInteresting solution. I had some concerns at first but increasing the threshold and manually whitelisting some common valuable but non-unique comments would probably go a long way. Maybe even reduce it to parts of a comment to reduce lazy jokes. reply robmccoll 16 hours agoparentprevI&#x27;d like clarification of whether politics is meant to cover matters of policy or strictly partisan politics and news about the lives of political figures. Surely regulatory policy with regards to technology, communications infrastructure, and similar is of interest. reply jl6 15 hours agorootparentIt may not be a useful distinction, when what we really want is to exclude based on “propensity for useless flamewar”. reply arp242 12 hours agorootparentStrong disagree on that criteria, because there are many interesting and very valid topics that attract a certain type of minority who will derail thing to a \"useless flamewar\". The problem isn&#x27;t with the topic, it&#x27;s with these users.I feel people are given too many chances sometimes, especially when they \"also make good comments\". The problem there is that these are often quite active users with a lot of total comments, so \"only n% of bad comments\" means a lot of \"bad comments\". The standards should be higher for very active users, not lower, as their influence on the site is much larger.For example I&#x27;m looking at at story where a single user posted 45 comments (~17%), quite a few in \"flame war style\" and (rightfully) flagged. Most other comments are fine, except the threads that user created. The topic didn&#x27;t cause the flamewar: that user did. Now, everyone can have a bad day and that&#x27;s okay, but I&#x27;m somewhat amazed some people are not banned as they frequently engage with a type of aggression, contempt for differing views, and bad faith nonsense in a way that really \"destroys what the site is for\", as Dang would say. I can name a number of them from the top of my head and I can virtually guarantee you they will have at least one flagged comment on their first two comments pages or so, and most likely several.The reason these topics are derailed are these people (and others), not the topic as such. Don&#x27;t ban topics, ban people if they can&#x27;t bring up the maturity and professionalism to keep some basic level of composure (maybe HN needs better tools for this; e.g. topic-bans, temporary bans, etc. but that&#x27;s a bit of a different discussion).Especially on difficult topics I want to have interesting conversations that explain differing viewpoints, and criticise other viewpoints in a constructive and good-faith way, or provide additional context.While I appreciate this is a difficult thing to moderate, this, in a nutshell, is my main criticism of HN&#x27;s moderation. reply mulmen 14 hours agorootparentprevAnd even more specifically we want to optimize for intellectually interesting conversation. reply sanderjd 16 hours agorootparentprevThis does seem like a good distinction. reply tantalor 16 hours agoparentprevThe existing moderation works fine.I bet if you looked through recent stories that made the front page, <1% would be classified as \"about politics\". reply thinkingemote 13 hours agorootparentDepends on the time of day, UK morning time before east coast USA wakes up there&#x27;s always one or two political posts which get quite a bit of attention. However they quickly go from the front page after a few hours.I&#x27;ve noticed some San Francisco specific post appearing too at similar hours. These generally get more comments but as before usually go after some time.---Personally, some political stuff is fine, interesting and worthy of comment. I do find myself replying and then deleting my comments on those threads after I realise the discussion is meaningless. reply minimaxir 16 hours agoparentprevGenerally submissions about politics without any tech angle do get flagged.Politics that do have a tech angle (e.g. SEC&#x2F;FTC actions, net neutrality) are more on-topic. reply rgrieselhuber 16 hours agoparentprevIt depends on the context.Obviously partisan politics don’t really have a place here but metapolitical critiques of the technology known as bureaucracy (which is pervasive in government, science, everywhere really) and how well it is or is not working is definitely relevant from a systems perspective, imo. reply bdcravens 16 hours agoparentprevYou can play a role. Depending on your points level, you can go to \"new\" and flag political posts. reply theptip 16 hours agoparentprevAgreed, those threads are usually terrible. reply sanderjd 16 hours agoparentprevI&#x27;m guilty of commenting on these, and I used to disagree about eliminating more of these - with my thought being that politics is interesting to \"hackers\" because it is interesting to people and \"hackers\" are people - but with the wisdom of years, I&#x27;m inclined to agree that the discussion on these submissions nearly universally sheds more heat than light. reply freedomben 16 hours agoparentprevthe big challenge here is that \"politics\" nowadays can include nearly everything, and many stories are very relevant to HN audience. Like Tiktok getting banned or regulated. Clearly very political, but also highly relevant to HN. A firmer hand would mean no exceptions for stories like that. reply paulddraper 12 hours agoparentprevHN does very well about this.The only \"politics\" stories are tech&#x2F;industry politics stories. reply tptacek 12 hours agorootparentThat&#x27;s not really the dividing line. It&#x27;s certainly easier to get tech politics onto the front page than other political stories, but the real distinction is how interesting the story is, not how technical it is. Or rather, how interesting the resulting thread is likely to be, where \"interestingness\" is sort of conceptually measurable as the distance that thread will have from previous threads on previous politics stories. reply bee_rider 16 hours agoparentprevYes comrade, for example we could get rid of these stories about these “start up companies,” they are clearly capitalism extremists pushing their political viewpoints.Jokes aside, I think it is hard to moderate too strictly on the topic of “no politics” without enforcing a particular political viewpoint, because we tend to see politics we like as normal, and politics we don’t like as politics. reply Clubber 15 hours agoparentprevI enjoy reading the discussions about politics on HN. Most comments are refreshingly thought out and not just lines being drawn and people parroting what they hear somewhere else. I don&#x27;t know of anywhere else on the internet that has actual thoughtful political discussions.Also, HN-ers tend to have very sharp BS detectors which really helps. reply TX81Z 16 hours agoparentprevMost internet technologies are currently in a phase change due to a changing regulatory and political environment. That has major implications for the direction of many types of technology discussed here so to that end I think tech policy is a very valid topic for HN.Now, the horse race of the day, or manufactured moral crisis? Not really what this is for. reply roflyear 15 hours agoparentprevI don&#x27;t know why people are so terrified of politics. reply Slow_Hand 15 hours agorootparentI’ll venture a guess. Mainstream politics (in America at least) has become something of a spectator sport that leads to unproductive, irritating, and dysfunctionally polarizing behavior. reply roflyear 14 hours agorootparentI don&#x27;t think it&#x27;ll get better by NOT talking about it. reply zogrodea 13 hours agorootparentSure, polarisation may exist elsewhere, but does that mean we have to bring it here too by talking about it? (Because the users on HN are subject to the same tendencies as everyone else, and almost invariably the kind of conversations that polarise elsewhere will polarise people here too.) reply tptacek 13 hours agorootparentprevIt is absolutely not part of HN&#x27;s charter to make US politics (or the politics of any country!) better. That&#x27;s a project worth undertaking, but there are better places for it. reply em-bee 14 hours agorootparentprevit&#x27;s not the topic itself that is terrifying but the antagonistic mode of discussion.i have no problem discussing political opinions themselves, but i have no interest arguing about who these opinions belong to and which party is on which side of the debate or judging people or groups for having a particular opinion, or worse attacking them for it. reply b59831 14 hours agorootparentprevBecause activists can talk about nothing else.It&#x27;s annoying, not terrifying reply 0xbadcafebee 15 hours agoprevOn submissions: if you blocked global news websites, at least a quarter of the top posts would be gone.On comments: they could solve a shitload of the complaints about comments by just adding meta-votes, like those on Slashdot, and letting individual users define their own filters for what they do and don&#x27;t want to see. Automating and letting the community manage itself would be so much more efficient and fair than relying on mods, or the extremely vague and unhelpful generic vote button. reply tptacek 14 hours agoparentGlobal news websites are, apparently, heavily downweighted. But they too often produce genuinely interesting stories to block entirely. reply dredmorbius 4 hours agoparentprevBy my own research and classification, \"general news\" sites accounted for 4.1% of front-page stories on HN in 2022 (most recent complete year&#x27;s data), and that percentage has fallen over the years (it was 8% in 2009), with a corresponding rise in programming-specific sites (GitHub&#x2F;GitLab, and language-specific sites, e.g., \"python.org\" or \"golang.org\".)Sites classified as \"general news\" (ordered by frequency in the front-page archive): nytimes.com, bbc.com, bbc.co.uk, theguardian.com, washingtonpost.com, reuters.com, npr.org, cnn.com, slate.com, vice.com, latimes.com, cnet.com, yahoo.com, sfgate.com, cbc.ca, cnbc.com, guardian.co.uk, bits.blogs.nytimes.com, vox.com, salon.com, time.com, nymag.com, telegraph.co.uk, boston.com, newsweek.com, chronicle.com, msn.com, axios.com, news.com.com, propublica.org, independent.co.uk, timesonline.co.uk, mercurynews.com, theglobeandmail.com, pbs.org, theintercept.com, usatoday.com, buzzfeednews.com, spiegel.de, rollingstone.com, thestandard.com, go.com, smh.com.au, cbsnews.com, abc.net.au, nbcnews.com, seattletimes.com, aljazeera.com, bloombergview.com, motherjones.com, firstlook.org, thehill.com, apnews.com, informationweek.com, news.com, thedailybeast.com, huffingtonpost.com, theage.com.au, csmonitor.com, nwsource.com, japantimes.co.jp, thestar.com, bostonglobe.com, dw.com, indiatimes.com, nypost.com, ap.org, chicagotribune.com, sfchronicle.com, dailymail.co.uk, news.com.au, foxnews.com, kqed.org, theatlanticwire.com, scmp.com, texasmonthly.com, wbur.org, yahoo.net, swissinfo.ch, nationalpost.com, spectator.co.uk, sfweekly.com, detroitnews.com, theweek.com, nzherald.co.nz, washingtonexaminer.com, aljazeera.net, cbslocal.com, nltimes.nl, weeklystandard.com, ctvnews.ca, miamiherald.com, nydailynews.com, thetimes.co.uk, dallasnews.com, startribune.com, bostonherald.com, euronews.com, kuow.org, themorningnews.org, upi.com, globalnews.ca, guardiannews.com, theherald.com.au, thesun.co.uk, belfasttelegraph.co.uk, houstonchronicle.com, ibtimes.co.uk, koreaherald.com, metro.co.uk, mirror.co.uk, seattleweekly.com, standard.co.uk, dailyherald.com, huffingtonpost.co.uk, huffingtonpost.com.au, huffpost.com, inquirer.com, ktvu.com, ocweekly.com, sundayherald.com, theweek.co.uk, wpri.com, wtsp.com, americanchronicle.com, annarborchronicle.com, augustachronicle.com, catholicherald.co.uk, dukechronicle.com, heraldsun.com.au, katu.com, kdvr.com, kfor.com, ktla.com, myfox8.com, myfoxdc.com, myfoxny.com, news-herald.com, news.google.ca, pressherald.com, thechronicleherald.ca, timesherald.com, wttw.com, wtvr.com, wunc.org, wvgazette.com.This is based on downloading all archived HN front pages from 2007-02-20 through 2023-06-21 and analysing stories by title, site, votes, comments, and submitter. reply myroon5 3 hours agorootparentCurious how financial-focused news that was excluded (economist, wsj, ft, bloomberg, etc) has fared. Wouldn&#x27;t be surprised if that&#x27;s a substantial portion reply dredmorbius 3 hours agorootparentI classify those as \"business news\", which were 1.5% of 2022 front-page stories, as compared to 3.7% in 2009.(I generally use 2009 as a representative \"early year\" as HN was sorting things out and evolving rapidly in 2007 & 2008.)By year: 2007 418 2008 438 2009 407 2010 290 2011 271 2012 222 2013 224 2014 259 2015 329 2016 442 2017 426 2018 476 2019 418 2020 251 2021 194 2022 167 2023 95This is the first I&#x27;ve looked at these numbers specifically. I&#x27;m noting the substantial fall-off in 2020, which I suspect is paywall-related. Note that data for 2023 are partial.Sites: bloomberg.com, wsj.com, economist.com, venturebeat.com, businessweek.com, businessinsider.com, fastcompany.com, inc.com, hbr.org, ft.com, alleyinsider.com, forbes.com, fortune.com, nikkei.com, marketwatch.com, xconomy.com, entrepreneur.com, portfolio.com, business2.com, cio.com, bizjournals.com, bloombergquint.com, insidefacebook.com, nasdaq.com, fool.com, financialpost.com, prnewswire.com, adweek.com, morningstar.com, americanbanker.com, businessinsider.com.au, industryweek.com, bankertimes.com, businessinsider.co.za, businessinsider.de, businessinsider.fr, forbesindia.comAs above, these are ordered by overall frequency within the FP archive. reply metadaemon 16 hours agoprevThese are great guidelines in general for building a healthy community. reply 105 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Hacker News guidelines specify the topics that would interest hackers, excluding politics, crime, sports, and celebrities.",
      "Titles should not be altered, and the original source should be submitted without self-promotion.",
      "In the comments section, users are expected to be polite, avoid snarkiness, and respond to arguments instead of resorting to name-calling. Using uppercase for emphasis and making astroturfing insinuations should be avoided. Complaints about inappropriate submissions should be flagged rather than discussed in comments."
    ],
    "commentSummary": [
      "Hacker News (HN) is a platform that discusses various topics, including commenting guidelines, empty comments on Reddit and HN, moderation practices, and community behavior.",
      "Users express frustration with flagging and rate limiting on HN, as well as the ethics of rate limiting and shadowbanning.",
      "Other discussions on HN involve the role of humor, potential updates to link submission guidelines, moderation of political stories, and the decline of \"business news\" stories."
    ],
    "points": 382,
    "commentCount": 355,
    "retryCount": 0,
    "time": 1692894348
  },
  {
    "id": 37248895,
    "title": "Hugging Face raises $235M from investors including Salesforce and Nvidia",
    "originLink": "https://techcrunch.com/2023/08/24/hugging-face-raises-235m-from-investors-including-salesforce-and-nvidia/",
    "originBody": "Login Join TechCrunch+ Search TechCrunch+ Startups Venture Security AI Crypto Apps Events More (opens in a new window) (opens in a new window) (opens in a new window) (opens in a new window) (opens in a new window) Link Copied AI Hugging Face raises $235M from investors, including Salesforce and Nvidia Kyle Wiggers@kyle_l_wiggers / 9:00 AM CDT•August 24, 2023 Comment Image Credits: Hugging Face AI startup Hugging Face has raised $235 million in a Series D funding round, as first reported by The Information, then seemingly verified by Salesforce CEO Marc Benioff on X (formerly known as Twitter). The tranche, which had participation from Google, Amazon, Nvidia, Intel, AMD, Qualcomm, IBM, Salesforce and Sound Ventures, values Hugging Face at $4.5 billion. That’s double the startup’s valuation from May 2022 and reportedly more than 100 times Hugging Face’s annualized revenue, reflecting the enormous appetite for AI and platforms to support its development. Hugging Face offers a number of data science hosting and development tools, including a GitHub-like hub for AI code repositories, models and datasets, as well as web apps to demo AI-powered applications. It also provides libraries for tasks like dataset processing and evaluating models in addition to an enterprise version of the hub that supports software-as-a-service and on-premises deployments. The company’s paid functionality includes AutoTrain, which helps to automate the task of training AI models; Inference API, which allows developers to host models without managing the underlying infrastructure; and Infinity, which is designed to increase the speed with which an in-production model processes data. “AI is the new way of building all software. It’s the most important paradigm shift of the decade and, compared to the software shift, it’s going to be bigger because of new capabilities and faster because software paved the way,” co-founder and CEO Clément Delangue told TechCrunch via email. “Hugging Face intends to be the open platform that empowers this paradigm shift.” Delangue, a French entrepreneur, launched Brooklyn-based Hugging Face in 2016 alongside Julien Chaumond and Thomas Wolf. The trio originally built a chatbot app targeted at teenagers. But after open sourcing the algorithm behind the app, Hugging Face pivoted to focus on creating a platform for creating, testing and deploying machine learning. The company has 10,000 customers today, it claims, and more than 50,000 organizations on the platform. And its model hub hosts over 1 million repositories. Contributing to the growth is the strong, sustained interest in AI from the enterprise. According to a HubSpot poll, 43% of business leaders say they plan to increase their investment in AI and automation tools over the course of 2023, while 31% say AI and automation tools are very important to their overall business strategy. Much of what Hugging Face delivers falls into MLOps, a category of tools for streamlining the process of taking AI models to production and then maintaining and monitoring them. The MLOps market is substantial in its own right, with one report estimating that it’ll reach $16.61 billion by 2030. But Hugging Face dabbles in other areas, too. In 2021, Hugging Face launched BigScience, a volunteer-led project to produce an open source language model as powerful as OpenAI’s GPT-3, but free and open for anyone to use. It culminated in Bloom, a multilingual model that for more than a year has been available to tinker with on Hugging Face’s model hub. Bloom is but one of several open source models to which Hugging Face has contributed development resources. Hugging Face collaborated with ServiceNow, the enterprise software company, to release a free code-generating AI model called StarCoder (a follow-up model, SafeCoder, debuted this week). And the startup made available its own free version of ChatGPT, OpenAI’s viral AI-powered chatbot, in partnership with the German nonprofit LAION. Hugging Face’s team-ups extend to major cloud providers, some of which are strategic investors. Hugging Face recently worked with Nvidia to expand access to cloud compute via Nvidia’s DGX computing platform. It has a partnership with Amazon to extend its products to AWS customers and leverage Amazon’s custom Trainium chips to train the next generation of Bloom. And Hugging Face collaborated with Microsoft on Hugging Face Endpoints on Azure, a way to turn Hugging Face-developed AI models into scalable production solutions hosted through Azure. With this latest investment, Delangue says that Hugging Face plans to “double down” on its supportive efforts in many domains, including research, enterprise and startups. It has 170 employees, but plans on recruiting new talent over the coming months. Hugging Face has raised a total of $395.2 million to date, placing it among the better-funded AI startups in the space. Those ahead of it are OpenAI ($11.3 billion), Anthropic ($1.6 billion), Inflection AI ($1.5 billion), Cohere ($435 million) and Adept ($415 million). More TechCrunch Meta releases Code Llama, a code-generating AI model As AI porn generators get better, the stakes get higher Watch India's Chandrayaan-3 moon landing live How and when to charge for adding AI to your enterprise software Please login to comment Login / Create Account TechCrunch Disrupt Sept 19-21 San Francisco, CA Register Now Sign up for Newsletters See all newsletters (opens in a new window) Daily Week in Review Startups Weekly Event Updates Advertising Updates TechCrunch+ Announcements TechCrunch+ Events TechCrunch+ Roundup Email Subscribe (opens in a new window) (opens in a new window) (opens in a new window) (opens in a new window) (opens in a new window) Copy Tags AI funding Hugging Face machine learning Startups AI Hugging Face raises $235M from investors, including Salesforce and Nvidia Kyle Wiggers 9:00 AM CDT•August 24, 2023 AI startup Hugging Face has raised $235 million in a Series D funding round, as first reported by The Information, then seemingly verified by Salesforce CEO Marc Benioff on X (formerly known as Twi... Social Reddit launches moderator rewards program amid sitewide discontent Morgan Sung 7:49 PM CDT•August 24, 2023 Reddit is launching the “Mod Helper Program” to reward moderators who offer helpful advice to other moderators, along with an updated moderator help center. The announcement comes amid growing dis... TechCrunch Growth Nvidia is flying high thanks to AI When Nvidia reported earnings this week with three-digit growth, it put extra pressure on the com... Ron Miller, Alex Wilhelm 4:07 PM CDT•August 24, 2023 Hardware You can finally buy Lego’s Braille Bricks Devin Coldewey 3:25 PM CDT•August 24, 2023 Building with Lego bricks has stayed a formative and important practice for kids around the world, partly because it’s so easily enjoyed by anyone, regardless of location, language, or abilit... TechCrunch Disrupt 2023 Last chance to host an After Hours event at TechCrunch Disrupt 2023 Lauren Simonds 3:00 PM CDT•August 24, 2023 Listen up, party people! You’re rapidly running out of time to host your own After Hours Event at TechCrunch Disrupt 2023, which runs September 19–21 in San Francisco. Build your brand, connect wit... Fundraising Advanced Ionics nets $12.5M Series A to inject green hydrogen into heavy industry Tim De Chant 2:47 PM CDT•August 24, 2023 Advanced Ionics hopes its more efficient approach to using electrolysis will give it an unfair advantage in producing hydrogen. Commerce Shein inks deal with Forever 21 as it looks to boost its reach Aisha Malik 2:05 PM CDT•August 24, 2023 Shein and Forever 21 have entered into a partnership that will give both brands new ways to reach customers, the retailers announced on Thursday. As part of the partnership, Shein will acquire arou... Crypto Friend.tech hype grows, Tornado Cash founders go for a spin and FBI’s monitoring North Korean hackers Jacquelyn Melinek 2:00 PM CDT•August 24, 2023 Welcome back to Chain Reaction. If you haven’t heard about friend.tech this week, you’re probably living under a rock. But that’s ok, we dove deep into the hype. Apps Meta is shutting down Messenger Lite for Android in September Aisha Malik 1:16 PM CDT•August 24, 2023 Meta is shutting down Messenger Lite, its lightweight stripped-down version of Messenger, the company confirmed to TechCrunch. Users of the app are starting to see a message that advises them to &#... Social No Man’s Sky updates are going strong with Starfield around the corner Taylor Hatmaker 1:08 PM CDT•August 24, 2023 With a big-budget space exploration game debuting in days, indie spacefaring mainstay No Man’s Sky continues to deepen its own world with no signs of slowing down. No Man’s Sky is one o... Hardware Astropad’s latest is a combo iPad screen protector/Apple Pencil Tip Brian Heater 1:00 PM CDT•August 24, 2023 One thing you can definitely say about Astropad: they didn’t let a good old-fashioned Sherlocking keep them down. Over the years, new Apple features have scorched the earth of many a startup, and w... Privacy Social media giants urged to tackle data-scraping privacy risks Natasha Lomas 12:20 PM CDT•August 24, 2023 A joint statement signed by regulators at a dozen international privacy watchdogs, including the U.K.’s ICO, Canada’s OPC and Hong Kong’s OPCPD, has urged mainstream social media ... Apps Starbucks is experimenting with ‘scanless checkout’ for drive-through users Sarah Perez 12:17 PM CDT•August 24, 2023 Starbucks is testing a new way for customers to pay for their favorite beverages — without even having to pull out their phone. The company confirmed an internal test of “scanless pay,&... AI Amazon brings new AI-driven features to Thursday Night Football Lauren Forristal 11:36 AM CDT•August 24, 2023 As Amazon’s Prime Video gears up for its second year as the exclusive rights holder to NFL’s Thursday Night Football (TNF), the streaming service hopes to give fans a more enhanced viewing experien... Hardware Sony is buying gaming headphone maker, Audeze Brian Heater 11:27 AM CDT•August 24, 2023 Sony Interactive Entertainment (basically the PlayStation wing) today announced plans to acquire Audeze, the company has confirmed with TechCrunch. The Orange Country, California-based firm is best... Social X (Twitter) blocked links to a Democratic political tool for a week Amanda Silberling 11:21 AM CDT•August 24, 2023 Formerly known as Twitter, the social platform X temporarily blocked links to EveryAction’s NGP VAN, possibly the most popular political organizing software for Democratic and progressive cam... Apps X tries to lure back advertisers with new $250 ad credit Sarah Perez 11:18 AM CDT•August 24, 2023 X, the company formerly known as Twitter, has a new initiative aimed at luring smaller businesses to advertise on its platform. The company announced on Wednesday it would offer a one-time ad credi... AI ChatGPT: Everything you need to know about the AI-powered chatbot Kyle Wiggers, Alyssa Stringer 11:00 AM CDT•August 24, 2023 ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm. It’s able to write essays, code and more given short text prompts, hyper-charging productivity. But it also h... Enterprise How Google Cloud learned to embrace its partner ecosystem Frederic Lardinois 11:00 AM CDT•August 24, 2023 Google Cloud’s annual Next event is happening in San Francisco next week (and we’ll be on the ground to cover all of the announcements), but ahead of the event, Google Cloud today put a... Crypto Vessel Capital emerges from stealth with $55M fund focused on web3 infrastructure and apps Jacquelyn Melinek 11:00 AM CDT•August 24, 2023 Vessel Capital, a web3 venture fund, has emerged from stealth with $55 million in assets under management to invest in infrastructure and applications, the firm exclusively told TechCrunch. Founded... AI Modular secures $100M to build tools to optimize and create AI models Kyle Wiggers 10:45 AM CDT•August 24, 2023 Modular, a startup creating a platform for developing and optimizing AI systems, has raised $100 million in a funding round led by General Catalyst with participation from GV (Google Ventures), SV ... About TechCrunch Staff Contact Us Advertise Crunchboard Jobs Site Map Legal Terms of Service Privacy Policy TechCrunch+ Terms Privacy Dashboard Code of Conduct About Our Ads Trending Tech Topics Tech Layoffs ChatGPT Threads FAQ Facebook (opens in a new window) Twitter (opens in a new window) YouTube (opens in a new window) Instagram (opens in a new window) LinkedIn (opens in a new window) Mastodon (opens in a new window) © 2023 Yahoo.All rights reserved.Powered by WordPress VIP (opens in a new window) .",
    "commentLink": "https://news.ycombinator.com/item?id=37248895",
    "commentBody": "Hugging Face raises $235M from investors including Salesforce and NvidiaHacker NewspastloginHugging Face raises $235M from investors including Salesforce and Nvidia (techcrunch.com) 348 points by immortal3 20 hours ago| hidepastfavorite186 comments QuadrupleA 19 hours agoHugging Face is early in the Silicon Valley enshittification cycle - currently burning VC money being incredibly good to it&#x27;s users. Next would be shifting that value to its business customers. Then clawing back and squeezing as much value as possible from those. Then collapse.Although, is it technically a platform &#x2F; marketplace?Anyway for now, enjoy the free beer from the VCs. reply version_five 18 hours agoparentThey represent a real risk to the AI ecosystem IMO (or opportunity if you&#x27;re an investor). They have really cornered the market on model hosting as well as frameworks for running them, it&#x27;s going to get ugly when they start turning the screws.I think it&#x27;s important for people to diversify away from them and not build anything that uniquely depends on them. It&#x27;s not good to have chokepoints like this. reply 0xcde4c3db 17 hours agorootparentDiversify to what, though? The economics of hosting models and datasets seem to just not be great in general. For the same reasons that we can expect HF to eventually crack down on the \"freeloaders\", I think pretty much any other entity also will unless it&#x27;s explicitly set up as a public benefit. I could see this sort of thing maybe being funded by universities or their affiliated foundations, but most companies with the resources to provide this kind of hosting also have a pretty strong incentive to extract revenue from it. reply michaelt 17 hours agorootparentPip, maven, npm, docker hub, apt-get, github and suchlike seem to manage to provide hefty binary downloads with no need to monetise anonymous downloads.I don&#x27;t quite understand how they do so, but it seems to be possible. Everyone who downloads a 5GB stable diffusion model probably downloaded 5GB of pytorch+cuda+cudnn first. reply 0xcde4c3db 15 hours agorootparentFor its part, PyPI is apparently funded by the Python Software Foundation and run by volunteer admins, with the bulk of its data served gratis by Fastly. This is based on a blog post about its infrastructure from 2021 [1], which also says that the list price for the throughput they&#x27;re doing is $1.8 million per month.[1] https:&#x2F;&#x2F;dustingram.com&#x2F;articles&#x2F;2021&#x2F;04&#x2F;14&#x2F;powering-the-pyth... reply Lord_Zero 17 hours agorootparentprevBack in the day, universities would host all that shit via their mirrors for free for everyone. Not sure where it all is today with the cloud being so prevalent. reply zo1 16 hours agorootparentYou don&#x27;t even hear the term mirror anymore. reply basilgohar 15 hours agorootparentLinux distros still have large networks of mirrors for downloading their releases and also packaged binary updates. Maybe we don&#x27;t \"hear\" the term but they are still there. reply outside1234 12 hours agorootparentprevWe call them CDNs now :) reply brucethemoose2 16 hours agorootparentprev> 5GB of pytorch+cuda+cudnnThis itself is kinda insane. In fact, it was literally untenable for PyPi, which is why (historically) installing all that was unecessarily painful. reply bpiche 11 hours agorootparentprevSpacy hosts them too, of course.python -m spacy download en-core-web-lgetc reply htrp 18 hours agorootparentprevDo they really? As far as I can tell, diffusers&#x2F;transformer are open sourced wrappers around torch implementations, there are a bunch of companies that are offering inference (just like they are), and there is some value in offering S3 storage to allow for model search.If they reach a point where they actively become community-hostile, someone will just fork their codebase and release a web app called \"FaceHugger\" reply jeroenhd 18 hours agorootparentTheir Git LFS based hosting is used by a lot of AI tools. Huggingface level data storage and transfer would also be VERY costly to accomplish for a small party. Some of these models are several gigabytes in size and downloaded hundreds or thousands of time per day.What they do isn&#x27;t too hard to replicate, but the price for which they do it is impossible to compete with. reply lsmeducation 17 hours agorootparentLol, I’m sorry what? Has anyone heard of BitTorrent or piracy in general? You’re telling me AI models&#x2F;data are too big?Someone utilize p2p for the love of god. Pretty sure there’s gigabytes of porn moving (freely) through the internet millions of times per day. reply jeroenhd 15 hours agorootparentSome models are distributed P2P. They download slower, in my experience, and require special software rather than the usual git commands.P2P model distribution isn&#x27;t impossible, but it&#x27;s a lot less interesting to many people, or they would&#x27;ve already spread their models through torrents in the first place. reply lostmsu 5 hours agorootparentThere is just no convenient torrent-based model hub yet.But if HF&#x27;s server code is open source it should be trivial to make one. reply esafak 15 hours agorootparentprevGitTorrent came and went. reply brucethemoose2 16 hours agorootparentprevCivitAI has somehow managed this over in Stable Diffusion land.In fact, I think the whole community is HF averse. The two most popular frameworks are based around the Stability implemenetaion and file format, not HF diffusers. reply osanseviero 14 hours agorootparentFYI the file format, safetensors, was proposed, developed and maintained by HF, and involved people from groups such as Eleuther and Stability for external security audits.https:&#x2F;&#x2F;github.com&#x2F;huggingface&#x2F;safetensors https:&#x2F;&#x2F;huggingface.co&#x2F;blog&#x2F;safetensors-security-audit reply version_five 16 hours agorootparentprevAny sense of why they are HF averse? reply IKantRead 13 hours agorootparentI think they&#x27;re HF averse because HF is fairly anti-NSFW content and it&#x27;s pretty clear that civit.ai has a fairly large NFSW focused audience.On top of that HF is just hard to use for your average user. Civit.ai is just \"click to download\" while HF is \"look here&#x27;s a broken model card... you can figure it out from here\".Despite the cute logo, I think most people find that HF comes across as fairly anti-user. Despite having years doing ML related work, I still find HF a bit byzantine to navigate. reply dragonwriter 15 hours agorootparentprev> Any sense of why they are HF averse?Technology-wise, path dependency from stuff that was built out before HF diffusers were available, and on which more continues to be built in the ecosystem.If you are doing a greenfield project that is mostly standalone, its not an issue, but for existing popular projects and the communities of satellite projects around them, the switching cost is high.In terms of content hosting, well, a fair amount is hosted on HF, but there is a difference of content focus between CivitAI and HF, and a lot of what CivitAI hosts HF probably wouldn’t want to. Also, CivitAI has a UI focused on the narrow space of imagegen, whereas HF is more general. reply brucethemoose2 16 hours agorootparentprevI&#x27;m not even sure its deliberate.Automatic1111 and ComfyUI implemented the SAI backend&#x2F;format in the early days because thats all there was, and now they are stuck with it. The intertia is tremendous. reply AuryGlenz 4 hours agorootparentThe popular fork of Automatic1111 SD.Next recently implemented diffusers for its SDXL support.It seems like an odd move to me as what makes Auto1111 so appealing are the extensions and I’m assuming that breaks an awful lot of them, but what do I know? reply dharmab 10 hours agorootparentprevIs that so different than some free to play video games? Those are sometimes hundreds of GB and downloaded by millions. reply coffeebeqn 8 hours agorootparentThey come with a finely tuned monetization system built in and are very profitable reply htrp 17 hours agorootparentprevIf Amazon&#x2F;Google&#x2F;Microsoft wanted to own that space, they could do it in a heartbeat.Rumor has it Github is actively working on something similar to HF Hub already reply forgingahead 17 hours agorootparentI&#x27;ve seen some repos on Github host the models on \"Releases\". Not sure how viable that is long term, but definitely easier to download and access than some random Google Drive link which is typical for a lot of other repos. reply mistrial9 17 hours agorootparentprevagile ; community-minded ; efficientpick one if you are lucky. Those Fortune-12 giants can&#x27;t do anything \"in a heartbeat\" .. listen to what that means.. nonsense reply version_five 17 hours agorootparentprevThey have this \"accelerate\" framework they push too: https:&#x2F;&#x2F;huggingface.co&#x2F;docs&#x2F;accelerate&#x2F;indexI don&#x27;t know much about it, and I think (but couldn&#x27;t quickly confirm) it&#x27;s open source, so your point about a fork still stands, although I don&#x27;t think that solves everything. If it did, people wouldn&#x27;t care that e.g. Hashicorp changed their license away from open source. reply bakuninsbart 17 hours agorootparentprevYou can replace this with \"container\" and \"docker\", and it turned out exactly or similar to how you predict. However, there is nothing with a big moat that Huggingface is offering. If they overeshittify, competitors will rise up. reply pradn 17 hours agorootparentLate in the \"enshittification cycle\", competitors do rise, but they&#x27;re usually under-resourced. So you get a overly-monetized primary product and a bunch of \"never quite there\" competitors. That&#x27;s overall worse than at the primary product&#x27;s \"free beer\" phase. reply coffeebeqn 7 hours agorootparentThe most likely successful entrants I can imagine are big tech. They’ll either build or buy the best competitor. And they all already have data centers ready to go reply foooorsyth 16 hours agorootparentprev>there is nothing with a big moat that Huggingface is offeringThere are network effects in play here. They have a big moat purely because of their large user base. reply coffeebeqn 7 hours agorootparentSimilar to GitHub which I imagine they want to emulate. Sure there are other public code repositories but most people find GitHub good enough to not bother looking at options reply vl 11 hours agorootparentprevWhen I use HF to get some base model I always make sure I have local copy and then load from the local copy. I push said copy into (remote, obviously) git for the eventuality of HF going down&#x2F;model being removed. reply amelius 13 hours agorootparentprevIt&#x27;s always the same with these f&#x27;ing marketplaces&#x2F;platforms. There should be new laws for crowdsourced value. reply amelius 13 hours agorootparentprevWhen it comes to that we&#x27;ll use AI to migrate everything over :) reply brucethemoose2 16 hours agorootparentprevBasically all the HF code is Apache and open source.Model hosting is a nice convenience, but if HF removed every single repo from GitHub tomorrow and paywalled the model repo, it wouldn&#x27;t be a big deal. Maintainers would clone their models and repos to somewhere else. reply NelsonMinar 19 hours agoparentprevYeah, enjoy the free beer and have a plan to take a case with you when the bar is closing. reply cloogshicer 19 hours agorootparentUnless the bar gets so big that all the other bars go out of business like with YouTube and many other monopolies&#x2F;oligopolies. reply echelon 18 hours agorootparentGitHub is pretty excellent. reply nkingsy 16 hours agorootparentIt’s a loss leader so msft can point to something when you complain about the abusive hellscape that is modern windows. reply esafak 15 hours agorootparentWorks for me; I don&#x27;t really use Windows. Also GitHub is paid so it does not have to be a loss leader. reply coffeebeqn 7 hours agorootparentprevIs it really? It’s the “SaaS” all startups I’ve seen seem happy to pay for. replyjudge2020 18 hours agoparentprevIt&#x27;ll go the same route as Docker. Anyone relying on it for critical software will pay, everyone else will use alternative but compatible sources once it&#x27;s no longer free. reply no_wizard 17 hours agorootparentI think with Docker&#x27;s recent pivots, its clear that they thought they were going to be the container company, but Swarm never caught on, and Dockerhub never really evolved beyond hosting images (though, its verified images feature is nice).What Docker ended up accelerating at is reproducible development environments that tear down and spin up easily. I think this is the largest faction of docker users.It never translated into a high volume of Docker Swarm and related sell through features materializing though.That&#x27;s what a swath of all their new paid features are focused on enterprise things like SSO, auditing etc.For Hugging Face, they will need to have a compelling set of features that make it either hard to migrate off of or vastly preferable to other options the majority of the time.Right now, their most compelling feature is being (mostly) free reply taminka 18 hours agoparentprevi&#x27;m curious what HF does, because iiuc they&#x27;re mostly just hosting model files? i know that they have some compute offers, and also created&#x2F;maintain a few libraries, but it&#x27;s not particularly widely used, i&#x27;m really not sure how they&#x27;re supposed to earn money... reply hereonout2 16 hours agorootparentI&#x27;ve been asking myself that for a while. Would they be so popular if they didn&#x27;t host & serve petabytes of model files for free? How will they monetize that aspect to match this valuation?Whilst the scale of their model hosting is impressive, the functionality seems pretty basic. The models are just BLOBs in git LFS repos, you&#x27;re usually relying on knowing which users to follow, then learning the way they name their models and how that naming convention applies to the particular framework and hardware you&#x27;re using.As an example the user \"TheBloke\" is prolific at publishing LLM models for various hardware &#x2F; framework combos, but look how little the HF interface actually helps navigate or find what you&#x27;re after: https:&#x2F;&#x2F;huggingface.co&#x2F;TheBlokeAlso, is anybody using HF Hub in \"production\"? We&#x27;ve deployed a few LLMs now and once we&#x27;ve decided on a model the first thing we do is get it off HF and into our own storage ready for deployment. There seems no reason to tightly integrate HF Hub with production systems given it&#x27;s a just a bunch of files you can copy and keep. reply Melting_Harps 10 hours agorootparent> I&#x27;ve been asking myself that for a while. Would they be so popular if they didn&#x27;t host & serve petabytes of model files for free? How will they monetize that aspect to match this valuation?From what I gather it&#x27;s mainly hosting with some maintaining of a few libraries, but then I recently starting to see they are offering lots of classes via DeepLearning platform; these lat couple of months as an AI student I&#x27;ve been asked to enroll into classes (temporarily for free) to assess where they are, here is the most recent example [0].To what end, I&#x27;m not entirely sure, but I guess it&#x27;s to get an overall pulse on what can be monetized and take it from there? I really think that this a low number compraed to where we were in the last few years, but ti also shows how little investment actually exists in the AI and ML space: consider that Git got bought by M$ for 7.5B and then tried cash in on it by releasing Co-Pilot and then got into legal issues as a result and then tried it&#x27;s hand with Open AI and $10B.This is starting to seem like a reversion to the mean, and AI&#x27;s promise was always to lower the cost to everything it can, but I think one of the harder pills to swallow is that the traditional VC model is not really being supported after all the hype and losses.Personally speaking, I&#x27;m thinking of moving on to Cyber Security after my finals this semester; I come from Bitcoin and the hype cycles there are something I was looking to get away from after nearly 13 years in that side of fintech.0: https:&#x2F;&#x2F;www.deeplearning.ai&#x2F;short-courses&#x2F; reply ladberg 18 hours agorootparentprevI think their \"spaces\" (i.e. running tons of models for free with a nice UI) are widely used. reply dbish 16 hours agorootparentThis isn’t sustainable though. Compute is expensive, maybe they’ll end up with paid plans for anyone trying to use a space reply jsemrau 16 hours agorootparentThat should be inversely related to their usage though. I am using HF frequently, but I am not sure if I would pay for it. reply dbish 15 hours agorootparentThat is the issue for sure reply ShamelessC 14 hours agorootparentprevThose are pretty lackluster in my experience. Do they even support GPUs? And in any case, it seems like they go down for anything sufficiently popular. reply myth_drannon 15 hours agorootparentprevIt is also used for discovery and search of models. Following your train of thought, Github is just hosting a bunch of src files. reply weeblewobble 2 hours agoparentprevHonestly when you put it like that it sounds like a pretty sweet deal. We get a few years of irrationally cheap services for free? I’ll take that.VC-subsidized Ubers were awesome in my mid 20s. It’s too expensive now for everyday use but I still banked all that consumer surplus. reply Palmik 16 hours agoparentprevAccording to Clement (the HF CEO) they are close to covering their costs, and have 10years runway: https:&#x2F;&#x2F;twitter.com&#x2F;ClementDelangue&#x2F;status&#x2F;16947653579682861... reply version_five 15 hours agorootparentCan someone who knows the VC industry explain why having 10 years runway would be considered good? Aren&#x27;t these companies supposed to be deploying capital as quickly as possible, not banking it. If a ceo said they needed your money 5+ years from now, wouldn&#x27;t you wait until then to commit? reply jasonwatkinspdx 14 hours agorootparentFOMO is a thing among VCs. You may not be let in the round 5 years from now, or the price may be less favorable, etc. reply ZephyrBlu 12 hours agorootparentprevCurrently 10 years of runway. I wouldn&#x27;t expect them to maintain that for a significant period of time. reply stevofolife 13 hours agorootparentprevSomeone who knows the VC industry should chime in on this - but AFAIK, companies don&#x27;t get all their money from investor at once. reply fulladder 22 minutes agorootparentNo, you typically get all the money wired into your bank account immediately after the deal closes.It&#x27;s possible to structure a deal where the company has to reach a series of milestones to unlock each additional tranche of funding, but this is less common. reply echelon 15 hours agorootparentprev> If a ceo said they needed your money 5+ years from now, wouldn&#x27;t you wait until then to commit?Why would a CEO give up equity if they don&#x27;t need the capital? Wouldn&#x27;t they prefer not to sell big chunks of flesh?If he&#x27;s not deploying it now, maybe the CEO is predicting rough times ahead and wants to de-risk for future cash flow or fundraising turbulence? Isn&#x27;t that, too, a kind of negative signal? Or is this all prudent? reply hustwindmaple1 7 hours agorootparentThere are times when capital is cheap and abundant and there are times capital is scarce and hard to come by reply mlguy123 14 hours agorootparentprevNotice the choice of words: \"Most of our OSS and free usage cost\". Who knows what&#x27;s omitted from that. Also assuming they have zero money left in the bank from the prev round (they def didn&#x27;t) they&#x27;re losing&#x2F;burning $2mm a month reply SkyMarshal 12 hours agoparentprevIt seems the enshittification cycle may have resulted at least in part from the Blitzscaling methodology [1]. Are there any studies on the effectiveness of Blitzscaling in general? I wonder if it&#x27;s a net success or not.[1]:https:&#x2F;&#x2F;www.blitzscaling.com&#x2F; reply iambateman 13 hours agoparentprevMaybe? Probably? Probably.As a counter point, GitHub has remained great for longer than expected, and has arguably improved since being bought by Microsoft.One can hope that their example will help set the expectation for other platforms like HF reply mistrial9 10 hours agorootparentwhat you do not know can hurt you ... behind closed doors they have added the equivalent of Airport Security on users, repos and access. Expect a profit center of maintaining your valid ID so you can start work each day. reply 2OEH8eoCRo0 17 hours agoparentprev> enjoy the free beer from the VCs.Careful not to become dependent on the free beer. reply shmatt 16 hours agoparentprevenshittification is such nonsense. the original article gives Facebook, TikTok, Amazon and other super successful super profitable companies as an example\"Then collapse\" - nope, then generate tens of billions of profit per quarter. Im sure the people of Hugging Face would love that reply claytonjy 13 hours agorootparent\"enshittification\" doesn&#x27;t refer to a change in _investor_ value, but to _user_ value. Facebook does make a ton of money, but at the expense of the user experience. They got huge by providing a great UX and making no money; it was the need to make money that triggered enshittification. reply throw10920 8 hours agorootparent> \"enshittification\" doesn&#x27;t refer to a change in _investor_ value\"enshittification\" doesn&#x27;t refer to anything at all. It&#x27;s a political term meant to be used by anti-corporate causes - it doesn&#x27;t have a real definition because it&#x27;s a made-up word with no value other than activism. reply latentcall 6 hours agorootparentIs anti-corporate a bad thing? Is activism also bad? Aren’t all words made up? The word does indeed refer to something. Just because you disagree with it doesn’t mean it doesn’t exist. replyjedberg 18 hours agoprevI love when Nvidia invests in AI companies. They know that money is coming right back to them. It&#x27;s basically just a loan to the company in exchange for potential upside of them doing something with Nvidia&#x27;s chips. :) reply extraduder_ire 10 hours agoparent\"Can we have the investment partly in stock?\" \"I guess, but our shareholders probably won&#x27;t be too happy.\" \"No no no, not shares. I mean stock like from a warehouse, we need them cores man!\" reply mmaunder 17 hours agoparentprevInteresting situation with public markets funding Nvidia which is investing in its own customers, driving further strong financial results driving further public investment. A high risk high reward play. Nvidia is eating AI. reply jtsiskin 8 hours agorootparentHumorously(?), you’re also exactly describing a pyramid scheme reply stevofolife 13 hours agoparentprevExactly and it would be extremely stupid for them not to take advantage of their current market position. It&#x27;s a now or never situation IMO. reply MasterScrat 12 hours agoparentprev> They know that money is coming right back to them.Oh I assumed they were directly delivering them truckful of A100s? do they actually still bother with cash? ;-) reply riku_iki 17 hours agoparentprev> They know that money is coming right back to them.it is totally can be condition of investment round: have specific vendor as compute provider. reply jedberg 16 hours agorootparentIt could be, but I&#x27;m guessing they don&#x27;t even have to. reply 1letterunixname 14 hours agoparentprevNvidia is likely to have a $36-40 B revenue year this year and next because of massive customer investments. Meta is spending $8 B on their gear and about the same next year. OpenAI+Microsoft are likely following suit with several billion in server buildout. I&#x27;m curious if Google or Apple will be adding large swaths of AI boxes to their fleet too. reply hackernewds 13 hours agorootparentRidiculous. This implies infinite supply. Neither the supply chain, nor nature is designed to churn out GPUs like this. That $ will take time to be captured. reply alberth 19 hours agoprevGenuine question … What business are you in when selling AI&#x2F;ML?I’m far from being knowledgeable in this space, but it seems like AI&#x2F;ML “is a feature, not a product”.And if that’s the case, what business are you in when a company sells AI&#x2F;ML?Are you in the business of licensing the model you created? Charging for the output? Hosting infrastructure? What exactly are you in the business to sell?To use an analogy, if you’re selling AI&#x2F;ML, are you in the IaaS industry, PaaS industry, SaaS industry (or something else?) reply emmender1 18 hours agoparentyou are:a) a hardware vendor nvidia&#x2F;amd whose products are needed by anyone in the gameb) you have a captive customer base already ( microsoft, salesforce, servicenow, adobe) to whom you can sell ai&#x2F;ml value addsc) you make money via ads (google facebook) and ai&#x2F;ml helps with better targetingeveryone else is pissing away VC money. reply htrp 18 hours agorootparent> a) a hardware vendor nvidia whose products are needed by anyone in the gameFTFY.... I don&#x27;t think AMD will be competitive in AI until at least 2025, though given their broken roadmap promises, not sure if anyone will be willing to invest in them reply unmole 18 hours agorootparentI mean you still need CPUs to run your workloads. And AMD makes decent ones. I work for a company that sells data centre network switches. There&#x27;s nothing AI specific in our boxes but we will sell a lot more if them if people are building more data centres to cater to AI driven demand.Something, something gold rush, shovels. reply htrp 17 hours agorootparentGreat point! But while demand for network switches explodes, do you really get a competitive advantage from one company&#x27;s switches vs another? (serious question as I&#x27;ve never had to build a DGX superpod or anything like it from scratch). reply unmole 17 hours agorootparent> do you really get a competitive advantage from one company&#x27;s switches vs another?I am obviously biased but IMHO, yes. High end switches are not commodity gear. And a lot of the differentiating secret sauce is in software. So, even if two switches from two different vendors have the same silicon, they might have dramatically different characteristics. That is without going into other aspects like integration with the rest of the stack, quality of support and even lead times. reply biztos 15 hours agorootparentprevd) you give people who can&#x27;t use b) a version of b) they can use. reply alberth 17 hours agorootparentprevA) so you’re competing against aws, azure, etc. That sounds brutally tough.B) re: value adds, like what exactly?C) this seems like such core functionality that a company wouldn’t outsource this to a 3rd party vendor. If that’s the case, there isn’t an opportunity to sell anything if you’re that AL&#x2F;ML vendor then. reply emmender1 16 hours agorootparentA) aws&#x2F;azure need nvidia&#x2F;amd chips in their servers... it is too difficult to homegrow these chips (altho aws is trying) B) microsoft (github autopilot 20$ per month per user), document&#x2F;image autogeneration from a prompt (likely in word doc 5$ a month per user for this) C) right yea, thats why fb&#x2F;goog have big ai farms reply PeterisP 13 hours agoparentprevI believe that some of the most valuable short-term use cases for AI&#x2F;ML seem to be \"feature, not a product\" - this means that the incumbents making various products can unlock lots of competitive value by adding those features in a way that is difficult for newcomers, because they not only need to develop the AI&#x2F;ML feature but also have to build a competitive solution for the core system which generates or contains the data on which the feature relies.Like, it&#x27;s plausible that many organizations would be willing to pay lots of money for a \"ChatGPT which knows my internal documents\" AI&#x2F;ML feature for the Sharepoint&#x2F;Confluence&#x2F;etc they are currently using, but a would be very wary of migrating those internal documents to some upcoming startups&#x27; new document management system. reply stevofolife 13 hours agoparentprevTo be fair, I don&#x27;t think there are clear dichotomies in this space. It really has the potential to be a feature or a product in either of the IaaS&#x2F;PaaS&#x2F;SaaS industry.Just do a quick HN search on companies selling AI&#x2F;ML, you will see what I mean. reply tilne 18 hours agoparentprevAren’t you in all of those?The further you keep the user away from training and hosting, the less you’re in those businesses. But I would think it’s only economical to do that if you have some type of advantage in implementing the things you’re abstracting away. reply traveler1 18 hours agorootparentI think the opposite may be true. If you control the training and hosting, surely that means you have to be more involved in many industries to make the product useful? Whereas with offloading training&#x2F;tuning to the user, you kinda just become PaaS, in that you provide a platform which enables others. reply nemo44x 18 hours agoparentprevThey are selling picks and shovels. There will be a few huge winners in the AI space, a good amount of modest winners, and a lot of losers. They don&#x27;t care who wins or loses but are happy to sell the supplies needed for anyone that wants to take a shot.If they can make it easier and worthwhile to use their product and create business value, then they will sell a lot of picks and shovels. reply version_five 18 hours agorootparentI agree and so far I think it&#x27;s picks and shovels all the way down. Most of the \"AI\" companies I see sell tooling, often to \"help your AI team work faster|better|spend less time doing x|whatever. It all presupposes there are end uses, which are few and far between, certainly almost none are being sold. AI is still in the hype mode of companies having internal budget to \"invest in AI\" and so that&#x27;s who the AI companies are targeting, as opposed to actually making products that do something. See also blockchain wallet companies.PS - I&#x27;m optimistic about AI, but it&#x27;s important to be realistic about the current state of the industry reply calebkaiser 17 hours agorootparentIt&#x27;s important to note that despite the recent excitement about LLMs, which is still an emerging technology, \"AI\" is not a new market by any means, nor are major companies only now investing in it. For the better part of a decade, ML has been widely adopted across industries, and the average person uses an \"AI\" system many times in a given day.For example, if you open the home screen on the average smartphone right now, you&#x27;ll see apps like:- Delivery apps like Uber, Lyft, etc., whose recommendations, ETA predictions, driver matching, and more are built on ML.- Media apps like YouTube, Netflix, etc., all of whom rely on models for recommendations.- Email apps like Gmail, whose filtering (both spam and categorization) and text completion are based on ML.- Photo apps like Instagram, Snapchat, and even your phone&#x27;s basic Camera app, all of which use computer vision.If you Google anything, you&#x27;re perusing the output of a model. If you&#x27;re being recommended something on basically any platform, you&#x27;re interacting with ML. If you ever use speech-to-text, you&#x27;re using a neural network. Your bank uses ML for fraud detection, your posts on social media are moderated by ML-based content moderation, and if you have a car with any recent-ish sort of lane departure assistance, you&#x27;re driving with help from a neural network.Most of these companies have large, mature ML teams, whose outputs represent massive amounts of revenue. Hence, they represent a legitimate market for selling picks and shovels. reply version_five 16 hours agorootparentThat&#x27;s the framing we&#x27;ve been using for years, look at some big tech ML or data science that we reframed as AI, your manufacturer&#x2F;transportation&#x2F;retail&#x2F;whatever company needs it too, but there are no products for end uses in your industry, just lots of tooling and consulting services you can buy for bespoke projects. reply nemo44x 17 hours agorootparentprevIndeed, lots of tooling out there. Which makes sense as it&#x27;s very early days. I imagine that LLM AI will be integrated into so many things down the road though that it will be an expected feature of most any product. reply alberth 16 hours agorootparentprevPicks and shovels are tools.But what “tools” are being sold for AI&#x2F;ML?- A model isn’t a tool, that’s a purpose built offering that can be used for 1 use case. Tools are by definition, intended to help with broad&#x2F;general use cases.- Hosting isn’t a tool, it’s a commodity and lots of cloud players already occupy that space.Please don’t take my comments as trolling, I just geninuely don’t understand what exactly is being sold that is new or unique that doesn’t already exist. reply nemo44x 11 hours agorootparentThey have a suite of software you can use to power your own software. These are tools and no different than what database vendors, etc in terms of being software you use to build software. In addition there’s support and services.I imagine they have big plans on how to expand and grow the business. reply 1letterunixname 14 hours agorootparentprevYep. Meta is spending $22 B on CapEx over 2 years without any plan of how to use it, with about half of it tied to buying shit tons of H100 to go in custom servers. reply kiratp 19 hours agoprevI love Huggingface. I worry they will be the next Docker.What is the moat? \"We will run your inference\" can&#x27;t be the answer. reply politelemon 18 hours agoparentA Hugging Swarm which then loses tech mindshare to an immensely complex frankensteined offering, \"cogit8s\". reply verdverm 18 hours agorootparentL7N already exists reply ramesh31 19 hours agoparentprev>What is the moat? \"We will run your inference\" can&#x27;t be the answer.Network effect. It&#x27;s more like a GitHub for ML.Also trust. When your business is hosting binaries, that&#x27;s no small feat. reply CardenB 17 hours agorootparentWhat do people think separated GitHub from docker?Docker also had DockerHub, but it wasn’t as necessary as GitHub and didn’t catch on as well.I think HF is more like docker than GitHub. GitHub had the wide scope to be huge. Docker was too niche (in comparison) and didn’t catch on so much to be necessary for every single project like Git did.Similarly, HF is also niche in the sense that docker is. There’s no need to host your model on HF, it’s just a convenience for some projects. It’s effectively a package manager for ML models.It seems that if there’s a way to make models more easily runnable, HF would not be necessary at all. They have a community there, but it’s not something that can be monetized well. reply hereonout2 15 hours agorootparentDockerhub is great for sharing images with the world at large, much like HF is for models. But once you&#x27;re at the point where you want to host your images &#x2F; models for business use do you really still want them?All cloud providers seem to have an image hosting feature, why go through hassle of managing and paying for a docker hub account when you&#x27;re already on AWS and can integrate better with ECR? The same problem exists for ML model hosting IMO.Github is totally different, it&#x27;s a more complex and human proposition. For many github has replaced an entire raft of tools, not just code hosting. reply CardenB 15 hours agorootparentAgree, HF is more similar to docker than it is to GitHub reply ramesh31 6 hours agorootparentprevDocker grew too fast. They chased VC dollars for what really was just a cool open source project. I spent some time at their first office in SF ten years ago for meetups. They had a really cool unique culture. I think that just doesn&#x27;t scale some times. reply ulrikhansen54 19 hours agorootparentprevThey also have an insane amount of traffic - very envious, they&#x27;ll be able to capitalise on other things as soon as they start to build commercial products people are willing to pay big money for. reply mlguy123 17 hours agoprevthrowaway since since i used to be affiliated with them.HF did an amazing job in community building, transformers library and being the central store for all oss models. That said they are ages away from PMF and just have a bunch of different products non of them commercially successful (services, autotrain, quantization, HF hub for EE, inference end points etc). The majority of their revenue comes from partnerships with SageMaker&#x2F;Azure where they pay them for sending users their way which wouldn&#x27;t continue to grow.While it&#x27;s always a possibility for a FANG company to buy them IMO they are completely screwed. At a $4.5B valuation they will have to reach at minimum $250m in ARR to IPO and at the moment they&#x27;re probably stuck at around $25m ARR. reply covi 17 hours agoparenthttps:&#x2F;&#x2F;www.forbes.com&#x2F;sites&#x2F;alexkonrad&#x2F;2023&#x2F;07&#x2F;13&#x2F;ai-startu...> Its revenue run rate has spiked this year and now sits at around $30 million to $50 million, three sources said — with one noting that it had more that tripled compared to the start of the year. reply throwaway644788 17 hours agoparentprevThrowaway for a similar reason.I can&#x27;t for the life of me understand the strategy that Clem and team have, other than raise as much money as possible just because they can. My experience with their sales teams was just absolutely awful, and it gave me no hope that they can grow ARR as soon as they need to. We practically begged them to sell us something, but it wasn&#x27;t until we went elsewhere definitively that they seemed interested. reply version_five 16 hours agorootparentI wonder if they, intentionally or inadvertently, have optimized for investment scale at the expense of everything else? There is a market demand for \"pure\" AI startups that can take 9 figure investments. It&#x27;s (comparatively) \"easy\" to optimize to be that company, but extremely hard to find a way to live up to the hype and provide a return in the investments, and this strategy often ruins the company. reply m_ke 11 hours agoparentprevYeah that was my concern as well. I used to work for an AI company that ended up in the same predicament, they raised way too much money at a high valuation and in the process cut down the potential acquirer pool to 3-4 companies. They are now a zombie with worthless common shares, no shot at an acquisition and nowhere near enough revenue to go public. reply pyuser583 6 hours agorootparent“I didn’t realize you could raise less money.” reply asadm 17 hours agoparentprevThey will be acquired. Either by Google or MS. reply biztos 15 hours agorootparentWhy Google (who has their own AI stuff) or MS (who has a hand in OpenAI) and not, say, Samsung? reply claytonjy 14 hours agorootparentBranding and trust. ML folks love HF, and rightly so. They have great software libraries, host everyone&#x27;s models, generally great UX all around. They do a great job of making it easy to do cutting edge stuff, while still making it possible to do bleeding edge stuff. They appeal to basically all ML folks in a way few other companies do.Google could grow GCP by more deeply integrating HF into GCP, I think, while retaining as much of the HF brand and interface as possible.Big friction point might be ethics, since HF is still seen as the \"good guys\" and where some folks who left Google over ethical concerns landed. reply m_ke 12 hours agorootparentprevMS makes sense since they could integrate it with github and azure into an ML platform that they could sell to their enterprise consumer base. It would also be a great addition to teams, bing and word suite. reply alberth 17 hours agorootparentprevMS has already invested $10B in OpenAI, so they aren’t going to be a buyer.Google has poured hundreds of million into Anthropic due to Eric Schmidt, so they aren’t going to be a buyer. reply asadm 16 hours agorootparentBoth Anthropic and OpenAI are not a replacement for huggingface. Which has complete monopoly on model hosting right now. reply nmfisher 5 hours agorootparentMonopoly is a stretch. Half of the models I try come direct from GitHub (and almost 100% of all model code comes from GH too).Hosting binaries isn&#x27;t really a stable business model. reply brucethemoose2 16 hours agorootparentprevMeta? reply PeterisP 13 hours agoparentprevI wouldn&#x27;t be surprised if they would eventually get acquihired by nVidia. Simply providing all that code and infrastructure to the community is a big boon to raise the value and sales of nVidia hardware; the classic strategy principle - commoditize your complements. reply fidotron 19 hours agoprevML models are the new apps. There is a huge opening for an App Store type situation which enables people to buy models and integrate them into their products, handling the appropriate licensing.Bonus points for certifying the models actually do what they say. That by itself will probably become a mini industry.Hugging Face are the clear leaders in terms of having mindshare in the community to be able to build it. reply dbish 16 hours agoparentModels != apps, they’re closer to the backend for apps or a core library, so your customers aren’t “everyone with a phone&#x2F;computer” like an app, it’s the much smaller, but potentially high impact, “everyone who creates apps”.We’re not in a world where non tech people are searching for models in the model store from their phone. reply fidotron 16 hours agorootparentWe are already in a world where “artists” are exchanging models online based on their ability to generate certain outputs. reply dbish 15 hours agorootparentDo you put artists in quotes for anyone who uses a computer for their art at all? Are photographers artists in your opinion? reply fidotron 15 hours agorootparentBecause of what many of the most popular models are actually for. replyjvalencia 18 hours agoprevFrom Nvidias point of view, this might be an investment in their own business via network effects rather than a straight up investment in Hugging Face. I hope so, because when the VC money goes, the billing will go through the roof. reply fidotron 17 hours agoparentExactly. At least $100M of that will go into buying nVidia GPUs.That kind of thing is par for the course when invested in by hardware companies, but it can work out very well for everyone. reply sceadu 18 hours agoparentprevComplementary service to go with their main product reply chakintosh 18 hours agoprevHF is the literal implementation of the old idiom \"During the gold rush, sell shovels.\" reply stagger87 18 hours agoparentI&#x27;ve said this on HN before, but Nvidia is the one selling shovels IMO. reply mousetree 18 hours agorootparentEveryone has said this reply stagger87 17 hours agorootparentSure, I was only arguing against the idea that HF is selling shovels. reply bleuchase 13 hours agorootparentprevYeah not exactly a novel hypothesis at this point. People have been saying that since the GPU mining heyday. reply frozencell 17 hours agorootparentprevIMO HF sell tents and Nvidia sell shovels reply kordlessagain 15 hours agorootparentHF feels more like mules than tents to me. reply alberth 19 hours agoprevConfusing Pricing.https:&#x2F;&#x2F;huggingface.co&#x2F;pricingI’m probably missing the obvious, but one part on the pricing page it says Spaces Hardware starts at $0 … and another part says it starts at $0.05. reply espadrine 19 hours agoparentThey are covering a range of use-cases. I agree the naming is inconsistent. It goes like this:• Repository storage is free, with a paid enterprise offering, à la GitHub.• Serving a demo app has hourly costs (“Spaces Hardware”)• Serving a production model for an app hosted elsewhere is also hourly (“Inference endpoints”)• Training models is free for now (“AutoTrain”; honestly I haven’t tried this one.) reply throwaway644788 17 hours agoparentprevThe whole GTM is confusing. They&#x27;re experts at ML and community, and awful at business. I know HN looks down on sales persons, but HF needs some good ones, ASAP. reply ShamelessC 14 hours agorootparent> experts at MLCitation needed. reply warthog 20 hours agoprevIt is crazy to me that it is still 100x the ARR at this stage. I think for Deel, it as around 12x reply immortal3 19 hours agoparentTo add further, i do not know what is end goal of hugging face. 1. They have inference API but all cloud provider can implement those in next year. 2. They offer subscription but market-size of subscription is questionable. 3. I hope this new set of funding don&#x27;t bring problem to them because making money with open source is hard and at this scale of funding it might be even harder. It see what happens in next set of years. reply JumpCrisscross 19 hours agorootparentGitHub for ML models? If they can anchor themselves to the open-source developer network, their acquisition value is in a tech giant being able to cross-sell to that community. reply verdverm 18 hours agorootparentAre they going to spend that money recreating Code Host features like PRs, code scanning, CI?I&#x27;m not going to host my code on multiple platforms, pretty easy to make a model available for download with S3 reply pizzafeelsright 19 hours agorootparentprev1. Raise $$$ 3. Spend $$$ 4. Exit w&#x2F; $ reply nytesky 19 hours agorootparentTake money off the table, that’s what all the startup gurus call it, but whose money is kinda the question. Have pension funds stopped chasing VC funds etc? reply PeterisP 13 hours agorootparentThe article is quite clear on whose money it is - \"Google, Amazon, Nvidia, Intel, AMD, Qualcomm, IBM, Salesforce and Sound Ventures\".For at least half of them, it might make sense to simply sponsor accelerating worldwide new AI product development because those new products will increase sales of their hardware and services; pitch in $20m together with others to support efforts like Huggingface, while expecting that their tools will indirectly cause an extra $1b sales for you in the next few years. reply smcleod 19 hours agorootparentprevThe companies that invest have products (or have other investments with products) that have a strong market - they end up increasing the price of products to cover the purchase of acquisitions and losses. This results in inflation and worsening wealth distribution. reply smcleod 19 hours agorootparentprevProbably the same as most privately funded tech startups 1) Gain user base 2) Take investment funding 3) Sell and make the people at the top rich 4) Repeat. reply stevenae 19 hours agorootparentprevI suppose the argument would be switching costs -- what stops any cloud provider from being interchangeable with another? reply toomuchtodo 19 hours agoparentprevBuying a lottery ticket is buying a dream. You too can raise like this if you sell a dream to people with deep pockets who will only be mildly perturbed when it goes bust. reply solarkraft 19 hours agoprev1) What do they want with all that money?2) How in the world are they going to pay it back?They better have a damn good idea because this seems like a good recipe for popping like a balloon. reply stevofolife 13 hours agoparentWelcome to VC 101:1) Grow 2) They don&#x27;t. It&#x27;s not a loan. VC world doesn&#x27;t operate on loans. You go to the bank for that. reply orwin 17 hours agoparentprevIt&#x27;s not a loan, they&#x27;re selling shares. reply dbish 16 hours agorootparentThere is expectation you return value though. I think that’s what most people mean when saying “pay it back” regarding investments like this. reply solarkraft 19 hours agoprevOh. When I last read about it I thought it was meant to be sustainable.I hope the founders take their share home and have fun burning the rest. At least hopefully some open software&#x2F;AI models will have come out of it when the company collapses under its own weight. reply steno132 17 hours agoprevCongratulations! Elon&#x27;s team over at X.ai, who I&#x27;m helping advise, is choosing between Hugging Face and a locally hosted alternative.What would HN recommend? I prefer Hugging Face as it has a stronger community built in but others prefer a open source project we can customize. reply dbish 16 hours agoparentIf you’re hosting for your own use, unclear why you wouldn’t just do that directly on cloud instances. If you’re trying to share models with others publicly, then HF is the best option right now. reply espadrine 16 hours agoparentprevWhat does X.ai seek: democratization or centralization?If it wants everyone to fork its models, having the model on Huggingface and using its libraries will increase adoption, as people are used to that format, having the quantization built-in, etc. Having to perform model conversions slows things down, despite TheBloke’s constant efforts to convert every format to every other.If the model will only be accessible through CLI, APIs, or a website UI, then custom can make sense. reply jprd 13 hours agoparentprevGoodness, good luck and congrats!I am curious however, why name drop Elon and X.ai when asking this question?With all due respect, I&#x27;m not sure how that is going to advance the technical conversation, and in some regards may indeed de-rail it and hinder the mentoring you might receive?I hope I do not sound combative!I am generally curious, as I see this behavior at $JOB, but in reverse. \"My customer is seeing this.\" \"I have a customer that is asking Y.\"I am generally curious on the different perspectives that teammates can come from, that can drive them to take wildly non-congruent approaches, even with similar career experiences. reply brucethemoose2 16 hours agoparentprevWhy not both?Y&#x27;all could host models on HF, and use the HF format&#x2F;download code (which is quite good).But make a pretty frontend for it.Down the road you could just host your own backend implementing the HF API, if such a thing is necessary. reply nmfisher 5 hours agoparentprevAre you able to provide a bit more detail on what they&#x27;re doing, or is it still all hush-hush? reply weego 17 hours agoprevI don&#x27;t know what this could ever do that isn&#x27;t easily reproducible with a tiny fraction of that investment. Fragmentation of communities is an absolute given in software.Added to the fact that of they get too dominant they&#x27;ll get leveraged out of the supply chain and I&#x27;m not sure what the value proposition is here.I mean obviously I&#x27;ll be wrong but it&#x27;s hard to not be skeptical reply waterheater 17 hours agoprevThe real question is why the company doesn&#x27;t use .ml as a domain name alias.Edit: dang, guess HN strips out emojis from posts. The Punycode version of the Hugging Face emoji on a relevant TLD supporting emoji domains would be http:&#x2F;&#x2F;xn--zp9h.ml&#x2F; reply sleepybrett 18 hours agoprevHugging face is a terrible name for an ai company. Predicting it suffocating us all both mentally and physically? reply jtsiskin 8 hours agoparentIt’s named after the emoji; started as a chat app for teens: https:&#x2F;&#x2F;techcrunch.com&#x2F;2017&#x2F;03&#x2F;09&#x2F;hugging-face-wants-to-beco... reply Apocryphon 13 hours agoparentprevI like how companies are embracing branding that evokes cyberpunk and other genres of dystopian science fiction. reply ineedtocall 15 hours agoprevI&#x27;m waiting on something like gumroad, but for curated models and datasets. reply thunkshift1 17 hours agoprevWhy salesforce?? It seems the want in on everything fancy in the market (looking at slack) reply dbish 14 hours agoparentThey have a VC arm that just looks for and does investments which doesn’t necessarily means salesforce proper is interested in the tech (though I’m sure there is some of that), kind of like Google Ventures. reply nytesky 19 hours agoprevI saw this and thought it was a startup in homage to a xenomorph facehugger. Ironic, since we are worried about AI destroying humanity. reply thrillgore 18 hours agoprevAre they gonna change licenses in the next week, too? reply mywacaday 16 hours agoprevI hadn&#x27;t heard of Hugging Face before and the first though that came to mind was the face huggers from the Alien movies reply hospitalJail 18 hours agoprevTime to find a new website to share models. reply AdmiralAsshat 18 hours agoprev [–] Really, throughout the entire funding process no one raised the similarity of \"Hugging Face\" to \"Face-huggers\", the larval name for the Xenomorphs from Alien? reply julien_c 18 hours agoparentwe have a secret plan to change our logo to a Face Hugger some time in the future :) reply mistrial9 18 hours agoparentprevexcept that it is literally named for a friendly and non-offensive chat signal. reply glompers 18 hours agoparentprev [–] There is that. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Hugging Face, an AI startup, has secured $235 million in Series D funding, with notable investors like Salesforce and Nvidia participating.",
      "The funding round has doubled Hugging Face's valuation to $4.5 billion since May 2022.",
      "Hugging Face offers data science hosting and development tools, including an AI code repository hub, models, and datasets, as well as web apps for AI-powered applications.",
      "The company provides libraries and paid functionalities such as AutoTrain, Inference API, and Infinity.",
      "The funds raised will be used by Hugging Face to expand its support in research, enterprise, and startups."
    ],
    "commentSummary": [
      "Hugging Face, an AI model hosting platform, has recently raised $235 million in funding from investors including Salesforce and Nvidia.",
      "The company's future plans include monetizing its services, which has sparked concerns about risks to the AI ecosystem and the need to reduce dependency on Hugging Face.",
      "Discussions are underway regarding potential monetization strategies, comparisons to other platforms, and the sustainability of free resources.",
      "There are debates surrounding the business model of selling AI/ML and confusion about the offerings provided by Hugging Face.",
      "The company intends to use the funding to expand its team and further develop its platform."
    ],
    "points": 348,
    "commentCount": 186,
    "retryCount": 0,
    "time": 1692885732
  },
  {
    "id": 37249623,
    "title": "Bypassing Bitlocker using a cheap logic analyzer on a Lenovo laptop",
    "originLink": "https://www.errno.fr/BypassingBitlocker.html",
    "originBody": "Bypassing Bitlocker using a cheap logic analyzer on a Lenovo laptop Guillaume Quéré GitHub LinkedIn Root-Me Architecture of a passwordless BitLocker with a discrete TPM Capturing the TPM exchange Decoding the captured signal SPI TIS TPM 2.0 Mounting and backdooring the disk Limitations Takeaways Have you ever been told that the company’s data on laptops is protected thanks to BitLocker? Well it turns out that this depends on BitLocker’s configuration… Architecture of a passwordless BitLocker with a discrete TPM The BitLocker partition is encrypted using the Full Volume Encryption Key (FVEK). The FVEK itself is encrypted using the Volume Master Key (VMK) and stored on the disk, next to the encrypted data. This permits key rotations without re-encrypting the whole disk. The VMK is stored in the TPM. Thus the disk can only be decrypted when booted from this computer (there is a recovery mechanism in Active Directory though). In order to decrypt the disk, the CPU will ask that the TPM sends the VMK over the SPI bus. The vulnerability should be obvious: at some point in the boot process, the VMK transits unencrypted between the TPM and the CPU. This means that it can be captured and used to decrypt the disk. Capturing the TPM exchange We’ll be using a dirt cheap logic analyzer, DSLogic Plus. I bought this for under $100 in 2021 (tax and shipping included). A note on signal capture: to comfortably acquire a signal the sampling frequency should be 3 to 4 times the bus frequency. This means that for our SPI 33MHz bus we should sample at the very least at 100MHz. Notice that the specs of the analyzer state that it can do up to 400MHz on up to 16 channels. I’ll help you read between the lines here: the more channels you capture at a time (by sets of 3), the lower the sampling frequency you have to distinguish stream mode and buffer mode. The first one will send results directly to the host computer and permits capture of large sets, up to a minute but it’s limited to 100MHz on 3 channels. The buffer mode allows sampling at 400MHz but it will only work for a few milliseconds, so there’s no practical use for it here. This means that this hardware can barely do the job we’re asking it to do. For a more professional option both hardware and software-wise (but also 10x pricier) have a look at Saleae. Otherwise there’s sigrok’s list of supported hardware. As for plugging the analyzer to the board, remember that SPI is a shared bus. This means that there’s no need to capture the signal right at the tiny TPM pins if there is a larger SPI component on the board that the hooks can be latched on to. From experience I identified a neighbouring SPI flash, but fortunately all components are marked so it’s rather easy to identify their use by looking up their datasheet. SPI has several lines but only 3 can be captured using the DSLogic because otherwise the sampling frequency drops. The 3 most important ones are the clock CLK and the two data lines MOSI and MISO. The threshold voltage (level at which the analyzer decides that the line has changed states) should be around half of the signal’s voltage, here the latter was measured at 3.3V so an appropriate threshold is around 1.6V. The VMK key we’re looking for is used late in the POST stage. For the Lenovo L13 I worked with it was just after the splash screen, about 14 seconds into the boot process out of a total boot time of about 25 seconds. There are SPI operations before that (mostly to read and verify the early boot stages) but they’re not TPM. You could either start the capture when booting the computer, or safely wait about 7 or so seconds to avoid capturing unnecessary data. Decoding the captured signal There are 3 layers to decode: SPI, which is the physical layer TIS TPM2.0, which contains the VMK SPI As far as SPI is concerned any logic analyzer should do this properly, it’s a rather simple protocol: The blue square wave is the clock, the other two lines (yellow and red) are data lines, respectively used for communications from slave to master (MISO) and master to slave (MOSI). When the clock signal is going up (transitioning from 0 to 1), the bit value is whatever state the data lines are in at this specific time. In our case the red line sits at 0 for 8 clock cycles, so the byte is 0. The yellow line only has the first bit set, so the decoded value is b10000000 = 0x80. The logic analyzer correctly decodes SPI so we’ll just trust its output. TIS TIS, which stands for TPM Interface Specification, is another beast entirely and that’s where I had most of my troubles. I couldn’t find a decoder that worked for my capture and decided to do it “manually”. Short of correctly decoding the data, the libsigrock decoders did at least indicate a rough window for the TPM exchanges which was a welcome tip since each capture has several million bytes of data. Maybe the decoders fail be because the capture is missing Chip Select (CS#) which is required in the TPM specification, maybe because the clock is incorrect, maybe because some bytes are occasionally missing, maybe for some other reason, who knows. Master to slave request: Sending a request seems to happen in this order: the slave sends byte 80 to signal that it’s ready the master sends a header we don’t care about (D4 00 24) and then sends the TPM byte in a loop (80) the slave acknowledges that it has read the byte by sending 01 FF at this point the cycle starts anew with the next byte So this whole frame is just to send the byte 0x80 from the master to the slave! Slave to master response: This is a completely different process that relies on setting and reading registers. The frame is the result of reading one byte from a set address (D4 00 24, meaning register 24). Again the slave seems to start the transaction with byte 80, then writes the size of the followong data which is only 1 byte (or it could be an ACK value to the read request, who knows) and finally the value we care about, here 0x80. The next TPM byte is 0x02. TPM 2.0 The TPM command that requests the key be sent back is the TPM2_Unseal command. It is described in part 3 of the TPM 2.0 specification. You might ask how I isolated the frames below since no decoder would work. We don’t actually care about the requests happening on MOSI, we’re mostly interested in the responses on the MISO line. As we’ve seen previously the TIS encoding around TPM bytes is rather simple, so the simplest way to isolate all TPM transactions is to filter the raw SPI data using the mask “80 00 00 00 01 ..” and only keep this wildcard last byte. The start of a TPM transaction can then be identified by its own 80 01 or 80 02 header. There should only be a few dozens TPM responses, the one with the key inside should be the longer authenticated one (starts with 80 02). There is a 10 milliseconds delay between the unseal command and the response, which is huge. This is probably because the request is authenticated (see below the 80 02 header indicating a password session as opposed to most requests using the plain 80 01 header) using a HMAC so the slave has to verify the signature and then reply using a HMAC of its own, which induces a notable delay. The TPM command and its response are obtained by reassembling bytes one by one using the method previously explained. Reconstituted Unseal command: 80 02 00 00 00 5B 00 00 01 5E 80 00 00 00 00 00 00 49 03 00 00 00 00 20 9D F7 05 43 7A 77 AE E4 20 92 66 17 EC DA BB A7 79 D2 47 0D 42 E5 D1 1C EB 4A 6B C1 C8 44 42 BC 00 00 20 D9 AF C7 DF 10 7A D4 30 C1 C5 28 63 5F CE CE 8A 24 1A 19 E5 DD 08 5F 77 AA 28 BE 75 16 16 91 F1 Decoded frame using this awesome tool: Response (I’ve stripped continuation bytes 1F 00, they become apparent if you capture several long frames): 80 02 00 00 00 81 00 00 00 00 00 00 00 2E 00 2C 2C 00 05 00 01 00 00 00 03 20 00 00 57 61 A3 91 DF E1 B3 85 28 28 C6 DD A6 F9 A5 FE AC E9 71 A4 AA AE 44 25 18 F7 4A A7 FE D6 E0 FC 00 20 8D DD A1 AE 93 5D 98 E9 DA A8 18 6F D5 64 A8 66 E6 DE AA 56 9E 2F 50 A7 41 E1 27 BF A1 2C 4D 92 00 00 20 00 20 BA C9 8F 34 60 5F 4F D4 76 9B 6B AA 68 C7 6C 79 EF 36 7D 1D D3 19 33 78 55 47 B2 E1 40 D4 Decoded response: In the buffer lies our key, it starts with 5761 and is 32 bytes long. Mounting and backdooring the disk Mounting the disk live in read/write mode (if you’d rather work offline do a disk copy with dd and then mount this copy using a loop device): echo 5761A391DF1F00E1B3852828C6DDA6F9A5FEACE971A4AAAE442518F74AA7FED6E0FCxxd -r -p > key dislocker-fuse -K key /dev/sdd3 ./mnt/ mount ./mnt/dislocker-file ./mnt2/ Then the simplest backdoor is to just overwrite the sticky keys program with cmd: cp ./mnt2/Windows/System32/cmd.exe ./mnt2/Windows/System32/sethc.exe Place the disk back in the laptop, boot and press shift 5 times to get a SYSTEM shell: Limitations I cannot recommend using the DSLogic for this task: a lot of captures were duds and had to be thrown away sampling at 3 times the bus speed was barely enough to have a coherent clock and some bytes were missing This forced me to spend way too much time to understand the protocols in order to decode the capture. In the end time is money, if you’re an employer reading this just buy a professional logic analyzer for your employees. Takeaways The use of a discrete (physical) TPM does not increase the security of the system as one would expect and creates the illusion of security. To protect against this attack you could either use a fTPM or if the discrete TPM has to be used, then it is necessary to set a PIN or passphrase on BitLocker (as recommmended by Microsoft). Edit: this article sparked a discussion on HackerNews, if you’re interested in the subject you might learn much more from them. I have altered the conclusion thanks to feedback I got there.",
    "commentLink": "https://news.ycombinator.com/item?id=37249623",
    "commentBody": "Bypassing Bitlocker using a cheap logic analyzer on a Lenovo laptopHacker NewspastloginBypassing Bitlocker using a cheap logic analyzer on a Lenovo laptop (errno.fr) 327 points by brohee 19 hours ago| hidepastfavorite138 comments als0 17 hours ago> using a fTPM would solve the problem.All TPMs support encrypted sessions to prevent these kind of MITM attacks. You use TPM2_StartAuthSession and specify encryption with each session command. But Bitlocker doesn&#x27;t use one, which is epic fail. Microsoft need to fix it.Edit: For comparison, systemd uses encrypted sessions when using LUKS disk encryption with the TPM https:&#x2F;&#x2F;github.com&#x2F;systemd&#x2F;systemd&#x2F;commit&#x2F;acbb504eaf1be51572... reply comex 17 hours agoparentThis isn’t even a proper MitM attack, just passive sniffing.But, I ask as someone unfamiliar with TPM, how do authenticated sessions work? How does the OS prove its identity to the TPM in a way an attacker couldn’t spoof in a real MitM attack? Any secrets or keys stored by the OS side would have to reside unencrypted on disk, since it doesn’t have an encryption key yet. Or even if the OS verifies the TPM’s identity somehow, even if this is done in a way that it can’t be worked around just by modifying some files on disk, what stops the attacker from running the same routine in an emulator?I don’t see how you get real security from this approach unless there’s some integration with Intel ME or SGX or other CPU-side ‘secure’ environments, but then you wouldn’t need the TPM to start with. reply mjg59 16 hours agorootparent\"Authentication\" here is something of a misnomer - it&#x27;s setting up an encrypted session without any proof of identity. In that form it&#x27;s sufficient to block passive sniffing and require an active MITM instead. The TPM&#x27;s side of things can be tied back to the EK and hence can be validated against the vendor-issued EK certificate, so in theory this can be implemented in a way that avoids that risk, but that still involves a mechanism for bootstrapping the trust in the EK signing authorities and if that&#x27;s not in the signed component of the boot chain then you&#x27;re going to have problems.I&#x27;m not sure what you&#x27;re considering in the emulator case. Either the PCR values are going to be different or the TPM is going to be different, and in both cases that means you&#x27;re not going to receive the decrypted secret. reply rstuart4133 2 hours agorootparentprev> How does the OS prove its identity to the TPM in a way an attacker couldn’t spoof in a real MitM attack? Any secrets or keys stored by the OS side would have to reside unencrypted on disk, since it doesn’t have an encryption key yet.Your intuition is sound. The only way for the OS to prove it&#x27;s identity is to have a secret only it knows, and prove to the TPM it knows it. TPM&#x27;s do support that, but in this case the OS has nowhere that is robustly secure to store the secret.Windows could store a obfuscate secret on disk, but it doesn&#x27;t bother. To be fair, there probably isn&#x27;t much point - if someone is willing to go to this much work, then it&#x27;s very likely they would be willing to invest the additional effort to break the obfuscation.This still gives you a level of protection you wouldn&#x27;t have without the TPM. The disk can only be read when the TPM is present - so someone stealing disk, or walking away with a bit for bit copy of it won&#x27;t get them very far. One place that&#x27;s useful in cloud environments. If the cloud provided replaces a fail disk and doesn&#x27;t wipe the old one - it&#x27;s still useless unless someone unless they know what motherboard it was paid with.Still, I think that&#x27;s an anti-feature for a laptop. It means if the motherboard fails you&#x27;ve lost the data on the disk even though it&#x27;s perfectly fine, and indeed that is the case with bitlocker. If you protect the disk with a password you entered on boot up it is immune to this sort of attack, and you can move it between machines. Win, win. That&#x27;s what I do. But, I don&#x27;t use Windows to do it.> Or even if the OS verifies the TPM’s identity somehowThat can be solved using attestation. Attestation is just a secret TPM knows, signed by the manufacturer. Windows could choose to deal only with TPM&#x27;s from manufacturers it trusts, and presumably a emulated one wouldn&#x27;t be one of them. Secure boot should prevent you from modifying Windows to accept any manufacturer, so it&#x27;s secure.But I&#x27;d lay long odds Windows doesn&#x27;t do this sort of verification. reply kobalsky 16 hours agorootparentprev> even if this is done in a way that it can’t be worked around just by modifying some files on disk, what stops the attacker from running the same routine in an emulator?this is a question for an TPM expert. I&#x27;m a novice at this so take my reasoning with a grain of salt.A software only emulation shouldn&#x27;t fool the TPM since part of the secure boot process ties the hash of some PCR banks to the firmware, bootloader and kernel booted, so if you were to modify them in a way that allows you see the key, then it TPM wouldn&#x27;t be able to produce the correct decryption key. I&#x27;m not sure if windows uses those PCR banks to secure bitlocker, but on other OSes you can.I&#x27;m guessing that a hardware mitm would be possible with a discrete tpm, unless you use an aditional factor to boot as it usually recommended to prevent evil maid or cold boot attacks. reply Vogtinator 16 hours agorootparentprevAgreed. I don&#x27;t see a way this can be done without one side trusting the other implicitly. If the sniffer&#x2F;MitM gets either the measured data (to replay) or the unsealed key (to use directly) it&#x27;s game over.> I don’t see how you get real security from this approach unless there’s some integration with Intel ME or SGX or other CPU-side ‘secure’ environments, but then you wouldn’t need the TPM to start with.fTPMs are basically implemented within (or closely working together with) Intel ME reps. AMD PSP. reply 0xbadcafebee 15 hours agorootparentprevMitM covers both passive and active. The traditional model for MitM was Telnet sessions, where a passive MitM would allow you to capture secrets and then initiate new sessions. With active mitm you can take over a session (or more!) but passive enables plenty of successful attacks, which is why you should use encryption, which MS didn&#x27;t. lolz reply voxic11 16 hours agorootparentprevYou are correct, see section 6.3 https:&#x2F;&#x2F;github.com&#x2F;nccgroup&#x2F;TPMGenie&#x2F;blob&#x2F;master&#x2F;docs&#x2F;NCC_Gr... reply jfim 15 hours agoparentprevI wonder if that oversight is intentional and what would be the reason for it. reply Dalewyn 11 hours agorootparentI would hazard a guess that it&#x27;s probably because BitLocker predates TPM by at least two years, and Microsoft wants to avoid bricking old BitLocker secured data because most users just aren&#x27;t going to be on top of this stuff. reply logical_person 14 hours agoparentprevauthenticated sessions are practically useless on anything but a fully integrated device, because there is no guarantee of the SRK&#x27;s identity - MITM is still possible. reply controversial97 18 hours agoprevAnother write up from 2021https:&#x2F;&#x2F;arstechnica.com&#x2F;gadgets&#x2F;2021&#x2F;08&#x2F;how-to-go-from-stole...One aspect of this is that some laptop manufacturers provide a setting to erase the TPM if the laptop is opened. You opened that laptop to see if you can add more RAM? Better hope you can access the bitlocker key or have a good backup. reply layer8 17 hours agoparentIt’s good practice to have a copy of the recovery key somewhere. reply controversial97 17 hours agorootparentLots of people and small companies just buy a windows laptop and are unaware that the harddrive&#x2F;ssd is encrypted with bitlocker.People who avoid making a Microsoft account to log on to a windows computer, or who don&#x27;t have access to the email address they used can find themselves in difficulty later when windows won&#x27;t boot or it wants the bitlocker key for some reason. You can&#x27;t get their files off the drive by connecting it to another machine because the bitlocker key is not available.Yes, people should have backups and copies of their keys but they very commonly don&#x27;t. reply gnopgnip 15 hours agorootparentMost small companies will login with a microsoft account and have the key saved by default to https:&#x2F;&#x2F;myaccount.microsoft.com&#x2F;If you don&#x27;t sign in with a microsoft account bitlocker isn&#x27;t enabled by default. When you setup bitlocker it \"forces\" you to make a backup of the key reply Crontab 17 hours agorootparentprevI was under the impression that BitLocker does not default to being on, even with a Microsoft account. That&#x27;s kind of dangerous if they have changed that without at least a warning. reply gambiting 17 hours agorootparentI recently got a new MSI laptop, came with Windows 11 - I immediately wiped the drive and installed Windows 10(Home edition), few days later installed a new BIOS update and the laptop asked me for a bitlocker key......but I never encrypted the drive??? What&#x27;s even weirder is that I logged into the Microsoft recovery thing and it had the recovery key for it????? So it does seem to be the default behaviour now. reply ysleepy 15 hours agorootparentWindows marks the device as bitlocker enables somewhere in the EFI partition or GPT disklabels. I needed to wipe the whole disk to have windows cease with bitlocker bootscreens. reply ixwt 16 hours agorootparentprevThis makes absolutely 0 sense. Bitlocker cannot be setup on Windows 10 Home edition. reply gambiting 16 hours agorootparentWell I upgraded to Pro about two days later, so maybe the upgrade did it? But either way, there was absolutely zero indication that the drive is getting encrypted or that it&#x27;s going to save my recovery key to my Microsoft account. reply wbkang 16 hours agorootparentprevIt&#x27;s called \"device encryption\" which seems to do the same thing and they allow it for Windows 10 home. It&#x27;s confusing. reply temac 16 hours agorootparentIt&#x27;s bitlocker but only activates if you log into a MS account in which case it:* silently activates* silently sends the key to MS.And this is the only way to have it on home. reply gambiting 16 hours agorootparentAh. Which is probably what happened to me as I&#x27;ve signed into my MS account. replybootsmann 15 hours agorootparentprevIt is default on in win 11, which is probably a huge privacy improvement for a majority of users. The recovery is sent to microsoft with your microsoft account, but against 99% of attacks (petty criminals stealing your laptop) this suffices.If you fall into the category of users that distrust microsoft with their key, you can take active action and configure bitlocker yourself. reply controversial97 16 hours agorootparentprevI can say from personal experience that for at least five years it has been common for small companies to buy a laptop direct from Dell and for it to have a bitlocker encrypted drive without anyone choosing that. reply vladvasiliu 16 hours agorootparentprevIME with win 11 pro, it won&#x27;t encrypt the drive if you (jump through hoops to) create a local account. But as soon as you link it to MS, it will encrypt it. reply withinboredom 17 hours agorootparentprevIf you do a volume order, I think you can ask for it to be turned on by default. reply replwoacause 6 hours agorootparentprevWell no kidding reply ComputerGuru 17 hours agoparentprevI’ve never seen a consumer device with chassis intrusion enabled by default. Were these maybe volume orders for a business account? Those can come with whatever configuration IT wants. reply ixwt 16 hours agorootparentFrom all the computers that I&#x27;ve seen with intrusion detection on by default, they only give you a warning from what I&#x27;ve seen. reply morpheuskafka 15 hours agoparentprevThat&#x27;s probably just relying on a push-button tamper switch which could be easily bypassed by cutting the back plastic instead. I doubt they are doing anything very fancy like running wires over the whole case. reply brunoqc 17 hours agoparentprev> One aspect of this is that some laptop manufacturers provide a setting to erase the TPM is the laptop is opened.Do you mean like if you remove the screws and get inside a laptop?Could they gain access by cutting the plastic instead (maybe Matrix parasite extraction style). reply redox99 17 hours agorootparentChassis intrusion is almost always just a small switch pushing against the side panel of the case. And yes there&#x27;s a million ways you could bypass that. reply sublinear 17 hours agorootparentWhich sounds potentially unreliable on a laptop. Seems like a hard knock or even just normal material fatigue might be enough to release the switch. reply hutzlibu 16 hours agorootparentOne laptop of mine has such a sensor, but not for bitlocker.After I opened it, it would just refuse to turn on, probably a safeguard when repairing and not wanting it to run anything.But I did not know and thought I broke it, but after closing it again and tightening one screw in the middle, it worked and so I found that sensor. It is a very simple, but reliable push button and before it breaks, the screen will be broken long before that. reply Ian678 17 hours agorootparentprevCould also use a light sensor or check if a circuit that runs on the inside of the case is broken. reply michaelmior 17 hours agorootparentStill seems not to difficult to bypass (if you know it&#x27;s there). reply o1y32 14 hours agoparentprevOff topic -- The joke is that you can hardly find a laptop with upgradable RAM these days. Not even on some ThinkPad lines. Gaming laptops often do. reply jsmith99 14 hours agoprevThere&#x27;s nothing new in this. The default configuration doesn&#x27;t require a PIN but the Microsoft documentation explains the various attacks and recommends setting a Bitlocker PIN which completely prevents this. The PIN can be quite weak because the TPM prevents brute forcing. See eg https:&#x2F;&#x2F;learn.microsoft.com&#x2F;en-us&#x2F;windows&#x2F;security&#x2F;operating... reply kotaKat 14 hours agoparentAlso amusingly, as far as I&#x27;m aware, Windows Defender now by default blocks any accessibility-based escalation attacks -- Behavior:Win32&#x2F;AccessibilityEscalation. reply allset_ 8 hours agoparentprevI would expect the TPM to wipe key material after X failed attempts, is that not the case? reply Octabrain 14 hours agoprevI would like to take the chance to ask about something that I never understood from Bitlocker and this kind of encryption, in general, where the decryption key is provided automatically by the system. Let&#x27;s say, if my laptop (I mean, the whole device) is stolen, which security does Bitlocker provide? From an attacker POV, the system will boot and it will ask for my user account password. So, to my understanding, it will protect my data if my hard disk is extracted from the laptop and attempted to run it from a different system.Worth mentioning that this probably silly misconception is what makes me to always set a password for Bitlocker that I have to type manually which is what I&#x27;ve always done on LUKS.Am I totally wrong? reply vel0city 14 hours agoparentIt requires the attacker to bypass the login, extract the key from memory from the system, or potentially with a physical TPM this style of attack. This is probably a lot more sophisticated of an attack than a random thief trying to make a quick buck stealing an expensive computer. Chances are they&#x27;ll just end up wiping the drive and try to sell it rather than actually try a cold boot attack, but it all depends on your threat profile.Personally I mostly use FDE on personal machines so I don&#x27;t have to care much about physical destruction when I need to get rid of storage devices. If a hard drive fails I don&#x27;t need to actually tear it apart to make sure my data is gone. My device is usually in sleep mode when I&#x27;m out and about so if they were going to do a cold boot attack they could do it anyways. reply itscrush 14 hours agoparentprevNot entirely wrong, but may be missing how the key is now exportable adding risk to the scenario.As you mention decryption key is provided automatically to the system. This means it&#x27;s in RAM ready for export and re-use by bad actor against your encrypted disk. Cold boot attacks[1] are one of the attack vectors you&#x27;d want to read more on to figure out if this is valid for your threat model.[1] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Cold_boot_attack reply tedunangst 14 hours agoparentprevWindows is not supposed to let anyone access the files until they enter the correct account password. So the disk will decrypt in this computer, but then Windows prevents access. reply Rygian 14 hours agoparentprevMy guess: if you didn&#x27;t set a password for the disk encryption, you have no protection for that scenario. reply ballenf 18 hours agoprevSince the key traverses the shared bus, does that mean that every component in the system could intercept the key just as easily as this logic analyzer does? Sounds like a supply chain security nightmare. reply psychphysic 18 hours agoparentThe point of this kind of encryption is that a removed hardrive can be sold or repurposed without data risk.Anyone can boot the laptop and get to the decrypted hard drive, what does it matter if they sniff the key first? They always had access to the end result of they can boot the laptop. reply brohee 18 hours agorootparentWell you will boot the laptop but still have to get past the login screen. Intercepting the key permits to read&#x2F;write whatever you want on the disk, and thus backdoor the OS (as he does). reply withinboredom 17 hours agorootparentDude. Bypassing the login screen is as simple as pressing shift five times. That’s like some kindergarten stuff. reply sznio 17 hours agorootparentIf I remember correctly, you needed to replace the accessibility executable with cmd.exe for that to work.Can&#x27;t do that if the machine is encrypted. And if it&#x27;s unencrypted there are better ways to reset the passwords. reply gquere 16 hours agorootparentWell that&#x27;s what I described. The drive was encrypted but there was no PIN so I just snooped the key, decrypted the drive and mounted it on another machine where I replaced sethc with cmd. reply cafeinux 16 hours agorootparentprevDoesn&#x27;t this method imply booting from an external disk, thus not decrypting the HDD, thus not being able to modify what needs to be modified in order to bypass the login screen? reply brohee 16 hours agorootparentBitLocker is mostly worthless if you don&#x27;t also password UEFI, disable booting off any other disk than the main one, and enable SecureBoot. reply plonk 16 hours agorootparentIf you booted anything but the OS that set up BitLocker, wouldn&#x27;t the TPM refuse to release the key? reply als0 14 hours agorootparentThat is correct. reply withinboredom 16 hours agorootparentprevIf you can trick the computer into decrypting the disk, why does it matter which disk you actually boot from? reply gquere 16 hours agorootparentprevCan&#x27;t do this attack if BitLocker is protected by PIN&#x2F;passphrase, which is rarely the case. reply monocasa 18 hours agoparentprevIt&#x27;s shared between a couple of components, but not nearly all of them. These days pretty much just the boot flash and the TPM (and the CPU itself as the bus master) are sitting on that SPI bus. reply layer8 17 hours agoprevIf you want Bitlocker to protect against someone stealing your laptop, you should be using a password anyway (and disable non-hibernation sleep modes). reply mananaysiempre 17 hours agoparentThe first point was not entirely obvious before this—your laptop being stolen is essentially the weakest[1] class of threats against which full-disk encryption makes sense, and Windows makes a big deal against not requiring anything but your usual account password for that. Is the “trusted” hardware in the TPM even doing anything now? Is boot measurement also spoofable?(Also, this is just offensive levels of dumb—why is the key material just strolling along the bus here in plain view? There isn’t even a key exchange protocol or anything.)[1] People are also talking about secure erase here, which, okay, is weaker, but FDE + a EEPROM in a socket that you can pull out and physically destroy does that part just as effectively. reply vladvasiliu 17 hours agorootparentThe windows password is not required for Bitlocker. It doesn&#x27;t work like macos&#x27; filevault.You can configure a dedicated password for bitlocker, or a pin (can be alphanumeric) in addition to the tpm, but there&#x27;s no link between that and your windows account once the os is booted.I think MS&#x27; point about the standard bitlocker setup is that people can&#x27;t just steal the drive and mount it in their own PC, they need your specific PC. And also, that windows is secure enough that if you have the correct PC with the drive and the OS boots, you can&#x27;t open the windows session (which by default requires a password). So in this context, bitlocker adds some security while being \"transparent\". reply layer8 17 hours agorootparentprevWindows supports multiple accounts, hence an account password doesn’t apply to Bitlocker, which encrypts the main Windows partition as a whole. You need a separate Bitlocker password that the boot loader requests from the user before Windows proper is loaded, and before any accounts come into play. reply mananaysiempre 16 hours agorootparentI am aware (and my point of comparison is LUKS, where the separate password is extremely in-your-face). But my impression from Windows was that, in the default FDE configuration, the (measured?) OS boots up, pulls the FDE key from the TPM with no user input, then presents the user with a login screen. So in ideal world the data is exactly as secure against a thief as the account password or passwords, thus my mention of them.This article, however, says that this setup does not protect the data at all against a thief willing to pay $100 lifetime (not per machine), which seems an absurdly low bar. (And I’d wager you can go even lower by wiring up a cheap devboard—basically everything has a SPI peripheral these days.) I mean, liquid nitrogen is not exactly expensive either, but it does require some fuss, whereas the attack in TFA could be made essentially as easy as opening the case. reply layer8 16 hours agorootparentI’d say that as soon as Windows fully boots up, you have a much larger attack surface anyway, even if you can’t log in due to the account password. Though I can’t point at anything specific off the top of my head. reply plonk 16 hours agorootparentIs there anything you could access from the keyboard or touchpad? Seems easy enough to only accept the inputs that the login screen needs and nothing else. reply gquere 15 hours agorootparentprevOnly DMA comes to mind but it requires a non-hardened configuration which isn&#x27;t that common on recent laptops + OS. reply mananaysiempre 11 hours agorootparentVery rarely are drivers, including USB drivers, written to assume a hostile device (see e.g. the PS3). Frankly, they rarely seem to be written by people who care about software at all. (I still can’t get over the very first Zenbook, which suffered spontaneous deaths under Linux because the ACPI bytecode in the firmware tried to initialize a nonexistent IDE controller. And people say it’s Linux that has a hardware support problem.) So this is a somewhat valid concern.But I still can’t get over the idea where the default configuration of BitLocker is completely useless for basically anything except working around storage devices that will lie to you and not erase things you told them to. I just refuse to accept that’s in any way sane. replyggambetta 17 hours agoprevWhat software was used to turn the raw signal into zeros and ones? I&#x27;ve had a similar project since forever (reading digital data off 80s-era cassette tapes), I have pretty good .wav versions of the tapes, but I haven&#x27;t found the right tool (or library) to turn it into zeros and ones :( Of course the fun part will begin once I can start decoding the zeros and ones...EDIT: I know how the bits are encoded, it&#x27;s Frequency Shift Keying[0]. What I don&#x27;t know is what to use to decode this into a stream of bits I can process further (with custom code).[0] https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Frequency-shift_keying reply ack_complete 14 hours agoparentFor decoding old FSK tapes, look into sliding Goertzel filters. They&#x27;re easy to implement filters that extract the amplitude of a frequency bin within a sliding window, and are often referenced in literature about DTMF decoding. Compare the outputs of a pair of these to produce a digital output. You can also use a sparse sliding DFT, but interpolating between frequency bins is more of a hassle, whereas the Goertzel filter handles that for you. reply aeonik 17 hours agoparentprevThis is a a major field called Digital Signal Processing, and it&#x27;s fundamentally what a modem or the ADC in your sound card is doing.I&#x27;m not aware of any single algorithm or software that can turn any raw signal to bytes. You need to figure out which modulating scheme the signal uses, and either find a decoder for it, or write your own.Generally it&#x27;s going to involve filtering, and other mathematical algorithms. But they tend to be pretty short and simple programs for basic decoding.It&#x27;s a pretty neat skill to learn because you can use the same techniques for all sorts of things. For example, once I learned a bit of DSP it unlocked a lot of abilities with Radio communication, Music and Sound design, image, and video processing. reply dekhn 16 hours agorootparentGNU radio has all the bits to do signal processing from raw analog data to symbols to bytes.For example, I can use my SDR to record various signals in my neighborhood, make a guess that it&#x27;s manchester encoded, then pass that signal to a symbol demodulaor, pass the symbols through a manchester decoder, then on to a protocol decoder (IIRC my tires have batteries and transmitters to send their pressure level to my car). GNU radio has bits for all these steps, but yeah, you kind of need to know the modulation schema and the codec scheme to make sense of it.Here&#x27;s a nice example: https:&#x2F;&#x2F;bkerler.github.io&#x2F;OregonDecoder&#x2F; reply 4gotunameagain 16 hours agorootparentprevThis is not DSP, this is just digital communication. DSP is digital manipulation of a sampled signal, whether that is infinite&#x2F;finite impulse response filters (IIR, FIR), discrete fourier transform, discrete wavelet transform etc.. reply matja 13 hours agoparentprevThe loading routines from that era just count the number of DC zero-crossings and convert X crossings into a 0 and Y crossings into a 1, they don&#x27;t care about frequency or amplitude (the raw signal is usually fed into a Schmitt trigger to implement hysteresis for a stable edge). That way, the polarity of the tape signal and the variation of the motor is compensated for. reply Karliss 17 hours agoparentprevPulseview https:&#x2F;&#x2F;github.com&#x2F;sigrokproject&#x2F;pulseview and probably other parts of Sigrok project https:&#x2F;&#x2F;github.com&#x2F;sigrokproject .Or since author mentioned DSlogic possibly the corresponding forks of those programs from the company making the logic analyzer. reply gquere 16 hours agorootparentIndeed I used DSView which is a fork of pulseview. reply mike_hock 16 hours agoparentprevThe article makes it sound easy. When the clock goes from low to high, the current level of the data line is the bit value, and you look for a one and seven zeros to find the start. reply tamimio 15 hours agoprev>The use of a discrete (physical) TPM actually decreases the securityMy laptop from 2015 didn’t have physical TPM and it prompted me when I tried to enable it: “Allow BitLocker without a compatible TPM (requires a password or a startup key on a USB flash drive)” and I thought it’s less secure.. the irony! Good thing I don’t use bitlocker anyway. reply pgraf 11 hours agoprevSame technique described in 2021: https:&#x2F;&#x2F;dolosgroup.io&#x2F;blog&#x2F;2021&#x2F;7&#x2F;9&#x2F;from-stolen-laptop-to-in... reply kristjank 14 hours agoprevI find the fact that the old elementary school trick of renaming Command prompt to the accessibility handler still works as well as it used to in the Windows Vista days incredibly funny. You would imagine Windows would authenticate something that runs with admin perms with no login required. Windows seems to be 75% security theather and about 25% other types of theather. reply kosasbest 17 hours agoprevThis is a non-issue for me, as I use LUKS2 (the recent version of LUKS which is much better). If I need to use Windows, for whatever reason, I jail Windows in a VM typically to use certain software that has no Linux equivalent.I don&#x27;t trust Bitlocker. Read somewhere Bruce Schneier uses Bitlocker for his daily computing, but I still don&#x27;t trust it. After all, this is Microsoft we&#x27;re talking about, who are in cahoots with the NSA, and Redmond has NSA on speed-dial. Avoid Bitlocker if you really want to protect sensitive data.(If you are going to use LUKS, use LUKS2 with a seven word passphrase). Currently this is the state-of-the-art for encrypting disks. reply lostmsu 9 hours agoparentFun stuff. I only ever use Linux under Hyper-V precisely because I could not find a reliable way to set up disk encryption that does not ask for password while giving the same protection as Bitlocker (e.g. you can keep your system automatically updated, and as long as your TPM and OS login screen are not vulnerable nobody can steal the machine and decrypt the drives).Even Fedora (which I think is in the better shape than most) does not set that up by default and the only tutorials I found require you to manually reconfigure TPM on every kernel update. reply NoZebra120vClip 11 hours agoparentprevReality check. If US-based Big Tech is undoubtedly pwned by USGov interests, why should you think that non-US-based tech is any different? Do you really think that MI5&#x2F;6 leaves Canonical alone? Red Hat is IBM and US-based too. Are the Finnish&#x2F;Scandinavian authorities just patting Linus on the head and saying \"do whatever you want bro!\"I think that it takes significant leaps of logic, yeah even with pervasive F&#x2F;OSS, that non-US intelligence is somehow weaker or less interested than US-based ones. In fact, your typical Linux supply chain and SBOM is far, far more complex than anything Windows can serve up. There are so many juicy opportunities in there. reply Already__Taken 15 hours agoparentprevluks2 and Tang+Clevis is a pretty tidy solution. I have a host boot that I connect into the VPN and unlock the inner container volumes of code. I would like if it was built upon less shell scripts. reply jrm4 18 hours agoprevBitlocker is the Windows one, that&#x27;s essentially known to be compromised, right?Not saying that it&#x27;s useless, might be fine for certain work environments, but I wouldn&#x27;t rely on it for anything truly personal. reply jeroenhd 18 hours agoparentI&#x27;m not aware of any proven compromise of Bitlocker. There are some bugs (Bitlocker disabling itself during certain updates and not re-enabling it after a BSOD during the update process) but I haven&#x27;t heard of any way for an attacker who doesn&#x27;t have full code execution already to bypass encryption. If you set a PIN you should be safe, otherwise the attacker can try to use various exploits or other methods to access the drives.For fTPM based encryption, the entire system should be safer because the keys don&#x27;t traverse an accessible bus like this.The vulnerability also applies to other encryption systems using the TPM, like LUKS disk encryption. reply als0 17 hours agorootparent> The vulnerability also applies to other encryption systems using the TPM, like LUKS disk encryption.No, this is a Bitlocker problem. Systemd LUKS disk encryption uses encryption on the bus by enabling TPM encrypted sessions: https:&#x2F;&#x2F;github.com&#x2F;systemd&#x2F;systemd&#x2F;commit&#x2F;acbb504eaf1be51572... reply jeroenhd 16 hours agorootparentI stand corrected, I&#x27;m glad systemd finally implemented encrypted TPM communication. I really don&#x27;t understand why Microsoft is still allowing their keys to be MITM&#x27;d.I really should switch from Grub to systemd but the lack of boot time configuration (and, slightly less importantly, theming support) still makes me prefer Grub. reply usr1106 4 hours agorootparentMicrosoft implementation is vulnerable to eavesdropping as the submitted article shows.systemd would be vulnerable to MITM, but you don&#x27;t MITM the SPI bus with some $100 hobbyist tooling. reply snvzz 14 hours agorootparentprev>I&#x27;m glad systemd finally implemented encrypted TPM communication.Note that, as far as I am aware, it never implemented unencrypted TPM communication.That&#x27;s Microsoft-specific insanity. reply hedora 17 hours agorootparentprevIt sends escrow keys to your employer in enterprise environments.I’d be a bit surprised if the azure compromise a few weeks ago didn’t also give the attackers access to the escrow keys for customer vms, etc. reply jeroenhd 16 hours agorootparentThat&#x27;s not a bypass, though, that&#x27;s part of the design. If you&#x27;re storing critical business info on company hardware that your boss can&#x27;t access when you leave&#x2F;get hurt, encryption becomes a business risk.I don&#x27;t know if key escrow is also fucked as well after the recent breach, but so far I haven&#x27;t heard anything about it. reply FirmwareBurner 18 hours agoparentprev>Bitlocker is the Windows one, that&#x27;s essentially known to be compromised, right?It&#x27;s not compromised if you set a PIN&#x2F;passkey, aka use it correctly.Technically, the lock on your house door is also compromised since any pro locksmith can open it within a few minutes, but that doesn&#x27;t mean it&#x27;s now useless to keep locking your door since most casual thieves aren&#x27;t pro locksmiths and laptop thieves aren&#x27;t gonna be black-hat hackers&#x2F;security researchers.Such security solutions are there to discourage low hanging fruits of amateur bad actors(99,99% of them) and make them give up and use their time somewhere else. reply vladvasiliu 17 hours agorootparent> It&#x27;s not compromised if you set a PIN&#x2F;passkey, aka use it correctly.The issue is that you have to go out of your way to set it up this way. Last I checked, you couldn&#x27;t just add a PIN. You had to enable it through GPO. reply FirmwareBurner 15 hours agorootparentIt&#x27;s on for corporate users, but I assume because it would be a terrible UX for consumers, having users always enter a PIN code at boot&#x2F;re-boot and would make them throw their PCs out the window.It&#x27;s even worse if you use a Bluetooth keyboard as that doesn&#x27;t work at BIOS level so you&#x27;d have to plug in an USB keyboard just to enter your PIN on boot. Would be maddening and people would just turn it off. reply GordonS 15 hours agorootparentprevIIRC you can set a PIN without fiddling with security settings or GPOs, but if you want to use a password instead of a PIN, then you&#x27;ve got to jump through some hoops to enable that. It always struck me as a very, very strange design choice - why make it so difficult?! reply shuntress 15 hours agoparentprev> might be fine for certain work environments, but I wouldn&#x27;t rely on it for anything truly personalFunny, I feel the same way but to an opposite conclusion.Hardware-locked encryption is basically the last thing I want on my notes&#x2F;projects&#x2F;code&#x2F;pictures&#x2F;etc. reply jrm4 12 hours agoparentprevso the answer is yes, yet downvoted to zero. weird. reply FirmwareBurner 18 hours agoprev>The use of a discrete (physical) TPM actually decreases the security of the system, using a fTPM would solve the problem.Errr... no. Using no TPM of any kind decreases your security.The discrete TPM&#x27;s threat model was never designed to cover you from attackers using oscilloscope to probe your laptop&#x27;s SPI bus during the boot process for unencrypted data.Unencrypted communications over any channel, SW or HW are bad and dTPM never claimed it would protect you from that, but it&#x27;s still better than no-TPM, and have your keys in system memory or on the disk where it could be accessed through software vulnerabilities.Of course fTPM, is the next step up in security, even though that&#x27;s also not impenetrable to attackers with the right side channel analysis equipment and expertise, but security threat model is anyway a matter of time and budget of your attackers, nothing can ever be 100% invulnerable to everything. reply c4mpute 18 hours agoparentThis is highly misleading.fTPM is more secure against _this_ kind of attack, with physical access to the bus wires. However, since fTPM is a Firmware-TPM, it is vulnerable to all kinds of attacks on the system&#x27;s firmware, even remotely, even via the network, even maybe if the computer is switched off. Remember all those (even unauthenticated, remote) XML-parser exploits in the Intel ME? fTPM is just one more ME module, and of course vulnerable to those exploits.So overall, I consider fTPM a huge step back, because you might even get access without physical presence. For an fTPM, attack surface is far larger (because all of the ME software), minimum attack complexity may be smaller (because there will one day be a metasploit module for all those software problems, whereas HW hacking is always a certain hurdle), required attacker privileges are less (prolonged unobserved physical presence vs. network). Thus objectively worse in all aspects.What would be better would be a dTPM that is integrated e.g. into a SoC, such that there are no exposed wires anywhere without decapping the SoC. Some systems such as phones work like that, but this is hard to tell even from the technical specs. reply FirmwareBurner 17 hours agorootparent>fTPM is more secure against _this_ kind of attack, with physical access to the bus wires. However, since fTPM is a Firmware-TPM, it is vulnerable to all kinds of attacks on the system&#x27;s firmware, even remotelyYes, fTPM is more vulnerable in theory to remote attacks, but fTPM could always be patched, while it&#x27;s more difficult to de-solder the TPM chip off your motherboard and replace with a non-vulnerable one and there are vulnerable dTPM chips out there.Both solutions have their own pros and cons you have to weigh in the context of cost, convenience and threat model.>What would be better would be a dTPM that is integrated e.g. into a SoCIsn&#x27;t that what fTPM is? The TPM spec firmware runs on the security microcontroller (Intel PTT and AMD PSP) built in the same SoC as the CPU.What would be better is having the TPM be removable from the machine, like the YubiKey. Currently, dTPM and fTPM are basically like having your YubiKey always plugged in and glued to your machine. Convenient for authenticating you, but not secure from guys stealing your machine and probing it in a lab. reply auguzanellato 15 hours agorootparent> but fTPM could always be patcheddTPMs can also be patched, the TPM in my Dell laptop is discovered by fwupd as being updatable. reply Guvante 17 hours agorootparentprevWhat threat model assumes it is easier to attack fTPM than the OS that is running?Once you are online Bitlocker does nothing and you can just attack the OS and bypass all of its protections trivially...Your threat model here assumes arbitrary code execution as a starting point of an exploit, the security game is up for the PC once that occurs. reply c4mpute 15 hours agorootparentAny thread model should take firmware into account. There have been examples of unauthenticated remote code execution against Intel ME[0]. This isn&#x27;t theoretical, this isn&#x27;t an assumption, this has happened. Those exploits are independent of the OS running, with certain configurations the system doesn&#x27;t even need to be switched on, just plugged in. With fTPM as an ME module (not all fTPMs are such) this provides an additional huge attack surface.[0] https:&#x2F;&#x2F;mjg59.dreamwidth.org&#x2F;48429.html reply mjg59 14 hours agorootparentThat vulnerability allowed unauthenticated access to AMT, not arbitrary code execution on the ME. I agree that an ME-based fTPM has a larger attack surface than a dTPM, but we haven&#x27;t seen many cases where that&#x27;s had real-world poor outcomes. reply etna_ramequin 17 hours agorootparentprev> What would be better would be a dTPM that is integrated e.g. into a SoC, such that there are no exposed wires anywhere without decapping the SoC. Some systems such as phones work like that, but this is hard to tell even from the technical specs.That’s Microsoft’s Proton chip, I believe. reply mjg59 14 hours agorootparentPluton rather than Proton, but yes. reply etna_ramequin 12 hours agorootparentYes, that’s right, thanks! reply withinboredom 17 hours agorootparentprevI was always under the impression that once an attacker got physical access: all bets were off. Literally anything is possible at that point. reply etna_ramequin 17 hours agoparentprev> The discrete TPM&#x27;s threat model was never designed to cover you from attackers using oscilloscope to probe your laptop&#x27;s SPI bus during the boot process for unencrypted data.I’m always very confused by this. TPM offers encrypted sessions (setup with the Endorsement Key) for exactly this kind of attack. Why couldn’t the firmware get the keys over an encrypted session? Is it for reliability in case certificate verification goes wrong? reply gquere 18 hours agoparentprevAuthor here.> Errr... no. Using no TPM of any kind decreases your security.You&#x27;re right, I wrote too fast, sorry about that. What I meant to say is that it discrete TPM with no PIN is an inferior solution compared to PIN&#x2F;passphrase or fTPM. Also I should have added that it gives the illusion of security which I hinted at in the foreword. I&#x27;m leaving it as is for now, the discussions here are interesting. reply gbil 17 hours agorootparentSome months ago my company (in the 200k+ employees big) decided to remove pin requirement to “enhance UX while staying secure”. Many objections from quite a few people, mine included pointing to PoC key extractions from TPM etc. and… nothing . Seems that a multi billion company with no-ask money for cybersecurity misses the basics reply zimmerfrei 17 hours agoparentprev>> The discrete TPM&#x27;s threat model was never designed to cover you from attackers using oscilloscope to probe your laptop&#x27;s SPI bus during the boot process for unencrypted data.This is not really true. All TPMs (or at least since v2.0, but no matter if discrete or not) support encrypted session against passive eavesdroppers. There is also the possibility to protect against MiTM attacks, but that is more complex (since you then need to setup credentials).See here [0]:\"Encryption sessions are useful for when the path to a TPM is not trused, such as when a TPM is a remote TPM, or when otherwise the path to the TPM is not trusted.\"The issue is that the OS &#x2F; Bootloader does not implement such mechanism.[0] https:&#x2F;&#x2F;github.com&#x2F;tpm2dev&#x2F;tpm.dev.tutorials&#x2F;blob&#x2F;master&#x2F;Int... reply candiddevmike 18 hours agoparentprevWouldn&#x27;t the keys for LUKS&#x2F;Bitlocker be stored in memory regardless of TPM&#x2F;no TPM? reply ongy 18 hours agoparentprevFor large symmetric operations like disk encryption, the MVK is still in memory.TPMs are slow and have rather restricted memory. They are fine for PCRs and some asymmetric operations.But here they only unseal a key that is then used in software for speed. It&#x27;s worse than something protected by a high entropy password. Which is still better than 90% of users would be otherwise reply logical_person 18 hours agorootparentthat&#x27;s still less secure, though. without a TPM you have no guarantee of the underlying state of firmware on the device. this enables a persistent backdoor.TPM with no PIN is practically bitlocker with no password. A high entropy PIN happens to solve this entire attack. reply ongy 18 hours agorootparentFor the claim of GGP (stealing out of memory) it&#x27;s worse, as that&#x27;s still possible, and there&#x27;s a bus the key travels over.The PCRs attest system state to the OS, yes. Though the verified boot (PSB&#x2F;Secure Guard + Secure Boot) chain is supposed to provide the same security there. Provided we assume security features aren&#x27;t broken by design... reply brohee 17 hours agorootparentAt least TME-MK and its AMD equivalent are supposed to address in memory key stealing&#x2F;memory bus snooping (even if it&#x27;s still unclear to me how the key are generated&#x2F;stored). There is still decapping and probing the CPU itself but given the size of features is that even remotely doable? reply ongy 17 hours agorootparentYes and no. Mostly no IMOThe memory encryption features are a solution to very specific problems.If the CPU is able to access the memory, then any exploit that gains the execution context of the legitimate user can also access the memory. If it doesn&#x27;t, the normal memory access control should be enough.I&#x27;m iffy on how well they protect against the various side channels. Mostly because I haven&#x27;t looked far enough into it.IME it protects against cold boot attacks, a theoretic attack of a logic analyzer on the memory bus, and potentially to some degree unbounded reads. But the latter only with very limited gadgets. reply brohee 17 hours agorootparentYeah I was unclear, it&#x27;s supposed to address the physical attacks part. If no key leaves the CPU unwrapped, it&#x27;s down to software exploits and decapping the CPU... reply ongy 16 hours agorootparentGotcha. YesThere&#x27;s also this project https:&#x2F;&#x2F;www.cs1.tf.fau.de&#x2F;research&#x2F;system-security-group&#x2F;tre... which reserves some CPU registers (iirc. A hardware aes accelerator on one core) to prevent key leakage. replybrohee 19 hours agoprevTLDR if you actually want to act upon that :TakeawaysThe use of a discrete (physical) TPM actually decreases the security of the system, using a fTPM would solve the problem.If the discrete TPM has to be used, then a PIN or passphrase on BitLocker is necessary. reply buran77 18 hours agoparent> If the discrete TPM has to be used, then a PIN or passphrase on BitLocker is necessary.I always considered that BitLocker without a PIN is 80% convenience and 20% security. reply yomlica8 18 hours agorootparentIIRC earlier versions of bitlocker would rely upon SSD firmware implementations for drive encryption. They stopped doing that when it was revealed many of these hardware encryption systems in common drives didn&#x27;t actually work. reply blibble 18 hours agorootparentnext [–]void encryptSector(struct context *c, long sector_no, unsigned char *data, size_t data_len) { &#x2F;&#x2F; TODO } reply yomlica8 18 hours agorootparentThis is also something to keep in mind when resale of SSDs is discussed and people recommend using the secure erase function of the SSD! reply dylan604 17 hours agorootparentIt&#x27;s only securely erased after I&#x27;ve put about six 5&#x2F;8\" holes with my drill in it reply vxNsr 17 hours agorootparentprevYup, when I was working desktop support a few years ago my manager told me to just format the drive and send it back to dell at the end of the lease, they’d secure erase it anyway and the data was safe, I never trusted that and used dd to overwrite every bit of the ssd twice with junk data, I’m sure it decreased the longevity of the drive but wasn’t my problem and it felt cool to be the only desktop support guy who knew any Linux. reply heavenlyblue 16 hours agorootparentSSD wear leveling mechanism would create new writes into different physical sectors so it was highly probable you were not in fct overwriting at least a proportion of the data reply blibble 16 hours agorootparentI can imagine the wear levelling function on some SSDs looks pretty similar to the encryptSector function replyveave 17 hours agorootparentprevWasn&#x27;t it tremendously naive of Microsoft to trust that SSDs did encryption correctly? So naive that it borders incompetence and&#x2F;or malice? reply ExoticPearTree 18 hours agoparentprev> The use of a discrete (physical) TPM actually decreases the security of the system, using a fTPM would solve the problem.Since only dTPM can be FIPS certified, I don&#x27;t see how an uncertifiable piece of hardware can be more secure. reply ongy 18 hours agorootparentFIPS certification doesn&#x27;t make something more secure. Just more certified.It&#x27;s incredibly slow to adapt to new technology.fTPM has a different attack surface, and protects against this specific attack. It&#x27;s most likely better than dTPM for hardware based attacks, but there&#x27;s known attacks as well reply monocasa 18 hours agorootparentprevBecause security isn&#x27;t certifications. reply als0 17 hours agoparentprevfTPMs (firmware TPMs) are also very bad advice, because they have been remotely exploited using only software techniques. reply gquere 16 hours agorootparentOTOH they can be patched and to exploit them locally you either need software code exec or do a physical side-channel attack which is miles beyond a simple bus snooping. reply 0xDEF 15 hours agoprevNow that the TPM has been proven to be security theater Microsoft should drop the TPM requirement for Windows 11 and allow older machines to upgrade.My previous job let me keep their 2016 laptop with an Intel i7 CPU, 32 GB RAM, and 512 GB SSD. Wonderful little bedtime laptop that is stuck on Windows 10. reply salad-tycoon 15 hours agoprev [–] Deleted replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author presents a method for bypassing the BitLocker encryption on a Lenovo laptop using a low-cost logic analyzer.",
      "The architecture of BitLocker and the storage of the encryption key in the TPM are explained.",
      "The process of capturing and decoding the TPM exchange to retrieve the encryption key is detailed, along with limitations of the method and recommendations for improved security."
    ],
    "commentSummary": [
      "The discussion focuses on the vulnerabilities and limitations of Microsoft's Bitlocker encryption on Lenovo laptops.",
      "Users express concerns about the security of TPMs and the potential for attacks.",
      "Topics also include the default settings of Bitlocker, the importance of backup recovery keys, and the feasibility of intercepting encryption keys.",
      "Other encryption systems like fTPM and LUKS are mentioned.",
      "Discussions touch on signal processing and decoding methods, as well as the limitations of using a discrete TPM.",
      "The conversation also covers SSD firmware-based encryption, hardware certifications, and TPM requirements in operating systems like Windows 11."
    ],
    "points": 327,
    "commentCount": 138,
    "retryCount": 0,
    "time": 1692889376
  },
  {
    "id": 37256817,
    "title": "The human Y chromosome has been completely sequenced",
    "originLink": "https://www.nature.com/articles/s41586-023-06457-y",
    "originBody": "Your Privacy We use cookies to make sure that our website works properly, as well as some optional cookies to personalise content and advertising, provide social media features and analyse how people use our site. By accepting some or all optional cookies you give consent to the processing of your personal data, including transfer to third parties, some in countries outside of the European Economic Area that do not offer the same data protection standards as the country where you live. You can decide which optional cookies to accept by clicking on \"Manage preferences\", where you can also find more information about how your personal data is processed. Further information can be found in our privacy policy. Accept all cookies Manage preferences Skip to main content Advertisement View all journals Search Log in Explore content About the journal Publish with us Subscribe Sign up for alerts RSS feed nature articles article Article Published: 23 August 2023 The complete sequence of a human Y chromosome Arang Rhie, Sergey Nurk, Monika Cechova, Savannah J. Hoyt, Dylan J. Taylor, Nicolas Altemose, Paul W. Hook, Sergey Koren, Mikko Rautiainen, Ivan A. Alexandrov, Jamie Allen, Mobin Asri, Andrey V. Bzikadze, Nae-Chyun Chen, Chen-Shan Chin, Mark Diekhans, Paul Flicek, Giulio Formenti, Arkarachai Fungtammasan, Carlos Garcia Giron, Erik Garrison, Ariel Gershman, Jennifer L. Gerton, Patrick G. S. Grady, …Adam M. Phillippy Show authors Nature (2023)Cite this article 1645 Accesses 1238 Altmetric Metrics details Abstract The human Y chromosome has been notoriously difficult to sequence and assemble because of its complex repeat structure that includes long palindromes, tandem repeats and segmental duplications1,2,3. As a result, more than half of the Y chromosome is missing from the GRCh38 reference sequence and it remains the last human chromosome to be finished4,5. Here, the Telomere-to-Telomere (T2T) consortium presents the complete 62,460,029-base-pair sequence of a human Y chromosome from the HG002 genome (T2T-Y) that corrects multiple errors in GRCh38-Y and adds over 30 million base pairs of sequence to the reference, showing the complete ampliconic structures of gene families TSPY, DAZ and RBMY; 41 additional protein-coding genes, mostly from the TSPY family; and an alternating pattern of human satellite 1 and 3 blocks in the heterochromatic Yq12 region. We have combined T2T-Y with a previous assembly of the CHM13 genome4 and mapped available population variation, clinical variants and functional genomics data to produce a complete and comprehensive reference sequence for all 24 human chromosomes. This is a preview of subscription content, access via your institution Access options Access through your institution Access Nature and 54 other Nature Portfolio journals Get Nature+, our best-value online-access subscription $29.99 / 30 days cancel any time Learn more Subscribe to this journal Receive 51 print issues and online access $199.00 per year only $3.90 per issue Learn more Rent or buy this article Prices vary by article type from$1.95 to$39.95 Learn more Prices may be subject to local taxes which are calculated during checkout Additional access options: Log in Learn about institutional subscriptions Read our FAQs Contact customer support Data availability The T2T-CHM13v2.0 (T2T-CHM13+Y) assembly, reference analysis set, complete list of resources—including gene annotation, repeat annotation, epigenetic profiles, variant-calling results from 1KGP and SGDP, gnomAD, ClinVar, GWAS and dbSNP datasets—are available for download at https://github.com/marbl/CHM13. The assembly is also available from NCBI and EBI with GenBank accession GCA_009914755.4. Annotation and associated resources are also browsable as ‘hs1’ from the UCSC Genome Browser (http://genome.ucsc.edu/cgi-bin/hgTracks?db=hub_3671779_hs1), the Ensembl Genome Browser (https://projects.ensembl.org/hprc/) (assembly name T2T-CHM13v2.0) and NCBI data-hub (https://www.ncbi.nlm.nih.gov/data-hub/genome/GCF_009914755.1/). Potential assembly issues are listed and can be tracked at https://github.com/marbl/CHM13-issues. 1KGP and SGDP short-read alignments and variant calls are available within AnVIL at https://anvil.terra.bio/#workspaces/anvil-datastorage/AnVIL_T2T_CHRY. Original data from the Gerton lab underlying this manuscript can be accessed from the Stowers Original Data Repository at http://www.stowers.org/research/publications/libpb-2358. Sequencing data used in this study are listed in Supplementary Table 1. Code availability Custom codes developed for data analysis and visualization are available at https://github.com/arangrhie/T2T-HG002Y, https://github.com/snurk/sg_sandbox and https://github.com/schatzlab/t2t-chm13-chry and are deposited with Zenodo159. Software and parameters used are stated in the Supplementary Methods with further details. References Skaletsky, H. et al. The male-specific region of the human Y chromosome is a mosaic of discrete sequence classes. Nature 423, 825–837 (2003). Article ADS CAS PubMed Google Scholar Miga, K. H. et al. Centromere reference models for human chromosomes X and Y satellite arrays. Genome Res. 24, 697–707 (2014). Article CAS PubMed PubMed Central Google Scholar Vollger, M. R. et al. Segmental duplications and their variation in a complete human genome. Science 376, eabj6965 (2022). Article CAS PubMed PubMed Central Google Scholar Nurk, S. et al. The complete sequence of a human genome. Science 376, 44–53 (2022). Article ADS CAS PubMed PubMed Central Google Scholar Schneider, V. A. et al. Evaluation of GRCh38 and de novo haploid genome assemblies demonstrates the enduring quality of the reference assembly. Genome Res. 27, 849–864 (2017). Article CAS PubMed PubMed Central Google Scholar Gustafson, M. L. & Donahoe, P. K. Male sex determination: current concepts of male sexual differentiation. Annu. Rev. Med. 45, 505–524 (1994). Article CAS PubMed Google Scholar Vog, P. H. et al. Human Y chromosome azoospermia factors (AZF) mapped to different subregions in Yq11. Hum. Mol. Genet. 5, 933–943 (1996). Article Google Scholar Miga, K. H. et al. Telomere-to-telomere assembly of a complete human X chromosome. Nature 585, 79–84 (2020). Article ADS CAS PubMed PubMed Central Google Scholar Logsdon, G. A. et al. The structure, function and evolution of a complete human chromosome 8. Nature 593, 101–107 (2021). Article ADS CAS PubMed PubMed Central Google Scholar Wenger, A. M. et al. Accurate circular consensus long-read sequencing improves variant detection and assembly of a human genome. Nat. Biotechnol. 37, 1155–1162 (2019). Article CAS PubMed PubMed Central Google Scholar Jain, M. et al. Nanopore sequencing and assembly of a human genome with ultra-long reads. Nat. Biotechnol. 36, 338–345 (2018). Article CAS PubMed PubMed Central Google Scholar Nurk, S. et al. HiCanu: accurate assembly of segmental duplications, satellites, and allelic variants from high-fidelity long reads. Genome Res. 30, 1291–1305 (2020). Article CAS PubMed PubMed Central Google Scholar Rautiainen, M. & Marschall, T. GraphAligner: rapid and versatile sequence-to-graph alignment. Genome Biol. 21, 253 (2020). Article PubMed PubMed Central Google Scholar Formenti, G. et al. Merfin: improved variant filtering, assembly evaluation and polishing via k-mer validation. Nat. Methods 19, 696–704 (2022). Article CAS PubMed PubMed Central Google Scholar Kirsche, M. et al. Jasmine and Iris: population-scale structural variant comparison and analysis. Nat. Methods 20, 408–417 (2023). Article CAS PubMed Google Scholar Jain, C., Rhie, A., Hansen, N. F., Koren, S. & Phillippy, A. M. Long-read mapping to repetitive reference sequences using Winnowmap2. Nat. Methods 19, 705–710 (2022). Article CAS PubMed Google Scholar Mc Cartney, A. M. et al. Chasing perfection: validation and polishing strategies for telomere-to-telomere genome assemblies. Nat. Methods 19, 687–695 (2022). Article Google Scholar Rhie, A., Walenz, B. P., Koren, S. & Phillippy, A. M. Merqury: reference-free quality, completeness, and phasing assessment for genome assemblies. Genome Biol. 21, 245 (2020). Article CAS PubMed PubMed Central Google Scholar Wang, T. et al. The Human Pangenome Project: a global resource to map genomic diversity. Nature 604, 437–446 (2022). Article ADS CAS PubMed PubMed Central Google Scholar Jarvis, E. D. et al. Semi-automated assembly of high-quality diploid human reference genomes. Nature 611, 519–531 (2022). Article ADS CAS PubMed PubMed Central Google Scholar Shumate, A. et al. Assembly and annotation of an Ashkenazi human reference genome. Genome Biol. 21, 129 (2020). Article CAS PubMed PubMed Central Google Scholar Zook, J. M. et al. Extensive sequencing of seven human genomes to characterize benchmark reference materials. Sci. Data 3, 160025 (2016). Article CAS PubMed PubMed Central Google Scholar Landrum, M. J. et al. ClinVar: improvements to accessing data. Nucleic Acids Res. 48, D835–D844 (2020). Article CAS PubMed Google Scholar Welter, D. et al. The NHGRI GWAS Catalog, a curated resource of SNP-trait associations. Nucleic Acids Res. 42, D1001–D1006 (2014). Article CAS PubMed Google Scholar Smigielski, E. M., Sirotkin, K., Ward, M. & Sherry, S. T. dbSNP: a database of single nucleotide polymorphisms. Nucleic Acids Res. 28, 352–355 (2000). Article CAS PubMed PubMed Central Google Scholar Karczewski, K. J. et al. The mutational constraint spectrum quantified from variation in 141,456 humans. Nature 581, 434–443 (2020). Article ADS CAS PubMed PubMed Central Google Scholar Byrska-Bishop, M. et al. High-coverage whole-genome sequencing of the expanded 1000 Genomes Project cohort including 602 trios. Cell 185, 3426–3440 (2022). Article CAS PubMed PubMed Central Google Scholar Mallick, S. et al. The Simons Genome Diversity Project: 300 genomes from 142 diverse populations. Nature 538, 201–206 (2016). Article ADS CAS PubMed PubMed Central Google Scholar Dunham, I. et al. An integrated encyclopedia of DNA elements in the human genome. Nature 489, 57–74 (2012). Article ADS CAS Google Scholar Ebert, P. et al. Haplotype-resolved diverse human genomes and integrated analysis of structural variation. Science 372, eabf7117 (2021). Article CAS PubMed PubMed Central Google Scholar Sanders, A. D. et al. Single-cell analysis of structural variations and complex rearrangements with tri-channel processing. Nat. Biotechnol. 38, 343–354 (2020). Article CAS PubMed Google Scholar Hallast, P. et al. Assembly of 43 human Y chromosomes reveals extensive complexity and variation. Nature https://doi.org/10.1038/s41586-023-06425-6 (2023). Hammer, M. F. et al. Extended Y chromosome haplotypes resolve multiple and unique lineages of the Jewish priesthood. Hum. Genet. 126, 707 (2009). Article CAS PubMed PubMed Central Google Scholar Poznik, G. D. et al. Punctuated bursts in human male demography inferred from 1,244 worldwide Y-chromosome sequences. Nat. Genet. 48, 593–599 (2016). Article CAS PubMed PubMed Central Google Scholar Vegesna, R., Tomaszkiewicz, M., Medvedev, P. & Makova, K. D. Dosage regulation, and variation in gene expression and copy number of human Y chromosome ampliconic genes. PLoS Genet. 15, e1008369 (2019). Article CAS PubMed PubMed Central Google Scholar NCBI RefSeq v110 Browser. Homo sapiens isolate NA24385 chromosome Y, alternate assembly T2T-CHM13v2.0. https://tinyurl.com/bdfudexn (2022). Hoyt, S. J. et al. From telomere to telomere: the transcriptional and epigenetic state of human repeat elements. Science 376, eabk3112 (2022). Article CAS PubMed PubMed Central Google Scholar Warburton, P. E. et al. Analysis of the largest tandemly repeated DNA families in the human genome. BMC Genomics 9, 533 (2008). Article PubMed PubMed Central Google Scholar Halabian, R. & Makałowski, W. A map of 3′ DNA transduction variants mediated by non-LTR retroelements on 3202 human genomes. Biology 11, 1032 (2022). Article CAS PubMed PubMed Central Google Scholar Weissensteiner, M. H. et al. Accurate sequencing of DNA motifs able to form alternative (non-B) structures. Genome Res. 33, 907-922 (2023). Tyler-Smith, C., Taylor, L. & Müller, U. Structure of a hypervariable tandemly repeated DNA sequence on the short arm of the human Y chromosome. J. Mol. Biol. 203, 837–848 (1988). Article CAS PubMed Google Scholar Xue, Y. & Tyler-Smith, C. An exceptional gene: evolution of the TSPY gene family in humans and other great apes. Genes 2, 36–47 (2011). Article CAS PubMed PubMed Central Google Scholar Saxena, R. et al. Four DAZ genes in two clusters found in the AZFc region of the human Y chromosome. Genomics 67, 256–267 (2000). Article CAS PubMed Google Scholar Altemose, N. et al. Complete genomic and epigenetic maps of human centromeres. Science 376, eabl4178 (2022). Article CAS PubMed PubMed Central Google Scholar Jain, M. et al. Linear assembly of a human centromere on the Y chromosome. Nat. Biotechnol. 36, 321–323 (2018). Article CAS PubMed PubMed Central Google Scholar Gershman, A. et al. Epigenetic patterns in a complete human genome. Science 376, eabj5089 (2022). Article CAS PubMed PubMed Central Google Scholar Kasinathan, S. & Henikoff, S. Non-B-form DNA is enriched at centromeres. Mol. Biol. Evol. 35, 949–962 (2018). Article CAS PubMed PubMed Central Google Scholar Nailwal, M. & Chauhan, J. B. Azoospermia factor C subregion of the Y chromosome. J. Hum. Reprod. Sci. 10, 256 (2017). Article CAS PubMed PubMed Central Google Scholar Kuroda-Kawaguchi, T. et al. The AZFc region of the Y chromosome features massive palindromes and uniform recurrent deletions in infertile men. Nat. Genet. 29, 279–286 (2001). Article CAS PubMed Google Scholar Repping, S. et al. A family of human Y chromosomes has dispersed throughout northern Eurasia despite a 1.8-Mb deletion in the azoospermia factor c region. Genomics 83, 1046–1052 (2004). Article CAS PubMed Google Scholar Porubsky, D. et al. Recurrent inversion polymorphisms in humans associate with genetic instability and genomic disorders. Cell 185, 1986–2005 (2022). Article CAS PubMed PubMed Central Google Scholar Teitz, L. S., Pyntikova, T., Skaletsky, H. & Page, D. C. Selection has countered high mutability to preserve the ancestral copy number of Y chromosome amplicons in diverse human lineages. Am. J. Hum. Genet. 103, 261–275 (2018). Article CAS PubMed PubMed Central Google Scholar Jobling, M. A. Copy number variation on the human Y chromosome. Cytogenet. Genome Res. 123, 253–262 (2008). Article CAS PubMed Google Scholar Navarro-Costa, P., Plancha, C. E. & Gonçalves, J. Genetic dissection of the AZF regions of the human Y chromosome: thriller or filler for male (in)fertility? Biomed Res. Int. 2010, e936569 (2010). Google Scholar Evans, H. J., Gosden, J. R., Mitchell, A. R. & Buckland, R. A. Location of human satellite DNAs on the Y chromosome. Nature 251, 346–347 (1974). Article ADS CAS Google Scholar Schmid, M., Guttenbach, M., Nanda, I., Studer, R. & Epplen, J. T. Organization of DYZ2 repetitive DNA on the human Y chromosome. Genomics 6, 212–218 (1990). Article CAS PubMed Google Scholar Manz, E., Alkan, M., Bühler, E. & Schmidtke, J. Arrangement of DYZ1 and DYZ2 repeats on the human Y-chromosome: a case with presence of DYZ1 and absence of DYZ2. Mol. Cell. Probes 6, 257–259 (1992). Article CAS PubMed Google Scholar Altemose, N. A classical revival: human satellite DNAs enter the genomics era. Semin. Cell Dev. Biol. 128, 2–14 (2022). Article CAS PubMed Google Scholar Gripenberg, U. Size variation and orientation of the human Y chromosome. Chromosoma 15, 618–629 (1964). Article CAS PubMed Google Scholar Mathias, N., Bayés, M. & Tyler-Smith, C. Highly informative compound haplotypes for the human Y chromosome. Hum. Mol. Genet. 3, 115–123 (1994). Article CAS PubMed Google Scholar Altemose, N., Miga, K. H., Maggioni, M. & Willard, H. F. Genomic characterization of large heterochromatic gaps in the human genome assembly. PLoS Comput. Biol. 10, e1003628 (2014). Article ADS PubMed PubMed Central Google Scholar Cooke, H. Repeated sequence specific to human males. Nature 262, 182–186 (1976). Article ADS CAS PubMed Google Scholar Frommer, M., Prosser, J. & Vincent, P. C. Human satellite I sequences include a male specific 2.47 kb tandemly repeated unit containing one Alu family member per repeat. Nucleic Acids Res. 12, 2887–2900 (1984). Article CAS PubMed PubMed Central Google Scholar Babcock, M., Yatsenko, S., Stankiewicz, P., Lupski, J. R. & Morrow, B. E. AT-rich repeats associated with chromosome 22q11.2 rearrangement disorders shape human genome architecture on Yq12. Genome Res. 17, 451–460 (2007). Article CAS PubMed PubMed Central Google Scholar Webster, T. H. et al. Identifying, understanding, and correcting technical artifacts on the sex chromosomes in next-generation sequencing data. GigaScience 8, giz074 (2019). Article PubMed PubMed Central Google Scholar Aganezov, S. et al. A complete reference genome improves analysis of human genetic variation. Science 376, eabl3533 (2022). Article CAS PubMed PubMed Central Google Scholar Bekritsky, M. A., Colombo, C. & Eberle, M. A. Identifying genomic regions with high quality single nucleotide variant calling. Illumina https://www.illumina.com/content/illumina-marketing/amr/en_US/science/genomics-research/articles/identifying-genomic-regions-with-high-quality-single-nucleotide-.html (2023). Breitwieser, F. P., Pertea, M., Zimin, A. V. & Salzberg, S. L. Human contamination in bacterial genomes has created thousands of spurious proteins. Genome Res. 29, 954–960 (2019). Article CAS PubMed PubMed Central Google Scholar Steinegger, M. & Salzberg, S. L. Terminating contamination: large-scale search identifies more than 2,000,000 contaminated entries in GenBank. Genome Biol. 21, 115 (2020). Article CAS PubMed PubMed Central Google Scholar Chrisman, B. et al. The human “contaminome”: bacterial, viral, and computational contamination in whole genome sequences from 1000 families. Sci. Rep. 12, 9863 (2022). Article ADS CAS PubMed PubMed Central Google Scholar Kent, W. J. et al. The Human Genome Browser at UCSC. Genome Res. 12, 996–1006 (2002). Article CAS PubMed PubMed Central Google Scholar Rautiainen, M. et al. Telomere-to-telomere assembly of diploid chromosomes with Verkko. Nat. Biotechnol. https://doi.org/10.1038/s41587-023-01662-6 (2023). Liao, W.-W. et al. A draft human pangenome reference. Nature 617, 312–324 (2023). Article ADS CAS PubMed PubMed Central Google Scholar Jiang, Z., Hubley, R., Smit, A. & Eichler, E. E. DupMasker: a tool for annotating primate segmental duplications. Genome Res. 18, 1362–1368 (2008). Article CAS PubMed PubMed Central Google Scholar Vollger, M. R., Kerpedjiev, P., Phillippy, A. M. & Eichler, E. E. StainedGlass: interactive visualization of massive tandem repeat structures with identity heatmaps. Bioinformatics 38, 2049–2051 (2022). Article CAS PubMed PubMed Central Google Scholar Skene, P. J. & Henikoff, S. An efficient targeted nuclease strategy for high-resolution mapping of DNA binding sites. eLife 6, e21856 (2017). Article PubMed PubMed Central Google Scholar Robinson, J. T. et al. Integrative genomics viewer. Nat. Biotechnol. 29, 24–26 (2011). Article CAS PubMed PubMed Central Google Scholar Shafin, K. et al. Nanopore sequencing and the Shasta toolkit enable efficient de novo assembly of eleven human genomes. Nat. Biotechnol. 38, 1044–1053 (2020). Article CAS PubMed PubMed Central Google Scholar Koren, S. et al. De novo assembly of haplotype-resolved genomes with trio binning. Nat. Biotechnol. 36, 1174–1182 (2018). Article CAS Google Scholar Kolmogorov, M., Yuan, J., Lin, Y. & Pevzner, P. A. Assembly of long, error-prone reads using repeat graphs. Nat. Biotechnol. 37, 540–546 (2019). Article CAS PubMed Google Scholar Poplin, R. et al. A universal SNP and small-indel variant caller using deep neural networks. Nat. Biotechnol. 36, 983–987 (2018). Article CAS PubMed Google Scholar Shafin, K. et al. Haplotype-aware variant calling with PEPPER-Margin-DeepVariant enables high accuracy in nanopore long-reads. Nat. Methods 18, 1322–1332 (2021). Article CAS PubMed PubMed Central Google Scholar Sedlazeck, F. J. et al. Accurate detection of complex structural variations using single molecule sequencing. Nat. Methods 15, 461–468 (2018). Article CAS PubMed PubMed Central Google Scholar Jiang, T. et al. Long-read-based human genomic structural variation detection with cuteSV. Genome Biol. 21, 189 (2020). Article CAS PubMed PubMed Central Google Scholar Bzikadze, A. V., Mikheenko, A. & Pevzner, P. A. Fast and accurate mapping of long reads to complete genome assemblies with VerityMap. Genome Res. 32, 2107–2118 (2022). Article PubMed PubMed Central Google Scholar Li, H. & Durbin, R. Fast and accurate short read alignment with Burrows–Wheeler transform. Bioinformatics 25, 1754–1760 (2009). Article CAS PubMed PubMed Central Google Scholar Porubsky, D. et al. breakpointR: an R/Bioconductor package to localize strand state changes in Strand-seq data. Bioinformatics 36, 1260–1261 (2020). Article CAS PubMed Google Scholar PacBio Revio WGS Dataset. Homo sapiens – GIAB trio HG002-4. https://downloads.pacbcloud.com/public/revio/2022Q4/ (2022). Poznik, D. yhaploIdentifying Y-chromosome haplogroups. GitHub https://github.com/23andMe/yhaplo (2022). Tseng, B. et al. Y-SNP Haplogroup Hierarchy Finder: a web tool for Y-SNP haplogroup assignment. J. Hum. Genet. 67, 487–493 (2022). Article CAS PubMed Google Scholar Li, H. Minimap2: pairwise alignment for nucleotide sequences. Bioinformatics 34, 3094–3100 (2018). Article CAS PubMed PubMed Central Google Scholar Li, H. Identifying centromeric satellites with dna-brnn. Bioinformatics 35, 4408–4410 (2019). Article CAS PubMed PubMed Central Google Scholar Harris, R. S. Improved Pairwise Alignmnet of Genomic DNA (Pennsylvania State Univ., 2007). Morgulis, A., Gertz, E. M., Schäffer, A. A. & Agarwala, R. WindowMasker: window-based masker for sequenced genomes. Bioinformatics 22, 134–141 (2006). Article CAS PubMed Google Scholar Chin, C.-S. et al. Multiscale analysis of pangenomes enables improved representation of genomic diversity for repetitive and clinically relevant genes. Nat. Methods https://doi.org/10.1038/s41592-023-01914-y (2023). Frankish, A. et al. GENCODE 2021. Nucleic Acids Res. 49, D916–D923 (2021). Article CAS PubMed Google Scholar Armstrong, J. et al. Progressive Cactus is a multiple-genome aligner for the thousand-genome era. Nature 587, 246–251 (2020). Article ADS CAS PubMed PubMed Central Google Scholar Kovaka, S. et al. Transcriptome assembly from long-read RNA-seq alignments with StringTie2. Genome Biol. 20, 278 (2019). Article CAS PubMed PubMed Central Google Scholar Stanke, M., Diekhans, M., Baertsch, R. & Haussler, D. Using native and syntenically mapped cDNA alignments to improve de novo gene finding. Bioinformatics 24, 637–644 (2008). Article CAS PubMed Google Scholar Fiddes, I. T. et al. Comparative Annotation Toolkit (CAT)—simultaneous clade and personal genome annotation. Genome Res. 28, 1029–1038 (2018). Article CAS PubMed PubMed Central Google Scholar Shumate, A. & Salzberg, S. L. Liftoff: accurate mapping of gene annotations. Bioinformatics 37, 1639–1643 (2021). Article CAS PubMed PubMed Central Google Scholar Dale, R. K., Pedersen, B. S. & Quinlan, A. R. Pybedtools: a flexible Python library for manipulating genomic datasets and annotations. Bioinformatics 27, 3423–3424 (2011). Article CAS PubMed PubMed Central Google Scholar Rhie, A. et al. Towards complete and error-free genome assemblies of all vertebrate species. Nature 592, 737–746 (2021). Article ADS CAS PubMed PubMed Central Google Scholar Pruitt, K. D. et al. RefSeq: an update on mammalian reference sequences. Nucleic Acids Res. 42, D756–D763 (2014). Article CAS PubMed Google Scholar Kapustin, Y., Souvorov, A., Tatusova, T. & Lipman, D. Splign: algorithms for computing spliced alignments with identification of paralogs. Biol. Direct 3, 20 (2008). Article PubMed PubMed Central Google Scholar Katoh, K. & Standley, D. M. MAFFT multiple sequence alignment software version 7: improvements in performance and usability. Mol Biol Evol. 30, 772-80 (2013). Slater, G. S. C. & Birney, E. Automated generation of heuristics for biological sequence comparison. BMC Bioinformatics 6, 31 (2005). Article PubMed PubMed Central Google Scholar Zook, J. M. et al. Integrating human sequence data sets provides a resource of benchmark SNP and indel genotype calls. Nat. Biotechnol. 32, 246–251 (2014). Article CAS PubMed Google Scholar Numanagić, I. et al. Fast characterization of segmental duplications in genome assemblies. Bioinformatics 34, i706–i714 (2018). Article PubMed PubMed Central Google Scholar Benson, G. Tandem repeats finder: a program to analyze DNA sequences. Nucleic Acids Res. 27, 573–580 (1999). Article CAS PubMed PubMed Central Google Scholar Arian, F. A. S., Hubley, R. & Green, P. RepeatMasker Open-4.0 2013-2015. http://www.repeatmasker.org (2015). Storer, J., Hubley, R., Rosen, J., Wheeler, T. J. & Smit, A. F. The Dfam community resource of transposable element families, sequence models, and genome annotations. Mob. DNA 12, 2 (2021). Article CAS PubMed PubMed Central Google Scholar Olson, D. & Wheeler, T. ULTRA: a model based tool to detect tandem repeats. ACM BCB 2018, 37–46 (2018) Quinlan, A. R. & Hall, I. M. BEDTools: a flexible suite of utilities for comparing genomic features. Bioinformatics 26, 841–842 (2010). Article CAS PubMed PubMed Central Google Scholar Storer, J. M., Hubley, R., Rosen, J. & Smit, A. F. A. Curation guidelines for de novo generated transposable element families. Curr. Protoc. 1, e154 (2021). Article PubMed PubMed Central Google Scholar Kent, W. J. BLAT—the BLAST-like alignment tool. Genome Res. 12, 656–664 (2002). CAS PubMed PubMed Central Google Scholar Szak, S. T. et al. Molecular archeology of L1 insertions in the human genome. Genome Biol. 3, research0052.1 (2002). Article Google Scholar Altschul, S. F., Gish, W., Miller, W., Myers, E. W. & Lipman, D. J. Basic local alignment search tool. J. Mol. Biol. 215, 403–410 (1990). Article CAS PubMed Google Scholar Cer, R. Z. et al. Searching for non-B DNA-forming motifs using nBMST (non-B DNA motif search tool). Curr. Protoc. Hum. Genet. 73, 18.7.1–18.7.22 (2012). Google Scholar Zou, X. et al. Short inverted repeats contribute to localized mutability in human somatic cells. Nucleic Acids Res. 45, 11213–11221 (2017). Article CAS PubMed PubMed Central Google Scholar Svetec Miklenić, M. et al. Size-dependent antirecombinogenic effect of short spacers on palindrome recombinogenicity. DNA Repair 90, 102848 (2020). Article PubMed Google Scholar Sahakyan, A. B. et al. Machine learning model for sequence-driven DNA G-quadruplex formation. Sci. Rep. 7, 14535 (2017). Article ADS PubMed PubMed Central Google Scholar Hao, Z. et al. RIdeogram: drawing SVG graphics to visualize and map genome-wide data on the idiograms. PeerJ Comput. Sci. 6, e251 (2020). Article PubMed PubMed Central Google Scholar Dotmatics. GraphPad Prism v.9.1.0 for Windows. https://www.graphpad.com (16 March 2021). Vollger, M. R. SafFire. GitHub https://github.com/mrvollger/SafFire (2022). Pendleton, A. L. et al. Comparison of village dog and wolf genomes highlights the role of the neural crest in dog domestication. BMC Biol. 16, 64 (2018). Article PubMed PubMed Central Google Scholar Hach, F. et al. mrsFAST: a cache-oblivious algorithm for short-read mapping. Nat. Methods 7, 576–577 (2010). Article CAS PubMed PubMed Central Google Scholar Escalona, M. et al. Whole-genome sequence and assembly of the Javan gibbon (Hylobates moloch). J. Hered. 114, 35–43 (2023). Article PubMed Google Scholar Cortez, D. et al. Origins and functional evolution of Y chromosomes across mammals. Nature 508, 488–493 (2014). Article ADS CAS PubMed Google Scholar Stamatakis, A. RAxML version 8: a tool for phylogenetic analysis and post-analysis of large phylogenies. Bioinformatics 30, 1312–1313 (2014). Article CAS PubMed PubMed Central Google Scholar Dotmatics. Geneious v2019.2.3. https://www.geneious.com/ (2019). Rambaut et al. FigTree v1.4.4. http://tree.bio.ed.ac.uk/software/figtree/ (2018). Tyler-Smith, C. & Brown, W. R. A. Structure of the major block of alphoid satellite DNA on the human Y chromosome. J. Mol. Biol. 195, 457–470 (1987). Article CAS PubMed Google Scholar Shepelev, V. A. et al. Annotation of suprachromosomal families reveals uncommon types of alpha satellite organization in pericentromeric regions of hg38 human genome assembly. Genomics Data 5, 139–146 (2015). Article CAS PubMed PubMed Central Google Scholar Lee, I. et al. Simultaneous profiling of chromatin accessibility and methylation on human cell lines with nanopore sequencing. Nat. Methods 17, 1191–1199 (2020). Article CAS PubMed PubMed Central Google Scholar Krumsiek, J., Arnold, R. & Rattei, T. Gepard: a rapid and sensitive tool for creating dotplots on genome scale. Bioinformatics 23, 1026–1028 (2007). Article CAS PubMed Google Scholar Rice, P., Longden, I. & Bleasby, A. EMBOSS: The European Molecular Biology Open Software Suite. Trends Genet. 16, 276–277 (2000). Article CAS PubMed Google Scholar Sun, C. et al. Deletion of azoospermia factor a (AZFa) region of human Y chromosome caused by recombination between HERV15 proviruses. Hum. Mol. Genet. 9, 2291–2296 (2000). Article CAS PubMed Google Scholar Lassmann, T. Kalign 3: multiple sequence alignment of large datasets. Bioinformatics 36, 1928–1929 (2020). Article CAS Google Scholar Wheeler, T. J. & Eddy, S. R. nhmmer: DNA homology search with profile HMMs. Bioinformatics 29, 2487–2489 (2013). Article CAS PubMed PubMed Central Google Scholar Stephens, Z. D. et al. Simulating next-generation sequencing datasets from empirical mutation and sequencing models. PLoS ONE 11, e0167047 (2016). Article PubMed PubMed Central Google Scholar Bushnell, B. BBMap: a fast, accurate, splice-aware aligner. OSTI.gov https://www.osti.gov/biblio/1241166 (2017). Aken, B. L. et al. Ensembl 2017. Nucleic Acids Res. 45, D635–D642 (2017). Article CAS PubMed Google Scholar Poznik, G. D. et al. Sequencing Y chromosomes resolves discrepancy in time to common ancestor of males versus females. Science 341, 562–565 (2013). Article ADS CAS PubMed PubMed Central Google Scholar McKenna, A. et al. The Genome Analysis Toolkit: a MapReduce framework for analyzing next-generation DNA sequencing data. Genome Res. 20, 1297–1303 (2010). Article CAS PubMed PubMed Central Google Scholar Schatz, M. C. et al. Inverting the model of genomics data sharing with the NHGRI Genomic Data Science Analysis, Visualization, and Informatics Lab-space. Cell Genomics 2, 100085 (2022). Article CAS PubMed PubMed Central Google Scholar Danecek, P. et al. Twelve years of SAMtools and BCFtools. GigaScience 10, giab008 (2021). Article PubMed PubMed Central Google Scholar Talenti, A. & Prendergast, J. nf-LO: a scalable, containerized workflow for genome-to-genome lift over. Genome Biol. Evol. 13, evab183 (2021). Article PubMed PubMed Central Google Scholar Guarracino, A., Mwaniki, N., Marco-Sola, S., & Garrison, E. wfmash: whole-chromosome pairwise alignment using the hierarchical wavefront algorithm. GitHub https://github.com/ekg/wfmash (2021). Sherry, S. T., Ward, M. & Sirotkin, K. dbSNP—database for single nucleotide polymorphisms and other classes of minor genetic variation. Genome Res. 9, 677–679 (1999). Article CAS PubMed Google Scholar Landrum, M. J. et al. ClinVar: improving access to variant interpretations and supporting evidence. Nucleic Acids Res. 46, D1062–D1067 (2018). Article CAS PubMed Google Scholar Buniello, A. et al. The NHGRI-EBI GWAS Catalog of published genome-wide association studies, targeted arrays and summary statistics 2019. Nucleic Acids Res. 47, D1005–D1012 (2019). Article CAS PubMed Google Scholar Van der Auwera G. A. & O’Connor B. D. Genomics in the Cloud: Using Docker, GATK, and WDL in Terra (O’Reilly Media, 2020). Langmead, B. & Salzberg, S. L. Fast gapped-read alignment with Bowtie 2. Nat. Methods 9, 357–359 (2012). Article CAS PubMed PubMed Central Google Scholar Ramírez, F. et al. deepTools2: a next generation web server for deep-sequencing data analysis. Nucleic Acids Res. 44, W160–W165 (2016). Article PubMed PubMed Central Google Scholar Zhao, H. et al. CrossMap: a versatile tool for coordinate conversion between genome assemblies. Bioinformatics 30, 1006–1007 (2014). Article PubMed Google Scholar Marçais, G. et al. MUMmer4: a fast and versatile genome alignment system. PLoS Comput. Biol. 14, e1005944 (2018). Article PubMed PubMed Central Google Scholar Ondov, B. D., Bergman, N. H. & Phillippy, A. M. Interactive metagenomic visualization in a Web browser. BMC Bioinformatics 12, 385 (2011). Article PubMed PubMed Central Google Scholar Rhie, A. Repositories for the analysis of T2T-Y and T2T-CHM13v2.0. Zenodo https://doi.org/10.5281/zenodo.8136598 (2023). Falconer, E. et al. DNA template strand sequencing of single-cells maps genomic rearrangements at high resolution. Nat. Methods 9, 1107–1112 (2012). Article CAS PubMed PubMed Central Google Scholar Download references Acknowledgements We thank P. Hallast, M. C. Loftus, M. K. Konkel, P. Ebert, T. Marschall and C. Lee for coordination and discussions, J.C.-I. Lee for sharing the GRCh38-Y coordinates used in Y-Finder and members of the Telomere-to-Telomere consortium and HPRC for constructive feedback. This work utilized the computational resources of the National Institutes of Health (NIH) HPC Biowulf cluster (https://hpc.nih.gov). Computational resources were partially provided by the e-INFRA CZ project (no. 90140), supported by the Ministry of Education, Youth and Sports of the Czech Republic and Computational Biology Core, Institute for Systems Genomics, University of Connecticut. Certain commercial equipment, instruments and materials are identified to specify adequately experimental conditions or reported results. Such identification does not imply recommendation or endorsement by the NIST, nor does it imply that the equipment, instruments or materials identified are necessarily the best available for the purpose. We thank the Intramural Research Program of NHGRI, NIH no. HG200398 (A.R., S.N., S.K., M.R., A.M.M., B.P.W. and A.M.P.); NIH no. GM123312 (S.J.H., P.G.S.G., G.A.H. and R.J.O.); NIH no. GM130691 (P.M., M.H.W. and K.D.M.); HHMI Hanna Gray Fellowship (N.A.); NIH no. CA266339 (J.G. and T.P.); NIH no. GM147352 (G.A.L.); NIH nos. HG002939 and HG010136 (R.M.H. and J.M.S.); NIH no. HG009190 (P.W.H., A. Gershman and W.T.); NIH nos. HG010263, HG006620 and CA253481 and NSF no. DBI-1627442 (M.C.S.); NIH no. GM136684 (K.D.M.); NIH nos. HG011274 and HG010548 (K.H.M.); NIH nos. HG010961 and HG010040 (H.L.); NIH no. HG007234 (M.D.); NIH no. HG011758 (F.J.S.); NIH no. DA047638 (E.G.); NIH no. GM124827 (M.A.W.); NIH no. GM133747 (R.C.M.); NIH no. CA240199 (R.J.O.); NIH nos. HG002385, HG010169 and HG010971 (E.E.E.); Stowers Institute for Medical Research (J.L.G. and T.P.); National Center for Biotechnology Information of the National Library of Medicine, NIH (F.T.-N. and T.D.M.); intramural funding at NIST (J.M.Z.); NIST no. 70NANB20H206 (M.J.); and NIH nos. HG010972 and WT222155/Z/20/Z and the European Molecular Biology Laboratory (J.A., P.F., C.G.G., L.H., T.H., S.E.H., F.J.M. and L.S.). RNA generation was supported by NIST no. 70NANB21H101 and NIH no. 1S10OD028587; the Ministry of Science and Higher Education of the Russian Federation, St. Petersburg State University, no. PURE 73023672 (I.A.A.); the Computation, Bioinformatics, and Statistics Predoctoral Training Program awarded to Penn State by the NIH (A.C.W.); and Achievement Rewards for College Scientists Foundation, The Graduate College at Arizona State University (A.M.T.O.). E.E.E. is an investigator for HHMI. Author information Author notes Sergey Nurk Present address: Oxford Nanopore Technologies Inc., Oxford, UK Ivan A. Alexandrov Present address: Department of Anatomy and Anthropology and Department of Human Molecular Genetics and Biochemistry, Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv-Yafo, Israel These authors contributed equally: Arang Rhie, Sergey Nurk, Monika Cechova, Savannah J. Hoyt, Dylan J. Taylor Authors and Affiliations Genome Informatics Section, Computational and Statistical Genomics Branch, National Human Genome Research Institute, National Institutes of Health, Bethesda, MD, USA Arang Rhie, Sergey Nurk, Sergey Koren, Mikko Rautiainen, Nancy F. Hansen, Ann M. Mc Cartney, Brian P. Walenz & Adam M. Phillippy Faculty of Informatics, Masaryk University, Brno, Czech Republic Monika Cechova Department of Biomolecular Engineering, University of California Santa Cruz, Santa Cruz, CA, USA Monika Cechova, Julian K. Lucas, Brandy M. McNulty, Hugh E. Olsen & Karen H. Miga Department of Molecular and Cell Biology, University of Connecticut, Storrs, CT, USA Savannah J. Hoyt, Patrick G. S. Grady, Gabrielle A. Hartley & Rachel J. O’Neill Department of Biology, Johns Hopkins University, Baltimore, MD, USA Dylan J. Taylor, Rajiv C. McCoy, Michael E. G. Sauria & Michael C. Schatz Department of Molecular and Cell Biology, University of California, Berkeley, CA, USA Nicolas Altemose Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, USA Paul W. Hook, Ariel Gershman, Jakob Heinz, Alaina Shumate & Winston Timp Federal Research Center of Biotechnology of the Russian Academy of Sciences, Moscow, Russia Ivan A. Alexandrov Center for Algorithmic Biotechnology, Saint Petersburg State University, St Petersburg, Russia Ivan A. Alexandrov & Alla Mikheenko European Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus, Hinxton, Cambridge, UK Jamie Allen, Paul Flicek, Carlos Garcia Giron, Leanne Haggerty, Thibaut Hourlier, Sarah E. Hunt, Fergal J. Martin & Likhitha Surapaneni UC Santa Cruz Genomics Institute, University of California Santa Cruz, Santa Cruz, CA, USA Mobin Asri, Mark Diekhans, Marina Haukness, Julian K. Lucas, Brandy M. McNulty, Hugh E. Olsen & Karen H. Miga Graduate Program in Bioinformatics and Systems Biology, University of California, San Diego, CA, USA Andrey V. Bzikadze Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA Nae-Chyun Chen, Samantha Zarate & Michael C. Schatz GeneDX Holdings Corp, Stamford, CT, USA Chen-Shan Chin Foundation of Biological Data Science, Belmont, CA, USA Chen-Shan Chin Department of Genetics, University of Cambridge, Cambridge, UK Paul Flicek The Rockefeller University, New York, NY, USA Giulio Formenti DNAnexus, Inc., Mountain View, CA, USA Arkarachai Fungtammasan Department of Genetics, Genomics and Informatics, University of Tennessee Health Science Center, Memphis, TN, USA Erik Garrison & Andrea Guarracino Stowers Institute for Medical Research, Kansas City, MO, USA Jennifer L. Gerton & Tamara Potapova University of Kansas Medical Center, Kansas City, MO, USA Jennifer L. Gerton Genomics Research Centre, Human Technopole, Milan, Italy Andrea Guarracino Institute of Bioinformatics, Faculty of Medicine, University of Münster, Münster, Germany Reza Halabian & Wojciech Makalowski Cancer Genetics and Comparative Genomics Branch, National Human Genome Research Institute, National Institutes of Health, Bethesda, MD, USA Nancy F. Hansen Department of Biology, Pennsylvania State University, University Park, PA, USA Robert Harris, Marta Tomaszkiewicz, Allison C. Watwood, Matthias H. Weissensteiner & Kateryna D. Makova Department of Genome Sciences, University of Washington School of Medicine, Seattle, WA, USA William T. Harvey, Alexandra P. Lewis, Glennis A. Logsdon, Katherine M. Munson, David Porubsky, Mitchell R. Vollger & Evan E. Eichler Institute for Systems Biology, Seattle, WA, USA Robert M. Hubley & Jessica M. Storer XDBio Program, Johns Hopkins University, Baltimore, MD, USA Stephen Hwang Department of Bioengineering, Department of Physics, Northeastern University, Boston, MA, USA Miten Jain Human Genome Sequencing Center, Baylor College of Medicine, One Baylor Plaza, Houston, TX, USA Rupesh K. Kesharwani, Luis F. Paulin, Fritz J. Sedlazeck & Yiming Zhu Department of Data Sciences, Dana-Farber Cancer Institute, Boston, MA, USA Heng Li Department of Biomedical Informatics, Harvard Medical School, Boston, MA, USA Heng Li Genome Technology Access Center at the McDonnell Genome Institute, Washington University, St. Louis, MO, USA Christopher Markovic Biosystems and Biomaterials Division, National Institute of Standards and Technology, Gaithersburg, MD, USA Jennifer McDaniel, Nathan D. Olson & Justin M. Zook Department of Computer Science and Engineering, Pennsylvania State University, University Park, PA, USA Paul Medvedev Department of Biochemistry and Molecular Biology, Pennsylvania State University, University Park, PA, USA Paul Medvedev Center for Computational Biology and Bioinformatics, Pennsylvania State University, University Park, PA, USA Paul Medvedev UCL Queen Square Institute of Neurology, UCL, London, UK Alla Mikheenko National Center for Biotechnology Information, National Library of Medicine, National Institutes of Health, Bethesda, MD, USA Terence D. Murphy & Françoise Thibaud-Nissen Masters Program in National Research University Higher School of Economics, Moscow, Russia Fedor Ryabov Departments of Biomedical Engineering, Computer Science, and Biostatistics, Johns Hopkins University, Baltimore, MD, USA Steven L. Salzberg Department of Computer Science, Rice University, Houston, TX, USA Fritz J. Sedlazeck Google Inc., Mountain View, CA, USA Kishwar Shafin Institute of Molecular Genetics, Moscow, Russia Valery A. Shepelev Center for Evolution and Medicine, School of Life Sciences, Arizona State University, Tempe, AZ, USA Angela M. Taravella Oill & Melissa A. Wilson Department of Biomedical Engineering, Pennsylvania State University, State College, PA, USA Marta Tomaszkiewicz Pacific Biosciences, Menlo Park, CA, USA Aaron M. Wenger Investigator, Howard Hughes Medical Institute, University of Washington, Seattle, WA, USA Evan E. Eichler Institute for Systems Genomics, University of Connecticut, Storrs, CT, USA Rachel J. O’Neill Department of Genetics and Genome Sciences, UConn Health, Farmington, CT, USA Rachel J. O’Neill Contributions V.A.S. is retired from the Institute of Molecular Genetics. Assembly was carried out by S.N., S.K. and M.R. Validation was performed by A.R., S.K., M.A., A.V.B., G.F., A.F., A.M.M., J.M., A.M., L.F.P., D.P., F.J.S., K.S., P.M., J.M.Z. and K.D.M. ChrY haplogroups were determined by A.R. and A.C.W. Alignment was done by C.-S.C., M.D., R. Harris, M.R.V. and K.D.M. Satellite annotation was performed by N.A., I.A.A., G.A.L., F.R., V.A.S. and K.H.M. N.A., J.G. and T.P. carried out FISH. Repeat annotation was done by S.J.H., P.G.S.G., G.A.H., R.M.H., J.M.S. and R.J.O. Retro-elements were dealt with by R. Halabian and W.M. Non-B DNA was dealt with by M.H.W. and K.D.M. Gene annotation was undertaken by A.R., M.D., P.F., C.G.G., L.H., M.H., J.H., T.H., F.J.M., T.D.M., S.L.S., A.S. and F.T.-N. A.R., R. Harris, W.T.H., P.M., M.T. and K.D.M. dealt with ampliconic genes. Structural annotation was performed by A.R., M.C., H.L., P.M. and K.D.M. Epigenetic analysis was performed by A.R., P.W.H., A. Gershman, W.T. and A.M.W. Mappability was performed by A.M.T.O., M.A.W. and J.M.Z. Non-B DNA was dealt with by M.H.W. and K.D.M. Variants and liftover were carried out by A.R., D.J.T., S.K., J.A., N.-C.C., M.D., E.G., A. Guarracino, N.F.H., W.T.H., S.E.H., S.H., R.C.M., N.D.O., M.E.G.S., L.S., M.R.V., S.Z., J.M.Z., E.E.E. and A.M.P. A.R., S.L.S., B.P.W. and A.M.P. dealt with contamination. Data generation was carried out by M.J., R.K.K., A.P.L., J.K.L., C.M., B.M.M., K.M.M., H.E.O., F.J.S. and Y.Z. Data management was undertaken by A.R., M.D., M.J. and J.K.L. Computational resources were sourced by R.J.O., M.C.S. and A.M.P. A.R., S.N., M.C., S.J.H., D.J.T., N.A., I.A.A., N.-C.C., E.G., J.G., P.G.S.G., A. Guarracino, R. Halabian, W.M., J.M., T.P., F.R., S.L.S., J.M.S., A.M.T.O., A.C.W., M.A.W., S.Z., J.M.Z., E.E.E., R.J.O., M.C.S., K.H.M., K.D.M. and A.M.P. wrote the manuscript draft. A.R. and A.M.P. edited the manuscript, with the assistance of all authors. J.M.Z., E.E.E., R.J.O., M.C.S., K.H.M., K.D.M. and A.M.P. supervised the research. Conceptualization was the responsibility of A.R., S.N., M.C., E.E.E., K.H.M., K.D.M. and A.M.P. Corresponding author Correspondence to Adam M. Phillippy. Ethics declarations Competing interests S.N. is now an employee of ONT. S.K. has received travel funding for speaking at events hosted by ONT. A.F. is an employee of DNAnexus. C.-S.C. is an employee of GeneDX Holdings Corp. N.-C.C. is an employee of Exai Bio. L.F.P. receives research support from Genetech. F.J.S. receives research support from Pacific Biosciences, ONT, Illumina and Genetech. K.S. is an employee of Google LLC and owns Alphabet stock as part of the standard compensation package. W.T. has two patents (nos. 8,748,091 and 8,394,584) licensed to ONT. E.E.E. is a scientific advisory board member of Variant Bio, Inc. The remaining authors declare no competing interests. Peer review Peer review information Nature thanks John Lovell, Mikkel Heide Schierup and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available. Additional information Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Extended data figures and tables Extended Data Fig. 1 Assembling the X and Y chromosomes of HG002. a. Chromosome X and Y components of the assembly string graph built from HiFi reads, detected based on node sequence alignments to T2T-CHM13 and GRCh38 references. Each node is colored according to the excess of paternal-specific (blue) and maternal-specific (red) k-mers, obtained from parental Illumina reads, indicating if they exclusively belong to chromosome Y or X, respectively. Most complicated tangles are localized within the heterochromatic satellite region on the Y q-arm. The X and Y subgraphs are connected in PAR1 and PAR2. Graph discontinuities are due to a lack of HiFi sequence coverage in these regions caused by contextual sequencing bias, with 9 out of 11 observed breaks falling within PAR1 on either chromosome (5 out of 5 for chromosome Y). Note that for visualization purposes the length of shorter nodes is artificially increased making the extent of the tangles appear larger than reality. b. The effects of manual pruning and semi-automated ONT read integration is illustrated from top to bottom. Top, zoomed in view of a tangle encoding the P1–P3 palindromic region in Y (approx. 22.86–27.08 Mb, see Fig. 4). Middle, corresponding subgraph following the manual pruning and recompaction. Nodes excluded from the curated “single-copy” list for automated ONT-based repeat resolution are shown in yellow. Three hairpin structures are highlighted, which form almost-perfect inverted tandem repeats encompassing the entire P3 and two P2 (red) palindromes. Node outlines in the palindromes are colored according to the palindromic arms as in Fig. 4. Bottom, corresponding subgraph following the repeat resolution using ONT read-to-graph alignments. Remaining ambiguities were resolved by evaluating ONT read alignments to all candidate reconstructions of the corresponding sub-regions. c. PAR1 subgraph labeled with HiFi read coverage on each node. Gaps (green edges) and uneven node coverage estimates indicate biases in HiFi sequencing across the region. Figure 1 shows an enrichment of SINE repeats and non-B DNA motifs in PAR1 that may underlie the sequencing gaps in this region. Extended Data Fig. 2 Validation and polishing of the T2T-Y. a. Evaluation and polishing workflow performed on T2T-CHM13v1.1 autosomes + HG002 XY assemblies. b. Venn diagram of the k-mers from the parents and child. On the left, hap-mers18 represent haplotype specific k-mers inherited by the child. The darker outlined circle inside the child k-mers represent single-copy k-mers (k-mers occurring once in the assembly and single-copy in the child’s genome). Right figure shows an example of the paternal specific, “single-copy” and “marker” k-mers. The marker set includes both multi-copy and single-copy k-mers specific to the paternal haplotype that were inherited by the child. Unlike polishing the nearly haploid CHM13 assembly17, both single-copy k-mers and marker k-mers were used for the marker-assisted alignments to HG002 XY. This helped align more reads within repetitive regions to the correct chromosome for evaluation during polishing. Right panel shows counts of the k-mers and coverage of HiFi and ONT reads using the marker-assisted Winnowmap2 alignment, in addition to alignments from VerityMap, which uses locally unique k-mers for anchoring the reads. c. Aggregated Strand-seq coverage profile across all 65 libraries on GRCh38-Y (top) and T2T-Y (bottom). Each bar represents read counts in every 20 kb bin supporting the reference in forward direction (light green) or reverse direction (dark green). Multiple spikes in reverse direction (black asterisks) in GRCh38-Y indicate inversion polymorphisms relative to HG002, likely due to differences between the haplogroups. Such spikes in coverage are not observed on T2T-X and T2T-Y, which confirm the structural and directional accuracy of the HG002 assemblies. A 3 kb inversion of the unique sequence between the P5 palindromic arms was identified as erroneous in T2T-Y (red asterisk), but was confirmed to be polymorphic in the population and left uncorrected in this version of the assembly. Extended Data Fig. 3 Large structural differences between T2T-Y and previous GRCh Y assemblies. a-b. Ampliconic genes and X-degenerate sequences revealed from alignments between GRCh38-Y (Y-axis) and T2T-Y (X-axis). a. Dotplot generated using LastZ93 after softmasking with WindowMasker94. b. Identity was computed from matches and mismatches over positions with alignments, excluding gaps. c. Structural differences revealed using PRG-TK95 against GRCh38-Y and GRCh37-Y in the euchromatic region of the Y chromosome. Extended Data Fig. 4 Repeat discovery and annotation of T2T-Y. a. Assembly completion allowed for a full assessment of repeats and resulted in the identification of previously unknown satellite arrays (predominantly in the PAR1) and subunit repeats that fall within one of three composite repeat units (TSPY, RBMY, DAZ). b. Ideogram of TE density (per 100 kb bin). This is an extension of Fig. 1 with non-SINEs expanded into separate TE classes (SVA, LTR, LINE, DNA/RC). Density scale ranges from low (white, zero) to high (black, relative to total density) and sequence classes are denoted by color. c. Summary (in terms of base coverage per region) across all five TE classes and two specific families: Alu/SINE and L1/LINE. The satellites in (b) were kept separate as two categories; Cen/Sat as the left satellite block including alpha satellites and DYZ19, while all other categories were combined per sequence classes. Extended Data Fig. 5 Non-B DNA motifs along the T2T-Y. HSat3 on the Yq and satellite sequences around the centromere are more enriched with A-phased repeats, direct repeats and STRs, while HSat1B is more enriched with inverted repeats and mirror repeats. Enrichment of non-B DNA sequences were also observed in the PAR region. Notably, the TSPY gene array is enriched for G4 and Z-DNA motifs, as shown in Extended Data Fig. 6b. Extended Data Fig. 6 Phylogenetic tree analysis of the ampliconic TSPY gene family and pattern of non-B DNA structure. a. Phylogenetic tree analysis using protein-coding TSPYs from a Sumatran Orangutan (Pongo abelii) and a Silvery gibbon (Hylobates moloch) as outgroups confirmed TSPY2 (distal to the array) and TSPY copies within the array originated from the same branch, distinguished from the rest of the TSPY pseudogenes. Rectangular inset shows a cartoon representation of the simplified tree. Numbers next to the triangles indicate the number of TSPY genes in the same branch. b. G4 and Z-DNA structures predicted for a typical TSPY copy inside the TSPY array. All TSPY copies in the array have the same signature, with one G4 peak present ~500 bases upstream of the TSPY (arrow). Higher Quadron score122 (Q-score) indicates a more stable G4 structure, with scores over 19 considered stable (dotted line). Extended Data Fig. 7 Recurrent inversions identified with Strand-seq. a. Five out of 15 individuals have the inverted variant as present in HG002 at the P3 palindrome (white arrow). Although inversions across P1–P2 (yellow and red arrows) are difficult to confirm with Strand-seq because of the high sequence similarity between the palindromic arms, different orientations are observable in these samples. b. Strand states for 65 Strand-seq libraries of HG002. Depending on the mappings of directional Strand-seq reads (+ reads: ‘Crick’, C, – reads: ‘Watson’, W), reference sequence was assigned in three states: WC, WW, and CC. WC, roughly equal mixture of plus and minus reads; WW, all reads mapped in minus orientation; CC, all reads mapped in plus orientation. Changes in strand state along a single chromosome are normally caused by a double-strand-break (DSBs) that occurred during DNA replication160 in a random fashion and we refer to them as sister-chromatid-exchanges (SCEs, yellow thunderbolts). Recurrent change in strand state over the same region in multiple Strand-seq cells indicates misassembly. Similarly, collapsed or incomplete assembly of a certain genomic region will result in a recurrent strand state change as observed for GRCh38-Y (black arrowheads). In contrast, T2T-Y shows strand state changes randomly distributed along each Strand-seq library with no evidence of misassembly or collapse. c. Strand-seq profile of selected libraries over T2T-Y summarized in bins (bin size: 500 kb, step size: 50 kb). Teal, Crick read counts; orange, Watson read counts. As ChrY is haploid, reads are expected to map only in Watson or Crick orientation. Light gray rectangles highlight regions where SCEs were detected in the heterochromatic Yq12 despite a lower coverage of Strand-seq reads. A modified breakpointR parameter was used (windowsize = 500000 minReads = 20) in order to refine detected SCEs presented in panel b and c. Extended Data Fig. 8 Satellite annotation and recent expansion events in the Yq heterochromatin. a. A plot showing the top repeat periodicities detected by NTRprism44 in 50 kb blocks tiled across T2T-Y, with centromeric satellite annotations overlaid on the X axis. Large arrays are labeled with their historic nomenclature1, HSat subfamilies61, and predominant repeat periodicities. b. An exact 2000-mer match dotplot of the Yq region (a dot is plotted when an identical 2000 base sequence is found at positions X and Y). The lower triangle has DYZ1/DYZ2 annotations overlaid as yellow and blue bars, respectively. Circled patterns in the upper triangle correspond to recent iterative duplication events, which are illustrated below the X axis. c. A reconstruction of a possible sequence of recent iterative duplications that could explain the observed dotplot patterns. d. A 2000-mer dotplot comparison of two ~800 kb HSat1B sub-arrays that were part of a recent large duplication event, along with self-self comparisons of the same arrays, revealing sites of more recent and smaller-scale deletions and expansions (annotated in yellow and red, with a possible sequence of events illustrated by the schematic on the right). Extended Data Fig. 9 Genomic similarity in PARs and XTR and improved MAPQ of the PARs through informed sex chromosome complement reference. a. Dotplots from LASTZ alignments of the CHM13-X, HG002-X, and HG002-Y (T2T-Y) over 96% sequence identity. Dashed gray lines represent the start and end of the approximate PARs or XTR boundaries. Disconnected diagonal lines indicate the presence of genomic diversity between each paired region. More genomic differences are observed in the PAR1 between the HG002-Y and CHM13-X. b-c. Average mapping quality (MAPQ) across GRCh38-X from simulated reads of an XX (b) and XY (c) sample. Top, a default version of GRCh38 (with two copies of identical PARs on XY). Middle, a version of GRCh38 informed on the sex chromosome complement (SCC) of the sample (entire Y hard-masked for the XX sample vs. only PARs on the Y hard-masked for the XY sample). Bottom, the difference in average MAPQ between the SCC and default approaches. MAPQ was averaged in 50 kb windows, sliding 10 kb across the chromosome. A positive value means MAPQ score is higher with SCC reference alignment compared to default alignment. Extended Data Fig. 10 Number of variants called from 1KGP and SGDP individuals. a. More variants are called on the X-PARs when using the sex chromosome complement reference approach (calling variants in diploid mode on PARs) than the non-masked approach (calling variants in haploid mode on PARs). The 1KGP results for GRCh38-Y are from Aganezov et al.66, which was performed on CHM13v1.0+GRCh38-Y. b. Num. of variants called from each 1KGP XY sample on chromosome GRCh38-Y and T2T-Y c. Num. of variants called in the syntenic region between the two Ys. A large num. of additional variants are called on each sample attributed to the newly added, non-syntenic sequences on T2T-Y. Within the syntenic regions, a reduction in the number of variants is observed for each population except for samples from R1 haplogroups as shown in Fig. 6c. d. Aggregated total number of variants for the 279 SGDP samples per chromosome. e. SGDP genome-wide counts of variants per-sample (n = 279) demonstrate increased variation in African samples regardless of reference. Each bar in the box plot represents the 1st, 2nd (median), and 3rd quartile of the number of variants in each population. Whiskers are bound to the 1.5 × interquartile range. Data outside of the whisker ranges are shown as dots. For the SGDP samples, variants were called using T2T-CHM13+Y or GRCh38 as the reference. All variants shown in this figure were filtered for “high quality (PASS)”. Extended Data Fig. 11 Human contaminants in bacterial reference genomes. a. Number of distinct RefSeq accessions in every 10 kb window containing 64-mers of GRCh38-Y (top), T2T-Y (middle), and in T2T-Y only (bottom). Here, RefSeq sequences with more than 20 64-mers or matching over 10% of the Y chromosome are included. b. Length distribution of the sequences from (a) in log scale. Majority of the shorter (<1 kb) sequences contain 64-mers found in HSat1B or HSat3. c. Number of bacterial RefSeq entries by strain identified to contain sequences of T2T-Y and not GRCh38-Y, visualized with Krona158. Supplementary information Supplementary Information This file contains Supplementary Methods, Figs. 1–19 and Notes 1–4. Reporting Summary Peer Review File Supplementary Tables This file contains Supplementary Tables 1–32. Supplementary Data This file contains Supplementary Data 1–3. Rights and permissions Reprints and Permissions About this article Cite this article Rhie, A., Nurk, S., Cechova, M. et al. The complete sequence of a human Y chromosome. Nature (2023). https://doi.org/10.1038/s41586-023-06457-y Download citation Received 02 December 2022 Accepted 19 July 2023 Published 23 August 2023 DOI https://doi.org/10.1038/s41586-023-06457-y Subjects Chromosomes Genetic variation Genome Genome informatics Genomics Comments By submitting a comment you agree to abide by our Terms and Community Guidelines. If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate. Access through your institution Buy or subscribe Sections Figures References Abstract Data availability Code availability References Acknowledgements Author information Ethics declarations Peer review Additional information Extended data figures and tables Supplementary information Rights and permissions About this article Comments Advertisement Nature (Nature) ISSN 1476-4687 (online) ISSN 0028-0836 (print) nature.com sitemap About Nature Portfolio About us Press releases Press office Contact us Discover content Journals A-Z Articles by subject Nano Protocol Exchange Nature Index Publishing policies Nature portfolio policies Open access Author & Researcher services Reprints & permissions Research data Language editing Scientific editing Nature Masterclasses Live Expert Trainer-led workshops Research Solutions Libraries & institutions Librarian service & tools Librarian portal Open research Recommend to library Advertising & partnerships Advertising Partnerships & Services Media kits Branded content Career development Nature Careers Nature Conferences Nature events Regional websites Nature Africa Nature China Nature India Nature Italy Nature Japan Nature Korea Nature Middle East Privacy Policy Use of cookies Your privacy choices/Manage cookies Legal notice Accessibility statement Terms & Conditions Your US state privacy rights © 2023 Springer Nature Limited",
    "commentLink": "https://news.ycombinator.com/item?id=37256817",
    "commentBody": "The human Y chromosome has been completely sequencedHacker NewspastloginThe human Y chromosome has been completely sequenced (nature.com) 320 points by birriel 8 hours ago| hidepastfavorite143 comments 10g1k 7 hours agoFor those who don&#x27;t recall: Back in the Dark Ages, there was a race to decode the human genome. The leading competitiors (wealthiest) were Celera Genomics and the Human Genome Project. After some time, Celera (headed by Craig Venter), announced they had done the deed. However, what Celera had actually done was used what they called a \"shotgun method\", which meant they took small samples here and there, then built a model of the genome with various statistical shenanigans. About five years later, after all the hype, they admitted they had not sequenced the entire genome.Ref: https:&#x2F;&#x2F;www.technologyreview.com&#x2F;2007&#x2F;09&#x2F;04&#x2F;223919&#x2F;craig-ven... reply jhbadger 5 hours agoparentAs noted, the shotgun sequencing wasn&#x27;t any worse than the traditional chromosome walking method used by the other human genome project, and neither created a truly complete sequence, which is only possible today with improvements in technology.And it is worth noting that despite all the critiques of shotgun sequencing at the time as \"cheating\", chromosome walking sequencing is dead, and shotgun is what we use today. If anything replaces that it will be long read technology like that done by Oxford Nanopore sequencing, although we aren&#x27;t really there yet (you still need to assemble that data and don&#x27;t really get end-to-end sequences yet). reply kazinator 3 hours agorootparentI feel a joke coming on.Mother: \"Amy, dear, you hardly touched any of your vegetables. Most of them are still on your plate.\"Amy: \"That&#x27;s not true, Mom; I completely sequenced them into my tummy using the shotgun method.\" reply udkl 3 hours agorootparentSomeone submit this to smbc comics ! reply dekhn 6 hours agoparentprevYes, but the HGP didn&#x27;t make a full sequence either, using their scaffold-based contig assembly. Both groups declared a truce and announced they were \"finished with the first draft\"35 years ago: https:&#x2F;&#x2F;www.nytimes.com&#x2F;1987&#x2F;12&#x2F;13&#x2F;magazine&#x2F;the-genome-proje...33 years ago: https:&#x2F;&#x2F;www.nytimes.com&#x2F;1990&#x2F;06&#x2F;05&#x2F;science&#x2F;great-15-year-pro...29 years ago: the competition gets fierce https:&#x2F;&#x2F;www.nytimes.com&#x2F;1994&#x2F;02&#x2F;22&#x2F;science&#x2F;scientist-at-work...24 years ago: the race is alive! https:&#x2F;&#x2F;www.nytimes.com&#x2F;1999&#x2F;03&#x2F;23&#x2F;science&#x2F;who-ll-sequence-h...23 years ago: draft is complete https:&#x2F;&#x2F;archive.nytimes.com&#x2F;www.nytimes.com&#x2F;library&#x2F;national...20 years ago: https:&#x2F;&#x2F;www.nytimes.com&#x2F;2003&#x2F;04&#x2F;15&#x2F;science&#x2F;once-again-scient...2 years ago: https:&#x2F;&#x2F;archive.nytimes.com&#x2F;www.nytimes.com&#x2F;library&#x2F;national...The celera approach using shotgun was tricky because assembling the bits required a great deal of computational finesse and horsepower; \"The final assembly computations were run on Compaq’s new AlphaServer GS160 because the algorithms and data required 64 gigabytes of shared memory to run successfully.\"At the time the GS160 was the monster machine, a classic big iron UNIX, which could be tightly clustered- unified IO&#x2F;filesystem between all the machines. The primary author of the shotgun assembly was Gene Myers, who previously had written BLAST, and invented the Suffix Array with Udi Manber.The public project had its own issues, as many of the teams assigned to work on it still had the \"cottage industry&#x2F;artisinal&#x2F;academic\" approach, then Eric Lander came along and turned it into an industrial process, and parlayed that into running the Broad Institute, a privately funded MIT&#x2F;Harvard research institute in Boston.These days petabytes of sequence data are generated every day and stored in clouds. The genome has been a fundamental tool for shaping our studies of humans, although its true potential for understanding complex phenotypes remains elusive. reply jghn 5 hours agorootparentLets not forget how Perl Saved The Human Genome Project [1], which I remember seeing in a print magazine at the time.As someone who is in the genomics world now as a software person, I find it amusing that I&#x27;ve gotten more into perl over the last year or so. It has its place, in the way that grep&#x2F;sed&#x2F;awk&#x2F;etc does.[1] https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=30327812 reply dekhn 5 hours agorootparentLincoln Stein is great, and perl was certainly critical to many processes, but it was and remains fairly niche in genomics, which used much more C++, Java, and later Python.IMHO the person who \"saved the genome project\" was WJ Kent, who developed the assembler, BLAT, that the public project needed. I strive to point out that he wasn&#x27;t a sole hero, nor was Lincoln. What I really like about BLAT is that while Celera was using Big Iron UNIX (massive 64-bit 64GB machines with 10s of terabytes of central high performance storage), BLAT ran on a cluster of linux machines, right around the time that people were waking up to the fact that linux was becoming a useful tool for scientific data processing. BLAT&#x27;s design allowed it to work on a cluster of cheaper&#x2F;smaller machines, while celera&#x27;s algorithm really needed a massive shared memory single machine. it was sort of a microcosm of the larger battle being fought between Big iron UNIX and little intel linux at the time. reply ryandv 4 hours agorootparentI had the privilege of working a co-op term at Stein&#x27;s lab at the OICR. I encountered quite a bit of Perl during my short time there, and have yet to see it elsewhere in the modern enterprise tech world. BioPerl in particular stands out as a fairly substantial project in the bioinformatics space. reply jghn 5 hours agorootparentprevI agree from the human genome sequencing perspective and the superlatives of saving the HGP. But at the time I was a standard software dev who thought the topic was cool, as was this new fan dangled language named perl.However, I got into the genomics world in the early aughts, and the perl hung on and on and on. I remember starting a new job in the mid-teens, and one of the first tasks I had was to port over a legacy perl script. Such is the world of scientific software. 99% of the people I know who have touched perl since ~2003ish are in the bioinformatics space. reply iten 5 hours agorootparentprevSmall correction: BLAT is a local alignment tool Jim Kent also wrote. I think his assembler you&#x27;re referring to is GigAssembler (https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC311095&#x2F;). reply jfoutz 5 hours agorootparentprevI know hn isn&#x27;t the place for memes, but, I&#x27;m obligated. Imagine what they could do with a beowulf cluster of pentium pros? reply epistasis 5 hours agorootparentThere was a NYTimes profile at the time of Kent&#x27;s efforts, and they IIRC literally got the UC Santa Cruz administration to hand over desktop computers destined to go to various people for a few months to assemble into a cluster. So it was likely a bunch of pentium pros or similar. Not a Beowulf cluster, of course, but whatever clustering software Kent had hand rolled out of C for the purpose. reply jacquesm 3 hours agorootparentprevThey weren&#x27;t using pentium pros, they were using Alpha&#x27;s because the memory interconnect between a beowulf cluster of pentium pros would be orders of magnitude slower. So likely &#x27;the same, but much slower&#x27;. reply jfoutz 3 hours agorootparentoh, ha. yeah, that was sort of the root of the joke. companies like Celera, or whoever had the money would write a (large) check for big iron.smaller organizations were realizing they could get slower computers power pretty cheap, and they could get a whole lot of them. There was a little flurry of activity with flocking algorithms, objective-c had a little renaissance due to swarm computing. probably the most famous and lasting was map-reduce, from alphabet, but they were called google back then.there were a bunch of clever little tricks, like channel bonded network cards to make multiple cards look like one fast card, so you could double or triple bandwidth.The beowulf cluster joke was kind of the spirit of the scrappy, make something cool out of junk approach while calling companies like sun, hp, compaq dinosaurs. and it continued for a while with people building stuff like this - https:&#x2F;&#x2F;ncsa30.ncsa.illinois.edu&#x2F;2003&#x2F;05&#x2F;ncsa-creates-sony-p... I think there was some weirdness with export controls of ps2&#x27;s for this kind of stuff.I don&#x27;t remember what pc chip was the new hotness back then, it was a good 20 years ago and my memory is dim.but that, I think, captures the gist of the meme. reply jghn 5 hours agorootparentprevI feel like this is the one domain where the beowfulf cluster meme is still funny reply dotancohen 1 hour agorootparentprevnext [–]> The primary author of the shotgun assembly was Gene MyersNo conflict of interest there! reply sublinear 5 hours agorootparentprev> The primary author of the shotgun assembly was Gene Myers, who previously had written BLAST...So... um... BLAST processing? reply mola 4 minutes agoprevDumb question: what does it mean to sequence \"the\" X?I presume our DNA are not identical. So do they sequence a particular person&#x27;s Y chromosome? Who&#x27;s?How similar are two Y chromosomes from different persons? reply space_fountain 6 hours agoprevAs I understand it this was hard because most mechanisms we have for sequencing genes work by first splitting large sequences of genes into random chunks and sequencing each chunk individually. These chunks then need arranged properly to form the entire genome. This is possible at all because we can get overlap between the chunks, but when a sequence has repeating sections overlap still isn’t enough to stitch everything together correctly. There’s also a newer technique involving nano pores. The dna is literally pulled through a little hole and the electrical properties change depending on which base pair is inside the pore, sadly it’s liable to errors in a deterministic way depending on the sequence. I don’t have access to the full paper so I’m not quite sure what was done here, but I have heard people talk about combining the two approaches above reply jakobnissen 3 hours agoparentThey relied mainly on PacBio HiFi reads (which I think is a truly understated revolutionary technology in genomics), then used Nanopore sequencing to link together the HiFi contigs to cover the truly gnarly regions of the chromosome.And yeah, you&#x27;re right: All modern large-scale sequencing is shotgun sequencing where the DNA is randomly broken up, each fragment is sequenced, and then the individual segments (reads) are assembled using a genome assembler. reply jshorty 7 hours agoprevCould someone explain exactly what it means to be \"completely sequence\" the human genome when all humans have distinct genetic makeup (ie, different sequences of nucleobases in their DNA&#x2F;RNA)? reply diekhans 3 hours agoparentWe really should say \"a human genome\". Reference genomes serve as a Rosetta Stone of genomics. So we can take DNA&#x2F;RNA sequences from other individuals and align (pattern match) them to the reference as a way of understanding and comparing individuals.It is not perfect, as a references can be missing or have large variability in DNA regions. The goal of the Human Pangenome Reference Consortium (HPRC) https:&#x2F;&#x2F;humanpangenome.org&#x2F; is to sequence individuals from different populations to address this issue. We are also working to develop new computation models to support analysis of data across populations. reply dekhn 6 hours agoparentprevThe public Human Genome Project used a group of people but most of the sequence library was derived from a single individual in Buffalo, NY. The celera project also used a group of people but it was mostly Venter&#x27;s genomehttps:&#x2F;&#x2F;www.nytimes.com&#x2F;2002&#x2F;04&#x2F;27&#x2F;us&#x2F;scientist-reveals-secr...I believe more recent sequencing projects have used a wider pool of individuals. I think some projects pool all the individuals and sequence them together, while others sequence each individual separately. This isn&#x27;t really so much of a problem since the large-scale structure is highly similar across all humans and we have developed sophisticated approaches to model the variations in individuals, see https:&#x2F;&#x2F;www.biomedcentral.com&#x2F;collections&#x2F;graphgenomes for an explanation of the \"graph structure\" used to reprsent alternatives in the reference, which can include individual single nucleobase differences, as well as more complex ones such as large deletions in one individual, to rearrangements and even inversions. reply pdonis 7 hours agoparentprevThey mean they have obtained the complete sequence for a particular Y chromosome that is considered to be a \"reference\" chromosome. This is similar to what was done for all the other chromosomes. reply chihuahua 7 hours agoparentprevI&#x27;ve never understood this either. I assume the genome is many megabytes of [ATCG]+. If we have that sequence, what does it tell us? Do we look at it and say \"Ah, yes, ...ATGCTACGACTACGACTAGCG... very interesting?\" reply jiggawatts 7 hours agorootparentMany genes are highly conserved or consistent enough. E.g.: if there&#x27;s a 1% difference between two people, then it&#x27;s a bit like two very unique sentences that have a couple of small typos. They&#x27;re sill recognisable, and it&#x27;s also still pretty obvious that they&#x27;re the \"same\".A gene sequence allows researchers to determine the amino acids that are coded for, and from those, which proteins match which genes.This can be matched up with genetic diseases. If you know that damage to a certain location in a chromosome causes a problem with a certain biological process, then ergo, the associated protein is needed for that process!So: genetic illness -> gene sequence -> protein -> role in the bodyWithout sequencing, that chain can&#x27;t be built. reply dclowd9901 4 hours agorootparentBut you can only know that by having a large sample of very “stable” (have few genetic irregularities) gene samples compared to a large pool of samples from people with very narrow and pronounced gene irregularities, right?Is this why it’s so hard? This feels more like a healthcare records keeping people and less like an “actually reading the data problem”.I can’t help but feel like some form of single payer healthcare is truly the way out of this problem. One where all disease record keeping is uniform and complete. reply Earw0rm 3 hours agorootparentSingle payer healthcare here (UK) is still subject to privacy controls in a way which would make it very difficult to do that.(Also our health system&#x27;s IT is a hellscape, but one reason for that is that people would literally rather not have a working system at all, than one with less than impeccable privacy controls.Personally I&#x27;d gladly sacrifice a fair bit of medical privacy in return for giving scientists greater insight into disease processes, but the average citizen here wants advanced healthcare without giving their data to research scientists. &#x2F;facepalm ) reply spookie 1 hour agorootparentI trust the scientists, the problem isn&#x27;t them. Look at the whole abortion data scandal in the U.S. reply bglazer 6 hours agorootparentprevIt’s actually about 3 gigabases (ATCG). There are some recurrent features of the genome whose function we’ve worked out. For example the TATA box is a classic sequence that typically indicates the start of a part of the genome that codes for a protein. The vast majority of the genome doesn’t code for proteins. The function of these genome regions are much more murky. Some of these regions function like scaffolds for proteins to assemble into complexes. These protein complexes then start transcribing the genome into into mRNA. So the genome regulates its own expression, in a sense. Many of the sequences that function in this way are known. There are also just a bunch of parts of the genome that probably don’t do anything. There are also many regions of the genome that are basically self replicating sequences. They code for proteins that are capable of inserting their own genetic sequence back into the genome. These are transposons.In short, a lot of very painstaking genetics and molecular biology work has gone into characterizing the function of certain sequences. reply dwattttt 1 hour agorootparentprevYou could say exactly the same of all data; it&#x27;s just 1s and 0s, but when I look I just see blonde, brunette. reply throw3823423 7 hours agorootparentprevFor the same reason Monsanto sequences basically anything: Because we can tell what proteins are encoded in there, and what is near them, and we can have good ideas of what proteins are expressed together. When dealing with genetic modification, we get to see whether our modification went in, and where it landed: Having a protein in a genome isn&#x27;t enough. Its expression might be having an effect on other things, depending on where it is.When we have baselines, we can compare different individuals, and eventually make predictions of how they are going to be based solely on the genetic code. If I know that a certain polymorphism is tied to some trait I want, I might not have to even bother spending the time growing a plant: I know that it&#x27;s not what I want, and discard it as a seed.With humans we are probably not going to see much modification soon, but just being able to detect genetic diseases, risk factors for other diseases that have genetic omponents, or allow for selection of embryos in cases of artificial insemination is already quite valuable.It&#x27;s not source code that we are all that good at understanding just yet, but there&#x27;s already some applications, and we have good reason to think there&#x27;s a lot more to come reply khazhoux 6 hours agorootparentprevIt&#x27;s just about 3 gigabytes (each byte a letter). Pretty mind-blowing, if you ask me. reply cvoss 6 hours agorootparentIt&#x27;s a slight exaggeration of the information content to report the data size using an ASCII encoding. Since there are 4 bases, each can be encoded using 2 bits, rather than 8. So we&#x27;re really talking 750 megabytes. But still mind-blowing. reply borissk 6 hours agorootparentI&#x27;m curious if these 750MB + the DNA of mitochondria + the protein metagenomics contain all the information needed to build a human, or if there&#x27;s extra info stored in the machinery of the first cell.That is if we transfer the DNA to an advanced alien civilization - would they be able to make a human. reply mjan22640 1 hour agorootparentImagine a machine shop that has blueprints of components of the machines they use in the shop, and processes to assemble machines from the components. When a machine shop grows large and splits in two, each inherits a half of shop with the ongoing processes and a copy of the blueprints. https:&#x2F;&#x2F;m.youtube.com&#x2F;watch?v=B7PMf7bBczQ&pp=QAFIAQ%3D%3DDNA is the blueprints. There are infinite possibilities what to do with them. The advanced civilization would need additional information, like that they are supposed create a cell from the components to begin with, and a lot of detailed information how exactly to do that.Edit: improved clarity reply dekhn 6 hours agorootparentprevThis is a complex question. The cocktail soup in a gamete (sperm or egg) and the resulting zygote contains an awful lot of stuff that would be extremely hard to replace. I could imagine that if the receiving civilization was sufficiently advanced and had a model of what those cells contained (beyond the genomic information) they could build some sort of artificial cell that could bootstrap the genome to the point of being able to start the development process. it would be quite an accomplishment.If they just received the DNA without some information about the zygote, I don&#x27;t think it would be practical for even advanced alien civilization (LR5 or LR6) but probably an LR7 and definitely an LR8 could. reply Angostura 1 hour agorootparentI’m just pondering this, and it’s not clear to me that there is anything intrinsic in the genome itself that explicitly’says’ “this sequence of DNA bases encodes a protein” or even “these three base-pairs equate to this amino acid”.I wonder if that information could ever really be untangled by a civilisation starting entirely from scratch without access to a cell reply namanyayg 4 hours agorootparentprevWhat do you mean by \"LR\"? I queried an LLM but no results there either. reply dekhn 4 hours agorootparentoops i&#x27;ve said too much reply borissk 5 hours agorootparentprevThe code how to build a sperm and an egg is inside the human DNA, isn&#x27;t it? reply dekhn 5 hours agorootparentYes, but it currently requires developmentally mature individuals to build the gametes, and the \"code\" is so complex you couldn&#x27;t really decipher it from first principles. reply tobinfricke 5 hours agorootparentprevThe code to build mitochondria is not. reply klyrs 4 hours agorootparentprevGiven code written for unknown hardware... can you execute it? reply borissk 4 hours agorootparentGiven that the code contains the instructions how to make the hardware - if one is very smart than yes. reply bbrx 3 hours agorootparentIt would not necessary be possible, because it&#x27;s incremental instructions on how to make the hardware, but based on already existing, unspecified and very complex, hardware. So the first instruction would be something like \"take the stuff you have on your left and fuse it with the stuff you have on your right\", both stuff being unspecified very complex protein assumed to be present. replypmoriarty 3 hours agorootparentprev\"if we transfer the DNA to an advanced alien civilization - would they be able to make a human.\"I&#x27;m really surprised that in all these responses to your question no one&#x27;s mentioned the womb or the mother, who (at least with current technology) is still necessary for making a human.That&#x27;s not to mention the necessity of the egg.We&#x27;re not just DNA. reply dchftcs 2 hours agorootparentThis is a question about theoretical possibilities and what you&#x27;re saying seems to be a rigid belief in an answer \"no\". But you provided no evidence or justification, except for \"with current technology\", which answers nothing about the theoretical question. reply borissk 2 hours agorootparentprevInstructions on how to make a womb and an \"egg\" are contained within the human DNA. reply crdrost 36 minutes agorootparentIt is known that that is not true, due to the distinct genetic code of mitochondria and known epigenetic influences of mothers on their children in utero.You could say “well that&#x27;s the last 10% of the details, maybe 90% is in the DNA,” but I think I would be suspicious that it&#x27;s that high, because one of the things we know about humans is that we are born with all of the ova that we will ever have, rather than deferring the process until puberty. I should think that if it could be deferred it would have been, “you will spend the energy to make these 15 years before you need to for no real reason” seems very unlike evolution whereas “my body is going to teach you how to make these eggs, just the same as my mother&#x27;s body taught me,” sounds quite evolutionarily reasonable. reply wizofaus 46 minutes agorootparentprevBut maybe you needed a pre-human womb to bootstrap the first human, and we no longer have the blueprint for that... reply senkora 6 hours agorootparentprevI can’t wait until we can bootstrap a human from a stage 3 tarball. reply kovacs_x 52 minutes agorootparentprevit&#x27;s bit like- if i have source code of Linux (think DNA), can I build a machine running Linux? (think cell). no- you cant, you need to have machine that can run the code.ie. \"software\" without \"machine\" to run it on, is kind of a useless. reply ejstronge 6 hours agorootparentprev> That is if we transfer the DNA to an advanced alien civilization - would they be able to make a human.You&#x27;d need a cell to start the process, with the various nucleic acids distributed correctly and proteins&#x2F;energy with which to create further proteins using the information encoded by the DNA. Thus the civilization would need information about cells and a set of building blocks before being able to use the DNA. reply borissk 5 hours agorootparentThe DNA contains all the code that creates and regulates the proteins. reply penteract 5 hours agorootparentIncluding code for the proteins that read DNA to produce proteins. You might hit similar problems trying to understand C given the source code for a C compiler - a non-standard environment could reproduce itself given the source code, meaning the code alone doesn&#x27;t strictly determine the output. reply kibibyte 4 hours agorootparentI&#x27;ll torture this DNA and C source code analogy a bit.Epigenetics is missing in this discussion about reproducing a human from just the DNA. These are superficial modifications (e.g. methylation, histone modification, repressor factors) to a strand of DNA that can drastically alter how specific regions get expressed into proteins. These mechanisms essentially work by either hiding or unhiding DNA from RNA polymerases and other parts of the transcription complex. These mechanisms can change throughout your lifetime because of environmental factors and can be inherited.So it&#x27;s like reading C source code, except there so many of these inscrutable C preprocessor directives strewn all throughout. You won&#x27;t get a successful compilation by turning on or off all the directives. Instead, you need to get this similarly inscrutable configuration blob that tells you how to set each directive.I guess in a way, it&#x27;s like the weights for an ML model. It just works, you can&#x27;t explain why it works, and changing this weight here produces a program that crashes prematurely, and changing a weight there produces a program with allergic reactions to everything. reply khazhoux 5 hours agorootparentprevAnd how will you decode it? reply mfld 3 hours agorootparentprevYes, there is extra information in the first cells, in particular regulatory elements such as miRNAs. The headline here is epigenetics. reply singularity2001 4 hours agorootparentprevOur DNA does not contain the mitochondria nor the gut bacteria so the raw data would most certainly not be enough to build a working copy reply dekhn 6 hours agorootparentprevAnd since the data is highly redundant the 750MB can be compressed down even further using standard approaches (DEFLATE works well, it uses both huffman coding and dictionary backreferences).Or, you could build an embedding with far fewer parameters that could explain the vast majority of phenotypic differences. the genome is a hierarchical palimpsest of low entropy.My standard interview question- because I hate leetcode- walks the interviewee through compressing DNA using bit encoding, then using that to implement a rolling hash to do fast frequency counting. Some folks get stuck at \"how many bits in a byte\", others at \"if you have 4 symbols, how many bits are required to encode a symbol?\", and other candidates jump straight to bloom filters and other probabilistic approaches (https:&#x2F;&#x2F;github.com&#x2F;bcgsc&#x2F;ntHash and https:&#x2F;&#x2F;github.com&#x2F;dib-lab&#x2F;khmer are good places to start if you are interested). reply khazhoux 6 hours agorootparentprevYes, and if you gzip it it&#x27;s even smaller. But the big takeaway is that the amount of info that fully defines a human, is what we consider \"not much data,\" even in its plainest encoding. reply dekhn 5 hours agorootparentbzip2 is marginally better, and then genome-specific compressors were developed, and then finally, people started storing individual genomes as diffs from a single reference, https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;CRAM_(file_format)Since genome files contain more data than just ATGC (typically a comment line, then a DNA line, then a quality score line), and each of those draws from a different distribution, DEFLATE on a FASTA file doesn&#x27;t reach the full potential of the compressor because the huffman table ends up having to hold all three distributions, and the dictionary backlookups aren&#x27;t as efficient either. It turns out you can split the file into multiple streams, one per line type, and then compress those independently, with slightly better compression ratios, but it&#x27;s still not great. reply astrange 5 hours agorootparentprevWe don&#x27;t know that it fully defines a human until we can create one without the starting condition of being inside another human. It&#x27;s prototype-based inheritance. reply hotnfresh 4 hours agorootparentSome of the research about being able to make simple animals grow structures from other animals in their evolutionary “tree” by changing chemical signaling—among other wild things like finding that memories may be stored outside the brain, at least in some animals—makes me think you need more than just the “code” to get the animal that would have been produced if that “code” were in its full context (of a reproductive cell doing all sorts of other stuff). Even if the dna contains the instructions for that reproductive cell, too, in some sense… which instructions do you “run”? There might be multiple possible variants, some of which don’t actually reproduce the animal you took the dna from. reply astrange 1 hour agorootparentMy favorite trivia here is that flamingos aren&#x27;t actually \"genetically\" pink but \"environmentally\" pink because they pick up the color from eating algae.Except of course \"genetics\" and \"environment\" aren&#x27;t actually separate things; sure, people&#x27;s skin color isn&#x27;t usually affected by their food, but only because most people don&#x27;t eat colloidal silver.https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Paul_Karason replydekhn 6 hours agorootparentprevIf you think like an ML engineer, the genome is a feature vector 3B bases (or 6B binary bits) long that is highly redundant (many sections contain repeats and other regions that are correlated to other regions), and the mapping between that feature vector and an individual&#x27;s specific properties (their \"phenotype\", which could be their height at full maturity, or their eye color, or hair properties, or propensity to diseases, etc) is highly nonlinear.If you had a list of all the genomes of all the people in the world, and all their phenotypes (height, eye color, hair type, etc), you could take all their genomes as input variables and treat all their phenotypes as output variables, and make embeddings or other models that mapped from genomes to phenotypes. The result would be a predictive model that could take a human genome, and spit out a prediction of what that person looks like and other details around them (up to the limits of heritability).A good example is height. If you take a very large diverse sample of people, and sequence them, you will find that about 50% of the variance in height can be traced to the genomic sequence of that individual (other things, such as socioeconomic status, access to health care, pollution, etc, which are non-genomic, contribute as well). originally many geneticists believed that a small number of genes- tiny parts of the feature vector- would be the important features in the genome that explained height.But it didn&#x27;t turn out that way. Instead, height is a nonlinear function of thousands of different locations (either individual bases, entire genes, or other structures that vary between individuals) in the genome. This was less surprising to folks who are molecular biologists (mainly based on the mental models geneticists and MBers use to think about the mapping of genotype to phenotype), and we still don&#x27;t have great mechanistic explanations of how each individual difference works in concert with all the others to lead to specific heights.When I started out studying this some 35 years ago the problem sounded fairly simple, I assumed it would be easy to find the place in my genome that led to my funny shaped (inherited) nose, but the more I learn about genomics and phenotypes, the more I appreciate that the problem is unbelievably complex, and really well suited to large datasets and machine learning. All the pharma have petabytes of genome sequences in the cloud that they try hard to analyze but the results are mixed.I spent my entire thesis working on ATGCAAAT, by the way. https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Octamer_transcription_factor is a family of proteins that are incredibly important during growth and development. Your genome is sprinkled with locations that contain that sequence- or ones like it- that are used to regulate the expression of proteins to carry out the development plan. reply aastronaut 2 hours agorootparent> If you had a list of all the genomes of all the people in the world, and all their phenotypes (height, eye color, hair type, etc), you could take all their genomes as input variables and treat all their phenotypes as output variables, and make embeddings or other models that mapped from genomes to phenotypes. The result would be a predictive model that could take a human genome, and spit out a prediction of what that person looks like and other details around them (up to the limits of heritability).Would such a predictive model really be possible? As far as I&#x27;m aware there is contradicting research whether a specific phenotype distinctly originates from a SNP&#x2F;genotype. reply alexchantavy 6 hours agorootparentprevFascinating, are there lots of people looking at genetics with this ML kind of lens? reply dekhn 5 hours agorootparentSure, although I&#x27;m not aware of anybody who is contemplating quite the level I believe is necessary to really nail the problem into the ground. When I worked at Google, I proposed that Google build a datacenter-sized sequencing center in Iowa or Nebraska near its data centers, buy thousands of sequencers, and run industrial-scale sequencing, push the data straight to the cloud over fat fiber, followed by machine learning, for health research. I don&#x27;t think Google wants to get involved in the physical sequencing part but they did listen to my ideas and they have several teams working on applying ML to genomics as well as other health research problems, and my part of my job today (working at a biotech) is to manage the flows of petabytes of genomic data into the cloud and make it accessible to our machine learning engineers.The really interesting approaches these days, IMHO, combine genomics and microscopic imaging of organoids, and many folks are trying to set up a \"lab in the loop\", in which large-scale experiments run autonomously by sophisticated ML systems could accelerate discovery. It&#x27;s a fractally complex and challenging problem.Statistics has been key to understanding genetics from the beginning (see Mendel, Fisher) and so at a big pharma you will see everything from Bayesian bootstrappers using R to deep learners using pytorch. reply 2dvisio 2 hours agorootparentGuys at Verily are working on Terra.bio with the Broad institute and others. Genomics England in the UK is also experiencing with multimodal and machine learning applied to whole genome sequences [1].[1] https:&#x2F;&#x2F;www.genomicsengland.co.uk&#x2F;blog&#x2F;data-representations-... reply krab 3 hours agorootparentprevBut why Google? This is what big pharma are doing. Also you can outsource the data collection part. See for example UK Biobank. Their data are available to multiple companies after some period so it makes it more cost efficient. reply panosfilianos 5 hours agorootparentprevI have spent the better part of the past year looking obsessively over genomics papers for cancer and I&#x27;ve grown very fond of the field.Are there any positions at Google&#x2F; companies you wold suggest me to look into? I&#x27;m coming from algortrading&#x2F; ML research with ML MSc. reply asielen 4 hours agorootparentYou could try Calico. They are an Alphabet company that specifically studies aging. There how a good amount of machine learning roles. However biotech typically pays less than finance or software.https:&#x2F;&#x2F;calicolabs.com&#x2F;careers&#x2F; reply panosfilianos 4 hours agorootparentThanks! reply krab 4 hours agorootparentprevYes. For example when word2vec came out, immediately there were people trying similar approaches to protein sequences. Transformers work better. reply globular-toast 2 hours agorootparentprevThe genetic code maps nucleotide sequences (DNA) to amino acid sequences (proteins). Every three bases (say AGT) maps to one amino acid. So you can literally read a sequence of ACGTs and decode it into a protein. A sequence that encodes a protein is called a gene.Almost all variations that humans have in their genomes (compared to each other or a reference genome) are tiny, mostly one base differences called single nucleotide polymorphisms (SNPs). These tiny changes encode who you are. The rest of it just makes you carbon-based organism, a eukaryote, an animal, a mammal etc, just like a whole load of other organisms. reply lopis 3 hours agoparentprevWhile you are correct, the differences between different people&#x27;s DNA is tiny, less 1% at best. So this information is still very valuable. This article is talking about the first time in finishing sequencing one person&#x27;s Y chromosome&#x27;s DNA. reply hk__2 1 hour agorootparent> While you are correct, the differences between different people&#x27;s DNA is tiny, less 1% at bestHow do we know this, if we have only sequenced the chromosome of one individual? reply lopis 57 minutes agorootparentWe have sequenced the genome using different sampling and statistical models for a long time. reply jhbadger 4 hours agoparentprevTraditional sequences of the Y chromosome (and other chromosomes) were missing parts, particularly the highly repetitive regions called \"telomeres\". This is different from the issue of individual variation (although the authors do provide a map of known variations as well). reply dclowd9901 4 hours agoparentprevThank you for putting into words exactly the thing I wanted to understand but couldn’t figure out how to ask. reply photochemsyn 5 hours agoparentprevGood question. Practically they call their complete sequence a &#x27;reference sequence&#x27; which can be thought of as a baseline for comparison to the complete spectrum of human Y chromosome genetic variation, so at least people have something to use as a standard for comparison. The line in the abstract \"mapped available population variation, clinical variants\" is about the only mention of the issue.Ideally we&#x27;d have hundreds if not thousands of complete genomes which in total would reveal the population diversity of the human species as it currently exists, but this is a big ask. \"Clincal variants\" are of particular interest as those are regions of the genome associated with certain inherited diseases, although the promises of individual genomic knowledge leading to a medical revolution have turned out to be wildly overblown.Since the paper is paywalled, there&#x27;s not much else to say than that they have a (fairly arbitrary in origin, i.e. it could have been from any one individual or possibly even a chimera of several individuals) reference sequence to which other specific human Y chromosomes can be compared, eventually leading to a larger dataset from many individuals which will reveal the highly conserved and highly variable regions of the chromosome, population-wise. reply gorjusborg 7 hours agoparentprevI had the same question. Perhaps this will help you.https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;DNA_sequencing reply mikepurvis 7 hours agorootparentThat page describes the human genome as having been sequenced back in 2003. *confusion intensifies* reply dekhn 5 hours agorootparentthe project started around 1990, they announced a draft completed in 2000, \"completion\" in 2003 (this was more a token announcement based on a threshold than a true milestone). Even then the scientists knew that major parts of the centromere, telomere, and highly repetitive regions were not fully resolved, and that was fully admitted. The work by Karen Miga at UCSC and others is more of a mop-up now that genome sequencing is a mature technology and we have much better ways at getting at those tricky regions.another \"completion\" happened 3 years ago, before this announcement. but this is the last one. I promise. reply wheelerof4te 3 hours agoparentprevIt means that they are trying to find a baseline from which they can eventually clone a human being.Let&#x27;s not pretend that this is not an end goal. It always was. reply msuvakov 4 hours agoprevThis news should be dated back in December, not now.The T2T team published a preprint [1] last December and released the data [2] in March. However, due to the peer review process, the findings have only just been formally published in Nature. The publication timeline can indeed be slow, and in cases like this one, the question is: what&#x27;s the point when all scientists interested in the topic already know about it and working with this assembly?[1] https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;10.1101&#x2F;2022.12.01.518724v1.... [2] https:&#x2F;&#x2F;github.com&#x2F;marbl&#x2F;CHM13 reply goodcanadian 2 hours agoparentwhat&#x27;s the point when all scientists interested in the topic already know about it and working with this assembly?In this context, I would say the point of a press release is getting the news out generally to non-scientists. reply coldtea 5 hours agoprevIs this like: \"we have a working keyboard driver\" or more like \"we identified all 104 keys on a standard 104-key US QWERTY layout\"? reply gandalfgreybeer 5 hours agoparentNot answering your question, but I have to say, this is one of the best analogies I&#x27;ve encountered in a while. reply quickthrower2 4 hours agorootparentThe keyboard driver means knowing what effect every key has? reply coldtea 4 hours agorootparentprevWow, thanks! reply moffkalast 30 minutes agoparentprevSounds more like they&#x27;ve been using the 87-key QWERTY so far, but now they also found the numpad. reply brayman30 7 hours agoprevThis is actually kind of a huge deal since it means that all 24 chromosomes have now been fully sequenced. As it says in the abstract, up until now the Y chromosome proved difficult to sequence due to its nature. reply AgentME 5 hours agoparentI thought the human genome project finished in 2003, but now that I look it up again, apparently \"finished\" meant 92%. And then it was finished in 2022. And now it&#x27;s finished again. Are there any remaining milestones left toward maybe finishing it again? Was the Y chromosome really just considered an exception until now? reply dclowd9901 4 hours agorootparenthuman_genome_final_FINAL_3.txt reply tobinfricke 5 hours agoparentprevWhat makes the Y chromosome more difficult? reply bux93 2 hours agorootparentIt&#x27;s on line 1 of the linked article: \"The human Y chromosome has been notoriously difficult to sequence and assemble because of its complex repeat structure that includes long palindromes, tandem repeats and segmental duplications\" and comes with 3 citations. reply BbzzbB 2 hours agorootparentprevMaybe someone can correct the details since it&#x27;s been a few years I done this, but we sequence DNA by PCR. Roughly, (1) breaking it up in small pieces and split strands, (2) mixing it with an enzyme that completes each single strand, (3) repeat 1 and 2 a bunch to multiply the strands many times over to make the solution a sense DNA juice, (4) pass it through a machine that&#x27;ll sequence thousands of these small strands and (5) align these short DNA sequences with a software that matches unique sequences.I did it with COI gene, which is just a short (1000ish base pairs with our snails IIRC) sequence of purely random ATGC base pairs. Lots of unique sequences make the short strands easy to match, just get a bunch of 10-15 BP bits and you can match the whole thing.Now if your gene is 62M BP of repeating palindrome sequences, you can imagine how hard it would be to align random pieces sequenced as it will be very hard to find unique sequences to match. reply inciampati 2 hours agorootparentWe don&#x27;t use PCR anymore! It&#x27;s direct sequencing of the primary DNA. We can read single molecules. That&#x27;s the quiet revolution in nanotechnology that&#x27;s driving all these complete assemblies. reply bonestamp2 7 hours agoparentprevAs others have asked in this thread, what does \"fully sequenced\" mean to the layman? reply yellowcake0 6 hours agorootparentIt looks like from the preprint that they sequenced the Y chromosome of HG002, which was one of the original 1000 genomes samples from way back in the day, still held in deep freeze at a number of biobanks.Short-read sequencing data is a notoriously bad datatype for reconstructing the low-complexity &#x2F; repetitive regions of genomes, so up until recently the most commonly used reference genomes have left many of these regions \"dark\". According to the preprint, the Y chromosome has the highest density of these low-complexity regions. It&#x27;s also something of a bioinformatic nuisance when constructing a generic human reference genome, as it&#x27;s only present in 50% of the population. reply scandum 1 hour agorootparentIsn&#x27;t the problem the absence of random DNA?I wouldn&#x27;t call random data &#x27;complex&#x27;, but it is easy to sequence when assembling short reads. reply icholy 6 hours agorootparentprevIt provides a complete baseline&#x2F;reference DNA \"map\". Common \"problems\" show up on specific parts of this map. So you can sequence small subsets of a patient&#x27;s DNA and compare it to these \"problem areas\" to detect genetic diseases. reply p1mrx 6 hours agoparentprevYou can tell it&#x27;s the Y chromosome because of the way it is. reply UI_at_80x24 7 hours agoprevFor a very entertaining and educational book that tangentially related; I can highly recommend: Y - The Descent of Man by Steve Jones [0]I am thrilled to see more chromosomes being mapped&#x2F;sequenced. Please excuse my high-school level of biology knowledge here, but have we definitively progressed beyond correlation when it comes to genes, gene expression, and how they all interact?Take \"Blue eyes\" as an example, we know that [1] OCA2 is responsible for brown&#x2F;blue eye colour. BUT are we sure that none of the 20,000 others are involved&#x2F;needed?In laymans terms I would guess that to get &#x27;blue eyes&#x27; would require several genes to ALL be on&#x2F;active&#x2F;present as well. More like a recipe, then a simple on&#x2F;off it&#x27;s located in 1 position.[0] https:&#x2F;&#x2F;www.goodreads.com&#x2F;work&#x2F;editions&#x2F;436071-y-the-descent... [1] https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;s41433-021-01749-x reply dekhn 6 hours agoparentEye color is subtle. How do you define blue eyes? It&#x27;s not just one phenotype; there are a range of blue eyes, whose differences correspond to fairly subtle variations between people. The article you linked [1], is quite good but requires quite some time to absorb completely. reply largbae 7 hours agoparentprevI would imagine all sorts of genes are necessary to have blue eyes depending on how you look at it. After all, you need eyes in order to have blue eyes, and a whole bunch of other machinery to open them to check the color... reply brayman30 6 hours agoparentprevFirst I would like to state that human genetics are very, very complex and we still do not have a complete understanding of them. For example, only relatively recently has the field of epigenetics made major advancementa, which (broadly speaking) studies how a cell&#x27;s behavior can be changed WITHOUT it&#x27;s DNA being changed.[1] This brings into question the age-old questions about environmental impact vs genetic impact in even greater detail. Anyways, sidebar over.No, we are not completely sure how many chromosomes play a role in determining eye color. However, we do have a pretty good guess. Most recent estimates I found out the number at 16. OCA2 and HERC2 have the largest impact on eye color, but, there are many OTHER genes that also have smaller impacts on eye color. [2] That article I cited is actually amazing. But, it does touch on some more advanced subjects that are more introductory college-level biology or AP Biology than standard high school bio e.g. Gene Regulation, introns and extrons, etc.To answer your more general question, in my (admittedly only mildly less basic, introductory college-level biology) opinion, it is unlikely that we will, anytime soon, reach a point where anything in genetics can be completly, 100% definitive. This is not to say that we haven&#x27;t made amazing advancements in the field of genetics and biology more broadly. BUT, it would be a mistake to take for granted the complexity of the human genome. There is most definitely things we still do not understand about the genome, and will not for some time.But, practically speaking, while other genes may have impact on some simple phenotypic traits, such as eye color, we can generally make an accurate guess based on only a few genes. In eye color, for example, one study was able to predict eye color with only 6 genes with about ~75% accuracy. [3]The crazy part is, sometimes the genes that effect the phenotypic trait, don&#x27;t actually store genetic material that determines the trait. In other words, they don&#x27;t DIRECTLY determine the trait at all. Rather, the only effect ORHER genes which then effect the expression of the trait more directly. You can imagine that this could become very complex very very quickly when you have multiple genes effecting other genes which effect other genes, not to mention accoubting for environmental and demographic baises when doing these studies and you begin to see why this genetics is such a difficult field of study.Apologies for the long post and rambling. Hopefully I was still able to provide you with some mediocre introductory-collage-level biology[1] https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;pmc&#x2F;articles&#x2F;PMC2791696&#x2F; [2] https:&#x2F;&#x2F;www.nature.com&#x2F;articles&#x2F;jhg2010126 [3] https:&#x2F;&#x2F;doi.org&#x2F;10.1016&#x2F;j.cub.2009.01.027 reply ManuelKiessling 4 hours agoprevSo, did they find the reason why BMW drivers are always tailgating me on the Autobahn? reply wallaBBB 3 hours agoparentYes, move out of the left lane. reply jacquesm 3 hours agoparentprevBecause you stay in the left lane when you shouldn&#x27;t? reply mrazomor 6 hours agoprevThis is exciting!BTW. if you want to know the applications of this work, have a look at this ACM SIGPLAN Keynote: https:&#x2F;&#x2F;youtu.be&#x2F;JTU3JYp3JYc?si=jOZz611ATQar3Gec (helped me understand DNA more than all biology classes at my high school) reply dramebaaz 4 hours agoparentThanks for that ACM SIGPLAN talk link, it was very fascinating and engaging. reply soligern 6 hours agoprevDoes this literally mean every single base pair with all the junk genome and everything else? Or is it some statistical model&#x2F;extrapolated etc. reply dekhn 5 hours agoparentIt is a completely gapless assembly from the beginning of the start of each chromosome all the way to it&#x27;s end (\"telomere to telomere\"). I haven&#x27;t read in enough detail but I would imagine there are still some slightly fuzzy regions that are sort of a best-guess, although those would be quite small. reply muizelaar 7 hours agoprevThe preprint: https:&#x2F;&#x2F;www.biorxiv.org&#x2F;content&#x2F;10.1101&#x2F;2022.12.01.518724v2.... reply catsarebetter 1 hour agoprevomg and with the new tech around generative AI...This is shaping up to be a very interesting decade to be in tech.We might actually be able to generate new sequences and test them against all the diseases to remove them. reply farhanhubble 4 hours agoprevDoes it make it any easier to snapshot Chromosomes and see them evolve with age and perhaps better correlate that with the onset of diseases? The correlation is still possible but will having multiple snapshots enable better association? reply moelf 5 hours agoprevI guess nih will update this soon: https:&#x2F;&#x2F;www.ncbi.nlm.nih.gov&#x2F;assembly&#x2F;GCF_009914755.1&#x2F; since it was gap-less except for Y chromosome reply dools 3 hours agoprevScary cowboy on Sesame Street: I WANNA KNOW Y!Scientists: here you go reply mikeyouse 6 hours agoprevA good article about the achievement from UC Santa Cruz, where one of the lead scientists of the Telomere-to-Telomere project works:https:&#x2F;&#x2F;news.ucsc.edu&#x2F;2023&#x2F;08&#x2F;t2t-y-chromosome.html reply xwdv 6 hours agoprevCould we in theory just build up any kind of creature from scratch if we write out its genome? How would we compile it into organic matter? reply jakobnissen 3 hours agoparentNo, this is not technically possible. Cells are simply to complex to just build using humanity&#x27;s current level of technology. The closest thing we have done is to fully synthesize a bacterium&#x27;s genome, remove the genome from a bacterial cell, then transplant the synthetic genome into the cell and have the cell survive: https:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Mycoplasma_laboratoriumThat&#x27;s insanely cool, but very far from what you are asking. An analogy: We have re-installed the operating system of an existing computer, when you are asking whether we can manufacture a computer. reply globular-toast 2 hours agoparentprevThere&#x27;s a bootstrapping problem. You need something to run the code. An egg cell and sperm cell contain loads of other stuff in addition to the genome and the only way to get that stuff is from the genome...It&#x27;s like if you had a program to 3D print a 3D printer but you don&#x27;t have a 3D printer that can read that program.It&#x27;s all ridiculously complicated. To get an idea about it you could learn about how simple RNA viruses like influenza or HIV replicate. It&#x27;s easy enough for anyone to understand. But no single person can fully understand humans (or other mammals, plants etc, we&#x27;re not special in that respect). reply renewiltord 3 hours agoprevSo I have my whole genome sequenced by Nebula. What do I have to do to match it up? reply readittwice 33 minutes agoparentCan someone explain how \"I have my whole genome sequenced by Nebula\" relates to the news just now that \"The human Y chromosome has been completely sequenced\"?How can someone have their whole (!) genome sequenced already when so far we weren&#x27;t able to fully sequence the Y chromosome. And this person seems to have a Y chromosome. reply mfld 3 hours agoparentprevYou could download the raw sequence reads (FASTQ files) and map them to the new T2T-Y. Probably it makes more sense to wait for a new release of the T2T human genome reference, as mapping to a subset of the genome increases false positives. It helps to have some genome bioinformatics knowledge to correctly handle those T2T references. reply Metacelsus 52 minutes agoparentprevBWA-MEM is a good alignment tool. Then you can view the .bam file in IGV. reply hanniabu 5 hours agoprevWhat are the implications of this? What&#x27;s now possible with this feat completed? reply Legend2440 7 hours agoprev [–] TIL the human Y chromosome hadn&#x27;t been completely sequenced until now. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Telomere-to-Telomere consortium has successfully sequenced and assembled the complete sequence of a human Y chromosome, adding new sequence and correcting errors.",
      "This achievement provides a comprehensive reference sequence for all 24 human chromosomes, aiding in genomic research and insights into human genetic variation and evolution.",
      "The study highlights the importance of accurate representation of the sex chromosome complement in reference genomes and reveals genomic differences and variations between individuals, contributing to our understanding of the human Y chromosome and genetic diversity."
    ],
    "commentSummary": [
      "Scientists have achieved the milestone of sequencing the human Y chromosome, advancing our understanding of human genetics and opening doors for future research.",
      "The sequencing of all 24 chromosomes, including the Y chromosome, will help in studying genetic variations, diseases, and their relationship with traits.",
      "Despite this achievement, comprehending human genetics remains complex due to multiple factors influencing traits and the challenges associated with mapping genetic differences to specific traits using machine learning."
    ],
    "points": 319,
    "commentCount": 142,
    "retryCount": 0,
    "time": 1692927377
  },
  {
    "id": 37247767,
    "title": "Open-source obsidian.md sync server",
    "originLink": "https://news.ycombinator.com/item?id=37247767",
    "originBody": "https:&#x2F;&#x2F;github.com&#x2F;acheong08&#x2F;obsidian-syncHello HN,I&#x27;m a recent high school graduate and can&#x27;t afford $8 per month for the official sync service, so I tried my hand at replicating the server.It&#x27;s still missing a few features, such as file recovery and history, but the basic sync is working.To the creators of Obsidian.md: I&#x27;m probably violating the TOS, and I&#x27;m sorry. I&#x27;ll take down the repository if asked. It&#x27;s not ready for production and is highly inefficient; Not competition, so I hope you&#x27;ll be lenient.",
    "commentLink": "https://news.ycombinator.com/item?id=37247767",
    "commentBody": "Open-source obsidian.md sync serverHacker NewspastloginOpen-source obsidian.md sync server 319 points by acheong08 18 hours ago| hidepastfavorite126 comments https:&#x2F;&#x2F;github.com&#x2F;acheong08&#x2F;obsidian-syncHello HN,I&#x27;m a recent high school graduate and can&#x27;t afford $8 per month for the official sync service, so I tried my hand at replicating the server.It&#x27;s still missing a few features, such as file recovery and history, but the basic sync is working.To the creators of Obsidian.md: I&#x27;m probably violating the TOS, and I&#x27;m sorry. I&#x27;ll take down the repository if asked. It&#x27;s not ready for production and is highly inefficient; Not competition, so I hope you&#x27;ll be lenient. kepano 14 hours ago(Obsidian CEO here)Impressive! It&#x27;s fun to see the diversity of ways people sync&#x2F;backup their Obsidian files. The nice thing about storing all your notes on your device is that it makes it possible to move and edit your Markdown files in many different ways. That diversity of solutions is what makes the ecosystem of Markdown tools resilient over the long term.There are already a handful of tools that allow you to sync your notes for free, including Git, Syncthing, and some other options more specialized for Obsidian (see community plugins).Obsidian is a small company, we&#x27;re not VC backed (100% user-supported), so the Sync pricing helps us stay in business and keep the lights on. We also have a 40% educational discount on all our services[1] so you could be paying $4.80 instead of $8 :)Reverse engineering things is a fun technical challenge, and also helps us find potential holes in our system. The main problems I see with your solution: 1. it could easily break in a future update to the app, 2. \"Obsidian Sync\" is a trademark, so you should consider renaming the repo otherwise it can be confused for an official tool — that would be my only request[1]: https:&#x2F;&#x2F;help.obsidian.md&#x2F;Licenses+and+payment&#x2F;Education+and+... reply iamdamian 8 hours agoparentI discovered Obsidian this year, and it&#x27;s not an understatement to say that it helped restore my faith in local-first computing and humane tools. Obsidian has helped me reclaim my thought process and my writing, and I&#x27;m much happier using it.Like others have mentioned, your approach and ethos are a large part of why I decided to go all in on Obisidian, and that ethos is reflected in Sync. With Sync, everything is end-to-end encrypted and can be unsynced at any time without having to \"export\" anything or jump through hoops. Configuration is file-based and can be selectively synced, including themes. Beyond that, I can rest easy knowing that if Sync is ever down, I have all of my files right there.When I downloaded Obsidian for the first time, I thought it was a shame that I didn&#x27;t need to pay for it. So I was more than happy to find Sync and pay for the service to help what I see as a good company.Kudos, and please keep up the good work. reply dansalvato 12 hours agoparentprevI&#x27;m a brand new user and thought all this time that Obsidian Sync was 100% cloud-only, so I spent a bunch of time trying to spin up a custom sync solution. This comment inspired me to look more carefully at it, and now I&#x27;m a paid user!I only wish that https:&#x2F;&#x2F;obsidian.md&#x2F;sync made it more obvious that you can sync a local vault to the cloud. Emphasis on \"You still own your data, no vendor lock-in\" is a huge sell for users like me who are typically forced to choose between seamlessness vs. owning our data. I&#x27;m delighted to learn that Obsidian offers both. reply ilyin 13 hours agoparentprevTime and again I keep being impressed with your selfless commitment to building and sharing things in the most humane and long-term way. A beautiful example to set, thanks. reply LorenDB 12 hours agorootparent> Time and again I keep being impressed with your selfless commitment to building and sharing things in the most humane and long-term way.And yet they haven&#x27;t open sourced the app. That would be truly humane and long-term. As it is, it&#x27;s just another proprietary app that, if it dies, can&#x27;t be continued by the community.I don&#x27;t think monetary issues should be a concern with open sourcing the app - companies like Bitwarden, Gitlab, and New Vector (the company behind Matrix) are doing just fine with their open source products. reply abnry 10 hours agorootparentThe kind of comment really, really rubs me the wrong way.Your data isn&#x27;t locked up in a format. Just use logseq or something if obsidian disappears.Those who write the code have the right to control its source code. They aren&#x27;t \"inhumane\" or thinking \"short-term\" just because its not open source. reply LorenDB 8 hours agorootparentWell, I would agree that \"humane\" is a poor term to use when describing software in general, but especially for open vs. closed source. I also realize that my comment was a bit harsh on Obsidian. I think they have a fine thing going (although I personally don&#x27;t need note taking software like that); I just would love to see more and more software become open source and I think this would be a prime candidate for open sourcing. reply sdf4j 7 hours agorootparentThere are plenty open source md note taking apps you can chose from. I don’t see why the tantrum for a tool you don’t even use. Are you doing a guilt trip for every closed source app shown here? reply brightball 12 hours agorootparentprevIf it dies I’ll still have all of my content in easily portable markdown though. reply nstart 4 hours agorootparentAnd especially awesome is that all their enhancements like properties and daily notes make use of markdown or json rather than closed binary&#x2F;hard to reverse xml formats. Any app could replicate the functionality if it wanted to and it would be portable next minute. The only thing that is kind of locked is the plugin but that’s outside of scope. reply hotstickyballs 7 hours agorootparentprevExactly this. I don’t really care if google drive or Dropbox is closed source. Why would I? I’ll just use syncthing (open sourced alternative) if shit hits the fan. Let them earn their money by providing bandwidth, safe storage and file versioning. reply rexpop 12 hours agorootparentprevUnder capitalism, it&#x27;s reasonable to charge for products and services.The jury is still out on \"companies like Bitwarden, Gitlab, and New Vector\". Kudos to them for pioneering novel business models. reply LorenDB 8 hours agorootparentI&#x27;d hardly say the jury is still out - Bitwarden has been around for 7 years, GitLab for 9, and New Vector for 6. Granted, they may not have reached the level of success that some software companies have, and they certainly could still fail, but 6-9 years of operation with a foreseeable future of success in the technology world seems like a pretty successful business to me. reply slj 11 hours agorootparentprevInteresting. In regards to your first point, do you have justification to back your claim? I’d be interested in reading more, or perhaps seeing an example? replybachmeier 7 hours agoparentprevI&#x27;ll join in with the others and say a few good words. It&#x27;s unusual in 2023 for a company to focus on delivering a good customer experience while respecting the preferences of the customer. Imagine a company that builds a business around providing value to the customer.Renewed for my third year of Sync yesterday. While I could use other tools to sync (I mostly have markdown files in my vaults, so there&#x27;s not a lot of data moving around), the quality of the sync service, and the ease of setting it up, makes me renew without thinking about it. And it&#x27;s not easy getting me to pay for anything these days due to subscription fatigue, scam fatigue, and price hike fatigue. reply intellectronica 13 hours agoparentprevThis attitude is in no small part the reason I&#x27;m happy to pay those $8 every month - support a great team building and continuously improving a package so useful it has become an integral part of my life and, as a bonus, get a slick and reliable sync service on top. reply guiambros 7 hours agorootparentSame. Love Obsidian, and pay for Sync mostly to contribute to the fantastic work they do. reply throwaway5959 8 hours agorootparentprevCame here to say this. Keep up the great work! reply qntmfred 9 hours agoparentprevI&#x27;ve been using obsidian since last year, and I love it. After previously haven fallen in and then out of love with notion, obsidian has been just what the doctor ordered.So I was excited to see a obsidian HN post, and really didn&#x27;t expect to see the CEO as the top post. Kudos to you.I&#x27;ve been a sync customer more or less since I started using obsidian, mostly because I use the same vault on my phone plus a couple PCs.But honestly, the sync has been disappointing. When I restructure folders or rename stuff, half the time the next time I open on a different device, it deletes shit. I can usually figure it out and recover from the sync log, that&#x27;s a big trustbreaker. reply kepano 9 hours agorootparentThe rename issue is already solved and in the process of being rolled out across all the clients. Our original implementation of renaming for Sync was naive and slow. This was especially noticeable if you renamed a folder with lots of files. It would first delete the remote file on the Sync server and re-upload the local file to the new path. If you did this with a whole folder it meant waiting for all the remote files be deleted and then reuploaded. It&#x27;s safe, just slow. Now we&#x27;re tracking renames which is much better in every way :) reply ler_ 7 hours agoparentprevI don&#x27;t usually comment but just wanted to say that I absolutely love Obsidian. I have been using it every day for about 2 years now and my life would not be the same without it. It&#x27;s amazing. I also gladly pay for Sync, it&#x27;s more than worth it. reply belthesar 12 hours agoparentprevA response like this was exactly the reminder I needed to upgrade my Catalyst license. My opsec can be a little on the paranoid side, so while I believe y&#x27;all have the best of intentions and would build sync with the expectation that my data is safe, I would prefer to not use your sync service. But I use Obsidian so regularly that it&#x27;s definitely worth supporting good work done by folks that align with me. Keep up the wonderful work, both as a software company and as a beacon for how to be a good steward in an increasingly cynical industry. reply kepano 12 hours agorootparentFor reference, below is our blog post on how you can verify the Sync encryption. Most people don&#x27;t have the time or skills to set up their own sync service, but if you do setting up a DIY solution can be a fun project.https:&#x2F;&#x2F;obsidian.md&#x2F;blog&#x2F;verify-obsidian-sync-encryption&#x2F; reply txnf 6 hours agoparentprevI just want to say how much I love your product. So many of the best things never make it financially, but I really really hope you all make it. I&#x27;m 100% willing to support obsidian financially, just need to know where and how to do that. I don&#x27;t want an account or a sync thing, I just wanna give you all money for the great product. reply jpgvm 13 hours agoparentprevI had never heard of your service until now but your reply has probably landed you $8&#x2F;month.Bootstrapped startups deserve my money and commendable leadership should be rewarded. reply spondyl 11 hours agoparentprevThis sync server project is pretty handy for a headless daemon I had been meaning to cobble together in the background.The sort of thing that could say; pull down markdown files inside a CI pipeline from the sync server which is probably better handled using Git for sync but it seemed like a fun challenge.I&#x27;ve got most of a working implementation from trawling through minified Obsidian code with the debugger, which of course is now a little moot given the OP&#x27;s project basically captures everything needed.Anyway, one core problem I ran into was how to decrypt file blobs. I was dreading the amount of time I would have to waste trawling through all the bits required and then they just... tweeted it out: https:&#x2F;&#x2F;obsidian.md&#x2F;blog&#x2F;verify-obsidian-sync-encryption&#x2F;I&#x27;m sure it would be possible to reverse engineer with enough time of course but it&#x27;s nice to see some \"unofficially official\" user script type stuff. It gives the perception (and I&#x27;m sure it&#x27;s accurate) that they dogfood and tinker with their own stuff as much as anyone else in the community.EDIT: Ah, I missed that Kepano had already shared that blog post below already but it&#x27;s still a neat writeup reply acheong08 8 hours agoparentprevThank you. I’ll be renaming the repository. (Looks like a situation similar to vaultwarden) reply ashishb 6 hours agoparentprevI love Obsidian over all the other tools that I have tried. https:&#x2F;&#x2F;ashishb.net&#x2F;all&#x2F;why-i-prefer-obsidian-for-taking-not... reply dabeeeenster 13 hours agoparentprevWhat a wonderful reply. Thank you and kudos! reply hyperific 3 hours agoparentprevJust gotta say I absolutely love Obsidian. I&#x27;ve been using it for about 6 months now and I&#x27;m continuously blown away at how versatile it is. Canvases were such an incredible addition. The plugins from the community are top notch. reply iepathos 8 hours agoparentprevGreat product, thank you. Really appreciate the way you handled the trademark issue here with a tactful request. Definitely earning points with open source community reply andymac4182 11 hours agoparentprevI have been looking at building a self hosted implementation of this service because of compliance reasons.The $$$ of the service isn&#x27;t the issue but making sure there is a good compliance option and self hosted to ensure that data doesn&#x27;t leave boundaries and is stored securely on company servers.If there was an option to have a paid self hosted option I would happily look at paying for that. reply kepano 11 hours agorootparentDown the road we might make something like that for the commercial use case — makes sense. reply guiambros 7 hours agorootparent+1. Many companies have policies against the use of 3P cloud services, so Obsidian Sync is a non-starter in those cases, irrespective of the data being e2e encrypted.Having a paid option where you can plug your own cloud storage (e.g. a Google drive folder, Dropbox, AWS, etc) would be fantastic. I&#x27;d gladly continue paying for my Sync subscription, but be able to point to my own cloud storage instead of Obsidian&#x27;s servers.But I understand you&#x27;d have to push the syncing logic to the client, and that is non-trivial. Alternatively, you could offer an official self-hosting server option, although it might not solve the issue for corporate users. reply fire 10 hours agoparentprevHonestly I just want a sync solution I can host on my NAS that the mobile app can still access, which unfortunately isn&#x27;t something the app natively supports, and more or less all of the current community solutions come with one caveat or another ( like the otherwise lovely git solution having issues on iOS clients, for example ) reply nsteel 2 hours agorootparentDoes Remotely Save not work on iOS? If it does, you can host a WebDAV server on your NAS. reply entilzha 12 hours agoparentprevWhile you’re here, a killer feature for me would be the ability to privately host obsidian sites (similar to publish). Even if it required subscribing to publish to download a tarball of the site (that isn’t public), it could still be worth it. My use case is sharing obsidian notes with non-users (eg coworkers) in a private way. reply kepano 12 hours agorootparentThere are a few options for this already. A good one just came out a few days ago called Quartz: https:&#x2F;&#x2F;github.com&#x2F;jackyzha0&#x2F;quartz reply entilzha 11 hours agorootparentI tried a few a while back. What I really want is as close to 1-1 to obsidian UI as possible. I found with some of the plugins that it could be hit&#x2F;miss on working correctly. If I were doing only markdown notes, then wouldn’t need obsidian ;) reply mind-blight 10 hours agoparentprevI love your reply here, and your product . Have you considered trying to implement a collaborative document editing tool? I would definitely pray for shared vaults that allow multiple users to modify files reply vGPU 12 hours agoparentprevI was previously using a third party sync solution, but guess who just got a new subscription? reply j_0 8 hours agoparentprevThank you kepano. I love this response and will continue to support Obsidian while cheering on this project that taps into your platform. reply shepherdjerred 6 hours agoparentprevJust wanted to say thank you for not attacking&#x2F;threatening the creator! reply jrgaston 10 hours agoparentprevObsidian is a great product, thank you! And the optional Sync service works beautifully to keep my files synched between Windows, iPhone, and iPad. reply stereoradonc 11 hours agoparentprevGive him sync for free! Or atleast let me sponsor the kid. reply kepano 11 hours agorootparentI don&#x27;t want to reduce his motivation to learn how to reverse engineer things! I learned a lot from those kinds of projects. However, we do have a way to gift someone a subscription[1]@acheong08 if you want a Sync subscription I&#x27;ll be happy to cover it.[1]: https:&#x2F;&#x2F;help.obsidian.md&#x2F;Licenses+and+payment&#x2F;Gifting reply y-curious 8 hours agorootparentGod you are so nice! Have a great day, love your product reply rogeliodh 11 hours agoparentprevPlease consider regional prices. US$8 monthly is high for in-develop countries reply kepano 11 hours agorootparentThis is very hard for us to do because we want to remain a small team — it will introduce a lot of complexity for payments&#x2F;localization reply gandalfgreybeer 3 hours agorootparentI never tried Obsidian because the recurring price was too steep for me and I understand that localization will be a challenge. I do have to say, however, that your responses here actually sound sincere (and the reaction to OP&#x27;s project is something I would not have expected) to the point that if I really need something similar to your product, I am definitely reconsidering.I wish you and your team good luck. reply poglet 9 hours agoparentprevWould love to get Dropbox support on iOS reply surge 17 hours agoprevYou&#x27;re prob not violating ToS since you&#x27;re not doing it for commercial use, and you&#x27;re actually reinventing the wheel as a couple of options for that are already available as community plugins. I&#x27;ve been using Remote-save for a while with a almost free private S3 bucket and encryption to sync between my computers and phone for a while.https:&#x2F;&#x2F;github.com&#x2F;remotely-save&#x2F;remotely-saveIt supports more than just S3 (as is listed in the README), its just what I use.That said, what you made is pretty cool. I guess you&#x27;re trying to replace the API&#x2F;backend similar to Vaultwarden does with BitWarden paid service.For me, its not that I can&#x27;t afford $8 a month, its just that $8 is to me fairly steep for basic file storage and sync I get for free from some services. $12 a year would be a fair price to me. I get some of it goes to support Obsidian development, but still seems steep, $2-3 a month would be something I&#x27;d subscribe for. reply nsteel 16 hours agoparentRemotely save is excellent. I use it with WebDAV to work between my computers, phone and tablet. reply echelon 15 hours agoparentprevIf Obsidian stops acheong08, I&#x27;m done with Obsidian.I want a durable way to edit, sync, and preserve my notes, not just a pretty interface.I&#x27;m happy to pay Obsidian for sync, but if they PM this to only one distribution channel and subsequently enshittify it, I don&#x27;t want it. Stopping acheong08 would be a bad signal forewarning what&#x27;s to come. reply Xeophon 13 hours agorootparentCEO Reply: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=37253639 reply rs_rs_rs_rs_rs 13 hours agorootparentprevDude, just pay the $8, no reason to cluch your pearls like that. reply echelon 13 hours agorootparentI don&#x27;t think my comment was uncalled for. The OP was worried they broke the TOS by writing their own service. I wanted to reassure them that any move by Obsidian to squash them would be met with incredible scrutiny.I already pay Obsidian, both monthly and with the one-time donation. I mentioned it in my comment. My post was upvoted +3 until you responded with snark. Now it&#x27;s at -4.Not sure how I&#x27;m pearl clutching. reply solarkraft 15 hours agoprevSyncthing actually works pretty well when you have a tool that automatically resolves sync conflicts: https:&#x2F;&#x2F;discuss.logseq.com&#x2F;t&#x2F;automatically-merge-syncthing-c... reply freedomben 13 hours agoparentI&#x27;m using Syncthing to keep in sync between a desktop and two Android phones over tailscale, and it works pretty good, but I have to occasionally open the Syncthing app on Android to \"bump\" it and get it to sync. It&#x27;s in a git repo (which syncthing handles great even though there are some older posts online telling you not to do that), and on the desktop I can review and \"sanity check\" stuff and then commit it to ensure it is safe. Overall a good solution. reply ephbit 2 hours agorootparent> .. I have to occasionally open the Syncthing app on Android to \"bump\" it and get it to sync.Almost the same with me.Turning WIFI off and on again is easier on my Android, it triggers syncthing to sync. But that might also require you to have set the run conditions of syncthing accordingly. reply UltimateEdge 13 hours agorootparentprevWhy not exclude the .git directory from being synced, if you&#x27;re not going to be committing on your mobile devices? This is what I do. reply karpour 15 hours agoparentprevI&#x27;m using syncthing with Obsidian but of course i have regular conflicts which i just deal with manually. Thanks for pointing me to this! reply runjake 13 hours agorootparentFWIW, I get sync conflicts with Obsidian Sync pretty regularly. They&#x27;re always pretty minor and not worth complaining about, but they happen nonetheless, and it may not be entirely SyncThing&#x27;s fault. reply dmje 16 hours agoprevFWIW - the sync service provided by Obsidian is really worth paying for. Dropbox &#x2F; Github just aren&#x27;t as slick and integrated. The mobile app doesn&#x27;t work without sync (not without some really nasty workarounds), the option to \"view sync version history\", the fact that it&#x27;s rock solid... all worth paying for IMO. reply input_sh 15 hours agoparentYeah I can think of 30 different ways to make the sync work, but I can&#x27;t be bothered to, Sync works really well, and I feel like financially supporting the Obsidian team in some way.$8&#x2F;month is a bit steep, but I snatched $5&#x2F;month early bird pricing and I consider that to be a lot more acceptable of a price.Edit: worth pointing out there&#x27;s a 40% discount for non-profits and students: https:&#x2F;&#x2F;help.obsidian.md&#x2F;Licenses+and+payment&#x2F;Education+and+... reply Sytten 8 hours agorootparentIt kind of boggles my mind when people say 8$&#x2F;month is steep. I get that we don&#x27;t all live in rich countries, but still. If you are using a tool everyday this is really not much. I think we have been conditioned to expect software to be free. Maybe because there is nothing tangible?It&#x27;s also hard to do micro payments on the internet ironically, on that 8$ you can easily pay almost a dollar of fees. If that wasnt the case I expect we would have a much different internet... reply nsteel 2 hours agorootparentOf course not everyone uses the app every single day. That&#x27;s a poor assumption to make.I think nearly $100 a year is steep for something that doesn&#x27;t meet my needs (I use a community sync plugin instead). So I made a one-time donation instead because I still want to support the core product. I only recently realised you can do this: https:&#x2F;&#x2F;help.obsidian.md&#x2F;Licenses+and+payment&#x2F;Catalyst+licen... reply justusthane 8 hours agorootparentprevSure, $8 by itself isn’t much, but when everything costs $8&#x2F;mo it starts to add up.I just had similar sticker shock recently to the remote access service for Home Assistant, which is $6.50&#x2F;mo. You still have to host and maintain HA locally, the service just allows you to easily access it remotely.Or Kagi Search, which charges $25&#x2F;mo for unlimited searches.For me, if it’s more than $5&#x2F;mo it better be something I really need. reply edizms 5 hours agorootparentprevDude you use ironically for no good reason, no wonder you don&#x27;t understand how much $8 is in many countries. Utter ignorance. reply Already__Taken 2 hours agorootparentprevalso consider this is a note app to run your life with. 8&#x2F;mo forever is a lot. is rather but 12 months and if I do use it buy it for life reply xmprt 16 hours agoparentprevI haven&#x27;t tried Dropbox or Github or Syncthing like others have suggested but having tried Obsidian Sync I&#x27;m not as impressed as everyone else seems to be. Maybe I need to set my bar lower but especially on my phone, background sync doesn&#x27;t work well and it usually takes a few seconds to load and a few more seconds to sync the data which feels like ages considering all the data required to load it is already on my phone and the diff is a few paragraphs at most. reply BrandoElFollito 13 hours agoparentprev> The mobile app doesn&#x27;t work without sync (not without some really nasty workarounds)You simply synchronize the folder as with the desktop apps. Works right of the box without any workarounds. reply m3adow 1 hour agorootparentYeah, not sure what this guy is talking about. I&#x27;m syncing my notes with my Nextcloud using the FolderSync App on Android which I used for other stuff anyways. Works like a charm, never had any problems.Obsidian is great, but I&#x27;m not paying over 90 bucks a year for a simple file syncing service I can build in less than an hour.Maybe the publish feature is worth it, but I&#x27;m content with the ObsidianPublisher workflow I set up for now. reply ytechie 16 hours agoparentprevIt works great for me just using iCloud Drive. reply iamdamian 8 hours agorootparentI tried iCloud Drive and didn&#x27;t mind it. I ended up moving to Sync, though, because 1) it&#x27;s end-to-end encrypted and 2) I can sync any directory, not just subdirectories of iCloud Drive. reply acheong08 16 hours agoparentprev> view sync version historyActively working on that. It’s a feature I’ll need since I mess up *very often* reply MH15 15 hours agoprevI&#x27;ve been using the main Obsidian git extension, https:&#x2F;&#x2F;github.com&#x2F;denolehov&#x2F;obsidian-git. Took some work to set it up ergnonomically but it works great now. I enabled auto-commit and push on save, and auto-pull when you start the editor. No merge conflicts yet between two machines.Should note I use Obsidian for a journal, so it&#x27;s pretty much append-only. reply microflash 4 hours agoparentObsidian Git has been working great for me too. I use different configuration directories for each device to avoid configuration conflicts. It works very seamlessly once set up. reply rodja_ 14 hours agoprev> I&#x27;m a recent high school graduate and can&#x27;t afford $8 per month for the official sync serviceWhat happened to the $47000 you got from Apple [1]?[1]: https:&#x2F;&#x2F;medium.com&#x2F;bugbountywriteup&#x2F;how-i-earned-47000-usd-a... reply Arch485 13 hours agoparentThat&#x27;s about 1 year of tuition in NA; OP is probably saving it for that reply freedomben 13 hours agorootparentDang, if money isn&#x27;t plentiful, there are way cheaper options in NA than that. A good school can definitely help you network with future successful people and to some orgs the name on the diploma can help open some doors, but the degree is less needed nowadays than it&#x27;s ever been. reply acheong08 8 hours agorootparentIt covers 2 years of tuition and a bit of living costs in UK. However, I’ve now lost financial support from my parents since I can “just earn it yourself” and I’m in no hurry to go into debt. Will probably work part time during the first two years to cover whatever is missing. reply vGPU 12 hours agoparentprevThe OP stated at the bottom that he was saving it for tuition. reply gandalfthepink 7 hours agoprevOP This is not addressed to you but to other folks in the comments.The two obsidian itself is very open and it&#x27;s free for use. Those making demands to reduce price or make the project open source are just thankless. How do you plan to make the business sustainable? Someone has to pay developer salaries, right?You want open source? Use MarkText, Zettlr. The company is generous enough to offer the main product for free. reply aae42 17 hours agoprevi use https:&#x2F;&#x2F;github.com&#x2F;vrtmrz&#x2F;obsidian-livesync and self-host a couchdb instance for it...this looks like it might be a bit cleaner once it&#x27;s all fleshed out... reply fold3 6 hours agoparentI use this as a docker instance running on my old laptop. It just took a minute to set up and works really well. The sync is as good as apple notes or whatever commercial software there is.Only issue is i could not sync with an old iphone running iOS 12. reply codetrotter 14 hours agoparentprevCouchDB is pretty nice, and gets less attention on HN than it deserves I think.First time I heard about CouchDB was many years ago. I bought an O’Reilly book about it, even. At the time MongoDB was gaining a lot of traction, and I think because of that many people overlooked CouchDB.I recently remembered CouchDB because I have some projects that could potentially benefit from replication between multiple machines. And in the case of my projects I think the database level would be an appropriate place to do replication. Hence CouchDB is an interesting proposition for my projects.I installed CouchDB on my laptop for the first time in ages, and started inserting documents into it with a third party library for Rust. So far it is working nicely. reply AlphaWeaver 12 hours agoprevWhat I&#x27;ve long been looking for is a sync service that handles syncing these directories of markdown, but then provides value added HTTP APIs on top of them.I can sync my markdown files from place to place with ease, but what I really want is the ability to POST myserver.com&#x2F;newpage and have it artificially inject a new Markdown file at the path I request.This could be system agnostic, Obsidian, Logseq, and tons of other local markdown knowledge bases could benefit from this. reply icedchai 11 hours agoparentSo you want WebDAV support? reply stephenr 4 hours agorootparentThis would be quite good if it also used SVN&#x27;s autoversioning mode (essentially a webdav client can create new versions of a document in svn without knowledge of svn). reply packetlost 15 hours agoprevI wish Obsidian had a better outliner mode&#x2F;plugin so I could switch to it from Logseq, but I just love the outliner&#x2F;block mode too much. reply malnourish 13 hours agoparentYep; I switched from Obsidian to Logseq because Logseq works the way I always wanted to take notes. They are both great tools, even if Logseq lacks some in the polish department (and honestly, it&#x27;s pretty good). reply packetlost 12 hours agorootparentI really wish Logseq had better&#x2F;more plugins, a less janky sync option, and publish. Maybe it&#x27;ll get there, but I kinda doubt it. I&#x27;ve toyed with creating a plugin for neovim that parses Logseq formatted markdown and gives me a similar experience, but it would be a lot of work. reply shanusmagnus 7 hours agorootparentTheir text editor is shit, their UI is shit (see e.g., their new right pane), and they keep going off and spending all their energy developing features that nobody is asking for, e.g., whiteboards. I assume most of this is bc they&#x27;re trying to differentiate somehow after having taken VC funding. Frustrating.Unfortunately, I expect Obsidian to have a serviceable outline mode before I expect Logseq to turn out a polished product. For god&#x27;s sake, take on that Neovim project, and post about it! reply istjohn 5 hours agorootparentprevI was suprised at how smooth Obsidian&#x27;s vim-mode is. reply fnfontana 12 hours agoprevI&#x27;d like to take this opportunity to say that I&#x27;ve been using and following Obsidian&#x27;s development since 2020 and I really appreciate the way your company supports the open source community! reply sandeep1998 5 hours agoprevI sync my obsidian notes in a git repo! reply threatofrain 17 hours agoprevWhat&#x27;s wrong with using Dropbox or Github? reply bitvoid 17 hours agoparentI can&#x27;t speak for OP&#x27;s motives, but one reason one might do this is because you can&#x27;t sync via Dropbox or Github on iOS. You can only use iCloud or Obsidian Sync. reply timrichard 16 hours agorootparentI use Obsidian on MacOS, iOS and Android, and keep my Vault on GitHub. I use Working Copy on iOS and PocketGit on Android to pull and commit&#x2F;push changes. reply rg111 16 hours agorootparentprevWhat about MEGA?Been using this way for years. reply euazOn 11 hours agorootparentPlease would you care to share your workflow? I, too, would love to sync my Obsidian vault via MEGA, but I have only recently switched to an iPhone. On Android, it works perfectly with the 3rd party Autosync for MEGA app (paid, I believe). reply oktwtf 17 hours agoparentprevI had to shell out for another app[0] on the iPhone to allow for a fairly seamless GitHub workflow. Not sure if it’s changed in recent times. It works great, but I’d imagine something more tightly coupled with obsidian.md would eliminate that need?0: https:&#x2F;&#x2F;workingcopy.app&#x2F; reply cjwoodall 15 hours agorootparentI did out together this blog post a while for doing this for free using ashellhttps:&#x2F;&#x2F;cwoodall.com&#x2F;posts&#x2F;2022-01-02-obsidian-ios-sync&#x2F; reply princevegeta89 17 hours agoparentprevThey are still 3rd parties - only good if you&#x27;re using E2E encryption. Additionally, Dropbox free version has a 3-device limit at any time. On Android you have to use something like DropSync to enable background syncing which may not be ideal.Git(hub) may be an okay choice though. But there would be issues like no SSH support for Git on Mobile clients. reply msm_ 14 hours agoparentprevWhat&#x27;s wrong with getting an FTP account, mounting it locally with curlftpfs, and then using SVN or CVS on the mounted filesystem? reply threatofrain 14 hours agorootparentDropbox is a consumer product, while Github is a nerd&#x27;s product. I put them both to indicate the range of options.Dropbox or iCloud are solutions you could put on a blog for folks who have no interest in learning how to use a CLI. reply kergonath 15 hours agoprev> I&#x27;m probably violating the TOS, and I&#x27;m sorry.Reverse engineering is fine. It certainly is from a moral point of view, and also from a legal one in a lot of jurisdictions.TOS depend more on the fact that you’ll behave than on whether they can actually be enforced (most have unenforceable clauses). reply w10-1 14 hours agoparentI think we should be careful when advising young or inexperienced people hacking for the joy of it, lest they make mistakes that are hard to recover. Time is precious -- better to choose wisely than learn from experience.> Reverse engineering is fine...from a legal [perspective] in a lot of jurisdictionsSorry, what jurisdiction permits one to violate a contract against reverse-engineering?This is a pretty big problem that can&#x27;t be hand-waved away. Companies everywhere have mere copyright on some materials that they make available if you agree e.g., not to reverse-engineer the interface or distribute the materials, essentially hoisting copyright to contract. This is how Java has worked for decades.> Reverse engineering is fine. It certainly is from a moral point of viewIn this case, the server is how Obsidian funds their work, offering free and paid parts. They&#x27;re clear about it up front; they don&#x27;t entice you and switch terms after you&#x27;re committed. So how is it morally justifiable in this case?> most have unenforceable clausesThe \"enforcement\" is not that they win their case, but the threat that they can take you to court and force you to pay a lot of money to escape the contract, especially in cases where you have significant investments or income. Unless you&#x27;re dedicated to being so irrelevantly small that no one cares, why waste time building IP you can&#x27;t benefit from, or telling the world that you don&#x27;t care?For people starting out, I would recommend picking viable projects, i.e., relevant to others, not illegal, not on dying technologies. They can exemplify not only your skills but also your judgment, and introduce you to the whole lifecycle of OS development if they have any legs.And it may be best to find an unoccupied niche; in this case, there are alternatives already (better to invent than re-invent). (Unless you aspire to being a giant-killer :)That&#x27;s in part why the standard young-entrepreneur pattern is to pick new applications of emerging technologies, particularly those that irreversibly disrupt old industries or build new markets.In this case there are many note-taking applications with syncing server. The unique project today e.g., might be to update an existing sync alternative to maintain a semantic model and then publish semantic cross-references, or publish a results of AI queries over the evolving set of highly-trafficked semantic topics. reply lijok 16 hours agoprevDoes anyone know whether Obsidian can do this with some plugin, or whether there&#x27;s another tool that can:I&#x27;m looking for a documentation tool with a decent GUI for editing documentation in, which is backed by git for tracking changes, without having to have git configured locally (for non-engineers). reply acheong08 16 hours agoparentOh sorry. I misread. Ignore my other comment. I forgot my password and can’t edit using the site. Using third party app for HN reply acheong08 16 hours agoparentprevI think there are a few plugins via git etc. Syncthing also seems to be recommended but doesn’t work on IOS reply jazzyjackson 16 hours agoparentprevhttps:&#x2F;&#x2F;www.gitbook.com&#x2F; reply mwilding 7 hours agoprevI work behind a firewall, Between the canvas and the kanban plugin, I have been able to manage some fairly complex software development coordination. reply aftbit 14 hours agoprevNice work, keep scratching itches and you&#x27;ll go far, whether you take this as a career or just a hobby. reply jeffmcneill 6 hours agoprevWhy nother, just use Syncthing. reply jeffmcneill 6 hours agoprevWhy bother, just use Syncthing reply dnxx 14 hours agoprevI&#x27;m still looking for a way to securely store and sync my Obsidian or Logseq notes with iOS. By \"securely\" I mean data encrypted at rest on the device, but also encrypted on an external server. It seems impossible. reply gettodachoppa 10 hours agoprev> To the creators of Obsidian.md: I&#x27;m probably violating the TOS, and I&#x27;m sorry. I&#x27;ll take down the repository if asked. It&#x27;s not ready for production and is highly inefficient; Not competition, so I hope you&#x27;ll be lenient.Brother, don&#x27;t be a wimp. You&#x27;re giving people an open-source plan B to a closed-source product. Do this with your head and middle fingers raised high. Do you think Richard Stallman apologized to HP for reverse-engineering their printer driver? No, he started the whole open-source movement.If you&#x27;re worried about legal consequences, learn what people used to do 20 years ago, which is use pseudonyms instead of their real names. Create a burner email, burner identity, new Github account, and give American tech corps the finger as you write what you want. reply acheong08 8 hours agoparentFWIW that’s the approach I took with OpenAI. However, Obsidian is a genuinely cool product especially considering that the client app is free. It’s not 100% justifiable to affect the business of a non-VC-backed company. reply JSavageOne 14 hours agoprev [–] What is it that people love about Obsidian? (not trying to throw shade, genuine question as I never understood the hype)Obsidian is not able to open a local folder on my machine stored in Windows Subsystem for Linux, which for me makes it a non-starter (my personal knowledge base is stored there).I personally prefer the Notion UI but hate being locked into their cloud, so I created an offline-first Notion alternative [1]. Offline mode is totally free (no user registration required), and aiming to add cloud syncing tomorrow or so. Still in active dev so needs a lot of work, but wondering whether others might find this useful. Goal is to make it be able to seamlessly sync across multiple data sources, and also easily to publish files&#x2F;folders (eg. can currently turn folders into APIs when synced to cloud).[1] https:&#x2F;&#x2F;mindgarden.app reply noahmasur 14 hours agoparent> What is it that people love about Obsidian?When Obsidian launched, there was already a lot of hype building in the note-taking community around Zettelkasten and Roam Research. With Roam, basically any word in your note could immediately link to another note, and you could see backlinks in your notes prominently.However, Roam was both expensive and online-only, so when Obsidian came out and it was: a) polished, b) provided most of the functionality of Roam, and c) was offline and plain-text (also unlike Notion), it was an immediate hit.The other special feature Obsidian offered was easy and powerful customization. The major settings are actually core plugins that can be enabled or disabled (like daily journal, tagging, or slideshows). Plugins and themes are easily discovered and installed from inside the app, which has led to a vibrant and popular plugin community. All you need is one plugin to be indispensable for users to never leave. reply fletchowns 13 hours agoparentprevFor me, it&#x27;s comments like this from the Obsidian CEO (from this very post):> The nice thing about storing all your notes on your device is that it makes it possible to move and edit your Markdown files in many different ways. That diversity of solutions is what makes the ecosystem of Markdown tools resilient over the long term.I had seen similar comments in the past, and it just made me like Obsidian even more.I&#x27;ve been using Obsidian for a few months now and loving it, and I had been meaning to find a way to support them financially in their endeavors. They share the same values that I do about the longevity of my notes :) I just purchased a Catalyst license. reply viraptor 14 hours agoparentprevIt&#x27;s a bit subtle and I didn&#x27;t get it for a long time either. But the features are great: I want the content available as portable simple text, I love the text representation for the extras like graphs and math, I love the offline apps. Look through the community plugins to see lots of other cool ideas. I started using it this year and I&#x27;ve not been that excited about basically a text editor in ages. reply llimllib 14 hours agoparentprev- it&#x27;s simple - (it&#x27;s also customizable so it doesn&#x27;t _have_ to be, but I happen to like pretty much the default features)- it&#x27;s free if you don&#x27;t need their sync - I just save my vault on an iCloud drive, which is convenient to me, and publish to the web with my own tool- it allows me to keep my files where I want them- it&#x27;s available on every platform I use- the UI is not distracting, and is Good Enough™ reply EspressoGPT 14 hours agoparentprev [–] > What is it that people love about Obsidian? (not trying to throw shade, genuine question as I never understood the hype)Tribalism. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A high school graduate has developed a sync service for Obsidian.md, providing an alternative to the official paid service.",
      "While the service is still in development and lacks some features, it offers basic sync functionality.",
      "The creator is aware of potential violations of the terms of service and is willing to remove the repository if necessary. The service is not aimed at competing with the official offering."
    ],
    "commentSummary": [
      "Users express satisfaction and support for Obsidian, a note-taking app, discussing various aspects such as sync service, pricing, user interface, and alternative options.",
      "The CEO of Obsidian responds to user feedback and announces upcoming improvements to the app.",
      "Some users suggest open-sourcing Obsidian and mention alternative syncing options, while others have varying opinions on different aspects of the app's features."
    ],
    "points": 318,
    "commentCount": 126,
    "retryCount": 0,
    "time": 1692878104
  },
  {
    "id": 37253035,
    "title": "FreeBSD on Firecracker",
    "originLink": "https://www.usenix.org/publications/loginonline/freebsd-firecracker",
    "originBody": "This website uses cookies We use cookies to personalise content and ads, to provide social media features and to analyse our traffic. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Consent Selection Necessary Preferences Statistics Marketing Show details Deny Allow selection Allow all Skip to main content USENIX supports diversity, equity, and inclusion and condemns hate and discrimination. About Conferences Publications Membership Students Donate Today Sign In Search Join the conversation Back to ;login: Online FreeBSD on Firecracker Experiences porting FreeBSD 14 to run on the Firecracker VMM August 22, 2023 DEPLOYED SYSTEM Authors: Colin Percival Article shepherded by: Rik Farrow Alarge amount of fantastic open source software originates from “scratching an itch”. Such was the case with Firecracker. In 2014, Amazon launched AWS Lambda as a “serverless” compute platform: Users can provide a function — say, ten lines of Python code — and Lambda provides all of the infrastructure between an HTTP request arriving and the function being invoked to process the request and generate the response. To provide this service efficiently and securely, Amazon needed to be able to launch virtual machines with minimal overhead. Thus was born Firecracker: A Virtual Machine Monitor which works with Linux KVM to create and manage “microVMs” with minimal overhead. Why FreeBSD on Firecracker? In June 2022, I started work on porting FreeBSD to run on Firecracker. My interest was driven by a few factors. First, I had been doing a lot of work on speeding up the FreeBSD boot process and wanted to know the limits that could be reached with a minimal hypervisor. Second, porting FreeBSD to new platforms always helps to reveal bugs — both in FreeBSD and on those platforms. Third, AWS Lambda only supports Linux at present; I’m always eager to make FreeBSD more available in AWS (although adoption in Lambda is out of my control, Firecracker support would be a necessary precondition). The largest reason, however, was simply because it’s there. Firecracker is an interesting platform, and I wanted to see if I could make it work. Launching the FreeBSD Kernel While Firecracker was designed for Lambda’s needs — launching Linux kernels — there were patches available from 2020 that added support for the PVH boot mode in addition to “linuxboot”. FreeBSD had support for PVH booting under Xen, so I decided to see if that would work. Here I ran into the first problem: Firecracker could load the FreeBSD kernel into memory but couldn’t find the address at which to start running the kernel (the “kernel entry point”). According to the PVH boot protocol, this value is specified in an ELF Note — a piece of special metadata stored in ELF (Executable and Linker Format) files. It turned out that there are two types of ELF Notes: PT_NOTEs and SHT_NOTEs, and FreeBSD wasn’t providing the one Firecracker was looking for. A small change to the FreeBSD kernel linker script fixed this, and now Firecracker was able to start executing the FreeBSD kernel. That lasted for about 1 microsecond. Early Debugging FreeBSD has wonderful debugging functionality, but if your kernel crashes before the debugger is initialized or the serial console is set up, you’re not going to get much help. In this case, the Firecracker process exited, telling me that the FreeBSD guest hit a triple-fault — but that’s all I knew. It turned out, however, that this was enough information to get me started, given a bit of creativity. If the FreeBSD kernel execution reached a hlt instruction, the Firecracker process would keep running but use 0% of the host’s CPU time (since it was virtualizing a halted CPU). As such, I could distinguish between “FreeBSD is crashing before this point” and “FreeBSD is crashing after this point” by inserting a hlt instruction — if Firecracker exited, I knew that it was crashing before reaching that instruction. Thus started a process I referred to as “kernel bisection” — rather than bisecting a list of commits to find one which introduced a bug (as in git bisect) I would do a binary search through the kernel startup code to find the line of code that was making FreeBSD crash. Xen Hypercalls The first thing I discovered in this process was Xen hypercalls. The PVH boot mode originated as the Xen/PVH boot mode, and FreeBSD’s PVH entry point was, in fact, an entry point specifically for booting under Xen — and the code made the quite reasonable assumption that it was, indeed, running inside Xen and could thus make Xen hypercalls. KVM (which provides the kernel functionality used by Firecracker) is not Xen, of course, so it doesn’t provide those hypercalls; attempting to use any of them resulted in the virtual machine crashing. As an initial workaround, I simply commented out all the Xen hypercalls; later, I added code to check CPUID for a Xen signature before making calls e.g., to write debugging output to the Xen debug console. There was one Xen hypercall that provided essential functionality, however: Retrieving the physical memory map. (Of course, inside a hypervisor, the “physical” memory is only virtually physical. It’s turtles all the way down.) Here, we’re saved by the fact that Xen/PVH was retroactively declared to be version 0 of PVH boot mode: From version 1 onwards, a pointer to the memory map is passed via the PVH start_info page (a pointer to which is provided in a register when the virtual CPU starts executing). I had to write code to make use of the PVH version 1 memory map instead of relying on a Xen hypercall to get the same information, but that was easy enough. Another related issue arose from how Xen and Firecracker arrange structures in memory: Whereas Xen loads the kernel first and then places the start_info page at the end, Firecracker placed the start_info page at a fixed low address and then loaded the kernel afterwards. This would have been fine but that FreeBSD’s PVH code – having been written with Xen in mind — assumed that the memory immediately after the start_info page would be free for use as scratch space. Under Firecracker, that very quickly meant overwriting the initial kernel stack — not an optimal outcome! A change to FreeBSD’s PVH code to assign scratch space after all the memory regions initialized by the hypervisor fixed this problem. ACPI — or Lack Thereof! On x86 platforms, FreeBSD normally makes use of ACPI to learn about (and in some cases control) the hardware on which it is running. In addition to discovering things via ACPI which we might commonly think of as “devices” — disks, network adapters, etc. — FreeBSD also learns about fundamental things like CPUs and interrupt controllers via ACPI. Firecracker, being deliberately minimalist, does not implement ACPI, and FreeBSD gets upset when it can’t figure out how many CPUs it has or where to find their interrupt controllers. Fortunately, FreeBSD has support for the historic Intel MultiProcessor Specification, which provides this critical information via an “MPTable” structure; it’s not part of the GENERIC kernel configuration, but for running in Firecracker, we want to use a stripped-down kernel configuration anyway, so it was easy to add device mptable to make use of what Firecracker provides. Except… it didn’t work. FreeBSD still couldn’t find the information it needed! It turned out that Linux has bugs in how it finds and parses the MPTable structure — and Firecracker, being designed to boot Linux, provided the MPTable in a way that Linux supported but was not in fact compliant with the standard. FreeBSD, having an implementation independently written to follow the standard, failed both to find the (incorrectly located) MPTable and to parse the (invalid) MPTable once it was found. So now FreeBSD has a new kernel option: You can add options MPTABLE_LINUX_BUG_COMPAT to your kernel configuration if you need bug-for-bug compatibility with Linux’s MPTable handling — and with that, FreeBSD managed to boot a bit further in Firecracker. Serial Console One of the few emulated devices — as opposed to virtualized devices like the Virtio block and network devices — provided by Firecracker is the serial port. In fact, in a common configuration, when you launch Firecracker, the standard input and output of the Firecracker process become the serial port input and output of the VM, making it seem like the guest OS is just another process running inside your shell (which, in a certain sense, it is). At least, that’s how it’s supposed to work. By this point in the process of bringing up FreeBSD inside Firecracker I was able to boot a FreeBSD kernel with a root disk compiled into the kernel image — I didn’t have the virtualized disk driver working yet — and read all the console output from the kernel. After all the kernel console output, however, FreeBSD entered the userland portion of the boot process, and I got 16 characters of console output — and then it stopped. Funnily enough, I’d seen that exact symptom over ten years earlier, when I was first getting FreeBSD working on EC2 instances. A bug in QEMU resulted in the UART not sending an interrupt when the transmit FIFO emptied; FreeBSD wrote 16 bytes to the UART and then wouldn’t write anymore because it was waiting for an interrupt which never arrived. Modern EC2 instances run on Amazon’s “Nitro” platform, but in the early days they used Xen and devices were emulated using code from QEMU. Somehow, a decade after this bug was fixed in QEMU, exactly the same bug was implemented in Firecracker; but luckily for me, the workaround I put into the FreeBSD kernel — hw.broken_txfifo=”1” — was still available, and adding that loader tunable (which, since Firecracker loads the kernel directly without going through the boot loader, meant compiling the value into the kernel as an environment variable) fixed the console output. I then found that the console input was also broken: FreeBSD didn’t respond to anything I typed into the console. In fact, tracing the Firecracker process, I found that Firecracker wasn’t even reading from the console — because Firecracker thought that the receive FIFO on the emulated UART was full. This turned out to be another bug in Firecracker: While initializing the UART, FreeBSD fills the receive FIFO with garbage to measure its size and then flushes the FIFO by writing to the FIFO Control Register. Firecracker didn’t implement the FIFO Control Register, so it was left with a full FIFO and quite sensibly didn’t try to read any more characters to put into it. Here, I added another workaround to FreeBSD: If LSR_RXRDY is still asserted after we try to flush the FIFO via the FIFO Control Register — which is to say, if the FIFO didn’t empty as requested — we now proceed to read and discard characters one by one until the FIFO empties. With this, Firecracker now recognized that FreeBSD was ready to read more input from the serial port, and I had a working bidirectional serial console. Virtio Devices While a system without disks or network could be useful for some purposes, before we can do very much with FreeBSD, we’re going to want those devices. Firecracker supports Virtio block and network devices and exposes them to virtual machines as mmio (memory-mapped I/O) devices. First step to getting these working in FreeBSD: Add device virtio_mmio to the Firecracker kernel configuration. Next up, we need to tell FreeBSD how to find the virtualized devices. FreeBSD expected mmio devices to be discovered via FDT (Flattened Device Tree), which is a mechanism commonly used on embedded systems; but Firecracker passes device parameters via the kernel command line with directives such as virtio_mmio.device=4K@0x1001e000:5. Second step to getting these working in FreeBSD: Write code for parsing such directives and creating virtio_mmio device nodes. (Once we create the device node, FreeBSD’s regular process for device probing kicks in and the kernel will automatically determine the type of Virtio device and hook up the appropriate driver.) If we have multiple devices however — say, a disk device and a network device — another problem arises: Firecracker passes directives the way Linux expects — as a series of key=value pairs on the kernel command line — while FreeBSD parses the kernel command line as environment variables… meaning that if there were two virtio_mmio.device= directives passed on the command line, only one was retained. To fix this, I rewrote the early kernel environment parsing code to handle duplicate variables by appending a numbered suffix: We end up with virtio_mmio.device= for one device and virtio_mmio.device_1= for the second device. With this, I finally had FreeBSD booting and discovering all of its devices — but one more problem arose with disk devices: If I shut down the virtual machine uncleanly, on the next boot the system would run fsck on the filesystem, and the kernel would panic. It turned out that fsck is one of very few things in FreeBSD that will cause non-page-aligned disk I/Os, and FreeBSD’s Virtio block driver was causing a kernel panic when trying to pass unaligned I/Os to Firecracker. When an I/O crosses a page boundary — as will happen with page-sized I/Os which aren’t aligned to page boundaries — the physical I/O segments will typically not be contiguous; most devices can handle I/O requests which specify a series of segments of memory to be accessed. Firecracker, being extremely minimalist, does not do this: Instead, it accepts only a single data buffer — meaning that a buffer that crosses a page boundary can’t simply be split into pieces the way it would with other Virtio implementations. Fortunately, FreeBSD has a system in place specifically for taking care of device complications like this: busdma. This was probably the hardest part of getting FreeBSD running in Firecracker, but after several attempts, I think I finally got it right: I modified FreeBSD’s Virtio block driver to use busdma, and now unaligned requests are “bounced” (aka. copied via a temporary buffer) in order to comply with the limitations of the Firecracker Virtio implementation. Revealed Optimizations Once I had FreeBSD up and running in Firecracker, it rapidly became clear that there were some improvements to be made. One of the first things I noticed was that, despite having 128 MB of RAM in the virtual machine I was testing, the system was barely usable, with processes being frequently killed due to the system running out of memory. The top(1) utility showed that almost half of system memory was in the “wired” state, which seemed odd to me; so I investigated further, and found that busdma had reserved 32 MB of memory for bounce pages. This was clearly far more than needed — given Firecracker’s limitations and the fact that bounce pages are generally not allocated contiguously, each disk I/O should use at most a single 4 kB bounce page — and I was able to reduce this memory consumption to 512 kB with a patch to busdma which limited its bounce page reservations for devices which supported only a small number of I/O segments. FreeBSD’s kernel random number generator usually obtains entropy from hardware devices, but in virtual machines this may not be an effective source. As a backup source of entropy, on x86 systems we make use of the RDRAND instruction to obtain random values from the CPU; but we were only obtaining a very small amount of entropy on each request and were only requesting entropy once every 100 ms. Changing the entropy gathering system to request enough entropy to fully seed the Fortuna random number generator shaved 2.3 seconds off the boot time. When FreeBSD first boots, it records a Host ID for the system. This is typically obtained from hardware via the smbios.system.uuid environment variable, which the boot loader sets based on information from BIOS or UEFI. Under Firecracker, however, there is no boot loader — and thus no ID being provided. We had a fallback system in place that would generate a random ID in software on systems that didn’t have a valid hardware ID; but we also printed a warning and waited 2 seconds to allow the user to read it. I changed this code to print the warning and wait 2 seconds if the hardware provided an invalid ID, but proceed silently and quickly if the hardware simply didn’t provide an ID. IPv6 mandates that systems wait for “Duplicate Address Detection” before using an IPv6 address. In rc.d/netif, after bringing up interfaces, we were waiting for IPv6 DAD if any of our network interfaces had IPv6 enabled. There’s just one problem with that: We always have IPv6 enabled on the loopback interface! I changed the logic to only waiting for DAD if we had IPv6 enabled on an interface other than the loopback interface and sped up the boot process by 2 seconds — if another system is trying to use the same IPv6 address as us on our lo0, we have bigger problems than an address collision! When rebooting, FreeBSD printed a message (“Rebooting...”) and then waited 1 second “for printf’s to complete and be read”. This seemed minimally useful, since people can usually tell that the system is rebooting — there is now a kern.reboot_wait_time sysctl which defaults to zero. When shutting down or rebooting, the FreeBSD BSP (CPU #0) waits for the other CPUs to signal that they have stopped… and then waited an extra 1 second to make sure that they had a chance to stop. I removed the extra second of wait time. Once the low-hanging fruit was out of the way, I pulled out TSLOG and started looking at flamecharts of the boot process. Firecracker is a great environment for doing this, for two reasons: First, the minimalist environment eliminates a lot of noise, making it much easier to see what’s left behind; and second, having Firecracker launch virtual machines extremely quickly made it possible to test changes to the FreeBSD kernel very rapidly — often well under 30 seconds to build a new kernel, launch it, and generate a new flamechart. Investigation with TSLOG revealed a number of available optimizations: lapic_init had a 100000-iteration loop to calibrate how long lapic_read_icr_lo took to execute; cutting this down to 1000 iterations shaved off 10 ms. ns8250_drain called DELAY after each character was read; changing this to check for LSR_RXRDY and only DELAYing if nothing was already available to be read shaved off 27 ms. FreeBSD makes use of a CPUID leaf which most hypervisors use to advertise the TSC and local APIC clock frequencies; Firecracker, unlike VMWare, QEMU, and EC2, did not implement this. Adding support for this CPUID leaf to Firecracker shaved 20 ms off the FreeBSD boot time. FreeBSD was setting kern.nswbuf (which controls the number of buffers allocated for a variety of temporary purposes) to 256 regardless of the size of the system; changing this to 32 * mp_ncpus shaved 5 ms off the boot time on a small (1 CPU) virtual machine. FreeBSD’s mi_startup function, which kicks off machine-independent system initialization routines, was using a bubblesort to order the functions it called; while this was reasonable in the 90s given the small number of routines needing to be ordered at that point, there are now over 1000 such routines and the bubblesort was getting slow. Replacing it with a quicksort will save 2 ms. (Not yet committed as of 22 August 2023). FreeBSD’s vm_mem initialization routine was initializing vm_page structures for all available physical memory. Even on a relatively small VM with 128 MB of RAM, this meant initializing 32768 such structures — and took a few ms. Changing this code to initialize vm_page structures “lazily” as the memory is allocated for use will save 2 ms. (Not yet committed as of 22 August 2023.) Firecracker was allocating VM guest memory via an anonymous mmap, but Linux was not setting up the paging structures for the entire VM guest address space. As a result, the first time any page was read, a fault would occur taking roughly 20,000 CPU cycles to be resolved while Linux mapped in a page of memory. Adding the MAP_POPULATE flag to Firecracker’s mmap call will save 2 ms. (Not yet committed as of 22 August 2023.) Current Status FreeBSD boots under Firecracker — and does so extremely quickly. Including uncommitted patches (to FreeBSD and also to Firecracker), on a virtual machine with 1 CPU and 128 MB of RAM, the FreeBSD kernel can boot in under 20 ms; a flame chart of the boot process appears in Figure 1. Figure 1: Flame chart of the boot process for FreeBSD 14 on Firecracker. There is still work to be done: In addition to committing the patches mentioned above and getting PVH boot mode support merged to “mainline” Firecracker, there’s a significant amount of “cleanup” work to be done. Due to the history of PVH boot mode originating from Xen, the code used for PVH booting is still mixed up with Xen support; separating those will simplify things significantly. Similarly, it’s currently impossible to build a FreeBSD arm64 kernel without PCI or ACPI support; finding the bogus dependencies and removing them will allow for a smaller FreeBSD/Firecracker kernel (and also shave off a few more microseconds from the boot time – we spend 25 us checking to see if we need to reserve memory for Intel GPUs). More aspirationally, it would be great to see if Firecracker could be ported to run on FreeBSD — at a certain point, a virtual machine is a virtual machine, and while Firecracker was written to use Linux KVM, there’s no fundamental reason why it shouldn’t be possible to make it use the kernel portion of FreeBSD’s bhyve hypervisor instead. Anyone wanting to experiment with FreeBSD in Firecracker can build a FreeBSD 14.0 kernel with the amd64 FIRECRACKER kernel configuration, and check out the feature/pvh branch from the Firecracker project; or if that branch no longer exists it means the code has been merged into the mainline Firecracker tree. If you try out FreeBSD on Firecracker — especially if you end up using it in production — please let me know! I started this project mainly out of interest, but I’d love to hear if it ends up being useful. This article originally appeared in the July/August issue of the FreeBSD Journal. Article Categories: Operating SystemsCloudProgramming Last updated August 23, 2023 AUTHORS: Colin Percival has been a FreeBSD developer since 2004 and was the project’s Security Officer from 2005 to 2012. In 2006, he founded the Tarsnap online backup service, which he continues to run. In 2019, in recognition of his work bringing FreeBSD to EC2, he was named an Amazon Web Services Hero. cperciva@tarsnap.com Log in or Register to post comments © USENIX 2023 Website designed and built by Giant Rabbit LLC Privacy Policy Contact Us Sign up for Our Newsletter:",
    "commentLink": "https://news.ycombinator.com/item?id=37253035",
    "commentBody": "FreeBSD on FirecrackerHacker NewspastloginFreeBSD on Firecracker (usenix.org) 302 points by jmmv 15 hours ago| hidepastfavorite99 comments ryanrussell 3 minutes agoFirecracker is amazing, but has a lot of edge cases that need documentation.A huge thank you to Colin Percival for sharing this.Particularly love the \"Once the low-hanging fruit was out of the way\" line... which to Colin means custom bus_dma patch(es).Now anyone can now enjoy for free:\"with 1 CPU and 128 MB of RAM, the FreeBSD kernel can boot in under 20 ms\"If you&#x27;re used to devops with k8s clusters or lots of docker, this is absolutely amazing. reply garganzol 14 hours agoprevI never really realized that Firecracker VM is a full-blown machine and not just some sort of a Linux container tech. At first, it may sound like an ineffective approach, but if you take a closer look on a real-world usage example such as fly.io, you will be surprised: micro-VMs are very small and capable. reply mjb 13 hours agoparentIf you&#x27;re interested in learning more about that, check out our NSDI&#x27;20 paper on how we chose this direction (https:&#x2F;&#x2F;www.usenix.org&#x2F;conference&#x2F;nsdi20&#x2F;presentation&#x2F;agache) and the Firecracker source and docs (https:&#x2F;&#x2F;github.com&#x2F;firecracker-microvm&#x2F;firecracker).Thanks to KVM, and to the minimal hardware support (no PCI, no ACPI, etc), Firecracker&#x27;s source is rather simple and even relatively readable for non-experts. reply cperciva 11 hours agorootparentFirecracker&#x27;s source is rather simple and even relatively readable for non-experts.... as long as they&#x27;re experienced at writing Rust. As a Rust newbie it took me a long time to figure out simple things like \"where is foo implemented\", due to the twisty maze of crates and uses directives.I totally get why this code is written in Rust, but it would have made my life much easier if it were written in C. ;-) reply codetrotter 10 hours agorootparent> it took me a long time to figure out simple things like \"where is foo implemented\"Out of curiosity, what development setup do you use?I imagine that with vanilla EMacs or vanilla Vim you’d have to do quite a bit of spelunking to answer that sort of question.With a full-blown IDE like for example JetBrains CLion with Rust plug-in installed, it is most of the time a matter of right-click -> go to definition &#x2F; go to type declaration. (Although heavy use of Rust macros can in some cases confuse the system and make it unable to resolve definitions&#x2F;declarations.)And with JetBrains CLion you still have Vim keybindings available as a plug-in.I switched from Vim to CLion + plug-ins years ago and haven’t looked back since. (Vanilla Vim is still on my servers though so that when I ssh in and want to edit some config files or whatever I can do so in the terminal.) reply cperciva 9 hours agorootparentMy development environment for this was mostly \"nano in an SSH session\". (Among other reasons, I can&#x27;t even build Firecracker locally.) For FreeBSD work that&#x27;s just fine since grep can find things for me. It didn&#x27;t work so well for Firecracker. reply danielheath 8 hours agorootparentI&#x27;m surprised `grep` didn&#x27;t work for finding implementations. Did you find out why? Was it eg searching first-party source code but not crates? reply cperciva 7 hours agorootparentFiguring out how to get all the crate source code extracted was the first step, yes. But when after that, the object oriented nature meant that there were often many different foo functions, so I had to dig through the code to figure out what type of object I was dealing with and which type each of the different foo implementations dealt with.Whereas in FreeBSD I just grep for ^foo and the one and only line returned is where foo is implemented -- because if there&#x27;s different versions of foo, they have different names.Namespaces sound good in principle but they impose a mental load of \"developers need to know what namespace they&#x27;re currently in\" -- which is fine for the original developer but much harder for someone jumping into the code for the first time. reply rstuart4133 1 hour agorootparentIf you go to the web site for the crate (or the standard library), and find the doco for the module &#x2F; function &#x2F; trait &#x2F; ..., you find an handy \"source\" button. It will take you straight to the definition.Eg, (me picking a random crate on crates.io): https:&#x2F;&#x2F;docs.rs&#x2F;syn&#x2F;2.0.29&#x2F;syn&#x2F; or the standard library: https:&#x2F;&#x2F;doc.rust-lang.org&#x2F;std&#x2F;option&#x2F;index.htmlIt&#x27;s all generated by the same system from comments in the source. You can generate the same thing for your code. reply wbl 8 hours agorootparentprevEtags makes answering that fairly simple in a C codebase and emacs can be an lsp client. reply nonsense_stream 8 hours agorootparentprevIn comparison, I remember spending much less time finding \"where is foo implemented\" in Rust than in C++, and also found Rust std to be much more readable than C&#x27;s when I wasn&#x27;t familiar with each language. But I can see how rust with all the procedural macros, crates, traits could become a maze for people most familiar with C, and I probably don&#x27;t feel that because of my C++ background. reply tmpX7dMeXU 10 hours agorootparentprev“Writing things in C to appease the C people” is reasoning that can’t possibly die soon enough. You’ve had a good run. reply NovemberWhiskey 14 hours agoparentprevThere&#x27;s no way an \"enterprise grade\" cloud vendor like AWS would allow co-tenancy of containers (for ECS, Lambda etc) from different customers within a single VM - it&#x27;s the reason Firecracker exists. reply nilptr 13 hours agorootparent> There&#x27;s no way an \"enterprise grade\" cloud vendor like AWS would allow co-tenancy of containers (for ECS, Lambda etc) from different customers within a single VM - it&#x27;s the reason Firecracker exists.I won&#x27;t speak for AWS, but your assumption about what \"enterprise grade\" cloud vendors do is dead wrong. I know, because I&#x27;m working on maintaining one of these systems. reply lima 13 hours agorootparentLots of enterprise grade cloud vendors trust the Linux kernel boundary WAY too much... reply jen20 13 hours agorootparent“Enterprise grade” deserves scare quotes for those people of course! reply abwizz 56 minutes agorootparenti read it like \"military grade\" meaning it&#x27;s on the side of over-provisioned&#x2F;-engineered and will not break in obvious ways reply sharts 4 hours agorootparentprevI think bryan cantrill founded a company (joyent? or triton?) to do just that several years ago. It may have been based on solaris&#x2F;smartos zones which is that exact use case w&#x2F; very secure&#x2F;isolated containers. reply abwizz 53 minutes agorootparentalthou it came with linux binary compat (of unknown quality) i think the solaris thing was just too off putting for most customers and the company did not do very well reply monocasa 14 hours agorootparentprevDoes google? I know they use gvisor in production, which is ultimately enforced by a normal kernel (with a ton of sandboxing on top of it). reply eddythompson80 13 hours agorootparentGoogle is moving away from gvisor as well.The \"process sandbox\" wars are over. Everybody lost, hypervisors won. That&#x27;s it. It feels incredibly wasteful after all. Hypervisors don&#x27;t share mm, scheduler, etc. It&#x27;s a lot of wasted resources. Google came in with gvisor at the last minute to try to say \"no, sandboxes aren&#x27;t dead. Look at our approach with gvisor\". They lost too and are now moving away from it. reply Rapzid 11 hours agorootparentReally? Has gvisor ever been popped? Has there ever even been a single high-profile compromise caused by a container escape? Shared hosting was a thing and considered \"safe enough\" for decades and that&#x27;s all process isolation.Can&#x27;t help but feel the security concerns are overblown. To support my claim; Well, Google IS using gvisor as part of their GKE sandboxing security.. reply eddythompson80 10 hours agorootparentshared this link on another reply, but google moved away from gvisor to hypervisor for cloud run. It won&#x27;t be long before they do for GKE as wellhttps:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;serverless&#x2F;cloud-run-... reply tptacek 11 hours agorootparentprevI don&#x27;t know what \"popped\" means here, but so far as I know there&#x27;s never been a major incident caused by a flaw in gvisor. But gvisor is a much more intricate and carefully controlled system than standard Linux containers. Obviously, there have been tons of container escape compromises. reply jsolson 9 hours agorootparentprevNote that GKE Sandbox allows GKE users to sandbox the workloads running on GKE nodes. The GKE nodes themselves are still GCE VMs. reply RainbowFriends 12 hours agorootparentprevCitation needed. gvisor seems to be under active development and just added support for the systrap platform, deprecating ptrace: https:&#x2F;&#x2F;gvisor.dev&#x2F;blog&#x2F;2023&#x2F;04&#x2F;28&#x2F;systrap-release&#x2F; reply eddythompson80 10 hours agorootparentCloud run has abandoned gvisor in their \"second generation\" execution environment for containershttps:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;serverless&#x2F;cloud-run-...Obviously there might be many reasons for that, but as someone who worked on a similar gvisor tech for another company, it&#x27;s dead in the water. No security expert or consultant will ever sign off on a process isolation model. Despite of architecture, audits, reviews, etc. There is just too much surface area for anyone to feel comfortable signing off on hostile multi-tenants with process isolation regardless of the sandboxing tech.Not saying that there are no bugs in hypervisors, but the surface area is so so much smaller. reply coryrc 6 hours agorootparentThe first sentence pretty much sums it up: \"Cloud Run’s new execution environment provides increased CPU and network performance and lets you mount network file systems.\" It&#x27;s not a secret that performance is slower under gvisor and there are compatibility issues: https:&#x2F;&#x2F;gvisor.dev&#x2F;docs&#x2F;architecture_guide&#x2F;performance&#x2F;Disclaimer: I work on this product but wasn&#x27;t involved in this decision. reply tptacek 9 hours agorootparentprevgvisor isn&#x27;t simply a process isolation model. Security experts will certainly sign off on gvisor for some multitenant workloads. The reason Google is moving from it, to the extent they are, is that hypervisors are more performant for more common workloads. reply lima 13 hours agorootparentprev> Google is moving away from gvisor as well.I&#x27;ve been wondering about this - are they really? reply beardedwizard 13 hours agorootparentI have seen zero evidence of this; but if it&#x27;s true I would love to learn more. The real action is in side channel vulnerabilities bypassing all manner of protections. reply eddythompson80 10 hours agorootparentseehttps:&#x2F;&#x2F;cloud.google.com&#x2F;blog&#x2F;products&#x2F;serverless&#x2F;cloud-run-... reply pjmlp 13 hours agorootparentprevIn a way, it feels like a sweet revenge for microkernels. reply intelVISA 9 hours agorootparentprevTbf gvisor was pretty much DOA by design. Hypervisors are alright, but nowadays security expectations go much lower than ring-1. reply tptacek 8 hours agorootparentCan you expand on this? What do you mean \"security expectations go lower than ring-1\", and how does that relate to gvisor? reply pjmlp 3 hours agorootparentFor example what Microsoft is doing at firmware level for Azure. replybasique 13 hours agorootparentprevAren&#x27;t Cloudflare Workers multitenant? Although, if you want to be cynical, that could be a reason they aren&#x27;t &#x27;enterprise grade™&#x27;. reply tyingq 13 hours agorootparentThey are using v8 isolates, which is maybe easier to do in a sound way than the whole broad space of containers. Previous discussion: https:&#x2F;&#x2F;news.ycombinator.com&#x2F;item?id=31740885 reply mochomocha 12 hours agorootparentprevBoth Lambda firecracker VMs and t2 instances are multi-tenant and oversubscribed. reply tptacek 11 hours agorootparentI take them to mean \"multiple tenants sharing a kernel\"; I think everyone understands that AWS and GCP have multitenant hypervisor hosts. reply rewmie 11 hours agorootparentprev> There&#x27;s no way an \"enterprise grade\" cloud vendor like AWS would allow co-tenancy of containers (...)I don&#x27;t think your beliefs are well founded. AWS&#x27;s EC2 by default only supoprts shared tenancy, and dedicated instances are a premium service. reply tptacek 11 hours agorootparentI take them to mean shared kernels. reply cthalupa 4 hours agorootparentprevBut the parent specifically called out co-tenancy of &#x2F;containers&#x2F;. EC2 instances are not containers. reply seabrookmx 14 hours agoparentprevWell they&#x27;re not a \"full-blown\" machine, in that they do cut out a lot of things unnecessary for Lambda&#x27;s (and incidentally, fly.io&#x27;s) use case. ACPI is one example given in the article.But yes, they do virtualize hardware not the kernel. I&#x27;m willing to bet you could swap out vanilla containerd with firecracker-containerd for most users and they wouldn&#x27;t notice a difference given they initialize so fast. reply packetlost 12 hours agoparentprevI&#x27;m very surprised the standard isn&#x27;t to build a microkernel that emulates Linux userspace (or *NIX userspace) and is tailored towards the subset of virtual hardware that Firecracker and QEMU provide. I don&#x27;t get the impression that implementing a new target for a PL is all that difficult, so if you create a psuedo-OS like WASI&#x2F;WASM and send PRs to the supported languages you could cut out most of the overhead.The \"hardest\" part is probably sufficiently emulating Linux userspace accurately: it&#x27;s a big surface area. That&#x27;s why I think creating a pseudo-OS target is the best route. reply tptacek 11 hours agorootparentYou&#x27;re describing gvisor. reply packetlost 11 hours agorootparentNo, I&#x27;m not. Gvisor is a security layer around Linux containers that emulates and constrains syscalls. It specifically runs on top of a container platform and kernel. What I&#x27;m suggesting is a stripped down Linux-like kernel that is really good at running exactly one process. I&#x27;m describing a microkernel. reply talideon 43 minutes agorootparentThat&#x27;s not what a microkernel is. A microkernel is a kernel that pushes services traditionally included in the kernel, such as networking, out into userspace.The closest things to what you&#x27;re describing are unikernels and NetBSD rump kernels. reply tptacek 11 hours agorootparentprevgvisor emulates a big chunk of the Linux system call interface, and, remarkably, a further large chunk of Linux kernel state. It&#x27;s architecturally similar to uml (though not as complete; like Firecracker, it&#x27;s optimized to a specific set of workloads).gvisor is not like a seccomp-bpf process sandbox that just ACLs system calls. reply packetlost 10 hours agorootparentOk, I oversimplified a bit. Regardless, I&#x27;m suggesting something that still runs in emulated hardware isolation and implements drivers for Firecracker&#x2F;QEMU&#x27;s subset of hardware. reply tptacek 10 hours agorootparentgvisor does emulate some hardware. See, for instance, its network stack.At any rate: why is this better than just using KVM and Firecracker? The big problem with gvisor is that the emulation you&#x27;re talking about has pretty tough overhead. reply packetlost 8 hours agorootparentLet&#x27;s you get the best of both gvisor and Firecracker: efficient use of resources (ie. not running a full Linux kernel + scheduler, and most importantly, network stack for every lambda) while getting the isolation that comes from virtualization. You can achieve this in one of 2 ways: make a new kernel and add support for targeting it in the supported languages, or strip the Linux kernel down and reimplement the parts that aren&#x27;t optimized for you short-lived VM lifecycle (scheduler, network stack, etc.). reply tptacek 8 hours agorootparentStripping the Linux kernel down is what people do with Firecracker. I&#x27;m curious what savings you see in the Linux networking stack. You could compile it out and just rely on vsocks, but now you&#x27;re breaking everyone&#x27;s code and you&#x27;re not winning anything on performance. reply packetlost 8 hours agorootparentPerhaps I&#x27;m off base (I&#x27;m not an expert in this area), but I recall reading that one of the major challenges with Lambda was the latency that initializing the network stack introduces. Perhaps that&#x27;s been solved by now, but my naive idea is to have the guest not really run it&#x27;s own network stack (at least the MAC&#x2F;IP portion of it) and instead delegate the entire stack (IP and all) to the virtual device, which can be implemented by Firecracker&#x2F;QEMU&#x2F;whatever. I guess at that point, the amount of mangling you&#x27;d need to do to the kernel probably isn&#x27;t worth it and you should just use Gvisor... ah oh well.Regardless, I&#x27;m still surprised microkernels aren&#x27;t more popular in this space, but perhaps the losing the ecosystem of Linux libs&#x2F;applications is a non-starter.Even if the idea wasn&#x27;t fruitful, the conversation was fun. Thanks for engaging and challenging my bad ideas!Edit: I&#x27;ve also realized I was thinking of Unikernels, not microkernels and I&#x27;ve been calling it the wrong thing all night. *sigh* reply monocasa 5 hours agorootparentFWIW, Linux itself has plenty of support for TCP offload engines. I don&#x27;t think Firecracker uses that at the moment, but there&#x27;s no reason why it has to be that way if that&#x27;s a true bottleneck in the system. reply touisteur 22 minutes agorootparentI think the Firecracker team has stated that PCIe bypass wasn&#x27;t something they wanted to do, so I don&#x27;t see how they&#x27;d open up to other accelerators&#x27; bypass method. But seems like building a vmm from the rust-vmm toolbox is &#x27;not that hard&#x27; and there are some PCIe bypass crates already, so... Have fun? caskstrength 32 minutes agorootparentprev> Linux itself has plenty of support for TCP offload enginesCould you link to any specific Linux kernel source that implements support for TCP offload? AFAIK networking subsystem maintainers were always opposed to accommodate TCP offload because it is A Bad Idea. dikei 7 hours agoparentprevKVM is amazing.Beside Firecracker, there&#x27;re all sorts of micro-VM being developed right now, such as crosvm, cloud-hypervisor, Kata&#x27;s Dragonball, all on top of KVM. reply touisteur 21 minutes agorootparentMost new vmm projects seem based on rust-vmm and hopefully the big players keep contributing back to the project and its many satellites. reply ekianjo 6 hours agoparentprevThats what powers lambda on aws reply Thaxll 14 hours agoparentprevIt&#x27;s not a full blown VM, it has limitations. reply tptacek 14 hours agorootparentIt is a full blown VM, it has limitations. reply Havoc 1 hour agoprevToyed around with firecracker a bit. Does what it promises on boot times, but still a pretty gnarly experience. e.g. After doing a victory dance for getting it to boot I was rather deflated to find out that getting networking takes another lengthy tutorial reply bborud 1 hour agoparentI think there is definitively room for someone to add a lot of value to this by creating some automation tools. It would be really nice to be able to download a single binary, fire it up, have both a web interface and an API available, be able to configure it quickly, have it download whatever it needs for you etc. reply nocarrier 8 hours agoprevOnce Colin&#x27;s patches land on FreeBSD and Firecracker, the total boot time for the kernel is under 20ms. Absolutely incredible times that we live in. reply mnsc 13 hours agoprevHere&#x27;s the recent BSDCan talk from Colin that was posted a couple of days ago.https:&#x2F;&#x2F;youtu.be&#x2F;MT3cdeuRTzs?si=l6baNriUjcvy0ZOE reply cperciva 11 hours agoparentFWIW, this is basically the same material -- after my BSDCan talk the FreeBSD Journal said \"hey, that was a great talk, can you turn it into an article for us\", and after the FreeBSD Journal article was published ;login: asked if they could republish it. reply andrewstuart 13 hours agoprevqemu has microvm, inspired by firecrackerhttps:&#x2F;&#x2F;qemu.readthedocs.io&#x2F;en&#x2F;latest&#x2F;system&#x2F;i386&#x2F;microvm.ht... reply bonzini 12 hours agoparentI wonder how many of these workarounds are needed with QEMU! Some of course will be needed because they are fixes for bugs in FreeBSD. reply tedunangst 14 hours agoprevIt&#x27;s funny how many one second pauses turn out to be less than necessary. How many sysadmins took meaningful action because the system paused when they had an invalid machine uuid? reply cperciva 11 hours agoparentProbably a significant proportion of the sysadmins who experienced that one-second pause.The \"print a message telling the user that we&#x27;re rebooting, then wait a second to let them read the console before we go ahead and reboot\", on the other hand... reply tedunangst 9 hours agorootparentMaybe I&#x27;m just different. I&#x27;ve watched a great many openbsd boot sequences, which tend to have a great many pauses, and I&#x27;ve never paid any special attention to the lines that come before pauses vs lines that come after pauses. reply cperciva 9 hours agorootparentI suspect that FreeBSD has fewer pauses than OpenBSD... especially after the work I&#x27;ve done over the past few years to speed it up.If anyone in the OpenBSD world is interested in speeding up your boot process I&#x27;d be happy to share tips and code. It&#x27;s a bit daunting to start with but with some good tools it becomes a lot of fun. reply pseudostem 4 hours agorootparentThank you! That would be me. I am clueless on amd64 on how to speed up the boot process and maybe change a few fonts during boot.I understand the reasons for no \"how-tos\". But sometimes they make sense for people like me. I wouldn&#x27;t mind delving a bit deeper given some direction. reply slim 4 hours agorootparentprevif the machine boots in 20ms, I think that message is actually useful, because something would reboot your machine and you&#x27;d think you got logged out because you blinked reply ruslan 9 hours agoprev> on a virtual machine with 1 CPU and 128 MB of RAM, the FreeBSD kernel can boot in under 20 ms;Oh, my... how could I achieve the same on real hardware without VMs ? ;) reply dikei 1 hour agoparentKernel boot is plenty fast with real hardware, usually under 1 seconds.It&#x27;s everything else that&#x27;s slow. For example, this is my machineStartup finished in 14.552s (firmware) + 2.885s (loader) + 741ms (kernel) + 23.116s (initrd) + 11.191s (userspace) = 52.488s reply laurencerowe 12 hours agoprevIt&#x27;s a shame neither AWS nor macOS on ARM support nested virtualization. It would would make it far easier to develop and deploy Firecracker based tech. reply saurik 12 hours agoparentFWIW, AWS a1.metal instances are pretty small and thereby reasonably cost effective for working with virtualization tech. reply Rapzid 11 hours agorootparentTheir metal offerings are puny in general though(as in, not a ton of options). reply znpy 11 hours agoparentprevAfaik you can do virtualisation on the .metal variants.Actually you can do virtualisation on any instance type afaik, but only with .metal instances you can use hardware acceleration. reply doublerabbit 13 hours agoprevI&#x27;m not wanting to sound snoody. What use-cases do firecracker instances and the likes chime?I use FreeBSD for everything from my colocated servers, to my own PC. By no means am I developer; seasoned Unix Admin at best. Bare-metal forever but welcome to the future. Especially anything that contributes to the OS.However I hear buzz words like Lambda and Firecracker and really have no idea where the usage is. I get docker, containers, barely understand k8s but why do you need to spin up a VM only to tear it down compared to where you could just spin up a VM and use it when you really need to. Always there, always when.Is it purely a cloud experience, cost saving exercise? reply r3trohack3r 12 hours agoparentInstances of an application are created as part of the request&#x2F;response lifecycle.Allows you to build a compute plane where any node in the plane can service the traffic for any application.Any one application can dynamically grow to consume the available free compute of the plane as needed in response to changes in traffic patterns.Applications use no resources when they aren&#x27;t handling traffic.Growing the capacity of the compute plane means bringing more nodes online.Can&#x27;t come up with a use case for this beyond managing many large-scale deployments. If you aren&#x27;t working \"at scale\" this is something that would sit below a vendor boundary for you. reply jedberg 12 hours agoparentprevThe main use case if for seldom used APIs. If I run a service where the API isn&#x27;t used often, but I need it quick when it is, Lambdas or something like it are perfect.As it turns out, a lot of APIs for phone apps fit this category. You don&#x27;t want a machine sitting around idle 99% of the time to answer those API calls. reply alberth 10 hours agorootparentDumb question, then why not stick that API on a machine&#x2F;service that does need to be used 99% of time. reply nonsense_stream 7 hours agorootparentBecause the API also needs some separation. The same reason you would want your services isolated in VMs instead of all running in one bare metal. reply assimpleaspossi 10 hours agorootparentprevThis sounds like a hack around a programming problem that needs to be fixed. reply jedberg 5 hours agorootparentI don&#x27;t even understand what that means. What programming problem? reply assimpleaspossi 2 hours agorootparentIf you rarely need an API but set something up like this just to rarely use it, it seems one needs to write their own code for this functionality and not go through hoops to run someone else&#x27;s. That just sounds so bizarre. reply wnolens 12 hours agoparentprev> just spin up a VM and use it when you really need to. Always there, always whenand always charging you :) reply turtlebits 12 hours agoparentprevJust about every single company can benefit from scaling as traffic is never consistent 24&#x2F;7. Most don&#x27;t bother as the effort outweighs the savings, but the potential is there. Things like lambda and firecracker make it much easier. reply sangnoir 11 hours agoparentprev> why do you need to spin up a VM only to tear it down compared to where you could just spin up a VM and use it when you really need to. Always there, always whenFirecracker has a much amaller overhead compared to regular VMs - which makes the (time and compute) costs of spinning up new VMs really low. This can be an advantage, depending on how chunky your workloads are - the less chunky they are - the more they can take advantage of finer-grained scaling. reply lproven 12 hours agoparentprev... \"snooty\"?https:&#x2F;&#x2F;www.merriam-webster.com&#x2F;dictionary&#x2F;snooty reply zaps 8 hours agorootparentsnotty reply Datagenerator 13 hours agoparentprevIoT devices can execute short lived actions by calling remote Functions. The provider wants complete isolation and wipes these micro VMs after every few seconds and let&#x27;s the user pay for use. The response from these can be anything, voice, data or API responses. reply artificial 13 hours agoparentprevFaaS, function as a service. Depending on how software is packaged and the expectations the richness a VM, like Firecraker, provides may be useful. Many of these tradeoffs are for velocity, I can run X easily on Y. reply willsmith72 12 hours agoparentprevInstead of (or alongside) a CDN, you can deploy mini services around the world at the \"edge\" reply znpy 11 hours agoparentprev> However I hear buzz words like Lambda and Firecracker and and really have no idea where the usage is.Sometimes you just want to slap some lines pf code together and run them from time to time, and don’t need a whole server (physical or virtual) for that.Sometimes you have no idea if you’ll have to run a piece of code 100 times a day or 10’000’000 times a day.Sometimes you don’t feel like paying a whole month for and maintaining a whole instance for a cronjob that lasts 20 seconds, and maybe it runs once a week. reply getcrunk 11 hours agoprev [–] So firecracker vs v8 isolates if only doing js or wasm? replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The author recounts their experience of successfully porting FreeBSD to run on the Firecracker Virtual Machine Monitor.",
      "Despite facing challenges, they managed to overcome them and make significant progress in optimizing FreeBSD to improve its boot time on Firecracker.",
      "The author also mentions future plans, including separating Xen support and potentially porting Firecracker to run on FreeBSD."
    ],
    "commentSummary": [
      "FreeBSD performs efficiently and quickly on the Firecracker micro-VM platform.",
      "Firecracker offers the advantages of a complete machine and an efficient development environment.",
      "The article explores the use of gvisor and hypervisors, optimizing the Linux kernel for short-lived VM lifecycles, and the benefits of technologies like Lambda and Firecracker compared to traditional methods."
    ],
    "points": 302,
    "commentCount": 98,
    "retryCount": 0,
    "time": 1692903166
  },
  {
    "id": 37247394,
    "title": "Jacobin: A more than minimal JVM written in Go",
    "originLink": "https://jacobin.org/",
    "originBody": "jacobin A more than minimal JVM written in Go and capable of running Java 17 classes. View the Project on GitHub platypusguy/jacobin Welcome to Jacobin JVM Jacobin is an implementation of the JVM specification for Java 17. It is written entirely in Go with no dependencies. The goal is to provide a more-than-minimal implementation of the JVM that can run most class files and JARs and deliver the same results as the OpenJDK-based JVMs (that is, the majority of JVM implementations today). A paramount consideration in the design and implementation of Jacobin is the codebase: making it cohesive and containing clear code. The cohesiveness, extensive commenting, and large test suite enable professionals who want to know more about how the JVM works to find the information quickly and in an easily accessible setting. Additional information on the Jacobin wiki provides more background and insight. Because Jacobin is strictly a JVM, its code is tightly focused on Java program execution. An important factor in reducing the size of the codebase and executable is that Jacobin relies on Go’s built-in memory management to perform garbage collection, and so it contains no GC code. Due to our desire for an utterly reliable product, Jacobin is heavily tested during development. As of February 2023, the test code is 231% the size of the production code and consists of more than 400 tests. We’re committed to increasing these numbers. When Jacobin advances some more, we intend to run the OpenJDK test suites against it. Current Status The current status is shown here. Updates are also posted in realtime on the Jacobin Twitter account.There are currently no packaged releases of Jacobin available (although you can always compile the code). We’ll issue releases when Jacobin is mature enough to run classes as expected. At present, all tasks and defects are logged in an instance of JetBrains’ YouTrack (kindly provided at no cost). The task numbers appear at the start of the comment for every commit and push. The GitHub ‘issues’ facility is used strictly for issues posted by users. This design allows users to find solutions without needing to dig through numerous unrelated matters. Contents As we progress, we post short explanations of project decisions and explanations of how the JVM works. Current material can be found below: Project Posts Jacobin at the 2-year mark Jacobin at 18 months Jacobin status at the 1-year mark Why was Go chosen for this project? How the Jacobin JVM works Command-line processing How Jacobin searches for methods Inside Java class files: the constant pool Inside the JVM: Arrays The Team (and Thanks) Jacobin is presently being developed by Andrew Binstock (platypusguy), Spencer Uresk, and Richard Elkins. Contributors are more than welcome. If you’d like to show your support the project but can’t contribute code, we’d love a GitHub star or for you to follow the project. This project could not have been possible without Github (for the excellent platform), JetBrains (for superb tools), Oracle’s Java team (for the great technology and best-in-class documentation), and these JVM experts: Ben Evans, Aleksey Shipilev, Chris Newland, and Bill Venners who have written helpful, in-depth articles on the machinery of the JVM. A big thanks to all! This project is maintained by platypusguy Hosted on GitHub Pages — Theme by orderedlist",
    "commentLink": "https://news.ycombinator.com/item?id=37247394",
    "commentBody": "Jacobin: A more than minimal JVM written in GoHacker NewspastloginJacobin: A more than minimal JVM written in Go (jacobin.org) 280 points by yla92 23 hours ago| hidepastfavorite165 comments ninkendo 15 hours ago> An important factor in reducing the size of the codebase and executable is that Jacobin relies on Go’s built-in memory management to perform garbage collection, and so it contains no GC code.This breaks my brain thinking about it. A lot of what the JVM does is interpreting&#x2F;JITing bytecode and ensuring it links&#x2F;executes correctly, and writing that logic itself in Go is one thing. But how does Go&#x27;s GC help you garbage collect objects in the JVM you&#x27;re implementing?For example, you have objects in the JVM heap, tracked by the code you&#x27;re writing in Go. You need to do a GC run. How does the Go GC know about the objects you&#x27;re managing in the JVM? Do you just... write wrapper objects in Go around each of them, and code up a destructor so that freeing the Go object frees the tracked JVM object? How do you inform the Go VM about which pointers exist to your JVM objects?I realize I&#x27;m in way out of my depth here, and only have a \"user\"&#x27;s understanding of what GC&#x27;s do, having never implemented one myself, but it seems crazy to me that Go&#x27;s GC can Just Work with a VM you&#x27;re writing in Go itself. reply paulddraper 12 hours agoparent> it seems crazy to me that Go&#x27;s GC can Just Work with a VM you&#x27;re writing in Go itself.Far from it, it is more natural to do that than anything else.Simplified example: type Array struct { items *any[] } type Object struct { fields map[string]*any }These are the JVM values, and when the references to them disappear, the JVM values they reference can be GC&#x27;d as well. reply 38 11 hours agorootparentyour example is not valid Go code:syntax error: unexpected ], expected type argument listand its also just poor style in general. \"any\" is already a pointer, so you would rarely design a pointer to any. example:https:&#x2F;&#x2F;godocs.io&#x2F;encoding&#x2F;json#Marshal reply earthboundkid 10 hours agorootparentIt’s just pseudo code, relax. You’re not a compiler. You know what they meant. replyfelixge 15 hours agoparentprevI suspect every JVM heap alloc is implemented by doing an alloc in Go. The JVM references to the object are pointers in the Go VM. So no special magic is needed. When the Go VM stops referencing an object, the Go GC will collect it. reply omoikane 12 hours agorootparentDoes this mean that code running inside Jacobin might be vulnerable to memory exhaustion issues[1], whereas in JVM they might have gotten an OutOfMemoryError instead because JVM heap size is fixed at startup time?[1] For example https:&#x2F;&#x2F;pkg.go.dev&#x2F;vuln&#x2F;GO-2023-1704 reply justinclift 11 hours agorootparentInteresting idea. That sounds like this could run java programs with only the memory they actually need, instead of dividing a server up into pieces just because a java program \"might\" some day, possibly, maybe, ever need that much.Which tends to be cargo culted into \"use these arguments when running java programs\", thus a \"hello world\" responder gets allocated 128GB of ram. reply NovemberWhiskey 15 hours agorootparentprevJava leans much more heavily on its GC than Go does so it will be interesting to see whether that&#x27;s really an approach that works. reply cvoss 12 hours agorootparentNot too familiar with Go, but my first instinct is how will it handle non-vanilla references, of the weak, soft, or phantom variety? reply bane 8 hours agoparentprevLeveraging the millions of man hours that goes into these run-time&#x27;s subsystems is starting to become a \"thing\" I&#x27;ve noticed -- especially when running code not meant for them. For example, there&#x27;s a Nintendo Switch emulator that I believe just uses the C# runtime&#x27;s JIT instead of trying to roll their own. Lo and behold, it works and they&#x27;ve saved themselves thousands upon thousands of hours writing and debugging their own.It&#x27;s kind of cool actually.I wonder if there&#x27;s a future where somebody can just pick and choose language and runtime components parts to create the environment they want before even writing a line of code. We sort of do it a level lower with VMs and containers, and then pick and choose language features we want to use (e.g. C++), but I don&#x27;t know of a good way to use Java&#x27;s JVM, C#&#x27;s JIT, somebody else&#x27;s memory profiler, another team&#x27;s virtual memory subsystem etc. without writing a bunch of different pieces in different languages to get those benefits. reply jsd1982 15 hours agoparentprevSince the VM controls allocation of Java objects, just implement the VM to allocate the Java objects into Go&#x27;s heap using Go&#x27;s native allocator thereby allowing the native Go GC to clean those up when they become unreferenced. reply ninkendo 13 hours agorootparentHow would one allocate Java objects using Go’s allocator, as a program written in Go? Does go provide such primitives?Naively, something like: &#x2F;&#x2F; Called when the hosted JVM code wants to allocate func makeJVMObject() (jObj, error) { var obj = new(jObj) &#x2F;&#x2F; on go’s heap &#x2F;&#x2F; do stuff return obj, nil }would make sense, except how do we keep track of who’s referencing it? JVM objects have fields which tell the GC how to crawl the object tree in the mark phase (and so do Go objects), but how do we make the Go GC aware of the fields the JVM knows about? A map maybe?Hmm, I guess a map could work… the jObj struct could have a map of fields it knows about, keys being the field name and values being where they point to…Now that I think of it this probably must be how all GC’s work, they can’t rely on static information to know the fields of each type they’ve compiled, it’s gotta be something like a map somewhere.I guess I may have answered my own question here. reply erik_seaberg 9 hours agorootparentMost languages have “precise garbage collectors” that always know from runtime type info which bits of an object are and are not heap pointers.Sometimes you see add-on “conservative garbage collectors” that have to assume any word might be a pointer if it looks like an aligned address in an allocated page. They can’t move objects to do compaction because they’re never sure which words are not pointers.Jacobin stores an object with a slice of its field values (each boxed as “any”) and types, so Go’s precise GC would be able to trace them: https:&#x2F;&#x2F;github.com&#x2F;platypusguy&#x2F;jacobin&#x2F;blob&#x2F;main&#x2F;src&#x2F;object&#x2F;... reply paulddraper 12 hours agorootparentprevYep :)In fact, I would go so far as to say that it&#x27;s harder to implement those without Go&#x27;s GC just working.https:&#x2F;&#x2F;news.ycombinator.com&#x2F;edit?id=37254746 reply tombert 20 hours agoprevI would be very curious to side by side performance benchmarks between this, GraalVM, and vanilla JDK. My gut tells me (with no data to back this us) that the vanilla JVM will inch ahead once it&#x27;s paid the cost of starting up but I would be interested to see how wrong I am. reply andrewbinstock 17 hours agoparentLead dev here. We&#x27;ve run a couple of benchmarks internally just for kicks. To create a fair comparison, you have to run the Hotspot JVM with the -Xint flag, which says interpret only. Right now our performance is anywhere from 15-25% of the speed of Hotspot with -Xint on small benchmarks. We figure that the use of go alone creates some important portion of that overhead when compared with the C++ of the Hotspot JVM. We&#x27;re guessing that a well-optimized Jacobin interpreter will eventually get to 50-60% of the Hotspot&#x27;s -Xint speed.But we first want to get feature parity, before pivoting to performance. When we have feature parity, we&#x27;ll run the Computer Language Benchmarks and post the results. That&#x27;ll be fun to see! reply kaba0 16 hours agorootparentDo you (can you even have in go?) have a direct threaded interpreter? That alone may give a 2x performance difference last time I checked, or is that no longer the case? reply wahern 12 hours agorootparentI don&#x27;t think you can even implement indirect threading in Go. Go supports neither computed goto nor mutually recursive tail-call optimization (only self-recursive).Jump tables for switch statements was only implemented last year. If you squint that&#x27;s close to indirect threading, but still with at least one unnecessary conditional per op.For the curious, here&#x27;s their giant switch: https:&#x2F;&#x2F;github.com&#x2F;platypusguy&#x2F;jacobin&#x2F;blob&#x2F;c508ec50f55ef381... In practice compilers have always been finicky when it comes to coaxing them to emit jump tables from switch statements, and I bet this is especially truly for Go. reply suresk 11 hours agorootparentYeah, I think any bytecode interpreter ends up with a giant switch in the critical path at some point :)Around the time that change was made to Go, Andrew and I were looking at this and wondering how big of a performance hit it was and if there were a better way to structure that. I had a hunch that the compiler should be smart enough to not compile that as a switch&#x2F;giant if block, and a quick trip to a disassembler showed it using binary search. This commit: https:&#x2F;&#x2F;github.com&#x2F;golang&#x2F;go&#x2F;commit&#x2F;1ba96d8c0909eca59e28c048... added the jump table and has some nice analysis on where it makes sense to do binary search vs jump tables.As far as I can tell, with certain restrictions (that are fine in this case), it is pretty reliable at optimizing giant if&#x2F;else blocks and switches. reply tombert 16 hours agorootparentprevThat&#x27;s fair; I thought maybe the use of the Go GC might make the results a bit more interesting. reply kaba0 15 hours agorootparentGo has a much more primitive GC, so I wouldn’t expect a positive result from that itself. reply suresk 18 hours agoparentprevI&#x27;m not the author, but I have contributed a few things to the project over the past year. The performance isn&#x27;t anywhere close to the vanilla JVM - several times slower at best. It is entirely interpreted and there aren&#x27;t any of the optimizations that have made their way into the JVM over the decades it has been around.It has been a fun project to play around with for someone like me who thinks this kind of stuff is fun and interesting but will probably never get a chance to work on it full time. Cool to see it noticed, though! reply twic 19 hours agoparentprevThis JVM has no JIT, so OpenJDK and Graal will rather more than inch past it. It&#x27;s not even a given that it will start up faster, since i don&#x27;t believe it has been optimised nearly as hard. reply pg_1234 19 hours agorootparentYou&#x27;d probably get better results writing a Go compiler in Java ... reply cfiggers 19 hours agorootparentWrote a Go compiler in Java, used it to compile this JVM implementation written in Go reply paulddraper 13 hours agorootparentGreat, now just use this JVM to run your compiler :) reply seanw444 18 hours agorootparentprevOuroboros reply KRAKRISMOTT 17 hours agorootparentLambda the ultimate reply adra 17 hours agorootparentprevWell, you&#x27;d probably get pretty good perf with graalvm truffle, but certainly the building blocks of golang shouldn&#x27;t be that problematic to implement in java given that the go language model is more straight-forward IMHO. I wouldn&#x27;t assume it&#x27;d beat pure golang compilation but who knows. reply layer8 19 hours agoparentprevThe startup cost is dominated by class loading, which Jacobin will have to do more or less the same as OpenJDK [*]. GraalVM of course profits from AOT compilation.[*] until the latter will implement condensers: https:&#x2F;&#x2F;openjdk.org&#x2F;projects&#x2F;leyden&#x2F;notes&#x2F;03-toward-condense... reply ptx 18 hours agorootparentDidn&#x27;t they introduce some new format with Java 9 and jlink to store modules more efficiently? Why hasn&#x27;t that fixed class loading performance? reply layer8 18 hours agorootparentThe issue isn’t the format. Class loading includes bytecode verification (verifying the type soundness of whatever code the class files contain), and then executing the initialization code defined by each class (static code blocks etc.).The optimizations in JDK 9 are for reducing the file size of the JDK (in terms of number of classes) when distributed with a standalone application, but that by itself doesn’t significantly affect startup time I believe, because classes are lazy-loaded only as required in any case. reply mike_hearn 18 hours agorootparentThe jimage format does optimize startup a bit because it builds a perfect hashtable to go from class name to classfile bytes. On the classical classpath that requires an O(N) scan of the JARs in the app. reply erik_seaberg 17 hours agorootparentprevDoes a JVM really need to re-verify the standard library it ships with? reply layer8 16 hours agorootparentIt’s actually the default to not do that (-Xverify:remote). So I was probably wrong about bytecode verification being a relevant part of startup time, unless you count the application itself. reply papercrane 18 hours agorootparentprevThe modules system is for better encapsulation and the ability to produce a JVM without features you don&#x27;t need.Faster start up time is in the works with projects like coordinated restore at checkpoint which will let you start a JVM up in an already \"warmed\" state.https:&#x2F;&#x2F;github.com&#x2F;CRaC&#x2F;docs reply ptx 15 hours agorootparentIf I understand the README correctly, CRaC in an abstract API that delegates to an implementation (CRIU) which is Linux-specific, described in its README as \"the never-ending story, because we have to always keep up with the Linux kernel\".So this wouldn&#x27;t help if I&#x27;m deploying a GUI app for Windows, for example. reply papercrane 13 hours agorootparentCorrect, it might, someday, become part of Java SE. If that ever happens I would expect it working on every platform Java supports would be a prerequisite for that.Right now it&#x27;s primarily useful for reducing start up times in AWS Lambdas and auto-scaling workloads. reply mike_hearn 18 hours agorootparentprevIt improves it a bit, and AppCDS improves it a lot (~30% startup win), but neither feature is widely used as it changes deployment workflows. reply tgv 18 hours agoparentprevI see it more as an niche opportunity to integrate bits of Java code in Go applications. The start-up costs can be \"paid\" when the app starts. Performance will be bad, but it might save some rewrites (provided they can get things like db connections going). reply tombert 16 hours agorootparentYeah that makes some sense; there&#x27;s probably millions of lines of Java code out there where performance doesn&#x27;t really matter, and so aren&#x27;t worth rewriting. Being able to embed a JVM just to run those from Go projects isn&#x27;t a bad idea.Tangential, but a long time ago, I wanted to reuse a node.js slug library in .NET. I thought about trying to port it at first, but then I realized that this actual job didn&#x27;t need to be terribly fast, so I instead embedded the Jurassic JS library into my code, and was able to load in the slug library that way directly). It wasn&#x27;t especially fast (but actually faster than I thought it would be!), but it was certainly fast enough, and I didn&#x27;t have to worry about not having feature parity. reply kaba0 15 hours agorootparentWhy not just do traditional IPC, or even a batch process starting up a JVM from time to time when needed? reply tgv 15 hours agorootparentThere are always other solutions. This one might just work in some cases. As I wrote: it&#x27;s (probably) niche. reply paulddraper 13 hours agorootparentprevExactly.The cool thing is that since this uses the Go garbage collector, you can create a very nice Go-native interface to that JVM code. reply jillesvangurp 18 hours agoparentprevClearly this is not going to be a high performance thing. I&#x27;d be surprised if it is even close.It seems the goals for this are purely academic and about figuring out how Java works. They&#x27;ll probably just do a simple interpreter and not a JIT compiler. That would be good enough for a POC. Additionally, they already indicated that they&#x27;ll use Go&#x27;s garbage collector, which won&#x27;t be setting speed records with this either. And Java&#x27;s typical usage of memory might actually stress it out a bit. Then there is the standard library which is going to need plenty of support for things like Threads, IO, various synchronization primitives and locks, etc. Doing that in Go is going to be a bit interesting but probably doable. Alternatively, they might just interface with native code directly and bypass the Go ecosystem. They might even reuse some things from openjdk for that. Speaking of which, native code and JNI would need to be implemented anyway. reply jsiepkes 19 hours agoparentprevIt looks like a cool research project. But realistically I would be surprised if it could beat OpenJDK in any benchmark (though I don&#x27;t think that&#x27;s the purpose of the project).Writing something which is compatible with a specification is one thing, making it performant is another thing. For example it&#x27;s not that hard to create a webserver from scratch but making it performant takes quite some effort. reply richieartoul 20 hours agoprevThis is so cool. Can’t wait to go digging around through the code this weekend. Good luck with the project! reply richieartoul 20 hours agoparentI know the link stresses that correctness and code clarity are the primary goals of this project, but I’m curious if performance is a goal as well? Do you hope that people will run “real” workloads with this or use it to embed other software in their Go applications? reply andrewbinstock 17 hours agorootparentAuthor here: Right now we&#x27;re entirely focused on getting parity of functionality so that anything that runs on the Hotspot JVM runs similarly on Jacobin. There&#x27;s still a lot of work to do to get there. However, once we do get there, we&#x27;ll start working on performance. reply riku_iki 17 hours agorootparentwhat is the reason for this project to be started? What is the end goal? Why current JVM is not good enough?.. reply andrewbinstock 16 hours agorootparentThanks for asking. I&#x27;ve always thought of the JVM as magical technlogy--I&#x27;m certainly not alone in that view. But in trying to learn more about it, I was greatly frustrated by the difficulty of reading the code base.As you likely know, the Hotspot JVM is open source. But reading the code is very difficult, in part because it grew organically and in part because of its unusual design, in which many actions are buried deep at the end of a long series of function calls involving unexpected classes and unusual methods, etc.This led me to thinking there would be value in a JVM written as a single cohesive codebase. And given that there is a 300+ page JVM specification and a reference implementation, I thought to myself, how long could this take? Two years later, and with help from two major contributors, we&#x27;re still finding out! ;-)Eventually, we hope, it will be a fun&#x2F;interesting experience for users to pop open their Go IDE and watch a Java program execute--which is why we&#x27;re intent on making sure it&#x27;s written in 100% go.In a larger context, Jacobin might eventually be useful as an embeddable JVM. reply layer8 20 hours agorootparentprevSince they emphasize cohesiveness and clear code, the goal seems to be more on the educational side. It doesn’t look like they’d want to implement JIT bytecode compilation. reply gabereiser 18 hours agoprevUmmm, excuse me, but where the f&$k has this been hiding? I’ve been looking for ways to extend my go applications with scripting support. I started with Lua (worked ) then Python (worked but hacky) then javascript using otto [1]. However it lacks ES6 support so having pretty OOP js code is a non-starter. I would love to have Java as a runtime that can be executed from goroutines.[1] https:&#x2F;&#x2F;github.com&#x2F;robertkrimen&#x2F;otto reply sam_on_the_web 18 hours agoparentHave you had a look at Starlark? Its a python-like scripting language built specifically for embedding into applications. Originally it was written in Java to be used in Bazel but its been re-implemented in go and rust and has found use in a bunch of other places.https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;starlark-go reply gabereiser 16 hours agorootparentYeah, it’s cool but doesn’t fit my use case. I’m not scripting configuration. I’m scripting functionality. I need to be able to enforce interfaces and signatures easily all while having near-go-like performance.I’ll play around with it some more and see if I can’t get some OOP pydantic-like stuff going with it. Otherwise it’s a non-starter. reply skitter 13 hours agorootparentIf you want near-go-like performance, Jacobin doesn&#x27;t help you either. reply gabereiser 12 hours agorootparentI can handle = 17 or Java The goal is to provide a more-than-minimal implementation of the JVM that can run most class files and JARsAs with everything, the final 10% is 90% of the work. reply andrewbinstock 14 hours agoparentLead dev here. It&#x27;s been an amazing amount of work. I&#x27;d change the above adage to: Every 10% is 90% of the work! reply yaqubroli 19 hours agoprevInitially I was very confused; why would a socialist magazine have an article about the JVM? reply andrewbinstock 17 hours agoparentAuthor here: Long ago, when I got the domain, the project was going to be JAva COmpiler to BINary = Jacobin. And as the Jacobins were revolutionaries, it sort of fit the intended project. I don&#x27;t recall whether Jacobin Magazine was in publication then or not TBH. reply lambda_garden 18 hours agoparentprevThey use Haskell in any case [0][0] https:&#x2F;&#x2F;jacobin.com&#x2F;2022&#x2F;05&#x2F;jacobin-is-looking-for-a-program... reply bullen 20 hours agoprevSo Go GC + Java GC? reply nonane 20 hours agoparentNo. It’s using Go’s built in GC: https:&#x2F;&#x2F;github.com&#x2F;platypusguy&#x2F;jacobin#garbage-collection reply karmakaze 20 hours agoparentprevThe Go GC could be the Java GC. reply perbu 20 hours agorootparentThen it would be hard to write this in Go. Can&#x27;t see how you&#x27;d be able to hook into the Go GC in an application written in Go. reply karmakaze 20 hours agorootparentEvery Java reference to an object can be a reference to the allocated Go object for that object. The Go objects are the Java objects with no extra indirection. The Go object would be bytes with each reference field being a struct with a pointer. There should be a low level use these bytes for &#x27;allocating&#x27; this object. reply perbu 20 hours agorootparentThanks. That makes a lot of sense and isn&#x27;t as complicated as I thought it would be. reply nightowl_games 20 hours agorootparentprevFrom TFA:> An important factor in reducing the size of the codebase and executable is that Jacobin relies on Go’s built-in memory management to perform garbage collection, and so it contains no GC code.I don&#x27;t see how you can&#x27;t see it. reply RetroTechie 14 hours agorootparentI can see how using Go&#x27;s GC reduces the codebase.But I don&#x27;t see how that reduces binary size.Compiled Go programs include a Go runtime in their binary, correct? (statically linked).So if Go program uses Go&#x27;s builtin GC, that GC wouldn&#x27;t be part of the program code, but would be part of the runtime that it&#x27;s packed with in the binary, right?In essence replacing [GC in Go program part of the binary] with [GC in Go runtime part of the binary].I mean, I can see the advantage(s) there. But reducing binary size doesn&#x27;t seem to be one of them. Unless you count [Go program using its own GC + the one in Go runtime] vs. [only the one in Go runtime].It&#x27;s still a (read: at least 1) GC included in the binary. reply coldtea 5 hours agorootparent>But reducing binary size doesn&#x27;t seem to be one of them. Unless you count [Go program using its own GC + the one in Go runtime] vs. [only the one in Go runtime]Yes, of course that&#x27;s what they mean. Not having 0 code for GC altogether, but just using the GC that you already have, and is required overhead, as opposed to implementing another and having both. reply skitter 13 hours agorootparentprevYou&#x27;re right, but that&#x27;s what&#x27;s meant - using the Go GC vs also implementing a custom one. reply coldtea 5 hours agorootparentprevI believe it&#x27;s a quit common practice to delegate the GC needs of a GC-language implemented on top of another GC-language, on the latter&#x27;s GC.As long as the language is GC agnostic, and just cares for stuff being collected, and not for some particular exposed semantics of the GC, it should be ok. reply perbu 20 hours agorootparentprevFrom the project page: GC is handled by the golang runtime, which has its own GCThis is pretty cool, imo. reply mbreese 20 hours agorootparentprevYou couldn’t necessarily “hook into” it from the Java side, as it would be an opaque interface. But the Go side would make the Java GC process “just work”. reply pjmlp 20 hours agorootparentprevGo GC is already written in Go. reply paulddraper 13 hours agorootparentprevIt&#x27;d be hard not to hook into the Go GC in an application written in Go... reply who-shot-jr 20 hours agorootparentprevInception GC reply lemper 20 hours agoparentprevonly go&#x27;s gc. there&#x27;s no gc code, if I read correctly. reply steno132 17 hours agoprevI once said that \"just as there&#x27;s no founder like Elon, there&#x27;s no Java expert like Andrew (project author)\"Andrew&#x27;s Java skills are at a different level. I only briefly met him once, but he used to be a core contributor to Oracle&#x27;s Java magazine. 80% of the \"Unix greybeard\" type advanced Java knowledge I have is due to his articles.Happy to see he&#x27;s still building. Thanks Andrew! reply andrewbinstock 16 hours agoparentThank you for such kind words! reply AtlasBarfed 15 hours agorootparentOk why are you doing this? To see if some end around to another language GC is faster? reply cylinder714 7 hours agorootparentI can see it being used to bootstrap OpenJDK, particularly on platforms other than Windows, macOS or Linux. reply usrnm 17 hours agoparentprevSo, where is Andrew&#x27;s x&#x2F;twitter? reply leetrout 17 hours agorootparenthttps:&#x2F;&#x2F;x.com&#x2F;platypusguy?s=21&t=emEe0Pw2GM5BS7u2A27-pQ reply agumonkey 16 hours agorootparentprevseems his blogspot is also full of stuff http:&#x2F;&#x2F;binstock.blogspot.com&#x2F; reply rbanffy 17 hours agoprev [–] For a second I wondered why the Jacobin would publish a story about a JVM… replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Jacobin is a Go-based JVM implementation that can execute Java 17 classes, offering a more comprehensive JVM implementation with clear and cohesive code.",
      "Unlike other JVM implementations, Jacobin leverages Go's built-in memory management and does not include garbage collection code.",
      "The project is extensively tested, and the development team aims to run OpenJDK test suites in the future."
    ],
    "commentSummary": [
      "Jacobin is a JVM written in Go that aims to have the same functionality as the Hotspot JVM.",
      "It currently has a performance of 15-25% compared to Hotspot with interpreted code.",
      "The developers plan to conduct further benchmarks once they achieve feature parity."
    ],
    "points": 280,
    "commentCount": 165,
    "retryCount": 0,
    "time": 1692874760
  },
  {
    "id": 37255079,
    "title": "Proof-of-Work Defense for Onion Services",
    "originLink": "https://blog.torproject.org/introducing-proof-of-work-defense-for-onion-services/",
    "originBody": "About Support Community Forum Donate Introducing Proof-of-Work Defense for Onion Services by pavelAugust 23, 2023 Today, we are officially introducing a proof-of-work (PoW) defense for onion services designed to prioritize verified network traffic as a deterrent against denial of service (DoS) attacks with the release of Tor 0.4.8. Tor's PoW defense is a dynamic and reactive mechanism, remaining dormant under normal use conditions to ensure a seamless user experience, but when an onion service is under stress, the mechanism will prompt incoming client connections to perform a number of successively more complex operations. The onion service will then prioritize these connections based on the effort level demonstrated by the client. We believe that the introduction of a proof-of-work mechanism will disincentivize attackers by making large-scale attacks costly and impractical while giving priority to legitimate traffic. Onion Services are encouraged to update to version 0.4.8. Why the need? The inherent design of onion services, which prioritizes user privacy by obfuscating IP addresses, has made it vulnerable to DoS attacks and traditional IP-based rate limits have been imperfect protections in these scenarios. In need of alternative solutions, we devised a proof-of-work mechanism involving a client puzzle to thwart DoS attacks without compromising user privacy. How does it work? Proof of work acts as a ticket system that is turned off by default, but adapts to network stress by creating a priority queue. Before accessing an onion service, a small puzzle must be solved, proving that some \"work\" has been done by the client. The harder the puzzle, the more work is being performed, proving a user is genuine and not a bot trying to flood the service. Ultimately the proof-of-work mechanism blocks attackers while giving real users a chance to reach their destination. What does this mean for attackers and users? If attackers attempt to flood an onion service with requests, the PoW defense will kick into action and increase the computational effort required to access a .onion site. This ticketing system aims to disadvantage attackers who make a huge number of connection attempts to an onion service. Sustaining these kinds of attacks will require a lot of computational effort on their part with diminishing returns, as the effort increases. For everyday users, however, who tend to submit only a few requests at a time, the added computational effort of solving the puzzle is manageable for most devices, with initial times per solve ranging from 5 milliseconds for faster computers and up to 30 milliseconds for slower hardware. If the attack traffic increases, the effort of the work will increase, up to roughly 1 minute of work. While this process is invisible to the users and makes waiting on a proof-of-work solution comparable to waiting on a slow network connection, it has the distinct advantage of providing them with a chance to access the Tor network even when it is under stress by proving their humanity. Where do we go from here? Over the past year, we have put a lot of work into mitigating attacks on our network and enhancing our defense for onion services. The introduction of Tor's PoW defense not only positions onion services among the few communication protocols with built-in DoS protections but also, when adopted by major sites, promises to reduce the negative impact of targeted attacks on network speeds. The dynamic nature of this system helps balance the load during sudden surges in traffic ensuring more consistent and reliable access to onion services. network onion services releases usability Comments We encourage respectful, on-topic comments. Comments that violate our Code of Conduct will be deleted. Off-topic comments may be deleted at the discretion of the moderators. Please do not comment as a way to receive support or to report bugs on a post unrelated to a release. If you are looking for support, please see our FAQ, user support forum or ways to get in touch with us. Upcoming Events September 15, 2023 – September 17, 2023 The Global Gathering by Team Community September 28, 2023 – September 30, 2023 SPJ Convention 23 October 8, 2023 – October 12, 2023 Internet Governance Forum (IGF) 2023 Recent Updates New Alpha Release: Tor Browser 13.0a3 (Android, Windows, macOS, Linux) by richardAugust 24, 2023 Tor Browser 13.0a3 is now available from the Tor Browser download page and also from our distribution directory. Introducing Proof-of-Work Defense for Onion Services by pavelAugust 23, 2023 Today, we are officially introducing a proof-of-work (PoW) defense for onion services designed to prioritize verified network traffic as a deterrent against denial of service (DoS) attacks with the release of Tor 0.4.8. New Alpha Release: Tor Browser 13.0a2 (Android, Windows, macOS, Linux) by richardAugust 12, 2023 Tor Browser 13.0a2 is now available from the Tor Browser download page and also from our distribution directory. Download Tor Browser Download Tor Browser to experience real private browsing without tracking, surveillance, or censorship. Download Tor Browser SUBSCRIBE TO OUR NEWSLETTER Get monthly updates and opportunities from the Tor Project: Sign up Trademark, copyright notices, and rules for use by third parties can be found in our FAQ.",
    "commentLink": "https://news.ycombinator.com/item?id=37255079",
    "commentBody": "Proof-of-Work Defense for Onion ServicesHacker NewspastloginProof-of-Work Defense for Onion Services (torproject.org) 277 points by simonpure 12 hours ago| hidepastfavorite118 comments 8organicbits 10 hours agoReally interesting! Digging into the proposal [1]:> make it harder for attackers to overload the service with introduction request> We hope that this proposal can help us defend against the script-kiddie attacker and small botnets.Sets expectations: does not counter large botnets.> We hope that this proposal will allow the motivated user to always connectA user who really wants to connect can get through durring a DoS attack, but it may still take work.Interesting choice of PoW algorithm: https:&#x2F;&#x2F;github.com&#x2F;tevador&#x2F;equix> Hence, instead of forcing clients to go below a static target like in Bitcoin to be successful, we ask clients to \"bid\" using their PoW effort. Effectively, a client gets higher priority the higher effort they put into their proof-of-work. This is similar to how proof-of-stake works but instead of staking coins, you stake work.[1] https:&#x2F;&#x2F;gitlab.torproject.org&#x2F;tpo&#x2F;core&#x2F;torspec&#x2F;-&#x2F;raw&#x2F;main&#x2F;pr... reply keyle 9 hours agoparentI never heard of CPP (client puzzle protocol) before. Interesting stuff. How can &#x27;large botnets&#x27; go around this, by causing havok on other ports? reply 8organicbits 1 hour agorootparentFrom the spec:> The large botnet is a serious operation with many thousands of computers organized to do this attack. Assuming 100k medium-range computers, we are talking about an attacker with total access to 200 THz of CPU and 200 TB of RAM. The upfront cost for this attacker is about $36k.They appear to define it by compute capacity, so I&#x27;d expect the attacker can solve harder puzzles than legitimate users would attempt. reply comex 9 hours agorootparentprevProbably by having enough computers that they can overload the server even if the number of requests coming from each individual computer is relatively low, as a multiple of what a normal user would send – low enough that those computers have enough CPU time to solve the challenges. reply capableweb 8 hours agorootparentFrom https:&#x2F;&#x2F;github.com&#x2F;tevador&#x2F;equix&#x2F;blob&#x2F;master&#x2F;devlog.md> The service would give the request a priority value based on the \"difficulty\" of the puzzle solution.Seems like single clients could increase the difficulty to higher than what the bot net would do (so it gets priority), and hence get access. Operators of the bot net would probably hard code one value as the difficulty, and it would be lower than what you could typically set on consumer hardware.Maybe user agents could even do this increase automatically? reply thephyber 2 hours agorootparent> Operators of the bot net would probably hard code one value as the difficultyBad assumption.Assumptions like these never last. People who say “I don’t have any money” are still valuable to hackers as phishing senders, legitimate social media accounts, residential + non-cloud + regionally convenient IP space, etc. If consuming connection &#x2F; server resources becomes valuable then botnet controllers will find a way to pay the cost. It’s easy because someone else is paying for the hardware, bandwidth, and power costs.But the effect of a market of PoW is the same — there is game theory involved in bidding (just like a silent auction). Even if a botnet uses a dynamic priority bid system, the cost increases as the botnet tries to starve the server of resources. The server’s resources are always zero-sum and the bidding will get progressively more expensive until the opportunity cost of the botnet changes behavior. reply enigmurl 7 hours agorootparentprevWould it really be lower on the bot net in the majority of cases? I&#x27;d imagine that real users probably wouldn&#x27;t want to have their entire cpu spent on this. reply croshan 6 hours agorootparentreal users have more CPU than a literal toaster (or smart air fryer, or IP camera, or many other common botnet devices) reply AnthonyMouse 5 hours agorootparentNot only that, real users actually want to use the service, not overload it. A real user might only make one request a second. A botnet device is trying to make a thousand requests per second to overload the server. Even if they each have the same CPU as a normal user, now each node in the botnet can only make as many requests per second as a user or the user can outbid them. reply KirillPanov 2 hours agorootparent^ this guy gets it replysalawat 10 hours agoparentprevSo now you have the drawbacks of both as well, in that the guy who has the most compute to use as a toaster can DoS everyone else.Plus, PoW is nothing but wasted, needless computation. Computing is not free. Every watt spent doing anything PoW is just that much more intensification of our current climate crisis.As someone with temps of 109 with heat index of 120 coming in the next few days, with all due respect, fuck anyone who proposes PoW is a good idea for anything.It isn&#x27;t interesting. It&#x27;s the most egregious example of conspicuous consumption on the planet. reply Uptrenda 3 hours agorootparentIDK, a mechanism that helps Tor continue to run does not seem like a &#x27;wasted&#x27;, &#x27;needless&#x27; computation to me. People literally use Tor to protect themselves in situations that might result in heavy penalties for exposing the truth (maybe even torture or death.) If hidden nodes can be easily DDoSed it just makes it easier to censor the facts (and that can be dangerous.) Tor really does represent the best of us. reply spencerchubb 10 hours agorootparentprevThe proof of work only engages when there is a Denial of Service attack. So if you&#x27;re going to be mad at anyone for useless consumption, be mad at the attacker. reply thephyber 2 hours agorootparentprevThis proposal applies a temporary cost to DoS and DDoS — which itself is already a big waste of power. This proposal has the ability (if it works as planned) to destroy DoS + DDoS as an effective tool against this kind of server. Likely a net positive in terms of power usage.Remember that this PoW proposal is a market. If the server has unconsumed cycles (eg. Is not saturated), the POW spot price can remain 0. The server only needs to set a PoW price after the server’s resources near saturation. For the same reason auctions end because nobody is willing to pay infinity dollars, clients can forego PoW and can opt to check back in on the server later when costs subside. reply rlpb 10 hours agorootparentprevI think the presence of this PoW system might mean that this form of abuse is discouraged enough that in practice it means that PoW will not be required. Who is going to compete with a huge amount of compute to DoS others? They&#x27;d need the same compute as all legitimate access put together to get to just 50% effectiveness.If this is the case and in practice PoW is never required, then your rant is moot, and instead it is interesting that this effect occurs. reply kaveh_h 8 hours agorootparentMy thought exactly. Would be interesting if they shared metric of pre and post level of DDoS attacks so there was some proof this scheme actually has desired effect. reply thechao 10 hours agorootparentprevMaybe we can ask the DoSers to stop, nicely? Everything else being equal, I bet the Tor&#x2F;Onion-folk are pretty smart people, and this is what they felt was necessary to keep the service running. reply synesso 9 hours agorootparentprevThis is an example of the common fallacy of conflating energy consumption with carbon-intensive energy generation. reply wmf 7 hours agorootparentThat&#x27;s what you get when the powers that be have spent decades promoting guilt-tripping instead of internalizing the externalities. reply cool_dude85 6 hours agorootparentprev\"Conflating\" energy consumption with energy generation, which here in the real world is still predominantly carbon intensive? I wouldn&#x27;t say there&#x27;s much conflating going on, rather, recognition of the reality we live in. reply AnthonyMouse 5 hours agorootparentIt&#x27;s addressing the problem from the wrong end. If you replace your generating capacity with non-carbon sources then energy consumption is no problem. If you don&#x27;t, you have a problem even at the current level of consumption, and that problem continues to have the same solution.It&#x27;s not even impossible for increased consumption to lower carbon emissions, because to meet the higher peak demand you may need to add more generating capacity. When the new capacity is renewables or nuclear then it adds no carbon emissions during peak usage times and allows for a reduction in carbon emissions whenever the grid is at less than full capacity by assigning the remaining load to the new plants and spinning down the legacy fossil fuel ones that would otherwise have been used. reply goodpoint 52 minutes agorootparentprevWrong. Currently most electricity is generated from sources that release co2. Also, all the energy used in computation is ultimately released as heat anyways! reply foota 9 hours agorootparentprevWithout this proof of work, users can be arbitrarily denied access due to overload.With the proof of work, I think the assumption is that a legitimate user will be willing to accept a sufficient delay to make botnet DoS attack impossible.The counter argument might be that the botnet can generate arbitrarily hard proof of work, but this isn&#x27;t true. Assuming some fixed capacity by the botnet, and that the botnet needs to send some amount of requests per time in order for the attack to be effective (e.g., if they only send one proof of work request per minute, then the \"bid\" for the rest of the time is quite low), then there&#x27;s some maximum effective \"price\" based on the capacity of the botnet past which a user is guaranteed access.For example say a botnet has access to a million compute nodes, so they have 1 million proof of work seconds per second.If there&#x27;s a service which can serve 1000 requests per second, then the average proof of work seconds they have per request is 1000 seconds of proof, so as long as the user is able to provide 17 minutes of proof of work, they can get access. In reality, the user&#x27;s hardware is likely more capable than the attacker&#x27;s botnet (which is probably IoT devices etc.,) so the ratio is more favorable.I find it amusing that this approach is pretty on brand for onion services, as an invisible hand type market solution from what I&#x27;d consider to be a fairly libertarian leaning group. reply dontupvoteme 3 hours agorootparentprevPoW (minus bitcoin, which is bad anyway for many other reasons) contributes an incalculably insignificant amount of energy to the atmosphere. It&#x27;s much, MUCH more important to protect the free internet.Sorry it&#x27;s hot there but this is absurd virtue signaling and should under no circumstance come into view as a reason to not do PoW. reply cinntaile 10 hours agorootparentprev> Computing is not free.That&#x27;s the whole point. reply hunter2_ 10 hours agorootparentWhat if instead of spending energy on compute, we just spend money instead? On the one hand, some people may be turned off by the idea of spending money, but on the other hand, the two are usually interchangeable unless you&#x27;re stealing energy. Someone with a lot of money and no hardware or energy can purchase hardware and energy; someone with a lot of hardware and energy can sell the hardware and sell energy back to the grid to make money. reply pseudo0 9 hours agorootparentThe goal with Tor is to preserve privacy. Payment systems come with significant legal and regulatory overhead, KYC and AML, etc. That introduces significant privacy risk. Meanwhile PoW just requires owning a computing device. reply ssklash 9 hours agorootparentprevHow do you suggest the people who are using Tor for anonymity pay money to use Tor? That might make sense for cryptocurrencies, but for Tor I think it&#x27;s unusable. reply foota 9 hours agorootparentI believe this could be done using zero knowledge proofs, ala tornado cash (which I&#x27;m not familiar with in practice, but I&#x27;ve read the algorithms behind it). You&#x27;d need some service that produces zero knowledge proofs that someone sent some funds to the service, and got their slot in return. Put down your pitchfork, but I think this would essentially be an NFT backed by a ZK-snark. reply _blk 9 hours agorootparentprevOops, with that message the temp just went up to 110. reply panny 10 hours agorootparentprev>So now you have the drawbacks of both as wellEverything has drawbacks. It&#x27;s always a tradeoff in software. You want a really simple interface? Now you can&#x27;t do complex things. And so on.Instead of complaining loudly, why not be the change you want to see? Proof of CPU makes you hot? How about proof of RAM? How about about something else, which you thought of yourself, which is a great idea, which you shared with their team, which they would eagerly accept as a superior solution to proof of work? reply extraduder_ire 11 hours agoprevI&#x27;m surprised something like this wasn&#x27;t done sooner, and also haven&#x27;t read the proposal [0] in enough detail to tell if this will lead to more data affecting the anonymity of users. Should be fine though, since it&#x27;s tied user-to-service and not stored anywhere.I&#x27;m wondering how much this will decrease load on the service being proxied vs the nodes themselves though, I assume it&#x27;ll have more benefit to services since access is spread out between multiple nodes.[0]: https:&#x2F;&#x2F;gitlab.torproject.org&#x2F;tpo&#x2F;core&#x2F;torspec&#x2F;-&#x2F;blob&#x2F;main&#x2F;p... reply KirillPanov 2 hours agoparent> I&#x27;m surprised something like this wasn&#x27;t done sooner,It should have been, but was delayed by people shrieking about oceans boiling. reply evgen 2 hours agorootparentFWIW, we talked about using things like hashcash to prevent abuse and similar attacks for anonymous remailers back in the early 90s. Talking about it is one thing, actually making the commitment to do it is something else entirely. Given interest in cryptocurrencies there has also been a lot more effort devoted to considering the cost&#x2F;feature tradeoffs of various PoW mechanisms (and a broader familiarity with the general concept among the target population), so it is possible that we are seeing a happy side-effect of years of cryptocurrency hype. reply bawolff 10 hours agoprevThe better article (real technical details) is https:&#x2F;&#x2F;gitlab.torproject.org&#x2F;tpo&#x2F;core&#x2F;torspec&#x2F;-&#x2F;blob&#x2F;main&#x2F;p...Appearently the PoW function they chose is equi-X. reply favflam 10 hours agoprevNice. Pretty soon, we won&#x27;t need CDNs for DDOS protection. We just serve API through Onion services. reply pawelduda 12 hours agoprevWhat&#x27;s preventing abusers from getting new identities when the PoW kicks in and continuing the DDoS?Edit: looks like PoW is set per \"service\" that&#x27;s under attack rather than client? reply bombcar 11 hours agoparentIt’s per service and it goes from being able to overwhelm an onion to having to exert more computing usage than the server does serving you. It helps. reply kragen 8 hours agoparentprevright, it&#x27;s not per client; if it was per client you could just ban the abusive clients instead of asking them for pow. anonymity (or freely available new identities) mean that attackers can use a sybil attack to deny service via capacity overload reply LordDragonfang 11 hours agoparentprevCorrect. PoW is also per request, so identity (new or old) is irrelevant. reply Uptrenda 9 hours agoprevI&#x27;m wondering if there is a more elegant way to solve sybil attacks here. For example: many CPUs are provisioned with key pairs that are unique to the processor and can be verified with the CA root cert of the issuer (Intel, AMD, etc.) You could tie PoW to successive signing and allow it to be verified in parallel. Then the operation couldn&#x27;t be parallelized to a botnet as all PoWs would be unique to a CPU.It seems that they&#x27;re targeting memory as a way to make it more costly for botnets. I think that there are many other ways to help minimize this attack scenario, too. The same logic could also be applied to mobile phones using ESIM. Later authentication with the mobile network uses public key crypto so I feel like you could also do unique proofs there, too.This is just a throw away comment though. I am probably missing obvious problems with this scheme. reply HWR_14 3 hours agoparentIf you are suggesting solutions based on immutable hardware keys and certified chain of custody from the manufacturer,I have to ask if you understand what TOR is. reply Uptrenda 2 minutes agorootparentThere are ways to do the verification with cryptography that would preserve anonymity and wouldn&#x27;t allow messages to be tied to public keys. I find condescending ignorant responses like yours highly annoying. One way to respond to people in the future is to start with the assumption that the person isn&#x27;t a fucking idiot. reply ignoramous 2 hours agorootparentprevIn OP&#x27;s defence, there might be a fully anonymous way to achieve attestation. Related: https:&#x2F;&#x2F;privacypass.github.io&#x2F; reply mjg59 8 hours agoparentprevProving your identity to an onion service in a way that can be tied to your use of other onion services feels like it might have bad outcomes? reply nsvd 9 hours agoparentprevOf course, this wouldn&#x27;t work if you don&#x27;t trust Intel, AMD, etc&#x27;s certificate, and I don&#x27;t see why you would in this application. reply keyle 9 hours agoparentprev\"Waiting for pair client connection\". That&#x27;d be something. Interesting thought but I can imagine a range of issues.In the same vein, how about the server would hold a pool of IPs in which the client has to return a proof of port knocking? e.g. here is a token, send that to this IP:port and wait for a unique response I can verify. Call this proof of latency. It would be low CPU, would spread the load across various machines and ports. On the downside, of course, you need multiple IPs and potentially servers. It could be implemented on the same machine but that would shift the cpu load to port connections. reply dmurray 1 hour agorootparentWhat does this prove about the client? Just that they have a reasonably fast connection (which in TOR-world can be painful to achieve), not that they aren&#x27;t part of a botnet.It allows you to scale your workload, but \"just pay for more servers and outscale the attacker\" isn&#x27;t generally an acceptable way to deal with DDOS. reply IngvarLynn 9 hours agoparentprevDDoS has nothing to do with sybil attacks. DoS happens because limited resource (connection initiation) is provided for free.They chose memory-hungry algorithm because that would prevent use of specific hardware (ASICs). reply Uptrenda 8 hours agorootparentAttackers can still outsource the PoWs. The sybil is the assumption that 1 PoW == one PC. But you can force this assumption with provisioning keys at least. reply IngvarLynn 8 hours agorootparentAnd why do we need this assumption exactly? reply Uptrenda 8 hours agorootparentProof-of-work uses resources like memory, CPU, hard drive space, and so on for their challenges which just means that the person with the most resources has a disproportionate impact within the system. A botnet owner has more total resources than anyone else so any PoW challenges that a server issues can be easily outsourced to the system.Overall, they will have more leverage from these resources than the number of systems they have access to. But you could at least restrict this to the number of systems with provisioning keys. The idea behind memory bound hash functions is that you&#x27;re trying to make it hard to paralyze the challenge to a farm. But many systems in the farm are still going to have multiple cores and gigabytes of RAM (so they can be used to leverage multiple challenges simultaneously.) The underlying problem to solve here is an identity problem: allowing an individual machine to act as a single identity which various proof-of-work schemes have tried to achieve.The ideal solution would also limit connections made by the same actors but that is probably not something you can achieve with something like TOR. This is a sybil problem, by the way. reply IngvarLynn 2 hours agorootparentYou&#x27;re trying to solve a straightforward engineering problem with an unfit solution to an ill-defined problem. The solution of sybil problem would not solve the case of coordinated attack by multiple nefarious agents. You can also call this meat botnet owned by master-coordinator. The solution would distinguish this from a normal botnet but in the end your service down in the very same manner and clients gave up most of their privacy for nothing.Imagine instead the following trivial scheme: instead of burning resources the client would pay to be served in reverse order of payment value. Let&#x27;s say client is willing to pay 1 cent to be served in the next 10 seconds. The attacker would have to pay more as he have to occupy the whole head of this queue all the time to be successful. Let&#x27;s say server can process 100 rps - now he&#x27;s making over a dollar per second, which he can use to scale his serving capacity. reply Uptrenda 6 minutes agorootparentIntroducing the requirement to spend money to use the service would drastically reduce its value. It wouldn&#x27;t be Tor anymore. Payments would make it easier to link identities and filter access to it. It would also mean not everyone could afford to pay for the service.>and clients gave up most of their privacy for nothing.Also not really sure how giving up privacy comes into this? Depending on how the scheme is implemented you can still preserve all the same privacy of using Tor with provisioning keys. E.g. you might use enclaves and keep verification hidden inside enclaves (so hosts cannot see the challenge protocol) or use zero-knowledge proofs to hide everything.There may even be simpler algorithms since the certificate chain would be using something like RSA SHA256 (which have some neat math tricks to modify them more compared to other algorithms.)seanhunter 3 hours agoprevSurely the DDossers will just use some of their botnets for generating the POWs? I don&#x27;t think I fully understand the scheme. Is the idea that as the attack progressed this would consume more and more of their resources making an attack impractical? Surely in that scenario more and more of the real traffic&#x27;s resources would be consumed by them having to solve puzzles also, so Tor would in effect be cooperating with the attackers and DDosing all of the valid clients ? reply Vecr 3 hours agoparentNo, I think it makes the the experience strictly better for normal (\"real\") users. On phones it might burn too much battery, but on desktops or plugged in laptops dedicated users can configure their user agent to send in difficult proof of work submissions, getting closer to the front of the line. The actual problem starts when each individual request coming from the botnet starts submitting more proof of work then the real users can tolerate (due to taking too long), and that&#x27;s where it&#x27;s pretty much the same as before the DDoS protection system existed. reply bootsmann 2 hours agoparentprevBotnets usually consist of networks of captured low spec IoT devices (mostly routers, sometimes exposed IP cams etc.). They might not have the hardware required to outbid real users in PoW. reply KirillPanov 2 hours agoparentprev> Surely the DDossers will just use some of their botnets for generating the POWs?It takes much, much, much more (proven) work to DoS a service than it does to use it normally. reply seanhunter 2 hours agorootparentThen that sounds like a very elegant solution in that case. reply marcodiego 10 hours agoprevI have an idea to minimize traffic on the tor network or make it faster. It should be possible to use the network as a cdn. If I want to make a file available, it should be possible for me to send pieces of the file to nodes who gave me permission to do so. When the file is requested, I then could point to these nodes. Of course, some care should be taken not to turn the tor network into a \"anonymous torrent replacement\" to avoid defeating its purpose.The current proposal discussed in the post talks about \"prioritize verified network traffic\". It would be interesting if sharing \"file pieces\" could prioritize your traffic since you&#x27;re actually helping the network. Instead of \"proof-of-work\" it would be \"proof-of-bandwidth-contribution\". reply bawolff 10 hours agoparentThat&#x27;s kind of more the freenet model (content based), where tor is traditionally anonoymous TCP real time networking.I dont really see how it minimizes traffic on the network though. You still have to talk to the CDN nodes. reply marcodiego 10 hours agorootparentYou&#x27;re right. This doesn&#x27;t minimizes traffic, it distributes it. reply Animats 11 hours agoprevThis has been suggested before, for email spam.Cloudflare could do this, too. Every time you access a busy site, seconds to minutes of useless crunching. The overall effect would be to drain batteries worldwide. reply sneak 11 hours agoparentThe suggestion for PoW for email bonds was called Hashcash, by Adam Back, and involved partial hash collisions.http:&#x2F;&#x2F;www.hashcash.org&#x2F;It served as the inspiration for Bitcoin&#x27;s PoW mining, interestingly enough. reply drfuchs 11 hours agorootparentThe original invention of PoW, as well as the idea of using it for email, was years earlier; see Naor and Dwork&#x27;s \"Pricing via Processing, Or, Combatting Junk Mail\" in CRYPTO&#x27;92. reply bombcar 11 hours agoparentprevCloud flare does do this. You get a screen saying checking your connection and it’s running hashes in your browser. reply kragen 8 hours agorootparentis it really running hashes, or is it probing your browser to see if your video card drivers look like phantomjs reply milsorgen 8 hours agorootparentI was actually quite curious about that and I found this.>With a JS challenge, Cloudflare presents challenge page that requires no interaction from a visitor, but rather JavaScript processing by their browser.>The visitor will have to wait until their browser finishes processing the JavaScript, which should be less than five seconds.https:&#x2F;&#x2F;developers.cloudflare.com&#x2F;fundamentals&#x2F;get-started&#x2F;c... reply kragen 5 hours agorootparentthat permits both possibilities reply dnstalk 11 hours agoparentprevJust like ads! They wear your battery but without your consent reply ivirshup 11 hours agoparentprevHey, that&#x27;s not a fair assessment.It would also dump greenhouse gasses into the atmosphere. reply hedora 11 hours agoprevThe article says that there is only a factor of 6 in solution time between a high end server and low end phone. How is that possible? The server likely has much more than 6x the ram and cpu count (and faster cpus) than the phone.Also, since it is DDOSing, the server’s work is embarrassingly parallel, but the client work isn’t necessarily parallelized at all.Even if it is only a factor of 6 (or one) they are talking about 1 minute solve times once a DDOS is detected.At that point the service is basically down anyway, right? reply bawolff 10 hours agoparent> The article says that there is only a factor of 6 in solution time between a high end server and low end phone. How is that possible? The server likely has much more than 6x the ram and cpu count (and faster cpus) than the phone.The limiting factor if equihash is allegedly memory bandwidth, which maybe doesn&#x27;t vary that much between srrvers and phones. reply 8organicbits 10 hours agoparentprevA good explanation of the algorithm is here: https:&#x2F;&#x2F;github.com&#x2F;tevador&#x2F;equix&#x2F;blob&#x2F;master&#x2F;devlog.md> they are talking about 1 minute solve times once a DDOS is detected.The point of this is to prevent an existing easy DoS attack (introduction flooding) into a partial outage&#x2F;slow down. It&#x27;s an incremental improvement on a hard problem. reply zacmps 10 hours agoparentprevI suspect they&#x27;re off by at least an order of magnitude in that estimate, if not two (or more if GPU acceleration is possible). reply kragen 8 hours agorootparentgpus don&#x27;t have more memory bandwidth, which is why they&#x27;re using a memory-hard problem reply 1vuio0pswjnm7 11 hours agoprevHow will the service operator know when their site is under \"stress\". Will this effectively prevent someone from having a \"high traffic\" hidden service free from Tor-imposed puzzles. If the hidden service operator is aware that the site is receiving high traffic, could the operator run several sites as mirrors, so that users had options if, e.g., one site was not responding fast enough. Is there guidance published anywhere on what is the the \"normal\" traffic for a hidden service. reply 1vuio0pswjnm7 10 hours agoparentFrom the onionbalance sitehttps:&#x2F;&#x2F;www.benthamsgaze.org&#x2F;wp-content&#x2F;uploads&#x2F;2015&#x2F;11&#x2F;sucu... reply solarpunk 10 hours agoparentprev>If the hidden service operator is aware that the site is receiving high traffic, could the operator run several sites operating as mirrors, so that users had options if, e.g., one site was not responding fast enough. Is there guidance published anywhere on what is the the \"normal\" traffic for a service.I think this[1] would help.[1]https:&#x2F;&#x2F;onionbalance.readthedocs.io&#x2F;en&#x2F;latest&#x2F; reply 8organicbits 10 hours agoparentprev> When the subsystem is enabled, suggested effort is continuously adjusted and the computational puzzle can be bypassed entirely when the effort reaches zero. reply parentheses 8 hours agoprevThis is a good use of proof of work. Seems useful as it bottlenecks DDOS attacks by burdening them with having to give proof. reply willvarfar 4 hours agoprevComputers are still getting faster. With time, the POW threshold will steadily increase. So will this discriminate against those with old sluggish hardware?And is that the kind of hardware that the users in regimes that TOR is supposed to help have? reply bunabhucan 10 hours agoprevI wonder if it would be possible to securely offload some of the aes processing to the proof of work cpus. Or make ddos requestors perform a fourth layer of encryption&#x2F;routing, possibly of data, possibly noise. reply hbfdhfdhadfhnfa 12 hours agoprevI though that its the last hop that operators control and they can intercept the traffic thats the problem. but this only saves them money and costs the users more when energy is expensive reply cypherpunks01 11 hours agoparentWith regular Tor > Web traffic, yes the exit relay (last hop) is able to tell the destination and can gather other metadata or intercept&#x2F;modify unencrypted traffic.With Onion Services however, there is no exit relay. Services are encrypted end to end between the client and the hidden service. reply dylkil 11 hours agoparentprevIt limits denial of services attacks on onion services reply rmac 5 hours agoprevwonder why they didn&#x27;t implement something like privacy pass (private access tokens &#x2F; private state tokens) reply remote_phone 9 hours agoprevI freaking love new ideas like this! This is the beauty of computer science, anything is possible if you’re smart enough and willing to work hard! reply m3kw9 10 hours agoprevSo there needs to be a token to be mined as an incentive? Lol reply quickthrower2 11 hours agoprevHold on you just made DoS more expensive, but a hell of alot more effective. If I need a RTX4090 to access your site now, the attacker has succeeded. reply grug_htmx_dev 11 hours agoparentCurrently attacking is nearly free, and you can&#x27;t access the site at all anyway. reply codetrotter 11 hours agoparentprevThere are PoW algorithms specifically developed to resist GPU and ASIC. Typically they do this by being memory intensive instead of (or in addition to) being compute intensive. reply hedora 11 hours agorootparentRegardless, you need a device that’s more powerful than whatever the attacker is using.The article says they target 1 minute solve times under load. If that’s 1 minute on a 5GHz, 64 core machine with 512GB ram, an A100 and an FPGA, then it’s going to be at least 5-15 minutes on your phone.Also, the server farm can parallelize work across an arbitrary number of challenges, but legitimate users cannot. reply remram 10 hours agorootparentThe attacker would need way more power actually, to send enough requests to flood the server. You only want to get one request in.If the server can process 10k requests per minute, and you need to send 10 requests per minute, you only need 0.1% as much power. reply hedora 10 hours agorootparentMy phone CPU normally draws well under a watt, but a server normally draws well over 100 watts. reply emporas 5 hours agorootparentprevRequiring regular users to compute PoW is a terrible idea. Actually it has the exact opposite effect. It will keep the attackers in, and the regular users out.The problem is that we don&#x27;t know how much is a cheap computation without first relying on a marketplace of computation and discovering the price. That marketplace of computation does exist, and it&#x27;s called blockchain. reply bandergirl 43 minutes agorootparentI think this just crowdsources the server’s load. Servers will certainly have to handle fewer requests thanks to PoW, at the expense of clients’s CPU time.The upside is that the server does not go down, so at least some users will be able to access the website, compared to zero users reply hsbauauvhabzb 11 hours agorootparentprevThe article itself lacks details on what proof of work actually is - based on your answer I’m assuming compute rather than captcha. Is there any example algorithms that are easy to understand? I’m curious to see an algo that’s expensive for the client but cheap for the server to verify, I assume it involves reversing an equation or similar? reply codetrotter 11 hours agorootparentOne of the most known compute based PoW algorithms is the one used by Bitcoin.Basically it goes like this:You are challenged to use some piece of data given to you, and to add some data to it, which will produce a hash with a given number of leading zeroes.For example let’s say I challenge you to find a sha3 hash of (“response to codetrotter for comment 37255449 on HN” + any data of your choosing), with difficulty set to 3. Meaning that in order for me to accept the hash, it has to have at least three leading zeroes.The higher the difficulty, the higher number of leading zeroes I ask for from you. Which in turn means it will take you more time to find. Because the only way to find a fitting hash is to try a bunch of different data until you find a fitting hash.The neat thing is that while it takes a lot of time for you to find a matching hash, it is trivially simple for me to validate your claim when you’ve found a matching hash.For this kind of PoW, people have developed software that runs on GPU faster than most CPU can do. And then they developed specialised hardware to be even faster - ASICs.That in turn is where memory-based algorithms come into play. To make the people with GPUs and ASICs not have an advantage over others. reply checkdrain 11 hours agorootparentprevEquihash (Birthday Problem): Memory Hardness https:&#x2F;&#x2F;en.m.wikipedia.org&#x2F;wiki&#x2F;EquihashRandomX (Execution of a random program): Memory Hardness (Inc. cache sizes), Speculative Execution&#x2F;Branching, ILP, some sort of chaining https:&#x2F;&#x2F;github.com&#x2F;tevador&#x2F;RandomX&#x2F;blob&#x2F;master&#x2F;doc&#x2F;design.mdEdit: these are examples of CPU-bound PoW. But the general idea with PoW is that you have some hash-like function H() with no known inverse function such that the only feasible way to determine the output is just running the function. The client runs H(x) with a different input x every time. If the output is a high enough number, the server lets the client though.The server runs H() to verify, and this is easy to parallelize. But in order to get through the server, the client must run H() many times on average.Also server provides a salt to prevent the client from reusing their old hashes. And the server usually indicates how high the output of H() must be (this is called the difficulty). reply whimsicalism 11 hours agorootparentprevPretty much any NP problem that we can&#x27;t currently solve in polynomial time, ie. prime factorization - can be a PoW.I&#x27;m not sure which are specialized for GPU-resistance, probably not prime factorization given it can be parallelized reply extraduder_ire 11 hours agoparentprevI think difficulty also kind-of scales per-user, due to the queue mechanism. reply wyldfire 11 hours agorootparentDo those queues have a way of resisting a Sybil attack? reply hedora 10 hours agorootparentProtecting against sybil attacks without violating tor’s security guarantees seems impossible. Would love to see a proof or counter example. reply zmmmmm 10 hours agoprevAs others have commented, it&#x27;s a shame there isn&#x27;t a proof of work that doesn&#x27;t also hurt the planet.It makes me wonder if there would ever be a way to actually do the opposite - your \"proof of work\" is somehow linked to extracting CO2 from the atmosphere? reply hunter2_ 10 hours agoparentIf you sell carbon credits, the money you make doing so is proof that you did it (well, it&#x27;s proof that you did something of value, which could also count). reply pcdoodle 9 hours agoparentprevWe helped secure the bitcoin network and prevented our basement pipes from freezing around 5 years ago (Old building, new heat pumps installed for 1st and 2nd floor. The old basement steam boiler being removed lead to really low basement temps). Resistive heat was the only option down there. After improvements (water heater + circulation fan + insulation), we shipped the miner to a buyer from a hydro facility to burn excess watts for the rest of its life.Don&#x27;t hate on the BTC crowd, some of us also care about ecological load. reply IngvarLynn 9 hours agoprev [–] It&#x27;s a shame that Torproject has decided to reinvent its own wheel, lagging 10 years behind the crypto crowd, instead of integrating with existing coin(s).The problem is, such integration would require the chosen coin to be anonymous, which is essentially forbidden: https:&#x2F;&#x2F;www.theverge.com&#x2F;2023&#x2F;8&#x2F;23&#x2F;23843161&#x2F;tornado-cash-ind... reply Zuiii 6 hours agoparentI agree with you in principle. Wasting energy like what this and hashcash do is unfortunate but that&#x27;s what happens when you have an irrational hate towards a technology rather than how it is used.That said, modeling it after a general cryptocurrency is probably a bad idea since it rising prices may prevent legitimate clients from being able to connect to onion services due to the challenge being too expensive (either in terms of computation or accusation). I think a much practical approach is to have each visitor contribute to a partial solution that can then be combined to derive funds (much like how mining pools work). That way, clients will be completely isolated from cryptocurrency and sites can actually benefit from the work rather than just throwing it away. It&#x27;s a win-win situation.I hope the next generation learns from our senseless technology-burnings. reply IngvarLynn 3 hours agorootparent>modeling it after a general cryptocurrency is probably a bad ideaNot modelling after but integrating of an existing one. Because this saves massive amount of engineering effort.>rising prices may prevent legitimate clients from being able to connect to onion services due to the challenge being too expensiveObviously, the price for legitimate clients would be much cheaper, as their requests shall be placed in the middle of priority queue (clients can wait a few seconds) while the attacker have to occupy the very top of this queue all the time. Also note that the bigger the DDoS in this scheme - the bigger profits server could make, which he could spend on expanding capacity.>each visitor contribute to a partial solution that can then be combined to derive fundsThis scheme predates monero, which was about 10 years ago.>the next generation learns from our senseless technology-burnings.Not if they would reinvent the wheel each time instead of adapting of existing tech to current needs. reply pyinstallwoes 9 hours agoparentprevWhat? Adopting a coin is nonsense. Your argument is also invalid based on the amount of coins that exist, each reinventing POW. reply dotnet00 4 hours agoparentprev [–] I think it&#x27;s pretty great that Tor hasn&#x27;t tied itself to crypto that deeply given how the vast majority of crypto users don&#x27;t actually give a shit about privacy, only the appearance of it. replyGuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Tor has implemented a proof-of-work (PoW) defense for onion services to prevent denial of service (DoS) attacks.",
      "Incoming client connections are required to solve a puzzle, proving their authenticity and discouraging attackers.",
      "The PoW mechanism prioritizes genuine traffic and makes large-scale attacks impractical, enhancing the security and reliability of the Tor network."
    ],
    "commentSummary": [
      "The debate focuses on the use of Proof of Work (PoW) in the Tor network to safeguard onion services from attacks.",
      "Environmental concerns, anonymity, and potential solutions like CPU identity-linked proofs of work are being discussed.",
      "Exploring the possibility of using Tor as a content delivery network and leveraging PoW algorithms to protect websites."
    ],
    "points": 272,
    "commentCount": 116,
    "retryCount": 0,
    "time": 1692914245
  }
]
