[
  {
    "id": 40694254,
    "title": "We Made The World's Smallest and Cheapest Network Switch",
    "originLink": "https://docs.murexrobotics.com/elec/boards/networking/switch",
    "originBody": "Hello, we&#x27;re Max and Byran from MUREX Robotics, a high school robotics team from Exeter, New Hampshire. We are super proud to have made this open source piece of technology! It is only 6.9 dollars (actually!) from JLCPCB :) I hope you like it.You can find us at byran@mrx.ee and max@mrx.ee as well if you have any questions.We will be putting a small run of these boards for sale somewhere (we have <25 units of stock), probably for $10+shipping. Let us know if you&#x27;re interested in more!Board files for everything we make is here: https:&#x2F;&#x2F;github.com&#x2F;murexrobotics&#x2F;electrical-2024",
    "commentLink": "https://news.ycombinator.com/item?id=40694254",
    "commentBody": "We Made The World's Smallest and Cheapest Network Switch (murexrobotics.com)527 points by Hello9999901 18 hours agohidepastfavorite145 comments Hello, we're Max and Byran from MUREX Robotics, a high school robotics team from Exeter, New Hampshire. We are super proud to have made this open source piece of technology! It is only 6.9 dollars (actually!) from JLCPCB :) I hope you like it. You can find us at byran@mrx.ee and max@mrx.ee as well if you have any questions. We will be putting a small run of these boards for sale somewhere (we haveOur company is often asked at expos if we supply 2 wire ethernet switches (e.g. Single Pair Ethernet SPE[1]) but the reality is there's little demand This reminds me of a funny conversation I had in a small town stationers when looking for an item. ‘No, we don’t stock it. People keep asking, and I keep having to explain that there is no demand.’ Though this wasn’t for an obscure Ethernet variant. reply varjag 8 hours agorootparentprevYeah that's the thing: neither of them is really standard, and both are fairly expensive. They are also available in very limited mechanical configurations (angle, mounting). Fortunately SPE does not really require either of them. In our product we're going with our own solution. reply globular-toast 12 hours agorootparentprevHmm... I thought everything still had collision detection and would work on a bus, like what you'd get using a hub. reply sgtnoodle 6 hours agorootparentIt might work in so far as you'll get packets through. The performance would be abysmal, though. Modern Ethernet is built around switching. reply globular-toast 5 hours agorootparentWould it really be that bad? If the devices were well behaved (ie. not too noisy, no gratuitous ARP etc) and the application could assume that most of the time either zero or no devices will be communicating, would it be that bad? This is something I might test myself. I have a couple of audio devices that will never be both \"active\" at the same time. In my current layout I need to run either two cables or just another switch and it just seems a waste. I wonder if I can buy daisy chained cable so I don't have to make one... reply varjag 11 hours agorootparentprevThere is normally no collision detection beyond 10Mbps. Also PoE would not trivially work daisy chained. reply toast0 2 hours agorootparent100base-Tx is specified for shared media (hub rather than switch), but I think you need some electronics to make a hub, you can't just do a passive connection, and so you probably end up with a hub IC and may as well use a switch IC instead. reply mike_d 20 minutes agoparentprevA Juniper EX4100 ticks all your boxes. Adding a sound requirement is stupid and ridiculous. You're wanting to take the power supplies from 48 90W devices and put them all in one dense little box and then complaining that it needs to be cool. If you have room for 48 PoE devices, you have room for a properly cooled and sound isoloated IDF. reply userbinator 14 hours agoparentprevFor example, a TrendNet 10/100 compact switch (not a hub) goes for $7.31 including shipping on eBay and it comes with a case and a power supply A 1G switch from Ali with a case, power supply, and the RJ45 connectors is also under $10. reply gertrunde 9 hours agoparentprevI suspect the combination of being able to dissipate 3.4kW of power, and the requested size and noise constraints may put this combination of features firmly beyond reasonable, even before considering cost. But there is always room to hope. :) reply crote 6 hours agorootparentA PoE-supplying switch doesn't need to dissipate that power. Assuming a power supply efficiency of 85%, supplying 3400W to downstream devices means having to dissipate 600W of heat. Keep in mind that you'd be supplying 71W to every single downstream port. That's an insane amount of power. Something like a Cisco Catalyst 9136I Access Point only comes up to 47W, and that's assuming 16 radios, double 5Gbit uplinks, and a USB device drawing 9W. reply AstroJetson 2 hours agoprevNice job, I'm always impressed with HS robotics projects. Clever design and nice form factor. I bought a stack of these: https://www.amazon.com/Tenda-Gigabit-Unmanaged-Wall-Mount-Pr... for some projects that need ethernet. They are mid-level quality. Not sure I'd put them on something that would break my heart to get back. reply Hello9999901 1 hour agoparentI agree. They're also so much larger than our design! If getting a switch ever interests you, please let us know at byran@mrx.ee. No pressure of course! reply xhrpost 37 minutes agoprevSorry if I missed it on the page but are all the ports Auto-MDIX? reply Hello9999901 8 minutes agoparentWe didn't try, but I think so. We always ensured the crossovers were correct. Sorry I can't give a better answer! reply rgovostes 13 hours agoprevThe comparable BotBlox SwitchBlox Nano is 25.50 x 25.50 mm, albeit with two fewer ports. This is 44.90 x 42.11 mm. How do you justify the claim of being the world's smallest? reply xamuil 7 hours agoparentHi, I'm Max, the lead designer of this V2 revision. You're absolutely correct! My team and I were not aware of BotBlox's 3-port switch, so a more specific description would be the world's smallest 5-port unmanaged switch. The smallest commercial alternative we found was also BotBlox's 5-port unmanaged switch [1], which we beat in both size and cost. Once again, our mission is to create open-source, cost-effective, and accessible electronics for as many people as possible -- I think our board is much more attractive in that respect and a win in my book :) [1] https://botblox.io/products/small-ethernet-switch reply mike_d 2 hours agorootparentSince you have thrown ISO/IEC 8877 out the window, which is referenced by 100BASE-TX, you surely can't call it an \"ethernet switch.\" reply bruce511 17 hours agoprevWell done. For those of us not generally in the hardware world (and thus not 100% familiar with the terminology) could you post more pics? Especially of the enclosure? I'm not really sure if you are just exposing headers, or if there are regular Ethernet plugs on the board? reply Hello9999901 17 hours agoparentThank you so much! We're so happy you like it. It means a lot to us. We will be adding more pictures right now! We're exposing 1.25mm pitch Molex Picoblade connectors to make the board as small as possible. The built-in magnetics allow it to be connected to any Ethernet device just from spicing into an RJ45 connector. reply voidmain0001 46 minutes agoprev“We are super proud to have made this open source piece of technology” - of course it’s open source - you live in the state of “Live free or die!” My favourite state motto. Thanks! reply zokier 11 hours agoprevWhy classic full-fat fast-ethernet (base-tx) instead of single-pair ethernet (base-t1 or t1l/t1s) if you are targeting embedded use? reply Hello9999901 7 hours agoparentThanks for asking! That is a very good question. However, we use bog-standard Ethernet connections, so using Fast Ethernet is super straight forward. Just splice the cable and we're all good. reply rbanffy 11 hours agoprevOne side project I never seem to start is a single board cluster based on Octavo SoMs. The idea is to have 32 cores per board to mimic a Thinking Machines CM-1-like cube. How easy is it to use a PCB to route Ethernet between nodes? What kind of components would go between the SoM and the switch? reply Hello9999901 6 hours agoparentThat would be super cool! I'm not sure how it'd work together. I would think we need a higher speed fabric-type connection. reply Blammar 17 hours agoprevNice work indeed. However, was there a reason you didn't support gigabit ethernet? I haven't used 100mbit ethernet for more than a decade... reply aunver 17 hours agoparentHi! I'm Altan, another member of Murex. Many of the design decisions behind the switch were driven by the requirements of our underwater robot. In our case, the communication speed was capped by the transfer speed achieved over our tether (we use galvanically isolated OFDM to inject data over our powerlines). Since size and cost were our primary goals, 100mbit was more suitable than gigabit ethernet. While it would have been cooler to have a gigabit switch, it would also increase the size and cost. reply nativeit 16 hours agoparentprevI’m not sure what your background is, but 100Mb Ethernet is still rather common in embedded devices and applications where the network protocol is primarily intended to facilitate UART serial communication. Just as a general note for context, I will defer to their more specific answer for this particular application. Neat project! reply procarch2019 16 hours agorootparentAgreed. Due to the long lifecycle of manufacturing equipment we still see a lot of 100mb out there, and it’s not even embedded. I would note that all new products seem to be gbe or better. reply jmb99 15 hours agoparentprevAs much as modern Ethernet standards are much nicer (my house is wired for and running 10Gb everywhere, with 40Gb Infiniband to a couple locations too), 100Mbps still has its place. Specifically, anything embedded, slow, and/or cheap. No reason to spend the extra money on 4 more wires and pins and trace routing if your microcontroller only sends a few packets/second. reply jtriangle 16 hours agoparentprevIf you're doing tethered ROV stuff, the weight of the teather is a big big deal, so adding 4 additional wires is a non starter. For the stuff that goes extremely deep, they use fiber because it's much lighter. It presents significant cost increases of course, which, you'd want to avoid if you can. reply teruakohatu 16 hours agorootparentYou can get neutrally buoyant cables: https://bluerobotics.com/store/cables-connectors/cables/fath... reply sgtnoodle 6 hours agorootparentIt's still mass, drag and cost. reply toast0 16 hours agoparentprevGigE needs twice the pin count. IMHO, there's not much room on the board for any more i/o. Certainly gigabit is nice, but there's plenty of applications where 100M is more than plenty. reply schobi 13 hours agoprevIt is great to see that this is accessible and possible with limited effort/budget! On the higher speeds, it remains difficult: In the datacenter, 10G ethernet is often standard or even outdated. But for non-mains powered systems, even 10G uplink is hard to come by. I would love to have a switch with 25/100G uplinks in a smaller-than-19\"-rack form factor with 12-40V DC power. Building one as a side project might still be too complex - if you would get access to chipsets at all. reply Hello9999901 6 hours agoparentWe only found ~gigabit and ~fast ethernet chipsets that are easily accessible. However, it's definitely something we will think about in the future! Thanks for the suggestion! reply crote 6 hours agoparentprevHow about the Mikrotik CRS510-8XS-2XQ-IN? 2x 100G uplink, 8x25G/10G/1G downlink, DC power input, and only 320mm (12.5in) wide. reply FredPret 7 hours agoprevYour group is incredibly cool, keep it up. It's exciting that kids in high school have access to this type of activity. I love living in the future! reply allenrb 4 hours agoparentSeriously, my high school was mostly boring and pointless. I’m in awe of the opportunities some kids are able to find/create today. reply Hello9999901 6 hours agoparentprevThank you! Attempt the impossible :) reply advael 13 hours agoprevThis is amazing, well done, no notes, would love to buy when available I think it's been rightly pointed out that you aren't beating commodity parts on price, but you're also not a manufacturing operation with scale and there is a certain niche for which anything with open hardware that's well-documented is a killer feature reply Hello9999901 6 hours agoparentPlease email us at byran@mrx.ee for now! reply lanewinfield 15 hours agoprevHey can I just say I appreciate y'all's mission and energy in the comments? Very inspiring, very welcoming—you're the best! reply Hello9999901 15 hours agoparentThank you so much! This energy has waked us all up!! We’re all living together right now preparing for the world championships next week in TN! This is soooo exciting. reply ChuckMcM 16 hours agoprevThis is truely awesome! Hat's off. If you're experience in college is anything like mine you will find that 90% of the incoming freshman class is looking at \"electronics\" for the first time (assuming you're going EE, but similar for CE or CS), you will be way ahead right from the start. That this switch is small and light might make for some interesting UAV applications as well! reply Hello9999901 15 hours agoparentThank you so much! Super excited for college. I think it should fit right into an UAV. I see a lot of use from Ardupilot forums (which we use). It’s the reason we have the LDO as well. We wanted to keep the application possibility open. reply spcebar 17 hours agoprevCongratulations! Impressive work for any age. Is creating bespoke parts a requirement for your robotics competition or just a part of your team's ethos? reply Hello9999901 17 hours agoparentOur mission is to create open source electronics that democratize technology for as much people as possible! This is a full list of stuff we've done this year: https://www.murexrobotics.com/mrxEE. It isn't a requirement for the MATE ROV competition (I wish it was though; it would be super cool!). reply minetest2048 16 hours agoprevI wish we have this 2 years ago, this will be extremely useful for our cubesat. 115k2 baud UART is too slow for ground development reply ooochang 16 hours agoparentHello! I'm Osbert, another elec member on MUREX. For sure, we use 115k2 UART on our \"custom\" ESC serial communication protocol, MASCP (murex async serial communication protocol). We stream 2 IP cameras, our CM4 board (open source as well!), and our mrxPLC (DC powerline data injection technology). Thanks for the encouragement. It means a lot to our team! reply auselen 12 hours agoprevCongrats. A few months ago I wanted to make a small lab out of a few SBCs. Looking for a cheap 10/100 switch, I was surprised to see prices are this low; got a tplink 8 port / LS1008 for 10$ from Amazon. reply Hello9999901 6 hours agoparentThank you! We also have those switches. They are fantastic cheap tech as well. reply tarasglek 13 hours agoprevNot a hardware guy,how does one crimp and secure those custom ends? reply Hello9999901 6 hours agoparentYou can buy them right of Digikey by searching \"4 position Molex Picoblade cable assemblies\" or similar! reply checker659 16 hours agoprevAre you telling me one does not need an EE degree to make hardware like this? How do high school folks have access to resources / mentorship to make such a polished product? reply Hello9999901 16 hours agoparentAbsolutely not!! This is what MUREX is all about. We are on a mission to show anybody can do this. Change the world one small bit at a time. This was all self learned from the internet, trial and error, lots of passion, and this community. Our mentor doesn’t have a background in engineering so he just gives us lots of emotional support and some physics help. Love you guys!! This is amazing. reply lostlogin 1 hour agorootparentI hope your mentor see this thread, they are doing a great job if your working anything to go by. reply Fordec 15 hours agoparentprevMost major chipsets have their design specs in PDF format online with all the info there for interfacing on a hardware level. Many drivers these days are open source. Kicad is free to use for designing PCBs. And finally https://www.youtube.com/@PhilsLab has some good tutorials. Finally, goo into things with an attention to detail to polish a board. A hobby board takes far less time than a product board, but all it is is time and thinking about each attribute more. You don't need third level education to have that work ethic. Best of luck! reply yonatan8070 17 hours agoprevThis extremely cool, when I was in high school a few years ago we made some power adapter boards, but we couldn't have hoped to build a functional network switch, great job! reply ChillPill 16 hours agoparentHi, I'm Crane and I am also part of MUREX robotics and this is very inspiring to me as an electrical engineer who is starting out. reply fragmede 15 hours agoprev> We will be putting a small run of these boards for sale somewhere Somewhere like http://tindie.com? reply Hello9999901 15 hours agoparentMaybe! If you’d like one, please email me at byran@mrx.ee! reply jpc0 12 hours agoprevSome details I would like to see: - Does the backplane support full 1.25Gbps throughput? - Does is switch at line rate for all packet size? - The switch chip supports LACP, port mirroring, vlan tagging, QOS, these would be amazing to integrate into a product even for slightly higher cost in a 5 port switch - It's generally a hard requirement for me the 801.3az be off by default or can be turned off. I've had far too many issue with it enabled on network reply Hello9999901 6 hours agoparentHello! It supports 100Mb throughput, nothing more, nothing less. It's been tested with iperf. I believe it switches at line rate, but don't quote me on that haha. The chip's extra features can be enabled with an EEPROM, which we removed to cut costs and size further. It's on V1 though. reply moffkalast 11 hours agoprev> It is only 6.9 dollars > probably for $10+shipping You could honestly sell it for $30-40 and it would still be a pretty good deal. Meanwhile Blue Robotics be like \"that'll be $175 plus $50 shipping and customs fees as a percentage of that $175 fam\" https://bluerobotics.com/store/comm-control-power/tether-int... God, everything they sell is overpriced to the point of insanity. They could really use some proper competition. reply numpad0 4 hours agoparentLow volume hardware pricing always look infuriatingly high, but they also start looking hopelessly low once you've dipped toes into it and tried multiplying your spent development man-hours with McDonalds wages or tolerable unit price by expected sales volume. I've never heard of Blue Robotics, but I doubt that $175 product ships 1k units/year, and even if they did, that's $170k revenue, or 2x entry level engineers salary worth of raw recovered cash before factoring in any expenditure whatsoever, let alone taxes and HR. It probably hardly feeds one, and that's based on an optimistic hypotheticals that they ship a thousand of that product every year. Large scale multinational corporations ship in orders of million units. That makes it way easier to amortize non-recurring engineering and ship small products virtually at cost. reply moffkalast 3 hours agorootparentI mean sure, I understand that. But that doesn't mean I have to like it. BR are really well known to anyone dealing with ROVs or AUVs, but that's not exactly the average person. Commercial consumer hardware R&D is mostly a fool's errand these days, since if it's something that's worth producing and sells there will be clones that work just as well available almost immediately. I'm not sure how say, Adafruit, sells anything at all to be honest, anything they make gets perfectly cloned and sold on Aliexpress for a tenth of the price. I guess going extremely niche and overpriced is one way to work around it. reply tgtweak 6 hours agoprevCan you make a 2.5g version reply Hello9999901 6 hours agoparentUnfortunately, it's not really useful for our use-case. Our robot only uses ~kB amount bandwidth. reply OrvalWintermute 3 hours agoprevCan you produce a 10Gb version of the same? reply jakeogh 17 hours agoprevVery cool. It says fully open source, are the board layout files available? reply Hello9999901 17 hours agoparentYes! It is here: https://github.com/murexrobotics/electrical-2024 under networking/switch Edit: We use KiCAD Nightly 8.99 for the new features. You can view our boards easiest with kicanvas.org and just pasting in the https://github.com/murexrobotics/electrical-2024/tree/main/n... reply UnlockedSecrets 16 hours agoprevI would love to have one of these, if still is available! reply Hello9999901 16 hours agoparentPlease send us an email! We will try our best to get you geared up. byran@mrx.ee reply teddy__d 6 hours agoprevimpossible is now possible reply Hello9999901 5 hours agoparentunleashing innovation :o reply cliftonk 14 hours agoprevj/c but why are we still maxing out at 1gb ethernet connections? why have the speeds essentially not progressed in 20 years? you can get a 40gb connection by just using usb-c on modern machines. what's going on? (curious about why this is the case industry-wide, i think this project is really cool) reply stephen_g 8 hours agoparentCombination of power and distance. Copper Ethernet standards tend to be specified for over 30 metres, and go (preferably) up to 100m. That’s pretty tricky to do, you need quite thick cable with individually foil shielded pairs to achieve those kind of long distances at 10Gbps. 40 Gbps USB-C on the other hand is recommended to travel over a maximum of a metre or so of cable, with the recommended being 0.8m (2.6ft) of cable or less! Thunderbolt cables that go longer need active driver chips inside the cable in each connector to make the whole thing work. Then there is the power issue, 10Gbps Ethernet uses significantly more than 1Gbps, so a 40GBase-T switch would be even more power hungry. The combination of these has meant that basically most people just use fibre if they need more bandwidth. reply wtallis 13 hours agoparentprevYou can get 40+ Gb/s over USB-C or connections like DisplayPort and HDMI by using thick expensive cables that top out around 10ft of length. Beyond that, price starts shooting up as you get either optical transceivers or active retimers/redrivers built into the cable assembly. Ethernet over copper is designed for cable runs of over 300ft and has to be much more forgiving of poor quality cables and connectors. That means for the same level of complexity and power consumption in the transceivers, you're just not going to be able to get as much bandwidth. Ethernet equipment suitable for 2.5Gb/s and 5Gb/s in consumer equipment (cheap, low power) is now readily available, but there's not enough demand to drive pricing down to parity with 1GbE and completely supplant it. 1GbE is good enough for most consumer use cases, especially given the dearth of multi-Gig WAN connections in the consumer market, the lack of popular use cases that would benefit from slightly faster LAN connections, and the continuing improvements to WiFi. reply MrMid 14 hours agoparentprevThe intended use-case for this board is some robotics applications. I don't think parts of robots need to communicate via gigabit. 10/100 Base-T is presumably easier to implement and thus cheaper and smaller (which is the point of this project) reply Hikikomori 11 hours agoparentprev2.5gbit is quite common and cheap. reply jeffrallen 13 hours agoprev> full Bob-Smith style termination for all center taps Man, that's some serious inside baseball right there. reply Hello9999901 4 hours agoparentThanks! Do it right, do it MUREX! reply TZubiri 17 hours agoprevCool. Is this designed for personal or industrial use? reply yonatan8070 17 hours agoparentGiven the caseless PCB and non-RJ45 connectors, it looks like it's designed to be used on robots, and I can certainly see it being used that way in my robotics team reply ChillPill 17 hours agoparentprevHello, I'm Crane and I'm also on the MUREX Robotics team. The price point we are aiming towards is $7-$10. Our network switch is currently used for personal purposes, in our underwater robot, and we look forward to expanding it for industrial purposes. reply iancmceachern 16 hours agoprevThis is awesome, you all rule reply Hello9999901 15 hours agoparentThank you it truly means a lot to the team!! reply bhouston 9 hours agoprevGreat work! reply Hello9999901 6 hours agoparentThank you! reply toomuchtodo 17 hours agoprevExcellent work, stay bold. reply Hello9999901 17 hours agoparentThank you! It means a lot to our team!! reply ojbyrne 15 hours agoprevTypo: “commerically” reply Hello9999901 6 hours agoparentThank you! Noted. reply chx 15 hours agoprevIf you are interested in such things, check botblox. They have a similar sized switch, a smaller one with fewer ports, a stacked one for Gigabit... it's very expensive though. reply xamuil 7 hours agoparentAh you're right –– the team and I were not aware of BotBlox's 3-port switch! I guess a more specific description would be the world's smallest 5-port unmanaged switch. We do however beat BotBlox's similar 5-port unmanaged switch [1] slightly in size and miles in cost. I'm Max by the way, the lead designer of this revision. [1] https://botblox.io/products/small-ethernet-switch reply jiveturkey 17 hours agoprevhmm ... not the cheapest. $7 is just for the PCB (assembly) right? you need an enclosure and power supply as well. monoprice #41710 is $10 all in with a price break starting at qty 2. maybe you want to qualify your description with 'embeddable'. > built-in magnetics interesting b/c the website says `external magnetics` reply Hello9999901 17 hours agoparentHello! I just want to clarify some of these points. Saying it is the world's smallest switch is a bold claim, and there are definitely alternative options around. However, our board scales really well. The main reason we say it's the cheapest is because the real BOM is only around 4-5 dollars. Our small run of ~25 boards came out to ~$7 each. If you agree with my interpretation, perhaps the words \"smallest and cheapest\" can be together? Magnetics: We have built-in \"external\" magnetics, so the physical ports don't have the magnetic inductors required in the Ethernet standard. This makes the ports super small, allowing us to use 1.25mm pitch Molex Picoblade connectors. Again, thanks for the suggestions. We're still learning and the team is taking all the comments very seriously. reply fragmede 15 hours agorootparentThe \"real\" BOM is what you can actually get. If you don't have the funding to make 10,000 boards in order to push to cost down to $4, then the BOM is $7. reply yonatan8070 17 hours agoparentprevGiven this was made by a high school robotics team and it accepts up to 12V, it's likely that the intended use case is on a robot that already has a 12V battery reply numpad0 15 hours agoparentprevFast Ethernet +/- pins go through a special 1-turn transformer for electrical isolation installed between the PHY and RJ45 connectors, commonly referred to as \"the magnetics\" in Ethernet world. It's physical ferrite and copper object molded like a chip, therefore it can't be trivially integrated into a silicon or in MCM. Hence most Ethernet chip require one external to the chip, and in this case it is indeed external to the chip, and integrated into the board at the same time. (yes a cap in-line works too if you know what you're doing) reply contingencies 17 hours agoprevNice job guys. For your next challenge, see if you can find a cost-effective way to add VLAN management, or do something cute with the form factor, like make it fit inside a standard electrical socket wall cavity with AC adaptor, or inside another ethernet port. PS. Try to reference vendor application notes or datasheets instead of stackexchange where possible. reply Hello9999901 17 hours agoparentThank you! This goes in our underwater robot, and it has all the features that let the system work without anything else. However, we will definitely keep your suggestions in mind for our future revisions. We're seeing how to make this board even smaller, while keeping the cost down. 7 dollars (technically 6.9) is the mark to beat. reply StephenSmith 7 hours agoprevNow do POE reply Hello9999901 6 hours agoparentThat’s one area we are exploring! reply gardnr 16 hours agoprev [–] It looks great! Have you considered running it through https://www.quilter.ai/ before sending it out? It's free. You can hear more about it in this podcast: https://wandb.ai/site/resources/podcast/episodes/ai-in-elect... reply Hello9999901 16 hours agoparent [–] I actually met with the Sergiy as well a few months back! Super cool guy. I also highly recommend quilter - thought it was super cool (not paid haha). Quilter doesn't have the best support for impedance matched traces. We do 90Ω on a 4 layer board and Bob Smith termination which has some pretty goofy design requirements. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "MUREX Robotics, a high school team from Exeter, NH, has released an open-source technology available for $6.9 from JLCPCB.",
      "They are selling a limited run of under 25 units for $10 plus shipping, with board files accessible on GitHub.",
      "For inquiries, contact Byran at byran@mrx.ee or Max at max@mrx.ee."
    ],
    "commentSummary": [
      "MUREX Robotics, a high school team from Exeter, NH, has developed the world's smallest and cheapest network switch, priced at $6.9.",
      "The switch is open-source and designed to be cost-effective and accessible, targeting applications where size and cost are critical.",
      "The team plans to sell a small batch of these boards soon, emphasizing their mission to democratize technology through open-source electronics."
    ],
    "points": 527,
    "commentCount": 145,
    "retryCount": 0,
    "time": 1718504815
  },
  {
    "id": 40694768,
    "title": "What You Get After Running an SSH Honeypot for 30 Days",
    "originLink": "https://blog.sofiane.cc/ssh_honeypot/",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131}button,html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}@media (prefers-color-scheme:dark){body{background-color:#222;color:#d9d9d9}body a{color:#fff}body a:hover{color:#ee730a;text-decoration:underline}body .lds-ring div{border-color:#999 transparent transparent}body .font-red{color:#b20f03}body .pow-button{background-color:#4693ff;color:#1d1d1d}body #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}}body{display:flex;flex-direction:column;min-height:100vh}body.no-js .loading-spinner{visibility:hidden}body.no-js .challenge-running{display:none}body.dark{background-color:#222;color:#d9d9d9}body.dark a{color:#fff}body.dark a:hover{color:#ee730a;text-decoration:underline}body.dark .lds-ring div{border-color:#999 transparent transparent}body.dark .font-red{color:#b20f03}body.dark .pow-button{background-color:#4693ff;color:#1d1d1d}body.dark #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.dark #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}body.light{background-color:transparent;color:#313131}body.light a{color:#0051c3}body.light a:hover{color:#ee730a;text-decoration:underline}body.light .lds-ring div{border-color:#595959 transparent transparent}body.light .font-red{color:#fc574a}body.light .pow-button{background-color:#003681;border-color:#003681;color:#fff}body.light #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.light #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI2ZjNTc0YSIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjZmM1NzRhIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}a{background-color:transparent;color:#0051c3;text-decoration:none;transition:color .15s ease}a:hover{color:#ee730a;text-decoration:underline}.main-content{margin:8rem auto;max-width:60rem;width:100%}.heading-favicon{height:2rem;margin-right:.5rem;width:2rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"blog.sofiane.cc\",cType: 'managed',cNounce: '90568',cRay: '894da1f1db142bd0',cHash: '1a73b06fd583d07',cUPMDTk: \"\\/ssh_honeypot\\/?__cf_chl_tk=05OnpUFzWlt5MN19CdOBoT.fhtLy.tYrAahERcoYZws-1718570611-0.0.1.1-3903\",cFPWv: 'g',cTTimeMs: '1000',cMTimeMs: '390000',cTplV: 5,cTplB: 'cf',cK: \"visitor-time\",fa: \"\\/ssh_honeypot\\/?__cf_chl_f_tk=05OnpUFzWlt5MN19CdOBoT.fhtLy.tYrAahERcoYZws-1718570611-0.0.1.1-3903\",md: \"UyaCQzXEu_bgd2RvTfiAKu65pKUjNumRQ4H9DeoKbD4-1718570611-1.1.1.1-D.Lgq.LlnexakPWzEGQrhpwTLrAB9fU6ca7nV5gasocLfmwBz5zvr4eE6gR_PJQhRPOEUQpZKICVJwE9_5XXCznfzqtW_jVZ.ymDHrCLXgjVu8dg_JBsq3DN0domGKcLIt5atdGOcf1eQnU0mUweSIT_Gd_u3lkg.d7hCtNf4b8KYPDlRSbh6X1IsEoWaQ.DsML36CxRazf9ozTmH8wkvyYsX7IP_vN08OGeqcqzHJOhQ5XQe.NOnzu2PRUFahkdrabtnkSNIO8KAQpjJlN3QmZBckzFv4FlaySJlN.5.0DVD4OEwxjUFJ.mAT4YUfB8HPtlZATPOO_lfcLVY46rVACIzg5DOQrpRJXzm6e4Y1qOU8foahyM1y45NM7ul.A5Uwx8UTNB0jX1i3nBtv8VoZU1klE.AdvwL5Wp6k6Ml2rW7gKgDpwGuDz3V8n2InjJG5i3ljvr5oosQrRNw62y0rtiAIo0wxDitHlWoxr.STiJMziZBOn9lCiblLl8DByU8xLGNMCQlrI0vr9kv2uWLbtEPWsMB9tFWUu.6ZDwgH1xTdDxXKYi6ZyiBC.JnwcKdXWyt6l579t7aRo60ZAOSAkaTCl4RyKV1Kd4SjWeSGzmk3MrDwWLpQ9wPW98i12rc4STfQcK2InIrTdCztWfhpRSRDyDVEB60y0dRcGSeFKuTWLoz69fSZ.svvv5inA1ZKnYGQ_ftaGs7_lWKYpktYWJESsOdjPXfKzhwSpTgwJ7FwE.0S.JggCbsCtjsVezKp8mNZ7q1OPGSTyWZzNQo.WkksUkLe6eOL5ZTNiDfCFuOvk.DzfCYECMqj1CPPJJmHXvv.dxPBC6wq0FeZ0c3WfrvSS9fInqMiPV3AnXZGMX6NgvU4HtQE2irt5c9ZlpOUr.ZUK0DJ6j6n2c1IBB.zEkluZ7Gh4vwlHYgwmk_Y3xjUYYGruhvWHI33yrZ2tZjSFcShEWOvc5OacQBCT4_PK5rKcG735Msl2BCz3dejr2w6saHFd9VVURbA9rnHhIZzkhZdy_.R9D9GXhs1o5B0m.NTcHEXsuULBbjSQ1Tboq8zsenFPqviARWPUkBxnPMedGVyGusWHGR9JR3vZTNue7EyqeE8hFRguBbrKKRL18feL2LTvii2t0vK5PmAxx_V70JCaEmDDvIPuyKjcEMpfP2oO7urLx5b.Vxmup2_EY9fCXeUtYmScVTTq.zzDFQbqV1Rm7GD.EfJz2Wl53aCY5xp16_8OsQ_H3jw.VOLC4rgB4BBSORJAS3cXlRWEXCeIC2YWyHPogc.FZJM8Vmxp1MRxvYvbPL9HRvCv4P3kfBSL9DWXrN3zeuW6BJFvTGwF7tsI34TXn4fwU1p_KBd0JF1iwHa9ZeWUApm0BiAmh23ySMRxCzb1RhdbcB5H0XnO5F_lP1Lpmqfr5Kl05FHMOdSOtu4.s5qwZeFLbA9s\",mdrd: \"qpEa.pf81VjK4kwr_JRPprtiyLp7IYR_gwlZS8FeW1Q-1718570611-1.1.1.1-ptvALOdSd.W2Lp1BloAqJjzSoedVpnruVwQUJHIjynnz9olO4KBqKuaS4hmTXVPdA0B6.c1SsmsuNjHW27XVbtq4VBH.SaYhjJQi7XUWk3jBiX.dp_9qZnBhfoblNeuW5_ims0AEfO0y3OPYnefqR0154PS_HhUNF_nv9Y1eIWvMfvNlARvC52nA4w5bDhrfB7pxCc6hzsFKSCP4Vh2V88p87IbDIKs_6eQI0IDB4bkvD3tHd2PtPNAY0e0BR3qPLgVhqkNQo4J0GH9A2avFsq9C9Z1Kl1WLvJ6zqV0FUToXZBT.Sx5cAYH372X5G1QOcbZOLEMkcGfyn01zWcHchvCXacTb5.R5XuaXyhCdECwLnpHmuzTjD2JwCZtRYm8Thljeu9Ww.aNlI3Bo9RHnclzToUbMK77nvpSyddgjLmQLMZ3GJwg_EIiLz9QQjEsoo5vOM.czkFTcj9mPtqJFqW.j4hoR0pP8ZkSzSrX5FmWIcp566tSpYqmqHfQG7ZWzbcmbQWojhg.P7YApPJiEDtVVxr2gFkNUt7U72OhFZnYQ1our3Au3sXKXlTVjOeW1oKv1hw8lhap.Dp0037jtXAeOJy6yaPoLHrYzzHEQ0tLV5QqKsmCwNToVVg9LkIiZ6J5jZ93XAnDR4oYmjYanQj7x0C1C_aLf8IY5hyNOrOMq1UMDbJF.8iMXFkokQnVc.g1hcdzQhZA9CgbdTcrdka2EAW9IrjruXZN3Vx3LA9Sm.WCgUpNSlQQzd3RLDRFcl91vrQg3RysejXh5VQFvgG8R8aQ6qeSMB5SAtYEwZQc7F2fJMeZGfAf1vlBvtW0S1kgKnNSLzPP3DpLFFZ..ziMZSqMLBG0brdDqfEg0RMUc_.yEUhiqiT.P7ZNF49F1tQLn8Sq.haLdqU4Yaow0YWz.R02xlg7Dfq5C_SMzvpUFz6BPBKuiVsMqWnUPdIXMMDWWVFmEuV6Pt1nCdSprFex1brH3ZLjK6vIEPOziLemUCbD.WCAEapeeFVHnJesiviPkqCDQjKirGhwUhFBUdO2YPMfHrV4_.LeH3ZejSBU9q8GF.zIeW8qhlwCi3f9ZlEWvco15hNjLMwvveCdgVRFoWEgCk7TaV2bjLxCBofwWfa_KMhhPgTYrmbZ_H0qq2iRDp_W4P1bPrdBjNy37CSNeHspel9w3nox4Mer_y2lCzRGF7nNfYCF5jSwFU5o3uU9wsT6O7OwjSQg3jnonQfMus7TznfFSgf3y9lzb6O0oZEFOMbLh_eQN3Yim0ooHvKQNfTDIyuo.3WfvyEpD4X38Vb.1JzYZEsHpeLjTadS_PyugFC51lJRKsxL7YxSHuYpfxl_TylZq7LgNsD7m.CgFKlIhLQlKGHzVQQHkh7Ilw5QaMuvdtcpLMqmsYJTseyQ8sPsBg1rNBIbk73STiyELfe3Lh6UC0NYmA_xjlSmJQLaQLesVXSWTy1ctwXYdikA_3ZQMo_rHSN.0tjEArZr55Sxc5blkF8xjEsVjeYY51W9PdFirCwcZmdewFTVWSSL5UKBOK1B2rJmQ1_sd9QWxWsuLq4tBPDY3ILwezXIs5aFNf.71dnNbxUYgxbSJDL_v6LCIsj079e16DjOWN3AawFO5A.e483NDT_KxNYW0ucYxAAindnXU2G5pfXzIinAQpQJRYSDjguRWdIgaOpbWOaV4Ek5s2q9bg_XQaWSr.1PhNtb99WjC7Ap.cW.lt7gnn2otSS5F0NRIbNy8vPFKEjqnwF38SFQOeXu2tGLFdyIMhvtOeEdT9xQFOwJ3SI5KtjvM.D87dCIVpaTfL4Dwzeis1QPuUBmxry73ZUw1nAncc2V7DP5tm0zgnP2I0vzvLSlUpzQhGHH5GSNvb_d1jWVFDmIpKgWxkrsHrphL2SjbaBth8SP0.4MGhMqETdtcCN1BDb9ybXfdgpu.iSKBGMbNfJarGMrk0lDgmXjUs6jTGNX0g4jAhr8rLX0V8rhoYmQ0ubczXpBAZhvMd.M2y.XwWAHpRuBW2kLcihXgWejrNjU5afplUlm7462bSP4dhJ_Gc23940M7j57gTHGinyc._dWkkpFiwf17fKMEgFF81KfM9bGQ2piJbAQRqmXavZyDWEwFBVODnqUi70eFAfG1yAnGMa.lSMX5XoS1qZJ6lv3WuUnzWv2eBSoeAzJhWRwpkD.G1ydRmnC5Bi52ASTV.lmWgNvlQ.f.Qg1xaybd7rxi4Wv2MwNlFZcAg5ELSJj3BMcoSFzO0JsY7DE.nY0BbLyM.ZEvF9tP2qpeal_.vDr7fxAhjsj0cDmUshN6.oDibDjznvNyBPyhXQ\",cRq: {ru: 'aHR0cHM6Ly9ibG9nLnNvZmlhbmUuY2Mvc3NoX2hvbmV5cG90Lw==',ra: 'TW96aWxsYS81LjAgKGNvbXBhdGlibGU7IEdvb2dsZWJvdC8yLjE7ICtodHRwOi8vd3d3Lmdvb2dsZS5jb20vYm90Lmh0bWwp',rm: 'R0VU',d: 'm9oLF4xvT4qZQu0LKnxHpSrLKE6EweMfy7HVNFrEbQpC/o33kIIymiL+3SVUlqgIqZw+snvLSZJrd8QBcAE6y1dnJgUmPxOpezqMXRyzhuKat0N5Xy5XrjH53RzNSRWRdSKnQP5O7ab3A2N2CM6dYv6JgTEvp2whbrN5AGc+zZ5w+ffCTtLCFZJ0PmIeQcC0z+pdY9DgXGgxGyOO3v43TuXu34cm2u8OoQcIH5SIs8mJfnLfEX8Rhran11lHOU8pNl/BqsRFy/HBwFsOlvOqmEUKUkBE5qV0vIP+umYUs+Vb3Y/x3vCHAYjKH2Vtauxfhj/+j10KU1WTeVcM23aWLEGK3tPqQSqvrl1z/o2FxVxKGIawR6VoCs1nLY0vq9aFX/71z8yMLm82sRlgqxmMhPPW7EuDbiT7gyYZG/p0gl5mRiXDeEN5i0wT7nhli2j8xuyEiOiaBa8g0ajLvQAYHRvdVPKtqLSSx5Vkfff6nm66ANrILRUu/ro0Kn13mucl',t: 'MTcxODU3MDYxMS4wMDAwMDA=',cT: Math.floor(Date.now() / 1000),m: '3Z666WkyZdaJIaSrrtlmAKAfVLjMxuDLguN+HqDwmiI=',i1: '+5Dfm3hTh6dEPQJr0nJF2g==',i2: 'rmKssmwFMthSKjth4oTqIg==',zh: 'gtqOVxE8549Fo1J6yGVSmYukoWsFIYuSopkV1QISD7o=',uh: 'idqvltDEaw6z1eUpAaUFY/6rIUCphTJo6GMHGHVnQbg=',hh: 'yp0cZrRqB1dxeoJjXiK86VdyZjQ89Lf/PSFhvC6MpFc=',}};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/g/orchestrate/chl_page/v1?ray=894da1f1db142bd0';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/ssh_honeypot\\/?__cf_chl_rt_tk=05OnpUFzWlt5MN19CdOBoT.fhtLy.tYrAahERcoYZws-1718570611-0.0.1.1-3903\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=40694768",
    "commentBody": "What You Get After Running an SSH Honeypot for 30 Days (sofiane.cc)480 points by SofianeHamlaoui 15 hours agohidepastfavorite320 comments BLKNSLVR 13 hours agoI self-host a (non-critical) mail server and a few other things and occasionally look at live firewall logs, seeing the constant flow of illegitimate traffic hitting random ports all over the place, some hitting legitimate service ports but others just probing basically anything and everything. I decided to setup a series of scripts that detect activity on ports that aren't open (and therefore there's no legitimate reason for the traffic to exist) and block those IP addresses from the service ports since the traffic source isn't to be trusted. Something that came out of analysis of the blocked IP addresses was that I discovered a few untrustworthy /24 networks belonging to a bunch of \"internet security companies\" whose core business seems to depend on flooding the entire IPv4 space with daily scans. Blocking these Internet scanner networks significantly reduced the uninvited activity on my open service ports. And by significantly I mean easily over 50% of unwanted traffic is blocked. Network lists and various scripts to achieve my setup can be found here: https://github.com/UninvitedActivity/UninvitedActivity Internet Scanner lists are here: https://github.com/UninvitedActivity/UninvitedActivity/tree/... Large networks that seem responsible for more than their fair share of uninvited activity are listed here: https://github.com/UninvitedActivity/UninvitedActivity/tree/... I'm semi-aware of the futility of blocking IP addresses and networks. I do believe, however, that it can significantly reduce the load on the next layers of security that require computation for pattern matching etc. Be aware: there are footguns to be found here. reply TacticalCoder 8 hours agoparentOne thing I do is I blocklist entire countries' and regional ISP' CIDR blocks. Believe it or not: straight to firewall DROP. China, North Korea, so many african countries who's only traffic is from scammers, tiny islands in the pacific that are used for nothing but scamming... Straight to DROP. And I do not care about the whining. reply mmsc 5 hours agorootparentHad a travel insurance do this and when I was in hospital in Asia I couldn't start a claim and the hospital nearly kicked me out. I'm sure the sysadmins thought it was a great way to reduce hacking attempts by blocking Asia. reply O5vYtytb 3 hours agorootparentThat's so remarkably stupid for travel insurance, it's unbelievable. reply mmsc 1 hour agorootparentI wrote a cynical take on \"how it happened\" at the time: https://joshua.hu/losing-sight-vision-mission-of-your-role I think it comes from the divorce of what people are hired to do versus what their work actually contributes to. I also remember the countless cloudflare turnstiles that I've had to get through one way or another on airlines' websites which reset every minute (looking at you, airserbia, for being the worst). reply dahart 3 hours agorootparentprevIf there’s one single business that I might expect to honor traffic from foreign countries, it would be the travel industry. I can suddenly envision using a VPN to route through Asia and check a travel agent’s site access before purchasing. reply lopkeny12ko 2 hours agorootparentprevIronic that GP commenter said \"I do not care about the whining\" about regional IP blocks and the first reply is just someone whining about it. reply boredtofears 4 hours agorootparentprevThat’s awful but why is the onus on random sys admins around the world to deal with this correctly and not the government hosting the problem entities? reply AJayWalker 4 hours agorootparentI would say because it’s their job to serve their customers, even if they’re abroad? Especially for a travel insurance company. reply krsdcbl 2 hours agorootparentprevif the government in question is supportive of said problem entities, they won't \"deal\" with it If the government in question has free reign on regulating said traffic, it's an avenue for repressions and censorship Otherwise it's a legal matter to seek action against such entities, which is already how it works (... but I'm afraid we're actually mostly talking about \"scenario 1 entities\" here, which makes it futile to seek action from the very offices that already play a role in making it harder to use existing legal means) reply bobthepanda 2 hours agorootparentAnd it’s not like we will invade countries to stop spam calls, although China is probably the closest to getting to that stage given that the scam centers in Myanmar seem to be a deciding factor in who they throw their support behind: https://www.theguardian.com/world/2024/jan/31/myanmar-hands-... reply kjkjadksj 4 hours agorootparentprevGovernment needs lobbying to act reply belk 4 hours agorootparentprevThat's like asking why don't we expect burglars to not burgle, they won't, but that doesn't mean walling off a whole neighborhood is the solution either. reply grishka 4 hours agorootparentprevAs a Russian, I hate it when people do this. It's extremely annoying when you just click some random interesting-looking link from HN or Reddit or Twitter only to be greeted by a 403 or a connection timeout. Then you turn your VPN on, and magically, it loads just fine. reply __turbobrew__ 3 hours agorootparentFor many services, the expected value of letting people from Russia access their service is negative. The reality is that Russia contributes a large portion of hacking attempts while providing very little to no revenue for the service. At the end of the day it is just business, and sometimes letting countries access your service is bad for the bottom line. reply snapplebobapple 2 hours agorootparentprevYour annoyance is a feature, not a bug. You are supposed to get annoyed enough as a group to lobby your government to fight the internal problem reply grishka 1 hour agorootparentYou're very naive to assume that this government takes any feedback. I'll just leave this thread here: https://twitter.com/IrineKuklina/status/1578339408801304580 reply snapplebobapple 34 minutes agorootparentyou are naive to think whether your government takes feedback is relevant or not (or that I was specifically talking about Russia, That is just one of many countries with shitty internet crime prevention that are routinely blocked and each of those shite countries have varying levels of shite leadership with varying levels of responsiveness). reply type0 8 minutes agorootparentprevoh but it does, you can submit it directly to Roskomnadzor so it can cooperate said hackers and GRU might even hire them directly /s reply nullifidian 1 hour agorootparentprevAh, yes, the remaining English speakers in Russia will overthrow the literal millions of the silovik class whose entire job is to repress (with violence) any independent political activity. There is no \"lobbying\" in Russia, if you didn't know. If you hate all Russians just say you hate all Russians. No need for this \"lobby your government\" euphemistic BS. reply wredcoll 1 hour agorootparentSo political change in russia is literally impossible and everything will be exactly the same 50 years from now? Obviously not. Is such change easy? Again, obviously not, but the only way countries change is their own citizens wanting to make the change. reply grishka 1 hour agorootparentOh we do want to make this change. Desperately. The only minor issue with that is that we lack any means to do so. I'll be sure to do my part as soon as the window of opportunity opens. reply firesteelrain 34 minutes agorootparentSure hope your govt is not monitoring your posts reply sqeaky 1 hour agorootparentprevWe in the west can't change your government to ban hacking requests. We can block whole countries and make a practical reduction in hacks. Sorry that you got caught in the middle and feel you have no options. Maybe someone who does have options and makes their money from non-hacking will be inconvenienced and ask for change instead. reply NicoJuicy 2 hours agorootparentprevHad a reddit clone. The amount of Russian spam coming in was nuts. Blocking the ru language blocked all spam. And since it didn't have Russian users, it was an easy choice to make. reply mistrial9 3 hours agorootparentprevpeople here are not thinking in whole systems-- roads have dual purpose.. there is security AND there is trade .. a world without trade is a poor world.. that includes the intellectual arts, civilian institutions cooperating, common issues like Climate. The voices here that say \"I block everyone, don't bother me with your whining\" .. it is a security practice.. OK. security is not the whole story of civilizations; obstinate thinking leads to ignorance, not evolution. The topic is SSH, an administrative and secured access. Yes security applies. to be on-topic reply grishka 3 hours agorootparentOf course one can obfuscate and secure their own SSH access as much or as little as they want. Run sshd on a different port, require port knocking, ban IPs after failed login attempts, all that kind of stuff. I'm, however, specifically talking about public-facing services like HTTP(S), which also get blocked with this \"I'll just indiscriminately blacklist IPs belonging to countries I don't like\" approach. reply phsau 3 hours agorootparentMalicious traffic is not limited to ssh and comes from the same usual suspects. Automated attacks against web applications is constant. I wouldn't say it's indiscriminate, it's practical. reply nequo 7 hours agorootparentprevI assume you don’t host anything that could be useful to the 1.5 to 2 billion people that you’re blocking. reply luma 7 hours agorootparentOr they host a business site that doesn't do business in those countries and so nothing of value is lost to them. For example, it's literally illegal for me to accept payments from .ru, so why bother wasting their time and my bandwidth? reply ajsnigrutin 6 hours agorootparentI live in EU,and a bunch of american sites just block the whole EU due to GDPR laws. Then someone in US uses my email by accident to subscribe to some newsletter (not the first time, I also get personal emails for that person, since it's just one letter difference, and i'm guessing it's someone old, considering the emails I get), i try to click \"unsubscribe\", and it just redirects me to \" is unavailable in EU, blah blah\" page, without unsubscribing. I make sure to report that site to every goddamn spam list possible. reply rapind 6 hours agorootparentIMO replying unsubscribe should always work for marketing emails and if it doesn’t then I flag the email as spam. Nope, I’m not going to visit that tracked / info gathering unsubscribe link. reply dheera 2 hours agorootparentI only use unsubscribe links from things I voluntarily and willingly subscribed to. If I was involuntarily subscribed to something, or subscribed because of an inconspicuous \"subscribe me\" checkbox that I probably didn't notice, including from a legit business that I purchased an item, it's getting reported as spam in Gmail. reply DEADMINCE 5 hours agorootparentprev> a bunch of american sites just block the whole EU due to GDPR laws. Which is incredibly reasonable. If the EU didn't try to claim EU law applies globally, those sites might still be up. reply arp242 1 minute agorootparent> If the EU didn't try to claim EU law applies globally, those sites might still be up. It doesn't; it applies to EU residents. Your non-EU business is free to do whatever it wants, but as soon as you do business with EU residents EU law applies. This is more or less how it works everywhere (with some exceptions). And deciding not to do business with EU residents (i.e. block in EU) is of course perfectly valid and reasonable choice. But not because \"EU laws apply globally\". robin_reala 5 hours agorootparentprevThe US is just as bad at extraterritorial law, see FATCA for just one example. https://en.wikipedia.org/wiki/Foreign_Account_Tax_Compliance... reply DEADMINCE 5 hours agorootparentThat situation is quite different. The US is using its significant power and weight to coerce those non-US banks into compliance with FACTA. Those banks don't have to comply, but they want to do business with the US and US companies, then they don't have much of a choice. It's not like they just made a law and now insisted it applies globally, which is what the EU did. reply echoangle 5 hours agorootparentIsn’t it actually exactly the same? The website doesn’t have to comply (and many don’t), but if they want to do business in the EU, they have to. How is that different? reply DEADMINCE 4 hours agorootparentNo, it's not remotely the same. The US is using the fact that people want to do business with them to coerce compliance, and as written the law only applies to US persons. The EU claims the GDPR applies globally, regardless of if people want to do business with the EU, or even if people ever set foot in the EU. It's amusing nonsense. reply belk 4 hours agorootparentprevit's effectively the same, small banks just shove you out of the building and refuse to open a bank account for you if FATCA applies to you, their compliance is through just not accepting US tax payers. This is a real issue that leaves US citizens only able to open accounts at bigger banks (with shittier services but enough budget to hire a FATCA compliance department) reply DEADMINCE 4 hours agorootparent> it's effectively the same Nope. Not even close. Practically the GDPR law has no teeth at all because its claim of extraterritorial jurisdiction is nothing but nonsense. FATCA applies because the US has a carrot or stick to enforce it. Also, the US law as written is entirely reasonable and doesn't try to claim the law applies to US citizens anywhere in the world. reply shkkmo 2 hours agorootparent> US law as written is entirely reasonable and doesn't try to claim the law applies to US citizens anywhere in the world. It absolutely does. The USA has laws that govern what it's own citizens do abroad like. You aren't allowed to have sex with minors or pay bribes when abroad. The USA also recently passed a law that allows it to prosecute foreign officials who solicit bribes from USA entities. https://www.ropesgray.com/en/insights/alerts/2023/12/us-cong... reply DEADMINCE 1 hour agorootparent> It absolutely does. Absolutely, absolutely, it does not. The USA law is saying US law applies to US persons wherever they may be in the world. The EU law is saying EU laws applies to ANYONE in the world if an EU person interacts with them via the internet. You realize those two things are not the same, right? reply mratsim 5 hours agorootparentprevWhy is it different? People don't have to comply to GDPR but if they want to serve EU folks then they don't have a choice. reply DEADMINCE 4 hours agorootparentThe EU claims their law applies globally regardless of if people set foot in or do business in the EU. According to the EU, an EU citizen just needs to visit a site and the law applies, regardless of where the site is hosted. According to the EU, the GDPR applies to some small shop owner in China with a website that harvests all data it can that isn't advertising in the EU, courting EU citizens in any way, has no business with the EU, etc. reply throwawaysm 2 hours agorootparentprevhttps://en.wikipedia.org/wiki/CLOUD_Act strikes me an example reply 3836293648 4 hours agorootparentprevWhat? No Claiming jurisdiction by server location is the stupidest thing ever if you trying to have any kind of customer protection laws. You have to go by customer location. However, the claim that they have jurisdiction over EU citizens abroad is very questionable. reply jkaplowitz 2 hours agorootparent> However, the claim that they have jurisdiction over EU citizens abroad is very questionable. The GDPR makes no jurisdictional claims at all based on citizenship, despite a lot of inaccurate summaries saying otherwise. For those cases where the GDPR cares about individuals being EU or non-EU, it only cares about their location, not about their citizenship / nationality or their residence. reply DEADMINCE 4 hours agorootparentprev> Claiming jurisdiction by server location is the stupidest thing ever if you trying to have any kind of customer protection laws. You have to go by customer location. I disagree, because that's impossible. That's why the EU's attempt is largely a joke. Literally - it seems to get mocked a lot when I tried reading up on the credibility and practicality of what they claim. > However, the claim that they have jurisdiction over EU citizens abroad is very questionable. It's the claim that they have jurisdiction over non-EU citizens and businesses in their own countries which is so laughable. reply jkaplowitz 1 hour agorootparent> Literally - it seems to get mocked a lot when I tried reading up on the credibility and practicality of what they claim. [...] > It's the claim that they have jurisdiction over non-EU citizens and businesses in their own countries which is so laughable. Most of this mockery is based on misunderstandings that overgeneralize what the EU is asserting and overlook what most other countries assert. Most countries have some laws that under some circumstances purport to apply to foreign non-citizens located outside the country, not just the EU. A key example is defamation law. If you are a Brazilian citizen located in Brazil and you specifically target publications online to UK or Canadian or US audiences in ways that are viewed as defamatory in those jurisdictions, you could very well get sued in those countries' courts, and there are absolutely cases where those courts would uphold their jurisdiction based on the specifically targeted publication. Similarly, when asked to decide if they have jurisdiction to enforce local consumer protection law against a foreign defendant, the courts in the Canadian province of Quebec will consider whether the foreign defendant has tried to target Quebec consumers, should know that it has ongoing substantial sales to Quebec consumers, et cetera - not only whether it has a business establishment in Quebec. Conversely, if you are a hotel in New Hampshire, USA and someone located in an EU country visits your US-based English-language USD-only hotel website and books a room for their upcoming visit, the GDPR probably does not apply, since there is no attempt to target the EU. Among other exceptions, the conclusion could be different if the hotel website allows bookings in EU currencies or languages (not counting English and maybe not US/Latin American Spanish because of their use in the US), since that shows an intention to target EU visitors. If merely being foreign allowed EU-focused businesses to avoid the GDPR, that would be an extremely huge loophole, and EU businesses would make deals with those foreign businesses to shift as much as possible of their data processing stream outside the scope of the GDPR. It would pretty much swallow the whole law. It's not a viable approach. Similarly, monitoring the behavior of visitors in the EU can also lead to the GDPR applying, since otherwise EU businesses would pay foreign businesses to track their visitors on their behalf, doing whatever legal ownership transfer shenanigans they have to in order to make that work. (\"Oh no, this is not a European-owned website, it's an American website to which we've licensed our brand content and which shares 99% of its subscription and ad revenue with us as their license fee... they are allowed to track you even if we can't...\") Of course, you're quite right if you view it as a mockable idea that the EU would be going into foreign countries to bust down doors and collect fines from foreign businesses. Just as clearly, they aren't pretending they can do that. But if a foreign company does get assessed with a GDPR violation fine in the EU, it certainly gets harder for them to continue to engage in business dealings with anyone in the EU without that fine becoming more possible to collect - and in some cases there are established mutual legal assistance treaties through which EU countries can get foreign countries to help with collecting a judgment outside of the EU. My guess as to why these non-EU companies prefer to block the EU instead of comply with the GDPR is simply that they don't view the risks of being found in violation as worth the benefits of the additional audience - not because they would necessarily be found in violation. Most of the local news channels would probably not be found in violation if they excluded visitors in the EU from behavior monitoring, but many of those sites don't consider it worthwhile even to take the risk. reply DEADMINCE 13 minutes agorootparent> Most of this mockery is based on misunderstandings that overgeneralize what the EU is asserting and overlook what most other countries assert. I think that mostly assumption. Much of the mockery was in legal journals for example - an audience that would be more familiar with the ext of the legislation than most. > Most countries have some laws that under some circumstances purport to apply to foreign non-citizens located outside the country, not just the EU. Maybe a few other countries have something in the same general category, but none as far reaching as GDPR law tries to be. And certainly it's a minority of countries that have such laws, not most. > A key example is defamation law. If you are a Brazilian citizen located in Brazil and you specifically target publications online to UK or Canadian or US audiences in ways that are viewed as defamatory in those jurisdictions, you could very well get sued in those countries' courts, and there are absolutely cases where those courts would uphold their jurisdiction based on the specifically targeted publication. I'm not exactly clear what you are saying here, but in any event, at least in any interpretation I can think of, the analogy doesn't map. If a UK entity sues a Brazilian in a Brazilian court, that's all pretty normal. That's just the UK entity doing something they are able to do in compatible courts, that's not UK law applying to Brazilians. > Similarly, when asked to decide if they have jurisdiction to enforce local consumer protection law against a foreign defendant, the courts in the Canadian province of Quebec will consider whether the foreign defendant has tried to target Quebec consumers, should know that it has ongoing substantial sales to Quebec consumers, et cetera - not only whether it has a business establishment in Quebec. And how is this relevant? That foreign defendant would be present in Quebec to be tried, so it's quite a bit different from the EU claiming Joe Schmoe halfway around the world who has no interest in the EU or Europe and has never been there, is subject to EU law because an EU citizen visited their data collecting site. > Conversely, if you are a hotel in New Hampshire, USA and someone located in an EU country visits your US-based English-language USD-only hotel website and books a room for their upcoming visit, the GDPR probably does not apply, since there is no attempt to target the EU. The attempt to target the EU would be simply be having online advertising that would show up in the EU. > Among other exceptions, the conclusion could be different if the hotel website allows bookings in EU currencies or languages (not counting English and maybe not US/Latin American Spanish because of their use in the US), since that shows an intention to target EU visitors. I don't think this is the actual text of the law. The EU claims GDPR applies to a small data collecting site, say, in Vietnam, that wants to store and retain and sell all the data it can about anyone that visits its site. That's what is ridiculous, that's what is incomparable to anything else you have listed. But in any event, let's say that is the law. Let's say this site in my Vietnamese example goes out of it's way to target the EU, having French and Spanish as default languages, having language flags for every EU country, and paying for advertisements (but only on US sites with US companies, lets say, just to reinforce the point that no business has been done in the EU) - well, in that case, it's still bonkers that the EU thinks they have any jurisdiction over the operator of that site. The ONLY thing they can do is firewall it off, like China does. That's it. Claiming to have global jurisdiction as they do just makes them look foolish. > If merely being foreign allowed EU-focused businesses to avoid the GDPR, that would be an extremely huge loophole, This is already reality, though. Any business in the world can court EU consumers, and only the EU can prevent that by further policing its citizens. They are powerless to stop foreign businesses any other way since they only have jurisdiction in their own borders...yet they claim the opposite. > Of course, you're quite right if you view it as a mockable idea that the EU would be going into foreign countries to bust down doors and collect fines from foreign businesses. Just as clearly, they aren't pretending they can do that. It's mockable that they claim they have any jurisdiction outside their borders in the contexts they do, period. > But if a foreign company does get assessed with a GDPR violation fine in the EU, it certainly gets harder for them to continue to engage in business dealings with anyone in the EU without that fine more becoming possible to collect - and in some cases there are established mutual legal assistance treaties through which EU countries can get foreign countries to help with collecting a judgment outside of the EU. There is absolutely no instance of a foreign court upholding a GDPR fine and I don't expect there ever will be, nor is there any treaty that would allow for that as far as I know. If you know otherwise and could name such a treaty I would appreciate it. The only thing the EU can do is get a judgement against that person or company and arrest people if they enter the EU, firewall off hosts, or police and punish its own citizens. DEADMINCE 5 hours agorootparentprevThat's very computationally inefficient. reply TacticalCoder 15 minutes agorootparent> That's very computationally inefficient. It's O(1) with iptables/nftables ipsets. Moreover as I blocklist entire CIDR blocks, there aren't that many entries in those ipsets. reply aforwardslash 4 hours agorootparentprevYou can trivially maintain a list of the size of the whole ipv4 space by using bitmaps reply ransom1538 6 hours agorootparentprevnext [2 more] [flagged] nativeit 4 hours agorootparentJust the best. reply ajsnigrutin 6 hours agorootparentprevPersonal page.. sure. Business? You're a pain to many people and don't care. I live in EU and many US pages just block the whole EU due to GDPR laws... then someone (by mistake) subscribes me to their newsletter, and the \"unsubscribe\" links leads to \"this page is unavalable in EU\"? I'll goddamn make sure your domain ends up on every goddamn possible antispam filter I can find. reply jkaplowitz 1 hour agorootparentThat's often worth an FTC complaint for a CAN-SPAM Act violation: https://www.ftc.gov/business-guidance/resources/can-spam-act... The FTC wouldn't accept \"we didn't want to deal with GDPR\" as an excuse for a business violating that law. reply cdelsolar 6 hours agorootparentprevWhy? Are they spam pages? reply DEADMINCE 5 hours agorootparentprev> I'll goddamn make sure your domain ends up on every goddamn possible antispam filter I can find. Honestly, individuals can't really do much to change the reputation of a domain. Maybe petition your representative to adjust the GDPR so they don't claim it applies globally? reply tiahura 7 hours agorootparentprevThe Biden administration needs to explain why they allow ISPs to import data from these countries. reply hahajk 6 hours agorootparentI'm not sure I understand what you're suggesting. Are you saying that the US govt should make it illegal for people in its borders to communicate with people in those countries? reply tomxor 5 hours agoparentprev> and block those IP addresses from the service ports since the traffic source isn't to be trusted Don't get me wrong, I want to do the same, I run a lot of servers and see all the automated nonsense aimed at public servers. However, you should consider the fact that today blocking an IP is akin to blocking a street, a village or sometimes even a town. For ~better or~ worse we now live in the age of CGNAT. If your threat model and use case means you only care about a known subset of users with static IPs who are lucky enough to not share IPs then fair enough; but if you are running services intended for wide spread consumption you are likely blocking legitimate users without even knowing it. reply nilsherzig 10 hours agoparentprevTry running some of your blocked ips through greynoise, they usually have some interesting information about them reply BLKNSLVR 9 hours agorootparentThanks for the tip. Looks like greynoise use ipinfo.io for IP metadata. I use https://www.abuseipdb.com/ for any manual IP address checks, and https://hackertarget.com/as-ip-lookup/ for finding what ASN an IP address (range) is a member of. I'll check out greynoise and see what extra info may be provided. reply Bengalilol 1 hour agoparentprevI was about to say out loud that it was a (kind of) relief not finding Google in your lists, then I found https://github.com/UninvitedActivity/UninvitedActivity/blob/... reply shaky-carrousel 9 hours agoparentprevGood idea. What I do is, I disallowed password login in my ssh server, and I permanently ban whichever address that tries to log in using a password. reply BLKNSLVR 9 hours agorootparentI use a bastion host on a VPS as the only source IP address allowed to ssh into my systems, so any attempts to connect to ssh (from any IP address other than the bastion) are both blocked and logged into \"the list\" to be blocked from connecting to any other service ports. reply pgraf 13 hours agoparentprevJust be aware that with your strategy “blocking 50% of unwanted traffic” means blocking non-attack traffic, as these Internet security companies are mostly legitimate. The automated attack traffic that you actually want to block is in the other half and will frequently change IPs. reply BLKNSLVR 12 hours agorootparent> these Internet security companies are mostly legitimate This is both subjective and highly dependent upon the scope of services being run. My setup would probably progressively create more hassle than it saves as on a scale from small business to large business. For the setup I have, I quite specifically want to block their traffic. I'm possibly overly militant about this, but they keep databases of the results of their scans, and their business is selling this information to ... whoever's buying. I don't want my IP addresses, open ports, services or any other details they're able to gather to be in these databases over which I have no control and didn't authorise. To steal an oft-used analogy, they're taking snapshots of all the houses on all the streets and identifying the doors, windows, gates, and having a peek inside, and recording all the results in a database. I believe all of them are illegitimate. They 'do' because they can, and it's profitable. \"Making the internet safer\" is not their raison d'être. Happy for any else to form their own opinion, but this is my current stance. reply appstorelottery 11 hours agorootparentWould be cool to have a \"don't scan me bro\" list of IP's that engage in this that we could share - is there such a thing? reply BLKNSLVR 10 hours agorootparentThe problem is that becomes a concentrator of IPs behind which privacy conscious individuals exist, which probably has higher value to \"whoever's buying\". It's a conundrum. reply yesbabyyes 9 hours agorootparentIt sounds like what GP is suggesting is to collect ips of all the scanners, and share the list of ips among ourselves, so we can collectively route their traffic to /dev/null. reply kjkjadksj 4 hours agorootparentWhy not also sell the scans of scanners to the scanners customers and make a little pocket change? reply BLKNSLVR 9 hours agorootparentprevaaaaah, that makes sense. See the links in my original post. reply zbentley 7 hours agorootparentprevThere's a comment downthread discussing something similar; I haven't tried it though: https://news.ycombinator.com/item?id=40695179 reply dataflow 10 hours agorootparentprevYou're being sarcastic, right? We did this for telephone numbers and saw how it turned out... reply nubinetwork 11 hours agorootparentprev> these Internet security companies are mostly legitimate Act like a bot, get treated like a bot. > Just be aware that with your strategy “blocking 50% of unwanted traffic” means blocking non-attack traffic You don't block them forever, just enough for them to move on to someone else. reply slt2021 4 hours agorootparentthey dont move on to someone else, they scan entire internet on a regular basis, just like gogle crawls web pages reply wl 7 hours agorootparentprevMy experience is that after blocking Censys, unwanted traffic on non-standard ports from other IP blocks has basically gone to zero. It appears to me that some bad actors are using Censys scans for targeting. reply rolph 5 hours agorootparenti get similar results reply chipdart 10 hours agorootparentprev> (...) as these Internet security companies are mostly legitimate. Note that you're basing your assertion on the motivation of random third parties exclusively on the fact that they exist and they are behind active searches for vulnerabilities. reply moffkalast 11 hours agorootparentprevLol legitimate. As legitimate as door to door salesmen. OP just put up a proverbial \"no soliciting\" sign. reply k8sToGo 13 hours agoparentprevHave you considered using crowdsec? reply BLKNSLVR 13 hours agorootparentI set it up in a fairly superficial way, and there are only a handful (two or three) rules that can be applied on the free tier, and I'm a tight-ass. It's still running, but it doesn't seem to block much - but that might be because I didn't put enough time into \"doing it properly\". reply teruakohatu 10 hours agorootparentprevAre there any downsides to crowdsec? reply snorremd 9 hours agorootparentYou end up sharing signals (IPs) to their crowd-sourced bad IP databases, but only get 3 free IP lists on the free plan. To get some of the bigger IP lists you need an enterprise plan at $2500 a month. Essentially they use the free customers to build the lists that drive their enterprise sales, which is fair enough as you get to use their free dashboard and open source software. But to me it seems they're really only targeting enterprise customers as a business. reply cranberryturkey 12 hours agoparentprevJust install fail2ban. reply WhackyIdeas 10 hours agorootparentFor SSH, changing to a random port number resulted in zero connection attempts from bots for months on end. It seems bots just never bother scanning the full 65535 port range. reply dizhn 10 hours agorootparentFor most of my VMs there's no ssh running. I use wireguard to connect to a private IP. I haven't done this on the bare metal yet but I might. Though barring exploits like we had recently nobody is getting into a server with either strong passwords or certificates. Fail2ban in my eyes is a log cleaner. It's not useful for much else. reply cranberryturkey 8 hours agorootparentit bans the bad ips, isn't that worth running? reply thfuran 3 hours agorootparentBut what does that actually accomplish? reply speleding 7 hours agorootparentprevA server with fail2ban can be DOSed by sending traffic with spoofed IP addresses, making it unavailable to the spoofed IP addresses (which could be your IP, or the IP of legitimate users). That is typically a bigger problem than polluting your logs with failed login attempts. reply CreatedAccount 7 hours agorootparentWhat would spoofing the IP of a packet when the underlying protocol requires a two-way handshake accomplish? reply ajsnigrutin 6 hours agorootparentWith CGNAT, a prepaid sim card and some effort, you can make them block a whole legit ISP in a few days without spoofing anything. reply hypeatei 5 hours agorootparentprevfail2ban is another layer which is susceptible to abuse and vulnerabilities. It might keep noise out of your logs but at a huge cost. I'd rather just change the SSH port to something non-standard and write it down. reply gnuser 2 hours agorootparentAdd it port knocking and this is how I do it. nftables ftw reply noduerme 13 hours agoprevGood grief. A couple days ago I re-enabled password logins on a server that normally only accepts private keys, just to check something from a third location, and then forgot to turn it off. Two days later the server's logs were full of thousands of failed login attempts that started a few hours after I enabled passwords and then ramped up to dozens per minute. Just because it didn't instantly say \"Goodbye\". I checked ip locations on the biggest offensing addresses; all were in China. I don't know what to call the idiocy and amorality that leads people to scan port 22 for a living (or the stupidity that leads them to guess random passwords for random usernames that don't exist), but I suppose that for every gardener there are a billion ants. reply p_l 10 hours agoparentThere's a cottage industry of shitty mass-scanning attacks that continue onto getting root on badly setup fresh installs of various linux distros and drop a rootkit on them. Some other common targets are websites to be reused for spam (hello, Wordpress!) or to hijack things like gitlab (again to drop a rootkit. The rootkits are then usually used either for DDoS extortion rackets (usually against game servers, including online gambling), spam (might be less big today than it used to be), and cryptocurrency mining (from my experience mainly monero). One time it happened in a network I set up due to miscommunication and misunderstanding of how vendor's install scripts worked (by vendor technicians!). During investigation, we found out that this particular \"kit\" was sold cheaply on a chinese forum (used to be russian forums back in the day, eh), as complete package to run on Windows to attack linux hosts for DDoS botnet purposes. reply mmcnl 4 hours agoparentprevI have SSH access to my server behind a VPN. Not opening port 22 makes life a lot easier. reply beastman82 7 hours agoparentprevThe name for it is \"authoritarian government\" reply simonmysun 9 hours agoprevCoincidently, I recently visualized the scanners for fun by plotting them on a globe[1]. It gives a more comprehensive view of the locations and ASNs of the scanners. The demo data is generated from 1 day of logs. [1]: https://github.com/simonmysun/where-are-the-scanners Amazingly there's no request from same ASN. I believe this is because the VPS provider has a quite strict validation process, e.g. you have to upload a photo of yourself with your ID and your handwritten username, etc. I would suggest we consider the reputation or credibility of the data centers so that the data centers have the motivation of banning such users. In my case, a lot of the requests were sent from Tencent or Alibaba data centers. reply jsiepkes 10 hours agoprevIf you have only public key authentication enabled with SSH I honestly don't understand why people bother with things like fail2ban. It just adds more moving parts with very little security gain. The real risk is a zero-day in OpenSSH and fail2ban probably isn't going to protect you from that. In that case you are better served by putting another layer of defense in front of SSH like a VPN. reply BrandoElFollito 9 hours agoparentfail2ban is the kind of pseudo-security applied just because someone's cousin mentioned that in his blog. It provides zero security. If your endpoint uses default usernames you will be shot anyway because of IP spread. If your security is good you add something that will block your legitimate connection when you are in the middle of nowhere and, shit, cannot access your . reply d-z-m 8 hours agorootparent\"security\" is a term that has to be defined in relation to a threat model. If your threat model is an attacker with a static IP hammering your server, fail2ban does provide some security against that sort of attacker. reply BrandoElFollito 5 hours agorootparentNo it does not. If the packet is at your door it is too late already. Then either it does not matter in which case you do nothing, or it matters (DoS) and then you have other problems. You are right that security works in the context of a threat model. There are however useless tools that give a false sense of \"security\" that do not fit in any reasonable model. I have cases where I block whole ranges of IPs for \"legal\" reasons - it does not make sense but there you are, the ones who write the rules are not the ones who actually know the stuff. reply SahAssar 3 hours agorootparentprevIf your server is on the internet with a public ssh server then it is probably providing some sort of internet service. That internet service is almost always easier to DoS than your openSSH server. If you are not providing a internet service then why is your SSH open to the internet? reply jszymborski 29 minutes agorootparentMaybe the service is provided over SSH via e.g. port-forwarding (or is simply \"SSH access to a server\"). reply kloop 1 hour agorootparentprev> If you are not providing a internet service then why is your SSH open to the internet? So that I can ssh into it from various places and do stuff on my home server from elsewhere reply SahAssar 1 hour agorootparentSo you are accessing that server's services from some network, why are you not only allowing SSH over that network? Or, if your service is open to the internet then why does not what I said above hold true? reply eikenberry 1 hour agorootparentprevI always read the main use case had nothing to do with security, but was to reduce log spam. reply ars 10 minutes agorootparentprevfail2ban increases your server performance. It cuts down on enormous amounts of logging from failed attempts, and reduces the CPU used to deal with the failures. Some sites get a mind boggling amount of attempts. For example I sysadmin some Jewish sites, and they get exponentially more hacking attempts than the sites not mainly used by Jews. (This was before the current war mind you, I'm sure it's worse now.) reply mmsc 5 hours agorootparentprevPeople don't believe it's possible for software to be secure, and need a secondary defense to \"protect them\". reply catalypso 56 minutes agorootparent> People don't believe it's possible for software to be secure Rightfully so. You'd statistically be almost always right considering a software unsecure given enough time (for the vulnerabilities to be introduced then found). > need a secondary defense to \"protect them\" Nothing wrong with that. It's called Defense in Depth and is rather advised. Once you understand that security measures are not bulletproof, stacking them proves to be an easy way to increase protection. The case of fail2ban is not trivial: reducing log noise is a great perk, and can indirectly help with monitoring (you'd more easily notice suspicious behaviour if it's the only thing on your logs), but it comes at the small cost of setting it up, and accepting the risk of having a shared IP unwillingly blocked. reply marcosdumay 23 minutes agorootparentprevExcept that it explicitly doesn't protect against security bugs. reply zbentley 8 hours agorootparentprevYou're not wrong, but I'd say fail2ban still has value for junior operators seeking to reduce load and increase stability. If you don't know how to harden SSH, fail2ban is offers a much friendlier way to reduce the volume of logspam, CPU burn, and network traffic. It's just a pity that it's understood/documented/pitched as something that substantially increases security. reply BrandoElFollito 5 hours agorootparent> If you don't know how to harden SSH then you do not open it to Internet. Otherwise you patch aggressively, you use ssh keys and not passwords and you move it to some random port to hide it a bit (it actually helps) > logspam you can filter this out in your log management tool > CPU burn if this is your concern, then you have a hep of issues you need to address. I have never seen a CPU perf hit because of such behaviour (there are cases where it happens, butthis is due to a vulnerability of the service) > network traffic the packet is here already, there is nothing to reduce reply Karunamon 4 hours agorootparentMoving ssh off of port 22 makes it a pain in the ass to work with. Ports are standardized for a reason. Authentication attempts are a useful security signal; I don't want to filter them out. I want hosts running dictionary attacks to not be able to connect to my services in the first place. If you are running an SSH bot, then I don't want you on my website or anything else. reply BrandoElFollito 4 hours agorootparent> Moving ssh off of port 22 makes it a pain in the ass to work with. Ports are standardized for a reason. yes, they were standardized in the ol' good times :) If you have a limited amount of people/services connecting then it is manageable. But of course YMMV. > Authentication attempts are a useful security signal; I don't want to filter them out. I want hosts running dictionary attacks to not be able to connect to my services in the first place. If you are running an SSH bot, then I don't want you on my website or anything else. enumeration and brute force on SSH fail by design when using keys. As for other services I do not see how this helps - you will block random IPs hoping that a vulnerable site is not taken over if they happen to get back. It is not common (at least in my monitoring of several honeypots in various locations) to have the same IP being particularly visible. Sure they are back sometimes but this is quite exceptional. Anyway - it is not worth the hassle, better have proper hardening. reply throwitaway1123 3 hours agorootparent> yes, they were standardized in the ol' good times :) If you have a limited amount of people/services connecting then it is manageable. But of course YMMV. Agreed. I've never found it difficult to manage this. I already tend to configure SSH hosts in my ~/.ssh/config file anyway so that I don't have to remember every IP and port combination for every host I have access to when I want to use SSH (or something that relies on the SSH protocol like rsync or scp). reply mekster 9 hours agoparentprevRepetitive log is something you appreciate by reducing and you don't have to give it unnecessary CPU cycles too. reply jcynix 9 hours agoparentprevFully agree. Limiting the networks which can access your server will help, e.g. limit access to just your local provider or your workplace and you'll see no attempts from Brazil, China, ... unless you are located there, of course ;-) reply ajsnigrutin 6 hours agorootparentIt's all fun and games, until you travel outside of your country, and try to access stuff at home. reply jcynix 6 hours agorootparentThat's manageable with a bit of preparation: when I'm travelling, I allow access from other networks, e.g. those from phone providers. Or add a web form where I activate the IP address with a cryptographically signed \"token\" which the server can verify and then add the IP address to the set of allowed ones. Used one or the other every now and then in the last 10+ years and still have my attackable footprint small the rest of the time. reply Too 8 hours agoparentprevHow do you protect your vpn? reply d-z-m 8 hours agorootparentuse a vpn that does not advertise its presence, like wireguard. reply josephcsible 1 hour agoprev> 1016 cd ~; chattr -ia .ssh; lockr -ia .ssh Does anyone know what the \"lockr\" command is? I can't find any references to it besides people saying they observed malware trying to run it, usually (as is the case here) right after a chattr command with the same arguments. reply ars 6 minutes agoparenthttps://blog.netlab.360.com/icnanker-trojan-downloader-shc-e... has: cp -f /usr/bin/chattr /usr/bin/lockr reply Kikawala 1 hour agoparentprevhttps://www.lockr.io/ reply josephcsible 1 hour agorootparentI think that's something totally unrelated that just happens to have the same name. I don't see anything in their docs that even hints at a UNIX command called \"lockr\", let alone one that makes sense to call like that. reply mianos 9 hours agoprevOver 90% of the ssh logins come from just a few China Telecom addresses. They just keep trying random ssh accounts over and over all day. I just geoblock China now. Maybe occasionally unblock it for a few minutes if the kids want to buy something from Shien. Then I honeypot the rest with the continuous ssh banner script. reply m0rde 4 hours agoparentWhat's a continuous ssh banner script? reply throwitaway1123 3 hours agorootparentIt's a tarpit that slowly sends a message to bots to keep them (and their bandwidth, memory, and CPUs) occupied: https://github.com/skeeto/endlessh?tab=readme-ov-file reply kristopolous 14 hours agoprevin the early 2000s I kept an anonymous ftp server open and would routinely get the latest cracked software delivered right to my hard drive. It was very convenient. reply sattoshi 14 hours agoparentCracked software can contain extra features. Especially when delivered in this way. reply seanthemon 13 hours agorootparentOoo like that awesome techno music on startup, or maybe bee movie during install reply Etheryte 12 hours agorootparentI like the idea that someone embedded an entire movie as a malicious payload in an installer. reply input_sh 7 hours agorootparentprevIn the early 2000s it was pretty much expected that each and every computer you encounter is full of viruses. That is, viruses on top of viruses that come by default from everyone running a cracked version of Windows XP. reply welder 5 hours agorootparentMost people on here didn't use Windows in the early 2000s, or ever. reply lofaszvanitt 9 hours agoparentprevOh, when you needed specific ftp clients, because most of them couldn't handle special characters needed to access the directory containing the LOOT :D. reply cranberryturkey 8 hours agorootparentserv-u and cuteftp baby! reply throw_m239339 8 hours agoparentprev\"H2O, try before you buy...\" reply JZL003 1 hour agoprevHow do people feel about using docker as a way of avoiding 0 day vulnerability It's all for personal use and maybe I'm just cosplaying as a sysadmin but I have apache proxy-pass ing to sets of docker containers. So as long as apache and ssh are kept up to date (on nixos), even if all my services are 0 day'd, they have to also escape the docker containment reply danielovichdk 14 hours agoprevI am not sure why this should keep anyone from hosting their own servers and services. I find it positive to know that whatever and whomever expose anything on the Internet someone will try to exploit it. For 443 and 80, why the concern ? Outsiders can try all they want bit if you are certain the software you use is secure, there will be no cigar. I'd much rather have these things out in the open than hiding things away with some obscure thought about that should help anything. If something is difficult do more of it. The same goes for understanding security. reply dotancohen 12 hours agoparent> if you are certain the software you use is secure This is the problem right here. You can be certain that the software you use has security issues. reply lofaszvanitt 9 hours agorootparentAnd who will fire a 10k+ exploit on your server? So you could record it and resell? In the early days, surfing shady sites with Internet Explorer, you could net a lot of interesting js that exploited the browser. reply dotancohen 4 hours agorootparentMy server is an attack vector for my 10k+ users, and all their contacts. A 1% ransomware infection rate could net them $1 million USD worst case, and potentially an order of magnitude more if one of my users is browsing from a work machine in their network. Don't underestimate the security value of people hitting your servers, even if all you think you're serving is emojis. reply lofaszvanitt 3 hours agorootparentI'm not underestimating. All I'm saying if someone pays 10k or more for an exploit against ssh/nginx/whatever, nobody is gonna pepper your server with it. They will sell it to a broker and pocket the money, end of story. You will be targeted if your server seems to be the lowest hanging fruit or most easily exploitable or the target is most easily reachable through your site. Otherwise noone will bother with your setup. reply input_sh 7 hours agorootparentprevThe question isn't does the software I run have some sort of yet-undetected security issues, but am I a valuable enough of a target for someone to waste their yet-undetected exploits specifically targeting me? If the answer's no, then your only job is to keep up with software updates. reply lazide 6 hours agorootparentIf you’re exposing your software to the external internet, you’re potentially valuable enough to get a drive by. reply input_sh 5 hours agorootparentAssuming your software is fairly up to date and/or you haven't badly misconfigured it, they're not gonna do anything. There are a ton of routers and IoT devices that are a much easier catch than a machine run by someone that actually gave a thought or two about securing their server. reply danielovichdk 10 hours agorootparentprevSure. And so what ? Should I stop using it ? reply tjoff 13 hours agoparentprev> if you are certain the software you use is secure The entirety of the problem is that you can't be certain the software you use is secure. reply danielovichdk 13 hours agorootparentExactly. And to overcome this you as a user of that software has to be aware of that specific software. Most people doesn't give a shit, they pull down or introduce dependencies and think \"wauw that was easy and fast\". Of course there is secure software, otherwise we wouldn't be able to live as we do. reply lazide 6 hours agorootparentAs history has shown repeatedly, there is no secure software - just software that folks have not yet discovered how to exploit widely and effectively yet. reply oopsallmagic 3 hours agorootparentThen why bother? I'm sorry, but where did this meek, defeatist attitude come from? It pervades software now. Sure, you're right, I guess I could get hit by a bus today, but that won't stop me from crossing the street, because there are a lot of things I can do to minimize my risk, like looking both ways, listening, and crossing at a signal. Software is similar. \"Nothing means anything, all is chaos\" might poll well on Reddit, but it's not good engineering. reply kloop 1 hour agorootparent> Then why bother? Because software is fun, and I get to work with cool things. There is a joy in programming in and of itself. I guess your question doesn't make sense to me. Just because it will eventually be broken, does that automatically mean there's no value in software? I don't think that's true, it just probably means you should have an analog backup process if possible, especially for critical things like government services. reply lazide 1 hour agorootparentprevWho says it’s defeatist? It’s realism. You might as well say noting mild steel only has a 60-80kpsi yield strength ‘defeatist’. That attitude allows practical risk management and effective engineering. Pretending software can be secure or mild steel has infinite yield strength cannot. There is no lock that can’t be picked either, which is why no one leaves millions in cash protected just by a lock without guards and a surveillance system. And why they insure large amounts of cash. At this point it should be pretty obvious - don’t put important secrets on computers without a way to expire/revoke them. If it’s a secret that can’t be expired/revoked, think long and hard about if you need it on a computer - and if you do, use a SCIF. Monitor any connected computer systems for compromise. Use encryption extensively, preferably with hardware protection, because software is insecure, etc. Same with controlling dangerous equipment - don’t rely on pure software or someone will get killed. Use hardware interlocks. Use multiple systems with cross checking. Don’t connect it to the internet. Etc. This is all industry best practice for decades now. reply hollerith 6 hours agorootparentprevThat gives the misleading impression that it is impossible to create and maintain a truly secure software system. reply kjkjadksj 4 hours agorootparentIs that impression not accurate? Everything is possible to exploit imo. Its why the us government spends a mountain on cyber defense and offense. reply oopsallmagic 3 hours agorootparentBetter pack it in then, y'all, we're done writing software. If it can't be absolutely 100% perfect all the time, then why even bother? reply lazide 6 hours agorootparentprevI have yet to find any such system - given enough time and exposure. What makes you think such a thing is possible? In reality, not theoretically. I also have yet to find an unpickable lock, given the same constraint. Locks still have utility. But only fools protect something very valuable with just a lock. reply hollerith 6 hours agorootparent>What makes you think such a thing is possible? The main source of my confidence is extrapolation from the results of successful initiatives to improve security. Rust is one such initiative: at relatively low cost, it drastically improves the security of \"systems software\" (defined for our purposes as software in which the programmer needs more control over resources such as compute time and latency than is possible using automatic memory management). Another data point is how much Google managed to improve the security of desktop Linux with ChromeOS. There's also the fact that even though Russia has enough money to employ many crackers, Starlink's web site continued operating as usual after Musk angered Russia by giving Starlink terminals to Ukraine -- and how little damage Russia has managed to do to Ukraine's computing infrastructure. (It is not credible to think that Russia has the ability to inflict devastating damage via cracking, but is reserving the capability for a more serious crisis: Russia considers the Ukrainian war to be extremely serious.) Sufficiently well-funded organizations with sufficiently competent security experts can create and maintain a software-based system that is central to the organization's process for delivering on the organization's mission such that not even well-funded expert adversaries can use vulnerabilities in that system to prevent the organization from delivering on its mission. reply lazide 6 hours agorootparent‘Secure’ == unable to be compromised. You seem to be saying ‘secure’ == ‘compromises are able to be fixed’. Which doesn’t fit any definition of secure I’m aware of. Every one of those things you mention has been compromised, and then fixed, at various times. Depending on specific definitions of course. And that is what we see publicly. Typically figure on an order of magnitude more ‘stealth’ compromises. For a compromise to be fixed, someone has to notice it. Exposing machines to the Internet increases attack surface dramatically. Allowing machines to talk to the Internet unmonitored and unrestricted increases their value to attackers dramatically. Without careful monitoring, many of the resulting compromises will go undetected. And hence unfixed. [https://www.cvedetails.com/vulnerability-list/vendor_id-1902...] [https://www.cvedetails.com/product/47/Linux-Linux-Kernel.htm...] [https://purplesec.us/security-insights/space-x-starlink-dish...] [https://www.pcmag.com/news/account-hacking-over-starlink-spa...] reply hollerith 6 hours agorootparentYou made a universal statement, namely, \"there is no secure software\". If you had written, \"99% of software used in anger is insecure,\" or, \"most leaders of most organizations don't realize how insecure the software is that their organizations depend on,\" or, \"most exploits go undetected\", I would not have objected. reply lazide 1 hour agorootparentThat is quite explicitly not what I wrote. You might want to re-read my comment. My point not only stands, but is reinforced by your comments. If software is eventually compromised, it was not secure. I have yet to see any software that does not eventually get compromised when it gets enough exposure. That those compromises can get fixed after the fact doesn’t change that. And ignoring the explicit cases where your examples were disproven doesn’t help your case either. reply hollerith 22 minutes agorootparentI find it obnoxious to correspond with you. quaintdev 13 hours agorootparentprevCommon the web servers like Nginx, Caddy are not secure? If they found a zero day in these application whole Internet will go up in flames. reply robertlagrant 12 hours agorootparentThe whole internet keeps patching those flaws as they are found. The problem with self-hosting is patching. reply wruza 11 hours agorootparentThis is a non-problem since the invention of unattended updates. This whole subthread spreads uncertainty and doubt over simple things like nginx or ssh. Service providers don’t patch their software by hand either. 20 years ago, when I was still young and naive, I took these concerns way too serious, remapped ports, believed in pwn, set up fail2ban and knocking, rotated logs. Later I realized it was all just FUD, even back then. You run on 22, 80 and 443 like a chad, use pw-based auth if you’re lazy, ignore login attempts and logs in general and never visit a server until it needs reconfiguration. Just say f* it. And nothing happens. They just work for years, the only difference is you not having tremors about it. The only time a couple of my vpses were pwned in decades was a week after I gave a sudoer ssh key to some “specialist” that my company decided to offload some maintenance to. What changed from back then is that software became easier to set up and config and less likely to do something stupid. Even your dog can run a vps with a bunch of services now. reply ricardo81 6 hours agorootparent>pw-based auth better off using key only logins and forgetting IMO reply denton-scratch 11 hours agorootparentprev> And nothing happens. Good luck. Some people have different experiences. reply wruza 7 hours agorootparentSome people install every php plugin they can find. Recently I gave my coworker an access to a gui server and next day he complained he can't install some chinese malbloatadware on it. People have different experiences due to different paradigms. My message is about not being anxious, not about being clueless. With opensource and how code works in general, we are all in the same boat with bigcorps and megacorps. And they receive the same updates at the same rate (maybe minutes faster cause they host repos). This quote, \"you can't be certain the software you use is secure\", is technically true but is similar to the \"you can't be certain you won't die buying groceries\". Perfectly useless fearoid for your daily life. reply tjoff 6 hours agorootparentI get what you are saying, and if anything all the \"attacks\" in the logs should build you some confidence. Oh, so 98% of all attacks assume I haven't changed the root password? I must be ahead in the game then. But the way you phrase it isn't really convincing, and for singling out 443 and 80 ports. As the subthread of breaches hint towards. You might not need to be worried about nginx, but whatever you host on nginx might be a problem and being \"certain the software you use is secure\" is also pretty darn useless as guidance. reply wruza 5 hours agorootparentHow do you run software? Or if you are using managed hosting or a platform for running software, how exactly they solve this “security strictly8181 root In 30 days? That's tad unrealistic. Just checked and there are dozens root login attempts per minute on my colo'ed server in the EU. Virtually all from the Chinese and post-Soviet IP space. But mostly Chinese. reply nubinetwork 11 hours agoparentI see ~1000 unique IP addresses hitting SSH every day. reply hugocbp 7 hours agoprevAmazing article! It is actually amazing how fast and thorough the connection attempts happen as soon as you put anything online. I've been playing around Hetzner and Coolify recently, and notice that, as soon as port 22 is opened, it is bombarded by those attempts. Several per second. It might be due to Hetzner IPs being reused, but happened to me every single time. Same with Postgres default port (those were the ones I've seen). I have defaulted to use Terraform and bash to only open those ports in the Hetzner firewall (and more common ones like 3000 or 8000) to my own current ip. It does mean I'll get drift and need to reapply the Terraform code if I change ips, but seems to be at least one way to defend. I fear that a lot of devs jumping into the \"you only need a VPS\" crowd on Twitter will end up with a huge attack surface on their apps and machines and most won't even know they are being targeted like that most of the time. To this day I still find it hard to find a comprehensive security guide for those newer Linux fresh boxes (and the ones you find are all so very different with different suggestions). If anyone knows of a good one, please share with me! reply fsmv 7 hours agoparentYou just need to turn off password authentication so it's keys only. They can attempt logins all they want and never get in. Also if you run ssh on a nonstandard port you get many fewer attempts. There are several groups that constantly scan all of ipv4 for open ports, if you use ipv6 they cannot scan that space anymore. Optionally you can set up fail2ban but I find it's not a big deal. reply ogud2025 6 hours agorootparentI changed my SSH configuration to only listen on an IPv6 address 6 months ago and since then the number of SSH attacks has fallen from 1000+/day to less than 10/week. reply e12e 7 hours agoparentprevI would recommend just using a VPN, like tailscale, for all non-public resources - rather than IP whitelisting. Ed: including private web services like self-hosted gitlab not used for publishing public projects. reply FredPret 6 hours agoprevI simply block traffic from countries where I do not do business in. I used to see constant attempts to mess with Wordpress URLs, which I know is not legitimate because I don't run Wordpress. Cutting out Russia & China basically removed this problem. I really hate locking up my tiny corner of the internet but I don't see another way. reply oopsallmagic 3 hours agoparentWaiting for the whatabout crew to show up asking what you'll do if the website for Joe's Barbecue and Grill needs to be accessible from Moscow. reply gunapologist99 4 hours agoprev> In conclusion, these commands represent a clear strategy to infiltrate, assess, and establish control over targeted systems. Oh hello, ChatGPT. You seem to be everywhere these days. reply laktak 13 hours agoprevWhat does `echo -e \"\\x6F\\x6B\"` do? reply ggambetta 13 hours agoparentIf you say it 3 times in front of a mirror, it summons Stallman reply moffkalast 11 hours agorootparentWith or without the swords? reply withinboredom 10 hours agorootparentOnly one way to find out! reply pompompurin 9 hours agorootparentprevHaha reply gpvos 9 hours agoparentprevTests whether `echo` supports the `-e` option. reply zh3 13 hours agoparentprevIt prints \"ok\" and shows they got in (it relies just on a shell, nothing else). reply lucianbr 12 hours agorootparentWhy not do 'echo \"ok\"'? reply kynetic 10 hours agorootparentAs shown by someone having to ask what it does, it obscures what it does. reply lucianbr 6 hours agorootparentDoesn't seem terribly useful. I mean it only obscures that it prints \"ok\". If you're looking at the logs, you probably already figured out someone is attacking you, and if you didn't, seeing \"echo ok\" will not help you figure it out. If the only thing the command does is \"obscure what it does\", then the only thing it obscures is \"obscure what it does\". I guess there's no requirement that whoever writes these scripts is a genuis. reply Retr0id 5 hours agorootparentPeople writing malware generally don't want to deploy it on honeypots, because then they're handing their payload (and other tradecraft) directly to analysts. So often the first stage is an attempt at honeypot detection, or more broadly, device fingerprinting. A bad honeypot might not even run a real /bin/sh, and this detects that right off the bat. reply ynoxinul 13 hours agoparentprevThis look like a simple test to see if remote command execution works. reply raverbashing 12 hours agoparentprevMaybe I should create a honeypot where cat, echo, sed, and curl/wget all drop random bytes in all commands they execute Would be fun reply thesnide 11 hours agorootparentBetter would be to just subtly change the output... Like do a +1 on the byte every 7 bytes. Bonus to do it only on every 7 printable chars. And you can even do A/B testing on the constant 7. reply spc476 13 hours agoparentprevIt echos \"ok\". reply Mxrtxn 13 hours agoparentprevPrints out `ok` reply pingec 12 hours agoprevA bit tangential but is there a service or self hosted solution that would take a list of IPs and then keep scanning them periodically and alert me if any new ports have suddenly open? reply bluish29 12 hours agoparentI think shodan could br useful in this regards https://www.shodan.io/ reply cranberryturkey 12 hours agoparentprevhmmm....you could do that with nmap script and a cronjob. reply cranberryturkey 5 hours agorootparentI just scanned my domain for all 65k ports and it took 20 seconds with a 10gbit pipe. i could scan yours for you and shoot you an email if a new port is discovered. Would charge you Like $100/year or something. reply ciebie 11 hours agoprevWhat is a `lockr` command? Is it file system specific or something? Never seen anything like this. It probably should lock permissions on .ssh, but how? reply nisa 9 hours agoprevSomewhat related due to a weak password a mail server from a community I'm involved in send out lot's of spam mail, after analysing the log files I've had over 1500 different IP addresses that logged in to send spam, about 10 mails for each address. ASN and subnets where spread across over the whole world. It seems like these attacks are coordinated using vast botnets and the use of single ssh public key here seems to confirm this. I had similar experiences going after attacks on WordPress instances and there I've also found attacks spread out across lots of hosts. I'm wondering if it's possible to pin down those behind these attacks, there must be mistakes. reply charles_f 4 hours agoprevI opened my personal server's 22 to the world because I screwed up my vpn config a couple weeks ago. I just had a look at the auth log and closed it again. It is non-stop. reply braza 2 hours agoprev(Long shot) I really would like to USA a spare machine for web serving a Jupyter Notebook server, but I did not found a single resource that blocks everyone except a single IP or something like this. Supper annoying to pay some cloud providers to have a resource that I already have. reply nilsherzig 10 hours agoprevCheck out https://viz.greynoise.io/ especially the trends > anomalies tab is very interesting reply jslakro 8 hours agoparentHow do you use that information? reply tanepiper 9 hours agoprevWe run internal sites that are on the public facing web - the logs from Akamai are a daily list of mostly the same requests to find unsecured Wordpress and MySQL installs, .cgi and php files and paths like \"..%C0%AF../..%C0%AF../..%C0%AF../..%C0%AF../..%C0%AF../..%C0%AF../etc/profile\" In 24 hours theres anywhere from 7000-9000 log events just from the CDN reply Tiberium 13 hours agoprevInteresting article, sadly due to my exposure to LLMs I couldn't help but notice that the parts about \"oinasf\" and sakura.sh are AI-edited at least. Kind of a weird choice considering that a lot of the article was clearly human-written. reply agilob 14 hours agoprevThere's a project for running Honeypot as a Service: https://haas.nic.cz The data is public and you can register your router too reply throw156754228 4 hours agoprevMy website backend APIs get repeated attempts at javascript prototype injection, all day, every day. reply poikroequ 14 hours agoprevI once tried hosting a web server at home by exposing ports 80 and 443 to the Internet. Hours later I reviewed the logs, thousands of attempts to hack into my lil Linux server. It spooked me to say the least, so I switched to using cloudflare tunnels instead. Exposing ports on the Internet is dangerous, especially SSH. You're much safer using a proxy or gateway of some sort, or better yet a VPN if it doesn't need to be publicly accessible. reply waingake 14 hours agoparentIs it? If you've got `PasswordAuthentication` disabled, only allow public key logins and keep your system up to date. Honest question. I self host my email ( docker-mailserver ) and host my personal website on an old laptop with a static IP. Have done for years now without issue. reply pkrotich 14 hours agorootparentThe keyword is diligently keeping your system up to date! That said you’ll still have exposure to zero day vulnerabilities and DOS attacks. reply Fabricio20 13 hours agorootparentBut an attacker with one of the biggest vulnerabilities on earth (hell, ssh noauth 0day) would very likely use it against big cloud providers and infrastructure (isps and others) and not burn it on your home server! Keeping it reasonably up to date with your distro's cycle is probably enough for most people doing this home server thing. So of course, as things always are with security this is a matter of risk assessment and understanding your attack surface, a server with only public key and maybe on a special port goes a very long way, add fail2ban on top and i'd say it's probably fine for quite a while. But that does make me think... what if... a wormable noauth 0day like that on ssh or some other popular system... how fast could it replicate itself to form the biggest botnet.. how long would it take, to take over all visible linux servers on the internet (so that your little home box ends up being a target)? I guess at that point you are limited by bandwidth, but since you can scale that with every compromised server... hope someone does the math on that one day! reply rcxdude 11 hours agorootparentIpv4 is only 4 billion addresses. It doesn't actually take very long to just try all of them. If you're running a service exposed to the internet and it has a published exploitable vulnerability, it's just a matter of time before it gets exploited. (that said, that time does give a little buffer for patching) reply kristopolous 14 hours agorootparentprevhttps://wiki.debian.org/UnattendedUpgrades Most distros have something like this. reply Beijinger 13 hours agorootparentThis reminded me of: https://github.com/ajgon/self-hosted-mailserver/blob/master/... reply Beijinger 13 hours agorootparentprev\"PasswordAuthentication disabled\" not sure I can even do this on my shared BSD server. I have ssh access via pw and need it. Is this really dangerous? reply Scramblejams 13 hours agorootparentYes, it's risky to accept password auth if someone sharing the box with you has a poor password. They could do things like: . Install a spam or brute force password bot, which could get the machine kicked off its internet connection (in addition to whatever havoc it causes first) . DoS the server by filling up the disk or using too much RAM (are quotas enforced?) . Exploit a local vuln to get root, if such exists on that box. (Is the kernel promptly patched and the box rebooted?) . Explore other users' directories (are permissions locked down correctly across users?) …and more thrilling possibilities! Embrace key auth. Future you will thank you. reply johnklos 13 hours agorootparentprevIt is, if for no other reason than you never know when some other user has a guessable password. You should switch everyone to ssh keys. It's a good excuse to learn :) reply fragmede 6 hours agorootparentprevHow good is your password? If it's long, with special characters, it's fine. Install fail2ban. The problem with auth keys is you can't get into the server if you don't have your laptop/phone/NFC device because you got pickpocketed/mugged? reply sneak 12 hours agorootparentprevYes. Authenticating with passwords is obsolete and dangerous. Use keys and disable password auth. reply tpoacher 11 hours agorootparentAnd if you really like passwords, you could always enable both, too! reply Beijinger 13 hours agorootparentprev\"I self host my email \" Is this still possible? Are your emails getting delivered? Downvoted. I don't know when the downvoter tried the last time to \"host their own email\". Yes, DMARC, DKIM und SPF. Good luck trying to get your email deliverd to t-online or something. https://forum.hestiacp.com/t/t-online-curious-story-about-th... They may even check if your domain has an \"imprint\". I kid you not. I use my own domains too, but I piggyback with infomaniak.com reply pja 12 hours agorootparent> Is this still possible? Are your emails getting delivered? Mine are. Although it probably helps to have a static IP with a 25 year long clean history. Are there very occasional glitches? Sure. But I've seen ISPs drop everything from GMail on the floor for no obvious reason. I've seen GMail drop GMail email before. Same for every other large email provider. To date I haven't seen any reason strong enough to push me to switch to a centralised email host. That day may yet come of course. reply A1kmm 8 hours agorootparentprevI self-host my email, and have not really had problems delivering normal quantities of personal email (except a bit of pain for Microsoft to accept mail in the first place, but it can be sorted quickly) - as long as you do DMARC / DKIM / SPF. I've never heard of t-online before or tried to send an email there to my knowledge... if one provider I've never heard of would refuse to accept my mail if I ever sent something to them, that's more of a them problem than a me problem - but it certainly isn't the norm for other providers. reply hggh 9 hours agorootparentprev> Is this still possible? Are your emails getting delivered? Yes and yes (if DMARC/DKIM/SPF configured correctly). reply johnklos 12 hours agorootparentprev> Good luck trying to get your email deliverd to t-online or something. People who say it cannot (or should not) be done should not interrupt those who are doing it. The dismissiveness is likely why you are downvoted, I'm guessing. The suggestion that because it's hard for you and therefore you're surprised others are doing it isn't a good look. Self hosting email isn't that hard, and there are many solutions for all sorts of self hosting issues. That's a topic for another discussion, though. reply Beijinger 12 hours agorootparent\"Self hosting email isn't that hard\". Self hosting is super easy. Getting your emails delivered is hard. And I am not even talking SPAM folder here (see t-online example). Smart comment from reddit: \"The problem with selfhosting email, unlike selfhosting services like Jellyfin or Nextcloud, is that you rely on other people's servers to play ball with you, but they often don't. Or they play for a while and then suddenly decide not to without telling you. It's unpredictable and we selfhosters don't have enough control over that.\" This describes it pretty well. reply cherryteastain 10 hours agorootparentprevI fo it too and can deliver to gmail/office365 etc addresses no problem. reply gsich 10 hours agorootparentprevyes and yes. Selfhost does not imply residential IP. reply kristopolous 14 hours agoparentprevI've been doing it for 25 years. It's fine. reply Hendrikto 9 hours agorootparent”Works for me.“ does not really answer the question. Having a 25 year history might be why your mail gets delivered, while many people trying to self-host have constant and unpredictable deliverability issues. reply kristopolous 6 hours agorootparentIt's more an advocacy against security paranoia. You will always get automated attacks, constantly. But they're almost all doing stuff like trying to exploit a 12 year old bug in Wordpress or IIS. They're about as sophisticated as any other scammer on the net. reply DEADMINCE 5 hours agoparentprevThe traffic doesn't matter if you are sure your setup is secure. Key auth only for SSH, reverse proxy in front of your actual web server and use secured containers or VMs for each service. Throw in fail2an or crowdsec and that's more than enough for a little home linux server. reply spc476 13 hours agoparentprevI checked the logs for May for one website I run---65% of failed requests were for PHP scripts (mostly Wordpress). I don't run PHP so I don't worry. The rest of the requests were bots that can't parse HTML [1] and other weird requests. I've been running a webserver, SMTP, SSH and DNS for over 25 years and only once had an issue due to an inside job [2] twenty years ago (hard to protect against those). [1] https://boston.conman.org/2019/07/09.1 [2] https://boston.conman.org/2004/09/19.1 reply aadhavans 14 hours agoparentprevOut of curiosity, what are the ramifications of exposing ports 80 and 443? Can these ports even be 'hacked'? It doesn't seem terribly unsafe to me, especially if you're serving static pages. reply koito17 14 hours agorootparentIn my experience, most of the noise on my web server are bots with spoofed iPhone or Google Chrome user-agents. I see three kinds of traffic patterns. 1. bogus /wp-login.php requests, or endpoints of presumably insecure wordpress plugins. These bots are pretty dumb and do it non-stop, even if the server constantly responds with a 404 2. testing recent Apache vulnerabilities by POST-ing to something like /cgi-bin/.%2e/.%2e/.%2e/.%2e/bin/sh . Even if your web server clearly communicates that it's not Apache, the bots still insist on testing Apache vulnerabilities. They also occasionally test vulnerabilities that exist in ancient Nginx versions. 3. less common, but bots that exist to scrape something from the internet. I remember two years ago seeing a bot whose sole purpose was to document as many registered, valid domain names as possible (I found out about this since they linked a website explaining who they were in their user-agent string) Overall, I would say the background noise of HTTP servers is tame compared to what you see for SMTP servers and, to some extent, SSH servers. I happen to also self-host e-mail; logs record failed login attempts about every second. They always pick a username like \"admin\" or \"adm\". There's also people who try using your SMTP server as a relay for spam. reply DEADMINCE 5 hours agorootparent> testing recent Apache vulnerabilities by POST-ing to something like /cgi-bin/.%2e/.%2e/.%2e/.%2e/bin/sh . Are they really recent vulns though? reply fpoling 13 hours agorootparentprevFor me the biggest source of noise in logs for a small site is the referrer spam. At some point like 12 years ago I enabled webalizer stats with a public link to the stats page. Soon I had to deal with massive amount of bot requests with http referrer pointing to porn and farmacy ads. That has not stopped after the public link was removed and the stats has started to use a public spam database. And the spam is still there after 12 years. reply tombrossman 3 hours agorootparentMatomo (self-hosted analytics, used to be called Piwik) maintain a list of referrer spam domains. I use it as a filter list with GoAccess and haven't seen referrer spam for a long time. Worth a look. https://github.com/matomo-org/referrer-spam-list reply aadhavans 14 hours agorootparentprevGotcha, thanks for the detailed response. I've seen the WordPress login attempts in my own web server logs, and that seems to be corroborated in your comment. reply hyperman1 13 hours agorootparentprevI've added a /wp-login.php and friends that firewall-blocks the IP of the requester for a week. It greatly cuts down the bot noise. reply immibis 13 hours agorootparentMy competing site can haveand customers won't be able to view your site after that. Thanks for the free customers! reply sweetjuly 10 hours agorootparentYep :) The real trick is to not be vulnerable to known issues, and then mitigate post-compromise like crazy on the off chance you get patch gapped or (very unlikely) zero dayed. Blocking IP addresses is extremely silly, especially in an IPv6 world where attacker can easily get access to gigantic numbers of addresses in hard to identify ways (there's no source of truth for what IPv6 range corresponds to one blockable \"customer\". Some get /56s, others get /48s, etc.). It's security theater which may well just break your service for real users. reply Beijinger 13 hours agorootparentprevCan you post the script? Obviously I assume you don't run wp. I think wordfence does something similiar. reply DEADMINCE 5 hours agorootparentIt's probably just an nginx fail2ban jail or something that looks for the wp pattern. reply e12e 6 hours agorootparentprevhttps://arstechnica.com/security/2024/06/thousands-of-server... reply ozim 11 hours agorootparentprev99.9999% of issues on 80/443 are apps run on the server not webserver itself. It is applications that you run on web server that are exploited. So serving static pages is safest thing you can do. reply ValtteriL 12 hours agorootparentprevPorts can't be hacked but the application listening on them can ;) You can have vulnerabilities on the server software and its configuration even if you are serving only static content. This should be unlikely if you use up-to-date battle-tested software like nginx without making crazy config changes. If you serve dynamic content, that may also have vulnerabilities that hackers can exploit. reply chipdart 13 hours agorootparentprev> Out of curiosity, what are the ramifications of exposing ports 80 and 443? Can these ports even be 'hacked'? These are the ports usually employed to serve HTTP and HTTPS traffic, which mean public-facing servers. Having a server listening to those ports is the precondition to have web servers running specific types of services, some of which have known vulnerabilities that can be and are exploited. reply chipdart 13 hours agoparentprev> I once tried hosting a web server at home by exposing ports 80 and 443 to the Internet. Hours later I reviewed the logs, thousands of attempts to hack into my lil Linux server. It spooked me to say the least, so I switched to using cloudflare tunnels instead. Isn't this hypothetical risk mitigated or outright eliminated by using stateless apps and periodically redeploying them in the spirit of cattle? reply metadat 13 hours agorootparentDepends, If they get into the stateless app and hoist that to penetrate into other stuff in your network, they might be able to install an APT. reply chipdart 10 hours agorootparent> (...) they might be able to install an APT. As you're periodically doing clean redeployments, that's not a concern isn't it? reply immibis 3 hours agorootparentClean deployments of your entire home network? reply INTPenis 14 hours agoparentprevI noticed earlier this year while deploying a CoreOS VPS with terraform that sometimes you'd get an interesting IP that would receive incoming HTTP requests for interesting domains such as theguardian.com. I of course destroyed and re-deployed the VPS several times so the interesting IPs are lost to me, but it might be worth running a HTTP honeypot as well as an SSH one. reply JackSlateur 9 hours agoparentprevEvery things on the internet is doing exactly this \"dangerous things\", with the exact same means you have at your disposal. Exposing a service is not dangerous. It is the same thing when you go to the sub and many people ask you for money : they keep asking, but that will not lead you to your bank account. So you have log, this is not an issue, this is not something to be scared of or even cared of. Just ignore them, as they are worthless and part of the v4 internet. reply nurettin 14 hours agoparentprevDon't worry, they are usually Russian/Chinese ips scanning for 5 year old php exploits. I've been exposing ports to the internet for decades with no issues. Always block ssh password and keep software relatively up to date. If you are very paranoid, make a vps beacon and remotely tunnel ports from your lab to it. That way you only expose the beacon. reply zelphirkalt 13 hours agorootparentI wonder, what is the issue with authenticating by password. If you choose a password of lets say 64 random chars, shouldn't it be pretty safe? Or is there something in the password method itself, that is inherently weak? reply denton-scratch 11 hours agorootparent> Or is there something in the password method itself, that is inherently weak? Your 64-character high-entropy password might be safe; other users on your system might baulk at memorising/typing in 64 random chars, and choose a less-secure password instead. With SSH keys, that can't happen. reply a_dabbler 10 hours agorootparentprevThe first benefit is some bots won't bother testing passwords as the SSH error message tells them the server doesn't use password auth. The second benefit is if your server is compromised it's quite easy for a rootkit to hijack SSH and steal your password when you login (and then abuse that on other servers you use it), the same is not true with a key and it is much harder for a rootkit to abuse as long as you only use the key on your local machine (there are strong protections against SSH handshake MITM attacks afaik) reply Hendrikto 9 hours agorootparentprev> Or is there something in the password method itself, that is inherently weak? You have to send your password/hash. With PKC, your private key never leaves your device. It can even live on a separate security key. All you ever send are signed messages, never your key. reply KAMSPioneer 12 hours agorootparentprevThere are still advantages to public key auth. Sibling comment mentioned resource use, but also consider ease of use: are you setting a random 64-character password on every machine that has SSH server installed? Would it not be easier to generate one ed25519 keypair, apply a reasonable passphrase (and/or use disk encryption), and then you have secure auth on all your machines without a password manager? If you're _not_ setting unique 64-character passwords per server, then you should consider what happens if your super strong password is discovered -- an attacker would have access to all your boxes. Compromising a key is harder than compromising a password. reply cess11 13 hours agorootparentprevSure, they probably won't crack that, but there are other things to consider as well. A sshd on IPv4 port 22 that accepts password auth attracts attention, and you'll spend CPU cycles constantly checking credentials from very large database dumps that float around. In my experience it leads to more log noise too, it seems many bots will discard your IP and stop pestering it if passwords aren't accepted. So in practice you'll probably also use something like fail2ban, firewall rules that only allow connections from certain IP blocks, things like that. reply mikhmha 14 hours agoparentprevYeah this is what keeps me away from self-hosting public facing stuff. To me its like opening a new pipe into your home that is open to the whole world. And I'm too carefree to get the settings down right. So I avoid it all with complete process isolation. Don't shit where you sleep! reply sureglymop 14 hours agorootparentBut couldn't, you, within your home, separate it from everything else? I don't see how it's any more dangerous really. reply mikhmha 13 hours agorootparentI should clarify. When I mean self host it’s for public facing applications that generate revenue. It involves some transaction in currency?value? between the user. Once money is involved you become a target. I don’t want anything that could be traced to my physical address. I told you I’m careless, I’ll eventually slip up on installing the patches or configuring something right. Public facing like serving some static webpages or blog, text content. Yeah do it. reply Nux 13 hours agorootparentprevObviously you need to know how and if you don't then it's always going to look very daunting. reply 19 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "A user running an SSH honeypot for 30 days noted significant illegitimate traffic, primarily from \"internet security companies\" scanning the IPv4 space.",
      "Blocking these networks reduced unwanted traffic by over 50%, but the discussion underscores the limitations of IP blocking due to CGNAT (Carrier-Grade Network Address Translation).",
      "Emphasis is placed on using security tools like fail2ban, VPNs, and public key authentication to protect servers, with users sharing experiences of self-hosting and the challenges of constant attacks."
    ],
    "points": 480,
    "commentCount": 320,
    "retryCount": 0,
    "time": 1718513532
  },
  {
    "id": 40695997,
    "title": "Do not try to be the smartest in the room; try to be the kindest",
    "originLink": "https://www.jorgegalindo.me/en/blog/posts/do-not-be-the-smartest-in-the-room-try-to-be-the-kindest",
    "originBody": "Founding / Scaling / Selling / Integrating /",
    "commentLink": "https://news.ycombinator.com/item?id=40695997",
    "commentBody": "Do not try to be the smartest in the room; try to be the kindest (jorgegalindo.me)349 points by jorgegalindo 10 hours agohidepastfavorite214 comments codelikeawolf 7 hours agoEver since that back and forth about \"East Coast being kind vs West Coast being nice\" thing a while back[1], I think it's important to distinguish the two. Because they are noticeably different (at least to me) and shouldn't be used interchangeably. I want someone to be kind to me in a meeting. I think niceness could seriously inhibit progress. A kind person will tell me that an idea I have won't work, but they'll offer to help me work through it. A nice person will tell me that a bad idea is good, just to avoid conflict. [1] https://www.upworthy.com/nice-vs-kind-are-east-coast-people-... reply steveBK123 7 hours agoparentTo summarize the idea in a work concept for those who won't read through - East Coast \"kind\" would be to tell the person working for you about their performance issues early, in a constructive feedback manner such that they could course correct or find a role they are better suited for. The hope is they either improve in the role, find a new role internally, or decide to move on before having to stomach a firing. West Coast nice would be to let the person working for you continue to perform poorly without feedback, being \"nice\" to them, but privately considering them incompetent. Eventually you will end up firing them without much warning when a cut actually has to be made. Think Amazon PIP. reply iancmceachern 2 hours agorootparentMy wife and I refer to the latter as \"Smile F'ing\" reply steveBK123 2 hours agorootparentI became familiar with this term in the mid 2000s and took it to be a Britishism, though I may have been wrong on its origin. Usually it was used in the context of some devious ladder climbing political hack manager in corporate that we'd refer to as a \"smile f'er\" as he (always he) would be smiling while he secretly f'd you. reply lotsofpulp 6 hours agorootparentprev>Eventually you will end up firing them without much warning when a cut actually has to be made. Think Amazon PIP. I would bet managers on the east coast keep under performers around just to have people to cut also, doesn’t take a genius to figure out the strategy. You invest in people you think can improve and help you, you get rid of the ones that hurt you, and you keep the so so ones for when you need to sacrifice. reply steveBK123 6 hours agorootparentMost companies don't run an Amazon style PIP program where you HAVE to cut X% annually on every team. Therefore, keeping around people who genuinely deserve firing is a drag on delivering. As a result it is always in your interest to get improvements out of your team members, whether by upskilling, role changing, hoping they leave on their own or worst case actually laying them off. I've worked in financial service tech for nearly 20 years across 6 companies and only 1 I would say did a \"5% every year\" thing, and even that got paused for years at a time when market conditions pushed that way. Even if your statement is true, it is a matter of framing. Obviously you keep your best staff, and fire the actively negatively contributing staff. The people in the middle aren't just \"for when you need to sacrifice\".. they are simply the middle 50%. You obviously want to see them improve as well. reply lotsofpulp 6 hours agorootparent>Most companies don't run an Amazon style PIP program where you HAVE to cut X% annually on every team. I cannot comment on pervasiveness, but I thought the \"fire bottom x%\" (or stack ranking or yank and rank) strategy started on the east coast, with businesses like GE, hence it would not be a trait isolated to either coast. https://en.wikipedia.org/wiki/Vitality_curve >The people in the middle aren't just \"for when you need to sacrifice\".. they are simply the middle 50%. You obviously want to see them improve as well. Everyone wants to see everyone improve, but time and energy are a scarce resource, so it is just a matter of how much you want to bet on each person. reply derefr 4 hours agorootparentIt's still not most companies. But it's maybe the top N public companies — the ones that are all \"headless\" in corporate-vision terms, and so hire the same few management consultancies to tell them what to do. Ignoring those few largest companies and focusing on the other 99% of businesses that don't hire management consultancies, this is definitely a \"thing\" with businesses on the west coast. reply sklargh 4 hours agorootparentJust want to correct something here. Management consultancies are *rarely* hired for expertise. They're functionally a form of career insurance for senior leadership's proposals and an internal political tool to allow unpalatable or political challenging things to be executed. reply derefr 3 hours agorootparentYes, management consultancies are not hired because anyone expects them to know what they're doing. But they are hired for a certain specific kind of \"expertise\" they uniquely possess — that being the internal knowledge about management decisions being made in other companies (perhaps with their guidance; or perhaps just with them there at the time to witness those decisions.) In other words, management consultancies can tell you how to \"copy the success\" of companies you personally think are worth copying, provided the management consultancy you hire has records of their consultants working at that company. (You won't actually be \"copying their success\", because you'll be applying your mental schema of what would make for success to deciding which of their internal practices and decisions should be copied. So it's more a \"cargo-culting of success.\" But executives still want that!) A CEO won't trust the thinking of a fresh 20-year-old sent over by Bain. But they will trust the thinking of a CEO they admire. And they're willing to pay big bucks just for Bain to send them the 20-year-old rather than Bain's best, not only because the 20-year-old is a political tool; but also because the 20-year-old is a channel through which the CEO can tap into Bain's institutional memory of private leadership meetings held by their most-admired CEOs! (And this creates an active transmission vector for the spread of business-management-theory memes. \"Return To Office\"? It may have started because a few bigcorps like Apple had big albatross investments of commercial real-estate in the form of massive HQ buildings. But it spread throughout the Fortune 500 via their shared reliance on the management-consultancy grapevine.) Management consultancies know that this is half the reason companies hire them — or at least the consultants who've been around the block know this. And this is why there's any place at all for senior management consultants, rather than it being strictly a \"get in, make your money, retire early\" sort of job. It's not that the senior consultants know more about business. It's that their field experience has enabled them to internalize and distill the current corporate zeitgeist — and so they can just tell you off the top of their heads what you should be doing to be the management-theory equivalent of \"fashionable.\" (And this doesn't look outwardly any different than the \"best practices\" advice the 20-year-old will give you based on what they learned in their MBA program. So there's plausible deniability in this, in a way there isn't in asking the 20-year-old to dredge up records from your competitors.) reply BeetleB 6 hours agoparentprevI have to say: It's really annoying that some idiot who wrote a book in the 90's has resulted in everyone redefining \"nice\", when they should have invented a new word. As far as the English language goes, what you define as \"kind\" is also \"nice\". reply codelikeawolf 5 hours agorootparentWell, unfortunately nobody did invent a new word. Considering a cursory search of the definitions of both words: Kind: of a sympathetic or helpful nature Nice: pleasing, agreeable I would argue that they are actually different. reply BeetleB 3 hours agorootparentMerriam Webster literally lists \"kind\" as one of the definitions of nice. The point is that nice is a pretty broad term. It can mean agreeable but that's merely one use of the word. You can be nice and not agreeable. reply ffsm8 4 hours agorootparentprevI think you're misunderstanding the point they were making. The given example for nice > nice would be to let the person working for you continue to perform poorly without feedback, being \"nice\" to them, but privately considering them incompetent. Is actually being hypocritical, not nice. The nice person would still tell the under performing person what's what, they'd just not be rude about it. You can also create a scenario in which being kind becomes detrimental if taken to the extreme. However, the author of that book decided that being nice was bad, and being kind was good. This understandably continues to annoy people when this frankly dumb definition is brought up. reply mgh2 3 hours agorootparentMost people are nice (convention, norm, culture, etc.) to conform to a set of rules, being kind is the exception to the rule. reply BeetleB 3 hours agorootparentYet another faulty categorization and coopting - this time of both words. Kind is only the exception to the norm if you're in a crappy culture. In some places the ethic is such that kindness is the norm. reply dingnuts 2 hours agorootparentthere's already a word for using a specific type of soft language regardless as to intent, and it's \"polite\" don't know why we need to quibble about the meaning of \"nice\" or invent a new word when polite will do politeness, unlike kindness or niceness, has no implication of intent, only tone, which is what's trying to be conveyed reply ThrowawayR2 4 hours agorootparentprevThe comment above and a recollection of the sub-title of Pratchett & Gaiman's Good Omens prompted me to look up the etymology of \"nice\" and it seems that it has had a surprising number of unrelated meanings: https://www.merriam-webster.com/wordplay/nice-multiple-meani.... Maybe that's not the right word to object to regarding changes in its meaning. reply BeetleB 4 hours agorootparentI get that it has multiple meanings. And others should get that if someone is a nice guy he's probably not like the archetype in that book. reply olddustytrail 6 hours agorootparentprevConsidering how many different things \"nice\" has meant over the past few hundred years, I doubt one more meaning will make a difference! reply Kye 7 hours agoparentprevThis is real. When the car broke down in a turn lane in the rain: lots of honking behind me When the hazard lights came on: honking stopped, people materialized to help push it back out of the road reply lotsofpulp 6 hours agorootparentI don’t understand the relevance of this example. Without the hazard light, there’s a 99% chance the person is simply looking at their phone, needlessly delaying everyone else, hence the honking to alert them to move. What else is another driver supposed to do? A hazard light means there is a problem that can’t be solved with honking. reply wrs 3 hours agorootparentI think unmentioned is that this is the east coast style. In Seattle we just let you sit there indefinitely because honking wouldn’t be “nice”. reply navane 3 hours agorootparentprevNice people wouldn't honk at the stationary car without it's hazards on. reply delichon 7 hours agoparentprev\"Tough love\" is kind but not nice. There doesn't seem to be a good phrase for the opposite in English but there should be. reply seadan83 2 hours agorootparentThinking of cats/dogs - euthanasia seems to also be a good fit for \"kind, but not nice\" reply seneca 6 hours agorootparentprevThe book Radical Candor calls the opposite \"ruinous empathy\". reply AgentOrange1234 4 hours agorootparentDefinitely a good book. As someone who is very prone to ruinous empathy, the mantra, “it isn’t mean, it’s clear” has been very helpful for giving me the courage to raise issues earlier, when they are not a big deal. reply delichon 3 hours agorootparentprevFeeding my dog as much as ... tough love: I think she needs. ruinous empathy: she thinks she needs. reply navane 2 hours agorootparentprevVirtue signaling is definitely adjecent reply hooverd 6 hours agorootparentprevUnfortunately \"though love\" as practiced is mostly just an excuse to be an asshole. reply cocacola1 4 hours agorootparentSame with “brutally honest”, where the one saying it is more about the “brutally” than the “honest”. reply derefr 4 hours agoparentprevWhich of the two would say nothing in the public meeting to let you save face, but then would pull you aside for a \"quick chat\" afterward, and tell you your idea is bad then? reply ekanes 3 hours agorootparentThe one who is both nice and kind. :P reply eleveriven 43 minutes agorootparentAnd smart reply jmull 5 hours agoparentprevHonestly, I think it’s a mistake to try to retroactively impose a technical distinction between two words that have been synonyms for quite a while. The intent is probably to clarify and communicate better. But with that word choice you end up confusing and muddying. The problem is, people have to know exactly what you mean already (which means you probably don’t have that much to talk about on that topic anyway). reply WarOnPrivacy 3 hours agoparentprev> Ever since that back and forth about \"East Coast being kind vs West Coast being nice\" thing a while back Missed the thing but what a front-loaded mess. What we want to say is Nice sucks, be kind. The rest feels unhelpful. Kinder to state the principle and let folks chew on it. reply brudgers 3 hours agorootparentA person can be both...though that might just be skilled kindness. reply WarOnPrivacy 3 hours agorootparentYou're right. Doubly so because either-or scenarios are usually false choices. The pithiness works in presentation but past that... reply vijucat 4 hours agoprevNice article. Definitely need more kindness in this achievement society. One small crib, though: > In Spanish, we have a saying, \"Maestro Liendre: De tó sabe, pero de ná entiende.\" I don't really know (and don't want) to translate it because it loses its punch, but it fits perfectly here. Wait, why mention it if I, the reader, cannot understand the saying or how it is even relevant to the article, but leave me with the tease that \"but it fits perfectly here\". Very puzzling, to say the least. Google Translate tells me \"Master Niendre: He knows everything, but he understands nothing\". Now I'm even more confused. That is so pithy and unambiguous that I really have to ask: what is it about the Spanish version that \"loses its punch\" when translated to English?! reply TheBozzCL 4 hours agoparentGoogle Translate is being too literal. It just means “jack of all trades, master of none”. A more literal translation (with some liberties for the rhyme) would be “handyman nit: knows a bit of everything, but understands jack shit”. reply steveoscaro 4 hours agoparentprevSide note: I find ChatGPT to be a much better translator. It doesn’t just do literal translations. Here’s how it explained this phrase: The saying \"Maestro Liendre: De tó sabe, pero de ná entiende\" generally means that someone appears to know a little bit about many things but doesn't have a deep understanding of any of them. It's used to describe someone who pretends to be knowledgeable but lacks true expertise. reply giraffe333 1 hour agoparentprevTIL: Spanish has a sort of written contractions. I speak conversational Spanish so I’ve heard people talk this way, like Puerto Rico or Dominican Republic speakers shortening things, just hadn’t seen it written before. tó = todo ná = nada https://www.spanishdict.com/guide/shortening-of-words > There are a few apocopes of very common words that are pronounced and written in informal Spanish as monosyllabic words. These popular apocopes include na, pa, and to, that stand for nada (nothing), para (for), and todo (all). You may find these words written with an apostrophe at the end, but spelling experts advise against it. reply obiefernandez 4 hours agoparentprevIt hits better with the rhyme reply vijucat 3 hours agorootparentMakes sense, thanks reply charlietran 4 hours agoparentprevfrom the context in the article, this seems to be the Spanish equivalent of “jack of all trades, master of none” reply frugalmail 1 hour agorootparentI think it has more of a negative connotation in the context of thinking you are a \"master of all trades\" despite not. reply pessimizer 4 hours agoparentprev\"A know-it-all who doesn't understand anything\" sounds fine in English to my ear. reply elteto 3 hours agoparentprev“Knows about everything yet understands nothing.” reply ozim 1 hour agorootparentSpanish version is much more compact and can be pronounced quicker so it can be used as pun. This English version, you cannot just punch it, there has to be a pause like after \"yet\" or a comma before yet and then punch is delivered but still \"understands nothing\" is a mouthful compared to \"pero de ná entiende\" even though my Spanish is non existing, still feels like I could pronounce it much faster or much easier. reply baazaa 7 hours agoprevIf we tallied up all technical projects in the Western world that failed, how many would be failing due to lack of kindness versus, say, straight-forwards incompetence? Because 100% fall in the latter category in my experience. One of the problems with engineers counter-signalling engineering values (like actual technical competence) is that we live in a world where those values are extremely underrated while every manager, HR-bot etc. are already pushing values like kindness. E.g. if you ever wonder why government doesn't work it's because they're absurdly skewed towards HR-values and opposed to engineering-values. reply lemmsjid 4 hours agoparentHuh! If I reflect back on my involvement in projects that had difficulties, there was rarely a dearth of competent people, and in fact it was often political and communication concerns that led to suffering. Look at Conway’s Law: “any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization's communication structure.” The “kind” people are the people who optimize an organization’s communication structure by helping competent people to have a voice and not be impeded by political wrangling. In short, I think it’s the ‘kind’ people who can help an organization realize an architecture that is less warped by political considerations and more true to the customer’s needs. Of course an organization needs both kindness and competence. In my decades in tech, competence was over-valued in my early years (the worship of the trope of the rockstar-but-asshole programmer), so if there is an overindication towards kindness right now, it is probably a counterbalance. I would also question your conclusion about the government. While I have not worked in the government myself, I come from a sort of “federal government family”, in that I have multiple close family who have spent decades in federal government roles, and they are full of stories of incompetent managers undermining their employees, politically fighting one another, etc. To your point, they also have plenty of stories of crass incompetence, Nepotism, etc. But I think it’s an easy and incorrect answer to say it’s simply due to “HR-values” as opposed to “engineering-values”: it’s multi-faceted in both directions. reply therobots927 7 hours agoparentprevI actually agree with you but at the same time, being unkind in those situations is only going to hurt yourself. The reality of many workplaces is that the technical aspect as not the main focus. Appearances and politics run the show at most companies. You can either accept that and work with the system or engage counterproductively with your colleagues in a misguided attempt to force them into technical competence (never gonna happen). Eventually I want to find a place to work full of technically competent people. I thought I would find that in my current company because it was so competitive to get a job here. Let’s just say that was not the case. It think it can be very hard for employees to filter on this without knowing someone on the inside. reply CM30 5 hours agoparentprevAnd how many would be from incompetence in terms of execution vs poor planning and a lack of knowledge about what's actually needed to complete the project? Feels like the majority of those well-known failures (the 'we spent $5 billion+ and spent 10 years on something that should have taken a few years and maybe a tenth of that budget ones) come from either management who has no idea what they want, planning that hasn't taken into account even half the obstacles the project will need to overcome, or dozens of leaders all trying to make their mark. Actual technical/work incompetence probably plays some part, but it's probably less of a matter of \"people weren't honest enough about the quality of other people's work\" and more of a matter of \"we hired the cheapest possible team to do the work, and they weren't qualified in the slightest\". Bonus points for the leader of that team being the nephew/niece/relative of some guy in charge of the project. reply bradly 6 hours agoparentprev> how many would be failing due to lack of kindness versus, say, straight-forwards incompetence? Kindness and incompetence are orthogonal. You can be kind and still give honest, direct feedback. And your feedback will probably be received better because of your kindness. reply spacebanana7 7 hours agoparentprevOpposing view - most large scale projects fail because of political and financial reasons rather than technology. Even the bad tech decisions are usually downstream of politics. If you’re wanting to build a high speed rail line, space rocket or nuclear power plant; a propaganda specialist is probably going to be more useful than an engineer. reply matt_heimer 7 hours agoparentprevI think you could argue that long term lack of kindness at all levels of an organization leads to organizational technical incompetence. It creates hostile work environment where employees don't feel valued which leads to talent attrition. Yes, only valuing kindness with valuing technical competence is not ideal but so is the inverse. You want both. reply zarathustreal 5 hours agorootparentYea I’d like to see some actual studies on that assertion, it has been the opposite in my experience. Technical competence requires a certain amount of self-discipline and sacrifice. You don’t become competent just by doing the same things over and over, so experience alone is not competence. With self-discipline comes a healthy habit of self-motivation. You don’t need your employer “making you” feel valued, you derive a sense of accomplishment from doing good work. You know you’re valued because you’re literally valued (in dollars). reply jmull 5 hours agoparentprevIncompetence isn’t a root cause though. You have to go deeper… why were the people involved in the project incompetent? If you find a project was held back by infighting, siloed groups, major shifts in direction or key people leaving, kindness will help with all of these things. The reality is, people working as individuals, no matter how competent those individuals are, can only accomplish things within the scope of a single person. There are some things like that, but there are many things that are not. To accomplish any of those things, people need to work together, in a complementary way, toward a common goal. That just won’t happen if they don’t get along. Social competence can become just as important as technical competence. Kindness is part of that. reply sidcool 6 hours agoparentprevIt's possible to be technically competent and kind. They're not mutually exclusive traits. One doesn't even need to be kind. Just don't be an asshole. reply globular-toast 4 hours agorootparentThe trouble is \"asshole\" is relative. As an engineer, I value disagreeable people. I want someone to tell me I'm wrong and disagree with me whenever appropriate. But to many HR types just the mere fact you're disagreeing and not blowing smoke up everyone's arse all the time makes you an asshole. People should also feel ok with calling out incompetence which, again, can make you seem like an asshole to some. reply PaulKeeble 2 hours agoparentprevI don't think anyone has yet worked out a way to convince people to live in reality and follow science and engineering and also be kind to people who are opposed to those ways of thinking. Being fake kind to people who are genuinely obstructing things getting done is unproductive but so is being unkind and it seems most people value being cordial even if it means things fail. Almost all problems on projects boil down to a people problem in the end many of which are made intractable by company and wider culture. reply BurningFrog 6 hours agoparentprevThe biggest problem with government organizations is that they're monopolies. The lack of competition means that (1) if the organization is dysfunctional, it won't be beaten by a better one, and (2) it has little incentive to improve. reply rdedev 7 hours agoparentprevI don't know if kindness is the right word you have used here. HR is not kind. At the end of the day they don't care about you. But they speak to you nicely. Same for the government too I guess reply steveBK123 6 hours agoparentprevActually the most dysfunctional engineering orgs I've worked in had unkind hardos in charge who would yell & scream at people. More of it was because they were poorly emotionally regulated than because they were right in whatever they were yelling or screaming about. Government projects stand apart because things like cost are balanced against the inherent jobs-creation objectives of funding them. Kindness doesn't mean to let incompetent people sit in roles they are incapable of indefinitely. That's more \"niceness\", using all sorts of HR speak about family/win together/blah blah blah while waiting until the budget cuts come to surprise fire people who were never performing in their role. Kindness is to give people feedback that helps them improve. It is sometimes a poorly socialized engineers impression that people simply do their jobs poorly on purpose. In reality it's a mix of skills and awareness. Eventually everyone gets put into a role they aren't truly capable of and either grows into it or moves on. Feedback helps that happen sooner rather than later. reply dogleash 4 hours agoparentprevThe article reads like kindness is only a correlated trait to what the author is actually trying to convey. To me this article is the same as any other basic \"collaboration\" explainer. I guess in cultures where a lot of external and internal pressure is put on exhibiting certain virtues, maybe framing it as kindness can override whatever other goals have made someone forget how to collaborate. reply BeetleB 6 hours agoparentprev> If we tallied up all technical projects in the Western world that failed, how many would be failing due to lack of kindness versus, say, straight-forwards incompetence? That's like saying a company didn't fail because it ran out of money. It failed because no one was around to operate it. A lack of kindness can lead to mistakes not being rectified, as well as the wrong type of folks doing the work. (Classic case of false dichotomy). reply doubloon 4 hours agoparentprevi would say yes, a lot of things fail from a lack of kindness. Tesla self driving Tesla robotaxi Tesla park summon Tesla cybertruck Tesla solar roof tiles Boring company etc etc One of the main things that Toyota Production System brings to manufacturing is the concept of respect, everything is supposed to be based on respect for each other. Maybe people fall short of that alot of the time, but that is the goal and intrinsic to all their other techinques like genchi genbutsu, kanban, just in time, waste elimination, etc. reply citizen_friend 6 hours agoparentprevIve also seen cases where business people truly don’t believe there is an underlying reality to a problem. They evaluate approaches and people purely from a sociability stand point. You make a good point about government, there are so many big problems including bad incentives about working hard, taking risks, etc, it’s hard for to see that as the main one. reply moandcompany 7 hours agoparentprevTechnically correct is the best kind of correct. reply EVa5I7bHFq9mnYK 5 hours agorootparentand the kindest best of correct) reply hooverd 6 hours agoparentprevGovernment works just fine when you let them do things in house instead of going with \"we just need to pay one more private contractor\". Also pay more. reply mydriasis 8 hours agoprevWork is hard and stressful. If we're sweet and kind to one-another, we get through it more easily, no matter how smart each of us is individually. Being kind is an investment, and its dividends pay out enormously as your organization grows. Like the article says, it's infectious. I believe that. I believe that if I show kindness, especially to people who are new to the organization, they'll mirror it right back, and try to show it to everyone else, too. reply atmavatar 3 hours agoparentYou have to be careful, though: there is no shortage of people who will happily take advantage of someone who shows them kindness. While I believe you should show a baseline level of kindness to people when you first meet them much like you should give people a baseline level of respect, there are actions which can and should lose both. reply eleveriven 38 minutes agoparentprevKindness fosters a sense of trust and camaraderie among team members reply flatline 7 hours agoparentprevSweetness and kindness are not necessarily the same thing. Just like how “nice” can be a toxic trait. His list of points is fine. It’s mostly the servant leadership mentality, which I’m all for. But sometimes to be an effective leader you have to make hard decisions. You’ve got to know your personal boundaries and know when to yield and when to hold them, or other less sweet people are going to steamrolling you, or you’re going to get overloaded by taking on too much, etc. And sometimes you have to be direct and blunt and not so sweet to show true kindness. Confrontation is hard and it’s not something most people really want, but I believe it’s sometimes necessary to embody kindness. For yourself, your teammates, the customer, the organization. Because at the end of the day if you are not effective, that’s going to hurt everyone. reply mgaunard 7 hours agoparentprevWill you be kind as well to the people who repeatedly fuck up and don't care about delivering good processes or products? reply maccard 7 hours agorootparentYes. They’re still human and they deserve to be treated with respect. But part of being kind is being direct and honest, and holding people to account. If you ignore it, or let it fester you’re being unkind to other people reply Kalium 6 hours agorootparentThere's a great deal of nuance to how kindness is defined. It's very easy for one set of actions to be either very kind or very unkind, depending on definitions. Listening, being respectful, and being empathetic may drive one person to bite their tongue and silence feedback that someone is performing poorly out of fear of hurting them or the morale of the team. Another may be driven by the very same things into giving candid feedback. This article does not do a good job of exploring the difference. It just asserts \"Being nice is the new punk\". reply the_snooze 7 hours agorootparentprevThere's a lot of kindness in clarity, even when it comes to bad news. Imagine a doctor has to deliver a terminal diagnosis; it would be very unkind to avoid or sugarcoat the news, just as it would be to trivialize the issue by joking \"don't bother buying green bananas.\" reply Kye 7 hours agorootparentprevWhat would being unkind accomplish here? reply thih9 7 hours agorootparentIt's not about being unkind, it's about not being kind; these are not the same. Being kind to a person that behaves as described in the grandparent comment could communicate that you find this kind of behavior helpful. Fine if that's really the case; problematic for everyone if not. reply Kye 7 hours agorootparentKindness and enabling are also not the same thing. This entire discussion needs to come to a screeching halt while people get together and hammer out some definitions. It's clear we're all working from different and contradictory assumptions about what these words mean. reply jzb 6 hours agorootparentprevI think people are conflating “kind” with a range of other behaviors. You can be kind while addressing poor performance, etc. You address the behavior, you might even have to fire someone, but those are not incompatible with kindness - if you’ve given someone ample opportunity, and clarity, then you’ve been kind. It’s unkind to let someone get to the point of firing without being clear that their job is at risk. It’s not unkind to take action when their performance threatens the organization, team, etc. I think most people would agree Fred Rogers was kind - but I have to imagine he had to fire people from the show over the course of its run. reply chupy 7 hours agorootparentprevWhat would be kind accomplish there? reply andrewshadura 7 hours agorootparentNot make things worse, for example? Or maybe it can help convey the message across and make things better? reply antisthenes 7 hours agorootparentprevNot being an asshole in your own eyes. If that's not worth anything to you, then Idk, guess we live on different planets. reply BeetleB 6 hours agorootparentprevYes. Not being kind leads to defensiveness and not owning up to their errors. I've worked in very competent teams and very incompetent teams. There were two types of incompetent teams. The type that always denied making mistakes, and the kind that owned up to their own incompetence. Being kind leads to the latter. It still sucked being in an incompetent team, but when they admit their weakness, they get out of your way and defer to you. When they don't admit it, you'll face barriers all the way. reply pcloadletter_ 7 hours agorootparentprevYes. A person's performance on the job does not change how I treat them as a human. reply therobots927 7 hours agorootparentprevYep. You have to be. You can provide feedback to them or their manager if possible but the reality is that the employment status of your incompetent coworker is not under your control. reply mgaunard 6 hours agorootparentYou're speaking under the assumption that \"you\" can't be a team lead or manager able to make the bad performer redundant. Moreover as an IC there is a lot you can do; most importantly you can quit if you feel the team you're in is being mismanaged. reply therobots927 6 hours agorootparentWell yes but you certainly can’t become a lead if you’re getting mad at people. At least in many situations you can’t. And yes you could quit, but the job market isn’t the best right now. And sometimes the jobs that pay more require dealing with less competent people so sometimes there are tradeoffs. reply demondemidi 4 hours agorootparentprevYes. I will. And I upvoted you because I think it is HN duty to help you out, and not bury you. If someone is fucking up, they are in the wrong position. People need to work for a living, and shouldn't be under duress constantly. It is up to them and their manager to find a position that is rewarding and engaging for them. If they don't care, they are also in the wrong position. It is no reason to not treat them with kindness. You don't have to blow them, but you don't need to be UNkind, as several have said below. The only people I don't treat with kindness are people who are legitimately trying to hurt me and people I love, or promote hateful ideas with glee. People who are failing at their job need help. And if they still annoy you, then I think the problem might be in how you view the situation. Compassion helps with anger. Try to think about why you are so angry, and if it really matters or helps to be so angry. Especially if you are not the manager. If you are the manager, consider that maybe the job isn't for you. You shouldn't be pissed at work all day!! reply jorisboris 7 hours agoparentprevSad to say that my experience is exactly opposite When I’m kind to people, especially in other departments, they don’t mirror it: they’re stressed, they’re pressured by their boss or it’s just not the culture of that department… even after months of cooperation reply demondemidi 4 hours agoparentprevExactly! When I look forward to working with people, we get more done and I don't come home burned out and discouraged. Even if the work is hard, at least you are in it together. reply anal_reactor 7 hours agoparentprevI love reading discussions of people to whom following the social norms comes naturally and they can't fathom the idea that behaving in a way that makes other people feel good is something I need to consciously put effort into. reply ttoinou 8 hours agoparentprevSo you want to be kind only for utilitarian motives, not because it’s a good thing in principle ? reply alluro2 1 hour agorootparentThat's not a very kind interpretation of the parent comment - a bit reductionist, don't you think? I personally don't believe it's possible to \"give out\" kindness, compassion, friendship solely from an utilitarian position. It would either be fake, and people feel the difference and the desired effect does not follow, or your utilitarian position is a front, in order to justify being kind to unkind people around you judging you. reply guy4261 8 hours agorootparentprevGood that does not sustain itself is quite sad - you can see the efforts going down the drain. Aligning good and sustainable (utilitarian) is worthwhile imho. reply CoastalCoder 7 hours agorootparentprevIt sounds like you're saying it's far better to be kind for altruistic reasons. Is that right? Some persons (me included) suspect that humans rarely if ever act with true altruism; that it's actually a nicely dressed up form of self-serving hedonism. And so for us, the challenge becomes how to get ourselves to act good / kind despite that. One way is to find ways to intentionally tie kind behavior to our own self-interest. reply beepbooptheory 7 hours agorootparentgp is refering to a morality that is deontologically grounded, not just one based on altruism. Here it is not necessarily for one \"reason\" or the other, but rather acting the way some ideal person would in a perfect world (famously for Kant within the \"kingdom of ends\" where every person is an \"end to themselves\"). It's a rather huge theoretical distinction that at least in the West goes all the way back! In general, one shouldn't confuse ethics itself with the whatever one might think is the most viable ethical system! It isnt a product to market. Utilitarianism is no less silly the anything else, and has its own ridiculous edge cases and all that. reply CoastalCoder 4 hours agorootparentThanks for introducing me to the concept of deontological ethics! It's been fascinating to read up on something about which my thoughts were only half-formed. reply bitshiftfaced 8 hours agorootparentprevWhat does it mean for a thing to be good in principle? reply glenstein 1 hour agorootparentI don't understand why they got down voted because this question has a rather obvious answer. Do you motivate a person to behave a specific way because it's instrumentally good for a higher purpose, or because the behavior itself is inherently valuable? That's a perfectly coherent, it makes a real distinction, and it's a legitimate question in this context. reply OmarShehata 7 hours agorootparentprevfun experiment: let's try to have the most charitable interpretation of this comment ^ My best is: they are saying it is worth taking a step back and making a prioritized list of our values. If we do this, we may place \"being kind\" over \"being productive\" I think their warning here is about: what happens in a situation where being kind is NOT productive? Will you just drop it? I think I agree with the broad strokes of this. My rebuttal is: the comment above this was just pointing out, for people who do not value kindness over productivity, that they are not in opposition. That you don't have to pick one or the other. You can have both. We can get mad and turn away from people who do not share our values/priorities. Or we can show them ways that our value systems do not clash and it can be win win reply ttoinou 7 hours agorootparentGreat sum up ! You can have both, but for me being productive is more important than not offending others reply growingkittens 7 hours agoprevI am generally considered to be a kind and helpful person. There are many situations where a kindness turns to an expectation, which leads to entitlement: suddenly you are the bad guy if you don't go above and beyond. Being helpful around people who view work as a zero sum game is a recipe for disaster. This article also reframes \"things you should do because it's an advantage to you\" as kindness. reply cmsefton 7 hours agoprevAgree with this wholeheartedly. I think where kindness really plays a key role is not passing snap judgements on people and their motivations. It's easy to interpret people's actions or intentions in a negative light, thinking they don't care or are incompetent. I would also like to add that kindness is not just being kind to other people, but to yourself as well. It's easy to beat ourselves up about the mistakes we make, or blaming ourselves for outcomes that sometimes are beyond our control. We can't be perfect. For the most part, I like to live in a world where the default position is that we're mostly well-intentioned, rising apes rather than fallen angels (RIP, Sir Terry Pratchett). This is clearly not always the case, and it's important to accept that, but it shouldn't stop me from still aspiring to be as kind as possible in my own life. reply maroonblazer 7 hours agoparent100%. I'd also add that it doesn't mean you don't have to make tough decisions that some people won't like. But there's a way to do that that leaves those people knowing that your decision-making process was fair and not capricious. That it's in the best interests of the team, project, organization, company. reply Xeamek 8 hours agoprevWouldn't say You have to choose one over another. Smartness without kindness makes you a dick. Kindness without some smartness makes you 'fake', or at least 'valueless'. reply Obscurity4340 8 hours agoparentWould kindness without intelligence (discernment) be more like naïve and easy to take advantage of? Not sure why it makes you fake, there's lots of nice, simple people that are authentic reply cheschire 8 hours agoparentprevYou're choosing one over another. You said kindness with some smartness, which implies kindness = 1.0, and smartness = some value between 0.0 and 1.0. The author never implies that one should be kind to the exclusion of being smart. reply KolmogorovComp 7 hours agoprevThese kind of over-generalist advice are pretty meaningless (especially the title, content being more specific). You do not always want to be perceived (because that's what you're going for) as kind, it is situation specific. You do not want to be kind during negotiation, because that means you're usually missing out on a better deal. You do not want to be kind when dealing with bad behaviour. I've too often seen missing stairs running loose for far too long due to \"kindness\" from HR, whether it was sincere or rather an expression of cowardliness . What do you want to aim at all time is respectful behaviour, because that is what could undermine your current position in the conversation. People do not listen to jerks. reply trxvaf 7 hours agoparentA stair is an inanimate object that other people step upon in order to move upwards. Perhaps the human beings in question refused to participate in that game and therefore went \"missing\"? People using the term \"missing stair\" are very often sanctimonious, obsessed with power, and just do enough of faking kindness to fly under the radar. And they treat others like inanimate objects. reply KolmogorovComp 7 hours agorootparent> People using the term \"missing stair\" are very often sanctimonious, obsessed with power, and just do enough of faking kindness to fly under the radar. And they treat others like inanimate objects. That's a lot of assumption to make from the use of one illustrated idiom, that were by no means intended from my side. reply therobots927 7 hours agoprevI definitely agree with this article. I’m at the stage of my career where my primary limiting factor is my inability to tolerate situations where it’s clear co-workers aren’t pulling their weight, don’t have the same philosophy I have about a project, or when they disagree about how to implement a solution. And nothing makes me angrier than when the tech lead or director in charge is clueless, which happens more often than not. Accepting that this is just the way things are is difficult the more emotionally invested you are in your technical work, if you happen to be on a non-technical or semi-technical team. I think this article is helpful for situations where either the pay compensates for bad work culture, or where you’re simply stuck on a team where maybe you are the “smartest” person in the room and it makes you hate your job. At least that’s how I’m interpreting it for my situation. reply farmeroy 3 hours agoparentI feel like I am struggling with the same thing in my current role and point in my career. On one hand, I feel like I just need to come to terms with the fact that different people have different standards. On the other hand, I just desperately want to work with people who hold themselves to high standards and also get stuff done. In the meantime, I'm finding I'm running out of kindness. I often wonder if it's just me thinking I know more than I do and everything is always this way, that some people just don't care about what they produce and how, or if there teams out there who _do_ care and I just need to find one of those reply benji-york 2 hours agorootparentI have found myself feeling similar things. Something that I've done that has helped me is to find ways to nudge people further along the path of \"hold[ing] themselves to high standards\". That's easier said than done, but I hoped the thought might help you a little. reply therobots927 2 hours agorootparentprevYeah you really just have to learn to accept the situation. If you find an opportunity to jump ship to a place with competent people, take it. But in the meantime I just remind myself that I’m lucky I’m not breaking my back outside to make a living. reply jl6 8 hours agoprevAnother way of putting it might be that there’s very little you can do to will yourself to be smarter, but you don’t have to go far out of your way to be kind. (Personally I’m not sure “kindness” is necessarily the right word that encompasses the four qualities listed. Resolutive? Seems like that’s something independent.) reply mjburgess 5 hours agoparentAnd, really, it's self-congratulatory. It says only, \"be like me, i'm great\". And in refusing to translate \"De tó sabe, pero de ná entiende\" -- how empathetic is the writer really? All together, it comes across a little smug. reply wseqyrku 15 minutes agoprevThat's not gonna work when people conflate team work with competition reply tomhoward 7 hours agoprevThe problem with content like this is it’s not realistically actionable for most people: it really amounts to saying (if you’re not already a temperamentally kind person), “fundamentally change your personality”, without offering actionable steps to accomplish that. It also doesn’t wrestle at all with the complexities and tradeoffs of how we deal with people in different scenarios. Be kind to bullies and assholes? There’s a way to do it, sure, but there’s a lot of technique and nuance involved, and this post doesn’t scratch the surface. reply steveBK123 7 hours agoprevRarely does one accomplish great things in life alone, or on the first try. Life is often a game of making sure you have enough at bats to eventually succeed. From a self interested utilitarian view, people will remember you warmly for being kind and be happy to work with you again / give you another shot, far more than they will if you are smart & difficult. Being incompetent and kind isn't my suggestion here. It is simply that if you are as smart and hard working as you think you are, it's not that hard to also be a little kind. If it is so hard for you, you may want to try working on it. reply laiqtzyx 8 hours agoprevThat is the ideal but the results depend on the work place or the OSS project. I have started out like that twice and was walked over by other people. Kindness with true reciprocity is very hard to find (I do not mean CoC compliant fake kindness that just keeps the actual power structures in place while everyone is backstabbing.) reply erikerikson 3 hours agoparentThis visits a hard coordination problem. I'd suggest the solution is coming and it will decentralize culture decisions the same way capitalism decentralized spending decisions. reply NickC25 3 hours agoprevDisagree with the title. What one should try to avoid being, is a dick. Help people improve. Point out their weaknesses and how they can improve, but get your ducks in a row beforehand - don't be a hypocrite. He who lives in a glass house and all that.... Have empathy, and understand your surroundings, as well as reading the room with context. Be direct with people, don't waste their time, but don't be rude or crass with them. Pleases and thank you's. If someone is falling behind at work, talk to them and understand why - don't just fire them (perhaps something outside of work that is serious is weighing them down - if that is the case tread with caution, and don't be so quick to make a decision that could cost you or your organization socially or fiscally down the road). If you must cut ties with someone, make sure you do so in a direct, honest and respectful way. If YOU were to be fired, how would you like to be treated? There's your baseline. Don't act like an HR drone trying to use flowery language around everyone. Be respectful of everyone as well as their time, and have a baseline level of professionalism that is applied to EVERYONE regardless if they are above or below you on the org chart. Every organization I've worked in, everyone from the janitor to the CEO got a \"good morning\" and a \"yes sir/no sir\" on a daily basis. Respect in life is earned, but there's a baseline of where it should be a given. Treat people with dignity. reply pcloadletter_ 2 hours agoparentNothing you mentioned here disagrees with the title or the article reply jasoneckert 8 hours agoprevWhile I think the points the author makes are sage advice, I think the blog post would have been a lot stronger against criticism if they had added a paragraph similar to the following: \"That is not to say you shouldn't come prepared and knowledgeable to meetings you attend. You should provide clear value to each and every meeting you attend from a knowledge perspective. However, the human value of kindness is far more important in the eyes of attendees.\" reply farmeroy 3 hours agoprevI really disagree with the quote at the end `just a few people are going to miss the smartest in the room, but everyone is going to miss someone kind.` This is true if the smartest person in the room is a jerk, but I don't find that to often be the case. In every group I've worked in, the smartest, most talented people are often _also_ confident in their abilities to the point where they don't have to _prove_ it to anyone. They help the team succeed. The people I am never sorry to see go are the insecure people with a chip on their shoulder who constantly try to prove that they are the smartest, most talented person in the room. They often are not. The kind or nice person, sure if they are some kind of glue to the team that helps the entire group work together, they don't need to be the highest performers. But incompetent nice people also are a problem. reply karaterobot 5 hours agoprevI agree that if you want to persuade people and be successful in the business world, being the smartest person in the room isn't the most important quality. Being the loudest and most confident is. Just say your opinions as though they are obvious facts, and if someone disagrees, ignore them and say your thing again with even more confidence. I do not do this—heaven forbid, I'm too kind to do that—but it's the characteristic I see most successful people sharing... if success is defined as organizational prominence and compensation, rather than more trivial heuristics like a history of your claims coinciding with reality. reply doubloon 4 hours agoprev\"Being nice is the new punk\" yes, this is a huge adjustment for me as old Gen X trying to work with Gen Z / Millenials. I feel like Michael Scott sometimes to be honest... raised in an environment where bigoted jokes, brutal insults, shouting, were the norm and expected, adjusting to being around the new generation which was raised on anti-bullying and therapy. I am glad things are changing, the old ways were very dysfunctional and counterproductive. Maybe its just the lead poisoning. reply zackmorris 3 hours agoparentGlad to see that kindness is finally going viral. I'm Gen X, raised feral like the rest. Movies like The Lost Boys, The Goonies and Explorers feel like biographies. We were vicious to one another before the arrival of political correctness in the early 90s, which received backlash like today's woke. But kindness is always on the right side of history. I agree though about feeling like some kind of crassaround young people today. I have a hard time staying domesticated as I watch society crumble under the guise of gentrification. I just want to act out so badly sometimes, deface something, watch it all burn like the good old days, SLC Punk style. But the real punk is to be ruthlessly human to one another. There's a certain thrill in sacrificing one's ego to help someone achieve their dreams that just can't be replaced. The biggest baddasses are teachers, nurses, your mom, and everyone knows it. reply eleveriven 44 minutes agoprevPrioritizing kindness and empathy over showcasing intelligence. Sometimes it is smarter to be kind reply pcloadletter_ 6 hours agoprevSome people here are confused. Kindness towards people doesn't preclude you from being assertive. It doesn't preclude you from being a shrewd negotiator. It doesn't preclude you from provide feedback to an employee who needs to improve performance. It doesn't preclude you from laying off an employee. reply mirekrusin 8 hours agoprevBeing too kind can also be negative, I prefer honesty and reality above the rest. reply wesselbindt 8 hours agoparentI too think that being too x, where x is any adjective, is a bad thing. I much prefer people being just the right amount of y, where y is any adjective. reply erikerikson 3 hours agoparentprevThis seems to misunderstand kind Kindness reduces barriers to accepting the honest truth and is thus part of maximizing honesty and realism. reply makeitdouble 8 hours agoparentprevYou could say that hiding or refraining from giving critical feedback is not kindness. reply Kalium 6 hours agorootparentThis article readily conflates niceness and kindness. It would be very easy to read this and take away the understanding that critical feedback that leaves a person feeling in any way negative is not kindness. reply mirekrusin 8 hours agorootparentprevIf this phrase can mean anything, it doesn't mean anything anymore. Ie. you could also say that egoism is being kind to yourself etc. reply makeitdouble 6 hours agorootparentI see \"being kind\" as towards others in the context of this discussion. If I feel I'm doing a disservice to the person by not speaking up, but still stay silent because I don't want to be confrontational or harsh, I don't think I'm being kind to the person. I'm only protecting the relation or myself, as I don't have the tools or a path to convey helpful information while making clear I'm having the person's good in mind. I see it as a failure in communication (it usually can be blamed on both parties), and clearly not a character quality. reply mirekrusin 6 hours agorootparentI can also argue that \"being smart\" means I recognize feelings of others, because not doing it is stupid - so that implies kindness. reply wtetzner 7 hours agorootparentprevI interpreted it to mean that lying to someone isn't actually being kind, even if that was the intention. reply mrfinn 6 hours agoparentprevHonesty doesn't conflict in any way with kindness, but with being \"nice\". Actually I think is a requirement of being genuinely kind. reply mirekrusin 1 hour agorootparentBeing smart also doesn't conflict with kindness - if anything, they go together. reply ricardo81 7 hours agoprevSeems like good common sense. Listen, be respectful, keep an open mind. To be fair does it not depend on the audience. There's a balance between the audience and an idea you want to push. Here in YC you can probably go full on with your tech/science knowledge/ideas/theories/whatever and people will judge you purely on your points made, and the people listening are in the same boat. In another context you may be the smartest person in the room by a long way on a topic and have something constructive to say, but no one else in the room is as competent so you cannot go full on with your YC-like comment and have to balance the knowledge/empathy available of the audience. I guess in the end it's about ignorance busting and offering some new insights into a thing that other people can appreciate. reply tpmoney 7 hours agoparent>Here in YC you can probably go full on with your tech/science knowledge/ideas/theories/whatever and people will judge you purely on your points made, and the people listening are in the same boat. I would disagree with this, even here it is important to be kind. Too often I find the comments on a given thread are full of self importance or worse disdain for the \"shortcomings\" of the topic in question. Whether or not that disdain might be due to a wealth of knowledge and experience, it brings the general experience of being here down, and in my opinion lowers the quality of the site and the person doing the disdaining. I'm not asking for fawning over every submission like it is a new revelation, but the adage that \"if you can't say anything nice, don't say anything at all\" springs to mind. HN is going to be full of people from differing experiences and walks of life. Tech is too big now for us to all be on the same page, or even within the same general age range. When someone drops a \"Show HN\" link to some hobby or passion project of theirs, and the comments are full of \"experienced\" people critiquing the project as if it were supposed to be a google scale web service or even as if it needed to be a viable commercial product – no matter how correct those assessments may be – that's damaging to our shared sense of community. My own philosophy over time has been to only offer critique if it is also accompanied by my own efforts at providing what solutions I can directly (code, documentation whatever). If it bothers me enough to think I should say something, then it should bother me enough to also put in the effort to be/submit the change I want to see. Anything less is at best a piling on of cheap criticism (\"cheap\" in this case in the sense of \"a dime a dozen\"), and at worst unkindness for the sake of showing off knowledge. Absent something to contribute beyond criticism / critique, the goal I set for myself is either to engage with the subject and the creator on the assumption of earnest passion for the project, or if I'm disinterested for whatever reason, to not engage at all. I definitely don't always succeed in this endeavor, but over the decades I've grown increasingly tired of the airs of cynicism that permeates the \"smart\" spaces I've been in. Be kind in all audiences, whether peers, betters or lay people and you will usually avoid being pretentious, confidently incorrect or condescending respectively. And those are 3 things I think we could do with less of in most communities. reply ricardo81 6 hours agorootparentI can't disagree with your philosophy and think you have a well considered approach to it. When it comes to social etiquette, empathy, agreeableness, there are definitely a lot of people 'on the scale' around here and that's absolutely fine. There are smart well-balanced people and there's uber-smart people who know more than most about a thing but perhaps lack that social etiquette- and that's fine to me. If they can communicate their point, I don't mind so much their lack of grace on it. reply erikerikson 3 hours agorootparentThe point isn't that we should be anyone other than ourselves. We can only be ourselves and we are out best version when comfortable with that. It's simply that learning to express ourselves with kindness and understand the importance of it will make us even more effective. At least being formerly graceless and continuing to develop grace, that has been my experience. reply ricardo81 1 hour agorootparentWhile I can't disagree with your general candour, you might find that I will challenge you on anything else :-) There it is, the allowance to do so. reply yobbo 2 hours agoprevThe reason people sometimes need to be \"unkind\" is to prevent some cost from being incurred. (Another conceivable reason is personality disorders, but let's assume normal healthy people.) For normal healthy people, kindness is the default state when it is free. When there are costs, it becomes a luxury only some people can afford. reply bjornsing 5 hours agoprevTo be honest I’ve come to see these posts as part of the “war”. If you’re not very smart, what’s your best move? Change the rules. Now you can be the most noteworthy person in the room, by being the kindest. With that said, of course you should be kind. But don’t be afraid to be smart too. The world needs smart. reply mehulashah 7 hours agoprevI’m wondering if this is really about life and not just meetings. Meetings are really about getting things done. The kindest act is to not have the meeting if it’s unnecessary. And if it is, outline what you want to get out of it at the start. During the meeting, yes, you should be kind. reply clarkdale 7 hours agoprev\"Being nice is the new punk\" I would say helping others is incredibly punk. Such as responding to chat messages requesting help in some particular coding problem. So many people will direct them to a support queue, but I love taking time to understand their issue and help them out. reply detourdog 5 hours agoparentWhat is interesting about that is the an aspect of original punkers was a desire for respect as individuals. The come as you are was very welcoming. The repulsionist look I saw as an attempt to see only inner beauty in humans. Punk was the reaction of the individual vs. the global machine. The global machine’s surface is nice but the machine is not kind. reply HideousKojima 4 hours agoparentprevI direct my coworkers to the documentation that I wrote and that they clearly never read, despite my providing it to them repeatedly in the past and despite my anticipating their exact questions/issues in it. reply elric 7 hours agoprevLearning not to take everything personally, and not being easily offended are two valuable life skills. I've come to value intent much more than when I was younger. \"Did they ignore me because they're mean, or were they simply too distracted to say hello?\" I struggle with being \"kind\" when under pressure. I don't mean to be unkind, but it can seem that way. People who don't know me well sometimes get offended by that. People who know me a little better don't get offended, they know I'll be more approachable when the deed is done (whatever the deed may be). It's ok to be a hedgehog sometimes. Not being kind sometimes is ok. Just don't be mean, that's much more important. reply ziggy_star 8 hours agoprevNever judge a man until you've walked two full moons in his moccasins. bows Edit: OK well you guys two full moons have definitely not gone by since I've made this comment I'm starting to think y'all ain't as kind as you make yourselves out to be.. reply Xenoamorphous 7 hours agoprevAs I usually say, be competent, not competitive. No one likes the uber competitive guy who always tries to stand above the rest at all cost. Which, by the way, screams insecurity. reply ungamedplayer 7 hours agoparentWhenever I hear the term insecurity used in a derogatory manner the caller often feels that it mitigates understanding more deeply in this area. There are personality types that thrive on competition, they get renewed passion and commitment by having others also better themselves, this is not an ego or alpha complex, instead of the mental models they work in. Or we can just call them insecure and be done with it. reply Xenoamorphous 7 hours agorootparentDepends on how you define competitiveness. The one I’m referring to, the truly bad kind, is not just about trying to stand out, it also involves trying to put others down, as that helps their goal. Those also tend to be overly sensitive whilst also being insensitive to others. That, to me, screams insecurity (hence the over the top sensitivity). Also they couldn’t care less about others becoming better, actually they’d prefer if they don’t. And yeah, nobody likes those guys. reply detay 7 hours agoprevI come from a culture where being kind is understood like a weakness. Sadly, this is a double-edged sword on certain situations. reply langsoul-com 7 hours agoprevThe 4 points the author listed is not the same as being kind. Listening, Being respectful, Being empathetic, Being resolutive. reply zug_zug 7 hours agoprevHot take - all these articles (telling employees how to be) are crap for one simple reason: If the management chain wants X, they need to incentivize X. In my experience 9/10 times, then management chain claims they value some set of values abstractly - but what they really mean is \"Make me more money, and don't upset the order of things. There is no skill you can have in any quality that will ever make me think you should have my job or better.\" If the management chain values kindness, let them communicate that request, then prove it by promoting people on that trait rather than nepotism/beauty/years/profitability/whatever. reply jackschultz 7 hours agoprevIf you're looking for an intro to mindfulness and meditation, the practice of mettā [0] is a truly a great way to start, and frankly, end with as well. Commonly translated as \"loving-kindness\", applicable to the post, but even more simply as \"friendliness\" to yourself and others. It's crazy the feelings that can come when you sit, say, and feel the effect of phrases like \"may I/you be happy\", \"may I/you be at ease\". This isn't a game where we try to get points for being nice for an afterlife, but somewhat of a compounding way of looking at life and interactions with others. There are many quick start posts, but this is a good one [1] to follow along. Rob Burbea has many talks about mettā, and these [2] are a good intro series. [0] https://en.wikipedia.org/wiki/Maitr%C4%AB [1] https://www.mettainstitute.org/mettameditation.html [2] https://dharmaseed.org/retreats/1084/ reply contrarian1234 8 hours agoprevI think the advice given by the author is a bit simplistic and obvious, but not wrong. I just wouldn't sum it up as being \"kind\" As someone who works in a \"kind\" culture (Taiwan) - there is an infuriating flip side If everyone is constantly worried about being kind, it becomes very difficult for people to say \"unkind\" things. - It's hard for people to give you important critical feedback - People will not give their half baked thoughts (which are the start of good discussions), and only bring stuff up when it's already a problem - People have a complete inability to tell you \"Hey when you do that thing A and B, I really don't like that\" The end result is that people end up masking a bunch of stuff in an effort to be kind which results in - People having huge blow ups when things boil over - Insane amounts of office gossip and people saying shit behind each other's back (bc they can't say it to your face and resolve it) reply tpmoney 7 hours agoparentI wonder if the middle ground is when one needs to be \"unkind\" in words, they should be \"kind\" in action. I worked on a team that had been moved to a project, in part because that project was behind schedule, haphazard and under-staffed. In our first months we were often (and to my dismay) unkind in words without kind actions to follow through. All of our critiques were correct. All of them were important and needed to be addressed. All of them were real problems. And often the critiques were blunt for the sake of being clear to management. But being right didn't stop that unkindness from stinging the other teams that were there before us. We were resisted and drew quite a bit of (understandable) animosity from those other teams. When we changed tack (partially in response to realizing we were being unkind, partially because we'd finally built up the knowledge we needed to do so) and started accompanying critique with solutions or at a minimum viable demonstrations of the solution, things were received much better. We still said hard things, we still brought in half bakes thoughts. But because we were being kind in bringing more than criticism to the table, it was much more effective. reply bootcat 8 hours agoprevYou want to be smart to gather attention, you need to be kind to sustain attention and transform it into meaningful relationships ! reply glitchc 7 hours agoparentIt's work. It's not where I make friends. It's far more worthwhile to have meaningful relationships with your neighbours than your colleagues. reply gyrovagueGeist 1 hour agoprev- \"In this world, Elwood, you must be oh so smart or oh so pleasant.\" Well, for years I was smart. I recommend pleasant\" reply ketanmaheshwari 5 hours agoprevI personally think being fair trumps being kind / nice / smart. reply ttoinou 8 hours agoprevjust a few people are going to miss the smartest in the room, but everyone is going to miss someone kind How is the goal of having people miss you related to achieving business goals ? On the contrary if the smartest is able to produce a lot, people are going to miss him On that topic, I’d rather have people trying to not become offended for little things, seems easier than faking kindness for personal benefits reply madeofpalk 7 hours agoparentPeople don't like working with jerks. I don't. It's hard to achieve business goals if no one wants to work with each other. reply ttoinou 7 hours agorootparentThat’s your problem if you are offended too easily. They might not be jerks but you too sensible reply madeofpalk 4 hours agorootparentMaybe, maybe not. We're talking about hypothetical examples here. As the jerk, you might not think it is your fault, but it is your problem if you are the common thread between other people not wanting to engage with you to meet \"business objectives\". Generally, I think it's useful to reflect on how your behaviour impacts the work of yourself and others around you. Even if you want to be as utilitarian as possible, work happens better around people who get on better with each other. reply __s 7 hours agoparentprevIn general, the kindest people will be the ones who have the maturity to not be offended reply xchip 7 hours agorootparentHow is that related? reply __s 7 hours agorootparentMaybe you're right. Deleted my continuing stream of thought. I just woke up so not at my smartest reply watermelon0 7 hours agoparentprevThe idea is to be genuinely kind, not to fake it. reply ttoinou 7 hours agorootparentRight, Im just assuming this kind of idea would push someone to look for environment with kind people over productive ones reply DEADMINCE 6 hours agoprevFor most people, ego dominates and comes far ahead of empathy. reply spacecadet 7 hours agoprev4 day work work, 6 hour days, better pay, the freedom to spend as much time with the people you want, doing the things you want, without fear of financial ruin or bodily injury. Thats what workers want... not for the work place to replace their family. We do not need to be friends, I do not need to be nice to you. This whining comes from people who place work over all else and need work to be something other than it is. A means to an end. Now, I do not mean passion projects... I mean wage slavery work hell holes... My passion projects and companies are made up of people I trust, have verified their experience. We are nice to each 60% of the time- we understand the other 40% is necessary. We don't take it personally, we brush it off. We are mature professionals, not whiney day care adults. reply therobots927 7 hours agoparentI’m guessing you work at a startup where you are nice 60% of the time? And I’m also guessing your coworkers actually give a shit about the job vs just trying to game the FAANG compensation algorithm? reply spacecadet 6 hours agorootparentI run a co-op consulting group. reply therobots927 6 hours agorootparentVery cool concept! Is it software engineering focused, and do you have to invest in sales or marketing to get clients? reply spacecadet 4 hours agorootparentBasically, we all have specifics, I focus on RF/Wireless Security projects for government... so you can imagine the sales cycle... sometimes there is overlap and we work together. reply therobots927 2 hours agorootparentVery cool. One day I would like to become a data science / engineering consultant. And I can see the upside of building a co-op business. reply GenerocUsername 4 hours agoprevDisagree with title. reply sundang 5 hours agoprevOkay buddy, you focus on nursing those $20/hour offshore contracts and I'll focus on convincing management they're pound-foolish, focus on routing projects around you cleaning up your trash code. > I live in Cádiz, a sunny city in the South of Spain You know the kind of dev this is. Don't tell me you don't. They just LGTM'd their Spaniard colleague's incoherent PR that's going to get you paged in three days. reply mrfinn 5 hours agoprevTo be kind is one of my specialties. I firmly believe that it's a requirement of any human group so people collaborate at heart. Yes people can be productive anyway without any kindness, but if people really collaborate then they actually multiply their forces and the result is incredibly powerful. If people fight each other that energy is terribly wasted. reply tommica 7 hours agoprevI was very confused for a moment, as I misread the title as \"Do not try to be the smartest tv in the room\" reply omoikane 5 hours agoprev> \"Maestro Liendre: De tó sabe, pero de ná entiende.\" I don't really know (and don't want) to translate it I think it translates to \"knows everything, understands nothing\" or \"jack of all trades, master of none\". reply delta_p_delta_x 8 hours agoprevPolar opposite advice frequently posted here is How to Ask Questions the Smart Way: http://www.catb.org/~esr/faqs/smart-questions.html No single article on the internet has irritated me as much as this. Being a 'hacker' does not mean someone gets special privileges to be a scumbag. reply hnthrowaway0328 7 hours agoprevI'd say just do whatever you think is the best for yourself and take the consequene. reply philodeon 4 hours agoprevTo me, this article seems designed to train junior employees to be more exploitable by the tech sector’s psychopathic managerial class. reply globular-toast 4 hours agoprevPeople who try to be the smartest person in the room never are. The only thing I try to do in meetings is be helpful. Whether that's kind or not is not for me to decide. reply ransom1538 6 hours agoprevThe title was worded wrong, I think engineers (at least me), would make more sense out of: \"The world needs more good people, the world does not need more smart people.\" Engineers often confuse \"good people\" with \"smart people\". But they are not related at all. And no, we don't need more smart people optimizing ads. We need more good people helping. reply newsclues 7 hours agoprevRather than try to be the smartest in the room, I try to learn from the smartest person in the room, but when I find I’m the smartest i start looking for a room with smarter people to learn from. Some people can teach others or be the smartest in the room, but I’ve not found those to be as rewarding. I like the challenge of getting to the top more than I do sitting at the peak. reply orangesite 7 hours agoprevListening is indeed the hardest thing to do if your organization's metrics places immense pressure on you to be (or at least appear to be) the smartest person in the room. Luckily there are other organizations out there that encourage kindness rather than penalizing it. Only catch is, you probably won't make it through the first interview if you don't start practicing being kind right where you are. Soft skills are hard and take sustained effort to internalize. reply getlawgdon 5 hours agoprevMore coastal exceptionalism throughout the comments. Wait until you find out how superior Chicago is. reply xchip 7 hours agoprevThanks for schooling us. reply neilv 7 hours agoprevI think one of the difficulties is that someone can, say, adopt this \"The Kind Framework\", and appear aligned on values and awarenesses with someone who appears the same way. Then the second person is blindsided when the first person goes and does something utterly selfish, as soon as the opportunity presents itself. And the first person is baffled that anyone wouldn't expect someone to do that, since they assume anyone would do the selfish thing. And they still think of themselves as a kind person. Where their definition of kind is presenting a certain vibe exterior. I call the first person a \"sunny sociopath\", after characters we'd often see in TV shows set in California. reply throwaway22032 7 hours agoprevNice guys finish last. There's not being a dick, and then there's being a doormat. You don't want to be close to either of those extremes. reply xiaodai 8 hours agoprevwhy try? just be reply demondemidi 4 hours agoprevThis is another way of saying \"behavioral skills matter\". Doesn't matter how smart you are, if you're an complete asshole you will find a lot of paths closed off to you. I'm really glad this generation is rejecting the notion that you have to be toxic to succeed. It's such bullshit. reply mycologos 8 hours agoprevNo, please, I come to Hacker News to get away from platitudinous, short, vague LinkedIn advice. reply user90131313 7 hours agoprevI was so kind at all YC meetings and in other places. That's how got one of the biggest funding and investor attention. That's how it works, right? Did you know that Steve Jobs was so kind so Apple fired him. Also Elon is kind and all founders just kind. etc. Great content reply ant6n 7 hours agoparentSarcasm is definitely the road to success! (Oh shit) reply jorgegalindo 10 hours agoprev [–] In my latest blog post, I highlight the value of kindness over intelligence in the workplace. I talk about how being kind—through listening, respecting others, showing empathy, and focusing on solutions—can significantly enhance team dynamics and productivity. While being smart is important, I believe that kindness leaves a lasting impact and creates a more positive and effective work environment. reply ttoinou 8 hours agoparentListening and focusing on solutions is being smart though. If you’re only looking for people who are ‘respecting you’ and ‘show empathy’ you might not find competent people with whom you’re gonna produce useful things to trade with the rest of society reply Spooky23 8 hours agoparentprevI’d go further and assert that kindness usually aligns with intelligence. Demonstrating that you’re the smartest guy in the room is an ape-like expression of dominance. The IQ is a distant second. reply boopmaster 8 hours agoparentprevhow is focusing on solutions a kind act? reply HeatrayEnjoyer 7 hours agoparentprev [–] Those actually do sound like smartness. Emotional intelligence is as important as any other. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "Emphasizing kindness over intelligence can improve team dynamics and productivity through listening, respect, empathy, and problem-solving.",
      "Kindness creates a lasting impact and fosters a positive work environment, which is crucial for long-term success.",
      "While intelligence is important, the benefits of kindness in a professional setting should not be underestimated."
    ],
    "points": 349,
    "commentCount": 214,
    "retryCount": 0,
    "time": 1718533643
  },
  {
    "id": 40696992,
    "title": "NLRB judge declares non-compete clause is an unfair labor practice",
    "originLink": "https://www.nlrbedge.com/p/in-first-case-of-its-kind-nlrb-judge",
    "originBody": "Share this post In First Case of its Kind, NLRB Judge Declares Non-Compete Clause Is an Unfair Labor Practice www.nlrbedge.com Copy link Facebook Email Note Other Discover more from NLRB Edge NLRB legal developments and commentary. Over 10,000 subscribers Subscribe Continue reading Sign in In First Case of its Kind, NLRB Judge Declares Non-Compete Clause Is an Unfair Labor Practice Coworker non-solicitation clauses also declared illegal for first time ever. Matt Bruenig Jun 14, 2024 11 Share this post In First Case of its Kind, NLRB Judge Declares Non-Compete Clause Is an Unfair Labor Practice www.nlrbedge.com Copy link Facebook Email Note Other Share Administrative Law Judge (ALJ) Sarah Karpinen issued her decision in J.O. Mory, Inc. yesterday. The case mostly revolves around an employer firing a union organizer that became employed at the company with the goal of organizing his coworkers (also known as “salting”). The union salt in this case lied about his employment history to get hired, declared he was a union organizer after being hired, and then was fired. Salting is protected activity, lying about your employment history to salt is also protected activity, and firing someone for salting is an unfair labor practice. Thus, Judge Karpinen ordered that the employer rehire the salt with backpay. As part of litigating this case, the General Counsel (GC) of the National Labor Relations Board (NLRB) also alleged that the employer’s non-compete clause and coworker non-solicitation clause were illegal work rules under the Stericycle standard. The GC has been pursuing this particular legal theory since early last year, but this is the first time the theory has been put in front of an ALJ and also the first time an ALJ has ruled that these kinds of clauses are unfair labor practices that violate the National Labor Relations Act (NLRA). NLRB Edge is a reader-supported publication. To receive new posts and support my work, consider becoming a free or paid subscriber. Subscribe Non-Compete Clause The non-compete clause in question states that: (A) For a period of twelve (12) months following termination or separation of employment for any reason, Employee will not directly or indirectly, on Employee's behalf or on behalf of others: … (iii) Engage in, be employed by, or become interested in, in any manner or capacity, as a principal, agent, partner, officer, director, employee, consultant, independent contractor, advisor or in any other capacity, with any insurance agency, insurance business or in any other business similar or competitive with Employer’s business as the same may exist at any time during the term of this Agreement, this covenant restricting Employee’s employment being limited to Employer’s service area which is defined as the county of the office where the Employee is located and to all contiguous counties thereto. If, during Employee’s employment, Employee is employed in any other of Employer’s locations, then these restrictions shall also apply to the county in which such office is located, and to all contiguous counties to that location. The parties expressly agree that the restrictions above set forth are fair and reasonable with regard to scope, time periods, geographic area and in all other respects. The ALJ determined that this clause was illegal with the following reasoning: The non-compete provision in Provision 2(A) is overly broad in scope and would deter a reasonable employee from engaging in protected activity by barring employees from directly or indirectly, and in any capacity, engaging in, being employed by, or becoming interested in any enterprise that is “similar or competitive” to the employer’s business. Not only is this provision ridiculously broad in scope (could an employee indirectly engage with a competitor by sending a family member to buy something from its store?), but it would also cause a reasonable employee to refrain from engaging in protected activities that come with a risk of retaliation. If an employee knows they are barred from being involved in any capacity with any company that operates a similar business to Respondent, they will logically be more fearful of being fired and less willing to rock the boat because they face the prospect of being unable to find any work in their geographic area if they are fired or forced to leave their job. Coworker Non-Solicitation Clause The coworker non-solicitation clause in question states that: (C) During the term of this Agreement and for a period of 24 months after termination of employment for any reason, Employee will not, either directly or indirectly for himself or on behalf of others, solicit, encourage, or attempt to persuade any other employee of Employer to leave the employ of Employer. This is intended to prevent “pirating” of Employer employees. The ALJ determined that this clause was illegal with the following reasoning: The prohibition in Provision 1(C) on soliciting employees to leave Respondent’s employ would dissuade a reasonable employee from engaging in protected activity like telling their coworkers about the wages and benefits offered by the Union out of a reasonable fear that Respondent might accuse them of inducing other employees to quit. See M.J. Mechanical Services, 325 NLRB 1098, 1106 (1998) (telling employees about union benefits, encouraging them to engage in salting activities, and referring them to union hall protected even when it resulted in one employee going to work for a union contractor). It may also deter employees from asking their coworkers to make a concerted threat to quit unless their working conditions improve. See Morgan Corp., 371 NLRB No. 142, slip op. at 5 (2022) (employee who told supervisor that he and his co-workers would quit over demand for higher wages was “indisputably” engaged in protected concerted activity). Despite all the discussion about the FTC banning non-competes, there still seems to be little recognition that non-competes for non-supervisory workers are effectively impossible to enforce at the moment due to the policies of the NLRB GC. Subscribe to NLRB Edge By Matt Bruenig · Hundreds of paid subscribers NLRB legal developments and commentary. Subscribe Error 11 Share this post In First Case of its Kind, NLRB Judge Declares Non-Compete Clause Is an Unfair Labor Practice www.nlrbedge.com Copy link Facebook Email Note Other Share",
    "commentLink": "https://news.ycombinator.com/item?id=40696992",
    "commentBody": "NLRB judge declares non-compete clause is an unfair labor practice (nlrbedge.com)339 points by lalaland1125 7 hours agohidepastfavorite196 comments giantg2 5 hours agoThat non-solicitation clause is interesting. My company forbids managers from providing references for employees. I wonder if that could also be considered an unfair labor practice since it negatively affect your ability to get a different job. Honestly, I'm starting to see that my company is doing a lot of shady employment things. I guess most companies do. reply ivan_gammel 4 hours agoparentIt should be unfair labor practice. Also, what does it achieve? It is not going to increase retention significantly, on the contrary, they will likely get lower eNPS. By the way in Germany employers are legally obliged to provide a reference (Arbeitszeugnis). Most of them that I have seen were too positive and sometimes obviously exaggerated. reply vessenes 1 hour agorootparentThere’s a complex balance of power in the US (and Germany) around these. A common reason companies ban references is to protect the company (and occasionally employee >Asking the person, \"Would you rehire this person?\" or \"Would you like to work with this person?\" has a 95% answer rate and says everything I don't know of any company in the UK that would ever answer such a question, maybe a small shop that hasn't learnt better yet. Companies will provide references that always just say \"this person has worked here for X years\", no one would ever say anything either positive or negative. reply ivalm 18 minutes agorootparentIf you ask HR then that’s the answer, if you ask employees they will give you a pretty useful reference (having done reference calls quite a bit, basically from folks at every major US tech company). reply amanaplanacanal 2 hours agorootparentprevBefore I retired (in the US), that was the policy where I worked. reply crazygringo 3 hours agorootparentprevWhat country are you in and what type of job? In the US at the corporate level, this would be extremely unusual. Not to mention how is it even useful? It's the easiest thing in the world to fake by passing along the phone number of a friend claiming to be a co-worker and full of effusive praise for you. It's not like most companies list the phone numbers of their employees somewhere publicly that you could verify. Decades ago when I was a bartender, it was common practice for your \"reference\" to be a buddy who would pretend to be the manager at your last restaurant. reply koolba 2 hours agorootparent> Decades ago when I was a bartender, it was common practice for your \"reference\" to be a buddy who would pretend to be the manager at your last restaurant. There’s a great clip of an Aussie radio show doing a prank like this. They call a random guy up and pretend that they have his number as a reference, and that he’s gonna get a call from some potential employer (who are considering g higher if the prankster). The random guy immediately agrees to say only great things about him and then the actual “reference call” is actually well done. https://twistedsifter.com/videos/hamish-and-andy-random-job-... reply SoftTalker 4 hours agorootparentprevMostly no, because almost no employer will provide them. reply BenFranklin100 5 hours agorootparentprev— reply Ar-Curunir 5 hours agorootparentYou’re a different person than the OP… reply BenFranklin100 5 hours agoparentprevThe reason this is done is that litigious ex-employees might try and sue for defamation. Even if the lawsuit is scurrilous, it will cost a company $20-30K to defend itself, so many companies have decided it’s not worth the risk. reply giantg2 5 hours agorootparentI can see why HR won't provide performance references. But I'm talking about if I'm a star employee and want to leave, I ask my boss if they'll write me a recommendation letter or if I can list them as a positive reference on my apps, they aren't allowed to by the company and may even get fired for it. reply BenFranklin100 5 hours agorootparentThat’s what I am talking about too. Companies don’t allow any sort of references of former employees, positive or otherwise, and from any level of management. It’s too hard to police and much simpler to just not allow the practice. It’s frustrating from the employee and prospectus employer perspective, but I see why companies do this. Bad apples can be very time-consuming and expensive to deal with. reply ghaff 1 hour agorootparentI've provided references from former co-workers, clients, etc. Never from an actual manager. Also no idea if references have ever been checked or not--especially given I knew a lot of folks at the hiring company. reply giantg2 4 hours agorootparentprevThere's no valid reason for it though. Hand me a letter of recommendation and if I don't like it, I simply won't share it with the next employer. If I'm the one who has the decision to share the recommendation, the responsibility should be on me. reply mattmaroon 4 hours agorootparentHe is explaining to you the valid reason, and you are simply not understanding it. People sue, very often, even in spots where the responsibility should have been on them. Companies stopped doing these sorts of things because companies got sued. It is very easy to bring a lawsuit, And while it is, perhaps not very easy to win it, someone still can easily have six figures in defending themselves. If you don’t like that, OK, I don’t either, it is awful. But it is a rational response to a problem that happens. reply giantg2 4 hours agorootparent\"He is explaining to you the valid reason, and you are simply not understanding it.\" Oh I understand it. But do you see the big picture here? People should be sueing for them not writing the letter. The NLRB should be taking cases for this as well. This is almost as anticompetitive as non-competes. Edit: shouldn't have said for not writing the letter, just for a policy forbidding the writing of letters. reply JumpCrisscross 53 minutes agorootparent> People should be sueing for them not writing the letter This gets awfully close to compelled speech. The only way this could be done is if we remove the right for employees to sue in respect of the content of the letter, which in turn opens up avenues for retaliation. Written recommendations are bullshit. The ban should be on requesting them. reply nickff 4 hours agorootparentprevWhat law would this policy violate? What’s the basis for the suit? That you think it might be anti-competitive because it reduces labor mobility? reply giantg2 3 hours agorootparentBased on the article, it seems that this could be reasonable to pursue. You don't need to break a law for a lawsuit, just show damages resulting from another's actions. If you convince the NLRB or a jury that not providing references suppress your ability to get a job or increase your salary at the next job, that could be all that is needed. But this would be applicable to laws on anticompetitive behavior, but that's more of an NLRB thing. reply sbuttgereit 3 hours agorootparentprevAlso consider this case. A manager writes a couple of glowing letters of recommendations for a couple of former employees that did great on the job. Wonderful. Now a poor performer asks and the manager doesn't feel comfortable writing a recommendation at all: either they'd risk having to be candid or there's simply no basis for \"recommendation\" and so the manager refuses. Well, now even the omission/refusal to write such a letter might get you sued. A policy that says our managers just don't write such letters is absolutely the safest. 1) the company and its managers don't identify in any way their thoughts on performance in a way that might be found prejudicial; 2) they avoid the risk of a poorly worded recommendation that could be called prejudicial; 3) they avoid having to monitor the standards and risks of such statements across possibly many managers that might write such letters absent such a rule. reply giantg2 3 hours agorootparentYou forgot the biggest benefits to the company - increased retention rates and salary suppression. reply winstonewert 4 hours agorootparentprevBut what if you get a bad letter of recommendation and sue about it? What if the manager refuses to write you a letter of recommendation and you sue them? The easiest solution from the company is simple: don't allow any letters of recommendation. That is what my former manager told me when I left my previous employer. He thought highly of my skills, but couldn't write me a letter due to company policy motivated by these concerns about being sued. reply giantg2 4 hours agorootparentWhat if I sue and have the NLRB open a case against them for the unfair, anti-trust labor practice of not allowing any letters to be written? reply crazygringo 4 hours agorootparentYou'll lose because it isn't unfair or anti-trust. It's not nice, but there's nothing illegal about it. The first amendment is widely interpreted to mean that you can't compel speech. Requiring a company to write recommendation letters would be compelling speech. That would be unconstitutional. (And it doesn't matter if an individual manager would like to write a letter of recommendation but corporate policy is against it. The manager is paid by the company, would be sharing company information, and is an agent of the company in this regard.) reply kedean 3 hours agorootparent> Requiring a company to write recommendation letters would be compelling speech It would, but that's not what's being discussed. The accusation is that the companies are restricting speech by saying that managers cannot provide a reference, even if they clearly state in said reference that the views are their own and not that of their employer. Nobody is trying to compel anyone else to provide a reference, the idea is that nobody should be prohibited from it, especially since for long term employees leaving on good terms their manager(s) is/are probably one of their best references. reply crazygringo 2 hours agorootparentCompanies are allowed to restrict speech by their employees about company information. Otherwise everyone would be allowed to leak every trade secret. A manager's evaluation of another employee's performance is internal company information. There's no reason that a company should be compelled to share that information externally. It doesn't matter if the manager wants to share it, any more than the manager wants to share all the source code the employee has written. Companies are allowed to determine what gets shared by their current employees, end of story. On the other hand, it is unconstitutional for the government to override that. There are exceptions for things like public companies that are compelled to release certain data on a quarterly basis in exchange for the benefits of being publicly traded. And plenty of information can be compelled to be shared privately with the government, whether taxes or for health inspections or whatever. But absolutely not forcing companies to allow their employees to talk publicly about other employees' performance. reply SpicyLemonZest 3 hours agorootparentprevManagers and supervisors are not protected by the NLRA, so whether they might like to provide a reference isn't really a matter of concern for the NLRB. (In practice, managers provide references informally all the time, and I can't imagine a company actually taking action against them for that unless the reference causes some huge problem.) reply ivan_gammel 4 hours agorootparentprev>But what if you get a bad letter of recommendation and sue about it? This is trivial to solve: both former employer and employee sign the letter, declaring that information in it is full, correct and they have no objections. It would be much harder to sue if you previously agreed that the letter is ok for you. reply WalterBright 2 hours agorootparentA negotiated letter is worthless. reply BenFranklin100 4 hours agorootparentprevThis is an example of how labor laws can hurt high-performing employees. Another is salary transparency requirements. reply giantg2 4 hours agorootparentBut there isn't a labor law supporting that. It's simply an anticompetitive corporate policy. reply BenFranklin100 4 hours agorootparent‘Established case law” or ‘Legal precedence’ to be more precise. Thank you. Ex-employees do have generous legal ground to sue for defamation. Edit: and remember, this is to file a suit, not win a defamation suit, which can be difficult. However it is very expensive for an employer to defend itself, easily tens of thousands if not six figures of dollars. How the game is played is a disgruntled ex-employee files a suit and then tries to settle for low tens of thousands of dollars, a portion of which goes to the employment attorney they hired. reply dec0dedab0de 4 hours agorootparentprevthere is no way to verify that’s real though. Anyone could have a friend write a letter for them and say it’s from an old boss. when you have current employees talking about former employees on behalf of the company, that is the same thing as the company talking about them. reply giantg2 4 hours agorootparentYou could call to confirm it, have it notarized, etc. But that's not really an issue since this practice used to be common and is sill common in many forms of employment today - some government jobs, academia, etc. I don't see it as the same as the company speaking. Things like concerted efforts by the workers to make conditions better are protected and not considered company speech. I guess it's only because they're managers that they don't qualify. reply SoftTalker 4 hours agorootparentprevMost companies will only verify dates of employment, and possibly whether the employee is eligible for rehire (yes/no, without getting into reasons). Writing a letter of reference is more and more a risky thing and even in non-employment situations, more people are reluctant to do it. reply ska 3 hours agorootparentThat’s what HR will do. Most companies don’t constrain an individual employee from providing a recommendation. People might not want to do it, but that’s a different issue. reply pjc50 3 hours agorootparentprevSo .. have they stopped asking for them? Or it this a \"We'll defect in prisoner's dilemma with no consequences to us\" move? reply nickff 5 hours agorootparentprevSomeone might sue because (they think) a letter wasn’t effusive enough to get them a job they wanted, or because someone else got a letter and they didn’t. reply giantg2 4 hours agorootparentAnd why can't I sue for this being an unfair labor practice? There should be more risk on this side of it than the other. reply mattmaroon 4 hours agorootparentIt is not an unfair labor practice, nobody owes you a letter of recommendation. Corporations that have this policy always tell you that when you check on a prospective employee. “ Our policy is only to give dates of employment and X worked here from…” It is not a negative when you check on somebody and hear that. I’ve heard it many times. I can hardly take it as a sign of a bad employee when their company simply has a policy not to give references reply giantg2 4 hours agorootparentThey don't have to owe you something for it to be unfair. It's anticompetitive behavior that makes getting another job harder. It's fine if they don't write you a letter. What isn't fine is a policy that forbids the writing of letters. reply crazygringo 4 hours agorootparentIt's not really anticompetitive though. It doesn't make getting another job harder because virtually nobody is getting references. Everyone's on the same playing field here. Letters of recommendations, or even reference phone calls, are something that are widespread in academia and in entry-level service jobs. Like if you want to be a server or bartender, they want to make sure you were actually showing up at your last job and didn't steal money from the register. They're not really a thing in the corporate world. Your technical expertise, certifications, and dates of employment pretty much speak for themselves. At least in the US. reply giantg2 2 hours agorootparentThere are some people getting references. Most places also ask for references. Informally, all the people talking about jobs found via their network are references. It is absolutely harder finding a job without references than with references. You also have less leverage for negotiating salary. \"Your technical expertise, certifications, and dates of employment pretty much speak for themselves.\" This isn't true at all. Why do interviews if you just make the decision off the resume? Why do code screens or LeetCode? I have tons of experience and a long tenure, a masters degree, multiple certs, etc yet I'm a low performer with a disability who struggles to even get interviews. But you wouldn't know that by looking at my resume. At one point I was a high performer and a letter of recommendation could have really helped me. reply crazygringo 2 hours agorootparentI never said make a decision off of a resume. When I said \"your technical expertise\", I meant as assessed by interviews, code screens, etc. I've never even been asked for references at any technical job in my life. HR departments generally do make some attempt at verifying employment, doing a background check, etc. So no, in these cases it's not harder. There's no leverage either way. Because what do reference letters even mean? How do you know the person writing the letter is even telling the truth? This is somebody you've never met and don't know at all. How do you know they don't unfairly hold a grudge against this ex-employee because they took it personally when they quit? Or how do you know they don't just write glowing references for everyone because they know \"it's tough out there\" and \"everyone deserves a second chance\"? I always assumed this is why I've never been asked for references in my professional career, because the companies I applied to knew that references aren't worth the paper they're written on. reply AdrianB1 4 hours agorootparentprev> nobody owes you a letter of recommendation It some countries they do. A friend sued his former employer because the letter of recommendation he got was not good enough. Strange thing is they agreed and also contacted him to come back working for them. But it depends on the country, in some countries letters of recommendation are very rare, I wrote a couple in more than 20 years, basically every time someone that worked for or with me asked for one. reply winstonewert 4 hours agorootparentprevI suspect it's much easier for someone to sue on the claim of being unfairly discriminated against than on the claim that a particular company policy with a legitimate stated justification is an unfair labor practice. reply giantg2 4 hours agorootparentJust because there's a justification doesn't make it an excuse to participate in anticompetitive behavior. The NLRB getting involved seems like a bigger risk than the letter of recommendation. reply winstonewert 4 hours agorootparentYou are wrong. Since you show no signs of recognizing that, or providing any reason to back up your assertions, I'm done with this conversation. reply giantg2 2 hours agorootparent\"You are wrong. Since you show no signs of recognizing that, or providing any reason to back up your assertions, I'm done with this conversation.\" Lol ok. You realize I can say the exact same thing to you... reply winstonewert 1 hour agorootparentThe difference is that me and others have repeatedly explained why you are wrong in this thread, and you keep repeating the same nonsense assertions. reply segmondy 4 hours agorootparentprevCan you provide an example article or case law when this happened? reply lowbloodsugar 3 hours agorootparentprevAgain, that sounds like a good reason, but it’s not the reason, and it would be easy to solve. The reason is wage suppression. reply BeefySwain 6 hours agoprev> Salting is protected activity, lying about your employment history to salt is also protected activity, and firing someone for salting is an unfair labor practice. Huh... TIL reply Quanttek 5 hours agoparentThe idea is pretty easy: If an employer could simply ask you about past union activity (or activity indicating it, such as certain training) and then fire you for lying about your employment history when you omit it, then the protection for unions is effectively neutralized. Unlike what other commentators imply, this judgment doesn't legitimize just inventing degrees or qualifications. It's closer to omitting that 2-month job that didn't work out reply ketzu 5 hours agoparentprevI assume quite a few people think of one way of \"lying\" about employment history, that they have very strong feelings about how it should be handled. Like * Omitting (or denying) that you have done a certain activity (eg., union founding, working with PHP, that only-2-month job because it sucked). * Claiming (or adding) jobs or degrees that you have not worked at or earned, on your CV (e.g., claiming to have worked for microsoft for 4 years when you didn't). To me the first one seems clearly okay, but the second one not so much. reply n2d4 5 hours agorootparentPersonally, I think \"denying\" is also bad, while \"omitting\" is fine. Instead, I think it's more reasonable to have exceptions for certain protected activities, such as salting. It's in the same category as sexual orientation for me; employers should not be allowed to ask or make decisions based on it, so if you're asked as an employee, you shouldn't have any obligation to tell the truth. reply SoftTalker 4 hours agorootparentI agree omitting is usually OK especially if it's not relevant. Omitting entire jobs if the experience isn't particularly relevant (particularly if it was a long time ago) can be OK. I omit that I worked at McDonald's when I was 17 in the 1990s when I am applying for a job in 2024. But if there are gaps in employment history you might be asked about it, especially if it's recent. Something like fudging employment dates along with omitting some jobs to disguise that you are a job-hopper gets into a much more grey area. I was surprised to learn that lying about employment history to hide that you are a salter was protected. I get that salting might be protected, but did not expect that lying on an application would be. reply cool_dude85 2 hours agorootparent>I was surprised to learn that lying about employment history to hide that you are a salter was protected. I get that salting might be protected, but did not expect that lying on an application would be. Making it so the employer can fire you for lying about the application would practically remove protection for salting. Nobody would hire you for a non-union job if they see you being employed by a union as an organizer in your last job. reply AndrewKemendo 5 hours agoparentprevWe have had decades of worker suppression that lead people to think that it’s illegal to collectivize against your employer and it’s just not the case reply hn_throwaway_99 4 hours agorootparentI don't think that's what people were surprised about. Just speaking for myself, I was originally surprised by the statement \"lying about your employment history to salt is also protected activity\". After all, it's seems to make perfect sense that I can be fired for lying on my resume. The bit that I didn't understand, and that some of the comments here cleared up, is that only lying about the employment pieces that specifically relate to past work as a union organizer are the things that are protected activity. reply Izkata 4 hours agorootparentYes, salting in general is adding something. Sounds like inventing a job you didn't actually do is protected? Doesn't make sense. Missed that this is a jargon word that has a special unrelated meaning here. reply CoastalCoder 6 hours agoparentprevI'm curious what the logic is to justify lying about employment history in order to salt a union. My understanding was that you couldn't be penalized for organizing a union per se, but that didn't mean you couldn't be fired for other non-unionization-related reasons. It seems like this is going a step further: things that could get someone fired in completely union-unrelated situations, are actually protected if done in service of unionization? If so, where's the line? Can an organizer simply not show up for work and still collect a paycheck? Can they harangue the business' customers because their job requires access to the company's customer list? reply Xylakant 6 hours agorootparentIn Germany, there are certain kinds of questions that are not permissible on an employment questionnaire, for example asking whether a candidate is pregnant or plans on having children, union affiliation, etc. However, these questions are often included in the questionnaire and not answering them would provide sufficient signal to the employer and the only remedy would be to sue the employer. So it's explictly permitted to lie in the answer, rendering the questions useless. I expect a similar line of reasoning applying to this case: The question is about a protected, legal activity which is nonetheless undesirable for certain employers. Asking the question and requiring a truthful answer would undermine the protected, legal activity. Hence an effective remedy is explicitly allowing to lie in the response. reply thegrim33 5 hours agorootparent> \"there are certain kinds of questions that are not permissible on an employment questionnaire\" .. \"these questions are often included in the questionnaire\". I don't follow. It's not permissible but these companies just blatantly ignore the law and ask it anyways? Or it is permissible? reply Xylakant 5 hours agorootparentThose companies ignore the law - knowing that a candidate could sue, but then they would remove the canditate from the pool for any unrelated reason. A union could sue on behalf of a candidate, but until the case is resolved, the questionnaire still stands. Allowing candidates to just fill in the expected answer, truthful or not, is an effective remedy - it renders the question useless as a signal for the employer. reply louiskottmann 4 hours agorootparentprevIt's not allowed, but you'd have to sue if you uncover one such questionnaire, which is a hassle. So instead, lying on your answer is not sue-able. Which makes including such questions ineffective. reply abhorrence 5 hours agorootparentprevPresumably they ignore the law. reply AdrianB1 4 hours agorootparentprevIn most of Europe there is no notion of punitive damages in a law suit. That means if you sue that company they will fix the questionnaire with no other consequences. 3 months later they can put it back, also without consequences. Suing them can be costly, so most people will not bother. There is zero reward for doing it, as a candidate you waste time and money with no net return. All negatives and no positives. So with very little risk, they do it. reply lazide 1 hour agorootparentprevIt renders the questions useless against experienced candidates, but not against naive or ignorant ones. So it still has value to employers. The best remedy to stop such things is a statutory ‘bounty’ for such activity - like the $2500 penalty for California employers for attempting to scare employees with unenforceable non-competes. reply alpinisme 6 hours agorootparentprevConsider the alternative where employers can fire you for lying about your employment history. Once you’ve done some union organizing, you’d be potentially unhireable. ETA: Here's the relevant part of the judicial decision in this case: > None of these employees [who were fired for lying and used to claim precedent in this case] are an appropriate comparator for McClure, who was never accused of stealing, violating traffic laws, or other criminal conduct. And, even if Respondent could show that the other employees were fired just for lying, and not for the underlying serious misconduct, Respondent could not use that to justify firing McClure because they were all accused of lying about conduct that Respondent could lawfully consider in hiring or firing them. In contrast, McClure lied about his history of working for union employers. Because Respondent could not refuse to hire McClure because of his union background, his lie about working for Deem can’t be used to justify firing him. reply ralferoo 6 hours agorootparentprev> I'm curious what the logic is to justify lying about employment history in order to salt a union. Being from outside the US, I'd never heard this term before, and actually in my country it's rare that you join a company and aren't given all the documentation by HR about what unions you can join on the first day. But anyway, when I googled this term, from the wikipedia article: > The tactic is often discussed in the United States because under US law unions may be prohibited from talking with workers in the workplace and salting is one of the few legal strategies that allow union organizers to talk with workers. It'd seem them that at least one reason why they might explicitly protect the right for union members to lie about their employment history when trying to join a company for the explicit reason of salting is that they would also be / have been an employee of a union, and disclosing that could well get them deselected from consideration for the role. Presumably the company will still be responsible for their own due diligence in checking that the potential hire had all the necessary qualifications to legally carry out the work, and might well discover the lie in that process. Presumably they could then also terminate the employee for that reason at that point because they couldn't actually legally carry out the job duties, but equally I'd imagine if they uncovered a lie which could be shown (presumably in court) to be for the purpose of salting, but they were otherwise legally able to perform the work, then the company couldn't fire them. reply ethbr1 4 hours agorootparentThe US tries to thread the needle between being \"pro management\" and \"pro labor\". Historically, the bargain that has been struck is that current employees have substantial protections around union organizing. However, outside unions have limited rights to directly solicit employees. That's at the federal level. At the state level, additional pro-union rights may layer on top of that (e.g. in the northeast) or not (e.g. in the southeast). Additionally, since you mentioned Germany, most US workers do not have a seat at the management table, in contrast to how I believe German companies are typically organized? reply 6510 5 hours agorootparentprev> in my country it's rare that you join a company and aren't given all the documentation by HR about what unions you can join on the first day. We have companies actively looking for an employee to represent the union. Few want the responsibilities. (hours are paid, activities take priority in the schedule) I imagine they most often end up with someone who cares about the company. reply dcre 6 hours agorootparentprevHere’s a case where calling the boss names is protected converted activity. https://www.nlrbedge.com/p/wall-street-journal-is-mad-at-wel... reply cess11 5 hours agorootparent\"In 1979, the NLRB issued its Atlantic Steel decision, which established the test for determining when an employee’s otherwise protected speech towards management becomes too extreme to remain protected. This standard considered: (1) the place of the discussion (2) the subject matter of the discussion (3) the nature of the employee’s outburst (4) whether the outburst was, in any way, provoked by an employer’s unfair labor practice.\" You should probably have added this for nuance, so people don't misunderstand you and get the idea that name calling per se is protected. reply ethbr1 4 hours agorootparent\"You fucking asshole... for prohibiting discussions of union organizing.\" reply jprete 5 hours agorootparentprevIANAL, but as far as I know, the line is \"intent\", and courts of law are empowered to infer intent from actions. > things that could get someone fired in completely union-unrelated situations, are actually protected if done in service of unionization? If you preferentially fire union organizers and preferentially ignore the infractions of non-union-members, then yes. reply nohuck13 6 hours agoparentprevIf lying about you employment history is a protected activity, then if a pre-employment background check catches you lying about your employment history, and you say \"no I am salting,\" that also is protection from having your offer rescinded? reply cess11 5 hours agorootparentIn court it would be tested whether your deceit is actually relevant to the salting. Faking an entire resume to get into a place where you can't do the work isn't likely to fly, hiding your time working for a union by claiming you did first line customer support might. reply scrapcode 6 hours agoparentprevThat seems absolutely ridiculous to me... what am I missing? I can lie about my work experience in order to infiltrate a business and form a union? reply spamizbad 6 hours agorootparentThe context here is salting so it would likely be omitting prior employment or education/training. I personally think this is completely reasonable in all cases. Non-salting example: over a decade ago I omitted an entire year of professional experience as a PHP developer when trying to get hired as a Python engineer, because I didn’t want to get pigeon-holed as “PHP dev who can maintain our crummy legacy PHP codebase nobody wants to touch”. Anyway it would be extremely problematic if employers were entitled to full and complete honesty from applicants but had no equivalent obligations from their side. If businesses had the choice they’d pick the status quo over mutual transparency. reply eterevsky 6 hours agorootparentI don't think omitting some of your old positions that you think are irrelevant amount to lying. reply spamizbad 5 hours agorootparentI lied about my potential value (by understating it) to an employer for (longer term) personal and professional gain. Going back to Union Salting: Often times the \"salt\" is a star employee; they're always on time, never say no to a job, pick up shifts nobody wants to take to ingratiate themselves both to management and their colleagues. They don't ask for raises and never complain to management. Their intention is to organize workers and so they want to be the sort of model employee a manager will keep around. The reason why this practice is allowed is because its illegal for unions to walk into an establishment and talk directly with employees about organizing while they're \"on the clock\" and on premise. reply cempaka 5 hours agorootparentprevThe parent didn't think they were irrelevant at all, they thought it might signal to the company that it could extract more value by assigning them work they didn't want to do. reply Drakim 6 hours agorootparentprevMaybe it's specifically in the context of unions and nothing else? If you lie about your work experience, it turns out you can't program Rust, then you can get fired for that. But if you lie about never having been part of a union before, and it turns out you have been part of a union before, then you can't get fired for that. reply scrapcode 6 hours agorootparentOkay - that makes a bit more sense, not having to list your involvement with a union. reply dartos 6 hours agorootparentprevWell, if you’re hired as a rust engineer and you don’t know rust, you’d be fired for not being able to fulfill your job duties. If you get fired for being part of a union, then you’re being fired for your political position. It’s not your fault for lying on the resume, it’s the hiring teams fault for not catching it reply seneca 5 hours agorootparent> It’s not your fault for lying on the resume, it’s the hiring teams fault for not catching it Anyone who ever complains about how ridiculous hiring interviews in software development have gotten should be referred to this comment. This is exactly why these absurd practices exist. Because people think they're entitled to lie, and it's your fault if you don't catch them. reply oooyay 5 hours agorootparentI've interviewed a lot of people over my career. I'm not sure \"entitlement\" is why the people who lie do so. Most of what I see people lie about isn't the companies they've worked at, it's the kind of work they do. For instance, when I was looking for a senior engineer I'd get people who said they did all this product architecture work, leading teams in the weeds of building products internal and external. A lot of those people turned out to be actually working on projects by themselves or they didn't actually do any technical work. The latter is pretty easy to identify because if you start asking them nitty gritty standards questions about what they built they'll be completely lost. One woman that stood out like this was part of a ton of professional organizations, and was even being granted some really big title in one of them so I was pretty bullish that I'd found my senior. The last major project she led a team on was an internal REST service, so I figured it'd appropriate for us to workshop a REST API design. Pretty easy stuff to iteratively improve through a conversation especially if you've done it a thousand times. She didn't understand the grammar of REST much less how APIs are grouped. By that point I was starting to realize her role was likely more administrative than technical as a lot of roles at her level at non-tech businesses become. Discovering engineers who say they've led teams who haven't is also pretty easy. Frankly, not many engineers have actually led teams - it's an actual rarity. Of all the things engineers are asked to do day to day, leading other engineers is generally not party to them. I'd generally ask something about how they implement \"trust but verify\" aka delegating work. Engineers who have worked primarily solo will not know how to break down work so that others can consume it and align to the actual idea. It's something that takes a lot of practice and the answer generally involves a pretext of what certain people's strengths and weaknesses were. I have no doubt both of these folks genuinely wanted to do what they were applying for. I don't think they'd ever really been given the chance, or worked at the wrong kind of companies for what they wanted to do. To call it the \"fault of the team\" is easy, but in reality we have a very disjointed industry with no standard practice for building software, much less as a group. reply dartos 4 hours agorootparentprevWell… everyone is entitled to lie, including employers. That’s the crux of the issue. Software has wild practices because there’s no agreed upon certification and there’s this myth of 10x developers and managers only want those mythical 10x-ers reply dartos 4 hours agorootparentprevIt’s not just software. It’s all industries. People are paid to find matching talent. Talent isn’t paid to be truthful on resumes. reply andylynch 6 hours agorootparentprevAccording to the ruling, yes, given the public interest as stated, in protecting the right to organise. This is broadly similar in principle to laws like those in many places allowing one to not disclose spent criminal convictions. reply InvaderFizz 6 hours ago [flagged]parentprevnext [10 more] That stuck out at me too. So, all you have to do to completely lie on your resume and keep employed, is pretend to be union organizing? reply tzs 5 hours agorootparentNo. You can lie about union organizing because an employer is not allowed to use whether or not you are a union organizer when making hiring or firing decisions. If you lie about something that the employer is allowed to use in making those decisions they can fire you. reply Volundr 5 hours agorootparentprev> So, all you have to do to completely lie on your resume and keep employed, is pretend to be union organizing? You can lie about your union involvement. You can't make up qualifications you don't have. reply p_l 5 hours agorootparentprevInventing qualifications is probably still not legal. Now, not mentioning a job in the past, or some details of it, are a different case. reply ralferoo 6 hours agorootparentprevI'd imagine it'd go to court and the union would have to testify that this is the case, and also have documentary evidence to back it up. reply frapaconi 6 hours agorootparentprevnext [6 more] [flagged] jdiff 5 hours agorootparentNope, that's also not allowed. reply frapaconi 5 hours agorootparentHow is it not allowed? Employers can’t choose who they want to hire? You’d obviously word it differently: unfortunately you’re not as good as another candidate. Better luck next time! reply saagarjha 1 hour agorootparentEmployers can’t choose who they want to hire when that decision is related to union involvement, yes. You’re not the first person to think that hiding the real reason for employment discrimination somehow makes it legal. It is not. reply ethbr1 4 hours agorootparentprevHow would you know? Equifax Employment Verification et al. Which begs the question of whether those are illegal too... reply immibis 5 hours agorootparentprevIt's not allowed because of exactly what you just said. reply jmyeet 4 hours agoparentprevHere's an exercise for you. Take almost any court case that makes it to the Supreme Court or Federal government action, regardless of the court's makeup, or what party controls the White house or Congress, and ask yourself this question: What is the pro-business or pro-government outcome of this case or legislation? Then see how the court ruled or the executive and legislature acted. You will find the majority of the time that the pro-business or pro-government (particularly pro-police) outcome matches what actually happens. reply jpambrun 6 hours agoparentprevnext [19 more] [flagged] dartos 6 hours agorootparentIf that has to be punishable, then job listings with false or misleading information should be too. Also, offer letters must be legally binding at the time of being offered. Also, saying you’re hiring when you’re actually not. Lying on the resume is literally all the leverage most people have in the job hunt. reply jpambrun 6 hours agorootparentEverything you mentioned is immoral. Two wrong doesn't make it right. If you cheat, to compete you your lies I now have to lie. And it completely breaks the system. Also, you don't deserve more leverage over other prospective candidate. This is cheating and fraud. It requires punishment. reply dartos 4 hours agorootparentEverything I mentioned is immoral. If anything I or OP mentioned is punishable, then it all should. > and it completely breaks the system The system of hiring is set up in such a way that employers and employees are encouraged to act immorally to get the best result. It’s not any individual’s fault that the system is broken, it just grew that way. And everyone has the same ability to lie on resumes. When job hunting you should use every advantage you can get. That being said, making outright lies may get you the first screening, most interviewers can smell too much bullshit. reply HeatrayEnjoyer 6 hours agorootparentprevnext [3 more] [flagged] jpambrun 5 hours agorootparentI am not in the US, so this is a bit moot, but I don't want liers as coworkers or on my team. To me this is unprofessional and absolutely disqualifying. I wouldn't care for the law. I would die on that hill. reply dartos 4 hours agorootparentThen you best be sure your hiring process can catch liars reply zug_zug 6 hours agorootparentprev> If that has to be punishable, then job listings with false or misleading information should be too. Currently, it's symmetrical. If either side lies, the other side can exit the contract with no notice, and may tell others their story. > Also, saying you’re hiring when you’re actually not. This would be nice and very actionable. Perhaps requiring a company to say how many resumes they've received, candidates they've talked to, and how long its been open on job listings could save everyone's time. reply dartos 4 hours agorootparentRight, neither side should be able to lie is the whole point. Currently lying on resumes is the only power would-be employees have, since employers can say or do _almost_ whatever they want during the hiring process reply bbarn 5 hours agorootparentprevIn some countries, that or nearly that is the case already. reply throw10920 4 hours agorootparentprevYes! All of the things! Honesty should be required from all parties. reply dartos 4 hours agorootparentExactly reply nohuck13 6 hours agorootparentprevYou're saying that if you as an employer find out that someone you hired lied to induce you to hire them, you should be legally required to continue employing them, as some kind of karmic balancing thing? reply dartos 4 hours agorootparentThat’s not even a little bit what I said. I assume you’re referring to the offer letter? Companies extend offer letters only to retract them before the agreed starting date. (Maybe since the offer they found a better candidate) That should be punishable. Hiring someone who lied on their resume and is unable to perform their work duties should be fired. reply joshbetz 6 hours agorootparentprevI've never heard of anywhere that cutting in line is illegal nor seen people get punished for cutting in line. reply jpambrun 15 minutes agorootparentI will punish you if you cut in line in front of me with a very stern scolding. I would call out your immoral behavior just like I am doing now. reply lithos 6 hours agorootparentprevIt's not punishable because it's checked by any competent employer for a competitive job. Employee background checks are only start at 1k usd or so, and grabs from data submitted by employers/tax firm/banks/credit card companies/insurance/courts and similar, meaning the employer knows your employer and pay levels pretty much perfectly. If the position isn't worth those prices for a background check, it only a fast food job where the only thing that matters is the Employee does as told. reply jdiff 6 hours ago [flagged]rootparentprevnext [3 more] And yet, cutting and lines coexist in the same universe. reply jpambrun 6 hours ago [flagged]rootparentnext [2 more] On that slope nothing should considered immoral.. if one kills we can all be murderers.. reply jdiff 6 hours ago [flagged]rootparentIf you invent a slope you're legally allowed to put anything you want on it, just know that slopes tend to turn into curves when you back up. The existence of carnivores hasn't eliminated herbivores. For some reason evaporation hasn't boiled all our oceans away. reply kingkawn 6 hours agoparentprevAs it should be reply jpambrun 6 hours agorootparentCare to elaborate? I can't think of any argument for this position. reply charlesabarnes 6 hours agorootparentOrganizing a union once in your employment history would bar you from employment at a ton of companies otherwise reply jpambrun 6 hours agorootparentWhat is this about then. Obviously you can omit stuff on your resume. I take offense at adding fake experiences. reply vintermann 5 hours agorootparentIt can maybe be tough to explain what you were doing in those years you were actually working at a well-known heavily unionized business. It sucks if you have to be allowed to just make up work experience, but the root of the problem is the power imbalance between employers and employees, and well, that's what's unions are trying to address. reply stavros 5 hours agorootparentprevThis isn't about adding fake experiences, though, no? It's about omitting experience you've had. reply SpicyLemonZest 2 hours agorootparentDepends on what you consider a \"fake experience\". The guy in this case legitimately had 4 years of HVAC experience, but he falsely claimed it was at one particular (non-unionized) company when it was actually at two different (unionized) companies. reply stavros 2 hours agorootparentAh, I see. In my opinion, this is OK, as otherwise a 4-year gap in a resume might telegraph a union affiliation and make people unhirable. The spirit of the law is that you're allowed to lie to hide union affiliation, so that's fine. I would be against people making up experience, but replacing one company's name for another might be OK, if the companies are of roughly similar caliber (no saying you worked at Google when you were an IT for a shop). reply ungreased0675 5 hours agorootparentprevAre there any other employers it’s legal to lie about? I don’t like the idea, even though I understand the goal. reply kingkawn 4 hours agorootparentprevUnions should be an inherent presence at every job. Any laws that help further their establishment so that business people who sell the labor of a single individual are able to organize beneficial business associations amongst themselves is a positive for the American workforce and the country. reply gigatexal 5 hours agoprevNice. Here’s hoping the extra freedom causes wages to rise and employers work to keep employees with benefits instead of handcuffs. reply steveBK123 6 hours agoprevThere's been moves by the FTC to ban non-competes as well. I work in financial services so am often covered by these clauses. Firstly, it seems insane that unpaid non-competes are legal at all, to start with. Also, seeing them applied to very junior level and even hourly paid roles is overly onerous. While my industry pays your base salary during your \"garden leave\" even this can be misleading in more senior roles where 50% or more of your compensation is bonus, plus some firms cut your healthcare coverage on resignation as well. Some companies have also extended the terms as long as 18 months or longer. Further, I have been under non-solicitations with terms as long as 5 years which is frankly insane. So all that is to say the free market is not exactly working here, and seeing some legal guardrails put in place would be good - pay required, terms limited, benefits defined, etc. reply anon291 5 hours agoparent> Firstly, it seems insane that unpaid non-competes are legal at all, to start with. Also, seeing them applied to very junior level and even hourly paid roles is overly onerous. They're not. I mean they're legal in that you can write one and ask someone to sign it. But good luck getting it enforced! I went to a college where people typically went on to finance roles and strategy consulting. I myself worked at Bain for a few months before deciding it was not for me. Our corporate law professor told us the same thing. She was head general counsel at an aerospace company. She said ignore all non-competes and don't accept payment for them. If there's no payment in a contract, there's no consideration. A non-compete has to be signed upon resignation. So just don't take the resignation bonus. Moreover, it doesn't really matter because no one is going to put someone on the government dole in order to enforce a non-compete. It's safe to ignore in almost all circumstances. Why would a state possibly take on yet another unemployment figure in order to protect a private company's interest? They want the tax money. Non-solicitation is different. IANAL, but take that as you will. I've followed this advice religiously and nothing happens. Most companies will be weirded out when you don't take the resignation bonus, but as long as no money changes hands, they have no power over you. reply tzs 4 hours agorootparentThat is true now due to the FTC ban on non-competes, but it was not true before that. The enforceability varied widely from state to state. Here's a table showing how it was in 2016 [1]. My guess is that your corporate law professor was talking about enforceability in the specific state you were in. Also, most I've seen were required to be signed when employment began, not when employment ended. [1] https://beckreedriden.com/50-state-noncompete-chart-2/ reply ghaff 5 hours agorootparentprevOne of the issues is that many small firms are just going to pass if you have a non-compete. I guess you can lie and just say you don't but that's probably not a great way to start a new employment relationship. I worked for a very small firm and someone having a non-compete was just a hard pass from our COO. Just too much risk. reply steveBK123 5 hours agorootparentprevFair. Something that is common practice but not going to hold up in court are uhh quasi-legal. A problem is that if you are moving within an industry that enforces non-competes they all generally respect each others for fear of invalidating their own. They also tend to know the terms of each others contracts as well so you can't exactly bluff your way through. So your new prospective employer will not do anything that is seen as soliciting you to break the prior contract. Also at the low end it works especially well because you won't take the risk of court / having to hire a lawyer. reply jfengel 6 hours agoparentprevTIL \"garden leave\", a period of time when you are mandated to be out of work. Thanks. reply steveBK123 6 hours agorootparentIt's pretty good for say, 3-6 months. Long enough to reset, not worry too much about health coverage, and if timed right.. not miss out on a bonus cycle. It's also short enough that you can interview and get a job offer from a company willing to wait for you. Often you can negotiate a signing bonus at the new shop to make up for compensation you may lose due to deferral or bonus cycle. The firms trying to force 18 month terms are also some of the highest turnover shops. Arguably you'd need to demand a 50-75% bump to take the role since on the way out the door you are going to miss out on 1-2 bonus cycles. The term is so long you likely need to quit before finding a new job too, and then kick off interviewing in the last 6 months. reply pkilgore 5 hours agorootparentprevImportantly compared to almost all non-competes: Garden Leave implies you are being paid to not work. reply ghaff 5 hours agorootparentAnd often it's some percentage of your salary and doesn't include bonuses, RSUs, benefits, etc. It does make a company put some skin in the game and may even seem like a decent deal depending where you are in life but isn't a panacea. (E.g. MA put some much-delayed legislation in place a few years back over strong opposition but it's still something like a 50% of base pay requirement.) reply ClumsyPilot 4 hours agoparentprevWhat does free market mean, in this particular case, even philosophically? Non-compete, as in preventing people from selling their labour, a violation of free market? Or is stopping people from agreeing to non-competes, a violation of free market? Is allowing a man to sell himself into slavery free market, or is banning such practice something that helps to ensure the market stays free? The more American idea of a free market is a kind of natural law of the jungle, where the strongest wins. The more European idea of free market is that it can only exist with rigorous protections and watchful eye of a government reply steveBK123 4 hours agorootparentWhat makes them anti-free-market in my mind is.. monopsony. Non-competes are a feature of monopsony because in a given industry all the buyers of labor enforce them. This is a concept related to monopoly, but on the demand rather than supply side. Even bad old USA takes (an increasing) hard line on monopolies. reply silverquiet 5 hours agoparentprevnext [5 more] [flagged] vsskanth 5 hours agorootparentLabor is human capital, and in a free market, people should be free to deploy their human capital wherever they want to get maximum ROI. reply nilamo 5 hours agorootparentprev> As ever I feel the need to remind people that we live in a capitalist economy, not a laborist one. And it should stay that way forever because...? reply silverquiet 4 hours agorootparentI don't know about should, but it will because of the various political decisions made in the last few decades that have locked us in. In case it was unclear from my previous comment, I am not happy with this state of affairs; I actually find it profoundly depressing. reply ClumsyPilot 4 hours agorootparentprev> Regulations to protect labor aren’t really what capital would call a free market I think thats backwards - it is only by power of law and courts that the contract can be enforced. We don’t get our courts to enforce what isn’t a valid commercial interest - you can’t can’t have a contract of sorts ‘if you leave this job in New York you must leave New York and not come back for 5 years’ Alternatively ‘If you leave this job you must not have sex for 1 year’ would not fly either So we already are making decision for what is allowed in the contract. And if you could put anything you want into contract, there would be many terrible contacts that make leaving your job too painfull, turning it into slavery-lite. reply nabla9 3 hours agoprevIf non-compete is must, you can always make garden leave contract. Employee must stay away from work during the notice period, while still remaining on the payroll. 6 or 12 month garden leave is common in financial sector. reply paulus_magnus2 4 hours agoprevNo need to ban it. Just automaticly award full salary for 2x the noncompete period they put in your contract, payable in full a week after contract termination. reply callalex 4 hours agoparentSuddenly your salary is $1/yr and your bonus is $1M/yr. (This really happens in the USA financial sector.) reply AgentOrange1234 3 hours agorootparentEmployees won’t tolerate that due to not being able to get mortgages? Our megacorp recently upped base salaries due to this. reply Dr_Birdbrain 1 hour agorootparentEmployees definitely tolerate this. As said above, this already happens in industry, and also for many years Amazon used to cap salaries at some hilariously low number—I think like 180k. That may not seem low until you try to buy a house in the Bay Area and lenders laugh in your face. People would either be part of a two-income household or wait for their stock to vest, but for many years they tolerated it fine. reply red_admiral 4 hours agoprevThis sounds reasonable. If you train as a plumber, work for ACME Plumbing Inc. and then leave, being told you can't work anywhere else in your trade for 24 months means you should do what exactly - become an uber driver for a couple of years? reply dataflow 6 hours agoprevHow much authority/jurisdiction does this judge/ruling have? It seems like the kind of thing that might easily get appealed and lost. reply granzymes 5 hours agoparentThis is a ruling from an Administrative Law Judge, which basically functions as a strong recommendation for how the National Labor Relations Board should decide a particular case. ALJs are Article II “in house” judges that specialize in the law of one particular administrative agency. They don’t have Constitutional life tenure protections and mostly do claims processing work for the Social Security Administration. The next step in this case is for a 3-member panel of the NLRB (a 5 member board appointed by the President, currently with 4 members) to decide whether to accept the proposed ruling of the ALJ or to substitute their own opinion of how the case should come out. Orders of the NLRB are not self-executing, so parties can appeal an adverse judgement to the Circuit of Appeals of their choice and the NLRB can cross-petition for enforcement of their decision. The Federal courts have final say over questions of law like “are non competes a violation of labor law”. The entire process takes several years to play out. reply dataflow 5 hours agorootparentThat's exactly what I was wondering, thank you! reply baryphonic 5 hours agorootparentprevNot to be too pedantic, but ALJs are technically Article I judges (or more precisely judges over Article I tribunals). The Constitution lists two different sources of judicial power, the first in Article I section 8 and the second in Article III. Article III courts have judges with life tenure, protection of salaries and are subject to review only by other Article III appeals courts including the Supreme Court. Article I courts have judges with fixed terms of office, and Congress can cut their salaries. All Article I courts are subject to review by Article III courts. There's an open controversy about how much deference the Article I courts in administrative agencies are owed by Article III courts, arising mostly from Chevron v NRDC. That decision requires Article III courts to defer to Article I courts' interpretations of their statutes and even their administrative rules except in extreme circumstances. Several justices on the Supreme Court find Chevron deference problematic, but it currently is the law of the land. reply bitwize 6 hours agoparentprevThe conservative SCOTUS has a vendetta against the administrative state. The overturn of the bump stock ban is just the beginning: they're going after Chevron deference. This, combined with conservative justices tending to favor contract law over consumer/employee protection, means that any federal ban on noncompetes is likely to be overturned absent a statute from Congress. reply lolinder 6 hours agorootparent> the administrative state. The overturn of the bump stock ban is just the beginning It's not even sort of the beginning. The conservative stance on the role of the Supreme Court has been pretty clear for a long time and this court has been ruling that way for a few years now. Their theory is that Congress makes the laws, the Executive branch enforces them, and the Judicial branch interprets. The precedent that they've overturned has consistently been in line with this logic: they've said over and over again that if America wants a law then Congress should create it, rather than relying on executive rulemaking that gets overturned every time an administration changes or on unelected judges legislating from the bench. Whether or not you agree with them on specific issues, I think we can all agree that the current status quo where worker rights take dramatic swings every time a new party takes control of the presidency is a ridiculous situation that needs to be fixed. I want a nation of laws, not a nation of administrative rules that have a 4-year shelf life. reply ryandrake 5 hours agorootparentThis is great in theory, and I agree with it in theory, but Congress has been dysfunctional for my entire adult life. With a few notable exceptions, Federal law is largely stuck at about 1993. Nobody's proposed a way to end the gridlock. reply lolinder 5 hours agorootparentYeah, I'm aware of that. I think the theory behind the Supreme Court's actions is that by undoing the patches that we've placed over our incompetent legislative branch they'll force actual change by making life uncomfortable enough for people to get their act together. To some extent this already has happened, just at the State level, and I think a patchwork of stable state laws is still better than a bunch of very short-lived rules at the federal level. reply kbolino 5 hours agorootparentprevI don't think your starting year is a coincidence: before then, Congress was nearly always held by one party: the Democrats. Though the Republicans were competitive for the Presidency, they rarely won majorities in Congress and could not hold them for long from FDR until Clinton. reply kbolino 5 hours agorootparentprevI do wonder if this strategy will actually move the needle at all. Conservatives have tried something like this at least twice before: lower taxes to starve the government of revenue and force cuts (largely failed and just got routed around with massive deficit spending) and interpreting the Anti-Deficiency Act in such a way that the government \"shuts down\" if Congress hasn't explicitly funded it, presumably in the hopes that Congress would responsibly pass a budget well before the deadline (obviously also a failure in general, since Congress waits till the last minute regularly now and shut downs happen about once or twice a Presidential administration). Edit: Make that at least three times: they've also capped the civil service which has just caused an explosion in contractors. reply lolinder 5 hours agorootparentYeah, I don't know. Congress is so completely and utterly broken that I'm unsure it can be fixed. Legislating from the bench is better than the administrative rulemaking in that it's at least generally more stable, but I do think that the conservative justices have a point that the actual laws should be more directly accountable to the people than the Supreme Court is. Basically, we should be able to change the laws, but it shouldn't be as simple as winning a single national election because that makes things too unstable. reply kbolino 5 hours agorootparentThe only system that aligns more with voters that I'm aware of is the Westminster system but it has is faults too. It is after all the same system that gave us \"Yes, Minister\" which illustrated and lampooned the fact that the civil service and elected politicians are distinct factions each with their own agendas rarely in alignment with each other (never mind the factions within each faction). reply umanwizard 4 hours agorootparentprevThe problem with the U.S. system is twofold: first, an unusually high amount of cooperation is required to pass any law (majority of the House, 60% of the Senate, and the presidency). Second, the first-past-the-post electoral system naturally leads to a two-party duopoly and polarization that makes cooperation very difficult. No other democracy in the world has both of these flaws although some have one of them (e.g. the UK). The best systems in practice seem to be proportional-representation parliamentary ones. They generally result in coalitions of multiple generally centrist parties so things don’t change too abruptly, but passing new laws is at least possible. Of course some parties refuse to cooperate with each other: in Germany for example no mainstream party will work with the right-wing AFD, and right-leaning mainstream parties additionally refuse to work with the left-wing Die Linke (legal successor to the East German ruling party although substantially more moderate nowadays). However this doesn’t stop the big mainstream parties from working together to an extent that would be unimaginable in the U.S. It’s indeed probably impossible to fix in the U.S. because it’s so hard to amend the constitution in such a radical way. reply czl 2 hours agorootparent> The best systems in practice seem to be proportional-representation parliamentary ones. They generally result in coalitions of multiple generally centrist parties so things don’t change too abruptly, but passing new laws is at least possible. When there are two major parties each representing say ~45% of the population, proportional-representation gives the left over swing voters equal power does it not? So perhaps ~6% of swing voters can have as much influence as ~45% of voters? Does this not happen in practice? Consider Israeli proportional-representation system for example. The Israeli % numbers are different but I have the impression they struggle with this problem due to proportional-representation. reply umanwizard 1 hour agorootparentIt's less likely for two stable parties to make up 90% of the electorate in such a system, because splitting parties is much easier. If the US had proportional representation, there's no way Nikki Haley and Marjorie Taylor Greene would be in the same party, nor Bernie Sanders and Kamala Harris. But this split will never happen in the current system because leaving one of the two major parties would be electoral suicide. There are ten factions represented in the Knesset (Israeli parliament) and the biggest one (Likud, Netanyahu's party) got 23% of the vote in the last election. It's true that fringe parties can have outsized influence in a proportional system, but the US system suffers from the opposite problem: fringe elements can take over one of the major parties, which seems to be well on its way to happening with the Republicans now. reply doctorpangloss 5 hours agorootparentprevOkay, but the Supreme Court justices who want to take down Chevron are insincere. The IRS exemptions for fake Christian seemingly organizations: do you think the court is going to defer to the IRS’s interpretation of the 3 word “exclusively for religious” part of the 501(c)(3) if it denies something Christian tax exemption? No. They’re going to see if that woman’s husband is a member of the Federalist Society, and if he is, then her bullshit charity that pays her salary will maintain tax exemption. My dude, Clarence Thomas’s wife is a beneficiary of deference on 501(c)(3). They like administrative deference when it suits them. Don’t try to make this about some sincere judicial opinion that has some legitimacy. reply lolinder 5 hours agorootparent> the Supreme Court justices who want to take down Chevron are insincere. Everyone says this about their opposition. Obviously you know that it's not true about the liberals—you know that they mean what they say. So when a conservative says that liberals are insincere and really have a hidden agenda you know that's nonsense. Turns out that that the same thing is also true on the conservative side. They generally really do believe what they say. Donald Trump is a notable exception, but even many of his supporters are sincere and are either stupidly taken in or see him as a means to a good end. reply simonbarker87 5 hours agoprevOf course it is. Non-competes are unenforceable in the UK as you can’t stop someone earning a living and if their skill or knowledge is that specific or valuable that they may not be able to get a job anywhere not covered in the non-compete. Want someone to not work for a competitor until their secret knowledge is out of date? Pay them gardening leave. reply quietbritishjim 4 hours agoparentThe UK government was due to introduce legislation (\"when parliamentary time allows\", which apparently it didn't) to limit non-complete clauses in employment contracts to a maximum of 3 months. That seems like implicit recognition that non-complete clauses longer than 3 months are currently valid. reply simonbarker87 4 hours agorootparentCan't speak to that explicitly but the advice I was given by 2 solicitors on the topic was \"they're not enforceable and won't stand up in court, they can't stop you earning a living with your skills\" reply KennyBlanken 4 hours agorootparentprevNo, it implies that's what legislators negotiated between different factions, or between legislators and lobbyists, or were outright bribed by lobbyists to go with. Ie, they wanted 1 month, but lobbyists wanted 6 months, legislators pushed back, and everyone compromised at 3. reply WalterBright 2 hours agoprevI'm curious if the NLRB has ever ruled in favor of business. reply ok_dad 2 hours agoparentYou could probably look that up. Instead you made a stupid comment meant to insinuate something sinister. Edit: Here ya go Walter, I guess your compiler skills are better than your google skills. Several cases here were in favor of the business. https://www.nlrb.gov/cases-decisions/decisions/notable-board... reply WalterBright 2 hours agorootparentThanks for the link. But I'm not going to spend all day reading those decisions (the language is so legalese it's hard to parse what they're talking about). I'll just say that every time the NLRB is in the news, I've never read of a case where they ruled for the business. If you want to point to a decision in particular, I'll take a look at it. > you made a stupid comment meant to insinuate something sinister It's a fair question. reply ok_dad 40 minutes agorootparentNot fair at all, insinuating something then doing no work to verify is lazy. You’re smarter than that! Put in the effort necessary to research your positions. reply Kiboneu 57 minutes agorootparentprevYou could read the comment guidelines. Instead you made an unnecessarily insulting comment with no real substance. Since you clearly have not bothered to read them, the guidelines are at the bottom of the site, or maybe try googling it. reply ok_dad 33 minutes agorootparentWalter constantly says things that are incorrect or lazy and no one calls him out, so this time I did so. I’m aware of the guidelines and the harsh language was because that’s all he understands. As you can see, he didn’t even care to read one or two decisions, because they’re in legalese. This is a man who writes compilers for a living, I would think he was smart enough to read some documents and determine for himself whether his “question” was answered there or not, but he literally doesn’t care. Asking leading questions is always put forth as “innocent” but it never is with these types of people. I don’t even know why I’m defending myself to you, I’m comfortable with what I’ve written here today. If dang thinks it’s rude he can ban my comments. reply mannyv 5 hours agoprevThe Supremes have been on a tear vs administrative judges, so expect this to get swatted down. There are other agencies in the non-compete mix that are better suited to make these sorts of policy decisions. This court would rather have agencies and politicians do their jobs when it comes to this stuff. reply wdreynolds1 6 hours agoprevThere is nothing in this ruling that is new as it relates to non-competes or non-solicitation. Overly broad non-compete’s and non-solicitation clauses have always been unenforceable. They must be specific and unambiguous. reply downrightmike 2 hours agoparentI had an employer only offer severance if I signed a new non compete for FIVE years and to get around the overly broad language they inserted clauses on every single thing that stated that there was no way around the non compete even though the state would find it illegal. My state has precedent that if the non compete doesn't allow a person to earn a living, they throw it out and if one clause does that, the whole thing is in valid. So the employer wrote their new non compete to completely try to circumvent it. They also paid shit, so severance wasn't worth it. reply ein0p 2 hours agoprevIf it goes like this the Supreme Court might declare water to be wet, much to the horror of corporate America. Of course it’s unfair to limit one’s employment options without just compensation for it. reply blackeyeblitzar 4 hours agoprevI agree that non competes are unfair but also think the NLRB has too much power and is effectively legislating. reply jmyeet 5 hours agoprevWhen you learn about enclosures [1] you cannot stop seeing them everywhere. The entirety of intellectual property is just an enclosure. Rather than promoting innovation it just promotes rent-seeking [2] or intermediation. Noncompetes fit this bill. They've been weaponized by private equity to medical practices. A PE firm will come along and buy up all the medical practices in an area. It's hard to resist that large buyout offer. The staff will then be put on noncompetes that essentially prevent them from practising in their area at all if they leave. This problem has gotten so bad that even places like Florida are seeking to ban medical noncompetes [3]. If you've wondered why your vet bills have gotten so large, well it's the same playbook [4]. Restraint on trade (such as noncopetes) is used to suppress wages and jack up prices for absolutely nobody's benefit other than the PE fund's investors. Absolutely no value is being created here so I'm glad to see the NLRB, the FTC and yes, even Florida take action here. I've previously thought that noncompetes may make sense in very limited circumstances and, if so, companies should have to pay through the nose. Example: when you quit the company has a one-time option to exercise that noncompete. If they do, they have to pay you out for the entire term. That payout? Take your highest earning year in the last 10 years. Double it. That's how much you have to be paid per year. Then we'll see how badly companies really need noncompetes. Even then I think I'd be just as happy if they were entirely illegal. [1]: https://en.wikipedia.org/wiki/Enclosure [2]: https://en.wikipedia.org/wiki/Rent-seeking [3]: https://www.hklaw.com/en/insights/publications/2024/02/flori... [4]: https://stateline.org/2024/03/29/vets-fret-as-private-equity... reply bushbaba 5 hours agoprev [–] While great, it's a huge blow to California who historically benefited from the innovations of non-competes being non-enforceable. reply ghaff 4 hours agoparentI'm very opposed to non-competes except in specific scenarios like selling a business (and non-solicitation agreements often make sense). However, I'm also very skeptical of the argument that CA's success in certain industries is remotely the result of unenforceable non-competes. There often seems to be an assumption that non-competes are the norm everywhere else and, while they certainly exist (and some firms/industries are notorious for enforcing them) that just isn't the case anything like universally in my experience. reply phyzome 3 hours agoparentprevOr it's exactly the opposite, depending on how mobile you think companies are. reply bbarn 5 hours agoparentprev [–] Why exactly? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "NLRB Judge Sarah Karpinen ruled that non-compete and coworker non-solicitation clauses are unfair labor practices, marking a landmark decision.",
      "The case involved J.O. Mory, Inc., where a union organizer was fired for \"salting\" (organizing coworkers), and the judge ordered the organizer's reinstatement with backpay.",
      "This is the first time an Administrative Law Judge (ALJ) has ruled these clauses as unfair labor practices, emphasizing the NLRB's stance against such clauses for non-supervisory workers."
    ],
    "commentSummary": [
      "An NLRB judge has ruled that non-compete clauses are an unfair labor practice, igniting discussions on other restrictive employment practices.",
      "The ruling has led to debates on non-solicitation clauses and company policies that restrict managers from giving references, which some argue hinder job mobility.",
      "This decision is part of a larger conversation about balancing power between employers and employees, with calls for increased worker protections to ensure fair treatment and job market mobility."
    ],
    "points": 339,
    "commentCount": 196,
    "retryCount": 0,
    "time": 1718545226
  },
  {
    "id": 40693451,
    "title": "French court orders Google, Cloudflare, Cisco to poison DNS to stop piracy",
    "originLink": "https://torrentfreak.com/google-cloudflare-cisco-will-poison-dns-to-stop-piracy-block-circumvention-240613/",
    "originBody": "HOME > ANTI-PIRACY > SITE BLOCKING > A French court has ordered Google, Cloudflare, and Cisco to poison their DNS resolvers to prevent circumvention of blocking measures, targeting around 117 pirate sports streaming domains. The move is another anti-piracy escalation for broadcaster Canal+, which also has permission to completely deindex the sites from search engine results. In France, where laws were introduced with site-blocking and similar anti-piracy measures already baked in, entertainment giant Canal+ seems intent on taking full advantage. Like similar broadcasters with lucrative sports rights to exploit, Canal+ has a subset of viewers who prefer to consume from pirate sources which charge much less, or even nothing at all. To maximize its existing site-blocking efforts through local ISPs, the French broadcaster has now taken the logical, albeit controversial, next step on the site-blocking ladder. DNS Tampering at the Local ISP Level In 2023, Canal+ went to court in France to tackle pirate sports streaming sites including Footybite.co, Streamcheck.link, SportBay.sx, TVFutbol.info, and Catchystream.com. The broadcaster said that since subscribers of local ISPs were accessing the pirate sites using their services, the ISPs should prevent them from doing so. When the decision went in favor of Canal+, ISPs including Orange, SFR, OutreMer Télécom, Free, and Bouygues Télécom, were required to implement technical measures. Since the ISPs have their own DNS resolvers for use by their own customers, these were configured to provide non-authentic responses to deny access to the sites in question. In response, increasingly savvy internet users that hadn’t already done so, simply changed their settings to use different DNS providers – Cloudflare, Google, and Cisco – whose resolvers hadn’t been tampered with; at least not yet. One More Step Up The Ladder: Public DNS Tampering Use of third-party DNS providers to circumvent blocking isn’t uncommon so last year Canal+ took legal action against three popular public DNS providers – Cloudflare (1.1.1.1), Google (8.8.8.8), and Cisco (208.69.38.205), demanding measures similar to those implemented by French ISPs. Tampering with public DNS is a step too far for many internet advocates but for major rightsholders, if the law can be shaped to allow it, that’s what will happen. In this case, Article L333-10 of the French Sports Code (active Jan 2022) seems capable of accommodating almost anything. When there are “serious and repeated violations” by an “online public communication service” whose main objective is the unauthorized broadcasting of sports competitions, rightsholders can demand “all proportionate measures likely to prevent or put an end to this infringement, against any person likely to contribute to remedying it.” Google, Cloudflare, and Cisco Ordered to Prevent Circumvention Two decisions were handed down by the Paris judicial court last month; one concerning Premier League matches and the other the Champions League. The orders instruct Google, Cloudflare, and Cisco to implement measures similar to those in place at local ISPs. To protect the rights of Canal+, the companies must prevent French internet users from using their services to access around 117 pirate domains. According to French publication l’Informé, which broke the news, Google attorney Sébastien Proust crunched figures published by government anti-piracy agency Arcom and concluded that the effect on piracy rates, if any, is likely to be minimal. Starting with a pool of all users who use alternative DNS for any reason, users of pirate sites – especially sites broadcasting the matches in question – were isolated from the rest. Users of both VPNs and third-party DNS were further excluded from the group since DNS blocking is ineffective against VPNs. Proust found that the number of users likely to be affected by DNS blocking at Google, Cloudflare, and Cisco, amounts to 0.084% of the total population of French Internet users. Citing a recent survey, which found that only 2% of those who face blocks simply give up and don’t find other means of circumvention, he reached an interesting conclusion. “2% of 0.084% is 0.00168% of Internet users! In absolute terms, that would represent a small group of around 800 people across France!” Court Rejected Arguments Against Blocking In common with other courts presented with the same arguments, the Paris court said the number of people using alternative DNS to access the sites, and the simplicity of switching DNS, are irrelevant. Canal+ owns the rights to the broadcasts and if it wishes to request a blocking injunction, it has the legal right to do so. The DNS providers’ assertion that their services are not covered by the legislation was also waved aside by the court. Google says it intends to comply with the order. As part of the original matter in 2023, it was already required to deindex the domains from search results under the same law. At least in theory, this means that those who circumvented the original blocks using these alternative DNS services, will be back to square one and confronted by blocks all over again. Given that circumventing this set of blocks will be as straightforward as circumventing the originals, that raises the question of what measures Canal+ will demand next, and from whom. Tribunal Judiciare De ParisCanal+Cloudflare/Google/Cisco Premier League UEFA Champions League footybite.cc footybite.tv footybite.io hesgoal.today hesgoal.name redditsoccerstreams.org pirlotv.app rsoccerstreams.net reddit-soccerstreams.com soccerstreams.football redditsoccerstreams.tv soccerstreamshd.com streameast.gg totalsporteks.net volokit.to sportsurge.app totalsportek.ac redditsoccerstreams.xyz soccerstreamlinks.com hesgoals.top socceron.name hdmatch.club lacasadeltikitaka.net bitestreams.net streamseast.ai livesoccer.sx bestsolaris.com footybite.one radamel.icu techclips.net sports.f1livestream.top sports.f1livestream.top backfirstwo.site reddit.soccerstreamshd.com reddit.volokit.to extratime.live hitsports.pro streameast.top tvhd.tutvlive.site soccerstreams.app dotsport.live freeviplive.com dotsport1.com fapxy.info elkoora.live 1l1l.to fel3ardaa.com futbolonlinetv.club golkoralive.com hesgoal.world silapathikaram.com hesgoaltv.me cainsoffering.net sporthd.me golkoralive.live cdnz.one kkooralives.com ivesoccer.sx koora-live.io livetv705.me kooralivs.com livetv706.me kora4live.net pirlotvhd.online live-kooora.com rojadirectatv.uno livekooora.online soccerstreams100.io live-kooora-tv.com tarjetarojaenvivo.me live-kooora-tv.net tarjetarojatvhd.com livekoora.io stream.pajitotv.info live-koora.online hesgoaled.com livetv707.me 1.ivesoccer.sx livetv708.me embx214129.apl275.me monlive.info emb.apl275.me rojadirectaenvivotv.me embx214161.apl275.me rojadirectaes.org stream.rodrixtv.info awtsport.com fk9.pw live7.pro m.soccerstreams100.io sportsonline.so ovo-line.com 4koora.elkoora.live sportschamp.fun f.fel3ardaa.com givemereddit.eu v3.sportsonline.sx streamseast.ai kora.live-koora.live tazz.tv alkora.golkoralive.live embx214374.apl275.me kooralive.koora-live.io hd.espnv2.online m.koora-live.io embx210801.apl275.me syria-live.us4kooralive.live-kooora.com5kooralive.live-kooora.comtvkoora.livekooora.onlinemypanlss.storekoora.live-kooora-tv.netv2.sportsonline.sokora.livekoora.iokoras.live-koora.onlineembx214129.apl274.meembx210130.apl276.mecapodeportes.runsports-stream.infotopstreams.mesports.chelsealivestream.comsportsleading.online",
    "commentLink": "https://news.ycombinator.com/item?id=40693451",
    "commentBody": "French court orders Google, Cloudflare, Cisco to poison DNS to stop piracy (torrentfreak.com)295 points by popcalc 21 hours agohidepastfavorite187 comments snowwrestler 20 hours agoOver a decade ago, a ton of tech companies (including Google) coordinated a “blackout the Internet” day of protest against U.S. legislation that would have required them to alter DNS to fight piracy. Interesting that now that France actually does it, they say they will comply. https://en.m.wikipedia.org/wiki/Protests_against_SOPA_and_PI... reply bognition 20 hours agoparentIn the last decade Tech has become part of the establishment. They are one of the dominant controlling forces. The blackout was _not_ about preserving free speech, or any other moral high road. It was purely about control. Tech hadn’t yet cemented their position as a dominant player and didn’t want to cede the control they had. Now that they’ve embedded themselves in the ruling class they don’t care as much because they already have control. reply darby_nine 19 hours agorootparentTech has always been part of the establishment, funded by capital trying to solve capital's problems. The only part of tech that really deviates from this is the free software community, which has always been hostile to capital. The blackout day emerged from people, not the industry, and people have changed. reply amatecha 15 hours agorootparentidunno, I remember when everything cool I found on the internet was on a .edu domain, because that's almost all there was. But yeah, capitalist tech has always been part of the establishment. A lot of the good stuff comes from non-profit-related motivations, fortunately. reply throwAGIway 3 hours agorootparentI remember how I used to call a BBS rather than go to the internet because there was much more than just universities and their research - took a long time until there wasn't a reason to call the BBS, around the point when all the people moved their content. reply JumpCrisscross 14 hours agorootparentprev> funded by capital trying to solve capital's problems Is this parody? Should we start against the trade unions and German barbarians next? (The latter to avenge Varus and recapture the Eagles.) reply HeatrayEnjoyer 12 hours agorootparentParody? It's obvious, and common sense. reply blackeyeblitzar 20 hours agorootparentprevThis is the right line of thinking. My interpretation is slightly different - I think the tech companies have run afoul of various norms when it comes to things like the privacy of customers, anti-trust, taxation, etc. Because they are now reliant on these unethical ways of holding onto economic power or growing their economic power, they need to not get into trouble with governments. This means playing nice with them so that they do not become subject to legislation that will rein them in. reply Dalewyn 19 hours agorootparentprevThere's also the nuance that while SOPA/PIPA were bills being legislated for potential passage, France is citing laws already in effect. For better or worse, if you do business inyou follow 's laws or GTFO. reply AnthonyMouse 19 hours agorootparent> For better or worse, if you do business inyou follow 's laws or GTFO. That does rather imply that the laws are worthless. Obviously there is going to be someone who doesn't do business in France and operates a public DNS server that doesn't censor anything. Regardless of that, I would challenge your premise. You can violate an unjust law and risk the consequences. And if you get the PR right, there may not even be any consequences: https://en.wikipedia.org/wiki/Apple%E2%80%93FBI_encryption_d... But to your point, this is one of the reasons it's important to get these laws off the books and keep them off the books. Once you have the law, the government gets to choose the test case. You know perfectly well they'll be using it against dissidents and false positives tomorrow, but the test case is going to be some loathsome terrorists or a commercial piracy operation with no shades of grey, and then that's the case that sets the precedent. They should never be allowed the opportunity. reply dgoldstein0 14 hours agorootparent> Obviously there is going to be someone who doesn't do business in France and operates a public DNS server that doesn't censor anything. and so when the rights holders notice enough people pirating using dns resolvers they can't force to do anything via the french courts, they'll probably just take it up with the french ISPs and ask for IP blocks of these resolvers. And I'd guess they may already be trying to IP block various piracy sites. Will be interesting to see them play whack-a-mole. I wonder if at some point France will just start maintaining national blocklists, that if you want to run an ISP or reply to DNS queries from France, you are legally obligated to follow (or get blocked yourself); from the article, it sounds like the current law is significantly short of that so the whack-a-mole will continue. reply immibis 13 hours agorootparentItaly has the system you're thinking of. It's called Piracy Shield. Upon receiving a blocking request from the government through the automated system developed for this purpose, all ISPs are required to block the domain or IP within 30 minutes or else their CEOs could be criminally charged and go to jail. reply mananaysiempre 10 hours agorootparentDoes it work in practice? The Russian censorship machine has only reached these kinds of reaction times in the last year or so, and they had to boil the frog for a decade to achieve that. reply immibis 8 hours agorootparentThings can change very quickly when CEOs are threatened with jail time. Maybe we should try it more often. reply tentacleuno 9 hours agorootparentprevThe correct link for that Wikipedia page is https://en.wikipedia.org/wiki/Apple%E2%80%93FBI_encryption_d... :-) reply fragmede 17 hours agorootparentprevYeah! Like Uber, or AirBnB! wait, hold on. reply TZubiri 18 hours agorootparentprevWhat? The tech ( dns in this case) is as neutral as you can get, these are french courts ordering the block, and the dns technicians are controlled by american corps. Dns just executes the orders of the corp, which in turn obeys the local courts. Tech is under corp in the chain or command, which in turn is under national law. Gross lack of extra-technical nuance here. reply m3kw9 15 hours agorootparentprevIf they had control they wouldn’t comply reply freddealmeida 5 hours agoparentprevI think these firms are all compromised. Poisoning dns is such a bad idea. reply cscurmudgeon 19 hours agoparentprevSame with tech and China. They fold like paper without any protest: https://www.nytimes.com/2021/05/17/technology/apple-china-ce... Chinese state employees physically manage the computers. Apple abandoned the encryption technology it used elsewhere after China would not allow it. And the digital keys that unlock information on those computers are stored in the data centers they’re meant to secure. reply mdhb 17 hours agorootparentApple have repeatedly thrown their customers under the bus especially in China. At least Google had the courage to withdraw entirely. reply thenthenthen 17 hours agorootparentGoogle never left China, they literally just moved to a new building on the other side of the road (in Zhongguancun, Beijing). They even “left a couple of boxes there”[1]. [1] Blum, Andrew, Tubes: A Journey to the Center of the Internet. New York, Ecco, 2012. https://archive.org/details/unset0000unse_p9b6 reply ApolloFortyNine 13 hours agorootparentYou can't even install the play store in China... Google hasn't been accessible there since in 15 years. You can buy an iPhone there today, and Apple has agreements with China to hand over user data and has done so in the past. reply jhugo 12 hours agorootparent> You can't even install the play store in China... Google hasn't been accessible there since in 15 years. You and GP are both correct. Most Google services are not accessible in China but Google the company still has a significant presence there. reply thenthenthen 13 hours agorootparentprevApple has a datacenter in Gui’an New Area, Guiyang, Guizhou, China (run by GCBD[1]). [1] https://www.apple.com/legal/internet-services/icloud/en/gcbd... reply sitkack 15 hours agorootparentprevGoogle employees had the courage to force Google to pretend to withdraw. reply zelphirkalt 13 hours agorootparentBut rarely do they have the courage to quit their jobs or go on strike, when Google does the next anti privacy thing. reply immibis 8 hours agorootparentThey tried it against Google's support of Israel and were immediately fired. reply didntcheck 11 hours agorootparentprevThis is why I can never take their current alleged passion for privacy fully seriously. Sure, I do appreciate some of the features they're coming out with, but I don't trust them to not eventually drop this marketing angle and pull rugs when it's no longer profitable reply machomaster 11 hours agorootparentprevGoogle had zero courage and went fully under Putin and helped him to silence Russian opposition (Navalny) during the crucial pre-election time. Telegram did the same, btw. reply m3kw9 15 hours agorootparentprevApple leaving china does essentially nothing, the people there won’t get end to end encryption either way reply banish-m4 15 hours agoparentprevYep. Net neutrality, my left foot. MAANG are all about participating in PRISM, monopolizing access, and choosing who can and can't speak because they compromise a for-profit, oligopolic, technocratic cartel. reply metadat 20 hours agoparentprevPiracy is simply Terrible, it's chopping the dear copyright holders off at the knees, they are frequently having to go on food stamps, and it's unclear how they'll continue on. /s Fighting online piracy: First world, or even zeroth world problem. It's not loke the pirates are saying \"hmm, should I pay exorbitant rates for this or should I pirate it?\" The real competition is alternatives: \"should I bother pirating this or just go do some other activity.\" Bottom line: In most cases it's actually free marketing, and has a net positive effect for the copyright holders. The continual attempts to aggressively clamp down really says a lot about the mentality of the Big Market Forces, *iaa, *aa, and now MS and Elgoog. Even when it's good fertilizer for their perpetual evergreen money tree, they still flip out. reply banish-m4 15 hours agorootparentIt's all about profit protectionism of the moats around streaming to enforce the arbitrary extraction of gotcha capitalism subscription fees from as many people as possible for as much as possible. reply ihsw 19 hours agoparentprevIt was not about standing up against IP juggernauts in the interest of users, but in the interest of themselves -- it was tech companies flexing their strength to show that cooperation with tech companies was required, and that they are open to cooperation in other ways too. reply Ayesh 20 hours agoprevHilarious how the article mentions the domain names at the end. It's like Google showing links of DMCA-striken lists, so you can easily find out the actual places to pirate. reply mananaysiempre 9 hours agoparent> It's like Google showing links of DMCA-striken lists Used to be like that. Now they have renamed “Chilling Effects” to “Lumen Database” and require submitting an email address to view each individual complaint. reply whamlastxmas 5 hours agorootparentIt still shows the domains for me, which is super useful, since I just go to the domain directly and then search again there reply applied_heat 19 hours agoparentprevWill read the article now thank you reply ThePowerOfFuet 11 hours agorootparentThis kind of comment is best left on reddit to keep the signal-to-noise ratio on HN as high as possible. Just hit that upvote button instead. :) reply elicksaur 8 hours agorootparentWhere do comments calling something Reddit-tier go? >Please don't post comments saying that HN is turning into Reddit. https://news.ycombinator.com/newsguidelines.html reply BitsOfBeard 6 hours agorootparentprevWhat if I'd want to warn users that the list really only encompasses sports related domains? Genuinely want to follow the etiquette here, but I like being useful. reply t0bia_s 10 hours agoparentprevYes, censorship by establishment makes public curious. Often it is best PR of those sites. reply AnthonyMouse 18 hours agoparentprevStreisand effect. reply hobobaggins 17 hours agoparentprevBut these names aren't resolvable (through compliant resolvers), while the transparency links would be. reply sofixa 12 hours agorootparentThey aren't resolvable with the listed in the article DNS providers, which makes it easy to find the other ones such as Quad9. reply t0bia_s 10 hours agorootparent9.9.9.9 reply sangnoir 14 hours agorootparentprevonly in France reply tialaramex 19 hours agoprevOne of the interesting technical questions is how these vendors will choose to reflect the forbidden DNS entries in protocols like DoH where they have a choice. For example a reasonable thing for a DoH server to say when asked a DNS question it has been forbidden to answer truthfully, is HTTP 451 Unavailable for Legal Reasons. reply callalex 2 hours agoparentThat would be a layer/protocol violation. The HTTP status codes used in DoH are used to discuss the semantics of the DNS query itself, unrelated to the DNS response. For example an NXDOMAIN response is still a 200, not a 404. Edit: for what it’s worth, Google is doing this the “right” way in the DNS protocol itself, see: https://news.ycombinator.com/item?id=40698650 reply steelbrain 20 hours agoprevThe title on the website is “Google, Cloudflare & Cisco Will Poison DNS to Stop Piracy Block Circumvention”. Curious why Cloudflare has been singled out in the submission title? reply anymouse123456 19 hours agoparentSame concern here. Also, the phrasing in both, but especially the HN title made me think Cloudflare chose to do something, but it turns out the French court is forcing all of them. reply dmitrygr 19 hours ago [flagged]rootparentnext [24 more] They could fight and choose not to. They could ignore this and choose not to. They deserve our judgement for that reply jsnell 19 hours agorootparentThey did fight it in court. They lost. I'm surprised you're so keen on having big tech companies intentionally ignore court orders and just break the law. Like, it's obviously something none of us should want. reply AnthonyMouse 18 hours agorootparentWhy should we not want this when the law is bad? The government should face pushback from all sides when attempting something odious. reply aniviacat 18 hours agorootparentIt's a democratic country. The voters decide if the laws their government passes are bad or not. reply immibis 13 hours agorootparentThere is actually no evidence this is the case, and there is evidence it is the opposite - that the less voters support something, the more likely it is to pass. reply aniviacat 11 hours agorootparentThis claim appears blatantly false. If being unpopular makes a law more likely to pass, then surely the French government tars and feathers all French children every other week. No, they don't, since the voters would prevent that by voting for a different government. reply AnthonyMouse 10 hours agorootparentObviously the claim exists within the space of bills that somebody actually wants. The premise is that things major industries or politically connected plutocrats want get passed over the interests of the general public for all of the usual reasons, not that things nobody wants get passed without explanation. reply immibis 8 hours agorootparentprevThat law was never proposed. Only laws that are beneficial to the ruling class get proposed. reply jsnell 18 hours agorootparentprevOne answers is that this case isn't actually a bad law. This appears to be blatant organized piracy. What's odious about copyright laws? This also appears to be pretty much the gold standard of due process. It's not like somebody submitting automated DMCA requests on videos with silent audio tracks or something. It's a court order for these specific domains, which would have been carefully curated and has been quite literally litigated. The other answer is that you really don't want big corporations to be ignoring laws they don't like, because odds are pretty good that your list of bad laws doesn't match theirs. Countries have sovereignty. If a company doesn't want to obey those laws, they should not operate in that country. If the law really were bad, the way you'd actually fix this is by the democratic process. That's up to the voters, not foreign corporations. reply AnthonyMouse 18 hours agorootparent> One answers is that this case isn't actually a bad law. It's censoring DNS. That's a bad precedent. The technical capacity to do it shouldn't exist because otherwise it will be used for every other form of censorship, and deprive democratic countries of any moral or technical authority to object when authoritarian countries want to do it. It will also be ineffective, leading for calls to make it effective, but the only way to do that is totalitarianism. There is no good that comes from setting out on that road. > The other answer is that you really don't want big corporations to be ignoring laws they don't like, because odds are pretty good that your list of bad laws doesn't match theirs. Ignoring the law doesn't get them out of paying the penalty, but penalties are meant to be sane, not some Hollywood accounting nonsense where one person watching one illicit stream of a sporting event causes the event organizers six billion dollars in damages. Then if Cloudflare wants to say \"yeah, we're not doing that\" and just pay the $100,000 dollar fine, it's clear that they're standing on principle -- they're paying $100,000 in exchange for ostensibly nothing -- and there is nothing wrong with that. The purpose of the penalty is to deter the underlying wrongdoing, not to deter civil disobedience. Anyone should be able to say \"I am going to suffer the consequences of this because my principles are worth more than the fine\" without having some authoritarians ratchet up the penalty to infinity. > Countries have sovereignty. Democratic countries have checks and balances. One of the checks and balances is that if you pass a law people don't respect, they don't respect it. Then you have to choose between punishing not the evildoers, but the principled idealists -- or repealing the law. reply sofixa 12 hours agorootparent> It's censoring DNS. That's a bad precedent France uses a sane legal system based on civil law, so precedents rarely matter. In this case the Sports Code says that piracy is bad and operators can be requested to block piracy websites if they're used and \"harm\" rights holders. That doesn't mean that tomorrow in a random case not related to sports piracy a judge can refer to that law and order censoring of other DNS entries. reply AnthonyMouse 10 hours agorootparentPrecedents aren't just in courts. People see something being done and then they want to do it too. If the law requires this then people who want to build systems that make it impossible would be in violation, which deters those systems from being built for the people who really need them. reply zzo38computer 19 hours agorootparentprevThere is other alternative, such as: get rid of their DNS service entirely, or make a petition for changing these laws. reply fastball 12 hours agorootparentWhat good would getting rid of their DNS service do? reply jsnell 18 hours agorootparentprevMaking a petition to change the laws sounds like a great way of achieving nothing. It will certainly not mean you get to ignore the court orders. Shutting down public DNS in France would be an option (a garbage option that nobody would actually choose in this case and that'd solve nothing, but an option nonetheless). That's not what dmitrygr was asking for though. They want big tech companies to ignore legitimate court orders to protect some scummy football pirate sites. reply charlieyu1 9 hours agorootparentprevIs a non-French company obligated to obey a French court order? I can probably name a few countries where most US companies won't enforce the court order from them reply callalex 2 hours agorootparentThey have paying customers in France/they operate their business in France for a profit. Just because their headquarters aren’t there doesn’t make it a non-French related business. reply ls612 18 hours agorootparentprevThere's a really bad equilibrium where every country (or at least every country big enough to have BigTech workers in their country) figures out they can globally censor the internet by using the assets and people of those companies as leverage. Then we would have Americans having their internet censored by every foreign power except China and Russia, where BigTech have largely left. And it would all be done under the color of local law. reply jsnell 18 hours agorootparentI see nothing in this article suggesting that the court order is for a global block, rather than a regional one. Do you have a source for that? reply ls612 18 hours agorootparentDoes Cloudflare operate different 1.1.1.1s for each country? reply Volundr 17 hours agorootparentIt's not required that they do so in order to implement a France only block. They just geolocate the requesting IP, and give different answers based on that. Same as Netflix or any other provider geo blocking there content, with the same workarounds. But also, in answer to your question, sort of, yes. 1.1.1.1 is any cast so that users will be routed to a server geographically near them. So then 1.1.1.1 a user gets in the US is quite literally a different one than a user in France will get. reply NilMostChill 15 hours agorootparentThe venn diagram of people who are technically savvy enough to be able to alter their dns records and people who can and will use a VPN to work around an ip geolocation block is almost a single circle. reply anymouse123456 18 hours agorootparentprevThe article is too thin to know what, if any fight was had. I suspect France could find a way to make things very difficult for them all. I suppose they could withdraw their service from the country in protest, but it's not obvious that would leave anyone better off. It's a difficult call and I'm not prepared to harshly judge an organization for complying with a legal, enforceable injunction. reply anymouse123456 18 hours agorootparentprevIf you want to judge someone so badly, why not go after the politicians who are creating these despicable policies? reply dang 17 hours agoparentprevFixed now, although leaving out the court order is also misleading. If anyone wants to suggest an accurate, neutral title that gets it all under the 80 char limit, we can change it again. reply imadj 13 hours agorootparentGoogle, Cloudflare, and Cisco will poison DNS to Block Piracy as Ordered by Court reply quaintdev 15 hours agorootparentprevAsked ChatGPT, it came up with this Court Orders Google, Cloudflare & Cisco to Poison DNS to Stop Piracy reply dang 3 hours agorootparentNot bad - I've consed \"French\" onto it and put it above. reply Imagenuity 12 hours agoparentprevGoogle runs widely used public DNS server 8.8.8.8 Cloudflare runs widely used public DNS server 1.1.1.1 That's my guess why these two companies were singled out. reply TZubiri 18 hours agoparentprevAlso, the country (france) is ordering the \"poisoning\", these american companies just comply with local regulations. Heavily biased article. Remember that dns/ip systems are decentralized at the national precisely so that countries have sovereignity. The editorial line would have us believe that france is committing a free speech crime or overturning internet infrastructure, while in actuality they are exherting their national rights. reply sealeck 8 hours agorootparentThis is literally just a framing issue. Note first that people generally believe in universal human rights, e.g. states shouldn't be allowed to do horrible things (e.g. genocide) just because they would be asserting their national rights. Further the action of a single state often influences other states, as is especially true when it comes to the internet which is global by nature. reply TZubiri 5 hours agorootparentIf you are comparing genocide with blocking pirating websites, I'm out reply jedberg 19 hours agoparentprevProbably because HN limits titles to 80 characters, so OP had to choose one to get under the limit. reply mkl 18 hours agorootparentNo, it's editorialising. The original title \"Google, Cloudflare & Cisco Will Poison DNS to Stop Piracy Block Circumvention\" is 77 characters. reply thejazzman 20 hours agoparentprevThey're the most respected / most surprising? reply Copenjin 11 hours agorootparentRespected by who? reply callalex 2 hours agorootparentRespect might not be the right word, but during their meteoric rise to popularity in the past decade they have consistently shouted “we don’t moderate content, we’re just a dumb pipe, don’t take this up with us take it up with the publisher!” In the past 3 years or so they have repeatedly proven that to be a lie; they weren’t able to have their cake and eat it too. But their old reputation still sticks around amongst people who don’t follow the space that closely. reply dcow 20 hours agorootparentprevDoubtful. reply shadowfiend 20 hours agoprevThe only provider here who is stated to have said they will be complying is Google, right? So not only is singling out cloudflare incorrect, the title itself is incorrect. “French court orders Cloudflare, Google, and Cisco to poison DNS to stop piracy block circumvention” is the correct title for the article contents, possibly with an addendum of Google saying it will comply. reply belorn 19 hours agoprevIt is times like this that I recommend technically inclined people to try setting up your own dns resolver and see how minimal impact a few/handful of milliseconds on first access has on the internet experience. Practically all popular domains also uses some form of anycast network, so the benefit of a single large shared resolver that caches the dns answers has steadily decreased each year. Just make sure its not configured to be a public resolver, and only allow local network or whitelisted addresses. reply josephcsible 19 hours agoparentSetting up your own recursive DNS resolver to circumvent ISP blocks is pointless unless you do so on a VPS or something, because otherwise, your ISP will just hijack the recursive queries it makes. And DNSSEC doesn't help if the ISP just wants to block you from learning the real IP. reply lucb1e 16 hours agorootparent> your ISP will just hijack the recursive queries it makes This level of deep packet inspection and injection is not what ISPs commonly do in my experience. At this point, it is much easier to just block the service's IP addresses than deep-inspect DNS traffic and match the query identifier and stuff to inject a false response. Why spend that engineering time when people will just fix the DNS server and can access the site directly? Might as well force people to set up a full tunnel (such as a VPN) to bypass the block, if your ISP or court order shows this level of motivation anyway. Insofar as I've experienced these things: fetching the mapping yourself, from a server not operated by your ISP, will circumvent DNS blocks your ISP was ordered to put in place. Currently I've got live access to one such blocking mechanism: $ dig +short thepiratebay.org 195.121.82.125 $ dig +short +trace thepiratebay.orgtail -1 A 162.159.137.6 from server 172.64.35.164 in 5 ms. The +trace option makes dig trace the delegations from root server (\"who is .org?\") until authoritative answer (\"who is piratebay.org?\"), basically this makes it a recursive resolver whereas in the default case it just asks your configured nameserver. The first IP address is a block page (accessible from outside the network, if anyone wants to take a look), the second one of the real IP addresses reply josephcsible 16 hours agorootparent> At this point, it is much easier to just block the service's IP addresses than deep-inspect DNS traffic and match the query identifier and stuff to inject a false response. Why spend that engineering time when people will just fix the DNS server and can access the site directly? Because IP addresses can change frequently, and also because if a site is behind a CDN, that would cause a lot of collateral damage. > The first IP address is a block page (accessible from outside the network, if anyone wants to take a look), the second one of the real IP addresses Okay, so your ISP's particular blocking mechanism doesn't hijack recursive queries. But others do. reply belorn 7 hours agorootparentCould you give a example of such ISP? I have seen ISP block all DNS traffic beyond to their own server, but those have been fairly locked networks like hotel wifi. It is much cheaper, safer, and less fragile to just block everything and force customers to the isp own servers. DPI and traffic injection carries risk of false positives and minor engineering mistakes can create large support costs, and would really only be beneficial if the intention is to hide the fact of the block. reply josephcsible 3 hours agorootparent> It is much cheaper, safer, and less fragile to just block everything and force customers to the isp own servers. Sure, that's common too. But that also precludes you from running your own recursive resolver to circumvent their blocks. reply hsbauauvhabzb 18 hours agorootparentprevI’ve heard this before. Is there a way to reliably detect if this is occurring or case studies of where this has occurred? Edit: I assume dns over https prevents this also, right? reply AnthonyMouse 18 hours agorootparentDNSSEC would reveal that it's happening straight away, but that doesn't get you the IP address. Of course, as mentioned putting your recursive DNS server on a cheap VPS somewhere that doesn't hack your connection would. reply josephcsible 18 hours agorootparentprevYes, DoH prevents that, unless the DoH provider is in on it too, which most of the major ones are now, as this article is about. reply cryptonector 15 hours agorootparentprevDJB was right. reply dano 13 hours agoparentprevhttps://docs.pi-hole.net/guides/dns/unbound/ reply taneq 19 hours agoparentprevThis was a big surprise for me when I set up a local DNS for work. Everything suddenly felt much snappier. reply JackSlateur 3 hours agoprevTechnically, google did it right (using the \"censored\" error code: https://datatracker.ietf.org/doc/html/rfc8914#name-extended-...): root@jack:~# dig footybite.cc @8.8.8.8 ; > DiG 9.18.19-1~deb12u1-Debian > footybite.cc @8.8.8.8 ;; global options: +cmd ;; Got answer: ;; ->>HEADER?\" reply bastien2 19 hours agoprevA great example of why you should be running your own validating recursor instead of relying on a third party reply OptionOfT 18 hours agoparentCan you elaborate on the validating part? reply betaby 17 hours agorootparenthttps://www.icann.org/resources/pages/dnssec-what-is-it-why-... And how to enable it on `unbound` https://www.howtoforge.com/how-to-set-up-local-dns-with-unbo... reply hsbauauvhabzb 18 hours agoprevI’ve always been curious why dns is a go-to for oppressing unwanted websites. Is it truly difficult to block at an IP level? There would be collateral damage in doing so, but it wouldn’t take long for most VPS providers to dump piracy sites if the alternate is their entire network block being dropped. reply OptionOfT 18 hours agoparentA good amount of these websites are proxied by Cloudflare, so you're connecting to CF and CF connects to the website. And many websites use CF, so if you were to block a CF IP, you'd block a whole bunch of websites. reply derekp7 8 hours agorootparentIn that case, what makes Cloudflare immune to court ordered blocks? reply AnthonyMouse 18 hours agoparentprevYou've identified exactly the problem. They'd be blocking thousands of unrelated innocent websites. Also, changing your IP address is really easy. reply santiagobasulto 13 hours agoprevThis is a great opportunity for a VPN provider to come up with an extra product being a paid DNS resolver. reply aryonoco 7 hours agoparentMullvad has it and it's not even paid, it's free. reply 1vuio0pswjnm7 18 hours agoprev\"A French court has ordered Google, Cloudflare, and Cisco to poison their DNS resolvers to prevent circumvention of blocking measures, targeting around 117 pirate sports streaming domains.\" Most if not all of these domains probably use Cloudflare as their authoritative DNS servers because they are using Cloudflare CDN. Why not just ask Cloudflare to \"poison\" those RRs. No need to issue orders to a selection of cache operators. reply gostsamo 15 hours agoprevIt is funny how the article lists the blocked websites and what content could be found there. Barbara strikes again. reply w-ll 15 hours agoparentare you not aware of torrentfreak? reply gostsamo 14 hours agorootparentI'm, but it is still funny. reply MenhirMike 14 hours agoprevSo, with 1.1.1.1 and 8.8.8.8 being useless then, what DNS Server is recommended going forward? reply Aldqueath 10 hours agoparentPersonally I use quad9 (https://www.quad9.net) reply _rs 13 hours agoparentprevMaybe opendns or nextdns? reply jpc0 10 hours agorootparentOpendns is literally cisco umbrella with less features. Which is one of the companies in the title. reply amarcheschi 11 hours agoprevIn Italy we gave rights to a private company to tell all ISPs what sites should be blocked by ip. Eventually, other websites go down when some cloudflare ip gets blocked reply sva_ 20 hours agoprevWell that could be considered a pretty useful list reply OscarTheGrinch 15 hours agoprevA new law requires plant shops to stop selling poisonous plants. If people really want to grow these plants they will find a way. Nature still exists. reply mlhpdx 17 hours agoprevI’d just add the IPs to my LMHOSTS file (Windows) if I really wanted to watch sports badly enough. I mean, I was doing that back in the day for local development anyway. reply vinay_ys 12 hours agoprevThere are many such local laws limitations that big techs have to bow to (that smaller obscure companies choose not to). For example, Google won't offer its VPN service as part of Google One in India. Whereas, proton/mullvad works just fine. reply mhitza 6 hours agoprevNo mention in dns0.eu, which is what I use and also hosted in the EU. reply hgyjnbdet 14 hours agoprevSo if you're using something like a pihole, and provided you're not using any of the mentioned companies, your go to go? reply gruez 5 hours agoparentAFAIK pihole still relies on an external recursive resolver (at least by default), so you'd still be subject to whatever blocks your ISP/cloudflare/google imposes. reply egberts1 11 hours agoprevThat's easy to circumvent. A VPS host running DNS resolver and point your boxes to it. You're welcome. reply egberts1 11 hours agoparentUnless France starts blocking DNS port 53/udp and 53/tcp and start whitelisting DNS servers ... :-/ reply KiloCNC 11 hours agorootparentThis would be the point where DNS over HTTPS would save the day if it had more widespread adoption.. reply egberts1 6 hours agorootparentAnd ultimately DNS over TCP should it further devolves into. reply pabs3 14 hours agoprevWonder why they don't just go after the DNS registrars for these domains, or the DNS root servers. reply wdb 9 hours agoprevIf you need to poison the DNS by court order. Can you also just poison the requestees DNS entries? E.g. Canal+ own websites? reply gruez 5 hours agoparentChildishness aside, this is a dumb idea because it's going to piss off more users than appease. Most don't care about the struggle for internet freedom or whatever, and just want their sites to work. For them blocking legitimate sites a sign that their ISP is broken, especially when their friends/colleges report that it's working fine on their connections. Moreover blocking illegal streaming sites is court sanctioned whereas blocking the plaintiff's sites is not, and likely expose them to getting sued for tortious interference or similar. reply wdb 3 hours agorootparentYou could just redirect it to the page they need to show for the bad sites :) reply gruez 0 minutes agorootparentI'm not sure how that's any less childish/tortious interference. At the end of the day you're still unilaterally deciding to interfere with some company's website. struant 8 hours agoparentprevThat is really good point. The court is basically giving them permission to do this, by asking them to not have net neutrality. reply TZubiri 18 hours agoprevThis looks like such a non issue to be honest. Government branches should have technical and legal capabilities to block domestic and foreign hosts. Legitimate foreign service providers, should either comply with local government, cease operations in that country, or be prepared for war. reply josephcsible 14 hours agoparentWouldn't China's GFW be considered a good thing by that argument? reply TZubiri 5 hours agorootparentNot a fan of categorizing stuff as good or bad. But yes, countries should have control over their borders, both physical and digital. reply mrbluecoat 17 hours agoprevI'm sure that will work. (too bad HN can't load my sarcasm font) reply blackeyeblitzar 19 hours agoprevIs there some decentralized anti-censorship technology that can prevent this type of action, where ISPs and DNS providers and other points of centralization are forced to implement things on behalf of other parties (like Canal+ or a government)? reply Anunayj 19 hours agoparentWell there are a couple of ways one can do this! 1. Recursively lookup DNS, so domains will have to be blocked at the registrar level, since DNS is unencrypted, it can be blocked at ISP level as well. 2. Use a protocol alternative to DNS, a good mature example is GNS. It aims to replace DNS, with a built from group up, modernish protocol. Using a DHT and public-key cryptography. 3. There are \"block chain\" solutions to the whole domain problem, look at Handshake, ENS etc. reply Dalewyn 19 hours agoparentprevNo. No matter how decentralized something is, ultimately you need to have a server and cables connecting it to the internet located somewhere. That somewhere will be within some legal entity or sovereign's jurisdiction which you must answer to and comply with. reply can16358p 18 hours agorootparentAs long as the protocol is easy to detect and block. If whatever technology that is being used is so intertwined into the base of all use cases (including totally legal) and legal vs. illegal is practically indistinguishable at scale, then decentralization cannot be blocked without physically blocking all the legal use cases too: sure they can \"cut cables\" but it will have much more greater consequences as they have just cut cables connecting all the legal activity too. reply Dalewyn 14 hours agorootparentI mean, this is literally a case of killing off the general infrastructure to stop illegal activities. DNS can be used for both legal and illegal purposes, and the French courts authorized dropping nukes on them to stop illegal activities with no damns given to the legal because the laws cited provided no such safeguards or reservations. reply immibis 13 hours agorootparentprevHave you ever used Tor? reply kmeisthax 19 hours agoparentprevDecentralized and global consensus are contradictory properties, in order to have an otherwise arbitrary ASCII string resolve to a particular machine EVERYWHERE, you need a central authority to say who's who. If you just want to prevent other central authorities (e.g. France) from barging in on the existing central authorities your computer expects to get answers from (e.g. ICANN, Verisign etc) there are plenty of projects for semiuncensoring DNS in a distributed way. But nobody is stopping, say, the US from doing to ICANN or Verisign what France is doing to CloudFlare and Google. reply redox99 19 hours agorootparent> Decentralized and global consensus are contradictory properties That's literally what blockchain solves. ENS (Ethereum Naming Service) already does this. reply immibis 13 hours agorootparentThe ethereum block chain is centralized - it may not have a geographical location, but there's still only one of it. In a global partition there become zero of it (only two incorrect fragments), not two of it. Other people have even argued that blockchains are states - as in governments, not as in distributed state replication protocols. reply m3kw9 15 hours agoprevOnly in France? reply Jamie9912 19 hours agoprevCouldn't Cloudflare route these DNS queries outside the country, and therefore not be subject to French laws? reply jedberg 19 hours agoparentThey could, but it would be weird. They use anycast for their DNS, so it will land on the French server before they know what the query is. There isn't really a way to tell a client, \"no go to another server with the same IP address\". But also they still want all the other French traffic to go to the French servers for performance reasons, so they wouldn't want to send all French traffic outside the country. reply TZubiri 18 hours agoprevAlternative title: French courts order American DNS providers to block unlicensed sports streaming websites. reply gruez 4 hours agoparent*American multinationals Your claim would make sense if they had no operations in France, but I highly doubt that's the case. If you operate in those countries, you have to comply with their laws. The fact that your company is incorporated elsewhere is irrelevant. reply TZubiri 4 hours agorootparentI agree. It would be pretty wild for courts to issue an order for something outside french soil. reply betaby 17 hours agoparentprevWhile refuting the fact that said unlicensed streaming websites are not hosted on American DNS servers. reply kgeist 14 hours agoprevI wonder if it's possible to just use Yandex DNS. Russia won't comply obviously. reply adam_hn 8 hours agoparentAlso, Yandex search is the best for certain search queries that google and American companies want/forced to remove. reply Shank 14 hours agoparentprevWith this DNS provider, I would be equally if not more worried about what the Russian government forces Yandex to block or censor. reply popcalc 14 hours agorootparentJust add 1.1.1.1 as the second dns server reply musicale 18 hours agoprev> rightsholders can demand “all proportionate measures likely to prevent or put an end to this infringement, against any person likely to contribute to remedying it.” Rightsholder: \"Let's see, life insurance payouts are €1M and we are losing at least €50M to these sites, so...\" reply zokier 11 hours agoprev [–] You know what would stop these judical overreaches? If rampant piracy stopped. Watching sports is not essential utility, this is not some moral dilemma \"is it acceptable to steal bread to feed starving children\", its more just \"is it acceptable to steal champagne for partying\" reply machomaster 11 hours agoparentRampant? Read the article before commenting, they are talking about 800 people in the whole of France. It's clearly not about severity, but about control. They would try the overreach even if there is no damage to be found (like using ridiculous \"this is the money we lost\" calculations). reply gruez 5 hours agorootparent>Rampant? Read the article before commenting, they are talking about 800 people in the whole of France. 800 is the figure given by google's attorney for people that would be affected by the block enforced by public DNS servers, not the total amount of \"rampant piracy\" that's going on. reply immibis 8 hours agoparentprev [–] Logical extensions of this principle: * Domestic abuse is the victim's fault because they shouldn't have made their partner angry. * The Chinese GFW is the fault of the people who criticized the government. They shouldn't criticize the government. * Israel indiscriminately bombing Gaza is the fault of the Gazans who fought back the last time Israel did that. * The Holocaust is the Jews' fault for not fleeing the country sooner. I don't think it's a good principle. reply gruez 5 hours agorootparent [–] >* Domestic abuse is the victim's fault because they shouldn't have made their partner angry. * The Chinese GFW is the fault of the people who criticized the government. They shouldn't criticize the government. * Israel indiscriminately bombing Gaza is the fault of the Gazans who fought back the last time Israel did that. * The Holocaust is the Jews' fault for not fleeing the country sooner. Except in all those cases, you can vaguely make the case that the \"victims\" were in the right (eg. the right to be not physically assaulted). It's far more questionable to claim that people have the right to free live sports streaming. reply immibis 3 hours agorootparent [–] Doesn't matter. Even if you have no right to be annoying, being annoying doesn't justify punching you in the face. Even if you have no right to kill 100 people, killing 100 people still doesn't justify killing 50000 people. Even if you have no right to watch sportsball, watching sportsball doesn't justify shutting down the Internet. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "A French court has mandated Google, Cloudflare, and Cisco to block access to approximately 117 pirate sports streaming domains via their DNS resolvers, intensifying anti-piracy efforts for broadcaster Canal+.",
      "Canal+ has also been granted permission to remove these sites from search results, leveraging existing site-blocking laws in France to combat piracy.",
      "Despite arguments about the minimal impact on piracy rates, the court upheld Canal+'s rights, and Google has confirmed it will comply with the order, raising questions about future anti-piracy strategies."
    ],
    "commentSummary": [
      "A French court has mandated Google, Cloudflare, and Cisco to alter their DNS resolvers to block access to approximately 117 pirate sports streaming domains.",
      "This ruling contrasts with previous resistance from tech companies against similar U.S. legislation, highlighting a shift in their stance to maintain control and avoid legal issues.",
      "Critics propose using personal DNS resolvers to circumvent these blocks, sparking ongoing debates about the balance between anti-piracy measures and internet freedom."
    ],
    "points": 295,
    "commentCount": 186,
    "retryCount": 0,
    "time": 1718493980
  },
  {
    "id": 40697831,
    "title": "The Raspberry Pi 5 Is No Match for a Tini-Mini-Micro PC",
    "originLink": "https://louwrentius.com/the-raspberry-pi-5-is-no-match-for-a-tini-mini-micro-pc.html",
    "originBody": "Louwrentius Home Solar About The Raspberry Pi 5 Is No Match for a Tini-Mini-Micro PC Sun 16 June 2024 Category: hardware I've always been fond of the idea of the Raspberry Pi. An energy efficient, small, cheap but capable computer. An ideal home server. Until the Pi 4, the Pi was not that capable, and only with the relatively recent Pi 5 (fall 2023) do I feel the Pi is OK performance wise, although still hampered by SD card performance1. And the Pi isn't that cheap either. The Pi 5 can be fitted with an NVME SSD, but for me it's too little, too late. Because I feel there is a type of computer on the market, that is much more compelling than the Pi. I'm talking about the tinyminimicro home lab 'revolution' started by servethehome.com about four years ago (2020). A 1L mini PC (Elitedesk 705 G4) with a Raspberry Pi 5 on top During the pandemic, the Raspberry Pi was in short supply and people started looking for alternatives. The people at servethehome realised that these small enterprise desktop PCs could be a good option. Dell (micro), Lenovo (tiny) and HP (mini) all make these small desktop PCs, which are also known as 1L (one liter) PCs. These Mini PC are not cheap2 when bought new, but older models are sold at a very steep discount as enterprises offload old models by the thousands on the second hand market (through intermediates). Although these computers are often several years old, they are still much faster than a Raspberry Pi (including the Pi 5) and can hold more RAM. I decided to buy two HP Elitedesk Mini PCs to try them out, one based on AMD and the other based on AMD. The HardwareElitedesk Mini G3 800 Elitedesk Mini G4 705 CPU Intel i5-6500 (65W) AMD Ryzen 3 PRO 2200GE (35W) RAM 16 GB (max 32 GB) 16 GB (max 32 GB) HDD 250 GB (SSD) 250 GB (NVME) Network 1Gb (Intel) 1Gb (Realtek) WiFi Not installed Not installed Display 2 x DP, 1 x VGA 3 x DP Remote management Yes No Idle power 4 W 10 W Price €160 €115 The AMD-based system is cheaper, but you 'pay' in higher idle power usage. In absolute terms 10 watt is still decent, but the Intel model directly competes with the Pi 5 on idle power consumption. Elitedesk 705 left, Elitedesk 800 right (click to enlarge) Regarding display output, these devices have two fixed displayport outputs, but there is one port that is configurable. It can be displayport, VGA or HDMI. Depending on the supplier you may be able to configure this option, or you can buy them separately for €15-€25 online. Click on image for official specs in PDF format Both models seem to be equipped with socketed CPUs. Although options for this formfactor are limited, it's possible to upgrade. Comparing cost with the Pi 5 The Raspberry Pi 5 with (max) 8 GB of RAM costs ~91 Euro, almost exactly the same price as the AMD-based mini PC3 in its base configuration (8GB RAM). Yet, with the Pi, you still need: power supply (€13) case (€11) SD card or NVME SSD (€10-€45) NVME hat (€15) (optional but would be more comparable) It's true that I'm comparing a new computer to a second hand device, and you can decide if that matters in this case. With a complete Pi 5 at around €160 including taxes and shipping, the AMD-based 1L PC is clearly the cheaper and still more capable option. Comparing performance with the Pi 5 The first two rows in this table show the Geekbench 6 score of the Intel and AMD mini PCs I've bought for evaluation. I've added the benchmark results of some other computers I've access to, just to provide some context. CPU Single-core Multi-core AMD Ryzen 3 PRO 2200GE (32W) 1148 3343 Intel i5-6500 (65W) 1307 3702 Mac Mini M2 2677 9984 Mac Mini i3-8100B 1250 3824 HP Microserver Gen8 Xeon E3-1200v2 744 2595 Raspberry Pi 5 806 1861 Intel i9-13900k 2938 21413 Intel E5-2680 v2 558 5859 Sure, these mini PCs won't come close to modern hardware like the Apple M2 or the intel i9. But if we look at the performance of the mini PCs we can observe that: The Intel i5-6500T CPU is 13% faster in single-core than the AMD Ryzen 3 PRO Both the Intel and AMD processors are 42% - 62% faster than the Pi 5 regarding single-core performance. Storage (performance) If there's one thing that really holds the Pi back, it's the SD card storage. If you buy a decent SD card (A1/A2) that doesn't have terrible random IOPs performance, you realise that you can get a SATA or NVME SSD for almost the same price that has more capacity and much better (random) IO performance. With the Pi 5, NVME SSD storage isn't standard and requires an extra hat. I feel that the missing integrated NVME storage option for the Pi 5 is a missed opportunity that - in my view - hurts the Pi 5. Now in contrast, the Intel-based mini PC came with a SATA SSD in a special mounting bracket. That bracket also contained a small fan(1) to keep the underlying NVME storage (not present) cooled. There is a fan under the SATA SSD (click to enlarge) The AMD-based mini PC was equipped with an NVME SSD and was not equipped with the SSD mounting bracket. The low price must come from somewhere... However, both systems have support for SATA SSD storage, an 80mm NVME SSD and a small 2230 slot for a WiFi card. There seems no room on the 705 G4 to put in a small SSD, but there are adapters available that convert the WiFi slot to a slot usable for an extra NVME SSD, which might be an option for the 800 G3. Noice levels (subjective) Both systems are barely audible at idle, but you will notice them (if you sensitive to that sort of thing). The AMD system seems to become quite loud under full load. The Intel system also became loud under full load, but much more like a Mac Mini: the noise is less loud and more tolerable in my view. Idle power consumption Elitedesk 800 (Intel) I can get the Intel-based Elitedesk 800 G3 to 3.5 watt at idle. Let that sink in for a moment. That's about the same power draw as the Raspberry Pi 5 at idle! Just installing Debian 12 instead of Windows 10 makes the idle power consumption drop from 10-11 watt to around 7 watt. Then on Debian, you: run apt install powertop run powertop --auto-tune (saves ~2 Watt) Unplug the monitor (run headless) (saves ~1 Watt) You have to put the powertop --auto-tune command in /etc/rc.local: #!/usr/bin/env bash powertop --auto-tune exit 0 Then apply chmod +x /etc/rc.local So, for about the same idle power draw you get so much more performance, and go beyond the max 8GB RAM of the Pi 5. Elitedesk 705 (AMD) I managed to get this system to 10-11 watt at idle, but it was a pain to get there. I measured around 11 Watts idle power consumption running a preinstalled Windows 11 (with monitor connected). After installing Debian 12 the system used 18 Watts at idle and so began a journey of many hours trying to solve this problem. The culprit is the integrated Radeon Vega GPU. To solve the problem you have to: Configure the 'bios' to only use UEFI Reinstall Debian 12 using UEFI install the appropriate firmware with apt install firmware-amd-graphics If you boot the computer using legacy 'bios' mode, the AMD Radeon firmware won't load no matter what you try. You can see this by issuing the commands: rmmod amdgpu modprobe amdgpu You may notice errors on the physical console or in the logs that the GPU driver isn't loaded because it's missing firmware (a lie). This whole process got me to around 12 Watt at idle. To get to ~10 Watts idle you need to do also run powertop --auto-tune and disconnect the monitor, as stated in the 'Intel' section earlier. Given the whole picture, 10-11 Watt at idle is perfectly okay for a home server, and if you just want the cheapest option possible, this is still a fine system. KVM Virtualisation I'm running vanilla KVM (Debian 12) on these Mini PCs and it works totally fine. I've created multiple virtual machines without issue and performance seemed perfectly adequate. Boot performance From the moment I pressed the power button to SSH connecting, it took 17 seconds for the Elitedesk 800. The Elitedesk 705 took 33 seconds until I got an SSH shell. These boot times include the 5 second boot delay within the GRUB bootloader screen that is default for Debian 12. Remote management support Some of you may be familiar with IPMI (ILO, DRAC, and so on) which is standard on most servers. But there is also similar technology for (enterprise) desktops. Intel AMT/ME is a technology used for remote out-of-band management of computers. It can be an interesting feature in a homelab environment but I have no need for it. If you want to try it, you can follow this guide. For most people, it may be best to disable the AMT/ME feature as it has a history of security vulnerabilities. This may not be a huge issue within a trusted home network, but you have been warned. The AMD-based Elitedesk 705 didn't came with equivalent remote management capabilities as far as I can tell. Alternatives The models discussed here are older models that are selected for a particular price point. Newer models from Lenovo, HP and Dell, equip more modern processors which are faster and have more cores. They are often also priced significantly higher. If you are looking for low-power small formfactor PCs with more potent or customisable hardware, you may want to look at second-hand NUC formfactor PCs. Stacking multiple mini PCs The AMD-based Elitedesk 705 G4 is closed at the top and it's possible to stack other mini PCs on top. The Intel-based Elitedesk 800 G3 has a perforated top enclosure, and putting another mini pc on top might suffocate the CPU fan. As you can see, the bottom/foot of the mini PC doubles as a VESA mount and has four screw holes. By putting some screws in those holes, you may effectively create standoffs that gives the machine below enough space to breathe (maybe you can use actual standoffs). Evaluation and conclusion I think these second-hand 1L tinyminimicro PCs are better suited to play the role of home (lab) server than the Raspberry Pi (5). The increased CPU performance, the built-in SSD/NVME support, the option to go beyond 8 GB of RAM (up to 32GB) and the price point on the second-hand market really makes a difference. I love the Raspberry Pi and I still have a ton of Pi 4s. This solar-powered blog is hosted on a Pi 4 because of the low power consumption and the availability of GPIO pins for the solar status display. That said, unless the Raspberry Pi becomes a lot cheaper (and more potent), I'm not so sure it's such a compelling home server. even a decent quality SD card is no match (in terms of random IOPs and sequential throughput) for a regular SATA or NVME SSD. The fact that the Pi 5 has no on-board NVME support is a huge shortcomming in my view. ↩ in the sense that you can buy a ton of fully decked out Pi 5s for the price of one such system. ↩ The base price included the external power brick and 256GB NVME storage. ↩ Comments Solar Status 71 TiB NAS 20C/40T 128G Server Projects fio-plot Showtools Storage Fan Control Grafana Dasboard for storage metrics Categories Apple Development hardware IT Linux Networking Projects Security Solar Storage Uncategorized ZFS Archive 2024 2023 2022 2021 2020 2019 2018 2017 2016 2015 2014 2013 2012 2011 2010 2009 2008 Social louwrentius Proudly powered by Pelican, which takes great advantage of Python. Based on the Gumby Framework",
    "commentLink": "https://news.ycombinator.com/item?id=40697831",
    "commentBody": "The Raspberry Pi 5 Is No Match for a Tini-Mini-Micro PC (louwrentius.com)257 points by louwrentius 5 hours agohidepastfavorite218 comments throwup238 4 hours agoThat's because RaspberryPis are no longer cheap throw away computers meant for education or hobbyists, they're developer kits for manufacturers that need a CPU running a well supported mainline Linux in their products. The only reason they don't cost $500 or more is because the foundation needs the hobbyist market to write and support the open source BSP, without which the RPi would be just another poorly supported also-ran in an already crowded market. With how well supported mainline Linux is on the Pi, EEs would be willing to pay a lot more. reply pclmulqdq 3 hours agoparentI think a lot of people don't realize that there was a decent size, but small market for SBCs for low-volume embedded work (including hobbyists) before Raspberry Pi. You could get a lot of different kinds of boards with good Linux support and a not terrible price. Often, a processor vendor would explicitly provide support for these things because it was a good vector for selling chips. Broadcom, having never wanted anything to do with this market since volumes were too low, had an abundance of a CPU SKU that was good for this. So some broadcom engineers founded Raspberry Pi to use up this excess stock, essentially getting these chips for free. The original RPi blew every other SBC out of the water on price performance (and many manufacturers out of the market) because by getting the most expensive component for free, they could sell Pis for an extremely low price. It also massively expanded the market for SBCs, as hobbyists flooded in to work with RPis. 5-10 years ago, the sweetheart deal with Broadcom went away. Now Raspberry Pi has to compete with everyone else for Broadcom SoCs, and during the semiconductor shortage of 2020, Broadcom had tremendous leverage. Now, Raspberry Pi pricing is nothing special, but they still have the brand name and they have captured the community (on the back of behavior that was borderline anticompetitive). reply ChuckMcM 2 hours agorootparentThis is spot on. There is a market for small SBCs that spans from weapons to washing machines. When the RPi was introduced it threw a huge wrench into that market because it came in, with an operating system and storage, at under the price for the typical enclosure, much less the board itself of the existing systems. Look at PC104 systems for example. The two pieces that have to be in place, as 'threshold' requirements are 1) The SBC exists and is available from a manufacturer 2) The same manufacturer provides an OS for that board and its associated board support package (BSP) which is drivers for all the I/O and system support functions. The industry is full of people who went out of business because they chose Vendor A's SBC and Vendor B's OS, only to fail to deliver when it didn't work with Vendor A and Vendor B point at the other saying it was their problem. So people just don't do that any more. What most vendors in the SBC space, prior to the introduction of the Raspberry Pi, didn't have was 20 to 30 thousand programmers writing random bits of code. What that meant was the Pi's feature set exploded rapidly, what's more there were lots of free tutorials on programming it. In the SBC space before Pi that \"Programmer Training\" was one of the ways the vendor made better margins at $500/hr for a class of \"up to 15 students\" at our facilities. So before, higher priced SBC + BSP, and you had to send your programmers on a road trip to the vendors facility to get the hands on training, and then you had to pay every time you made a service request. After, cheap SBC + BSP!, a bunch of different programming videos on the web for free! Program doesn't work? Just ask the community of enthusiasts what they think! We are not surprised a whole lot of the smaller SBC vendors closed down after that. reply throwup238 2 hours agorootparentprev> I think a lot of people don't realize that there was a decent size, but small market for SBCs for low-volume embedded work (including hobbyists) before Raspberry Pi. You could get a lot of different kinds of boards with good Linux support and a not terrible price. Often, a processor vendor would explicitly provide support for these things because it was a good vector for selling chips. Before RPi became really popular and the 4 came out, I used BeagleBoard, PandaBoard, Aria G25, Gumstix, Cubieboard, i.MX devkits, and spun custom boards using Marvell, TI, Freescale (now NXP), and Qualcomm CPUs - I don't remember any of them having as good a BSP or being as easy to develop with as the RPi was five years ago. Maybe my memory is (very) faulty but the experience was leagues worse. PTSD-inducing level of worse. I wasted weeks or months on every major project shaving silicon yaks that should have been handled by the vendor (and is now handled by the RPi community). The modern i.MX toolchain may now be comparable many years later but I've long since given up on everything else since CM4 came out in 2020. My understanding is that they lost the sweetheart deal after they pivoted to supporting commercial, right in time for the pandemic supply crunch. reply 05 1 hour agorootparentYocto works the same way whether it’s Pi or iMX, most of the learning curve has nothing to do with the SoC. So it’s really strange to hear that your Pi workflow is better than anything you’d get with another chip.. reply transpute 1 hour agorootparentBSP quality is famously variable by board vendor, https://www.youtube.com/watch?v=niH1-NB6W8w Two products.. leveraged a Yocto-based board support package (BSP); one being in AgTech, and the other being in the veterinary space. These products have followed disparate practices when leveraging the BSP for custom hardware and software.. this talk [described] the two products, how the BSP was customized and used, and the resulting consequences.* reply nottorp 1 hour agorootparentprevBut on a Pi you don't have to use Yocto. Raspbian is always faster to develop for. Source: have worked on both Pi based solutions and custom hardware with yocto. reply bloggie 1 hour agorootparentprevNot using Yocto simplifies and speeds development extremely, unless you have dedicated staff familiar with Yocto. It’s a big reason to prefer Pi. reply Aurornis 1 hour agorootparentprev> I think a lot of people don't realize that there was a decent size, but small market for SBCs for low-volume embedded work (including hobbyists) before Raspberry Pi. You could get a lot of different kinds of boards with good Linux support and a not terrible price. And you still can! The big innovation from Raspberry Pi was making it all feel very accessible through the documentation, community, and various utilities to configure things via menus instead of by editing files. The Raspberry Pi was rarely the best board, but it was the easiest to recommend to beginners because you could point them to volumes of documentation and community threads. reply transpute 2 hours agorootparentprevThis business history would add valuable context to RPi wiki, or a public reference on the history of SBCs, https://en.wikipedia.org/wiki/Raspberry_Pi reply justin66 51 minutes agorootparentprev> essentially getting these chips for free > by getting the most expensive component for free I get that you're exaggerating, and you perhaps aren't trying to be deceptive by misusing the word \"free,\" but the low markup the RPi guys initially paid to Broadcom does not explain as much as you think it does about the Pi's success. To explain why let's examine something else you're wrong about: > You could get a lot of different kinds of boards with good Linux support and a not terrible price. Often, a processor vendor would explicitly provide support for these things because it was a good vector for selling chips. Prior to the Pi you could get one board with good Linux support and a not terrible price from a vendor who provided support because they thought it was a good vector for selling chips. That was the BeagleBoard, from TI. I mean, the BB barely checked all those boxes: the support wasn't very good, it was kind of nonexistent compared to the support community the Raspberry Pi people created. But they sure didn't have to worry about the cost of the CPU. So back to the original point: getting the CPU \"for free\" (since we're apparently just saying \"free\" now when we mean \"at cost\") wasn't a decisive advantage for the Raspberry Pi people, since the TI people had the same advantage. TI had a few other advantages as well, like a first mover advantage, their own assembly lines, and relationships with everyone who sells electronics components. TI's support was crap when compared to something like RPi which deliberately targeted newbies, and as far as I remember they didn't have a few amazing people in their community dedicated to making a whole new spin of Debian and supporting it like RPi did. And, you know, PR matters. All that stuff is what made the difference. > anticompetitive I guess we're just throwing words around without caring what they mean today for some reason. reply ThrowawayR2 4 hours agoparentprevThe Model 1B was $35 (in 2012 dollars) and the still available Model 4B starts at $35? It might even be argued that the Model 1B's successor is more the Raspberry Pi Zero 2W for $15, which is cheaper than the original. The Raspberry Pi 5's base model does start at $60 but its specs are too different for a comparison to be meaningful. [EDIT] Oops, I hadn't realized the 4B with 1 GB was discontinued. So the starting price of the 4B would be $45 for the 2 GB version. reply AnotherGoodName 3 hours agorootparentThere are complete passively cooled n3350 based systems on Ali express with 64gb storage and 6gb ram in a case with power supply ready to go for $65 with free shipping. That works out cheaper than the cheapest pi after buying case, storage and power for the pi. You can buy usb gpio breakouts forOops, I hadn't realized the 4B with 1 GB was discontinued. Is it? I can buy one for $35 at my local Microcenter, and I can see that Adafruit is selling them for $35 as well. [0] It's still listed as a $35 part on the official Raspberry Pi product page. [1] [0] https://www.adafruit.com/product/4295 [1] https://www.raspberrypi.com/products/raspberry-pi-4-model-b/ reply stkdump 1 hour agorootparentprevInflation adjusted the 1B (with 512MB, which was the only available variant) was slightly more expensive than the 5 with 2GB at their respective release. The price \"increase\" is that 4 and 8GB models are available at all and most people buy them, presumably because people actually don't care about the purchase price so much. But you still get the cheapest variant, if you really want to. Also, there are different variants of the Zero, all of which are cheaper than the 1A at release. The power brick got more expensive due to the increased power use. Also if you want to make use of the full power, you need a cooler. But you can also do without cooler, because it just gracefully slows down when overheated. I think the Pi drove the price of lower end computers down so far that people completely lost their sense of perspective. reply justin66 33 minutes agorootparent> the 1B (with 512MB, which was the only available variant) Hey now. Proud owner of a 256MB 1B here. Although they upgraded the baseline spec right after that first production run. reply kohbo 3 hours agorootparentprevThose low price ones are never available. The cheapest 4b I see right now is $60. Which isn't bad, but not $35. reply ThrowawayR2 3 hours agorootparentI checked Digi-Key through RPiLocator and they report several thousand units in stock each of the Raspberry Pi 4 2GB at $45 and of the Raspberry Pi 3B+ 1GB at $35: https://rpilocator.com/?vendor=digikeyus For those unfamiliar with them, Digi-Key is a electronic components supplier to manufacturers but they also sell to individuals. Their stock count should be accurate. reply justin66 29 minutes agorootparentprevLook harder? They're available at a number of retailers, and if you're in the US, Adafruit is recommended - but I wouldn't pay more than $35 + shipping in any case. There are a couple of dozen online retailers here with the 4B 1GB: https://rpilocator.com/?cat=PI4 reply ianburrell 1 hour agorootparentprevEvery single official US retailer has units available for MSRP. Where are you looking? Which model are you looking at? Are you talking about the Pi5 4GB which is $60? We are talking about the Pi4 2GB which is $45. For many things, the cheaper, older version is fine. reply ahepp 39 minutes agoparentprevI see the Raspberry Pi model B+ available right now on Adafruit for $30. It has a single core 700 MHz CPU and 512M RAM. The Raspberry Pi Zero 2 W is available right now for $15 with a 1 GHz 64 bit quad core CPU and 512 MB RAM. So it seems to me that you can get a Raspberry Pi SBC today, that has higher or equal specs in every regard, for a lower cost than the original. Am I missing something? Looking at https://github.com/raspberrypi/linux, I scrolled a few pages of commits and didn't even see one from outside the Raspberry Pi org. I'm picking through their merged PRs and it looks like maybe there are a couple, it's hard to tell. But it looks to me like they just do a great job supporting their own product? reply justin66 4 hours agoparentprev> That's because RaspberryPis are no longer cheap throw away computers meant for education or hobbyists They’ve got a full product line now, including systems that are comparable in cost but much more capable than the original Raspberry Pi. reply Vogtinator 2 hours agoparentprevThe Pi 5 is still not supported mainline. Proper mainline support for older models was contributed by third-parties, not the RPi foundation, which just care about their kernel fork. reply SahAssar 4 hours agoparentprevWasn't there a very long time that the Pi wasn't fully supported on mainline? And it's boot sequence is still a bit weird in that the GPU handles bootstrapping? reply asddubs 3 hours agorootparentI think the main point is that you know the company/product support isn't just going to disappear into the sunset in 2 years and you're stuck with an increasingly outdated hacked together kernel thrown over a wall reply WillPostForFood 4 hours agoparentprevwell supported mainline Linux This is one of the main advantages for hobbyists. reply Aurornis 1 hour agorootparentGiven that Raspberry Pi hasn’t actually been well supported by mainline Linux and that the Raspberry Pi foundation hasn’t put a lot of effort into upstreaming things, I don’t think it’s actually a big deal. People don’t care where their kernel comes from as long as it works. I am surprised by all of the comments here that assume Raspberry Pi has great upstream support. It’s amazing that people just assumed their boards were working great with upstream kernels. Raspberry Pi has a history of doing nonstandard things that serve their community but are actually a little bit quirky when it comes to normal embedded Linux. reply gumby 3 hours agorootparentprevAnd for professionals. reply squarefoot 3 hours agorootparentI highly doubt so. In fact, save for the RP2040 which isn't Linux capable (0), all their processors aren't for sale anywhere; Broadcom simply won't sell them to you, no matter if you order 1 or 100000. That is, you can't build your product around one of their CPU and you have to put their entire boards in you product instead, which translates in huge costs, no industrial rated parts and forced use of SD cards for system disks, which in that context are a no-no. The RPi is a hobbyist board with a huge potential for teaching, but I wouldn't consider it for anything beyond that use. 0: yeah, I know you can run it in theory; I mean in a usable way. reply nottorp 1 hour agorootparent> no industrial rated parts and forced use of SD cards for system disks, which in that context are a no-no They kinda work if the system is not mission critical. Just have them self reboot every 4 hours :) reply yjftsjthsd-h 2 hours agorootparentprevThere's the compute modules reply ThrowawayR2 2 hours agorootparentprevIsn't their Compute Module 4 SOM industrial rated? reply squarefoot 2 hours agorootparentThat forces you to sandwich two boards together (connector, more costs, etc), and still you have no freedom regarding which peripherals to place around the RPi SoC. reply colejohnson66 2 hours agorootparentThere’s a free PCIe lane that you can put whatever you want on reply imtringued 44 minutes agorootparentprevThe average integrator doesn't want to mess around with things like DDR5 routing or designing power supplies for the SoC. There are lots of other companies such as AMD and Nvidia selling SOMs so the fact that they are selling SOMs can hardly be something to complain about. reply Aurornis 2 hours agoparentprev> they're developer kits for manufacturers that need a CPU running a well supported mainline Linux in their products. Raspberry Pi 5 isn’t as well supported in mainline. You’re still going to be using their kernel if you want all the features, just like many other module these days. > The only reason they don't cost $500 or more $500 is a huge exaggeration. There are numerous modules and small boards well under that price that come with good support, including many with full x86-64 CPUs. I think it’s more correct to say that the boards are approaching equilibrium with other boards and modules in price, not that they’re secretly some premium $500 product sold at a discount for reasons. Nobody would be buying Raspberry Pi anything at $250, let alone $500. reply whywhywhywhy 2 hours agoparentprev>they're developer kits for manufacturers that need a CPU running a well supported mainline Linux in their products It's not a great choice if you're hoping to productize from it, for various reasons. reply LtWorf 36 minutes agoparentprevYou forget gpio reply mytailorisrich 3 hours agoparentprevPlenty of PIs in labs of hardware tech companies. Very convenient when you need a small linux box, indeed, or when you need to access a piece of equipment over a serial terminal, et.c reply beardyw 4 hours agoprevThe pi has a lot of exposed pins and associated hardware capabilty. That was an intrinsic part of it's design. It's what got me interested in electronics again. Any comparison should include that. It was never meant to be just a computer. reply bri3d 3 hours agoparentThis. The Pi is a great little real worldcomputer interface. The hat ecosystem is really cool. Using one as a general computer is foolish. Unfortunately each Pi generation seems to move more towards the computer case and away from the real-world one. reply NegativeLatency 3 hours agorootparentThe RP2040 and pi zero are still very much not regular computers for desktop use: - https://www.raspberrypi.com/products/rp2040/ - https://www.raspberrypi.com/products/raspberry-pi-zero-w/ reply manojlds 9 minutes agoparentprevThey do talk a bit about it at the end with the solar powered setup they have. reply kalium-xyz 4 hours agoparentprevDepends on what youre comparing. Some people buy a pi just to run home assistant or some other compute task reply stavros 3 hours agorootparentI bought a few used NUCs for $150 each, they're amazing home servers. Much, much faster, more capable, more flexible than a Pi, at only twice the price. reply distances 3 hours agorootparentWhat do you use them for? I'm one of those that have Raspberry Pi 5 mostly just for Home Assistant. It's clearly overpowered for that use case, but I wanted the NVMe support. I'm not convinced by these articles -- used x86 box that maybe achieves almost the same low power draw still doesn't have any actual upsides if you don't realistically need that computing power. reply stavros 3 hours agorootparentI have one where I deployed K9s so I can learn Kubernetes better, and one where I have deployed Harbormaster (http://harbormaster.readthedocs.io/). The Harbormaster one has a bunch of stuff (Zigbee2MQTT, my smart home stuff, my apps, etc. I have a Pi 4 that has Octoprint, services on the NUC load instantly whereas Octoprint feels a bit sluggish. The NUC is an x86 (well, amd64) box, with a 10W power draw, which is great. I don't think a desktop PC will do less than 100W... reply AshamedCaptain 3 hours agorootparentYou can have full-size desktop PCs (large mobos, large GPU, multiple SSDs, fancy power supply) that idle at 20W. reply stavros 2 hours agorootparentReally? How? Mine is an order of magnitude more than that. reply nottorp 1 hour agorootparentNot sure about GPUs but I have a Ryzen 5 system under my desk which with the integrated graphics, 64 G ram and two SSDs idles at a little under 20 W. The M2 Mac Mini though idles at 12 or less... reply kccqzy 3 hours agorootparentprevI have a home server that stores and processes all my photos, using PhotoPrism. Things like face recognition does require a bit of a compute. A NUC is perfect for this use case. reply zimpenfish 1 hour agorootparentI've got one that does PhotoPrism + other media (sabnzbd, gerbera, flexget) as a general \"media storage\" box, one that just runs a Minecraft server, and one that's \"everything else\" (currently Home Assistant, Grafana, Prometheus, my webcam bird detection stuff, NATS, etc.) Originally started with HA on a Pi 4 but it wasn't really up to it. reply distances 2 hours agorootparentprevThat's a nice use case, thanks for the tip about PhotoPrism! reply distances 25 minutes agorootparentJust as a quick update after trying out: seems like a very nice local photo album service. The initial scan will take a long while, but looks like Pi5 is quite enough to handle the service after that completes. I will need a larger SSD for my Pi if I intend to keep all my photos in this, though. reply moffkalast 4 hours agorootparentprevSo you're saying that the Pi is a proverbial Toyota Hilux and people are buying it to highway commute to work and back instead of using it for what it was meant for, and then saying it compares poorly to sedan? Yea, no shit. If you're not using the GPIO or any of the ribbon cable peripherals there are much better options out there. But a Pi will be able to do things those machines never will. reply Johnny555 4 hours agorootparentI think they are comparing a $700 micro PC to an $80 Raspberry pi, but pretending they are in the same price range since the micro PC is available cheap in the refurb market. reply amluto 3 hours agorootparentYou don’t need to pay that much. For example, Minisforum is selling a barebones MS-01 for $399 new. This isn’t quite apples to apples — the Raspberry Pi includes RAM (but not much), whereas the MS-01 includes a case, a cooling system, a power supply, and an RTC battery. (And the MS-01 uses a non-janky 19V supply, whereas the Raspberry Pi 5 wants a weird not-to-spec not-quite-sure-what-they-were-thinking 5V USB supply by default.) For the price, you get massively more CPU power, 3x the number of easily connectable NVMe devices, at higher bandwidth each, 22x (!) the network bandwidth, and the ability to connect a real multi-lane PCIe card of your choice. I still find it sad that NVMe is an afterthought in the Raspberry Pi ecosystem. SD is convenient, but it’s also slooooow, and it holds back a lot of raspberry pi use cases. The new-to-RPi5 official NVMe support still seems really awkward in the way it interferes with the overall thermal performance and the way it interferes with the IO header if you use the official board. reply mech422 59 minutes agorootparentCheckout the odroid H+ series...about $125 for full x86 passively cooled system with dual nics, up to 32G of RAM, sata and m.2, etc. reply Johnny555 1 hour agorootparentprevYou don’t need to pay that much. For example, Minisforum is selling a barebones MS-01 for $399 new That doesn't really change my point that they are comparing the Pi to a PC that costs 4 - 8 times more (and in a much larger formfactor), so it's not surprising that it's faster. reply justinsaccount 1 hour agorootparentprev> 22x (!) the network bandwidth It's 25x, the copper ports are 2.5g. It's even more if you use the usb-4 ports for ip over thunderbolt. reply bigstrat2003 3 hours agorootparentprevNot only are they very different in price, the micro PC is 10x the size. Size doesn't matter for all uses, but there are going to be things where a Pi will fit but these micro PCs won't. reply mech422 1 hour agorootparentprevPersonally, I'm a fan of the odroid H+ series - full x86 SOC with dual nics, and some on-board gpu stuff for $125. I have 3 of the old H2 series and I love them. reply nine_k 3 hours agorootparentprevNo, an apt comparison would be with a PC like a used ThinkCentre off eBay, where $50 buys you an i5 with 8 GB RAM and a real SSD. reply imtringued 41 minutes agorootparentprevBmax B1 Pro costs less than $130 for 8GB RAM and it comes with 128GB storage and a case out of the box. reply mrighele 2 hours agorootparentprevFor $150 you can get a new mini pc with a low power intel cpu (e.g. N100) and 8GB of Ram. It comes with an SSD, a power supply and (gasp) a case. Add those to a raspberry pi and the price is not much different. reply manojlds 4 minutes agorootparentI have been looking at a N100, are they good in general as a Pi alternative. I am mostly looking at running K8s and running apps and running things like Pihole squarefoot 2 hours agorootparentprev$700? Here's one with 4GB RAM, 128GB eMMC and Linux already installed at $87,49. New. https://t.ly/S-OW6 (shortened Amazon link) Now the 4020 isn't certainly a monster, but I can assure you it's way more performant than a RPi. Also, bear in mind that, as is the case with many Chinese products, those mini PCs are produced in huge quantities and sold under at least a dozen different ever changing \"brands\". Don't let the name \"Wo-We\" make you think this is something deemed to disappear in a few months; the name could certainly be thrown away but the product will most certainly reincarnate under another \"brand\". reply Johnny555 1 hour agorootparentI got the $700 figuring by looking up the list price of one of the mini PC's mentioned in the article, which use an Intel i5-6500 or AMD Ryzen 3 PRO 2200GE CPU (which each have 4 cores @ 3.6Ghz), I think if they'd compared against a 2 core 2.8Ghz Celeron, it would have been more evenly matched. The Raspberry Pi 5 beats the 4020 in both single and multi-core performance in this benchmark: https://www.cpu-monkey.com/en/compare_cpu-raspberry_pi_5_b_b... Don't let the name \"Wo-We\" make you think this is something deemed to disappear in a few months; the name could certainly be thrown away but the product will most certainly reincarnate under another \"brand\". Does that matter? If it dies in 2 months and I can't find the manufacturer because it's operating under a different name now, is that any different than if the manufacturer folded completely? reply squarefoot 1 hour agorootparentThe manufacturer is the same, what dies is the brand name; the very same product is just being packaged in a box with another name. I mean, you shouldn't place too much importance in the name, just look at the real iron inside the box. We, as westerners, are used to give a lot of importance to brand names, possibly because it comes from the old times when brand names identified products with the families that created them; that is completely different from how it works in far east today. reply Johnny555 1 hour agorootparentThe reason I give importance to the brand name is because if the company has been around for a decade (or many decades), it's likely to still be around in a year or two to give me support when the product fails. If the company resurrects itself every 6 months under a different name, then there's effectively no warranty on the product and there's no reason to think that it's built to be long lasting, since even bad reviews won't show up under the new brand name. reply yumraj 2 hours agorootparentprevLinux already installed from a Chinese vendor. I guess it’s subsidized by the malwares that come preinstalled. reply squarefoot 1 hour agorootparentOK I understand the RPi must have very good press, but nitpicking every part of a message just to find something to attack isn't constructive. Linux preinstalled means that Linux works out of the box, that is, you don't even have to search around for Linux compatibility with any of the peripherals inside that mini PC. Of course I would never ever trust anything preinstalled, neither Linux nor Windows, just as I got rid of stock Android on my recently bought Pixel 7 in favor of GrapheneOS like 2 hours after unboxing it. I only meant about compatibility, certainly I wasn't suggesting that anyone runs unknown software from China. reply layer8 3 hours agoparentprevYou can add something like an Adafruit FT232H to the PC and still come out cheaper according to TFA’s price calculation. reply louwrentius 3 hours agoparentprevThe blog article is hosted on a Pi4, which also runs some python to manage the solar setup it is powered by. In particular I’m using the GPIO pins to drive the LCD display showing solar stats and a relay to disable/enable the inverter. reply afavour 3 hours agoparentprevYeah, the first thing you see on raspberrypi.org is: > Empowering young people to use computing technologies to shape the world With a link to learning resources. So the article is true but beside the point: the Pi 5 is no match for something the Pi isn’t even aiming to be. reply tjoff 4 hours agoprevI don't see the appeal of using these mini-PCs. Using an old second hand power supply is enough to turn me away. And the PI has many advantages. Power supply dies? I can order a new one in literally seconds. And meanwhile I wait for it to arrive I can use a spare notebook charger or whatever. Etc. The shortage sucked, but it is solved now. Last image I created I tucked in a Raspberry Pi 1, and it worked just fine. The versatility is unmatched. Equally I can test an image at my home and then let someone install it on the other side of the globe. The point of a Pi for me is more that you can have it where you need it. Attached to your TV or whatever. For a home server I would recommend something beefier, an old desktop will be superior to any mini-pc and the Pi. But probably bulkier and more power hungry. A Pi5 with nvme does work and be a decent home server for tinkering though. From my perspective the niche for the mini-PC is pretty much nonexistent. But I don't think maximum utility is the goal though, it is a hobby. Do what you enjoy! Tinkering with low power PCs might be enough of a reason alone. But these comparisons to the Pi doesn't make much sense to me. reply pelorat 35 minutes agoparentWell for one, they have an normal HDD interface. The worst part of a Pi is the SD card. It's truly the worst interface to use for booting off. Extremely unreliable and due to kernel bugs, having your system on an SD card is extremely unstable. (but that is more of a Linux issue than an Pi issue). reply amluto 2 hours agoparentprev> Power supply dies? I can order a new one in literally seconds. For the RPi 5, for fully reliable operation, you need an oddball 5V/5A power supply, which is not actually a standard device. IMO Raspberry Pi messed this one up. At the price point, either use a barrel jack or support USB-PD for real. (The latter would be great for many use cases, because the same conversion circuitry would enable driving from a wide voltage range. A tiny cheap ESP board can do this — why not a rather pricey Raspberry Pi?) reply tjoff 1 hour agorootparentIt is part of USB-PD though, it is just a recent addition (PPS) that isn't that common yet. I agree it isn't ideal, but you shouldn't blindly buy a PSU to any computer. Extra easy mistake to make when it is USB-C though. reply amluto 1 hour agorootparentI can’t find any evidence that RPi5 supports PPS or that anyone makes a 5V/5A PPS charger, except perhaps a massive 100W charger or something along those lines. It’s a silly voltage/current combination. edit: PPS is not supported. See: https://forums.raspberrypi.com/viewtopic.php?t=359918 https://github.com/raspberrypi/rpi-eeprom/issues/497 reply tjoff 6 minutes agorootparentThanks for the correction! reply ianburrell 1 hour agorootparentprevPPS is getting more common. Quite a few phones need PPS for fastest charging so seeing more chargers that support it. It is still cheaper to buy official charger but barely. And there are multi-port chargers where might be able to support multiple Pi5. reply goosedragons 4 hours agoparentprevYou can get new Mini PCs for not much more than a Pi 5, especially if you want an 8GB model, case etc. $150-$200 will get you an okay bottom barrel Intel PC with support for stuff like SATA and M.2 SSDs which are more annoying to have on the Pi. reply AnotherGoodName 3 hours agorootparentAnd $150 is overstating it. Look up ‘n3350 all in one’. Lots of models and retailers selling these atm. Intel must be selling these cpus for a few cents given the price for these complete systems with storage ram, case and power supply is ~$65 even when not on sale. reply ac29 2 hours agorootparentN3350 is nearly ten years old and I suspect a lot of the ultra cheap \"new\" systems using it are actually using salvaged parts. reply AnotherGoodName 46 minutes agorootparentI honestly don’t get it at all considering the sheer volume of these on the market right now. Is there any chance intel would run off an old low cost design that doesn’t compete with the high end just to keep the 14nm fabs busy? It seems like there’s too many on the market for salvage alone to explain it. reply jnovek 4 hours agoparentprevI use two of them (Lenovos) in my small homelab. They take up 1U side-by-side so they’re great if you have limited space. reply justsomehnguy 3 hours agoparentprev> I don't see the appeal of using these mini-PCs. Suprise - you are not the ones who do. > Using an old second hand power supply is enough to turn me away. > And the PI has many advantages. Power supply dies? I can order a new one in literally seconds'. This is a quite a stupid argument. a) it's totally the same for any other PC: you just order another 'in literally seconds' b) if you don't like a second hand PSU then order a new one in the first place > And meanwhile I wait for it to arrive I can use a spare notebook charger or whatever ... just like you can have a compatible charger for a mini-PC ?[0] > For a home server I would recommend something beefier, an old desktop will be superior to any mini-pc and the Pi For most of the people there is no need in 'beefier', 32Gb RAM, 256-1024Gb SATA/NVMe is all they need. > The point of a Pi for me is more that you can have it where you need it. Attached to your TV or whatever. Anyone can have mini-PC where they need it. It's because they are mini, not a desktop ones. [0] by the way, most of the time those mini-PCs have a notebook style external PSUs (not some anemic square brick of 15W) and they are quite rare to break reply tjoff 2 hours agorootparentThe argument was that you already have a PSU at home. Or in my small town I can get one in 15 minutes, or order it and have it delivered tomorrow. On the contrary, the notebook style external PSUs are more likely to break and much harder to find replacements to. When it has happened to me the best source to buy has been to order it from another country. reply Neywiny 4 hours agoprevI think these are great options for where pis aren't needed. Over the years I've seen a deluge of \"I needed a microcontroller but didn't know what that was so I used a pi\" and \"I needed little more than a docker image but I didn't know what that was so I used a pi\". The pi really comes in handy when you need the combo of the 2. Otherwise, people are just jacking up the price for those who really do need it. And that's not me, but rather people I've known who had great use cases and couldn't buy them. reply bmitc 3 hours agoparentAfter having bought Pis and then sold them all, I've never understood them. The Pico and Pi Zero seem to have a place, but the performance of the big Pi is so bad, it's rather pointless as an \"embedded\" computer or general purpose computer with a display. reply nkozyra 1 hour agorootparentFor an embedded computer you basically need to go bare metal with Circle or something similar. But then I'd wonder what you're building because there are powerful microcontrollers you can buy for $15/1 that will handle anything with basic networking and sensors. I know some musical synthesizers are made with rPi4 and I'm befuddled that they're not the most powerful synths ever made. I think they oddest one out is the Arduino line, which is generally underpowered and expensive compared to just having a drawer of esp32s sitting around. reply imtringued 31 minutes agorootparentThe Arduino \"line\" is a bunch of dev boards. The attiny40 chips cost less than $0.50 at high volumes. reply nkozyra 22 minutes agorootparentWell yeah I'm just saying they have a lot of overlap in the market with rPi despite being a much less powerful, different thing. Getting started with esp32 dev board is cheaper, more powerful, and not any harder, so I don't understand their niche. reply jki275 32 minutes agorootparentprevArduino pre-dates the existence of ESP, at least in the western market. Also, Arduino as I think you're using it here is really just slang for AVR microcontroller dev boards. Arduino isn't actually that, it's a boot loader and a highly simplified set of libraries to interact with a wide variety of microcontrollers including ESP-32 and what people traditionally think of as \"Arduino\" meaning the branded dev boards labelled that way. Of course the whole Arduino ecosystem is basically garbage, but it does help beginners get into the idea of doing embedded things. reply bongodongobob 2 hours agoparentprevThis is so true. Back when I used to use reddit, I had to leave the raspberry pi subreddit for this reason. 95% of the projects only needed a small C program and microcontroller but instead used a full blown OS and Python. It drove me nuts. reply InvaderFizz 4 hours agoprevCompletely depends on intended use case. If your goal is good compute and connectivity, a used minipc or a new N100 is the obvious choice. If you need GPIO, the Pi is the obvious choice. I end up with multiple N100 systems and a single RaspberryPi. reply mech422 53 minutes agoparentI use the odroid H series(1) for basic 'small server' usage. Dual nics for use as a firewall, DDR5 upto 48G, multiple sata ports, m.2 port, etc. Totally silent and very low power draw. They run from like $125 to $175 new, depending on model. I've had 3 of the old H2 series and I really love them... 1.https://ameridroid.com/products/odroid-h4-h4-h4-ultra reply GordonS 3 hours agoparentprevHow does the idle and loaded power draw compare between an Rpi 4 (or 5, if you prefer) and an N100? Genuinely would like to know, because I think power usage (and heat) is an important part of the equation. reply zamadatix 4 hours agoparentprevAlso worth considering getting the $6 Pi Pico microcontroller in such a pairing. Keeps the microcontroller capabilities at a lower cost and without having to maintain 2 operating systems across 2 different architectures. reply jsheard 4 hours agorootparentYeah, any PC can have GPIOs if you plug a cheap USB microcontroller into it. That's more or less how the Pi5 works internally anyway, as they've moved the main SOC to more modern silicon processes its internal GPIOs have become less able to tolerate hobbyist abuse, so now they proxy the GPIOs through their custom southbridge chip instead, which is an amalgamation of a microcontroller and various other peripherals. reply analog31 3 hours agorootparentIndeed, a USB MCU is my preferred GPIO these days. It makes my peripherals platform independent, and I can do my code development at my comfy desktop workstation with its big displays. I find it easier to write real-time code on the MCU. In fact, I've disciplined myself to make all of my projects -- hardware and software -- capable of running on any modern platform. It turns out that's not hard to do. reply Dalewyn 4 hours agoparentprevVery much this. If you just need a small, low power computer to be a server or whatever, it's hard to beat used business/enterprise SFF computers or a new N100 based NUC. rPi's defining use case is as a microcontroller, it can also serve as just a computer but it most definitely isn't optimized for that. reply nisa 4 hours agoprevNice overview, another venue worth looking at is thin clients. Some models like the Fujitsu Futro s740 are passive cooled, draw only 3-4w idle, can encode hevc in hardware and support up to 16gb memory and a nvme drive. There is a nice overview here: https://github.com/R3NE07/Futro-S740/blob/main/README_EN.md Another very similar alternative with support for 32g memory and dual channel is the Dell wyse 5070 https://github.com/pflavio/Dell-Wyse-5070-Home-Server/wiki These can be brought used for around 60-80€ on eBay. For about 150€ you can buy new Intel n100 mini computers on Ali express with similar low idle power but vastly better top performance. reply sspiff 4 hours agoparentI've been using some of these off-brand n100 mini PCs as a homelab cluster for the past year or so. Their physical size is smaller than a Raspberry Pi with case, and performance is more than twice a RPi5. And you get full x86 software compatibility. Idle power is around 4-5W measured from the wall. reply tacticalturtle 4 hours agoprevIf you’re in a small apartment or sensitive to noise, I think it’s still worth considering the Pi or a new fanless N100 system. I bought a tiny Lenovo i5-6500 system on eBay, and while it’s fantastic from a price/performance perspective, you can still hear a subtle whine when the ambient noise drops. Which makes total sense - the acoustic output is probably not a major consideration when they’re optimizing for footprint and cost. reply ulnarkressty 1 hour agoparentBuyer beware - Dell mini PCs also have this problem, they run constantly and are clearly audible in a quiet room. The BIOS doesn't have any options to disable or reduce the RPM, software sensors don't see the fan and if you unplug it or try to undervolt it the motherboard panics and doesn't boot anymore. Had to sell mine away. Otherwise they're a nice piece of kit. Perhaps someone can hack the BIOS to remove the fan protections. reply TacticalCoder 4 hours agoparentprev> I think it’s still worth considering the Pi or a new fanless N100 system. I bought a tiny Lenovo i5-6500 system on eBay, and while it’s fantastic from a price/performance perspective, you can still hear a subtle whine when the ambient noise drops. This. I basically made nearly the same comment somewhere else in this thread. But then we have similar nicknames so... reply tacticalturtle 3 hours agorootparentAnd at almost exactly the same time! Maybe some parallel universes crossed over. reply mynegation 2 hours agoparentprevThis is situation I am in and I went for a completely fanless mini ITX system that works very well for me for close to 10 years already (yes, it is time for an upgrade - probably to a fanless N100 based mini ITX). These systems are a great alternative to both Raspberry Pi’s (that now need fans) and those repurposed office PCs, even if you do not mind the fans. reply fbdab103 3 hours agoparentprevAt least for the lower power draw models, can you disable the fan entirely? Or cut the RPMs in half? reply tacticalturtle 2 hours agorootparentIt’s an i5-6500T, which is the same as the regular Skylake, but limited to a max of 2.5GHz I actually solved the problem by just discretely routing an Ethernet cable to a closet - but considering that it averages 10W from the wall, I definitely suspect I could get away with taking the lid off and adding a larger heat sink. reply scosman 3 hours agoprevNew vs used is mentioned, but kinda critical for the comparison. Yes a $60 board is definitely less capable than a $300 PC. The cost difference is primarily driven by the factors compared: better CPU, better IO, and more memory. You get what you pay for and you can get deals in the used market. Pi's are great for their ecosystem, being fanless, and cost for a brand new device. Aside: ESP32/ESP8266 have taken over a lot of the hobbyist realm for connectivity + GPIO. $3 dev boards that are plenty fast for almost any single use-case scenario. reply TacticalCoder 4 hours agoprevI find TFA interesting because I've got at home, both on my desk and in the closet, a mix of Raspberry Pis and... HP EliteDesk mini PCs / NUCs. I mean: literally the same HP EliteDesk as pictured in TFA. I bought three HP EliteDesk that were decommissioned from a nearby NATO base (so I bought them factory reset and without any hard disk in them). One advantage the EliteDesk do have is that they are not ARM, which can help at times when I need to run that's only shipped as an image and that wasn't compiled for ARM. I know there are other ways but, well, when that happens I just run that on the EliteDesk. Now the very obvious advantage the Raspberry Pi have: no fans. That is, to me, a big one. A huge one. My main PC is so quiet that I do hear the EliteDesk's fans when I turn one on. Typically I'll just run a Plex server at home on the EliteDesk and only turn it on when I want to stream something: the rest of the time they're off. The Pi do run servers not requiring lots of CPU: like an unbound DNS server. I don't see these as mutually exclusive: they can be complementary. If I had to pick only one I'd probably still pick a Pi though. reply louwrentius 3 hours agoparentThe Pi 5 needs a fan, unless you can find a special case that allows the device to run without a fan. I run the Pi4 which hosts this blog fan-less and that works fine, even 'right now'. reply distances 3 hours agorootparentNot the parent, but I run my Pi5 without a case, out of sight. I do have the Active Cooler fan on it, but on normal low intensity usage the fan turns on only during bootup and otherwise stays off. reply t43562 3 hours agorootparentprevYou can choose not to use a fan. reply IndySun 4 hours agoprevPerhaps the title could have been \"2nd Hand Tiny Mini Micro PCs are a match for new Raspberry Pi 5s in many aspects\"? reply Teknomancer 4 hours agoparentAgreed. The whole premise of this article is absurd. An apples to oranges a comparison. The Pi is a platform for embedded systems development and design. And is excellent for what it is designed for. It's not a desktop workstation. reply louwrentius 3 hours agorootparentThis blog post is not even talking about the role of these machines as a desktop workstation. reply atVelocet 4 hours agoprevIf you ever plan to use any of these older PCs: Disable Spectre and Meltdown mitigations! As a bonus you should also remove CPU microcodes from the BIOS/UEFI and make sure that no microcode is loaded via software. The performance gain is huge if done correctly. There is no need for these mitigations on homelabs. reply unique_parrot2 1 hour agoparentYou made me try this, my cpu went from 16% to 9% on my proxmox-box running a home-assistant vm and a few lxcs. Thanks for your post. reply kayson 1 hour agoparentprevAny guides on how to do this? reply jki275 30 minutes agorootparentUsually it's just a bios option you can turn off. reply johnchristopher 4 hours agoprevI don't have room for that tinyminimicro pc case. I could fit 8 pi's in it. > The Pi 5 can be fitted with an NVME SSD, but for me it's too little, too late. Because I feel there is a type of computer on the market, that is much more compelling than the Pi. My pi4 has been running from an ssd for years now, no sd card. Usb3,not nvme but still good enough for my (most ?) use case. reply earnesti 4 hours agoprevI always keep coming back to RPi because of the software support. Now when I think about it, basically everything is secondary to that. Most of the stuff with RPi just works like charm, and when not, you usually find tons of information how to make it working. Not so with other devices reply supportengineer 4 hours agoprevAdvantages of Raspberry Pi: No fans, no moving parts, no dust. Huge amount of software, documentation, support available. reply ThrowawayR2 4 hours agoparentThe Raspberry Pi 5's official heatsink comes with a fan and its collection of software is dwarfed by what's available for a x86 PC regardless of whether it's running Linux or Windows. reply distances 3 hours agorootparentThat fan stays idle on low loads, and if you wanted you could also leave it unplugged to just rely on the heatsink. Then again, N100 can also be bought with passive cooling. But not so sure how the mini PCs of the article would fare without a fan. reply jki275 28 minutes agorootparentI've been running a fanless mini-pc as a firewall for years. They work just fine. The ones you get from aliexpress come in a case where half of the case is a massive heat sink, and it will get a little bit warm. reply 42lux 4 hours agoparentprevMhm... mini PC: [X] No fans available with atoms or i3s [X] No moving parts [X] x86... Huge amount of software [X] documentation The only thing is support but the raspberry foundation is also not really helpful if you go into the nitty gritty parts. reply linux2647 4 hours agoparentprevThough a fan is recommended for the 4 and 5 models reply lomereiter 4 hours agoparentprevFor some Mini PCs there are fanless cases, e.g. from Akasa: https://akasa.co.uk/update.php?tpl=list%2FCHASSIS+POWER.tpl&... I've got one of those, and it houses a system with 8 CPU cores, 32 GB RAM (can be upgraded to 64 if need be), 1 TB NVMe and 4 TB SSD - and it's all inside, whereas with an RPi the SSD would have to be external. The only thing that's collecting dust now is the old RPi. reply rat9988 4 hours agoparentprevHuge amount of software compared to? reply TillE 4 hours agorootparentIf you're doing stuff with the GPIO, I'm sure there's far more software written for the Raspberry Pi than anything else. If you're just using it like a normal computer, then it's not special. reply michaelt 4 hours agorootparentThere is more and better GPIO support for Arduino, ESP32 and STM32 than anything Linux based. reply shadowgovt 4 hours agorootparentprevMostly other options with no fans, dust, or moving parts. The fact that you can run a Linux on it means you can tap into a big ecosystem of existing software. Nice to have. reply dingnuts 4 hours agorootparentprevgood question -- methinks the GP didn't read the article. the rpi does have a ton of software compared to other SBCs, but the article is about fking x86 machines. With power consumption so low on some of these, I feel like they defeat most of the benefit of ARM and you get way more native software on x86 reply tyingq 4 hours agoparentprevI would add GPIO pins that are also well documented. reply RenThraysk 3 hours agoparentprevRugged Intel NUCs have no fans. reply agumonkey 4 hours agoparentprevwhat software is rpi only ? honest question reply pmalynin 4 hours agorootparentNot sure if this is still the case but I thought you could get a free version of Wolfram Mathematica for RPI for free reply freeone3000 4 hours agorootparentIt’s available, but not free. The language server is free for all linuxes, sans data. reply hinkley 4 hours agorootparentprevRunning Mathematica on underpowered hardware lead me to hate Macs for over a decade. I have concerns. reply ddulaney 4 hours agorootparentprevAlmost everything can be modified or configured to run on another system, but it’s pretty common for RPi to be the default or best-tested platform. reply lhl 4 hours agoprevPi's are great for easy hardware hacking, but I don't know if they ever made that much sense as home servers. You could always pick up used office/minipcs for even cheaper than a bare pi board, and if you picked carefully, you wouldn't really be using much more idle power. Also €100-150 for those used 1L boxes sounds a bit pricey to me, since in that range you can buy brand new minipcs that perform similarly (personally for a network-centric device probably I'd go on aliexpress and grab one of the fanless N100 router-style pcs). reply mmastrac 3 hours agoparentThey are ridiculously overpowered for a number of usecases, even the older and cheaper 3 models. I'm running progscrape.com on a 4 and it held up to HN traffic without sweating at all. I had a Pi1 running Stylus for home monitoring with maybe 10% CPU use at any time. reply turtlebits 35 minutes agoprevYou don't buy a Pi for performance. You buy it for peace of mind. If one dies you can easily find a replacement and just swap out the SD card. reply pi-rat 17 minutes agoparentNot that different for the prodesk/elitedesk small form factors IMHO. There’s a steady supply of cheap used ones available on most online marketplaces (there’s probably millions of them being cycled out of offices every year). Get a new replacement one, swap over the NVME. Doesn’t have to be the same cpu, linux handles the rest. reply gizmo686 3 hours agoprevThese conversations around the rPi make no sense to me. To me the value of rPi has always been: * Simple to install a well supported OS with a full UI. * GPIO array (including pwm, i2c, etc) I could take one. Connect a keyboard and monitor. Jumper a few pins into a breadboard with an LED matrix, and right a python script to bitbang a multiplexed LED array The only other product I have seen that I view as even competing in the same space is the OrangePi line. However, those are vastly inferior in terms of support. reply AshamedCaptain 3 hours agoparentCompared to an x86 PC which is what TFA is showing ? The only argument in favour of the RPi is GPIOs, but \"simple to install\" and \"support\" definitely are a thousand times better on standard x86 PCs than on any of these ARM SBCs. reply gizmo686 2 hours agorootparentRight. It is the combination of the two features. If all you want is the GPIO array, there are thousands of other boards you could buy. If all you want is a well supported, easy to use computer, there are hundreds of options to choice from. If you want both in a single product, your options are very limited. reply nullify88 2 hours agoprevPowertop is a great utility for identifying wakeups and CPU C states, but for tweaking power management flags in Linux, I find TLP (https://linrunner.de/tlp/index.html) to achieve greater power savings at the \"cost\" of more configuration. reply Someone1234 4 hours agoprevI recently spent some time looking into exactly this. I ultimately decided to go with an N100 running Proxmox. It is a wonderful compromise between power utilization and compute. The N100 was roughly $50 more than the Pi 5 (after adding storage to the Pi). The idle cost to power both is roughly $5/year for the Pi5 and $10/year for an N100 (based on local electricity rates YMMV). I'd argue the Pi still has a purpose: Running it off of battery/solar is likely better, it is physically smaller, and it also has pin-outs and documentation/software to support it. If all you're after though is a small-low power usage computer, it may not be the first choice anymore. reply squarefoot 2 hours agoprevI've moved my media players and servers to mini PCs and unlocked Chromeboxes and couldn't be more happy. Performance is on another planet compared to the RPi. Mini PCs however can't be used when one needs a small board with lots of gpios, but there's a lot of (often cheaper and faster) competition in that field as well. Please, keep in mind that the usual story \"other boards don't have decent Linux support/community\" is simply not true. Here are Armbian and DietPi pages where you can find images with mainline support for a lot of common boards, including forums. Images supplied by the board manufacturer should rather be intended for quick testing only as you can't count on their support; just ignore them and go straight to Armbian or DietPi sites, and consider contributing for their hard work. https://www.armbian.com/download/ https://dietpi.com/#download reply tonymet 1 hour agoprevI consolidated about a dozen raspberry pis and virtual servers onto a Hyper V server https://info.microsoft.com/ww-landing-microsoft-hyper-v-serv... Hyper V Server runs any Linux VM via VHD or ISO installation image. You can provision using Vagrant to automate your setup. It was nice to consolidate all of my resources, clean up the spider web of raspberry pi’s, and reduce VM costs by running everything locally . reply stock_toaster 1 hour agoparentI’m curious… Why hyper-v and not something like proxmox? reply tonymet 1 hour agorootparentOriginally the server & VMs were running on my windows 11 pro dev machine. Keeping HyperV made it easier to move them to another machine. Now that I have a separate server, I find it easier to develop the VMs on my dev machine, snapshot and then migrate them to the server. I have a library of base images for alpine, Debian & Kali Linux that I can launch as easily as AWS. Using Hyper-V across both makes this seamless. I can manage the servers using the Windows Management Instrumentation (gui) or RDP into the server. I know many Linux users have aversion to Windows, but I get a lot of benefit out of Windows for other applications as well (gaming, one drive, document indexing, copilot, as well as all the great native apps) reply axegon_ 46 minutes agoprevWell... Yeah... I have a bunch of raspberry pis from back when they were cheap + a raspberry pi 400 I won at a hackathon a few years ago. There are things about them that I love(the older ones to be more specific): low power and great thermals. But ever since their prices skyrocketed, I have completely abandoned the newer ones and opted out for what me and my friends refer to as \"cubes\". Optiplex micros and similar ones. They are a tiny bit more expensive but you have expandable storage and memory and in lots of cases upgradable cpu if it comes down to it. And most importantly x86, which I take over ARM any day of the week, especially when I have to dive a layer or two deeper - it's just more convenient having all the additional tools. However I have one or two projects that I keep kicking down the road due to time constraints which involves a rasprerry pi zero w2. The reason being is that it's compact, packs a decent punch and is extremely easy to power it from an 18650 battery and keep a low profile. I'm fine with the current prices of the raspberry pis but it's hard to justify using one of them if you don't need GPIO pins or something that uses little power. My advice to the raspberry pi foundation is to stop trying to push performance and focus on features. I'd be the first in line to get a new raspberry if it comes with a battery hat and LoRa built in(the project I was referring to really). Here's another one(which ironically already sort of exists): the milkv duo. There are lots of cases when you don't need a full operating system 24/7, which would waste a lot of resources to do one-off tasks every now and then. Ideally you should be able to boot the OS from a sensor or some sort of signal, which is hooked to a very under-powered micro-controller only when you really need it, let it do it's job and then power it off. As we stand, the raspberry pi foundation largely offers the same product in different form factors with some arguably marginal upgrades, which most people don't really need. reply rcarmo 2 hours agoprevOf course it's not. It's not even a match against the Rockchip boards I've been testing over the past few months: https://taoofmac.com/space/blog/2024/06/16/1800 I also have recently gotten an N100 mini-PC, which helped me put one of my ancient mini-ITX i7 machines out to pasture. Those are amazing (and are dipping under $120 with 12GB RAM and 512GB SATA SSDs). But more to the point, I think the space the original Pi occupied in hobbyist land is being eaten up by RP2040 and ESP32 MCUs, which can do everything I need I/O wise and with increasingly sophisticated software support (MicroPython is amazing for prototyping, and I even got a WaveShare RP2040 board to test that is a direct drop-in replacement for a Pi Zero) reply PreInternet01 2 hours agoprevThis headline makes as much sense as \"the Kia Niro is no match for the Volvo FH\" -- it really all depends on what you want to do with it? RPi5 is a great platform for prototyping, and many hobbyist applications, even if you move to ESP32 or similar afterwards, or if you decide that PC-ish platforms work better for you after all. \"One size fits all\" has never worked in computing history and most likely never will... reply ein0p 2 hours agoprevMy home router runs on a dual core Intel Celeron. Software wise it’s OPNSense in KVM and a few docker containers on the host. Measured power draw is 4-5W. That’s with an SSD and 16GB RAM. It’s also way faster than any Raspberry Pi. The notion that Intel draws a lot of power is wildly outdated. reply diffeomorphism 4 hours agoprevUsed, many years old PCs are cheap compared to new, non-used ones and can be still perfectly sufficient for basic tasks. True, but also seems very apples to oranges. The proper comparison would be either be pi vs new mini PC (e.g. n100 based) or new mini PC vs used mini PC. reply xhrpost 3 hours agoprevThis is timely, after not getting my Orange pi to boot an image, I saw I can get an actual mini PC like these used on eBay for like $60 shipped. 8GB ram and 500gb SSD with small form factor. I'm considering buying more and trying to host some old school LAN parties as used LCD monitors can also be had for about $50. reply marricks 4 hours agoprevHas the Raspberry Pi tripled in price since launch? I was skeptical of all these threads of “this is better” but it doesn’t seem like it’s as ridiculously affordable as it once was. reply michaelt 4 hours agoparentThe original Raspberry Pi had a single-core 700MHz CPU and 256MB RAM. Right now I can buy: Raspberry Pi 5, 2.4GHz Quad-core CPU, 8GB for £76.80 Raspberry Pi 4, 1.5GHz Quad-core CPU, 1GB RAM, for £33.60 Raspberry Pi Zero 2 W, 1GHz Quad-core CPU, 512MB RAM, for £14.40 (None of those prices include SD card, PSU, case, or any peripherals) Is that a price rise, or just the high end getting higher? reply franciscop 4 hours agoprevI feel these comparisons are a bit funny. The \"RasPi 5 is no match for X\", showing a picture of a computer that seems around 5-8x times bigger in area, and probably around 20x bigger in volume. They also cost A LOT more, but if you get them second hand only +50%. Color me surprised, even when ignoring the general totally different markets of those, even as a tiny PC these are not fair comparisons (specially comparing a second-hand device to the full cost of a new Raspi, adding the accessories that we all hackers/makers already have). reply louwrentius 4 hours agoparentA ton of people use Pis as small home servers and for that use case, there are imho better options. reply franciscop 3 hours agorootparentYes, for ALL purposes that people use the Pis for there's definitely a better, more specific option. But that's the great thing of the Pis, that they are very general-purpose for hobbyists, while also being very well standardized and documented (and run Ubuntu). reply userbinator 50 minutes agoprevThe AMD-based system is cheaper, but you 'pay' in higher idle power usage. That 6W more costs around $5.26 per year at $0.10/kWh, which is basically nothing. reply krasin 47 minutes agoparentIn SF Bay Area, the cost of electricity is $0.42/kWh, so around $20/year for just extra idle usage. Still not a lot, but it adds up. reply rr808 4 hours agoprevRemember when the Pi first came out, it was cheap for small hobby projects. Rpi 5 is $80? At these prices you might as well get a refurb x86 micro pc. reply forinti 4 hours agoparentYou can still get a cheaper model. You don't have to buy a Pi 5. reply YetAnotherNick 1 hour agoparentprevRaspberry Pi 5 is $60 for 4 GB RAM. Raspberry Pi 1 was $35 in 2012, which is $50 just accounting for inflation. reply demondemidi 4 hours agoparentprevPlease point to the GPIO pins on the refurb PC. The PI is about making hardware hacking accessible on a linux-based platform. A refurb PC fails horribly at that. reply manfre 3 hours agorootparentI'd wager that most people are not using any GPIO on theirs. Typical usage is likely a low power computer they can optionally plug a USB cable into; 3d print controller, home assistant w/dongle, etc. reply White_Wolf 3 hours agorootparentprevI'm using AVR/STM for IO. have plenty of them around. Just loaded with a basic serial to IO passthrough program. Can't complain for £2 each on aliexpress. EDIT: added STM. reply numpad0 4 hours agorootparentprevBut what do you use Pi GPIO for? Using Pi GPIO directly leaves pins unconfigured or stuck while your app is inactive. Aren't most need for GPIO better served by Arduino + PC? reply ssl-3 1 hour agorootparentI have a Pi Zero W that is a spooky-good GPS-backed NTP server. It relies on GPIO for getting tightly-accurate PPS pulses from the GPS module (which a USB-connected Arduino won't help me with -- the timing would be much sloppier). I have also used a different Pi Zero W with an SDR dingle to decode APRS weather data, while also using GPIO to read a local DS18B20 temperature sensor and to switch a solid-state relay. I could have done this last thing with any random Linux-ey PC plus an Arduino, but then I'd have two problems. (It would have also cost me rather substantially more money: I bought these Zero Ws very, very cheaply from Microcenter.) reply jki275 23 minutes agorootparenthttps://github.com/DennisSc/PPS-ntp-server Not mine, just something I found. I had a feeling one could run a GPS backed NTP server on a microcontroller without too much difficulty. reply demondemidi 57 minutes agorootparentprevI don't think you understand how GPIO is used on a Raspbery Pi. You can flip GPIOs in a BASH script, or set events on them in Python. GPIOs are first-class citizens in Rpi land, which is what makes it so convenient: you get GPIOs + Linux, seamlessly. I have a Pi4 hooked up to a motion detector, a camera, a solenoid and some SCRs for a floodlight. A python script waits for an event interrupt from the motion detector on a GPIO. Then it turns on the lights and opens a door via GPIO, and starts recording in another thread (via a pipe to gstreamer). When the motion times out, it pushes the video to an private S3 bucket (using my own handshake for a token so that it can't be spammed). (I used to have some GPIOs connected to motorized cat toys so that I could trigger them remotely while watching an realtime stream, but that throttled the above camera which was more important.) ... It is also a BLE gateway that monitors 4 temperature sensors, and also pushes that data up to the cloud with another python script. ... and it also is an MQTT gateway for a few NXP WiFi devices scattered around the yard, and their data ... you guessed it... is pushed up to the cloud (they control sprinklers because BLE doesn't have the range). I can log into my personal website and turn sprinklers on from anywhere my phone works. Sure I could do the WiFi and BLE with a PC, but why waste the energy and space when I can use a tiny Pi that is already doing a bunch of other things? I just keep adding things to it because I have my own cloud system (HomeAssistant is a big fat bloated joke). Having a good BLE sensitivity and WiFi chip on a tiny linux board that runs dozens of python processes listening to GPIOs, and running Gstreamer would be too much of a hassle with a PC and far beyond an arduino. reply haunter 3 hours agoprevI have some of these mini PCs at home. Not just HP but Lenovo and Dell are also making them. A Dell Optiplex 3080 with i5-10500T, 16GB DDR4, and 256GB NVMe SSD is ~200€ and can be upgraded to 64GB RAM with a lot of storage (NVMe + a 2,5\") reply chad1n 2 hours agoprevRaspberry Pi is mostly an expensive toy at this point, it costs 60-80$ and it's pretty hard to buy one to begin with. You can't use it for most electronics projects because it's overkill and also it's not as powerful as a n100 or a second hand pc. If you are lucky, you can snipe a bunch of ryzen 3 hps or dells (if you don't need a lot of performance) for 60-80$ or ryzen 5s at 120$ (if you need a bit more). reply louwrentius 3 hours agoprevThe irony is that HN is now hitting my solar-powered Pi4 on which this blog is hosted, and the cores don't even go past 25% if they even get there. No need for a tiniminimicro to host a static blog site :-) reply raffraffraff 3 hours agoprevI wrote a post on my (deleted) blog back in 2022, and in it I documented some of the issues I ran into with the Raspberry pi 4 when I was building a media pc that I bolted onto the back of a TV. Briefly, the Pi absolutely sucked in a bunch of ways compared to the MeLE Quieter 3Q that replaced it. 1. Pi couldn't use USB 7.1 audio device in the mode I needed (7.1 out + line in). No idea why, but Linux totally froze up when I selected that mode, and remained frozen until I physically unplugged the usb device. On the same USB device this worked fine on other computers. This meant that I couldn't use my external Bluetooth receiver seamlessly via the Pi. 2. YouTube failed in a bunch of ways. Seriously! Neither Chrome nor Firefox would work 100% reliably. Sound issues on most videos, awful performance, locking up the browser. https://forums.raspberrypi.com/viewtopic.php?t=323640&start=... https://forums.raspberrypi.com/viewtopic.php?t=151632 3. Can't be put to sleep or remotely started using Wake On LAN 4. Lacking sufficient hardware encoders/decoders 5. Everything goes through the USB bus, so you get awful storage/network performance 6. Can't use Wine to run windows apps. While this may not be an issue for many people it was for me because I wanted to use MusicBee. Wine works fine on the Pi if you've got ARM compatible windows apps. So good luck with that. 7. The hassle and cost of getting a decent case. I ended up spending a few hundred bucks on the MeLe and everything just worked. Flawlessly. First time. And I had a wide-open choice of Linux distributions. reply complaintdept 4 hours agoprevOfftopic, but does anyone know of a decent mini pc with ECC? reply demondemidi 4 hours agoprevIt is odd to me that people call the RPi 3/4/5 \"not capable.\" It depends on your needs. I find it perfectly capable when I need more than an STM32/ESP, but less than a PC, which is about 90% of the gadgetry I find enjoyable. I don't understand all the anger. If you need a different platform, you need a different platform. /shrugs/ reply floating-io 3 hours agoparentI'm starting to wonder if we're seeing the ramping up of an Arm vs. Intel war at the same level as Mac vs. Windows, or emacs vs. vi, with Raspberry Pi as a convenient proxy, and all the usual foibles of every other us vs. them war. It wouldn't surprise me if paid influencers were fanning the flames, either; certain folks have a lot to lose if arm goes mainstream on the desktop. And then there's the recent Raspberry P-IPO or whatever it was, which seems to have pissed a bunch of people off... The timing is interesting. I can see the appeal of the N100 and similar -- and am currently considering one -- but it's hard to beat the ~1W DNS/DHCP/Consul servers that have been humming away in this house trouble free for the last decade... I don't need those to power my homelab. There's a reason they're separate, and tiny low-power Pi's are ideal for that job. I have in my possession more than merely a hammer. :) reply AshamedCaptain 2 hours agorootparentWhere are these tiny low-power RPis that idle at 1W ? Are you measuring at the wall (i.e. with the power adapter inefficiencies?) The entire point of the article is that at least the non-micro RPis are not \"low-power\" at all (something that agrees with my observations). The article is quoting around 3.5W for the RPi5. I was also getting a similar reading for my older RPi4 after months of fine-tuning, while _out of the box_ an N4000 miniPC had 1.8W consumption at idle. RPi may be cheap, but not much else. reply politelemon 4 hours agoprevCan the mini PCs mentioned be used for videostreaming? From what I recall RPIs are weak at Plex/Jellyfin. reply louwrentius 4 hours agoparentYes, the Intel-based one supports Quick Sync. reply crawsome 4 hours agoprevThose intel 6500u processors also have Quicksync, so you can run a modest PLeX server on one. I have a micro Dell PC, and it runs like a champ. I'd take it over the Pi anyday for my uses. reply giantrobot 1 hour agoprevI've gone this direction with my home lab stuff as well. I have an assortment of older RPis up to a couple RPi 4Bs. Most I bought to use on projects where I wanted Linux plus GPIOs and they were and still are good for that purpose. I've also given in to the temptation to use them as little servers on my LAN for various sorts of things. I've even tried to use them for HTPC boxes and they have worked ok. However I have sent all my Pi's back to projects where I just want Linux plus GPIO. For everything else I replaced them with cheap mini PCs. 1) a bare Pi on a workbench/desk is fine but when connected to a TV in the living room has a very low WAF. 2) the arrangement of ports on a Pi are a complete pain in the ass. Even with a case any installation of a Pi looks like a careless hack job. 3) MicroUSB is complete fucking garbage. The port/connector wears or breaks and the slightest bump powers off the Pi. MicroUSB power supplies are usually also garbage and typically have criminally short cables. \"Appliance\" appropriate power for a Pi costs more than the Pi itself. USB-C in the 4B is better but I've only got one of those. 4) like power supplies a decent microSD card that won't randomly fail in a Pi ends up costing as much as a Pi. I replaced a bunch of individual Pis running servers with a single mini PC with an N95. The Pis weren't taxed with the server loads so the N95 doesn't break a sweat. It's also way easier to manage since the various server apps are managed by a docker compose file. The mini PCs replacing the HTPC Pis are just a better experience overall. The ports are all on one side, they have same barrel connectors for power, and their local storage doesn't magically corrupt itself because the unknowingly cheap power supply didn't provide enough power. I still love the Pis for small nerd projects but just don't want to deal with them anymore for pretty much anything else. If you don't need GPIO for a project and physical volume isn't a prime concern a <$100 mini PC is a far more convenient option today than a Pi. That wasn't true ten years ago which was why I started using Pis for servers and stuff but today it is definitely the case. reply KaiserPro 3 hours agoprevSorry, but if you're going to write the Pi5 off, do it properly compare it to an intel n100 machine. https://www.amazon.co.uk/TRIGKEY-Lake-N100-Processor-G4-Comp... £165 16 gigs of ram, 500gig ssd. 1957 single core passmark and 5548 multicore. More importantly its 5 watts at full CPU You can run it off 19v DC, and its physically tiny. Yes, it has a fan, but its not that loud, significantly quieter than the HP The second hand HP is just not compelling anymore, unless you need more than one drive, or you need something physically larger. TLDR: the PI isn't great for KVM. The n100 is. I have a mix of n100s, NUCs and Pis. Each has their purpose. If you really want cheap ephemeral linux, then the pi-zero is still dirt cheap. £20 for a linux machine with wifi. reply dabeeeenster 3 hours agoprevI have a Pi 4. It runs home assistant and bunch of other docker images. It has a DVBT-2 hat that feeds tvheadend that lets me watch broadcast TV on my laptop and phone. It doesnt make a noise. It doesnt reboot randomly. It doesnt get hot. It doesnt get hacked. After that, who cares? reply louwrentius 4 hours agoprevDepending on what you want to do, the Pi may still be a good option, yet I think it's good that people are aware of alternatives such as these second-hand mini PCs. reply 2OEH8eoCRo0 3 hours agoprevI buy every Pi and try to run MechWarrior 2 in dosbox and they've all fallen short. I also have a Surface Go 2 (bought used for $80) w/ 4GB of memory + Pentium Gold and it runs flawlessly. Relatedly- I find that old hardware is still very capable but ruined by new media codecs that lack HW acceleration. Are the new codecs really worth it when they essentially render whole generations obsolete for media? reply shadowgovt 4 hours agoprevHas anyone else had thermal management problems with the pi5? I have one running just a couple of servers tucked away on a shelf and a corner of a room, and I find myself needing to physically recycle power on the thing about once every few days (This on top of the daily auto reboot script I have set up as a cron job). I suspect the Wi-Fi is overheating it. reply floating-io 3 hours agoparentAlso check your USB cables if they're supplying power. Low-quality cables are notorious causes of instability with older Pi's, and I doubt the 5 is any different in that respect. reply mvkel 3 hours agoprevI mean it's, what, 5X the volume of a raspi? I would hope it's in a different class. reply robertlagrant 1 hour agoprev [–] TL;dr: brand new top end Pi 5 similar price to second hand base spec of another type of computer. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Raspberry Pi 5, released in fall 2023, offers improved performance but is still limited by SD card storage and higher costs compared to previous models.",
      "Second-hand 1L mini PCs from brands like Dell, Lenovo, and HP outperform the Pi 5 in terms of processing power, RAM capacity, and storage options (SATA and NVME SSDs).",
      "While the Raspberry Pi 5 is energy-efficient, second-hand mini PCs are better suited for home server applications due to their superior performance and built-in SSD/NVME support."
    ],
    "commentSummary": [
      "The Raspberry Pi 5 has lost its affordability due to the end of a special deal with Broadcom, making it less competitive in the current market.",
      "Users are finding better value in second-hand mini PCs, which offer more power and features for a similar price.",
      "While the Pi 5 remains strong in educational and GPIO (General-Purpose Input/Output) applications, alternatives like used Intel NUCs or new N100 mini PCs are more attractive for general computing tasks."
    ],
    "points": 257,
    "commentCount": 218,
    "retryCount": 0,
    "time": 1718552283
  },
  {
    "id": 40693944,
    "title": "SimCity in the web browser using WebAssembly and OpenGL",
    "originLink": "https://micropolisweb.com/",
    "originBody": "X This is Micropolis in WebAssembly! Based on the original SimCity Classic from Maxis, designed by Will Wright, ported by Don Hopkins. This is just an unfinished evolving scrappy fiddle. Please support its further development via Patreon. GitHub: https://github.com/SimHacker/MicropolisCore. YouTube: \"MicropolisWeb Demo 1\" and \"Space Inventory Cellular Automata Music 1\". More Info: Chaim Gingold's book \"Building SimCity\" and Chaim Gingold's \"SimCity Reverse Diagrams\". Drag left button to pan, spin mouse wheel to zoom. Arrow keys pan, comma and period keys zoom. Letter keys load various cities, tab to generate. Numeric keys set the speed, 0 toggles pause. The brackets lower and raise the tax rate. Click the \" X \" button above to hide this window. More features and easter eggs on the way... WARNING: DO NOT hit the space bar, because that will open up the Space Inventory !",
    "commentLink": "https://news.ycombinator.com/item?id=40693944",
    "commentBody": "SimCity in the web browser using WebAssembly and OpenGL (micropolisweb.com)214 points by tambourine_man 19 hours agohidepastfavorite44 comments modeless 13 hours agoPorting old games to the web is fun! Many are smaller than a typical modern webpage. They load fast and run great. I just ported Quake 3 and I'm having some fun with it: https://thelongestyard.link/ reply geuis 13 hours agoparentThat was a lot of fun and a blast from the past. Thanks for porting that. reply modeless 12 hours agorootparentThanks! This is loading just the demo assets, but I got the Emscripten support merged into upstream ioquake3 so you can check out the code, build it yourself, and with the right game asset files you can play the full game, Team Arena, mods, or whatever. https://github.com/ioquake/ioq3/pull/658 The only major feature missing from the original game is networking. Obviously kind of important for Quake 3. Should be possible with WebRTC DataChannel. And while the original game didn't have it, for the modern web a touchscreen control scheme is essential since half of everyone is on their phone. Of course it won't be great compared to mouse/keyboard but some mobile support is better than none. So those are the two features I'd like to add (besides performance optimizations; it's a bit slower than it should be for some reason). reply hauxir 11 hours agorootparentcheck out https://openarena.live its open arena running on humblenet which does take advantage of webrtc/p2p reply langarus 1 hour agoparentprevreally love this. Where would one start in order to get better at this? Mainly porting old games to wasm reply noxa 1 hour agoparentprevmy favorite map too :) reply Jyaif 12 hours agoparentprevThat input latency is why I hate browsers when making games. Great job though! reply wffurr 9 hours agorootparentPointerrawupdate events: https://w3c.github.io/pointerevents/#the-pointerrawupdate-ev... would help with that. If tearing is Ok, the canvas can be desynchronized and updated immediately. We can get 10 msec inking latency with those on a 60 Hz display. reply modeless 3 hours agorootparentIn the past I have experimented with pointerrawupdate and desynchronized, and I was unable to reproduce any latency benefit in practice. These features have a lot of caveats and are not reliable, in my experience, which is probably why practically nobody uses them. It's way too easy to fall off the fast path, if the fast path is even supported on your platform at all. Also, native apps have a lot of options to reduce latency without any risk of tearing artifacts, and it's unfortunate that web apps don't have access to those options. The web has a long way to go to match native on the latency front and there really hasn't been meaningful progress in that direction. I would like to experiment with pointerrawupdate and desynchronized again. But I'm currently relying on Emscripten's SDL implementation for input and drawing, and replacing or modifying that is daunting. After all, this is just a fun side project for me. A much easier and more widely supported latency fix would be to use a blocking API like WebGL's ReadPixels to synchronize the content process and GPU process and defeat the deep frame pipelining that the browser usually falls into, at some cost to performance. I plan to try that first. reply CyberDildonics 9 hours agorootparentprevIs inking latency the new pixel to pixel latency or input to pixel latency? I like to keep up with the new names for old things. reply modeless 3 hours agorootparentThe features he's talking about were added to Chrome for ChromeOS/Win8 tablet stylus drawing support, which they refer to as \"inking\". They're kind of a specific fast path for that use case. They were not tested for any other use case and as a result tend not to be usable in practice due to various caveats, unfortunately. reply tonmoy 8 hours agorootparentprevI’m guessing “inking” is a autocorrect of a typo that was meant to be “input” reply dleeftink 7 hours agorootparentFrom hereon it shall be inking [0]: https://en.wikipedia.org/wiki/Inking reply DonHopkins 11 hours agorootparentprevIf you refactor and structure your code in the right way, you can get it to perform pretty well. What will kill you is stacking up layers of emulation, so you're feeding browser input into a Windows or Mac emulation layer, and even an x86 instruction set emulator, plus a useless obsolete operating system \"middle ware\", because the way input and animation works on old desktop guis is a lot different and much less efficient that how it works in the browser. It's certainly possible to run the original version of Mac or Windows SimCity in the browser inside a Mac or Windows emulator inside a WebAssembly module, but not only is the user interface itself terrible, klunky, and awkward, it's extremely slow and flakey because it's emulating all that obsolete operating system crap and instruction set underneath all the web browser crap between your mouse clicks and the game engine. Since the web browser is so much better and more flexible at user interface and graphics stuff, you want to totally strip all of the user interface and graphics and sound out of the game, implement an efficient API and callback mechanism (that doesn't spend a lot of time thunking and marshalling and unmarshalling parameters, and pass simple primitive data types, sending what you need all at once, instead of ping-ponging back and forth with proxy objects), and implement all of the UI in the browser (especially the animation timers and input handlers), calling back to the simulator only when necessary. One thing I did was to use shared memory between the WebAssembly module and the WebGL tile renderer, and write a custom shader that understands the native 16 bit unsigned int column major SimCity tile format, so WebGL only has to draw two triangles, and there is zero copying to draw the tiles. reply pton_xd 3 hours agorootparent> and implement all of the UI in the browser (especially the animation timers and input handlers) I may have misunderstood you, but in my experience using the DOM for UI is a bad idea if performance is a concern. DOM updates in the browser are incredibly slow, especially for something like a game which wants to modify UI elements every frame. Meticulously avoiding relayouts, style recalculations, and other slowdowns is a constant headache. EDIT: run a few second performance profile of your site. Now do it again while waving the mouse back and forth over the UI links. Notice all the recalculate style and hit test calls that take more time than your entire WASM update! And that's with a UI that's doing nothing! reply lukevp 2 hours agorootparentI think you did misunderstand their point. Browser native doesn’t just mean DOM, there’s also Canvas and directly reading mouse offsets and various other approaches. What they mean is don’t transit a mouse click through an OS emulation layer through a hardware emulation layer to the simulator, just directly read input from the browser and skip all the intermediate layers and inject the value directly to the code. Imagine that the mouse is simulating a PS2 hardware device with input polling and interrupts on top of a whole simulated OS and all that crap. The approach suggested is assuming you have access to the code to modify how it gets input data, or you’re willing to update the memory directly when input happens. reply yanslookup 6 hours agoprevI'm not a gamer but I remember playing SimCity as a kid... Did game play change in the last ~25 years or is my browser broken? It doesn't seem to do anything? I can load a city and watch it do things but I remember being able to actually build cities myself in SimCity... Is there supposed to be a way for players to... play? reply DonHopkins 4 hours agoparentIt's an early snapshot of a work in progress -- I just got the simulator and tile engine working, but haven't implement much more of the user interface yet. (I'll put a disclaimer on the page to avoid confusion.) The \"Space Inventory\" is actually a couple of cellular automata rules, one is a dithered 8 bit chaotic wrapping heat diffusion, kind of like \"Heat\", and the other is a variation of \"EcoLibra\" that Rudy Rucker came up with and published in Autodesk's Cellab, which he made with John Walker. It combines \"Anneal\" (aka \"Vote 4/5\") with \"Life\" and \"Brian's Brain\". https://www.fourmilab.ch/cellab/ https://www.fourmilab.ch/cellab/manual/rules.html#EcoLiBra https://www.fourmilab.ch/cellab/manual/rules.html#Life https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life https://www.fourmilab.ch/cellab/manual/rules.html#Brain https://en.wikipedia.org/wiki/Brian%27s_Brain https://www.fourmilab.ch/cellab/manual/rules.html#Vote https://conwaylife.com/wiki/List_of_Life-like_rules https://www.fourmilab.ch/cellab/manual/rules.html#Heat I added those CA rules to SimCity so they display the cell values with the SimCity tiles back in 1991, which I distributed via anonymous ftp as a free fully functional unlockable demo, that used cellular automata as DRM: you could play the game for a few minutes, then if you hadn't bought a license, it would switch to the cellular automata and melt your city! https://www.donhopkins.com/home/catalog/simcity/simcity-anno... https://www.donhopkins.com/home/catalog/simcity/simcity-revi... https://www.donhopkins.com/home/HyperLook-SimCity-Manual.pdf https://www.donhopkins.com/home/catalog/hyperlook/HyperLook-... https://www.donhopkins.com/home/catalog/hyperlook/SimCity.IN... >Now that you have installed SimCity, you can run the \"GetKey\" shell script to get a license key from DUX software, or run \"SimCity\" in demo mode without getting a key. In demo mode, your city will melt after 5 minutes, or when you try to save it to disk, so buy a license, it's cheap! When you buy a license, DUX will ship you the latest version of the software, a nice 100 page manual with lots of nifty illustrations, and a handy reference card. And when you're ordering, don't forget to ask how to embezzle funds! reply parasti 11 hours agoprevThis is cool. I didn't expect much on mobile (hey it's Simcity), but this page actually froze Firefox for me, on Android. Had to kill the process. That happens rarely. BTW, here's a little game that I ported to the browser. Getting it to run was very straightforward (Emscripten+SDL2 is a great combo), but honestly making it fully playable on a phone took the most effort: https://play.neverball.org/ reply Neywiny 6 hours agoparentI'm also Firefox on Android and it didn't for me. Though I have noticed that some of the newer versions of Firefox can be kinda sucky for PDFs. Maybe it's linked to versions. reply noduerme 10 hours agoparentprevThis is shockingly high frame rate and stutter-free on a 4 year old bottom shelf android phone in firefox. Not that it's so many textures or polygons but even so I'm not used to anything performing remotely that well in a browser on this phone. Nice job! reply DonHopkins 11 hours agoparentprevI fully intend to make it support mobile! And I already fixed one bug that prevented it from running on Firefox on Ubuntu, thanks to a well written bug report that included a stack trace. Give it another try, maybe it works now, and if not, please report the bug and include a stack trace and any information about your platform. https://github.com/SimHacker/MicropolisCore/issues/1 I wanted to release this as soon as possible so other people could run it, instead of waiting until it was finished and perfect, so there's a lot more work to do on the user interface, robustness, cross platform support, mobile, etc. But once I got the simulator and tile renderer working, I threw together a minimalistic zooming panning + keyboard control interface, and a little window with hints that you can close by clicking the \"+\" button in the upper right corner. What I'm really looking forward to doing is integrating it with visual programming languages like Snap! so you can live code it and write plug-in zones, robots, monitoring and control systems, data visualization and export (i.e. Grafana dashboards, etc), and alternative interfaces via visual programming, instead of raw non-interactive JavaScript or TypeScript! Edit for parasti: You can use a USB cable to attach an Android phone to a Mac or PC, or an iPhone to a Mac, and then use the Chrome (or Safari on Mac) browser's debugger to attach to the phone and remotely see the console messages, debug, and even live code it! It might even work over Wifi if you can get all the stars to align, if Google hasn't canceled that feature, or if Apple hasn't forbidden it in the first place. reply parasti 11 hours agorootparentThat's awesome, looking forward to it. Would love to report more, but this is on Android - I wouldn't even know how to go about getting a stack trace. Being on Android, I can't even see the developer console. reply detuks 13 hours agoprevA while back ported RuneScape client to web. https://play.rsps.app/ Wasm, Typescript and WebGL reply super_linear 14 hours agoprevhttps://github.com/SimHacker/MicropolisCore reply DonHopkins 12 hours agoprevMicropolis Web Demo 1: https://www.youtube.com/watch?v=wlHGfNlE8Os Micropolis Web is the browser based version of Micropolis (open source SimCity), that uses WebAssembly, WebGL, and SvelteKit. Based on the original SimCity Classic code, designed by Will Wright, ported by Don Hopkins. This first demo shows an early version that runs the WebAssembly simulator and animates the tiles with WebGL, but most of the user interface is still a work in progress. Live MicropolisWeb Site: https://MicropolisWeb.com GitHub Repo with source code and documentation: https://github.com/SimHacker/MicropolisCore Much more Info in Chaim Gingold's book, \"Building SimCity\": https://mitpress.mit.edu/9780262547482/building-simcity/ Chaim Gingold's \"SimCity Reverse Diagrams\": https://smalltalkzoo.thechm.org/users/Dan/uploads/SimCityRev... Micropolis Web Space Inventory Cellular Automata Music 1: https://www.youtube.com/watch?v=BBVyCpmVQew Micropolis Web is the browser based version of Micropolis (open source SimCity), that uses WebAssembly, WebGL, and SvelteKit. Based on the original SimCity Classic code, designed by Will Wright, ported by Don Hopkins. This first video has music by Juho Hietala, Blamstrain, and the Space Inventory Cellular Automata is performed by Don Hopkins. Music by Juho Hietala, Blamstrain: https://blamstrain.com/ reply ziggy_star 11 hours agoparentMr Hopkins you are by far one of my favorite posters on this website and these sort of comments are golden. On occasion they get appropriate engagement but sometimes there are no replies. You should know that it does not go unnoticed. The breadcrumbs you leave will be followed by youngsters far into the future, a worthwhile endeavor. Thank you for brightening my sunday and everything you’ve done and your efforts at documenting and preservation. While HN is not what it used to be I consider you royalty and old school users like yourself are the reason many of us still frequent this place. You are appreciated sir. Cheers. reply lioeters 7 hours agoparentprev> Building SimCity: How to Put the World in a Machine Oh wow, this book by Chaim Gingold was just published on June 4, 2024. I loved the diagrams he made of SimCity algorithms, and I believe I read his dissertation(?) which goes into juicy details of how SimCity works internally. Ah here it is: Gingold, Chaim. “Play Design.” Ph.D. thesis, University of California Santa Cruz, 2016. https://www.proquest.com/docview/1806122688 So the book I'm sure will be wonderful. --- The WASM port of Micoropolis sounds like it could be the start of a new stage in its development. SimCity Classic on the Macintosh was a big influence in my childhood, on how I think about computers and software. I'm happy to see new life breathed into it. reply DonHopkins 4 hours agorootparentYes, his thesis was outstanding, and a lot of the best parts ended up in the book. I really appreciated the big section at the beginning about Doreen Nelson's life work, Design Based Learning, which he also covered in depth in the Building SimCity book. She and Michael Bremmer wrote the SimCity Teacher's Guide (which Cliff Basinger (LGR) found on eBay, made an unboxing video review about, and sent me his copy of. I have been meaning to scan it and put it online -- I'll see if I can dig it up and scan it, since it would make a great addition to the Micropolis project). LGR - SimCity Educational Version Unboxing & Overview: An overview of the \"School Edition\" Lab Pack of SimCity Classic by Maxis. Unboxing, first impressions of the package and testing of the radically rad software ensues. https://www.youtube.com/watch?v=edXRNtuAGTg More about Doreen Nelson: https://news.ycombinator.com/item?id=21049206 DonHopkins on Sept 23, 2019parentcontextfavoriteon: OLPC’s $100 laptop was going to change the world (... >There were many reasons the OLPC failed, but I don't think constructionist education was one of them, when it's succeeded in so many other places. >EA donated SimCity to OLPC because of its relation to constructionist education, thanks to Maxis's collaboration with Doreen Nelson, who wrote the SimCity teacher's guide, and developed \"City Building Education\" and \"Design Based Learning\", in which kids built cities out of cardboard instead of pixels: https://news.ycombinator.com/item?id=20329281 >SimCity can be used educationally, but not in the sense of literally training people to be urban planners or mayors. It's more useful for \"Constructionist Education\" and \"Design Based Learning\", as practiced by Seymour Papert and Doreen Nelson. >[...] One of the teachers [Clair] Curtin hired was Doreen Nelson, a brilliant and innovative educator who had developed a pedagogy called City Building Education, in which students collaboratively built cities out of craft materials and role play. Nelson become a regular visitor to Maxis, and Curtin made some trips to Los Angeles to see City Building in action, where she found the experience of “watching a classroom actually go through a couple of days worth of creation” to be “very inspiring. … I will never forget that experience” (Curtin 2015; Nelson 2015). [5] >[5]> This translation took the form of a short teacher’s guide, a pamphlet, really, written by Michael Bremer, and published by Maxis in 1989—the same year SimCity was released, explaining the limitations and applications of SimCity, and offering curricular questions and scripts. Within a few years, Maxis became more serious about tackling the education market, and hired Claire Curtin, in 1992, as their first educational product manager, charging her with finding ways to package SimCity, SimEarth, and SimAnt for the school market. Prior to joining Maxis, Curtin had been the senior producer of Brøderbund’s hit educational franchise, Where In The World Is Carmen Sandiego?, a job she had started in 1988, immediately after finishing graduate studies at NYU’s Educational Communication and Technology program, where she had studied with the noted education technology researcher Roy Pea. Over the course of her career at Maxis, Curtin shifted roles and projects, a result of Maxis’s fickle focus and its inability to produce hits beyond SimCity (chapter 5). Later, when Maxis defocused on a hard to reach education market, Curtin would go on to co-design or co-produce the kids’ titles SimTown (1995) and SimSafari (1998). Curtin collaborated closely with Roxana (“Roxy”) Wolosenko, and after Maxis decided not to do any more kid specific titles, the two of them were shifted to Wright’s “Dollhouse” project—a title that was not spoken out loud due to its gender connotations—where they were instrumental, as Wright’s co-designers, in evolving the design focus away from time management and towards people and interactions inspired by everyday life. It is this more human centric vision of Dollhouse that eventually saw release as The Sims, which became, at long last, the second commercially successful Sim title (Curtin 2015). >page 366> Play has a complex relationship to what is not play. Depending on who you ask, SimCity, the software toy, is either a frivolous diversion or an earnest model—and sometimes both. Right from the start, SimCity had appeal as an educational tool, a quality that Maxis tried to capitalize on. According to Braun, “It was never our intention to go into the education market, but the education market came to us and said: ‘This is what we need if you’re gonna work with us.’ ” What the education market wanted was teacher’s guides that translated and adapted SimCity for classroom use. It didn’t hurt that Brøderbund, Maxis’s publishing partner, was deep into the then hot educational software market, and that along with the investment Maxis received from venture capitalists in 1992, came a hunger for aggressive growth into new markets. Wright, of course, was busy making titles like SimEarth and SimAnt for an uncertain market. Maybe that market was education? Chaim also wrote a section in his thesis about open sourcing SimCity: Open Sourcing SimCity, by Chaim Gingold. https://donhopkins.medium.com/open-sourcing-simcity-58470a27... >Excerpt from page 289–293 of “Play Design”, a dissertation submitted in partial satisfaction of the requirements for the degree of Doctor in Philosophy in Computer Science by Chaim Gingold. His book also covered a lot of interesting stuff about cellular automata, including John von Neumann's 29 state cellular automata and universal constructor! Von Neumann Universal Constructor (wikipedia.org) https://news.ycombinator.com/item?id=22727228 https://en.wikipedia.org/wiki/Von_Neumann_universal_construc... My JavaScript CAM6 cellular automata machine simulator has an implementation of it, but it needs a better user interface if you want to build a non-trivial machine (especially a self replicating one!) https://github.com/SimHacker/CAM6/blob/cbad2920fd0fab5b35baf... More about the theory of self reproducing cellular automata: https://news.ycombinator.com/item?id=32960377 https://archive.org/details/theoryofselfrepr00vonn_0 https://news.ycombinator.com/item?id=21855249 \"Signal crossing solutions in von Neumann self-replicating cellular automata\", page 453-503 https://donhopkins.com/home/documents/automata2008reducedsiz... https://news.ycombinator.com/item?id=21858465 >>The von Neumann probe, nicknamed the Goo, was a self-replicating nanomass capable of traversing through keyholes, which are wormholes in space. The probe was named after Hungarian-American scientist John von Neumann, who popularized the idea of self-replicating machines. >Third, the probabilistic quantum mechanical kind, which could mutate and model evolutionary processes, and rip holes in the space-time continuum, which he unfortunately (or fortunately, the the sake of humanity) didn't have time to fully explore before his tragic death. >p. 99 of \"Theory of Self-Reproducing Automata\": >Von Neumann had been interested in the applications of probability theory throughout his career; his work on the foundations of quantum mechanics and his theory of games are examples. When he became interested in automata, it was natural for him to apply probability theory here also. The Third Lecture of Part I of the present work is devoted to this subject. His \"Probabilistic Logics and the Synthesis of Reliable Organisms from Unreliable Components\" is the first work on probabilistic automata, that is, automata in which the transitions between states are probabilistic rather than deterministic. Whenever he discussed self-reproduction, he mentioned mutations, which are random changes of elements (cf. p. 86 above and Sec. 1.7.4.2 below). In Section 1.1.2.1 above and Section 1.8 below he posed the problems of modeling evolutionary processes in the framework of automata theory, of quantizing natural selection, and of explaining how highly efficient, complex, powerful automata can evolve from inefficient, simple, weak automata. A complete solution to these problems would give us a probabilistic model of self-reproduction and evolution. [9] >[9] For some related work, see J. H. Holland, \"Outline for a Logical Theory of Adaptive Systems\", and \"Concerning Efficient Adaptive Systems\". https://www.deepdyve.com/lp/association-for-computing-machin... https://deepblue.lib.umich.edu/bitstream/handle/2027.42/5578... https://www.worldscientific.com/worldscibooks/10.1142/10841#... reply usrbinbash 10 hours agoprevWhy is there a fire department in almost every city block?! reply _ache_ 13 hours agoprevSeriously, I'm stun about what happen if you it the space bar. Nice fractals. reply DonHopkins 12 hours agoparentGame Helpin' Squad's review of World Quester 2 is the inspiration for the Space Inventory, and I aspire to design the Micropolis menus and user interface to be as freaking awesome as World Quester 2! https://www.youtube.com/watch?v=0Gy9hJauXns reply simonebrunozzi 13 hours agoprevWondering whether an LLM could be able to port a game like this instantly. reply DonHopkins 12 hours agoparentGood question, please don't downvote -- there's an interesting discussion to be had about that! The best approach is to use it like any other tool, and not expect it to do all the hard work for you, just relieve you of a lot of tedious work, and help you learn how to be a better programmer yourself, not replace you. There's no such thing as a free lunch, but some lunches are tastier and more nutritious and less expensive than others. I've been using ChatGPT to develop it, and it's helped a lot, and takes a great deal of iteration and guidance, but it's anything but instant. LLMs won't replace programmers, but programmers with LLMs will replace programmers without LLMs. Here's an example of how it was helpful in simply explaining the documentation and best practices of tools like Emscripten and Embind, getting the makefile to work, analyzing the code, categorizing methods and instance variables as private and public (to be wrapped by embind), generating the boilerplate Embind declarations, and writing the documentation through a back-and-forth discussion of goals and requirements, and acting like a glorified grep that actually understands the code syntax and accepts English queries instead of obscure command line arguments. The comments at the top (included below) were mostly written by ChatGPT in response to me writing the strategy, telling it in detail what I wanted to do, describing my goals, and how I wanted it to work, with lots of iterating and refining and hand editing: https://github.com/SimHacker/MicropolisCore/blob/main/Microp... The process was anything but automatic or instant -- in total it took about 33 years (and counting, I'm not done yet). I had to guide ChatGPT a lot, drawing from my previous experience porting the Mac version of SimCity to HyperLook on the NeWS window system in 1991, and other platforms later on. At the time I considered using a Mac compatibility library for X11, but that would have resulted in a terrible klunky user interface, could not have taken advantages of the Sun Workstation Unix programming and user interface environment (networking, big screen, better window management, pie menus and other nice user interface components, scalable color PostScript graphics and fonts, using native file formats for resources, audio mixing, lots of computing power to animate fast and zoom into the map, run the simulation super fast by skipping screen updates, profiling and optimizing the code, etc), tied the game to a proprietary library that is long obsolete, and would have only supported X11, not NeWS. For a game like SimCity, it was well worth throwing away the Mac UI, cleaning up the simulator to be independent of the UI, and writing a new high quality UI for HyperLook in NeWS (then later another for TCL/Tk in X11). Porting it to NeWS required separating the simulator from the user interface and defining a clean network API and shared memory raster animation library, rewriting the user interface in PostScript, and defining a messaging protocol between the simulator and UI. Then a few years later I ported that to TCL/Tk on X11, refactoring the simulator/UI messaging interface into TCL extensions. TCL/Tk made it possible to develop a networked multi-player version of SimCity. X11 SimCity Demo: https://www.youtube.com/watch?v=Jvi98wVUmQA Multi Player SimCityNet for X11 on Linux: https://www.youtube.com/watch?v=_fVl4dGwUrA TCL Doc: https://github.com/SimHacker/MicropolisCore/blob/main/notes/... Callbacks: https://github.com/SimHacker/MicropolisCore/blob/main/notes/... A couple of decades later, we made SimCity open source, released the TCL/Tk/X11 version for the OLPC and Linux, then I cleaned up and overhauled the simulator code into C++, and used SWIG to define the API and a callback mechanism, so I could plug it into Python. Micropolis Core: https://github.com/SimHacker/micropolis/tree/master/Micropol... Refactoring the code as C++ really helped modularize and organize it, made it easy to use doxygen to generate documentation, and much easier to wrap and port to different platforms. Doxygen documentation (current): https://micropolisweb.com/doc/ Development Plan (old): https://github.com/SimHacker/MicropolisCore/blob/main/notes/... OLPC Plan (old): https://github.com/SimHacker/MicropolisCore/blob/main/notes/... To Do (old): https://github.com/SimHacker/MicropolisCore/blob/main/notes/... User Interface Plan (old): https://github.com/SimHacker/MicropolisCore/blob/main/notes/... OLPC Notes (old): https://github.com/SimHacker/MicropolisCore/blob/main/notes/... I implemented a couple of Python user interfaces, including a desktop based PyGTK/Cairo/X11 interface, and a web based TurboGears/AMF/OpenLaszlo/Flash client/server interface. Micropolis Online (SimCity) Web Demo (old): https://www.youtube.com/watch?v=8snnqQSI0GE Bil Simser used SWIG it integrate the simulator engine with C#. (SWIG's point is to integrate C++ code into many different scripting languages, not just Python.) C# Micropolis: https://github.com/SimHacker/micropolis/tree/master/Micropol... After all that work, and writing and executing on the design documents linked above, I had a pretty good idea how to prompt ChatGPT to write a design for the Emscripten/Embind API, and it was helpful for writing the boilerplate code, and validating the design, but not so much for coming up with the design in the first place. Beyond refactoring and wrapping the API, ChatGPT has also been extremely useful for learning the intricacies and best practices of TypeScript, SvelteKit, node, WebGL, canvas, CSS, HTML, etc, for developing the user interface. //////////////////////////////////////////////////////////////////////// // This file uses emscripten's embind to bind C++ classes, // C structures, functions, enums, and contents into JavaScript, // so you can even subclass C++ classes in JavaScript, // for implementing plugins and user interfaces. // // Wrapping the entire Micropolis class from the Micropolis (open-source // version of SimCity) code into Emscripten for JavaScript access is a // large and complex task, mainly due to the size and complexity of the // class. The class encompasses almost every aspect of the simulation, // including map generation, simulation logic, user interface // interactions, and more. // // Strategy for Wrapping // // 1. Core Simulation Logic: Focus on the core simulation aspects, such // as the methods to run the simulation, update game states, and handle // user inputs (like building tools and disaster simulations). This is // crucial for any gameplay functionality. // // 2. Memory and Performance Considerations: JavaScript and WebAssembly // run in a browser context, which can have memory limitations and // performance constraints. Carefully manage memory allocation, // especially when dealing with the game's map and various buffers. // // 3. Direct Memory Access: Provide JavaScript access to critical game // data structures like the map buffer for efficient reading and // writing. This can be done using Emscripten's heap access functions // (HEAP8, HEAP16, HEAP32, etc.). // // 4. User Interface and Rendering: This part might not be necessary to // wrap, as modern web technologies (HTML, CSS, WebGL) can be used for // UI. However, providing some hooks for game state (like score, budget, // etc.) to JavaScript might be helpful. // // 5. Callbacks and Interactivity: Ensure that key game events and // callbacks are exposed to JavaScript, allowing for interactive and // responsive gameplay. // // 6. Optimizations: Where possible, optimize C++ code for WebAssembly, // focusing on critical paths in the simulation loop. // // Decisions and Explanations // // - Excluded Elements: // // - Low-level rendering or platform-specific code, as this can be // handled more efficiently with web technologies. // // - Parts of the code that handle file I/O directly, as file access // in a web context is typically handled differently (e.g., using // browser APIs or server-side support). // // - Any networking or multiplayer code, as web-based // implementations would differ significantly from desktop-based // network code. // // - Included Elements: // // - Core game mechanics, such as map generation, zone simulation // (residential, commercial, industrial), disaster simulation, and // basic utilities. // // - Game state management, including budgeting, scoring, and city // evaluation. // // - Direct memory access to critical structures like the map // buffer, allowing efficient manipulation from JavaScript. // // - Essential callbacks and event handling mechanisms to ensure // interactivity. // // Conclusion // // Given the complexity and size of the Micropolis class, wrapping the // entire class directly is impractical. However, focusing on key areas // essential for gameplay and providing efficient interfaces for // critical data structures can create a functional and interactive city // simulation in a web context. Further optimizations and adjustments // would likely be needed based on testing and specific requirements of // the web implementation. // // Implementation Notes // // The enum_, class_, constructor, function, and property functions // from the emscripten namespace are used to specify how C++ // constructs should be exposed to JavaScript. You can use these to // control which parts of your code are accessible and how they should // be used from JavaScript. // // I've made some assumptions here: // // The types MapValue and MapTile are simple types (like integers or // floats). If they are complex types, they would need their own // bindings. // // I'm assuming that the copy constructor and copy assignment // operator for the Position class are correctly implemented. If // they aren't, then the Position object may not behave as expected // in JavaScript. // // Micropolis Binding Design // // The Micropolis interface organizes the Micropolis class header into // categories of functions that are relevant for interaction with the // JavaScript user interface, scripts, or plugins. The aim is to expose // functions that could help in monitoring and controlling game state // effectively. // reply JKCalhoun 9 hours agorootparent> LLMs won't replace programmers, but programmers with LLMs will replace programmers without LLMs. I like that. I would darken it a bit though: \"LLMs won't replace programmers, but a programmer with an LLMs might replace two programmers without LLMs.\" reply zamadatix 4 hours agorootparentYou could say the same thing about every improvement to programming workflows (version control systems, context aware editors, CI/CD, test frameworks, better languages/language improvements, package managers, Q&A repositories like StackOverflow, build systems, and so on). Whether you really consider increasing individual output dark/bad/ominous is up to you but if you apply that outlook historically you'll have had decades of negative outlook on the thought the job is going to become scarce while the number of high paying software jobs continued to increase despite efficiency improvements. In a more direct way: Making one programmer able to output what two programmers can do is almost always a gain for everyone involved. Making one programmer able to output what 10,000 programmers can do is a sign the field is being replaced. I don't think we'll get anywhere near concerns of the latter with LLMs. reply cubefox 7 hours agorootparentprevA little bit darker: \"LLMs won't replace programmers, but the LLM successors will.\" reply DonHopkins 4 hours agorootparentAgreed -- I purposefully avoided saying \"AI\" instead of \"LLMs\" because LLMs aren't all that's required for AI to replace programmers. And my guess is that it will be a long time until AI replaces programmers. reply TapamN 9 hours agoprevI worked on a port of Micropolis to the Sega Dreamcast, but never finished it. https://www.youtube.com/watch?v=MlFu-y1LDbs One thing I really disliked about the SNES port of SimCity Classic was how slow the interface was. Having to access the menu for everything was a pain. For my port, the cursor would move faster, and snap instantly to the next tile if it was tapped. The analog stick could be used for fast cross map movement. The menuing was replaced by mapping every command to a button combination, with different palettes of commands available depending on what shoulder buttons were pressed. If you weren't holding a shoulder button, the ABXY buttons were set up for A (primary action button) for roads, X (secondary action) for rail, Y (the green button) for parks, and B (cancel button) for bulldozer. Holding L was reserved for system commands, you could zoom in or out with A or Y, and adjust the speed with X and B. Holding R completely would allow building zones, color coded to the controller's buttons, with the red (A) button to build residential, blue (B) for commercial, and yellow (X) for industrial. There were two more palettes, accessed by either pressing L+R, or half pressing the R button, for infrequently built things like power plants and airports. It might sound complicated from the description, but I think it would be pretty easy to get used to if you actually tried it a bit. I did a bit more work after I made the video, like adding map overlays (pollution, traffic, etc) and a display of what the current face button palette is, to help learn the combinations. I was also adding split screen, for multiplayer. I was planning for you to be able either build a city together with someone else, or do competitive city building, like race to clear a scenario, or get the highest population or funds in a certain amount of time. I think I got the split screen two different cameras on the same city working, but no controls for anyone besides player 1. I spent some time optimizing the simulation, because I wanted absolute solid 60 FPS. There would be occasional 1 or 2 frame stutters on large cities went certain phases of the simulation ran. The worst was when it calculated power. The power grid connectivity is calculated in a bizarre way. Instead of a regular, scanline based flood fill, it basically has a Logo turtle walk the power grid. It uses the exact same class that the monster uses for movement, tracking the facing of the turtle, with functions to turn, take one step forward, etc. The version of GCC I was using was not automatically inlining the movement functions (they were in .CPP files, and no LTO), so it added a ton of overhead to an already slow algorithm. I moved the functions into the header so they would be inlined, which helped a lot, but was still planning to replace the whole thing with a real flood fill. Even after inlining the walker, there were still single frame stutters. A lot of the map data for things like pollution and land value have filters applied to them, and the filter has a slow implementation. It does X and Y bounds checking on every tap of the filter, even in the middle when it can't go out of bounds. A better filter implementation would have helped. The C++ simulation seemed to have some kind of bug, which would cause periodic mass abandonment, that I never figured out. I never noticed the Java version having the same problem. reply robblbobbl 11 hours agoprevGood job! Now we need a Age of Empires and Empire Earth port! reply gnfedhjmm2 14 hours agoprev [–] It’s funny I was thinking about writing some browser based games using Pyscript with web assembly. But now I think by the time I finish the games they’ll have ported enough of Python into web assembly that I might as well write it with Kivy or Pygame and then it would be cross platform. Pygame already in the browser, but slow and clunky IMO. In 6 months who knows? reply nextaccountic 13 hours agoparent [–] Don't let analysis paralysis deter you from writing games. Pyscript is fine. Other stuff is fine too. Pick whatever technology you want, and make quick games with rapid prototyping. Join some game jams and keep your scope small. It's better to create and ship many small games. About pygame in the browser: check out pygbag. reply gnfedhjmm2 13 hours agorootparent [–] Would like technical thoughts, not cheerleading. I’ve written many games before just not with a new shaky stack. reply JKCalhoun 9 hours agorootparent [–] Some of us appreciated the cheerleading though. :-) reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Micropolis in WebAssembly is a port of the original SimCity Classic by Maxis, designed by Will Wright and ported by Don Hopkins.",
      "The project is evolving, with ongoing development supported on Patreon and available on GitHub.",
      "Users can interact with the game using various controls, such as mouse and keyboard shortcuts, with more features and easter eggs promised in future updates."
    ],
    "commentSummary": [
      "SimCity has been ported to the web browser using WebAssembly and OpenGL, making it accessible without needing to install software.",
      "This project is based on the original SimCity Classic code and aims to bring the game to modern platforms with improved performance and accessibility.",
      "The port is still a work in progress, with ongoing efforts to enhance the user interface, add mobile support, and optimize performance."
    ],
    "points": 214,
    "commentCount": 44,
    "retryCount": 0,
    "time": 1718500358
  },
  {
    "id": 40694103,
    "title": "The Architecture Behind a One-Person Tech Startup (2021)",
    "originLink": "https://anthonynsimon.com/blog/one-man-saas-architecture/",
    "originBody": "BlogTwitter/X The Architecture Behind A One-Person Tech Startup Apr 7, 2021@anthonynsimon This is a long-form post breaking down the setup I use to run a SaaS. From load balancing to cron job monitoring to payments and subscriptions. There's a lot of ground to cover, so buckle up! As grandiose as the title of this article might sound, I should clarify we’re talking about a low-stress, one-person company that I run from my flat. It's fully self-funded, and I like to take things slow. It's probably not what most people imagine when I say \"tech startup\". For context, I run a one-man SaaS, and this is a more detailed version of my post on my tech stack. I use Kubernetes on AWS, but don’t fall into the trap of thinking you need this. I learned these tools over several years mentored by a very patient team. These tools work well for me, but they might not be the right fit for you. By the way, I drew inspiration for the format of this post from Wenbin Fang’s blog post. I really enjoyed reading his article, and you might want to check it out too! With that said, let's jump right into the tour. Table of contents A bird’s eye view Automatic DNS, SSL, and Load Balancing Automated rollouts and rollbacks Let it crash Horizontal autoscaling Static assets cached by CDN Application data caching Per endpoint rate-limiting App administration Running scheduled jobs App configuration Keeping secrets Relational data: Postgres Columnar data: ClickHouse DNS-based service discovery Version-controlled infrastructure Terraform for cloud resources Kubernetes manifests for app deployments Subscriptions and Payments Logging Monitoring and alerting Error tracking Profiling and other goodies That's all folks A bird’s eye view My infrastructure handles multiple projects at once, but to illustrate things I’ll use my most recent SaaS, a web performance and traffic analytics tool, as a real-world example of this setup in action. Browser Timings chart in Panelbear, the example project I'll use for this tour. From a technical point of view, this SaaS processes a large amount of requests per second from anywhere in the world, and stores the data in an efficient format for real time querying. Business-wise it's still in its infancy (I launched six months ago update: it's been acquired), but it has grown rather quickly for my own expectations, especially as I originally built it for myself as a Django app using SQLite on a single tiny VPS. For my goals at the time, it worked just fine and I could have probably pushed that model quite far. However, I grew increasingly frustrated having to reimplement a lot of the tooling I was so accustomed to: zero downtime deploys, autoscaling, health checks, automatic DNS / TLS / ingress rules, and so on. Kubernetes spoiled me, I was used to dealing with higher level abstractions, while retaining control and flexibility. Fast forward six months, a couple of iterations, and even though my current setup is still a Django monolith, I'm now using Postgres as the app DB, ClickHouse for analytics data, and Redis for caching. I also use Celery for scheduled tasks, and a custom event queue for buffering writes. I run most of these things on a managed Kubernetes cluster (EKS). A high-level overview of the architecture. It may sound complicated, but it's practically an old-school monolithic architecture running on Kubernetes. Replace Django with Rails or Laravel and you know what I'm talking about. The interesting part is how everything is glued together and automated: autoscaling, ingress, TLS certificates, failover, logging, monitoring, and so on. It's worth noting I use this setup across multiple projects, which helps keep my costs down and launch experiments really easily (write a Dockerfile and git push). And since I get asked this a lot: contrary to what you might be thinking, I actually spend very little time managing the infrastructure, usually 0-2 hours per month total. Most of my time is spent developing features, doing customer support, and growing the business. That said, these are the tools I’ve been using for several years now and I’m pretty familiar with them. I consider my setup simple for what it’s capable of, but it took many years of production fires at my day job to get here. So I won’t say it’s all sunshine and roses. I don't know who said it first, but what I tell my friends is: \"Kubernetes makes the simple stuff complex, but it also makes the complex stuff simpler\". Automatic DNS, SSL, and Load Balancing Now that you know I have a managed Kubernetes cluster on AWS and I run various projects in it, let's make the first stop of the tour: how to get traffic into the cluster. My cluster is in a private network, so you won’t be able to reach it directly from the public internet. There’s a couple of pieces in between that control access and load balance traffic to the cluster. Essentially, I have Cloudflare proxying all traffic to an NLB (AWS L4 Network Load Balancer). This Load Balancer is the bridge between the public internet and my private network. Once it receives a request, it forwards it to one of the Kubernetes cluster nodes. These nodes are in private subnets spread across multiple availability zones in AWS. It's all managed by the way, but more on that later. Traffic gets cached at the edge, or forwarded to the AWS region where I operate. \"But how does Kubernetes know which service to forward the request to?\" - That’s where ingress-nginx comes in. In short: it's an NGINX cluster managed by Kubernetes, and it's the entrypoint for all traffic inside the cluster. NGINX applies rate-limiting and other traffic shaping rules I define before sending the request to the corresponding app container. In Panelbear’s case, the app container is Django being served by Uvicorn. It's not much different from a traditional nginx/gunicorn/Django in a VPS approach, with added horizontal scaling benefits and an automated CDN setup. It’s also a “setup once and forget” kind of thing, mostly a few files between Terraform/Kubernetes, and it’s shared by all deployed projects. When I deploy a new project, it’s essentially 20 lines of ingress configuration and that’s it: apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: namespace: example name: example-api annotations: kubernetes.io/ingress.class: \"nginx\" nginx.ingress.kubernetes.io/limit-rpm: \"5000\" cert-manager.io/cluster-issuer: \"letsencrypt-prod\" external-dns.alpha.kubernetes.io/cloudflare-proxied: \"true\" spec: tls: - hosts: - api.example.com secretName: example-api-tls rules: - host: api.example.com http: paths: - path: / backend: serviceName: example-api servicePort: http Those annotations describe that I want a DNS record, with traffic proxied by Cloudflare, a TLS certificate via letsencrypt, and that it should rate-limit the requests per minute by IP before forwarding the request to my app. Kubernetes takes care of making those infra changes to reflect the desired state. It’s a little verbose, but it works well in practice. Automated rollouts and rollbacks The chain of actions that occur when I push a new commit. Whenever I push to master one of my projects, it kicks off a CI pipeline on GitHub Actions. This pipeline runs some codebase checks, end-to-end tests (using Docker compose to setup a complete environment), and once these checks pass it builds a new Docker image that gets pushed to ECR (the Docker registry in AWS). As far as the application repo is concerned, a new version of the app has been tested and is ready to be deployed as a Docker image: panelbear/panelbear-webserver:6a54bb3 \"So what happens next? There’s a new Docker image, but no deploy?\" - My Kubernetes cluster has a component called flux. It automatically keeps in sync what is currently running in the cluster and the latest image for my apps. Flux automatically keeps track of new releases in my infrastructure monorepo. Flux automatically triggers an incremental rollout when there’s a new Docker image available, and keeps record of these actions in an \"Infrastructure Monorepo\". I want version controlled infrastructure, so that whenever I make a new commit on this repo, between Terraform and Kubernetes, they will make the necessary changes on AWS, Cloudflare and the other services to synchronize the state of my repo with what is deployed. It’s all version-controlled with a linear history of every deployment made. This means less stuff for me to remember over the years, since I have no magic settings configured via clicky-clicky on some obscure UI. Think of this monorepo as deployable documentation, but more on that later. Let it crash A few years ago I used the Actor model of concurrency for various company projects, and fell in love with many of the ideas around its ecosystem. One thing led to another and soon I was reading books about Erlang, and its philosophy around letting things crash. I might be stretching the idea too much, but in Kubernetes I like to think of liveliness probes and automatic restarts as a means to achieve a similar effect. From the Kubernetes documentation: “The kubelet uses liveness probes to know when to restart a container. For example, liveness probes could catch a deadlock, where an application is running, but unable to make progress. Restarting a container in such a state can help to make the application more available despite bugs.” In practice this has worked pretty well for me. Containers and nodes are meant to come and go, and Kubernetes will gracefully shift the traffic to healthy pods while healing the unhealthy ones (more like killing). Brutal, but effective. Horizontal autoscaling My app containers auto-scale based on CPU/Memory usage. Kubernetes will try to pack as many workloads per node as possible to fully utilize it. In case there’s too many Pods per node in the cluster, it will automatically spawn more servers to increase the cluster capacity and ease the load. Similarly, it will scale down when there’s not much going on. Here’s what a Horizontal Pod Autoscaler might look like: apiVersion: autoscaling/v1 kind: HorizontalPodAutoscaler metadata: name: panelbear-api namespace: panelbear spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: panelbear-api minReplicas: 2 maxReplicas: 8 targetCPUUtilizationPercentage: 50 In this example, it will automatically adjust the number of panelbear-api pods based on the CPU usage, starting at 2 replicas but capping at 8. Static assets cached by CDN When defining the ingress rules for my app, the annotation cloudflare-proxied: \"true\" is what tells the Kubernetes that I want to use Cloudflare for DNS, and to proxy all requests via it’s CDN and DDoS protection too. From then on, it’s pretty easy to make use of it. I just set standard HTTP cache headers in my applications to specify which requests can be cached, and for how long. # Cache this response for 5 minutes response[\"Cache-Control\"] = \"public, max-age=300\" Cloudflare will use those response headers to control the caching behavior at the edge servers. It works amazingly well for such a simple setup. I use Whitenoise to serve static files directly from my app container. That way I avoid needing to upload static files to Nginx/Cloudfront/S3 on each deployment. It has worked really well so far, and most requests will get cached by the CDN as it gets filled. It's performant, and keeps things simple. I also use NextJS for a few static websites, such as the landing page of Panelbear. I could serve it via Cloudfront/S3 or even Netlify or Vercel, but it was easy to just run it as a container in my cluster and let Cloudflare cache the static assets as they are being requested. There’s zero added cost for me to do this, and I can re-use all tooling for deployment, logging and monitoring. Application data caching Besides static file caching, there's also application data caching (eg. results of heavy calculations, Django models, rate-limiting counters, etc...). On one hand I leverage an in-memory Least Recently Used (LRU) cache to keep frequently accessed objects in memory, and I’d benefit from zero network calls (pure Python, no Redis involved). However, most endpoints just use the in-cluster Redis for caching. It's still fast and the cached data can be shared by all Django instances, even after re-deploys, while an in-memory cache would get wiped. Here's a real-world example: My Pricing Plans are based on analytics events per month. For this some sort of metering is necessary to know how many events have been consumed within the current billing period and enforce limits. However, I don't interrupt the service immediately when a customer crosses the limit. Instead a \"Capacity depleted\" email is automatically sent, and a grace period is given to the customer before the API starts rejecting new data. This is meant to give customers enough time to decide if an upgrade makes sense for them, while ensuring no data is lost. For example during a traffic spike in case their content goes viral or if they're just enjoying the weekend and not checking their emails. If the customer decides to stay in the current plan and not upgrade, there is no penalty and things will go back to normal once usage is back within their plan limits. So for this feature I have a function that applies the rules above, which require several calls to the DB and ClickHouse, but get cached 15 minutes to avoid recomputing this on every request. It's good enough and simple. Worth noting: the cache gets invalidated on plan changes, otherwise it might take 15 minutes for an upgrade to take effect. @cache(ttl=60 * 15) def has_enough_capacity(site: Site) -> bool: \"\"\" Returns True if a Site has enough capacity to accept incoming events, or False if it already went over the plan limits, and the grace period is over. \"\"\" Per endpoint rate-limiting While I enforce global rate limits at the nginx-ingress on Kubernetes, I sometimes want more specific limits on a per endpoint/method basis. For that I use the excellent Django Ratelimit library to easily declare the limits per Django view. It's configured to use Redis as a backend for keeping track of the clients making the requests to each endpoint (it stores a hash based on the client key, and not the IP). For example: class MySensitiveActionView(RatelimitMixin, LoginRequiredMixin): ratelimit_key = \"user_or_ip\" ratelimit_rate = \"5/m\" ratelimit_method = \"POST\" ratelimit_block = True def get(): ... def post(): ... In the example above, if the client attempts to POST to this particular endpoint more than 5 times per minute, the subsequent call will get rejected with a HTTP 429 Too Many Requests status code. The friendly error message you'd get when being rate-limited. App administration Django gives me an admin panel for all my models for free. It’s built-in, and It’s pretty handy for inspecting data for customer support work on the go. Django's built-in admin panel is very useful for doing customer support on the go. I added actions to help me manage things from the UI. Things like blocking access to suspicious accounts, sending out announcement emails, and approving full account deletion requests (first a soft delete, and within 72 hours a full destroy). Security-wise: only staff users are able to access the panel (me), and I’m planning to add 2FA for extra security on all accounts. Additionally every time a user logs in, I send an automatic security email with details about the new session to the account’s email. Right now I send it on every new login, but I might change it in the future to skip known devices. It’s not a very “MVP feature”, but I care about security and it was not complicated to add. At least I’d be warned if someone logged in to my account. Of course, there's a lot more to hardening an application than this, but that's out of the scope of this post. Example security activity email you might receive when logging in. Running scheduled jobs Another interesting use case is that I run a lot of different scheduled jobs as part of my SaaS. These are things like generating daily reports for my customers, calculating usage stats every 15 minutes, sending staff emails (I get a daily email with the most important metrics) and whatnot. My setup is actually pretty simple, I just have a few Celery workers and a Celery beat scheduler running in the cluster. They are configured to use Redis as the task queue. It took me an afternoon to set it up once, and luckily I haven’t had any issues so far. I want to get notified via SMS/Slack/Email when a scheduled task is not running as expected. For example when the weekly reports task is stuck or significantly delayed. For that I use Cronitor.io. The cron job monitoring dashboard from Cronitor.io The celery monitoring integration makes it super easy to instrument my scheduled tasks: # Auto-discovers celery beat tasks import cronitor.celery from celery import Celery app = Celery() cronitor.celery.initialize(app, api_key=\"super-secret\", celerybeat_only=True) App configuration All my applications are configured via environment variables, old school but portable and well supported. For example, in my Django settings.py I’d setup a variable with a default value: INVITE_ONLY = env.str(\"INVITE_ONLY\", default=False) And use it anywhere in my code like this: from django.conf import settings # If invite-only, then disable account creation endpoints if settings.INVITE_ONLY: ... I can override the environment variable in my Kubernetes configmap: apiVersion: v1 kind: ConfigMap metadata: namespace: panelbear name: panelbear-webserver-config data: INVITE_ONLY: \"True\" DEFAULT_FROM_EMAIL: \"The Panelbear Team \" SESSION_COOKIE_SECURE: \"True\" SECURE_HSTS_PRELOAD: \"True\" SECURE_SSL_REDIRECT: \"True\" Keeping secrets The way secrets are handled is pretty interesting: I want to also commit them to my infrastructure repo, alongside other config files, but secrets should be encrypted. For that I use kubeseal in Kubernetes. This component uses asymmetric crypto to encrypt my secrets, and only a cluster authorized to access the decryption keys can decrypt them. For example this is what you might find in my infrastructure repo: apiVersion: bitnami.com/v1alpha1 kind: SealedSecret metadata: name: panelbear-secrets namespace: panelbear spec: encryptedData: DATABASE_CONN_URL: AgBy3i4OJSWK+PiTySYZZA9rO43cGDEq... SESSION_COOKIE_SECRET: oi7ySY1ZA9rO43cGDEq+ygByri4OJBlK... ... The cluster will automatically decrypt the secrets and pass them to the corresponding container as an environment variable: DATABASE_CONN_URL='postgres://user:pass@my-rds-db:5432/db' SESSION_COOKIE_SECRET='this-is-supposed-to-be-very-secret' To protect the secrets within the cluster, I use AWS-managed encryption keys via KMS, which are rotated regularly. This is a single setting when creating the Kubernetes cluster, and it's fully managed. Operationally what this means is that I write the secrets as environment variables in a Kubernetes manifest, I then run a command to encrypt them before committing, and push my changes. The secrets are deployed within a few seconds, and the cluster will take care of automatically decrypting them before running my containers. Relational data: Postgres For experiments I run a vanilla Postgres container within the cluster, and a Kubernetes cronjob that does daily backups to S3. This helps keep my costs down, and it’s pretty simple for just starting out. However, as a project grows, like Panelbear, I move the database out of the cluster into RDS, and let AWS take care of encrypted backups, security updates and all the other stuff that’s no fun to mess up. For added security, the databases managed by AWS are still deployed within my private network, so they’re unreachable via the public internet. Columnar data: ClickHouse I rely on ClickHouse for efficient storage and (soft) real-time queries over the analytics data in Panelbear. It’s a fantastic columnar database, incredibly fast and when you structure your data well you can achieve high compression ratios (less storage costs = higher margins). I currently self-host a ClickHouse instance within my Kubernetes cluster. I use a StatefulSet with encrypted volume keys managed by AWS. I have a Kubernetes CronJob that periodically backups up all data in an efficient columnar format to S3. In case of disaster recovery, I have a couple of scripts to manually backup and restore the data from S3. ClickHouse has been rock-solid so far, and it’s an impressive piece of software. It’s the only tool I wasn’t already familiar with when I started my SaaS, but thanks to their docs I was able to get up and running pretty quickly. I think there’s a lot of low hanging fruit in case I wanted to squeeze out even more performance (eg. optimizing the field types for better compression, pre-computing materialized tables and tuning the instance type), but it’s good enough for now. DNS-based service discovery Besides Django, I also run containers for Redis, ClickHouse, NextJS, among other things. These containers have to talk to each other somehow, and that somehow is via the built-in service discovery in Kubernetes. It’s pretty simple: I define a Service resource for the container and Kubernetes automatically manages DNS records within the cluster to route traffic to the corresponding service. For example, given a Redis service exposed within the cluster: apiVersion: v1 kind: Service metadata: name: redis namespace: weekend-project labels: app: redis spec: type: ClusterIP ports: - port: 6379 selector: app: redis I can access this Redis instance anywhere from my cluster via the following URL: redis://redis.weekend-project.svc.cluster:6379 Notice the service name and the project namespace is part of the URL. That makes it really easy for all your cluster services to talk to each other, regardless of where in the cluster they run. For example, here’s how I’d configure Django via environment variables to use my in-cluster Redis: apiVersion: v1 kind: ConfigMap metadata: name: panelbear-config namespace: panelbear data: CACHE_URL: \"redis://redis.panelbear.svc.cluster:6379/0\" ENV: \"production\" ... Kubernetes will automatically keep the DNS records in-sync with healthy pods, even as containers get moved across nodes during autoscaling. The way this works behind the scenes is pretty interesting, but out of the scope of this post. Here’s a good explanation in case you find it interesting. Version-controlled infrastructure I want version-controlled, reproducible infrastructure that I can create and destroy with a few simple commands. To achieve this, I use Docker, Terraform and Kubernetes manifests in a monorepo that contains all-things infrastructure, even across multiple projects. And for each application/project I use a separate git repo, but this code is not aware of the environment it will run on. If you’re familiar with The Twelve-Factor App this separation may ring a bell or two. Essentially, my application has no knowledge of the exact infrastructure it will run on, and is configured via environment variables. By describing my infrastructure in a git repo, I don’t need to keep track of every little resource and configuration setting in some obscure UI. This enables me to restore my entire stack with a single command in case of disaster recovery. Here’s an example folder structure of what you might find on the infra monorepo: # Cloud resources terraform/ aws/ rds.tf ecr.tf eks.tf lambda.tf s3.tf roles.tf vpc.tf cloudflare/ projects.tf # Kubernetes manifests manifests/ cluster/ ingress-nginx/ external-dns/ certmanager/ monitoring/ apps/ panelbear/ webserver.yaml celery-scheduler.yaml celery-workers.yaml secrets.encrypted.yaml ingress.yaml redis.yaml clickhouse.yaml another-saas/ my-weekend-project/ some-ghost-blog/ # Python scripts for disaster recovery, and CI tasks/ ... # In case of a fire, some help for future me README.md DISASTER.md TROUBLESHOOTING.md Another advantage of this setup is that all the moving pieces are described in one place. I can configure and manage reusable components like centralized logging, application monitoring, and encrypted secrets to name a few. Terraform for cloud resources I use Terraform to manage most of the underlying cloud resources. This helps me document, and keep track of the resources and configuration that makes up my infrastructure. In case of disaster recovery, I can spin up and rollback resources with a single command. For example, here's one of my Terraform files for creating a private S3 bucket for encrypted backups which expire after 30 days: resource \"aws_s3_bucket\" \"panelbear_app\" { bucket = \"panelbear-app\" acl = \"private\" tags = { Name = \"panelbear-app\" Environment = \"production\" } lifecycle_rule { id = \"backups\" enabled = true prefix = \"backups/\" expiration { days = 30 } } server_side_encryption_configuration { rule { apply_server_side_encryption_by_default { sse_algorithm = \"AES256\" } } } } Kubernetes manifests for app deployments Similarly, all my Kubernetes manifests are described in YAML files in the infrastructure monorepo. I have split them into two directories: cluster and apps. Inside the cluster directory I describe all cluster-wide services and configuration, things like the nginx-ingress, encrypted secrets, prometheus scrapers, and so on. Essentially the reusable bits. On the other hand, the apps directory contains one namespace per project, describing what is needed to deploy it (ingress rules, deployments, secrets, volumes, and so on). One of the cool things about Kubernetes, is that you can customize almost everything about your stack. So for example, if I wanted to use encrypted SSD volumes that can be resized, I could define a new “StorageClass'' in the cluster. Kubernetes and in this case AWS will coordinate and make the magic happen for me. For example: apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: encrypted-ssd provisioner: kubernetes.io/aws-ebs parameters: type: gp2 encrypted: \"true\" reclaimPolicy: Retain allowVolumeExpansion: true volumeBindingMode: WaitForFirstConsumer I can now go ahead and attach this type of persistent storage for any of my deployments, and Kubernetes will manage the requested resources for me: # Somewhere in the ClickHouse StatefulSet configuration ... storageClassName: encrypted-ssd resources: requests: storage: 250Gi ... Subscriptions and Payments I use Stripe Checkout to save all the work in handling payments, creating checkout screens, handling 3D secure requirements from credit cards, and even the customer billing portal. I do not have access to the payment information itself, which is a huge relief and enables me to focus on my product instead of highly sensitive topics like credit card handling and fraud prevention. An example Customer Billing Portal in Panelbear. All I have to do is create a new customer session and redirect the customer to one of Stripe's hosted pages. I then listen for webhooks about whether the customer upgraded/downgraded/cancelled and update my database accordingly. Of course there's a few important parts like validating that the webhook really came from Stripe (you have to validate the request signature with a secret), but Stripe's documentation covers all the points really well. I only have a few plans, so it's pretty easy for me to manage them in my codebase. I essentially have something like: # Plan constants FREE = Plan( code='free', display_name='Free Plan', features={'abc', 'xyz'}, monthly_usage_limit=5e3, max_alerts=1, stripe_price_id='...', ) BASIC = Plan( code='basic', display_name='Basic Plan', features={'abc', 'xyz'}, monthly_usage_limit=50e3, max_alerts=5, stripe_price_id='...', ) PREMIUM = Plan( code='premium', display_name='Premium Plan', features={'abc', 'xyz', 'special-feature'}, monthly_usage_limit=250e3, max_alerts=25, stripe_price_id='...', ) # Helpers for easy access ALL_PLANS = [FREE, BASIC, PREMIUM] PLANS_BY_CODE = {p.code: p for p in ALL_PLANS} I can then use it in any API endpoint, cron job and admin task to determine which limits/features apply for a given customer. The current plan for a given customer is a column called plan_code on a BillingProfile model. I separate the user from the billing information since I'm planning to add organizations/teams at some point, and that way I can easily migrate the BillingProfile to the account owner / admin user. Of course this model won't scale if you're offering thousands of individual products in an e-commerce shop, but it works pretty well for me since a SaaS usually only has a few plans. Logging I don’t need to instrument my code with any logging agent or anything like that. I simply log to stdout and Kubernetes automatically collects, and rotates logs for me. I could also automatically ship those logs to something like Elasticsearch/Kibana using FluentBit, but I don’t do that yet to keep things simple. To inspect the logs I use stern, a tiny CLI tool for Kubernetes that makes it super easy to tail application logs across multiple pods. For example, stern -n ingress-nginx would tail the access logs for my nginx pods even across multiple nodes. Monitoring and alerting In the beginning I used a self-hosted Prometheus / Grafana to automatically monitor my cluster and application metrics. However, I didn’t feel comfortable self-hosting my monitoring stack, because if something went wrong in the cluster, my alerting system would go down with it too (not great). If there’s one thing that should never go down is your monitoring system, otherwise you’re essentially flying without instruments. That’s why I swapped my monitoring / alerting system with a hosted service (New Relic). All my services have a Prometheus integration that automatically records and forwards the metrics to a compatible backend, such as Datadog, New Relic, Grafana Cloud or a self-hosted Prometheus instance (what I used to do). To migrate to New Relic, all I had to do was to use their Prometheus Docker image, and shutdown the self-hosted monitoring stack. Example New Relic dashboard with a summary of the most important stats. I also monitor uptime around the world using New Relic's probes. The migration from a self-hosted Grafana/Loki/Prometheus stack to New Relic reduced my operational surface. More importantly, I'd still get alerted even if my AWS region is down. You might be wondering how I expose metrics from my Django app. I leverage the excellent django-prometheus library, and simply register a new counter/gauge in my application: from prometheus_client import Counter EVENTS_WRITTEN = Counter( \"events_total\", \"Total number of events written to the eventstore\" ) # We can increment the counter to record the number of events # being written to the eventstore (ClickHouse) EVENTS_WRITTEN.incr(count) It will expose this and other metrics in the /metrics endpoint of my server (only reachable within my cluster). Prometheus will automatically scrape this endpoint every minute and forward the metrics to New Relic. The metric automatically shows up in New Relic thanks to the Prometheus integration. Error tracking Everyone thinks they don’t have errors in their application, until they start error tracking. It’s too easy for an exception to get lost in logs, or worse you’re aware of it but unable to reproduce the problem due to lack of context. I use Sentry to aggregate and notify me about errors across my applications. Instrumenting my Django apps is very simple: SENTRY_DSN = env.str(\"SENTRY_DSN\", default=None) # Init Sentry if configured if SENTRY_DSN: sentry_sdk.init( dsn=SENTRY_DSN, integrations=[DjangoIntegration(), RedisIntegration(), CeleryIntegration()], # Do not send user PII data to Sentry # See also inbound rules for special patterns send_default_pii=False, # Only sample a small amount of performance traces traces_sample_rate=env.float(\"SENTRY_TRACES_SAMPLE_RATE\", default=0.008), ) It’s been very helpful because it automatically collects a bunch of contextual information about what happened when the exception occurred: Sentry aggregates and notifies me in case of exceptions. I use a Slack #alerts channel to centralize all my alerts: downtime, cron job failures, security alerts, performance regressions, application exceptions, and whatnot. It's great because I can often correlate issues when multiple services ping me around the same time, on seemingly unrelated problems. Example Slack alert due to a CDN endpoint being down in Sydney, Australia. Profiling and other goodies When I need to deep dive, I also use tools like cProfile and snakeviz to better understand allocations, number of calls and other stats about my app’s performance. Sounds fancy but they’re pretty easy to use tools, and have helped me identify various issues in the past that made my dashboards slow from seemingly unrelated code. cProfile and snakeviz are great tools to profile your Python code locally. I also use the Django debug toolbar on my local machine to easily inspect the queries that a view triggers, preview outgoing emails during development, and many other goodies. Django's Debug Toolbar is great for inspecting stuff in local dev, and previewing transactional emails. That's all folks I hope you enjoyed this post if you've made it this far. It ended up being a lot longer than I originally intended as there was a lot of ground to cover. If you're not already familiar with these tools consider using a managed platform first, for example Render or Railway. This might help you focus on your product, and still gain many of the benefits I talk about here. \"Do you use Kubernetes for everything?\" - No, different projects, different needs. For example this blog is hosted on Vercel. That said, I do intend to write more follow up posts on specific tips and tricks, and share more lessons learned along the way. Apr 7, 2021·@anthonynsimon",
    "commentLink": "https://news.ycombinator.com/item?id=40694103",
    "commentBody": "The Architecture Behind a One-Person Tech Startup (2021) (anthonynsimon.com)203 points by thunderbong 18 hours agohidepastfavorite67 comments cj 9 hours agoSmall secret: The best tech stack when starting a startup is one you don't have to learn. There's a million things you learn when starting a company. Don't make yourself learn an entirely new tech stack on top of everything else. This advice means you'll be using whatever you've used in the past which might not be the sexiest or newest technology, but your users won't care. Your users want a working product. Choose the stack that will result in a working product the quickest. Refactor and migrate to a better stack later, if necessary. (It rarely is) For me, that meant deploying to Elastic Beanstalk (I know, boring, no one talks about it, but it works!) and using Mongo because I was already comfortable with it. It also meant not using React, at first. This was the right answer for me, but might be the wrong answer for you! Build your app on the technology you know. reply CuriouslyC 8 hours agoparentThat's true if you're optimizing for start-up success. The odds of a startup succeeding are pretty low and mostly tech is not the cause of failures though. When people learn a new stack for a startup they're optimizing for the startup failing, so they can still derive some value out of the failure. This just comes down to a napkin calculation of expected value of building a startup given P(success). If your startup is looking like a real business out of the gate, using the simple stack you know is the way to go, and if it's more of a hobby project that you'd like to monetize eventually, learn something new. reply NameError 7 hours agorootparentThis lines up with how I make tech stack decisions for my own projects. But I think it's not always obvious going into something if it's going to end up being a money-making endeavor or just an educational project in the end, so I'll fall somewhere in between. What makes the most sense to be is to be really selective about what new technologies to use, and try to really learn ~one thing per project. E.g. my current project is a small search engine, and I've spent a lot of time exploring / figuring out how to use LLM Embedding models and vector indices for search relevance (vs. falling back on using ElasticSearch the same way we use it at work), but I'm using tools that are familiar to me for the UI/db/infrastructure. reply grogenaut 4 hours agoparentprevIf anyone tells you different you can take stacks like Beanstalk VERY FAR. Probbably way further than you want to. We just moved our highest TPS (Transactions per second) and OPS (Objects Per Second) service off of beanstalk after 7 years. At peak this service was serving around 1.1M TPS and around 8M OPS with peaks up to 3M TPS and 14M OPS. It was horizontally scaled and run by about .25 engineers. That was actually the main problem. That and the company got real good at running ECS. Our services are all golang so beanstalk eventually was getting in the way, and one of our last major issues had to do with nginx proxy on bean stalk not keeping up with our go service. There's several other edge cases with Beanstalk like how to do health checks right, and speed of deploys esp when they get wedged. But if you know it you can, as we found, go very far with it, powering a core feature of a very large web property (check my bio). Am I happy we moved off, yes. Was I impressed how big we took a very simple \"starter\" setup, also yes. Again one of the biggest reasons was that all of our competence in the company was no longer on beanstalk but on ECS where we had solved the issues we had with it with more complex setups more in our control. If I were starting again would I use Beanstalk? no not me personally but when we started ecs didn't exist and beanstalk was better than bare EC2. now I know and am comfortable with ECS. Did it help the company? very much so, we leveraged the heck out of Beanstalk to scale the company horizontally and vertically. reply kugelblitz 8 hours agoparentprevFor my 12 year side project, I recently moved from Elastic Beanstalk after 6-7 years to Platform.sh, because \"it just works\" even more so and it was way easier to debug (EB just says \"error in step 18_install_yarn\" or something). I use Symfony (Php) and have not used a full SPA after I retired AngularJS (v1) like 10 years ago. What people now call server side rendering (SSR) is just how Symfony works with its regular Twig templating language (heavily inspired by Django's templating language). As I gained more experience, I rewrote it. Once from vanilla PHP to Laravel, then later to Symfony. reply throwAGIway 4 hours agorootparentServer side rendering of React applications doesn't just refer to the fact that it's generated on the server like you do with PHP. The main difference is that there are IDs that allow the client side code to seamlessly attach event handlers (this is called hydration) to the DOM - and that there is no difference between server and client side code. In your case, you'd have to do that manually - a huge difference (speaking as someone who used to do that with jQuery). reply Bilal_io 6 hours agorootparentprevHey, I'd be curious to know what made you move from Laravel to Symphony. I've not been exposed to any of the two and only dealt with PHP as part of messing with WordPress in the past. reply lopatin 8 hours agoparentprevElasticBeanstalk is wonderful. Each to his own but for me it was the answer to the question \"I agree Kubernetes is overkill for me .. but then what should I use?\". I certainly didn't want to be manually creating instances, installing Java / Node / Docker, starting / stopping services and doing deploys manually because that's also annoying work :) Elastic Beanstalk + the Github actions deploy plugin is dead simple and just works. reply eyphka 4 hours agoparentprevSeconded, (and also started on elastic beanstalk!) Has kept surprisingly well over time, with some hiccups around platforn version changes. reply mattbillenstein 4 hours agoprevGuy lost me at k8s and terraform - just put your thing on a single VM and yolo. reply oooyay 1 hour agoparentI can understand why you'd say that, but I don't think the world's that black and white. Many people would say a detached, Typescript frontend is less simple than SSR. At this point in my career writing a bunch of ad-hoc, per-page Javascript would be more toilsome than writing components. Thus, the prevailing idea of \"simple\" would be less simple for me. In that same way, if you've spent a large chunk of your career in Kubernetes then managed Kubernetes is probably a lot more simple than maintaining an image production pipeline and a disjointed Terraform deploy. You'd have to make a choice between immutability and non-immutability with VMs as well, and design lifecycles for them if you choose immutability. That choice is made for you with Kubernetes and has well-established patterns. That's to say, simple is highly subjective. Like another comment said, simple is the technology you know best today (and that you can easily hire for). reply marcosdumay 54 minutes agorootparent> You'd have to make a choice between immutability and non-immutability with VMs as well I'd like to emphasize the yolo from the GP. I does really not imply image maintenance and immutability. (By the way, \"non-immutability\" is called \"mutability\".) And no, if you know kubernetes to your heart, it's still very often easier to start the grug way and build OPS up only after you have something to run on it. (But, of course, there are exceptions. There are always exceptions.) reply tracerbulletx 45 minutes agoparentprevk8s is easy once you know it imo. My recent project I made a Digital ocean cluster and some Github actions to deploy to it in like half an hour, and it would be easy to port to another cloud, or self hosted k8s cluster. It can auto scale nodes, do 0 downtime deployments, bg deployments, has automated certificate provisioning, it does everything I need. reply mrj 21 minutes agorootparentI don't know why this is being downvoted, this is my experience too. I don't mess with networking or volumes in k8s but it gives me a lot of stuff out of the box for when I need it later. It takes a couple of minutes to copy and paste the Deployment definition and change a few things. The trouble with \"single vm and yolo\" it is tech debt of the worst kind. It's not a shortcut you might have to expand on someday, it's the kind where whole platform changes are necessary. Someday that vm process won't be enough and that'll require changing everything about the deploy, potentially at a time when big changes aren't desirable. If the business is starting to pick up so that we need something more reliable, that's the wrong time to want to replatform. I'd rather but in a small amount of upfront knowing that I won't have a big tech debt to pay back later. So I keep it real simple, and keep away from parts that I know will give me a headache. I use a managed service and plan to give it to somebody else when we're big enough to have that somebody else. Then they can worry about the parts I didn't. It's wise not to do too much upfront, for sure. But it's wise not to back into corners that are hard to undo later, too. reply jonas21 3 minutes agorootparent> Someday that vm process won't be enough For a surprisingly large set of cases, it will be enough though. The best debt is the kind you never have to pay off. reply dmwilcox 12 hours agoprevContext: I write mostly write Python for a living and run a Django app as a major responsibility I always wonder if python, auto scaling, and cloud change the kinds of businesses (and margins) required. Running 60+ pods of gunicorn for an app incurs lots of overhead, especially if one is using small VMs. I can't count the number of war stories I've heard from SRE friends who joined some company and realized they were taking over a Django stack for the core of a business that was blowing gaskets left and right. This sort of thing just leaves me wondering if margins have to be high to support a slower language, slower framework, and complicated deployment model to work around the Python GIL. Call me jaded but I just wonder if it's worth the time to market to do Python these days versus say Go and be able to deploy a static binary and use all your CPU cores simply. K8s is way less tempting for a \"one-process-architecture \" (minus database and maybe nginx) until the system is much larger (instead a couple of systemd units would sort you) reply marcosdumay 47 minutes agoparentPython can waste 90% or 99% of your ops budget. But auto-scaling starts from 99%, and can go all the way to 4 or 5 9s of wastage. Of course, if you combine them, you add up the 9s. Anyway, it's patently obvious that increasing your unit costs by 7 orders of magnitude will constrain the kinds of business you can run. A few people will deny that, but the cloud is so impactful that those are very few nowadays. What a lot of people will deny is the relative importance of those two. If you take your C code from an auto-scaling environment and replace it with bare metal Python, you often get a few orders of magnitude gain. reply redman25 4 hours agoparentprevWeb apps are generally IO bound by the database. Hardly any time gets spent in cpu even in python. There could be a number of things contributing to having to horizontally scale python more than compiled frameworks. Many apps are still stuck on non-async frameworks. Many devs are also bad at knowing how not to block server processes. reply schrodinger 4 hours agoparentprevTotally agreed. Such a fan of Go for this. It obviates just about any reason to use docker. You compile a single binary, for any platform from any platform, and just… copy it onto a server. Hell there’s even first class support to compile assets into it if you wanna throw your whole site into the binary, or many other use cases that would otherwise make docker nice. Damn I miss the startup that was a Go build and deploy to 3 static VMs over my current company’s dozens of microservices + ecs + kafka + aurora postgres. Startup A had the servers all sitting around at 2% cpu all day, trivially scalable by adding more vms. No downtime over 3 years. Startup B had 10x the users, but an elaborate docker + ecs + dozens of microservices (that could have just been libraries, avoiding all that complexity) + aurora postgres. Downtime all the time. Most recent was so hard to detect: a db server running fine at 40% load and our application around the same, yet db timeouts left and right so considered an official outage. Aws had throttled the network throughout between the DB and App with no warning! We even had an AWS support person on the call and took them 2 hours to figure it out. reply williamdclt 1 hour agorootparentI don’t see how using a go binary vs dockerized microservices is related to database concerns? You need a database either way, and this problem you describe doesn’t seem related to the application level reply p_l 9 hours agoparentprevStack Overflow used to claim that the money they spent on licensing etc. to run their stack on .NET was well recouped in reduced hardware and energy spend, because .NET AOT compilation meant they got way more performance per buck. reply lifeisstillgood 12 hours agoparentprevI’m not sure I understand - pythonnis “just” a process once you kick it off, want to run 8 processes on 8 CPUs, kick off 8 processes. Are you saying that to run this 8 processes you suddenly need 8 VMs running in the cloud - yeah. That does seem expensive. It’s very tempting to say one should not start in the cloud but host locally, but that seems an unpopular view. But maybe as we start to see more and more local workspaces catering to people working from home, we will see more and more “mini data centres” - it might even by Oxides sweet spot. Edit: “”” because it actually winds up being less DevOps work, on average, to support open-source systems running on bare VMs, than to try to keep up with Google’s deprecation treadmill “”” https://steve-yegge.medium.com/dear-google-cloud-your-deprec... Mr Yegge makes my point much better ofc reply schrodinger 4 hours agorootparentWe went through a migration from Ruby on Rails (as a json api) to Go and it just really does make a difference when you need 1/50th the servers to run (don’t remember exact multiple, but it really was that dramatic—the concurrency model enabled so many parallel requests per instance compared to Ruby). It’s kinda like using a map reduce cluster when a beefy server with a few Linus commands piped could have handled the “big data” needs. Both have their time and place, but it’s amazing how far a simple setup can go, so don’t overengineer prematurely. reply CuriouslyC 8 hours agoparentprevPro tip, the strangler fig pattern is great for taming those oversized Django monoliths. FastAPI is a good replacement if you want to stay python, it's much faster. reply qeternity 9 hours agoprevI see a lot of comments to the effect that this is a complicated setup, especially for one person. I really think most people need to re-evaluate their stacks without all of the marketing of cloud providers and gigascalers. This setup is very similar to the startup that I run. We have used k8s from day one, despite plenty of warnings when we did, but it has been rock solid for 3 years. We also decided to run Postgres and Redis on k8s using Patroni + Sentinel and the LVM storage class. This means we get highly performant local storage on each node and we push HA down to the application. Was there a learning curve? Yes, it took a solid week to figure out what we were doing. And we've had the odd issue here and there, but our uptime has exceeded what we would have had with a cookie cutter AWS setup, and our costs have been a fraction (including human capital costs). reply marcinzm 8 hours agoparentSame. The simple fact that every PR can deploy a full stack, including RDS and managed Redis if desired, automatically in it's own namespace with proper DNS pointing to services is a massive win for us. As in, if you label the PR then it all happens automatically and then it all shuts down automatically when the PR is closed. reply williamdclt 1 hour agorootparentDo you have any resource to how to set that up? I’m interested! reply marcinzm 1 hour agorootparentShould make a blog post but in short: - Every service is deployed via a Helm chart and using containers - GitHub actions build the container and deploy the helm chart Some of the details that matter: - ACK is used to create AWS services (RDS, Redis, etc.) via Helm charts (we also have a container option for helm charts as it's faster and less expensive) - External Secrets is used to create secrets in the new namespace and also do things like generate RDS passwords - ExternalDNS creates DNS entries in Route53 from the Ingress objects - Namespace name is generated automatically from the branch name - Docker images use the git hash for the tag Some things that are choices: - Monorepo although each service aims to be as self-contained as possible. - Docker context is the git root as this allows for a service to include shared libraries from the repo when creating a container. This is for case where we break the previous rule. reply CuriouslyC 8 hours agoparentprevK8s is overkill though. Google cloud run gives you the good bits with less work and it's still reasonably priced. Azure container apps in theory should be similarly good, but it's kind of buggy and poorly engineered. reply victor106 8 hours agorootparent> Azure container apps in theory should be similarly good, but it's kind of buggy and poorly engineered. 100% agree. At a mega corp they were mandated to use Azure(worst decision) and we choose Azure container apps. Nothing worked: from the deployment ARM templates to scalability. It was a disaster. This was after we had the highest level of support from Azure. The engineer working with us in this almost admitted this shouldn’t have been released in it’s current form. I can’t for the life of me understand how Microsoft releases such products!!! reply mitjam 5 hours agorootparentprevCloudRun with Django works well, but for a complete setup, you need to configure, manage and pay other services, too, like Cloud SQL for PostgreSQL, Memorystore for Redis, API Gateway, Observability, Cloud Build, Artefact Registry, Cloud Key Management, IAM, Pub/Sub, CDN, and Cloud Storage. When you have a live service, you probably also want to pay for Google Cloud Customer Care. The same is true for AWS and Azure. Depending on training and experience, it may be easier to setup a GCP than a Kubernetes based solution, but it's still not exactly trivial. And, once a fitting Kubernetes platform is up and running, it's almost trivial to add new services, as the article describes. I think, even in 2024, and even for a one-person business like the authors', starting with Kubernetes is not a bad decision. I'm currently building my own Kubernetes based platform, but on a less expensive service (Hetzner Cloud). I use a separate single-node Kubernetes \"cluster\" with Rancher for management, and ArgoCD for continuous deployment from git. Currently I only have a single-node \"playground\" cluster up and running for my \"playground\" workloads, to save costs, but I will upgrade this to a proper HA cluster before a service goes live. Later, I can still upgrade to GCP, or in my case probably Azure. Until then, I don't need to worry about large cloud bills, which is also a good thing. reply qeternity 8 hours agorootparentprevWhy do you say it's overkill? Why do people think k8s (or k3s) is some impossible monster? Have you deployed and managed k8s before? What did you find more complicated than learning the ins and outs of the cloud variants? reply dinkleberg 7 hours agorootparentIn my experience, people who think k8s is really hard to user are either: a) someone who had k8s forced on them without getting a chance to learn it (or had no interest in the first place) and was stuck with its complexity, or b) has never actually used k8s and is just parroting what they've heard. The former situation does suck. K8s is amazing and once you understand it, it is easy to work with. But if you haven't learned the concepts and core resources, it will definitely appear as a black box with a ton of complexity. But I think for many of us who have used Kubernetes a lot, it is a no-brainer in a lot of situations as it doesn't matter which cloud provider you're using (for the most part), you get a common and familiar interface. reply EuAndreh 3 hours agorootparentprevFrom the fact that the LoC count of the implementation is beyond \"millions\". How about this equivalence: I appreciate how extremely sophisticated GCC is, and the very well optimized output it generates. It is still is 100x more complex internally (and thus, error prone, buggy, more complex to modify when needed) than TinyCC, for instance. reply CuriouslyC 8 hours agorootparentprevI'm not saying it's an impossible monster but I can setup and deploy a project from scratch with cloud run in ~5 gcloud cli commands while being somewhat protected from my own ignorance. reply mitjam 5 hours agorootparentCaution: Working with CloudRun with ignorance on any level can lead to very large bills: https://news.ycombinator.com/item?id=25372336 - The article discussed there is a good cautionary tale: https://archive.is/D5qc8 - I prefer to explore and experiment on a less scalable solution which is usually also less scalable in terms of costs. reply FlyingSnake 7 hours agoparentprevFor a startup that was generating revenue and got acquired, this is par for the course. What are people expecting instead? reply malux85 9 hours agoparentprevI am solo builder and runner of https://atomictesselator.com and I have used k8s from day one. I also agree with you, it's been rock solid, and the ability to horizontally scale so easily is great. I dont even know which physical machines in my rack the jobs/pods are running on, I just have a high level dashboard (lens) and I can see the CPU+GPU utilization hit 100% as everything self balances, it's great, this has been very helpful scaling my GPU workload which has increased a lot recently reply FlyingSnake 7 hours agorootparentLooks like the setup didn’t survive a death hug from HN, the site’s not loading for me. reply azornathogron 6 hours agorootparentIt's just a typo in the URL. It should be https://atomictessellator.com (two Ls) reply codeisawesome 1 hour agoprevI’d love to read a blog post from successful one person startups that are in the highly competitive spaces like DevOps tooling (uptime, analytics…) on how they go-to-market and differentiate. reply welanes 13 hours agoprevThings are much easier for one-person startups these days—it's a gift. I remember building a todo app as my first SaaS project, and choosing something called Stormpath for authentication. It subsequently shut down, forcing me to do a last-minute migration from a hostel in Japan using Nitrous Cloud IDE (which also shut down). Just pain upon pain.[1] Now, you can just pick a full-stack cloud service and run with it. My latest SaaS[2] is built on Google Cloud, so Authentication, Cloud Functions, Docker containers, logging, etc straight out of the box. Not to mention, modern JavaScript and CSS are finally good. With so many fewer headaches, it’s a great time to build. [1] Admittedly, I was new to software dev and made some rather poor tech choices [2] https://simplescraper.io reply robertlagrant 12 hours agoparentHow do you find the costs involved with a cloud service like that? I remember getting bitten once with a bill from Azure because a service went wild with logging once. reply joshstrange 10 hours agorootparentAlso solo founder here, for myself you just have to watch costs like a hawk when you make any big changes. AWS and friends have calculators but there is only so much you can estimate and it’s hard to know the usage patterns till something is live. I’m lucky that my work is event-based, as is it used by in-person live events so my usage comes in waves (pre-sales a month or two out, steady traffic the week leading up to the event, and high traffic the day before or week/day of the event). This means that at worst I only have to ride out the current “wave” and then I have some amount of time before the next event (gives me an opportunity to fix run-away costs. One of my big runaway costs was when I tried to use something like Datadog/NewRelic/Baseline. You work yourself up to the cost of the service, make your peace with it (the best you can, since it’s also hard to estimate), then get hit with AWS fees (that none of the providers call out) for things like CloudWatch when they are pulling logs/metrics out. I’ve had the CloudWatch bills be 4-6x as expensive as the service itself and it’s a complete surprise (or was the first time). Thankfully AWS refunded it when it happened. I caught it after 2 days and had run up a few hundred dollars in that time, I could have handled it but thankfully they refunded it for me. The second runaway cost was Google Maps, once you fall off that free tier the costs accumulate quickly. In just a few days I had a couple hundred in fees from that. I scrambled a switch to ProtonMaps and took my costs down to a couple dollars a month. reply mitchbob 15 hours agoprev(2021). Discussion of this when it was first submitted (320 comments): https://news.ycombinator.com/item?id=26737771 reply wiradikusuma 10 hours agoprevMy backend setup for my one-person startup (\"case study\" for my book, https://opinionatedlaunch.com) is GitHub (for code repo and CI/CD), Firebase (auth, analytics, push notif) and CloudFlare (static pages, DNS stuff) and Fly.io. Less work but more done. My only complaint Fly.io doesn't have managed DB (https://fly.io/docs/postgres/getting-started/what-you-should...) and task queue. At work we use GCP, but try to be as high as possible in the abstraction layer (e.g. use Cloud Run and Cloud SQL). reply vindex10 9 hours agoparentI was able to use managed Postgres ~a year ago on Fly.io. They seem to have offloaded its maintenance to Supabase, but it is still seamlessly interfaced with Fly.io. Moreover, they still allow 1 free db per account: > Supabase offers one free, resource-limited database per Fly.io user Are you concerned that it is not directly managed by Fly.io? * also Kafka: https://fly.io/docs/reference/kafka/ reply esafak 14 hours agoprevThis is pretty sophisticated for one person. reply swagasaurus-rex 12 hours agoparentFairly simple and explainable for an organization reply EuAndreh 4 hours agoparentprevs/sophisticated/complex/ FTFY reply enahs-sf 5 hours agoprevI think the nice benefit here is because of OPs infrastructure experience and process, he can now quickly run and test new ideas and projects for a reasonable marginal cost. Seems legit. Very clean setup. reply FlyingSnake 12 hours agoprevCame here expecting a tangled mess of disparate frameworks but was pleasantly surprised to see sane choices in using Django as a base. Sane choices and it shows why the product got acquired. reply extr 15 hours agoprevWould be interested to know which parts have better solutions as of 2024. But still feels pretty relevant. reply _puk 13 hours agoparentIf you click the link the original SAAS (Panel Bear) is now \"a part of\" cronitor.io. Wonder if they kept it as is, and how many people manage it nowadays. reply amzans 10 hours agorootparentHey I'm the author of the post. We ran Panelbear for about a year before merging it into Cronitor's codebase. Cronitor is also a Django monolith but on EC2 and was already humming along nicely for several years through frequent traffic spikes. We had no reliability issues with K8s, but came down to: as a small team we decided to have less moving parts. The new setup is not too different from what I describe here: https://anthonynsimon.com/blog/kamal-deploy/ reply ACV001 5 hours agoprevStack and the technical part is rarely the important factor in success. The idea and marketing seem to be the important bit. The stack can be the cause of failure, but it can never be the reason for the success of a startup. reply danesparza 1 hour agoparentBecause you'll be fighting a lot of forces that don't care if you fail (as a startup entrepreneur) confidence in your stack will help you sleep at night. And this is a good thing. reply nunez 7 hours agoprevHonestly, this is a pretty solid stack. I wonder how they make time to manage it all _and_ iterate on projects _and_ have a life outside of that. This is the biggest problem I've long struggled with. I don't know of a good solution. reply danesparza 1 hour agoparentA solid Kubernetes stack kind of manages itself. This will help you have a life. Boundaries will also help (you need to time box certain activities it sounds like). You can do this. Just keep trying. reply dakiol 11 hours agoprevI wish they could have explained the deployment/release part via ci/cd more in depth. reply andrewstuart 11 hours agoprev [–] I closed the page at \"Kubernetes\", despite the \"you may not need this\", because that was all I needed to hear to know this setup has little to do with the ordinary one person tech startup. reply KronisLV 10 hours agoparentI guess some people are just very used to it nowadays, hence it will work pretty well to them - same as how someone might have 10+ years of experience in Java and pick it for a project and use it successfully, whereas someone else could find the pace of development in it to be slower than the alternatives (despite how decent it is nowadays). Personally, I think that containers are a good choice for most webdev projects. If you are just starting out, then Docker Compose is probably very much sufficient for anything that touches upon a single node. Realistically, once you need to most past that, I feel like most folks would be served just fine by something like Docker Swarm + Portainer, you'd still need to run your own web server in front of your containers if you want something similar to an ingress, but in my eyes that's a plus, given how simple the config is (if you've ever installed Apache/Nginx/Caddy it's very much like that), or maybe go with Traefik if you must. There's scaling, resource reservations and limits, overlay networking between nodes, port mapping, storage, restart policies, configuration and pretty much most of the things you might reasonably need. Something like Hashicorp Nomad could also be mentioned here, but Docker Swarm seems like the simpler option to me. Past that, it's not like you can't run a bit cut down versions of Kubernetes, that will decrease its surface area somewhat - K0s, K3s and others all try to do this. I personally rather like K3s, it also integrates with Portainer/Rancher nicely if you need a dashboard, you can take advantage of Helm charts and all that other good stuff. I found the choice of K3s using Traefik by default (when I last used it) a bit suspect (configuring a custom non-ACME wildcard cert as the default for the ingress wasn't exactly well documented), but overall it was an okay experience and the resource usage wasn't anything crazy either. For my personal stuff nowadays, I still run a Docker Swarm cluster and I've no complaints there. It doesn't have autoscaling out of the box, but then again, my workloads are too boring to need that and I enjoy the predictability in billing I get. reply udev4096 5 hours agoparentprevWell, let's hear it. Is it because you heard somewhere that \"k8s is overwhelming and unnecessary for everyone\" or do you actually have some constructive argument for not using k8s? reply EuAndreh 3 hours agorootparentNot GP, but nothing wrong with kubernetes per se. It is simply unnecessary. You can get to gigantic success and extraordinary scale by growing vertically, without needing to add a very complex layer that kubernetes is. Think of the many literal millions of lines of code, and thus, potential bugs and liabilities one inherits by \"just using kubernetes\". It's not a requirement, neither problematic. Its simply unnecessary for anything remotely resembling a \"one-person tech startup\". Besides unnecessary features like horizontal scaling, necessary features like restarting a service already exist, and most likely are already installed in the base distro and being used by the rest of the system. Its not like this couldn't be done before, all kubernetes provides is a conveniet and streamlined package for all that, at the cost of black-hole levels of extra complexity via several added indirections. reply danjl 1 hour agoparentprevAssuming that \"ordinary\" means the same thing to everyone is a bit of a generalization. reply dimitar 10 hours agoparentprev [–] I would normally avoid recommending k8s, but perhaps the founder already was pretty comfortable with k8s from a previous job and knows what to avoid. There are no production dbs in k8s, no service meshes, monitoring is only side-cars that send data to an off-cluster backend, The automatic deployment with flux seems pretty nice! reply p_l 9 hours agorootparent [–] Having learnt k8s once, I found out it greatly simplifies things for me when I want to run new projects, even if it's single server only (there I use k3s). Especially if there's a chance I need to run more than one client, or environment, on a given server, which is more important for \"solo\" enterprise than for a bigger company because I do not have money or time to care of multiple servers. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post outlines the infrastructure setup for running a one-person SaaS (Software as a Service) using Kubernetes on AWS, highlighting its low-stress, self-funded nature.",
      "Key components include traffic management with Cloudflare and AWS, deployment automation via GitHub Actions and Flux, and reliability through Kubernetes' autoscaling and liveliness probes.",
      "Additional features cover caching with Redis, rate-limiting with Django Ratelimit, scheduled tasks with Celery, and monitoring with New Relic and Sentry, providing a comprehensive overview of managing a solo tech startup."
    ],
    "commentSummary": [
      "The best tech stack for a startup is one that the team is already familiar with, as learning new technologies can add unnecessary complexity.",
      "Prioritize quick deployment and consider refactoring later; users care more about a functional product than the underlying technology.",
      "While some new technologies like Kubernetes might be overkill, simpler solutions such as Docker Swarm or managed services can be more appropriate for balancing simplicity and scalability."
    ],
    "points": 203,
    "commentCount": 67,
    "retryCount": 0,
    "time": 1718502714
  },
  {
    "id": 40695839,
    "title": "Simple sabotage for software (2023)",
    "originLink": "https://erikbern.com/2023/12/13/simple-sabotage-for-software.html",
    "originBody": "Simple sabotage for software 2023-12-13 CIA produced a fantastic book during the peak of World War 2 called Simple Sabotage. It laid out various ways for infiltrators to ruin productivity of a company. Some of the advice is timeless, for instance the section about “General interference with Organizations and Production”: Insist on doing everything through “channels”. Never permit short-cuts to be taken in order to expedite decisions. Make “speeches”. Talk as frequently as possible and at lengths. Illustrate your “points” by long anecdotes and accounts of personal experience. Never hesitate to make a few “patriotic” comments. When possible, refer all matters to committees for “further study and consideration”. Attempt to make committees as large as possible — never less than five. Bring up irrelevant issues as frequently as possible. Haggle over precise wordings of communications, minutes, resolutions. Refer back to matters decided upon at the last meeting and attempt to re-open the question of the advisability of that decision. Advicate “caution”. Be “reasonable” and urge your fellow conferees to be “reasonable” and avoid haste which might result in embarrassments or difficulties later on. Be worried about the propriety of any decision — raise the question of whether such action as is contemplated lies within the jurisdiction of the group or whether it might conflict with the policy of some higher echelon. I guess I've always been fascinated with how well this has stood the test of time? I even got this particular section framed and hung up at our office: Your mission Let's say you were employed as a CTO behind the front lines and you wanted to destroy productivity for as long as you can without getting caught. You can of course make a series of obviously bad decisions, but you'd get fired quickly. The real goal here is to sap the company of its productivity slowly, while maintaining a façade of plausibility and normalcy. What are some things you can do? Technology When joining, require a 6-18 months rewrite of core systems. Blame the previous CTO. Encourage everyone use their own language and frameworks. Split systems along arbitrary boundaries: maximize the number of systems involved in any feature. Encourage a complex dev setup: running a service mesh with a dozen services at a minimum. Make sure production environment differs from developer environments in as many ways as possible. Deploy as infrequently as possible. Urge extreme caution about deployments. Leverage any production issue as a reason to “pull the brakes”. Introduce very complex processes for code change and common workflows. Blame it on “security” or “compliance”. Make sure every task is tracked in a task tracker and has been reviewed, prioritized, and signed off by a group of at least five people. Disallow anything outside the scope of the original task, such as code cleanup or other drive-by improvements. Build in-house versions of almost anything that's not a core competency. Justify it by “avoiding vendor lock-in”. Insist on adding abstraction layers on top of everything. Use vendors that are themselves abstractions and then add extra layers of abstractions. Encourage technical decisions based on wildly optimistic expectations of scale. Plan for at least 3 orders of magnitude more load than you have. Encourage communal ownership of systems. Make sure no one feels responsible for maintenance. Insist on centralizing almost everything as a “platform” owned by the “platform team”. Understaff the platform team and prevent other teams from building anythings that the platform might “own”. Make the platform team iterate on APIs frequently and mandate that other teams refactor their code to the latest version as frequently as possible. Hire “architects” and require even small changes to have an “architecture review”. Require even small changes to have a “security review”. Product Dismiss useful metrics on academic grounds (e.g. “biased” or “lagging indicator”). Pick vanity metrics with little or no correlation with business value and high amount of noise. Insist on anything to be done as a “big bet” and insist on everything to be completely done before deployed. Consider every feature a “must-have” and critical part of “version zero”. Do not budge. Develop incredibly detailed “strategic” plans. Pivot frequently. Dismiss obvious improvements as “local optimization”. Use latest trends to tie up resources. Kickstart a vacuous “AI strategy” that seems plausible at the surface. Spend heavily on vendors and consultants for these. Encourage product managers to spend most of their time on “strategy” and “planning”. Make it hard/impossible for engineers and product manager to use the product internally. Dismiss users as “stupid” internally. Leadership Link compensation to title, and title to to team size, in order to incentivize bloat. Make big talk about strategies, features, or technical complexity. Make expensive acquisitions to enter new product areas. Refer to “synergies”. Shut down the acquired product. Use lots of dotted lines in the reporting structure. As much as possible, have people to report into managers in other teams, locations, or functions. Make sure managers are ill-equipped to supervise their reports. Frequently reassign underperformers to other teams. Put high performers on highly speculative R&D projects with unclear deliverables. Always require a meeting for any decision, no matter how trivial. Insist that every “stakeholder” needs to be present in the meeting. Hiring Create a hiring process that seems plausibly objective but in reality subjective. Reject the best people based on “poor culture fit” or other vague criteria. Hire the weakest candidates based on “potential” or “attitude” or other vague criteria. Recruit very expensive senior leaders with large headcount promises. Use inflated titles and made-up roles to attract opportunists. Hire highly specialized “experts”, then create contrived projects to prevent them from quitting. Use specialization as a justification to hire other, complementary people. Project management Require very detailed estimates for any project. Encourage projects that span as many teams as possible, ideally in different locations. Add new requirements that depend on work done by other teams. Frequently make use of expensive agencies. Make the scope ambigious and hand over unfinished prototypes on the in-house team for them to finish. Build complex “self-service” systems for stakeholders in other teams. This is from the 1994 music video Sabotage by Beastie Boys. The lyrics are mostly about technology leadership and developer productivity. The outcome It's a hard job to pull it off! But if you can parachute behind the enemy front lines, and land a job as a CTO, you can make this happen. For the non-saboteur: this is obviously a story about how to get the most out of your team. Productivity in general is a story of a thousand cuts, and none of these things are in themselves the thing that will ruin the productivity. But productivity adds up on a logarithmic scale, meaning that all these things compound in a multiplicative way. Basically, do 100 things that each is a 5% tax on productivity, and you just slowed everything down by 131x! The only way to keep engineers happy is to say no to 100 minor cuts that each sound plausible and specious. Tagged with: management, software",
    "commentLink": "https://news.ycombinator.com/item?id=40695839",
    "commentBody": "Simple sabotage for software (2023) (erikbern.com)187 points by adammiribyan 11 hours agohidepastfavorite46 comments roenxi 9 hours agoThe major thing that springs to mind here is I've never seen a compelling reason to believe that the original CIA suggestions actually worked. In my experience workers like that exist naturally and organisations are great at just sidelining them. I think in that section the CIA was just writing a listicle that sounded good [0]. The way to cripple a company is to get bad people promoted into management and have them optimise something plausible but not profitable. Like what happened in a lot of slow-fail engineering companies - insist on maximising the profit metric to the point where the actual product becomes compromised. That strategy can be intiated from almost anywhere in management too because a constant \"what if we optimise for profit\" [1] usually does well at meetings. Being a destructive CTO is almost too easy. Just don't do anything much, weed out any competent people in the level below you and develop a culture of pushing blame aaaaalllllllll the way down the org chart, ideally out of the technical part of the tree, so that nothing broken gets fixed. When people catch on, allow blame to move 1 level up the org chart and do a big shakeup to clear out any institutional knowledge that might have built up in spite of you. That game can go on for years. [0] I've seen people where \"do things through official channels\" and \"demand written orders\" would have made them more productive. We are our own worst enemies. [1] Yes, the irony here is that naive optimising for profit is typically not profitable. reply krisoft 8 hours agoparent> I've never seen a compelling reason to believe that the original CIA suggestions actually worked. Let’s set asside the fact that the document wasn’t written by the CIA. The purported goal of this document was to provide practicaly applicable advice to the regular citizen who found themselves under enemy occupation. Most concretely to be given to the French people who did not like the German occupation. You are talking about the strategy “working” or “not working” as if these are binary things. The goal here was not that these simple steps will bring Germany to their knees but to increase the cost of the occupation. To cause enough deniable friction which bogs down the resources and make everything just a bit more inefficient. > In my experience workers like that exist naturally They do. And that is the point. That is what makes these strategies deniable. > and organisations are great at just sidelining them If that is your experience I would love to work where you worked. In my experience when someone is following this strategy sidelining only happens slowly and at great costs. One of the many costs is people comitting avoidable blunders when they dismiss real and well reasoned objections in their haste to cut through a sea of useless ones. > to get bad people promoted into management Sure. But that takes time. You are thinking on a different time scale than the authors of this document were thinking about. The document was published in Jan 1944. The Normandy landings happened in June the same year and by the end of the next year the war was won. You don’t have time to slowly promote bad people into management. If a dude who read your booklet bumbles about a bit and delays the repair of a train line by days that is a win in this context. Nobody expected that Germany is going to collapse on their own just because enough people sabotage meetings and plug up toilets. (That is by the way also a suggestion from the manual 5.1.b.2. Somewhat less often cited than the points applicable to office work.) reply _djo_ 2 hours agorootparent> Let’s set asside the fact that the document wasn’t written by the CIA. What do you mean? The CIA has publicly stated that the document was written by the OSS, its wartime predecessor. [0] [0] https://www.cia.gov/stories/story/the-art-of-simple-sabotage... reply fuzzfactor 6 hours agorootparentprev>>workers like that exist naturally Ones whose only significant effort (if any) is to be a mainstream employee in all other ways since nothing will ever make them productive or capable of efficient operation. >> and organisations are great at just sidelining them >If that is your experience I would love to work where you worked. Me too. That does seem like uncommon good fortune. Too often these are the ones that get promoted into higher levels of mangement, it is so widespread among different companies it goes undetected in the way the CIA intended. Plausibility beats productivity. reply oldgradstudent 7 hours agoparentprevYou can do far far worse than naive optimizing for profit. Optimizing for *REPORTED* profit. People learn very quickly to manipulate the reporting, modeling, and accounting. Just less than two decades ago we had the entire financial system lending massive amounts of money to the worst possible borrowers and REPORTING massive profits. reply jt2190 8 hours agoparentprevRefer to the section “(11)(b) Managers and Supervisors” https://www.cia.gov/static/5c875f3ec660e092cf893f60b4a288df/... reply stavros 2 hours agoparentprevThey do work, we had a director who did all that in a previous company (probably unintentionally), and things ground to a halt and productivity fell to zero. reply mattacular 2 hours agoparentprev> [1] Yes, the irony here is that naive optimising for profit is typically not profitable. Yes but only over a relatively long time period, which the overarching system itself is not incentivizing anyone to look at too carefully. reply hobs 8 hours agoparentprevOh yeah, this one really is fun. We used to joke that the CTO of one of the companies I worked for made a killing as his second job was for our competitors. Turns out the dude has been doing that for about 15 years between various places and now is about to retire, blameless in the eyes of everyone who doesn't understand what happened. reply andrei_says_ 3 hours agorootparentDoing what? Getting paid by a competitor to destroy his current company? reply hobs 3 hours agorootparentNo, being incompetent to the point where if you squinted he might as well be. reply patrakov 4 hours agoprevThe manual misses the most important step: getting rid of people who have even the slightest idea of how the product as a whole should work and/or a coherent vision of a better future. The word \"vision\" is not even present in the text. Visioners are the ones who can sabotage the saboteurs. reply krisoft 8 hours agoprev> CIA produced a fantastic book during the peak of World War 2 called Simple Sabotage. Not quite right. The Office of Strategic Services did that. The CIA was created only in 1947 several years after the end of the second World War in 1945. reply llm_trw 4 hours agoparent> 4. Bring up irrelevant issues as frequently as possible. Excellent. Continue the good work. reply 01HNNWZ0MV43FF 3 hours agorootparentLet's keep talking about this. How is two years \"several\"? That's \"a couple\" literally and maybe \"a few\" reply 082349872349872 2 hours agorootparentprevSo while we're here: anyone know if Sonia Brownell ever worked with PWE before working with IRD? (or have suggestions as to where to look for this sort of thing?) reply throwawayqqq11 1 hour agorootparentprevSorry, but i have to flag your comment. 1) dang has to decide whether this is too snarky or not. 2) Please stay on topic, its about CIA or not. 3) Its hardly \"frequently bringing up irrelevant issues\". Have i missed something? reply hinkley 4 hours agoparentprevThe head of the OSS also founded the CIA, so is it really that big of a stretch? reply KronisLV 6 hours agoprev> Make sure production environment differs from developer environments in as many ways as possible. I feel like this, in some capacity, is borderline inevitable in the modern architectures with a bunch of external services, or at the very least will 100% require that your devs are connected to the Internet all the time to be able to do anything, vs systems that are 100% self hostable. Or even just running a complex Kubernetes cluster with a service mesh and other solutions on the test/staging/prod infra vs loosely mapping to more lightweight options locally, unless you have a super beefy setup. And even then, if everything is split into multiple separate services far enough, you just won't be able to run everything locally, meaning that you need to use some of the components from shared dev environments which will inevitably lead to stepping on each other's heels. Once you go past something like Docker Compose for local environments, things can go sour. reply hinkley 4 hours agoparentI used nginx as a forward proxy a couple times before Docker was a thing. Poor man’s service mesh still has some utility. reply teddyh 4 hours agoparentprevIm some ways, this is an unsolvable problem, due to entropy. You can’t even step into the same river twice. reply penguin_booze 7 hours agoprevThe 'Hiring' section needs an update: ask Leetcode hard-level problems, and demand to witness enlightenment and an optimized solution in under 30 minutes. Uncertainty and doubt shall not be tolerated. reply ohyes 9 hours agoprevThis is interesting because a lot of the decisions to “sabotage” are about convincing people to attempt to cover their own asses. I think in that light, number 1 is to foster an atmosphere of fear where anyone attempting to make things better will be confronted if things don’t go perfectly. reply btbuildem 4 hours agoprevThe eight rules laid out in the beginning of the article are strictly followed, almost word-for-word, at my workplace. Not ironically, not for sabotage reasons, but legitimately as \"best practices\". It's a miracle that somehow the company remains in business. reply misswaterfairy 9 hours agoprevI've noticed a lot of consultants I've worked with over the years do most, if not all, of these things. reply pcloadletter_ 6 hours agoprevI left Microsoft a year ago because the group I worked for checked pretty much every one of the items on this list. It was wildly unproductive. reply xjay 6 hours agoprevIn a web context, I was thinking this when I checked out the web site of the Electronic Frontier Foundation (EFF) [1]; why would they use a thin, small typeface with light gray color on a bright/white background which makes the text less appealing to read? It must be subtle sabotage from within! (Some may counter this with Hanlon's razor [2]; Never attribute to malice that which is adequately explained by stupidity.) [1] https://www.eff.org/ [2] https://en.wikipedia.org/wiki/Hanlon's_razor reply wgx 2 hours agoparentI find the EFF site perfectly readable. Not sure what you’re experiencing but it looks fine to me. reply thenthenthen 2 hours agoprevI recall the original OSS included some more hands-on techniques, like throwing your files (the ones you grind with) into the drawer instead of laying them down carefully. I wonder what the equivalent in software dev. would be. Throw files into folders with a lot of force? Ddos? The legitimacy of this document has been questioned, but it is surely food for thought. And don’t call me Cherly reply thenthenthen 2 hours agoparent(A pegboard or tool block could have easily mitigated any wrong handling of the tools?) reply kstrauser 4 hours agoprevPhoto caption: > This is from the 1994 music video Sabotage by Beastie Boys. The lyrics are mostly about technology leadership and developer productivity. That caught me off guard. Well done. reply red_admiral 4 hours agoprevSo cloud-based microservices for everything, then? reply photonthug 6 hours agoprevAll this is so normalized these days that many of the items on this list are referred to with reverence as best practice. Plus calling these things \"sabotage\" isn't right even as a metaphor, and IMO confuses the issue. These people aren't on a third-party payroll, they are just self-serving. No one is creeping into your office in the middle of the night. You invited them over, let them in, watched them piss in the fish tank, and then gave them a promotion and a raise. Now you're surprised everyone is lining up to fuck up the place? As usual the value judgements are just a distraction in matters of economics, look at the incentives. reply eganist 6 hours agoprevIt's cute, but in quite a few industries, a lot of these are driven by outside e.g regulatory forces that have proven to be necessary (\"written in blood\" etc), so the better question to ask is how many of these process encumberments can be streamlined e.g with paved road approaches. Security and compliance benefit heavily from this approach, and I'm sure it can be extended elsewhere as well (architecture reviews etc). reply coopykins 4 hours agoprevThat list of sabotaged software development reminds me of my time at Oracle reply desio 7 hours agoprevClever framing of the authors own biases. I'd argue that for at least some of these, the opposite behaviour would be the true sabotage. reply ohyes 6 hours agoparentLet’s make a committee to discuss! we need all the key players involved, so let’s invite all of dev and QA, ~60 people for an hour long discussion? reply mike_hock 3 hours agoparentprevIn fact, a sabotage manual should include the opposite action for each point. These are not the methods of sabotage, they're the methods of shrouding your sabotage in plausibility. It wouldn't provide you plausible deniability if doing the things on the list was never reasonable. reply quantum_state 9 hours agoprevVery humorous … ironically, it’s happening in many companies… reply doytch 5 hours agoprev> Build complex “self-service” systems for stakeholders in other teams. Is the sabotaging bit here the \"complex\" part? reply julik 6 hours agoprevAbout 60% of that list checks out for a place I worked at. reply lelanthran 4 hours agoprevSome of these conflict: > Encourage a complex dev setup: running a service mesh with a dozen services at a minimum. ... > Build in-house versions of almost anything that's not a core competency. So if you need functionality A, B, C ... H, what do you do? Do you build them all in-house or do you have 9 different services each providing the functionality required? reply isidor3 4 hours agoparentYou build 9 different services in-house, obviously. reply davidgerard 7 hours agoprevMandatory RTO, tech teams first. reply chrisandchris 9 hours agoprev [–] Duplicate (15d) https://news.ycombinator.com/item?id=40538920 and (5m) https://news.ycombinator.com/item?id=38707591 reply behnamoh 3 hours agoparent [–] @dang maybe merge the threads? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The CIA's \"Simple Sabotage\" book from World War 2 provides timeless advice on disrupting productivity, now humorously adapted for modern tech environments.",
      "Suggested sabotage techniques for a CTO include requiring lengthy rewrites, encouraging diverse languages, and splitting systems to increase complexity.",
      "Other methods include dismissing useful metrics, linking compensation to title and team size, and creating a subjective hiring process, all aimed at subtly slowing down productivity through plausible actions."
    ],
    "commentSummary": [
      "A discussion on simple sabotage in software, referencing a 2023 article by Erik Bernhardsson, questions the effectiveness of original CIA sabotage tactics.",
      "Commenters debate the practicality and impact of these strategies, noting that bad management and misguided profit optimization can naturally cripple organizations.",
      "The conversation includes historical context, the role of incompetence, and modern practices like complex self-service systems and mandatory return-to-office policies that may inadvertently align with sabotage principles."
    ],
    "points": 187,
    "commentCount": 46,
    "retryCount": 0,
    "time": 1718530792
  },
  {
    "id": 40695754,
    "title": "European Alternatives",
    "originLink": "https://european-alternatives.eu",
    "originBody": "Sponsored Find out which cloud provider hosts any website Find out which cloud provider hosts any website Learn more European alternatives for digital products We help you find European alternatives for digital service and products, like cloud services and SaaS products. Support local businesses When you buy from local businesses, you are supporting yourself down the road. Taxes paid by the company come back to you indirectly and the company creates jobs in your region. Data protection / GDPR Some companies outside Europe tend to ignore data protection and related laws such as the GDPR or do not implement them correctly. VAT / Billing As a business that operates in Europe, it is possible to get a VAT refund for products/services of other European companies. European companies also tend to offer payment methods that are commonly used in Europe. Similar legal requirements Within the EU, many laws and framework conditions are set by the EU, which helps to cover a large market without having to consider large country-specific differences. It is also easier to enforce your rights against another company located in the EU. Categories Web analytics services A web analytics service tracks user behavior on websites so that website owners can understand user usage and optimize their websites. 31 alternatives Cloud computing platforms A cloud computing platform provides on-demand hosting services. 12 alternatives Content delivery network (CDN) services A content delivery network (CDN) is a geographically distributed network. 7 alternatives Email providers An email provider provides its users with an e-mail address and the corresponding mailboxes. 20 alternatives Virtual private server (VPS) hosters A virtual private server (VPS) hoster provides virtual servers with predefined RAM, storage, traffic and virtual cores. 23 alternatives Search engines A search engine allows their users to search the internet. 6 alternatives Transactional email service A transactional mail service offers users the ability to send emails from their applications via the service. 5 alternatives Domain name registrars Domain name registrars are companies that manages the reservation of Internet domain names. 12 alternatives Navigation apps Navigation apps help you get from A to B. 9 alternatives Microblogging services A microblogging service allows users to post short texts, images or links to videos. 2 alternatives Uptime monitoring services An uptime monitoring service periodically checks if a website or other service is active. 8 alternatives File hosting services With a file hosting service, users can upload files to back them up or share them with others. 9 alternatives Machine translation services A machine translation service (translator) is a service that programmatically translates text from one language to another. 5 alternatives Professional networking platforms A professional networking platform is a social network focused on business relationships. 1 alternatives Object storage providers Object storage providers allow their users to store files hierarchically. 10 alternatives See all Any suggestions? Use the chat in the right bottom corner",
    "commentLink": "https://news.ycombinator.com/item?id=40695754",
    "commentBody": "European Alternatives (european-alternatives.eu)182 points by lijunhao 11 hours agohidepastfavorite84 comments lijunhao 11 hours agohttps://european-alternatives.eu/about --- Conditions for a listing All the products and services listed on European Alternatives meet the following criteria: The company is based in an EU, EEA, EFTA, or DCFTA member country. If the company has a parent or holding company, this company is also based in an EU, EEA, EFTA, or DCFTA member state. For hosting providers: It is not allowed that a hosting provider is simply a sub-hosting provider of a company that is not based in an EU or EFTA member country. Example: Hosting provider that just configures servers on AWS. reply radicalbyte 10 hours agoparentWhy? For the US - The Cloud Act: https://en.wikipedia.org/wiki/CLOUD_Act For China - the law is whatever they want it to be. reply byyll 10 hours agorootparentBecause they have a website and they make the rules, it's not a law. The west Balkans and Belarus are also part of Europe but in none of the unions, associations, etc. mentioned so the domain is misleading too. It's not european, it's \"those unions we like\". reply ffsm8 8 hours agorootparentprevEver heard of prism? reply matt-p 8 hours agorootparentOh yeah and countries like Germany weren't a part of that at all reply brabel 9 hours agoparentprevWhy is Keycloak in this list? https://european-alternatives.eu/category/identity-and-acces... The listing itself says it's an American company's product (RedHat). reply p_l 9 hours agorootparentNote it's in subcategory of \"self-hosted\". Lots of places use it completely self-hosted or even offer EU-hosted keycloak for clients as SaaS. reply KronisLV 9 hours agoprevI wonder if Rackray https://www.rackray.com/ or Time4VPS https://www.time4vps.com/ would qualify under the VPS provider category (they're in Lithuania). I've been using Time4VPS for a few years at this point, they've always been pretty decent. That said, they have been gradually rising prices and I think that something like Hetzner is more affordable at this point. Well, either that or Contabo for the cases where I just need a box that has enough RAM and don't do anything super CPU intensive. Scaleway also used to be competitive with them price-wise, but I don't think that's been the case for a while, it'd have to be more of a feature based comparison. I think there's a bunch of smaller companies in the Baltics as well, but maybe that'd make the list quite long and many of them seem to focus on local services mostly (nano.lv for hosting comes to mind). Either way, really cool site, I'm glad that this exists! reply OldOneEye 9 hours agoprevI can only speak positively of Hetzner. I particularly like that they have a Terraform provider. I've only used them for personal projects, though, so I can't say anything to the suitability in a corporate environment. In particular their support. That's quite an important factor when working in a corporate setting. I wish they already had that S3-like service they've announced for some time. It would be really handy. reply number6 9 hours agoparentThey have an outstanding professional support with in depth Linux knowledge and provide help, even if it is out of scope e.g. failed distro updates on a vps reply lijunhao 11 hours agoprevA list of search engines I haven't known before: https://european-alternatives.eu/category/search-engines reply ricardo81 9 hours agoparentPresumably because of Brexit, Mojeek is not listed. Is sort-of-interesting how some European lists include/exclude the UK. https://www.mojeek.com/ One of the largest Western world indexes outside of Bing/Google, own crawler/ranking and privacy friendly. reply mike_hearn 3 hours agorootparentRedefining Europe to mean something other than the geographical location is a very bad habit of the pro-EU contingent. The EU institutions do this all the time but they aren't the only offenders, which is how Eurovision ends up including Australia and Israel. These people seem to really hate that Europe is a geographically defined landmass (which includes Russia), and would much rather it be a social construct reflecting a specific set of cultural values. But I guess \"EU/EFTA Alternatives\" is not as snappy. reply toni 9 hours agoparentprevStartpage is owned by an American advertising company (System1) https://old.reddit.com/r/privacy/comments/di5rn3/startpage_i... reply timeon 10 hours agoparentprevSeems like mostly Bing-based. reply usrnm 9 hours agorootparentThe only search engine with its own index in Europe (not EU) is Yandex. There is a lot of controversy around it for obvious reasons, but at least it exists reply ricardo81 8 hours agorootparentNot true, there's Mojeek. reply matt-p 8 hours agoparentprevAll of these are bing based and/or have US parent Cos. So how exactly are they \"European\"? A European company put a react UI ontop of the bing API - seriously? Meanwhile the UK has at least one serious option (e.g https://mojeek.com) with it's own index, possibly larger than yandex and privacy friendly - but can't be included because we're not in the right protectionist club. Well guys, I hope this works for you. I voted against Brexit, but the behaviour of folks on the continent since has been beyond childish and has been making me reconsider the whole EU concept. reply bblommers 8 hours agorootparentFrom the homepage: > As a business that operates in Europe, it is possible to get a VAT refund for products/services of other European companies. > European companies also tend to offer payment methods that are commonly used in Europe. > Within the EU, many laws and framework conditions are set by the EU, which helps to cover a large market without having to consider large country-specific differences. > It is also easier to enforce your rights against another company located in the EU. That sounds to me like there are plenty legitimate reasons to exclude the UK from a European (Union)-based list. They do seem to conflate Europe with the EU, which is unfortunate. reply matt-p 8 hours agorootparentUK meets all of these points too FYI :). VAT is not paid/or refunded, we use the same payment methods and many will even accept euros if push comes to shove. GDPR is enshrined in law, we have an EU trade and co-op agreement. reply p3rls 7 hours agorootparentprevI just tried Mojeek and it's is probably the worst engine I've ever used. My first query I went with something standard out of my niche, \"minju kpop\" and #1 result was deepfake porn. The subsequent searches in other niches didn't do much better. I mean, say what you want about the tenets of Google and pagerank, dude. At least it's not deepfake porn. reply mike_hearn 2 hours agorootparentThe problem is not their ranking but that by default SafeSearch is off on Mojeek. This is a questionable choice. Click the cog, enable SafeSearch and repeat the query. The deepfake porn is gone. I just tried Mojeek too, and found the results to be reasonable on a selection of programming related queries. I didn't know Mojeek existed, but the design is clean and the results are fast. Ranking isn't as precise as Google but that's OK, the right result is usually still in the top results. The summarize feature worked well and was also very fast. The news is clean, hopefully more trustworthy than Google News. I love the idea of their Substack search, but they should consider unlaunching it and trying again. Although the rendering of the results is a bit off (the date runs into the URL) the bigger issue is that there doesn't seem to be any way to rank by date, and old blog posts are often near the top. That's probably not what's wanted for a blog search. Honestly I don't know why this site isn't better known, if it's genuinely an independent index which it seems to be. It feels like Google in the early days. I'll definitely try it out and see how viable its ranking is. It's really sad (but absolutely 100% predictable) to hear that self-proclaimed \"Europeans\" refuse to mention it. To such people \"Europe\" is not and never has been about regional alliances or collaboration. It is and was always a social ideology of control. The UK rejected that system and is thus in their minds no longer \"European\", despite that it's still there and not going anywhere. reply ricardo81 6 hours agorootparentprevI hope you can appreciate that Mojeek is a startup vs the trillion dollar valuations of Bing and Google. Vanity queries are pretty common for trying new engines. It's also not a very intuitive query. Maybe you're conditioned to using Google and their vast history of query data that no one else has. reply pseudalopex 4 hours agorootparent> Vanity queries are pretty common for trying new engines. Your point was what? > It's also not a very intuitive query. Maybe you're conditioned to using Google and their vast history of query data that no one else has. What would have been an intuitive query? reply ricardo81 4 hours agorootparentMy point was that vanity queries often look for very specific things, and beyond Google and Bing you're struggling to get that. That's the current reality. Maybe ask yourself why. It's not an intuitive query because it yields about precisely zero results with those two words in a consecutive manner, on Google. You're chucking two spaghetti words together and expecting the search engine to figure out what you mean, which is fine to an extent but OTOH, wth do you mean? reply timeon 8 hours agorootparentprevDid they refuse your proposal or is your attitude based only on fact that you have expected it to be there from start? > protectionist club > beyond childish Seems like you have already made your mind. reply matt-p 8 hours agorootparentThey refused. It's honestly unfortunate and I desperately wish it wasn't true, but this is actually how it is. reply nunodonato 11 hours agoprevFunny, couldnt find Hetzner in there reply lijunhao 11 hours agoparenthttps://european-alternatives.eu/product/hetzner reply Simon_ORourke 9 hours agoparentprevGood, I still have flashbacks to their awful cloud server uptime from a few years back. Every single hot summer afternoon when the temperature would hit 95 or 100 their servers would just mysteriously go offline. This was in Berlin btw, and I think their data center was somewhere not too far away in Germany. reply tasuki 7 hours agorootparentTo be fair I wouldn't expect the temperature to ever hit 95 or 100 in Berlin. That's either in a sauna or American funny units. reply manuelmoreale 8 hours agorootparentprevDefinitely not my experience. Have a bunch of VPS for personal and client stuff and never had a single issue so far. reply karmakaze 5 hours agoprevThese all appear to be hosting-type services. Is there a similar list that's more consumer-oriented? Or are there zero alternative social network platforms? reply nalekberov 10 hours agoprevmy two cents: Avoid using Tuta, I am talking as a person with more than 4 years experience using their product. Its search extremely bad, UI is so simple and everything is unnecessarily big, not event possibility to add any label. They barely improved their product within my >4 years of usage. I have already migrated most stuff to another mail provider. reply nutrie 5 hours agoparent> They barely improved their product within my >4 years of usage. Same with mailbox.org, having had my (paid) account with them for over 4 yrs since I went sans-Google, it was mostly a terrible experience. I recently tried Proton and they just kept flooding the inbox with conversion reminders, which I absolutely hate. Which different provider did you go with? reply nalekberov 4 hours agorootparent> Which different provider did you go with? I actually fell back to Gmail for the time being - I just don't like to \"advertise\" any Google product for known reasons, even though Gmail is a quite solid product, sorry about the confusion - but that's my temporary solution. I am planning to either give Migadu a try or host my own mail provider. (I have seen some good feedback about https://mailcow.email) reply nutrie 2 hours agorootparentYep, it's still hard to beat Gmail as a product. I had been with them since beta, I think it was by invite only back then. Time flies. I'm giving iCloud a try, even though it's rather painful on non-Apple systems. reply xigoi 1 hour agoparentprevAnd most importantly, they don’t support third-party clients. reply nalekberov 1 hour agorootparentYes, they are actually quite \"allergic\" to anything \"non-Tuta\". reply matt-p 3 hours agoparentprevIt's honestly so embarrassing that they are a 'top 5' for commercial email service made in Europe. Proton mail is 'getting there' and I think the best we collectively have to offer but let's be honest, it's not patch on Gmail,O365, iCloud, Zoho or one of the plethora of other services that hail from the US. A damming state of affairs. reply throwaway77384 9 hours agoparentprevI don't know if they are listed on the EU alternatives website, but for mail, I find Migadu to be excellent. I think they are Swiss. reply lnxg33k1 9 hours agoprevAvoid to sympathize for companies based on non-competitive parameters, they aren't your friends or do anything for you regardless of where they are, don't choose them for reasons like \"Oh they pay taxes where you are so it will come back\", chances are, they're not even paying taxes reply ivan_gammel 9 hours agoparentCompliance with EU regulations is an important parameter for many EU CTOs, so this can be indeed a useful project. reply lnxg33k1 9 hours agorootparentCompanies from everywhere selling on EU territories already have to be compliant with EU regulations, so EU CTOs maybe need to learn something about import/export reply ivan_gammel 7 hours agorootparentHave to be compliant != compliant, and there are multiple reasons for that. 1. An American company without any EU representation is still happy to sell the product to anyone who can pay them regardless of location. They may or even will do the bare minimum to have compliance on paper, but that is often not enough for legal team/DPOs. If you are big enough customer you may push them to complete the checklist, but in the end see 2. 2. An American company with significant business in EU will do everything to be compliant, but they cannot overcome limitations of American laws and thus will never be compliant unless there will be a solution not leading to Schrems III/IV etc. A few of them are very creative and actually find such solution (see e.g. AWS CloudHSM), but most of them don’t have resources or technical possibilities to build such things. reply matt-p 8 hours agorootparentprevYeah literally. Law and standard contracts provide for this already, this is just pure \"one of us, one of us\" protectionism reply lnxg33k1 5 hours agorootparentEU companies are the worst, I am from EU, born and raised. They say \"The workforce needs to be flexible and competitive with people from all over the world\" but then when they have to sell they break balls with the \"We're an EU company\", hell to them, I am going to pick the most competitive for me regardless of where they are reply ivan_gammel 7 hours agorootparentprev> Law and standard contracts provide for this already I don’t think you really understand what are you talking about. https://www.europarl.europa.eu/RegData/etudes/ATAG/2020/6520... When US and EU laws are in conflict, a business can be compliant only with one of them. reply matt-p 6 hours agorootparentFair enough, I was coming from a UK standpoint which has a trade agreement and GDPR in law. reply ivan_gammel 5 hours agorootparentUK is kind of special. On paper, yes, there’s GDPR. In fact the most annoying people on this planet are UK recruiters using American data mining services. To the point where I have now a mental block for UK country code on business matters. Would I trust my data to an UK business? I‘m not sure. reply matt-p 4 hours agorootparentIt's exactly the same GDPR that every country in the EU has. That recruitment practice sounds like it could be a breach, I would go ahead and submit a SAR just to put the frighteners on them to be honest. reply matt-p 9 hours agoprevIt seems incredibly petty to me to exclude UK companies from this list. We left, yeah ok. But this says European alternatives and we're in Europe as far as I'm aware.GDPR is enshrined in law and we've a EU-UK Trade and Cooperation Agreement. You're missing out on a massive plethora of services, London's tech industry is one of if not the strongest in Europe. reply p_l 9 hours agoparentFor legal purposes, including GDPR [1], UK is a \"third country\". Trade agreements do not change that - those that do, are listed on the site. [1] It currently has GDPR included in law, but there's nothing keeping it in law. reply matt-p 9 hours agorootparentGenuinely I'd love to understand why this is an issue. This can trivially be solved contractually, indeed any UK tech company will have it in thier standard contract since they encounter it so often. reply p_l 8 hours agorootparentNational law trumps corporate contracts, that's essentially the core of it. Similarly, GDPR gave teeth to pre-existing privacy laws in EU. Private contracts are nowhere near as enforceable, especially in terms of consequences - but the EU side of the contract will still be on the hook for legal consequences if UK company fails to uphold their side, or if UK changes a law that makes it incompatible with GDPR requirements (as in with US CLOUD act and the like). reply matt-p 6 hours agorootparentYes, but a contract is under a country's law (which may or may not inherit some or all EU 'law'). For example a Portuguese company selling a service to a German one will be under Portuguese jurisdiction. Portugal \"could\" decide to unilaterally leave the EU and therefore GDPR tomorrow. But that's insanely unlikely. UK \"could\" decide to remove GDPR tomorrow. But that's just as unlikely. Tell me the difference between these two? Realistically a B2B contract should draw in as first party terms that all the relevant protections will be provided, confirm in compliance with GDPR (which UK has in law) if the UK removes it the protections still apply. That's more on security than just agreeing a contract with portugese supplier because 'they`re in the EU too' reply p_l 6 hours agorootparent> Realistically a B2B contract should draw in as first party terms that all the relevant protections will be provided, confirm in compliance with GDPR (which UK has in law) if the UK removes it the protections still apply. The moment UK makes a legal change that overrides those protections, you're left with worthless words on paper. And the point of GDPR status as \"EU Regulation\" is that it's not exactly feasible for EU members to override it like that. And leaving EU isn't instant thing. reply matt-p 3 hours agorootparentNo, I don't agree with that, they're first party terms so the only law that would impact it is if the UK said \"you MUST NOT protect users privacy or you'll go to jail\" that won't happen. They would only revoke default protection, which doesn't matter as the protection is expressly contractual. Passing, revoking or changing a UK law is not an instant thing either, trust me. So the only difference in those scenarios are that Portugal leaving the EU would take a bit longer than the UK removing a law from the statutes? So essentially there's no difference whatsoever? reply p_l 2 hours agorootparentNo, the idea is that UK might pass a law that overrides the mandatory protections, just like US CLOUD Act. So it's not even a theoretical issue, it's a well-trodden path from attempts at trade-deal guaranteeing things with USA. reply matt-p 6 hours agorootparentprevAlso you would of thought the EU would of accepted the UKs request of bringing GDPR into scope of the trade agreement and therefore not making it a third country (which is insane as the UK has the exact same GDPR in Law with no intention of removing it, we could of codified that the UK would keep it inline with the EUs version and forgo/have to renegotiate it's trade deal if it removes it). reply p_l 6 hours agorootparentYou can't escape \"third country\" status with a trade deal, though. As in, this is base EU law. At best, you could get some agreement which would be accepted to treat UK as acceptable party for GDPR-conscious business, but you're still a third party, and navigating patchwork agreements is why some companies will want to deal with company completely in EU instead. reply matt-p 3 hours agorootparentWho says? The EU. There are other statuses that exist like EFTA and so on that don't have this issue, there's no reason at all why this couldn't be agreed (except that the EU haven't the incentive to make this work, quite the opposite). reply p_l 2 hours agorootparent\"Third country\" is a term of EU law in this case, and refers to one country's status with regards to EU law - including how entities in EU can deal with them. reply scrollaway 9 hours agoparentprevTrade agreements only get you so far.. The UK is also a member of five eyes, among other things, which is one of the reasons why someone might be seeking a “European alternative”. reply matt-p 9 hours agorootparentGermany has 81 large US military bases, Italy has 26, UK has 14. Sorry but if you think your internet traffic isn't being tapped by the US regardless you're completely delusional. At least in the UK were probably not letting EU countries tap it too :') reply kkfx 7 hours agoprevI have an European alternative, my own iron in my own home, it's European since I'm an EU citizen living in the EU... The alternative to the modern computing is the classic iron ownership instead of living on the shoulder of giants, otherwise there is no difference between a US company and an EU one selling the same services. They are both third party whose job is making money for their shareholders. \"But.... HW cost money!\", yes, because someone else computers are notoriously free... https://tech.ahrefs.com/how-ahrefs-gets-a-billion-dollar-wor... and of course owned hw is not a asset with an eventual resale value and a vast series of possibilities if a startup idea fail... Oh, yes, bandwidth might be tricky but co-location until a company is large enough to pay a personal proper link it's still an option, on their own hw. Dear devs startuppers where the recliner is the most valuable owned asset you have, it's about time to recalculate your economy....... reply rand1239 10 hours agoprevIn GitHub alternatives it shows https://gitlabhost.com/. Does anyone knows how copyright works when a different company uses GitLab name and offers competitive hosting to GitLab itself? reply Macha 9 hours agoparentTrademarks, not copyright would be the issue here. This is a clear use of the Gitlab trademark, which gives two options for being permitted to use it: 1. An agreement with Gitlab themselves. Gitlab's own published trademark guidelines do not allow its use within a business name, but this company claims to be in a partner program with Gitlab, so they may have worked on the side. (This is also how Gitlab/Github were grandfathered in for their use of the Git trademark) 2. Descriptive use. This is what allows e.g. \"Bob's Kia Repairs\". The laws on this vary a lot from jurisdiction to jurisdiction and usually e.g. consider how likely it is to be confused with the trademarked business. I think gitlabhost would fail that test as you can see people thinking it is an offer from Gitlab themselves. And in general because of the non-uniformity of rules, you probably want to avoid relying on them for anything not inherently limited to a single jurisdiction. reply kennethwolters 9 hours agoparentprevThis actually looks great. More choices in terms of GitLab hosting pricing models. reply wakaru44 9 hours agoparentprevas far as I Know they are doing nothing wrong and work in partnership with gitlab. They have a program for this. Check the gitlab wiki. reply eastbound 11 hours agoprev [15 more] [flagged] TwentyPosts 10 hours agoparent> Proton is clearly a front for the CIA Do you have any evidence to back that up? reply wil421 10 hours agorootparentHush mail and similar providers were supposed to be the go to private email back in the day. Turns out the FBI was running the servers for who knows how long. I’ve had similar concerns about proton, looks like I’m not the only one. https://www.wired.com/2007/11/encrypted-e-mai/ reply g15jv2dp 10 hours agorootparentThe article you linked is about Hushmail. Nothing about Protonmail. reply bbarnett 9 hours agorootparentprevI don't know if he does, but I vouched for this flagged thread, as this is a Hacker site, and such allegations should be met or discussed at least. reply christophilus 10 hours agoparentprevDoes it matter if it’s a front for the CIA? I assume the big governments can reach me. What I don’t want to participate in is giving more data to Google. reply stoperaticless 10 hours agorootparentWell, I don’t want anybody to get access to my emails. I understand that if they would spend any effort they could easily get access (via breaking my phone or bones), but I don’t want to voluntarily send over my emails. (Happy proton subbcriber; that would change if those allegations would appear true) reply phh 10 hours agoparentprev> EU keeps people poor. They keep people so poor that Americans need to hire European people for the high-end AI researchers, because EU still has the best education, despite having probably ten times less money. (Unless you consider being \"poor\" is exclusively about money and not quality of life, enlightenment and improvements to the society. In this case I'm happy to be poor but have all of those) reply rafaelmn 10 hours agorootparentI mean it's to his point that US companies are willing to pay for top talent unlike EU. reply sofixa 10 hours agorootparentEU companies are willing to pay for top talent too, it's just that the amounts they can afford to pay are smaller than US companies, for a variety of reasons. reply OKRainbowKid 10 hours agoparentprev [–] > the EU keeps people poor. Please elaborate, that's a wild claim. reply AnthonyMouse 9 hours agorootparent [–] The general premise is that they favor large institutions over small businesses, e.g. by having more and more complicated rules that require more overhead to comply with. As a result people are less able to start their own business, which is one of the major checks on the need for large employers to pay higher wages (competition for labor) or charge lower prices (competition for customers). High levels of government assistance also tend to create poverty traps, because paying net benefits to high earning people is uneconomical but avoiding this when the base level of benefits is higher requires higher benefit phase out rates, which is equivalent to a higher marginal tax rate, in addition to the higher formal tax rates to pay for the benefits. The result is less incentive for individuals to try their hand at entrepreneurship, because the higher risk is still there (you could still go several years without making any money) but the higher reward is blunted. reply p_l 9 hours agorootparent [–] The reality is more that USA built up VC and the like by having lots of capital (often government capital - Silicon Valley, Boston route 128, etc being built heavily on military funding), ridiculous demand (only western industrial country that didn't have its industry heavily damaged), lots of workforce (returning soldiers, considerably low losses). Hell, Marshall Plan essentially fueled demand for american goods, because funds provided in US Dollars pretty much translated to purchasing things that could be sold for USD. The network effects were huge and paved the way for dot com boom and later cycles, especially with zero interest rates combined with huge 401k funds looking for any return. reply scrollaway 9 hours agorootparent [–] I’m extremely pro EU but GP has a point. The field advantages the US had doesn’t change the fact that the EU as a whole is less friendly to small businesses. Where I will disagree however is that it’s not an EU thing, it’s a country thing. The Netherlands for example is extremely SMB friendly. Yes EU has more regulations but most of the ones that matter, US SMBs also have to deal with them so it doesn’t change the playing field. reply p_l 7 hours agorootparent [–] To me, the way it simply doesn't align with reality because of differences between countries in EU, makes the whole argument even more detached from reality. Unfortunately, small companies when facing level playing field are also easier to be destroyed by bigger ones, and EU did level the playing field quite a bit... reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post highlights European alternatives for various digital services and products, emphasizing support for local businesses and adherence to GDPR (General Data Protection Regulation).",
      "It lists categories of services with the number of alternatives available, such as web analytics, cloud computing, and email providers, among others.",
      "The post underscores the benefits of choosing European providers, including VAT refunds, common European payment methods, and easier enforcement of rights within the EU due to unified laws."
    ],
    "commentSummary": [
      "European Alternatives lists products and services from companies based in EU, EEA, EFTA, or DCFTA member countries, excluding non-EU/EFTA sub-hosting providers.",
      "The site covers categories such as identity and access management, VPS providers, and search engines, with discussions on post-Brexit UK exclusion and EU regulation compliance.",
      "Users also debate the quality of services like Hetzner and Tuta, and the geopolitical implications of data privacy and competition in the European tech landscape."
    ],
    "points": 182,
    "commentCount": 84,
    "retryCount": 0,
    "time": 1718529476
  },
  {
    "id": 40698442,
    "title": "Building SimCity: How to put the world in a machine",
    "originLink": "https://mitpress.mit.edu/9780262547482/building-simcity/",
    "originBody": "Home Game Histories games & activities computers social science Building SimCity Game Histories Building SimCity How to Put the World in a Machine by Chaim Gingold Foreword by Janet H. Murray Paperback $50.00 Paperback ISBN: 9780262547482 Pub date: June 4, 2024 Publisher: The MIT Press 486 pp., 6 x 9 in, 108 color illus. MIT Press BookstorePenguin Random HouseAmazonBarnes and NobleBookshop.orgIndieboundIndigoBooks a Million eBook 486 pp., 6 x 9 in, 108 color illus. Paperback 9780262547482 Published: June 2024 Publisher: The MIT Press $50.00 eBook 9780262377584 Published: June 2024 Publisher: The MIT Press $54.99 MIT Press Bookstore Penguin Random House Amazon Barnes and Noble Bookshop.org Indiebound Indigo Books a Million Other Retailers: MIT Press Bookstore Penguin Random House Amazon Barnes and Noble Bookshop.org Indiebound Indigo Books a Million Amazon.co.uk Blackwells Bookshop.org Foyles Hive Waterstones Description Author(s) Praise Description A deep dive into the trailblazing simulation game SimCity, situating it in the history of games, simulation, and computing. Building SimCity explores the history of computer simulation by chronicling one of the most influential simulation games ever made: SimCity. As author Chaim Gingold explains, Will Wright, the visionary designer behind the urban planning game, created SimCity in part to learn about cities, thinking about the world as a complex system and appropriating ideas from traditions in which computers are used for modeling. As such, SimCity is a microcosm of the histories and cultures of computer simulation that engages with questions, themes, and representational techniques that reach back to the earliest computer simulations. Gingold uses SimCity to explore a web of interrelated topics in the history of technology, software, and simulation, taking us far and wide—from the dawn of programmable computers to miniature cities made of construction paper and role-play. An unprecedented history of Maxis, the company founded to bring SimCity to market, the book reveals Maxis's complex relations with venture capitalists, Nintendo, and the Santa Fe Institute, which shaped the evolution of Will Wright's career; Maxis's failure to back The Sims to completion; and the company's sale to Electronic Arts. A lavishly visual book, Building SimCity boasts a treasure trove of visual matter to help bring its wide-ranging subjects to life, including painstakingly crafted diagrams that explain SimCity's operation, the Kodachrome photographs taken by Charles Eames of schoolchildren making model cities, and Nintendo's manga-style “Dr. Wright” character design, just to name a few. Author(s) Praise Related Books Previous Next",
    "commentLink": "https://news.ycombinator.com/item?id=40698442",
    "commentBody": "Building SimCity: How to put the world in a machine (mitpress.mit.edu)129 points by jarmitage 3 hours agohidepastfavorite72 comments chaimgingold 1 hour agoHi! I wrote this book. Ask me anything. I also was a designer on Spore. I'm also trying to feed my 8 month old lunch and he is very excited to asn``wer anything too. reply chaimgingold 4 minutes agoparentI want to bump a few things that folks linked to below: [1] Will Wright (designer of SimCity) will be interviewing me about the book on July 19th at 2PM ET. We thought it would be fun to turn the tables and have him interview someone else for a change. On Twitch, free, online, and live. Hosted by ROMchip. RSVP here: https://www.tickettailor.com/events/romchipajournalofgamehis... [2] Stewart Brand wrote a brief review on X I'm still in disbelief over (\"It is one of the best origin stories ever told and the best account I've seen of how innovation actually occurs in computerdom.\"). Read more here: https://twitter.com/stewartbrand/status/1800941614287946003 reply jokoon 39 minutes agoparentprevDon't you think the granularity of factorio is what brought its success? Don't you think it would be interesting the mix the sims and sim city for more granularity in the game? reply chaimgingold 15 minutes agorootparentThat’s a fascinating idea! One of the surprising things I learned while researching this book was that Maxis was actually trying to do that at one point, and in fact more. They had an initiative called SimWorld that would allow all their sim games to link together and even be open to third party development. This very ambitious OS-like architecture meant that The Sims really was seen as zooming into SimCity, and in fact early prototypes of what became The Sims let you do just that. And SimCopter did let you open SC2k save files and fly through them. While SimWorld didn’t take off it seems that without it we wouldn’t have The Sims, which introduced an innovative object-oriented architecture that underwrote its cutting-edge AI, UI, and business model (modular expansion packs). Some fun primary sources: [1] Will Wright interview for SimCity 2000 CDROM: https://www.youtube.com/watch?v=NcgV4YolDkg [2] Game Developer magazine piece on SimWorld and early The Sims: https://ubm-twvideo01.s3.amazonaws.com/o1/vault/GD_Mag_Archi... (An old Game Developer magazine piece) [3] Will Wright shows a very early The Sims demo at Terry Winograd’s Stanford seminar: https://searchworks.stanford.edu/view/yj113jt5999 reply ryani 1 hour agoparentprevHi Chaim! I really enjoyed working with you on Spore. What have you been up to in the intervening years besides writing this book? reply chaimgingold 58 minutes agorootparentHi Ryan!! I got a PhD, did some indie game stuff, made some babies (with some help, mainly from my wife), design consulting. You can see more of my projects here: https://chaim.io, like some tangible/mixed reality computing (done while I was working at a research lab with Bret Victor), and Earth: A Primer, a science book made of simulation toys. reply xanderlewis 1 hour agoparentprevCool! Possibly off topic, but: what did you work on for Spore? Was it around the time of the now (in?)famous E3 demo in ~2006, or closer to the final release? The final game seemed to differ significantly from what many of us were hoping for, and I never really heard much of a story of what happened in between. reply chaimgingold 1 hour agorootparentThe main thing I did was design the Editors (like the Creature Creator), but I initially joined as an intern in 2001 and did some really fun divergent prototypes for Will Wright while the project was in a nascent state, and a bunch of other stuff during development. There's a whole book to be written about Spore (but I'm done writing books for now), but the simple answer is that the difference between \"hoping for\" and \"final\" product encompasses a lot of what makes software and game development (or really any creative project for that matter) interesting. Especially when multiple people are involved. And that is part of what sparked this project, which took over a decade to research and write. (Also, many years ago I wrote a chapter for another MIT Press book about some early Spore history. It's reproduced on this deprecated blog: http://www.levitylab.com/blog/2011/02/brief-history-of-spore...) reply xanderlewis 51 minutes agorootparentThanks. I should add that I did enjoy the final game very much; it was just quite different to what was demoed. I’ll probably be buying your book! reply chaimgingold 37 minutes agorootparentThank you! Not to be defensive, but I want to say more about this because I think it's a fascinating subject with Spore in particular and games, software, and technology generally. My take is that Will Wright had a very exciting vision but visions are just that: not real. They are inherently nebulous and everyone on the team (and many many people beyond it) had their own idea on what Spore would be or turn into. We converged on something and negotiated with one another and many constraints, social and technical, and arrived at something. It didn't help that part of the game's marketing appeal was a bit Rorschach-y in the first place and capitalized on the exciting but vague promise of Will Wright (Sim-) + Universe (-Everything). reply hellodang_ 1 hour agoparentprevAfter SimCity 4 what’s the next great building sim you’d recommend? reply chaimgingold 52 minutes agorootparentHonestly, I'm not much of a building sim player these day! I love videogames but they're so complicated and take so much time, right? Seems like City Skylines is the heir, right? Or maybe it's Minecraft and Tiny Glade? I think that SimCity and Maxis can be seen as helping establish the whole world of open-ended creative sandbox games that have since proven to be dominant. A big takeaway from this book for me, looking at the history of videogames and computing, is that the medium of videogames is really about creativity and making games. (Look at the top-selling games of all time.) reply ziggy_star 1 hour agoparentprevI linked elsewhere Will talking about the procedural generation. But now we have The Power of Generative AI. Those editors you've built could sure be way different, just doodle your monster and watch it come alive. 'etc. I would like to make Spore meets Second Life Powered by AI. Also Space Exploration games really took off in the years since Spore.. This is fertile ground there are so many directions to take it with modern hardware and the recent advancments. Time for another kick at the cat I say. Wanna apply to YC together? :) I'm not even kidding, I gots ideas. Also randoms reading this if you're picking up what I'm laying down. But to get on the team first you have to buy and read his book. P.S. - Somebody recently called me about how a Burger King Advertisement doxxed them. In the middle of the commercial it knew their name and IP address and zoomed unto their house with custom comical narration about which burger they like. One day a Simulation of Everything Game with a little trickery could plausibly stun the player by suddenly showing them a little cartoonish version of themselves playing it in their own room. I'm just sayin'. reply chaimgingold 43 minutes agorootparentLOL. Thanks! I think a lot of videogaming ideas took off after Spore that were very likely influenced by it. Shades of Jodorowsky's Dune? (But I think Spore was actually more successful than many give it credit for, which has been pointed out to me many times. 191m+ creations and counting on Sporepedia.) Generative AI certainly opens up new possibilities! It's analogous to GPUs (enabled real-time 3D) which opened new possibilities and audiences for videogames. I also think that the fundamental magic of creative tools doesn't actually need fancy tech at all. reply ziggy_star 37 minutes agorootparentJodorowsky's Dune is perfectly apt actually. I think you were the right people with the right vision but very early and we all simply fell into the darkest timeline because what should have been hasn't happened. If you think about it this sort of your responsibility to save the universe by embarking on this quest with me and righting a cosmic wrong. Otherwise another Covid might happen. Also VCs have moneybags for you we got all the buzzwords neatly lined up. Come Mr. Gingold, you cannot resist this potent of a reality distortion field from an internet stranger. Or dare I say... internet friend? ;) reply chaimgingold 13 minutes agorootparentI definitely feel like I've made a new internet friend. :D reply tunnuz 1 hour agoparentprevGood luck with the baby and congrats for the book.Spore is a computer simulation game directed by Will Wright (SimCity, The Sims). I designed its suite of powerful yet fun to use 3d tools that players used to make alien creatures, buildings, and vehicles. > I designed Spore's critically acclaimed creative tool suite, e.g. the Spore Creature Creator, which has been used to make over 189 million creations. > In 2002, I was handpicked by Will Wright for Spore's nucleic R&D team. Responsibilities also included design and prototyping across the entire project, directing interns, and interfacing with journalists. From: http://chaim.io reply ziggy_star 1 hour agorootparentI like the cut of his jib. reply card_zero 1 hour agoparentprevSounds interesting, if perhaps less fun than Masters of Doom. I look forward to reading it for free some day. And I probably like that ink smell, although I agree that it's important that a book should smell good. reply DonHopkins 2 hours agoparentprevHere is Will Wright's talk \"Interfacing to Microworlds\" from April 26 1996, which he presented to Terry Winnograd's user interface class at Stanford. I sat in on the talk, asked questions, took notes, and wrote up a summary, had Will review it, then went to work with him on Dollhouse which became The Sims. After we shipped in 2000 I updated my summary of the talk with some thoughts and retrospectives about working with Will on The Sims. Stanford recently published the video, so again I updated my write-up with more information from the talk, transcript excerpts, screen snapshots, links and citations. All I had to go on for the 27 years between the talk until the video surfaced and I could finally watch it again were my notes and memory, so I'd forgotten how just prescient and purposeful he was, and I didn't remember that he was already planning on leaning into the storytelling and user created content and self and family representation aspects, and making the people speak with \"Charlie Brown Adults\" mwop mwop mwop speech, among many other things. Will Wright - Maxis - Interfacing to Microworlds - 1996-4-26 https://www.youtube.com/watch?v=nsxoZXaYJSk >Video of Will Wright's talk about \"Interfacing to Microworlds\" presented to Terry Winograd's user interface class at Stanford University, April 26, 1996. >He demonstrates and gives postmortems for SimEarth, SimAnt, and SimCity 2000, then previews an extremely early pre-release prototype version of Dollhouse (which eventually became The Sims), describing how the AI models personalities and behavior, and is distributed throughout extensible plug-in programmable objects in the environment, and he thoughtfully answers many interesting questions from the audience. >This is the lecture described in \"Will Wright on Designing User Interfaces to Simulation Games (1996)\": A summary of Will Wright’s talk to Terry Winograd’s User Interface Class at Stanford, written in 1996 by Don Hopkins, before they worked together on The Sims at Maxis. Use and reproduction: The materials are open for research use and may be used freely for non-commercial purposes with an attribution. For commercial permission requests, please contact the Stanford University Archives (universityarchives@stanford.edu). https://searchworks.stanford.edu/view/yj113jt5999 Will Wright on Designing User Interfaces to Simulation Games (1996) (2023 Video Update) https://donhopkins.medium.com/designing-user-interfaces-to-s... A summary of Will Wright’s talk to Terry Winograd’s User Interface Class at Stanford, written in 1996 by Don Hopkins, before they worked together on The Sims at Maxis. Now including a video and snapshots of the original talk! Will Wright and Brian Eno discussing generative systems at a Long Now Foundation talk: https://www.youtube.com/watch?v=UqzVSvqXJYg SimCity takes a lot of short cuts to fool you. It's what Will Wright calls the \"Simulator Effect\": Will Wright defined the “Simulator Effect” as how players imagine the simulation is vastly more detailed, deep, rich, and complex than it actually is: a magical misunderstanding that you shouldn’t talk them out of. He designs games to run on two computers at once: the electronic one on the player’s desk, running his shallow tame simulation, and the biological one in the player’s head, running their deep wild imagination. \"Reverse Over-Engineering\" is a desirable outcome of the Simulator Effect: what game players (and game developers trying to clone the game) do when they use their imagination to extrapolate how a game works, and totally overestimate how much work and modeling the simulator is actually doing, because they filled in the gaps with their imagination and preconceptions and assumptions, instead of realizing how many simplifications and shortcuts and illusions it actually used. The trick of optimizing games is to off-load as much as the simulation from the computer into the user's brain, which is MUCH more powerful and creative. Implication is more efficient (and richer) than simulation. Some muckety-muck architecture magazine was interviewing Will Wright about SimCity, and they asked him a question something like “which ontological urban paradigm most influenced your design of the simulator, the Exo-Hamiltonian Pattern Language Movement, or the Intra-Urban Deconstructionist Sub-Culture Hypothesis?” He replied, “I just kind of optimized for game play.” During development, when we first added Astrological signs to the characters, there was a discussion about whether we should invent our own original \"Sim Zodiac\" signs, or use the traditional ones, which have a lot of baggage and history (which some of the designers thought might be a problem). Will Wright argued that we actually wanted to leverage the baggage and history of the traditional Astrological signs of the Zodiac, so we should just use those and not invent our own. The way it works is that Will came up with twelve archetypal vectors of personality traits corresponding to each of the twelve Astrological signs, so when you set their personality traits, it looks up the sign with the nearest euclidian distance to the character's personality, and displays that as their sign. But there was absolutely no actual effect on their behavior. That decision paid off almost instantly and measurably in testing, after we implemented the user interface for showing the Astrological sign in the character creation screen, without writing any code to make their sign affect their behavior: The testers immediately started reporting bugs that their character's sign had too much of an effect on their personality, and claimed that the non-existent effect of astrological signs on behavior needed to be tuned down. But that effect was totally coming from their imagination! They should call them Astrillogical Signs! The create-a-sim user interface hid the corresponding astrological sign for the initial all-zero personality you first see before you've spent any points, because that would be insulting to 1/12th of the players (implying [your sign] has zero personality)! https://www.youtube.com/watch?v=ffzt12tEGpY From: \"Gavin Clayton\"Newsgroups: alt.family-names.sims,alt.games.the-sims Sent: Tuesday, April 11, 2000 2:59 PM Subject: No other game has done this... > Hi... no need to reply to this cos it's just a whimsical thought :-) > > When I first got the game I tried to make my own family, trying to get > their personalities accurate too. When making myself, my dad and my > sister, I attributed points to all the personality categories, and I > found I had points left over. But when I made my mum I ran out of > available points and was wishing for more -- I wanted to give her more > points than are available. It made me realise for the first time in > years how much I love my mum :-) > > Now what other game has ever done *that*? :-) > > Gavin Clayton reply card_zero 47 minutes agorootparent> Implication is more efficient (and richer) than simulation. I guess that why lacking a water supply in SimCity 2000 didn't inhibit the city's growth at all, and the negative effect on your mayoral approval rating could be removed by building a single pump anywhere, with no pipes. reply szvsw 2 hours agoprevPeople interesting in this might be interested in Silicon Second Nature by Stefan Helmreich, a pretty brilliant MIT anthropologist/historian of science. It’s all about the Santa Fe Institute and the science of emergence, from both a technical and social level. One of the best books I’ve ever read I think! https://www.ucpress.edu/book/9780520208001/silicon-second-na... reply chaimgingold 2 hours agoparentStefan Helmreich's book is indeed brilliant! I used it extensively when writing Building SimCity. Stefan was quite helpful in researching my book, sharing and checking some old SFI documentation so I could determine things like who visited SFI when for what event (and with whom). The attendee list for some of the early Artificial Life conferences was quite cool. Peter Molyneux shows up as well as one of Maxis's venture capitalists. reply szvsw 1 hour agorootparentHey thanks for the response. I’m looking forward to picking up the book now. Silicon Second Nature left a big enough impression on me that I did a performance art piece inspired by it in undergrad (back when I thought I might be an artist, LOL)… unfortunately I don’t have access any longer to video documentation but there are some pics and description on my (currently offline) website: https://web.archive.org/web/20210802234726/https://samwolk.i... There’s also a short 16mm experimental film I made around the same time: https://vimeo.com/198901474 Just sharing since it’s pretty rare for me to meet someone who might actually be interested in these, ha! reply chaimgingold 9 minutes agorootparentYour film has some beautiful stuff in it! reply DonHopkins 2 hours agorootparentprevI was delighted how you covered Doreen Nelson's life work, Design Based Learning, like you did in your thesis. I have a copy of the \"School Edition\" Lab Pack of SimCity Classic that she and Michael Bremer wrote, which I'll dig up and scan, so I can put it on archive.org and include ìt with the open source Micropolis project. LGR - SimCity Educational Version Unboxing & Overview: An overview of the \"School Edition\" Lab Pack of SimCity Classic by Maxis. Unboxing, first impressions of the package and testing of the radically rad software ensues. https://www.youtube.com/watch?v=edXRNtuAGTg I was also thrilled you wrote about John von Neumann's 29 state self replicating cellular automata machine! Super interesting and important stuff. I wrote more about that stuff in the discussion of SimCity for WebAssembly: https://news.ycombinator.com/item?id=40698110 Chaim, I'm looking forward to Will Wright interviewing you about Building SimCity, Fri Jul 19, 2024 2:00 PM - 3:30 PM EDT. It will definitely be weird! https://x.com/cgingold/status/1798790177814663294 >I thought it would be fun to turn the tables and give Will Wright a chance to interview someone else: me (!), about Building SimCity. >@ROMchip_Journal: Mark your calendars! Next month, ROMchip is hosting @cgingold and Will Wright for a discussion of Gingold's new book BUILDING SIMCITY >Event will broadcast live on Twitch Friday, July 19 @ 2PM EST. Grab your free tickets for the oneline interview: here: https://app.tickettailor.com/events/romchipajournalofgamehis... reply chaimgingold 2 hours agorootparentThanks, Don! Please scan that! She recently found a shrink wrapped copy of a teacher guide she coauthored with Michael Bremer and opened it (!) because we disagreed about what was in there, LOL. It's destined now for her UCLA archive. Apparently she also wrote guides for many other Maxis titles but not all saw the light of day. Or maybe they did but need to be recovered. reply benbreen 3 hours agoprevReading this now and really enjoying it. Here's a brief review from Stewart Brand: https://twitter.com/stewartbrand/status/1800941614287946003 reply neonate 3 hours agoparenthttps://threadreaderapp.com/thread/1800941614287946003.html reply 42lux 2 hours agoprevWhenever Maxis comes up I always imagine some government simulations running on refined models but still using the SimCity 2000 interface. reply atan2 3 hours agoprevI tried to look it up but I am still not sure if this book discusses SimCity's programming or not. reply chaimgingold 2 hours agoparentYes. There's a whole chapter on this with tons of diagrams, not code. reply SillyUsername 2 hours agoprevPrice seems a bit steep. Needs to lower taxes for me to buy it. reply otteromkram 2 hours agoprevIs this an advertisement? reply thenthenthen 2 hours agoprevThis should have been a game reply curiousgal 3 hours agoprevWhat's the point of posting a book listing? A review or an analysis would have been more interesting. reply atan2 2 hours agoparentI don't see anything wrong with posting about a book, a course, etc., especially if it's a newly released product. It's good to know what's being done. reply juice_bus 3 hours agoprev [–] The ebook is $4.99 more expensive than the physical copy - wild. reply crtasm 3 hours agoparentand \"6 x 9 in\", I thought only PDFs were fixed sizes :) https://mitpress.mit.edu/9780262537759/minitel/ is $39.99 ebook, $40 paperback, but $35 hardcover. bizarre pricing. reply mtillman 1 hour agorootparentbig pdf: https://alexwlchan.net/files/2024/universe.pdf reply solalf 3 hours agoparentprev [–] And the paperback is $50. What happened here? reply Shadowmist 3 hours agorootparent [–] 100 color photo pages reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "\"Building SimCity\" by Chaim Gingold explores the history and development of the influential simulation game SimCity, created by Will Wright.",
      "The book covers the impact of SimCity on computer simulation and the history of Maxis, the company behind the game, with visual materials like diagrams and photographs.",
      "Published by The MIT Press, it will be available in both paperback and eBook formats starting June 2024."
    ],
    "commentSummary": [
      "Chaim Gingold, author and designer on Spore, is available for a Q&A session, with Will Wright interviewing him on July 19th at 2 PM ET on Twitch, hosted by ROMchip.",
      "Stewart Brand praised Gingold's book as one of the best origin stories and accounts of innovation in computing.",
      "Gingold recommends City Skylines, Minecraft, and Tiny Glade as modern successors to SimCity, highlighting the influence of generative AI on game development."
    ],
    "points": 130,
    "commentCount": 72,
    "retryCount": 0,
    "time": 1718556931
  },
  {
    "id": 40693500,
    "title": "SQLite is likely used more than all other database engines combined",
    "originLink": "https://sqlite.org/mostdeployed.html",
    "originBody": "Small. Fast. Reliable. Choose any three. Home Menu About Documentation Download License Support Purchase Search About Documentation Download Support Purchase Search Documentation Search Changelog Most Widely Deployed and Used Database Engine SQLite is likely used more than all other database engines combined. Billions and billions of copies of SQLite exist in the wild. SQLite is found in: Every Android device Every iPhone and iOS device Every Mac Every Windows10 machine Every Firefox, Chrome, and Safari web browser Every instance of Skype Every instance of iTunes Every Dropbox client Every TurboTax and QuickBooks PHP and Python Most television sets and set-top cable boxes Most automotive multimedia systems Countless millions of other applications Since SQLite is used extensively in every smartphone, and there are more than 4.0 billion (4.0e9) smartphones in active use, each holding hundreds of SQLite database files, it is seems likely that there are over one trillion (1e12) SQLite databases in active use. Most Widely Deployed Software Module of Any Type? SQLite is probably one of the top five most deployed software modules of any description. Other libraries with similar reach include: The original zlib implementation by Jean-loup Gailly and Mark Adler. The original reference implementation for libpng Libjpeg from the Independent JPEG Group Libc is omitted from the above list even though it is more common than SQLite because libc is not a single software component but rather several competing implementations (ex: BSD vs. GNU) with similar interfaces. There are also independent implementations of libjpeg and libpng, though in those cases the canonical implementations are very popular. Precise numbers are difficult to obtain and so exact rankings are impossible. But our best guess is that SQLite is the second mostly widely deployed software library, after libz. Some commentators observe that SQLite tends to be statically linked and thus have multiple instances on each machine, whereas libz tends to have just a single instance per machine in the form of a shared library or DLL. So even though the number of devices containing libz may be greater than the number of devices that contain SQLite, the total number of instances per device might be higher for SQLite and so SQLite might be the single most widely deployed and used software component.",
    "commentLink": "https://news.ycombinator.com/item?id=40693500",
    "commentBody": "SQLite is likely used more than all other database engines combined (sqlite.org)126 points by ysabri 21 hours agohidepastfavorite76 comments paradox460 20 hours agoIn the past, I've used it as a file format for an online application. Users often wanted to download bits and bobs of data from the app, not to view it or edit it on their desktop, but more as backups or to share a particular configuration Previously we'd used a json+zip pair, but the lack of enforced schema became a problem. Switching over to a gzipped sqlite db with a \"custom\" file extension worked incredibly well reply TZubiri 20 hours agoprevIn terms of installations, sure. In terms of total data, probably not. In terms of important data, 100% not. Important data needs guarantees, and its privacy is second to its longevity. Server side and centralized beats client side decentralized for all but sensitive consumer data. reply simonw 19 hours agoparentYou may be shocked to learn how much of the world's \"important data\" lives in Excel files. reply strogonoff 19 hours agorootparentA lot of world’s important data is on paper. As far as important data served from a relational database is concerned, MySQL most likely beats the hell out of everything in terms of popularity. The bulk of SQLite’s usage has to be various runtime caches, file data, and so on. reply TZubiri 18 hours agorootparentPostgresql superseded mysql ever since the maria fork/oracle acquisition. reply strogonoff 18 hours agorootparentThe topic is not quality but popularity. reply TZubiri 18 hours agorootparentYes. In terms of popularity (installs/time) psql superseded mysql. Although of course at the tipover point msql still may have beaten psql in terms of total installations, i'm pretty sure even by that metric psql already won. reply strogonoff 17 hours agorootparentSource? I’ve only been using PostgreSQL, but I believe most legaxy systems are not going to rush to update, and world consists of legacy systems and systems that will become legacy tomorrow. reply TZubiri 15 hours agorootparentI'm the source we have been living in a psql era for longer than mysql, so it has had enough time to catchup. If you feel otherwise it's probably that memory bias effect where distant events seem closer and we underestimate the passage of time, There's an xkcd for that https://xkcd.com/891/ \"The death of mysql(2010) is closer to its birth(1995) than to the present (2025)\" will become a true statement next year. reply ffsm8 15 hours agorootparentSo it's essentially your gut feeling? It's obviously going to be hard to determine a number for a statistic like \"most popular\", and there are always very different interpretations of the available numbers, ending up with vastly different rankings. I.e. this one keeps Oracle DB at place 1, mysql at second: https://db-engines.com/en/ranking It links to their method at the top of the statistics. (Oracle has basically a DB monopoly if you believe that ranking, as these are both owned by them) It's dataset is probably flawed, but I think we can say \"Rumors of mysqls death have been greatly exaggerated\" reply strogonoff 10 hours agorootparentprevThere are stats that claim MySQL is used more, but I did not link to them because I don’t know if they are trustworthy. You, meanwhile, just made a fact out of thin air. reply ksec 5 hours agorootparentIt is unfortunate how HN discussions has fallen. Not only are most ( if not all ) of DB discussions completely ignoring MySQL, it is as if Oracle and MS SQL Server isn't a thing. reply novariation 19 hours agorootparentprevFun fact: my (french) company audited the french navy and found out they share important nuclear submarine maintenance data as excel files through email. reply ARandomerDude 19 hours agorootparentFormer US military officer here. This does not surprise me at all. I wasn’t in subs but we absolutely did this for maintenance of other multimillion dollar assets. reply ysabri 18 hours agorootparentMicrosoft is in so many government offices around the world it's not even funny. reply yunohn 12 hours agorootparentI’m certain MS is in all government offices almost globally, except that one municipality in Germany that keeps attempting a Linux transition every other year. reply TZubiri 18 hours agorootparentprevNot shocked, not a problem. Easier to copy/replicate, packaged with a GUI, provider with a commercial relationship, programmatic support ( formulas, vba, COM, raw data access) Would be closer to sqlite than server side though, but it's capacity for replication and sharing makes it more adecuate for sqlite. Sqlite's lack of GUI gives data a programmer bias, important data uses excel because unless you are in a technocratic environment. reply RyanHamilton 16 hours agorootparentThere's quite a few guis available, eg here's mine: https://www.timestored.com/qstudio/database/sqlite You raise an interesting idea. What if sqlite database s has also been .exe executable to give at least a cli. That would have been interesting, similar to redhead. reply alganet 20 hours agoparentprevHow would you go about measuring that, or determining what's important? Huge SQL for servers is just a different use case. Someone's temporary browser data or settings for my android alarm app could be just as important and sensitive as an average record on those big servers. Fortunatelly, SQL fits the role of a small transactional engine very well to support those small use cases for a large number of applications. It deserves the good reputation. reply TZubiri 18 hours agorootparentWe don't need to measure everything, we may talk about variables that are hard or subjective to measure. reply arh68 19 hours agoparentprevRight. In terms of installations, I bet textfiles still win. Doesn't mean much, does it? reply TZubiri 18 hours agorootparentGross theoretical error. Text files are a (ambiguous and undefined) file format, while sqlite is an application. reply II2II 19 hours agoparentprev> In terms of total data, probably not. > In terms of important data, 100% not. Choosing not to focus upon quantity or quality is likely the reason why SQLite is so popular. It is a lot easier to manage and develop for SQLite than it is to do the same for large databases that require high availability and reliability under heavy loads. There are many more applications for small databases that contain data that is important to the end user even though that data may not be important to anyone else. reply TZubiri 18 hours agorootparentYou can also use a plain file system, it allows data to be exported more easily and through un unbiased app like a file explorer. I'd say if the data is important and client side, you'd probably want it to be accesible in a protocol format rather than a sqlite file format. It's cool that sqlite is open source and u can technically recover the data, but at the end of the day excel data is more accesible, which defeats the ethos of open sourceness reply yndoendo 19 hours agoparentprevWould you classify a nurse call system as requiring important data retention and access? Mapping backbone devices with passive and interactive end user devices with means to communicate whom should provide assistance? Works great there too with μC/OS-II. Competition was using Windows XP and Microsoft Access. Only time ever using Oracle has been with internal business analytics, not very important. reply TZubiri 18 hours agorootparentNo I would not, the application is important and critical, but the data? What data are you holding? Historical auditable data regarding calls? I have some experience with hospitals, and deep data like this would never be used for diagnostics or even epidemiology tracing. reply bob1029 19 hours agoparentprev> Server side and centralized beats client side decentralized SQLite works on the server too. Important data can live in a SQLite database. reply ysabri 18 hours agoparentprevI remember reading or seeing this post about how SQLite can really scale and supports a really high amount of transactions per second. I don't know if it supports distrubuted loads that well, which might be the reason why it's use didn't pick up server side. reply TheRealPomax 20 hours agoparentprevI'm not sure I buy the \"important data\" one: my Lightroom catalog, to me, constitutes incredibly important data. Losing it and just having the base files would destroy over a decade of work. It also happens to be a SQLlite3 database. And the same is true for a slew of other applications that (quite rightly) use SQLite databases as their file format. You might be thinking of things like financial transactions, or medical records, but that's not the only kind of important data there is. reply out_of_protocol 9 hours agorootparent+1 So is contacts list, sms messages, Whatsapp data, browser data etc etc. whese are separate installations of sqlite, hundreds per phone. And they ARE important, at least to me. reply TZubiri 18 hours agorootparentprevHow do you physically store it? An external disk? I venture a guess that for each sqlite db holding important work data, you have dozens or hundreds of traditional db datasets, that are critical to your work. And yes, I mean your bank, but also messaging apps, online services. If you backup your hard drive in the cloud at all, you are already depending on trad dbs for the very use case supposedly highlighting your dependence on sqlite. reply hehdhdjehehegwv 19 hours agorootparentprevThe number of societal-wide problems that occur if your Lightroom database gets corrupted is zero. The amount of hell that would be unleashed if the financial systems layers upon layers of database transactions got broken is impossible to comprehend. So if you mean “important” as “necessary for society to function”, then no, your browser bookmark files, contact list, or the other two dozen things your laptop and phone use SQLite for are not important. reply tibbar 19 hours agorootparentThis is a false equivalence, as one user’s particular usage of SQLite is not comparable to all financial instructions’ databases. Better to compare to the prospect of all smartphones being irreversibly corrupted at once. reply hehdhdjehehegwv 18 hours agorootparentLiterally all smartphones dying at once is preferable because they are all backed up into heavy duty databases. You can restore every phone from the cloud in this thought experiment. You can not restore a data center from a pile of phones. reply wavemode 19 hours agorootparentprevThe goalposts keep moving here. You can just take any arbitrary definition of important and use it to exclude SQLite deployments. It's all semantics, and also irrelevant to the original article anyway, since nowhere does it argue that SQLite holds the most data (important or otherwise). reply hehdhdjehehegwv 19 hours agorootparentI didn’t comment earlier so I can’t move a goalpost I never set down. I agree with the root comment that there may be more instances of SQLite, the most important data is not in SQLite. For what it’s worth, I have used any number of databases over the years and SQLite is very good for a number of things. None of those things are the core infrastructure that stores your emails, money, and other must have, shared, high availability data. There are different tools for different jobs, that’s fine. reply qazxcvbnmlp 20 hours agoprevSQLite solves a lot of problems well enough that you can focus on other things. Have an mvp you’re not sure you’ll ever have more that 2 users - yep. Storing a little data for an application on the disk and don’t want to write your own schema. Want to teach someone how databases work without setting up a sever - sure. reply achillean 19 hours agoparentA few others: - Want to distribute data to users that don't want to manage a server? A lot of people don't want to manage a server and don't need the best possible performance. - Want to take data with you on a thumb drive and work with it offline? It's extremely convenient to be able to use SQLite for an app that has to work offline. - Does the app mostly just read from the database and fit in memory? It's undervalued to just put the entire database into memory so you don't hit the disk and don't introduce network latency. For example, the following website does all enrichment with in-memory SQLite databases: https://shdn.io/analyze?target=ycombinator.com At Shodan, we distribute versions of our datasets as SQLite and they're a popular way to consume the data without having to manage infrastructure. reply mharig 9 hours agoprevAstonishing no commenter mentions that SQLite unleashes the power (and pain) of SQL for what were in ancient times dark binary blobs or obscure text formats. I.e. guaranteed consistency, easy versioning with better up/down compatibility, excellent complex retrievals, ... reply talkingtab 19 hours agoprevFor niche uses of database I am sure this is true. But if you are not in that niche, then Postgresql is usually a much better choice. For example Firefox uses SQLite, because it wants to store lots of application specific data. It is good for that. Personally, I find the tooling, documentation, familiarity and quality of Postgresql makes it my choice even in situations where SQLite might work. reply oneplane 19 hours agoparentIf I'm not mistaken, Apple's CoreStorage is based on SQLite, so pretty much every Apple device for the last years (or decade, probably) is constantly using tens (or more) SQLite databases, per OS. That includes Macs, Phones, Watches, AppleTV etc. That has got to be more than 3 billion devices (since there are at least 2 billion of the phones in active use). SQLite is also quite often a CI/CD default when building and testing software where you might want to do some tests without starting an entire RDBMS server. But I suppose it's different if we think in terms of networked databases, or multiuser. reply Twirrim 19 hours agorootparentIt's also heavily used on Android, so that's some 3bn devices (based on active users numbers from earlier this year). Plus it's in Firefox, Chrome, and so on. reply oneplane 8 hours agorootparentIt's probably on all Electron apps as well, and considering some of the parts of Android and Chromium are used on Smart TVs, head units in cars and game consoles, that's probably at least another 1bn. Suffice to say SQLite is probably at least 6bn active usages in size. reply saulpw 19 hours agoparentprevI think the headline statistic negates the claim that these are \"niche\" uses of database. reply 0xcde4c3db 19 hours agoparentprevAt some point, such local usages were sufficiently non-niche that the temp file extension was changed from \"sqlite\" to \"etilqs\" to stem the flood of angry emails about local application databases taking up too much disk space. (cf. Daniel Stenberg getting angry emails because everybody and their dog embeds libcurl, sometimes multiple times in the same app) reply simonw 19 hours agorootparentHere's the commit from 18 years ago explaining that change: https://github.com/sqlite/sqlite/commit/fd288f3549a1ab9a309a... ** 2006-10-31: The default prefix used to be \"sqlite_\". But then ** Mcafee started using SQLite in their anti-virus product and it ** started putting files with the \"sqlite\" name in the c:/temp folder. ** This annoyed many windows users. Those users would then do a ** Google search for \"sqlite\", find the telephone numbers of the ** developers and call to wake them up at night and complain. ** For this reason, the default name prefix is changed to be \"sqlite\" ** spelled backwards. So the temp files are still identified, but ** anybody smart enough to figure out the code is also likely smart ** enough to know that calling the developer will not help get rid ** of the file. reply mapcars 19 hours agoparentprevThe article is about number of installations, instances across all types of devices reply darby_nine 19 hours agoparentprevI'd guess most programs ever written are single-process programs with no need for the benefits postgres provides over sqlite. Postgres doesn't even have analogous functionality for eg an in-memory sql instance! reply hehdhdjehehegwv 19 hours agorootparentIt most definitely does and I’m serving several read-only production databases from memory. It is insanely fast if you do it right. https://www.postgresql.org/docs/current/pgprewarm.html reply MattGaiser 19 hours agoparentprevThe most frequent use of it is local storage of application data. Postgres is overkill for that. reply foobarian 19 hours agoprevI wonder what happened to bdb. I guess maybe authors lost interest/sold to Oracle and the license changed development just didn't keep up with the times. Bdb used to be the sqlite before sqlite existed and ended up used by various embedded applications or even graphical interfaces e.g. to index file thumbnails and such. I'm not sure but I think MacOS at one point used it this way. reply lm411 19 hours agoparentI haven't even thought of Berkeley DB in years. Used to use it quite a bit but most notably perhaps with apache mod_auth_db to handle authentication and subscriber information on a fairly high traffic site (yes, this was long long ago ;) ). reply cmur 20 hours agoprevI’m curious, is the prevalence of SQLite similar to how PHP is widely used because it’s behind many WordPress sites? reply pkaye 20 hours agoparentCouple of major companies like Adobe, Apple, Google, Mozilla use it in their products. That would add up quick. https://www.sqlite.org/famous.html reply duskwuff 19 hours agorootparentChrome's use of SQLite for history, cookies, and local storage would probably put it in first place on its own. Its extensive use in iOS and Android just guarantees the \"win\". reply yen223 13 hours agoparentprevKind of, at least in regards to mobile. When developing iOS and Android apps, the \"default\" frameworks for storing data (Core Data for iOS, Room for Android) are wrappers around sqlite. I would guess >50% of apps installed on your phone uses sqlite. reply darby_nine 19 hours agoparentprevI think Sqlite's accessibility and ease of use definitely help. However, the fact you can distribute an entire db with a single file is something that shouldn't be overlooked, nor sqlite's legendary reliability and insane test coverage. Finally the fact you can embed it in memory makes for an amazing testing story. reply ethagnawl 19 hours agoparentprevIt's also the default database used when creating new projects using many web frameworks, like Rails or (IIRC) Django. reply TheRealPomax 20 hours agoparentprevI'm trying to understand this sentence: it seems to suggest that PHP is only popular because of Wordpress, which just... makes no sense? Wordpress uses PHP because PHP existed, and was good enough to build Wordpress on. And it's certainly not just clinging onto life, hanging around just because Wordpress is built on top of it, today? So it's hard to understand which similarity you're asking about, but SQLite is popular because it does one thing, and does that one thing really well, and that thing also happens to be a perfect fit for complex file formats. reply sargun 19 hours agoprevI love SQLite. It’s pluggable interfaces and concise C code make it enjoyable to use (and sometimes to debug - as long as you don’t have to go through the single file version!). Unfortunately, I wish there were multiple implementations of it, and that the file format was documented and stable. reply ankitrgadiya 7 hours agoparentThe sqlite file format is documented and probably has the most insane backwards compatibility out there. The developers pledged to keep it backwards compatible until 2050. In fact Library of Congress has recognised it as one of the few data formats for long term archival. https://sqlite.org/fileformat2.html https://sqlite.org/lts.html https://sqlite.org/locrsf.html reply quasarj 20 hours agoprevMost likely, indeed. reply albertopv 13 hours agoprevThere are far more ants in the world than human beings. So what? reply axlee 20 hours agoprevOnce that is said, does OSS move forward? Not an inch, good luck getting any change upstream reply spencerchubb 20 hours agoparentOSS does not mean anyone can contribute. It means anyone can view source reply tombert 20 hours agoparentprevIt's still OSS, you're allowed to fork and maintain Sqlite if you don't like the upstream merge requirements. reply AlexErrant 19 hours agorootparentThe test suite is (partially) proprietary. Good luck maintaining a fork for a DB without tests. https://www.sqlite.org/th3.html see bottom reply oneplane 19 hours agorootparentYou can buy a license, and maintain your public fork while also letting everyone know you validated your fork with the same TH3 as the origin version. You just won't be able to show people your TH3 since I doubt you can buy a license that allows that. reply doubloon 20 hours agoprev [–] i find it ironic one of the most gatekeepy, closed, walled garden companies in the history of the planet, Bloomberg, is a sponsor of one of the most free most open piece of software ever. reply TZubiri 20 hours agoparentBloomberg sells pacakaged public information, they rely on commonwealth and transparent regulation disclosures, they are agents of such transparency. They gatekeep their product sure, but you need to do that if you want to sell it. reply mirekrusin 20 hours agoparentprevSqlite is not open for contributions. Amazying piece of code whatever you look at it. I'd also probably win test to code ratio contest. reply foobarian 19 hours agoparentprevAnother irony is that according to Wikipedia [1] Bloomberg maintains a fork of BDB. [1] https://en.wikipedia.org/wiki/Berkeley_DB reply jameshart 20 hours agoparentprev [–] The majority of these SQLite use cases that the article is celebrating are... as the internal data store in an app where it is locking up user data in a proprietary, closed, gate kept wall garden. This irony has layers. Like an onion. reply out_of_protocol 9 hours agorootparent [–] Do you use music player? Most, including open source are using SQLite inside. There are open source tiling maps formats like MBTiles, based on SQLite. Just dig around, you can find plenty of examples. It's other way around since database format is well known with tooling available reply jameshart 7 hours agorootparent [–] I’m not remotely claiming ‘I never use software that has SQLite inside it’. I use loads of programs that do. And that’s precisely the kind of walled garden I’m talking about. Keeping your playlists in a specific music player app’s SQLite database forces you to use that app to search or delete or share those playlists. Heck, some apps use SQLite blob storage to store images or even music files. Open software should use open file formats and store data in the file system where other programs can access it. reply thunky 3 hours agorootparent [–] > Open software should use open file formats and store data in the file system where other programs can access it That's what SQLite is. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "SQLite is the most widely deployed and used database engine, present in billions of devices and applications, including Android, iOS, Mac, Windows 10, major web browsers, and various popular applications.",
      "With over 4 billion smartphones each containing hundreds of SQLite databases, there are likely over one trillion active SQLite databases globally.",
      "SQLite is one of the top five most deployed software modules, potentially the second most widely deployed software library after zlib, and possibly the most widely deployed software component due to its multiple instances per device."
    ],
    "commentSummary": [
      "SQLite is extensively used, likely more than all other database engines combined, due to its ease of use, reliability, and offline functionality.",
      "Users are transitioning from json+zip to gzipped SQLite for better schema enforcement when downloading data for backups or sharing.",
      "Despite its popularity, SQLite is not open for contributions, but its file format is well-documented and stable, making it ideal for many applications, including iOS and Android."
    ],
    "points": 126,
    "commentCount": 76,
    "retryCount": 0,
    "time": 1718494730
  },
  {
    "id": 40699079,
    "title": "Experts vs. Imitators",
    "originLink": "https://fs.blog/experts-vs-imitators/",
    "originBody": ". fs.blog Cloudflare 894da24a29ce116f • 172.183.112.112 •",
    "commentLink": "https://news.ycombinator.com/item?id=40699079",
    "commentBody": "Experts vs. Imitators (fs.blog)121 points by harperlee 2 hours agohidepastfavorite59 comments garciasn 1 hour agoImitators may get frustrated by the need to go deep with others because they can’t, but to say that experts don’t share that same frustration is nonsense. There are many audiences who want you to go deep, but are not capable of a necessary level of understanding. In fact, these audiences are the ones who become what the author claims are imitators; pretending to understand when they do not. Experts are experts not because they’re teachers; they’re experts because they’re experienced and are executionally excellent. reply nickelpro 1 hour agoparentIn my career I've at times been a leading expert on, as is the way of these things, a couple niche technologies. I'm speaking from that perspective. While certainly there are those who struggle to connect with layman audiences, especially in academia, a complete inability to communicate the challenges and successes of a technology, technique, or theory to laymen is a huge demerit against a claim of expertise. There's a huge difference between walking through technical and theoretical mechanical specifics, and being able to communicate about a subject at different levels of abstraction. The greatest experts can often walk with a laymen right down to and rub against the jargon-filled specifics in a way that leaves no doubt they're able to step over that line without problem. This is important because we don't perform ideation, architecture, or structural problem solving in the terms of white papers and technical specifications. If an expert does not have an abstract internal narrative with which to navigate the mechanics of the subject, they are likely not an expert at all. reply mjburgess 1 hour agorootparentThis isn't really true for anything but the basics. If you're having a conversation with someone who asks more than surface-level questions, but hasnt more than surface-level knowledge, the answers can require many years of study -- or, at least, hours of conversation to get anywhere. This situation is incredibly frustrating if you're an expert, often because these question-askers aren't at all willing to listen to hours of you explaining many things to them. Consider a person who says, \"I heard rust was better than python because its safe\" -- where would one even begin? Suppose now you're dealing with a person who knows enough to make the claim, but isnt patient enough to have memory safety, garbage collection, interpreters, etc. explained This is often the situation experts are in. Indeed, it's a majority of hackernews threads. reply sqeaky 2 minutes agorootparentIf I were presented such questions I would provide some basic context in a sentence or two and then ask why they care about the difference. Perhaps something like this: Sqeaky: rust and python are both good programming languages rust is good for high performance, safety oriented, systems development. While python is good for hooking two systems together or processing a little data right in front of me. Why do you ask what are your goals, maybe some context would help me understand? Q: I'm a new developer and I want to build a web page I wasn't sure what to use? Sqeaky: well let's get into what programming you know and let's discuss some Libraries Python and rust both have options! Q: ... And the conversation would carry on from there based on the context the asker provided, because contextualizing conversations, questions, and data around a topic is part of having expertise. reply Espressosaurus 1 hour agorootparentprevIt's easy. \"Rust is better for safety than C because it makes it harder or impossible to make certain kinds of mistakes that are easy to make than C.\" \"What kind of mistakes?\" \"There are times when you need to acquire some shared resource. Let's say memory. In Rust, it's easy to ensure you return that memory when you're done with it. In C, it's easy to forget to return that memory when you're done with it. This is called a memory leak, and you might find that eventually there's not enough memory for other programs to run.\" \"What's memory?\" \"Think of a program as a recipe you're performing. Memory then is like working space. Like your counter space in your kitchen. If you run out of counter space, you don't have room to chop up more vegetables or temporarily store your cooked meat or what-have-you. Maybe you ran out of counter space because you left last night's dirty dishes on it. Rust automatically puts the dirty dishes in the dishwasher. In C, you have to remember to do that yourself, and sometimes you forget to.\" And so on. There's an easy explanation as long as you're not expecting them to perform detailed analysis. And I'm not. edit: eventually you'll get to your limit of simplicity, things like \"what is fire?\" and maybe you need to say \"I don't know, let's find out together!\" We all have limits to our expertise, after all. reply charleslmunger 9 minutes agorootparent>In Rust, it's easy to ensure you return that memory when you're done with it. This is a false explanation though - the problem is that memory is returned before you're done with it. https://doc.rust-lang.org/book/ch15-06-reference-cycles.html This is extra-wrong as python has a garbage collector to break reference cycles. If giving a simplified explanation to a layman, it's important that if they repeat the explanation to another expert they don't hear \"well that's wrong\". reply mjburgess 51 minutes agorootparentprevI said python, not C. Answering the C vs. Rust question would be presumably easier, because the claim is true (ie., it doesnt rest on a misunderstanding) and the person asking is likely familiar enough with the relevant concepts. The person claiming Rust is safer than python is so whoely confused this 2min tap-dance isnt good enough. When you're dealing with people with a-bit-more-than-surface understandings, the main problem is their head is full of misunderstandings. It is these that can take hours, or years, to undo. To suppose otherwise is to suppose that all questions can be answered in a cute couple of setences. This is, indeed, the opposite lesson of expertise. reply Espressosaurus 41 minutes agorootparentI shifted it to C because I am intimately familiar with C's drawbacks. I don't have the same understanding of Python's drawbacks. And it's always about explaining to the target person's level of understanding. A layman isn't going to know the difference between languages and why pick one vs. another. That's a long digression. Explaining why to use Rust to a Python expert is a very different discussion. An expert can switch between explanations as required for the audience. Non-experts, in my experience, cannot tailor the explanation for the audience. They typically bottom out at a level that leaves them unable to meet the questioner in the middle. Hell, I've been the non-expert, especially when it comes to something like why a particular material was acting like a diode instead of not passing the signal or passing the signal intact. I can regurgitate that the half-rectified signal from the aggressor is bleeding into the signal of interest, but I can't tell you why. That's when I'll tell you to talk to the EE team for specifics on why, as well as what they plan to do to fix it. reply mjburgess 33 minutes agorootparentThe purpose of my choosing python is that the comparison is essentially a category error. Python's semantics, and that of all GC'd interpreted languages, make memory safety irrelevant.. there is no manual allocation of memory in the language. I chose this example as I assumed it would be clear and non-controversial enough to make my point, ie., I assumed most HN readers would appreciate that a person claiming Rust's memory safety model made it safter than an interpreted language would be a person clearly deeply confused about the meaning of any of these terms. reply wruza 14 minutes agorootparentprevYou and the commenter above are confusing expertise with ability to determine and speak someone’s language. It’s just a distinct skill. You may not understand their level, and may be unable to negotiate it due to vocabular barrier (people invent non-standard vocab all the time). Your oversimplifications may bear unintended consequences, etc. You must take that into account and create a plan to make it clear. And when you have that skill without any expertise, they call you politician. Only a politician may answer “easy” on a hard question and tell something unrelated for few paragraphs cause he doesn’t know anything on the original one. reply alexey-salmin 55 minutes agorootparentprev> what is fire Funny you ask, this was the most frustrating question in my childhood because no one could give a satisfactory answer of what exactly is the visible part of fire or whether it even exists as a body. reply mjburgess 37 minutes agorootparentfire is a fundamentally organic phenomenon. you heat dry organic material until there's a gas-like emission of particles, these are then nearly instantaneous oxidised causing more light and heat. The emission of heat and light in this gas-like state (\"plasma\") then causes more emission and so on. reply jcynix 23 minutes agorootparentYou can burn certain metals (magnesium, sodium, sulfur, even iron (wool)) neither of which is \"organic\". So fire isn't a fundamentally organic phenomenon ... reply hurril 59 minutes agorootparentprevThis hinges on a thorough understanding of safety. It also does not even mention trading things off. Both of which are topics that will require further clarifications. And as it were: and so on. reply Espressosaurus 56 minutes agorootparent\"Why doesn't everyone use Rust then?\" \"Because it turns out that people aren't using the language too much yet, and it makes some things that are easy to do in C, hard to do in order to keep the language safe. It's all tradeoffs.\" At some point the person asking is satisfied and that tangent ends. This is how conversation works. You aren't trying to teach a layman how to write production-ready Rust code, and they aren't interested in learning how. reply TheOtherHobbes 28 minutes agorootparentprevThat's not an explanation, it's a description-by-analogy. If you think they're the same, consider why we need explanations at all if a description-by-analogy does the same job. reply ToValueFunfetti 22 minutes agorootparentIf someone thinks that they're the same, they probably don't already agree that we need both reply bragr 48 minutes agorootparentprevIn my experience, very few people are able to articulate their lack of understanding with straight forward questions like \"What's memory?\", and that's before we get into cognitive blind spots. For example, you've completely skipped over what it means to aquire and free memory, so I'm not sure your explanation is as clear as you think. reply exe34 30 minutes agorootparentThey usually make several leaps of imagination from the lack of understanding to the question they actually ask. reply AlotOfReading 50 minutes agorootparentprevNotice that you've shifted the parent's question from Rust vs Python to the entirely different discussion of Rust vs C. reply MrJohz 51 minutes agorootparentprevI think you're both right, but I think you're talking about different kinds of knowledge transfer. Imagine, as a simple model of expertise, three different levels of knowledge in a subject: beginner, intermediate, and advanced. In my experience, an expert can always explain their knowledge to the next level down: if you've got someone at the advanced level in a room of intermediates, then if the person at the advanced level should be able to explain what's going on to their intermediate peers. If they can't, I would be deeply sceptical that they know their stuff. But beyond that - someone at the advanced level in a room full of beginners, for example - communication gets harder, and the expert usually needs to be skilled in teaching in addition to their specialist subject in order to effectively explain what they're on about. So in your example, the expert is dealing with someone who only knows the basics, and so will need to do a lot of explaining to get them up to speed. But if instead the expert was asked something like \"How does the use of ADTs in Rust change how you would model data in comparison to Python?\", then the person they're dealing with probably knows enough that the expert only needs to explain the relevant specifics to them. So in summary: yes, teaching someone who knows relatively little compared to you requires a lot of specific teaching skills, even as an expert. But if you really are an expert, you should be able to explain your expertise to peers who just don't have the specific knowledge you have. reply noobermin 55 minutes agorootparentprev> Consider a person who says, \"I heard rust was better than python because its safe\" -- where would one even begin? Suppose now you're dealing with a person who knows enough to make the claim, but isnt patient enough to have memory safety, garbage collection, interpreters, etc. explained This means that the asker is impatient, not the expert. An expert can explain everything from 0, and might even enjoy it. reply treflop 58 minutes agorootparentprevIt’s all about analogies. You can explain anything to anyone. Rust is safer than Python in the way same way as having a backup sensor in your car versus not. Sure, you won’t need most of the time but it may catch you that one time that you almost backed into a wall because you were still groggy after a night out. You got their attention and they understand your expert PoV. If they’re still curious and want to know more, you go deeper. reply a_wild_dandan 40 minutes agorootparentprev\"If you can't explain something in simple terms, you don't understand it.\" - Richard Feynman Experts deeply understand their subject, and tailor answers to meet the audience where they're at. If you express genuine interest in someone's passion, they'll be ecstatic. That's what the OP is talking about. It's not about how experts (or anyone) interacts with belligerent and dismissive interlocutors. And observing teaching moments is just one aspect of a larger smell test for detecting imposters. I think it's a good heuristic within that scope! reply jwandborg 13 minutes agorootparentExperts deeply understand their subject. - Experts that tailor their answers to meet the audience are experts, but not only experts, they also have the luck of finding good analogues for parts of a system or topic, and a skill, or luck, of story telling and structuring teaching. - Individuals who use analogues and simplifications to describe a system or topic are not necessarily experts, they can also be lucky or skilled imitators, or just teachers. - Experts who are experts by the definition of having a deep understanding of the subject, but who are incapable or unwilling to simplify and/or structure the story well (in your subjective opinion), are still experts, but unless you also become an expert on the topic, it will be hard for you, or anyone else, to trust their expertise. reply Espressosaurus 1 hour agorootparentprevAgreed. My experience with experts--both being one in my domain and working with others in their domain--is that if they can't explain how it works to a layman, chances are they don't know how it works. True experts can understand from the layman's perspective and tailor the response to that level of understanding. reply edgarvaldes 43 minutes agorootparentprevNot so sure. It implies that a bad communicator can't be an expert at anything. reply g4zj 21 minutes agorootparentThis is my take. As an autistic individual, I struggle a lot with communication in general, especially speaking in-person as opposed to typing slowly and carefully like I am doing now. No matter how well I understand something, my ability to relay that information effectively to another individual will always be another matter entirely. It's true that I can't explain something I don't understand, but it doesn't logically follow that I only truly understand something if I can explain it. reply james_marks 11 minutes agorootparentprevI sense some self-selection that experts tend to be decent communicators, at least in some mediums. How would anyone know they are an expert if they can’t make themselves understood? reply tetha 22 minutes agorootparentprevThere is also a similar thing many experienced people complain about: Eventually, you'll have to be able to explain the cost and merit of a technical decision in business terms. Like, yeah I'm able to explain our postgres HA setup + DC-redundancy at fairly detailed technical level. But then a member of the board asks \"Yeah but what does it cost and what benefit does it bring the customers and why?\" Finding a satisfying and comprehensive answer to that question takes a whole new perspective and made me understand a few things more. And question a few more. reply zh3 14 minutes agoparentprevIndeed, this article could easily - and possibly should have - equate imitators to current AI (which tend to fail on deep knowledge, and - unlike experts - show inflexibility when challenged). Which is not to say that shallow knowledge (whether AI or human) is a bad thing. I'm very happy to be helped out by ChatGPT in places where I'd be in the shallow knowledge ('imitator') camp. Still, the limitations of current AI seem quite similar to the 'imitators' described here (noting that plenty of humans aren't above making stuff up either). reply doctorhandshake 52 minutes agoprevIn my line of work, clients are often looking for something new - something that hasn’t been done before or is at least substantially novel in important ways. I’ve noticed that the difference between neophytes and experts in my biz is that amateurs say ‘I’ve never done that before but how hard could it be?’, whereas experts say ‘I’ve never done that before but I assume it’s full of unknowns and traps.’ reply etbebl 36 minutes agoparentThere's something like this as well in academia or at least science: because only successful studies get published (the file drawer problem), it's easy for someone who's read a lot of papers but not gotten their hands dirty yet to think that a technique is much easier and less failure prone than it actually is. Of course it's necessary to try new things and every so often they succeed, but if there are 50 papers on some system and none of them have been able to answer a question that seems obviously important, there's probably a reason why. I realized this too late and am now dealing with the consequences as a senior grad student. reply yonz 1 hour agoprevI love fs.blog, a relevant one for this is the chauffeur test from https://fs.blog/two-types-of-knowledge/ reply upmind 22 minutes agoprev>> Imitators can’t answer questions at a deeper level Not sure about others but I feel like most engineers (I know) only learn what they need, are these engineers all imitators? How does one become an expert? reply nimbius 1 hour agoprev\"If you want the highest quality information, you have to speak to the best people.\" what a silly thing to say. High quality information is derived from accurate sources subjected to scientific rigor over time. The best people? Best at what? Character and competence arent the same. reply skilled 58 minutes agoparentHigh quality information comes from direct experience. reply g4zj 4 minutes agorootparentSo do anecdotes. How does one tell the difference? reply paulpauper 17 minutes agoparentprevHigh quality information withstands the test of practice or evidence. It's not time, as bad practices can still persist a long time. It's more like, what produces the best results. reply glutamate 1 hour agoprev\"In the beginner’s mind there are many possibilities, but in the expert’s there are few\" (Shunryū Suzuki) Not always bad not to be an expert. And it's fairly rich to start with an example from asset management, which is an industry that habitually mistakes luck for expertise. reply mikemitchelldev 1 hour agoprevI've heard some professors stop publishing once they receive tenure not wanting to risk losing the aura of being an expert with a low-quality research. reply a_wild_dandan 28 minutes agoparentA more charitable explanation: universities use publication frequency as a proxy for your academic worth. Once the \"publish or perish\" pressure is released, you can focus on paper quality over quantity. Given the fire hose of trivial academic publications filling up journals, that's good news for everyone. reply paulpauper 15 minutes agoparentprevtenure means you can just coast . the incentives are misaligned reply Joel_Mckay 22 minutes agoprevThe article is conflating buzzword laden hype-cycles with qualitative artifacts. It takes experience to recognize most software is still garbage, but more importantly determine which parts of the garbage heap is useful. The primary problem is the very definition of any unique terminology or product is distorted by the industry itself to fit a marketing niche. After a few years people sound like they had a stroke, and bought a Turbo Encabulator: https://www.youtube.com/watch?v=Ac7G7xOG2Ag reply paulpauper 19 minutes agoparentyeah I m not sure why that blog is so popular. A lot of its analysis is shallow and easily countered. It subscribes to a view that it's possible to reduce the world to logical heuristics. This works sometimes but often fails greatly too. reply paulpauper 30 minutes agoprevI have basically been an imitator my whole life...being reasonably good at approximating an expert in certain domains but never quite reaching the levels of true expertise--except for maybe one or two things. As Covid showed in which experts could not decide what policy, if any worked, or endless forecasts of recession/crisis that are worse than flipping a coin, the value of expertise in many respects is overrated anyway. Think of all the money managers who borrow their talking points from Warren Buffett. They might sound like Buffett, but they don’t know how to invest the way Buffett does. They’re imitators. Charlie Munger once commented: “It’s very hard to tell the difference between a good money manager and someone who just has the patter down.” The best ones will not take your money, or there is no easy way to invest (e.g. Renaissance Technologies) . the bad ones are practically begging for clients and spend lots of $ on advertising. Also, performance metrics... reply stanleykm 1 hour agoprevThis is better off as a linkedin post. reply Tao3300 44 minutes agoprevThis is an effect you see on Reddit a lot. The fitness sub used to have some pretty knowledgeable people in it, but over time it got clogged up with imitators who would just parrot answers from more credible accounts. It's one of the worst side effects of the dopamine rush from fake internet points. I haven't read it in probably a decade for that reason, but that's how it was at the time. reply paulpauper 16 minutes agoparentWhich fitness sub? there are so many of them reply cess11 47 minutes agoprevIt's just an ad? Anyway, doesn't work on me, I'm not afraid of not being able to tell bullshitters from people with experience, and I'm also not afraid of listening to bullshitters. As the Principia Discordia reminds us, \"bullshit makes the flowers grow, and that is beautiful\". reply swayvil 1 hour agoprevExperts may have a deep understanding etc but it's the imitators that you want to invite to the party. reply jdlshore 1 hour agoparentI think you’re implying that imitators are more interesting or fun, but I disagree. I’m in a field that became very popular and lucrative. It has far more imitators than experts. Some of them are interesting and fun, but a lot are shallow snake-oil salesmen. Namedropping and self-promotion abounds. reply thot_experiment 1 hour agoparentprev100% disagree, often I meet bullshitters and I think, well this is a person I would never invite to anything. reply Espressosaurus 1 hour agoparentprevWhy? reply yonz 1 hour agoparentprevParty maybe, your company hard no. reply demondemidi 1 hour agoprevnext [4 more] [flagged] flappyeagle 54 minutes agoparentWhy reply demondemidi 50 minutes agorootparentThe author barely eked out 500 words, claiming to be an authority on the subject, and offered brief platitudes and no depth. Literally what they are complaining about. The internet is just full of hastily written, vapid attempts at being an \"expert\" on something. lmfao. reply arp242 36 minutes agorootparentYour comment barely ekes out 45 words; offers brief platitudes and not depth. Literally what you are complaining about. The internet is just full of hastily written, vapid comments. lmfao. There ya go; I can be a dismissive cynical asshole too, attacking the mere form of your post without even spending a single word on the content. reply incognito124 2 hours agoprev [–] That was on a today's newsletter reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "The discussion contrasts experts with imitators, emphasizing that true expertise involves deep understanding and effective communication.",
      "Experts argue that the ability to explain complex topics in simple terms is crucial, highlighting the importance of good communication skills alongside technical knowledge.",
      "The conversation touches on the challenges experts face in conveying intricate concepts to laymen, using examples like programming languages Rust and Python to illustrate these difficulties."
    ],
    "points": 121,
    "commentCount": 59,
    "retryCount": 0,
    "time": 1718562798
  },
  {
    "id": 40695165,
    "title": "Making my first embedded Linux system",
    "originLink": "https://popovicu.com/posts/making-my-first-embedded-linux-system/",
    "originBody": "Follow @popovicu94 This post is the documentation of my journey to building my first Linux system. I started with no PCB experience whatsoever and I am here to document the journey to my Linux-ready PCB. The initial part of this text may seem somewhat off-topic, but I promise there is cohesion to all these sections, so please patiently read through the whole text. Table of contents Open Table of contents Don’t be scared! While I’m not claiming that my design is something that should immediately go into production and be used to manage the treatment of hospital patients, I do think my prototype at least boots and runs Linux and if you’re reading this article, that’s probably your only goal to start with. Once you go through this initial hurdle, you’ll have a much better idea of where to go next to indeed get to that production readiness. I’m sure as someone who is not a PCB expert I made a ton of rookie mistakes in my design for the Linux board, but it got the job done — and it was easier than I thought it would be. If you know some basics of electrical engineering, and you’re disciplined and can spare a few hours a day, I think you may be a single-digit number of days away from putting together a similar prototype that can boot Linux. I hope that’s encouraging and I hope this text makes you cross that journey much faster. Pre-reading If V = IR means nothing to you, probably you should take a step back and review the absolute basics of electric circuits. You should have some intuition around words like resistors, capacitors, and inductors before you proceed. That said, the rest of this text should be easy to follow with only the absolute basics in electronics (not that I know much more anyway). Off-the-shelf PCBs and hiding the details PCBs like Raspberry Pi are nice and popular, but if we just keep using them, especially by following the manufacturers’ basic tutorials, we probably don’t get much idea about how things work; and we need that knowledge to make our PCBs. My observation is that this is in particular true with microcontrollers, so we’ll use that as an example. First, let’s see what’s different with Linux, though. For example, if you use Raspberry Pi to boot Linux, or any other board, at some point, you will reach an area of familiar environment. No matter whether you’re on a full-blown desktop Linux or some tiny RPi image, you still see things like /dev and often run familiar commands like ls and so on. The reason for this is the stability of the API (ABI?) of the Linux system. Standardization like this doesn’t exist with the microcontrollers. When you load a sample code into an Arduino board, you may be going through a completely different journey compared to an STM32 Nucleo board. Not only is the process of loading the code different, but the methodology for writing the code itself can vary wildly. We see different IDEs and flows to do the same thing: write some C code to flicker LEDs. Sadly, the manufacturers indeed often corner us into using their customized flows (presumably to increase the vendor lock-in; consciously or otherwise, use your judgment and skepticism). Very first custom PCB board (not Linux-ready) After observing the above, I decided to make my own first PCB with some programmable digital logic on it and make it as simple as possible. First of all, what does it even mean to program the board? We write some code, compile it, send it over somehow to a chip that is capable of running the compiled machine code, and observe the effects. I won’t focus on writing and compiling the code, but rather, on what happens afterward. Booting a chip Thinking of some extremely simple microcontrollers, I asked myself — what happens when I power on a chip (no matter how I do it)? Where does it read the code from? And how does it give me a chance to give it some code in the first place? A few years ago, I was looking for the cheapest possible MCUs and ran into the Atmel ATtiny MCUs (the brand is now Microchip, I believe). You can get these MCUs for like $1 per piece, if not less. Now the question is, once we have this chip, but just the chip and nothing else around it, how do we get started with it? Surely it must be very simple with such a tiny chip. Conceptually, upon providing the power voltage, an ATtiny chip will inspect the state of its pins. If you satisfy certain conditions, such as setting some pins high or low, the chip will enter the programming mode. This mode then enables you to talk to the chip via some protocol, for example, SPI, and load its on-chip flash with some code. After you’re happy with the code you loaded, you can reset the chip, “unsatisfy” the programming conditions, and let the new code run. Usage of programmers (i.e. “enter the dragon”) If I’m on my computer, however, I don’t have any individual pins or wires poking out of it to do the above, let alone run something like SPI protocol. I probably have a bunch of USB ports, and a lot of pre-cooked PCBs connect to our computers via USB for programming, so that may be the right approach. However, I don’t have a board here, I just have my chip, so how do I go about programming over USB? ATtiny has SPI programming only, so something must bridge the gap between the USB and SPI. In the ATtiny case, there’s something called AVR Dragon that’s the solution to this problem. Image from the official AVR Dragon page This is a device that you can connect to your computer via USB and drive through some software on your computer to do the signal orchestration that we mentioned above. Once your computer commands the AVR Dragon to program the ATtiny chip, AVR Dragon will satisfy the programming conditions and run the protocol (e.g. SPI) with the chip itself to fill out the on-chip flash of the microcontroller with the compiled code. For the ATtiny use case, I was able to do the programming by connecting the Dragon and the MCU with a breadboard. Programming would fail until I figured out there’s a parameter to slow down the data rate of the code upload to the MCU, and once I did that, the breadboard setup worked just fine. All I had to do for the most part was hook up AVR Dragon’s SPI to my chip’s SPI. The dudes who program: avrdude We now have the hardware solution to the USB -> SPI dance, but what on our host computer would make this programming happen? There needs to be an application that would drive the messages on the USB port to the Dragon. In my case, I used avrdude. It’s an open-source application that can program various Atmel/Microchip chips, including the ATtiny series. One of the parameters to the avrdude is what kind of programming you’re doing. In my case, it was as simple as setting one of the flags to something like avr_dragon. With this, I was able to load up my ATtiny with some code, then power it down, put it on another breadboard, and flicker some LEDs. Great, so now I have a few important pieces of info if I were to do a PCB with ATtiny chips: I either program the chips like here, on a separate surface, and “drop” them into their operating environment, or… Expose SPI pins so that I can hook them up to an AVR Dragon. The latter has a somewhat obvious consequence if those same pins connect to something like LEDs, these can flicker as the Dragon is setting the pins high and low, but that’s not of huge importance here. What is a Dragon, and do I need it? Now that we unpacked the end-to-end programming flow for the ATtiny, we understand that the AVR Dragon doesn’t do anything extremely complicated — as long as we have some device that can send out some SPI messages to the chip, we can use that device as a programmer. Well, interestingly, avrdude can be used with a different flag value for the same flag that took in avr_dragon as the parameter. This value is meant to be used on Raspberry Pi and utilizes RPi’s GPIO pins to do the programming. A detailed write-up is here. Designing a PCB for ATtiny At this point, I have a simple way to program my ATtiny using a breadboard and AVR Dragon connected to my computer, though I could even eliminate the Dragon if I wanted to. My PCB goal now is to design a PCB where I have a socket in which I can plug a pre-programmed ATtiny. Once that PCB is powered on, some LEDs would flicker. This is an extremely simple PCB. You only need a DIP-8 socket, which replaces your breadboard’s holes, and a few PCB traces which replace the jumper wires from your breadboard prototype. My circuit will be powered by a single 5 V trace that goes into the chip, then 2 traces come out of the GPIOs to power the LEDs, and then there’s a GND trace everywhere to close the circuit. Here’s the result: And the actual PCB: So there are 2 parts of the design here: the schematic and the physical implementation. The schematic is your textbook-like logical model of the circuit. Once you design that, you will click a button in your tool with which you’ll get a blank PCB surface to organize your components and connect them. The schematic drives your work here and your EDA tool can use it to catch errors, e.g. if you’re trying to make connections that exist nowhere in your schematic. You can watch a somewhat lengthy absolute beginner 7-piece tutorial by Robert Feranec on building out your first PCB, though it can get fairly long. I’d say it’s worth at least just scanning through to see a knowledgeable person in action: Now that I’ve gone through this experiment successfully, I thought let’s just go all in and make an embedded Linux board. What goes into designing an embedded Linux system? There is a really good high-level article by Jay Carlson on getting started here, and you can find it on this link. If you’re already sold on ‘why embedded Linux’, you can skip a decent chunk of the intro text there and hop into the design workflow section. We’ll deal with something much simpler than a BGA package, though, and we’ll also skip complex bits like DDR routing since all our RAM will be on-chip within the SoC we’ll explore. We also won’t be mega disciplined about the signal integrity as all our components will run reasonably fast (slow?) and will be forgiving when it comes to design decisions. With that in mind, still read Jay’s article, and consider this article a gentler introduction to what Jay wrote about. Inspirational design As I wrote in the text on running Linux on $5 hardware, my inspiration for the first embedded Linux system was the business card that runs Linux. The fact that it’s a business card signaled to me it would be as simple as possible in its design and it would be the right design to study. The article’s author generously posted the schematic for the circuit design and understanding this was the first part of the journey. Designing the schematic There aren’t that many components in the inspirational design, and that seems right. After all, we have demonstrated it’s possible to boot and run Linux with just on-board flash plus an Allwinner SoC! Let’s break down the problem of designing the schematic and center it around the F1C100s SoC. Power supply As Jay Carlson mentioned and the inspirational design confirms, a Linux-ready SoC will need a couple of different voltages for the power supply. If we look at the F1C100s datasheet, we see the following: We see a couple of different voltages in the game, like VCC-IO, VDD-CORE, etc. 3.3 V seems to be the recommended voltage for a few values, so we can mark it right now that we’ll need that voltage on our board. We also see 2.5 V for VCC-DRAM and it’s also still within the OK values for AVCC. Let’s thus add 2.5 V to the list of voltages we need on-board. Finally, VDD-CORE has a pretty “tight” range, and we’ll add 1.1 V to our list. The Linux board can be powered from the USB host, meaning our board will connect over USB to another machine and source 5 V from there. If this seems a bit unfamiliar, please check out my recent text on building USB devices. That’s the only voltage we’ll have from “the external world” and we’ll need to equip our PCB with some components that can convert 5 V down to these values listed above. We’ll use voltage regulators for these, and we need 3 of them, one for each voltage needed. We’ll put some capacitors around these voltage regulators and the way you go about finding out what you should do there is you would open the datasheet for your voltage regulator and find a section that’s titled something like “typical application”. Crystal F1C100s needs some oscillation to be able to run at 24 MHz clock speed. Therefore, we need a 24 MHz crystal for that, and we’ll need some capacitors around it. Luckily, this is a well-known recipe. Please check out this page for this recipe (crystal + 2 capacitors). And yes, in my design, I also estimated Cstray at 5 pF. Decoupling capacitors We’ll need to put a bunch of decoupling capacitors around the voltage supply pins. Without talking too much outside the area of my expertise, I’ll just link to a few YouTube videos I found helpful on this topic. The first one will give you a very high-level idea of what these capacitors do: The next one is an awesome video on practical use cases from Zach Peterson: Finally, I also found this video from EEVblog useful to expand my intuition around this capacitor usage: I pretty much used a bunch of 100 nF decoupling capacitors all over the place. Connectors, pins and IO I powered the PCB via a USB connection (USB-micro connector on-board) and also used that same connection to fill up the onboard flash/RAM (more about it later). I’d say for this exercise, you’d want that the minimum. Other pins and connections you would add at this point are your choice. How do you want your PCB to interact with the outside world? Maybe you want to expose an I2C port, a UART port, or something else, it’s really up to you. One thing you may want to make your debugging easier is adding some LEDs, which should be easy. “FEL mode” button Going back to the article on running Linux on $5 hardware: FEL mode with F1C100s is very important to us. I’ll go through this again briefly in this article, but for now — I added a button that will ground the clock on the SPI flash which effectively takes it down. It may seem strange, but it makes life easier. SPI flash Something went wrong here. :) I wanted a 16 MB flash chip but ended up getting 2 MB only. Not sure if I messed up or the fabricator (with its documentation or otherwise), but it doesn’t matter, I managed to bail out here. The initial ramble about programming ATtiny is an important lesson here! More importantly, for now, there were a couple of things about the SPI flash: We want it to be big enough to store our Linux image and maybe even store some runtime data (optional). Ideally, we want it to be powered by a voltage that we already have on-board. 3.3 V should be doable. SVREF weirdness There was one very weird pin on the SoC called SVREF. The datasheet says nothing about this pin except that it exists. In this case, I just looked at what the other designs do here and copied the approach. For this particular thing, I just applied a simple resistor-based voltage divider (take a look at the schematic from the inspirational design, for example). Concrete components What we listed above is pretty much everything you need, high-level, to stitch together your Linux system. You do need, however, to figure out which components exactly you want to use in your design. For example, you want to use 100 nF decoupling capacitors, but there are tons of models out there that your fabricator can use, each with different characteristics (price included as a characteristic). Additionally, some of these components may be preferred by your fabricator, some of them may be added faster to your PCB, some of them may or may not be in stock, etc. In my case, I used JLCPCB and they call these “easier-to-use” parts basic parts. For the prototype, make sure the parts click together well. For example, if you use a resistor, make sure it can handle the current you’d be passing through it. Additionally, pay attention to the geometry as well, aka the footprints. The footprint is the space and connection layout for your component. You’ll see different designations for things like resistors. There are 0603 resistors, but they’re bigger than 0402 resistors. I used 0402 footprints for the most part, for both capacitors and resistors. Lastly, there’s a strong reason why I liked using EasyEDA for this exercise: they provide a massive library of components they can throw onto the PCB, along with the footprints. Very often PCB designers (as I understand, I’m not a PCB designer) spend time struggling with component datasheets and whatnot to establish what the exact footprints are and how to match them to the components they want to use — EasyEDA links very nicely with the JLCPCB fabrication process. Putting the schematic together Take a look at the schematic here. Caution: Please don’t expect a very readable schematic. :) Experienced PCB people will likely recoil after seeing it. It’s just a proof-of-concept and it’s hacky. On top of that, I’m most definitely not a PCB expert. I never really meant to share this schematic, but I guess it could still be useful to some of you. I’ll summarize below what is going on in this schematic: Most of the SoC pins are unconnected. The SoC itself is U1. U2, U3, and U4 are the voltage regulators to obtain those different voltages you need to power up the SoC. U5 is the SPI NOR flash memory. Again, check out the old article on $5 hardware Linux to figure out how to boot from here and so on. This memory can be “disabled” by holding the button U6 in the schematic, which grounds the clock signal. This enables you to restart the SoC and make it believe there is nothing to boot from, thus forcing it to enter the FEL mode. U7 is the reset switch. U8 and U9 are LED drivers. Total overkill, you can just hook up your LEDs to the GPIOs. The decoupling capacitors should be fairly easy to spot at this point (there are a lot of them). USB1 is the USB-micro connector, which both provides the raw 5 V to the voltage regulators and also gives you the differential pair you can route to the SoC for the USB communication. Check out the article on making USB devices to understand what’s going on here. X is the crystal and it follows the standard recipe for hooking up the crystal to the chip. L1 is the ferrite bead. As I understand, many times when you plug your USB into something like an outlet with a USB port, that 5 V can be noisy, and the ferrite bead helps. The rest is mostly just header pins to expose signals to the outer world. And that’s pretty much it! Routing the PCB Now that we have the schematic, it’s time to route things around and end up with a real piece of electronics. For me, a big challenge here was laying out these decoupling capacitors. They should be as close as possible to the SoC pins, per best practices (check out the videos from the above), but the SoC packaging makes things challenging here. I thought it was my lack of experience that kicked in here, but then I found a video from Phil’s Lab that goes into detail on this matter. Namely, this packaging is called a QFN package, and the pins here are quite dense, everything is pretty tiny. Even though those capacitors aren’t very big, they still cluster pretty fast around those SoC pins and things become difficult. This is when I decided to use a 4-layer PCB instead, per best practices shared by Phil. The video is below: The other part that may seem challenging here is the USB routing. However, we’re only going for USB 2.0 full-speed, which is very very forgiving. Again, refresh your knowledge of USB devices here, and don’t worry too much here. I just used EasyEDA’s differential pair routing from the USB-micro connector to the SoC. No need to pay too much attention to the trace width, and length, as long as it’s all reasonable (e.g. keep your trace length below 2 inches, I guess, and don’t use some weird width); things will just work. Everything else should be pretty much straightforward. I used the following layer stack up: signal-GND-power-signal. The top signal layer has a lot of GPIO traces, as well as the USB differential pair (from what I understand you shouldn’t hop through different layers when routing a differential pair). GND is just ground, the whole layer. In the power layer, I routed different voltages for powering the SoC with fairly thick traces. The bottom signal layer is mostly decoupling capacitors. I don’t think I should go into more detail on routing — I would probably give bad knowledge, so I’ll just stop here. Creating the software image Ideally, I should have created a custom device tree for this board, but I was lazy and wanted to see the results right away. For my running Linux on $5 hardware exercise, I created an image for Lichee Pi, which also doesn’t have much more than just SoC + flash, and I decided to use the same, it should just work. And it did work, but there was a catch — as I said, I somehow ended up with a 2 MB on-board flash instead of 16 MB as I originally intended. It would have been lots of work to slim down the image, and I just wanted to see something work. This is where the FEL mode shines and why it’s important to have something like that hacky button that disables on-board flash easily. I used the sunxi-fel tool to communicate with my SoC since it was directly exposed to my computer via the USB differential pair. One of the things that this tool can do for you is populate the RAM with some content and then boot up while preserving those contents. This is why I had that intro talk about programming ATtinys and figuring out what are the ways you can pipe the bytes into your chip and get it to run some code you want it to run. Therefore, instead of loading the U-boot FIT image from the on-board flash, I downloaded it from my computer and booted from that point. Linux worked just fine. To have more confidence my connection with the on-board flash works as intended, I could package the U-boot image and write it into the NOR flash storage, but putting Linux alongside that was tight. U-boot worked just fine, though. Conclusion This was an extremely hacky journey, but it satisfied a lot of my curiosity, and seeing the PCB come to life after all the studying and designing and waiting for the fabrication was a great feeling. I hope you feel the same joy once you put together your first embedded Linux system too. Good luck! Please consider following on Twitter/X and LinkedIn to stay updated.",
    "commentLink": "https://news.ycombinator.com/item?id=40695165",
    "commentBody": "Making my first embedded Linux system (popovicu.com)120 points by sam_bristow 13 hours agohidepastfavorite7 comments Neywiny 8 hours agoAs mentioned by another comment, the flash chosen a 16 Mbit according to Avnet's listing. Storage during component selection is pretty much always in bits, whereas consumers like bytes. That being said, the board should be reworkable to swap the flash. Other notes: 1. Differential routing was mentioned, but no mention of impedance. It's a short run so it's probably fine (I've run high speed over jumper wires before) but it should be noted. 2. There's merit to it being a very simple board, but an SD card connector may have saved the usability and likely really expanded what you can do with the system. 3. The workaround to load directly into DDR was good thinking. 4. Again understood for simplicity but LDO-ing almost 4V down for a core rail is unideal. I couldn't easily find specs on how much current will be taken on this (or any) rail, but just remember that every milliamp here is 4 milliwatts burned as heat. 5. Good to use a simple SoC like this. Integrating DDR and QFN show a real reverence for the challenges one can run into with modern LP5 and BGA parts. Really don't want that so early in the education. Overall good article, and good work reply dimman 11 hours agoprevWelcome to the world of embedded! :) As for the SPI flash size: they are almost always given in Mbit, so 16Mbit is 2MB hence the confusion if I were to guess. You would be looking for a 128Mbit one to get 16MB. Nice work and keep on tinkering! reply throwaway173738 4 hours agoprevHaving used a ton of vendor Linux BSPs over the years, I can say that often they’re not trying to lock you in to a particular approach when they describe how to EG blink an led. Rather they’re demonstrating that it can be done somehow. Every vendor expects you to take their demo code, evaluate it, and make decisions on your own to get to a working system. I’ve seen a lot of employers get into trouble over the years by shipping the vendor’s code unmodified. Even for LED blinking I might use the vendor’s code as a jumping off point and use the LED subsystem to implement different blink rates. But if I’m using EG a TI AM3359 I might want to go the direct register route instead of the LED is used by the real time coprocessor instead in my application. Usually more hands-on distributors like Arrow have Application Support Engineers who can advise for a particular board so you’re not stuck crawling vendor message boards for advice. reply nrclark 4 hours agoprevFor the curious - it looks like this uses the Allwinner F1C100S, which is a 533MHz single-core ARMv7 with 32MB of onboard DRAM. What other parts are out there that are similar to this? It would be fun to play with one that has a little more RAM, and maybe a faster clock rate. reply dragontamer 4 hours agoparentMicrochips SAM9x60D1G is 128MByte / 1Gbit of onboard DRAM on package. Single core lol ARMv5 because I assume someone out there still wants Jazelle or something? Updated to 600MHz. More recent SAM9x75 is 800MHz but still ARMv5. So Microchip coming in with all the ARMv5 that the market wants today! reply not_the_fda 4 hours agoparentprevThe F1C200s has 64MB of RAM, but usually these class of processors move to external RAM. If you are willing to move to external RAM the iMX6 line is a great processor. Up to 1Ghz, eMMC, some have a GPU. Really great Linux support and documentation. reply lemonlime0x3C33 7 hours agoprev [–] I think your PCB schematic looks great, especially for your first design! It is quite readable :) I also started with easyEDA for my first few PCB's, it is very intuitive. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The post details the author's journey of building a Linux system from scratch, starting with no prior PCB (Printed Circuit Board) experience.",
      "Key steps include programming microcontrollers like the Atmel ATtiny, designing a custom PCB, and creating an embedded Linux board using the F1C100s SoC (System on Chip).",
      "The project involved using tools like avrdude for programming, a 4-layer PCB for complex routing, and adapting a Lichee Pi software image for the custom board."
    ],
    "commentSummary": [
      "A user shared their experience creating their first embedded Linux system, sparking a discussion on technical details and improvements.",
      "Key points include the use of a 16 Mbit flash, differential routing, and the potential benefits of adding an SD card connector.",
      "The project utilized the Allwinner F1C100S, a 533MHz single-core ARMv7 with 32MB of onboard DRAM, prompting comparisons with other similar processors."
    ],
    "points": 120,
    "commentCount": 7,
    "retryCount": 0,
    "time": 1718520685
  },
  {
    "id": 40693787,
    "title": "A collection of 2,299 blogs about every topic",
    "originLink": "https://ooh.directory/",
    "originBody": "🎨 Arts and media (883) Architecture Books Design Games Music 🧑💻 Computers, internet, tech (381) Hardware Internet Web development 🌍 Countries, states, towns, etc. (121) London UK USA 💰 Economics and business (80) BBC Economics Management 🎓 Education (38) ⚖ Government, politics and law (59) Law Military Politics 📚 Humanities (167) Futures Geography History Language 😀 Personal blogs (358) 💃 Recreation (239) Food & drink Sport & exercise Travel 🧪 Science (141) Earth science Mathematics Space 🧑🤝🧑 Society (44) Death & graves Psychogeography Religion ❓ Uncategorizable blogs (41) Completionist blogs 🔔 First post in over eight months! Hellbox · Type : Writing, 10 hours ago, more info On Ligatures Typographic glyphs have their moments. The @ symbol was barely used before it became indispensable for email and social media. The creation of the single European currency saw thousands of fonts being reissued to include € at the turn of the century. It’s likely that some crypto-boosters are hoping this will happen again, and the […] By Benjamin Campbell, 58 words Recently added blogs Or see recently updated blogs Hold Fast Bespoke Blog Stay abreast of what's happening in my midcoast Maine workroom. This is where I share a glimpse into the world of bespoke tailoring. 🇺🇸 More info Updated 2 weeks ago BLAKE GOPNIK on art 🇺🇸 More info Updated 2 days ago Orange Crate Art “It goes idea by idea”. By Michael Leddy. 🇺🇸 More info Updated 7 hours ago St. John's Wort Beery Musings And Amusing Beers. By Jordan St. John. 🇨🇦 More info Updated 3 weeks ago ht.xyz - Blog posts I'm passionate about creativity, storytelling, and technology, and this website is my nook on the internet to express that passion. By Hitarth Thummar. 🇮🇳 More info Updated 3 weeks ago Jamie Lord Solution Architect at CDS, based in Nottingham, UK, using Azure and C# to build awesome projects. 🇬🇧 More info Updated a week ago aows — black and white photography Film & Digital Monochrome Photography. By Adrian Vila. 🇺🇸 More info Updated 23 hours ago Flashing Palely in the Margins An epistolarian, anthropologist, urban explorer, and over-user of the discretionary comma. By Sameer Vasta. 🇨🇦 More info Updated 3 weeks ago Silvia Maggi - Designer I write about design, technology, their effects on our lives, photography, and more. I curate the inspiration series Design, Digested. 🇬🇧 More info Updated a week ago Paweł U. Ruby on Rails Web Development Consultant Full Stack Blog. By Paweł Urbanek. 🇵🇱 More info Updated 5 days ago Happiness MachinesEntries Technical and not-so technical articles I write. By Ignacio Brasca. 🇦🇷 More info Updated 4 weeks ago Pants On Fire The questionable activities of William J. Denby and his band of grifters in the city of Kawartha Lakes, Ontario, Canada. 🇨🇦 More info Updated a day ago atmtx photo blog For the Love of Photography + Stories + Gear. By Andy. 🇺🇸 More info Updated 17 hours ago Shoegazing.com One of the largest blogs in the world on quality shoes, mainly welted footwear. Articles on shoe care, shoe construction, buying guides and more. By Jesper Ingevaldsson. 🇸🇪 More info Updated 10 hours ago Seven Out Of Ten A personal writing project about video games, music and other things I’m interested in. By Liam Richardson. More info Updated a week ago See more, or see recently updated blogs ooh.directory is a place to find good blogs that interest you. Find out more… 🤷🏻 See random blogs! Latest site blog posts TypePad feeds are back (2024-01-17) A page for every blog (2024-01-07) Subscribe to site blog by email Enter your email Subscribe ✉ Find out more… Follow for site updates 🦣 Mastodon RSS feeds Recently added blogs Site blog posts",
    "commentLink": "https://news.ycombinator.com/item?id=40693787",
    "commentBody": "A collection of 2,299 blogs about every topic (ooh.directory)116 points by raytopia 20 hours agohidepastfavorite17 comments nativeit 16 hours agoThis reminds of the World Wide Web circa 1993. Yahoo was a kind of categorized link directory. reply newzisforsukas 16 hours agoparenthttps://en.wikipedia.org/wiki/Yahoo!_Directory https://web.archive.org/web/20141122194515/https://dir.yahoo... reply gofreddygo 8 hours agorootparentI never really used anything pre-google so I dont have enough context. The yahoo directory page, i found, is very useful for discovery. I spent a good amount of time digging into sub-directories of recent interest for example [0] and found the limited number of links very very refreshing and of high quality. Links work, no ads, and i skipped what i did not think useful without fatigue. 10 mins later, i learned something new. Google search for the same topic lends 2 screen fulls of ads and a popup asking for permission for my location and then this[1] garbage. 10 mins later, I had just spent time avoiding ads and paid content slop. A very basic example of why \"google it\" isn't a great tool for discoverability any more. Simpler tools, better outcomes. A modern looking, but fundamentally same concept of a categorized, curated directory could very well be an improvement over the current state of affairs. [0]: https://web.archive.org/web/20141122222807/https://dir.yahoo... [1]: https://www.google.com/search?q=homeschooling reply beardyw 12 hours agoparentprevYes, exactly what I thought. reply zakhar 16 hours agoprevPrevious discussion (Nov 2022): https://news.ycombinator.com/item?id=33719983 reply penguin_booze 10 hours agoprevHow do people make use of such an aggregator? Do people checkout blogs individually and subscribe to feeds to individual blogs or interest? The sheer number of the collection dissuades me. I'm wondering, instead, if it'd be useful for the aggregator to offer an aggregated feed itself, but that might be too rand om a feed and subjects! reply manuelmoreale 14 hours agoprevSuch a great resource.It’s incredibly valuable for me personally since I’m always hunting for new blogs and new people to interview for my series. I also interviewed Phil, the creator of ooh back in February: https://manuelmoreale.com/pb-phil-gyford reply smetj 11 hours agoprevAbsolutely awesome ... an oasis in a hostile desert. We needs more webrings and curated link portals (which this essentially is) ... Thank you devs! reply rhelz 17 hours agoprevFascinating. Search engines are so bad, that we are going back to the pre-search engine era of pages of hand-curated links. reply bigtunacan 16 hours agoparentAt this point it may be necessary. All of the search engines are essentially the same now and all you can find are mostly a handful of curated e-commerce sites. The \"wide\" part of the web has all but disappeared. reply riffraff 15 hours agorootparentThis is true for stuff that can be sold, but for example my personal blog has most search traffic going to a page about a cartoon theme song. People still rely on search engines for a bunch of things beyond \"best phone 2024\". reply ekianjo 16 hours agoparentprevwith the explosion of AI generated content to meet SEO criteria that may be the only way to have proper access to real content reply theendisney4 17 hours agoprevI would love an opml with everything. reply some_furry 17 hours agoprevhttps://ooh.directory/search/?q=furry Ah damn, I'm the only one so far? reply hifikuno 15 hours agoparentSomeone's gotta be first. You're paving the way for others! reply Takennickname 11 hours agoparentprevAfaic, that's one too many reply yesbut 17 hours agoprev [–] Guess they aren't a fan of fuzz pedals: https://ooh.directory/search/?q=big+muff reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [],
    "commentSummary": [
      "A new collection of 2,299 blogs on various topics has been launched on ooh.directory, reminiscent of early web directories like Yahoo's categorized link directory.",
      "Users appreciate the curated nature of the directory, which improves discoverability compared to ad-filled search engines.",
      "The directory is seen as a valuable resource for finding new blogs and interviewees, especially in an era where AI-generated content is prevalent."
    ],
    "points": 116,
    "commentCount": 17,
    "retryCount": 0,
    "time": 1718498525
  }
]
