[
  {
    "id": 39386156,
    "title": "Sora: OpenAI's AI Model Generates Realistic Videos from Text",
    "originLink": "https://openai.com/sora",
    "originBody": "Close SearchSubmit Skip to main content Site Navigation Research Overview Index GPT-4 DALL·E 3 Sora API Overview Pricing Docs ChatGPT Overview Team Enterprise Pricing Try ChatGPT Safety Company About Blog Careers Residency Charter Security Customer stories Search Navigation quick links Log in Try ChatGPT Menu Mobile Navigation Close Site Navigation Research Overview Index GPT-4 DALL·E 3 Sora API Overview Pricing Docs ChatGPT Overview Team Enterprise Pricing Try ChatGPT Safety Company About Blog Careers Residency Charter Security Customer stories Quick Links Log in Try ChatGPT SearchSubmit Capabilities Safety Research Sora Creating video from text Sora is an AI model that can create realistic and imaginative scenes from text instructions. Read technical report All videos on this page were generated directly by Sora without modification. Play We’re teaching AI to understand and simulate the physical world in motion, with the goal of training models that help people solve problems that require real-world interaction. Introducing Sora, our text-to-video model. Sora can generate videos up to a minute long while maintaining visual quality and adherence to the user’s prompt. 1 of 9 Prompt: A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse. She wears sunglasses and red lipstick. She walks confidently and casually. The street is damp and reflective, creating a mirror effect of the colorful lights. Many pedestrians walk about.Prompt: A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse. She wears sunglasses and red lipstick. She walks confidently and casually. The street is damp and reflective, creating a mirror effect of the colorful lights. Many pedestrians walk about. 0:00 / 0:00 Prompt: Several giant wooly mammoths approach treading through a snowy meadow, their long wooly fur lightly blows in the wind as they walk, snow covered trees and dramatic snow capped mountains in the distance, mid afternoon light with wispy clouds and a sun high in the distance creates a warm glow, the low camera view is stunning capturing the large furry mammal with beautiful photography, depth of field.Prompt: Several giant wooly mammoths approach treading through a snowy meadow, their long wooly fur lightly blows in the wind as they walk, snow covered trees and dramatic snow capped mountains in the distance, mid afternoon light with wispy clouds and a sun high in the distance creates a warm glow, the low camera view is stunning capturing the large furry mammal with beautiful photography, depth of field. 0:00 / 0:00 Prompt: A movie trailer featuring the adventures of the 30 year old space man wearing a red wool knitted motorcycle helmet, blue sky, salt desert, cinematic style, shot on 35mm film, vivid colors.Prompt: A movie trailer featuring the adventures of the 30 year old space man wearing a red wool knitted motorcycle helmet, blue sky, salt desert, cinematic style, shot on 35mm film, vivid colors. 0:00 / 0:00 Prompt: Drone view of waves crashing against the rugged cliffs along Big Sur’s garay point beach. The crashing blue waters create white-tipped waves, while the golden light of the setting sun illuminates the rocky shore. A small island with a lighthouse sits in the distance, and green shrubbery covers the cliff’s edge. The steep drop from the road down to the beach is a dramatic feat, with the cliff’s edges jutting out over the sea. This is a view that captures the raw beauty of the coast and the rugged landscape of the Pacific Coast Highway.Prompt: Drone view of waves crashing against the rugged cliffs along Big Sur’s garay point beach. The crashing blue waters create white-tipped waves, while the golden light of the setting sun illuminates the rocky shore. A small island with a lighthouse sits in the distance, and green shrubbery covers the cliff’s edge. The steep drop from the road down to the beach is a dramatic feat, with the cliff’s edges jutting out over the sea. This is a view that captures the raw beauty of the coast and the rugged landscape of the Pacific Coast Highway. 0:00 / 0:00 Prompt: Animated scene features a close-up of a short fluffy monster kneeling beside a melting red candle. The art style is 3D and realistic, with a focus on lighting and texture. The mood of the painting is one of wonder and curiosity, as the monster gazes at the flame with wide eyes and open mouth. Its pose and expression convey a sense of innocence and playfulness, as if it is exploring the world around it for the first time. The use of warm colors and dramatic lighting further enhances the cozy atmosphere of the image.Prompt: Animated scene features a close-up of a short fluffy monster kneeling beside a melting red candle. The art style is 3D and realistic, with a focus on lighting and texture. The mood of the painting is one of wonder and curiosity, as the monster gazes at the flame with wide eyes and open mouth. Its pose and expression convey a sense of innocence and playfulness, as if it is exploring the world around it for the first time. The use of warm colors and dramatic lighting further enhances the cozy atmosphere of the image. 0:00 / 0:00 Prompt: A gorgeously rendered papercraft world of a coral reef, rife with colorful fish and sea creatures.Prompt: A gorgeously rendered papercraft world of a coral reef, rife with colorful fish and sea creatures. 0:00 / 0:00 Prompt: This close-up shot of a Victoria crowned pigeon showcases its striking blue plumage and red chest. Its crest is made of delicate, lacy feathers, while its eye is a striking red color. The bird’s head is tilted slightly to the side, giving the impression of it looking regal and majestic. The background is blurred, drawing attention to the bird’s striking appearance.Prompt: This close-up shot of a Victoria crowned pigeon showcases its striking blue plumage and red chest. Its crest is made of delicate, lacy feathers, while its eye is a striking red color. The bird’s head is tilted slightly to the side, giving the impression of it looking regal and majestic. The background is blurred, drawing attention to the bird’s striking appearance. 0:00 / 0:00 Prompt: Photorealistic closeup video of two pirate ships battling each other as they sail inside a cup of coffee.Prompt: Photorealistic closeup video of two pirate ships battling each other as they sail inside a cup of coffee. 0:00 / 0:00 Prompt: A young man at his 20s is sitting on a piece of cloud in the sky, reading a book.Prompt: A young man at his 20s is sitting on a piece of cloud in the sky, reading a book. 0:00 / 0:00 Today, Sora is becoming available to red teamers to assess critical areas for harms or risks. We are also granting access to a number of visual artists, designers, and filmmakers to gain feedback on how to advance the model to be most helpful for creative professionals. We’re sharing our research progress early to start working with and getting feedback from people outside of OpenAI and to give the public a sense of what AI capabilities are on the horizon. 1 of 8 Prompt: Historical footage of California during the gold rush.Prompt: Historical footage of California during the gold rush. 0:00 / 0:00 Prompt: A close up view of a glass sphere that has a zen garden within it. There is a small dwarf in the sphere who is raking the zen garden and creating patterns in the sand.Prompt: A close up view of a glass sphere that has a zen garden within it. There is a small dwarf in the sphere who is raking the zen garden and creating patterns in the sand. 0:00 / 0:00 Prompt: Extreme close up of a 24 year old woman’s eye blinking, standing in Marrakech during magic hour, cinematic film shot in 70mm, depth of field, vivid colors, cinematicPrompt: Extreme close up of a 24 year old woman’s eye blinking, standing in Marrakech during magic hour, cinematic film shot in 70mm, depth of field, vivid colors, cinematic 0:00 / 0:00 Prompt: A cartoon kangaroo disco dances.Prompt: A cartoon kangaroo disco dances. 0:00 / 0:00 Prompt: A beautiful homemade video showing the people of Lagos, Nigeria in the year 2056. Shot with a mobile phone camera.Prompt: A beautiful homemade video showing the people of Lagos, Nigeria in the year 2056. Shot with a mobile phone camera. 0:00 / 0:00 Prompt: A petri dish with a bamboo forest growing within it that has tiny red pandas running around.Prompt: A petri dish with a bamboo forest growing within it that has tiny red pandas running around. 0:00 / 0:00 Prompt: The camera rotates around a large stack of vintage televisions all showing different programs — 1950s sci-fi movies, horror movies, news, static, a 1970s sitcom, etc, set inside a large New York museum gallery.Prompt: The camera rotates around a large stack of vintage televisions all showing different programs — 1950s sci-fi movies, horror movies, news, static, a 1970s sitcom, etc, set inside a large New York museum gallery. 0:00 / 0:00 Prompt: 3D animation of a small, round, fluffy creature with big, expressive eyes explores a vibrant, enchanted forest. The creature, a whimsical blend of a rabbit and a squirrel, has soft blue fur and a bushy, striped tail. It hops along a sparkling stream, its eyes wide with wonder. The forest is alive with magical elements: flowers that glow and change colors, trees with leaves in shades of purple and silver, and small floating lights that resemble fireflies. The creature stops to interact playfully with a group of tiny, fairy-like beings dancing around a mushroom ring. The creature looks up in awe at a large, glowing tree that seems to be the heart of the forest.Prompt: 3D animation of a small, round, fluffy creature with big, expressive eyes explores a vibrant, enchanted forest. The creature, a whimsical blend of a rabbit and a squirrel, has soft blue fur and a bushy, striped tail. It hops along a sparkling stream, its eyes wide with wonder. The forest is alive with magical elements: flowers that glow and change colors, trees with leaves in shades of purple and silver, and small floating lights that resemble fireflies. The creature stops to interact playfully with a group of tiny, fairy-like beings dancing around a mushroom ring. The creature looks up in awe at a large, glowing tree that seems to be the heart of the forest. 0:00 / 0:00 Sora is able to generate complex scenes with multiple characters, specific types of motion, and accurate details of the subject and background. The model understands not only what the user has asked for in the prompt, but also how those things exist in the physical world. 1 of 8 Prompt: The camera follows behind a white vintage SUV with a black roof rack as it speeds up a steep dirt road surrounded by pine trees on a steep mountain slope, dust kicks up from it’s tires, the sunlight shines on the SUV as it speeds along the dirt road, casting a warm glow over the scene. The dirt road curves gently into the distance, with no other cars or vehicles in sight. The trees on either side of the road are redwoods, with patches of greenery scattered throughout. The car is seen from the rear following the curve with ease, making it seem as if it is on a rugged drive through the rugged terrain. The dirt road itself is surrounded by steep hills and mountains, with a clear blue sky above with wispy clouds.Prompt: The camera follows behind a white vintage SUV with a black roof rack as it speeds up a steep dirt road surrounded by pine trees on a steep mountain slope, dust kicks up from it’s tires, the sunlight shines on the SUV as it speeds along the dirt road, casting a warm glow over the scene. The dirt road curves gently into the distance, with no other cars or vehicles in sight. The trees on either side of the road are redwoods, with patches of greenery scattered throughout. The car is seen from the rear following the curve with ease, making it seem as if it is on a rugged drive through the rugged terrain. The dirt road itself is surrounded by steep hills and mountains, with a clear blue sky above with wispy clouds. 0:00 / 0:00 Prompt: Reflections in the window of a train traveling through the Tokyo suburbs.Prompt: Reflections in the window of a train traveling through the Tokyo suburbs. 0:00 / 0:00 Prompt: A drone camera circles around a beautiful historic church built on a rocky outcropping along the Amalfi Coast, the view showcases historic and magnificent architectural details and tiered pathways and patios, waves are seen crashing against the rocks below as the view overlooks the horizon of the coastal waters and hilly landscapes of the Amalfi Coast Italy, several distant people are seen walking and enjoying vistas on patios of the dramatic ocean views, the warm glow of the afternoon sun creates a magical and romantic feeling to the scene, the view is stunning captured with beautiful photography.Prompt: A drone camera circles around a beautiful historic church built on a rocky outcropping along the Amalfi Coast, the view showcases historic and magnificent architectural details and tiered pathways and patios, waves are seen crashing against the rocks below as the view overlooks the horizon of the coastal waters and hilly landscapes of the Amalfi Coast Italy, several distant people are seen walking and enjoying vistas on patios of the dramatic ocean views, the warm glow of the afternoon sun creates a magical and romantic feeling to the scene, the view is stunning captured with beautiful photography. 0:00 / 0:00 Prompt: A large orange octopus is seen resting on the bottom of the ocean floor, blending in with the sandy and rocky terrain. Its tentacles are spread out around its body, and its eyes are closed. The octopus is unaware of a king crab that is crawling towards it from behind a rock, its claws raised and ready to attack. The crab is brown and spiny, with long legs and antennae. The scene is captured from a wide angle, showing the vastness and depth of the ocean. The water is clear and blue, with rays of sunlight filtering through. The shot is sharp and crisp, with a high dynamic range. The octopus and the crab are in focus, while the background is slightly blurred, creating a depth of field effect.Prompt: A large orange octopus is seen resting on the bottom of the ocean floor, blending in with the sandy and rocky terrain. Its tentacles are spread out around its body, and its eyes are closed. The octopus is unaware of a king crab that is crawling towards it from behind a rock, its claws raised and ready to attack. The crab is brown and spiny, with long legs and antennae. The scene is captured from a wide angle, showing the vastness and depth of the ocean. The water is clear and blue, with rays of sunlight filtering through. The shot is sharp and crisp, with a high dynamic range. The octopus and the crab are in focus, while the background is slightly blurred, creating a depth of field effect. 0:00 / 0:00 Prompt: A flock of paper airplanes flutters through a dense jungle, weaving around trees as if they were migrating birds.Prompt: A flock of paper airplanes flutters through a dense jungle, weaving around trees as if they were migrating birds. 0:00 / 0:00 Prompt: A cat waking up its sleeping owner demanding breakfast. The owner tries to ignore the cat, but the cat tries new tactics and finally the owner pulls out a secret stash of treats from under the pillow to hold the cat off a little longer.Prompt: A cat waking up its sleeping owner demanding breakfast. The owner tries to ignore the cat, but the cat tries new tactics and finally the owner pulls out a secret stash of treats from under the pillow to hold the cat off a little longer. 0:00 / 0:00 Prompt: Borneo wildlife on the Kinabatangan RiverPrompt: Borneo wildlife on the Kinabatangan River 0:00 / 0:00 Prompt: A Chinese Lunar New Year celebration video with Chinese Dragon.Prompt: A Chinese Lunar New Year celebration video with Chinese Dragon. 0:00 / 0:00 The model has a deep understanding of language, enabling it to accurately interpret prompts and generate compelling characters that express vibrant emotions. Sora can also create multiple shots within a single generated video that accurately persist characters and visual style. 1 of 8 Prompt: Tour of an art gallery with many beautiful works of art in different styles.Prompt: Tour of an art gallery with many beautiful works of art in different styles. 0:00 / 0:00 Prompt: Beautiful, snowy Tokyo city is bustling. The camera moves through the bustling city street, following several people enjoying the beautiful snowy weather and shopping at nearby stalls. Gorgeous sakura petals are flying through the wind along with snowflakes.Prompt: Beautiful, snowy Tokyo city is bustling. The camera moves through the bustling city street, following several people enjoying the beautiful snowy weather and shopping at nearby stalls. Gorgeous sakura petals are flying through the wind along with snowflakes. 0:00 / 0:00 Prompt: A stop motion animation of a flower growing out of the windowsill of a suburban house.Prompt: A stop motion animation of a flower growing out of the windowsill of a suburban house. 0:00 / 0:00 Prompt: The story of a robot’s life in a cyberpunk setting.Prompt: The story of a robot’s life in a cyberpunk setting. 0:00 / 0:00 Prompt: An extreme close-up of an gray-haired man with a beard in his 60s, he is deep in thought pondering the history of the universe as he sits at a cafe in Paris, his eyes focus on people offscreen as they walk as he sits mostly motionless, he is dressed in a wool coat suit coat with a button-down shirt , he wears a brown beret and glasses and has a very professorial appearance, and the end he offers a subtle closed-mouth smile as if he found the answer to the mystery of life, the lighting is very cinematic with the golden light and the Parisian streets and city in the background, depth of field, cinematic 35mm film.Prompt: An extreme close-up of an gray-haired man with a beard in his 60s, he is deep in thought pondering the history of the universe as he sits at a cafe in Paris, his eyes focus on people offscreen as they walk as he sits mostly motionless, he is dressed in a wool coat suit coat with a button-down shirt , he wears a brown beret and glasses and has a very professorial appearance, and the end he offers a subtle closed-mouth smile as if he found the answer to the mystery of life, the lighting is very cinematic with the golden light and the Parisian streets and city in the background, depth of field, cinematic 35mm film. 0:00 / 0:00 Prompt: A beautiful silhouette animation shows a wolf howling at the moon, feeling lonely, until it finds its pack.Prompt: A beautiful silhouette animation shows a wolf howling at the moon, feeling lonely, until it finds its pack. 0:00 / 0:00 Prompt: New York City submerged like Atlantis. Fish, whales, sea turtles and sharks swim through the streets of New York.Prompt: New York City submerged like Atlantis. Fish, whales, sea turtles and sharks swim through the streets of New York. 0:00 / 0:00 Prompt: A litter of golden retriever puppies playing in the snow. Their heads pop out of the snow, covered in.Prompt: A litter of golden retriever puppies playing in the snow. Their heads pop out of the snow, covered in. 0:00 / 0:00 The current model has weaknesses. It may struggle with accurately simulating the physics of a complex scene, and may not understand specific instances of cause and effect. For example, a person might take a bite out of a cookie, but afterward, the cookie may not have a bite mark. The model may also confuse spatial details of a prompt, for example, mixing up left and right, and may struggle with precise descriptions of events that take place over time, like following a specific camera trajectory. 1 of 5 Prompt: Step-printing scene of a person running, cinematic film shot in 35mm.Prompt: Step-printing scene of a person running, cinematic film shot in 35mm. Weakness: Sora sometimes creates physically implausible motion. 0:00 / 0:00 Prompt: Five gray wolf pups frolicking and chasing each other around a remote gravel road, surrounded by grass. The pups run and leap, chasing each other, and nipping at each other, playing.Prompt: Five gray wolf pups frolicking and chasing each other around a remote gravel road, surrounded by grass. The pups run and leap, chasing each other, and nipping at each other, playing. Weakness: Animals or people can spontaneously appear, especially in scenes containing many entities. 0:00 / 0:00 Prompt: Basketball through hoop then explodes.Prompt: Basketball through hoop then explodes. Weakness: An example of inaccurate physical modeling and unnatural object “morphing.” 0:00 / 0:00 Prompt: Archeologists discover a generic plastic chair in the desert, excavating and dusting it with great care.Prompt: Archeologists discover a generic plastic chair in the desert, excavating and dusting it with great care. Weakness: In this example, Sora fails to model the chair as a rigid object, leading to inaccurate physical interactions. 0:00 / 0:00 Prompt: A grandmother with neatly combed grey hair stands behind a colorful birthday cake with numerous candles at a wood dining room table, expression is one of pure joy and happiness, with a happy glow in her eye. She leans forward and blows out the candles with a gentle puff, the cake has pink frosting and sprinkles and the candles cease to flicker, the grandmother wears a light blue blouse adorned with floral patterns, several happy friends and family sitting at the table can be seen celebrating, out of focus. The scene is beautifully captured, cinematic, showing a 3/4 view of the grandmother and the dining room. Warm color tones and soft lighting enhance the mood..Prompt: A grandmother with neatly combed grey hair stands behind a colorful birthday cake with numerous candles at a wood dining room table, expression is one of pure joy and happiness, with a happy glow in her eye. She leans forward and blows out the candles with a gentle puff, the cake has pink frosting and sprinkles and the candles cease to flicker, the grandmother wears a light blue blouse adorned with floral patterns, several happy friends and family sitting at the table can be seen celebrating, out of focus. The scene is beautifully captured, cinematic, showing a 3/4 view of the grandmother and the dining room. Warm color tones and soft lighting enhance the mood.. Weakness: Simulating complex interactions between objects and multiple characters is often challenging for the model, sometimes resulting in humorous generations. 0:00 / 0:00 Safety We’ll be taking several important safety steps ahead of making Sora available in OpenAI’s products. We are working with red teamers — domain experts in areas like misinformation, hateful content, and bias — who will be adversarially testing the model. We’re also building tools to help detect misleading content such as a detection classifier that can tell when a video was generated by Sora. We plan to include C2PA metadata in the future if we deploy the model in an OpenAI product. In addition to us developing new techniques to prepare for deployment, we’re leveraging the existing safety methods that we built for our products that use DALL·E 3, which are applicable to Sora as well. For example, once in an OpenAI product, our text classifier will check and reject text input prompts that are in violation of our usage policies, like those that request extreme violence, sexual content, hateful imagery, celebrity likeness, or the IP of others. We’ve also developed robust image classifiers that are used to review the frames of every video generated to help ensure that it adheres to our usage policies, before it’s shown to the user. We’ll be engaging policymakers, educators and artists around the world to understand their concerns and to identify positive use cases for this new technology. Despite extensive research and testing, we cannot predict all of the beneficial ways people will use our technology, nor all the ways people will abuse it. That’s why we believe that learning from real-world use is a critical component of creating and releasing increasingly safe AI systems over time. 1 of 10 Prompt: The camera directly faces colorful buildings in burano italy. An adorable dalmation looks through a window on a building on the ground floor. Many people are walking and cycling along the canal streets in front of the buildings.Prompt: The camera directly faces colorful buildings in burano italy. An adorable dalmation looks through a window on a building on the ground floor. Many people are walking and cycling along the canal streets in front of the buildings. 0:00 / 0:00 Prompt: An adorable happy otter confidently stands on a surfboard wearing a yellow lifejacket, riding along turquoise tropical waters near lush tropical islands, 3D digital render art style.Prompt: An adorable happy otter confidently stands on a surfboard wearing a yellow lifejacket, riding along turquoise tropical waters near lush tropical islands, 3D digital render art style. 0:00 / 0:00 Prompt: This close-up shot of a chameleon showcases its striking color changing capabilities. The background is blurred, drawing attention to the animal’s striking appearance.Prompt: This close-up shot of a chameleon showcases its striking color changing capabilities. The background is blurred, drawing attention to the animal’s striking appearance. 0:00 / 0:00 Prompt: A corgi vlogging itself in tropical Maui.Prompt: A corgi vlogging itself in tropical Maui. 0:00 / 0:00 Prompt: A white and orange tabby cat is seen happily darting through a dense garden, as if chasing something. Its eyes are wide and happy as it jogs forward, scanning the branches, flowers, and leaves as it walks. The path is narrow as it makes its way between all the plants. the scene is captured from a ground-level angle, following the cat closely, giving a low and intimate perspective. The image is cinematic with warm tones and a grainy texture. The scattered daylight between the leaves and plants above creates a warm contrast, accentuating the cat’s orange fur. The shot is clear and sharp, with a shallow depth of field.Prompt: A white and orange tabby cat is seen happily darting through a dense garden, as if chasing something. Its eyes are wide and happy as it jogs forward, scanning the branches, flowers, and leaves as it walks. The path is narrow as it makes its way between all the plants. the scene is captured from a ground-level angle, following the cat closely, giving a low and intimate perspective. The image is cinematic with warm tones and a grainy texture. The scattered daylight between the leaves and plants above creates a warm contrast, accentuating the cat’s orange fur. The shot is clear and sharp, with a shallow depth of field. 0:00 / 0:00 Prompt: Aerial view of Santorini during the blue hour, showcasing the stunning architecture of white Cycladic buildings with blue domes. The caldera views are breathtaking, and the lighting creates a beautiful, serene atmosphere.Prompt: Aerial view of Santorini during the blue hour, showcasing the stunning architecture of white Cycladic buildings with blue domes. The caldera views are breathtaking, and the lighting creates a beautiful, serene atmosphere. 0:00 / 0:00 Prompt: Tiltshift of a construction site filled with workers, equipment, and heavy machinery.Prompt: Tiltshift of a construction site filled with workers, equipment, and heavy machinery. 0:00 / 0:00 Prompt: A giant, towering cloud in the shape of a man looms over the earth. The cloud man shoots lighting bolts down to the earth.Prompt: A giant, towering cloud in the shape of a man looms over the earth. The cloud man shoots lighting bolts down to the earth. 0:00 / 0:00 Prompt: A Samoyed and a Golden Retriever dog are playfully romping through a futuristic neon city at night. The neon lights emitted from the nearby buildings glistens off of their fur.Prompt: A Samoyed and a Golden Retriever dog are playfully romping through a futuristic neon city at night. The neon lights emitted from the nearby buildings glistens off of their fur. 0:00 / 0:00 Prompt: The Glenfinnan Viaduct is a historic railway bridge in Scotland, UK, that crosses over the west highland line between the towns of Mallaig and Fort William. It is a stunning sight as a steam train leaves the bridge, traveling over the arch-covered viaduct. The landscape is dotted with lush greenery and rocky mountains, creating a picturesque backdrop for the train journey. The sky is blue and the sun is shining, making for a beautiful day to explore this majestic spot.Prompt: The Glenfinnan Viaduct is a historic railway bridge in Scotland, UK, that crosses over the west highland line between the towns of Mallaig and Fort William. It is a stunning sight as a steam train leaves the bridge, traveling over the arch-covered viaduct. The landscape is dotted with lush greenery and rocky mountains, creating a picturesque backdrop for the train journey. The sky is blue and the sun is shining, making for a beautiful day to explore this majestic spot. 0:00 / 0:00 Research techniques Sora is a diffusion model, which generates a video by starting off with one that looks like static noise and gradually transforms it by removing the noise over many steps. Sora is capable of generating entire videos all at once or extending generated videos to make them longer. By giving the model foresight of many frames at a time, we’ve solved a challenging problem of making sure a subject stays the same even when it goes out of view temporarily. Similar to GPT models, Sora uses a transformer architecture, unlocking superior scaling performance. We represent videos and images as collections of smaller units of data called patches, each of which is akin to a token in GPT. By unifying how we represent data, we can train diffusion transformers on a wider range of visual data than was possible before, spanning different durations, resolutions and aspect ratios. Sora builds on past research in DALL·E and GPT models. It uses the recaptioning technique from DALL·E 3, which involves generating highly descriptive captions for the visual training data. As a result, the model is able to follow the user’s text instructions in the generated video more faithfully. In addition to being able to generate a video solely from text instructions, the model is able to take an existing still image and generate a video from it, animating the image’s contents with accuracy and attention to small detail. The model can also take an existing video and extend it or fill in missing frames. Learn more in our technical report. Sora serves as a foundation for models that can understand and simulate the real world, a capability we believe will be an important milestone for achieving AGI. Sora All videos on this page were generated directly by Sora without modification. Research LeadsBill Peebles & Tim Brooks Systems LeadConnor Holmes Contributors Clarence Wing Yin Ng David Schnurr Eric Luhman Joe Taylor Li Jing Natalie Summers Ricky Wang Rohan Sahai Ryan O’Rourke Troy Luhman Will DePue Yufei Guo Special ThanksBob McGrew, Brad Lightcap, Chad Nelson, David Medina, Gabriel Goh, Greg Brockman, Ian Sohl, Jamie Kiros, James Betker, Jason Kwon, Hannah Wong, Mark Chen, Michelle Fradin, Mira Murati, Nick Turley, Prafulla Dhariwal, Rowan Zellers, Sarah Yoo, Sandhini Agarwal, Sam Altman, Srinivas Narayanan & Wesam Manassra Communications Elie Georges Justin Wang Kendra Rimbach Niko Felix Thomas Degry Veit Moeller Legal Che Chang Fred von Lohmann Gideon Myles Tom Stasi External EngagementAlex Baker-Whitcomb, Allie Teague, Anna Makanju, Anna McKean, Becky Waite, Brittany Smith, Chan Park, Chris Lehane, David Duxin, David Robinson, James Hairston, Jonathan Lachman, Justin Oswald, Krithika Muthukumar, Lane Dilg, Leher Pathak, Ola Nowicka, Ryan Biddy, Sandro Gianella, Stephen Petersilge, Tom Rubin & Varun Shetty Executive ProducerAditya Ramesh Built by OpenAI in San Francisco, California Published February 15, MMXXIV Research Overview Index GPT-4 DALL·E 3 Sora API Overview Pricing Docs ChatGPT Overview Team Enterprise Pricing Try ChatGPT Company About Blog Careers Charter Security Customer stories Safety OpenAI © 2015 – 2024Terms & policiesPrivacy policyBrand guidelines Social Twitter YouTube GitHub SoundCloud LinkedIn Back to top",
    "commentLink": "https://news.ycombinator.com/item?id=39386156",
    "commentBody": "Sora: Creating video from text (openai.com)2910 points by davidbarker 15 hours agohidepastfavorite1676 comments dang 6 hours agoRelated ongoing thread: Video generation models as world simulators - https://news.ycombinator.com/item?id=39391458 - Feb 2024 (43 comments) Also (since it's been a while): there are about 1500 comments in the current thread. To read them all, you need to click More links at the bottom of the page, or like this: https://news.ycombinator.com/item?id=39386156&p=2 https://news.ycombinator.com/item?id=39386156&p=3 https://news.ycombinator.com/item?id=39386156&p=4[etc.] crazygringo 14 hours agoprevThis is insane. But I'm impressed most of all by the quality of motion. I've quite simply never seen convincing computer-generated motion before. Just look at the way the wooly mammoths connect with the ground, and their lumbering mass feels real. Motion-capture works fine because that's real motion, but every time people try to animate humans and animals, even in big-budget CGI movies, it's always ultimately obviously fake. There are so many subtle things that happen in terms of acceleration and deceleration of all of the different parts of an organism, that no animator ever gets it 100% right. No animation algorithm gets it to a point where it's believable, just where it's \"less bad\". But these videos seem to be getting it entirely believable for both people and animals. Which is wild. And then of course, not to mention that these are entirely believable 3D spaces, with seemingly full object permanence. As opposed to other efforts I've seen which are basically briefly animating a 2D scene to make it seem vaguely 3D. reply patall 12 hours agoparentI disagree, just look at the legs of the woman in the first video. First she seems to be limping, than the legs rotate. The mammoth are totally uncanny for me as its both running and walking at the same time. Don't get me wrong, it is impressive. But I think many people will be very uncomfortable with such motion very quickly. Same story as the fingers before. reply justworkout 6 hours agorootparentI think a lot of these issues could be \"solved\" by lowering the resolution, using a low quality compression algorithm, and trimming clips down to under 10 seconds. And by solved, I mean they'll create convincing clips that'll be hard for people to dismiss unless they're really looking closely. I think it's only a matter of time until fake video clips lead to real life outrage and violence. This tech is going to be militarized before we know it. reply geysersam 4 minutes agorootparentI've always found that take quite ridiculous. Fake videos have existed for a long time. This technology reduces the effort required but if we're talking about state actors that was never an issue to begin with. People already know that video cannot be taken at face value. Lord of the rings didn't make anyone belive orcs really exist. reply OscarTheGrinch 1 hour agorootparentprevYeah, we are very close to losing video as a source of truth. I showed these demos to my partner yesterday and she was upset about how real AI has become, how little we will be able to trust what we see in the future. Authoritative sources will be more valuable, but they themselves may struggle to publish only the facts and none of the fiction. Here's one possible military / political use: The commander of Russia's Black Sea Fleet, Viktor Sokolov, is widely believed to have been killed by a missile strike on 22 September 2023. https://en.wikipedia.org/wiki/Viktor_Sokolov_(naval_officer) Russian authorities refute his death and have released proof of life footage, which may be doctored or taken before his death. Authoritative source Wikipedia is not much help in establishing truth here, because without proof of death they must default to toeing the official line. I predict that in the coming months Sokolov (who just yesterday was removed from his post) will re-emerge in the video realm, and go on to have a glorious career. Resurrecting dead heroes is a perfect use of this tech, for states where feeding people lies is preferable to arming them with the truth. Sokolov may even go on to be the next Russian President. reply antris 1 hour agorootparent> Yeah, we are very close to losing video as a source of truth. I think this way of thinking is distracted. No type of media has ever been a source of truth in itself. Videos have been edited convincingly for a long time, and people can lie about their context or cut them in a way that flips their meaning. Text is the easiest media to lie on, you can freely just make stuff up as you go, yet we don't say \"we cannot trust written text anymore\". Well yeah duh, you can trust no type of media just because it is formatted in a certain way. We arrive at the truth by using multiple sources and judging the sources' track records of the past. AI is not going to change how sourcing works. It might be easier to fool people who have no media literacy, but those people have always been a problem for society. reply dugite-code 3 hours agorootparentprevAnd further down the page the: \"The camera follows behind a white vintage SUV with a black roof\": The letters clearly wobble inconsistently. \"A drone camera circles around a beautiful historic church built on a rocky outcropping along the Amalfi Coast\": The woman in the white dress in the bottom left suddenly splits into multiple people like she was a single cell microbe multiplying. reply Yiin 2 hours agorootparentSure, but think what it will be capable of two papers ahead :) reply csomar 2 hours agorootparentProgress is this field has not been linear, though. So it's quite possible that two papers ahead we are still in the same place. reply dr_dshiv 1 hour agorootparentOn the other hand, this is the first convincing use of a “diffusion transformer” [1]. My understanding is that videos and images are tokenized into patches, through a process that compresses the video/images into abstracted concepts in latent space. Those patches (image/video concepts in latent space) can then be used with transformers (because patches are the tokens). The point is that there is plenty of room for optimization following the first demonstration of a new architecture. Edit: sorry, it’s not the first diffusion transformer. That would be [2] [1] https://openai.com/research/video-generation-models-as-world... [2] https://arxiv.org/abs/2212.09748 reply sinuhe69 3 hours agorootparentprevYeah. I think people nowadays are in a kind of AI-euphoria and they took every advancement in AI for more than what they really are. The realization of their limitations will set in once people have been working long enough on the stuff. The capacity of the newfangled AIs are impressive. But even more impressive are their mimicry capabilities. reply Qwero 2 hours agorootparentAre you joking? We were not even able to just create random videos by just text promoting a few years back and now this. The progress is crazy. Why do you dismiss this? reply cezart 1 hour agorootparentNot dismissing, but being realistic. I observed all the AI tools, usually amaze most people initially by showing capabilities never seen before. Then people realise their limitations, ie what capabilities are still missing. And they're like: \"oh, this is no genie in a bottle capable of satisfying every wish. We'll still have to work to obtain our vision...\" So the magic fades away, and the world returns to normal, but now with an additional tool very useful in some situations :) reply Qwero 34 minutes agorootparentI'm still amazed. The progress doesn't slow down right now at all. This is probably one of the most exciting developments in the world besides the Internet. And Geminis news regarding the 1 million token window shows were we are going. This will impact a lot of people faster than a lot of people realize reply bowsamic 22 minutes agorootparentprevSure there are limitations but this is still absurdly impressive. My benchmark is the following: imagine if someone 5 years ago told you that in 5 years we could do this, you would think they were crazy. reply lukan 12 hours agorootparentprevYeah, it looks good at first glance. Also the fingers are still weird. And I suppose for every somewhat working vid, there were dozens of garbage. At least that was my experience with image generation. I don't believe, movie makers are out of buisness any time soon. They will have to incorporate it though. So far this can make convincing background scenery. reply itronitron 5 minutes agorootparentI can see this being used extensively for short commercials, as the uncanny aspect of a lot of the figures will help to capture people's attention. I don't necessarily believe it will be less expensive than hiring a director and film crew however. reply anoopelias 7 hours agorootparentprev> I don't believe, movie makers are out of business any time soon My son was learning how to play keyboard and he started practicing based on metronome. At some point, I was thinking, why is he learning it at all? We can program which key to be pressed at what point in time, and then a software can play itself! Why bother? Then it hit me! Musicians could automate all the instruments with incredible accuracy since a long time. But they never do that. For some reason, they still want a person behind the piano / guitar / drums. reply inference-lord 5 hours agorootparentIsn't it obvious? Life is about experiences and enjoyment, all of this tech is fun and novel and interesting but realistically, it's really exciting for tech people because it's going to be used to make more computer games, social media posts and advertisements, essentially, it's exciting because it's going to \"make money\". Outside of that, people just want to know what it feels like to be able to play their favorite song on guitar and to go skiing etc. Being perfect at everything would be honestly boring as shit. reply bruce511 4 hours agorootparentI completely agree. There is more to a product than the final result. People who don't play an instrument see music I terms of money. (Hint: there's no money in music). But those who play know that the pleasure is in the playing, and jamming with your mates. Recording and selling are work, not pleasure. This is true for literally every hobby people do for fun. I am learning ceramics. Everything I've ever made could be bought in a shop for a 100th of the cost, and would be 100 times \"better\". But I enjoy making the pot, and it's worth more to me than some factory item. Sona will allow a new hobby, and lots will have fun with it. Pros will still need to fo Pro things. Not everything has to be viewed through the lens of money. reply disqard 4 hours agorootparentYou articulated what I wanted to add to this thread -- thank you! I play the piano, and even though MIDI exists, I still derive a lot of enjoyment from playing an acoustic instrument. reply numpad0 1 hour agorootparentprevI think it's not. If musicians and only musicians wanted themselves behind instruments, for the sake of being, there should be a market for autogenerated self-playing music machines for their former patrons who wouldn't care. And that's not the case; the market for ambient sound machines is small. It takes equal or more insanity to have one at home than, say, having a military armored car in the garage. On the other hand you've probably heard of an iPod, which I think I could describe as a device dedicated to give false sense of an ever-present musician, so to speak. So, \"they\" in \"they still want a person behind the piano\" is not just limited to hobbyists and enthusiasts. People wants people behind an instrument, for some reason. People pays for others' suffering, not for a thing's peculiarity. reply vitro 2 hours agorootparentprevI like this saying: “The woods would be very silent if no birds sang except those who sang the best.” It's fun learning to play the instrument. reply alisonatwork 4 hours agorootparentprevI don't think this is entirely accurate. There are entire genres of music where the audience does not want a person behind the piano/guitar/drums. Plenty of electronic artists have tried the live band gimmick and while it goes down well with a certain segment of the audience, it turns off another segment that doesn't want to hear \"humanized\" cover versions of the material. But the point is that both of those audiences exist, and they both have lots of opportunity to hear the music they want to hear. The same will be true of visual art created by computers. Some people will prefer a stronger machine element, other people will prefer a stronger human element, and there is room for us all. reply picklesman 5 hours agorootparentprevWhen I was studying music technology and using state of the art software synthesizers and sequencers, I got more and more into playing my acoustic guitar. There's a deep and direct connection and a pleasure that comes with it that computers (and now/eventually AI) will never be able to match. (That being said, a realtime AI-based bandmate could be interesting...) reply inference-lord 5 hours agorootparentMy son is an interesting example of this, I can play all the best guitar music on earth via the speakers, but when I physically get the guitar out and strum it, he sits up like he has just seen god, and is total awe of the sounds of it, the feel of the guitar and the site of it. It's like nothing else can compare. Even if he is hysterically crying, the physical isntrument and the sound of it just makes him calm right down. I wonder if something is lost in the recording process that just cannot be replicated? A live instrument is something that you can actually feel the sound of IMO, I've never felt the same with recorded music even though I of course enjoy it. I wonder if when we get older we just get kind of \"bored\" (sadly) and it doesn't mean as much to us as it probably should. reply vczf 4 hours agorootparentMirror neurons? reply inference-lord 4 hours agorootparentWhat does this have to do with it? reply vczf 4 hours agorootparentI'm speculating that one would have more mirror neuron activation watching a person perform live, compared to listening to a recording or watching a video. Thus the missing component that makes live performance special. reply _glass 1 hour agorootparentprevFor me the guitar is like the keyboard I am writing on right now. It will never be replaced, because that is how I input music into the world. I could not program that, I was doing tracker music as a teenager, and all of the songs sounded weird, because the timing, and so on is not right. And now when I transcribe demos, and put them into a DAW, there seem to be the milliseconds off, that are not quite right. I still play the piano parts live, because we don't have the technology right now to make it sound better than a human, and even if we had, it would not be my music, but what an AI performed. reply throwaway14356 4 hours agorootparentprevI really briefly looked at AI in music, lots of wild things are made. It is hard to explain, one was generating a bunch of sliders after mimicking a sample from sine waves (quite accurately) reply sdrothrock 5 hours agorootparentprev> Musicians could automate all the instruments with incredible accuracy since a long time. But they never do that. For some reason, they still want a person behind the piano / guitar / drums. This actually happened on a recent hit, too -- Dua Lipa's Break My Heart. They originally had a drum machine, but then brought in Chad Smith to actually play the drums for it. Edit: I'm not claiming this was new or unusual, just providing a recent example. reply shon 5 hours agorootparentThis goes way back. Nine Inch Nails was a synth-first band with the music being written by Trent in a studio on a DAW. That worked but what really made the bad was live shows so they found ways even using 2 drummers to translate the synths and machines into human-plated instruments. Also way before that back in the early 80’a Depeche Mode displayed the recorded drumb-reel onstage so everyone knew what it was, but when the got big enough they also transitioned into an epic live show with guitars and live drum a as well as synth-hooked drums devices they could bag on in addition to keyboards. We are human. We want humans. Same reason I want a hipster barista to pour my coffee when a machine could do it just as well. reply inference-lord 5 hours agorootparentSame reason I want a hipster barista to pour my coffee when a machine could do it just as well. I've wondered about this for a long time too, why on earth is anyone still able to be a barista, it turns out, people actually like the community around cafes and often that means interacting with the staff on a personal level. Some of my best friends have been barista's I've gone to over several years. reply baq 3 hours agorootparentBack before Twitter was born, or perhaps tv, cafes were just that - a place to spend evenings (…just don’t ask who watched over the kids) reply lukan 3 hours agorootparentprevA good live performance is intentionally not 100% the same as in the studio, but there can and should be variations. A refrain repeated another time, some improvisation here. Playing with the tempo there. It takes a good band, who know each other intimately, to make that work, though. (a good DJ can also do this with electronic music) A recorded studio version, I can also listen to at home. But a full band performing in this very moment is a different experience to me. reply czl 7 hours agorootparentprev> Musicians could automate all the instruments with incredible accuracy since a long time. But they never do that. What do you judge was the ratio of automated music (recordings played back) to live music played in the last year? reply anoopelias 6 hours agorootparentJust to be clear, I was talking about the original sound produced by a person (vs. a machine). Of course it was recorded and played back a _lot_ more than folks listening live. But I take it, maybe I'm not so familiar with world music, I was talking more about Indian music. While the music is recorded and mixed across several tracks electronically, I think most of it is played (or sang) originally by a person. reply Larrikin 3 hours agorootparentHis point still stands. In the US atleast there's the occasional acoustic song that becomes a hit, but rock music is obviously on its way to slowly becoming jazz status. It and country are really the last genres where live traditional instruments are common during live performances. Pop, Hip Hop, and EDM basically all are put together as being nearly computer perfect. All the great producers can play instruments, and that's often times the best way to get a section out initially. But what you hear on Spotify is more and more meticulously put together note by note on a computer after the fact. Live instruments on stage are now often for spectacle or worse a gimmick, and it's not the song people came to love. I think the future will have people like Lionclad[1] in it pushing what it means to perform live, but I expect them to become fewer and fewer as music just gets more complex to produce overall. [1] https://www.youtube.com/watch?v=MuBas80oGEU reply Tainnor 51 minutes agorootparentThankfully, art is not about the least common denominator and I'm confident that there will continue to be music played live as long as humanity exists. reply Larrikin 42 minutes agorootparentMusic has a lot of people who believe that not only is their favorite genre the best but that they must tear down people who don't appreciate it. You aren't better because you prefer live music, you just have a preference. Music wasn't better some arbitrary number of years ago, you just have a preference. Nobody said one form is objectively better, just that there is a form that is becoming more popular. But to state my opinion, I can't imagine something more boring than thinking the best of music, performance, TV, or media in general was done best and created in the past. reply code51 2 hours agorootparentprevThe real dilemma is with composition/song-writing. Ability to create live experiences can still be a motivating factor for musicians (aside from the love of learning). Yet, when AI does the song-writing far more effectively, then will the musician ignore this? It's like Brave New World. Musicians who don't use these AI tools for song-writing will be like a tribe outside modern world. That's a tough future to prepare for. We won't know whether a song was actually the experience and emotions of a person or not. reply anigbrowl 3 hours agorootparentprevMusicians could automate all the instruments with incredible accuracy since a long time. But they never do that. For some reason, they still want a person behind the piano / guitar / drums. You've never been to a rave, huh? For that matter, there's a lot of pop artists that use sequencers and dispense with the traditional band on stage. reply dugite-code 3 hours agorootparentprev> fingers are still weird Also keep an eye on teeth and high contrast text. Anything small and prone to distortion in low resolution video and images used to train this stuff. reply Solvency 11 hours agorootparentprevI love these hot takes based on profoundly incredible tech that literally just launched. Acting like 2030 isn't around the corner. reply chefandy 10 hours agorootparent> I love these hot takes based on profoundly incredible tech that literally just launched. Acting like 2030 isn't around the corner. It seems bizarre to think the gee whiz factor in a new commercial creative product makes critiquing its output out-of-bounds. This isn't a university research team: they're charging money for this. Most people have to determine if something is useful before they pay for it. reply bamboozled 11 hours agorootparentprevWe’re glad you love them. reply goatlover 4 hours agorootparentprevLet me guess, hard singularity take-off in 2030? Does the hype cycle not exist for techno-optimists? Just one breathless prediction after another? reply andrepd 10 hours agorootparentprevAnything less than absolute enrapture is a \"hot take\"... :) reply Hoasi 12 hours agorootparentprev> I disagree, just look at the legs of the woman in the first video. The people behind her all walk at the same pace and seem like floating. The moving reflections, on the other hand, are impressive make-believe. reply b1gnasty 5 hours agorootparentReally makes me think of The Matrix scene with the woman in the red dress. Can't tell if they did this on purpose to freak us all out? Are we all just prompts? reply kyrra 11 hours agorootparentprevIf you watch the background, you'll see one guy has hits pants change color. And also, some of the guys are absolute giants compared to people around them. reply anigbrowl 3 hours agorootparentprevSame story as the fingers before. This is weird to me considering how much better this is than the SOTA still images 2 years ago. Even though there's weirdo artefacts in several of their example videos (indeed including migrating fingers), that stuff will be super easy to clean up, just as it is now for stills. And it's not going to stop improving. reply bamboozled 11 hours agorootparentprevAgreed and these are the cherry picked examples of course. reply samstave 5 hours agorootparentprev>>>just look at the legs of the woman Denise Richards hard sharp knees in '97 -- these infant tech are already insanely good... just wait and rahter try to focus on the \"what should I be betting on in 5 years from now? I suggest 'invisibility cloaks' (ghosts in machines?) reply gerash 13 hours agoparentprevWhen others create text to video systems (eg. Lumiere from Google) they publish the research (eg. https://arxiv.org/pdf/2401.12945.pdf). Open AI is all about commercialization. I don't like their attitude reply comex 6 hours agorootparentGoogle is hardly a good actor here. They just announced Gemini 1.5 along with a \"technical report\" [1] whose entire description of the model architecture is: \"Gemini 1.5 Pro is a sparse mixture-of-expert (MoE) Transformer-based model\". Followed by a list of papers that it \"builds on\", followed by a definition of MoE. I suppose that's more than OpenAI gave in their GPT-4 technical report. But not by much! [1] https://storage.googleapis.com/deepmind-media/gemini/gemini_... reply jstummbillig 12 hours agorootparentprevNot to be overly cute, but if the cutting edge research you do is maybe changing the world fundamentally, forever, guarding that tech should be really, really, really far up your list of priorities and everyone else should be really happy about your priorities. And that should probably take precedence over the semantics of your moniker, every single time (even if hn continues to be super sour about it) reply cloogshicer 12 hours agorootparentI'd much rather this tech be open - better for everyone to have it than a select few. The more powerful, the more important it is that everyone has access. reply crazygringo 12 hours agorootparentDo you feel the same way about nuclear weapons tech? That \"the more powerful, the more important it is that everyone has access\"? Especially considering that the biggest killer app for AI could very well be smart weapons like we've never seen before. reply nlnn 33 minutes agorootparentWhile it's probably too idealistic to be possible, I'd rather try and focus on getting people/society/the world to a state where it doesn't matter if everyone has access (i.e. getting to a place where it doesn't matter if everyone has access to nuclear weapons, guns, chemical weapons, etc., because no-one would have the slightest desire to use them). As things are at the moment, while supression of a technology has benefits, it seems like a risky long-term solution. All it takes is for a single world-altering technology to slip through the cracks, and a bad actor could then forever change the world with it. reply spdustin 12 hours agorootparentprevI feel this is a false equivalence. Nukes aren’t even close to being commodities, cannot be targeted at a class of people (or a single person), and have a minutely small number of users. (Don’t argue semantics with “class of people” when you know what I mean, btw) On the other hand, tech like this can easily become as common as photoshop, can cause harm to a class of people, and be deployed on a whim by an untrained army of malevolent individuals or groups. reply nearbuy 4 hours agorootparentSo if someone discovered a weapon of mass destruction (say some kind of supervirus) that could be produced and bought cheaply and could be programmed to only kill a certain class of people, then you'd want the recipe to be freely available? reply sanitycheck 2 hours agorootparentThis poses no direct threat to human life though. (Unlike, say, guns - which are totally fine for everyone in the US!) The direct threat to society is actually this kind of secrecy. If ordinary people don't have access to the technology they don't really know what it can do, so they can't develop a good sense of what could now be fake that only a couple of years ago must have been real. Imagine if image editing technology (Photoshop etc) had been restricted to nation states and large powerful corporations. The general public would be so easy to fool with mere photographs - and of course more openly nefarious groups would have found ways to use it anyway. Instead everybody now knows how easily we can edit an image and if we see a shot of Mr Trump apparently sharing a loving embrace with Mr Putin we can make the correct judgement regarding a probable origin. reply lastdong 3 hours agorootparentprevI understand your perspective regarding the potential risks associated with freely available research, particularly when it comes to illegal weapons and dangerous viruses. However, it's worth considering that by making research available to the world, we enable a collaborative effort in finding solutions and antidotes to such threats. In the case of Covid, the open sharing of information led to the development of vaccines in record time. It's important to weigh the benefits of diversity and open competition against the risks of bad actors misusing the tools. Ultimately, finding a balance between accessibility and responsible use is key. What guarantee do we have that OpenAI won't become an evil actor like Skynet? reply nearbuy 1 hour agorootparentI'm not advocating for or against secrecy. I'm just not understanding the parent comment I replied to. They said nukes are different than AI because they aren't commodities and can't target specific classes of people, and presumably that's why nukes should be kept secret and AI should be open. Why? That makes no sense to me. If nukes had those qualities, I'd definitely want them kept secret and controlled. reply tavavex 12 hours agorootparentprevAn AI video generator can't kill billions of people, for one. I'd prefer it if access wasn't limited to a single corporation that's accountable to no one and is incentivized to use it for their benefits only. reply jstummbillig 12 hours agorootparent> accountable to no one What do you mean? Are you being dramatic or do you actually believe that the US government will/can not absolutely shut OpenAI down, if they feel it was required to guarantee state order? reply tavavex 12 hours agorootparentFor the US government to step in, they'd have to do something extremely dangerous (and refuse to share with the government). If we're talking about video generation, the benefits they have are financial, and the lack of accountability is in that they can do things no one else can. I'm not saying they'll be allowed to break the law, there's plenty of space between the two extremes. Though, given how things were going, I can also see OpenAI teaming up with the US government and receiving exclusive privileges to run certain technologies for the sake of \"safety\". It's what Altman has already been pushing for. reply ngcazz 1 hour agorootparentprevMake it high-enough fidelity, and it will be used to convince people to kill billions. reply huytersd 9 hours agorootparentprevI think it could. The right sequence of videos sent to the right people could definitely set something catastrophic off. reply czl 7 hours agorootparent> The right sequence of videos sent to the right people could definitely set something catastrophic off. ...after amazing public world wide demos that show how real the AI generated videos can be? How long has Hollywood had similar \"fictional videos\" powers? reply huytersd 4 hours agorootparentFlat earth Billy can now make videos with a $20 subscription. reply 8n4vidtmkvmk 3 hours agorootparentI think that's great. Billy will feed his flat earther friends for a few weeks or months and pretty soon the entire world will wise up and be highly skeptical of any new such videos. The more of this that gets out there, the quicker people will learn. If it's 1 or 2 videos to spin an election... People might not get wise to it. reply huytersd 3 hours agorootparentGiven the last 10 years I have no such faith in the common person. reply solardev 9 hours agorootparentprev> Especially considering that the biggest killer app for AI could very well be smart weapons like we've never seen before. A homing missile that chases you across continents and shows you disturbing deepfakes of yourself until you lose your mind and ask it to kill you. At that point it switches to encourage mode, rebuilds your ego, and becomes your lifelong friend. reply bb88 8 hours agorootparentprevI don't think it's really that hard to make a nuclear weapon, honestly. Just because you have the plans for one, doesn't mean you have the uranium/plutonium to make one. Weapons-grade uranium doesn't fall into your lap. The ideas of critical mass, prompt fission, and uranium purification, along with the design of the simplest nuclear weapon possible has been out in the public domain for a long time. reply Vinnl 11 hours agorootparentprevOof, imagine if our safeguard for nuclear weapons was that a private company kept it safe. reply lagrange77 10 hours agorootparentprevOn a geopolitical level 'everyone' does have access. reply jstummbillig 12 hours agorootparentprevAs long as destroying things remains at least two magnitudes easier than building things and defending against attacks, this take (as a blanket statement) will continue to be indefensible and irresponsible. reply iwsk 12 hours agorootparentprevShould nukes be open source? reply baq 3 hours agorootparentIf you have two pieces of plutonium and put them too close together you have accidentally created a nuclear weapon… so yeah nukes are open source, plutonium breeding isn’t. reply spdustin 12 hours agorootparentprevI humbly refer you to this comment: https://news.ycombinator.com/item?id=39389262 reply esafak 5 hours agorootparentML models of this complexity are just as accessible as nuclear weapons. How many nations possess a GPT-4? The only reason nuclear weapons are not more common is because their proliferation is strictly controlled by conventions and covert action. reply nradov 4 hours agorootparentprevThe basic designs for workable (although inefficient) nuclear weapons have been published in open sources for decades. The hard part is obtaining enough uranium and then refining it. reply bamboozled 11 hours agorootparentprevWhat a load…image if everyone else guarded all their discoveries, there’d be no text to video would there? reply andrepd 11 hours agorootparentPeople defending this need to meditate on the meaning of the phrase \"shoulders of giants\". reply clayhacks 10 hours agorootparentNew technology will always be new giants to see from, but open source really is a nice ladder up to the shoulders of giants. So many benefits from sharing the tech reply spookie 5 hours agorootparentThis reminded me of a conversation with a historian. He requested the reconstruction of a monument in France that a game studio had already made. The studio told him the model was their property, and they wouldn't share it. Peculiar reasoning, isn't it? reply creatonez 11 hours agorootparentprevThis is meaningless until you've defined \"world changing\". It's possible that open sourcing AIs will be world-changing in a good way and developing closed source AIs will be world-changing in a bad way. If I engineered the tech I would be much more fearful of the possibility of malice in the future leadership of the organization I'm under if they continue to keep it closed, than I would be fearful of the whole world getting the capability if they decide to open source. I feel that, like with Yellow Journalism of the 1920s, much of the misinformation problem with generative AI will only be mitigated during widespread proliferation, wherein people become immune to new tactics and gain a new skepticism of the media. I've always thought it strange when news outlets discuss new deepfakes but refuse to show it, even with a watermark indicating it is fake. Misinformation research shows that people become more skeptical once they learn about the technological measures (e.g. buying karma-farmed Reddit accounts, or in the 1920s, taking advantage of dramatically lower newspaper printing costs to print sensationalism) through which misinformation is manufactured. reply towelpluswater 5 hours agorootparentThis is a fantastic write up and great parallel to the state of where we’re headed. reply opportune 10 hours agorootparentprevHow convenient for all the OpenAI employees trying to make millions of dollars by commercializing their technology. Surely this technology won’t be well-understood and easily replicable in a few years as FOSS reply spookie 5 hours agorootparentIt'll, even if they guard their secret sauce. Let's not be naive about this, obfuscation is and always will be a minor nuisance. reply andrepd 11 hours agorootparentprev>If you have world-changing technology it's better for a megacorp to control it. You need to watch more dystopian movies. reply neya 4 hours agorootparentprevWhen has OpenAI - for a company named \"Open\" AI ever released any of their stuff into anything open? reply hnben 1 hour agorootparentThey stopped releasing their stuff openly around the time GPT3 came to be. reply y_gy 12 hours agorootparentprevIronic, isn't it! OpenAI started out \"open,\" publishing research, and now \"ClosedAI\" would be a much better name. reply ionwake 12 hours agorootparentTBH they should just rename to ClosedAI and run with it, I and others would appreciate the honesty plus it would be amusing. reply polygamous_bat 12 hours agorootparentHowever if you are playing for the regulatory capture route (which Sam Altman seems to be angling for) it’s much easier if your name is “OpenAI”. reply tavavex 12 hours agorootparentIf you go full regulatory capture, you might as well name it \"AI\", The AI Company. reply ionwake 11 hours agorootparentYou never go \"full\" regulatory capture. reply efrank3 12 hours agorootparentprevgottem reply ShamelessC 11 hours agorootparentprevSick burn! reply disillusioned 9 hours agorootparentprevMore like ClosedAI, amirite? reply mtillman 12 hours agorootparentprevOAI requires a real mobile phone number to signup and are therefore an adtech company. reply BadHumans 12 hours agorootparentMight be one of the most absurd things said on here. Requiring a phone number for sign up does not automatically mean you are selling ads. reply polygamous_bat 12 hours agorootparentWhen the time for making money comes, if you don’t think OpenAI will sell every drop of information they have on you, then you are incredibly naive. Why would they leave money on the table when everyone else has been doing it for forever without any adverse effects? reply Zacharias030 11 hours agorootparentThey are currently hiring people with Adtech experience. The most simple version would be an ad-supported ChatGPT experience. Anyone thinking that an internet consumer company with 100m weekly active users (I‘m citing from their job ad) is not going to sell ads is lacking imagination. reply jstummbillig 11 hours agorootparentprevIf Google Workspace was selling my or any customers information, at all or \"forever\", it would not be called Google Workspace, it would be called Google We-died-in-the-most-expensive-lawsuit-of-all-time. reply 8n4vidtmkvmk 3 hours agorootparentThere's a difference. Open AI essentially has 2 products. The chat bot $20 a month thing for Joe shmoe which they admit to training on your prompts, and the API for businesses. Workspace is like the latter. The former is closer to Google search. reply esafak 5 hours agorootparentprevWe're face to face with AGI and you're worried about ads?? Get your risks in order!! reply 8n4vidtmkvmk 3 hours agorootparentWe're still nowhere near AGI. reply kitd 16 minutes agoparentprevMaybe it's my anthropocentric brain, but the animals move realistically while the people look still quite off. It's still an unbelievable achievement though. I love the paper seahorse whose tail is made (realistically) using the paper folds. reply Sohcahtoa82 14 hours agoparentprev> Motion-capture works fine because that's real motion Except in games where they mo-cap at a frame rate less than what it will be rendered at and just interpolate between mo-cap samples, which makes snappy movements turn into smooth movements and motions end up in the uncanny valley. It's especially noticeable when a character is talking and makes a \"P\" sound. In a \"P\", your lips basically \"pop\" open. But if the motion is smoothed out, it gives the lips the look of making an \"mm\" sound. The lips of someone saying \"post\" looks like \"most\". At 30 fps, it's unnoticeable. At 144 fps, it's jarring once you see it and can't unsee it. reply windowshopping 5 hours agoparentprevHuh, strong disagree. I've seen realistic CGI motion many times and I don't consider this to feel realistic at all. reply omega3 13 hours agoparentprevOut of all the examples, the wooly mammoths one actually feels like CGI the most to me, the other ones are much more believable than this one. reply mtlmtlmtlmtl 12 hours agorootparentPossibly because there are no videos or even photos of live wooly mammoths, but loads and loads of CG recreations in various documentaries. reply mikeInAlaska 12 hours agorootparentprevI saw the cat in the bed grows an extra limb... reply krapp 12 hours agorootparentCats are weird sometimes. reply lastdong 3 hours agoparentprevRegarding CGI, I think it has became so good that you don’t know it’s CGI. Look at the dog in Guardians of the Galaxy 3. There’s a whole series on YouTube called “no cgi is really just invisible cgi” that I recommend watching. And as with cgi, models like SORA will get better until you can’t tell reality apart. It's not there Yet, but an immense astonishingly breakthrough. reply bamboozled 11 hours agoparentprevI’m a bit thrown off by the fact the mammoths are steaming, is that normal for mammoths ? reply throw310822 10 hours agorootparentGood question :) reply unsigner 1 hour agoparentprevDon't think of them as \"computer-generated\" any more than your phone's heavily processed pictures are \"computer-generated\", or JWST's false color, IR-to-visible pictures are \"computer-generated\". This article makes a convincing argument: https://studio.ribbonfarm.com/p/a-camera-not-an-engine reply lynguist 42 minutes agorootparentThat is such a gem of an article that looks at AI with a new lens I haven’t encountered before: - AI sees and doesn’t generate - It is dual to economics that pretends to describe but actually generates reply geor9e 9 hours agoparentprevIt's possible that through sheer volume of training, the neural network essentially has a 3D engine going on, or at least picked up enough of the rules of light and shape and physics to look the same as unreal or unity reply samsullivan 5 hours agorootparentIt would have to in order to produce the outputs, our brains have crazy physics engines though, F1 drivers can simulate an entire race in their heads. reply djmips 12 hours agoparentprevI'm not sure I feel the same way about the mammoths - and the billowing snow makes no sense as someone who grew up in a snowy area. If the snow was powder maybe but that's not what's depicted on the ground. reply globular-toast 1 hour agoparentprevNah this still has the problem with connecting surfaces that never seems to look right in any CGI. It's actually interesting that it doesn't look right here as well considering they are completely different techniques. reply isthispermanent 13 hours agoparentprevPixar is computer generated motion, no? reply viewtransform 13 hours agorootparentMain Pixar characters are all computer animated by humans. Physics effects like water, hair, clothing, smoke and background crowds use computer physics simulation but there are handles allowing an animator to direct the motion as per the directors wishes. reply minimaxir 13 hours agorootparentprevWith extreme amounts of man-hours to do so. reply swamp40 14 hours agoparentprevIt's been trained on videos exclusively. Then GPT-4 interprets your prompt for it. reply colordrops 8 hours agoparentprevYou might just be subject to confirmation bias here. Perhaps there were scenes and entities you didn't realize were CGI due to high quality animation, and thus didn't account for them in your assessment. reply samstave 5 hours agoparentprevSerious: Can one just pipe an SRT (subtitle file) and then tell it to compare its version to the mp4 and then be able to command it to zoom, enhance, edit, and basically use it to remould content. I think this sounds great! reply pantulis 1 hour agoprevThis is the harbinger that announces that, as a technologist, the time has come for me to witness more and more things that I cannot understand how they work any more. The cycle has closed and I have now become my father. reply megamix 1 hour agoparentThankfully it's nothing magical. But are you willing to learn about it or not? Think about animation, how a program can generate a sequence of a bouncing ball between two key frames. Think about what defines a video. The frames right? From there I can try to imagine. reply georgespencer 1 hour agoparentprevI'm on the very cusp of this, you helped me realize. Thanks. reply sebastiennight 13 hours agoprevI think the implications go much further than just the image/video considerations. This model shows a very good (albeit not perfect) understanding of the physics of objects and relationships between them. The announcement mentions this several times. The OpenAI blog post lists \"Archeologists discover a generic plastic chair in the desert, excavating and dusting it with great care.\" as one of the \"failed\" cases. But this (and \"Reflections in the window of a train traveling through the Tokyo suburbs.\") seem to me to be 2 of the most important examples. - In the Tokyo one, the model is smart enough to figure out that on a train, the reflection would be of a passenger, and the passenger has Asian traits since this is Tokyo. - In the chair one, OpenAI says the model failed to model the physics of the object (which hints that it did try to, which is not how the early diffusion models worked ; they just tried to generate \"plausible\" images). And we can see one of the archeologists basically chasing the chair down to grab it, which does correctly model the interaction with a floating object. I think we can't underestimate how crucial that is to the building of a general model that has a strong model of the world. Not just a \"theory of mind\", but a litteral understanding of \"what will happen next\", independently of \"what would a human say would happen next\" (which is what the usual text-based models seem to do). This is going to be much more important, IMO, than the video aspect. reply bamboozled 3 hours agoparentWouldn't having a good understanding of physics mean you know that a women doesn't slide down the road when she walks? Wouldn't it know that a woolly mammoth doesn't emit profuse amounts steam when walking on frozen snow? Wouldn't the model know that legs are solid objects in which other object cannot pass through? Maybe I'm missing the big picture here, but the above and all the weird spatial errors, like miniaturization of people make me think you're wrong. Clearly the model is an achievement and doing something interesting to produce these videos, and they are pretty cool, but understanding physics seems like quite a stretch? I also don't really get the excitement about the girl on the train in Tokyo: In the Tokyo one, the model is smart enough to figure out that on a train, the reflection would be of a passenger, and the passenger has Asian traits since this is Tokyo I don't know a lot about how this model works personally, but I'm guessing in the training data the vast majority of people riding trains in Tokyo featured asian people in them, assuming this model works on statistics like all of the other models I've seen recently from Open AI, then why is it interesting the girl in the reflection was Asian? Did you not expect that? reply csomar 1 hour agorootparent> Wouldn't having a good understanding of physics mean you know that a women doesn't slide down the road when she walks? Wouldn't it know that a woolly mammoth doesn't emit profuse amounts steam when walking on frozen snow? Wouldn't the model know that legs are solid objects in which other object cannot pass through? This just hit me but humans do not have a good understanding of physics; or maybe most of humans have no understanding of physics. We just observe and recognize whether it's familiar or not. AI will need to be, that being the case, way more powerful than a human mind. Maybe orders of magnitude more \"neural networks\" than a human brain has. reply pera 1 hour agorootparentprevI agree, to me the most clear example is how the rocks in the sea vanish/transform after the wave: The generated frames are hyperreal for sure, but the represented space looks as consistent as a dream. reply pests 3 hours agorootparentprevThey could test this by trying to generate the same image but set in New York, etc. I bet it would still be asain. reply RhysU 11 hours agoparentprev> very good... understanding of the physics of objects and relationships between them I am always torn here. A real physics engine has a better \"understanding\" but I suspect that word applies to neither Sora nor a physics engine: https://www.wikipedia.org/wiki/Chinese_room An understanding of physics would entail asking this generative network to invert gravity, change the density or energy output of something, or atypically reduce a coefficient of friction partway through a video. Perhaps Sora can handle these, but I suspect it is mimicking the usual world rather than understanding physics in any strong sense. None of which is to say their accomplishment isn't impressive. Only that \"understand\" merits particularly careful use these days. reply mewpmewp2 10 hours agorootparentQuestion is - how much do you need to understand something in order to mimick it? The Chinese Room seems to however point to some sort of prewritten if-else type of algorithm type of situation. E.g. someone following scripted algorithmic procedures might not understand the content, but obviously this simplification is not the case with LLMs or this video generation, as the algorithmic scripting requires pre-written scripts. Chinese Room seems to more refer to cases like \"if someone tells me \"xyz\", then respond with \"abc\" - of course then you don't understand what xyz or abc mean, but it's not referring to neural networks training on ton of material to build this model representation of things. reply RhysU 7 hours agorootparentGood points. Perhaps building the representation is building understanding. But humans did that for Sora and for all the other architectures too (if you'll allow a little meta-building). But evaluation alone is not understanding. Evaluation is merely following a rote sequence of operations, just like the physics engine or the Chinese room. People recognize this distinction all the time when kids memorize mathematical steps in elementary school but they do not yet know which specific steps to apply for a particular problem. This kid does not yet understand because this kid guesses. Sora just happens to guess with an incredibly complicated set of steps. (I guess.) reply ketzo 5 hours agorootparentI think this is a good insight. But if the kid gets sufficiently good at guessing, does it matter anymore..? I mean, at this point the question is so vague… maybe it’s kinda silly. But I do think that there’s some point of “good-at-guessing” that makes an LLM just as valuable as humans for most things, honestly. reply seydor 13 hours agoparentprevFacebook released something in that direction today https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-jo... reply sebastiennight 12 hours agorootparentWow this is a huge announcement too, I can't believe this hasn't made the front page yet. reply gspetr 12 hours agoparentprevThis seems to be completely in line with the previous \"AI is good when it's not news\" type of work: Non-news: Dog bites a man. News: Man bites a dog. Non-news: \"People riding Tokyo train\" - completely ordinary, tons of similar content. News: \"Archaeologists dust off a plastic chair\" - bizarre, (virtually) no similar content exists. reply sva_ 9 hours agoparentprevI found the one about the people in Lagos pretty funny. The camera does about a 360deg spin in total, in the beginning there are markets, then suddenly there are skyscrapers in the background. So there's only very limited object permanence. > A beautiful homemade video showing the people of Lagos, Nigeria in the year 2056. Shot with a mobile phone camera. > https://cdn.openai.com/sora/videos/lagos.mp4 reply bamboozled 4 hours agorootparentAlso the women in red next to the people is very tiny and the market stall is also a mini market stall, and the table is made out of a bike. For everyone that's carrying on about this thing understanding physics and has a model of the world...it's an odd world. reply lostemptations5 2 hours agorootparentThe thing is -- over time I'm not sure people will care. People will adapt to these kinds of strange things and normalize them -- as long as they are compelling visually. The thing about that scene is it looks weird only if you think about it. Otherwise it seems like the sort of pan you would see in some 30 second commercial for coffee or something. If anything it tells a story: going from market, to people talking as friends, to the giant world (of Lagos). reply lostemptations5 2 hours agorootparentprevThough I'm not sure your point here -- outside of America -- in Asia and Africa -- these sorts of markets mixed in with skyscrapers are perfectly normal. There is nothing unusual about it. reply po 6 hours agorootparentprevIn the video of the girl walking down the Tokyo city street, she's wearing a leather jacket. After the closeup on her face they pull back and the leather jacket has hilariously large lapels that weren't there before. reply ketzo 5 hours agorootparentObject permanence (just from images/video) seems like a particularly hard problem for a super-smart prediction engine. Is it the old thing, or a new thing? reply vingt_regards 7 hours agorootparentprevThere are also perspective issues: the relative sizes of the foreground (the people sitting at the café) and the background (the market) are incoherent. Same with the \"snowy Tokyo with cherry blossoms\" video. reply PoignardAzur 9 hours agorootparentprevYeah, some of the continuity errors in that one feel horrifying. reply XCSme 9 hours agoparentprevIt doesn't understand physics. It just computes next frame based on current one and what it learned before, it's a plausible continuation. In the same way, ChatGPT struggles with math without code interpreter, Sora won't have accurate physics without a physics engine and rendering 3d objects. Now it's just a \"what is the next frame of this 2D image\" model plus some textual context. reply yberreby 5 hours agorootparent> It just computes next frame based on current one and what it learned before, it's a plausible continuation. ... > Now it's just a \"what is the next frame of this 2D image\" model plus some textual context. This is incorrect. Sora is not an autoregressive model like GPT, but a diffusion transformer. From the technical report[1], it is clear that it predicts the entire sequence of spatiotemporal patches at once. [1]: https://openai.com/research/video-generation-models-as-world... reply og_kalu 4 hours agorootparentprevGPT-4 doesn't \"struggle with math\". It does fine. Most humans aren't any better. Sora is not autoregressive anyway but there's nothing \"just\" and next frame/token prediction. reply 8n4vidtmkvmk 3 hours agorootparentIt absolutely struggles with math. It's not solving anything. It sometimes gets the answer right only because it's seen the question before. It's rote memorization at best. reply og_kalu 3 hours agorootparentNo it doesn't. I know because I've actually used the thing and you clearly haven't. And if Terence Tao finds some use for GPT-4 as well as Khan Academy employing it as a Math tutor then I don't think I have some wild opinion either. Now Math isn't just Arithmetic but do you know easy it is to go out of training for say Arithmetic ? reply shostack 8 hours agoparentprevI'm hoping to see progress towards consistent characters, objects, scenes etc. So much of what I'd want to do creatively hinges on needing persisting characters who don't change appearance/clothing/accessories from usage to usage. Or creating a \"set\" for a scene to take place in repeatedly. I know with stable diffusion there's things like lora and controlnet, but they are clunky. We still seem to have a long way to go towards scene and story composition. Once we do, it will be a game changer for redefining how we think about things like movies and television when you can effectively have them created on demand. reply Animats 10 hours agoprevThe Hollywood Reporter says many in the industry are very scared.[1] “I’ve heard a lot of people say they’re leaving film,” he says. “I’ve been thinking of where I can pivot to if I can’t make a living out of this anymore.” - a concept artist responsible for the look of the Hunger Games and some other films. \"A study surveying 300 leaders across Hollywood, issued in January, reported that three-fourths of respondents indicated that AI tools supported the elimination, reduction or consolidation of jobs at their companies. Over the next three years, it estimates that nearly 204,000 positions will be adversely affected.\" \"Commercial production may be among the main casualties of AI video tools as quality is considered less important than in film and TV production.\" [1] https://www.hollywoodreporter.com/business/business-news/ope... reply snewman 9 hours agoparentHonest question: of what possible use could Sora be for Hollywood? The results are amazing, but if the current crop of text-to-image tools is any guide, it will be easy to create things that look cool but essentially impossible to create something that meets detailed specific criteria. If you want your actor to look and behave consistently across multiple episodes of a series, if you want it to precisely follow a detailed script, if you want continuity, if you want characters and objects to exhibit consistent behavior over the long term – I don't see how Sora can do anything for you, and I wouldn't expect that to change for at least a few years. (I am entirely open to the idea that other generative AI tools could have an impact on Hollywood. The linked Hollywood Reporter article states that \"Visual effects and other postproduction work stands particularly vulnerable\". I don't know much about that, I can easily believe it would be true, but I don't think they're talking about text-to-video tools like Sora.) reply quickthrower2 13 minutes agorootparentRight now you’d need a artistic/ML mixed team. You wouldn’t use an off the shelf tool. There was a video of some guys doing this (sorry can’t find it) to make an anime type animation. With consistent characters. They used videos of themselves running through their own models to make the characters. So I reckon while prompt -> blockbuster is not here yet, a movie made using mostly AI is possible but it will cost alot now but that cost will go down. Why this is sad it is also exciting. And scary. Black mirror like we will start creating AI’s we will have relationships with and bring people back to life (!) from history and maybe grieving people will do this. Not sure if that is healthy but people will do it once it is a click of a button thing. reply Animats 8 hours agorootparentprevI suspect that one of the first applications will be pre-viz. Before a big-budget movie is made, a cheap version is often made first. This is called \"pre-visualization\". These text to video applications will be ideal for that. Someone will take each scene in the script, write a big prompt describing the scene, and follow it with the dialog, maybe with some commands for camerawork and cuts. Instant movie. Not a very good one, but something you can show to the people who green-light things. There are lots of pre-viz reels on line. The ones for sequels are often quite good, because the CGI character models from the previous movies are available for re-use. Unreal Engine is often used. reply MauranKilom 53 minutes agorootparentprevThe OpenAI announcement mentions being able to provide an image to start the video generation process from. That sounds to me like it will actually be incredibly easy to anchor the video generation to some consistent visual - unlike all the text-based stable diffusion so far. (Yes, there is img2img, but that is not crossing the boundary into a different medium like Sora). reply Karuma 9 hours agorootparentprevIt wouldn't be too hard to do any of the things you mention. See ControlNet for Stable Diffusion, and vid2vid (if this model does txt2vid, it can also do vid2vid very easily). So you can just record some guiding stuff, similar to motion capture but with just any regular phone camera, and morph it into anything you want. You don't even need the camera, of course, a simple 3D animation without textures or lighting would suffice. Also, consistent look has been solved very early on, once we had free models like Stable Diffusion. reply QuadmasterXLII 7 hours agorootparentprevPeople are extrapolating out ten years. They will still have to eat and pay rent in ten years. reply Qwero 2 hours agorootparentprevIt shows that good progress is still made. Just this week sd audio model can make good audio effects like doors etc. If this continues (and it seems it will) it will change the industry tremendously. reply theptip 10 hours agoparentprevProbably a bad time to be an actor. Amazing time to be a wannabe director or producer or similar creative visionary. Bad time to be high up in a hierarchical/gatekeeping/capital-constrained biz like Hollywood. Amazing time to be an aspirant that would otherwise not have access to resources, capital, tools in order to bring their ideas to fruition. On balance I think the ‘20s are going to be a great decade for creativity and the arts. reply gwd 6 hours agorootparent> Probably a bad time to be an actor. I don't see why -- the distance between \"here's something that looks almost like a photo, moving only a little bit like a mannequin\" and \"here's something that has the subtle facial expressions and voice to convey complex emotions\" is pretty freaking huge; to the point where the vast majority of actual humans fail to be that good at it. At any rate, the number of BNNs (biological neural networks) competing with actors has only been growing, with 8 billion and counting. > Amazing time to be a wannabe director or producer or similar creative visionary. Amazing time to be an aspirant that would otherwise not have access to resources, capital, tools in order to bring their ideas to fruition. Perhaps if you mainly want to do things for your own edification. If you want to be able to make a living off it, you're suddenly going to be in a very, very flooded market. reply hackermatic 4 hours agorootparentprevIt's always a bad time to be an actor, between long hours, low pay, and a culture of abuse, but this will definitely make it worse. My writer and artist friends are already despondent from genAI -- it was rare to be able to make art full-time, and even the full-timers were barely making enough money to live. Even people writing and drawing for marketing were not exactly getting rich. I think this will lead to a further hollowing-out of who can afford to be an actor or artist, and we will miss their creativity and perspective in ways we won't even realize. Similarly, so much art benefits from being a group endeavor instead of someone's solo project -- imagine if George Lucas had created Star Wars entirely on his own. Even the newly empowered creators will have to fight to be noticed amid a deluge of carelessly generated spam and sludge. It will be like those weird YouTube Kids videos, but everywhere (or at least like indie and mobile games are now). I think the effect will be that many people turn to big brands known for quality, many people don't care that much, and there will be a massive doughnut hole in between. reply arvinsim 2 hours agorootparent> Even the newly empowered creators will have to fight to be noticed amid a deluge of carelessly generated spam and sludge. It will be like those weird YouTube Kids videos, but everywhere (or at least like indie and mobile games are now). Reminds me of Syndrome's quote in the Incredibles. \"If everyone is super, then no one will be\". reply sva_ 9 hours agorootparentprev> Probably a bad time to be an actor. I'm thinking people will probably still want to see their favorite actors, so established actors may sell the rights to their image. They're sitting on a lot of capital. Bad time to be becoming an actor though. reply lIl-IIIl 4 hours agorootparentYou are talking about movie and TV stars, not actors in general. The vast majority of working actors are not known to the audience. reply Animats 2 hours agorootparentEven the average SAG-AFTRA member barely makes a living wage from acting. And those are the ones that got into the union. There's a whole tier below that. If you spend time in LA, you probably know some actress/model/waitress types. There's also the weird misery of being famous, but not rich. You can't eat fame. reply throwaway743 9 hours agorootparentprevLikely less and less tho given that people will be able to generate a hyper personalized set of actors/characters/personalities in their hyper personalized generated media. Younger generations growing up with hyper personalized media will likely care even less about irl media figures. reply dingclancy 3 hours agoparentprevThe idea that this destroys the industry is overblown, because the film industry has already been dying since 2000's. Hollywood is already destroyed. It is not the powerful entity it once was. In terms of attention and time of entertainment, Youtube has already surpassed them. This will create a multitude more YouTube creators that do not care about getting this right or making a living out of it. It will just take our attention all the same, away from the traditional Hollywood. Yes there will still be great films and franchises, the industry is shrinking. This is similar with Journalism saying that AI will destroy it. Well there was nothing to destroy because the a bunch of traditional newspapers already closed shop even before AI came. reply LegitShady 1 hour agoparentprevWithout a change in copyright law, I doubt it. The current policy of the USCO is that the products of AI based on prompts like this are not human authored and can't be copywritten. No one is going to release AI created stuff that someone else can reproduce because its public domain. reply treesciencebot 15 hours agoprevThis is leaps and bounds beyond anything out there, including both public models like SVD 1.1 and Pika Labs' / Runway's models. Incredible. reply drdaeman 15 hours agoparentLet's hold our breath. Those are specifically crafted hand-picked good videos, where there wasn't any requirement but \"write a generic prompt and pick something that looks good\", with no particular requirements. Which is very different from the actual process where you have a very specific idea and want the machine to make it happen. DALL-E presentation also looked cool and everyone was stoked about it. Now that we know of its limitations and oddities? YMMV, but I'd say not so much - Stable Diffusion is still the go-to solution. I strongly suspect the same thing with Sora. reply treesciencebot 15 hours agorootparentThe examples are most certainly cherry-picked. But the problem is there are 50 of them. And even if you gave me 24 hour full access to SVD1.1/Pika/Runway (anything out there that I can use), I won't be able to get 5 examples that match these in quality (~temporal consistency/motions/prompt following) and more importantly in the length. Maybe I am overly optimistic, but this seems too good. reply htrp 15 hours agorootparentprevhttps://twitter.com/sama/status/1758200420344955288 They're literally taking requests and doing them in 15 minutes. reply drdaeman 14 hours agorootparentCool, but see the drastic difference in quality ;) reply golol 14 hours agorootparentLack of quality in the details yes but the fact that characters and scenes depict consistent and real movement and evolution as opposed to the cinemagraph and frame morphing stuff we have had so far is still remarkable! reply zamadatix 10 hours agorootparentprevThat particular example seems to have more a \"cheap 3d\" style to it but the actual synthesis seems on par with the examples. If the prompt had specified a different style it'd have that style instead. This kind of generation isn't like actual animating, \"cheap 3d\" style and \"realistic cinematic\" style take roughly the same amount of work to look right. reply gigglesupstairs 12 hours agorootparentprevDrastic difference in quality of the prompts too. Ones used in the OP are quite detailed ones mostly. reply karmasimida 13 hours agorootparentprevIt has a comedy like quality lol But all to be said, it is no less impressive after this new demo reply ShamelessC 13 hours agorootparentprevThere are absolutely example videos on their website which have worse quality than that. reply z7 14 hours agorootparentprevDepends on the quality of the prompts. reply minimaxir 14 hours agorootparentprevThe output speed doesn't disprove possible cherry-picking, especially with batch generation. reply efrank3 12 hours agorootparentWho cares? If it can be generated in 15 minutes then it's commercially useful. reply lostemptations5 1 hour agorootparentEspecially of you think that after you can get feedback and try again..15 minutes later have a new one...try again...etc reply djoletina 14 hours ago [flagged]rootparentprevnext [2 more] What is your point? That they make multiple ones and pick out the best ones? Well duh? That’s literally how the model is going to be used. reply dang 13 hours agorootparentPlease make your substantive points without swipes. This is in the site guidelines: https://news.ycombinator.com/newsguidelines.html. reply raydev 13 hours agorootparentprevOpenAI people running these prompts have access to way more resources than any of us will through the API. reply timdiggerm 14 hours agorootparentprevLooks ready for _Wishbone_ reply 999900000999 10 hours agorootparentprevThe year is 2030. Sarah is a video sorter, this was her life. She graduated top of her class in film, and all she could find was the monotonous job of selecting videos that looked just real enough. Until one day, she couldn't believe it. It was her. A video of of her in that very moment sorting. She went to pause the video, but stopped when he doppelganger did the same. reply esafak 4 hours agorootparenthttps://en.wikipedia.org/wiki/Joan_Is_Awful reply Zondartul 3 hours agorootparentI got reminded of an even older sci-fi story: https://qntm.org/responsibility reply turnsout 10 hours agorootparentprevSeems like in about two years I’ll be able to stuff this saved comment into a model and generate this full episode of Black Mirror reply dragonwriter 14 hours agorootparentprev> Stable Diffusion is still the go-to solution. I strongly suspect the same thing with Sora. Sure, for people who want detailed control with AI-generated video, workflows built around SD + AnimateDiff, Stable Video Diffusion, MotionDiff, etc., are still going to beat Sora for the immediate future, and OpenAI's approach structurally isn't as friendly to developing a broad ecosystem adding power on top of the base models. OTOH, the basic simple prompt-to-video capacity of Sora now is good enough for some uses, and where detailed control is not essential that space is going to keep expanding -- one question is how much their plans for safety checking (which they state will apply both to the prompt and every frame of output) will cripple this versus alternatives, and how much the regulatory environment will or won't make it possible to compete with that. reply theLiminator 13 hours agorootparentI suspect given equal effort into prompting both, Sora probably provides superior results. reply dragonwriter 11 hours agorootparent> I suspect given equal effort into prompting both, Sora probably provides superior results Strictly to prompting, probably, just as that is the case with Dall-E 3 vs, say, SDXL. The thing is, there’s a lot more that you can do than just tweaking prompting with open models, compared to hosted models that offer limited interaction options. reply karmasimida 13 hours agorootparentprevGenerate stock video bits I think. reply og_kalu 14 hours agorootparentprevIt doesn't matter if they're cherrypicked when you can't match this quality with SD or Pika regardless of how much time you had. and i still prefer Dalle-3 to SD. reply sebzim4500 14 hours agorootparentprevIn the past the examples tweeted by OpenAI have been fairly representative of the actual capabilities of the model. i.e. maybe they do two or three generations and pick the best, but they aren't spending a huge amount of effort cherry-picking. reply ChildOfChaos 13 hours agorootparentprevStable diffusion is not the go-to solution, it's still behind midjourney and DAllE reply educaysean 13 hours agorootparentprevWould love to see handpicked videos from competitors that can hold their own against what SORA is capable of reply schleck8 12 hours agorootparentprevWrong, this is the first time I've seen an astronaut with a knit cap. reply blibble 14 hours agorootparentprevthey're not fantastic either if you pay close attention there are mini-people in the 2060s market and in the cat one an extra paw comes out of nowhere reply dartos 12 hours agorootparentThe woman’s legs move all weirdly too reply throwaway4233 13 hours agorootparentprevWhile Sora might be able to generate short 60-90 second videos, how well it would scale with a larger prompt or a longer video remains yet to be seen. And the general logic of having the model do 90% of the work for you and then you edit what is required might be harder with videos. reply sebastiennight 12 hours agorootparent60 seconds at a time is much better than enough. Most fictional long-form video (whether live-action movies or cartoons, etc) is composed of many shots, most of them much shorter than 7 seconds, let alone 60. I think the main factor that will be key to generate a whole movie is being able to pass some reference images of the characters/places/objects so they remain congruent between two generations. You could already write a whole book in GPT-3 from running a series of one-short-chapter-at-a-time generations and passing the summary/outline of what's happened so far. (I know I did, in a time that feels like ages ago but was just early last year) Why would this be different? reply throwaway4233 11 hours agorootparent> I think the main factor that will be key to generate a whole movie is being able to pass some reference images of the characters/places/objects so they remain congruent between two generations. I partly agree with this. The congruency however needs to extend to more than 2 generations. If a single scene is composed of multiple shots, then those multiple shots need to be part of the same world the scene is being shot in. If you check the video with the title `A beautiful homemade video showing the people of Lagos, Nigeria in the year 2056. Shot with a mobile phone camera.` the surroundings do not seem to make sense as the view starts with a market, spirals around a point and then ends with a bridge which does not fit into the market. If the the different shots generated the model did fit together seamlessly, trying to make the fit together is where the difficulty comes in. However I do not have any experience in video editing, so it's just speculation. reply esafak 4 hours agorootparentprevThe CGI industry is about to be turned upside down. They charge hundreds of thousands per minute, and it takes them forever to produce the finished product. reply Solvency 11 hours agorootparentprevYou do realize virtually all movies are made up of shots often lasting no longer than 10 seconds. Edited together. Right. reply davidbarker 15 hours agoparentprevI'm almost speechless. I've been keeping an eye on the text-to-video models, and if these example videos are truly indicative of the model, this is an order of magnitude better than anything currently available. In particular, looking at the video titled \"Borneo wildlife on the Kinabatangan River\" (number 7 in the third group), the accurate parallax of the tree stood out to me. I'm so curious to learn how this is working. [Direct link to the video: https://player.vimeo.com/video/913130937?h=469b1c8a45] reply calgoo 15 hours agorootparentThe video of the gold rush town just makes me think of what games like Red Dead and GTA could look like. reply 93po 14 hours agorootparentholy cow, is that the future of gaming? instead of 3D renders it's real-time video generation, complete with audio and music and dialog and intelligent AI conversations and it's a unique experience no one else has ever played. gameplay mechanics could even change on the fly reply joegibbs 12 hours agorootparentI think for the near future we’ll see something like this: https://youtube.com/watch?v=P1IcaBn3ej0 From a few years ago, where the game is rendered traditionally and used as a ground truth, with a model on top of it that enhances the graphics. After maybe 10-15 years we will be past the point where the entire game can be generated without obvious mistakes in consistency. Realtime AI dialogue is already possible but still a bit primitive, I wrote a blog post about it here: https://jgibbs.dev/blogs/local-llm-npcs-in-unreal-engine reply gdubs 14 hours agorootparentprevThat's why NVIDIA's CEO said recently that in the future every pixel will be generated — not rendered. reply Keyframe 12 hours agorootparentfive years ago: https://www.youtube.com/watch?v=ayPqjPekn7g I'm eager to see an updated version. reply dartos 12 hours agorootparentprevSometimes, but for specific or unique art styles, statistical models like this may not work well. For games like call of duty or other hyper realistic games it very likely will be. reply arvinsim 2 hours agorootparentFor games like 2D/3D fighting games where you don't to generate a lot of terrain, the possibilities of randomly generating stages with unique terrain and obstacles is interesting. reply yard2010 12 hours agorootparentprevThe answer is most definitely YES. Computer games, and of course, porn, the stuff the internet is made up for. reply monlockandkey 14 hours agorootparentprevShove all the tech you mentioned into a VR headset and it is literally game over for humans reply rightbyte 12 hours agorootparentYou'd still get a headache after 20 minutes. No matter how addictive, it wont be bad until you can wear VR headsets for hours. reply theshackleford 5 hours agorootparentMany people can. I can and have been since the DK1. I’ve done 12 hour plus stints in it. reply arathis 39 minutes agorootparentlol horseshit reply krapp 12 hours agorootparentprevEven otherwise, and no matter how good the screen and speakers are, a screen and speakers can only be so immersive. People oversell the potential for VR when they describe it as being as good as or better than reality. Nothing less than the Matrix is going to work in that regard. reply trafficante 11 hours agorootparentYep, once your brain gets over the immediate novelty of VR, it’s very difficult to get back that “Ready Player One” feeling due to the absence of sensory feedback. If/once they get it working though, society will shift fast. There’s an XR app called Brink Traveler that’s full of handcrafted photogrammetry recreations of scenic landmarks. On especially gloomy PNW winter days, I’ll lug a heat lamp to my kitchen and let it warm up the tiled stone a bit, put a floor fan on random oscillation, toss on some good headphones, load up a sunny desert location in VR, and just lounge on the warm stone floor for an hour. My conscious brain “knows” this isn’t real and just visuals alone can’t fool it anymore, but after about 15 minutes of visuals + sensory input matching, it stops caring entirely. I’ve caught myself reflexively squinting at the virtual sun even though my headset doesn’t have HDR. reply Xirgil 13 hours agorootparentprevDigital Westworld reply notpachet 11 hours agorootparentprevLucid Dreaming as a Service. See also: https://en.wikipedia.org/wiki/Vanilla_Sky reply QuadmasterXLII 12 hours agorootparentprevThe diffusion is almost certainly taking place over some sort of compressed latent, from the visual quirks of the output I suspect that the process of turning that latent into images goes latent -> nerf / splat -> image, not latent -> convolutional decoder -> image reply Zelphyr 15 hours agoparentprevAgreed. It's amazing how much of a head start OpenAI appears to have over everyone else. Even Microsoft who has access to everything OpenAI is doing. Only Microsoft could be given the keys to the kingdom and still not figure out how to open any doors with them. reply Voloskaya 15 hours agorootparentMicrosoft doesn’t have access to OpenAI’s research, this was part of the deal. They only have access to the weights and inference code of production models and even then who has access to that inside MS is extremely gated and only a few employees have access to this based on absolute need to actually run the service. AI researcher at MSFT barely have more insights about OpenAI than you do reading HN. reply vitorgrs 3 hours agorootparentNo. They have early access. Example: MSFT was using Dall-e Exp (early 3 version) in PUBLIC, since February of 2023. In the same month, they were also using GPT4 in public - before OpenAI. And they had access to GPT4 in 2022 (which was when they decided to create Bing Chat, now called Copilot). All the current GPT4 models at MSFT are also finetuned versions (literally Creative and Precise mode runs different finetuned versions of GPT4). It runs finetuned versions since launch even... reply toneyG 15 hours agorootparentprevThis is not true. Microsoft have a perpetual license to all of OpenAI's IP. If they really wanted to they could get their hands on it. reply 93po 14 hours agorootparentYeah but what's in the license? It's not public so we have no way of knowing reply Zelphyr 15 hours agorootparentprevI didn't realize that. Thank you for the clarification. reply costcofries 13 hours agorootparentprevI promise you this isn't true. reply Jensson 13 hours agorootparentprevMicrosoft said that they could continue OpenAI's research with no slowdown if OpenAI cut them off by hiring all OpenAI's people, so from that statement it sounds like they have access. reply pcbro141 15 hours agorootparentprevMany people say the same about Google/DeepMind. reply SeanAnderson 15 hours agorootparentprevEh. MSFT owns 49% of OpenAI. Doesn't really seem like they need to do much except support them. reply Zelphyr 15 hours agorootparentExcept they keep trying to shove AI into everything they own. CoPilot Studio is an example of how laughably bad at it they are. I honestly don't understand why they don't contract out to OpenAI to help them do some of these integrations. reply SeanAnderson 15 hours agorootparentEvery company is trying to shove AI into everything they own. It's what investors currently demand. OpenAI is likely limited by how fast they are able to scale their hiring. They had 778 FTEs when all the board drama occurred, up 100% YoY. Microsoft has 221,000. It seems difficult to delegate enough headcount to all the exploratory projects of MSFT and it's hard to scale headcount quicker while preserving some semblance of culture. reply frabcus 13 hours agorootparentprevThey don't own 49% of OpenAI. They have capped rights to 49% of OpenAI's profits. reply SeanAnderson 13 hours agorootparentApparently all the rumors weren't true then, my mistake. I don't think what you're saying is correct though, either. All the early news outlets reported 49% ownership: https://en.wikipedia.org/wiki/OpenAI#:~:text=Rumors%20of%20t... https://www.theverge.com/2023/1/23/23567448/microsoft-openai... https://www.reuters.com/world/uk/uk-antitrust-regulator-cons... https://techcrunch.com/2023/01/23/microsoft-invests-billions... The only official statement from Micorosft is \"While details of our agreement remain confidential, it is important to note that Microsoft does not own any portion of OpenAI and is simply entitled to share of profit distributions,\" said company spokesman Frank Shaw. No numbers, though. Do you have a better source for numbers? reply sschueller 14 hours agoparentprevYes, but I am stuck in their (American) view of what is consider appropriate. Not what is legal, but what they determine to be OK to produce. Good luck generating anything similar to an 80s action movie. The violence and light nudity will prevent you from generating anything. reply throwitaway222 13 hours agorootparentI am guessing a movie studio will get different access with controls dropped. Of course, that does mean they need to be VERY careful when editing, and making sure not to release a vagina that appears for 1 or 2 frames when a woman is picking up a cat in some random scene. reply Fricken 12 hours agorootparentWe can't do narrative sequences with persistent characters and settings, even with static images. These video clips just generic stock clips. You cut cut them together to make a sequence of random flashy whatever, but you still can't do storytelling in any conventional sense. We don't appear to be close to being able to use these tools for the hypothetical disruptive use case we worry about. Nonetheless, The stock video and photo people are in trouble. So long as the details don't matter this stuff is presumably useful. reply Xirgil 13 hours agorootparentprevI suspect it's less about being puritanical about violence and nudity in and of themself, and more a blanket ban to make up for the inability to prevent the generation of actually controversial material (nude images of pop stars, violence against politicians, hate speech) reply SamBam 13 hours agorootparentPut like that, it's a bit like the Chumra in Judaism [1]. The fence, or moat, around the law that extends even further than the law itself, to prevent you from accidentally commiting a sin. 1. https://en.m.wikipedia.org/wiki/Chumra_(Judaism) reply UberFly 12 hours agorootparentNa. It's more like what he said: Cover your ass legally for the real problems this could cause. reply wilg 13 hours agorootparentprevNo, it's America's fault. reply zamadatix 10 hours agorootparentprevI wonder how much of it is really \"concern for the children\" type stuff vs not wanting to deal with fights on what should be allowed and how and to who right now. When film was new towns and states started to make censorship review boards. When mature content became viewable on the web battles (still ongoing) about how much you need to do to prevent minors from accessing it came up. Now useful AI generated content is the new thing and you can avoid this kind of distraction by going this route instead. I'm not supporting it in any way, I think you should be able to generate and distribute any legal content with the tools, but just giving a possible motive for OpenAI being so conservative whenever it comes to ethics and what they are making. reply TulliusCicero 13 hours agorootparentprevIt's not a particularly American attitude to be opposed to violence in media though, American media has plenty of violence. They're trying to be all-around uncontroversial. reply golergka 8 hours agorootparentprevI've been watching 80s movies recently, and amount of nudity and sex scenes often feels unnecessary. I'm definitely not a prude. I watch porn, I talk about sex with friends, I go to kinky parties sometimes. But it really feels that a lot of movies sacrificed stories to increase sex appeal — and now that people have free and unlimited access to porn, movies can finally be movies. reply jsheard 15 hours agoparentprevWhere is the training material for this coming from? The only resource I can think of that's broad enough for a general purpose video model is YouTube, but I can't imagine Google would allow a third party to scrape all of YT without putting up a fight. reply Zetobal 15 hours agorootparentIt's movies the shots are way to deliberate to have random YouTube crap in the dataset. reply cma 13 hours agorootparentYou can still have a broad dataset and use RLHF to steer it more towards the aesthetic like midjourney and SDXL did through discord feedback. I think there was still some aesthetic selection in the dataset as well but it still included a lot of crap. reply xnx 15 hours agoparentprevIt's very good. Unclear how far ahead of Lumiere it is (https://lumiere-video.github.io/) or if its more of a difference in prompting/setttings. reply vunderba 12 hours agorootparentThe big stand out to me beyond almost any other text video solution is that the video duration is tremendously longer (minute+). Everything else that I've seen can't get beyond 15 to 20 seconds at the absolute maximum. reply ehsankia 15 hours agorootparentprevIn terms of following the prompt and generating visually interesting results, I think they're comparable. But the resolution for Sora seems so far ahead. Worth noting that Google also has Phenaki [0] and VideoPoet [1] and Imagen Video [2] [0] https://sites.research.google/phenaki/ [1] https://sites.research.google/videopoet/ [2] https://imagen.research.google/video/ reply mizzao 15 hours agoparentprevMust be intimidating to be on the Pika team at the moment... reply alokjnv10 4 hours agorootparentyou nailed it reply jasonjmcghee 13 hours agoparentprevI agree in terms of raw generation, but runway especially is creating fantastic tooling too. reply JKCalhoun 13 hours agoparentprevI know it's Runway (and has all manner of those dream-like AI artifacts) but I like what this person is doing with just a bunch 4 second clips and an awesome soundtrack: https://youtu.be/JClloSKh_dk https://youtu.be/upCyXbTWKvQ reply rvz 12 hours agoparentprevAll those startups have been squeezed in the middle. Pika, Runway, etc might as well open source their models. Or Meta will do it for them. reply iLoveOncall 15 hours agoparentprevIt is incredible indeed, but I remember there was a humongous gap between the demoed pictures for DALL-E and what most prompts would generate. Don't get overly excited until you can actually use the technology. reply jug 13 hours agoparentprevYup, it's been even several months! ;) But now we finally have another quantum leap in AI. reply 1401 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Sora is an AI model created by OpenAI that generates realistic and creative videos based on text instructions.",
      "It aims to address real-world interaction challenges and has the capability to create intricate scenes.",
      "While it excels in many areas, it has limitations in comprehending cause and effect as well as accurately simulating physics."
    ],
    "commentSummary": [
      "The discussion explores the capabilities of text-to-video models and their potential impact on the entertainment industry.",
      "Participants express both excitement and skepticism about AI technology and discuss concerns about the ethical and societal implications of AI-generated content.",
      "The value of human involvement in creative fields, particularly music, is discussed, as well as the challenges faced by startups in the AI industry."
    ],
    "points": 2910,
    "commentCount": 1676,
    "retryCount": 0,
    "time": 1708020858
  },
  {
    "id": 39383446,
    "title": "Google unveils Gemini 1.5: Next-gen AI model for enhanced performance and long-context understanding",
    "originLink": "https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/",
    "originBody": "AI Our next-generation model: Gemini 1.5 Feb 15, 2024 min read Share Twitter Facebook LinkedIn Mail Copy link The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities. Sundar Pichai CEO of Google and Alphabet Demis Hassabis CEO of Google DeepMind Share Twitter Facebook LinkedIn Mail Copy link In this story In this story Note from Sundar Introducing Gemini 1.5 Efficient architecture Long context window Enhanced performance Ethics and safety testing Build with Gemini A note from Google and Alphabet CEO Sundar Pichai: Last week, we rolled out our most capable model, Gemini 1.0 Ultra, and took a significant step forward in making Google products more helpful, starting with Gemini Advanced. Today, developers and Cloud customers can begin building with 1.0 Ultra too — with our Gemini API in AI Studio and in Vertex AI. Our teams continue pushing the frontiers of our latest models with safety at the core. They are making rapid progress. In fact, we’re ready to introduce the next generation: Gemini 1.5. It shows dramatic improvements across a number of dimensions and 1.5 Pro achieves comparable quality to 1.0 Ultra, while using less compute. This new generation also delivers a breakthrough in long-context understanding. We’ve been able to significantly increase the amount of information our models can process — running up to 1 million tokens consistently, achieving the longest context window of any large-scale foundation model yet. Longer context windows show us the promise of what is possible. They will enable entirely new capabilities and help developers build much more useful models and applications. We’re excited to offer a limited preview of this experimental feature to developers and enterprise customers. Demis shares more on capabilities, safety and availability below. — Sundar Introducing Gemini 1.5 By Demis Hassabis, CEO of Google DeepMind, on behalf of the Gemini team This is an exciting time for AI. New advances in the field have the potential to make AI more helpful for billions of people over the coming years. Since introducing Gemini 1.0, we’ve been testing, refining and enhancing its capabilities. Today, we’re announcing our next-generation model: Gemini 1.5. Gemini 1.5 delivers dramatically enhanced performance. It represents a step change in our approach, building upon research and engineering innovations across nearly every part of our foundation model development and infrastructure. This includes making Gemini 1.5 more efficient to train and serve, with a new Mixture-of-Experts (MoE) architecture. The first Gemini 1.5 model we’re releasing for early testing is Gemini 1.5 Pro. It’s a mid-size multimodal model, optimized for scaling across a wide-range of tasks, and performs at a similar level to 1.0 Ultra, our largest model to date. It also introduces a breakthrough experimental feature in long-context understanding. Gemini 1.5 Pro comes with a standard 128,000 token context window. But starting today, a limited group of developers and enterprise customers can try it with a context window of up to 1 million tokens via AI Studio and Vertex AI in private preview. As we roll out the full 1 million token context window, we’re actively working on optimizations to improve latency, reduce computational requirements and enhance the user experience. We’re excited for people to try this breakthrough capability, and we share more details on future availability below. These continued advances in our next-generation models will open up new possibilities for people, developers and enterprises to create, discover and build using AI. Context lengths of leading foundation models Highly efficient architecture Gemini 1.5 is built upon our leading research on Transformer and MoE architecture. While a traditional Transformer functions as one large neural network, MoE models are divided into smaller \"expert” neural networks. Depending on the type of input given, MoE models learn to selectively activate only the most relevant expert pathways in its neural network. This specialization massively enhances the model’s efficiency. Google has been an early adopter and pioneer of the MoE technique for deep learning through research such as Sparsely-Gated MoE, GShard-Transformer, Switch-Transformer, M4 and more. Our latest innovations in model architecture allow Gemini 1.5 to learn complex tasks more quickly and maintain quality, while being more efficient to train and serve. These efficiencies are helping our teams iterate, train and deliver more advanced versions of Gemini faster than ever before, and we’re working on further optimizations. Greater context, more helpful capabilities An AI model’s “context window” is made up of tokens, which are the building blocks used for processing information. Tokens can be entire parts or subsections of words, images, videos, audio or code. The bigger a model’s context window, the more information it can take in and process in a given prompt — making its output more consistent, relevant and useful. Through a series of machine learning innovations, we’ve increased 1.5 Pro’s context window capacity far beyond the original 32,000 tokens for Gemini 1.0. We can now run up to 1 million tokens in production. This means 1.5 Pro can process vast amounts of information in one go — including 1 hour of video, 11 hours of audio, codebases with over 30,000 lines of code or over 700,000 words. In our research, we’ve also successfully tested up to 10 million tokens. Complex reasoning about vast amounts of information 1.5 Pro can seamlessly analyze, classify and summarize large amounts of content within a given prompt. For example, when given the 402-page transcripts from Apollo 11’s mission to the moon, it can reason about conversations, events and details found across the document. 10:25 Gemini 1.5 Pro can understand, reason about and identify curious details in the 402-page transcripts from Apollo 11’s mission to the moon. Better understanding and reasoning across modalities 1.5 Pro can perform highly-sophisticated understanding and reasoning tasks for different modalities, including video. For instance, when given a 44-minute silent Buster Keaton movie, the model can accurately analyze various plot points and events, and even reason about small details in the movie that could easily be missed. 10:25 Gemini 1.5 Pro can identify a scene in a 44-minute silent Buster Keaton movie when given a simple line drawing as reference material for a real-life object. Relevant problem-solving with longer blocks of code 1.5 Pro can perform more relevant problem-solving tasks across longer blocks of code. When given a prompt with more than 100,000 lines of code, it can better reason across examples, suggest helpful modifications and give explanations about how different parts of the code works. 10:25 Gemini 1.5 Pro can reason across 100,000 lines of code giving helpful solutions, modifications and explanations. Enhanced performance When tested on a comprehensive panel of text, code, image, audio and video evaluations, 1.5 Pro outperforms 1.0 Pro on 87% of the benchmarks used for developing our large language models (LLMs). And when compared to 1.0 Ultra on the same benchmarks, it performs at a broadly similar level. Gemini 1.5 Pro maintains high levels of performance even as its context window increases. In the Needle In A Haystack (NIAH) evaluation, where a small piece of text containing a particular fact or statement is purposely placed within a long block of text, 1.5 Pro found the embedded text 99% of the time, in blocks of data as long as 1 million tokens. Gemini 1.5 Pro also shows impressive “in-context learning” skills, meaning that it can learn a new skill from information given in a long prompt, without needing additional fine-tuning. We tested this skill on the Machine Translation from One Book (MTOB) benchmark, which shows how well the model learns from information it’s never seen before. When given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person learning from the same content. As 1.5 Pro’s long context window is the first of its kind among large-scale models, we’re continuously developing new evaluations and benchmarks for testing its novel capabilities. For more details, see our Gemini 1.5 Pro technical report. Extensive ethics and safety testing In line with our AI Principles and robust safety policies, we’re ensuring our models undergo extensive ethics and safety tests. We then integrate these research learnings into our governance processes and model development and evaluations to continuously improve our AI systems. Since introducing 1.0 Ultra in December, our teams have continued refining the model, making it safer for a wider release. We’ve also conducted novel research on safety risks and developed red-teaming techniques to test for a range of potential harms. In advance of releasing 1.5 Pro, we've taken the same approach to responsible deployment as we did for our Gemini 1.0 models, conducting extensive evaluations across areas including content safety and representational harms, and will continue to expand this testing. Beyond this, we’re developing further tests that account for the novel long-context capabilities of 1.5 Pro. Build and experiment with Gemini models We’re committed to bringing each new generation of Gemini models to billions of people, developers and enterprises around the world responsibly. Starting today, we’re offering a limited preview of 1.5 Pro to developers and enterprise customers via AI Studio and Vertex AI. Read more about this on our Google for Developers blog and Google Cloud blog. We’ll introduce 1.5 Pro with a standard 128,000 token context window when the model is ready for a wider release. Coming soon, we plan to introduce pricing tiers that start at the standard 128,000 context window and scale up to 1 million tokens, as we improve the model. Early testers can try the 1 million token context window at no cost during the testing period, though they should expect longer latency times with this experimental feature. Significant improvements in speed are also on the horizon. Developers interested in testing 1.5 Pro can sign up now in AI Studio, while enterprise customers can reach out to their Vertex AI account team. Learn more about Gemini’s capabilities and see how it works. Get more stories from Google in your inbox. Email address Your information will be used in accordance with Google's privacy policy. Subscribe Done. Just one step more. Check your inbox to confirm your subscription. You are already subscribed to our newsletter. You can also subscribe with a different email address . POSTED IN: AI Developers Google Cloud Google DeepMind",
    "commentLink": "https://news.ycombinator.com/item?id=39383446",
    "commentBody": "Our next-generation model: Gemini 1.5 (blog.google)1082 points by todsacerdoti 18 hours agohidepastfavorite514 comments vessenes 17 hours agoThe white paper is worth a read. The things that stand out to me are: 1. They don't talk about how they get to 10M token context 2. They don't talk about how they get to 10M token context 3. The 10M context ability wipes out most RAG stack complexity immediately. (I imagine creating caching abilities is going to be important for a lot of long token chatting features now, though). This is going to make things much, much simpler for a lot of use cases. 4. They are pretty clear that 1.5 Pro is better than GPT-4 in general, and therefore we have a new LLM-as-judge leader, which is pretty interesting. 5. It seems like 1.5 Ultra is going to be highly capable. 1.5 Pro is already very very capable. They are running up against very high scores on many tests, and took a minute to call out some tests where they scored badly as mostly returning false negatives. Upshot, 1.5 Pro looks like it should set the bar for a bunch of workflow tasks, if we can ever get our hands on it. I've found 1.0 Ultra to be very capable, if a bit slow. Open models downstream should see a significant uptick in quality using it, which is great. Time to dust out my coding test again, I think, which is: \"here is a tarball of a repository. Write a new module that does X\". I really want to know how they're getting to 10M context, though. There are some intriguing clues in their results that this isn't just a single ultra-long vector; for instance, their audio and video \"needle\" tests, which just include inserting an image that says \"the magic word is: xxx\", or an audio clip that says the same thing, have perfect recall across up to 10M tokens. The text insertion occasionally fails. I'd speculate that this means there is some sort of compression going on; a full video frame with text on it is going to use a lot more tokens than the text needle. reply swalsh 17 hours agoparent\"The 10M context ability wipes out most RAG stack complexity immediately.\" I'm skeptical, my past experience is just becaues the context has room to stuff whatever you want in it, the more you stuff in the context the less accurate your results are. There seems to be this balance of providing enough that you'll get high quality answers, but not too much that the model is overwhelmed. I think a large part of developing better models is not just a better architectures that support larger and larger context sizes, but also capable models that can properly leverage that context. That's the test for me. reply HereBePandas 16 hours agorootparentThey explicitly address this in page 11 of the report. Basically perfect recall for up to 1M tokens; way better than GPT-4. reply westoncb 16 hours agorootparentI don't think recall really addresses it sufficiently: the main issue I see is answers getting \"muddy\". Like it's getting pulled in too many directions and averaging. reply a_wild_dandan 16 hours agorootparentI'd urge caution in extending generalizations about \"muddiness\" to a new context architecture. Let's use the thing first. reply westoncb 14 hours agorootparentI'm not saying it applies to the new architecture, I'm saying that's a big issue I've observed in existing models and that so far we have no info on whether it's solved in the new one (i.e. accurate recall doesn't imply much in that regard). reply a_wild_dandan 13 hours agorootparentAh, apologies for the misunderstanding. What tests would you suggest to evaluate \"muddiness\"? What comes to my mind: run the usual gamut of tests, but with the excess context window saturated with irrelevant(?) data. Measure test answer accuracy/verbosity as a function of context saturation percentage. If there's little correlation between these two variables (e.g. 9% saturation is just as accurate/succinct as 99% saturation), then \"muddiness\" isn't an issue. reply danielmarkbruce 11 hours agorootparentManual testing on complex documents. A big legal contract for example. An issue can be referred to in 7 different places in a 100 page document. Does it give a coherent answer? A handful of examples show whether it can do it. For example, GPT-4 turbo is downright awful at something like that. reply somenameforme 4 hours agorootparentprevYou need to use relevant data. The question isn't random sorting/pruning, but being able to apply large numbers of related hints/references/definitions in a meaningful way. To me this would be the entire point of a large context window. For entirely different topics you can always just start a new instance. reply westoncb 14 hours agorootparentprevWould be awesome if it is solved but seems like a much deeper problem tbh. reply mlsu 4 hours agorootparentprevI am skeptical of benchmarks in general, to be honest. It seems to be extremely difficult to come up with benchmarks for these things (it may be true of intelligence as a quality...). It's almost an anti-signal to proclaim good results on benchmarks. The best barometer of model quality has been vibes, in places like /r/localllama where cracked posters are actively testing the newest models out. Based on Google's track record in the area of text chatbots, I am extremely skeptical of their claims about coherency across a 1M+ context window. Of course none of this even matters anyway because the weights are closed the architecture is closed nobody has access to the model. I'll believe it when I see it. reply smeagull 12 hours agorootparentprevI believe that's a limitation of using vectors of high dimensions. It'll be muddy. reply Aeolun 5 hours agorootparentNot unlike trying to keep the whole contents of the document in your own mind :) reply sirsinsalot 10 minutes agorootparentIt's amazing we are in 2024 discussing the degree a machine can reason over millions of tokens of context. The degree, not the possibility. caesil 10 hours agorootparentprevUnfortunately Google's track record with language models is one of overpromising and underdelivering. reply chaxor 9 hours agorootparentThis is only specifically for web interface LLMs in the past few years that it's been lack luster. However, this statements is not correct for their overall history. W2V based lang models and BERT/Transformer models in the early days (*publicly available, but not in web interface) were far ahead of the curve, as they were the ones that produced these innovations. Effectively, Deepmmind/Google are academics (where the real innovations are made, but they do struggle to produce corporate products (where openai shines). reply andy_ppp 1 hour agorootparentprevDid you think the extraction of information from a the Buster Keaton film was muddy? I thought it was incredibly impressive to be this precise. reply koliber 1 hour agorootparentprevLLMs are able to utilize “all the worlds” knowledge during training and give seemingly magical answers. While providing context in the query is different than training models, is it possible that more context will give more materials to the LLM and it will be able to pick out the relevant bits on its own? What if it was possible, with each query, to fine tune the model on the provided context, and then use that JIT fine-tuned model to answer the query? reply chuckcode 16 hours agorootparentprevWould like to see the latency and cost of parsing entire 10M context before throwing out the RAG stack which is relatively cheap and fast. reply theolivenbaum 14 hours agorootparentprevAlso unless they significantly change their pricing model, we're talking about 0.5$ per API call at current prices reply patja 9 hours agorootparentprevI think there are also a lot of people who are only interested in RAG if they can self-host and keep their documents private. reply jimmySixDOF 5 hours agorootparentYes and the ability to have direct attribution matters so you know exactly where your responses come from. And costs as others point out, but RAG is not gone in fact it just got easier and a lot more powerful. reply aik 13 hours agorootparentprevHave to consider cost for all of this. Big value of RAG already even given the size of GPT-4’a largest context size is it decreases cost very significantly. reply tkellogg 15 hours agorootparentprevcosts rise on a per-token basis. So you CAN use 10M tokens, but it's probably not usually a good idea. A database lookup is still better than a few billion math operations. reply sjwhevvvvvsj 13 hours agorootparentI think the unspoken goal is to just lay off your employees and dump every doc and email they’ve ever written as one big context. Now that Google has tasted the previously forbidden fruit of layoffs themselves, I think their primary goal in ML is now headcount reduction. reply swyx 16 hours agorootparentprevalso costs are always based on context token, you dont want to put in 10m of context for every request (its just nice to have that option when you want to do big things that dont scale) reply 1024core 11 hours agorootparentHow much would a lawyer charge to review your 10M-token legal document? reply hereonout2 9 hours agorootparent10M tokens is something like 14 copies of war and peace, or maybe the entire harry potter series seven times over. That'd be some legal document! reply xp84 5 hours agorootparentHmm I don’t know but I feel like the U.S. Congress has bills that would push that limit. reply usaar333 17 hours agoparentprev> They are pretty clear that 1.5 Pro is better than GPT-4 in general, and therefore we have a new LLM-as-judge leader, which is pretty interesting. They try to push that, but it's not the most convincing. Look at Table 8 for text evaluations (math, etc.) - they don't even attempt a comparison with GPT-4. GPT-4 is higher than any Gemini model on both MMLU and GSM8K. Gemini Pro seems slightly better than GPT-4 original in Human Eval (67->71). Gemini Pro does crush naive GPT-4 on math (though not with code interpreter and this is the original model). All in 1.5 Pro seems maybe a bit better than 1.0 Ultra. Given that in the wild people seem to find GPT-4 better for say coding than Gemini Ultra, my current update is Pro 1.5 is about equal to GPT-4. But we'll see once released. reply panarky 16 hours agorootparent> people seem to find GPT-4 better for say coding than Gemini Ultra For my use cases, Gemini Ultra performs significantly better than GPT-4. My prompts are long and complex, with a paragraph or two about the general objective followed by 15 to 20 numbered requirements. Often I'll include existing functions the new code needs to work with, or functions that must be refactored to handle the new requirements. I took 20 prompts that I'd run with GPT-4 and fed them to Gemini Ultra. Gemini gave a clearly better result in 16 out of 20 cases. Where GPT-4 might miss one or two requirements, Gemini usually got them all. Where GPT-4 might require multiple chat turns to point out its errors and omissions and tell it to fix them, Gemini often returned the result I wanted in one shot. Where GPT-4 hallucinated a method that doesn't exist, or had been deprecated years ago, Gemini used correct methods. Where GPT-4 called methods of third-party packages it assumed were installed, Gemini either used native code or explicitly called out the dependency. For the 4 out of 20 prompts where Gemini did worse, one was a weird rejection where I'd included an image in the prompt and Gemini refused to work with it because it had unrecognizable human forms in the distance. Another was a simple bash script to split a text file, and it came up with a technically correct but complex one-liner, while GPT-4 just used split with simple options to get the same result. For now I subscribe to both. But I'm using Gemini for almost all coding work, only checking in with GPT-4 when Gemini stumbles, which isn't often. If I continue to get solid results I'll drop the GPT-4 subscription. reply sho_hn 16 hours agorootparentI have a very similar prompting style to yours and share this experience. I am an experienced programmer and usually have a fairly exact idea of what I want, so I write detailed requirements and use the models more as typing accelerators. GPT-4 is useful in this regard, but I also tried about a dozen older prompts on Gemini Advanced/Ultra recently and in every case preferred the Ultra output. The code was usually more complete and prod-ready, with higher sophistication in its construction and somewhat higher density. It was just closer to what I would have hand-written. It's increasingly clear though LLM use has a couple of different major modes among end-user behavior. Knowledge base vs. reasoning, exploratory vs. completion, instruction following vs. getting suggestions, etc. For programming I want an obedient instruction-following completer with great reasoning. Gemini Ultra seems to do this better than GPT-4 for me. reply sjwhevvvvvsj 13 hours agorootparentI’m going to have to try Gemini for code again. It just occurred to me as a Xoogler that if they used Google’s code base as the training data it’s going to be unbeatable. Now did they do that? No idea, but quality wins over quantity, even with LLM. reply barrkel 12 hours agorootparentThere is no way NTK data is in the training set, and google3 is NTK. reply sjwhevvvvvsj 8 hours agorootparentI dunno, leadership is desperate and they can de-NTK if and when they feel like it. reply cpeterso 8 hours agorootparentprevWhat is “NTK”? reply mjamaloney 7 hours agorootparent\"Need To Know\" I.e. data that isn't open within the company. reply lyu07282 10 hours agorootparentprevIt constantly hallucinates APIs for me, I really wonder why people's perceptions are so radically different. For me it's basically unusable for coding. Perhaps I'm getting a cheaper model because I live in a poorer country. reply sho_hn 9 hours agorootparentAre you using Gemini Advanced? (The paid tier.) The free one is indeed very bad. reply oceanplexian 50 minutes agorootparentI asked Gemini Advanced, the paid one, to \"Write a script to delete some files\" and it told me that it couldn't do that because deleting files was unethical. At that point I cancelled my subscription since even GPT-4 with all its problems isn't nearly as broken as Gemini. reply koreth1 8 hours agorootparentprev> My prompts are long and complex, with a paragraph or two about the general objective followed by 15 to 20 numbered requirements. Often I'll include existing functions the new code needs to work with, or functions that must be refactored to handle the new requirements. I guess this is a tough request if you're working on a proprietary code base, but I would love to see some concrete examples of the prompts and the code they produce. I keep trying this kind of prompting with various LLM tools including GPT-4 (haven't tried Gemini Ultra yet, I admit) and it nearly always takes me longer to explain the detailed requirements and clean up the generated code than it would have taken me to write the code directly. But plenty of people seem to have an experience more like yours, so I really wonder whether (a) we're just asking it to write very different kinds of code, or (b) I'm bad at writing LLM-friendly requirements. reply vineyardmike 4 hours agorootparentNot OP but here is a verbatim prompt I put into these LLMs. I'm learning to make flutter apps, and I like to try make various UIs so I can learn how to compose some things. I agree that Gemini Ultra (aka the paid \"advanced\" mode) is def better than ChatGPT-4 for this prompt. Mine is a bit more terse than OP's huge prompt with numbered requirements, but I still got a super valid and meaningful response from Gemini, while GPT4 told me it was a tricky problem, and gave me some generic code snippets, that explicitly don't solve the problem asked. > I'm building a note-taking app in flutter. I want to create a way to link between notes (like a web hyperlink) that opens a different note when a user clicks on it. They should be able to click on the link while editing the note, without having to switch modalities (eg. no edit-save-view flow nor a preview page). How can I accomplish this? I also included a follow-up prompt after getting the first answer, which again for Gemini was super meaningful, and already included valid code to start with. Gemini also showed me many more projects and examples from the broader internet. > Can you write a complete Widget that can implement this functionality? Please hard-code the note text below:reply Dayshine 16 hours agorootparentprevIs there any chance you could share an example of the kind of prompt you're writing? I'm always reluctant to write long prompts because I often find GPT4 just doesn't get it, and then I've wasted ten minutes writing a prompt reply qingcharles 9 hours agorootparentprevI've found Gemini generally equal with the .Net and HTML coding I've been doing. I've never had Gemini give me a better result than GPT, though, so it does not surpass it for my needs. The UI is more responsive, though, which is worth something. reply TaylorAlexander 8 hours agorootparentprevHow do you interact with Gemini for coding work? I am trying to paste my code in the web interface and when I hit submit, the interface says \"something went wrong\" and the code does not appear in the chat window. I signed up for Gemini Advanced and that didn't help. Do you use AI Studio? I am just looking in to that now. reply spott 15 hours agorootparentprev> Gemini Pro seems slightly better than GPT-4 original in Human Eval (67->71). Though they talk a bunch about how hard it was to filter out Human Eval, so this probably doesn't matter much. reply cchance 16 hours agorootparentprevI mean i don't see GPT4 watching a 44 minute movie and being able to exactly pinpoint a guy taking a paper out of his pocket.. reply CharlieDigital 17 hours agoparentprev> The 10M context ability wipes out most RAG stack complexity immediately. Remains to be seen. Large contexts are not always better. For starters, it takes longer to process. But secondly, even with RAG and the large context of GPT4 Turbo, providing it a more relevant and accurate context always yields better output. What you get with RAG is faster response times and more accurate answers by pre-filtering out the noise. reply killerstorm 17 hours agorootparentHopefully we can get a better RAG out of it. Currently people do incredibly primitive stuff like chunking text into chunks of a fixed size and adding them to vector DB. An actually useful RAG would be to convert text to Q&A and use Q's embeddings as an index. Large context can make use of in-context learning to make better Q&A. reply mediaman 15 hours agorootparentA lot of people in RAG already do this. I do this with my product: we process each page and create lists of potential questions that the page would answer, and then embed that. We also embed the actual text, though, because I found that only doing the questions resulted in inferior performance. reply CharlieDigital 15 hours agorootparentSo in this case, what your workflow might look like is: 1. Get text from page/section/chunk 2. Generate possible questions related to the page/section/chunk 3. Generate an embedding using { each possible question + page/section/chunk } 4. Incoming question targets the embedding and matches against { question + source } Is this roughly it? How many questions do you generate? Do you save a separate embedding for each question? Or just stuff all of the questions back with the page/section/chunk? reply mediaman 1 hour agorootparentRight now I just throw the different questions together in a single embedding for a given chunk, with the idea that there’s enough dimensionality to capture them all. But I haven’t tested embedding each question, matching on that vector, and then returning the corresponding chunk. That seems like it’d be worth testing out. reply behnamoh 17 hours agorootparentprevDon't forget that Gemini also has access to the internet, so a lot of RAGging becomes pointless anyway. reply beppo 17 hours agorootparentInternet search is a form of RAG, though. 10M tokens is very impressive, but you're not fitting a database, let alone the entire internet into a prompt anytime soon. reply behnamoh 17 hours agorootparentYou shouldn't fit an entire database in the context anyway. btw, 10M tokens is 78 times more context window than the newest GPT-4-turbo (128K). In a way, you don't need 78 GPT-4 API calls, only one batch call to Gemini 1.5. reply cchance 16 hours agorootparentI don't get this why is it people think that you need to put an entire database in the short-term memory of the AI to be useful? When you work with a DB are you memorizing the entire f*cking database, no, you know the summaries of it and how to access and use it. People also seem to forget that the average is 1b words that are read by people in their entire LIFETIME, and at 10m, with nearly 100% recall thats pretty damn amazing, i'm pretty sure I don't have perfect recall of 10m words myself lol reply choilive 10 hours agorootparentYou certainly don't need that much context for it to be useful, but it definitely opens up a LOT more possibilities without the compromises of implementing some type of RAG. In addition, don't we want our AI to have superhuman capabilities? The ability to work on 10M+ tokens of context at a time could enable superhuman performance in many tasks. Why stop at 10M tokens? Imagine if AI could work on 1B tokens of context like you said? reply Qwero 11 hours agorootparentprevIt increases the use cases. It can also be a good alternative for fine-tuning. And the use case of a code base is a good example: if the ai understands the whole context, it can do basically everything. Let me pay 5€ for a android app rewritten into iOS. reply rvnx 16 hours agorootparentprevWell it's nice, just sad nobody can use it reply CharlieDigital 17 hours agorootparentprevThis may be useful in a generalized use case, but a problem is that many of those results again will add noise. For any use case where you want contextual results, you need to be able to either filter the search scope or use RAG to pre-define the acceptable corpus. reply panarky 13 hours agorootparent> you need to be able to either filter the search scope or use RAG ... Unless you can get nearly perfect recall with millions of tokens, which is the claim made here. reply tveita 17 hours agoparentprev> The 10M context ability wipes out most RAG stack complexity immediately. The video queries they show take around 1 minute each, this probably burns a ton of GPU. I appreciate how clearly they highlight that the video is sped up though, they're clearly trying to avoid repeating the \"fake demo\" fiasco from the original Gemini videos. reply cchance 16 hours agoparentprevThe youtube video of the Multimodal analysis of a video is insane, imagine feeding in movies or tv shows and being able to autosummary or find information about them dynamically, how the hell is all this possible already? AI is moving insanely fast. reply vineyardmike 4 hours agorootparent> imagine feeding in movies or tv shows Google themselves have such a huge footprint of various businesses, that they alone would be an amazing customer for this, never mind all the other cool opportunities from third parties... Imagine that they can ingest the entirety of YouTube and then dump that into Google Search's index AND use it to generate training data for their next LLM. Imagine that they can hook it up to your security cameras (Nest Cam), and then ask questions about what happened last night. Imagine that you can ask Gemini how to do something (eg. fix appliance), and it can go and look up a YouTube video on how to accomplish that ask, and explain it to you. Imagine that it can apply summarization and descriptions to every photo AND video in your personal Google Photos library. You can ask it to find a video of your son's first steps, or a graduation/diploma walk for your 3rd child (by name) and it can actually do that. Imagine that Google Meet video calls can have the entire convo itself fed into an LLM (live?), instead of just a transcription. You can have an AI assistant there with you that can interject and discuss, based on both the audio and video feed. reply anhner 2 hours agorootparentI'd love to see that applied to the Google ecosystem, the question is - why haven't they already done this? reply TweedBeetle 15 hours agoparentprevRegarding how they’re getting to 10M context, I think it’s possible they are using the new SAMBA architecture. Here’s the paper: https://arxiv.org/abs/2312.00752 And here’s a great podcast episode on it: https://www.cognitiverevolution.ai/emergency-pod-mamba-memor... reply LightMachine 15 hours agorootparentAs a Brazilian, I approve that choice. Vambora amigos! reply nestorD 10 hours agoparentprevRegarding the 10M tokens context, RingAttention has been shown [0] recently (by researchers, not ML engineers in a FAANG) to be able to scale to comparable (1M) context sizes (it does take work and a lot of GPUs). [0]: https://news.ycombinator.com/item?id=39367141 reply jebarker 9 hours agorootparent> researchers, not ML engineers in a FAANG Why did you point out this distinction? reply nestorD 6 hours agorootparentIt means they have significantly less means (to get a lot of GPUs letting them scale up in context length) and are likely less well-versed in optimization (which also helps with scaling up)[0]. I believe those two things together are likely enough to explain the difference between a 1M context length and a 10M context length. [0]: Which is not looking down on that particular research team, the vast majority of people have less means and optimization know-how than Google. reply vineyardmike 2 hours agorootparentprevProbably to indicate that its research and not productized? reply freedomben 17 hours agoparentprevIs 10M token context correct? The blog post I see 1M but I'm not sure if these are different things Edit: Ah, I see, it's 1M reliably in production, up to 10M in research: > Through a series of machine learning innovations, we’ve increased 1.5 Pro’s context window capacity far beyond the original 32,000 tokens for Gemini 1.0. We can now run up to 1 million tokens in production. > This means 1.5 Pro can process vast amounts of information in one go — including 1 hour of video, 11 hours of audio, codebases with over 30,000 lines of code or over 700,000 words. In our research, we’ve also successfully tested up to 10 million tokens. reply p1esk 7 hours agorootparentHow could one hour of video fit in 1M tokens? 1 hour at 30fps is 3600*30=100k frames. Each frame is converted in 256 tokens. So either they are not processing each frame, or each frame is converted into fewer tokens. reply KTibow 4 hours agorootparentThe model can probably perform fine at 1 frame per second (3600*256=921600 tokens), and they could probably use some sort of compression. reply huytersd 16 hours agorootparentprevI know how I’m going to evaluate this model. Upload my codebase and ask it to “find all the bugs”. reply cs702 17 hours agoparentprev> 1. They don't talk about how they get to 10M token context > 2. They don't talk about how they get to 10M token context Yes. I wonder if they're using a \"linear RNN\" type of model like Linear Attention, Mamba, RWKV, etc. Like Transformers with standard attention, these models train efficiently in parallel, but their compute is O(N) instead of O(N²), so in theory they can be extended to much longer sequences much efficiently. They have shown a lot of promise recently at smaller model sizes. Does anyone here have any insight or knowledge about the internals of Gemini 1.5? reply sebzim4500 16 hours agorootparentThe fact they are getting perfect recall with millions of tokens rules out any of the existing linear attention methods. reply candiodari 17 hours agorootparentprevThey do give a hint: \"This includes making Gemini 1.5 more efficient to train and serve, with a new Mixture-of-Experts (MoE) architecture.\" One thing you could do with MoE is giving each expert different subsets of the input tokens. And that would definitely do what they claim here: it would allow search. You want to find where someone said \"the password is X\" in a 50 hour audio file, this would be perfect. If your question is \"what is the first AND last thing person X said\" ... it's going to suck badly. Anything that requires taking 2 things into account that aren't right next to eachother is just not going to work. reply spott 15 hours agorootparent> Anything that requires taking 2 things into account that aren't right next to eachother is just not going to work. They kinda address that in the technical report[0]. On page 12 they show results from a \"multiple needle in a haystack\" evaluation. https://storage.googleapis.com/deepmind-media/gemini/gemini_... reply declaredapple 15 hours agorootparentprev> One thing you could do with MoE is giving each expert different subsets of the input tokens. Don't MoE's route tokens to experts after the attention step? That wouldn't solve the n^2 issue the attention step has. If you split the tokens before the attention step, that would mean those tokens would have no relationship to each other - it would be like inferring two prompts in parallel. That would defeat the point of a 10M context reply deskamess 15 hours agorootparentprevIs MOE then basically divide and conquer? I have no deep knowledge of this so I assumed MOE was where each expert analyzed the problem in a different way and then there was some map-reduce like operation on the generated expert results. Kinda like random forest but for inference. reply kristjansson 12 hours agoparentprevFor other's reference, the paper: https://storage.googleapis.com/deepmind-media/gemini/gemini_... reply nborwankar 13 hours agoparentprevRe RAG aren’t you ignoring the fact that no one wants to put confidential company data into such LLM’s. Private RAG infrastructure remains a need for the same reason that privacy of data of all sorts remains a need. Huge context solves the problem for large open source context material but that’s only part of the picture. reply AaronFriel 15 hours agoparentprevThere will always be more data that could be relevant than fits in a context window, and especially for multi-turn conversations, huge contexts incur huge costs. GPT-4 Turbo, using its full 128k context, costs around $1.28 per API call. At that pricing, 1m tokens is $10, and 10m tokens is an eye-watering $100 per API call. Of course prices will go down, but the price advantage of working with less will remain. reply elorant 12 hours agorootparentI don't see a problem with this pricing. At 1m tokens you can upload the whole proceedings of a trial and ask it to draw an analysis. Paying $10 for that sounds like a steal. reply ithkuil 3 hours agorootparentUnfortunately the whole context has to be reprocessed fully for each query, which means that if you \"chat\" with the model you'll incur in that $10 fee for every interaction which quickly sums up. It may still be worth it for some use cases reply staticman2 11 hours agorootparentprevWhile it's hard to say what's possible on the cutting edge, historically models tend to get dumber as the context size gets bigger. So you'd get a much more intelligent analysis of a 10,000 token excerpt of the trial than a million token complete transcript of the trial. I have not spent the money testing big token sizes in GPT 4 turbo, but it would not surprise me if it gets dumber. Think of it this way, if the model is limited to 3,000 token replies, if an analysis would require a more detailed response than 3,000 tokens, it cannot provide it, it'll just give you insufficient information. What it'll probably do is ignore parts of the trial transcript because it can't analyze all that information in 3,000 tokens. And asking a followup question is another million tokens. reply AaronFriel 11 hours agorootparentprevOf course, if you get exactly the answer you want in the first reply. reply 7734128 12 hours agorootparentprevWould the price really increase linearly? Isn't the demands on compute and memory increasing steeper than that as a function of context length? reply resouer 16 hours agoparentprev> The 10M context ability wipes out most RAG stack complexity immediately. This may not be true. My experience of the complexity of RAG lays in how to properly connect to various unstructured data sources and perform data transformation pipeline for large scale data set (which means GB, TB or even PB). It's in the critical path rather a \"nice to have\", because the quality of data and the pipeline is a major factor for the final generated the result. i.e., in RAG, the importance of R >>> G. reply localhost 15 hours agoparentprevRE: RAG - they haven't released pricing, but if input tokens are priced at GPT-4 levels - $0.01/1K then sending 10M tokens will cost you $100. reply campers 7 hours agorootparentIn the announcements today they also halved the pricing of Gemini 1.0 Pro to $0.000125 / 1K characters, which is a quarter of GPT3.5 Turbo so it could potentially be a bit lower than GPT-4 pricing. reply s-macke 15 hours agorootparentprevIf you think the current APIs will stay that way, then you're right. But when they start offering dedicated chat instances or caching options, you could be back in the penny region. You probably need a couple GB to cache a conversation. That's not so easy at the moment because you have to transfer that data to and from the GPUs and store the data somewhere. reply localhost 10 hours agorootparentThe tokens need to be fed into the model along with the prompt and this takes time. Naive attention is O(N^2). They probably use at least flash attention, and likely something more exotic to their hardware. You'll notice in their video [1] that they never show the prompts running interactively. This is for a roughly 800K context. They claim that \"the model took around 60s to respond to each of these prompts\". This is not really usable as an interactive experience. I don't want to wait 1 minute for an answer each time I have a question. [1] https://www.youtube.com/watch?v=SSnsmqIj1MI reply bschne 9 hours agoparentprev> The 10M context ability wipes out most RAG stack complexity immediately. 1. People mention accuracy issues with longer contexts 2. People mention processing time issues with longer contexts 3. Something people haven't mentioned in this thread is cost -- even thought prompt tokens are usually cheaper than generated tokens, and Gemini seems to be cheaper than GPT-4, putting a whole knowledge base or 80-page document in the context is going to make every time you run that prompt quite expensive reply renonce 15 hours agoparentprev> They don't talk about how they get to 10M token context I don't know how either but maybe https://news.ycombinator.com/item?id=39367141 Anyway I mean, there is plenty of public research on this so it's probably just a matter of time for everyone else to catch up reply albertzeyer 14 hours agorootparentWhy do you think this specific variant (RingAttention)? There are so many different variants for this. As far as I know, the problem in most cases is that while the context length might be high in theory, the actual ability to use it is still limited. E.g. recurrent networks even have infinite context, but they actually only use 10-20 frames as context (longer only in very specific settings; or maybe if you scale them up). reply renonce 7 hours agorootparentThere are ways to test the neural network’s ability to recall from a very long sequence. For example, if you insert a random sentence like “X is Sam Altman” somewhere in the text, will the model be able to answer the question “Who is X?”, or maybe somewhat indirectly “Who is X (in another language)” or “Which sentence was inserted out of context?” “Which celebrity was mentioned in the text?” Anyways the ability to generalize to longer context length is evidenced by such tests. If every token of the model’s output is able to answer questions in such a way that any sentence from the input would be taken into account, this gives evidence that the full context window indeed matters. Currently I find Claude 2 to perform very well on such tasks, so that sets my expectation of how a language model with an extremely long context window should look like. reply joshsabol46 12 hours agoparentprev> The 10M context ability wipes out most RAG stack complexity immediately. RAG is needed for the same reason you don't `SELECT *` all of your queries. reply Havoc 7 hours agoparentprev>3. The 10M context ability wipes out most RAG stack complexity immediately. I'd imagine RAG would still be much more efficient computationally reply lqcfcjx 8 hours agoparentprevThis might be a stupid question - even if there's no quality degradation from 10M context, will it be extremely slow in reference? reply ren_engineer 16 hours agoparentprevRAG would still be useful for cost savings assuming they charge per token, plus I'm guessing using the full-context length would be slower than using RAG to get what you need for a smaller prompt reply nostrebored 16 hours agorootparentThis is going to be the real differentiator. HN is very focused on technical feasibility (which remains to be seen!), but in every LLM opportunity, the CIO/CFO/CEO are going to be concerned with the cost modeling. The way that LLMs are billed now, if you can densely pack the context with relevant information, you will come out ahead commercially. I don't see this changing with the way that LLM inference works. Maybe this changes with managed vector search offerings that are opaque to the user. The context goes to a preprocessing layer, an efficient cache understands which parts haven't been embedded (new bloom filter use case?), embeds the other chunks, and extracts the intent of the prompt. reply mediaman 15 hours agorootparentAgreed with this. The leading ability AI (in terms of cognitive power) will, generally, cost more per token than lower cognitive power AI. That means that at a given budget you can choose more cognitive power with fewer tokens, or less cognitive power with more tokens. For most use cases, there's no real point in giving up cognitive power to include useless tokens that have no hope of helping with a given question. So then you're back to the question of: how do we reduce the number of tokens, so that we can get higher cognitive power? And that's the entire field of information retrieval, which is the most important part of RAG. reply golol 15 hours agorootparentprevThe way that LLMs are billed now, if you can densely pack the context with relevant information, you will come out ahead commercially. I don't see this changing with the way that LLM inference works. Really? Because to my understanding the compute necessary to generate a token grows linearly with the context, and doesn't the OpenAI billing reflect that by seperating prompt and output tokens? reply kylerush 15 hours agoparentprevI assume using this large of a context window instead of RAG would mean the consumption of many orders of magnitude more GPU. reply zitterbewegung 16 hours agoparentprevRAG doesn’t go away at 10 Million tokens if you do esoteric sources like shodan API queries. reply karmasimida 15 hours agoparentprevEven 1m tokens eliminate the need for RAG, unless it is for cost. reply 7734128 12 hours agorootparent1 million might sound like a lot, but it's only a few megabytes. I would want RAG, somehow, to be able to process gigabytes or terabytes of material in a streaming fashion. reply karmasimida 11 hours agorootparentRAG will not change how many tokens LLM can produce at once. Longer context on the other hand, could put some RAG use cases to sleep, if your instructions are like, literally a manual long, then there is no need for rag. reply 7734128 2 hours agorootparentI think RAG could be used that do that. If you have a one time retrieval in the beginning, basically amending the prompt, then I agree with you. But there are projects (classmate doing his masters thesis project as one implementation of this) that retrieves once every few tokens and make the retrieved information available to the generation somehow. That would not take a toll on the context window. reply sroussey 15 hours agorootparentprevOr accuracy reply jorvi 16 hours agoparentprevI just hope at some point we get access to mostly uncensored models. Both GPT-4 and Gemini are extremely shackled, and a slightly inferior model that hasn’t been hobbled by a very restricting preprompt would handily outperform them. reply ShamelessC 14 hours agorootparentYou can customize the system prompt with ChatGPT or via the completions API, just fyi. reply oblio 6 hours agoparentprevWhat's RAG? reply ohmyiv 4 hours agorootparentRetrieval Augmented Generation. In basic terms, it optimizes output of LLMs by using additional external data sources before answering queries. (That actually might be too basic of a description) Here: https://blogs.nvidia.com/blog/what-is-retrieval-augmented-ge... reply girvo 4 hours agorootparentprevRetrieval augmented generation. > Retrieval Augmented Generation (RAG) is a technique where the capabilities of a large language model (LLM) are augmented by retrieving information from other systems and inserting them into the LLM’s context window via a prompt. (stolen from: https://github.com/psychic-api/rag-stack) reply aubanel 13 hours agoparentprev> They are pretty clear that 1.5 Pro is better than GPT-4 in general, and therefore we have a new LLM-as-judge leader, which is pretty interesting I fully disagree, they compare Gemini 1.5 Pro and GPT4 only on context length, not on other tasks where they compare it only to other Gemini which is a strange self-own. I'm convinced that if they do not show the results against GPT4/Claude, it is because they do not look good. reply theGnuMe 17 hours agoparentprevFor #1 and #2 it is some version of mixture of experts. This is mentioned in the blog post. So each expert only sees a subset of the tokens. I imagine they have some new way to route tokens to the experts that probably computes a global context. One scalable way to compute a global context is by a state space model. This would act as a controller and route the input tokens to the MoEs. This can be computed by convolution if you make some simplifying assumptions. They may also still use transformers as well. I could be wrong but there are some Mamba-MoEs papers that explore this idea. reply a_vanderbilt 13 hours agoparentprevAfter their giant fib with the Gemini video a few weeks back I'm not believing anything til I see it used by actual people. I hope it's that much better than GPT-4, but I'm not holding my breath there isn't an asterisk or trick hiding somewhere. reply outside1234 13 hours agoparentprevIt takes 60 seconds to process all of that context in their three.js demo, which is, I will say, not super interactive. So there is still room for RAG and other faster alternatives to narrow the context. reply tbruckner 17 hours agoparentprevHow do you know it isn't RAG? reply qwerty_clicks 13 hours agoparentprevFYI, MM is the standard for million. 10MM not 10M I’m reading all these comments confused as heck why you are excited about 10M tokens reply MichaelNolan 10 hours agorootparentMaybe for accountants, but for everyone else a single M is much more common. reply needlesslygrim 17 minutes agoprevPersonally, I've given up on Gemini, as it seems to have been censored to the point of uselessness. I asked it yesterday [0] about C++ 20 Concepts, and it refused to give actual code because I'm under 18 (I'm 17, and AFAIK that's what the age on my Google account is set to). I just checked again, and it gave a similar answer [1]. When I tried ChatGPT 3.5, it did give an answer, although it was a little confused, and the code wasn't completely correct. This seems to be a common experience, as apparently it refuses to give advice on copying memory in C# [2], and I tried to do what was suggested in this comment [3], but by the next prompt it was refusing again, so I had to stick to ChatGPT. [0] https://g.co/gemini/share/238032386438 [1] https://g.co/gemini/share/6880989ddfaf [2] https://news.ycombinator.com/item?id=39312896 [3] https://news.ycombinator.com/item?id=39313567 reply scarmig 17 hours agoprevOne interesting tidbit from the technical report: >HumanEval is an industry standard open-source evaluation benchmark (Chen et al., 2021), but we found controlling for accidental leakage on webpages and open-source code repositories to be a non-trivial task, even with conservative filtering heuristics. An analysis of the test data leakage of Gemini 1.0 Ultra showed that continued pretraining on a dataset containing even a single epoch of the test split for HumanEval boosted scores from 74.4% to 89.0%, highlighting the danger of data contamination. We found that this sharp increase persisted even when examples were embedded in extraneous formats (e.g. JSON, HTML). We invite researchers assessing coding abilities of these models head-to-head to always maintain a small set of truly held-out test functions that are written in-house, thereby minimizing the risk of leakage. The Natural2Code benchmark, which we announced and used in the evaluation of Gemini 1.0 series of models, was created to fill this gap. It follows the exact same format of HumanEval but with a different set of prompts and tests. reply alphabetting 18 hours agoprevMassive whoa if true from technical report \"Studying the limits of Gemini 1.5 Pro's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens\" https://storage.googleapis.com/deepmind-media/gemini/gemini_... reply Workaccount2 18 hours agoparent10M tokens is absolutely jaw dropping. For reference, this is approximately thirty books of 500 pages each. Having 99% retrieval is nuts too. Models tend to unwind pretty badly as the context (tokens) grows. Put these together and you are getting into the territory of dumping all your company documents, or all your departments documents into a single GPT (or whatever google will call it) and everyone working with that. Wild. reply kranke155 17 hours agorootparentSeems like Google caught up. Demis is again showing an incredible ability to lead a team to make groundbreaking work. reply huytersd 16 hours agorootparentIf any of this is remotely true, not only did it catch up, it’s wiping the floor with how useful it can be compared to GPT4. Not going to make a judgement until I can actually try it out though. reply singularity2001 15 hours agorootparentIn the demo videos gemini needs about a minute to answer long context questions. Which is better than reading thousands of pages yourself. But if it has to compete with classical search and skimming it might need some optimization. reply a_wild_dandan 12 hours agorootparentReplacing grep or `ctrl+F` with Gemini would be the user's fault, not Gemini's. If classical search for a job already a performant solution, use classical search. Save your tokens for jobs worthy of solving with a general intelligence! reply huytersd 14 hours agorootparentprevThat’s a compute problem, something that involves just throwing money at the problem. reply og_kalu 17 hours agoparentprevAnother whoa for me >Finally, we highlight surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person learning from the same content. Results - https://imgur.com/a/qXcVNOM reply usaar333 17 hours agorootparentI think this somewhat is mostly due to the ability to handle high context lengths better. Note how Claude 2.1 already highly outperforms GPT-4 on this task. reply a_wild_dandan 12 hours agorootparentGPT-4V turbo outperforms Claude on long contexts, IIRC. Unless that's mistaken, I'd suspect a different explanation for that task. reply cchance 16 hours agoparentprevDid you watch the video of the Gemini 1.5 video recall after it processed the 44 minute video... holy shit reply megaman821 18 hours agoparentprevSo, will this outperform any RAG approach as long as the data fits inside the context window? reply CuriouslyC 17 hours agorootparentA perfect RAG system would probably outperform everything in a larger context due to prompt dilution, but in the real world putting everything in context will win a lot of the time. The large context system will also almost certainly be more usable due to elimination of retrieval latency. The large context system might lose on price/performance though. reply TheGeminon 18 hours agorootparentprevOutperform is dependent on the RAG approach (and this would be a RAG approach anyways, you can already do this with smaller context sizes). A simplistic one, probably, but dumping in data that you don't need dilutes the useful information, so I would imagine there would be at least _some_ degradation. But there is also the downside of \"tuning\" the RAG to return less tokens you will miss extra context that could be useful to the model. reply megaman821 18 hours agorootparentDoesn't their needle/haystack benchmark seem to suggest there is almost no dilution? They pushed that demo out to 10M tokens. reply ArcaneMoose 18 hours agorootparentprevCost would still be a big concern reply chasd00 12 hours agorootparentprevare you going to upload 10M tokens to Gemini on every request? That's a lot of data moving around when the user is expecting a near realtime response. Seems like it would still be better to only set the context with information relevant to the user's prompt which is what plain rag does. reply saliagato 18 hours agorootparentprevbasically, yes. Pinecone? Dead. Azure AI Search? Dead. Quadrant? Dead. reply _boffin_ 18 hours agorootparentPrompt token cost still a variable. reply matsemann 18 hours agoparentprevCould you (or someone) explain what this means? reply ehsankia 14 hours agorootparentIt's how much text it can consider at a time when generating a response. Basically the size of the prompt. A token is not quite a word but you can think of it as roughly that. Previously, the best most LLMs could do is around 32K. This new model does 1M, and in testing they could put it up to 10M with near perfect retrieval. As the other comment mentions, you can paste the content of entire books or documents and ask very pointed question about it. Last year, Anthropic was showing off their 100K context window, and that's exactly what they did, they gave it the content of The Great Gatsby and asked it questions about specific lines of the book. Similarly, imagine giving it hundreds of documents and asking it to spot some specific detail in there. reply liamYC 10 hours agorootparentAwesome explanation, thanks for the comparison reply FergusArgyll 16 hours agorootparentprevThe input you give it can be very long. This can qualitatively change the experience. Imagine, for example, copy pasting the entire lord of the rings plus another 100 books you like and asking it to write a similar book... reply HarHarVeryFunny 15 hours agorootparentI just googled it, and the LOTR trilogy apparently has a total of 480,000 words, which brings home how huge 1M is! It'd be fascinating to see how well Gemini could summarize the plot or reason about it. One point I'm unclear on is how these huge context sizes are implemented by the various models. Are any of them the actual raw \"width of the model\" that is propagated through it, or are these all hierarchical summarization and chunk embedding index lookup type tricks? reply mburns 12 hours agorootparentFor another reference, Shakespeare’s complete works are ~885k words. The Encyclopedia Britannica is ~44M words. reply staticman2 11 hours agorootparentprevReading Lord of the Rings, and writing a quality book in the same style, are almost wholly unrelated tasks. Over 150 million copies of Lord of the Rings have been sold, but few readers are capable of \"writing a similar book\" in terms of quality. There's no reason to think this would work well. reply pfooti 7 hours agorootparentI mean, Terry Brooks did it with the Sword of Shannara. (/s) reply teaearlgraycold 16 hours agorootparentprevI doubt it’s smart enough to write another (coherent, good) book based on 103 books. But you could ask it questions about the books and it would search and synthesize good answers. reply stavros 18 hours ago [flagged]parentprevnext [4 more] Until I can talk to it, I care exactly zero. reply peterisza 17 hours agorootparentyou can buy their stock if you think they'll make a lot of money with their tech reply HarHarVeryFunny 16 hours agorootparentWell that's really the right question .. what can, and will, Google do with this that can move their corporate earnings needle in a meaningful way? Obviously they can sell API access and integrate it into their Google docs suite, as well as their new Project IDX IDE, but do any of these have potential to make a meaningful impact ? It's also not obvious how these huge models will fare against increasingly capable open source ones like Mixtral, perhaps especially since Google are confirming here that MoE is the path forward, which perhaps helps limit how big these models need to be. reply plaidfuji 16 hours agorootparentIn the long run it could move the needle in enterprise market share of Workspace and GCP. They have a lot of room to grow and IMO have a far superior product to O365/Azure which could be exacerbated by strong AI products. Only problem is this sales cycle can take a decade or more, and Google hasn’t historically been patient or strategic about things like this. reply gpjanik 18 hours agoprev0 trust to what they put out until I see it live. After the last \"launch\" video which was fundamentally a marketing edit not showing the real product, I don't trust anything coming out of Google that isn't an instantly testable input form. reply dingclancy 7 hours agoparentEssentially, the focus seems to be on leveraging the media buzz around Gemini 1.0 by highlighting the development of version 1.5. While GPT-4's position relative to Gemini 1.5 remains unclear, and the specifics of ChatGPT 4.5 are yet to be disclosed, it's worth noting that no official release has taken place until the functionality is directly accessible in user chats. Google appears to be making strides in catching up. When it comes to my personal workflow and accomplishing tasks, I still find ChatGPT to be the most effective tool. My familiarity with its features has made it indispensable. The integration of mentions and tailored GPTs seamlessly enhances my workflow. While Gemini may match the foundational capabilities of LLMs, it falls short in delivering a product that efficiently aids in task completion. reply frays 8 hours agoparentprevI completely share the same views as you after their last video - and it appears that they've learnt their lesson this time. If you watch the videos in the blog post, you can see it's a screen recording on a computer without any editing/stitching of different scenes together. It's good to be sceptical but as engineers we should all remain open. reply tfsh 10 hours agoparentprevThe videos shown in these demos have clearly learnt from that as they're using a real live product, filmed on their computers with timers in the bottom showing how long the computations take. reply replwoacause 8 hours agoparentprev100%. Google continues to underwhelm. Not buying it until I can try it. reply og_kalu 18 hours agoprev>Finally, we highlight surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person learning from the same content. Results - https://imgur.com/a/qXcVNOM From the technical report https://storage.googleapis.com/deepmind-media/gemini/gemini_... reply seydor 16 hours agoparentwhat if we ask it to translate an undeciphered language reply dougmwne 15 hours agorootparentIt produces basically random translations. This is covered in the 0-shot case where no translation manual was included in the context. Due to how rare this language is, it’s essentially untranslated in the training corpus. reply og_kalu 14 hours agorootparentprevIf you mean to dump random passages of text with no parallel corpora or grammar instructions then it won't do better than random. That said, I think that if you gave a LLM language text to predict during training, I believe that even if no parallel corpora exists during training, we could have a LLM that could still translate that language to some other language it also trained on. reply seydor 13 hours agorootparentWhat if we added a bunch of linguistic analysis books or something reply poulpy123 17 hours agoparentprev> at a similar level to a person learning from the same content. That's an incredibly low bar reply elevatedastalt 15 hours agorootparent:muffled sounds of goalposts being shifted in the distance: Just a few years ago we used to clap if an NLP model could handle negation reliably or could generate even a paragraph of text in English that was natural sounding. Now we are at a stage where it is basically producing reams of natural sounding text, performing surprisingly well on reasoning problems and translation of languages with barely any data despite being a markov chain on steroids, and what does it hear? \"That's an incredibly low bar\". reply glenstein 15 hours agorootparentI'm going to keep beating this dead horse, but if you were a philosophy nerd in the 80s, 90s, 00s etc you may know that debates RAGED over whether computers could ever, even in principle do things that are now being accomplished on a weekly basis. And as you say, the goalposts keep getting moved. It used to be claimed that computers could never play chess at the highest levels because that required \"insight\". And whatever a computer could do, it could never to that extra special thing, that could only be described in magical undefined terms. I just hope there's a moment of reckoning for decades upon decades of arguments, deemed academically respectable, that insisted that days like these would never come. reply empath-nirvana 13 hours agorootparentForget goalpost shifting, people frequently refuse to admit that it can do things that it obviously does, because they've never used it themselves. reply mewpmewp2 12 hours agorootparentListen, you little ... reply elevatedastalt 14 hours agorootparentprevHonestly. I am ok with having greater and greater goals to accomplish but this sort of dismissive attitude really puts me off. reply ithkuil 17 hours agorootparentprevIt's incredible how fast goalposts are moving. The same feat one year ago would have been almost unbelievable. reply zacmps 13 hours agorootparentprev> The author (the human learner) has some formal experience in linguistics and has studied a variety of languages both formally and informally, though no Austronesian or Papuan languages From the language benchmark (parentheses mine). reply KeplerBoy 17 hours agorootparentprevSince when are we expecting super-human capabilities? reply andsoitis 16 hours agorootparentAnd in fact it already is super human. Show me a single human who can translate amongst 10+ languages across specialized domains in the blink of an eye. reply empath-nirvana 13 hours agorootparentChat GPT has been super human in a lot of tasks even since 3.5. People point out mistakes it makes that no human would make, but that doesn't negate the super-human performance it has at other tasks -- and the _breadth_ of what it can do is far beyond any single person. reply KeplerBoy 12 hours agorootparentWhere exactly does it have super-human performance? Above average and expert-level? Sure, I'd agree, but I haven't experienced anything above that. reply newzisforsukas 3 hours agorootparentprevindeed, or a human who can analyze a hundred page text document in less than a minute and provide answers in less than a second. the issue remains on accuracy. i think a human in that scenario is still more accurate with their responses, and i do not yet see that being overcome in this multi-year llm battle. reply coffeebeqn 9 hours agorootparentprevThe model does already have superhuman ability by knowing hundreds of languages reply JyB 11 hours agorootparentprevJarring you're not adding more context to your comment. reply newzisforsukas 3 hours agorootparentprevyou are insane if you actually think this. reply zippothrowaway 17 hours agoprevI've always been suspicious of any announcement from Demis Hassabis since way back in his video game days when he did a monthly article in Edge magainze about the game he was developing. \"Infinite Polygons\" became a running joke in the industry because of his obvious snake-oil. The game itself, Republic [1], was an uninteresting failure. He learned how to promote himself from working for Peter \"Project Milo\" Molyneux and I see similar patterns of hype. [1] https://en.wikipedia.org/wiki/Republic:_The_Revolution#Marke... reply Qwero 11 hours agoparentFunny read about his game. Nonetheless while still underwhelming in comparison to gpt-4 (excluding this announcement as I haven't tried it yet), alpha go, zero and especially fold were tremendous! reply COAGULOPATH 9 hours agoparentprevYeah, it's funny. I used to think \"Demis Hassabis...where have I heard that name before?\" And then I realized I saw him in the manuals for old Bullfrog games. reply pradn 11 hours agoparentprevThe line between delusional and visionary is thin! I know I'm too grounded in \"expected value\" math to do super outlier stuff like starting a video game company... reply killthebuddha 16 hours agoprev10M tokens is an absolute game changer, especially if there's no noticeable decay in quality with prompt size. We're going to see things like entire domain specific languages embedded in prompts. IMO people will start thinking of the prompt itself as a sort of runtime rather than a static input. Back when OpenAI still supported raw text completion with text-davinci-003 I spent some time experimenting with tiny prompt-embedded DSLs. The results were very, very, interesting IMO. In a lot of ways, text-davinci-003 with embedded functions still feels to me like the \"smartest\" language model I've ever interacted with. I'm not sure how close we are to \"superintelligence\" but for baseline general intelligence we very well could have already made the prerequisite technological breakthroughs. reply empath-nirvana 15 hours agoparentIt's pretty slow, though looks like up to 60 seconds for some of the answers, and uses god knows how much compute, so there's probably going to be some trade offs -- you're going to want to make sure that that much context is actually useful for what you want. reply drusepth 12 hours agorootparentTBF: when talking about the first \"superintelligence\", I'd expect it to take unreasonable amounts of compute and/or be slow -- that can always be optimized. Bringing it into existence in the first place is the hardest part. reply unshavedyak 11 hours agorootparentYea. Of course for some tasks we need speed, but i've been kinda surprised that we haven't seen very slow models which perform far better than faster models. We're treading new territory, and everyone seems to make models that are \"fast enough\". I wanna see how far this tech can scale, regardless of speed. I don't care if it takes 24h to formulate a response. Are there \"easy\" variables which drastically improve output? I suspect not. I imagine people have tried that. Though i'm still curious as to why. reply TaylorAlexander 4 hours agorootparentI think the problem is that 24 hours of compute to run a response would be incredibly expensive. I mean hell how would that even be trained. reply thot_experiment 12 hours agoprevI gotta say, I've been trying out Gemini recently and it's embarrassingly bad. I can't take anything google puts out seriously when their current offerings are so so much worse than ChatGPT (or even local llama!). As a particularly egregious example, yesterday night I gave Gemini a list of drinks and other cocktail ingredients I had laying around and asked for some recommendations for cute drinks that I could make. It's response: > I'm just a language model, so I can't help you with that. ChatGPT 3.5 came up with several delicious options with clear instructions, but it's not just this instance, I've NEVER gotten a response from Gemini that I even felt was more useful than just a freaking bing search! Much less better than ChatGPT. I'm just going to assume they're using cherrypicked metrics to make themselves feel better until proven otherwise. I have zero confidence in Google's AI plays, and I assume all their competent talent is now at OpenAI or Anthropic. reply staticman2 1 hour agoparentI don't think \"I'm just a language model, I can't help you with that\" comes from Gemini. Google has a seperate censorship model that blocks you from receiving Gemini's response in certain situations. When Gemeni (Ultra) refuses to do something itself it is more verbose and specific as to why it won't do it, it my experience. reply samspenc 7 hours agoparentprevMy experiences are similar, but I think we are talking about the Gemini free model, available on the Google Gemini website. I think the rest of the comments are saying the paid versions (Pro / Ultra) are significantly better, though I haven't tested it myself to compare. reply shellfishgene 1 hour agorootparentI have the 2 months trial for the paid version, and find myself going back to free ChatGPT often. Gemini loves to put everything in bullet point lists and short paragraphs with subheadings for example, even when asking for a letter. I'm not a heavy user, but it seems to not quite get what I want often. Not important but annoying: It starts almost every answer with \"Absolutely!\", even when it doesn't match the question (e.g. \"How does x work?\"). reply Aeolun 1 hour agoprevThis got my trying Gemini, but doing so is such a hassle that I'm almost ready to give up. Trying out ChatGPT is as simple as signing up (either for pro, or the API), and getting a single API key. Google requires me to navigate their absolutely insane console (seriously, I thought the AWS console was bad, but GCP takes the cake), only to tell me there is not even a way to get an API key... I had to ask Gemini through the built in interface to figure that out. reply losvedir 18 hours agoprevIf I understand correctly, they're releasing this for Pro but not Ultra, which I think is akin to GPT 3.5 vs 4? Sigh, the naming is confusing... But my main takeaway is the huge context window! Up to a million, with more than 100k tokens right now? Even just GPT 3.5 level prediction with such a huge context window opens up a lot of interesting capabilities. RAG can be super powerful with that much to work with. reply cchance 16 hours agoparentIt's sizes Nano/Pro/Ultra are model SIZES. 1.0/1.5 is generations of the architecture. reply danpalmer 17 hours agoparentprevThe announcement suggests that 1.5 Pro is similar to 1.0 Ultra. reply benopal64 17 hours agorootparentI am reaching a bit, however, I think its a bit of a marketing technique. The Pro 1.5 being compared to the Ultra 1.0 model seems to imply that they will be releasing a Ultra 1.5 model which will presumably have similar characteristics to the new Pro 1.5 model (MOE architecture w/ a huge context window). reply danpalmer 17 hours agorootparentApparently the technical report implies that Ultra 1.5 is a step-up again, I'm not sure it's just context length, that seems to be orthogonal in everything I've read so far. reply amf12 12 hours agoparentprevMaybe this analogy would help: iPhone 15, iPhone Pro 15, iPhone Pro Max 15 and then iPhone Pro 15.5 reply ygouzerh 16 hours agoparentprevSo Pro and Ultra are from my understanding link to the number of parameters. More parameters means more reasonning capabilities, but more compute needed. So Pro is like the light and fast version and Ultra the advanced and expensive one. reply sonium 17 hours agoprevI just watched the demo with the Apollo 11 transcript. (sidenote: maybe Gemini is named after the space program?). Wouldn't the transcript or at least a timeline of Apollo 11 be part of the training corpus? So even without the 400 pages in the context window just given the drawing I would assume a prompt like \"In the context of Apoll 11, what moment does the drawing refer to?\" would yield the same result. reply technics256 16 hours agoparentGemini is named that way because of the collaboration between Google brain and deep mind reply singularity2001 15 hours agoparentprevCorrect except that it spits out the timestamp reply torginus 14 hours agoparentprevGemini is named after the spacecraft that put the second person into orbit - pretty aptly named, but not sure if this was the intention. reply DrNosferatu 2 hours agorootparentGoogle needs their Apollo. reply empath-nirvana 13 hours agoparentprevi asked chatgpt4 to identify three humorous moments in the apollo 11 transcript and it hallucinated all 3 of them (i think -- i can't find what it's referring to). Presumably it's in it's corpus, too. > The \"Snoopy\" Moment: During the mission, the crew had a small, black-and-white cartoon Snoopy doll as a semi-official mascot, representing safety and mission success. At one point, Collins joked about \"Snoopy\" floating into his view in the spacecraft, which was a light moment reflecting the camaraderie and the use of humor to ease the intense focus required for their mission. The \"Biohazard\" Joke: After the successful moon landing and upon preparing for re-entry into Earth's atmosphere, the crew humorously discussed among themselves the potential of being quarantined back on Earth due to unknown lunar pathogens. They joked about the extensive debriefing they'd have to go through and the possibility of being a biohazard. This was a light-hearted take on the serious precautions NASA was taking to prevent the hypothetical contamination of Earth with lunar microbes. The \"Mailbox\" Comment: In the midst of their groundbreaking mission, there was an exchange where one of the astronauts joked about expecting to find a mailbox on the Moon, or asking where they should leave a package, playing on the surreal experience of being on the lunar surface, far from the ordinary elements of Earthly life. This comment highlighted the astronauts' ability to find humor in the extraordinary circumstances of their journey. reply ComputerGuru 17 hours agoprevThe context window size - if it really works as advertised - is pretty ground-breaking. It would replace the need to RAG or fine tune for one-off (or few-off) analys{is,es} of input streams cheaper and faster. I wonder how they got past the input token stuffing problems everyone else runs into. reply lumost 16 hours agoparentThey are almost certainly using some form of sparse attention. If you linearize the attention operation, you can scale up to around 1-10M tokens depending on hardware before hitting memory constraints. Linearization works off the assumption that for a subsequence of X tokens out M tokens, where M os much greater than X there are likely only K tokens which are useful for the attention operation. There are a bunch of techniques to do this, but it's unclear how well any of them scale. reply ein0p 15 hours agorootparentNot \"almost\", but certainly. Dense attention is quadratic, not even Google would be able to run it at an acceptable speed. Their model is not recurrent - they did not have the time yet (or resources - believe it or not, Google of 2023-24 is very compute constrained) to train newer SSM or recurrent based models at practical parameter counts. Then there's the fact that those models are far harder to train due to instabilities, which is one of the reasons why you don't yet see FOSS recurrent/SSM models that are SOTA at their size or tokens/sec. With sparse attention, however, long context recall will be far from perfect, and the longer the context the worse the recall. That's better than no recall at all (as in a fully dense attention model which will simply lop off the preceding parts of the conversation), but not by a hell of a lot. reply kiraaa 10 hours agorootparentmaybe they are using ring attention, on top of their 128k model. reply ein0p 7 hours agorootparentMore likely some clever take on RAG. There’s no way that 1M context is all available at all times. More likely parts of it are retrievable on demand. Hence the retrieval-like use cases you see in the demos. The goal is to find a thing, not to find patterns at a distance reply nbardy 15 hours agoparentprevRAG will stick around, at some point you want to retrieve grounded information samples to inject in the context window. RAG+long context just gives you more room for grounded context. Think building huge relevant context on topics before answering. reply torginus 14 hours agoparentprevTbh, I haven't read the paper, but I think it's pretty self-evident that large contexts aren't cheap - the AI has to comb through every word of the context for each successive generated token at least once, so it's going to be at least linear. reply popinman322 15 hours agoparentprevvs RAG: RAG is good for searching across >billions of tokens and providing up-to-date information to a static model. Even with huge context lengths it's a good idea to submit high quality inputs to prevent the model from going off on tangents, getting stuck on contradictory information, etc.. vs fine tuning: smaller, fine-tuned models can perform better than huge models in a decent number of tasks. Not strictly fine-tuning, but for throughput limited tasks it'll likely still be better to prune a 70B model down to 2B, keeping only the components you need for accurate inference. I can see this model being good for taking huge inputs and compressing them down for smaller models to use. reply jcuenod 17 hours agoparentprevIt won't remove the use of RAG at all. That's like saying, \"wow, now that I've upgraded my 128GB HDD to 1TB, I'll never run out of space again.\" reply madisonmay 17 hours agorootparentIt's more like saying \"I've upgraded to 128GB of RAM, I'll never use my disk again\". reply sebzim4500 16 hours agorootparentprev10 TB for an accurate proportion. And I think people who buy a laptop with a 1TB SSD generally don't run out of space, at least I don't. reply Havoc 10 hours agoparentprevSaw testing earlier that suggested the context does indeed work right reply Imnimo 17 hours agoprevThis is the first time I've been legitimately impressed by one of Google's LLMs (with the obvious caveat that I'm taking the results reported in their tech report at face value). reply replwoacause 8 hours agoparentIt’s just marketing at this point, nothing to be impressed by. It’s a mistake to take at face value. reply Yusefmosiah 16 hours agoprevI see a lot of talk about retrieval over long context. Some even think this replaces RAG. I don't care if the model can tell me which page in the book or which code file has a particular concept. RAG already does this. I want the model to notice how a concept is distributed throughout a text, and be able to connect, compare, contrast, synthesize, and understand all the ways that a book touches on a theme, or to rewrite multiple code files in one pass, without introducing bugs. How does Gemini 1.5's reasoning compare to GPT-4? GPT-4 already has superhuman memory; its bottleneck is its relatively weak reasoning. reply sinuhe69 15 hours agoparentIn my experience (I work mostly and deeply with Bard/Gemini), the reasoning capability of Gemini is quite good. Gemini Pro is already much better than ChatGPT 3.5, but they still make quite a few mistakes along the way. What is more worrying is that when these models made mistakes, they tried really hard to justify their reasoning (errors), practically misleading the users. Because of their high mimicry ability, users really have to pay attention to validate and eventually spot the errors. Of course, this is still far below the human level, so I'm not sure whether they add value or are more of a burden. reply og_kalu 12 hours agoparentprevThe most impressive demonstration of long context is this in my opinion, https://imgur.com/a/qXcVNOM Testing language translation abilities of an extremely obscure language after passing in one grammar book as context. reply reissbaker 14 hours agoprevThe long context length is of course incredible, but I'm more shocked that the Pro model is now on par with Ultra (~GPT-4, at least the original release). That implies when they release 1.5 Ultra, we'll finally have a GPT-4 killer. And assuming that 1.5 Pro is priced similarly to the current Pro, that's a 4x price advantage per-token. Not surprising that OpenAI shipped a blog post today about their video generation — I think they're feeling considerable heat right now. reply topicseed 14 hours agoparentGemini 1 Ultra was also said to be on par with ChatGPT 4 and it's not really there so let's see for ourselves when we can get our hands on it. reply reissbaker 13 hours agorootparentUltra benchmarked around the original release of GPT-4, not the current model. My understanding is that was fairly accurate — it's close to current GPT-4 but not quite equal. However, close-to-GPT-4 but 4x cheaper and 10x context length would be very impressive and IMO useful. reply refulgentis 4 hours agorootparentNo, it benchmarked around the original release of GPT-4 given 32 attempts versus GPT-4's 5. reply tigershark 10 hours agoparentprevFeeling the heat? Did you actually watch the videos? That was a huge leap forward compared to anything existing at the moment. Order of magnitudes away from a blog post discussing a model that maybe will finally be on par with chat gtp 4... reply mupuff1234 4 hours agorootparentThe openai announcement is also more or less a blog post, isn't it? Do we know how much time or money does it take to create a movie clip? reply tigershark 1 hour agorootparentThere was Sam Altman taking live prompt requests on twitter and generating videos. They were not the same quality as some of the ones in the website, but they were still incredibly impressive. reply mupuff1234 1 hour agorootparentAnd how much compute were those requests using? reply Alifatisk 17 hours agoprevI remember one of the biggest advantages with Google Bard was the heavily limited context window. I am glad Google is now actually delivering some exciting news now with Gemini and this gigantic token size. Sure it's a bummer that they slap the \"Join the waiting list\", but it's still interesting to read about their progress and competing with ClosedAi (OpenAi). One last thing I hope they fix is the heavily morally and ethically guardrail, sometimes I can barely ask proper questions without it triggering Gemini to educate me about what's right and wrong. And when I try the same prompt with ChatGPT and Bing ai, they happily answer. reply elevatedastalt 11 hours agoparent\"biggest advantages with Google Bard\" Did you mean disadvantages? reply aubanel 17 hours agoprevFor reference, here is the technical report: https://storage.googleapis.com/deepmind-media/gemini/gemini_... reply prakhar897 18 hours agoprevCan anyone explain how context length is tested? Do they prompt something like: \"Remember val=\"XXXX\" .........10M tokens later....... Print val\" reply halflings 17 hours agoparentYep that's pretty much it! That's what they call needle in a haystack. See: https://github.com/gkamradt/LLMTest_NeedleInAHaystack reply cchance 16 hours agoparentprevyep they hide things throughout the prompt and then ask it about that specific thing, imagine hiding passwords in a giant block of text and then being like, what was bobs password 10 million tokens later. According to this it's remembering with 99% accuracy, which if you think about it is NUTS, can you imagine reading a 22x 1000 page books, and remembering every single word that was said with 100% accuracy lol reply foota 15 hours agorootparentInterestingly, there's a decent chance I'd remember if there was an out of context passage saying \"the password is FooBar\". I wonder if it would be better to test with minor edits? E.g., \"what color shirt was X wearing when...\" reply kenjackson 4 hours agorootparentI think instead you could just do a full doc of relationships. \"Tina and Chris have five children named ...\" Then you can ask it who is Tina's (great)^57 grandmother's twice removed cousin on her father's side? It would have to be able to remember the context of the relationships up and down the document and there'd be nothing to key into as you could ask about any relationship. reply ambichook 7 hours agorootparentprevi feel you would recognise that more as a quirk of how humans think, remember that LLMs think fundamentally differently to you and i. i would be curious about someone making a benchmark like that and using it to compare as an experiment however reply foota 6 hours agorootparentI'm not trying to anthropomorphize the model, but it's not hard to imagine that a model would attribute significance to something completely out of context, and hence \"focus\" on it when computing attention. Another possible synthetic benchmark would be to present a list of key value pairs and then ask it for the value corresponding to different keys. Or present a long list of distinct facts and then ask it about them. This latter one could probably be sourced from something like a trivia question and answers data set. I bet there's something like that from Jeopardy. reply NhanH 18 hours agoparentprevYep, that’s actually a common one reply blovescoffee 18 hours agoparentprevVery simplified There are arrays (matrices) that are length 10M inside the model. It’s difficult to make that array longer because training time explodes. reply guybedo 18 hours agoprevlooks interesting enough that i wanted to give Gemini a try and join the waitlist. And i thought it would be easy, what a rookie mistake. Looks like \"France\" isn't on the list of available regions for Ai Studio ? Now i'm trying to use Vertex AI, not even sure what's the difference with Ai Studio, but it seems it's available. So far i've been struggling for 15 minutes through a maze of google cloud pages: console, docs, signups. No end in sight, looks like i won't be able to try it out reply IanCal 18 hours agoparentIt's not available outside of a private preview yet. The page says you can use 1.0 ultra in vertex but it's not available to me in the UK. I can't get on the waitlist, because the waitlist link redirects to aistudio and I can't use that. I should stop expecting that I can use literally anything google announces. reply 264 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google has introduced Gemini 1.5, an advanced AI model that improves performance and long-context understanding across different modalities.",
      "The model utilizes an efficient Mixture-of-Experts architecture and has the capability to process up to 1 million tokens, enabling analysis and summarization of large volumes of information.",
      "Gemini 1.5 surpasses its previous version in benchmark tests and has undergone thorough ethics and safety testing. A limited preview is available to developers and enterprise customers, with pricing tiers based on the context window size being planned."
    ],
    "commentSummary": [
      "Google's Gemini 1.5 language model is capable of analyzing 10 million token contexts, which has generated mixed opinions among users.",
      "Users discuss their experiences with Gemini, comparing it to other models like GPT-4, and debate the effectiveness of different models and architectures.",
      "There are concerns about accuracy, cost, and scalability in using extensive context, but also excitement about the potential applications of large context sizes in language models for tasks like coding, video analysis, and translation."
    ],
    "points": 1083,
    "commentCount": 514,
    "retryCount": 0,
    "time": 1708009329
  },
  {
    "id": 39388218,
    "title": "Apple intentionally breaks iPhone web apps in EU due to new Digital Markets Act regulation",
    "originLink": "https://techcrunch.com/2024/02/15/apple-confirms-its-breaking-iphone-web-apps-in-the-eu-on-purpose/",
    "originBody": "(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window) Link Copied Apps Apple confirms it’s breaking iPhone web apps in the EU on purpose Sarah Perez@sarahpereztc / 7:31 PM UTC•February 15, 2024 Comment Image Credits: Apple Well, it turns out it’s not a bug that broke iPhone web apps, also known as progressive web apps (PWAs), in the EU. Following developer complaints and press reports about how PWAs were no longer functional in the EU after installing the most recent iOS betas, Apple has updated its website to explain why. No surprise, the tech giant is blaming the new EU regulation, the Digital Markets Act, for the change, saying that the complexities involved with the DMA’s requirement to allow different browser engines is the root cause. To catch you up, security researcher Tommy Mysk and Open Web Advocacy first noticed that PWAs had been demoted to website shortcuts with the release of the second beta of iOS 17.4. Initially, it was unclear if this was a beta bug — stranger things have happened — or if it was intended to undermine the functionality of PWAs in the EU, a market where Apple is now being forced to allow alternative app stores, third-party payments, and alternative browser engines, among other things. In the betas, PWAs, which typically allow web apps to function and feel more like native iOS apps, were no longer working. Developers noticed that these web apps would open like a bookmark saved to your Home Screen instead. As MacRumors pointed out at the time, that meant no “dedicated windowing, notifications, or long-term local storage”; iOS16.4 also allowed PWAs to badge their icons with notifications, as native apps could. Beta users of iOS 17.4 reported that when they opened a web app while running the iOS beta, the system would ask them if they wanted to open the app in Safari or cancel. The message indicates that the web app will “open in your default browser from now on,” it said. Afterward, users said they experienced issues with data loss, as a Safari website shortcut doesn’t offer local storage. Notifications also no longer worked. Still, there was reason to be cautious about whether or not the change was intentional. Multiple staff at TechCrunch repeatedly asked Apple for comment but received no reply. (We had wanted to know if the company would confirm if this was a beta bug or an intentional change, and if the latter, what Apple’s reasoning for it was.) After the next beta release emerged, The Verge ran a report indicating that Apple “appears to be“ breaking PWAs in the EU, after also not likely getting a formal response from the tech giant. Now Apple has responded, in its way. Today, it updated its website detailing its DMA-related changes in the EU to address the matter. In a new update, the company explains how it’s had to make so many changes to the iOS to comply with the EU guidelines that continued support for PWAs was simply off the table. Traditionally, the iOS system provided support for Home Screen web apps by building directly on WebKit (Safari’s browser engine) and its security architecture, Apple said. That allowed web apps to align with the same security and privacy models as found in other native apps. But with the DMA, Apple is being forced to allow alternative browser engines. It argues that without the isolation and enforcement of the rules applied to WebKit-based web apps, malicious apps could be installed that could do things like read data from other web apps or “gain access to a user’s camera, microphone or location without a user’s consent,” Apple said. “Addressing the complex security and privacy concerns associated with web apps using alternative browser engines would require building an entirely new integration architecture that does not currently exist in iOS and was not practical to undertake given the other demands of the DMA and the very low user adoption of Home Screen web apps. And so, to comply with the DMA’s requirements, we had to remove the Home Screen web apps feature in the EU,” the website reads. The company informs EU users they will be able to access websites from their Home Screen through bookmarks as a result of the change, confirming developers’ concerns that PWAs were effectively being disabled in the EU. “We expect this change to affect a small number of users. Still, we regret any impact this change — that was made as part of the work to comply with the DMA — may have on developers of Home Screen web apps and our users,” Apple says. Critics have argued that Apple’s desire to hold on to its power in the iOS app ecosystem was so strong that it would break web app functionality for users of its devices. Apple’s defenders, meanwhile, will probably argue that the company’s explanation is reasonable and aligns with Apple’s desire to keep iOS safe for its users. The truth, as it often does, likely lies more in the middle. Apple still has not responded to requests for comment. Please login to comment Login / Create Account TechCrunch Early Stage April 25, 2024 Boston, MA Register Now Sign up for Newsletters See all newsletters(opens in a new window) TechCrunch AM and PM Week in Review Startups Weekly Event Updates Advertising Updates Email Subscribe (opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window)(opens in a new window) Copy Tags Apple Apps developers DMA Progressive Web Apps",
    "commentLink": "https://news.ycombinator.com/item?id=39388218",
    "commentBody": "Apple confirms it's breaking iPhone web apps in the EU on purpose (techcrunch.com)666 points by M2Ys4U 13 hours agohidepastfavorite557 comments LeoPanthera 13 hours agoSince the article doesn't actually repeat what Apple has said, here's what Apple says: == Begin quote == The iOS system has traditionally provided support for Home Screen web apps by building directly on WebKit and its security architecture. That integration means Home Screen web apps are managed to align with the security and privacy model for native apps on iOS, including isolation of storage and enforcement of system prompts to access privacy impacting capabilities on a per-site basis. Without this type of isolation and enforcement, malicious web apps could read data from other web apps and recapture their permissions to gain access to a user’s camera, microphone or location without a user’s consent. Browsers also could install web apps on the system without a user’s awareness and consent. Addressing the complex security and privacy concerns associated with web apps using alternative browser engines would require building an entirely new integration architecture that does not currently exist in iOS and was not practical to undertake given the other demands of the DMA and the very low user adoption of Home Screen web apps. And so, to comply with the DMA’s requirements, we had to remove the Home Screen web apps feature in the EU. EU users will be able to continue accessing websites directly from their Home Screen through a bookmark with minimal impact to their functionality. We expect this change to affect a small number of users. Still, we regret any impact this change — that was made as part of the work to comply with the DMA — may have on developers of Home Screen web apps and our users. == End quote == Source: https://developer.apple.com/support/dma-and-apps-in-the-eu/#... reply fennecbutt 3 minutes agoparent>Without this type of isolation and enforcement, malicious web apps could read data from other web apps and recapture their permissions to gain access to a user’s camera, microphone or location without a user’s consent Sounds like Apple is saying webkit is insecure and to not use safari or iOS webviews because if they can't be trusted to run a PWA then they can't be trusted for anything ;3 reply benguild 11 hours agoparentprevThe “low usage” comment is going to be more ammo against Apple unfortunately. The whole reason they are low usage on PWAs is because of a lack of investment from Apple and a lack of parity, yet for the longest time Apple has played both sides by saying PWAs are a viable alternative to the App Store, all while channeling people to App Store for actual app downloads and not providing similar marketing or anything for PWAs reply thimp 11 hours agorootparentAre you sure this isn't a tech industry viewpoint? I don't know anyone who knows what the difference between an app and a PWA is. I don't think I've seen anyone outside of the tech industry with a PWA active. In context 99% of the users I meet don't even know what USB-C is. reply JacobThreeThree 3 hours agorootparent>Are you sure this isn't a tech industry viewpoint? I don't know anyone who knows what the difference between an app and a PWA is. I don't think I've seen anyone outside of the tech industry with a PWA active. The more important context is the legal one, not what laypeople think. Apple is presenting PWAs as viable alternatives to the app store in a legal context: https://www.accc.gov.au/system/files/Apple%20Pty%20Limited%2... reply afavour 7 hours agorootparentprevYou’re right but a lot of that has to do with discoverability and the lack thereof on iOS. On Android you can show an install prompt via the browser or even package your PWA to be distributed via the Play Store. On iOS you have to do a strange incantation of “sharing” a web page to your Home Screen via a submenu. Its utterly unituitive so it’s not too surprising that most don’t. reply benguild 11 hours agorootparentprevCorrect on it being a tech industry viewpoint— people think \"apps come from the App Store\" and therefore anything else that's clunky requires a fair amount of education and payoff for users to adopt. It's off balance, and it shows now that the tech has to be removed since it wasn't actually at parity despite it being an argument for it unfortunately. The worst part? This has been the case for 15 years. It's not like there wasn't enough time to fix it. That's plenty of time to hire and develop solutions, yet now look at the reasons for it being taken away. reply lloeki 3 hours agorootparentprev> In context 99% of the users I meet don't even know what USB-C is. OH (frequently): - hey I need to to up, do you have a phone charger? - yup, which kind? - not \"an Apple\" - oh, so USB? - yeah the \"standard\" one, not the \"new usb\" That said, I'm surprised many do know about the literal \"usb-c\" term. Micro USB A though flies over their head, it's \"small usb\" or \"standard usb\" every time. Of note: EU here, and while they by and large don't know about the EU standardising stuff they did notice the effect. I've seen a few refer to USB-C as \"universal one\" (largely coz it works the same for both phones and laptops) reply pmontra 1 hour agorootparentWith my friends it's either \"USB-C\" or the \"round USB\". Maybe it's already too old to be referred to as the \"new USB\". The old one is definitely the \"old USB\" or the \"not round USB\". reply anakaine 11 hours agorootparentprevFair call on your first point about PWA knowledge level in users. Regarding your users knowledge of what USB-C is: are you sure your user group are not potato's? Most people I know, including the teenage daughters and their friends, all know what USB-C is these days. reply thimp 11 hours agorootparentOne of them was going to buy a new phone because it took a long time to charge. This was because she had a crap charger and crap cable. I am unsure if they are potatoes or not but I suspect they might be :) reply pmontra 1 hour agorootparentIt can be only the charger or the cable. It usually happens when using the charger of an old phone for a new one or when buying a new cable, maybe because the one coming with the phone is too short and doesn't go from the plug to the table. Both chargers and cables usually list their compatible phones. reply red369 10 hours agorootparentprevI don't necessarily think it applies in your example, but I've heard some very silly reasons given by people as their reason for upgrading. I think a lot of the time people give an excuse, or perhaps even a justification to themselves, when they really just want the excitement of new phone. I often catch myself inventing reasons why I should replace my perfectly fine phone. reply thimp 10 hours agorootparentNo it was 6 months old and she doesn't care about it or phones. She thought it was broken. I charged it with my powerbank, an anker PD one and she ordered a proper charger off amazon. I gave her my spare USB-C cable. It was seen as a potential financial inconvenience having to do anything about it as well. Literally many people do not care enough to understand it. It's just a modern necessity, a tool. reply illumin8 6 hours agorootparentThis is my wife. She purchased a bunch of USB-A to USB-c cables off Amazon and wonders why her laptop runs out of power while plugged in - it's because the laptop needs 25-30 watts and those cables can only put out 5 watts because they're limited by the USB-A port. USB-c PD is such a dumpster fire of a standard. Even with supposedly high end cables like Anker you often can't charge a Macbook Pro faster than it can drain it's own battery under load. We can't expect normal people to understand why there are a dozen different cable types that all have the same tip but charge at vastly different rates... reply literalAardvark 14 minutes agorootparentThat's true of all things that don't respect standards, not a PD issue. If you buy a wheel and it's not up to spec it'll crack. If you buy a power cable and it has a type-c on one end and a 110/220v plug on the other, that's not going to work well either. Buy stuff that's up to spec, and it'll be fine. Dylan16807 3 hours agorootparentprevThe charging speed of USB-C cables (C on both ends) is pretty much just the slow ones and the fast ones, and \"slow\" is 60 watts. reply throwaway2990 2 hours agorootparentNo. reply Dylan16807 2 hours agorootparentYes. Every conforming cable supports 3 amps and 20 volts. If you think something's incorrect with that, be specific. But the spec is pretty clear. The exact details of the faster cables are murky because there's old and new versions of that section of the spec, but very few devices use enough power to care about that. reply oarsinsync 1 hour agorootparent> Every conforming cable The problem is all the non-conforming cables that people have, that look exactly the same as conforming cables. reply geoelectric 1 hour agorootparentExcept they were responding to a comment criticizing USB-C PD as a standard. Non-standard cables are irrelevant to that discussion. reply dhosek 4 hours agorootparentprevI recently discovered that I can use my iPad and MacBook charging brick to test PD of a usb cable. If it’s low wattage, the charging brick will not provide any power to the iPad. High wattage and it will. reply diffeomorphism 2 hours agorootparentprevIt is a bit curious that you immediately jump to PD being a dumpster fire instead of the much more immediate \"apple is a dumpster fire and incompatible just to be obnoxious\". reply darylteo 9 hours agorootparentprevGoing on a slight tangent: I do get many clients inquiring about PWA because \"they don't need to pay 30% per purchase\". This is anecdotal, of course... they wouldn't be able to tell you what it is, but all they care about is that they save 30%. So there is definitely \"interest\" in PWAs. reply formerly_proven 1 hour agorootparentprevSo what's a Home Screen Web App in this context? Is it adding a bookmark to the home screen (you open it, and it opens in the regular full iOS Safari), or something else? reply tester89 11 hours agorootparentprevThe only PWA that I think gets any use on i(Pad)OS is that for the Financial Times. reply dangus 8 hours agorootparentprevI think PWAs are an outright failure and a technical solution looking for a problem. I don’t even know where to find one. For one thing, if Apple is complying with the EU’s alternative App Store and browser engine mandate, they’re even less useful than before. Why do I as a user want a PWA when I could have a native app? reply mgoetzke 4 minutes agorootparentIt allows us from our webapp to easily allow a user to i.e. PIN a section of the app onto the homescreen (e.g import photos into this folder).. really nice. reply anon373839 54 minutes agorootparentprevYou think that a technology that allows mobile apps to be developed and distributed in a way that’s secure, free and open, and platform-independent is a solution in search of a problem? Honestly? reply jc_dc 6 hours agorootparentprevPWA’s on Android can be installed directly from a website…it’s awesome, less friction and less scammy than the Play Store. On iOS you need to use the Share > Add to Home Screen which normies have no clue about. You’ll find out if the site supports PWA features AFTER you add it to your Home Screen. This of course is done entirely on purpose to make them harder to find and less appealing than the revenue generating App Store. For me, I use iPhone entirely because pixel doesn’t support cardav and caldav out of the box…if I can’t use PWA’s on my phone then I’m going back to android cause I can solve the email problem easier than I can solve the productivity tools not being available via PWA’s. reply dangus 4 hours agorootparentGoogle should in theory have the same play store revenue motivation to hide PWAs, right? Granted, they also want people to stay on the web to continue using Google.com, so I guess those are two competing priorities. That to me is a bit of an indicator that Apple just doesn’t believe in the merits of the technology. I think they might be asking the same question in asking: what problem is this solving? Every platform with a web browser has a better way to run applications, which is to just run an application. A web site that is masquerading as an installed application is basically just a less capable application. As a side note, I’m also not really sure how an app store can be considered scammier than the entire web. The web is a Wild West with far fewer “rules” than the Play Store. reply jc_dc 1 hour agorootparentGoogle have an interest in moving people away from desktop applications because they don’t have a desktop OS (not counting Chromebook). We run 3 SaaS apps. One is strictly native, and the other two are strictly web. Writing for 4 platforms on the native app is an extremely expensive exercise and then we are also subject to the insanity that is the App Store. Long story here, everything from App Store review times on mission critical software to the fact that their billing mechanism simply doesn’t work for B2B SaaS…and by the way, we get zero traffic from the App Store as that’s simply not where our customers are looking for the solution we provide. Fortunately, bulk of our customers start on desktop where we self distribute (code signing on windows and notarization on mac) with ev ssl on marketing sites. Why is the App Store scammy over the open web…search for any number of popular apps and look at how many have been cloned. Sure, you can do this on the web with paid ads and enough SEO effort but it’s much harder. To this day, Apple continue to allow keyword stuffing, advertising on trademarked names, and blatant copyright infringement in app descriptions and even I (fairly tech savvy) accidentally purchased a clone of poly bridge for my kid cause they’ll list the clone above the real one on an exact term search. What was apples response when I said I purchased the wrong app? Tough cookies! This is the same reason I hate shopping on Amazon. I simply prefer to have a direct relationship with the companies I buy things from, and from what I can tell, our customers prefer have a direct relationship with us. But back to why PWA’s are awesome…simply put, iteration time. We can publish dozens of improvements every day and roll back instantly when an issue arises. We simply can’t do that with native as long as the Apple / Google act as a gate keepers. When we allow proper sideloading without the scare tactics and dirty tricks, we’ll take the time to build native again. reply JacobThreeThree 3 hours agorootparentprev>Google should in theory have the same play store revenue motivation to hide PWAs, right? Google in theory has a financial motivation to make their competitor Apple look like the bad actor. reply TheCapeGreek 2 hours agorootparentprev>technical solution looking for a problem In some regards yes. In practical regards they're a threat to app store margins (on all app stores, not just Apple), so there's no incentive to truly support them other than developers being loud about it. >I don’t even know where to find one. Because Apple has crippled the ability for you to use them, so developers can't really spend time working on them. Chicken and egg problem. >if Apple is complying They're not really, they're twisting and turning as much as possible to look like complying but make the desired outcomes even more difficult to achieve. reply johnnyanmac 7 hours agorootparentprevI mean, the problem is the same one introduced since the two big mobile platforms were established: \"I want to publish to IOS/Android as a native app without needing to have two separate builds to manage\". PWAs make that pitch to those who already have websites to triple dip. It never has to promise to be as good as a native app, just \"good enough\". Does it live up to that? YMMV. It's probably fine for very simple apps, probably comes apart at the seams for anything trying to look modern or have fancier functionality. reply claytongulick 6 hours agorootparentI've built large, complex and beautiful healthcare apps as a PWA. The only two things I've ever missed from native functionality are: - background geolocation - push notifications on ios The second one was fixed recently. In contrast, from what I've seen 90+ percent of apps I see in the app stores would be better as a web page / PWA. reply dangus 4 hours agorootparentBut the real question is where most of your users live. I’d take a decent wager that most of your users are most familiar with apps and would prefer installing full apps. Doesn’t matter that most apps would be better suited to being a web page or PWA if that’s not where the users are. That’s kind of like saying that PCs are better at gaming than consoles. Yes, that’s true, but that’s not where the majority of users are. reply kristiandupont 4 hours agorootparent>But the real question is where most of your users live. Well, they \"live\" on their phone. I would just put a button on my website to install the app, users would find that easily. reply johnnyanmac 4 hours agorootparentprevI mean, PWAs aren't made with the goal to maximize User UX. It's a cost saving measure like any other solution that isn't making 2 dedicated native apps for IOS/Android.it won't get as much traffic as a native app, but it's almost \"free\" to deploy. To use the gaming console example, it's not unlike using an emulator to launch your game on PC (if you could somehow monetize an emulated rom). It's not the ideal experience, but it requires very little extra work. reply callalex 2 hours agorootparentI find PWAs to have a vastly superior UX. I can trust that they are running in the strongest sandbox my device has to offer. I don’t have to download anything, and I don’t have to update anything. I don’t have to remember any account passwords to install anything, and my ad blockers and password managers just work inside them. I don’t have to worry about arbitrary content policies of Apple or Google, the app can just show me whatever it wants. reply treflop 3 hours agorootparentprevFrom Apple’s PoV, PWAs don’t earn them any money, aren’t forced through review by Apple, and decrease lock-in. There is no incentive for Apple to support PWAs. reply ikekkdcjkfke 3 hours agorootparentSo it is now their fiduciary duty to enshitify the web? Nice system reply pjmlp 3 hours agorootparentEnshitify ChromeOS actually. reply nemothekid 6 hours agorootparentprev>The whole reason they are low usage on PWAs is because of a lack of investment from Apple I don’t know if this ironic given that apple originally didn’t want to support native apps and gave in due to developer demand. Apple both did and didn’t want web apps reply turquoisevar 4 hours agorootparentprev> The whole reason they are low usage on PWAs is because of a lack of investment from Apple and a lack of parity This is a trite argument that hasn’t been true ever since Jen Simmons joined Apple in 2020 and changed the course of Safari significantly to the point that PWAs not only are viable, they have been given feature parity with native apps on many fronts. Simultaneously, the argument completely bypasses the fact that install rates of PWAs are abysmal on any platform. Whether it be iOS, Android or Windows. Contrary to what PWA developers, industry organizations and other stakeholders proselytize, PWAs aren’t the second coming and the next best thing since sliced bread. At least not when it comes to install rates. Edit: Don’t get me wrong, I’m sure they’re great as “websites”. Lord knows people who sell PWAs[0] love to brag about bounce rates and conversion rates and what not. But there’s a reason why you can find barely anything about install rates other than some vague statistics about individual unnamed PWAs[1] or PWA sellers[2] talking about obviously bogus 10x and 3-5x install rates, and it’s not because the PWA crowd is too shy to brag. 0: https://www.pwastats.com/ 1: https://developer.chrome.com/blog/pwa-install-features 2: https://mobsted.com/pwa_vs_native_mobile_apps_install_rates_... reply jchw 4 hours agorootparentThat's kind of the point, PWAs don't have parity on any platform, but Apple's platforms are the only ones where it is being positioned as a legitimate alternative; Android has \"sideloading\", Windows has REGULAR loading. It doesn't matter who joined Apple when and did what, PWAs on iPhone are not like native apps, it's not even really close. It's good that this pathetic line of argument wasn't much of a deterrence for the EU. What people want isn't PWAs, they just want the kind of capabilities that computers have had for decades, including many of Apple's current computers for sale today. To be able to install an application and run it. reply turquoisevar 3 hours agorootparentnext [2 more] > That's kind of the point, PWAs don't have parity on any platform That’s not true, nor what I posited. PWAs have almost all the native features, if not all, depending on the platform. Plenty of “pro-PWA” people go out of their way to demonstrate this[0]. I’m talking about install rates and usage by end users in a way similar to using a native app. Whether you agree on parity or not, you seem to concede that PWAs aren’t wildly adopted the way native apps are. As such, it makes sense that Apple wouldn’t want to waste engineering resources on it by rewriting the underlying architecture, which is the topic at hand. That in and of itself ends the debate. You then go on, OT, about whether Apple should or shouldn’t position websites and PWAs as legitimate alternatives. Saying: > but Apple's platforms are the only ones where it is being positioned as a legitimate alternative Specifically, Apple states[1]: > If the App Store model and guidelines are not best for your app or business idea that’s okay, we provide Safari for a great web experience too. An alternative isn’t, as you seem to imply, an identical option; instead, it is simply understood to mean a different choice, usually a choice different from what is usual. One might say, \"In the absence of a better alternative, we’ll have to proceed with our original plan.” This use in and of itself implies that one option is better than another, thus not identical. Whether something is “legitimate” or, more specifically, a “legitimate alternative” entirely depends on the person making the consideration and the value judgment they make based on their needs and wants. I might consider soda a “legitimate alternative” to coffee because I’m just looking for a beverage, whereas a different person might not deem it a legitimate alternative. After all, they are solely interested in a warm beverage. With that in mind, I consider web pages, particularly PWAs, a legitimate alternative to native apps because most native functions are available to PWAs on iOS. You might not because your need might be one of the few things PWAs can’t provide. That doesn’t make it a bad-faith argument on Apple’s part; they never claimed that PWAs are an identical option to native apps via their App Store. They offered up an alternative that can provide some, if not most, of what a native app can provide. You continue with your OT by presenting a false equivalence > Android has \"sideloading\", Windows has REGULAR loading. It’s a false equivalence because neither Google nor OEMs present sideloading as a legitimate alternative; it simply exists, but it’s not promoted as an alternative option. Google specifically likes to write copious amounts of words in blog posts[1] and whatnot, talking about how great PWAs are while wearing their Chrome hat. Meanwhile, the PWA experience on Android is marginally better than that on iOS, provided you use Google’s browser. Where is your indignation for that? They’re promoting PWAs harder than Apple will ever do. For that matter, Microsoft also doesn’t call “regular loading” a legitimate alternative, so again, your equivalence makes no sense. > It doesn't matter who joined Apple when and did what Of course it does; if you don’t go OT, that is. Whether Safari is or isn’t suitable for PWAs is essential to assess if PWAs are used in meaningful quantities. If someone posits that Safari doesn’t properly support PWAs when that isn’t true, like GP did, then it’s important to point that out and provide context on when that changed. It doesn’t matter to you because you’re having an entirely separate discussion. > PWAs on iPhone are not like native apps Yes, they are. As stated above, they’re not identical, but they are similar to, or if you prefer, “like” native apps. > it's not even really close This is a value judgment because it requires that you and I agree on the definition of “close.” I argue that they’re pretty close because they can do about 90% of what native apps can do. > It's good that this pathetic line of argument wasn't much of a deterrence for the EU. Let’s keep it classy and within HN guidelines. > What people want isn't PWAs Hence, the low install rate of PWAs and why it’s not weird that Apple didn’t decide to spend engineering resources on rewriting the underlying architecture for PWA installs. Again, that, in and of itself, ends the debate. > they just want the kind of capabilities that computers have had for decades, including many of Apple's current computers for sale today. To be able to install an application and run it. I’m not sure what you base this on. From here, it looks like you’re projecting your own wants onto the average iPhone user base at large. Do you have anything that expands on how many iPhone users share your vision? The commercial success of iPhones suggests that not many seem to care for this. I suppose alternatively, you could argue that the fact that Android dominates globally indicates there is a demand for this in the smartphone market[2]. Still, the obvious question then becomes why those iPhone users wouldn’t just join in Android’s dominance and switch over, particularly those who feel so strongly about this that they’d spend their time online lamenting its absence. 0: https://whatpwacando.today 1: https://developer.apple.com/app-store/review/guidelines/#int... 2: This is simplified, of course; one feature wouldn’t be the sole driver of Android’s dominance reply jchw 2 hours agorootparentI'm not going to go point by point on this one, but I do have some remarks. I am not \"projecting\", I own multiple Apple devices, therefore, I am very well within my right to talk about what I want as an owner of Apple hardware and on behalf of likeminded users, even if people on Hacker News don't like that fact as is evident from time to time. Wanting \"sideloading\" aka regular loading is not wildly off topic, it's literally MORE on topic than PWA vs native app parity, which is really not relevant to the EU DMA compliance issues at hand. And on that note, of course PWAs do not have parity with native applications. They're quite a lot slower, for starters. Is anyone shocked? No... it's not weird that it is much slower when you are going through Webkit instead of native APIs like Metal, in WebAssembly and JavaScript instead of C and Swift. That's disregarding the fact that both policy-wise and in what APIs are available, clearly PWAs have significantly more limited access to integrate with their host platforms, which again, is hardly surprising for glorified bookmarks. reply jdminhbg 10 hours agorootparentprevSo are PWAs really popular on Android? reply shuckles 8 hours agorootparentI think the advocate retort is that lack of support on iOS makes them a nonstarter for developers on all platforms. I think this argument is more of an excuse. reply dangus 8 hours agorootparentRight, Android has something like 70% global marketshare. PWAs aren’t popular because they don’t really benefit developers/businesses. They also don’t offer any advantages in user experience over a native app. Apart from the economics, there’s no developer friction advantage since you can use something like react native and deploy anywhere. The kind of deep user information you can gather by installing a full blown app compared to a more sandboxed web app is worth way more than the 30% royalty cut. reply kristiandupont 4 hours agorootparentThere is great value in building one product instead of three. >The kind of deep user information you can gather by installing a full blown app compared to a more sandboxed web app is worth way more than the 30% royalty cut. What kind of information is that? reply m463 7 hours agorootparentprevhow do they know low usage if there is no download from apple? reply Teckla 7 hours agorootparentMost likely telemetry in iOS itself. iOS knows when users pin web pages to the home screen, and iOS knows each time a user taps on and opens those pinned web pages. reply overstay8930 7 hours agorootparentprevBecause they know what’s on your Home Screen If you enable Usage analytics? reply stephenr 8 hours agorootparentprev> not providing similar marketing or anything for PWAs It's functionality to add an arbitrary webpage. What exactly are you expecting them to \"provide\"? reply zer00eyz 12 hours agoparentprevWithout this type of isolation and enforcement, malicious... camera, microphone or location ... Browsers ... 30 some million lines of code in chromium browsers. Thats bigger than the linux kernel. The HN crowed might not LIKE apples response but they have a very defensible position. Edit: Its not like we haven't seen this play out on the desktop recently: https://www.theverge.com/24054329/microsoft-edge-automatic-c... reply arghwhat 10 hours agorootparentIt really doesn't make sense. By that logic, I shouldn't be allowed to load web pages because it's impossible to secure a browser. PWA's only need a few extra integration privileges like badge- and window control, rest is just a web as usual. What you link is a case of one app (edge) reading the data of another app (chrome), which is entirely unrelated to PWAs. reply wokwokwok 8 hours agorootparent> By that logic, I shouldn't be allowed to load web pages because it's impossible to secure a browser. Indeeed, and 'whatever browser engine you picked here' is responsible for correctly implementing these additional security features. That's the argument; if you write an app that lets you run other apps inside it how do we make sure your app does security correctly? When you look at it from that perspective, you can see that unless at an OS level you provide additional 'meta-security' features that allow apps that run in other apps to have fine grains access control that is managed by the OS, it's pretty much \"security? Well, whatever...\". Right? I mean, whether you agree or not, it's a pretty reasonable position to take and it entirely makes sense. reply neurostimulant 3 hours agorootparent> if you write an app that lets you run other apps inside it how do we make sure your app does security correctly? But browsers already have this security features that isolates websites from each other? How come PWA, which essentially just placing a website shortcut in the home screen and hiding browser ui, affect browser's existing security features? reply anon373839 46 minutes agorootparentIt doesn’t, of course. Apple’s real concern is that if Chrome is allowed to host standalone PWAs, it can also remove some of the unnecessary pain pointed that Apple’s Safari maliciously injected to kneecap PWAs in the first place. For example, Chrome could make it easy for users to install a PWA. Chrome could support more web standards. Etc. This would create a true alternative to the App Store, with no Apple tax, and of course Apple isn’t going to let that happen without kicking and screaming. reply johnnyanmac 7 hours agorootparentprev>and 'whatever browser engine you picked here' is responsible for correctly implementing these additional security features. so, Apple? Since Apple has also required browsers for years to use their own safari backend, this isn't even an issue of \"oh well it doesn't work on Firefox\". Sounds like they cornered themselves there. reply nip 4 hours agorootparentApple’s hand has been forced to implement changes that didn’t fit their vision and roadmap. I imagine that if you’re on HN you are close to developers or are a developer yourself. And if so, I imagine that you have already had an important customer (to who you cannot say “no”), completely change your plans and architecture with a new feature request while setting an aggressive deadline (ie, you don’t have time to implement everything and must make choices) Now replace you with “Apple” and “important customer” with EU. reply MrDresden 1 hour agorootparentThat is simply just nonsense. They had 1,5 years from the time of being identified as gatekeepers to work on this. The DMA was voted on by the EU parliament and then the council in july 2022, Apple was identified as a gatekeeper in september 2022, the law became legally implemented in november 2022, with gatekeepers required to comply with it by march 6th 2024. I do not buy for a second that the richest tech company on the planet, that owns, designs and manufactures the whole tech stack their product uses was unable to respond in due time to the legally required changes and so 'just had to go this route due to time constraints'. reply johnnyanmac 4 hours agorootparentprev>I imagine that you have already had an important customer (to who you cannot say “no”), completely change your plans and architecture with a new feature request while setting an aggressive deadline Sure. I sure do wish the demands were actually consumer centric, and not \"force all these advertising tracking into your site, tank performance, and grab a bunch of unneeded user data\". And of course, if I maliciously complied and \"oops the tracking only gets 1% of user data\", I would simply be fired instead of get another strongly worded letter leading to meetings re-defining what \"grab a bunch if unneeded user data\" is. reply nip 3 hours agorootparentYou are confusing the “important customer” with “other customers”. EU is the “important customer”, the users of PWA are “other customers”. Using your example, you would implement tracking for that important customer (and comply 100% to the requirements as Apple did) but because of this additional bloat, the website would load 2 times slower. After a discussion with your colleagues, you would realize that: - Most users won’t care about the slow loading (including the important customer) - Re-architecturing the website to keep the same level of performance while adding the necessary tracking required by the important customer would delay shipping the tracking by 1 year, past the 2 months deadline required by the important customer. Back to your desk, you start implementing the tracking that will incur a 2x slower load time. reply johnnyanmac 3 hours agorootparent>You are confusing the “important customer” with “other customers”. I'd love to one day work for a place where I can dismiss monetization as \"the other customer\". But alas, my career hasn't been that friendly. >Using your example, you would implement tracking for that important customer (and comply 100% to the requirements as Apple did) but because of this additional bloat, the website would load 2 times slower. Given how the topic is: >Following developer complaints and press reports about how PWAs were no longer functional in the EU after installing the most recent iOS betas I fail to see how the EU is the \"important customer\" here. And not the powers that be in Apple telling me to maliciously comply. The EU said \"allow other app stores to exist\" and my theoretical manager at Apple is saying \"okay, PWAs can exist but they don't have to run well. Add in unnecessary security (because the NA version doesn't have it) that disables functionality\". I don't even see how it has to do with complying with the EU, unless it's soke long term OS lock down for future app stores. Tell me how the EU here is the one telling me to slow down my OS/browser? reply derefr 8 hours agorootparentprev> you can see that unless at an OS level you provide additional 'meta-security' features that allow apps that run in other apps to have fine grains access control that is managed by the OS, it's pretty much \"security? Well, whatever...\". I don't think that's the only solution. A simple alternative is to declare that \"apps that run in other apps don't get to do anything at all.\" I.e. in this case, in response to a EU requirement to support alternative browser engines, Apple could — rather than disabling PWA integration altogether — drop all additional privileges that PWAs have that regular webpages don't. Make installed PWAs in the EU market into just \"webpages, but with a home-screen icon, a separate task-manager card, and no address bar.\" Which is 99% of the reason anyone installs a PWA anyway. No camera/microphone, no extra storage, etc. Not for Chrome PWAs, not for Safari PWAs; not for any PWAs (on these devices.) They're just webpages presented differently. No \"meta-security\" required! reply rahkiin 2 hours agorootparentThis would run foul against the DMA, unless they make safari PWA also less capable. reply giantrobot 7 hours agorootparentprevThen everyone will just bitch PWAs can't do anything. reply Izkata 4 hours agorootparentThe Peapod grocery delivery app was already just single webview to their website. Worked fine. reply kristiandupont 4 hours agorootparentprevI don't see how this refutes GP's point. Yes, it's a big challenge but when they are allowing other browsers, the challenge is met already. The \"install to home screen\" feature adds but very minute extra features. reply rahkiin 2 hours agorootparentI guess the issue is that PWA is more deeply integrated… so instead of having this integration within the OS using their WKWebView component, they need to make it a user choice which browser component is used. This component then has to be installable through the App Store. This then also means an ‘app’ is hosted by another ‘app’, and to do this properly that host app needs to many permissions reply elbear 3 hours agorootparentprevMy understanding is that Apple can provide security guarantees only for their own browser, because it's tightly integrated with the rest of their stack. reply ants_everywhere 8 hours agorootparentprev> What you link is a case of one app (edge) reading the data of another app (chrome), which is entirely unrelated to PWAs. In one sense, sure. But in another sense Edge taking Chrome's tabs means Microsoft is getting insight into Google's data. A lot of Apple's defenses seem really targeted at reducing the ability of Microsoft, Google, and Meta to extract value from Apple's users. Apple sees the union of all the app data, but their competitors can't put together that picture. So in that sense, Edge eating Chrome data may be the sort of thing they're looking to prevent. reply sagarm 8 hours agorootparentAfter all, Apple users are the product. They even pay for the privilege! reply xwolfi 5 hours agorootparentThey are a cash flow generating financial product, like a bond ETF. Apple packages users, resell them to the highest bidder, and interest is collected as return on investment from the payments users make. Ofc, like a bond, a user pays for a reason: he gets something out of the facility provided by Apple, in kind. reply emgeee 10 hours agorootparentprevIn my experience even \"a few extras privileges\" can take many months to implement, especially for a company as large as Apple. reply layer8 9 hours agorootparentThe EU gave them six months after being designated as a gatekeeper. The regulation already entered into force an additional ten months earlier, so Apple arguably could have already prepared for their likely designation. The real issue, however, is that Apple is not saying “we need more time to implement the APIs”, which the EU would very likely concede, but “we don’t think it’s worth it for us”. reply summerlight 12 hours agorootparentprevWhy should we trust Apple for security in that context? Apple also provides all those functionalities via their proprietary API, which is not even audit-able. If Apple really believes in that argument, they should disable their own API as well. reply M4v3R 12 hours agorootparentYou have to trust someone if you're using a computing device connected to the Internet. The point of being in Apple ecosystem is that you trust Apple, and then (supposedly) you can not trust anyone else. To many that's a very strong proposition. reply addicted 10 hours agorootparentWhy can’t I choose to trust Apple for iOS and another developer for other functionality that runs on iOS? We do this all the time. I don’t uniquely depend on Microsoft for stuff that runs on Windows. Same for stuff that runs on macOS. And on Linux I’m not even sure who I’m trusting from the ground up other than a huge and disparate collection of people. So what makes iOS so unique that it can’t run PWAs, which is little more than adding some chrome and a handful of APIs to already pre-existing browser capabilities. What an F’ing joke. And the bigger joke are the Apple fans who are going out of their way to defend Apple sticking it up their nether parts. reply zappb 7 hours agorootparentIt’s not unique to Apple. It’s an inherent problem to securing Turing machines. reply trinsic2 8 hours agorootparentprevI'd rather trust a public (not-for-profit) institution that actually had a real incentive to protect user security. Instead we get for-profit companies that have a vested interest (conflict of interest) to do security the way it thinks it should be done. In my experience, that usually is bad for the people that are using the platform because there is no real surety that security is being done for the sake of the users. Apple has no interest in working with public institutions that have a close relationship with the people they serve. That's a big red flag in my book. You cant trust a company that serves content and hardware and at the same time trust them with security. It's too many eggs in one basket, to easy of a target for rogue entities (NSA) even if they have good motives . reply blackoil 5 hours agorootparentprevThere are two kinds of trust, I may trust Apple to not intentionally steal data. But I may trust Signal to create a more inherently secure messenger, or I may trust Google to create technically a more secure browser. What Apple and some users here are saying that users don't have intelligence to judge it and so will have to trust only Apple. reply jc_dc 6 hours agorootparentprevAnd to a degree, that’s why developers tend to hate Apple. They paint us as a pack of crims trying to steal from unsuspecting Apple users. reply MrDresden 1 hour agorootparentI think you are conflating the relationship between consumers/developers and the corporation (that you work for?). I don't hate Apple, but rather realise that it's bottom line and fiduciary duty to its shareholders is stronger than what is best for us (consumers/developers). I do not trust the corporate marketing one bit (and honestly, why should I?). This behaviour of Apple just further supports that view. As a company, it seems to believe it is somehow above following the rules meant to benefit consumers/developers, something the conpany has been marketing its self with since the 80's. So lets stop the 'Leave Apple alone (and us that work there)' crying, and just acknowledge what the whole thing revolves around. reply troupo 1 hour agorootparentprev> They paint us as a pack of crims trying to steal from unsuspecting Apple users. Have you seen the world around you for the past 20 years or so? I'd say this characterises developers (well, companies they work for at least) quite well, don't you think? reply summerlight 11 hours agorootparentprev> The point of being in Apple ecosystem is that you trust Apple, This seems to be over-generalization? Users are using Apple devices because those are good products, not because they want to delegate every single trust problem to the Apple ecosystem. That might be a great proposition for people like you, but there is a significant number of people who consider it a compromise rather than a value. reply chongli 11 hours agorootparentUsers trust Apple because Apple is ultimately accountable for security breaches on iOS devices. If a 3rd party app causes a data breach it does not matter if the breach was made possible by compliance with regulations like the DMA, Apple will still take the blame. reply summerlight 11 hours agorootparent> Users trust Apple because Apple is ultimately accountable for security breaches on iOS devices. As a long time user of Windows which historically had an incomparably large amount of security incidents, I can assure you that Apple won't get blamed that much for 3rd party data breach unless it involves Apple's own service and user data. reply chongli 11 hours agorootparentSince you’re a commenter on HN I’m going to assume you’re a tech person. I’m not talking about tech people, who through their discussions try to find the correct person/company to blame for issues. I’m talking about the general public. If a story about a data breach in a 3rd party app — affecting iOS users — hits the news cycle, Apple will take the blame and their brand reputation and sales will be impacted. It doesn’t matter whose fault it really is, Apple is the face of the iPhone and through their walled garden they have accepted final responsibility for everything that occurs on iOS. reply Wowfunhappy 11 hours agorootparentI don't see how this matters to the GP's argument. Windows was a virus hotbed for decades and that does not appear to have affected its reputation in a meaningful way. reply chongli 11 hours agorootparentThat’s because Windows’ reputation was already mud. Microsoft made their business on corporate users anyway. Apple is a consumer brand. A data breach on iOS is like nudity in a Disney movie: utterly brand-destroying. reply Wowfunhappy 11 hours agorootparentWindows was both. If you were buying a computer in the early 2000s, it was almost certainly a Windows PC. reply chongli 10 hours agorootparentRight, but Apple built their brand on being the alternative to Windows for people who didn’t want to deal with security issues, viruses, crashes, bundled junkware, etc. You can draw a direct line between Apple’s original marketing pitch (easy to use, simple, secure, appliance-style computing) and the iOS walled garden. Just as you can with Disney and their family-oriented brand. It’s not a compelling argument to say that other film studios have nudity in their films when Disney is the brand at issue. reply zappb 7 hours agorootparentprevThat was because Microsoft abused their monopoly in operating systems at the time to force OEMs to use their OS on all their computers in order to maintain the industry discounts on OEM licensing. reply ffgjgf1 2 hours agorootparentAlso because there weren’t really any credible alternatives reply overstay8930 7 hours agorootparentprevWindows doesn’t have a reputation. It’s the default. Nobody actually likes using windows you just have to. Do you really think there are people out there asking for advertisements in their start menu? reply jc_dc 6 hours agorootparentTo this day, I prefer windows, and I have to switch between Mac and windows all day every day. reply addicted 9 hours agorootparentprevWhat was the last 3rd party breach Apple took the blame for? reply overstay8930 7 hours agorootparentFappening. Apple took all of the blame and then we got mandatory MFA. The logjc works even if it’s the own users fault for getting scammed. reply anon84873628 11 hours agorootparentprev>there is a significant number of people who consider it as a compromise rather than a value. I suspect that from Apple's perspective, it is definitively not a significant number. For Apple, ownership of the \"trust problem\" is an intrinsic part of \"making good products\". reply summerlight 11 hours agorootparent> For Apple, ownership of the \"trust problem\" is an intrinsic part of \"making good products\". Yes, this might be true. And the majority of elected officials in EU fundamentally disagrees with that statement. reply paulmd 11 hours agorootparentYeah, as I’ve said before: the root problem here is that the EU wants to outlaw apples business model. People don’t think of it that way, they tell themselves all the reasons why that’s a good thing, but that’s ultimately what it is - a legislative solution to end the “android vs iOS” debate for all time. The argument is walled gardens shouldn’t exist, so the solution is to either legislate requirements that apple destroy the walls, or that they exit the market. That is a statement that most android advocates would agree with. And the EU will largely just keep ratcheting up the legislation until that happens. Driving apple out is the point - walled gardens are (in the EU sense) unacceptable and the option for a walled-garden business model needs to be removed from the market. Apple is (correctly) perceiving this and pulling out of the market, first by dropping the affected features, and I’m sure there will be a “next compliance requirement” before many years too. reply munk-a 10 hours agorootparentI feel like this is a win for consumers - I'd much rather there remain more OS competition on mobile devices[1] but if Apple wants to pursue a business model that excludes large portions of the world from their customer base that's their decision. I don't believe there exists any maliciousness from the EU towards Apple - they do, after all, benefit greatly from corporation tax revenues from Apple and iPhones are still quite popular in the EU. I think at the end of the day there's just a difference in the social expectation of privacy and freedom between the EU and NA. Apple, being primarily steeped in NA's expectations for freedom, hasn't built an ecosystem that is compatible with the EU's higher expectations. 1. Still hoping to see something amazing RIM! reply justinclift 9 hours agorootparent> NA's expectations for freedom That'd be \"corporate freedom\" rather than \"end user freedom\" yeah? That's my impression of what the NA model of freedom seems to mean these days. reply jokethrowaway 9 hours agorootparentprevI don't see how you can call EU having any expectation of freedom when commenting about a law which forces a company to comply to regulation. This actively reduces freedom, the freedom of running your business. You just don't care about it. If you don't like walled gardens you can just not use them (I certainly never bought anything Apple for this very reason), there's no need to infringe on the freedom of everyone else who wants to use walled gardens. The EU is in general becoming increasingly less free, thanks to barely elected bureaucrats who line up their pockets with sponsors money. reply munk-a 9 hours agorootparentI think this is a great example of what I had mentioned as social differences of freedom between the EU and NA - in NA the freedom of businesses is often well protected up until it causes actual harm to human beings[1] - in the EU the freedom of human beings tend to be given priority of those of companies. It's important to remember that there are a lot of freedoms in this world and they often conflict in major ways. A quote that I love is \"Your right to swing your arms ends just where the other man's nose begins\". Freedoms are extremely easy to guarantee if they're non-conflicting but that's rarely the case. In this case the EU is siding with the freedoms of the customers rather than the freedom of the corporation - whether that makes the society less or more free overall is a matter of opinion. 1. I'd point to a great example from one of our current justices in this regard: https://www.theguardian.com/law/2017/mar/23/neil-gorsuch-sup... reply jquery 8 hours agorootparentThat dissent sent him to the top of the Heritage Foundation SC shortlist for being a corporate kowtowing stooge. reply johnnyanmac 7 hours agorootparentprev>This actively reduces freedom, the freedom of running your business. You just don't care about it. In the same way Right to Repair, Minimum Wage, and Disciminatory hiring affects the freedom of running a business, sure. Unfortunately, rules are written in blood and this is happening because other businesses at this point abused the point of labor or customer satisfaction and needed to get dinged for it. In this case, Blame Microsoft, I guess. Heck, even Google. we already know the result of a closed system abusing its platform and large share to make its product worse. I'm glad we're actually jumping into this before it's too late (like we usually do). reply trinsic2 8 hours agorootparentprevCompanies don't have freedom. People do. Companies are a collection of people that have a responsibility to the people who allow them to operating by charters. In our current age, I'd say that justice in this regard isn't operating as it should, because our governments are allowing selfish individuals within companies to do illegal stuff that go against the original intent of charters. Individuals that would normally be held accountable for their actions are now being protected from being prosecuted for harms they commit while being part business. Companies are designed and allowed, by characters, to operate within the scope of whats good for society. If it harms the public good then it needs to be reigned in. I have no illusions that companies have the same standing and rights as living beings do. They are lifeless entities meant to be subject to the will of people. reply justinclift 9 hours agorootparentprev> line up their pockets with sponsors money. That's not just an EU problem though. It seems to be well established (and perhaps worse?) in many places. reply FireBeyond 8 hours agorootparentprev> If you don't like walled gardens you can just not use them (I certainly never bought anything Apple for this very reason), there's no need to infringe on the freedom of everyone else who wants to use walled gardens. No-one's forcing Apple customers to go outside the walled garden. They can still source their apps from only the Apple App Store. reply Nullabillity 10 hours agorootparentprevApple is free to switch to a less fascistic business model. reply dingle_thunk 11 hours agorootparentprevBecause of course elected officials without any expertise, representing a very small minority of humanity, are the best arbiters of reality. reply munk-a 10 hours agorootparentNon experts have to rule on expert subjects all the time - sometimes this goes hilariously wrong (like the internet being a series of tubes) but usually what happens is that the non-expert relies on the testimony of experts to make their judgement. Politicians aren't expected to be experts due to the immense breadth of subjects they need to consider - they're expected to consult experts. Whether an individual politician is an expert[1] is pretty irrelevant. All of these statements are about our general expectations of politicians - whether you think politicians adhere to that point or have comments on specific politicians is beside the scope of my comment. As a less controversial example it might be good to instead consider how judges operate who are expected to provide well reasoned judgements on subjects they know nothing about. 1. Sometimes those former expert politicians are the worst of all since they _think_ they know the way things are and won't listen to actual experts but they've been out of the industry so long that they've lost their familiarity with the subject. reply Qwertious 5 hours agorootparent>sometimes this goes hilariously wrong (like the internet being a series of tubes) That didn't go hilariously wrong, though - the internet is a series of tubes. Not physically (copper cables aren't tubes) but he obviously wasn't talking about specific stuff but broad-strokes analogy (his exact line was \"It's not a big truck. It's a series of tubes.\"), and his description was basically accurate. reply troupo 1 hour agorootparentprevUnlike trillion-dollar corporations? reply geodel 11 hours agorootparentprev> And the majority of elected officials in EU fundamentally disagrees with that statement. Well, EU can and will force, fine, or ban US companies as they see fit but there is not some fundamental correctness to their viewpoint reply ImPostingOnHN 11 hours agorootparentAny fundamental correctness of their viewpoint is by virtue of them representing more people (EU citizens) than Apple's CEO represents (himself and, I guess, the Apple corporation, if you count that). On moral issues, the fundamentally \"correct\" viewpoint (if there is one) is, by definition, the one that more people say is the fundamentally \"correct\" viewpoint. reply zappb 7 hours agorootparentChina represents twice as many people as the EU. This is not an enticing argument. Can you at least qualify this with democratic representation? reply Nullabillity 5 hours agorootparentWhich free and democratic election did Xi win? reply bryanrasmussen 2 hours agorootparentnone, which is what the comment was complaining about. reply cwyers 8 hours agorootparentprevGovernments in other countries have come to a different view, and it's for Apple to determine how worth it is for them to conform to the view come to by the representatives of the EU citizens versus catering to markets with other regulatory regimes. reply mckn1ght 9 hours agorootparentprevWhat you should be comparing is the percentage of the market the EU represents in the total market available to Apple. EU politicians are accountable to their population. Apple’s CEO is accountable to every Apple customer. The EU does not now, nor has it ever, constituted a majority of Apple revenue. reply trinsic2 8 hours agorootparentI'd argue that's not the case. CEO's are accountable to share holders, not its customers. And before you say its the same thing, there are a lot of pubically traded companies who get away with unlawful actions that direct effect its customer's for a long, long time without their bottom line being effected. reply ImPostingOnHN 9 hours agorootparentprevI don't believe the concept of a market has any fundamental place in morality, and my morality isn't limited to any particular \"market\". Indeed, who apple is or isn't able to sell to, doesn't affect what people think is moral or immoral. As for Apple's CEO representing Apple's customers: Are you sure? We didn't elect him. We just bought stuff made by an organization he currently runs. reply geodel 11 hours agorootparentprev> Users are using Apple devices because those are good products,.. For general populace good also include secure by default. \"every single trust problem to the Apple ecosystem.\" is rather technical point that very few people would even understand meaning of it. > significant number of people who consider it a compromise How significant compare to iPhone user base? reply xwolfi 5 hours agorootparentprevBut that's what the EU is willing to reform. Apple isnt a EU company, hell it may even not contribute much to the tax base, there's less reason to trust them in exchange for gatekeeping against EU companies trying to generate tax revenue on their plarform. Trusting Apple is nice in the US where it's probably a net contributor to the country's development. Elsewhere, not so. reply arghwhat 10 hours agorootparentprevWell, while the argument is entirely bogus as \"PWAs are unsafe\" implies that loading web pages in that browser itself is unsafe and thus stopping PWAs but not loading pages is pointless, you do have to have full trust in Apple for security of your device as they are the sole provider for the core platform providing most of the security primitives used. That just doesn't exclude trusting others as well. reply Terretta 10 hours agorootparent> Well, while the argument is entirely bogus as \"PWAs are unsafe\" implies that loading web pages in that browser itself is unsafe Except that's exactly what Apple is saying. Their engine -- and their brand depends on it -- offers users assurances arbitrary engines do not offer. Apple says PWAs are safe because Safari is safe, while not-Safari PWAs are not-safe. And, if not safe, Apple is at least accountable. Google's brand, for instance, does not depend on it: https://www.engadget.com/the-morning-after-google-will-settl... reply anon373839 38 minutes agorootparentIt doesn’t matter - they are going to support third party browsers anyway. They are just afraid the browsers will host PWAs better than Safari does, making them a more viable alternative to the App Store. reply addicted 9 hours agorootparentprevApple’s inability to protect its “brand” while doing what nearly every other platform owner in the world does routinely does not justify monopolistic and anti competitive behavior. reply troupo 1 hour agorootparentprevWell, that link definitely plays in Apple's favour :) reply Dalewyn 9 hours agorootparentprev>implies that loading web pages in that browser itself is unsafe Since when was loading web pages ever considered safe, at least by those who actually breathe computer? It's frankly alarming how much trust we (must) give to Arbitrary, Remotely Executed Code(tm), especially given how many attack vectors are remote code executions. reply johnnyanmac 7 hours agorootparentNever, but the world wide web is the one force of nature even Jobs couldn't fight back against. I'm sure he tried, too. So like most \"too popular\" stuff, it was given an exception that no other type of app would ever dream of. reply thimp 11 hours agorootparentprevWe don't entirely trust Apple. We just trust them more than other vendors. reply fsflover 32 minutes agorootparentThis is a false dichotomy. Completely trusting any single entity who doesn't really care about you (and only cares about extracting money from you) is riskier than trusting FLOSS, which is being constantly verified by independent actors. reply rickdeckard 11 hours agorootparentprevWho is \"we\"? reply thimp 11 hours agorootparentProbably the folk upvoting my comment. reply Retric 11 hours agorootparentprevUsing an Apple device requires trust in Apple even if you run a 3rd party operating system let alone a 3rd party application on their OS. reply EasyMark 9 hours agorootparentprevI don't trust anyone, but historically they seem on par with the big guys like Microsoft and Google. At some point you accept someone's security model or you roll your own system I guess and hope you're better than the security teams at these companies? reply zaphirplane 12 hours agorootparentprevApple’s business model excludes Clickjacking, stealing personal Information, stealing passwords, commissions from redirects, commissions from gambling sites redirects. Those in that business use browser plugins to get inside your security boundary so your argument maybe over my head or baby bath water thing reply cqqxo4zV46cp 12 hours agorootparentprevnext [4 more] [flagged] summerlight 11 hours agorootparentYour argument might be only applicable to some sort of fundamentalists. Most people in the real world make informed decision based on lots of different factors. I'm pointing out that Apple speaks like a security fundamentalist but doesn't act like such. They should choose either one of being fundamentalist or realist, not cherrypicking whatever traits that work in favor of themselves. reply Nullabillity 10 hours agorootparentprevNot everyone makes their own device choices. Or they didn't know the problems involved yet when they bought the device. Or there could be a thousand other reasons. reply Wowfunhappy 11 hours agorootparentprevI share the GP's view and I use an iPhone because I must have access to iMessage and there is no alternate way to do that. reply rchaud 10 hours agorootparentprevAndroid handles this just fine. These are the world's largest corporations we're talking about, not some mom and pop shop that will be crushed under the heel of overzealous regulation. reply natch 7 hours agorootparentAndroid \"handles it\" if you want to call shrugging it off \"handling it,\" by making different security tradeoffs that do not emphasize security as much as Apple does. reply internetter 5 hours agorootparentAndroid zero days are worth as much as iPhone ones. reply nonethewiser 10 hours agorootparentprevFirst, we should not be content to crush mom and pop shops with regulations. Second, it’s entirely dependent on the regulation whether it crushes (or even just hurts) a behemoth. reply 2OEH8eoCRo0 10 hours agorootparentprevSuddenly the user respecting innovators are all out of ideas! reply SigmundA 10 hours agorootparentprevSo Android allows alternative rendering engines besides Chrome for PWA? If you install Firefox it uses Gecko but still has native app look feel? I honestly don't know but would be surprised if they did. reply Pfhortune 9 hours agorootparent> So Android allows alternative rendering engines besides Chrome for PWA? Yes: https://developer.mozilla.org/en-US/docs/Web/Progressive_web... I tested just now in Firefox with an app from https://appsco.pe and it does indeed work! I can do the same with the Android version of Brave. > If you install Firefox it uses Gecko but still has native app look feel? That depends on your definition. Making an app _feel_ native is a matter of implementation. But the opposite is also true: A native app is free to feel non-native if the app creator makes it that way. The app does show as a distinct entry in the app switcher, but still has a Firefox icon when I tested it just now. reply prmoustache 2 hours agorootparent> I tested just now in Firefox with an app from https://appsco.pe and it does indeed work! I tested just now in firefox with an app from https://appsco.pe and it just...opened a browser tab with the website. So I understand a PWA is just a website but isn't the whole point to have a dedicated window/card for it? reply teki_one 10 hours agorootparentprevI think Android already allowed that 7+ years ago: https://hacks.mozilla.org/2017/10/progressive-web-apps-firef... reply SigmundA 9 hours agorootparentOk so I guess Android has some sort of API for allowing an app to install additional icons on the desktop with specific parameters like a shortcut and it shows the icon with a little icon representing the parent app, makes sense. So if you install a PWA from Firefox it runs in Firefox and from Chrome it runs in Chrome similar to desktops. Looking at it this way I could see Apple doing something similar with less effort than trying to standardize a web view API and have PWA use the \"system default browser\". reply Symbiote 10 hours agorootparentprevInstalling a PWA on Firefox for Android adds the icon to the homescreen with a tiny Firefox icon at the bottom. The look and feel is Android, there's no obvious bits that would look either Firefox or Chrome. https://web.dev/learn/pwa/tools-and-debug#using_physical_dev... at \"Firefox Remote Debugging\" says there's a way to debug Firefox for Android PWAs. So I'm fairly sure the PWA is running using Firefox for Android. I also never accepted the terms and conditions for Chrome on this phone. reply rchaud 8 hours agorootparentThe look and feel of the app itself is a CSS issue. There are web app frameworks that specifically offer themes matching style guides provided by Apple and Google. Framework7 is an example: the demo app on the home page is styled using iOS UI elements, and there is an option for more Android style designs as well. https://framework7.io/ reply rafram 5 hours agorootparentI wouldn’t say that demo is very convincing… reply dazilcher 10 hours agorootparentprev\"On Android, Firefox, Chrome, Edge, Opera, and Samsung Internet Browser all support installing PWAs.\" https://developer.mozilla.org/en-US/docs/Web/Progressive_web... reply anon373839 11 hours agorootparentprev> The HN crowed might not LIKE apples response but they have a very defensible position. You and Apple both are ignoring the fact that these permission APIs exist even if the website isn’t being displayed in standalone/full screen mode. The modern web is built on them, and third-party browser engines WILL provide access to these APIs in Europe. reply lukan 28 minutes agorootparentprevIf chrome is really the problem, then chrome is already the problem and nothing about PWAs can change that. And if PWAs from chrome are the problem, then it would also be possible to not allow chrome PWA's but still allow webkit PWA's. reply heisenbit 2 hours agorootparentprevIt makes absolutely no sense. Apple could have pointed out to the EU that there are major and not - in the given time - fixable security issues with allowing other browsers on the home screen. PWA runtime platform could be seen as imho. other market than general web browsers. PWA serve niche markets (and corporate in-house) and this move may hurt the long tail in the EU but also globally. reply cma 12 hours agorootparentprevBut the plain browser already can request camera permissions, in a bad security situation a site that didn't request it still receives it from the browser's system level request. This is just Apple wanting to avoid people being able to develop a platform on top of their platform without paying a tax. reply Gigachad 11 hours agorootparentBrowsers can still do that. It's more that PWAs look like entirely separate apps which the user would expect to be sandboxed. While a tab in a browser is clearly part of the browser app. reply anon373839 11 hours agorootparentThis is not a meaningful distinction. Users ALSO expect ordinary websites’ data to be sandboxed. Users trust that pornhub.com won’t be allowed to read data entered into irs.gov. reply Gigachad 7 hours agorootparentThere is also a brand rep issue. If there is a Chrome bug that leaks data, it will be seen as a Google issue. If PWAs have the same problem, it will be seen as an Apple security issue. One that they have no ability to fix. reply almostnormal 9 hours agorootparentprev> Users trust that pornhub.com won’t be allowed to read data entered into irs.gov. Likely, most are worried about the other direction. reply zitterbewegung 12 hours agorootparentprevThat’s not the point though because WebKit is already secured by Apple but if you have multiple blink related apps like Microsoft edge or brave or Firefox apple will have to audit those too and be on the hook if something breaks and then Apple will have to take the blame over a security oversight they aren’t responsible for. reply Ajedi32 11 hours agorootparentSo extending this logic to other platforms: if Chrome has a security bug on Windows... you believe people will blame Microsoft? And you think that would be valid justification for Microsoft pushing a \"security update\" that uninstalls all competing browsers and replaces them with Edge? reply graeme 11 hours agorootparentIf you made a \"Microsoft Windows Desktop Citibank App\" from Edge, and then in stall Chrome, and the Uber app now uses Chrome, and a bug in Chrome lets someone steal your Citibank info, yes, the user probably would blame Microsoft as it was Windows software which made the Desktop app for Citibank. And yes, if Windows had this feature and then Europe demanded it work like I described, Microsoft would be acting reasonably if it disabled the Desktop App feature in Europe. Apple doesn't disable competing browsers, it just doesn't allow different web engines to underly the browsers. You can argue with that but it isn't the same as \"uninstalling all competing browsers\". reply spaceribs 11 hours agorootparentprevThat assumes that Apple would be blamed for Edge/Brave/Firefox's security oversight. reply ChilledTonic 11 hours agorootparentWhy wouldn't they be? Especially considering their existing reputation in consumers minds for security and reliabilty? reply spaceribs 7 hours agorootparentBecause they own and maintain the operating system, not the vulnerable software? I understand that they've built this image of being a grand infinite protector for all their users within the walls of their garden, but they've had plenty of security issues within their own software, and plenty of cases where application developers have sidestepped their rules. This relationship of trust with Apple is cultish at best. To say that I can trust Apple but not Mozilla? What are we smoking here? reply pjerem 3 hours agorootparentprevBecause it never ever happened on any other platform including MacOS. reply etchalon 11 hours agorootparentprevThey would absolutely be blamed by users for it. reply pjerem 3 hours agorootparentLike when it happens on MacOS ? Oh wait… reply shagie 11 hours agorootparentprevIf you add a PWA (with Safari) a year ago to your Home Screen and then change your browser to Firefox, and that PWA breaks out and steals some other application data... Will you blame the software maker that you used to install the icon on the screen? or the one that is seemingly unrelated to the icon on your Home Screen? reply m-p-3 10 hours agorootparentWhy silently change the underlying browser engine of an existing PWA without the user's knowledge? That sounds like a bad UX. At least make the existing PWA stay with Safari and provide the ability to switch the underlying engine for each PWA afterwards if migrating is possible. reply shagie 8 hours agorootparentAs I understand the legislation, Apple has three choices for how to comply with the law. They can either allow third party browsers the elevated system access that Safari currently has in order to be able to access the data for multiple PWAs ... which compromises Apple's security standards, but puts Safari and other browser engines on the same footing. Or, Apple can remove the additional security permissions that Safari uses in order to access the data of multiple PWAs so that Safari and other web browsers are on the same footing again. Or, Apple can invest significant time and resources into creating a new sandbox for browser engines (including Safari) such that a PWA running in the browser engine will not be able to escape and access the elevated permissions of the browser engine or the data of other PWAs through a flaw in the browser engine. Given the amount of effort that the third option would take, the low adoption of PWAs from most users within the European market, and the not going to compromise on the first option - the second option of removing security permissions from Safari (and other browser engines) to run PWAs is the only option to comply with the law in Europe. reply pjerem 3 hours agorootparent> They can either allow third party browsers the elevated system access that Safari currently has That’s a fable. Apple have a good history in security design. There is absolutely no way Safari have some \"system access\" that another app can’t have. Safari is probably just as sandboxed by the OS than every other app or else that would be an incredibly stupid decision. If Apple wanted to implement PWAs correctly, they’d just run whatever engine + the web page in the same solid OS sandbox and there wouldn’t be any more security issue than with any App Store App. Any iOS dev knows that it’s impossible for any app to gain any useful access without being granted the permission by the OS. The point is Apple is stuck being forced to hide that the security model of iOS is based on this (working well) sandboxing because it goes against their narrative that all the security comes from App Store policies (which they technically can’t enforce because all they’ve got to review is binary code). reply seszett 11 hours agorootparentprevI would probably blame the \"the software maker\" for silently switching the engine used by previously installed PWAs. Why do that? reply rickdeckard 11 hours agorootparentprevYou think this uneducated me would know that this was a PWA and no app and also remember that it was installed by Safari, an app I apparently don't own anymore at this stage...? Why wouldn't Safari remove all its PWA icons when I uninstall it, considering that it anyway cannot transfer the data to another browser...? reply jc_dc 6 hours agorootparentprevI don’t buy it. Apple build iOS and I’m sure they will sandbox alt browsers as they do with every other 3rd party app on the phone. reply thimp 12 hours agorootparentprevAs an end user who has been fucked over by the other side (MS/Google/crappy app vendors), I am behind their decision. If I was not I can choose to leave. I know this is a divisive comment. Please see my further extrapolation in a child comment. reply circuit10 11 hours agorootparentHow does removing web apps help anything? To me it seems like part of a ploy to create backlash against this law by removing features reply thimp 11 hours agorootparentIt's a move against the third party browser engines which have been the bane of my existence from a security perspective on other platforms. For example, the about box in an Android app bundled a whole different browser engine which circumvented device policy entirely and allowed data to be exfiltrated. This app change was delivered in an update by clueless or lazy developers. This is not possible on iOS due to the platform restrictions. In this case they have to change the integration and sandbox model to allow the security policy to remain intact for people who want and need it. That breaks a few things but it stops the integration from being used for exfiltration among other things. Note that they're not completely breaking it, just ensuring that the security model stays intact when browser engines have to coexist on the same device. That means sacrificing some convenience for security. reply anon84873628 11 hours agorootparentprevI know it is not en vogue to be charitable towards tech companies, but it seems fair to assume that some teams are making a good faith effort to follow the law, and may be forced to accept imperfect design tradeoffs. Like they say, it affects a relatively small number of users, there is a sufficient workaround, and the technical fix would require major investment. Not everything is a conspiracy. reply lukan 25 minutes agoparentprev\"EU users will be able to continue accessing websites directly from their Home Screen through a bookmark with minimal impact to their functionality. \" Does this \"minimal impact to their functionality\" mean, the app will loose its local data after 7 days of not using the app, like it is for normal websites? That is a pretty heavy impact. reply sigmar 12 hours agoparentprevtbh, I thought the summary in techcrunch was much easier to read and concise. >Browsers also could install web apps on the system without a user’s awareness and consent. Couldn't this be entirely solved with an OS permission-like prompt \"are you sure you want [progressive web app name] added to home screen?\" reply madeofpalk 11 hours agorootparentI guess that's why they say that \"would require building an entirely new integration architecture that does not currently exist in iOS and was not practical to undertake given the other demands of the DMA and the very low user adoption of Home Screen web apps\" reply saiya-jin 1 hour agorootparentWell, this is just 'we don't want to do it because our market projections steer us in a different direction, but we really don't have any solid arguments so here is some blah our marketing & legal came up with'. 3 trillion company can implement this without breaking a sweat properly if they cared, what are they trying to say here - 'we are incompetent'? Not buying that for a second, we know they can deliver. reply Sabinus 1 hour agorootparentprevPersonally, I'm not concerned with the costs of an EU mandate on Apple for interoperability but that could just be me. reply natch 7 hours agorootparentprevSo, as an abusive stepparent, you run the \"Spy on Me\" PWA on your stepdaughter's phone, and click the permission dialog, and she's none the wiser. Do you think that's great? Apple does not. reply sensanaty 5 hours agorootparentIf you're an abusive step-parent with access to your daughter's phone, you can already install \"Spy on Me\" software in the form of regular apps, a PWA changes nothing here. reply rapidaneurism 4 hours agorootparentTrue, but in the regular app case apple gets its cut. reply bmicraft 6 hours agorootparentprevYou can already do that with apps reply NoPicklez 9 hours agorootparentprevSounds like the type of dialogue message I got sick of in Android reply npunt 12 hours agorootparentprevYou don't want random processes firing off permissions prompts, you want them to remain meaningful to users on a platform else they'll get prompt fatigue. Think of all the prompts users see and just press 'ok' to. reply sigmar 11 hours agorootparentHeard. But we're going to entirely eliminate all PWAs because there might be an additional prompt added? Seems excessive/specious to me. reply npunt 11 hours agorootparentIt's not one additional prompt, it's a class of prompts that could be exploited over and over again. A single site could trigger hundreds by sites popping up in the background each which trigger it, and then the user's home screen is full of fake PWAs with names like 'save money' 'in debt?' 'casino cash bucks' etc. Next you're developing mitigations, spam cleanup, etc. We've gone through this kind of thing before. reply seszett 11 hours agorootparentIf that's a real potential problem, why doesn't this already happen on Android? Why would this be exploited on the relatively small marketshare platform that is iOS, when in all those years this year not been a problem on the dominant platform? Because it's not a real problem. reply ricardobeat 10 hours agorootparentYou mean like this? https://www.tomsguide.com/news/hackers-are-using-a-new-trick... This stuff is part of the reason people commit to the Apple ecosystem despite its shortcomings. While Android dominates globally, iOS has nearly 60% market share in the US and some other countries. reply willsmith72 10 hours agorootparenti don't think that's right, i think apple dominates the US because they're genius at marketing and design. you don't have to build something more secure, you just have to convince people you did reply seszett 10 hours agorootparentprevI'm not especially aware of this particular thing, but sending an SMS with a link to a web page that asks to install a PWA seems to me like it would work on any platform that allows PWAs, irrespective of whether PWAs are restricted to one rendering engine or not, and totally unrelated to the exploit outlined in the post I was responding to (about a somewhat unclear process to me, that would open sites in the background, sending prompts to the user and somehow automatically installing many different PWAs this way). What we are talking about is specifically targeted at the EU where iOS represents about 30% of users, and doesn't apply to the US. So it's unlikely that scammers would just hold off from exploiting Android and wait for the EU to force iOS to allow different browsers, and only then exploit this class of vulnerability. reply sigmar 11 hours agorootparentprevThe user would get rid of the app/browser that is doing this, no? The same way they would have to for any malicious app that persistently requests a special permission? reply npunt 11 hours agorootparentYeah ideally. Given there are nearly 1.5 billion active iPhones tho, a lot (100s of millions) of users aren't going to understand the relationship between the prompts and the browser and/or know (/know how) to uninstall the browser and/or have desire to do it at the moment they experience the problem, especially if the browser has other qualities they like. Many more would just blame it on themselves, ignore the problem, etc. These users may make up a plurality or majority of iOS users, and have a totally different experience from a technical user working on a desktop OS (HN crowd). reply samatman 11 hours agorootparentprevI'm guessing you've never had to clean up a relative's Windows machine. I wish I could say the same. reply anakaine 11 hours agorootparentprevAre you sure we can't have additional plugin toolbars for Safari? Maybe have one or two that tell us that we can get paid to surf the Web, and a couple of others that definitely don't show popups? reply lxgr 11 hours agorootparentprev\"Yes, allow install (this time)\" / \"No, don't allow install (this time)\" / \"No, and never prompt me again\"? iOS has been doing something very similar and it's arguably worked pretty well. reply crazygringo 12 hours agoparentprevThanks for posting that. I'm no iOS expert but it actually sounds like a pretty reasonable explanation. It's at least good to hear Apple's side here, and more knowledgeable commenters here can weigh in as to whether it really does seem genuine. reply below43 6 hours agorootparentIt's a massive blow for PWAs. There are a lot of corporate apps that are PWAs as the app stores do not really support \"private\" distribution of apps (other than via MDM-based solutions which doesn't work for use cases where you don't control the users' devices). Furthermore, by forcing the apps to load in a browser tab (rather than as a full screen home screen app) it breaks the support for push notifications. In my opinion this is malicious compliance. reply alex_suzuki 2 hours agorootparentSo much this. I am the author of a barcode scanning library for JavaScript, my customers are mainly SMBs running in-house apps, and they love frigging PWAs. - No App Store review - Full control of distribution channel - Instant deployment from CI/CD - Single codebase - Easy to source developers, even in-house - No administrative burden from having to maintain accounts at Apple/Google. Adding to home screen is important for non-technical end-users to recognize it as an \"app\" and not a \"website\". reply candiodari 12 hours agorootparentprevSure it's reasonable ... because of course all these browsers don't have a security model and just allow web apps to do whatever they want. This is essentially saying no-one can build a secure browser. reply dividedbyzero 11 hours agorootparentI don't think they're saying that. I read their statement more like \"someone might build an insecure browser\", which isn't that invalid a concern I think. I'd like Apple to be a bit more daring and just open up those APIs too, but I kind of get their incentives point the other way. Apart from some landmark design decisions, Apple is an extremely conservative company, and stalling on an issue like this is just what such an org would do. reply e12e 9 hours agorootparentBut they already give the \"insecure browser\" access to display web pages, access the camera etc. They just don't want \"runs best on chrome\" pwas eating they're app store cake. reply MrDarcy 12 hours agorootparentprevNo, it’s saying they’re being forced to support at least one insecure browser which would affect the security of an obscure feature so they’re removing the feature. reply weberer 11 hours agorootparentprevI know at least Firefox has per-site permissions for location, webcam, and microphone access. Is it a correct interpretation that Safari on iOS does not have this feature? reply shuckles 11 hours agorootparentTheir argument was they want the system (iOS) to enforce those permissions, not browsers on behalf of apps they've added. reply jwells89 9 hours agorootparentIdeally there should be both browser-level and OS-level controls. Reduces the chances of things slipping through the cracks and it limits the blast radius in case a browser vendor can’t get a hole patched up quickly for some reason. reply manmal 11 hours agorootparentprevSafari has those features. reply bee_rider 11 hours agorootparentprevNobody can build a secure browser. reply shuckles 11 hours agorootparentTruer words have not been spoken! Maybe only second to nobody can build a secure baseband. reply dividedbyzero 11 hours agorootparentSecurity is well achievable, absolute security is not. Somehow almost everyone seems to grasp that intuitively, but a subset of IT keeps pretending they're the same thing. reply nozzlegear 11 hours agorootparentprevNobody but Apple has experience building a secure browser. [1] [1] On iOS. reply jensensbutton 12 hours agoparentprevSeems like an OS problem. They should fix that. reply lannisterstark 12 hours agorootparentOr they could just not. reply luuurker 12 hours agorootparentWhat's the benefit for you as a user to side with Apple on things like this? reply robertlagrant 11 hours agorootparent> What's the benefit for you as a user to side with Apple on things like this? Looking at these things as sides is a mistake. Instead of just being tribal, it's better to look positions on their merits. reply kibwen 10 hours agorootparentI've been asking these people for the merits of Apple's decisions for years, and all I ever get in response is \"Apple knows best, I don't need these features.\" reply shuckles 8 hours agorootparentThat seems like a perfectly reasonable argument on the merits. What user actually needs web apps? What's the market for apps whose developers can't stomach a $99 developer fee and/or with functionality not allowable by app review? reply pompino 56 minutes agorootparentI hope you realize the irony that this just your personal view on what is reasonable and what is or isn't a merit. I don't see the point in bullying someone who is simply expressing an opinion - which happens to be anti-Apple - and one which makes a lot of sense to me. reply breather 4 hours agorootparentprevWell shit, what user needs an app store to begin with? It was never about need, it was about what they could convince users to put up with. reply breather 4 hours agorootparentprev> it's better to look positions on their merits How do you do this when any value a \"merit\" could have is based in this dichotomy of vendor/user? reply robertlagrant 2 hours agorootparentIt's not based on that, as far as I can see. Saying \"browsers are extremely complex from a security perspective and we will only allow the one we made on to our platform\" is in service of making a better product. You might say that that's not true, and browsers are easy to secure, but that would be arguing the point on its merits. Not on the tribalist lens you're seeing this situation through. reply gretch 12 hours agorootparentprevApple has a decade+ track record of making devices that i really like. (At several points I’ve compared solutions across the market). Instead of siding with Apple, why would I side with anonymous and random internet commentators who have never made devices I want to buy? reply pompino 54 minutes agorootparentIt is definitely odd to outsource your moral principles based on which mega corp you opened your wallet to. reply elbear 3 hours agorootparentprevThe fact that Apple controls the entire stack means that they can provide better guarantees for security and experience and also make optimisations that are difficult or impossible when integrating 3rd party software. reply moogly 12 hours agorootparentprevA seat at Steve Jobs' table in the lunch cafeteria in he...aven? reply asadotzler 5 hours agorootparentprevboots taste good and these kids are too young to recall why any of this matters. reply nonethewiser 7 hours agorootparentprevThere are lots of things that Apple could do to benefit me that aren’t reasonable. reply shuckles 11 hours agorootparentprevThe sides in this debate are: Apple, Chrome advocates (with a little bit of separation), and the EU. It's not that perplexing to choose the first. reply breather 4 hours agorootparentprevThere's little benefit to the user for many of Apple's design decisions; that seems like an odd way to predict their behavior. reply natch 7 hours agorootparentprevAdvocating for security and user privacy protection. reply vdaea 12 hours agorootparentprevHe's not necessarily siding with Apple. He's pointing out they don't have to do that. reply pb7 11 hours agorootparentprevPretty simple: I like the way Apple does most things. I'm rarely disappointed by the culmination of all of their decisions. I'm frequently disappointed with how other companies do things therefore I don't want their disease to spread to things I'm perfectly content with. reply adamtaylor_13 6 hours agorootparentI couldn’t put my feelings into words but this sums it up fairly well. Apple, for all their flaws, typically creates an outstanding product from a security, privacy, and general end-user perspective. At the end of the day, Apple has earned my trust to make choices that maybe aren’t the most “open” choices, because usually they end up being the best experience for me as an end consumer. reply cqqxo4zV46cp 12 hours agorootparentprevPlease drop the tribalistic vitriol and be an adult about this. The statement is “or they could not”. It’s factual. It’s what Apple did. It’s not a religious stance. reply masto 11 hours agorootparentThe question was \"What's the benefit for you as a user to side with Apple on things like this?\". There's no vitriol there. Jumping to the defense of a trillion dollar corporation seems religious or at least tribalistic to me. And lest I be dismissed as a hater, I currently own five Apple computers, an iPhone I've upgraded every year since they came out, an iPad, a watch, and a virtu^wspatial computing heads^wdevice. But that's because of the transactional value they provide, not because I believe Apple loves me and has my best interests at heart. They love my money and that's where it ends. I use several PWAs and I will be very disappointed if this is the stick Apple uses to close the window on this short period of time where we had a reasonably interoperable standard for making \"apps\" using web technologies. I can run Elk in a browser, but it's suboptimal. reply vundercind 9 hours agorootparentprevI don't care about PWAs and would generally prefer companies not have the option so they can't try to push me into one. Anything that makes that less-viable is good for me. I wish Apple'd held a hard line on the \"no apps that should be a web site\" rule(s) for similar reasons. Alas, they did not. reply jquery 8 hours agorootparentI agree. My experience with PWAs is they are usually downgrade from a safari bookmark... they are created to benefit the provider, not the user, by taking away browser abilities from me (back, forward, copy url, etc). reply agust 12 hours agorootparentprevThey could develop APIs to support alternate browser engines but could not allow them to install sandboxed web apps on the system? Like all other OSes do, including macOS? How surprising. reply bobbylarrybobby 11 hours agorootparentThe whole point is that doing so would privilege safari over other browsers, which is illegal. reply kmbfjr 12 hours agorootparentprevAre not some of the changes in the EU so that people won’t have to rely on Apple’s APIs? reply mixmastamyk 10 hours agorootparentprevSpend money to lose money, not a great investment in their eyes. reply TheGlav 12 hours agorootparentprevOf course they could. They looked at the cost of rewriting the entire integration and framework for running PWAs and said, \"eh, nah.\" reply jeroenhd 11 hours agorootparentThey'll have to allow some kind of app installation API to allow for alternative app stores. If Google implements some kind of WebAPK technology on iOS, they may just be able to launch a Google Play for iOS to work around these PWAs as a workaround, and Safari will be down a feature. I have the feeling Apple is betting on Google not caring enough about the PWA platform to try to compete. Maybe they're right, but if they're not, they're only making the browser wars worse for themselves. reply jdminhbg 10 hours agorootparent> I have the feeling Apple is betting on Google not caring enough about the PWA platform to try to compete. I don't think it's about Google, I think they assume consumers won't care, and they're probably right. reply shuckles 8 hours agorootparentprevMy guess is it's easier for developers to throw their website into Cordova than to start paying Apple a Core Technology Fee and convince users to download an alternative app marketplace to support what is effectively a differently packaged Cordova app. reply WWLink 10 hours agoparentprevApple's argument was the iOS was a robustly secure platform AND the app store made it even more secure. The reality of the situation looks more like the app store was a bandaid over a maybe-not-as-robustly-secure-as-we-hoped platform. reply breather 4 hours agoparentprevThis would be a lot easier to believe if they allowed you to stop apps from accessing the internet. As they don't, I simply don't buy any argument they make from a privacy or security perspective. reply Roark66 3 hours agoparentprev>low usage This is hilarious. As a developer, if PWAs work properly I'm much more interested in writing them, test them on ios and market them to ios users. If the feature is uncertain, or outright broken like now of course no sane, businesses sense driven dev will spend the time to build a PWA app specifically for iOS. reply rahkiin 2 hours agorootparentI have never used PWAs, so could you elaborate what you mean with ‘work properly’? What happens now that is not ideal? reply glenjamin 11 hours agoparentprevAm I missing something? Couldn’t they allow you open PWAs in Safari, or fall back to opening a URL in another browser? Is there some part of the DMA which demands full feature parity? reply graeme 10 hours agorootparent>Is there some part of the DMA which demands full feature parity? Very likely the EU wouldn't like them prioritizing their own browser for a feature reply oddevan 9 hours agoparentprevFeels like the same kind of malicious compliance with the rest of their DMA changes: 1. WebKit has access to special OS-level APIs that allow it to install and power web apps. 2. The DMA requires support for alternative browser engines with the same abilities as WebKit. 3. It is reasonable to assume this requirement extends to PWAs. 4. By taking away WebKit's ability to power PWAs, all browser engines are now on a level playing field. _Could_ they have done it differently? Maybe, maybe not: software development always takes longer than you think, and throwing more engineers at a problem doesn't always make it go faster. Do I think they saw another chance to be petulant and took it? Yes. So yeah, I'm disappointed, but no more here than with the rest of Apple's DMA response. reply kelnos 1 hour agoparentprevMy hat's off to Apple PR on this one: they came up with some spin for why they were adding a malicious component to how they are complying with the DMA. They're likely not lying when they say that it's more difficult to maintain their security standards while at the same time allowing any browser engine to run PWAs. But this is a problem they absolutely could solve, and a company with Apple's size and skill absolutely has the resources to make this work. But they've chosen not to. Another option would be to actually engage with EU regulators on the issue, and see if they could carve out an exception -- temporary or otherwise -- to allow them to require PWAs to run under their existing WebKit-based framework, regardless of the default browser. But they've again chosen not to do that. PWA adoption is likely as low as Apple claims. I think they're toeing a line here: because Home Screen Apps are a bit of a niche feature, they can break it without pissing off too many users, but also give a subtle middle finger to the EU. \"Poor Apple users, Apple just has to disable a feature some people like because of the evil, overreaching EU and its burdensome DMA!\" This is a shame in that I personally think we all should be relying less on mostly-closed-source, proprietary apps for everything. While the web platform is a bit of a mess, it actu",
    "originSummary": [
      "Apple has admitted to deliberately disabling progressive web apps (PWAs) on iPhones in the EU, citing compliance with the new Digital Markets Act regulation as the reason.",
      "The complexity of the regulation's requirement to allow multiple browser engines led to the elimination of PWA functionality on iOS 17.4 beta, downgrading PWAs to mere website shortcuts.",
      "This move has caused significant problems for users, including data loss and non-functioning notifications, making it impractical for Apple to continue supporting PWAs in the EU."
    ],
    "commentSummary": [
      "Apple has admitted to intentionally breaking iPhone web apps in the EU to meet regulatory requirements and address security concerns.",
      "Critics believe this move demonstrates Apple's lack of support for Progressive Web Apps (PWAs) as an alternative to the App Store.",
      "The discussion revolves around various topics including frustration over USB-C cables, comparisons between PWAs and native apps, trust in Apple's security measures, and debates about regulations and Apple's App Store policies."
    ],
    "points": 667,
    "commentCount": 558,
    "retryCount": 0,
    "time": 1708028529
  },
  {
    "id": 39387641,
    "title": "Astral Releases uv: A Fast and Comprehensive Python Project and Package Manager",
    "originLink": "https://astral.sh/blog/uv",
    "originBody": "TL;DR: uv is an extremely fast Python package installer and resolver, written in Rust, and designed as a drop-in replacement for pip and pip-tools workflows. uv represents a milestone in our pursuit of a \"Cargo for Python\": a comprehensive Python project and package manager that's fast, reliable, and easy to use. As part of this release, we're also taking stewardship of Rye, an experimental Python packaging tool from Armin Ronacher. We'll maintain Rye as we expand uv into a unified successor project, to fulfill our shared vision for Python packaging. At Astral, we build high-performance developer tools for the Python ecosystem. We're best known for Ruff, an extremely fast Python linter and formatter. Today, we're releasing the next tool in the Astral toolchain: uv, an extremely fast Python package resolver and installer, written in Rust. 0s 1s 2s 3s uv poetry pip-compile pdm 0.60s 1.56s 3.37s 0.01s 0s 2s 4s uv poetry pdm pip-sync 0.99s 1.90s 4.63s 0.06s 0s 1s 2s 3s uv poetry pip-compile pdm 0.60s 1.56s 3.37s 0.01s 0s 2s 4s uv poetry pdm pip-sync 0.99s 1.90s 4.63s 0.06s Resolving (left) and installing (right) the Trio dependencies with a warm cache, to simulate recreating a virtual environment or adding a dependency to an existing project (source). Resolving (top) and installing (bottom) the Trio dependencies with a warm cache, to simulate recreating a virtual environment or adding a dependency to an existing project (source). uv is designed as a drop-in replacement for pip and pip-tools, and is ready for production use today in projects built around those workflows. Like Ruff, uv's implementation was grounded in our core product principles: An obsessive focus on performance. In the above benchmarks, uv is 8-10x faster than pip and pip-tools without caching, and 80-115x faster when running with a warm cache (e.g., recreating a virtual environment or updating a dependency). uv uses a global module cache to avoid re-downloading and re-building dependencies, and leverages Copy-on-Write and hardlinks on supported filesystems to minimize disk space usage. Optimized for adoption. While we have big aspirations for the future of Python packaging, uv's initial release is centered on supporting the pip and pip-tools APIs behind our uv pip interface, making it usable by existing projects with zero configuration. Similarly, uv can be used as \"just\" a resolver (uv pip compile to lock your dependencies), \"just\" a virtual environment creator (uv venv), \"just\" a package installer (uv pip sync), and so on. It's both unified and modular. A simplified toolchain. uv ships as a single static binary capable of replacing pip, pip-tools, and virtualenv. uv has no direct Python dependency, so you can install it separately from Python itself, avoiding the need to manage pip installations across multiple Python versions (e.g., pip vs. pip3 vs. pip3.7). While uv will evolve into a complete Python project and package manager (a \"Cargo for Python\"), the narrower pip-tools scope allows us to solve the low-level problems involved in building such a tool (like package installation) while shipping something immediately useful with minimal barrier to adoption. You can install uv today via our standalone installers, or from PyPI. curl irm pip pipx $ curl -LsSf https://astral.sh/uv/install.shsh uv supports everything you'd expect from a modern Python packaging tool: editable installs, Git dependencies, URL dependencies, local dependencies, constraint files, source distributions, custom indexes, and more, all designed around drop-in compatibility with your existing tools. uv supports Linux, Windows, and macOS, and has been tested at-scale against the public PyPI index. A drop-in compatible API # This initial release centers on what we refer to as uv's pip API. It'll be familiar to those that have used pip and pip-tools in the past: Instead of pip install, run uv pip install to install Python dependencies from the command line, a requirements file, or a pyproject.toml. Instead of pip-compile, run uv pip compile to generate a locked requirements.txt. Instead of pip-sync, run uv pip sync to sync a virtual environment with a locked requirements.txt. By scoping these \"lower-level\" commands under uv pip, we retain space in the CLI for the more \"opinionated\" project management API we intend to ship in the future, which will look more like Rye, or Cargo, or Poetry. (Imagine uv run, uv build, and so on.) uv can also be used as a virtual environment manager via uv venv. It's about 80x faster than python -m venv and 7x faster than virtualenv, with no dependency on Python. uv virtualenv venv uv virtualenv venv 0s 0.02s 0.04s 0.06s 0.08s 74.4ms 24.1ms 4.1ms 0s 0.5s 1s 1.5s 141.4ms 1.54s 18.2ms 0s 0.5s 1s 1.5s uv virtualenv venv 141.4ms 1.54s 18.2ms 0s 0.02s 0.04s 0.06s 0.08s uv virtualenv venv 74.4ms 24.1ms 4.1ms Creating a virtual environment, with (top) and without (bottom) seed packages like pip and setuptools (source). Creating a virtual environment, with (left) and without (right) seed packages like pip and setuptools (source). uv's virtual environments are standards-compliant and work interchangeably with other tools — there's no lock-in or customization. Building our own package management stack from scratch also opened up room for new capabilities. For example: uv supports alternate resolution strategies. By default, uv follows the standard Python dependency resolution strategy of preferring the latest compatible version of each package. But by passing --resolution=lowest, library authors can test their packages against the lowest-compatible version of their dependencies. (This is similar to Go's Minimal version selection.) uv allows for resolutions against arbitrary target Python versions. While pip and pip-tools always resolve against the currently-installed Python version (generating, e.g., a Python 3.12-compatible resolution when running under Python 3.12), uv accepts a --python-version parameter, enabling you to generate, e.g., Python 3.7-compatible resolutions even when running under newer versions. uv allows for dependency “overrides”. uv takes pip's “constraints” concepts a step further via overrides (-o overrides.txt), which allow the user to guide the resolver by overriding the declared dependencies of a package. Overrides give the user an escape hatch for working around erroneous upper bounds and other incorrectly-declared dependencies. In its current form, uv won't be the right fit for all projects. pip is a mature and stable tool, with extensive support for an extremely wide range of use cases and a focus on compatibility. While uv supports a large fraction of the pip interface, it lacks support for some of its legacy features, like .egg distributions. Similarly, uv does not yet generate a platform-agnostic lockfile. This matches pip-tools, but differs from Poetry and PDM, making uv a better fit for projects built around the pip and pip-tools workflows. For those deep in the packaging ecosystem, uv also includes standards-compliant Rust implementations of PEP 440 (version identifiers), PEP 508 (dependency specifiers), PEP 517 (a build-system independent build frontend), PEP 405 (virtual environments), and more. A \"Cargo for Python\": uv and Rye # uv represents an intermediary milestone in our pursuit of a \"Cargo for Python\": a unified Python package and project manager that is extremely fast, reliable, and easy to use. Think: a single binary that bootstraps your Python installation and gives you everything you need to be productive with Python, bundling not only pip, pip-tools, and virtualenv, but also pipx, tox, poetry, pyenv, ruff, and more. Python tooling can be a low-confidence experience: it's a significant amount of work to stand up a new or existing project, and commands fail in confusing ways. In contrast, when working in the Rust ecosystem, you trust the tools to succeed. The Astral toolchain is about bringing Python from a low-confidence to a high-confidence experience. This vision for Python packaging is not far off from that put forward by Rye, an experimental project and package management tool from Armin Ronacher. In talking with Armin, it was clear that our visions were closely aligned, but that fulfilling them would require a significant investment in foundational tooling. For example: building such a tool requires an extremely fast, end-to-end integrated, cross-platform resolver and installer. In uv, we've built that foundational tooling. We saw this as a rare opportunity to team up, and to avoid fragmenting the Python ecosystem. As such, in collaboration with Armin, we're excited to be taking over Rye. Our goal is to evolve uv into a production-ready \"Cargo for Python\", and to provide a smooth migration path from Rye to uv when the time is right. Until then, we'll be maintaining Rye, migrating it to use uv under-the-hood, and, more generally, treating it as an experimental testbed for the end-user experience we're building towards. While merging projects comes with its own challenges, we're committed to building a single, unified tool under the Astral banner, and to supporting existing Rye users as we evolve uv into a suitable and comprehensive successor project. Our Roadmap # Following this release, our first priority is to support users as they consider uv, with a focus on improving compatibility, performance, and stability across platforms. From there, we'll look towards expanding uv into a complete Python project and package manager: a single binary that gives you everything you need to be productive with Python. We have an ambitious roadmap for uv. But even in its current form, I think it will feel like a very different experience for Python. I hope you'll give it a try. Acknowledgements # Finally, we'd like to thank all those that contributed directly or indirectly to the development of uv. Foremost among them are Jacob Finkelman and Matthieu Pizenberg, the maintainers of pubgrub-rs. uv uses PubGrub as its underlying version solver, and we're grateful to Jacob and Matthieu for the work they put into PubGrub in the past, and for the way they've engaged with us as collaborators throughout the project. We'd also like to thank those projects in the packaging space that've inspired us, especially Cargo, along with Bun, Orogene, and pnpm from the JavaScript ecosystem, and Posy, Monotrail, and Rye from the Python ecosystem. In particular, thanks to Armin Ronacher for collaborating with us on this effort. Finally, we'd like to thank the maintainers of pip and the members of the PyPA more broadly for all the work they do to make Python packaging possible.",
    "commentLink": "https://news.ycombinator.com/item?id=39387641",
    "commentBody": "Uv: Python packaging in Rust (astral.sh)539 points by samwho 14 hours agohidepastfavorite174 comments hprotagonist 11 hours agoA VC-backed pip-and-more doesn't make sense to me. It's 2024: what's the revenue model when the free money printer's on the fritz? reply dj_gitmo 11 hours agoparentThat was one of my first questions, but Anaconda exists https://www.anaconda.com/download/ Python is used by loads of scientists, academics, and other non software engineers. Those people need an easy way to use python. reply nateglims 11 hours agorootparentI knew they sold something, but I am amazed to learn they have 300 employees. reply BiteCode_dev 11 hours agorootparentAnaconda is very big in corporate envs. If you want to have a platform that allow to manage Python on all machines, including allowed packages and version, integrated with ldap, with auditing capabilities, they are pretty much the only game in town. And big companies want that. reply throwaway2037 6 hours agorootparentI agree. Real question: Why didn't ActiveState (ActivePython) win this battle? In my corporate experience, they are invisible. reply BiteCode_dev 3 hours agorootparentBecause Continum had a loss leader with anaconda that, in 2010, was solving a ton of packaging problems. Today I would say anaconda brings more problems than it solves (https://www.bitecode.dev/p/why-not-tell-people-to-simply-use), but at the time, we didn't have wheels for everything, and it was a life saver for anybody that wanted to use c extensions. So anaconda became first popular because it solved a real end user problem, then it moved on to be the corporation providers because it already was well known. It was a very good strategy. reply pjmlp 3 hours agorootparentprevThey were quite big in the 2000, on my bubble they faded away as .NET and Java with their IDEs came into the picture, alongside Tcl, Perl and Python improving their Windows support story. They were never big outside Windows shops. reply lacker 8 hours agoparentprevSell build-related services to companies. Imagine GitHub Actions, but it's cleanly built into your Python tooling in some reasonable way, so it's just the natural thing to use. I think it's pretty straightforward, although we'll see whether it works out for them. reply pininja 11 hours agoparentprevNPM comes to mind. I’m imagining private package management and team support https://www.npmjs.com/products reply plorkyeran 6 hours agorootparentnpm, Inc. was an unsuccessful business that got acquired for a pittance because MS can afford to throw away a few million dollars in case it turns out that having control over npm is useful. The team working on it isn't very large but I'd still be surprised if it's actually operating at a profit. reply jitl 7 hours agorootparentprevNPM did not go well, and selling to Microsoft happened after the team there fell apart. In my view some of that is leadership issues, and some of that is pressure from a struggling business. reply Kwpolska 11 hours agorootparentprevNPM’s got Microsoft/GitHub behind it. I doubt those features bring in any serious money, given the abundance of free alternatives. reply LtWorf 11 hours agoparentprevI'm curious to see what the pydantic start up will do. reply epage 13 hours agoprevCongrats! > Similarly, uv does not yet generate a platform-agnostic lockfile. This matches pip-tools, but differs from Poetry and PDM, making uv a better fit for projects built around the pip and pip-tools workflows. Do you expect to make the higher level workflow independent of requirements.txt / support a platform-agnostic lockfile? Being attached to Rye makes me think \"no\". Without being platform agnostic, to me this is dead-on-arrival and unable to meet the \"Cargo for Python\" aim. > uv supports alternate resolution strategies. By default, uv follows the standard Python dependency resolution strategy of preferring the latest compatible version of each package. But by passing --resolution=lowest, library authors can test their packages against the lowest-compatible version of their dependencies. (This is similar to Go's Minimal version selection.) > uv allows for resolutions against arbitrary target Python versions. While pip and pip-tools always resolve against the currently-installed Python version (generating, e.g., a Python 3.12-compatible resolution when running under Python 3.12), uv accepts a --python-version parameter, enabling you to generate, e.g., Python 3.7-compatible resolutions even when running under newer versions. This is great to see though! I can understand it being a flag on these lower level, directly invoked dependency resolution operations. While you aren't onto the higher level operations yet, I think it'd be useful to see if there is any cross-ecosystem learning we can do for my MSRV RFC: https://github.com/rust-lang/rfcs/pull/3537 How are you handling pre-releases in you resolution? Unsure how much of that is specified in PEPs. Its something that Cargo is weak in today but we're slowly improving. reply charliermarsh 12 hours agoparentThanks Ed! Your work as always is a big source of inspiration. > Do you expect to make the higher level workflow independent of requirements.txt / support a platform-agnostic lockfile? Being attached to Rye makes me think \"no\". Yes, we absolutely do. We don't do this today, the initial scope is intentionally limited. But in the next phase of the project, we want to extend to multi-platform and multi-version resolution. > How are you handling pre-releases in you resolution? Unsure how much of that is specified in PEPs. Its something that Cargo is weak in today but we're slowly improving. This is something we talked with Jacob about quite a bit. Turns out (as you know) it's a very hard problem. For the initial release, we added a constraint: our default behavior is that if you want to use a pre-release, you _have_ to specify the package as a first-party dependency and use a pre-release marker in the version specifier. (We also support globally enabling and disabling pre-releases.) So, we basically don't support \"transitive\" pre-releases right now -- but we give you a dedicated error message if your resolution fails for that reason. reply thaliaarchi 9 hours agorootparentAny plans to tackle the Python version installation side of things and make it as seamless as rustup has? I've previously used `pyenv install` for this, but it would be nice to fold it into one tool. reply charliermarsh 7 hours agorootparentYeah, this is very much on our roadmap and probably one of the first things we'll tackle next. reply woodruffw 12 hours agoparentprev> How are you handling pre-releases in you resolution? Unsure how much of that is specified in PEPs. The living version of PEP 440 has a bit on how pre-releases are handled[1]. The basic version is that the installer shouldn't select them at all, unless the user explicitly indicates that they want a pre-release. Once opted into, they're ordered by their phase (alpha, beta, rc) and pre-release increment (e.g. `.beta.1 > `.alpha.2`). [1]: https://packaging.python.org/en/latest/specifications/versio... reply techwizrd 12 hours agoparentprevPyTorch doesn't work well with platform-agnostic lockfiles. It's a constant source of issues for me when using Poetry. reply jvolkman 10 hours agorootparentThe vast majority of pypi packages are not PyTorch, however. reply OJFord 12 hours agoparentprevThat is great. Fuzzing would be cool too - just completely randomise the versions within the claimed compatibility constraints. reply endgame 11 hours agoprevHow does a language ecosystem that bakes \"there should be one-- and preferably only one --obvious way to do it\" into the interpreter* as a statement of values end up with such a convoluted packaging story? * Try running `python -c 'import this'sed -n 15p` reply yen223 10 hours agoparentBecause packaging is a very complex problem, and it's rare that any one packaging solution can get everything right in the first try. You will notice that every package management solution from all your favourite languages will have its own set of tradeoffs. reply lolinder 8 hours agorootparentPackaging is hard but it's not hard enough to wholly explain pip. Lock files alone are a proven piece of technology that pretty much just works across all modern package managers, and yet the best that pip can recommend to date is `pip freeze > requirements.txt`, which is strictly inferior than what is available in other package managers because there's no hash verification and no distinction between transitive dependencies and explicit dependencies. That pip still doesn't have an answer for lock files is a sign of a deep problem in the Python package management world, not the natural result of packaging being hard. reply Too 3 hours agorootparentpip has had constraints.txt forever, it is equivalent to lock file. Your are not supposed to freeze into requirements.txt. Hopefully uv can make this the default behavior. It seems like the majority of users are not aware of its existence because it’s an optional flag. reply lloeki 2 hours agorootparent> Your are not supposed to freeze into requirements.txt ironic that pip freeze literally generates a requirements.txt with == constraints.txt certainly did not exist back when I was doing python. Conversely Ruby packaging has been a solved problem for a decade, when the python community has been extremely resistant to conceptually similar solutions for the longest time on strange ideological grounds, and came around only recently. reply lolinder 2 hours agorootparentprevSomehow I've managed to go all this time without ever having heard of this feature. If this is the blessed path, can you explain why the pip docs recommend freezing to requirements.txt [0]? And why does the documentation for Constraints Files in the next section talk about them as though they're for something completely different? Here's what they say about requirements: > Requirements files are used to hold the result from pip freeze for the purpose of achieving Repeatable Installs. In this case, your requirement file contains a pinned version of everything that was installed when pip freeze was run. Here's what they say about constraints: > Constraints files are requirements files that only control which version of a requirement is installed, not whether it is installed or not. ... In terms of semantics, there is one key difference: Including a package in a constraints file does not trigger installation of the package. > ... Write a single constraints file for your organisation and use that everywhere. If the thing being installed requires “helloworld” to be installed, your fixed version specified in your constraints file will be used. > Constraints file support was added in pip 7.1. In Changes to the pip dependency resolver in 20.3 (2020) we did a fairly comprehensive overhaul, removing several undocumented and unsupported quirks from the previous implementation, and stripped constraints files down to being purely a way to specify global (version) limits for packages. This sounds like something vaguely similar to a lock file, but they seem to intend it to be used globally at the organization level, and they're certainly not pushing it as the answer to locking dependencies for a specific project (they specifically recommend requirements for that). Maybe you can use it that way—although this Stack Overflow answer says that the 2020 update broke it for this use case [1]—but even so it doesn't answer the fundamental need for lock files unless everyone is actually on board with using it for that, and even the pip maintainers don't seem to think you should. [0] https://pip.pypa.io/en/latest/user_guide/#requirements-files [1] https://stackoverflow.com/questions/34645821/pip-constraints... reply larme 6 hours agorootparentprevLockfile does not work perfectly for me because it does not lock python version. Using a lock file with different python version or even same version but different OS may fail. reply lolinder 5 hours agorootparentThere's no reason why Python version couldn't be baked into the lock file or package manifest if pip had one. package.json does this [0]. Since all pip has is requirements.txt, it's a bit of a moot point. [0] https://docs.npmjs.com/cli/v10/configuring-npm/package-json#... reply zadokshi 5 hours agorootparentprevThat’s literally his point. Other languages have solved this. It makes no sense that it’s not solved in python. (If your not sure how look at a golang go.mod file or a rust Cargo.toml file.) reply __MatrixMan__ 5 hours agorootparentprevSounds like you want a nix flake. reply lucideer 10 hours agorootparentprevThis is absolutely true, but I haven't seen any language ecosystems that have gotten things wrong as often as Python. And quite a few where the tradeoffs are minor enough to be well worth some sanity & consistency. reply yen223 1 hour agorootparentYou haven't used Swift before I see reply rtpg 8 hours agorootparentprevC++. I think Java is pretty close in nastiness but I haven't used it in a while. reply mixmastamyk 10 hours agorootparentprevIt's because no-one is in charge anymore, and Guido never cared about packaging anyway. reply linsomniac 9 hours agorootparentIf you think Guido never cared about packaging, try calling it \"The Cheese Shop\" in distance of his hearing. :-) reply mixmastamyk 3 hours agorootparentWasn’t any better back then. Not much of a cheese shop, is it? reply stared 10 hours agoparentprevWell, there are languages better at incorporating the Zen of Python than Python itself, vide (full disclosure: my blog post) https://p.migdal.pl/blog/2020/03/types-test-typescript/. When it comes to package managers, as you noted, the situation is even more ironic, as nicely depicted in https://xkcd.com/1987/. reply mixmastamyk 10 hours agorootparentOne way to do things becomes impossible to after thirty years unless one wants to make large, breaking changes. After Python 3: >>> from __future__ import braces File \"\", line 1 SyntaxError: not a chance reply endgame 9 hours agorootparentThat's been around since at least Python 2.6, and I think I remember seeing it before then: $ LC_ALL=C NIX_PATH=nixpkgs=https://github.com/NixOS/nixpkgs/archive/release-13.10.tar.gz nix-shell -p python26 --run 'python -c \"from __future__ import braces\"' File \"\", line 1 SyntaxError: not a chance reply mixmastamyk 3 hours agorootparent“After Python 3” doesn’t mean it arrived then. It was supposed to be read, “after Python three … not a chance.” reply lijok 10 hours agorootparentprevHaha, didn't know about this easter egg, amazing reply surfingdino 10 hours agorootparentprevWhat's your view on how Golang deals with this problem? Serious question. reply zadokshi 5 hours agorootparentGolang users don’t sit around arguing about package managers, nor do they have trouble with trying to make sure they have the right version of go installed. Early versions of go didn’t solve things well, but go has had this fixed for a long time now. Any arguments about packaging issues are likely related to older out of date problems people had. The only real problem people have these days is around private non open source packages. You can do it, but you need to learn how to set environment variables. reply nindalf 12 hours agoprevFeel like I called this 11 days ago - https://news.ycombinator.com/item?id=39251014 > I had to guess, that’s the path that the Astral team would take as well - expand ruff’s capabilities so it can do everything a Python developer needs. So the vision that Armin is describing here might be achieved by ruff eventually. They’d have an advantage that they’re not a single person maintenance team, but the disadvantage of needing to show a return to their investors. reply davidthewatson 1 hour agoprevI've complained about the resemblance to the Ruby community's packaging conflict a decade ago almost two years ago now. I may have been in the minority, but was apparently not alone: https://news.ycombinator.com/item?id=32116649 Python packaging has gotten asymptotically worse in the last 90 days from my experience having used the language for 20 years now and working on a multi-platform triumvirate of Lin-Mac-Win that has not changed in twenty years. I can honestly say that, given how daily failures in the packaging ecosystem such as pip failing to build egg, pkg-config, and similar problems, I'm happy to see a solution from rust, because I sent an intern into the polars underworld 2 years ago to great success and have only grown my own reliance on rust infrastructure more broadly since. This may very well be the only packaging innovation in python that I actually look forward to trying tomorrow. I'd already be working in rust full-time if I could only get past the syntax that reminds me too much of perl after bathing in the semantic whitespace light for this long. reply ddanieltan 7 hours agoprevAny plans to adopt Rye's approach of using standard Python builds to cover the installing of different Python versions? I feel uv should provide a way to install different python versions to truly cover an end-to-end tool. The current approach of searching for existing virtualenvs of conda envs helps but I was hoping to completely remove the need for another package/dependency manager. (Taken from the docs) If a --python-version is provided to pip compile (e.g., --python-version=3.7), uv will search for a Python interpreter matching that version in the following order: - An activated virtual environment based on the VIRTUAL_ENV environment variable. - An activated Conda environment based on the CONDA_PREFIX environment variable. - A virtual environment at .venv in the current directory, or in the nearest parent directory. - The Python interpreter available as, e.g., python3.7 on macOS and Linux. On Windows, uv will use the same mechanism as py --list-paths to discover all available Python interpreters, and will select the first interpreter matching the requested version. - The Python interpreter available as python3 on macOS and Linux, or python.exe on Windows. reply eigenvalue 13 hours agoprevLooks awesome. I find that pip is usually pretty fast for me, and when it's not, it is mostly because it has to download so much data or wait for native libraries to compile in the background (or anything involving cuda which always seems to take forever). What really needs some help with speed is conda, which is just so absurdly slow for literally anything, even on ridiculously powerful machines. reply rogue7 13 hours agoparentFor conda there is mamba [0], a drop-in replacement that's really fast. By the way, the creator of mamba started his own company at https://prefix.dev/ They want to essentially leverage the conda(-forge) infrastructure to build a new cross-platform, cross-language, cargo-like package manager: pixi [0] https://github.com/mamba-org/mamba reply maxnoe 12 hours agorootparentSince last year, conda itself is actually using the mamba solver: https://conda.org/blog/2023-11-06-conda-23-10-0-release/ reply daniel_grady 12 hours agoparentprevWhat are some of the reasons that teams use conda (and related tools) today? As a machine learning scientist, I used conda exclusively in the mid-2010s because it was the only framework that could reliably manage Python libraries like NumPy, PyTorch, and so on, that have complex binary dependencies. Today, though, pip install works fine for those packages. What am I missing? reply blactuary 8 hours agorootparentFor me personally, I prefer conda because it is dependency resolution (mamba), virtual environments, and a package repository (conda-forge) all from one base miniconda installation. And for all of my use cases, all of those just work. Dependency solving used to be painfully slow, mamba solved that. Packages used to be way behind the latest, setting conda-forge as my default solved that. After fiddling with different solutions for years and having to start fresh with a new Python install, I've been using nothing by miniconda for years and it just works reply tehnub 5 hours agorootparentprevOne reason to choose one over the other is the dependencies they’re bundled with. Take numpy. With PyPI, it’s bundled with OpenBLAS, and with conda, it’s bundled with Intel MKL, which can be faster. See https://numpy.org/install/# reply daniel_grady 2 hours agorootparentThat’s a great point; I didn’t know about that! reply Ringz 11 hours agorootparentprevUnfortunately, far too often: tradition. Using only „Pythons native tools“ like pip and venv simply works nowadays so good that I wonder about the purpose of many tools like poetry etc. etc. reply RockRobotRock 10 hours agorootparentHas anyone else been paying attention to how hilariously hard it is to package PyTorch in poetry? https://github.com/python-poetry/poetry/issues/6409 reply gcarvalho 8 hours agorootparentprevFor me it's the easiest and fastest cross-platform way to consistently install a Python version. pip and venv work fine, but you have to get them first; and that can be a struggle for unseasoned python devs, especially if you need a version that's not what your distro ships, and even more so on Windows and macOS. I use micromamba [1] specifically, which is a single binary. [1] https://mamba.readthedocs.io/en/latest/user_guide/micromamba... reply pininja 11 hours agorootparentprevAnother reason I used to use conda was for easy native Windows installation. GPU accelerated packages like OpenCV were especially difficult when I used use it 6 years ago. Now there’s Linux subsystem.. has pip support dramatically improved on Windows? reply nateglims 11 hours agorootparentprevThe biggest advantage for poetry I found, working with a lot of non-traditional software people, is that it does a lot of things by default like pin versions and manage virtual envs. Unfortunately, it does complicate some things. reply Ringz 11 hours agorootparentI can understand that well. A few articles from ByteCode! helped me to \"follow my intuition\" and do as much as possible with native Python tools. https://www.bitecode.dev/p/back-to-basics-with-pip-and-venv https://www.bitecode.dev/p/relieving-your-python-packaging-p... reply daniel_grady 9 hours agorootparentThose are interesting pointers; appreciate it! My own experience over the past three years has been similar. I tried using Pipenv, and then Poetry, for internal projects at my company; in both cases the tool seemed overly complicated for the problem, slow, and I had a hard time getting co-workers on board. About a year and a half ago, I saw [Boring Python: dependency management](https://www.b-list.org/weblog/2022/may/13/boring-python-depe...), which recommends using the third-party `pip-tools` library alongside the standard library’s `pip` and `venv`, and switched to that for the next project. It’s been working great. The project has involved a small team of scientists (four or five, depending) who use a mix of macOS and Windows. We do analysis and development locally and write production-facing algorithms in Python packages tracked in our repository, and publish releases to Gitlab’s PyPI. For our team, the “get up and running” instructions are “clone, create a venv, and pip install -r requirements.txt” and for the software team that manages the production systems, deploying an update just means pip installing a new version of the package. Every team’s got different constraints, of course, but this has been working very smoothly for us for over a year now, and it’s been easy, no pushback, with everyone understanding what’s going on. Really impressed with the progress of the core Python packaging infrastructure over the past several years. reply dragonwriter 10 hours agorootparentprev> Today, though, pip install works fine for those packages. pip install works, but pip's dependency management doesn't seem to (for Pytorch, specifically) which is why projects that have pip + requirements.txt as one of their installation methods will often have separate pytorch installation instructions when using that method, though if the same project supports conda installation it will be a one-stop-shop installation that way. reply daniel_grady 10 hours agorootparent> pip's dependency management doesn't seem to (for Pytorch, specifically) That’s interesting — I’ve also had difficulties with PyTorch and dependency resolution, but only on the most recent versions of Python, for some period of time after they’re released. Picking Python 3.9 as a baseline for a project, for example, has been very reliable for PyTorch and all the related tooling. reply paulddraper 13 hours agoparentprevYeah, I'm curious how much uv is actually faster. npm -> Yarn was life changing performance-wise. I wonder what pip -> uv is. reply the_mitsuhiko 13 hours agorootparentFrom my testing in rye it’s significantly faster in day to day. There are numbers in the blog post obviously but it’s the feeling you get using it locally that makes it much more fun to use. reply laborcontract 13 hours agorootparentprevBun, ruff/uv, polars.. all have been major qol improvements. I’m loving the pace of release with this crop of speed obsessed projects and I cannot wait for astral to tackle typing. reply laborcontract 10 hours agorootparentOk, here are some benchmarks installing an application that has a couple build-heavy dependencies: Installation times (MM:SS): # No cache - uv: 01:05 - pip: 01:56 # Cache: - uv: 00:02 - pip: 00:42 reply driverdan 6 hours agorootparentprevI did some basic testing today and uv was around 2x faster than pip for a clean venv and cold cache on a real, decent sized project. With warm uv cache it was incredibly fast, under 10 sec. reply eigenvalue 13 hours agorootparentprevnpm seems to have gotten a lot faster lately. All that competition from yarn and now bun seems to have pushed them to focus on optimization. reply paulddraper 13 hours agorootparentOh certainly. Npm has improved greatly. Npm features follow a two-step process: (1) Get implemented in Yarn (2) Get implemented in npm. reply ZeroCool2u 11 hours agoprevSo uv uses pubgrub-rs, a rust implementation of the pubgrub version solving algorithm originally written for the dart language. I suppose I shouldn't be surprised, but I always loved Pub the Dart/Flutter packaging tool. It's the only thing out there that comes close to cargo that I know of. Fun to see these chains of inspiration reach across languages. reply lijok 11 hours agoprevGonna put my pessimist hat on and say, great - another python package manager. If it was at least a drop-in replacement for pip, we could switch to it as we did to ruff just for the speed gains. We need a permanent solve for python package management, governed by the python steering council. reply keb_ 11 hours agoparentLiterally the first words in the article says that it's a drop-in replacement for pip. reply joshSzep 11 hours agorootparentAnd the following examples show it is not. While it is pretty straightforward to add `uv ` in front of any pip calls, it is not API compatible. reply romantomjak 11 hours agorootparentGranted they are still working on it, but in the meantime - add a shell alias for uv? alias pip=\"/usr/bin/uv pip\" reply aragilar 7 minutes agorootparentHow does that solve the problem that uv isn't a drop-in replacement? Are they going to implement the whole of pip, warts and all? Unlikely, because even though its in rust, they're getting a fair bit of speedup by making assumptions (see their ruff benchmarks, most of pylint isn't implemented), and as we've seen with both poetry and pipenv, those assumptions break down. pixi may get somewhat closer (given their experience with conda, and so familiarity with workflows and needs outside webdev), but I suspect uv will only further add issues and confusion to Python installs (especially if people decide to try aliasing and things break). reply lijok 11 hours agorootparentprevAnd you just took a VC-backed company at its word on a marketing article? I'm sure that's what they're aiming for, but at this time, it's not reply throw12344612 11 hours agoparentprevThe PSF has been asleep at the wheel for the past 10-15 years. The python packaging ecosystem has only gotten more fragmented under their stewardship. reply lijok 11 hours agorootparentFully agree - they need to get it together reply kzrdude 11 hours agorootparentA lot is happening these last few years, it's literally exploding. I think it will start to consolidate. reply raccoonDivider 11 hours agoparentprevIsn't it a replacement for pip? I've seen people on Twitter saying that they migrated very quickly. TFA: > TL;DR: uv is an extremely fast Python package installer and resolver, written in Rust, and designed as a drop-in replacement for pip and pip-tools workflows. reply lijok 11 hours agorootparentI tested it on my repo, multiple errors, it's not a drop-in replacement. (.venv) lijok@mbp icebreaker % python -m uv pip install --upgrade uv setuptools wheel error: unexpected argument '--upgrade' found tip: to pass '--upgrade' as a value, use '-- --upgrade' Usage: uv pip install [OPTIONS] |--editable > For more information, try '--help'. (.venv) lijok@mbp icebreaker % python -m uv pip install -- --upgrade uv setuptools wheel error: Failed to parse `--upgrade` Caused by: Expected package name starting with an alphanumeric character, found ' --upgrade ^ I'm sure it can be made to work - but it's definitely not drop in reply drcongo 16 minutes agorootparentWhat happens if you don't prefix with `python -m`? There's no mention of doing that in the blog post and it certainly feels wrong to call a rust package with python -m reply capital_guy 6 hours agoprevA lot of uncalled for pessimism here in the comments. If python folks reading haven’t used ruff yet, i can highly recommend it. The astral folks have proven themselves to me already. Looking forward to more and more of their rust built python tooling. reply SushiHippie 13 hours agoprevIsn't this basically what pixi wants to be? Wouldn't it be better to work together? https://github.com/prefix-dev/pixi/ reply theLiminator 13 hours agoparentPixi is even more ambitious but with a different philosophy (I think? Specifically thinking about how pixi went with their own lock and manifest format as well as first class conda support). I'd definitely prefer if they worked together instead or instead dedicated their time to type checking python which imo there still isn't a great solution for. reply SushiHippie 13 hours agorootparentEspecially the conda support is IMO a cool thing. As conda/pip interop is just not great. And even micromamba (C++ implementation of conda) is relatively slow to resolve compared to pip. But agreed either work together or create a type checker. I use mypy currently but it definitely slows down my editor. reply theLiminator 13 hours agorootparentYeah, pixi has decent mixed support for conda/pypi, it currently solves and installs conda (then locks it) and then solves and installs pypi. I think it's on their roadmap to solve them together, which would be a killer feature. reply davidhalter 11 hours agorootparentprevI have been working on a faster type checker for 3.5 years now. It's coming, I promise :) reply fydorm 5 hours agorootparentprevHave you tried Pyright? It made me actually enjoy Python development. reply RMPR 2 hours agorootparentFor type checking it is very good, however, the error messages are sometimes not very human-readable. For example: def _deep_merge(updates: dict[str, str]) -> None: for key, update_info in updates.items(): if isinstance(update_info, dict) and \"values\" in update_info: value = update_info[\"values\"] Errors out with Pyright: - error: Argument of type \"Literal['values']\" cannot be assigned to parameter \"__key\" of type \"SupportsIndexslice\" in function \"__getitem__\" Type \"Literal['values']\" cannot be assigned to type \"SupportsIndexslice\" \"Literal['values']\" is incompatible with protocol \"SupportsIndex\" \"__index__\" is not present \"Literal['values']\" is incompatible with \"slice\" (reportGeneralTypeIssues) 1 error, 0 warnings, 0 informations It took me a great amount of starring to figure out that changing the signature of updates to dict[str, dict] was what it was complaining about. reply Cannabat 1 hour agorootparentprevI don't know if I'd use the word \"enjoy\", but it certainly makes python tolerable. With all due respect, it blows mypy out of the water. reply woodruffw 13 hours agoprevThis is very exciting! Congratulations to the Astral team on their work here. I have historically expressed trepidation towards external attempts to \"fix\" Python packaging, largely because each attempt has historically accreted another layer of incompatibilities and hacks onto the giant pile of hacks that are already needed to keep the ecosystem running. As such, it makes me happy to see that compatibility is a priority here: the Astral team has gone out of their way to emphasize both formal (PEP) and informal (pip CLI) compatibility with existing tooling and standards. (Separately, I share concerns about VC funding and sustainability. But everything I've seen so far indicates that Charlie and the other folks at Astral are not in it to screw or otherwise leverage the Python community. So I choose to be optimistic here.) reply eviks 13 hours agoparentPrioritizing compatibility with a giant incompatible pile of historical hacks is how you grow the pile reply woodruffw 13 hours agorootparentI don't think that's true, at least in the case of Python packaging. The pile has historically grown because of informal or non-existent standards, along with multiple independent implementations attempting to align their observed (but not specified) behaviors. reply fwip 12 hours agorootparentprevWell, they do explicitly list certain historical features that they don't intend to support, like installation from eggs or editable installs. So they're doing some work to trim the pile while they're there. reply SonOfLilit 11 hours agorootparentThey do support editable installs, but only from local directories. So you have to perform git clone yourself and then install. reply charliermarsh 7 hours agorootparentWe do actually support direct installation of Git and direct URL dependencies. Like, you can do run `uv pip install` with: ``` black @ git+https://github.com/psf/black ``` We also support editable installs for local directories, like you mentioned: ``` black @ ../black ``` The thing we don't support is using _editable_ installs for Git and direct URL dependencies, like: ``` -e git+https://github.com/psf/black ``` In my experience, these are really rare, and we didn't see a reason to support them. reply amelius 13 hours agoprevIirc, some pip packages require compilation which depends on entire toolchains with e.g. gcc, g++, and with dependencies like gtk, Qt, etc. How do they intend to make that less error prone and thus more user-friendly? reply cavallo71 12 hours agoparentThat's exactly what conda/mamba/micromamba is covering: the whole toolchain. reply amelius 12 hours agorootparentI've used conda/mamba, but often ended up with broken installs (random coredumps) that were mysteriously fixed by just using pip3 instead. reply ZeroCool2u 12 hours agorootparentprevThat's what they attempt to cover, but they're not super successful at it. reply mixmastamyk 10 hours agoparentprevWheels have been a thing for a decade+. If not available from the developer the complexity doesn't reduce much. reply nmca 6 hours agoprevInitially I was confused by the business model here, but I eventually figured it out --- improved python tooling is going to accelerate AI so much that they can just rely on the future gratitude of the machine god. reply notatallshaw 13 hours agoprevThere are a couple of promising tools written in Rust looking to replace Pip for most users. Rip (https://github.com/prefix-dev/rip/issues) which is more of a library for other rust tools to be on top of like Pixi (which is looking to replace both Pip and Conda). And now uv, which seems to be looking to replace Pip, Pip-Tools, and eventually Poetry and PDM. A lot of the explosion in tools in the Python world is coming from the desire for better workflows. But it has been enabled by the fact that build configuration and calling has been standardized and tool makers are able to follow standards instead of reverse engineering easy install or setup tools. I know a lot of people are put off by there being so many tools, but I think in a few years the dust will settle and there will emerge a best practice work flow that most users can follow. As a primarily Python developer and someone who occasionally contributes to Pip to solve complex dependency resolution issues it does make me wonder if I should hang my hat on that and learn enough rust to contribute to one of these projects eventually. reply ShamelessC 13 hours agoparentMy experience with Rust developers who dwell in Python land is that they fundamentally disagree with most of the language that is Python and think they know better than incumbents what belongs and what doesn't. reply klardotsh 13 hours agorootparentThe Rust ecosystem gets so much right that honestly, even as a career-long Python developer myself (and Rust for many years, but that's less of my point), they honestly probably do know how to build a good devxp better than much of the Python ecosystem. Put other ways: the Python ecosystem has had 30+ years to figure out how to make packaging not suck. It has continually failed - failed less and less over time, sure, but the story is still generally speaking a nightmare (\"throw it all in an OCI container\" is an extremely reasonable solution to Python packaging, still, in 2024). I welcome advances, especially those inspired by tooling from languages that focused heavily on developer experience. reply theLiminator 9 hours agorootparentTbf, being able to start from scratch makes it much easier to get those things right. Being compatible with the mess that exists is where the difficulty comes from. reply drawnwren 13 hours agorootparentprevTo be fair, python package management is in such a poor state that I would expect any outside opinion to not be worse. reply sophacles 13 hours agorootparentprevI have written a couple million lines of python professionally. Some of that is still in prod. The last 5 or so years I've mostly done work in rust... so I guess I'm a rust developer now. Do the last 5 years invalidate my opinions, thoughts, or skills w.r.t. python somehow? reply daxfohl 12 hours agorootparentprevI'm surprised anyone who has gone from python to rust still finds contributing back to the python ecosystem worthwhile. reply __MatrixMan__ 5 hours agorootparentThere's a lot of important work that happens in python. Most of it isn't being done by software engineers. I think the idea of improving things for that group is plenty meaningful. reply marclave 11 hours agoprev> Like pip-compile, uv generates a platform-specific requirements.txt file (unlike, e.g., poetry and pdm, which generate platform-agnostic poetry.lock and pdm.lock files). As such, uv's requirements.txt files may not be portable across platforms and Python versions. really curious on the reasoning behind this decision :) reply Too 3 hours agoparentHard to give a concrete example but you can end up in dependency deadlocks, with combination of packages that require new features vs packages that don’t work on newer versions. Mostly it’s useful right after a new release where prebuilt wheels aren’t available for all packages yet and you have users who may care or not about this. If you only have single requirements file, you get forced to choose which platform to support. With multiple, you can break out if needed. These breaking changes and deadlocks are rare. It’s still good to have an escape hatch. reply ofek 13 hours agoprevExciting stuff! I view Hatch [1] as becoming the Cargo for Python because it's already close and has an existing (and growing) user base but I can definitely see depending on this for resolution and potentially not even using pip after it becomes more stable. [1]: https://hatch.pypa.io/latest/ reply singhrac 12 hours agoprevSomething that is super super important to me is editable installs, and local references to those editable installs. Often I have several editable packages set up in a virtualenv which I think of as like my \"base\" virtualenv. One reason I struggled with Rye earlier is that it kind of felt like this wasn't entirely supported, possibly because I couldn't parse the information on the workspaces or virtual projects page. Maybe someone else figured this out? It does seem common enough that I would be surprised if it wasn't supported. reply charliermarsh 7 hours agoparentI think having a good story for local workspaces is gonna be a key piece of this next phase of the project, where we grow uv from a \"pip replacement\" to a \"Poetry replacement\" -- or, phrased differently, to something that looks more like Cargo. (Cargo does a bunch of nice things here that I want to learn from.) reply Zizizizz 3 hours agoparentprevThis does editable installs, I tried it myself yesterday reply duped 13 hours agoprevDo you plan to support platform-agnostic lockfiles? From the wording it sounds like \"yes\" but also \"this is a feature not a bug.\" Which is it? Checksum verification and portable lockfiles are kind of table stakes for me, which is why I use poetry everywhere possible. I can't give up correctness for speed. sidenote: this would be super useful as a library so I could plug it into build systems. Managing python dependencies in standards-compliant ways is a pain, so shelling out to tools like poetry and pip are used even though it would be nicer to write that code eg in Rust and just use the parts you care about. reply charliermarsh 7 hours agoparentYes, we absolutely want to support platform-agnostic lockfiles. Very important thing. The \"feature not a bug\" tone is probably because we intentionally limited the scope of this release to _not_ support platform-agnostic resolution, since it adds a lot of complexity (and we were still able to ship something that's immediately useful for those that rely on pip and pip-tools today). reply captn3m0 13 hours agoprevSo what's the plan for monetization? NPM getting acquired by GitHub was an anomaly, and I'm wary of letting VC-backed companies becoming ecosystem lynchpins. reply anze3db 13 hours agoparentI hope they answer this ASAP. People in the Python community are already concerned that Astral is following the Embrace, extend, and extinguish playbook. reply aidos 13 hours agorootparentIf all they did right now was leave Ruff exactly as it was and walk away they would have given the Python community a great gift. Sure, it’s rendered a bunch of projects obsolete, but it’s because it’s so much better than the predecessors. reply anze3db 12 hours agorootparentIf they stop development on Ruff today, Ruff won't be useful anymore after a few new Python releases. If the maintainers of the tools that Ruff is replacing stop maintaining them, the whole Python community will be in a really bad place. So, there is reason to be cautious. Astral being transparent on how they plan to make money would be very helpful. reply the_mitsuhiko 12 hours agorootparent> If they stop development on Ruff today, Ruff won't be useful anymore after a few new Python releases That is true for every single development tool in the Python space. reply aidos 12 hours agorootparentprevI do get the caution, but I think that even in that case there’s enough momentum behind Ruff for the community to fork and carry on. Obviously it would be pretty crummy to end up in a situation like pyright where MS really have leant in to their embrace, extend, extinguish strategy. reply theLiminator 10 hours agorootparentprevPeople could just fork it if that happens. Since the foundation of the tooling is solid, I 'm sure the community would rally around a fork that keeps it going. reply cqqxo4zV46cp 12 hours agorootparentprev“People in the Python community”? Yeah. Probably precisely the same people that call everything EEE. You’ll always find people acting alarmist about anything. reply sophacles 13 hours agoparentprevIt's MIT and Apache dual licensed. If the company fails, you fork and move on. If the company never makes a dime, that's OK for me: some folks got paid to make open source tooling. reply anze3db 13 hours agorootparentWhat they are doing is already discouraging people from contributing to the projects their tools are replacing[0]. If they go out of business and stop supporting their tools, it might leave the Python community in a bad place. [0] https://www.youtube.com/watch?v=XzW4-KEB664 reply bdzr 10 hours agorootparentThat video is.. weird. It claims that astral isn't contributing back despite the entirety of their code being permissively licensed. It's also sort of baffling that making tooling more accessible doesn't seem to be considered contributing back. I'm not sure what the maker of that video wants, does he want money to be poured back into the community, or for no one else to make money? reply eviks 12 hours agorootparentprevWouldn't their failure re-encourage people to contribute? reply woodruffw 13 hours agorootparentprevI'm not sure this is a reasonable framing: LLVM stole much of GCC's thunder by being significantly easier to contribute to (and extend externally), but I don't think it would be accurate to say that LLVM is \"discouraging\" people from contributing to GCC. reply anze3db 12 hours agorootparentI'm not sure if you can compare a project that came out of a university and got adopted by Apple with a project developed by a VC backed company with no revenue. I'm sure Charlie has the best intentions with both ruff and uv, but we have no idea how this is going to play out. reply woodruffw 12 hours agorootparentMy understanding of Ruff's history is that it predates Astral, and was originally a side project by Charlie. I have similar reservations about VC funding and sustainability, but I don't think Ruff was created as a trojan horse or with a secret takeover plan in mind. I agree that we have no idea how it'll play out. But I've seen nothing but good faith from Charlie and others, and I see no reason to preemptively condemn their attempt to build a business. reply marwis 12 hours agorootparentprevLLVM was at least written in the same language it is compiling. In this case they are replacing Python code with Rust which might exclude large part of Python community from being able to contribute. reply woodruffw 12 hours agorootparentBy this token, we should be concerned that CPython is not written in Python. But that historically has not posed a significant risk to CPython's longevity, nor to the ability of motivated contributors to learn the C necessary to contribute to it. (Or another framing: only the tiniest fraction of the Python community was contributing to CQA tooling in the first place. It's not clear that prioritizing the interests of the 99.9% of Python programmers who -- rightfully! -- will never modify these tools makes sense.) reply ForHackernews 12 hours agorootparentprevThe slow death of GCC has been unquestionably bad for copyleft software. reply woodruffw 12 hours agorootparentWhy is it LLVM's job to be good for copyleft software? reply ForHackernews 12 hours agorootparentIt's not. But some suspicion of successor projects is probably warranted by the devs and users of existing tools. reply alfalfasprout 13 hours agoprevWhile we don't particularly care about pip lockfiles, etc. as we're moving to the conda/mamba ecosystem a faster pip is most welcome. We invoke it a lot programmatically and it's very, very slow. reply bagels 9 hours agoprevWhat is wrong with pip that people thought we needed conda, and all these other managers? reply duped 9 hours agoparentIf you want to learn every lesson a package manager author has learned in the last twenty years by way of counterexample, use pip. Global dependencies by default (fixed by venvs). Shipping precompiled binaries that are not portable across platforms or python versions (kinda fixed by wheels, I forget the PEP number). No lock files with checksum verification by default (kinda fixed by requirements.txt with require hashes, but not really). Also, there's a bunch of weird shit that can happen if the pip version and python version disagree due setup tools. It's got a great interface for installing stuff. But the likelihood that what it installs breaks something on your machine is pretty high the longer you use it. Edit: the real, fundamental problem with pip is that it can't be saved. Too many dockerfiles and server provisioning scripts are relying on it - it's interface, semantics, CLI output, etc. It's not 100% broken, which is why it's still useful. But any true fix has to be done by creating a separate tool. reply lolinder 9 hours agoparentprevA long list of terrible defaults with workarounds that get you halfway to a decent package manager: * Defaults to installing packages globally instead of per project. * requirements.txt feels very much like a second class citizen when you contrast it with package.json, Cargo.toml, build.gradle, pom.xml, or most other dependency systems in other package managers. * No native support for lockfiles short of pinning every version of every project in requirements.txt. This solution is inferior to what is available in ~every other package manager, because a pip freeze doesn't distinguish between explicit dependencies and transitive dependencies. I'm sure there are others, but they're all along the same lines—pip is strictly inferior than basically every other package manager out there for other languages. Things that people expect to be part of a package manager have ugly hacky workarounds instead that aren't uniformly applied across projects. reply __MatrixMan__ 5 hours agoparentprevHave you ever seen a pip failure that required you to go use a different package manager and then come back and try pip again? That's what. reply bagels 39 minutes agorootparentI haven't. The only packaging problem I saw deploying python applications was with one particular package that was only available through conda. I was able to build useful things with pip + virtualenv reply okanat 9 hours agoparentprevImperative dependency (mis)management. Pip resolves what needs to be installed while it installs things depending on the setup script of the package. It requires a full execution and it is neither repeatable nor reproducible. So it is impossible to know what needs to be pulled from Pypi ahead of time. Pip is also strongly tied to the specific Python version. If you upgraded Python interpreter on a system, congrats all virtual environments and all PyPi packages are broken now. Hopefully you saved the minimum set of requirements and they don't have some catastrophic dependency breakage. You run pip install and pray. What? Native binaries? Building them on the fly while installing a pip package? Oh you're brave. reply 0cf8612b2e1e 14 hours agoprevCoupling with Rye is very interesting, as that or the PyBi idea seem inevitable to take over. Managing different interpreters is just too much effort which each tool is handling differently. Of course, the PSF will remain silent on the issue and let yet another tool exist in the ecosystem. I really do not care who wins, but we need a standard to be decided. reply OJFord 12 hours agoparentI hadn't heard of Rye before I don't think, but sounds like a strange arrangement to me - basically the same project & idea, so the new one to start switched the old one to use it 'under the hood', 'took it over', and will replace it 'when the time is right'? Why.. any of that, why not just buy it and let it be uv instead of starting uv, or just leave it alone? reply the_mitsuhiko 12 hours agorootparentI wrote down a small little FAQ at the bottom, hope it answers some questions: https://lucumr.pocoo.org/2024/2/15/rye-grows-with-uv/ reply OJFord 12 hours agorootparentThat is helpful, and fair enough, thanks! reply theyinwhy 11 hours agoparentprevWhy do people here claim that the PSF has any leverage to stop tools being developed? reply 0cf8612b2e1e 10 hours agorootparentI don’t want the PSF to declare tools cannot be made. I want the PSF to pick a winner so we can finally consolidate on a workflow. Just today, I was helping a beginner setup Python on their laptop. A nightmare collection of tooling complexity (so you have Python, but you need to worry about virtual environments, to do that, I use this combination of pipx+virtualenvwrapper, but to do actual projects, you need Poetry, but…) all the while noting that this is an opinionated workflow that I happen to utilize because of the tradeoffs that matter to me. Ask someone else, and they will definitely have a different configuration. Entire first lesson was just to get Python installed with tons of elided complexity. I should be able to point to a document on Python.org that says, “This is the way.” Yet for decades, they have refused to take a stand. reply theyinwhy 3 hours agorootparentIsn't it your job as an engineer to pick the right toolchain for the job? reply the__alchemist 12 hours agoprevVery cool! Of note, I made something along these lines a few years ago, although with a slightly broader scope to also include managing and installing python versions. I abandoned it due to lack of free time, and edge cases breaking things. The major challenge is that Python packages that aren't wheels can do surprising things due to setup.py running arbitrary code. (https://github.com/David-OConnor/pyflow) For some more context, at the time, poetry and pipenv were both buggy, and had some limitations their teams listed as \"wont-fix\". The sort of thing where you hit a breaking bug immediately on certain systems. These have since been fixed. reply maxvt 13 hours agoprevI'd be curious to see how \"packaging for production\" is addressed. As described, this is a tool for development purposes: > Think: a single binary that bootstraps your Python installation and gives you everything you need to be productive with Python, bundling not only pip, pip-tools, and virtualenv, but also pipx, tox, poetry, pyenv, ruff, and more. A lot of that dev tooling is not needed in prod, in fact it is a liability (features available for misuse, code/image size, higher resource requirements). Would there be a \"uv-prod\" to only deal with the minimum subset of environment setup / container building that enables production use? Would uv build packages that are runnable in prod but themselves don't contain uv? It'd be interesting to hear the plans. reply radus 7 hours agoparentMy approach for this is to use multi-stage dockerfiles. Build tools live and operate in a build stage, and you copy the /venv into your runtime stage. I think this same approach should work with uv so long as it doesn't bundle itself into the venv. reply 12_throw_away 12 hours agoprevThis article says they don't support \"platform-agnostic lockfiles\" YET. And platform-agnostic lockfiles have been mentioned in several comments here, times too. I haven't encountered these before (with python, anyway) - how do they work platform-specific dependencies, e.g., binary wheels? For instance, there are >30 dists for numpy 1.26.4 [1], with different artifacts for different platforms and python interpreters. Which of those hashes ends up in a platform-agnostic lockfile? Do you have to stick with sdists only? [1] https://pypi.org/project/numpy/#files reply orf 12 hours agoparentAll of them - poetry adds them as an array, and the right one is installed for the platform. reply jvolkman 12 hours agoparentprevPDM and Poetry would include hashes for all possible wheels, and would also follow transitive paths for platforms other than the current host. E.g. if my host is Linux and I depend on foo, and foo depends on bar only on windows, and bar depends on baz, my lock file will still contain baz. reply iwebdevfromhome 13 hours agoprevVery nice! Not long ago we got rid of a bunch of tools at work in favor of ruff. I'm looking forward to this. Specially when the time comes to be able to replace poetry with it, hoping it is a good implementation. reply gary_0 12 hours agoprevSomething I've been waiting to see from language package managers is more attention paid to security. I believe both cargo and pip packages can run arbitrary code as the local user the instant they are installed, and malicious packages have existed in the wild for years. I also recall a blog post where someone was scanning PyPI for malicious Python packages, only to realize that `pip download` also executed code. Just downloading a library to a local source code directory should not cause arbitrary code to run on your system, and there should be safeguards in place so developers are not one typo away from a malicious package pwning their entire system. Supply chain attacks remain a huge area of concern. Instead, when I \"ctrl+f security\" the homepages of any of these new packaging systems, I get 0 results. Not good. reply woodruffw 12 hours agoparent> I also recall a blog post where someone was scanning PyPI for malicious Python packages, only to realize that `pip download` also executed code. I think you're thinking of this post[1]. The code being searched for wasn't malicious, just buggy :-) [1]: https://moyix.blogspot.com/2022/09/someones-been-messing-wit... reply gary_0 12 hours agorootparentThanks, that's the one! I was actually just trying to find it. Heh, I forgot about the anime catgirl part. reply SamEdwardes 13 hours agoprevSign me up! A single binary to manage Python is something I have been hoping for. reply marmaduke 13 hours agoprevFor envs which are pets, who cares, but this will be great for those cattle situations. reply ericra 14 hours agoprevWhile I don't see the immediate need to switch from using pip, I am such a fan of ruff that I'm always happy to check out what you guys come out with. Please keep doing what you're doing! reply rengler33 13 hours agoprevThis is great. Just adopted the pip-tools approach on a project and that has been great. Excited to give this a try. reply murkt 13 hours agoprevAn ability to override dependencies, finally! reply drcongo 14 hours agoprevI've been dying to see what they came up with next given how in love I am with Ruff. In my wildest dreams I didn't expect it to be a package resolver. I'm very excited about this. edit: As a side note, if anyone from Astral happens by, any chance of an RSS feed on your blog? reply singhrac 13 hours agoparentI was kind of hoping it was a better type checker, something like mypy + pyright. To be fair that's an incredible amount of work, so maybe we'll see that later. Still very excited. reply fydorm 5 hours agorootparentWhy include mypy at all? Pyright is amazing and all you need. reply drcongo 13 hours agorootparentprevThat was actually my first guess, and while I certainly would love to see that, packaging is such a headache for so many people that this could be amazing. Even with poetry I still occasionally get mysterious errors and wildly wrong resolver claims about versions not existing. reply chrisshroba 13 hours agoprev [–] Obligatory two xkcd's, but I'm super excited about this project! Definitely going to try it out. https://xkcd.com/1987/ https://xkcd.com/927/ reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Astral has released a new Python package installer and resolver called uv, intended to replace pip and pip-tools.",
      "The uv tool is focused on performance and is significantly faster than its counterparts.",
      "Astral plans to develop uv into a comprehensive Python project and package manager, aligned with the vision of the experimental packaging tool Rye. They aim to provide a smooth migration path for Rye users."
    ],
    "commentSummary": [
      "The discussion explores the limitations of current Python package management tools such as pip and the potential advantages of alternative package managers like conda and uv.",
      "Concerns about fragmentation, lack of standards, and the need for better dependency resolution and platform compatibility in the Python ecosystem are addressed.",
      "Users emphasize the desire for faster and more reliable package management, the importance of hash verification and lock files, and express security concerns and opinions regarding the inclusion of development tools."
    ],
    "points": 539,
    "commentCount": 174,
    "retryCount": 0,
    "time": 1708026627
  },
  {
    "id": 39383386,
    "title": "Observable 2.0: A Game-Changing Static Site Generator for Data Apps",
    "originLink": "https://observablehq.com/blog/observable-2-0",
    "originBody": "Product Learn Community Pricing SearchSign inSign up Back to blog Product Observable 2.0 Announcing: Observable Framework Mike Bostock Founder / Office of the CEO February 15, 2024 Today we’re launching Observable 2.0 with a bold new vision: an open-source static site generator for building fast, beautiful data apps, dashboards, and reports. Our mission is to help teams communicate more effectively with data. Effective presentation of data is critical for deep insight, nuanced understanding, and informed decisions. Observable notebooks are great for ephemeral, ad hoc data exploration. But notebooks aren’t well-suited for polished dashboards and apps. Enter Observable Framework. With Framework, you can build the best data apps your team has ever seen. Framework combines the power of JavaScript on the front-end for interactive graphics, with any language on the back-end for data preparation and analysis. SQL, Python, R, Rust, Go… you name it. It’s the polyglot programmer’s dream. Everything you need is at your fingertips: interactive charts and inputs, responsive grids, themes, dark mode, keyboard-friendly navigation, and more. And because it’s code, there’s no limit to customization! Framework is free and open-source. Projects are just local files. Use your favorite editor, preview locally, check it all into git, write unit tests, add CI/CD, even work offline. You can host projects anywhere or deploy instantly to Observable to share them securely with your team. Observable Framework solves the “last mile” problem of data apps: loading data. Conventional dashboards are slow because they run queries on view while the user waits; Framework’s data loaders run on build so that pages load instantly. And because data loaders run on your servers, you control privacy and security. If you’re ready to dive in, visit our Getting started tutorial, or open a terminal and run: npm init @observablehq If you’d like to hear more about why we built Framework, please read on. Beyond notebooks 📓 This moment — Observable 2.0 — reflects lessons learned over many years. We believe the lightweight, collaborative nature of computational notebooks makes them ideal for exploring data and answering ad hoc questions. We founded Observable in 2016, pioneering a reactive, web-first approach to notebooks and seeking to make data visualization easier, more practicable, and more social. We dreamed that notebooks might be the “one ring to rule them all” — powering not just notes, but apps, dashboards, and reports. Yet no single interface can excel at every task. As cool as reactive notebooks are, a notebook can’t compete with a custom web app in terms of user experience. Notebooks are constrained by: A single-column, narrow layout Low visual information density Always-visible editor chrome These same limitations make notebooks great for tinkering and learning — the code is always at your fingertips, adjacent to the output — but not so great for presentation. To fill that latter role, we need better data apps. A good data app embodies an empirical perspective; it fosters a shared understanding. Whereas notebooks tend to be for individuals, data apps are more often for a team. And whereas notebooks tend to be transient byproducts of point-in-time exploration, data apps often sustain value over time as people return to see how things change. The differences between notebooks and data apps extend to development. A notebook editor desires speed: jotting down thoughts, running a query, sketching a chart. A data app developer prioritizes correctness, performance, and maintainability: making careful, deliberate changes that others depend on, favoring code review and testing before publishing. We had three goals in mind when we set out to reimagine data app development: A better developer workflow — meeting the needs of developers A better user experience — the “proof is in the pudding” A better data architecture — solving the “last mile” problem A better developer workflow 👩💻 Modern development is built on files. Files have myriad strengths, but the strongest is interoperability. When every tool uses files, it’s far easier to incorporate a new tool — and now Observable — into your workflow. This isn’t just about using your preferred text editor. Now you can bring your own source control and code review system, too. You can write unit tests and run linters. You can automate builds with continuous integration or deployment. You can work offline. You can self-host. You can generate or edit content programmatically, say to format code or to find-and-replace across files. As we break new ground with Observable Framework, we’re further improving interoperability by adopting vanilla JavaScript syntax. And we’re deprecating require in favor of modern ES import. These changes make Observable easier to learn, and to share code with other applications. (We’ll port these improvements back to Observable notebooks in the future.) Check out our examples on GitHub. A better user experience 😍 A toolmaker can’t care only about the developer experience — what does the developer experience matter if the resulting app is not demonstrably better? The merit of a creative tool should be judged by the quality of its creations, not its process. Or: “the proof of the pudding is in the eating.” We believe that well-designed tools help developers build more efficiently by focusing their efforts on high-value work. We favor opinionated tools, with defaults and conveniences that foster a good user experience. We nudge you into the pit of success. Framework’s lightweight Markdown syntax — with light and dark mode, thoughtful colors, responsive grids, and built-in navigation — gives you beautiful pages from the start. It’s highly customizable if you need it, but it’s quick to get started with batteries included. Most importantly, Framework’s data architecture practically forces your app to be fast because data is precomputed. Performance is critical for dashboards: users don’t like to wait, and dashboards only create value if users look at them. Slow dashboards waste time. (And you certainly don’t want your database and dashboard falling over under load!) A better data architecture Every data visualization requires data. Obviously. But less obviously, each data visualization requires highly-specific data prepared with that visualization in mind. In fact, most of the work of visualization isn’t choosing visual encodings or laying out axes or visualizing per se — it’s preparing data. As I wrote previously, working with data should be 80% of the work of visualization. Visualization is the end result of analysis — the visible manifestation of data, to be seen, shared, and appreciated by experts and non-experts alike — and as such it sometimes gets too much credit. To produce a visualization, one must first find data, clean it, transform, join, model, etc. Working with data is sometimes needlessly denigrated as “janitorial” when it represents the critical step of understanding the data as it is, warts and all. Given how much work goes into preparing data, it follows that developers want to use any language (say Python or R or SQL), to use any library (say NumPy or dplyr), to use any data source (database, data warehouse, API, files, etc.), and to crunch data ahead of time (offline) while still leveraging JavaScript in the browser for interactive graphics. Framework’s data loaders solve this “last mile” problem by computing static data snapshots at build time. These snapshots can be highly-optimized (and aggregated and anonymized), minimizing the data you send to the client. And since a data loader is just a fancy way of generating a file on-demand (with clever caching and routing), loaders can be written in any language and use any library. This flexibility is not unlike CGI from 30 years ago, and Unix pipes. And since data loaders run on your servers, viewers don’t need direct access to the underlying data sources, and your dashboards are more secure and robust. The speed of modern data warehouses is astonishing. But far too often something is missing for new analysis — some untapped data source, some not-yet-materialized view for a query to run at interactive speeds. Framework’s data loaders let you bypass these hurdles and produce a fast dashboard without “heavy lifting” in your data warehouse. And once your analysis demonstrates value, you can shift work to your data warehouse and simplify your data loaders. Framework lets you build faster and quickly validate your ideas. We believe Framework will change how you think about data, and effect a better user experience. And by securely hosting apps alongside notebooks, Observable now offers an end-to-end solution for data analysis and presentation. Thank you 🙏 We wouldn’t be here without the support, feedback, and encouragement from you — our community. Thank you for using Observable notebooks, Observable Plot, and D3. We’re thrilled to share Observable Framework with you now, and can’t wait to hear what you think. To learn more about Framework, read the docs. To share your questions or feedback, please visit our forum. Build better data apps, dashboards, and reports Sign up nowRead the docs Product Security Integrations Docs Observable Framework docs Observable Plot docs D3 docs Learn Release notes Customer stories Blog Community Examples Community Slack Forum GitHub Company About Careers Contact us Newsletter signup Pricing © 2024 Observable, Inc.PrivacyTerms of Service",
    "commentLink": "https://news.ycombinator.com/item?id=39383386",
    "commentBody": "Observable 2.0, a static site generator for data apps (observablehq.com)536 points by tmcw 19 hours agohidepastfavorite118 comments mbostock 16 hours agoHey, HN. We’re thrilled to release Observable Framework today — a new open-source tool for developing data apps. I highly recommend viewing this example report adapted from our internal dashboard analyzing web logs: https://observablehq.com/framework/examples/api/ This technique of “just plot everything” (7.6M requests as a scatterplot) has revealed surprising insights we’ve used to optimize our servers and better control traffic. We’re also sharing a more traditional dashboard that visualizes the adoption of our open-source visualization library (and in some ways the successor to D3), Observable Plot: https://observablehq.com/framework/examples/plot/ In addition to releasing Observable Framework, we’ve also made Observable free again for individuals (including private notebooks and databases connectors). Let me know if you have any questions! reply vermarish 15 hours agoparentHi! Some background first: I'm putting together a blog right now using Hugo and D3. I'm a huge fan of D3's infinite flexibility, as seen in some famous scrollytellers [0-1], and I've spent some time experimenting with that format myself [2]. My question is: what does Observable Framework offer for data storytellers who want to blog? Is this meant to go up against Hugo/Jekyll in terms of full-fledged max-efficiency site generation? If not, are there plans to add integrations with other blogging frameworks? [0]: http://r2d3.us/ [1]: https://algorithms-tour.stitchfix.com/ [2]: https://vermarish.github.io/big-brother-barometer/ reply mbostock 11 hours agorootparentWe’re not expressly targeting the blogging use case — we primarily want to support data apps, dashboards, and reports. But Observable Framework is quite flexible and you can use it for a lot of things; the Framework documentation is itself written using Framework, for example. So I would say that if you are working with data and you want an automated process to keep your data up-to-date, or to work with multiple languages (e.g., Python and JavaScript), or if you want to do a lot of interactive visualizations then you should give Framework a go. But we don’t have much built-in affordances for blogging, so you might find some things missing. Feel free to file feature requests! We’d love to hear your ideas, though we’re primarily focused on reporting and data app development for work. I’m not sure what better integration with other blogging frameworks would look like — like, part of the page is rendered by Framework, but the site as a whole is handled by the blogging framework? Perhaps we could develop Framework’s API further so it could function like a plugin. But this is speculative and not a priority for us currently. If you explore the possibilities here please let us know! reply ipsum2 11 hours agorootparentHow do dashboards work if data is computed at build time? Does that mean every time you want to update the data you need another build? I'm interested in live dashboards, is Obversable framework the wrong tool for the job? reply mbostock 10 hours agorootparentYes, we use continuous deployment (cron) to rebuild as needed. You can also get realtime data on the client if you need to (via fetch or WebSocket to your own servers — it’s “just” JavaScript), but generally we find building static data snapshots a useful constraint because it forces you to think about exactly what data is needed, and as a result the dashboard loads instantly. reply ipsum2 1 hour agorootparentMy use case is monitoring machine learning models as they train, static snapshots doesn't seem like the right approach for me. reply sroussey 8 hours agorootparentprevRow64 dashboards are pretty instant. And interactive. Edit: link: https://row64.com/ reply bsimpson 4 hours agoparentprevYou've sponsored some very cool, state of the art tools. I've had friends work at Observable. I want you to succeed. I tried to get our team to use Observable Notebooks a few years back. The researchers I work with are more comfortable in Python. Clearly that's one of the things you're trying to solve in this release. The other half of that uphill battle was discomfort posting code externally. In some ways you've also mitigated that in this release, but I wonder how sustainable it is. Small teams eat for free by virtue of being small. Large organizations with trepidation or bureaucracy about using SaaS hosting will self host. That leaves the people in the middle: big enough to need to pay, but small enough to not have institutional problems with external hosting. Moreover, if the Observable bill ever gets much higher than the equivalent on Firebase et. al., the medium guys can self-host too. How do you anticipate the paid side of the new business to work out? What's the hook (beyond thinking you guys are cool and trying to keep you in business) that gets someone to pay for Observable? reply asimpletune 13 hours agoparentprevOne question I have is if there's a way to integrate an observable framework project into an existing static site? I see how I could easily add a project as a subdomain, but what if I wanted to interleave a project I make with observable framework into my existing domain and that static site generator I already use for that domain? By the way, thank you making this. I've been reading and enjoying very much the documentation. It looks like it has huge potential. reply mbostock 11 hours agorootparentThank you. At a minimum, you could iframe pages built with Framework, or have them live alongside your other pages and link to them. Maybe it would be possible to use Framework’s internal API to generate HTML that could be embedded within another static site generator page but we haven’t explored that idea yet. reply asimpletune 1 hour agorootparentThank you for answering my question. I'm sure after more people use framework an elegant design will make itself more clear. The decision to make data loaders agnostic to specific technology was a welcomed approach, and so I have no doubt a similar result will be achieved with integrating observable framework into existing static sites, however that may look. Thank you! reply 0cf8612b2e1e 13 hours agorootparentprevMy question as well. If I had say a Hugo blog, how much effort would it be to embed the output to its own page? reply hanniabu 12 hours agorootparentprevAlso curious if it can be worked into my jekyll sites reply polskibus 14 hours agoparentprevThank you Mike for pushing the visualisation envelope for so many years. Is the new Framework going to support virtualized data access for data sets too large to be sent over network (think of a pivot table that allows to browse huge data warehouse) - it is impossible to prepare entire file upfront, so data queries must happen incrementally with users actions? Or is it completely the other direction from where your vision for Framework is? reply mbostock 14 hours agorootparentIf you generate Apache Parquet files you can use DuckDB to make range requests and not download everything to the client. This is pretty magical and allows you to have surprisingly large datasets still queryable at interactive speeds. But the general idea is to not send everything the client — to be more deliberate and restrictive in what you send, and also what you show. So you probably shouldn’t use this for a general-purpose pivot table that’s trying to show “everything” in your data warehouse and enable ad hoc exploration. You’d instead design more specific, opinionated views, and then craft corresponding data loaders that generate specific pre-aggregated datasets. reply chrisjc 8 hours agorootparentIt's not always clear which pushdowns are available in DuckDB. For instance, while x = y has been available for a while, x in (y, z, ...) hasn't. The DuckDB team seems very eager and motivated to get all the pushdown functionality working though, so hopefully becomes a non-issue soon (perhaps already in 0.10.0). Another way to use DuckDB if you're warehouse supports it would be e2e Arrow (no col->row->col overhead). warehouse --> ADBC --> arrow --> DuckDB Of course this differs in that you would be reading from the warehouse directly, but in my experience fully pre-aggregating data and then staging it (keeping parquet files on S3 up to date) might solve one issue, but results in unimaginable issues. Perhaps the sweet spot might be something like Iceberg in the middle? warehouse --> iceberg table (parquet) --> DuckDB > craft corresponding data loaders Do you have an example of this using DuckDB? I'm very interested in seeing an actual implementation of Observable's data loaders combined with DuckDB (or any other SQL DB) edit: nm, found it. https://observablehq.com/framework/lib/duckdb edit2: eh, I didn't even realize who i was responding to, lol. The more I read into this, the more I see how this is all heavily based on static files. So the static parquet files thing makes more sense, the solution I added makes little. Although I guess you could add a static iceberg table and interact with its manifest with the duckdb iceberg extension. reply daniel_grady 12 hours agoparentprevCongratulations on this release! Your writing at bost.ocks.org, D3, and Observable have been big sources of inspiration over the years, and it’s always exciting to see new ideas from this team. reply ZeroCool2u 16 hours agoparentprevThis seems nice and the plots look great, but I have a hard time imagining switching to Observable from Plotly since there doesn't seem to be a way to make any plots interactive. By which I mean Zoom and Pan. The nearest point high light feature is nice, but what if I want to zoom in? None of the examples here seem to be able to do that and quick google search doesn't make it seem like that's straight forward. That's not even additional code when I use Plotly, it's just built-in. There's also the issue of convincing staff to use JS instead of Python which is still just a tough sell. I think everyone on my team (of data scientists) would look at me like I've got two heads if I were to suggest that. Maybe we're not the target demographic though. I do like the idea of shipping the data straight to the client, but I don't have a lot of confidence in our corporate network doing well and not slowing stuff down. Perhaps the graphics all are sent pre-rendered over the wire though? I'm not sure, but would be cool if Observable figured out a way to side step that issue. reply mbostock 15 hours agorootparentWe’re working on zooming and panning for Observable Plot (https://github.com/observablehq/plot/pull/1738) and other interactions such as brushing (https://github.com/observablehq/plot/pull/721) — all of this is already possible, we just haven’t packaged it up in a convenient way yet (https://github.com/observablehq/plot/pull/1871). And as skybrian pointed out, you can also get interactivity “for free” with Observable’s reactivity and re-rendering. We’ve been focused primarily on the static display of visualizations because that’s what viewers see first, and often that’s often the only thing they see. Relying too heavily on interaction places an onus on the user to find the insights; a good display of data should be opinionated about what it shows and guide the user to what is interesting. We’re not trying to convince you to switch to JavaScript here — a main value prop of Observable Framework is that you can write data loaders in any language (Python, R, Go, Julia, etc.). So do all your data preparation and analysis in whatever language you like, and then do your front-end in JavaScript to leverage the graphics and interactive compute capabilities of modern browsers. It’s pipes and child_process.spawn under the hood. And you still get instant reactivity when you save changes to your data loaders (when you edit Python) because Framework watches files and pushes new data to the client with reactive hot data & module replacement. And you can compress (aggregate or filter) the data as much as you like, so it’s up to you how much data you send to the client. For example your data loader could be a minimal CSV file that’s just the numbers you need for a bar chart. Or it could be a Parquet file and you use DuckDB (https://observablehq.com/framework/lib/duckdb) on the client to generate dynamic visualizations. reply oulipo 11 hours agorootparentInteresting! What are your thoughts on PRQL (integrated with DuckDB)? Also: sure, I get your point on opinionated viz, but this means someone already \"played with the data\" to figure out what to viz \"cleanly\", and then coded that now what if we want to build a viz to do this first \"data playground\" allowing to ruffle with the data? we would need some sort of interactivity reply zurfer 14 hours agorootparentprevI also love how Observable Plot looks, but agree with top poster, the things that keep me from switching are: - Python wrapper - Out of the box interactivity reply mbostock 14 hours agorootparentWe’re working on the interactivity, but we’re not going to do a Python wrapper as the goal of Observable Framework (and Plot) is to leverage web technologies with JavaScript in the front-end for interactive graphics — while doing whatever language you like, including Python, on the back-end for data analysis. There is a R wrapper for Observable Plot (https://github.com/juba/obsplot) and so I imagine someone could write one for Python, but ultimately we don’t think you’ll need it with Framework’s polyglot data loaders since you can seamlessly move between languages (front-end and back-end). reply ddanieltan 7 hours agorootparentFYI: Same dev building obsplot is also building a Python version at https://github.com/juba/pyobsplot reply mbostock 6 hours agorootparentAh, that’s what I thought at first, but I googled for “obsplot” and found the R one and thought I misremembered. Thank you for the correction. reply skybrian 16 hours agorootparentprevThough it’s not designed for animation, Observable Plot is just a JavaScript library and it renders fast enough that you can do things like that just by re-rendering. Here are some old notebooks with experiments with audio data hooked up to UI controls: https://observablehq.com/collection/@skybrian/observable-plo... reply jwilber 15 hours agorootparentprevObservable is much more than its library, plot. You mean to compare plot to plotly. There are a number of reasons to choose Observable’s plot over plotly, but to address your point, there is no lock-in here with using plot for the view - you can seemingly use any JS library, including plotly, vega, D3, etc., so I don’t think that’s a huge issue. I agree with your point regarding convincing other scientists to use JavaScript - that was the biggest point of failure for Observable notebook adoption that I saw. (As an anecdote, rather than adopt Observable, my science team @bigtech decided to write a Jupyter -> interactive static site transpiler, so the scientists could continue their work in python). Observable 2.0 seems built on recognizing that friction, and making it so that the it’s much easier for non-js users to collaborate. But the npm dependency will still scare many data folks away. To anyone from observable reading: I think getting mass adoption involves making this as seamless for python users as possible. (E.g. something similar to marimo notebooks or evidence). Also: great work! reply mbostock 15 hours agorootparentI don’t think the `npm install` will scare people away (Evidence uses that, too), and we’ve definitely tried to make the onboarding process as guided as possible (shout-out to clack.cc for a great CLI prompt library): https://observablehq.com/framework/getting-started And plus you can import libraries directly from a CDN rather than needing to use npm or yarn to manage dependencies. (Though we plan on supporting the latter in the future, too.) https://observablehq.com/framework/javascript/imports See this example for getting started with Python: https://github.com/observablehq/framework/tree/main/examples... But of course we’d love to add more affordances and documentation for other languages. We’re naturally biased towards JavaScript as our focus has historically been on visualization, but I like to think we’re making progress on the polyglot dream. reply time4tea 2 hours agorootparentImporting libs from a cdn is a big no-no for almost any system I work on - they are just another way of surveilling users on the Internet, and building information about the insides of organisations. reply fredguth 8 hours agoparentprevInteresting to see ObservableHQ making strides towards dashboards, similar to what Quarto and Evidence are doing. Observable Notebooks reactivity feels intuitive, much like spreadsheets, but the lack of self-hosting options is no-go Drawback in my work context. reply d--b 14 hours agoparentprevAt last! Time to call it quits for https://www.jigdev.com :-D Godspeed Observable, hope you guys make it big reply xixixao 15 hours agoparentprevSuper cool! Especially for low cardinality, low interactivity dashboards this approach makes a ton of sense. How is Observable going to make money off of the framework? reply mbostock 15 hours agorootparentHosting & compute — operationalizing/productionizing data apps. Observable Framework is open-source, but our hope is that we offer a compelling complementary paid service for you to host your (typically private) data apps on Observable. We make it easy for you to share data apps securely with your team or customers or clients or whoever, and manage the complexities of keeping your app & data up-to-date with continuous deployment, scheduled builds, access control, collaboration, monitoring, analytics, etc. reply JackFr 15 hours agorootparent> we offer a compelling complementary paid service In case you ever forget the difference between complementary and complimentary, that's it right there. reply mbostock 15 hours agorootparentHaha, my compliments. reply ayhanfuat 15 hours agoparentprevI was looking for a way to integrate Observable Inputs to VitePress and this came as a big surprise. Love what you are doing. reply tootie 15 hours agoparentprevIs this meant to be a competitor to tools like Tableau or Metabase? Something more dev-friendly and maybe git-versioned as opposed to a configurable SaaS tool? reply mbostock 15 hours agorootparentMore developer-focused, and yes, you can use git for version control and develop locally, setup continuous deployment, and self-host apps anywhere. reply espinielli 14 hours agoparentprevThis looks like a dream! reply hanniabu 12 hours agoparentprevWhile the docs look great, I'm having trouble getting over the hump of starting. It would be great if you had a repo with a started app we could fork and play around with to help us understand everything before diving in from scratch. reply mbostock 12 hours agorootparentDid you try running `npm init @observablehq`? It’ll create a starter app for you with everything you need to get started, as described in the Getting started tutorial. https://observablehq.com/framework/getting-started If you want more starter apps to look at, you can browse our examples on GitHub: https://github.com/observablehq/framework/tree/main/examples reply mbostock 16 hours agoprevAnother tidbit buried in this announcement is that Observable Framework is 100% vanilla JavaScript syntax — so you get Observable’s reactive runtime without the quirky Observable JavaScript syntax (as in Observable notebooks). And you can use static ES imports from npm or local modules, declare multiple top-level variables in a code block (not just a single named variable per cell), call the built-in display(…) function to put things on the page, etc. It’s a huge relief to have vanilla syntax and greatly improves interoperability. And we’re figuring out how to port these improvements back to Observable notebooks in the near future. reply skybrian 15 hours agoparentWith regard to code edits (rather than UI reactivity), this looks similar to how many web development environments watch the file system for changes and then rebuild and reload the page. Is there more to it? How are syntax errors reported? Is there support for TypeScript syntax and type-checking? Can a page partially run that has errors in some JavaScript snippets, like a notebook with errors in some cells? In the examples, there is a “view source” link that goes to GitHub. Understanding the code involves finding the Markdown file and then going back and forth between the published page and the Markdown file, which hopefully correspond to the same version. It seems like the thing that’s lost compared to notebooks is letting the user see and edit the code in the browser. But I suppose that’s a niche use case for coding tutorials. Not everything needs to be a notebook. Even so, better built-in “view source” support might be nice, even if it doesn’t allow editing. It doesn’t have to be as prominent as it is in a notebook to be useful. reply mbostock 14 hours agorootparentYou can read about our reactive runtime here (it’s the same as Observable notebooks even though Framework uses vanilla JavaScript syntax): https://observablehq.com/@observablehq/how-observable-runs And the source is here: https://github.com/observablehq/runtime The “trick” is to structure all code as reactive variables (or nodes, defined as pure functions) within a dataflow graph. So if you replace one variable (by replacing a function with a new import), you then have to recompute any downstream variables that depend on the replaced variable, while cleaning up old variables and updating the display. Invalid syntax doesn’t prevent other code blocks from running (though if it means a variable is then undefined, that might cause downstream errors). Syntax errors are displayed in the page, and also in the console for the running preview server. We’d like to improve the error display in the console to show more context around where the error occurred, since unlike notebooks the code isn’t immediately adjacent to the output. We don’t support TypeScript yet, but there’s a PR (https://github.com/observablehq/framework/pull/129) and we are interested in stronger validation at build time to catch more errors. And yes, we’re making different tradeoffs, optimizing for data apps and dashboards (more polished presentation) rather than ad hoc exploration in notebooks. So it’s more work to find and edit the code, but conversely it’s a more careful, deliberate process that allows code review, unit tests, continuous integration, etc. And we think that’s appropriate for data apps that are depended on by many people. But still, a view source link back to your source control would be nice, yes! reply EasyMark 12 hours agoparentprevI too appreciate this. It is so easy to turn javascript into a DSL that doesn't much look like vanilla javascript. Give me a great API anytime over a DSL except in some very specific cases. reply alanbernstein 12 hours agoparentprevThanks for highlighting this. Realistically, this is what will make me want to try it out. reply rmbyrro 15 hours agoparentprevIf more developers understood the value of using vanilla JS when appropriate, we would all be much happier. reply kepano 14 hours agoprevI appreciate the nod to \"File over app\"[1] in the announcement. It's so cool that a Markdown file with code blocks can be the source for complex data visualizations and dashboards. Interoperability of this kind makes me giddy. I played around with editing an Observable site from Obsidian and it works great[2]. [1]: https://stephango.com/file-over-app [2]: https://twitter.com/kepano/status/1758202572446581025 reply tophtucker 13 hours agoparentWe’ve talked about and shared your “File over app” manifesto so many times internally over the last few months. It’s one of those tweets that gets immortalized as the perfect crystallization of an ethos that we might otherwise have only been able to gesture at vaguely. It gives the ethos weight and clarity and credibility, and it’s such a relief to be able to point to it! I’m very grateful. —an Observable employee reply dleeftink 7 hours agoparentprevMy mind immediately went to how these Dasboards could be integrated in Obsidian, and seeing the `import` dependency graph reflected in Obsidian's graph view. reply xrd 16 hours agoprevI love Observable. And, this is a phenomenal approach, untethering Observable from observablehq.com. I'm so excited. It probably goes without saying that EVERYONE should have a blog, and this approach from Observable means journalists everywhere can now easily create a dynamic and information-driven blog. It isn't a coincidence that Observable came from a guy that did amazing data visualizations at the NYTimes. We are on the precipice of a major power shift back to journalists and away from dubious corporations, and tools like this enable that transition. (Shameless plug: Svekyll is going towards the same goal. Svekyll is a static site generator inspired by Jekyll. If you want to use Svelte in your blog, check it out. Svekyll bundles the incredible Apache ECharts so you can use echarts in your blog with a few lines of code (and no complicated build process). https://extrastatic.dev/svekyll/svekyll-cli. These are ideas I've been thinking about too.) reply simonw 15 hours agoprevThere's an almost bewildering amount of interesting ideas buried in this. Things like data loaders which are ANY script that can output data (as JSON or something else) to standard output. Markdown files with ```js blocks in that get executed. The reinvention of the core Observable notebook to avoid custom syntax. This is really big. reply tophtucker 14 hours agoparentYeah data loaders are like a UNIX pipe to a reactive notebook cell (?). There needn’t be any question of “do the data loaders support this or that”; it doesn’t even have a concept of “supporting” beyond supporting stdout… Still thinking through how to understand it myself!! reply skybrian 11 hours agorootparentData loaders seem like an interesting way to define a multi-language build system without having to write a makefile. Lots of build systems do this, but the boundaries between build steps often isn't as clean and uniform as having a single output per build step and relying on a file naming convention. It's not truly reactive if you have to do a build to make anything happen. But maybe that doesn't matter, as long as it's reactive during development? reply tophtucker 7 hours agorootparentYeah there are some open issues about more granular rebuilds and chaining data loaders. https://github.com/observablehq/framework/issues/638, https://github.com/observablehq/framework/issues/332 It’s kinda cool to think about the shearing layers of reactivity. Reactivity is what originally drew me to Observable. But the way notebooks have to be recomputed live for every viewer every time makes them feel silly for, like, a BI dashboard that changes daily at most. Like they only have one pace layer. Like they’re trying so hard to be _live_ that they can’t be _fast_! Idk. I guess even a chalkboard is reactive on the timescale of “someone noticing some information and telling it to someone who writes it down” lol. reply skybrian 5 hours agorootparentAnother interesting example: since Go packages use minimum version selection, publishing a new version of a package doesn't do anything right away. Someone has to notice it (perhaps reading a release announcement) and bump the version number on a dependency. Then, after testing, they might release a new version, which again, doesn't do anything until projects downstream from them decide to upgrade. That's deliberate, since they don't want packages to update their dependencies without testing them, and builds are supposed to be deterministic. So it seems like for cross-project data dependencies, there's a tradeoff between deterministic results and getting the latest data? If one project depends on a JSON file from another project, and the JSON changes, when do you want or expect to see the change? There needs to be a version history for changes to the external JSON file to get a choice in the matter. (Perhaps it's cached locally.) reply dleeftink 7 hours agorootparentprevScripting with hot-reload? reply dleeftink 53 minutes agoprevI've setup a codespace starter template that pulls in the required dependencies to start building dashboards with Observable Framework, right inside your browser. You can access the starter template here: [0]: https://github.com/dleeftink/observable-codespace reply ddanieltan 16 hours agoprevI'm super excited to try this out! Couple of questions since I see @mbostock active in the comments. 1. Is the flexibility of languages used in data loaders/backend going to eventually come to the front end/ui? Or will the paradigm always be bring-your-own-language for the data loading but build your dashboard with observablejs/observable plot? 2. Considering ObservableJS is supported by Quarto, can we look forward to Observable Framework integrated with Quarto too? Or is the fact that the latest Quarto version also featured Dashboards more of a competitor to Framework? 3. Saw some comparison to Evidence.dev in the comments. I saw some shades of similarity with the markdown focused dev experience too but I recall Evidence chose Apache Echarts for their main charting library. Any thoughts of the pros/cons of Echarts vs ObservableJS/Plot? reply kuatroka 5 minutes agoparent3. Apache echarts are much more interactive out of the box. The API is indeed clunky, but they’ve got all the chart type and all interactions you might need. IMHO, Plot in comparison, is very limited in interactivity and even chart types ( there are no heat maps or donuts). echarts have a huge example library with clear examples and though Plot has it too, the library is not thought out well. You might looks at an example in the Plot Library only to realize later that it’s a D3 example. On the good side, the API in Plot is much cleaner and easier to work with. reply cscheid 13 hours agoparentprev(disclosure: Quarto dev here). I'm a huge Observable fan. Speaking entirely for myself, this space is so important that I'm thrilled to have more activity rather than less. Quarto's great and Observable's great. I hope folks pick the tool that's best for their use case! reply an1sotropy 12 hours agorootparentI'm looking forward to learning more about which one makes it easier to see how various possible changes in the data are mapped to legible changes in the visualization. reply cscheid 11 hours agorootparent... sorry about the weird question, but do I know you in person? (there's a tiny chance your comment is specifically an obscure inside joke from a past life of mine, and I can't stop myself from taking the bait if so) reply mbostock 15 hours agoparentprev1. We don’t have immediate plans to bring other languages to the front-end — maybe TypeScript, but that’s just stripping annotations; maybe some WebAssembly. Our idea is to have a clear serializable “membrane” separating your back-end (in any language, running on build on your servers) from your front-end (in JavaScript, running on load in the client). Data loaders produce data during build, which gets handed-off to the client to render. Trying to do data processing on the client is often a frustrating and poor user experience. Likewise trying to render great interactive charts without web technologies is quite limiting! 2. I can’t speak to Quarto’s plans. Observable Framework is open-source so they might pick up some of this stuff. I look at Framework more as an alternative to Quarto than a complement. 3. As the creator of Observable Plot (and D3 before that), I’m a huge fan of visualization grammars! Apache Echarts is a chart typology, and while it’s got a lot of chart types in it, it has no overarching conceptual model of how to represent a visualization. And so it’s not very interesting. But “the proof of the pudding is in the eating” as I say in the post, so I encourage you to look at Observable Plot and decide for yourself if you like both the syntax and the resulting plots. I certainly do! Leland Wilkinson said it best: “If we endeavor to develop a charting instead of a graphing program, we will accomplish two things. First, we inevitably will offer fewer charts than people want. Second, our package will have no deep structure. Our computer program will be unnecessarily complex, because we will fail to reuse objects or routines that function similarly in different charts. And we will have no way to add new charts to our system without generating complex new code. Elegant design requires us to think about a theory of graphics, not charts.” reply apitman 5 hours agorootparentThat's an interesting quote. What is the difference between charting and graphing in this context? reply kuatroka 11 hours agoprevA couple of questions: 1. Let's say I got a Sqlite/Duckdb database file on my server. It's got multiple tables and some of them 100M to 150M records. I want to create a plot/table that would have a slider/filter to only bring and show a slice of data at a time. Since it's statically generated data, how is this interactivity achieved? All the possible facets of data filtered by which ever way will be generated? Won't it be huge and how long will it take to generates this static data or is there an actual call back to the server to the duckdb file (I assume it works with .duckdb file too?) 2. If Observable Framework provides the front-end, does it mean I can use any auth library if I want to create a web site with a log in and subscription options? 3. If it's a static web page, does it mean that at any time a user views a chart, they will also be able to go to the Dev Tools and download the file with data that's behind the viz? 4. When (if you can share of course) is the planned release of Plot's interactions: zoom, pan, interactive legend, brush? 5. Deployment - with big parquet, sqlite, csv files, it's impossible to do CI/CO through github or vercel and such. Will your hosting services offer an option to host those files and runtimes to generate them? Thanks reply tophtucker 6 hours agoparentGood questions. 1. It’s just JavaScript so you can fetch stuff dynamically too (see https://observablehq.com/framework/lib/duckdb). But yeah, only client-side. (Though see https://github.com/observablehq/framework/issues/234.) 2. Sure, it’s all open source, I bet you could make that work. Or `yarn deploy` to Observable and configure sharing there (though it wouldn’t let you charge others). 3. Yup. Which is part of the appeal of model of running data loaders at build time: you can query some private data and viewers would only be able to see the final result set. (The lack of something like this has always been a huge problem for Observable notebooks. You’d make some great query-driven charts and then couldn’t make it public without some awkward manual dance of downloading and re-uploading a file to a fork of the notebook.) 4. I wish I knew! It’s being tracked here https://github.com/observablehq/plot/issues/1711. Lately there’s been a lot more work on Framework naturally but now that that’s out… 5. Another good question. We’re definitely interested in tailoring it more to this sort of use case but lots is TBD! reply chrisjc 8 hours agoparentprevCame here with similar questions and Cmd-F \"DuckDB\". See the comment about \"data loaders\". Seems like a \"data loader\" would provide most of what you're asking about. I'm also thinking that a \"data loader\" combined with duckdb-wasm and arrow would be a pretty nice combination. I imagine that it might not be too difficult to switch two between two implementations of the \"data loader\" as needed. Switch between reading from a remote system (in your case DuckDB on a server) and DuckDB running locally in the browser (that can interact with its own remote or local data sources). edit: welp https://observablehq.com/framework/lib/duckdb reply recifs 1 hour agorootparentSee the example at https://huggingface.co/spaces/observablehq/fpdn where DuckDB is used both as a data loader (to download and digest 200GB worth of source data into a small 8MB parquet file) and on the client-side to allow the user to do live search queries on the minimized data. Server-side, we're using duckdb-the-binary, and client-side we're using duckdb-wasm. reply 77ko 10 hours agoprevThis looks amazing! I really like the clear seperation of loading/prepping data, and presenting it. Some requests: Add simple examples and more clarity to the publish docs. I assume most ppl would prefer to deploy via github actions[1], which the docs currently just link to a complex deploy file - can you please add some more documentation on this, or add an example of the simplest possible deploy file? Suggestion: is it possible to use a interface (like in vercel) to connect to a github repo and build/publish on changes? [1]: https://observablehq.com/framework/getting-started#deploying... reply j-pb 12 hours agoprevIf you play the history of Observable backwards you start with a company creating a static site generator for dashboards, which then struggles to find a market fit as it tries to bring datascience to middle management, to finally reach a focused, simple and elegant tool for exploratory programming, data visualisation, and interactive documentation in javascript. reply nextworddev 5 hours agoparentOk but is anyone paying for it? reply j-pb 3 hours agorootparentWe used to pay for 4 licenses, until they switched to the weird pricing schemes and the new editor targeted towards people with no programming experience. I really wish they would open source Observable 0.5, Pluto is currently the only other notebook left that has the flexible data-flow model at reasonable simplicity. reply RobinL 15 hours agoprevObservable is such an incredible, powerful and enjoyable tool. I use it heavily, including to power my blog. I love it, but I've always had a slight concern about needing to rely on the Observable notebook website. So this has really made my day. To give a sense of the kind of performant, statically hosted interactive content that has only really been within my reach since using Observable, here are some examples: Highly interactive vis: https://www.robinlinacre.com/visualising_fellegi_sunter/ Editable computations that flow through the document https://www.robinlinacre.com/computing_fellegi_sunter/ Multiple synced representations of data: https://www.robinlinacre.com/prob_bf_mw/ https://www.robinlinacre.com/partial_match_weights/ (half way down, under 'Understanding the partial match weight chart and waterfall chart) Of course, there are a huge number of additional examples: https://observablehq.com/trending but i think the whole thing makes much more sense to the end-user when embedded (sadly at which point they don't even know it's observable!) reply beefman 15 hours agoprevNo mention of math formatting but from the docs it looks like there is TeX support! https://observablehq.com/framework/lib/tex reply mbostock 15 hours agoparentAnd Graphviz (dot) and Mermaid, too! reply cheptsov 2 hours agoprevCongrats on the launch! Excited to hear that you go fully open-source with this! There is a certain need for great visualization tools that enable building apps. reply tetris11 3 hours agoprevI miss source loading D3 into a simple HTML page, and having D3 tutorials that were up to spec with the latest D3 release. Yeah Observable data pages look cool, but it really feels like excessive JS bloat for the features. I think I miss throwing a D3 viz together without having to load an entire framework library. reply recifs 2 hours agoparentYou can still use D3 the good old-fashioned way, as a standalone script. See https://d3js.org/getting-started#d3-in-vanilla-html for examples. reply meowtimemania 3 hours agoparentprev@observablehq/plot is what you're looking for if you want to have the same charts loaded via a script tag. https://observablehq.com/plot/getting-started#plot-in-vanill... reply 0cf8612b2e1e 16 hours agoprevSounds a bit like the “baked data” pattern. Which I think is a really good idea. I have long been toying with how to use Datasette to make a deliverable dashboard, so this is interesting. reply mbostock 16 hours agoparentYes! It first felt counterintuitive and constraining to prepare data ahead of time, rather than just loading whatever you want on the fly. But we’ve found this to be a great discipline in practice because it forces you to think about what data you actually need to show, and to shift as much of the compute to build time to reduce file sizes (through aggregation and filtering) and accelerate page load. And once you become accustomed to instant dashboards it becomes unthinkable to go back to slow queries. reply rmnclmnt 16 hours agoparentprevMe too, and that lead to developing the « datasette-dashboards » plugin[0]. I use this for my company where all the data is gathered by connectors scheduled in CI, storing data in Git, and triggering a SQLite db build and Datasette deployment. « BI as Code » if you will [0] https://github.com/rclement/datasette-dashboards reply pzmarzly 14 hours agorootparentHow often do you refresh the data (how often your CI runs)? reply farhanhubble 5 hours agoprevI love how much is possible with the Observable framework and support for libraries like d3.js. However many data apps cannot precompute their outputs. For example, a pipeline that extracts text from documents based on what a user queries, cannot precompute the results and any visualizations must be updated every time. The best hack to accomplish this seems to be rebuilding the app on each update. Or is there another solution? reply recifs 2 hours agoparentThe code in a Framework can do whatever you want it to do—it can load data on demand, call an external API, etc. Precomputing data is only an option, not an obligation. But even when you want things to be very interactive it is a good idea to minimize the data. Expose only the \"rows and columns\" that you need, and compress it as much as possible. This can be done in a data loader. For example, see the data app we deployed yesterday on hugging-face: its data loaders ingest a large source database (320 files totaling 200GB), and digests it into a single 8MB parquet file that we can then use on the page to \"live query\" 3 million newspaper titles and dates. https://huggingface.co/spaces/observablehq/fpdn reply rad_gruchalski 13 hours agoprevGetting started guide: https://observablehq.com/framework/getting-started. Looks very nice! reply lf-non 16 hours agoprevThe new direction seems very similar to what evidence has been doing for a while https://evidence.dev reply mbostock 16 hours agoparentYep, Evidence is doing good work. We were most directly inspired by VitePress; we spent months rewriting both D3’s docs (https://d3js.org) and Observable Plot’s docs (https://observablehq.com/plot) in VitePress, and absolutely loved the experience. But we wanted a tool focused on data apps, dashboards, reports — observability and business intelligence use cases rather than documentation. Compared to Evidence, I’d say we’re trying to target data app developers more than data analysts; we offer a lot of power and expressiveness, and emphasize custom visualizations and interaction (leaning on Observable Plot or D3), as well as polyglot programming with data loaders written in any language (Python, R, not just SQL). reply amcaskill 16 hours agorootparentOne of the founders of Evidence here. Thanks the kind words Mike - that means a lot coming from you. I think that distinction is right -- we are focused on making a framework that is easy to use with a data analyst skill set, which generally means as little javascript as possible. As an example, the way you program client-side interactions in Evidence is by templating SQL which we run in duckDB web assembly, rather than by writing javascript. Evidence is also open source, for anyone who's interested. Repo: https://github.com/evidence-dev/evidence Previous discussions on HN: https://news.ycombinator.com/item?id=28304781 - 91 comments https://news.ycombinator.com/item?id=35645464 - 97 comments reply vramana 15 hours agoparentprevThanks for sharing. Evidence looks pretty great! Git controlled BI reporting. reply rogue7 16 hours agoprevInteresting pivot from the Observable team. I loved observable and wrote a couple of notebooks, it worked great ! I'm gonna try Framework asap ! reply johnmorrison 11 hours agoprevThis is very cool to see! We've been building something very similar (in some regards, very different in others) in https://rysana.com/bundown Somehow ideas like this emerge in waves seemingly with no coordination, kind of like what happened when Calculus was first invented (Of course there's a lot of prior art here but it's interesting to see a specific jump towards polyglot single-file Markdown 'apps' and so on happen around the same time) reply one_buggy_boi 7 hours agoprevWhat would be a good design pattern to put these dashboards behind auth? I suppose since they're static files you could just serve them with something like FastAPI or Spring Boot and have your CI/CD refresh the static files throughout the day on shared storage? reply apitman 5 hours agoparentI'd recommend a reverse proxy and login server using \"forward auth\". I made a list of such login servers here: https://github.com/lastlogin-io/obligator?tab=readme-ov-file... reply a-ve 6 hours agoparentprevIf you're putting these behind a reverse proxy (nginx, etc.) you can just setup client certificate authentication by using your own locally generated CA or by using something like Vault for UI-based certificate generation. When you visit this site with a certificate installed on your device, it will authenticate successfully, and for those who do not have a correct certificate installed, a \"No certificate presented\" error will be shown. It's fairly easy to setup and there are multiple guides available for it. Here's one: https://fardog.io/blog/2017/12/30/client-side-certificate-au... reply mbostock 6 hours agoparentprevFor one, you can deploy them to Observable (with `observable deploy`) and we’ll provide access control. reply mrtimo 16 hours agoprevIt would be really cool if you guys supported Malloy. Maybe you already do? https://www.malloydata.dev/ reply mythmon_ 15 hours agoparentObservable engineer here. I haven't looked into Malloy much, but Framework's data loaders are very flexible. If you can write a script or binary that uses Malloy and writes to stdout, it can be a data loader. For example, although we use SQL a lot in our internal usage of Framework, Framework doesn't actually have any specific SQL support. We just use our database's normal bindings. reply chrisjc 8 hours agorootparentCan you link to the \"data loader\" API or perhaps even a \"data loader\" example implementation for something similar to malloy, duckdb, or any other DB/SQL data source/provider? Would love to see it, thanks in advance! edit: found it https://observablehq.com/framework/lib/duckdb reply mythmon_ 8 hours agorootparentThe docs for data loaders are here: https://observablehq.com/framework/loaders. The simple version is they are simply programs that write their output to standard out. Very Unixey. When those programs are referenced in client side parts of the JS, they are reactively run when in development, and prebuilt for deployment. I don't think we have any full examples of using a database yet, but we have written a bit about using DuckDB via its Node bindings here: https://observablehq.com/framework/lib/duckdb I imagine that either Malloy's CLI or its Python bindings would fit very well here. reply janice1999 13 hours agoprevAre there any similar projects that allow you to plot thousands or tens of thousands of datapoints and also allows the viewer zoom into time series plots? I'd love to have an in-browser matplotlib replacement. So far I haven't found one. Observable plots look static. reply omneity 11 hours agoprevThis is super cool! I’ve been looking for ways to integrate Observable with my blog posts and make them more interactive and engaging. This might just be it. Thank you and congrats on the release! reply jeffbee 16 hours agoprevI am totally psyched up to try this. Observable (1.0) has been a very effective outlet for my research. There is no other platform that could have hosted it and offered me the quick and easy tools to make persuasive visualizations. I was a little concerned when I heard some people got laid off from the company, but it seems like it is still going. reply nrjames 12 hours agoprevI love this and hope that a django-observable package comes along that makes it very easy to integrate and serve these static apps through a larger Django site. reply yodon 16 hours agoprevLots of good stuff here, but are you really naming your framework \"Framework\" (as in \"With Framework, you can build...\")? You do realize that naming only makes sense inside your own company, right? To everyone who uses it, it's \"a\" framework or \"Observable's framework\". No consumer of the framework is going to refer to it as \"Framework\" without ridiculous amounts of confusion resulting. reply alexgarcia-xyz 15 hours agoparentObservable has other open source libraries with similar \"generic\" names: Plot, Runtime, Inputs. When speaking generically, most people say \"Observable Plot\" or \"Observable Runtime.\" In projects where people already know about them, then I say \"Plot\" or \"Inputs\" without much fuss. I imagine most people will say \"Observable Framework\" when talking out in the open, and \"Framework\" on established projects. reply prakis 16 hours agoparentprevYes, it is confusing. It took me sometime to realize their product name itself is framework. reply renewiltord 16 hours agoparentprevIt's called Observable Framework one sentence before and on the product page. It's normal to write like this in a blog post. For instance, the Kubernetes deployments page uses the word \"Deployment\" doesn't say Kubernetes Deployment everywhere. It just says Deployment. I think introducing it like that is fine. You don't have to say Observable® Framework™ every sentence. That would be strange. reply nalgeon 16 hours agoprevAnd if you want a simpler tool for creating interactive docs, maybe try Codapi: https://codapi.org/ reply terpimost 16 hours agoprevWow guys. That is so cool! Thank you for what you do. This is a great example of high quality product! reply CJefferson 14 hours agoprevCan anyone with knowledge of both systems compare this to quarto for me? reply coolca 10 hours agoprevIt is so beautiful reply austinpena 16 hours agoprevI'm curious where this fits in relative to streamlit which I use heavily reply jwilber 16 hours agoprevThis is really a game changer for creating data apps. I loved observable, but convincing scientists with no js knowledge to try the platform was almost impossible. Markdown + language agnostic loaders seems like the perfect way to collaborate. Are there any plans to allow existing observable notebooks to be deployed? For example, a one-click “deploy” button? reply mbostock 15 hours agoparentThe Observable Framework CLI supports a `convert` command for downloading an Observable notebook and converting it to Markdown. E.g., `observable convert @d3/bar-chart` will download the notebook and save a bar-chart.md and alphabet.csv to your current working directory. (We did it from the command line so it’s easy for you to automate or batch-convert or refresh and keep things in sync.) You may have to make some tweaks to the code due to Framework’s vanilla JavaScript syntax, but we’ll work on making that more seamless over time. And you can `observable deploy` to deploy your app to Observable for sharing — though most often you’ll want to setup continuous deployment to keep your app up-to-date automatically. reply greenie_beans 15 hours agoprevthis is exciting. love observable. reply lloydatkinson 15 hours agoprevThere are simply too many tools and sites called Observable reply foolswisdom 17 hours agoprev [–] I really like this idea. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Observable has released Observable 2.0, an open-source static site generator for creating data apps, dashboards, and reports.",
      "The platform combines front-end JavaScript with backend languages to facilitate effective data communication within teams.",
      "Observable Framework is free, customizable, and can be hosted anywhere, solving the issue of slow-loading data by running data loaders during the build process for faster page loading times."
    ],
    "commentSummary": [
      "Observable Framework is an open-source tool for creating data apps, dashboards, and reports with features like real-time data updates and integration with external sources.",
      "The framework supports various purposes, including server optimization, web traffic control, and local development with version control.",
      "It prioritizes polished presentation but plans to add interactivity in the future, and supports data loaders in multiple languages and offers reactivity and data compression/filtering."
    ],
    "points": 536,
    "commentCount": 118,
    "retryCount": 0,
    "time": 1708009069
  },
  {
    "id": 39384731,
    "title": "Exploring the Evolution of Mac OS X and macOS Wallpapers in Stunning 6K Resolution",
    "originLink": "https://512pixels.net/projects/default-mac-wallpapers-in-5k/",
    "originBody": "Every Default macOS Wallpaper – in Glorious 6K Resolution Every major version of Mac OS X macOS has come with a new default wallpaper. As you can see, I have collected them all here. While great in their day, the early wallpapers are now quite small in the world of 5K and 6K displays. If you want to see detailed screenshots of every release of OS X, click here. If you are looking for Mac OS 9 wallpapers, this page is for you. Sponsored by Rogue Amoeba Rogue Amoeba is proud to continue our sponsorship of the 512 Pixels Mac Wallpaper Archive. We’ve been making amazing macOS audio software Aqua was the hot new thing. From recording anything with Audio Hijack to getting superior control over all the sound on your Mac with SoundSource, we have tools for all your audio needs. Visit rogueamoeba.com to learn about all our great utilities. 10.0 Cheetah & 10.1 Puma The first two releases of Mac OS X shared the same wallpaper. The sweeping blue arcs and curves helped set the tone of the new Aqua interface. Download 5K version. Download 6K version. 10.2 Jaguar Jaguar took the same Aqua-inspired theme but added some depth and motion to things. In my head, the trails streaking across the screen were from a set of comets. Download 5K version. Download 6K version. 10.3 Panther While Panther inflicted Macs everywhere with Brushed Metal, its wallpaper stayed on brand, refreshing the original 10.0 image. Download 5K version. Download 6K version. 10.4 Tiger Many consider Tiger to be the best “classic” version of Mac OS X. While that may or may not be true, it is my favorite Aqua-inspired wallpaper. Download 5K version. Download 6K version. 10.5 Leopard Complete with a revised, unified user interface and shiny new Dock, 10.5 broke the Aqua mold. As such, Leopard was the first version of OS X to break from the Aqua-themed wallpaper. It ushered in the “space era” of OS X wallpapers, which was used heavily in the new Time Machine interface as well. Download 5K version. Download 6K version. 10.5 Leopard Server The server version of Leopard server came with its own unique wallpaper that is a real treat: Download 5K version. Download 6K version. 10.6 Snow Leopard The “no new features” mantra for Snow Leopard didn’t ban a new wallpaper, thankfully. This starscape is still one of my favorites. The Server version isn’t bad either! Download 5K version. Download 6K version. Download 5K version. Download 6K version. 10.7 Lion Lion kept up the space theme, this time showing off the Andromeda galaxy. The space nerd in me likes the idea, but the execution of this one leaves dead-last on my list of favorites. Download 5K version. Download 6K version. 10.8 Mountain Lion Just like Snow Leopard before it, with Mountain Lion, Apple opted to clean up and revise the existing theme as opposed to changing directions for what would be a less-impactful release of OS X. Download 5K version. Download 6K version. 10.9 Mavericks Mavericks marked the beginning of Apple’s “California location” naming scheme for Mac releases. The wave depicted looks as intimidating as the ones in the famous surfing location. Download 5K version. Download 6K version. 10.10 Yosemite Yosemite brought another UI refresh to the Mac, making things flatter and more modern. The wallpaper ushered in a new era based on … well … mountains. Download 5K version. Download 6K version. 10.11 El Capitan Named after a breathtaking spot in Yosemite National Park, El Capitan was a clean-up year after 10.10. Download 5K version. Download 6K version. 10.12 Sierra More mountains. Download 5K version. Download 6K version. 10.13 High Sierra Even more mountains. Download 5K version. Download 6K version. 10.14 Mojave No more mountains! Mojave brought a new system-wide Dark Mode, and the OS shipped with two versions of its default wallpaper to match. Users could even have macOS slowly fade between the two background images over the course of the day. Download 5K versions: Mojave Day Mojave Night Download 6K versions: Mojave Day Mojave Night 10.15 Catalina macOS Catalina brought big changes to the Mac, including the ability to run iPad apps natively, opening the platform up to a much larger number of developers than ever before. Catalina shipped with multiple variants of its default wallpaper, and the ability to shift between them as time progresses throughout the day: Download 6K versions: Catalina Day Catalina Night macOS Big Sur This version of macOS is such a big deal, Apple changed the version number to 11.0. It will be the OS that brings support for Apple Silicon-powered Macs, and features a brand new design. Download 6K versions: Big Sur Colorful Day Big Sur Colorful Night Big Sur Day Big Sur Night macOS Monterey This version of macOS builds on Big Sur, bringing Shortcuts and a range of features that are also part of iOS and iPadOS 15. As of the first beta, Monterey does not include any new nature wallpapers as previous releases has. Download 6K versions: Monterey Light Monterey Dark macOS Ventura macOS 13 brings big changes to system apps like Mail and Messages, as well as a new multitasking user interface named Stage Manager. Download 6K versions: Ventura Light Ventura Dark macOS Sonoma macOS Sonoma brings several goodies, including the ability to use interactive widgets on the Desktop, enhanced video conferencing, updates to many core apps and the inclusion of stickers … for some reason. Download 6K versions: Sonoma Light Sonoma Dark Become a member of 512 Pixels. Support projects like these, receive exclusive content in the monthly newsletter and enjoy advanced screenings of my YouTube videos.",
    "commentLink": "https://news.ycombinator.com/item?id=39384731",
    "commentBody": "Every default macOS wallpaper (512pixels.net)461 points by jorgesborges 17 hours agohidepastfavorite145 comments rezmason 14 hours agoDon't forget the OS 9 wallpapers: https://512pixels.net/projects/mac-os-9-5k-wallpapers My favorites among these are the gradient-rich desktops that dropped in Mac OS 8.5 back in '98, like those UFO ones. That's when the OS gained support for icons with 24-bit color and 8-bit masks, which are the direct ancestors to today's 1024x1024 32-bit app icons. Perhaps to commemorate this full leveling up of the classic Mac desktop to millions of colors, Apple hired a small team of designers to custom make the UFO, Capsule and Tub desktop pictures. Screen sized gradients between two relatively close colors almost always land in the sandbar of banding or dithering in order to quantize all those subtle variations to the limited color depth. But these desktops do a beautiful job at avoiding that. I'm not sure, but I think they achieved it by color grading a zero-to-255 3D render with a high bits/channel ratio in Photoshop, tuning the grade and quantizing to 8 bits per pixel from time to time as a sort of gamut warning. Any problematic areas could then be \"buffed out\" with careful blend mode shenanigans on the boundaries. reply djhn 13 hours agoparentWow, I always thought there was something strange about those gradients, and you’re right! The distinct lack of banding despite the limited variation in hue! reply hcarvalhoalves 15 hours agoprevThese were the best ones IMO: https://wallpapertag.com/img/eyJpdiI6ImlFY2hqYStNSno4Z0dBcGY... https://wallpapertag.com/img/eyJpdiI6IlZ2N1R4bVpXYm9DVTRPS3l... reply Sunspark 13 hours agoparentDebatable. They're visually too busy and noisy to see all the time. reply Someone 13 hours agorootparentI think laptop users rarely see much of their wallpaper, and that’s a significant fraction of users. You could even argue that, if you see your wallpaper close to “all the time”, your monitors are larger than you need most of the time. reply MSFT_Edging 11 hours agorootparentJokes on you, I give my terminals a slight opacity so I can see the wallpaper all the time. Sometimes I'll keep an empty workspace up just to declutter and focus on something on the other monitor. reply StefanBatory 58 minutes agorootparentSame - I always keep some opacity on my windows and I use gaps on i3 It's not necessary, I could as well set black wallpaper and no gaps, but I like it so it's good enough excuse ;) reply nomel 5 hours agorootparentprevI agree completely. The best wallpaper is pure black. I haven't used anything other than black in ~20 years. reply jacurtis 2 hours agorootparentblack wallpaper will be awesome for battery life once OLED laptop screens come out reply post_break 14 hours agoparentprevThe fish one on my 2006 white plastic macbook takes me back. reply data-ottawa 8 hours agorootparentFor me it's the grass one, and creating Adium themes to complement it! reply yreg 10 hours agorootparentprevIt was also used in many marketing materials for the original iPhone. (Although the default wallpaper was the Earth one, I believe.) reply xattt 7 hours agorootparent9:42 reply alltrue1 13 hours agorootparentprevStill have mine and that is definitely my wallpaper reply marpstar 11 hours agoparentprevI worked at Best Buy circa 2005 and we had a single Mac Mini on the floor that had the fish wallpaper and it always drew me in. I had no interest in Macs at the time, but there was something alluring behind that wallpaper. reply lldb 6 hours agoparentprevI noticed they recently brought back the clownfish as a built in option on iPhone! reply justworkout 4 hours agoparentprevThese were the exact two I had in mind. I never used default wallpapers aside from these two. reply jrmg 6 hours agoparentprevI love the grass backdrop, but that folded over tip near the center-top always jumps out at me. reply xanderlewis 13 hours agoparentprevThe second one. Yes! reply xattt 12 hours agorootparentThe lore behind the second one was that it was taken by Steve Jobs. I remember seeing it on the Leopard keynote. It was glorious with the translucent menubar that ditched the rounded corners. reply vanilla_nut 16 hours agoprevI wish more OSes would work with independent photographers to compile a set of beautiful wallpapers. It used to feel easy to find good wallpaper online, but nowadays, especially with macOS's hiDPI settings and my personal desire for #000 true black wallpapers to hide notches and camera holes, it can feel very difficult. Search engines don't yield good results for 4k or 5k images, and a lot of the hi-res wallpaper subreddits have disappeared since their API debacle. I source solid wallpapers from a couple of OSes for use in macOS: * https://stories.gregannandale.com/raspberry-pi-desktop-image... * Ubuntu has some default hits (and misses): https://www.omgubuntu.co.uk/every-ubuntu-default-wallpaper * Ubuntu hosts a wallpaper competition (most years) for photographers all over the world: https://ubuntu.com/blog/winners-of-the-21-10-wallpaper-compe... * and here's a somewhat-outdated repo of wallpapers from a bunch of Linux distros: https://github.com/LinuxKits/Distro-wallpapers -- I'm especially fond of the Elementary OS images. reply keane 34 minutes agoparentYour comment took me back. 20 years ago the best place for this was InterfaceLIFT. I'm amazed to find they're still online today: https://interfacelift.com/wallpaper/downloads/date/any/ reply bbrks 13 hours agoparentprevTry searching at somewhere like wallhaven.cc[1], which aggregates wallpapers with good tagging, colour, size and ratio-based searches. A lot of the wallpapers there come from other sources like Flickr, interfacelift, Reddit, 4chan (for better or for worse, /wg/ isn't too bad), or just direct uploads. I wouldn't say credit is preserved particularly well at all times, which is a shame, but it is just a reverse image search away usually to find the original. [1] https://wallhaven.cc/ reply xattt 7 hours agorootparentA lot of amateur wallpapers have this weird cliché aesthetic. It’s the same two-thirds framing, and (at least to me) some intangible form of unresolved tension or a general feeling of the photographer trying too hard (vs an impromptu shot). reply xanderlewis 12 hours agorootparentprevI get all of mine from https://unsplash.com. reply edu 11 hours agorootparent+1 to unsplash reply jwells89 12 hours agorootparentprevAnother vote for wallhaven, have found several high quality 5k and 6k+ desktop pictures there, as well as some for odd aspect ratios (e.g. 5k portrait). Its predecessor Wallbase was also great. One thing I appreciate is that its users do a decent job of tagging images so it’s easy to find all the work of a particular artist or location. reply mmsc 3 hours agoparentprevhttp://boards.4chan.org/wg/ reply AlexAndScripts 11 hours agoparentprevIt's infuriating finding an excellent wallpaper, only to find that it's 900 pixels wide or \"4k\" with so much compression it looks worse than uncompressed 720p. That and the grotesque photoshops that fill the results when looking for space wallpapers. On the plus side, Tineye can be quite helpful for finding things in their original size. And I only use 1080p! reply gaetgu 8 hours agorootparentRe: space wallpapers My favorite source for all space-related pictures are the Apollo flight journal photography archives[1]. I’m not sure if there’s a better resource, as-is you have to click through to see a higher resolution version to check if the picture is even in focus, but honestly that adds to the fun of it :) [1]: https://www.nasa.gov/history/afj/ap08fj/a08-photoindex.html reply mattlondon 9 hours agoparentprevFWIW my windows 11 laptop I use has a new high quality wallpaper every day. I don't know where it gets the images from, but many are pretty cool even if they are a bit \"too HDRy\" at times. reply ambigious7777 8 hours agorootparentMight it be Microsoft Bing's wallpaper[0] app? [0]: https://www.microsoft.com/en-us/bing/bing-wallpaper reply luuurker 14 hours agoparentprevTo \"hide\" the notch, try Top Notch: https://topnotch.app/ reply Kwpolska 14 hours agoparentprevIf you need to hide the dumb notch, I’d take my nice wallpaper, scale it down to the exact resolution, and just add a black bar as high as the menu bar is. This can be a bit ugly when the wallpaper appears without the menu bar, but it’s a fine solution nonetheless. (I had to do this in Big Sur, since the OS thought my wallpaper works best with a black text on the menu bar, which wasn’t actually too readable.) reply dylan604 15 hours agoparentprev> I wish more OSes would work with independent photographers to compile a set of beautiful wallpapers. Why though? Why should someone be subjected to all of this extra cruft when you can just find the images from websites? As long as Google image search exists, people will find whatever images they want to use. If you're thinking an OS vendor would do proper licensing, that's a nice thought, but the vast majority of people using custom wallpapers don't care about it. reply danans 15 hours agoprevTangentially, I find wallpaper to be fascinating as it's one of the few aspects of desktop UX that is basically still 100% open to self-expression. For functional reasons, every other desktop UI surface has converged with only a few minor variations. But the static desktop OS background - perhaps because it has no inherent functional purpose and remains covered most of the time - remains as a canvas. reply jwells89 12 hours agoparentI leave at least a few pixels around the edges of windows to let my desktop picture show through, partially because that’s some of the little remaining customization but also because having my screens filled to the brim with windows negatively impacts my mood, as silly as that sounds. The desktops I choose usually carry a positive and/or calming vibe and that’s felt during my workday if some of it can show through. reply nullhole 15 hours agoparentprev> the static desktop OS background Eons ago, there was a (paid) 3rd-party program for MacOS Classic that would give you a slideshow desktop background. The images were of the Golden Gate bridge, and were a timelapse over the course of a day. The changes were (afair) synced to your local solar time, so 'sunset' in the desktop background would line up with your local sunset. I'd have to search to find the name of the program, but I kind of wish I had it back. reply cwizou 13 hours agorootparentTo be fair, most built in wallpapers in macOS do have a day/night version (for example Sonoma), or multiple versions with sunrise/day/sunset/night (Ventura, Monterey, Big sur). Apple does call them Dynamic backgrounds and they will switch automatically during the day. Also, I hate to do this but if I'm allowed, tinniest plug, I do maintain a screensaver project for macOS that does video both screensaver and wallpaper integration with solar time adaptation : https://aerialscreensaver.github.io (the default download will give you the app that does the wallpaper integration). reply lgl 15 hours agorootparentprevWell, it's not for MacOS, but software to run animated wallpapers exist for Windows. One example is the very popular WallpaperEngine [0]. Another cool one (and open source) is Lively Wallpaper [1]. Selfless plug: I've also developed and released LumoTray [2] which is a wallpaper/screensaver manager for windows with some other extra features but without any animated wallpapers except slideshows as I still find it a bit of a resource waste for something that I rarely see. [0] https://www.wallpaperengine.io [1] https://www.rocksdanister.com/lively/ [2] https://lumotray.com/ reply p_l 11 hours agorootparentI think ActiveDesktop still works, too reply jwells89 12 hours agorootparentprevThere was one of these apps for early versions of OS X too. I’ve searched for it several times, but as far as the web is concerned it never existed. Would really like to find it because its default desktop picture was pleasant (during the day, a blue sky over a field of flowers if I recall correctly) and it would be nice to see it again. Sadly a lot of early-mid-00s Mac shareware like that has seemingly vanished. reply dylan604 15 hours agorootparentprevIn classic Apple fashion, that's built in to the OS now. reply squiffsquiff 11 hours agorootparentprevCurrent versions of MacOS allow you to have a slideshow for your wallpaper reply ruined 17 hours agoprev(admirable) these images did incredible psychic damage to kde designers i used the catalina bg until late last year, when they started shipping the former appletv video backgrounds as the default, because it was just so good. seriously, after that on a 5k display, i thought i would never enjoy another desktop background reply neoberg 48 minutes agoparentYears ago in one of my previous jobs, we started to have issues with the internet connection multiple times a day. After a couple of days someone noticed that the issues happen whenever I go out for smoking. When they first introduced those aerial videos for Apple tv, someone made a screensaver out of them for MacOS and I was using that. It turns out whenever I went to smoke, my screensaver would activate and choke the network with 4k (5k?) glory. reply _benj 16 hours agoparentprev> (admirable) these images did incredible psychic damage to kde designers made me chuckle :-) But for real, there is something about a good wallpaper, at least for me, the wallpaper being the first thing I set on a new linux install. I fully believe that a solid default wallpaper can help with desktop manager adoption (i.e. kde, gnome, xfce4), at least for the bohemians types like me! reply dylan604 15 hours agorootparent> the wallpaper being the first thing I set on a new linux install For me, that would be the last time I ever see it. I have so many windows open providing me quick access to whatever I need without flipping spaces or whatever, that I just never see the desktop. It's just one of those things that over time of using computers, I just don't care about it any more. I don't begrudge anyone that does, but it is just one of those funny things one realizes how time changes one's outlook reply archargelod 6 hours agorootparentprev> the wallpaper being the first thing I set on a new linux install That's something I also always do. Even though I use i3 with 100% opaque windows (transparency is ugly and distracting IMO). I could only see wallpaper after startup and maybe 2-3 times during the day if I'm switching from my usual workflow. But for some reason I always set the background. Perhaps an old habit from Windows XP days (Autumn is the best XP wallpaper, fight me). reply Affric 12 hours agorootparentprevDo you have a recommendation for a good place to source wallpapers? With the photography it’s one of the things Apple get so right about UX. reply SSLy 11 hours agorootparentunsplash perhaps? reply pkaye 16 hours agoparentprevI don't use KDE but recently came upon some wallpapers on store.kde.org that I really liked. Particularly the Ketsa Color ones. https://store.kde.org/browse?cat=299&ord=latest reply ChrisMarshallNY 17 hours agoprevThe one that mystifies me, is why Apple pulled their original Dubai At Night screensaver[0]. [0] https://www.facebook.com/watch/?v=766810966790684 (This seems to be the only place to find it online). reply rgovostes 16 hours agoparentI was in a room of Apple TV engineers when the screensaver of I-110 in LA came on. Everyone agreed that it caused mild anxiety. I'm glad I don't see it in the rotation anymore. https://bzamayo.com/watch-all-the-apple-tv-aerial-video-scre... reply ravetcofx 16 hours agorootparentI don't know why anyone would want to look at gross car dependent hell. Not something to be in awe of reply pimlottc 15 hours agorootparentprevThe videos on this page don't work for me (tried Chrome and Firefox) reply zbirkenbuel 14 hours agorootparentIt links off to `https://sylvan.apple.com/` which has a name mismatch cert error. If you follow the url in the console (and ignore the cert error) you can download it. Not super convenient but there you are. reply rvnx 14 hours agorootparentprevhttps://sylvan.apple.com/Videos/comp_LA_A005_C009_PSNK_ALT_v... reply Affric 12 hours agorootparentprevWeirdly I that always happened to me and I thought I was the only one. reply Gigachad 11 hours agorootparentprevIt's a beautiful recording of a dystopic society. reply viraptor 3 hours agoparentprevThat's weird, it immediately made me think of the Genshin impact loading screen. https://youtu.be/rBnfA4pXw6U reply mig39 17 hours agoparentprevI'd take a guess and say that Dubai is one of those places that's a bit paranoid of aerial imagery? Was this filmed with a drone or helicopter? Is it possible the right \"permits\" weren't obtained before flying over the rush hour traffic? reply ChrisMarshallNY 16 hours agorootparentI have no idea. It’s an awesome video. I have a couple of friends that used to work for Apple, and neither one has any idea why. reply 10729287 16 hours agorootparentCould something be copyrighted here ? Eiffel Tower isn't, but lights are : https://www.toureiffel.paris/en/business/use-image-of-eiffel... reply madeofpalk 16 hours agorootparentprevThere's still a daytime top-down Dubai screensaver video on Apple TV I believe. reply randgoog 16 hours agorootparentMy Apple TV shows downtown LA. reply madeofpalk 16 hours agorootparentLooks like there's five active Dubai screensavers. The one parent was talking about is missing. https://bzamayo.com/watch-all-the-apple-tv-aerial-video-scre... also https://aerial-videos.netlify.app/ https://sylvan.apple.com/Videos/comp_DB_D011_C010_PSNK_DENOI... https://sylvan.apple.com/Videos/comp_DB_D008_C010_PSNK_v21_S... https://sylvan.apple.com/Videos/comp_DB_D002_C003_PSNK_v04_S... https://sylvan.apple.com/Videos/comp_DB_D001_C001_PSNK_v06_S... https://sylvan.apple.com/Videos/comp_DB_D001_C005_COMP_PSNK_... Looks like they're hosted on a domain with invalid certificate, so your browser might take a bit of convincing to load them. reply randgoog 10 hours agorootparentThank you for these! I think I'll have to enable a setting on mine to get the other screensavers. reply ace2358 14 hours agoparentprevI thought you could pick that categories in the settings, I swear I turned off the city ones cause I hate the city and I don’t live i. A city. reply cwizou 13 hours agoparentprevThe files are still available in both 4K and 4K HDR versions, I still have them by default in Aerial if you miss them. reply pompino 39 minutes agoprevThe 10.4 wallpaper brings back some nostalgia for me. It was the first time I could afford to buy a new laptop and I splurged on the 06 core duo macbook pro. reply johnbehnke 17 hours agoprevThe macOS screenshot library from Stephen is also excellent: https://512pixels.net/projects/aqua-screenshot-library/ reply fumar 17 hours agoparentIntense nostalgia. I remember my updating my MacBook from Tiger to Leopard and being inthralled with the new OS welcome video. It was a powerful feeling like a genuine leap was made after rebooting and new powers unlocked. 10.3 used Rokysopp's Eple, and I still love that song and album. reply xattt 16 hours agorootparentThe Welcome videos were technological showcases. Where else were you going to see 1080p videos in 2005-2008? reply vvillena 15 hours agoparentprevLooking back at the 10.4-10.7 era, I really miss those app icons, they were so easy to tell apart from each other just from shape. The rest of the design language was also a marvel in usability, it was so clear what everything was and how to interact with it. reply mostlysimilar 16 hours agoprevThey're beautiful, but a small tangent... the latest macOS has a bug that repeatedly reverts the wallpaper to the default whenever I unplug/plug my external monitor and it's driving me crazy. reply jwells89 16 hours agoparentI think what’s actually happening here is that spaces have separate desktop picture settings between displays. I noticed this a few days ago when moving a space from one monitor to the other and seeing its desktop picture change. Moving the space back to the original monitor restored the desktop picture. Not sure why it’s this way, kind of an odd choice. reply mostlysimilar 15 hours agorootparentI think it's a deeper issue than that. I shouldn't have to set the wallpaper back both when I plug in and when I unplug. reply pixelHD 16 hours agoparentprevHappens to me too. I use a display link'd dell dock from work, with 3 monitors. Every few times i plug it in, the wall papers revert, and the wallpapervideoextension process starts soaking up ram and cpu cycles (I dont use video wallpapers at all, just static images from my folder as wallpapers everywhere). I've made it a habit to check the activity manager everyday after I plug in the mac, and kill that process if its taking up too much resources. reply cwizou 12 hours agoparentprevSonoma did change the way wallpaper (and screensavers) get integrated (preferences have moved in an unusual place/preferences format too) which may be the root cause of this (although I admit I never hit that precise bug). Are you using classic images or some of the built in videos ? reply mostlysimilar 12 hours agorootparentIt always defaults back to one of the new animated ones, and I always manually set it back to the solid black color option. reply cwizou 11 hours agorootparentIf you are willing to try something, I would suggest an image (of your solid black color) instead. Because of how the new system work, I wouldn't be surprised the bug is limited to those solid color backgrounds (which are handled quite differently for historic reasons, and it could very well be why you get the error). The new wallpaper system is a bit of a mess, and solid colors have always been treated weirdly in their preferences. reply cmiller1 17 hours agoprevHere's an album containing all of the built in wallpapers in every version including for the classic Mac OS https://photos.google.com/share/AF1QipNNQyeVrqxBdNmBkq9ILswi... reply Bondi_Blue 16 hours agoprevA few photographers recreated some of them: https://petapixel.com/2019/09/16/this-photographer-trio-recr... They also created one for Monterey since it didn’t ship with exclusive landscape photography: https://www.techradar.com/news/photographers-make-their-own-... reply yrro 17 hours agoprevHere are some ones from MacOS 7: https://osxdaily.com/2018/01/01/classic-mac-os-tiling-wallpa... reply jandrese 16 hours agoparentEven more fun was the fact the wallpaper widget had a little pixel editor built in that let you make your own tiling pattern. I seem to recall that it updated the desktop in realtime as you changed the pixels so you always knew exactly what your pattern looked like tiled. reply 101008 16 hours agorootparentOh, memory unblocked! Didn't Windows 98 had something similar? It could be Win95 but I think it would be too much for that time, and for XP we already had background images in \"good quality\". reply jandrese 16 hours agorootparentI don't think Windows ever included anything like it with the OS. Windows 95 switched to having a giant JPEG background for the wow factor. Certainly there could have been a third party program that implemented that functionality, but I don't think Microsoft ever shipped it with the OS. Maybe as one of those optional fun pack things they used to offer? reply fourteenfour 14 hours agorootparentWindows 3.1 and 2000 definitely had a pattern editor. I think it was removed in XP. reply mattl 16 hours agoparentprevSystem 7... it didn't become Mac OS until 7.6 or something, and then Mac OS 8 came out very soon after that. reply MenhirMike 14 hours agorootparentAlso conveniently made sure that clone manufacturers (who only had a license for System 7) didn't have a modern Mac OS anymore. reply mattl 9 hours agorootparentRight except that one clone maker they bought IIRC? reply Waterluvian 17 hours agoparentprevRepeating bears in overalls is all I can see when I think System 7 desktop pattern. reply jwells89 16 hours agorootparentFor me it’s the grass, stones, and star patterns. They look way too busy on modern displays but at 640x480 or 800x600 they weren’t too bad. reply scq 8 hours agoprevIt's not mentioned on the page, but at least 10.0 to 10.8 are AI upscaled -- you can tell from the artifacts when looking at the image closely. I don't think it's reasonable to call this an \"archive\", as the link does, when the images have undisclosed changes to them and are clearly not the original files :/ reply Retr0id 7 hours agoparentThank you for saying it, undisclosed \"enhancements\" like this just remind me of the botched Ecce Homo painting restoration. A request to the world: If you're going to post an \"enhanced\" version of something, at least share the original too. reply Erazal 9 hours agoprevI'm obsessed with having a clean desktop, and beautiful wallpapers. Until recently, I used a neat little app for MacOS called Artdiario [1] that would update my wallpaper every day with a beautiful piece of art and I LOVED it. \"Used to\" because it looks it's not updated anymore since around 2 months :( Was thinking of re-creating the same \"open-source\" version of it, that would pick and show art from museums around the world every day [2]. Would some of you be interested? And if by chance you're reading me Jimmy - I love the app and would be happy to help maintain / curate it! [1] https://www.artdiario.com/ [2] a ton of museums provide free access to their art, such as the National Gallery of Art - https://www.nga.gov/open-access-images.html reply hisnameisjimmy 8 hours agoparentYo I would love the help to maintain/curate. A combination of the holidays and a really aggressive start to the new year at work made me fall off the update wagon. Email me and we can setup a time to chat. Edit: This was really nice to see/hear. Thank you for appreciating this publicly! reply watersb 9 hours agoprevYou can run screen savers on your Mac desktop (wallpaper), buy running the \"ScreenSaverEngine\" with the \"-background\" option from the command line. The executable is inside the screen saver application package. cd /System/Library/CoreServices/ScreenSaverEngine.app/Contents/MacOS ./ScreenSaverEngine -background (Earlier versions of macOS have the app under /System/Library/Frameworks/ScreenSaver.framework/Resources ) reply mvexel 16 hours agoprevThere is a link at the top for pre-OSX wallpapers. There was one in MacOS 7 or 8 that was called \"platte pinda's\" in Dutch meaning \"flat(tened) peanuts)\". That name mystified me at the time. Googling it now, there's only one result for that phrase, completely unrelated. Am I making this up? reply nrabulinski 15 hours agoprevTo me leopard is the most iconic. In my head it’s the wallpaper of modern macOS. I still remember back in the day that was the first thing I downloaded when I tried to make my Vista PC look at least a little bit like a Mac :-) reply nlunbeck 14 hours agoparentAgreed, it felt like such a major leap in modernity from the Aqua wallpapers. I still think of it as the definitive 2000s Mac OS X wallpaper, it really was everywhere in no way any of their wallpapers have been since. It was like the Bliss counterpart to Mac OS X reply kccqzy 15 hours agoparentprevTo me the default wallpaper on Tiger is the most iconic. I'm probably biased because Tiger is the first version I used (on a borrowed computer!). reply chungy 2 hours agoprevThose 10.0-10.4 wallpapers remind me a lot of wallpapers I made with Fyre back when I ran Windows 95 as a primary. reply zamadatix 16 hours agoprevThese seem to be upscaled, does anyone know where to find a collection of the original image files (not scaled or recompressed)? reply Ezhik 16 hours agoprevI miss pre-Yosemite vibes and Aqua's skeuomorphic iteration. An elegant design language, for a more civilized age. reply concinds 14 hours agoprevJust got a MacBook Air from the store, latest Sonoma 14.3.1, and the default wallpaper was the photorealistic one (“Sonoma Horizon”), not the abstract one. reply divbzero 13 hours agoprevThis is the analogous website with every Apple TV aerial screensaver: https://bzamayo.com/watch-all-the-apple-tv-aerial-video-scre... reply davidhariri 15 hours agoprevLouie Mantia has colored, re-rendered versions of the 10.0 Cheetah Wallpaper that include Dark Mode versions. They are great: https://lmnt.me/blog/wallpapers/ reply alltrue1 17 hours agoprevTiger is just so nostalgic reply jsz0 12 hours agoprevI'm not a big fan of any of the modern macOS or iOS wallpapers. They're so busy it's hard to even read text labels on top of them. My goto background for many years was Leopard Server but it was eventually replaced by the Linen tile texture that IIRC wasn't a default wallpaper choice but could be copied out of the system folder. reply dredmorbius 7 hours agoprevI'd stumbled across this site just recently after realising that the MacOS Monterey upgrade apparently deletes the Yosemite wallpapers. Which is quite unfortunate. reply marsissippi 12 hours agoprevSo cool! I made this thing that breaks down each image by fraction of each color used https://www.julyp.com/shared/018dae67-9ec0-7191-bd9f-7fe9c85... Looking at it like a source of color palettes, I really like Venture more... reply BjoernKW 14 hours agoprevThe Catalina one always used to remind me of a certain island somewhere deep in the Caribbean. Seems like I'm not the only one: https://www.reddit.com/r/MonkeyIsland/comments/dgwm03/the_ne... reply Sunspark 13 hours agoprevNot a critique of MacOS here, but generally stock OS bundled wallpapers for any device are always so generic. Probably a lot of effort goes into picking ones that offends the least amount of people, hence the trend in recent years of just colours and shapes. Only the colour-blind would be offended by those. reply lizardking 12 hours agoprevStrong nostalgia for this one https://512pixels.net/downloads/macos-wallpapers-thumbs/10-2... Takes me back to my dorm room on my 13-inch iBook. reply geon 14 hours agoprevI kind of miss the original aqua white striped theme: https://miro.medium.com/v2/resize:fit:720/format:webp/1*Xwuj... reply globular-toast 1 hour agoprevI remember when having a wallpaper was a big deal. I have a few screenshots of my desktops over the years and they do bring back memories. But I've used a tiling window manager for the past 5 years or so and there's no point having a wallpaper. I consider it a waste of screen space now. reply Thrymr 16 hours agoprevBeyond the defaults, there were 7 different wallpapers available in 10.15 (Catalina): https://9to5mac.com/2019/09/29/macos-catalina-wallpapers/ reply Kehvarl 14 hours agoprevMy last mac was a Powerbook g4 12 inch with OS 10.3 Panther, but for some reason I clearly recall the 10.0 wallpaper being the one it came with and the one I stared at for years. The proper 10.3 wallpaper doesn't look familiar at all. reply bredren 16 hours agoprevTangentially related, my pal had a photo similar to the Andromeda in macOS 10.7 Lion licensed via 500px->Getty Images and it was used on Colbert last night: https://i.imgur.com/wtnLpt8.jpeg reply binarymax 15 hours agoprevThe Catalina wallpaper threw me off guard when I first saw it. It looks exactly like a Bryce landscape I made in the late 90s. I spent some time trying to find it in my data archives but alas it is likely lost. reply Yhippa 14 hours agoprevI can remember eras of my life gone by with these wallpapers. reply zgs 7 hours agoprevI was far more used to the MacsBug screen of despair. reply uticus 13 hours agoprevWhat was the one with rotating windmill-like propeller geometric shapes? Or maybe that is a screensaver I'm thinking of... reply JoshGlazebrook 15 hours agoprevCan we do this with iOS wallpapers too? I still have fond memories of those fish from the very first phone. They brought it back in iOS 16 thankfully. reply rickreynoldssf 15 hours agoprevI still use a background tile from MacOS 7.5. I guess that makes me reallly old and a bit spectrumy reply dbtc 15 hours agoprevA change from abstract to space after 2005. A change from space to earth after 2012. And back to abstract in 2021. reply BizarreByte 15 hours agoprev10.3 and 10.4 were the best ones and I still use one of those two to this day. reply felixding 7 hours agoparentSame! reply wk_end 17 hours agoprevEverything up through 10.6 makes me feel indescribably warm and fuzzy. I don't like Steve Jobs very much as a person, and I don't quite buy the myth that he was as much of a unique genius as some people believe, but...is it a coincidence that 10.7 marked the end of the (second) Jobs-era at Apple? ...or maybe it's just nostalgia. reply jwells89 16 hours agoparent> Everything up through 10.6 makes me feel indescribably warm and fuzzy. 10.2/10.3/10.4 are the ones that do it for me. Spent way too much time on my Macs through those years, through which I frequently used the default desktop pictures because they were so smooth and nice to look at, and each OS X release was nicer to use than the last which made for positive associations with each. 10.5/10.6 were good too, but I found the default desktops on those too busy and usually used something else. I also typically used custom themes by way of Shapeshifter[0] because I found the gray metal look of those releases too dark and modded my dock with themes found on MacThemes. As a result the default 10.5/10.6 desktops aren’t emotionally evocative for me. I do however miss the 10.5/10.6 implementation of virtual desktops, which gave you a 2D grid to place desktops on instead of just a line. [0]: https://apple.fandom.com/wiki/ShapeShifter reply freitzkriesler2 12 hours agoprevI forgot how much I missed those blue cones. This and bliss put me in a wicked nostalgic mood. reply Lammy 12 hours agoprevSee also, for the other (non-default) Mac OS X walls: https://macintoshgarden.org/apps/macos-desktop-pictures reply imwillofficial 8 hours agoprevThings brings back so many great memories. I got into computing just as OS X launched. I installed every version with great anticipation. A ritual with my Mac geek friends every year. I feel we have lost that excitement in todays world. reply mattl 9 hours agoprevMeanwhile I have the same generic blue background from Rhapsody still on all my devices. reply runlevel1 4 hours agoparentAs in Mac OS X before it was Mac OS X? That Rhapsody? reply chris_wot 10 hours agoprevThe default wallpaper for Sonoma for me has been an interactive image of what looks like wine country in France? reply stbtrax 1 hour agoparentSonoma is wine country in Northern California reply avereveard 16 hours agoprevThe copyright claim from apple will be legendary reply david422 15 hours agoparentI'm curious about this. Somebody pulls a bunch of images from Apple and hosts them on their site. Surely this runs afoul of something. I have a small site that allows some user uploaded content, and I get random notices that threaten legal action unless I buy license (for users that have uploaded content from wherever). My response is just to take them down. reply justinzollars 16 hours agoprevThe California thing is kinda played. We need a new theme. reply Theodores 16 hours agoprevEven if you never use Apple Veblen Goods and have no idea how to use the funny keyboard, mouse and interface that defines Mac OSX, these desktop wallpapers are very familiar. This is remarkable because Apple is supposed to be about individuality. Changing the wallpaper could be two clicks away yet most Apple users stay with the stock wallpaper. I think they are focused on work rather than tinkering, with everyone happy with the stock wallpaper. Meanwhile, on Ubuntu, the first thing I change is the wallpaper. It goes. But then I have full screen apps and never see the wallpaper ever again. Personally I want the desktop wallpaper to be a black and white terminal window with it showing console messages from syslog, representing the guts of the machine. reply sebastianconcpt 16 hours agoprevYou can't unsee it once seen: The last three releases as somehow vaginal canals. reply reify 1 hour agoprev [–] Running out of ideas to promote the website More boring and uninteresting Apple boringness What is so interesting about wallpapers? Nothing! The typical self promotion through HN. Become a member of 512 Pixels. Support projects like these, receive exclusive content in the monthly newsletter and enjoy advanced screenings of my YouTube videos. Fraidy not old boy A fly in the ointment reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The article features every default wallpaper from previous versions of Mac OS X and macOS in 6K resolution.",
      "Rogue Amoeba, a company that creates audio software for macOS, sponsors the Mac Wallpaper Archive mentioned in the article.",
      "The article includes download links for each wallpaper and offers a brief overview of design changes in each operating system version."
    ],
    "commentSummary": [
      "Users engage in a discussion about their favorite wallpapers on macOS and Mac OS, discussing sources, challenges, and the impact on desktop manager adoption.",
      "Topics covered include screensavers, wallpaper bugs, tiling patterns, nostalgia for older wallpapers, Apple TV screensavers, and copyright concerns.",
      "Some users express interest in creating open-source wallpaper apps, referencing the deletion of wallpapers in a MacOS upgrade and expressing a desire for a new theme."
    ],
    "points": 461,
    "commentCount": 145,
    "retryCount": 0,
    "time": 1708014579
  },
  {
    "id": 39383798,
    "title": "Asahi Linux project surpasses Apple with OpenGL support on Apple Silicon",
    "originLink": "https://arstechnica.com/gadgets/2024/02/asahi-linux-projects-opengl-support-on-apple-silicon-officially-surpasses-apples/",
    "originBody": "who needs metal? — Asahi Linux project’s OpenGL support on Apple Silicon officially surpasses Apple’s Newest driver supports the latest versions of OpenGL and OpenGL ES. Andrew Cunningham - 2/14/2024, 10:00 PM Enlarge / Slowly but surely, the Asahi Linux team is getting Linux up and running on Apple Silicon Macs. Apple/Asahi Linux reader comments 66 For around three years now, the team of independent developers behind the Asahi Linux project has worked to support Linux on Apple Silicon Macs, despite Apple's total lack of involvement. Over the years, the project has gone from a \"highly unstable experiment\" to a \"surprisingly functional and usable desktop operating system.\" Even Linus Torvalds has used it to run Linux on Apple's hardware. The team has been steadily improving its open source, standards-conformant GPU driver for the M1 and M2 since releasing them in December 2022, and today, the team crossed an important symbolic milestone: The Asahi driver's support for the OpenGL and OpenGL ES graphics have officially passed what Apple offers in macOS. The team's latest graphics driver fully conforms with OpenGL version 4.6 and OpenGL ES version 3.2, the most recent version of either API. Apple's support in macOS tops out at OpenGL 4.1, announced in July 2010. Developer Alyssa Rosenzweig wrote a detailed blog post that announced the new driver, which had to pass \"over 100,000 tests\" to be deemed officially conformant. The team achieved this milestone despite the fact that Apple's GPUs don't support some features that would have made implementing these APIs more straightforward. \"Regrettably, the M1 doesn’t map well to any graphics standard newer than OpenGL ES 3.1,\" writes Rosenzweig. \"While Vulkan makes some of these features optional, the missing features are required to layer DirectX and OpenGL on top. No existing solution on M1 gets past the OpenGL 4.1 feature set... Without hardware support, new features need new tricks. Geometry shaders, tessellation, and transform feedback become compute shaders. Cull distance becomes a transformed interpolated value. Clip control becomes a vertex shader epilogue. The list goes on.\" Advertisement Further Reading Asahi Linux’s new “flagship” distro for M-series Macs is a Fedora Remix Now that the Asahi GPU driver supports the latest OpenGL and OpenGL ES standards—released in 2017 and 2015, respectively—the work turns to supporting the low-overhead Vulkan API on Apple's hardware. Vulkan support in macOS is limited to translation layers like MoltenVK, which translates Vulkan API calls to Metal ones that the hardware and OS can understand. Apple's OpenGL support has been stuck at the 4.1 level since macOS 10.9 Mavericks was released in 2013. Since then, the company has shifted its focus to its proprietary Metal graphics API, which, like DirectX 12 and Vulkan, is a \"low-overhead\" API meant to reduce the performance overhead sometimes associated with older APIs like OpenGL. But despite declaring OpenGL officially deprecated in 2018, Apple has left its existing OpenGL implementation alone since then, never updating it but also maintaining support even as it has transitioned from Intel's processors to its own CPUs and GPUs. Rosenzweig's blog post didn't give any specific updates on Vulkan except to say that the team was \"well on the road\" to supporting it. In addition to supporting native Linux apps, supporting more graphics APIs in Asahi will allow the operating system to take better advantage of software like Valve's Proton, which already has a few games written for x86-based Windows PCs running on Arm-based Apple hardware. Though there are still things that don't work, Fedora Asahi Remix is surprisingly polished and supports a lot of the hardware available in most M1 and M2 Macs—including the webcam, speakers, Wi-Fi and Bluetooth, and graphics acceleration. Other features, like Thunderbolt, running displays over USB-C, the system's built-in microphone, and the Touch ID fingerprint sensors, remain non-functional. Asahi's most recent update blog post, published in mid-January, highlighted HDMI support, support for DRM-protected websites via Google's proprietary Widevine package, Touchbar support for the handful of Apple Silicon Macs that use one, and more. As for the newest wave of M3 Macs, Asahi developer Hector Martin said in October 2023 that basic support for the newest chips would take \"at least six months.\" Among other things, the team will need time to support the M3 GPU in their drivers; the team also relies primarily on Mac mini models for development, and the M3 Mac mini doesn't exist yet. reader comments 66 Andrew Cunningham Andrew is a Senior Technology Reporter at Ars Technica, with a focus on consumer tech including computer hardware and in-depth reviews of operating systems like Windows and macOS. Andrew lives in Philadelphia and co-hosts a weekly book podcast called Overdue. Advertisement Channel Ars Technica SITREP: F-16 replacement search a signal of F-35 fail? Footage courtesy of Dvids, Boeing, and The United States Navy. SITREP: F-16 replacement search a signal of F-35 fail? Sitrep: Boeing 707 Steve Burke of GamersNexus Reacts To Their Top 1000 Comments On YouTube Scott Manley Reacts To His Top 1000 YouTube Comments LGR's Clint Basinger Reacts To His Top 1000 YouTube Comments How Forza's Racing AI Uses Neural Networks To Evolve The F-35's next tech upgrade Fighter Pilot Breaks Down Every Button in an F-15 Cockpit Linus \"Tech Tips\" Sebastian Reacts to His Top 1000 YouTube Comments Customizing Mini 4WD Racers For High Speeds On A Small Scale MegaBots: Born to Smash Anything in Their Path First Look: Xbox Adaptive Controller Quantum Computing Expert Explains One Concept in 5 Levels of Difficulty Kids versus 80s tech: Game Boy, Vectrex and a stereo system Expert Explains One Concept in 5 Levels of Difficulty - Blockchain Best wearable tech of 2017 The Moov HR Sweat - heart rate monitor in a headbandArs Technica More videos ← Previous story Next story → Related Stories Today on Ars",
    "commentLink": "https://news.ycombinator.com/item?id=39383798",
    "commentBody": "Asahi Linux project's OpenGL support on Apple Silicon officially surpasses Apple (arstechnica.com)365 points by throwaway2037 18 hours agohidepastfavorite142 comments neogodless 16 hours agoSee also: https://news.ycombinator.com/item?id=39371669 (100+ comments) Conformant OpenGL 4.6 on the M1 (rosenzweig.io) reply Aurornis 16 hours agoprevThe original article ( https://rosenzweig.io/blog/conformant-gl46-on-the-m1.html ) has more details. The important part to note is that the M1 hardware doesn't map well to newer OpenGL standards because Apple deprecated OpenGL in 2018: > Regrettably, the M1 doesn’t map well to any graphics standard newer than OpenGL ES 3.1. While Vulkan makes some of these features optional, the missing features are required to layer DirectX and OpenGL on top. No existing solution on M1 gets past the OpenGL 4.1 feature set. > How do we break the 4.1 barrier? Without hardware support, new features need new tricks. Geometry shaders, tessellation, and transform feedback become compute shaders. Cull distance becomes a transformed interpolated value. Clip control becomes a vertex shader epilogue. The list goes on. OpenGL has been officially deprecated since macOS Mojave (2018), so it shouldn't come as a surprise to anyone that in 2024 the hardware doesn't map well to newer OpenGL features. The media narrative is trying to push this as an \"outdoing Apple at their own game\" thing, but Apple very clearly stopped supporting OpenGL and did so with advance warning years ago. That said, it's an impressive accomplishment that they managed to translate the newer calls into compute shaders and other tricks. It's very impressive work. reply dang 11 hours agoparentDiscussed yesterday: Conformant OpenGL 4.6 on the M1 - https://news.ycombinator.com/item?id=39371669 - Feb 2024 (103 comments) reply wkat4242 16 hours agoparentprevThey shouldn't have deprecated OpenGL though. It's really important for desktop software. Several games have lost Mac support due to this like elite dangerous. Of course they push metal but that's not interesting to desktop developers. reply selectodude 14 hours agorootparentOpenGL itself has been depreciated for almost 7 years now. I won’t wade into Vulkan vs Metal but depreciating OpenGL seems pretty reasonable to me. reply pests 14 hours agorootparentIt's a little different from depreciating since OpenGL was still impented and available on non-M Mac. reply rowanG077 1 hour agorootparentprevDeprecating opengl is reasonable if they would have supported vulkan. Metal is just going backwards. reply jijijijij 15 hours agoparentprev> The media narrative is trying to push this as an \"outdoing Apple at their own game\" thing Big Linux at it again, eh?! reply btown 16 hours agoprevOne of the coolest things (IMO) about the entire Asahi effort, and why I'm not at all surprised that they surpassed Apple, was the dedicated effort to build bespoke developer-friendly Python tooling early in the reverse engineering process. https://asahilinux.org/2021/08/progress-report-august-2021/ > Since the hypervisor is built on m1n1, it works together with Python code running on a separate host machine. Effectively, the Python host can “puppeteer” the M1 and its guest OS remotely. The hypervisor itself is partially written in Python! This allows us to have a very fast test cycle, and we can even update parts of the hypervisor itself live during guest execution, without a reboot. > We then started building a Python implementation of this RPC protocol and marshaling system. This implementation serves a triple purpose: it allows us to parse the DCP logs from the hypervisor to understand what macOS does, it allows us to build a prototype DCP driver entirely in Python, and it will in the future be used to automatically generate marshaling code for the Linux kernel DCP driver. Code here: https://github.com/AsahiLinux/m1n1/blob/main/proxyclient/m1n... If you watch any of Asahi Lina's streams from the time before they had their full drivers implemented in Rust, she's able to weave together complex bitflag-manipulating pipelines at the speed of thought with self-documenting code, all in Python running on the host machine, all while joking with viewers via her adorable avatar. I've never seen anything like it before. The whole workflow is a tremendous and unprecedented accomplishment by the entire Asahi team. reply binsquare 16 hours agoparentWatched asahi Lina's stream and her ability to multitask while working on an what appears to be a very delicate problem is incredible. reply gyomu 12 hours agoparentprevKnowing how to build effective scaffolding, in the right sequence, that continuously enables tighter and faster iteration loops on a project is a huge meta-skill that contributes to why the high end of experienced engineers are orders of magnitude more effective than others. reply WanderPanda 10 hours agorootparentI was wondering if it is possible to formalise this and cast it into a book or lecture so that new devs don‘t have to grind out ten years of hard-gained experience. But at this point I think the only real way to really learn this is to go e.g. through dependency hell yourself at least once. reply notyoutube 15 hours agoparentprevMmh, is that a similarity with postmarketos? I have a fuzzy memory that pmbootstrap or some other tool was kind of important to start porting to new devices? reply panick21_ 16 hours agoparentprevI really like this talk by Bryan Cantrill on tool making. https://www.p99conf.io/session/sharpening-the-axe-the-primac... reply jjice 14 hours agorootparentI completely agree, this is a great talk. I can listen to Bryan and friends speak for hours. I'm not sure if he's a natural story teller or if he's learned over time, but that combined with his experience just makes for a treat. reply panick21_ 10 hours agorootparentIn case you haven't seen this gem: https://www.youtube.com/watch?v=TgmA48fILq8 Young Bryan is on a whole different level. reply whitehexagon 15 hours agoprev6 years ago I said I'd never give apple another cent, but the Asahi Linux project, and especially their efforts around OpenGL, or more specifically their ES 3 support, finally convinced me to pick up a secondhand M1 last month. Amazing work by the team! I wonder if one day the USB4 ports will be able to fully support USB3, so confusing. Anyway I haven't felt the need to boot macos so far :) and the installation was a breeze, big thanks to the team. As a bonus the unified memory allowed me to get an LLM running locally, but I suspect it is CPU bound and probably not using the new GPU driver. reply pjmlp 2 hours agoparentWhen I give money to Apple is for the whole experience, if I want to support Linux, I give money to Linux OEMs, like Asus netbooks in the past. reply psanford 16 hours agoprevI love this work, but I will point out that the Asahi GPU driver still struggles on certain real world workloads. The one I run into quite often is that Google Maps will hang for long periods of time. This is a known issue and they are working on it, so I'm sure it will be fixed sometime this year. reply paulmd 13 hours agoparentwouldn't surprise me if google maps had some obscene amount of drawcalls instead of proper culling/\"LOD\" reply psanford 11 hours agorootparentFrom the gpu issue tracker[0]: > For a bit of context -- Google Maps loads images to the GPU at.. inopportune times. While games would typically load their images during a load screen (so slow image loading just means longer loading screens), Google Maps loads when scrolling around I think (so slow image loading means the whole map stutters). I don't think there's a fundamental driver bug we can fix here, but we can make image loading a lot faster which makes the symptoms go away. [0]: https://github.com/AsahiLinux/linux/issues/72#issuecomment-1... reply ianschmitz 8 hours agorootparentThat sounds like how raster image rendering works on most mapping applications? The tiles are loaded on demand as you pan/zoom reply steveklabnik 17 hours agoprevAre these the Rust-based drivers they've talked a ton about, or different ones? reply dathinab 16 hours agoparentyes, rust-based drivers at the core but also a bunch of other things like it uses mesa and similar parts of the normal GPU support stack and also involved some kernel patches outside of the rust kernel module as far as I vaguely remember really a grate achievement where in the end rust was like a tool to make certain parts easier but all the hard parts are in the end unrelated to rust (like reverse engineering, coming up with solutions for the many issues of mapping GPU APIs Apple doesn't care much about to hardware mainly focused on on just Metal etc.) reply urschrei 16 hours agoparentprevThese are the Mesa drivers linked from the blog post: https://gitlab.freedesktop.org/asahi/mesa, so not Rust AFAICS reply alexlarsson 16 hours agorootparentThe rust part is in the Kernel reply dylan604 14 hours agoprevJust the thought of how to prioritize things in all of the reversing is enough to make me overwhelmed. Have they talked about how they prioritize? \"Asahi's most recent update blog post, published in mid-January, highlighted HDMI support, support for DRM-protected websites via Google's proprietary Widevine package, Touchbar support for the handful of Apple Silicon Macs that use one, and more.\" Seems odd to me that a Linux open source focused something would spend so much effort on supporting DRM over USB3 functionality. So for them to go that direction implies to me they have good reasons. Are they trying to satisfy users? My knee jerk reaction would be the users willing to use this would be accepting of not supporting DRM. reply chippiewill 14 hours agoparentThe Asahi team isn't some monolithic corporation with a prioritised backlog. The skillsets and amount of work involved in getting Widevine working (quickly porting the binary from ARM64 ChromeOS) vs USB 3 (reverse engineer Apple's unique undocumented implementation and write a Linux kernel driver for it) are completely different. It's open source, if someone volunteers a Widevine implementation for Asahi then the maintainers aren't going to say no. Generally speaking Alyssa does GPU reverse engineering, Marcan does the other hardware reverse engineering, Asahi Lina writes the GPU driver and everyone else does various miscellaneous bits (like userspace binaries). reply HeWhoLurksLate 13 hours agoparentprevfor one data point, I'd much rather have DRM supported than USB 3 support- one lets me do casual things and use my machine while I relax or do whatever, and for most USB 3 devices I can just suck it up and wait for a file transfer, or do what I normally do and work off of my NAS. reply rowanG077 48 minutes agoparentprevIt's also a part of effort. USB is very hard taking months and months. Widevine is easy in contrast. So it's also a resource payoff tradeoff. reply johnmaguire 11 hours agoprev> Rosenzweig's blog post didn't give any specific updates on Vulkan except to say that the team was \"well on the road\" to supporting it. In addition to supporting native Linux apps, supporting more graphics APIs in Asahi will allow the operating system to take better advantage of software like Valve's Proton, which already has a few games written for x86-based Windows PCs running on Arm-based Apple hardware. Does anyone know whether these improvements will also help with gaming on macOS? I assume that Mac ships its own driver without these APIs, but e.g. will Proton for Mac or Whisky (Wine for Mac) be able to make use of them? reply tiffanyh 11 hours agoprevSource post: https://rosenzweig.io/blog/conformant-gl46-on-the-m1.html reply Sunspark 14 hours agoprevApple should embrace this if the project is in need of reference materials. Apple is a hardware company primarily, so if someone buys their hardware because it will be compatible with an OS they may like more, that's still a sale for Apple. No funds are lost, because MacOS doesn't charge for a new install on Apple hardware. reply pjmlp 2 hours agoparentApple sells a complete experience, like everyone else was doing before IBM lost ownernship of the PC. Even UNIX, CP/M and MSX vendors, only supported their own version of it, on their own hardware. reply overstay8930 13 hours agoparentprevApple does not want to be a hardware company, in fact when they sell lots of hardware their stock price goes down. If they can't charge a monthly fee for it, they're not doing it. reply Juicyy 13 hours agorootparentOnly 20-25% of Apple's revenue is services. about 50% is iPhone about 8% for Mac and 8% for iPad. They're a hardware company. reply threeseed 11 hours agorootparentApple has always been a hardware and software company. Nobody is buying the iPad or iPhone because it has better specs. Most don't even know how much memory they have. It's because of the OS, apps, ecosystem etc. reply palata 14 hours agoparentprevI really love the project, but I would guess that Apple just doesn't care because it's not bringing enough profit for them to care. reply pockmockchock 14 hours agoprevusing Asahi on my m2 for a year now and it's awesome, the install is straight forward my grandmother could do it. also love the rolling releases. reply BirAdam 17 hours agoprevHonestly, I have been a bit disappointed by Apple. On one hand, they make some seriously awesome hardware with amazing performance doing tasks like rendering and whatnot. On the other hand, they seem incapable of getting awesome performance in other areas, the hardware is incredibly locked away from the supposed owners of the devices, and the pricing for RAM and storage are insane. I don't want to dislike Apple because the hardware is great and their stand against US law enforcement on things like encryption, but a handful things shatter the experience for me. Asahi seems to be solving part of the problem, but the hardware being so ... expensive and locked away remains an issue. reply echelon_musk 16 hours agoparent> their stand against US law enforcement on things like encryption Are you referring to the San Bernadino shooter's iPhone? Because Apple's attempt to introduce CSAM scanning is certainly not what I would call a stand against US law enforcement. reply r00fus 15 hours agorootparent> Because Apple's attempt to introduce CSAM scanning is certainly not what I would call a stand against US law enforcement. I do. Because they listened to the dissent and changed course. CSAM scanning offline on the phone is effectively dead. reply buildbot 16 hours agorootparentprevI imagine they are, as well as the e2e encryption added to icloud after they dropped the CSAM thing. My pet theory is basically a rouge VP started the on device scanning project with whatever external org they worked with, and basically blindsided the rest of the company. Tim Cook probably called the person and was like what the fuck. Or at least I’d like to imagine that. I wonder if that VP still works at Apple? reply astrange 12 hours agorootparentprevAutomated CSAM scanning is another Europe thing. The US doesn't require it and isn't going to. reply stephenr 16 hours agorootparentprevMy understanding is that on-device scanning was meant to prevent an argument from {government, law enforcement, 'think of the children' types} against E2EE solutions. Apple's solution for a lot of things in general, is to favour on-device solutions. reply wkat4242 16 hours agorootparentTrue but it's really hard to imagine how they ever expected the \"my own device spies on me by design\" to fly. Maybe they miscalculated that the \"for the children\" argument would convince the consumer which was obviously a huge miscalculation. Even though they clearly thought of safeguards so it wouldn't lead to many issues in practice, it's just so incredibly wrong at the core that it creeps people out just thinking of it. I can't think of anyone in my circles who would accept this. It's just so extremely out of bounds. And I lost a lot of respect for Apple as a result considering they thought it was ok to propose this. And it would have been total theater anyway because obviously the real offenders would just use something else. reply paulmd 13 hours agorootparentone could argue that it was intended not to fly and that apple successfully threaded the needle of getting E2EE out the door without invoking a legislative response on the basis of \"think of the children/terrorists\". look at what apple did: they lined up E2EE, got the pushback from law enforcement, floated a solution that would have accomplished the stated goals, then effectively invoked the court of public opinion which said \"hell no\" and then just launched E2EE anyway. Now we are in the end-state of successfully having E2EE without a bunch of backdoors, and the only real victim is apple's public reputation with a bunch of android nerds who were never going to like them anyway. reply wkat4242 12 hours agorootparent> the only real victim is apple's public reputation with a bunch of android nerds who were never going to like them anyway. I don't agree. I have several Apple fan friends whose admiration for Apple really dropped. They're still on iOS and Mac because they're so invested (walled garden and all). But the enthusiasm and deep devotion is gone. Not just because of that, though it was the first drop. But also the recent sideloading malicious compliance thing. That deep trust is gone. I used to be an apple fan too but I already dropped off earlier (for want of deciding what I can run on my own hardware). So I'm definitely an android nerd. But this made waves even inside the Apple camp. reply smoldesu 9 hours agorootparentprev> without a bunch of backdoors And on what authority can you make that claim? We assumed notifications weren't backdoored until, oops: https://arstechnica.com/tech-policy/2023/12/apple-admits-to-... reply threeseed 11 hours agorootparentprev> Apple's attempt to introduce CSAM scanning Apple almost certainly has CSAM scanning and has had so for years. They just wanted to move it to your device where it's private rather than doing so server side. reply kjkjadksj 16 hours agoparentprevIt feels like the hardware engineers are just marching blind making stronger hardware for these computers by the year. Like the hardware feels like it has no constraints when you run a game. The emulation layers the game has to run through seem to limit the fps to 40, but interestingly there is zero performance impact to changing graphical settings all the way to ultra for many games that are able to run through rosetta. This shows there is a ton of headroom available if apple developers bothered making it easy for game developers to write natively for these computers. Instead, good faith between apple and third party developers is totally burned and not even Valve is writing games for mac anymore despite how absurdly performant these devices are, especially compared to ten years ago when mac gaming was supposed to get its renaissance per apples marketing and the good relationships they had with developers back then. reply larrik 16 hours agoprevI switched to an M1 Air back at the beginning of 2021, was on Linux (desktop machine) about a decade before that. It's basically purely a work machine (software and management). The hardware is amazing. The battery life is astounding. The software, in almost every area, is inferior to my experience in Linux. The Apple parts generally worst of all (only Microsoft Office on it is worse). In the end, I'm probably 70% as efficient on macOS as I was on Linux after 3 years of using it. The one thing macOS did better than my Linux box, hands-down, was supporting a 4k monitor. My Linux install was a little long in the tooth, though, so hopefully it's gotten better? I really look forward to using Asahi when/if it's ready. I'd love to go back to Linux. Example gripes: - macOS offers this great feature that announces the time every half hour (or whatever you set it to). For a year, after a major OS update, it just didn't work after reboot unless you went in and changed it. Solutions? Wait for Apple to fix it (or write a wonky script to fix it on boot, which I did). Eventually they did, but ug. - to support using 3 finger clicks as middle-click I had to buy software. On Windows this is just built in. On Linux it's on by default. - to make Spotify work somewhat properly I had to download separate software (BeardSpice). After 3 years, I forget what that actually does - if I open Spotify and hit the Play button on my keyboard, Apple Music opens. (Once I actually play Spotify it fixes it, though) - it took me a LONG time to figure out how to set Excel to open CSVs instead of Apple's Numbers app - The Apple calendar app alerts me whenever I create an event in another app (Outlook, Google, whatever). Like I got invited. To an event I created. It didn't used to do that... reply Scubabear68 16 hours agoparentIt seems a lot of those gripes are about specific apps, or simply not understanding that MacOS does somethings differently. By contrast I have never been able to use Linux successfully as a desktop OS because there is a dearth of polished commercial apps, and the HW compatibility has always been iffy. MacOS generally works out of the box with the HW, and the apps are generally highly polished. I caveat the apps as “generally” because there are some turds for sure. iTunes and now Music have always been horrible, and somehow they managed to make Music even worse than iTunes. Historically Macs do benefit from 3rd party software (see also Alfred), over time the best of it seems to eventually get baked into the OS. I don’t see that as a downside really. reply benn0 12 hours agorootparentThis x100. I have regularly tried to set up a Linux environment, thinking that there really isn't that much of a barrier to being productive on Linux, but with the lack of polished commercial apps and the hardware quirks I always seem to spend more time finding workarounds than actually working. I have found more recently that I can get something reasonable (for me) set up, although I'm confident I'll always need a Mac nearby to do some things on. reply Sunspark 14 hours agorootparentprevLinux's desktop experience also lacks polish in a lot of areas. It's not a talent or expertise issue, it just comes down to lack of resources. You can do a lot of polishing if you say here's 50 million dollars and a staff of 50, have at it. reply makeitdouble 11 hours agorootparentprevIt's always about specific apps. I need about 10 apps to work on my work machine, and if any of them is fighting the OS it would be enough to degrade the whole experience. In the olden days it was having a decent unix comand line environment. Windows didn't, osx and linux did, and many of us switched. For others it's a good Adobe suite experience. For others it will be Excel and Office etc. I totally sympathise with parent and Apple Music starting up every damn time the play button is pressed without a media app already started. That's a button I used to press a lot, and at some point I stopped playing music on the mac altogether. The move to kill kernel extension nullified a lot of the historical advantage of the mac: many stuff that was changing low level behavior became a lot more unreliable . Having keyboard remappings get stuck or unresponsive for instance is a huge QOL degradation. reply jlund-molfese 15 hours agoparentprevThe tone of the community is really different, too—and imo the worst thing about the transition from Linux -> OS X. And ok, it's not a fair comparison, because Linux users tend to be way more technical due in part to the OS family's barriers of entry. Still, it's annoying when you search for how to do something in OS X and the first few threads are full of people saying \"that isn't how it works! Instead of wanting to change it, you need to understand and follow the Apple Way™!\" You're usually able to find the solution after a bit more searching, but the Apple Forums are especially bad. reply curt15 13 hours agorootparentI still remember the apologists (circa 2011) trying to justify OS X's system-wide autosave feature when it came out despite its obvious pitfall -- users could make inadvertent edits to their documents without noticing. When users pointed out that Apple's own XCode didn't adopt that feature, the apologists' excuse was simply \"IDEs are different\". reply ace2358 11 hours agorootparentWhat? Autosave also has versioning. You can always go back through the auto save history. You can also revert to the original opened file. This is done from the file menu. Also, if like a good mac user you have Time Machine configured and on, you can browse your versions further into the past. Heavy iWork user, I don’t know about Xcode though. reply curt15 9 hours agorootparentDoes the version browser show a line-by-line diff? When I last used it ~10 yrs ago it displayed a fancy Time Machine-like interface that was useless for telling if I accidentally inserted a character in page 11. reply wtallis 14 hours agorootparentprevIf your mental model for how the software works is not an accurate abstraction for how it actually functions, you're going to be frustrated. If, when confronted with evidence that your mental model is inaccurate, you refuse to update your mental model, you will have difficulty coming up with solutions for the things that bug you, and difficulty even asking the right questions. Being mad at software for operating in a different paradigm than you are used to is not productive. This all applies just as much to users coming to macOS from Windows (or imitations thereof) to macOS as it does to users coming to git from svn. reply michaelcampbell 13 hours agorootparentI'm reminded of a saying... The reasonable man expects to change to fit in the world. The unreasonable man expects the world to change around him. Thus, all progress is made by unreasonable men. (Paraphrased) > Being mad at software for operating in a different paradigm than you are used to is not productive. Indeed, it is often the ONLY thing that causes progress. reply wtallis 13 hours agorootparentThe \"unreasonable men\" who come up with better solutions are usually the people who have the deepest understanding of what is wrong with the status quo. I don't think the people who refuse to understand the problem are usually coming up with good solutions. reply tech_ken 13 hours agorootparentprevOkay yes but git and an OS are very different pieces of software. One does one thing (version control), and to be effective at that single task its highly opinionated. This is fine and good; he restriction allows the tool to laser focus on being good at a few things. OTOH an OS needs to do many very different things, as many different things as there are users. Creating a single paradigm, and obstructing basic configuration stuff like mouse input settings, is the opposite of what you want in this case. An OS should be flexible customizable, to allow the user to fine-tune it to match their use case needs as closely as possible. Just telling an OS user \"get with the program\" kind of misses the point, IMO. I prefer OSs which meet my needs, rather than the other way around. reply wtallis 13 hours agorootparentYou may wish to note that I'm explicitly not telling the OS user to just \"get with the program\". I'm telling the OS user that they need to understand the OS before they can effectively modify it to suit their needs. reply tech_ken 13 hours agorootparent> Still, it's annoying when you search for how to do something in OS X and the first few threads are full of people saying \"that isn't how it works! Instead of wanting to change it, you need to understand and follow the Apple Way™!\" > Being mad at software for operating in a different paradigm than you are used to is not productive. This all applies just as much to users coming to macOS from Windows (or imitations thereof) to macOS as it does to users coming to git from svn. I guess I can see how you intended your comment to mean what you're saying, but reading these two comments in sequence I think one can understand my confusion. You may wish to directly say what you mean, rather than speak in glib generalities. reply wtallis 12 hours agorootparentI don't think I'm the one being glib here. I'm trying to both illustrate that there's a problem that truly is general and not specific to macOS, and trying to make the fine distinction between telling users to understand and suck it up vs telling users to understand so that they can better figure out how to get what they want. That latter distinction is what you seem to be having more trouble with. reply tech_ken 11 hours agorootparentOkay good talk reply kjkjadksj 16 hours agoparentprevThe way these modern macs are set up in terms of permissions is really strange and has put some projects on a backburner for me. My latest woe is getting newsboat to refresh my rss feeds either as a cronjob or launchd service. On my mojave machine this was as trivial as it sounds, either a single line in crontab or a single line with some window dressing to make it into a launchd plist file then its OK. I try and do this now and it doesn’t work, since it appears newsboat runs and pulls changes but is unable to actually write changes to the cache database now. I have gone down the rabbit hole now of giving full disk access to the shell, cron, launchd, launchctl, and the newsboat binary, but no dice. I can’t get it to work and I can’t find anything about why this shouldn’t work other than permitting full disk access. Even then that shouldn’t be required because the cache.db file sits in the users home directory. reply frizlab 16 hours agorootparentOh that’s interesting to me. I’ve gone deep into the automation and stuff on macOS and it really _should_ work… Do you have logs? reply zamadatix 16 hours agoparentprevBy 4k monitor do you mean a high DPI monitor? Not much has changed in regards to resolution support, that should always have been fine, but a lot has changed in regards to high DPI support with Wayland now having \"real\" (direct) fractional scaling which makes it even better at approaching the problem than macOS which has \"fake\" (render and scale) fractional scaling. KDE Plasma and QT apps (the default desktop environment for Fedora Asahi) should support this already, I don't remember if Gnome has gotten around to defaulting to the newer protocol yet or if it was still experimental. reply larrik 15 hours agorootparentSure, high DPI. I really mean scaling. On Linux, I plugged in the 4k and everything is tiny tiny tiny. I tried to make it a little bigger, and some stuff grows, other stuff doesn't, and some stuff just broke. Then in the end I was sort of stuck in this weird frankenstein of settings that looked like crap on any monitor. Like I said, this was over 3 years ago and the Linux install was very old at that point (I think it was a Linux Mint based on 18.04 at the latest, possibly even 16.04 still). Mac has a slider that changes the scaling of everything, smoothly and all at once. I probably should have just gotten a bigger 4k reply viraptor 14 hours agorootparentThis is just a slider in KDE these days. You tried it on an ancient system where it wasn't implemented yet. reply Sunspark 13 hours agorootparentprevIf using Gnome, only use integer scaling. 100%, 200%, 400%. KDE will have working fractional scaling for the DE and apps using QT and there you can adjust a slider to a % you like. reply mavamaarten 13 hours agorootparentSee but that's exactly the thing, on Mac you can just pick a scaling and every scaling option looks flawless across the board. Integer scaling is silly for me: it's either huge or tiny. Yes, KDE does it better and with Wayland you can also do fractional scaling. But the original point stands: it sucks on (most) linux and works flawlessly on Mac. reply delta_p_delta_x 2 hours agorootparent> See but that's exactly the thing, on Mac you can just pick a scaling and every scaling option looks flawless across the board. Not really, if you have a discerning eye. Any non-integer resolution on macOS is rendered at twice that resolution, and then raster-scaled down and anti-aliased. So, if you have MacBook with a 2560×1400 display and you select any other resolution besides that and 1280×800 (exactly half), the desktop render will be raster scaled. To be fair, it works better than Wayland's previous behaviour because of the 2× rendering factor, but you can absolutely still see scaling artifacts if you look for them, and I certainly do. Ringing around text in a dark-mode editor is especially obvious. The only OS that has gotten HiDPI right is Windows. reply zamadatix 13 hours agorootparentprevIt's not that Gnome can't, it's that it's not recommended. Gnome actually handles e.g. 150% scaling the exact same way as macOS does: render at a higher resolution then downscale. The reason it's not recommended over integer scales is that's inefficient, not that it doesn't work. The same recommendation exists on macOS. The difference in quality of life is macOS is generally better about assuming a given display should be high DPI the first time you use that display (and doesn't even show you the tiny options at all by default in such cases). So long as you select the same scale things should seem identical between Gnome and macOS though. Windows/Android also use the superior direct render approach. The reason you always heard about Windows having horrible scaling was due to legacy Windows apps not having an understanding of how to use scaling, the actual scaling approach itself is very good (and most all apps still getting updates should be good by now). reply jwells89 15 hours agorootparentprev“Better” still has some asterisks, for example though KDE is by far the best of the major DEs in terms of fractional scaling support under Wayland, it still has some oddities like Aurora window decoration themes not drawing properly with fractional scaling, limiting the user to one of a tiny handful of C++ window decorations (the overwhelming majority are Aurora). GTK apps under KDE can act a bit funny too, with e.g. your cursor drawing at 2x when hovering over a GTK window. I deal with these things daily using a Thinkpad with a display that requires 1.5x scaling to be usable. Can’t wait for these issues to be solved and for the asterisks to disappear. reply NekkoDroid 13 hours agorootparent> GTK apps under KDE can act a bit funny too, with e.g. your cursor drawing at 2x when hovering over a GTK window. Yea, GTK4 to my knowledge until now doesn't support fractional scaling, but the new™ ngl and vulkan renderers should be able to do fractional scaling. If it's actually hooked up to do so is another question. https://blog.gtk.org/2024/01/28/new-renderers-for-gtk/ reply monooso 15 hours agoparentprevSome people prefer Linux (or Windows) to macOS, and that's perfectly reasonable. Some of your gripes are a little curious, though: > Solutions? Wait for Apple to fix it (or write a wonky script to fix it on boot, which I did). Eventually they did, but ug. Writing a wonky script to fix something on boot sounds eerily like my Linux experiences. > to support using 3 finger clicks as middle-click I had to buy software. On Windows this is just built in. On Linux it's on by default. This could also be phrased as \"in some ways macOS works differently to Windows and Linux. However, there is a solution for those who prefer the Linux way.\" > to make Spotify work somewhat properly I had to download separate software... That's Spotify, not macOS. > if I open Spotify and hit the Play button on my keyboard, Apple Music opens Yes, Apple Music opening for inexplicable reasons is very annoying. > it took me a LONG time to figure out how to set Excel to open CSVs instead of Apple's Numbers app That's just not understanding how macOS works. A 10-second web search would have ended your suffering. > The Apple calendar app alerts me whenever I create an event in another app (Outlook, Google, whatever). That doesn't sound entirely unreasonable to me. reply paulddraper 12 hours agorootparent> in some ways macOS works differently to Windows and Linux No one will disagree. OP would be a bit more specific, and say \"worse.\" reply askonomm 14 hours agoparentprevYour list sounds more like app related things rather than OS related things to be honest. Also, contrasting your issue list with the issue list of Linux, where Wayland barely works, audio issues are constant, the whole system is so delicate that an automatic update can easily brick the OS, 10 different ways to install apps leading to no consistency at all (flatpak, snap, .tar.gz, AppImage, native binary, apt-get, software center ...), makes MacOS sound really great. reply koiueo 13 hours agorootparentYour list sounds more like Ubuntu related, rather than Linux related to be honest. reply BodyCulture 12 hours agorootparentprevYou must be doing something wrong. I have zero problems with Linux updates since many years. reply 12345hn6789 12 hours agorootparentprevThose are all issues with Ubuntu. Switch to arch reply tech_ken 11 hours agorootparentUpside: better than Ubuntu. Downside: wait too long to update and your computer is headed for the shadow realm. reply mavamaarten 13 hours agoparentprevMiddleClick is a free app that brings middle click functionality: https://github.com/artginzburg/MiddleClick-Sonoma reply Phemist 15 hours agoparentprevMy main gripe - how on vanilla MacOS alt(cmd)-tabbing cycles through applications first and then _all their windows_ rather than windows first, doing _nothing_ on a per application basis. I cannot imagine how this matches at all to anyone's workflow. Nobody at apple works on a single project across multiple applications (documentation in browswr, your IDE, an emulator, some terminals, etc.).? You have to install a specific app and give it some crazy permissions to fix those issues. Pfft reply jwells89 15 hours agorootparentCommand-` is the shortcut you want for cycling through windows within an app, otherwise Exposé/Mission Control is the layer that can be configured to think in “windows” instead of in “applications”. reply ace2358 11 hours agorootparentDon’t forget to add the shift key to scroll backward through the apps or windows. reply breather 14 hours agoparentprevMeanwhile linux keybindings appear stuck in the 80s reply opan 14 hours agorootparentTiling WMs tend to make heavy use of the super key. I would hate to lose all my keybinds because of copy/paste and such moving. I do think the macOS approach is conceptually cool (emacs/readline binds everywhere is neat) and makes sense, but I also hate actually using macOS, especially window management stuff. I guess if there were a way for people to have it both ways, all would be well. reply benn0 12 hours agorootparentprevI'm trying to manage working on both Linux and MacOS, and this has been the number one frustration. Fortunately, toshy.app (as well as into) exists and does a pretty great job at mapping shortcuts to match MacOS. reply shrimp_emoji 14 hours agorootparentprevHow? They exist and they're customizable, unlike Windows's. And I'll bet you you can't bind xkill to Ctrl-Alt-Esc, and your cursor turns into a little skull-and-crossbones, and whatever you click immediately vaporizes via a SIGKILL, on a Mac. :p reply breather 14 hours agorootparentI'm referring specifically to the use of ctrl as a primary key for both the shell and the ux. How did this happen? Anyway, keybindings are certainly changeable if you're ready to dive into a hundred distinct projects each defining their own key handling. There's no truly system wide way to alter system keybindings in any meaningful sense. reply kps 12 hours agorootparentIt happened because Windows adopted IBM CUA, and the ‘desktop Linux’ crowd had a fetish for copying Windows. Before that, X11 programs were typically fully configurable, with key bindings in X resources. Currently I think KDE is the least-bad option, as common shortcuts can be remapped globally, but it could be a lot better — Qt can universally remap ‘Control’ shortcuts to the GUI key, but it's only available on Mac builds. reply sunshowers 14 hours agorootparentprevOn balance, I really like that Ctrl is overloaded in that way. Means that Super/Win/Cmd can be used for a wide variety of things on top. For example, I use Super for tiling window management, launching programs, and other things. On macOS, with Yabai and skhd, you can't use plain Cmd to do that. Overloading Ctrl has downsides, but I think it is a net benefit overall. reply breather 5 hours agorootparentI mean yea, but in practice I run into frustration that the terminal doesn't have a key dedicated to commands far more than I need to do something globally. Anyway, you can use cmd, you just need to have an actual command (non-modifier-key) to pass it—I have no use for a key that does one thing. reply blastersyndrome 15 hours agoprevnext [13 more] I thought Asahi Linux's sole developer didn't allow discussion of his project here? I remember there being quite a lot of fallout from that, what happened? reply nozzlegear 14 hours agoparentEveryone else is asking how they wouldn’t allow discussion on HN, but I’m more interested in why they don’t want discussion on HN? reply pests 13 hours agorootparentSomeone in the project considers HN not a safe-space for queer viewpoints / racist / homophobic. I am very much at a loss as well as this has never been my experience. A lot of the arguments started with \"when you enable showdead, there's lots of dead comments of people being vile\". Just not sure what to say. reply squigz 11 hours agorootparentHere's some context [0] Indeed, it does often boil down to dead comments being... not great, unsurprisingly. [0] https://news.ycombinator.com/item?id=36226845 reply throw10920 6 hours agorootparentThe fact is that they're dead, though. They've been killed - by either the users, or the mods. Getting upset over them is unreasonable. reply RobotToaster 13 hours agorootparentprevSomeone here pointed out that one of the developers on the project is actually the primary developer's vtuber persona. That's literally it. reply cobertos 13 hours agorootparentprevProbably just not wanting to deal with the unsavory side of the lurking userbase on HN or the poor, ill-informed discussion on sensitive/political topics? There are certain things HN is not good at talking about There are multiple people I've seen express this in-desire towards HN reply E39M5S62 14 hours agoparentprevHow can someone forbid discussion of something on a site they don't own/control? reply ZekeSulastin 12 hours agorootparentThey can’t forbid discussion but they can try to make it so people visiting from HN can’t see the page; they aren’t the only ones, either, as the poster upthread mentioning jwz’s image redirect noted. reply zamadatix 13 hours agoparentprevAsahi Linux has many developers, the author of this driver (Alyssa Rosenzweig) isn't even the lead developer (Hector Martin). reply larvaetron 14 hours agoparentprev> didn't allow How would he even enforce this? reply blastersyndrome 13 hours agorootparentfor a short time, he was monitoring the referral header and made his website display an offensive message if you clicked the link from HN. HN's mods then edited links to his domain so they would emit the referral header, and he responded by implementing a browser exploit to detect if certain HN URLs were in your browser history. In any case, I apologize for using the wrong wording. reply chippiewill 14 hours agorootparentprevIIRC it was if you link directly to the Asahi Linux website then a bit of javascript picks up the HN referrer and blocks viewing the page. reply HideousKojima 15 hours agoprevnext [24 more] [flagged] WaffleIronMaker 14 hours agoparentInteresting! I didn't know they were the same person, but coming from a queer perspective, I'm inclined to just treat people as they ask to be treated. If someone is doing impressive work, I think it's important to respect the way they want to be treated, even if it's non-traditional. reply faitswulff 15 hours agoparentprevIs...that Hector Martin's vtuber persona? I was under the impression that they were different people. reply asoneth 15 hours agorootparentThere is some evidence to that effect: https://news.ycombinator.com/item?id=35237006 (Note that I'm not necessarily endorsing any specific views about this, just linking to a past discussion.) reply chippiewill 14 hours agorootparentprevIt almost certainly is. But it's never been officially confirmed and I doubt Hector ever would as it was never his intention. reply sickofparadox 15 hours agoparentprevV-tubers in general are very strange, and attract fanbases of strange individuals. A sort of natural attraction. reply hn8305823 15 hours agoparentprevWhy do we care? Ashai Linux is obviously a high-IQ effort and we are very fortunate they are motivated to work on this instead of something else (like ML) reply faitswulff 14 hours agorootparentI actually don’t care, and I think the community is better off being explicitly welcoming of folks of all kinds. reply HideousKojima 15 hours agorootparentprevnext [15 more] [flagged] delroth 15 hours agorootparentYour obsession with how people decide to present themselves is what's creepy and weird. reply HideousKojima 14 hours agorootparentnext [12 more] [flagged] dj_mc_merlin 14 hours agorootparentSome parts of the programming community has always embraced counterculture/things the public sees as bizzare. Surprise surprise, it's also the part that spends a lot more on the computer than even the already addicted average programmer. So they tend to be godly at the craft compared to us lesser mortals that still maintain some normal social behaviour and they can produce amazing stuff like this. Be thankful for it. reply vdaea 14 hours agorootparentYou can be thankful for the work done and still think marcan acts weird and is off-putting with his \"asahi\" vtuber persona. reply tux3 14 hours agorootparentWe knew you could, but you might as well not. Even if you don't see the empathy angle, who benefits from alienating people who do amazing work for free? reply RedComet 13 hours agorootparentEven if you restrict his work to technology, it might be a wash at best. Wasn't he one of those leading the charge in getting Cloudflare to drop a site due to bullying allegations? I think I'd rather have Cloudflare be neutral than have a few Linux drivers for new MacBooks a couple of years sooner than otherwise. reply throw10920 6 hours agorootparent> Wasn't he one of those leading the charge in getting Cloudflare to drop a site due to bullying allegations? Yikes, is this true? That would be wild - do you have sources? reply vdaea 13 hours agorootparentprevBut I don't see it as alienating. Marcan seems an intelligent person so he knows that his vtuber persona is weird. I suppose other people noticing and commenting on it is something he likes or even encourages. It's like... people who dye their hair green, or who wear thick golden chains or teeth grills. They want the attention. reply sunshowers 14 hours agorootparentprevAs someone who is weird along many dimensions, I do expect people to treat harmless weirdness as normal. Expanding the set of acceptable behaviors to encompass all harmless ones is an important part of social progress. reply polotics 14 hours agorootparentprevMaybe consider that the loudness you resent is the result of reflexivity, and in a world where no-one would flip an eyelid over such persona creation and whatnot, there would only be the loudness you'd mistakenly perceive. reply WesolyKubeczek 14 hours agorootparentprevI'm wondering if you call authors using pen names \"weird\". If I ever at all did youtube videos of anything at all, I would more likely than not adopt some persona (and give it a weird accent to boot) so it would distinctly be not \"me\". reply louthy 14 hours agorootparentprevWhat’s “normal”? You? reply HideousKojima 14 hours agorootparentnext [2 more] [flagged] pests 13 hours agorootparentPeople have used pen names all the time. Look at you, HideousKojima. What's your real name? Why do you pretend to be this online alias? Is it normal to hide your identity and interact as if you were someone else? reply numpad0 13 hours agorootparentprevTake it with as much grains of salt as you want: IMO we're watching anime eat the world, Just like software did. Anime style audio-visual stimuli are synthetic data with human and its sexual drive in loop, now also connected with Internet mob judgement system like Twitter for a decade or so. Instagram style beauty filters and Diffusion ML models are no technical match, as their feedback loops are much longer, more constricted by ideologisms as well as by physicality. Some platforms like TikTok and App Store had been fighting to un-realize the shift but that's only been delaying eventuality. We are already seeing increasingly beautified Tim Cook, anthropomorphized Earth, and two Chinese anime games on Apple presentations last year, there's only going to be more. reply porphyra 14 hours agorootparentprevBruh there's a huge difference between murdering your wife and being a vtuber. The latter has never hurt anyone. reply faitswulff 14 hours agoparentprevHow would you suggest that people treat them? reply alephaleph 14 hours agoparentprevbecause it’s fun reply fluxem 16 hours agoprevnext [7 more] [flagged] sebzim4500 16 hours agoparentBecause they want to run Linux on Apple Silicon reply fluxem 15 hours agorootparentnext [6 more] [flagged] tlivolsi 15 hours agorootparentBecause the hardware is good, and some people want to run Linux instead of macOS on it. reply fluxem 15 hours agorootparentnext [4 more] [flagged] binarymax 15 hours agorootparentApple PC/Laptop hardware far exceeds that of Dell. reply babypuncher 15 hours agorootparentprevBecause then the hardware wouldn't be as good. But the real answer is, why not? reply mrguyorama 15 hours agorootparentprevThe M series chips are relatively unique in the market right now. Being able to do real work for several hours on battery is quite impressive. Hopefully that carries over to a linux install. reply sekLabs 15 hours agorootparentprevbecause they don't like macos reply charcircuit 16 hours agoprev [–] OpenGL has been deprecated on Mac for 6 years which is why Apple stopped investing into their implementation. Instead apps should be using Metal. reply MBCook 16 hours agoparent [–] This is such lazy framing. What the team has done is great, but this article says they’ve beat Apple in a race Apple refused to run. Duh. Of course they won. The original blog post has tinges of this framing, which just reads sort of like dunking/hostility to me (for the reason above). This Ars article, and others I’ve seen, just run with it and make it the centerpiece. Apple isn’t trying. It’s not a race. So framing it like that is a disservice to the reader. Just celebrate the accomplishment. Write about the fact the team is doing so great. You don’t need to shove it into some incorrect narrative. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Asahi Linux project has announced that its GPU driver now supports the latest versions of OpenGL and OpenGL ES, surpassing Apple's support in macOS.",
      "Despite the limitations of Apple's GPUs, the team was able to achieve this milestone.",
      "The next goal of the project is to support the low-overhead Vulkan API on Apple's hardware, which will enable better compatibility with software like Valve's Proton and native Linux apps."
    ],
    "commentSummary": [
      "The Asahi Linux project has achieved superior OpenGL support on Apple Silicon compared to Apple's own capabilities.",
      "Some argue that Apple should not have deprecated OpenGL, as it plays a crucial role in desktop software.",
      "The success of the Asahi team's reverse engineering efforts and developer-friendly Python tooling have contributed to their achievement."
    ],
    "points": 365,
    "commentCount": 142,
    "retryCount": 0,
    "time": 1708010797
  },
  {
    "id": 39391688,
    "title": "Google's Magika: AI-Powered File-Type Identification for Fast and Accurate Detection",
    "originLink": "https://opensource.googleblog.com/2024/02/magika-ai-powered-fast-and-efficient-file-type-identification.html",
    "originBody": "opensource.google.com Events Projects Programs and services Documentation About Blog Google Open Source Blog The latest news from Google on open source releases, major projects, events, and student outreach programs. Magika: AI powered fast and efficient file type identification Thursday, February 15, 2024 Today we are open-sourcing Magika, Google’s AI-powered file-type identification system, to help others accurately detect binary and textual file types. Under the hood, Magika employs a custom, highly optimized deep-learning model, enabling precise file identification within milliseconds, even when running on a CPU. Magika command line tool used to recognize a identify the type of a diverse set of files You can try the Magika web demo today, or install it as a Python library and standalone command line tool (output is showcased above) by using the standard command line pip install magika. Why identifying file type is difficult Since the early days of computing, accurately detecting file types has been crucial in determining how to process files. Linux comes equipped with libmagic and the file utility, which have served as the de facto standard for file type identification for over 50 years. Today web browsers, code editors, and countless other software rely on file-type detection to decide how to properly render a file. For example, modern code editors use file-type detection to choose which syntax coloring scheme to use as the developer starts typing in a new file. Accurate file-type detection is a notoriously difficult problem because each file format has a different structure, or no structure at all. This is particularly challenging for textual formats and programming languages as they have very similar constructs. So far, libmagic and most other file-type-identification software have been relying on a handcrafted collection of heuristics and custom rules to detect each file format. This manual approach is both time consuming and error prone as it is hard for humans to create generalized rules by hand. In particular for security applications, creating dependable detection is especially challenging as attackers are constantly attempting to confuse detection with adversarially-crafted payloads. To address this issue and provide fast and accurate file-type detection we researched and developed Magika, a new AI powered file type detector. Under the hood, Magika uses a custom, highly optimized deep-learning model designed and trained using Keras that only weighs about 1MB. At inference time Magika uses Onnx as an inference engine to ensure files are identified in a matter of milliseconds, almost as fast as a non-AI tool even on CPU. Magika Performance Magika detection quality compared to other tools on our 1M files benchmark Performance wise, Magika, thanks to its AI model and large training dataset, is able to outperform other existing tools by about 20% when evaluated on a 1M files benchmark that encompasses over 100 file types. Breaking down by file type, as reported in the table below, we see even greater performance gains on textual files, including code files and configuration files that other tools can struggle with. Various file type identification tools performance for a selection of the file types included in our benchmark - n/a indicates the tool doesn’t detect the given file type. Magika at Google Internally, Magika is used at scale to help improve Google users’ safety by routing Gmail, Drive, and Safe Browsing files to the proper security and content policy scanners. Looking at a weekly average of hundreds of billions of files reveals that Magika improves file type identification accuracy by 50% compared to our previous system that relied on handcrafted rules. In particular, this increase in accuracy allows us to scan 11% more files with our specialized malicious AI document scanners and reduce the number of unidentified files to 3%. The upcoming integration of Magika with VirusTotal will complement the platform's existing Code Insight functionality, which employs Google's generative AI to analyze and detect malicious code. Magika will act as a pre-filter before files are analyzed by Code Insight, improving the platform’s efficiency and accuracy. This integration, due to VirusTotal’s collaborative nature, directly contributes to the global cybersecurity ecosystem, fostering a safer digital environment. Open Sourcing Magika By open-sourcing Magika, we aim to help other software improve their file identification accuracy and offer researchers a reliable method for identifying file types at scale. Magika code and model are freely available starting today in Github under the Apache2 License. Magika can also quickly be installed as a standalone utility and python library via the pypi package manager by simply typing pip install magika with no GPU required. We also have an experimental npm package if you would like to use the TFJS version. To learn more about how to use it, please refer to Magika documentation site. Acknowledgements Magika would not have been possible without the help of many people including: Ange Albertini, Loua Farah, Francois Galilee, Giancarlo Metitieri, Luca Invernizzi, Young Maeng, Alex Petit-Bianco, David Tao, Kurt Thomas, Amanda Walker, and Zhixun Tan. By Elie Bursztein – Cybersecurity AI Technical and Research Lead and Yanick Fratantonio – Cybersecurity Research Scientist Labels: AI , deep learning , Learn    Popular Posts Mentor organizations announced for Google Summer of Code 2023! Google Summer of Code 2023 accepted contributors announced! Introducing Service Weaver: A Framework for Writing Distributed Applications Rust fact vs. fiction: 5 Insights from Google's Rust journey in 2022 Google Summer of Code 2024 Celebrating our 20th Year! Archive GOOGLE PRIVACY TERMS",
    "commentLink": "https://news.ycombinator.com/item?id=39391688",
    "commentBody": "Magika: AI powered fast and efficient file type identification (googleblog.com)356 points by alphabetting 8 hours agohidepastfavorite92 comments stevepike 8 hours agoOh man, this brings me back! Almost 10 years ago I was working on a rails app trying to detect the file type of uploaded spreadsheets (xlsx files were being detected as application/zip, which is technically true but useless). I found \"magic\" that could detect these and submitted a patch at https://bugs.freedesktop.org/show_bug.cgi?id=78797. My patch got rejected for needing to look at the first 3KB bytes of the file to figure out the type. They had a hard limit that they wouldn't see past the first 256 bytes. Now in 2024 we're doing this with deep learning! It'd be cool if google released some speed performance benchmarks here against the old-fashioned implementations. Obviously it'd be slower, but is it 1000x or 10^6x? reply ebursztein 4 hours agoparentCo-author of Magika here (Elie) so we didn't include the measurements in the blog post to avoid making it too long but we did those measurements. Overall file takes about 6ms (single file) 2.26ms per files when scanning multiples. Magika is at 65ms single file and 5.3ms when scanning multiples. So Magika is for the worst case scenario about 10x slower due to the time it takes to load the model and 2x slower on repeated detection. This is why we said it is not that much slower. We will have more performance measurements in the upcoming research paper. Hope that answer the question reply jpk 3 hours agorootparentDo you have a sense of performance in terms of energy use? 2x slower is fine, but is that at the same wattage, or more? reply alephnan 3 hours agorootparentThat sounds like a nit / premature optimization. Electricity is cheap. If this is sufficiently or actually important for your org, you should measure it yourself. There are too many variables and factors subject to your org’s hardware. reply djxfade 2 hours agorootparentTotally disagree. Most end users are on laptops and mobile devices these days, not desktop towers. Thus power efficiency is important for battery life. Performance per watt would be an interesting comparison. reply true_religion 1 hour agorootparentWhat end users are working with arbitrary files that they don’t know the identification of? This entire use case seems to be one suited for servers handling user media. reply michaelt 38 minutes agorootparentTheoretically? Anyone running a virus scanner. Of course, it's arguably unlikely a virus scanner would opt for an ML-based approach, as they specifically need to be robust against adversarial inputs. reply underdeserver 1 hour agorootparentprevIn general you're right, but I can't think of a single local use for identifying file types by a human on a laptop - at least, one with scale where this matters. It's all going to be SaaS services where people upload stuff. reply prmph 58 minutes agorootparentWe are building a data analysis tool with great UX, where users select data files, which are then parsed and uploaded to S3 directly, on their client machines. The server only takes over after this step. Since the data files can be large, this approach bypasses having to trnasfer the file twice, first to the server, and then to S3 after parsing. reply metafunctor 3 hours agoparentprevI've ended up implementing a layer on top of \"magic\" which, if magic detects application/zip, reads the zip file manifest and checks for telltale file names to reliably detect Office files. The \"magic\" library does not seem to be equipped with the capabilities needed to be robust against the zip manifest being ordered in a different way than expected. But this deep learning approach... I don't know. It might be hard to shoehorn in to many applications where the traditional methods have negligible memory and compute costs and the accuracy is basically 100% for cases that matter (detecting particular file types of interest). But when looking at a large random collection of unknown blobs, yeah, I can see how this could be great. reply renonce 7 hours agoparentprevFrom the first paragraph: > enabling precise file identification within milliseconds, even when running on a CPU. Maybe your old-fashioned implementations were detecting in microseconds? reply stevepike 7 hours agorootparentYeah I saw that, but that could cover a pretty wide range and it's not clear to me whether that relies on preloading a model. reply ryanjshaw 4 hours agorootparent> At inference time Magika uses Onnx as an inference engine to ensure files are identified in a matter of milliseconds, almost as fast as a non-AI tool even on CPU. reply awaythrow999 1 hour agoprevWonder how this would handle a polyglot[0][1], that is valid as a PDF document, a ZIP archive, and a Bash script that runs a Python webserver, which hosts Kaitai Struct’s WebIDE which, allowing you to view the file’s own annotated bytes. [0]: https://www.alchemistowl.org/pocorgtfo/ [1]: https://www.alchemistowl.org/pocorgtfo/pocorgtfo16.pdf Edit: just tested, and it does only identify the zip layer reply rvnx 57 minutes agoparentYou can try it here: https://google.github.io/magika/ It's relatively limited compared to `file` (~10% coverage), it's more like a specialized classificator for basic file formats, so such cases are really out-of-scope. I guess it's more for detecting common file formats then with high recall. However, where is the actual source of the model ? Let's say I want to add a new file format myself. Apparently only the source of the interpreter is here, not the source of the model nor the training set, which is the most important thing. reply alexandreyc 34 minutes agorootparentYes, I totally agree; it's not what I would qualify as open source. Do you plan to release the training code along the research paper? What about the dataset? In any case, it's very neat to have ML-based technique and lightweight model for such tasks! reply m0shen 6 hours agoprevAs someone that has worked in a space that has to deal with uploaded files for the last few years, and someone who maintains a WASM libmagic Node package ( https://github.com/moshen/wasmagic ) , I have to say I really love seeing new entries into the file type detection space. Though I have to say when looking at the Node module, I don't understand why they released it. Their docs say it's slow: https://github.com/google/magika/blob/120205323e260dad4e5877... It loads the model an runtime: https://github.com/google/magika/blob/120205323e260dad4e5877... They mark it as Experimental in the documentation, but it seems like it was just made for the web demo. Also as others have mentioned. The model appears to only detect 116 file types: https://github.com/google/magika/blob/120205323e260dad4e5877... Where libmagic detects... a lot. Over 1600 last time I checked: https://github.com/file/file/tree/4cbd5c8f0851201d203755b76c... I guess I'm confused by this release. Sure it detected most of my list of sample files, but in a sample set of 4 zip files, it misidentified one. reply michaelt 14 minutes agoparent> The model appears to only detect 116 file types [...] Where libmagic detects... a lot. Over 1600 last time I checked As I'm sure you know, in a lot of applications, you're preparing things for a downstream process which supports far fewer than 1600 file types. For example, a printer driver might call on file to check if an input is postscript or PDF, to choose the appropriate converter - and for any other format, just reject the input. Or someone training an ML model to generate Python code might have a load of files they've scraped from the web, but might want to discard anything that isn't Python. reply m0shen 6 hours agoparentprevMade a small test to try it out: https://gist.github.com/moshen/784ee4a38439f00b17855233617e9... hyperfine ./magika.bash ./file.bash Benchmark 1: ./magika.bash Time (mean ± σ): 706.2 ms ± 21.1 ms [User: 10520.3 ms, System: 1604.6 ms] Range (min … max): 684.0 ms … 738.9 ms 10 runs Benchmark 2: ./file.bash Time (mean ± σ): 23.6 ms ± 1.1 ms [User: 15.7 ms, System: 7.9 ms] Range (min … max): 22.4 ms … 29.0 ms 111 runs Summary './file.bash' ran 29.88 ± 1.65 times faster than './magika.bash' reply ebursztein 4 hours agoparentprevWe did release the npm package because indeed we create a web demo and thought people might want to also use it. We know it is not as fast as the python version or a C++ version -- which why we did mark it as experimental. The release include the python package and the cli which are quite fast and is the main way we did expect people to use -- sorry if that hasn't be clear in the post. The goal of the release is to offer a tool that is far more accurate that other tools and works on the major file types as we hope it to be useful to the community. Glad to hear it worked on your files reply m0shen 3 hours agorootparentThank you for the release! I understand you're just getting it out the door. I just hope to see it delivered as a native library or something more reusable. I did try the python cli, but it seems to be about 30x slower than `file` for the random bag of files I checked. I'll probably take some time this weekend to make a couple of issues around misidentified files. I'll definitely be adding this to my toolset! reply lebean 6 hours agoparentprevIt's for researchers, probably. reply m0shen 6 hours agorootparentYeah, there is this line: By open-sourcing Magika, we aim to help other software improve their file identification accuracy and offer researchers a reliable method for identifying file types at scale. Which implies a production-ready release for general usage, as well as usage by security researchers. reply lifthrasiir 8 hours agoprevI'm extremely confused about the claim that other tools have a worse precision or recall for APK or JAR files which are very much regular. Like, they should be a valid ZIP file with `META-INF/MANIFEST.MF` present (at least), and APK would need `classes.dex` as well, but at this point there is no other format that can be confused with APK or JAR I believe. I'd like to see which file was causing unexpected drop on precision or recall. reply HtmlProgrammer 6 hours agoparentMinecraft mods 14 years ago used to tell you to open the JAR and delete the META-INF when installing them so can’t rely on that one… reply supriyo-biswas 5 hours agoparentprevThe `file` command checks only the first few bytes, and doesn’t parse the structure of the file. APK files are indeed reported as Zip archives by the latest version of `file`. reply m0shen 4 hours agorootparentThis is false in every sense for https://www.darwinsys.com/file/ (probably the most used file version). It depends on the magic for a specific file, but it can check any part of your file. Many Linux distros are years out of date, you might be using a very old version. FILE_45: ./src/file -m magic/magic.mgc ../../OpenCalc.v2.3.1.apk ../../OpenCalc.v2.3.1.apk: Android package (APK), with zipflinger virtual entry, with APK Signing Block reply supriyo-biswas 4 hours agorootparentInteresting! I checked with file 5.44 from Ubuntu 23.10 and 5.45 on macOS using homebrew, and in both cases, I got “Zip archive data, at least v2.0 to extract” for the file here[1]. I don’t have an Android phone to check and I’m also not familiar with Android tooling, so is this a corrupt APK? [1] https://download.apkpure.net/custom/com.apkpure.aegon-319781... reply m0shen 3 hours agorootparentThat doesn't appear to be a valid link. Try building `file` from source and using the provided default magic database. reply supriyo-biswas 3 hours agorootparentI also tried this with the sources of file from the homepage you linked above, and I still get the same results. You could try this for yourself using the same APKPure file which I uploaded at the following alternative link[1]. Further, while this could be a corrupt APK, I can’t see any signs of that from a cursory inspection as both the `classes.dex` and `META-INF` directory are present, and this is APKPure’s own APK, instead of an APK contributed for an app contributed by a third-party. [1] https://wormhole.app/Mebmy#CDv86juV9H4aRCL2DSJeDw reply charcircuit 6 hours agoparentprevapks are also zipaligned so it's not like random users are going to be making them either reply lopkeny12ko 4 hours agoprevI don't understand why this needs to exist. Isn't file type detection inherently deterministic by nature? A valid tar archive will always have the same first few magic bytes. An ELF binary has a universal ELF magic and header. If the magic is bad, then the file is corrupted and not a valid XYZ file. What's the value in throwing in \"heuristics\" and probabilistic inference into a process that is black and white by design. reply vintermann 1 hour agoparentConsider, it's perfectly possible for a file to fit two or more file formats - polyglot files are a hobby for some people. And there are also a billion formats that are not uniquely determined by magic bytes. You don't have to go further than text files. reply potatoman22 4 hours agoparentprevThis also works for formats like Python, HTML, and JSON. reply LiamPowell 4 hours agorootparentfile (https://www.darwinsys.com/file/) already detects all these formats. reply ebursztein 4 hours agorootparentIndeed but as pointed out in the blog post -- file is significantly less accurate that Magika. There are also some file type that we support and file doesn't as reported in the table. reply LiamPowell 4 hours agorootparentI can't immediately find the dataset used for benchmarking. Is file actually failing on common files or just particularly nasty examples? If it's the latter then how does it compare to Magika on files that an average person is likely to see? reply schleck8 3 hours agorootparent> Is file actually failing on common files or just particularly nasty examples? If it's the latter then how does it compare to Magika on files that an average person is likely to see? That's not the point in file type guessing is it? Google employs it as an additional security measure for user submitted content which absolutely makes sense given what malware devs do with file types. reply vunderba 8 hours agoprevAs somebody who's dealt with the ambiguity of attempting to use file signatures in order to identify file type, this seems like a pretty useful library. Especially since it seems to be able to distinguish between different types of text files based on their format/content e.g. CSV, markdown, etc. reply thorum 8 hours agoprevSupported file types: https://github.com/google/magika/blob/main/docs/supported-co... reply s1mon 7 hours agoparentIt's surprising that there are so many file types that seem relatively common which are missing from this list. There are no raw image file formats. There's nothing for CAD - either source files or neutral files. There's no MIDI files, or any other music creation types. There's no APL, Pascal, COBOL, assembly source file formats etc. reply photoGrant 3 hours agorootparentYeah this quickly went from 'additional helpful tool in the kit' to 'probably should use something else first' reply vintermann 1 hour agorootparentprevWell, what they used this for at Google was apparently scanning their user's files for things they shouldn't store in the cloud. Probably they don't care much about MIDI. reply _3u10 7 hours agorootparentprevNo tracker / .mod files either, just use file. reply ebursztein 4 hours agorootparentThanks for the list, we will probably try to extend the list of format supported in future revision. reply NiloCK 8 hours agoprevA somewhat surprising and genuinely useful application of the family of techniques. I wonder how susceptible it is to adversarial binaries or, hah, prompt-injected binaries. reply jamesdwilson 7 hours agoparentFor the extremely limited number of file types supported, I question the utility of this compared to `magic` reply star4040 5 hours agoparentprevIt gets a lot of binary file formats wrong for me out-of-the-box. I think it needs to be a bit more effective before we can truly determine the effectiveness of such exploits. reply dghlsakjg 8 hours agoparentprev“These aren’t the binaries you are looking for…” reply thangalin 2 hours agoprevMy FOSS desktop text editor performs a subset of file type identification using the first 12 bytes, detecting the type quite quickly: * https://gitlab.com/DaveJarvis/KeenWrite/-/blob/main/src/main... There's a much larger list of file signatures at: * https://github.com/veniware/Space-Maker/blob/master/FileSign... reply Labo333 1 hour agoprevI wonder what the output will be on polyglot files like run-anywhere binaries produced by cosmopolitan [1] [1]: https://justine.lol/cosmopolitan/ reply krick 5 hours agoprevWhat are use-cases for this? I mean, obviously detecting the filetype is useful, but we kinda already have plenty of tools to do that, and I cannot imagine, why we need some \"smart\" way of doing this. If you are not a human, and you are not sure what is it (like, an unknown file being uploaded to a server) you would be better off just rejecting it completely, right? After all, there's absolutely no way an \"AI powered\" tool can be more reliable than some dumb, err-on-safer-side heuristic, and you wouldn't want to trust that thing to protect you from malicious payloads. reply nindalf 5 hours agoparent> no way an \"AI powered\" tool can be more reliable The article provides accuracy benchmarks. > you would be better off just rejecting it completely They mention using it in gmail and Drive, neither of which have the luxury of rejecting files willy-nilly. reply n2d4 5 hours agoparentprevVirus detection is mentioned in the article. Code editors need to find the programming language for syntax highlighting of code before you give it a name. Your desktop OS needs to know which program to open files with. Or, recovering files from a corrupted drive. Etc It's easy to distinguish, say, a PNG from a JPG file (or anything else that has well-defined magic bytes). But some files look virtually identical (eg. .jar files are really just .zip files). Also see polyglot files [1]. If you allow an `unknown` label or human intervention, then yes, magic bytes might be enough, but sometimes you'd rather have a 99% chance to be right about 95% of files vs. a 100% chance to be right about 50% of files. [1] https://en.wikipedia.org/wiki/Polyglot_(computing) reply VikingCoder 4 hours agoprevWhat does it do with an Actually Portable Executable compiled by Cosmopolitan libc compiler? reply supriyo-biswas 4 hours agoparentIt’s reported as a PE executable, `file` on the other hand reports it as a “DOS/MBR boot sector.” reply diimdeep 13 minutes agoprev> Magika: AI powered fast and efficient file type identification of 116 file types with proprietary puny model with no training code and no dataset. > We are releasing a paper later this year detailing how the Magika model was trained and its performance on large datasets. And ? How do you advance industry by this googleblog post and source code that is useless without closed source model ? All I see here is loud marketing name, loud promises, but actually barely anything useful. Hooly rooftop characters sideproject? reply userbinator 8 hours agoprevToday web browsers, code editors, and countless other software rely on file-type detection to decide how to properly render a file. \"web browsers\"? Odd to see this coming from Google itself. https://en.wikipedia.org/wiki/Content_sniffing was widely criticised for being problematic for security. reply rafram 7 hours agoparentContent sniffing can be disabled by the server (X-Content-Type-Options: nosniff), but it’s still used by default. Web browsers have to assume that servers are stupid, and that for relatively harmless cases, it’s fine to e.g. render a PNG loaded by aneven if it’s served as text/plain. reply account-5 3 hours agoprevAssuming that I've not misunderstood, how does this compare to things like: TrID [0]?? Apart from being open source. [0] https://mark0.net/soft-trid-e.html reply JacobThreeThree 3 hours agoparentThe bulk of the short article is a set of performance benchmarks comparing Magika to TrID and others. reply account-5 3 hours agorootparentArgh, the risks of browsing the web without JavaScript and/or third party scripts enabled, you miss content, because rendering text and images on the modern web can't be done without them, apparently. (Sarcasm). You are of course correct. I can see the images showing the comparison. Apologies. reply Nullabillity 5 hours agoprevIt seems to detect my Android build.gradle.kts as Scala, which I suppose is a kind of hilarious confusion but not exactly useful. reply vrnvu 7 hours agoprevAt $job we have been using Apache Tika for years. Works but occasionally having bugs and weird collisions when working with billions of files. Happy to see new contributions in the space. reply rfl890 8 hours agoprevWe have had file(1) for years reply samtheprogram 8 hours agoparentThis is beyond what file is capable of. It’s also mentioned in the third paragraph. RTFA. reply wruza 6 hours agorootparentSome HN readers may not know about file(1) even. It's fine to mention that $subj enhances that, but the rtfa part seems pretty unnecessary. reply Vogtinator 1 hour agorootparentprevFWICT file is more capable, predictable and also faster while being more energy-efficient at the same time. reply aitchnyu 4 hours agoparentprevThis group of Linux users used to brag Linux will identify files even if you change the extension, Windoze needs to police you about changing extension, nearly 20 years back. reply Am4TIfIsER0ppos 7 hours agoparentprevnext [3 more] [flagged] samtheprogram 7 hours agorootparentThis a 1mb Keras ML model that’s open source. I passionately dislike Surveillance Capitalism but bringing it up when it’s completely irrelevant only weakens the argument. RTFA. reply floobertoober 6 hours agorootparent> Please don't comment on whether someone read an article. \"Did you even read the article? It mentions that\" can be shortened to \"The article mentions that\". From the HN guidelines reply star4040 5 hours agoprevIt seems like it defeats the purpose of such a tool that this initial version doesn’t have polyglot files. I hope they’re quick to work on that. reply Imnimo 7 hours agoprevI wonder how big of a deal it is that you'd have to retrain the model to support a new or changed file type? It doesn't seem like the repo contains training code, but I could be missing it... reply johnea 7 hours agoprevThe results of which you'll never be 100% sure are correct... reply wruza 7 hours agoparentThey missed such an opportunity to name it \"fail\". It's like \"file\" but with \"ai\" in it. reply tamrix 6 hours agorootparentWhat about faile? reply rfoo 5 hours agoparentprevBut file(2) is already like that - my data files without headers are reported randomly as disk images, compressed archives or even executables for never-heard-of machines. reply plesiv 2 hours agoparentprevOther methods use heuristics to guess many filetypes and in the benchmark they show worse performance (in terms of precision). Assuming benchmarks are not biased, the fact that this approach uses AI heuristics instead of hard-coded heuristics shouldn't make it strictly worse. reply kazinator 6 hours agoprev> So far, libmagic and most other file-type-identification software have been relying on a handcrafted collection of heuristics and custom rules to detect each file format. This manual approach is both time consuming and error prone as it is hard for humans to create generalized rules by hand. Pure nonsense. The rules are accurate, based on the actual formats, and not \"heuristics\". reply cAtte_ 4 hours agoparentthe rules aren't based on the formats, but on a small portion of them (their magic numbers). this makes them inaccurate (think docx vs zip) and heuristic. reply Vt71fcAqt7 7 hours agoprevThis feels like old school google. I like that it's just a static webpage that basically can't be shut down or sunsetted. It reminds of when Google just made useful stuff and gave them away for free on a webpage like translate and google books. Obviously less life changing than the above but still a great option to have when I need this. reply a-dub 3 hours agoprevprobably a lot of interesting work going on that looks like this for the virustotal db itself. reply semitones 8 hours agoprevIs it really common enough for files not to be annotated with a useful/correct file type extension (e.g. .mp3, .txt) that a library like this is needed? reply SnowflakeOnIce 7 hours agoparentYes! Sometimes a file has no extension. Other times the extension is a lie. Still other times, you may be dealing with an unnamed bytestring and wish to know what kind of content it is. This last case happens quite a lot in Nosey Parker [1], a detector of secrets in textual data. There, it is possible to come across unnamed files in Git history, and it would be useful to the user to still indicate what type of file it seems to be. I added file type detection based on libmagic to Nosey Parker a while back, but it's not compiled in by default because libmagic is slow and complicates the build process. Also, libmagic is implemented as a large C library whose primary job is parsing, which makes the security side of me jittery. I will likely add enabled-by-default filetype detection to Nosey Parker using Magika's ONNX model. [1] https://github.com/praetorian-inc/noseyparker reply callalex 7 hours agoparentprevNothing is ever simple. Even for the most basic .txt files it’s still useful to know what the character encoding is (utf? 8/16? Latin-whatever? etc.) and what the line format is (,\\cr\\lf,\\lf) as well as determining if some maniac removed all the indentation characters and replaced them with a mystery number of spaces. Then there are all the container formats that have different kinds of formats embedded in them (mov,mkv,pdf etc.) reply cole-k 2 hours agorootparentA fun read in service of your first point: https://en.wikipedia.org/wiki/Bush_hid_the_facts reply m0shen 4 hours agoparentprevAt multiple points in my career I've been responsible for apis that accept PDFs. Many non-tech savvy people seeing this, will just change the extension of the file they're uploading to `.pdf`. To make matters worse, there is some business software out there that will actually bastardize the PDF format and put garbage before the PDF file header. So for some things you end up writing custom validation and cleanup logic anyway. reply hiddencost 8 hours agoparentprevmalware can intentionally obfuscate itself reply kushie 8 hours agoprevthis couldnt have been released at a better time for me! really needed a library like this. reply ebursztein 4 hours agoparentThanks :) reply petesergeant 6 hours agoparentprevTell us why! reply earth2mars 2 hours agoprev [–] how do i pronounce this? Myajika or MaGika? anyhow, its super cool. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "Google has released Magika, an AI-powered file-type identification system, as an open-source project on GitHub.",
      "Magika utilizes a custom deep-learning model to accurately detect binary and textual file types within milliseconds, even on a CPU.",
      "It outperforms other tools by 20% on a 1M files benchmark and is particularly effective in identifying textual files.",
      "Magika is already used internally by Google to improve file type identification and enhance user safety.",
      "Integration with VirusTotal will further improve the platform's efficiency and accuracy in detecting malicious code."
    ],
    "commentSummary": [
      "Magika is an AI-powered file type identification tool developed by Google.",
      "Some users express confusion and skepticism about its speed and limited file type detection compared to existing tools.",
      "Others appreciate its usefulness in specific applications and mention faster alternatives.",
      "Concerns are raised about open-source access to the training code and model.",
      "Accurate file type detection and security measures are seen as important considerations."
    ],
    "points": 356,
    "commentCount": 92,
    "retryCount": 0,
    "time": 1708045356
  },
  {
    "id": 39390965,
    "title": "Happy 33rd Anniversary to Lemmings: A Game that Changed the Scottish Gaming Industry",
    "originLink": "https://scottishgames.net/2024/02/14/it-was-33-years-ago-today-happy-birthday-lemmings/",
    "originBody": "POSTED ON 14/02/2024 BY SCOTTISHGAMES It Was 33 Years Ago Today: Happy Birthday Lemmings! Today, February 14th, 2024, marks the 33rd anniversary of Lemmings, the game that transcended mere entertainment to become a cultural icon and a catalyst for Scotland’s thriving game development industry. But before the green-haired hordes invaded screens worldwide, let’s rewind to 1991 and trace its remarkable journey. Born from the minds of DMA Design (now of course Rockstar North), a small Dundee studio, Lemmings was a revolutionary concept. Instead of blowing things you, you were tasked with saving the plummeting rodents’ lives. However, DMA’s genius lay in its execution. With charming character design (at an astonishingly small scale), addictive puzzle mechanics, and more than a touch of what would become DMA’s slapstick humour, they transformed a complex concept into a game anyone could pick up and play. Lemmings offered a simple premise: guide a predetermined number of lemmings to an exit by assigning them roles like blocker, climber, builder, and floater. But simplicity masks depth. Each level presented a unique challenge, requiring strategic thinking, quick reflexes, and a touch of trial-and-error gory death. Success was immediate. Lemmings conquered consoles and computers, selling over 15 million copies and becoming the UK’s best-selling game of 1991. Awards and accolades rained down, but perhaps the most significant impact was on Scottish gaming itself. Lemmings put DMA Design on the map, attracting talent and investment and inspiring the world’s first games degree. The Scottish Games Network spoke to several of the original team members to ask for their thoughts on the impact of the game: Mike Dailly, the creator of the original animation of tiny things being splattered, said: I’m constantly amazed at the legacy of Lemmings. Where ever I go, there are fans, old and new who love the game. With the style, and accessibility of it, it not only entertained, but brought families closer together as kids played with their non-game playing parents and grandparents. I get people getting in touch all the time telling me of their happy memories of playing it with their relatives who never had an interest in games before, and being able to share their hobby with them, meant the world to them. Even now at shows, some 33 years later, you’ll still see the odd person dressed up as a Lemming and expressing love for the game, the music, the sound effects, the characters – or how they were useless at it, but loved to just nuke them! Lemmings is still the game I’m most proud to have been a part of, in a world of first person shooters, it’s as popular now as it ever was with young and old alike Russell Kay, told us his dream is to bring the games to a new generation: 33 years ago we released a game that is still loved today that is very gratifying and I don’t think any of us would have believed you if we were told at the time. Over the years we have fallen in and out of love with the franchise but it holds a special place in our hearts, personally I would love to be able to update the characters and franchise but Sony hold onto the rights jealously, it would be fantastic to get a chance to see what the Lemmings would make of the modern gaming world! Lemmings’ influence resonated far beyond Scotland. It can be said to have popularised puzzle games, inspiring titles like The Incredible Machine. Its emphasis on physics and user-generated content laid the groundwork for future sandbox games (possibly even Minecraft…?) Moreover, its humour and memorable characters solidified DMA Design’s reputation for innovative, surprising and engaging gameplay, paving the way for future classics like Grand Theft Auto, the often overlooked (and far more bonkers) Tanktics, cult-classic Body Harvest and the underrated Wild Metal Country. Today, Lemmings remains a beloved puzzle classic, enjoying re-releases on various platforms and inspiring new generations of designers. But its legacy extends far beyond nostalgic pixelated memories. Dundee’s city centre plays host to a beloved series of statues of Lemmings, hard at work, climbing and bridging a garden gateway overlooking the river Tay. On the 20th anniversary in 2011 a plaque was unveiled at the bottom of Perth Road in the city, commemorating DMA’s first office, where the game was originally born. In 2022 Lemmings: Can You Dig It? a feature-length documentary was released, which charted the design and development of the original game and its impact upon gamers today. You can watch it here: Happy birthday Lemmings! Share the AWESOME Click to email a link to a friend (Opens in new window) Click to share on Facebook (Opens in new window) Click to share on Twitter (Opens in new window) Click to share on LinkedIn (Opens in new window) Click to share on Pinterest (Opens in new window) Click to share on Pocket (Opens in new window) Click to share on Tumblr (Opens in new window) Click to share on Reddit (Opens in new window) Click to print (Opens in new window) Like this: Loading... Categories dundee, Film, Scotland Tags anniversary, dma design, dundee, games, lemmings, scotland",
    "commentLink": "https://news.ycombinator.com/item?id=39390965",
    "commentBody": "Happy Birthday Lemmings (scottishgames.net)295 points by Timothee 10 hours agohidepastfavorite92 comments netcoyote 7 hours agoLemmings is such a fun game! I played many hours of it trying to perfectly solve its many puzzles. Lemmings inspired Ron Millar, a designer at Silicon & Synapse (later Blizzard Entertainment), to invent The Lost Vikings, our first original game: https://en.m.wikipedia.org/wiki/The_Lost_Vikings The original design for Vikings was very similar to Lemmings but saw massive changes during the course of development, going from many Vikings to five to eventually just three. We owe a debt of gratitude to the Lemmings devs for inspiring our efforts. reply alecthomas 49 minutes agoparentJust wanted to say I loved The Lost Vikings, thanks for many good memories :) reply kwar13 1 hour agoparentprevMany fond memories of The Lost Vikings! reply muzani 7 hours agoparentprevI loved the Lost Vikings as a kid! It's actually charmed me about as much as Lemmings, though if I had to pick, I still prefer Lemmings' dark humor. reply rob74 2 hours agorootparentYeah, the ambivalence between \"oh, I want to save every one of these cute little critters\" and \"f** this, I'm sick of it, I'll just click 'nuke' instead of pressing the escape key to restart\" was really something special... reply cptskippy 6 hours agoparentprevThe Lost Vikings was one of my favorite games growing up. There have been so many attempts to copy the formula (e.g. Trine) but none have been so memorable or endearing. The character and level designs are wonderful. reply rob74 2 hours agorootparentTwo more memorable clones (that also changed the formula a bit, but the basic premise of \"save x critters to progress\" is the same) are \"World of Goo\" (https://store.steampowered.com/app/22000/World_of_Goo/) and \"Spirits\" (https://store.steampowered.com/app/210170/Spirits/). reply jacobolus 5 hours agorootparentprevDoes anyone know if there's a good way to play Three Vikings on a modern laptop or iPad? reply opengears 4 hours agorootparentYou want to look into emulators https://en.wikipedia.org/wiki/Emulator . vAmigaWeb is an Amiga emulator that should also work on iPad. https://vamigaweb.github.io/doc/about.html reply imadethis 3 hours agorootparentprevIt's included in the Blizzard Arcade Collection, which you can at least get on PC today for $9.99 USD. reply BuildTheRobots 8 hours agoprevDHTML Lemmings is still playable in a modern browser: https://www.elizium.nu/scripts/lemmings/ It's dated 2004, but I'm convinced I remember playing it earlier. reply micheljansen 48 minutes agoparentThe first version is from 2003: https://gathering.tweakers.net/forum/list_message/18377456#1... It got taken down shortly after that by BREIN, the Dutch copyright watchdog, but it lives on as Pumpkins. Amazing that JS from the Internet Explorer era still works well 20 years later. reply tsukurimashou 1 hour agoparentpreva shame it has no sound reply micheljansen 45 minutes agorootparentIt used to (see control.js) but it doesn't seem to be working anymore. reply shaunxcode 8 hours agoparentprevI definitely played it around 2001 when it was posted to slashdot! reply andirk 3 hours agoparentprevCan I please get some codes to do further levels? reply gnicholas 2 hours agorootparentThe furthest I have handy is 12: KOMHCMOMCX reply thom 8 hours agoprevWhenever I pass this building in Sheffield, I immediately think “you need bashers this time”. https://www.sheffield.ac.uk/acse/department/facilities/diamo... reply Symbiote 2 hours agoparentLemmings tourists might also appreciate the statue in Dundee: https://www.atlasobscura.com/places/lemmings-statue (OK, also linked in the article.) reply boredhedgehog 32 minutes agoprevI wonder why the open source ports never caught on like they did for other games. In any thread about Transport Tycoon, it's five minutes until people start talking about OpenTTD, yet NeoLemmix and Lix are barely known, despite all the innovation and custom level design taking place there. reply louthy 1 hour agoprevIt always blew my mind how well animated the 12 pixel high lemmings were. The dynamics were incredible. reply justinludwig 3 hours agoprevI loved Lemmings (the game) as a kid! But as an adult, I found out everything I thought I knew about lemmings (the animal) was a lie: https://www.snopes.com/fact-check/white-wilderness-lemming-s... reply jl6 2 hours agoprevI first played Lemmings on a Mac IIsi, and later on an Amiga 1200. I remember the pixel-perfect timing being brutally difficult with the low-quality Amiga ball mouse, but I played it enough that I can still hum all the tunes. reply rob74 2 hours agoparentI remember that the \"P\" key was your friend... and I never thought the Amiga mouse was bad quality, but maybe those shipped with the Amiga 500 were still better, I used to clean it regularly, and of course I hadn't used optical mice until then :) reply antihipocrat 7 hours agoprevThere was one level that stumped me for a long time, it was the level that introduced the one dig direction game mechanic. I was young and there was no internet to look up a solution. One night I dreamed the solution, how obvious it was! Even now I still remember this experience when confronted with an intractable problem. reply bombcar 7 hours agoparentI worked out the rescuing your blocker trick on my own, but had to learn the build to turn around trick from a strategy guide. reply jamiek88 1 hour agorootparentHow do you rescue the blocker?! reply mnw21cam 57 minutes agorootparentYou remove the ground it is standing on, and it stops being a blocker. reply Symbiote 1 hour agorootparentprevI think the acceptable ways to find that out is watching a parent or older sibling play the game, or figuring it out yourself ;-) reply cwillu 9 hours agoprevhttps://archive.org/details/lemmings_2_the_tribes_1992 reply advael 7 hours agoprevI loved lemmings as a kid, and bits of the soundtrack get stuck in my head to this day (I know a lot of it is just chippy arrangements of otherwise famous public domain music, but the arrangements were great). Even at the time it was a really original concept in a way that people seldom manage, like something that could have (but as far as I can tell didn't) become its own \"genre\" of game reply Symbiote 2 hours agoparentMany of those traditional or folk songs I first heard in Lemmings. \"Dad, are they playing Lemmings music?\" \"It's called Pachebel's Canon, it's from the 17th century!\" https://m.youtube.com/watch?v=QwXthGJfHLc&t=118s (And I choose that one as the forlorn, mournful sound seems most appropriate as all the lemmings march to their death.) Documentary: https://m.youtube.com/watch?v=RbAVNKdk9gA reply rob74 36 minutes agorootparentOther well-known tunes include the ouverture from Orphée aux enfers by Offenbach (better known as \"the can-can music\") and How much is that lemming, er, doggie in the window reply wackget 5 hours agoparentprevI could have sworn I saw a documentary where they talked about having legal issues with some of the music, because some of it (e.g. \"She'll Be Coming Round the Mountains\") was not public domain. There's a little bit written about it on Wikipedia but I wish I could find the documentary: https://en.wikipedia.org/wiki/Lemmings_(video_game)#Developm... reply advael 4 hours agorootparentO. My mistake, thanks for letting me know Also, if you're not being facetious and actually didn't notice, they do have a youtube embed of the full documentary made in 2022 at the bottom of the linked article. I haven't taken the time to watch it, but maybe that's the one you're thinking of reply tempodox 2 hours agoprevLemmings was a game that I thoroughly enjoyed at the time. Happy birthday! reply DeathArrow 1 hour agoprevI was a poor child when Lemmings came out, so I didn't have a PC. reply FirmwareBurner 56 minutes agoparentYou can play it today. reply qingcharles 9 hours agoprevI still remember the day I walked into my local games store and bought it off the shelf. It was flying off the shelves. I think there was a cover disc demo the previous month which had started the hype machine. reply jedberg 8 hours agoprevAnnnnnnd now I'm playing Lemmings. reply ensocode 1 hour agoprevMy first contact to computer games. Now thinking of introducing computers with this to my 5 yo reply markx2 2 hours agoprevIf the Lemmings games were remastered and slated for release I'd pay full price in a heartbeat. I'm sure a Kickstarter for this purpose would be very well received. reply rob74 22 minutes agoparentUnfortunately Sony has been sitting on the IP for Lemmings for quite some time now and hasn't done a lot with it. There was a mobile game a few years ago however (https://play.google.com/store/apps/details?id=com.sadpuppy.l...), but apparently the free version is pretty ad-infested (haven't tried it yet). There was also \"Lemmings Revolution\" (https://en.wikipedia.org/wiki/Lemmings_Revolution) which is over 20 years old by now, but tried to translate the original concept into something that would look good in 3D. I thought it was ok, but didn't enjoy it quite as much as the originals (which of course could have something to do with the fact that I was younger when I played the original games). reply willvarfar 3 hours agoprevI remember Lemmings! I remember getting into programming by trying to make games because of games like Lemmings! So where is the outlet? (I just did a search for Ludum Dare, and it seems ... dead?) reply unwind 49 minutes agoparentDead? The schedule page [1] has recent and upcoming instances scheduled, at least: Ludum Dare 54 — September 29th - October 2nd, 2023 Ludum Dare 55 — April 12th - 14th, 2024 Ludum Dare 56 — October 4th - 7th, 2024 I never tried it, I don't have a quickly accessible game programming framework. Nor the time, heh. [1]: https://ludumdare.com/#schedule reply dmurray 1 hour agoparentprevPretty sure Ludum Dare is still around; a friend competed in a recent one. The website looks a bit behind, with a YouTube video and calls for signups for a 2022 event. But the competition still seems to be running and got \"an avalanche of submissions\" for the most recent event in September 2023 [0]. Maybe you can find more about it on Reddit [1], and there's also mention of a Discord server. [0] https://flashlight13.medium.com/ludum-dare-54-hidden-gems-by... [1] https://www.reddit.com/r/ludumdare/ reply garquis 4 hours agoprevFirst video game I remember playing. Dad worked at a warehouse for the local school district and when I’d go to work with him, he’d set me up on their IBM PC and let me play lemmings the entire day. Truly loved that game reply torbengee 8 hours agoprevLOL I just played through Lemmings in one of those DosBox emulators a few days ago ... so much fun!! The music alone brought back some good memories. reply vintermann 1 hour agoprevTim Wright's Lemmings music is low-key brilliant. It has a deliberately rough and dorky instrumentation with very \"synthetic\" trumpets and accordion (You can make much \"better\" instrumented music on the Amiga, and we know Tim could do that too!). It is somehow as cute and vexing as the little critters themselves. And yet there's that subtle element of old English-Scottish folk that makes it magical. reply johndhi 9 hours agoprevSo many memories reply mdekkers 54 minutes agoprevAlso see https://www.lemmingsforums.net/index.php?topic=5306.0 for info on where to find and play Lemmings! reply gokhan 8 hours agoprevvgalemmi tgalemmi Don't know why I still remember those. reply archsurface 9 hours agoprevOh I enjoyed Lemmings. Nice flashback. reply Razengan 7 hours agoparent> Nice flashback. Another great game from that era ;) reply vardump 4 hours agorootparentFrom another world. reply Razengan 4 hours agorootparentFlashback 2 came out a few months ago: https://store.steampowered.com/app/2008420/Flashback_2/ reply Razengan 9 hours agoprevWe need some modern games like Lemmings or the \"classic\" 2D Worms. HOW did they do that pixel-perfect terrain destruction anyway? reply FirmwareBurner 8 hours agoparent>We still don't have any modern games like Lemmings or the \"classic\" 2D Worms That's like complaining we haven't made a modern Elvis Presley or Michael Jackson or that we haven't remade The Godfather. If the originals are so simple, accessible, and so good, what more could you bring to the table with a new modern version to guarantee a big sales success to offset the risk and cost of starting such and endeavor when gamers can just play the existing originals. Not everything needs a reboot/remake, especially if perfection has already been achieved. reply selcuka 8 hours agorootparent> If the originals are so good and can be played today on modern systems, what more could you bring to the table with modern versions to guarantee a big success. That's a weird deduction. Everything can be improved upon. Why do we have loads of modern games like Doom, for example? It was good too, and can be played today on modern systems. reply nottorp 1 hour agorootparentDoom, like Lemmings and Worms, was the first of its kind and you won't be able to recreate the experience just by redoing the graphics. Not to mention that when people say \"improved\" they usually mean \"adding more stuff\". More isn't necessarily better. reply samatman 8 hours agorootparentprev> Everything can be improved upon Arguable. I've seen variations of Tetris, but never improvements. Nor do I think you can improve stud poker, or Go. reply toast0 7 hours agorootparentSome of the early versions of Tetris only let you rotate one direction. Adding counter rotation is a clear improvement. I like the multiplayer versions over the years. The Tetris Effect is pretty fun, although maybe not strictly an improvement. I'm a little on the fence about 7-bag, because it's a little too evenly distributed, but early Tetris had some gnarly distribution. reply autoexec 6 hours agorootparentI had an old job once where the team all played Tetrinet and it was fun, but it did feel very different from normal Tetris. reply Eric_WVGG 7 hours agorootparentprevTetris Effect is Tetris polished to a freakin diamond. reply toast0 6 hours agorootparentI enjoy it a lot, but some of the people I've shared it with find the atmosphericness distracting and prefer a Tetris that's only business. reply Razengan 6 hours agorootparentprevYou can still improve the UI and UX around the gameplay. See the various online Go or Chess servers for example. reply FirmwareBurner 8 hours agorootparentprevApples to oranges. Doom is a different genre. Some genres, like Worms, just peak much sooner than others, like Doom, and don't benefit from newer graphics or technological improvements. Just like UX design, at some point you peak, and any more changes you try to add for the sake of improvements, just end up making the product worse. Look at current commercial operating systems or at Reddit. They also made a 3D Worms game a while back and it was a massive flop. Often, simpler is better. Sure, everything can always be improved an you might hypothetically be able to build an even better Worms game than the original, but since the bar is already so high, you have very little chance of topping it and all the risks of failure. reply autoexec 6 hours agorootparentprevI'm still waiting for FMV games to come back into fashion. They were a neat blend of theater and adventure games (which is another genre that doesn't get enough love) reply caf 8 hours agorootparentprevWorms was already a remake of Scorched Earth, wasn't it? reply GauntletWizard 7 hours agorootparentWorms is in the same genre as Scorched Earth and owes it a lot for inspiration, but it adds a ton of distinct weapons and movement technique that certainly qualifies it as it's own game. reply chongli 3 hours agorootparentYeah! This genre is called \"artillery games\" [1] and it has an impressive number of titles going all the way back to 1972! Scorched Earth is at least the 16th game in the genre, albeit the most famous pre-Worms. My favourite iteration growing up was called Dome Wars [3] and it's not even on that Wikipedia list! [1] https://en.wikipedia.org/wiki/Artillery_game [2] https://en.wikipedia.org/wiki/List_of_artillery_video_games [3] https://macintoshgarden.org/games/dome-wars reply muzani 6 hours agorootparentprevI mean Android is sadly lacking of any of these kinds of games. There were great Worms clones back in the day as well, now there are afaik, none. It reminds me of rock as a genre. As a teenager, rock stars were everywhere, but there's barely any new rock bands after 2010. It doesn't mean the genre has achieved perfection, but everyone who would be doing rock is now doing something else. There was a resurgence in Interactive Fiction about 10 years ago, which evolved into AIF (thanks internet), which then disappeared in just 1-2 years, to be replaced by all these Ren'Py games. There's a huge gap and demand for Guitar Hero type of games, but nobody wants to make them. (Maybe related to the decline of rock, as there's still beat games) reply jamiek88 1 hour agorootparentAIF? reply muzani 40 minutes agorootparentAdult IF. There's some incredibly detailed mechanics, but I'll spare the details. And once people couldn't make the mechanics better, they had to focus on plot, puzzles, or images (though puzzles went against the spirit of IF). It got to a point where there were large communities like the roguelikes, awards, and suddenly it collapsed after things got too ambitious or I guess after everyone has seen everything in the genre. I think there might be a resurgence now or later with Twine and Patreon though. reply Razengan 7 hours agorootparentprevWow, then in that case we should stop making any FPS games because we already have Doom, no more RPGs because Ultima exists, and no more movies because there's Bambi. reply nottorp 1 hour agorootparentHaven't they stopped making FPS games? Multiplayer first dudebro \"properties\" don't count. Serious Sam seems to survive. They tried to continue Doom but it wasn't Doom so much. What else is there? reply snerbles 9 hours agoparentprev> We still don't have any modern games like Lemmings or the \"classic\" 2D Worms.. or do we? Noita comes to mind. Also includes some pretty wild fluid dynamics. > HOW did they do that pixel-perfect terrain destruction anyway?? Usually the terrain is a bitmap, and various effects paint/erase it. reply cwillu 9 hours agoparentprevThe video framebuffer isn't rendered from the game state, it is the game state. reply chongli 8 hours agorootparentThat may have been the case for the original Lemmings — where the background is black so you can collision test directly against black pixels — but newer games have background textures. If you want to have complex backgrounds and terrain textures with pixel-perfect collisions and terrain modification then you’ll likely want to keep separate buffers for foreground and background. Then your game engine would operate on a bitmask for collision and destruction of terrain, and you’d construct the framebuffer by blitting [1] the foreground and background using the mask to select between them. [1] https://en.wikipedia.org/wiki/Blitter reply vardump 4 hours agorootparentFor example Amiga and most 16-bit consoles could just have two (or more) playfields (like layers or screen size sprites) superimposed on each other. For the game code those pixels would still be \"black\", well, transparent, even with background graphics showing through. No blitting required, playfields were drawn by the display hardware at scanout. reply prmoustache 1 hour agoparentprev> We need some modern games like Lemmings or the \"classic\" 2D Worms. Yes we have. https://hedgewars.org/ reply Eric_WVGG 7 hours agoparentprevThe humor is occasionally (often) crude, but Zombie Night Terror is a fantastic modern Lemmings-style game. You run a zombie invasion, the zombies have attributes not unlike the ones from Left 4 Dead, but the gameplay is pure Lemmings. https://www.zombienightterror.com (Incidentally the best game I've ever played on an iPad.) reply kibwen 8 hours agoparentprevWhile I wouldn't quite call Liero \"modern\", dating from 1998, the modern part is that you can play it multiplayer in your browser instantly: https://www.webliero.com/ There's also King Arthur's Gold, which is a free multiplayer game that I'm sure only has like ten players online these days but is an absolute hoot regardless: https://store.steampowered.com/app/219830/King_Arthurs_Gold/ reply chongli 3 hours agorootparentKing Arthur's Gold looks familiar! Must be an homage to the hidden gem King Arthur's World [1] for the SNES. I played the heck out of that game. Fantastic music and clearly an interesting take on the Lemmings genre! [1] https://en.wikipedia.org/wiki/King_Arthur%27s_World reply xtracto 8 hours agoparentprevI remember enjoying a later version of lemmings called lemmings tower or something similar. It was pretty cool. reply RGamma 9 hours agoparentpreveets (2006) is similar. reply adzm 8 hours agoprevLet's go! reply th0ma5 8 hours agoprevFirst time I ever stayed up all night playing a game it was Lemmings. Second time was Angry Birds lol. I don't game much. reply orionblastar 9 hours agoprevI played Lemmings on my Amiga 1000. Later when I bought a 386DX PC Clone I bought Lemmings for DOS and VGA. Open Source version is Pingus: https://pingus.seul.org/ reply sirspacey 8 hours agoparentMe too man!! What an amazing time that was. reply fourseventy 9 hours agoprevlove that game reply ijhuygft776 6 hours agoprev [–] a classic. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The game Lemmings, developed by DMA Design, celebrated its 33rd anniversary today.",
      "Lemmings was a groundbreaking game that focused on saving the lives of the characters rather than destroying them.",
      "The game's success, selling over 15 million copies, helped catalyze Scotland's game development industry and inspired the world's first games degree."
    ],
    "commentSummary": [
      "The website discussions primarily focus on the game Lemmings and its impact on other games.",
      "Users reminisce about their experiences with Lemmings and explore the idea of playing it on modern devices.",
      "The discussions also cover topics such as the longevity and effectiveness of JavaScript, the iconic music in Lemmings, and the desire for a remastered version of the game."
    ],
    "points": 296,
    "commentCount": 92,
    "retryCount": 0,
    "time": 1708040934
  },
  {
    "id": 39385228,
    "title": "The Three Virtues of a Great Programmer: Laziness, Impatience, and Hubris",
    "originLink": "https://thethreevirtues.com/",
    "originBody": "Three Virtues According to Larry Wall(1), the original author of the Perl programming language, there are three great virtues of a programmer; Laziness, Impatience and Hubris Laziness: The quality that makes you go to great effort to reduce overall energy expenditure. It makes you write labor-saving programs that other people will find useful and document what you wrote so you don't have to answer so many questions about it. Impatience: The anger you feel when the computer is being lazy. This makes you write programs that don't just react to your needs, but actually anticipate them. Or at least pretend to. Hubris: The quality that makes you write (and maintain) programs that other people won't want to say bad things about. (1) Quoted from \"Programming Perl\", 2nd Edition, O'Reilly & Associates, 1996 This is a website recovered from the Wayback Machine. threevirtues.com was orginally made by Daniel Sherer and is preserved here for historical purposes. Please contact admin@aronwk.com for any inquiries.",
    "commentLink": "https://news.ycombinator.com/item?id=39385228",
    "commentBody": "Three virtues of a great programmer (thethreevirtues.com)269 points by tosh 16 hours agohidepastfavorite104 comments neilv 8 hours agoLaziness, Impatience, and Hubris were especially clear/obvious in Perl at the time. Perl was a gazillion times more powerful than Bourne and C-shell (including all the Unix shell tools like `awk`), much more rapid than working in C, incredibly terse (perhaps too much so), and also portable (to all the oddball systems you might have). And the purposes to which Perl was put were often to automate things you'd been doing manually, or that you couldn't do without Perl. You'd be quietly doing big things with Perl. And there were sayings about how you'd automated your job, and presumably spent your time writing more Perl scripts and reading Usenet. And the occasional joke of replacing someone else with a one-line Perl script. Also, note that not only was this before the dotcom boom (when programmers suddenly were no longer nerds but getting rich and fashionable), but also-- a lot of the programmers using Perl professionally weren't even professional programmers, but actually sysadmins or random university researchers, who happened to have the power of Perl. The majority of professional programmers on Unix actually didn't know Perl. So, Perl people speaking of Perl people in terms of vices could be seen as a self-deprecating, joking spin conscious of the unusual power that they wielded. reply picometer 13 hours agoprevI’ve had a variety of responses to this list over my programming life (~10 years hobby, ~10 years professional). When I first encountered them as a hobbyist, they were surprising, as perhaps intended, due to the framing of classic vices as virtues. On some reflection though, it made sense, and shaped my understanding of programming as somehow _inherently different_ than other types of creation. When I got started with a professional career, they functioned to soften the edge of anxiety. It meant that the community of programmers who came before me - which presumably included Larry Wall - would understand that these patterns in coder behavior were ultimately beneficial and that I would maybe fit in with a corporate programming environment. (Now I know that this isn’t always true; sometimes coworkers, both programmers and non-programmers, don’t always realize these unintuitive points, and in some special cases, those programmer instincts aren’t actually valuable.) At some point, I disagreed with the framing. As others have pointed out, the patterns can be reframed as classic or functional virtues such as curiosity. Then I backpedaled and realized that the framing is important because these are unintuitive patterns and it makes us re-think habitual incentives that reward, e.g., work that is more productive but not more effective. How did it hit me now? I realize that it’s also related to power dynamics. Programmers are assets to their employers but they’re also potential disrupters. The traditional “virtuous” framing of potentially-less-effective behavior, like patience, is related to the organizing and taming of a workforce. It’s also related to the types of problems we encounter. When we work with computers, Larry’s list does usually lead to more effective outcomes. But when working with other humans, who have their own agency and idiosyncrasies, the traditional virtues are better-adapted behavior. This is also more true for the complex technical systems we deal with nowadays. So, as our careers transition from programming to system engineering and/or management, the traditional virtues become more relevant. Anyhow, this is an evergreen and thought-provoking nugget of wisdom. Thanks to Larry Wall and those who have preserved it. reply Enk1du 12 hours agoprevIt was kind of a thing at the time. In the Afterword of Æleen Frisch's Essential System Administration (also 1991) subtitled \"Don't Forget to Have Fun\", there are listed _seven_ virtues of a system administrator: * Flexibility: being able to wriggle out of tight spots and escape when irate users seem to have you cornered * Ingenuity: realizing that you can use syslog to send messages to your friend on another system * Patience: remaining capable of waiting until the final sendmail bug is fixed * Persistence: the compulsion to try just-one-more-thing to fix a problem before going home * Adherence to Routine: insisting on real milk and sugar-in-the-raw in your coffee (which is Kona or nothing) * Attention to Detail: noticing that the clock on one of your systems is using Aleutian time, and changing all the others to match * Laziness: writing a 250-line Perl script to avoid typing 15 characters I took the last one to heart and have admired those who could utilize the first one, because I never could. reply baerrie 11 hours agoprevMy whole life I have been called lazy. In filmmaking as an assistant this was a weakness, work harder not smarter and all that. I still feel insecure about it sometimes but over the past few years of transitioning into coding full time I have learned that this is my best trait. Life is short, you must demand to live your life how you want otherwise you will be convinced that working hard for someone else makes sense. reply cloverich 6 hours agoparentCongrats on the jump, changing careers is hard! reply lr4444lr 8 hours agoprevThat last one (\"hubris\") I'm going to call out. Maybe the author means another word, for what he describes, but the actual \"hubris\" I'm seeing among my colleagues is the belief that lots of people out there don't know how to write code, but that their own $%^& doesn't stink. It's the utter subjectiveness of \"best practices\" that aren't tied to actual issues of performance, security, or flexibility, or worse - blowing one or more of these attributes of good code way out of proportion to the actual importance of the code. And \"readability\"? Don't get me started ... there's hardly a linter rule that I haven't seen turned into a caricature of what it was intended to do. What devs do is part art and part science, and there's hardly consensus on which part is which. reply xarope 7 hours agoparentI interpreted this \"hubris\" to mean that I believe I can make a difference, rather than feel that I can't contribute. You can understand why I, personally, would think this is a virtue. reply RangerScience 10 minutes agorootparent“audacity” might be a better word for you for that :) (To be clear: I mean this as a good thing. Audacity… seems pretty important, and very nice to have, at the right times and places) reply dt3ft 3 hours agoparentprevI especially love it when these people turn code which can be debugged (breakpoints can be set and hit) into one-liners for no reason which you have to rewrite in order to even set breakpoints. Well done, I hope you’re proud. reply ruined 2 hours agorootparentyou can't debug within a line? reply db48x 44 minutes agorootparentYea, if you cannot set a breakpoint on an arbitrary expression, then your tools are bad and you should feel bad. On the other hand the dev tools in the average web browser lacked that capability until relatively recently, so it’s not an uncommon experience. reply hirvi74 7 hours agoparentprevI just look at popular Github projects and ask myself why doesn't my code look that nice? I completely agree with your take though. There is so much \"distraction\" in what are best practices, readability, etc.. It's all so subjective. Best practice for what? Readability for who? I feel like software engineering : engineering :: psychiatry : medicine. reply tacitusarc 4 hours agorootparentI recommend this talk on that subject: https://youtu.be/CmIGPGPdxTI?si=vOxiooCemwR7CygI I found it incredibly interesting. reply Izkata 5 hours agoparentprevYeah, \"pride\" fits better with his description. reply hyperhello 14 hours agoprevI don’t have the time or want to read the page, but I’m sure I’m already as good as him. reply artemonster 33 minutes agoparentMaybe someone can do a quick TL;DR; version of it? :) reply amiantos 14 hours agoparentprevYou're only dunking on yourself here, the page is four sentences long. Being proudly ignorant is still just ignorance. reply stacktraceyo 12 hours agorootparentYikes reply petsfed 14 hours agorootparentprevYou missed the joke. Should I diagram it for you? reply drewcoo 13 hours agorootparentIn UML, the joke would be much longer. And is the punch line solid or dotted? reply slowmovintarget 5 hours agorootparentSelf-composite diamond for recursive association. reply teach 14 hours agorootparentprevwhoosh reply GMoromisato 14 hours agoprevI'd add Curiosity instead of Impatience. Impatience is related to Laziness. In both cases we want the computer to do the work instead of us. But Curiosity is orthogonal and important. The best programmers I know were always curious: Why was it built that way? Why does it give that output? Why did she say that? Curiosity is the beginning of knowledge. If you're not curious, you will miss out on a lot of opportunities for learning and improvement. reply woooooo 10 hours agoparentIt doesn't work as well rhetorically as having all 3 virtues be typically thought of as flaws. reply simonkagedal 2 hours agorootparentI was thinking that something about having communicative skills should be added to the list, but struggled to reframe that as a flaw… any ideas? reply kweingar 4 hours agorootparentprevCuriosity is a classical vice, I think it works reply bryanrasmussen 1 hour agorootparentyes but not one of the seven deadly sins https://en.wikipedia.org/wiki/Seven_deadly_sins although impatience isn't one I think it should actually be wrath here. reply Izkata 5 hours agorootparentprevKinda works anyway: \"curiosity killed the cat\" reply GMoromisato 9 hours agorootparentprevYou're right! I didn't catch that. Maybe Snooping? Nosiness? Meddling? reply dkz999 7 hours agorootparentDisruption? \"Fixing what isn't broken\"? Im going with: Making perfect the enemy of the good. reply softfalcon 12 hours agoparentprevSeconded, and I’d add this is a quality of a great human being. Curious people are curious about others too, not just systems. It’s related to caring. You have to care to be curious and we could use more people taking care in their lives. reply pompino 12 hours agoprevOne missing virtue is never impart programming advice or wisdom on the internet - Because 10 other programmers who know nothing about you or your job will tell you in detail all the ways in which you're doing it wrong. reply hansvm 4 hours agoparentThe internet is famously hostile. If only two other people complain about my methodology I think I must have done something right. reply marssaxman 11 hours agoparentprevThis is essentially Cunningham's law, eh? Perhaps you want to learn how you could do it better! reply pompino 10 hours agorootparentYeah, good point. reply dang 11 hours agoprevRelated: The Three Virtues of a Great Programmer - https://news.ycombinator.com/item?id=32487944 - Aug 2022 (2 comments) Larry Wall's Three Great Virtues of a Programmer - https://news.ycombinator.com/item?id=24107571 - Aug 2020 (1 comment) Develop the three great virtues of a programmer: laziness, impatience, and hubris - https://news.ycombinator.com/item?id=11516215 - April 2016 (72 comments) The Three Virtues of a GREAT Programmer - https://news.ycombinator.com/item?id=10942079 - Jan 2016 (4 comments) The Three Great Virtues of a Programmer: Laziness, Impatience, and Hubris - https://news.ycombinator.com/item?id=9788088 - June 2015 (67 comments) reply AtlasBarfed 8 hours agoparentThe most reposted four lines ever? reply samatman 15 hours agoprevI would say that the character arc of Perl, and the profession generally, leads me to this observation: laziness and impatience are virtues. Be careful with hubris. reply Enk1du 12 hours agoparentHubris was really about building the community. It encouraged you to build things that you would want to share, so that we could all benefit from your Laziness and Impatience. reply dgfitz 14 hours agoparentprevI'd even go so far as to say !hubris Pride often leads to unintentional blindness and irrational defensiveness. Humility is where the fun is. reply mr_toad 9 hours agorootparentIf you’re too humble you might listen to all the people telling you it can’t be done, and later that it shouldn’t be done, and then finally that you did it wrong. reply scj 6 hours agoparentprevI'd argue hubris is balanced by laziness and impatience. Where I don't believe the three are equal. I'd add a conditional lesser virtue when working on certain codebases that should have been accounted for when making perl6: Fear. reply mcbuilder 15 hours agoparentprevI'd say wisdom should be the third, but that in turn often leads to hubris. reply ludston 14 hours agorootparentWisdom is to know yourself. Hubris is the belief that your accomplishments and skills are greater than they are. Are these not mutually exclusive? reply 65 10 hours agoprevIt's funny, I can't get myself to do many other creative activities I think I should enjoy (illustration, leather working, cooking) because of the tedium of doing the same thing over and over inherent in those activities. Programming is great because every single thing you're doing isn't tedious. It's the opposite of tedium. Maybe it's not so much laziness, but more so a hatred of tedium. reply HermitX 14 hours agoprevI would also like to add one more thing: hesitation. From my own experience, in my programming career, the most time my team wasted was on redoing something from scratch. Why redo it? Because the previous design was not comprehensive enough to meet subsequent requirements. If everyone could spend more time researching and discussing the plan before starting, and get things right in one go, in my view, this is much more effective than rushing into development work. reply quietbritishjim 14 hours agoparent> Because the previous design was not comprehensive enough to meet subsequent requirements. YAGNI. Hesitation to avoid unnecessary work, sure. But not to anticipate future requirements. The number of times I've had to fight a fancy design that left expansion points / abstractions for future features that were never needed (or not in the form the designers expected) enormously outnumber the times any such thing was useful. Just make the code do its current job in the simplest way possible. That's the easiest design to expand later. reply twh270 14 hours agorootparentThere's \"simple\" and there's \"naively simple\". I agree 100% with YAGNI, but you can also wedge yourself into a corner with a design that allows no room for growth unless you scrap it and start from scratch. reply hirvi74 6 hours agoparentprev> Why redo it? Is a reason like, \"being built like shit by the cheapest contractors that won the bid\" ever a good reason? My work is huge on what I call, \"fire, forget, then rewrite.\" Basically, we have tons of legacy apps that have lifespans of like 10 - 20 years, many of which never receive a single update. So, they eventually get old and unsupported enough that it's honestly just easier/quicker to rewrite them. And in case you were wondering, yes, I work in Gov.. reply leetrout 14 hours agoparentprevHindsight / survivorship bias affects this viewpoint. You will never get it \"right\" the first time as much as you can avoid doing it \"very wrong\". The key is to have enough experience and taste to appropriately break down problems into pieces that encapsulate the volatility of the various domains. Then you can refactor easier which should be the real goal. Prune and tend to the garden. reply hinkley 7 hours agorootparentReversible decisions are a simple enough concept to grasp, but a difficult one to really comprehend. Some people see effective people making 'bad' decisions and miss the bit where there were eight bad ways to accomplish something and they rejected 6 as being more work overall. Then they take their misreading of the situation as justification for YOLOing decisions to avoid analysis paralysis. reply AnimalMuppet 14 hours agorootparentprevYeah. It's easier to not do something stupid than it is to do something smart. Take the time to avoid doing stupid things (which takes somewhat more time than you expect!) and don't take the time to try (and usually fail) to be overly smart. reply donatj 3 hours agoprevOur three weapons are Laziness, Impatience, and Hubris… and an almost fanatical devotion to the pope. reply donatj 1 hour agoparentAnd of course python ... Monty Python reply pugworthy 14 hours agoprevIf you're not familiar with Larry Wall's style this might seem a bit off putting. The first time I ever saw him speak was the 1997 first annual O'Reilly Perl conference. I remember thinking, \"This guy is a jerk\" while also thinking \"I love this guy\" reply UncleOxidant 13 hours agoparentBy all accounts he's actually a really nice guy. reply iamcreasy 14 hours agoparentprevIs there any publicly available talk of Larry Wall that might evoke it today? reply Enk1du 12 hours agorootparentA quick explanation of the Three Virtues by Larry and then an impromptu explanation of why Hobbits would make good programmers https://www.youtube.com/watch?v=G49RUPv5-NU reply cratermoon 14 hours agorootparentprevAny of his \"State of the Onion\" talks. https://www.youtube.com/watch?v=a1SEt_-QMDo reply zbentley 14 hours agoprevOh Larry, never change. I often give a similar list as a glib answer in interviews when asked \"what are your greatest strengths?\" Mine are usually: I'm stupid (not smart enough to overcomplicate), lazy (prefer turning MVP in on time rather than adding too many bells and whistles), and forgetful (document everything because I won't remember what I was doing the next day). reply lexarflash8g 14 hours agoparentWhat is your biggest weakness: \"I work too hard\" -- humblebrag reply amarant 13 hours agorootparentAs someone currently recovering from burnout, that is indeed my greatest weakness, and it's anything but a brag! Working too hard means you're liable to disappear for 6+months, no sane employer should want that! reply elvis10ten 12 hours agorootparentAs someone who has worked hard for years (at some point I had three con-concurrent jobs), I’m not sure working hard is the variable that causes burnout :thinking_face: I will say tho, it gave me persistent back problems and RSI for two years :). But that again is not just “working hard”. It was bad posture, lack of stretching, breaks and exercise, I think. Edit: Perhaps it’s the nature of the work or working hard unhealthily (physical and mental?) or the person’s characteristics. reply tommica 12 hours agorootparentI remember hearing about burnout, that it becomes more likely to happen the less meaningful work you do. reply actionfromafar 11 hours agorootparentNot sure about that. reply amarant 11 hours agorootparentprevWhat's the equivalent of \"victim blaming\" for sick people? Because this is that. reply tommica 4 hours agorootparentReally, you think it sounds that? reply multiplied 12 hours agorootparentprevDo you work too hard or spend a lot of time on work? (before downvoting me, please consider that those things maybe different) reply amarant 12 hours agorootparentA bit of both I suppose. In my case I think taking on too many responsibilities and stressing out too much over any production issues that arose were the main ingredients for disaster. But there were others as well. Burnout is complicated. reply pompino 12 hours agorootparentprevAre they still asking that ridiculous question? reply hirvi74 6 hours agorootparentprev\"That I have no strengths\" reply akavi 12 hours agoparentprevI've never been asked \"my greatest weakness\" or \"my greatest strength\" in an interview. What sort of jobs have asked you those questions? (I've worked (and interviewed) as a programmer at VC backed startups and FAANG in SF and NYC over the past 12 years) reply layer8 11 hours agoparentprevThat kind of cuteness in an interview would be a red flag for me. OTOH, I also wouldn’t ask that question. reply petsfed 14 hours agoprevI've never really liked his inclusion of hubris here. Hubris is often defined as unjustified arrogance. Justified confidence, even if you're a jerk about it, was never the fatal flaw of a Greek hero. So I've always substituted arrogance for hubris: the belief that you better understand, and can better address, the requirements than any off-the-shelf library/program/ecosystem. reply francisofascii 13 hours agoparentI read hubris here as...you want to be the best, you don't want to be criticized, so you will work hard and be super motivated to make your program work very well, handling all the various edge cases, making it better than the competition. reply graemep 12 hours agorootparentYes, but that is not what the word hubris means. It means pride in the seven deadly sins sense. The pride that comes before a fall. Hubris would not mean working hard to reduce the scope for criticism. It would mean not accepting valid criticism because you think you are better than the critics. He could have just used the word \"pride\" (which is far broader and has positive meanings too) instead. In some ways \"ambition\" might be a better fit. reply clayg 12 hours agorootparentAmbition might stand out in the same list as laziness. Plus I'd be reticent to tell programmers to \"be more ambitious!\" - I see greenhorns esp just trying to do too damn much at once. In the context of \"code that is going to be reviewed\" maybe even \"vanity\" might have been closer to what he was getting at? (did you even RUN this?) Except us old neck beards obviously don't care about how WE look ;)} - just how our code reads. I think \"take pride in your work\" would have substituted well; but given the options, maybe hubris was fine - he explains what he means in a couple of sentences. reply agumonkey 10 hours agorootparentprevso they try to describe a balanced sense of pride and values reply mattbee 14 hours agoparentprevWhen you learn programming, you are told to never roll your own crypto, or to always use the ready-made libraries, or to avoid manual memory management - and you can have a perfectly fruitful career following rules like that. But you don't get big changes or ambitious intellectual growth without spotting that - if you did choose to break those sorts of rules - you could build something really new and exciting. Anyhow that's how I've always taken the \"hubris\" part - knowing when there's an opportunity to achieve something in a way that someone will tell you is too risky. reply bluefirebrand 13 hours agorootparent> When you learn programming, you are told to never roll your own crypto, or to always use the ready-made libraries, or to avoid manual memory management I've always taken this sort of advice, such as \"never reinvent the wheel\" to mean \"inventing the wheel is time consuming so give yourself an advantage by using already existing wheels\", which really has nothing to do with hubris. I never took it as \"Don't bother trying to reinvent the wheel because you aren't capable of it\" reply eloisant 12 hours agorootparentYou can build a better wheel if you want to focus on that. If you want to build a car however, focus on building the car and not creating a new kind of wheel. reply henryreynolds 15 hours agoprevImpatience also makes you write more performant software because you can't stand waiting on build/test/run cycles. reply throwawaymaths 7 hours agoprevDiscernment: The virtue of not thinking you're building something great when you're building something awful reply rlv-dan 14 hours agoprevHobby programmer perhaps. But a professional systems developer in a larger corporation? Not so sure... reply forinti 10 hours agoprevYou can't mention these without explaining false laziness, false hubris, and false impatience. I think Larry Wall gives us some great insights wrapped in great humour. reply from-nibly 10 hours agoprevThis aligns well with ADHD. As someone who has ADHD and is also a programmer this is why I love programming so much! reply librasteve 10 hours agoprevi always thought that the Laziness virtue was a tacit reference to lazy evaluation of arrays (LISP-like) ... I get the feeling that most ML languages have quietly dropped this aspiration (Haskell, ML, ELM, I'm looking at you) ... meantime Larry's opus magnus \"raku\" (renamed from per6) is still lazy at heart reply komodus 12 hours agoprevCuriosity, we waste time learning a thousand useless 'shiny' things at the same time, then we apply all we learnt solving problems easily reply RustyRussell 11 hours agoprevI always said the fourth virtue is fear (of complexity). Keeps the others in check, particularly hubris:) reply augustk 13 hours agoprevI think programming is an basically an exercise in effective communication. Edsger Dijkstra said that \"Besides a mathematical inclination, an exceptionally good mastery of one's native tongue is the most vital asset of a competent programmer.\" This means being able to write down a description of a problem or a solution in a clear and concise way. This is the test I would use if I hired people (not only programmers). At my job I have noticed that quite a few people cannot write proper sentences or are way too verbose in their writing. reply soneca 13 hours agoparent> ”… an exceptionally good mastery of one's native tongue …” Does that imply that one cannot be a competent programmer if working on an environment where the spoken tongue is not their native one? reply ineptech 12 hours agorootparentNo, I'm 90% certain both Dijkstra and OP meant that what's critical is mastery of any tongue. In context, he was talking about what makes someone good at programming, not about the need to contribute to a team or communicate ideas. https://www.cs.virginia.edu/~evans/cs655/readings/ewd498.htm... reply jdbernard 12 hours agorootparentprevI don't think so. I think the core of Djikstra's thought is that mastery of your native tongue coincides with strong communication skill and ability to logically organize and present thoughts. You can articulate your thoughts and do so in a way that others can understand. Working outside your native tongue may add hurdles, but from my experience having worked with brilliant people who's native tongue is not English, those hurdles can be overcome. The skills still translate. reply tmaly 14 hours agoprevOne could have also titled it Three Virtues of ChatGPT reply phantomathkg 9 hours agoprevHugged to death by HN again. Here's the archive version. https://archive.is/yS4op reply Simon_ORourke 14 hours agoprevI'd add a variation on that third one - it's all they've got going for them. The really great coders I've worked with live and breathe the work, and come 5pm on a weekday they just continue on coding only this time for fun at home themselves. reply lexarflash8g 14 hours agoparentIf you come at 5pm or past to work on an OSS project or your own side project more power to you. For a corp job why work longer than you need to when you are not paid for it? Bragging rights? reply golergka 11 hours agoprevI would add stupidity. I know I'm stupid, that's why I write types, tests and documentation. reply lacoolj 13 hours agoprevI found my new bible reply ChrisArchitect 13 hours agoprev(1991) reply annoyingnoob 13 hours agoprevHow did that work out for Perl? reply IvyMike 13 hours agoparentThey had a good run. reply djaouen 13 hours agoprevPerl. Lol reply glouwbug 5 hours agoprev [–] The best programmer saves their earnings and retires early reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "According to Larry Wall, the original author of Perl, there are three main virtues of a programmer: laziness, impatience, and hubris.",
      "Laziness encourages the creation of efficient and useful programs and documentation.",
      "Impatience drives the creation of programs that anticipate and meet user needs.",
      "Hubris motivates programmers to create and maintain programs that are highly regarded by others."
    ],
    "commentSummary": [
      "The article discusses the virtues that contribute to being a great programmer, including laziness, impatience, hubris, curiosity, effective communication skills, and discernment.",
      "Code readability and balancing virtues are emphasized as important aspects of programming.",
      "The role of experience in decision-making, potential negative effects of hubris, and the reputation of Larry Wall, the creator of Perl, are also mentioned in the discussion."
    ],
    "points": 269,
    "commentCount": 104,
    "retryCount": 0,
    "time": 1708017015
  },
  {
    "id": 39387850,
    "title": "Building an Automatic Differentiation Framework from Scratch: Creating a Language Model for Deep Learning",
    "originLink": "https://bclarkson-code.github.io/posts/llm-from-scratch-scalar-autograd/post.html",
    "originBody": "Setup LLM from scratch: Automatic Differentiation I’m building a modern language model with all the bells and whistles completely from scratch: from vanilla python to functional coding assistant. Borrowing (shamelessly stealing) from computer games, I’ve built a tech tree of everything that I think I’ll need to implement to get a fully functional language model. If you think anything is missing, please let me know: The LLM from scratch tech tree Before we can move onto building modern features like Rotary Positional Encodings, we first need to figure out how to differentiate with a computer. The backpropagation algorithm that underpins the entire field of Deep Learning requires the ability to differentiate the outputs of neural networks with respect to (wrt) their inputs. In this post, we’ll go from nothing to an (admittedly very limited) automatic differentiation library that can differentiate arbitrary functions of scalar values. This one algorithm will form the core of our deep learning library that, eventually, will include everything we need to train a language model. Creating a tensor We can’t do any differentiation if we don’t have any numbers to differentiate. We’ll want to add some extra functionality that is in standard float types so we’ll need to create our own. Let’s call it a Tensor. class Tensor: \"\"\" Just a number (for now) \"\"\" value: float def __init__(self, value: float): self.value = value def __repr__(self) -> str: \"\"\" Create a printable string representation of this object This function gets called when you pass a Tensor to print Without this function: >>> print(Tensor(5))With this function: >>> print(Tensor(5)) Tensor(5) \"\"\" return f\"Tensor({self.value})\" # try it out Tensor(5) Tensor(5) Next we’ll need some simple operations we want to perform: addition, subtraction and multiplication. def _add(a: Tensor, b: Tensor): \"\"\" Add two tensors \"\"\" return Tensor(a.value + b.value) def _sub(a: Tensor, b: Tensor): \"\"\" Subtract tensor b from tensor a \"\"\" return Tensor(a.value - b.value) def _mul(a: Tensor, b: Tensor): \"\"\" Multiply two tensors \"\"\" return Tensor(a.value * b.value) We can use use our operations as follows: def test(got: Any, want: Any): \"\"\" Check that two objects are equal to each other \"\"\" indicator = \"✅\" if want == got else \"❌\" print(f\"{indicator} - Want: {want}, Got: {got}\") a = Tensor(3) b = Tensor(4) test(_add(a, b).value, 7) test(_sub(a, b).value, -1) test(_mul(a, b).value, 12) ✅ - Want: 7, Got: 7 ✅ - Want: -1, Got: -1 ✅ - Want: 12, Got: 12 Scalar derivatives Diving straight into differentiating matrices sounds too hard so let’s start with something simpler: differentiating scalars. The simplest scalar derivative I can think of is differentiating a tensor with respect to itself: 𝑑 𝑥 𝑑 𝑥 = 1 A more interesting case is the derivative of two tensors added together (note we are using partial derivatives because our function has multiple inputs): 𝑓 ( 𝑥 , 𝑦 ) = 𝑥 + 𝑦 𝜕 𝑓 𝜕 𝑥 = 1 𝜕 𝑓 𝜕 𝑦 = 1 We can do a similar thing for multiplication and subtraction 𝑓 ( 𝑥 , 𝑦 ) 𝜕 𝑓 𝜕 𝑥 𝜕 𝑓 𝜕 𝑦 𝑥 + 𝑦 1 1 𝑥 − 𝑦 1 − 1 𝑥 × 𝑦 𝑦 𝑥 Now that we’ve worked out these derivatives mathematically, the next step is to convert them into code. In the table above, when we make a tensor by combining two tensors with an operation, the derivative only ever depends on the inputs and the operation. There is no “hidden state”. This means that the only information we need to store is the inputs to an operation and a function to calculate the derivative wrt each input. With this, we should be able to differentiate any binary function wrt its inputs. A good place to store this information is in the tensor that is produced by the operation. We’ll add some new attributes to our Tensor: args and local_derivatives. If the tensor is the output of an operation, then args will store the arguments to the operation and local_derivatives will store the derivatives wrt each input. We’re calling it local_derivatives to avoid confusion when we start nesting functions. Once we’ve calculated the derivative (from our args and local_derivatives) we’ll need to store it. It turns out that the neatest place to put this is in the tensor that the output is being differentiated wrt. We’ll call this derivative. class Tensor: \"\"\" A number that can be differentiated \"\"\" # If the tensor was made by an operation, the operation arguments # are stored in args args: tuple[\"Tensor\"] = () # If the tensor was made by an operation, the derivatives wrt # operation inputs are stored in derivatives local_derivatives: tuple[\"Tensor\"] = () # The derivative we have calculated derivative: Optional[\"Tensor\"] = None def __init__(self, value: float): self.value = value def __repr__(self) -> str: \"\"\" Create a printable string representation of this object This function gets called when you pass a Tensor to print Without this function: >>> print(Tensor(5))With this function: >>> print(Tensor(5)) Tensor(5) \"\"\" return f\"Tensor({self.value})\" For example, if we have a = Tensor(3) b = Tensor(4) output = _mul(a, b) Then output.args and output.local_derivatives should be set to: output.args == (Tensor(3), Tensor(4)) output.derivatives == ( b, # derivative of output wrt a is b a, # derivative of output wrt b is a ) Once we have actually computed the derivatives, then the derivative of output wrt a will be stored in a.derivative and should be equal to b (which is 4 in this case). We know that we’ve done everything right once these tests pass: a = Tensor(3) b = Tensor(4) output = _mul(a, b) # TODO: differentiate here test(got=output.args, want=(a, b)) test(got=output.local_derivatives, want=(b, a)) test(got=a.derivative, want=b) test(got=b.derivative, want=a) ❌ - Want: (Tensor(3), Tensor(4)), Got: () ❌ - Want: (Tensor(4), Tensor(3)), Got: () ❌ - Want: Tensor(4), Got: None ❌ - Want: Tensor(3), Got: None First, let’s add a function to our Tensor that will actually calculate the derivatives for each of the function arguments. Pytorch calls this function backward so we’ll do the same. class Tensor: \"\"\" A number that can be differentiated \"\"\" # If the tensor was made by an operation, the operation arguments # are stored in args args: tuple[\"Tensor\"] = () # If the tensor was made by an operation, the derivatives wrt # operation inputs are stored in local_derivatives: tuple[\"Tensor\"] = () # The derivative we have calculated derivative: Optional[\"Tensor\"] = None # optionally give this tensor a name name: Optional[str] = None # Later, we'll want to record the path we followed to get # to this tensor and some operations we did along the way # don't worry about these for now paths: List[Tensor] = None chains: List[Tensor] = None def __init__(self, value: float): self.value = value def backward(self): if self.args is None or self.local_derivatives is None: raise ValueError( \"Cannot differentiate a Tensor that is not a function of other Tensors\" ) for arg, derivative in zip(self.args, self.local_derivatives): arg.derivative = derivative def __repr__(self) -> str: \"\"\" Create a printable string representation of this object This function gets called when you pass a Tensor to print Without this function: >>> print(Tensor(5))With this function: >>> print(Tensor(5)) Tensor(5) \"\"\" return f\"Tensor({self.value})\" This only works if we also store the arguments and derivatives in the output tensors of operations def _add(a: Tensor, b: Tensor): \"\"\" Add two tensors \"\"\" result = Tensor(a.value + b.value) result.local_derivatives = (Tensor(1), Tensor(1)) result.args = (a, b) return result def _sub(a: Tensor, b: Tensor): \"\"\" Subtract tensor b from a \"\"\" result = Tensor(a.value - b.value) result.local_derivatives = (Tensor(1), Tensor(-1)) result.args = (a, b) return result def _mul(a: Tensor, b: Tensor): \"\"\" Multiply two tensors \"\"\" result = Tensor(a.value * b.value) result.local_derivatives = (b, a) result.args = (a, b) return result Let’s re-run our tests and see if it works a = Tensor(3) b = Tensor(4) output = _mul(a, b) output.backward() test(got=output.args, want=(a, b)) test(got=output.local_derivatives, want=(b, a)) test(a.derivative, b) test(b.derivative, a) ✅ - Want: (Tensor(3), Tensor(4)), Got: (Tensor(3), Tensor(4)) ✅ - Want: (Tensor(4), Tensor(3)), Got: (Tensor(4), Tensor(3)) ✅ - Want: Tensor(4), Got: Tensor(4) ✅ - Want: Tensor(3), Got: Tensor(3) So far so good, let’s try nesting operations. a = Tensor(3) b = Tensor(4) output_1 = _mul(a, b) # z = a + (a * b) output_2 = _add(a, output_1) output_2.backward() # should get # dz/db = 0 + a = a test(b.derivative, a) ❌ - Want: Tensor(3), Got: None Something has gone wrong. We should have got a as the derivative for b but we got 0 instead. Looking through the .backward() function, the issue is pretty clear: we haven’t thought about nested functions. To get this example working, we’ll need to figure out how to calculate derivatives through multiple functions instead of just one. Chaining Functions Together To calculate derivatives of nested functions, we can use a rule from calculus: The Chain Rule. For a variable 𝑧 generated by nested functions 𝑓 and 𝑔 such that 𝑧 = 𝑓 ( 𝑔 ( 𝑥 ) ) Then the derivative of 𝑧 wrt 𝑥 is: 𝜕 𝑧 𝜕 𝑥 = 𝜕 𝑓 ( 𝑢 ) 𝜕 𝑢 𝜕 𝑔 ( 𝑥 ) 𝜕 𝑥 Here, 𝑢 is a dummy variable. 𝜕 𝑓 ( 𝑢 ) 𝜕 𝑢 means the derivative of 𝑓 wrt its input. For example, if 𝑓 ( 𝑥 ) = 𝑔 ( 𝑥 ) 2 Then we can define 𝑢 = 𝑔 ( 𝑥 ) and rewrite 𝑓 in terms of u 𝑓 ( 𝑢 ) = 𝑢 2 ⟹ 𝜕 𝑓 ( 𝑢 ) 𝜕 𝑢 = 2 𝑢 = 2 𝑔 ( 𝑥 ) Multiple Variables The chain rule works as you might expect for functions of multiple variables. When differentiating wrt a variable, we can treat the other variables as constant and differentiate as normal 𝑧 = 𝑓 ( 𝑔 ( 𝑥 ) , ℎ ( 𝑦 ) ) 𝜕 𝑧 𝜕 𝑥 = 𝜕 𝑓 ( 𝑢 ) 𝜕 𝑢 𝜕 𝑔 ( 𝑥 ) 𝜕 𝑥 𝜕 𝑧 𝜕 𝑦 = 𝜕 𝑓 ( 𝑢 ) 𝜕 𝑢 𝜕 ℎ ( 𝑦 ) 𝜕 𝑦 If we have different functions that take the same input, we differentiate each of them individually and then add them together 𝑧 = 𝑓 ( 𝑔 ( 𝑥 ) , ℎ ( 𝑥 ) ) We get 𝜕 𝑧 𝜕 𝑥 = 𝜕 𝑓 ( 𝑢 ) 𝜕 𝑢 𝜕 𝑔 ( 𝑥 ) 𝜕 𝑥 + 𝜕 𝑓 ( 𝑢 ) 𝜕 𝑢 𝜕 ℎ ( 𝑥 ) 𝜕 𝑥 More than 2 functions If we chain 3 functions together, we still just multiply the derivatives for each function together: 𝜕 𝑧 𝜕 𝑥 = 𝜕 𝑓 ( 𝑢 ) 𝜕 𝑢 𝜕 𝑔 ( 𝑥 ) 𝜕 𝑥 = 𝜕 𝑓 ( 𝑢 ) 𝜕 𝑢 𝜕 𝑔 ( 𝑢 ) 𝜕 𝑢 𝜕 ℎ ( 𝑥 ) 𝜕 𝑥 And this generalises to any amount of nesting 𝑧 = 𝑓 1 ( 𝑓 2 ( . . . . 𝑓 𝑛 − 1 ( 𝑓 𝑛 ( 𝑥 ) ) . . . ) ) ⟹ 𝜕 𝑧 𝜕 𝑥 = 𝜕 𝑓 1 ( 𝑢 ) 𝜕 𝑢 𝜕 𝑓 2 ( 𝑢 ) 𝜕 𝑢 . . . 𝜕 𝑓 𝑛 − 1 ( 𝑢 ) 𝜕 𝑢 𝜕 𝑓 𝑛 ( 𝑥 ) 𝜕 𝑥 $ A picture is worth a thousand equations As you probably noticed, the maths is starting to get quite dense. When we start working with neural networks, we can easily get 100s or 1000s of functions deep so to get a handle on things, we’ll need a different strategy. Helpfully, there is one: turning it into a graph. We can start with some rules: Variables are represented with circles and operations are represented with boxes Inputs to an operation are represented with arrows that point to the operation box. Outputs point away. For example, here is the diagram for 𝑧 = 𝑚 𝑥 And that’s it! All of the equations we’ll be working with can be represented graphically using these simple rules. To try it out, let’s draw the diagram for a more complex formula: This is an example of a structure called a graph (also called a network). A lot of problem in computer science get much easier if you can represent them with a graph and this is no exception. The real power of these diagrams is that they can also help us with our derivatives. Take 𝑦 = 𝑚 𝑥 + 𝑝 = add ( 𝑝 , mul ( 𝑚 , 𝑥 ) ) . From before, we can find its derivatives by differentiating each operation wrt its inputs and multiplying the results together. In this case, we get: 𝜕 𝑦 𝜕 𝑝 = 𝜕 add ( 𝑢 1 , 𝑢 2 ) 𝜕 𝑢 1 = 1 𝜕 𝑦 𝜕 𝑚 = 𝜕 add ( 𝑢 1 , 𝑢 2 ) 𝜕 𝑢 2 𝜕 mul ( 𝑢 1 , 𝑢 2 ) 𝜕 𝑢 2 = 1 × 𝑥 = 𝑥 𝜕 𝑦 𝜕 𝑥 = 𝜕 add ( 𝑢 1 , 𝑢 2 ) 𝜕 𝑢 2 𝜕 mul ( 𝑢 1 , 𝑢 2 ) 𝜕 𝑢 1 = 1 × 𝑚 = 𝑚 We can also graph it like this: If you imagine walking from 𝑦 to each of the inputs, you might notice a similarity between the edges you pass through and the equations above. If you walk from 𝑦 to 𝑥 , you’ll pass through a->c->d. Similarly, if you walk from 𝑦 to 𝑚 , you’ll pass through a->d->e. Notice that both paths go through c, the edge coming out of add that corresponds to the input 𝑢 2 . Also, both equations include the term 𝜕 add ( 𝑢 1 , 𝑢 2 ) 𝜕 𝑢 2 . If I rename the edges as follows: We can see that going from 𝑦 to 𝑥 , we pass through 1 , 𝜕 add ( 𝑢 1 , 𝑢 2 ) 𝜕 𝑢 2 and 𝜕 mul ( 𝑢 1 , 𝑢 2 ) 𝜕 𝑢 1 . If we multiply these together, we get exactly 𝜕 add ( 𝑢 1 , 𝑢 2 ) 𝜕 𝑢 2 𝜕 mul ( 𝑢 1 , 𝑢 2 ) 𝜕 𝑢 1 = 𝜕 𝑦 𝜕 𝑥 ! It turns out that this rule works in general: If we have some operation op ( 𝑢 1 , 𝑢 2 , . . . , 𝑢 𝑛 ) , we should label the edge corresponding to input 𝑢 𝑖 with 𝜕 op ( 𝑢 1 , 𝑢 2 , . . . , 𝑢 𝑛 ) 𝜕 𝑢 𝑖 Then, if we want to find the derivative of the output node wrt any of the inputs, The derivative of an output variable wrt one of the input variables can be found by traversing the graph from the output to the input and multiplying together the derivatives for every edge on the path To cover every edge case, there are some extra details If a graph contains multiple paths from the output to an input, then the derivative is the sum of the products for each path This comes from the case we saw earlier where when we have different functions that have the same input we have to add their derivative chains together. If an edge is not the input to any function, its derivative is 1 This covers the edge that leads from the final operation to the output. You can think of the edge having the derivative 𝜕 𝑦 𝜕 𝑦 = 1 And that’s it! Let’s try it out with 𝑧 = ( 𝑥 + 𝑐 ) 𝑥 : Here, instead of writing the formulae for each derivative, I have gone ahead and calculated their actual values. Instead of just figuring out the formulae for a derivative, we want to calculate its value when we plug in our input parameters. All that remains is to multiply the local derivatives together along each path. We’ll call the product of derivatives along a single path a chain (after the chain rule) We can get from 𝑧 to 𝑥 via the green path and the red path. Following these paths, we get: red path = 1 × ( 𝑥 + 𝑐 ) = 𝑥 + 𝑐 Along the green path we get: green path = 1 × 𝑥 × 1 = 𝑥 Adding these together, we get ( 𝑥 + 𝑐 ) + 𝑥 = 2 𝑥 + 𝑐 If we work out the derivative algebraically: 𝜕 𝑧 𝜕 𝑥 = 𝜕 𝜕 𝑥 ( ( 𝑥 + 𝑐 ) 𝑥 ) = 𝜕 𝜕 𝑥 ( 𝑥 2 + 𝑐 𝑥 ) = 𝜕 𝑥 2 𝜕 𝑥 + 𝑐 𝜕 𝑥 𝜕 𝑥 = 2 𝑥 + 𝑐 We can see that it seems to work! Calculating 𝜕 𝑧 𝜕 𝑐 is left as an exercise for the reader (I’ve always wanted to say that). To summarise, we have invented the following algorithm for calculating of a variable wrt its inputs: Turn the equation into a graph Label each edge with the appropriate derivative Find every path from the output to the input variable you care about Follow each path and multiply the derivatives you pass through Add together the results for each path Now that we have an algorithm in pictures and words, let’s turn it into code. The Algorithm™ Surprisingly, we have actually already converted our functions into graphs. If you recall, when we generate a tensor from an operation, we record the inputs to the operation in the output tensor (in .args). We also stored the functions to calculate derivatives for each of the inputs in .local_derivatives which means that we know both the destination and derivative for every edge that points to a given node. This means that we’ve already completed steps 1 and 2. The next challenge is to find all paths from the tensor we want to differentiate to the input tensors that created it. Because none of our operations are self referential (outputs are never fed back in as inputs), and all of our edges have a direction, our graph of operations is a directed acyclic graph or DAG. The property of the graph having no cycles means that we can find all paths to every parameter pretty easily with a Breadth First Search (or Depth First Search but BFS makes some optimisations easier as we’ll see in part 2). To try it out, let’s recreate that giant graph we made earlier. We can do this by first calculating 𝐿 from the inputs y = Tensor(1) m = Tensor(2) x = Tensor(3) c = Tensor(4) # L = (y - (mx + c))^2 left = _sub(y, _add(_mul(m, x), c)) right = _sub(y, _add(_mul(m, x), c)) L = _mul(left, right) # Attaching names to tensors will make our # diagram look nicer y.name = \"y\" m.name = \"m\" x.name = \"x\" c.name = \"c\" L.name = \"L\" And then using Breadth First Search to do 3 things: Find all nodes Find all edges Find all paths from 𝐿 to our parameters We haven’t implemented a simple way to check whether two tensors are identical so we’ll need to compare hashes. edges = [] stack = [(L, [L])] nodes = [] edges = [] while stack: node, current_path = stack.pop() # Record nodes we haven't seen before if hash(node) not in [hash(n) for n in nodes]: nodes.append(node) # If we have reached a parameter (it has no arguments # because it wasn't created by an operation) then # record the path taken to get here if not node.args: if node.paths is None: node.paths = [] node.paths.append(current_path) continue for arg in node.args: stack.append((arg, current_path + [arg])) # Record every new edge edges.append((hash(node), hash(arg))) Now we’ve got all of the edges and nodes, we have complete knowledge of our computational graph. Let’s use networkx to plot it # Assign a unique integer to each # unnamed node so we know which # node is which in the picture labels = {} for i, node in enumerate(nodes): if node.name is None: labels[hash(node)] = str(i) else: labels[hash(node)] = node.name graph = nx.DiGraph() graph.add_edges_from(edges) pos = nx.nx_agraph.pygraphviz_layout(graph, prog=\"dot\") nx.draw(graph, pos=pos, labels=labels) If you squint a bit, you can see that this looks like the graph we made earlier! Let’s take a look at the paths the algorithm found from 𝐿 to 𝑥 . for path in x.paths: steps = [] for step in path: steps.append(labels[hash(step)]) print(\"->\".join(steps)) L->1->2->4->x L->8->9->10->x The paths look correct! All we need to do now is to modify the algorithm a bit to keep track of the chain of derivatives along each path. y = Tensor(1) m = Tensor(2) x = Tensor(3) c = Tensor(4) # L = (y - (mx + c))^2 left = _sub(y, _add(_mul(m, x), c)) right = _sub(y, _add(_mul(m, x), c)) L = _mul(left, right) y.name = \"y\" m.name = \"m\" x.name = \"x\" c.name = \"c\" L.name = \"L\" stack = [(L, [L], [])] nodes = [] edges = [] while stack: node, current_path, current_chain = stack.pop() # Record nodes we haven't seen before if hash(node) not in [hash(n) for n in nodes]: nodes.append(node) # If we have reached a parameter (it has no arguments # because it wasn't created by an operation) then # record the path taken to get here if not node.args: if node.paths is None: node.paths = [] if node.chains is None: node.chains = [] node.paths.append(current_path) node.chains.append(current_chain) continue for arg, op in zip(node.args, node.local_derivatives): next_node = arg next_path = current_path + [arg] next_chain = current_chain + [op] stack.append((arg, next_path, next_chain)) # Record every new edge edges.append((hash(node), hash(arg))) Let’s check if the derivatives were recorded correctly. print(f\"Number of chains: {len(x.chains)}\") for chain in x.chains: print(chain) Number of chains: 2 [Tensor(-9), Tensor(-1), Tensor(1), Tensor(2)] [Tensor(-9), Tensor(-1), Tensor(1), Tensor(2)] Looks reasonable so far. We have 2 identical paths, each with 4 derivatives (one for each edge in the path) as expected. Let’s multiply the derivatives together along each path and add the total for each path together and see if we get the right answer. According my calculations (and Wolfram Alpha) the derivative of 𝐿 wrt 𝑥 is: 𝜕 𝐿 𝜕 𝑥 = 2 𝑚 ( 𝑐 + 𝑚 𝑥 − 𝑦 ) Plugging the values for our tensors in, we get 2 × 2 ( 4 + ( 2 × 3 ) − 1 ) = 36 total_derivative = Tensor(0) for chain in x.chains: chain_total = Tensor(1) for step in chain: chain_total = _mul(chain_total, step) total_derivative = _add(total_derivative, chain_total) total_derivative Tensor(36) The correct answer! It looks like our algorithm works. All that remains is to put all the pieces together. Putting it all together When dreaming up the algorithm, we kept a record of the nodes, edges and paths which made plotting and debugging easier. Now that we know that it works, we can remove these and simplify things a bit. def backward(root_node: Tensor) -> None: stack = [(root_node, [])] while stack: node, current_derivative = stack.pop() # if we have reached a parameter (it has no arguments # because it wasn't created by an operation) then # record the path taken to get here if not node.args: if node.chains is None: node.chains = [] node.chain.append(current_derivative) continue for arg, op in zip(node.args, node.local_derivatives): stack.append((arg, current_derivative + [op])) There is also no need (for now) to store the derivatives and calculate them separately. Instead, we can avoid a bunch of repeated calculations by multiplying the derivatives as we go. def backward(root_node: Tensor) -> None: stack = [(root_node, Tensor(1))] while stack: node, current_derivative = stack.pop() # if we have reached a parameter (it has no arguments # because it wasn't created by an operation) then add the # derivative if not node.args: if node.derivative is None: node.derivative = current_derivative else: node.derivative = _add(node.derivative, current_derivative) continue for arg, derivative in zip(node.args, node.local_derivatives): stack.append((arg, _mul(current_derivative, derivative))) Let’s make sure we didn’t break anything y = Tensor(1) m = Tensor(2) x = Tensor(3) c = Tensor(4) left = _sub(y, _add(_mul(m, x), c)) right = _sub(y, _add(_mul(m, x), c)) L = _mul(left, right) backward(L) print(f\"{x.derivative = }\") test(got=x.derivative.value, want=36) x.derivative = Tensor(36) ✅ - Want: 36, Got: 36 Let’s put this algorithm into our Tensor object class Tensor: \"\"\" A float that can be differentiated \"\"\" args: tuple[Tensor] = () local_derivatives: tuple[Tensor] = () # The derivative (once we've calculated it). This is None if the derivative # has not been computed yet derivative: TensorNone = None def __init__(self, value: float): self.value = value def __repr__(self) -> str: return f\"Tensor({self.value.__repr__()})\" def backward(self): if self.args is None or self.local_derivatives is None: raise ValueError( \"Cannot differentiate a Tensor that is not a function of other Tensors\" ) stack = [(self, Tensor(1))] while stack: node, current_derivative = stack.pop() # if we have reached a parameter (it has no arguments # because it wasn't created by an operation) then add the # derivative if not node.args: if node.derivative is None: node.derivative = Tensor(0) node.derivative = _add(node.derivative, current_derivative) continue for arg, derivative in zip(node.args, node.local_derivatives): new_derivative = _mul(current_derivative, derivative) stack.append((arg, new_derivative)) Let’s try it out y = Tensor(1) m = Tensor(2) x = Tensor(3) c = Tensor(4) left = _sub(y, _add(_mul(m, x), c)) right = _sub(y, _add(_mul(m, x), c)) L = _mul(left, right) L.backward() test(x.derivative, Tensor(36)) ❌ - Want: Tensor(36), Got: Tensor(36) Huh? By default, if you compare two objects in python with ==, python will check whether the object on the left has the same reference as the object as the one on the right. Because Tensor(36) is a different object (that just happens to have the same value) to x.derivative, x.derivative == Tensor(36) returns False. It makes a lot more sense to compare two tensors based upon their .value. To achieve this, we can add the __eq__ special method to Tensor which will change the behaviour of the == operator for Tensor objects def __eq__(self, other) -> bool: \"\"\" Tells python to compare .value when applying the `==` operation to two tensors instead of comparing references \"\"\" if not isinstance(other, \"Tensor\"): raise TypeError(f\"Cannot compare a Tensor with a {type(other)}\") return self.value == other.value Similarly, if we try to use +, - or * on our tensors, we’ll get an error. We can tell python how to do these operations on our tensors by defining the following special functions: __add__ let’s us use + __sub__ let’s us use - __mul__ let’s us use * def __add__(self, other) -> Tensor: if not isinstance(other, \"Tensor\"): raise TypeError(f\"Cannot add a Tensor to a {type(other)}\") return _add(self, other) def __sub__(self, other) -> Tensor: if not isinstance(other, \"Tensor\"): raise TypeError(f\"Cannot subtract a Tensor from a {type(other)}\") return _sub(self, other) def __mul__(self, other) -> Tensor: if not isinstance(other, \"Tensor\"): raise TypeError(f\"Cannot multiply a Tensor with a {type(other)}\") return _mul(self, other) Finally, we can add the __iadd__, __isub__ and __imul__ methods to allow us to use +=, -= and *=. def __iadd__(self, other) -> Tensor: self = self.__add__(self, other) return self def __isub__(self, other) -> Tensor: self = self.__sub__(self, other) return self def __imul__(self, other) -> Tensor: self = self.__mul__(self, other) return self While we’re here, let’s clean up our backward function a bit by replacing the ugly _add and _mul operations with + and *. def backward(self): if self.args is None or self.local_derivatives is None: raise ValueError( \"Cannot differentiate a Tensor that is not a function of other Tensors\" ) stack = [(self, Tensor(1))] while stack: node, current_derivative = stack.pop() # if we have reached a parameter (it has no arguments # because it wasn't created by an operation) then add the # derivative if not node.args: if node.derivative is None: node.derivative += current_derivative else: node.derivative += current_derivative continue for arg, derivative in zip(node.args, node.local_derivatives): stack.append((arg, current_derivative * derivative)) Putting all of these improvements together, we get a final Tensor object as follows: class Tensor: \"\"\" A float that can be differentiated \"\"\" args: tuple[Tensor] = () local_derivatives: tuple[Tensor] = () # The derivative (once we've calculated it). This is None if the derivative # has not been computed yet derivative: TensorNone = None def __init__(self, value: float): self.value = value def __repr__(self) -> str: return f\"Tensor({self.value.__repr__()})\" def __eq__(self, other) -> bool: if not isinstance(other, Tensor): raise TypeError(f\"Cannot compare a Tensor with a {type(other)}\") return self.value == other.value def __add__(self, other) -> Tensor: if not isinstance(other, Tensor): raise TypeError(f\"Cannot add a Tensor to a {type(other)}\") return _add(self, other) def __sub__(self, other) -> Tensor: if not isinstance(other, Tensor): raise TypeError(f\"Cannot subtract a Tensor from a {type(other)}\") return _sub(self, other) def __mul__(self, other) -> Tensor: if not isinstance(other, Tensor): raise TypeError(f\"Cannot multiply a Tensor with a {type(other)}\") return _mul(self, other) def __iadd__(self, other) -> Tensor: return self.__add__(other) def __isub__(self, other) -> Tensor: return self.__sub__(other) def __imul__(self, other) -> Tensor: return self.__mul__(other) def __repr__(self) -> str: return f\"Tensor({self.value})\" def backward(self): if self.args is None or self.local_derivatives is None: raise ValueError( \"Cannot differentiate a Tensor that is not a function of other Tensors\" ) stack = [(self, Tensor(1))] while stack: node, current_derivative = stack.pop() # if we have reached a parameter (it has no arguments # because it wasn't created by an operation) then add the # current_derivative to derivative if not node.args: if node.derivative is None: node.derivative = current_derivative else: node.derivative += current_derivative continue for arg, derivative in zip(node.args, node.local_derivatives): stack.append((arg, current_derivative * derivative)) Let’s take it for a spin. We’ll try calculating 𝐿 again y = Tensor(1) m = Tensor(2) x = Tensor(3) c = Tensor(4) diff = y - ((m * x) + c) L = diff * diff L.backward() test(got=x.derivative, want=Tensor(36)) ✅ - Want: Tensor(36), Got: Tensor(36) Much easier! To really see what this baby can do, I asked a language model for the most complicated expression it could think of and it gave me this: 𝑓 ( 𝑥 ) = ( 2 𝑥 3 + 4 𝑥 2 − 5 𝑥 ) × ( 3 𝑥 2 − 2 𝑥 + 7 ) − ( 6 𝑥 4 + 2 𝑥 3 − 8 𝑥 2 ) + ( 5 𝑥 2 − 3 𝑥 ) According to Wolfram Alpha, the derivative of this expression is: 𝑑 𝑓 ( 𝑥 ) 𝑑 𝑥 = − 38 + 102 𝑥 − 33 𝑥 2 + 8 𝑥 3 + 30 𝑥 4 If we plug 2 into this equation, the answer is apparently 578 (again, thanks to Wolfram Alpha). Let’s try it with our algorithm x = Tensor(2) y = ( (Tensor(2) * x * x * x + Tensor(4) * x * x - Tensor(5) * x) * (Tensor(3) * x * x - Tensor(2) * x + Tensor(7)) - (Tensor(6) * x * x * x * x + Tensor(2) * x * x * x - Tensor(8) * x * x) + (Tensor(5) * x * x - Tensor(3) * x) ) y.backward() test(got=x.derivative, want=Tensor(578)) ✅ - Want: Tensor(578), Got: Tensor(578) Once again, we got the right answer! Conclusion From nothing, we have now written an algorithm that will let us differentiate any mathematical expression (provided it only involves addition, subtraction and multiplication). We did this by converting our expression into a graph and re-imagining partial derivatives as operations on the edges of that graph. Then we found that we could apply Breadth First Search to combine all the derivatives together to get a final answer. Differentiating scalars is (I hope you agree) interesting, but it isn’t exactly GPT-4. That said, with a few small modifications to our algorithm, we can extend our algorithm to handle multi-dimensional tensors like matrices and vectors. Once you can do that, you can build up to backpropagation and, eventually, to a fully functional language model. Next time, we’ll extend our algorithm to vectors and matrices and build up from there to a working neural network. If you want to peek ahead, you can check out the repo for Tricycle which is the name for the deep learning framework we’re building.",
    "commentLink": "https://news.ycombinator.com/item?id=39387850",
    "commentBody": "Building an LLM from Scratch: Automatic Differentiation (2023) (bclarkson-code.github.io)258 points by netwrt 14 hours agohidepastfavorite14 comments cafaxo 12 hours agoI did a similar thing for Julia: Llama2.jl contains vanilla Julia code [1] for training small Llama2-style models on the CPU. [1] https://github.com/cafaxo/Llama2.jl/tree/master/src/training reply 3abiton 1 hour agoparentHow hard was it to find open source data nowadays? I saw that books3 are already made illegal to train on. reply andxor_ 7 hours agoparentprevGreat stuff. Thanks for sharing. reply itissid 11 hours agoprevEvery one should go through this rite of passage work and get to the \"Attention is all you need\" implementation. It's a world where engineering and the academic papers are very close and reproducible and a must for you to progress in the field. (see also andre karpathys zero to hero nn series on youtube as well its very good and similar to this work) reply calebkaiser 8 hours agoparentI would also recommend going through Callum McDougall/Neel Nanda's fantastic Transformer from Scratch tutorial. It takes a different approach to conceptualizing the model (or at least, it implements it in a way which emphasizes different characteristics of Transformers and self-attention), which I found deeply satisfying when I first explored them. https://arena-ch1-transformers.streamlit.app/%5B1.1%5D_Trans... reply joshua11 3 hours agorootparentThanks for sharing. This is a nice resource reply simfoo 1 hour agoparentprevThat magic moment in Karpathys first video when he gets to the loss function and calls backward for the first time - this is when it clicked for me. Highly recommended! reply bschne 9 hours agoparentprev+1 for Karpathy, the series is really good reply wredue 7 hours agoparentprevIs this YouTube series also “from scratch (but not really)” Edit - it is. Not to talk down on the series. I’m sure it’s good, but it is actually “LLM with PyTorch”. Edit - I looked again and I was actually not correct. He does ultimately use frameworks, but gives some early talk about how those function under the hood. reply andxor_ 7 hours agoprevVery well written. AD is like magic and this is a good exposition on the basic building block. I quite like Jeremy's approach: https://nbviewer.org/github/fastai/fastbook/blob/master/17_f... It shows a very simple \"Pythonic\" approach to assemble gradient of a composition of functions from the gradients of the components. reply nqzero 8 hours agoprevis there an existing SLM that resembles an LLM in architecture that includes the code for training it ? i realize the cost and time to train may be prohibitive and that quality on general english might be very limited, but is the code itself available ? reply sva_ 8 hours agoparentNot sure what you mean with SLM, but https://github.com/karpathy/nanoGPT reply asgraham 13 hours agoprev [–] As a chronic premature optimizer my first reaction was, \"Is this even possible in vanilla python???\" Obviously it's possible, but can you train an LLM before the heat death of the universe? A perceptron, sure, of course. A deep learning model, plausible if it's not too deep. But a large language model? I.e. the kind of LLM necessary for \"from vanilla python to functional coding assistant.\" But obviously the author already thought of that. The source repo has a great motto: \"It don't go fast but it do be goin'\" [1] I love the idea of the project and I'm curious to see what the endgame runtime will be. [1] https://github.com/bclarkson-code/Tricycle reply gkbrk 12 hours agoparent [–] Why wouldn't it be possible? You can generate machine code with Python and call into it with ctypes. All your deep learning code is still in Python, but in the runtime it gets JIT compiled into something faster. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The text discusses the creation of a language model from scratch, with a focus on automatic differentiation in deep learning.",
      "The importance of derivatives of tensors is explained, with code examples provided for calculating and storing derivatives.",
      "The use of graphs to represent complex formulas and calculate derivatives, along with the implementation of methods for comparing Tensor objects and finding derivatives using the chain rule, is discussed."
    ],
    "commentSummary": [
      "The post provides guidance on creating a differentiable programming language model from the ground up.",
      "It suggests additional resources and tutorials for further learning on this subject.",
      "The post mentions a question on sourcing open source data and highlights a GitHub repository containing a sizable language model."
    ],
    "points": 258,
    "commentCount": 14,
    "retryCount": 0,
    "time": 1708027312
  },
  {
    "id": 39385301,
    "title": "Feds' scapegoat claim against Flipper Zero doubted by experts",
    "originLink": "https://www.vice.com/en/article/4a388g/flipper-zero-ban-canada-hacking-car-thefts",
    "originBody": "Feds Want to Ban the World’s Cutest Hacking Device. Experts Say It's a ‘Scapegoat’ Canada is moving to ban the TikTok-famous Flipper Zero, claiming that it contributes to car thefts. It doesn’t. by Janus Rose New York, US February 12, 2024, 4:08pm Share Tweet Snap Image: Flipper Zero The government of Canada has its sights set on banning the Flipper Zero, an adorable handheld hacking device that is cherished by security researchers and hobbyist hackers and has gained a sizable following on TikTok. The device is modeled and named after the virtual dolphin from the movie Johnny Mnemonic, and it’s essentially a Tamagotchi you can use to hack stuff. Flipper can scan radio frequencies and clone key fobs, control infrared-based devices, and is generally a kind of Swiss Army knife for security researchers, who actually use it to improve device security. It’s also used by hobbyists who like playing around with computers, and more generally it’s just really adorable. But there's a lot of misinformation floating around about its capabilities due to bombastic—and often staged—videos on TikTok and other social media platforms. Advertisement Flipper’s popularity has resulted in the device being named as a target in an upcoming National Summit on Combating Auto Theft, where the Canadian government claims, without any evidence, that the device is being used to steal cars. “Criminals have been using sophisticated tools to steal cars. And Canadians are rightfully worried,” wrote François-Philippe Champagne, the Canadian Minister of Innovation, Science and Industry, in a tweet. “Today, I announced we are banning the importation, sale and use of consumer hacking devices, like flippers, used to commit these crimes.” Canada does have a problem with car thefts at the moment tied to organized crime networks, but there's no evidence that Flipper Zero is playing a major role in these thefts. The Flipper Zero scans frequencies and records signals that can be replayed. While the Flipper Zero can do this for a car key fob, allowing a user to open a car with the device, it only works once due to the rolling codes that have been implemented by car makers for 30 years, and only if the key fob is first activated out of range of the car. More effective approaches used by criminals involve actually plugging a device into a car with a cable or employing a \"relay\" (not replay) attack that involves two devices—one by the car and one near the fob, which tricks the car into thinking the owner is nearby. Advertisement Champagne linked a press release for an upcoming national summit where government will be “Pursuing all avenues to ban devices used to steal vehicles by copying the wireless signals for remote keyless entry, such as the Flipper Zero, which would allow for the removal of those devices from the Canadian marketplace through collaboration with law enforcement agencies,” according to one the conference’s agenda items. The press release does not include any evidence that the device is being used for auto theft. Naturally, this has riled digital rights groups and sections of the hacker and cybersecurity community, who are both upset and unsurprised that the Canadian government has their beloved Flipper in its crosshairs. \"We shouldn't be blaming manufacturers of radio transmitters for security lapses in the wireless unlock mechanisms of cars,\" Bill Budington, Senior Staff Technologist at the Electronic Frontier Foundation, said in a statement to Motherboard. \"Flipper Zero devices, because of their ease of use, are convenient scapegoats to blame for gaping security holes in fob implementations by car manufacturers. Banning Flipper Zero devices is tantamount to banning a multi-tool because it can be used for vandalism, or banning markers because they can be used for graffiti. Moreover, tools like the Flipper Zero are used by security researchers involved in researching and hardening the security of systems like car fobs—banning them will result in tangible harms.\" Advertisement Canadian digital rights group OpenMedia concurred that banning the Flipper Zero would do more harm than good. \"A ban on sale of general purpose tools like the Flipper Zero will do more to hurt than help Canadian cybersecurity,\" said OpenMedia Executive Director Matt Hatfield. \"The core problem here is the vulnerability of the keyless entry systems cars are using, not the fact that ordinary technology can reveal this vulnerability. By blocking the lawful sale of these devices, Canada will make it harder for cybersecurity researchers to do their work of testing vulnerabilities and informing the Canadian public, while doing little to prevent motivated car thieves from acquiring tools and exploiting these vulnerabilities.\" When reached for comment, Flipper Devices COO Alex Kugalin reiterated that modern cars are largely protected from the simple attacks the device is capable of. “Flipper Zero can’t be used to hijack any car, specifically the ones produced after the 1990s, since their security systems have rolling codes. Also, it’d require actively blocking the signal from the owner to catch the original signal, which Flipper Zero’s hardware is incapable of doing”, said Alex Kulagin, COO of Flipper Devices. “Flipper Zero is intended for security testing and development and we have taken necessary precautions to ensure the device can’t be used for nefarious purposes.\" Advertisement The company pointed Motherboard to a January 2023 alert from the New Jersey Cybersecurity & Communications Integration Cell, a state organization. The alert stated that \"most modern wireless devices are not vulnerable to simple replay attacks\" and added that the Flipper Zero is unable to make purchases using signals captured from contactless credit cards. The alert also pointed to reporting from Wired that stated most of the dramatic videos on TikTok showing a Flipper Zero being used to steal a car are likely staged. The proposed ban prompted bemused reactions from cybersecurity professionals on social media. “The only thing that can stop a bad guy with a Flipper Zero is a good guy with a Flipper Zero. I have a right to protect my family and community,” wrote security researcher Wesley McGrew, in a cheeky tweet referencing the frequently-used pro-gun rhetoric. McGrew also responded to Champagne’s post with a “Come And Take It” meme spinning off the popular libertarian slogan. Security experts lined up to lambaste the Canadian government and its insistence that the device is enabling crime. “Instant reactive thought… Isn’t stealing a car already a crime - that the criminal is ok breaking?” wrote security consultant Josh Corman. Others mocked the government’s belief that devices like Flipper Zero are dangerous and all-powerful hacking tools. “I don’t find the Flipper to be that useful. Its built-in radio frequency support is barely more than you get from a good rooted phone. And I was unable to purchase the RF frequency modules because they were sold out. But imagine that *this* is considered a threat!” wrote Matthew Green, a professor of cryptography at Johns Hopkins University. Jordan Pearson contributed reporting to this article. Tagged:computer securityCanadaFlipper Zerohackers ORIGINAL REPORTING ON EVERYTHING THAT MATTERS IN YOUR INBOX. Your Email: Subscribe By signing up, you agree to the Terms of Use and Privacy Policy & to receive electronic communications from Vice Media Group, which may include marketing promotions, advertisements and sponsored content. Advertisement 0 Advertisement",
    "commentLink": "https://news.ycombinator.com/item?id=39385301",
    "commentBody": "Feds want to ban the Flipper Zero – Experts say it's a scapegoat (vice.com)248 points by LinuxBender 16 hours agohidepastfavorite232 comments neom 16 hours agoI mentioned this last time it came up[1] but I'll mention it again, if anyone is directly affected by this precedent being potentially set, please reach out to me. A little more context, I'm the founder in residence at a very large Canadian law firm, and we have a government relations group. I'd be willing to use a bit of my budget to see if we can't push into this somehow. [1]https://news.ycombinator.com/item?id=39310369 reply declaredapple 15 hours agoparentI'm curious what the impact of this would be on non-flippers. The flipper is just some common off-the-shelf radios and microcontroller, albiet in a nice package. That's it. Like common radios found in your everyday stuff, like say a garage door remote. Would regulations affect every product using these? I assume they'd have to in order to have any teeth? Would this impact a developer who wants to buy an cc1101 evaluation board for development? reply wkat4242 2 hours agorootparentYeah it's just an ESP32 with a few cheap radio modules really. I'm surprised how expensive it is in fact. Also, banning it is not going to actually make it unavailable to bad actors obviously. It will just hamper white hat security researchers. reply neom 15 hours agorootparentprevThis is very much my concern. Flipper is cool and all, but I'm more concerned about the chilling effect it might have across the industry. As pierat mentioned in the comments here, it could end up being a real mess and hamper innovation in Canada, that's why I'm willing to stick my neck out a bit. reply EA-3167 15 hours agorootparentThe term \"chilling effect\" gets thrown around a lot online, but if this isn't the correct application I don't know what is. I truly can't imagine the thinking behind such sloppy legislation. reply notatoad 14 hours agorootparentthe thinking is that the federal justice minister's government-issued vehicle has been stolen three times in the last three years, and he's pissed. it's the classic \"we must do something\" problem, where the definition of \"something\" isn't the important bit. reply graemep 14 hours agorootparentPolitician's syllogism from Yes Minister: We must do something This is something Therefore, we must do this I also love the touching naivety of legislators who seem to think that to stop bad people doing things all you need to do is pass laws making the bad things they do illegal. reply Verdex 13 hours agorootparent> I also love the touching naivety of legislators who seem to think that to stop bad people doing things all you need to do is pass laws making the bad things they do illegal. This is something that always frustrated me for hot button political issues. One side wants to make the thing everyone already agrees is bad double illegal, and the other side wants enforcement of existing options. Or if we're talking about something that ought to be done. One side wants to throw money at the problem; the other side suggests that people should just try to not have bad things happen to them. Ultimately, the refrain endlessly repeated is that people who want something to happen or don't want something to happen both want someone else to fix it. Somehow. Lets make flipper zero illegal. Huh, someone stole the car again. Using a (now illegal) flipper zero (I mean technically it sounds like this isn't being facilitated by flipper zero, but use some imagination for a sec). Now what are you going to do. Make flipper zero MORE illegal? Stealing a car is already pretty high up there in terms of things that people don't want you to do. The neat thing about automation and consumer electronics is that I can fix things myself. I don't have to influence a policy that is going to harness the efforts of potentially millions of other people (taxes, more laws, enforcement). reply AnthonyMouse 13 hours agorootparent> Stealing a car is already pretty high up there in terms of things that people don't want you to do. This is the core flaw in laws like this and DMCA 1201. You have something which is already illegal, people are breaking the law, so you pass a law to make it illegal to have shoes because the criminals were wearing shoes while breaking the law. Obviously this needs to be prohibited because it helps them to run away. Then criminals continue to both commit crimes and wear shoes and all you've really done is force people who obey the law to go barefoot. reply wwweston 10 hours agorootparentprev\"Make things you don't want people to do harder\" can be a pretty reasonable course of action even when you can't make them impossible. The real problem isn't that you can't make things harder (certainly we could cross the threshold \"can't sell off-the-shelf products that make car theft easy\"), it's how far you get into making things harder before you hit tradeoffs making entirely innocent things harder. And where that tradeoff stops being worth it isn't always clear. Personally I'd like the convenience of a device like Flipper Zero but it's hard for me to say that my right to have someone else make me something turnkey trumps people's rights to maybe not have it quite so easy to have their cars stolen. And yes, I absolutely get it that people will still make/have them. That's not the point. The point is that fewer people would, the fruit gets higher hanging and that changes the statistics. Worth it? Maybe, maybe not, but it's not a ridiculous position. reply philistine 13 hours agorootparentprevTo be extra crispy clear: the justice minister's governmental car has indeed been stolen three times in three years. But there have been two different persons who were minister in the last three years to whom it happened. reply happytiger 16 hours agoparentprevBless you for doing this. I’ll point some friends to your post. reply pierat 15 hours agoparentprevI would suggest you also look into potential illegalization of things like SDRs like the HackRF portapack, and other SDRs. My kit can easily do a LOT of naughty stuff. JUst because I can, doesn't mean I do. But again, this won't just be a flipper zero ban, but a SDR RX/TX ban. (Im aware the flipper0 is not a SDR, but using the chip Texas Instruments CC1101 chip, but is functionally able to record/playback IQ-ish data.) reply Dalewyn 15 hours agoparentprevBefore anyone asks \"Why is a Canadian law firm concerned with the USA?\", the headline by Vice is hideously misleading: \"Feds\" as in the Canadian federal government, not the US federal government. Writing like this is one of many reasons I despise \"journalism\" now. reply dghlsakjg 15 hours agorootparentThat all headlines are not contextualized to the US is why you hate journalism? reply tdb7893 15 hours agorootparentJournalism has its flaws but my experience is that some people just want to hate on journalists and will use every excuse. Edit: it's also a little funny to see people who work in tech throwing stones at journalists reply mrguyorama 14 hours agorootparentI have some empathy because a lot of \"journalists\" writing the news aren't actually journalists by trade or training, but rather marketing or \"social media gurus\" or similar nonsense that hasn't taught you how to judge source material, and because they are under immense pressure to do more with less than their ancestors, so nearly every article is just someone else's press release with a little flair added. In many ways, journalism of today is empirically worse off and less useful than journalism of yesterday, simply due to it's seeming takeover by marketing types who have a lose understanding of what we should consider \"truth\" because they like to make money. But it's so insane when people act like we didn't go to war with spain in 1890s over a supposed attack on our warship that DID NOT HAPPEN, and then didn't increase our involvement in war with vietnam over a supposed attack on our warship that DID NOT HAPPEN, and then we didn't go bomb the desert for two decades because they were full of supposed WMDs that DID NOT EXIST. Yellow journalism is older than your grandparents. reply bluGill 14 hours agorootparentprevThis is vice.com not vice.ca. If Vice.ca said the feds I'd assume Canada. A .com I shouldn't know at all what it refers to, but given that almost nothing is in .us I generally assume .com means US. Context is very important, and the context implies US so it is important to specify. reply dghlsakjg 13 hours agorootparent.com is used in Canada and the entire rest of the world as well. It doesn't belong exclusively to the US by right or by custom. reply bluGill 12 hours agorootparentBy custom other countries use their own country code much more often. You are correct .com does not actually belong to the us. reply saint_fiasco 14 hours agorootparentprev> given that almost nothing is in .us I generally assume .com means US. Wait, that doesn't follow. All squares are rectangles but not all rectangles are squares. In fact, most rectangles aren't squares. reply Dalewyn 15 hours agorootparentprevNo, I hate headlines that are unnecessarily vague or misleading. \"Canada wants to ban the Flipper Zero\" would have been the same word count and infinitely more descriptive. Also, I'm not going to read the contents of every bloody article. Especially if the contents don't particularly interest me. Headlines exist for easy and reasonably accurate summarization, which this one fails to do. reply dghlsakjg 14 hours agorootparentYou don’t have to read the article. The sub headline includes the context of the country being Canada. “Canada is moving to ban the TikTok-famous Flipper Zero, claiming that it contributes to car thefts. It doesn’t.” The least you could do is refrain from commenting on articles that you haven’t even clicked on. reply Repulsion9513 4 hours agorootparentThe least the article could do is make it clear before I click, that I don't need to click on it because it's the same news I already read days ago... especially since I am passingly familiar with Vice and know they have a significant amount of US coverage as well. But then they wouldn't get clicks that are ultimately worthless to literally everyone involved except for them! reply autoexec 10 hours agorootparentprevYeah, but by being vague they don't lose the clicks from anyone who would think \"Not my country so no need to read about it!\" - this way they can instill a sense of panic/indignation in everyone no matter what English speaking country with \"Feds\" they are in. reply nnnnnnnnnn 14 hours agorootparentprevThat headlines are purposefully vague to generate more clicks is why he hates journalism. reply jhbadger 15 hours agorootparentprevCanada also has a federal government. The USA is not unique in being made up of smaller units with their own governments with an overall federal government at a higher level. reply philistine 13 hours agorootparentYeah but a US website saying the feds totally implies the US government. I assumed the feds were the US and I'M CANADIAN. And I mean it's not the only stupid thing that journalists do. I just so happen to live near the capital of the country. I'll see articles that say Ottawa wants to ban single-use plastic bags. The city of Ottawa, or the federal government by using the capital city name as shorthand? Then you read the article and it is often impossible to find clues to indicate which organization wants to do the thing. reply aardshark 12 hours agorootparentThat's just because you're used to a US-centric view of the internet from all the other Americans who perpetuate the silliness. reply zonkerdonker 5 hours agorootparentIt is vice.com, not vice.ca reply WarOnPrivacy 15 hours agorootparentprev> hideously misleading: \"Feds\" as in the Canadian ... not the US This seems like a picayune complaint, especially when the article has one the most responsible observations possible. where the Canadian government claims, without any evidence reply froh 14 hours agorootparentprevI appreciate providing the context. however the overgeneralization and emotio al excursion on \"journalism\" is missing the point of thinking the implicit context of a world wide forum is the usa. the headline per se isn't misleading, not is journalism. what's misleading is the implicit bias in our heads. reply Repulsion9513 4 hours agorootparentWouldn't you assume that the implicit context of a non-world-wide forum such as a news site was the USA, if almost every article you had previously seen from that forum was covering social or political issues in the USA? Here's their top (place-specific) headlines right now: Tucker Carlson+Putin (US/RU); Alejandro Mayorkas (US); Trump/Taylor Swift (US); Neo-Nazi concerts (EU) reply mholt 16 hours agoprevInstead of banning game boys with radios, maybe fix the swiss cheese cars. reply crest 16 hours agoparentAnd hold the manufactures selling negligent product designs to the public responsible. They won't improve until it's more expensive to sell crap. reply Reason077 14 hours agorootparentI suspect it does affect the manufacturers indirectly: if you make an insecure car (ahem, Hyundai/Kia), theft rates and insurance premiums rise. That in turn means that residuals (resale values) go down which affects the profitability of leases and reduces demand for new cars, at least until the flaws are fixed. reply jedberg 12 hours agorootparentI don't think most people check stuff like that when buying a used car. They just go for the one that has the features they like. Most people don't even price out insurance until after they buy, which means it won't affect resale. The Kia one maybe just because it is so well known, but in most cases it probably has no effect at all. reply armada651 15 hours agorootparentprevRight, but they have a lobby, so that will actually be met with resistance. This approach was chosen as it's a quick way to appear that you're doing something to combat car theft without actually meeting a lot of political resistance. reply MikusR 14 hours agoparentprevInstead of fixing swiss cheese cars, maybe try catching and punishing the criminals. Just because i hold my phone in my hand and not in a locked safe doesn't mean you can take it. reply galleywest200 14 hours agorootparentHow about we do both? No reason we cannot punish criminals while also holding lazy manufacturers to account. reply undersuit 3 hours agorootparent>No reason we cannot punish criminals while also holding lazy manufacturers to account. I think you're talking about the same thing. reply willcipriano 14 hours agorootparentprevMy proposed solution, manufacturers have to stop bring lazy and install it and it solves the criminal problem: https://m.youtube.com/watch?v=7U4ZYOBzEEs reply coltonv 14 hours agorootparentprevBecause this is not an easy crime to catch or punish, these cars are so easy to steal a layman can do it in minutes without making much noise, take it to a chop shop, and be off with some money in no time. Getting better at identifying and shutting down these chop shops is a good idea obviously, but that's also hard. On the other hand, forcing companies who didn't give a shit about security for years to pay for retrofitting the shitty cars they put out is actually a lot easier. reply retrochameleon 7 hours agorootparentSounds like we need more surveillance, facial recognition, and AI behavior and activity tracking around cities then /s reply op00to 16 hours agoparentprevAs a Hyundai owner, TTTHHHIIISSS! reply Reason077 14 hours agorootparentWas going to mention Hyundai/Kia. (Background: many pre-2023 or so Hyundai, Kia, and Genesis models have a catastrophic security flaw that allows thieves to open, start, and drive affected vehicles without needing any access to the key fob at all. This is far worse than a signal cloning or relay attack and has resulted in skyrocketing theft rates and spiralling insurance costs in many countries…) reply op00to 14 hours agorootparentThat catastrophic security flaw? That the US Gov't didn't require immobilizers on cars until way too late. Funnily enough, Canada DID require immobilizers, so I think they're not subject to the same BS my car is subject to. reply Reason077 13 hours agorootparentNothing to do with immobilizers: that was a separate issue that was apparently fixed in 2021. It’s a wireless attack that affects late model cars with proximity-based keyfobs (ie: ones that do not require a button to be pressed on the fob for the car to detect it), including 2022 and 2023 models such as the Ioniq 5 EV: https://www.reddit.com/r/Ioniq5/comments/17lksic/increase_in... All countries seem to be affected, not just US models. reply op00to 12 hours agorootparentI guarantee you that issue was not fixed for everyone in 2021, looking at my car without a software update. :) reply Reason077 12 hours agorootparentYeah, fixed in new cars from 2021 onwards I mean. reply op00to 11 hours agorootparentAh, I’m sorry! I understand now! reply cloudedcordial 12 hours agoparentprevInstead of putting money towards educating great cybersecurity professionals to overcome the bad actors, some folks want to get one tool banned. By the time ban comes in effect, I bet that there will be even more nifty tools than Flipper Zero. The folks who suggested or agreed on this ban ignored how tech moves faster than law creation and enforcement. reply mfer 16 hours agoparentprevI believe this was fixed. Decades ago. The Flipper Zero can't be used on a car made in the past couple decades. reply kube-system 15 hours agorootparentDepends entirely on the particular attack and the particular implementation. Even rolling code systems have vulnerabilities (e.g. relay attacks), they're just harder to attack. reply ikekkdcjkfke 15 hours agorootparentYup, someone stole teslas by relaying the key inside the house reply Reason077 14 hours agorootparentRelay attacks can be defeated by precisely measuring the latency between the car and the fob/key device. Apparently relay attacks on Teslas are very difficult now days for this reason. reply shrimp_emoji 14 hours agoparentprevVirginia bans radar detectors, which is wild. You're not even emitting radio -- you're detecting it when it's being shot at you, and that's illegal?! reply toast0 5 hours agorootparentRadar detectors usually do emit some radio as a byproduct of how the receiver works. Plus it lets the radar detector companies sell radar detector dectors to the cops. And upgraded radar detectors to the chronic speeders that can detect the dectector detectors. Etc. reply Mtinie 13 hours agorootparentprevAFAIK, it’s not about emissions or reception, it’s about increasing the LEO coffers via traffic fines. It may be described as a signals concern but that’s simply window dressing. reply superkuh 15 hours agoparentprevRadio hobbyists don't have the extensive lobby buying legislators like car manufacturers do. reply sgerenser 16 hours agoprevWent ahead and ordered one of these last week after hearing stories about a potential ban. No idea what I’m going to do with it, but not being able to get one made me want to have one just to play around with. reply evilduck 16 hours agoparentFor the hacker minded electronics geek, you can build out the same utility of the Flipper for pennies on the dollar from components if you can solder and write a bit of software in C or even Micropython. SDR is a pretty big hobby. This move is really akin to banning a Hello Kitty Lockpick set after discovering most locks are snake oil, instead of demanding reasonably secure locks be sold instead. reply autoexec 15 hours agorootparentIf you actually know where to find a Hello Kitty Lockpick set please post a link. I know some people who would be very interested! reply sgerenser 13 hours agorootparentprevI own a 3D printer, and have a couple Raspberry Pis and breadboards in a closet somewhere. But there’s no way I’d have the time or inclination to put everything together in a way that is actually worth it over just paying $169 for a flipper. Someone already posted it but this reminded me of the “I don’t get the point of Dropbox when we already have FTP and CVS” comment from 2008. reply cloudedcordial 12 hours agorootparentFTP and CVS in 2008...Please remind us about this discussion in 2040! reply michael1999 12 hours agorootparentprevBut that's kind of the point, isn't it? If you have the skills to build a GHz SDR from components, and write some C to attack a car starter, you probably have better ways to make $2k than stealing a car. Evilduck obviously has better things to do. Releasing a Hello Kitty SDR makes these attacks practical for a much less capable population who actually will go steal a car. I can testify that the bike theft industry in Toronto was driven by one mad genius for a generation. Igor Kenk was like a spiderman villain. He ran a vertically integrated business: providing specialized tools for cracking locks; training on their use; and then providing coke/crack directly for stolen bikes eliminating the cash-handling risks of the business. Just a total mad Chad. If Flipper enables another guy like Kenk to build an empire of idiot car thieves, I can understand the butt-hurt. reply pierat 15 hours agorootparentprevThat is true you can cobble shit on a breadboard. And it's highly non-portable and extremely anti-usable. Having a simple nice form-factor for something that can do under 1GHz am/fm, BTLE, IR, dallas 1wire, and pinouts for expansion in a simple smaller-than-cellphone device is pretty sweet. Sure, script kiddies will be script kiddies. And sure, they shouldn't do bad shit, but they will. It's also your responsibility to run reasonably secure stuff. And no, the FCC won't help you. You're not big money like cell, digital TV, or avionics. ------------------------ EDIT cause of too many comments bullshit: This conversation chain is sure sounding like https://news.ycombinator.com/item?id=9224 , the whole \"dropbox is inferior to FTP\". We all know how that worked out. Having done actual RF, electronic, software, and encasement design - it's nowhere as simple as \"cobble it and 3d print a case and done\". If it was, we would have seen a Flipper Zero like thing ages ago. Prove me wrong. If it's that simple, point me to a blog or github that you execute on all the assets within a week. (because it aint) reply sumtechguy 15 hours agorootparent> That is true you can cobble shit on a breadboard. And it's highly non-portable and extremely anti-usable. For the kind of person who does that putting it in a 'ok' case is not that much work... reply JoeCortopassi 14 hours agorootparentThe case is not trivial, not crazy, but not trivial. It's also the least hard part about putting together a similar package. A non-EE type person could probably get some dev boards from sparkfun/adafruit, and connect them up to a raspberry pi with some sort of display with some buttons. But that last mile of getting them to play nice, not be a massive battery hog, and have simple/usable software is man-months of work. This also assumes you have a passing knowledge of circuits and are decent enough programmer to get a job, neither of which are low bars This is likely @pierat's point: sure, it's possible, but your diy version will be objectively worse in a variety of ways while also taking you a pretty long time to put together. reply evilduck 14 hours agorootparentI agree, the skill acquisition time and effort would keep out script kiddies and normal consumers, but there's a large number of people who do have these skills, especially on this site. reply giantg2 15 hours agorootparentprevEspecially since many likely have a 3D printer, or a friend with one. reply evilduck 14 hours agorootparentprev> That is true you can cobble shit on a breadboard. And it's highly non-portable and extremely anti-usable. I've already done basically this level of stuff for my own custom bluetooth mechanical keyboard projects (a keyboard is larger overall, for obvious reasons, but the space beneath it where you can fit electronics is quite limited) and I've made a few resin cases for other electronic hobby projects. The software side of the Flipper is much more time investment but still something I could do if I was fully motivated and had no other obligations getting in the way. Or I would just cheat and specifically use the same STM32WB55 microcontroller and re-use the existing Flipper's firmware directly. Designing a case and a PCB for something of the Flipper's complexity is really not that hard. A day or two each. Honestly, I find the Flipper's case to be pretty poorly designed for actual usability, it's mostly just directly exposing hardware externally in as small of a space they could get away with, it's a complete pocket brick otherwise. It's a striking visual design with the angles but actually kind of terrible at slipping in and out of your pocket and is awkward and clumsy to use one handed or subtly. Cell phones (at least up until very recently) carried similar radios, IR blaster, SD slots and ports in much better and smaller form factors, and are so normalized in public use that it might have flown under the radar both in consumer's eyes and regulator attention if it wasn't actually so visually distinctive. reply giantg2 15 hours agorootparentprevI'd be highly interested in a cheaper DIY version, even if it were slightly uglier or bulkier. I don't feel I could do it well from scratch, but a tutorial or even a kit (like truSDX). reply vdaea 15 hours agorootparentI'd be highly interested in an aliexpress version that has the same features and is software-compatible but at 1/5 the cost. reply happytiger 16 hours agoparentprevThey are super great for teaching kids. Absolutely brilliant little device. reply megiddo 16 hours agoparentprevDamn, I've been trying to sell mine. Is there a used market place for them? reply danesparza 14 hours agorootparentI think there is a place called 'electronic Bay'. You might try there. Yes, that was a Ron Swanson reference. reply user_7832 16 hours agorootparentprevThere might be some variant of a r/hardwareswap. Side note, if you/anyone in the Netherlands is trying to sell one I'm interested. reply Zircom 16 hours agorootparentprevDrop me an email(on my profile) I'd be interested possibly. reply dbrueck 15 hours agorootparentprevSold mine for $300 on ebay. reply stronglikedan 15 hours agorootparentThat's nuts considering they're available for $170, unless it was one of the sold out transparent ones. reply dbrueck 14 hours agorootparentWell, it was soon after they really got their shipping rhythm going. I got mine in the mail, it sat on my desk for a few weeks because I was busy with other stuff, and it made me sad to just have it sit there unused. I wasn't completely sold on getting rid of it, so I put it on ebay for what I assumed to be an outrageous price, and it was gone within an hour. I shoulda bought 2! reply TheRealPomax 14 hours agoparentprevOne thing it's great at is discovering how easy it is to hack your own stuff. Garage door? Car? Anything bluetooth enabled? Your wifi? It's a great way to ground yourself in an understanding of what the security level is that you accepted in your day-to-day life, and then go \"huh. And I guess that's been more than secure enough for me for years, so now I know my baseline\". reply 2OEH8eoCRo0 14 hours agoparentprevSmart. That's the same reason I buy AR-15 stripped lowers and chuck them into storage whenever there are rumors of a ban. reply scrps 14 hours agoprevPresumably having a flipper in your pocket, if the ban happens, will subject you to legal liability and something tells me the penalties will be less than stealing a car. So the people who are trying to use the flipper zero to commit a greater crime will simply not care and carry on because who cares about a misdemeanor when you are about to commit a felony. Organized criminals can get bespoke hardware simply by hiring skilled labor overlooked or outcast by industry. Skilled tech-based criminals can build their own kit. This hurts mostly people who want to get into some form of security or hacking and at best maybe stops high school antics but threatens to upend the entire way hackers have always honed their skills by doing and tinkering and also upending the small industries that support them and the security professionals who use the gear in production. Edit: typo reply ihumanable 13 hours agoparentI wonder if this ends up being more like lockpicks in practice. It's legal to own lockpicks but some jurisdictions consider possessing a lockpick to be prima facie intent to commit crime. reply scrps 13 hours agorootparentThat at least heads toward rationality. Something along the lines of if you are caught with a flipper zero during the commission of a crime AND the flipper zero was used to further it then it becomes a \"burglary tool\" or some such classification. Edit: typo... Again reply evilbob93 15 hours agoprevI got the black Kickstarter-only version. I got interested in coding in C again. My (now) ex broke up with me over this thing on the mistaken notion that I was messing with her somehow electronically. I got told i had to leave. Tonight. And take all my electronics with me. She cited having her \"black hat friend\" looking into it and he said it was pretty evil. I am sure she is reading the recent news with some level of satisfaction. I bought another a couple months later and if I can get over my ADHD, I still hope to make the radio chat useful. reply pierat 15 hours agoparentSounds like you dodged a bullet there. She sounds crazy AND stupid. My SO was like, \"Wheres mine?\" reply fransje26 13 hours agoparentprev> She cited having her \"black hat friend\" looking On the first pass I read it as: \"She cited having her tinfoil hat friend looking into it\".. reply Havoc 15 hours agoparentprev>the mistaken notion that I was messing with her somehow electronically Let me guess...via 5G? reply fransje26 13 hours agorootparentNo, it's interfering with the nano antennas injected with the Covid vaccines.. reply dmonitor 16 hours agoprevI kind of hate the Flipper Zero on principle. It's basically a script kiddy device for hardware. People use them to essentially DDOS cell phones with BLE connection requests. You can do it with any micro controller with a 2.4ghz radio, but this thing makes it easy for annoying people to just pull a script from the internet and make it everyone else's problem. reply diggan 15 hours agoparent> and make it everyone else's problem Seems like the focus should be on who is allowing and enabling this type of usage. Manufacturers, since they do not act of their own free will, need to be compelled to actually release secure software. If anything, I love that the Flipper Zero is revealing how vulnerable a lot of this technology is. It hasn't been this easy before to execute radio hacks while mobile, nor in such a game-like/product format. Consequently, I think many people have not realized how secure their devices actually are. It seems that people are finally becoming aware of how unsafe many of these products are. Unfortunately, they are mistakenly focusing the blame on the wrong party. Fixing the security holes also protects everything against truly \"evil malicious\" actors, not just \"fun malicious\" actors, so it has its benefits to force manufacturers to up their game. reply armada651 15 hours agorootparentThere's a limit to how resilient you can make wireless communication. Ultimately protocols like Wi-Fi relies on everyone on the frequency working together to facilitate smooth communication. If you want to disrupt that, then you'll always be able to throw a wrench into that. reply rthomas6 14 hours agorootparentDenying communication will always be possible, you just have to be loud enough to drown everyone else out. But spoofing stuff doesn't have to be possible. You can design rf communications with various kinds of encryption that makes spoofing very difficult. reply kube-system 15 hours agorootparentprevRF jammers also expose how vulnerable most RF devices are to DOS attacks. But I don't think that's particularly helpful to anyone, nor should those devices be unrestricted in their distribution or use. RF spectrum inherently requires rules and cooperation -- if it were a free for all, user beware type of situation, it just wouldn't work. reply kstrauser 14 hours agorootparentThe Flipper Zero scaremongering isn't about DoS attacks, but about protocol attacks. It probably could be used as a jammer but that's not interesting. It's more useful for demonstrating that a lot of firmware is about as secure as using plaintext telnet with u/p \"admin/admin\". reply kube-system 13 hours agorootparentThe GP mentioned DoS attacks which was why I pulled on that thread. The vulnerabilities exploited by this Flipper Zero are not novel, they're already known to industry experts. The main difference with this device that they're more accessible to non-technical folks. That in and of itself is bringing attention to the issue, but is that really helpful? To me, it seems akin to handing out bricks in nice neighborhoods to highlight the security weaknesses posed by windows without bars on them. Security is not without cost. The ideal society to live in is not one with the most security, it is the one with the most trust. A lot about order in society relies on most mischievants being actors of opportunity. reply kstrauser 13 hours agorootparentI’ve worked in infosec for decades. Yes, it’s absolutely helpful to bring attention to the issue. Manufacturers have historically ignored findings that didn’t get press. That’s why groups like Google’s Project Zero have policies to disclose vulnerabilities after the vendor has been given a reasonable window to fix them in. It’d be awesome if the vendors would fix their stuff without that pressure, but again, data shows that most won’t. I think the brick and window analogy fails here. Thing is, the real bad guys generally already know about the best weaknesses to exploit. I think a better analogy would be pointing out that a storefront in a high-crime area doesn’t actually have glass in its windows. Robbers already knew that. Now the locals are telling the shop owner that they need to install some windows, quickly. reply kube-system 13 hours agorootparent> Thing is, the real bad guys generally already know about the best weaknesses to exploit. Who are \"the real bad guys\"? Highly motivated, highly intelligent attackers? That's a valid concern if you're a high value target, but most people aren't. The vast majority of crime is the result of ease and opportunity, not expertise. I live in a place with high rates of vehicle thefts. Essentially all of them are performed by low skill attackers who use low skill attacks at the physical layer. Carjackers don't care about anyone's rolling code implementation. I don't think Flipper Zero is anything to worry about, most abuse is probably just going to be edgy kids who are doing annoying things, unsyncing their friend's car keys, etc. But I disagree with the general sentiment that any proliferation of tools that escalates the need for security is always a good thing. Generally, increasing the opportunity and ease of crime is a bad thing. reply kstrauser 12 hours agorootparentWhile I get and appreciate your point, I still disagree. If a vulnerability is patched, it doesn't matter if there are 1 or 1,000 tools targeting it. In the case of small, RF-configurable systems, there are already enough in the wild to get the attention of bad actors. I was in a conference where someone discussed exploratory attacks they'd found where an attacker would target an embedded medical device, compromise it, then have the device emulate a Bluetooth keyboard to target the victim's work computer. I genuinely believe that the makers have such devices have coasted way too long on security through obscurity. These weaknesses need to be highlighted so that there's political pressure to fix them. If someone users a Flipper Zero or the like to attack a cochlear implant, they should be punished for it. So should the manufacturer of the implant who released an insecure medical device into the wild. If the Flipper's popularity is what draws attention to the broken medical device, then good for Flipper! Maybe they'll patch the problem before North Korea can use it to launch cyberattacks. reply kube-system 12 hours agorootparentI think that's a naively academic and cryptographically focused view of security. Bad actors are not a monolith. There are many different types of attackers with different means and motivations who will take different actions against different targets and different types of technologies. Threat profiling is a thing for a reason, and it absolutely does matter whether or not a particular threat has the means and/or motivation to exploit a vulnerability. It is the only thing that does matter, outside of a technical academic context. Yes, security through obscurity is not an rigorous approach to implementing a cryptography system, but it is a completely valid approach in other security disciplines outside of cryptography or digital security. Too many people make the mistake of incorrectly assuming that cryptography security principles apply to the broader practice of security as a whole. Digital security is only as useful as it is to support a holistic model of security. Digital security in isolation is just an academic exercise. It has to be implemented to be useful, and when implemented, operational security and threat modeling are very relevant. > If a vulnerability is patched, it doesn't matter if there are 1 or 1,000 tools targeting it. It does matter what the real-world observed rate of patch compliance is, the cost to patch, and whether or not those tools will be used nefariously. If you have an academically obscure remote exploit for a pacemaker, that requires a hardware patch, please don't write a script that makes it easy for non technical people to exploit, and post it on GitHub. While this will certainly encourage a fix to future pacemakers, the cost may not be worth it. reply anigbrowl 14 hours agorootparentprevThis is the common excuse for adversarial hacking, and while it has some basis in fact it's also a justification for the endless security arms race and downward spiral into zero-trust. As the man said “Your scientists were so preoccupied with whether they could, they didn't stop to think if they should.” reply 2OEH8eoCRo0 14 hours agorootparentprevManufacturers can do better but aren't these users committing felonies? Why aren't we focusing on that? Also- maybe we don't want to deal with all the extra BS that secure RF requires. reply jasonjayr 15 hours agoparentprevOn the other hand, it's exposing just how sloppy devices are with their wireless signals + code handlers. IIRC this is in Canada, but in US (and probably Canada too), FCC has rules against creating harmful interference. Fine + punish the people creating the interference, rather than the tools that people can use to learn, debug + protect these devices that are vulnerable. reply dmonitor 15 hours agorootparentThere is nothing this can do that a normal microcontroller can’t do. banning this device does nothing to harm penetration testing. it just mitigates the ease with which these exploits can be widely abused. reply Root_Denied 15 hours agorootparentThat's kind of the point though - the more widespread you see it being used the more likely it is that the tool itself will get more attention and the targets of the tool will get more attention. The point of a bill like this is to show the population that politicians are doing something, and trying to avoid nation/global news covering the topic. For another example of similar politician behavior just look at how LA is handling the graffiti towers. They're driven by concern about being on the national stage and the corruption of the whole system being put on display, not about the graffiti. reply anigbrowl 14 hours agorootparentprevFine + punish the people creating the interference This isn't a realistic solution because the difficulty of identifying people abusing these devices is high. The usual US approach is to jack penalties up way high to offset the low probability of capture, which inevitably leads to disproportionate sentences and an even greater erosion of respect for the legal system. reply Kuinox 15 hours agorootparentprevSecurity is needed because somes doesn't want to play by the rules. If nobody try to breaking in, why bother putting a lock on your door ? reply dymk 15 hours agorootparentprevThat's like saying any infrastructure is sloppily done because it's vulnerable to DDoS attacks. DDoS attacks are already illegal, but people still perform attacks. That's not the site operator's fault, and it's victim blaming. reply kstrauser 15 hours agorootparentExcept here \"DDoS\" means \"one person with a $200 radio\". I don't expect my devices to stand up to prolonged attacks against state actors. I do hope they can survive someone sending them invalid packets. reply dymk 13 hours agorootparentOh they'll survive invalid packets. It's the sheer amount of packets that are the problem, and wireless signals are just inherently hard to protect against malicious jamming. reply kstrauser 12 hours agorootparentThat's not true. Again, forget jamming for a little bit. You can build a jammer with any random spark gap transmitter. The novel attacks are one where a Flipper Zero can send an iPhone 1,000 \"hey, I'm an Apple TV, wanna hang out?\" messages in a row and the phone acts on each of them. Even if you space those messages out so that they only take a tiny percent of available throughput, the phone's response to the messages will still make it unusable. Because such a flood is now easy to trigger, phones now implement rate limiting that effectively mitigates the attacks. After all, you're not legitimately going to see 1,000 Apple TVs trying to connect at once, so there's no need to give each one of them personal attention. reply user_7832 15 hours agoparentprevDo you also dislike say the arduino or the raspberry pi which popularized sbcs/microcontrollers, as they can be used for nefarious tasks? What about bell labs, without whom none of these issues would have occurred? Technology will always develop, it's important to plan and regulate it, sure, but bans are need to be extremely carefully thought out to enforce well. reply dymk 15 hours agorootparentEven the smallest amount of friction to acquiring a device like this (e.g. you have to build your own and flash your own firmware) would prevent basically all the attacks we see on the news with a Flipper. \"Script kiddies\", by definition, are buying pre-made, turnkey devices and lack the ability to build their own. reply dghlsakjg 15 hours agorootparentThis is a really expensive device in Canada, and you do have to flash the firmware if you want access to the more harmful capabilities. The people stealing cars are an international organized group that have managed to exploit holes in the federal government, the railroad companies, and the ports. The way they are stealing these cars is outside of the capabilities of a stock flipper, and requires custom hardware. Banning the flipper is going to do precisely nothing to increase the friction on the problem they are trying to solve. reply wmil 15 hours agorootparentThe problem they are trying to solve is the perception they aren't doing anything to stop organized car theft. Banning the Flipper is a minimal effort way to minimize it as an election issue. reply dymk 3 hours agorootparentIf people are stealing cars with a Flipper, banning it seems like more than a token gesture reply kps 13 hours agorootparentprevThe major ports (Montréal and Vancouver) are controlled by organized crime. But those people are scary (and/or well-connected). Much easier to go after hobbyists. Sport shooters can insert a certain James Franco meme here. reply dmonitor 15 hours agorootparentprevi’d be more forgiving of the device if it had practical utility beyond “fucking up other people’s shit”. for me it’s in the same category as stink bombs, glitter bombs, and vuvuzelas. reply kstrauser 15 hours agorootparentI use mine as a handy NFC reader/writer, and for emulating a handful of badges and key fobs so I don't have to carry them all around with me. So are you more forgiving of it now? reply galleywest200 14 hours agorootparentprevI use mine to open my own garage door and I use the GPIO pins to check if some of my I2C devices on my breadboards are using the correct address they are supposed to be using. reply wwweston 14 hours agorootparentDoes this mean your garage door doesn't have rolling codes, or does it mean that you know how to make the flipper work with that? reply blueelephanttea 13 hours agorootparentPresumably since they have access to their own garage door the Flipper can be synced as a new remote without any \"hacking\" or brute forcing rolling codes. reply SpicyLemonZest 15 hours agorootparentprevIf you choose, as Flipper Zero has, to market your device as a tool for \"pentesting radio protocols, access control systems, hardware\", I think you have some responsibility to mitigate the obvious and trivially foreseeable consequence of people using it to just outright penetrate those things. reply user_7832 14 hours agorootparentThat's fair, I wasn't aware that was how they advertised it. I would hope they use more responsible advertising, however I still don't think that deserves it to be banned. reply skjoldr 14 hours agorootparentprevHow do the developers of Kali Linux mitigate against black hats? They don't. It's impossible. reply SpicyLemonZest 13 hours agorootparentThey don't, for example, make posts on the front page of their public website (https://flipperzero.one/) about specific technologies such as key cards which are subject to easy exploitation. reply jwr 15 hours agoparentprevIt's also a pretty useful device if you are into electronics. Or need backups of your access cards. Or of your silly garage key fobs. There are many great uses of this thing. I'm also annoyed by the script kiddies, but I do like the device. A lot. reply ganoushoreilly 16 hours agoparentprevScript kiddies aren't new, they will always be around regardless of the tools. The response is build better tools to mitigate their rudimentary attacks. reply anigbrowl 13 hours agorootparentThat works OK if you can deploy through the net. But many devices are not net connected (eg garage door openers) and we've seen the many problems with trying to make every electrical appliance net connected - surveillance, data leaks, remote shutdowns, device bricking when then IP connectivity goes down. Technology shouldn't force consumers into endless upgrade cycles in the name of better security. reply kj4ips 15 hours agoparentprevI don't think it is limited to skiddie use, it's a nice hardware platform that is pretty easy to write for. I've gotten my kabuki desuicide pretty much functional on it. It's already FCC'd, has a BMS and lots of other things that are a pain to get right. There is something about lowering the bar to disruption, and the possibility of this causing a bit of a reckoning for devices that don't do a good job of \"Accepting any interference received\" reply techplex 15 hours agoparentprevWhy not hate the cell phone manufacturers for not making secure devices? reply yummypaint 15 hours agoparentprevPart of the problem is that the design feels somewhat toy-like with the bright plastic etc. This makes using it feel like a game, and masks the seriousness of potential consequences. Some people have implanted insulin pumps and other medical devices controlled over bluetooth, and a flipper zero user may have no concept of this. reply kstrauser 15 hours agorootparentThat last bit is absolutely infuriating. Medical device manufacturers are cranking out insecure devices that rely on security through obscurity. No, I don't think people should be using Flipper Zeros to hack someone else's insulin pump. It's also unforgivable that someone should make an insulin pump that another can hack with a Flipper Zero. I use netcat for legitimate things every day. If someone made an IP server that I could hack with netcat, they should be ashamed of themselves. It's not netcat's fault that their security sucks. Well, same with Flipper Zero. reply giantg2 15 hours agorootparentprev\"medical devices controlled over bluetooth, and a flipper zero user may have no concept of this.\" And they would if it were not in a \"bright plastic case\"? reply fencepost 14 hours agoparentprevPeople use them to essentially DDOS cell phones with BLE connection requests. That's one of the situations where I'd feel justified in taking a device and stomping it to bits, and I'd support anyone else doing the same. If anyone does encounter this in the wild with Apple devices, first, install your damn updates because I'm pretty positive this is now blocked, but in the meantime turn on Lockdown mode to keep this from interfering with you. reply FireBeyond 12 hours agorootparentYou might feel justified, but courts would likely disagree. Apropos of anything else, the FCC regs around the 2.4GHz spectrum are pretty explicit, \"Part 15 devices ... must accept any interference that may be received\". In their eyes, the device that is flawed is the phone, not the Flipper. reply BenjiWiebe 8 hours agorootparentI believe there's equivalent language (even for licensed uses) about not causing interference, so probably the Flipper and the phone are doing poorly here. reply giantg2 15 hours agoparentprevMaking RF tinkering more accessible is a great way to get actual kids into tech and learning about how stuff works. reply iisan7 15 hours agoparentprevAgreed. I get why folks on this site repeat the mantra that it's shedding light on insecure hardware, and of course that's true. But civilization depends not on ironclad laws and politics, but on good faith actions. An unhackable society would be a pretty miserable one. reply skjoldr 14 hours agoparentprevBuddy, I'm from Ukraine and drone jammer and drone early warning schematics are basically public knowledge at this point. Drones mostly use the same sub-1GHz bands, 2.4 GHz bands and 5 Ghz bands that other consumer electronics also use. You can't put this genie back into the bottle. Both radio- and cyberwarfare are here to stay. Y'all just don't know it yet. After the war there are going to exist a whole bunch of people who know how to deny GPS, defend against drones, build attack drones that bypass primitive countermeasures, spoof mobile networks, monitor the RF space for unencrypted signals, and set up actually secure comms. And not all of them are going to remain completely silent about all of this. Toys like Flipper are going to be the least problematic. Banning it achieves nothing. reply JTbane 15 hours agoparentprevThis, I saw an anecdotal Reddit post about a guy DDoSing cell phones in a restaurant and showing off to his table. These kind of devices attract the worst people. reply BizarreByte 15 hours agorootparentThese devices attract the very kind of people who cause them to get banned. Sure the device is fine, but not the assholes who want them to fuck with other people. reply ikekkdcjkfke 15 hours agoparentprevPeople are already driving around with fake base stations sending scam sms impersonating legit senders reply 2OEH8eoCRo0 14 hours agoparentprevAgreed. If people could do it before then why weren't they? reply pierat 15 hours agoparentprevIt's OK. We hate your apple devices too. BTW, wanna connect to the Apple TV? :D reply clarkrinker 15 hours agoparentprevI’m running this in the coffee shop now in honor of this comment reply NovemberWhiskey 16 hours agoprevThe term that we're looking for here is \"moral panic\". reply 2024throwaway 16 hours agoprevI knew from the headline this was about my beloved Flipper Zero. It is absolutely a scapegoat. There's nothing magical about it, and it doesn't do anything that can't be done with other devices. reply jgrahamc 16 hours agoparentWhat do you love about it? I have one and I've only used it very occasionally (e.g. https://blog.jgc.org/2024/02/repairing-sort-of-dyson-fan-rem...). I did make a backup of the NFC card that I use to charge my car because it's super useful to have a duplicate, although even that I barely use because I'd need to carry the Flipper Zero around with me. reply 2024throwaway 16 hours agorootparentCloned various remote controls (treadmill, ceiling fan, floor fan) into one interface. Also the article isn't wrong, it's cute! reply jgrahamc 16 hours agorootparentAre these all infrared? Because I've done that and it's handy, but I could also have done that with a universal remote. reply 2024throwaway 16 hours agorootparentOnly the floor fan is infrared. The rest are radio. reply wil421 16 hours agorootparentprevOr just get a few smart home products, connect your devices, and automate everything from you phone. Easier than carrying around your Flipper Zero at home. reply 2024throwaway 15 hours agorootparent\"Replace your ceiling fan and treadmill\" is certainly not easier than having a small device sitting on my desk. reply Larrikin 15 hours agorootparentWhat is the use case for a flipper zero and a treadmill? There are plenty of automations you can do with a treadmill and a smart plug, but I can't think of a single use for a treadmill and any of the components in a flipper zero. Are you just turning on the fan from the treadmill? That would be better served using a power reading from the treadmill and an IR blaster. You can tie in other automations as well. I have mine setup to turn off a light that causes a TV glare visible only from the treadmill and to turn on an extra speaker next to the treadmill reply 2024throwaway 15 hours agorootparentIt is an under desk / walking treadmill. I'm turning it on and off and adjusting the speed. I really don't need more advanced automation. reply wil421 15 hours agorootparentprevWhy on earth would you do that? An IR blaster costs $25 and will connect to Homebirdge so you have it in Apple Home (or Android whatever). I made 2 dehumidifiers and 2 floor fans “smart” by buying the cheapest possible smart plugs on Amazon, an Amazon branded smart plug cost me $1 during a sale. BroadLink RM4 Mini IR Universal Remote Control, Smart Home Automation Wi-Fi Infrared Blaster https://a.co/d/8GnOVRU reply 2024throwaway 15 hours agorootparentThat covers the floor fan. Now I need a radio blaster to control the ceiling fan and treadmill. So two extra devices, plus having to set up new automation integrations. This all sounds WAY more complicated than just cloning the remotes like I've done. Would it be more flexible/powerful? Absolutely. Do I need any of that? Absolutely not. reply wil421 15 hours agorootparentThen you pay $15 more for the IR/RF blaster combo and a $35 raspberry pi 3. If you can copy an image to an SD card you can install homebridge (or home assistant). You already saved money over the $169 cost of a flipper zero and your fans/treadmill can come over whenever you enter the room or at a certain time of day. If you can play with a flipper zero you can setup automation. reply 2024throwaway 15 hours agorootparentI honestly don't know what point you are trying to make. Of course I can set up automation. I have Home Assistant running in my house already. I also happen to own a Flipper that does a great job at controlling these devices. Why would I introduce complexity where simplicity is working great? I'm done with this conversation, I'd say it's been fun, but.. reply nosrepa 15 hours agorootparentprevOP said only one device was infrared and you don't know how their other devices behave when just turned off and on. Also, smart plugs can only turn things off and on., whereas OP cloned the whole remote. reply abnry 16 hours agoparentprevFrom what I understand, it is magical in the sense that it makes everything easy to do, even for people without much knowledge. reply ghostpepper 16 hours agorootparentIt makes some things magically easy to do, but stealing cars is not one of them. reply Reason077 14 hours agorootparentDepends very much on the car. Do you own a Hyundai or Kia? reply Astraco 13 hours agorootparentMaybe we should ban Hyundais and Kias until they fix their security holes. Just an idea about banning things reply hnav 13 hours agorootparentprevthe whole debacle with hyundai/kia is that they shipped cars where you can physically start it without electronics reply Reason077 13 hours agorootparentThere’s an electronic attack too. This apparently affects many late-model Hyundai/Kia vehicles up to 2023 or so. https://www.reddit.com/r/Ioniq5/comments/17lksic/increase_in... reply aaronbrethorst 15 hours agoprevnamed after the virtual dolphin from the movie Johnny Mnemonic The dolphin was named Jones not Flipper. And Jones was also a part of the short story that predated the film adaptation by several years. Check out \"Burning Chrome,\" William Gibson's collection of short stories, for this and others. Well worth the read. reply jhbadger 15 hours agoparentYes, Flipper was the name of a dolphin in a 1960s TV show of that name (that has had various TV and movie reboots since). That's the reference they were going for. reply shakow 16 hours agoprevCrazy idea – what if we just got back to physical keys for car? Simple, cheap, ecological, durable – what's not to love? reply pnutjam 16 hours agoparentI hated the idea of push button start and wireless keyfob; until I got one. Now I feel put out every time I have to dig my keychain out of my pocket. reply midasuni 15 hours agorootparentI’ve had wireless hire cars. Horrible things, never sure where they key is and tend to come with “features” like automatically locking and setting the alarm if you walk away from the car reply Reason077 14 hours agorootparentAnd then they unlock automatically when you walk back to them. Much more convenient than having to manually fumble for the lock and unlock buttons. Not sure what the problem is here! reply midasuni 11 hours agorootparentAlarm goes off as the car isn’t empty reply Reason077 11 hours agorootparentNever had this happen in my experience. Sounds like an issue with an aftermarket alarm? reply iisan7 7 hours agorootparentPark at a convenience store. Go in to get a coffee. Leave friends in car. Friend decides they want a coffee too. They open the door-- car alarm goes off. I'm sure some cars are better programmed but this has happened to me in several cars. (For the record, I still prefer keyless!) reply Reason077 14 hours agorootparentprevHaving a keyfob at all seems awkward and old-fashioned after driving a Tesla. Same goes for the start/stop button. reply mikestew 15 hours agoparentprevCrazy idea – what if we just got back to physical keys for car? At any point did you stop and ask yourself, \"I wonder why they put that fence there?\" Simple, cheap, ecological, durable – what's not to love? What's not to love is the part where even a random HN user who hasn't professionally worked on cars in over 30 years could probably be driving down the road in your car before your dog even barks. Go ask some (probably former) Kia and Hyundai owners. reply shakow 14 hours agorootparentAnd did the guy who worked in cars for over 30 years heard about keys with chips? reply mikestew 13 hours agorootparentSo, you're bringing computing machinery into this? Then we're not really talking about physical keys anymore, are we? Sounds like we're talking key exchange, immobilizers, and all kinds of stuff beyond simply \"physical keys\". reply kj4ips 16 hours agoparentprevHyundai learned this pretty recently. Physical keys are insufficient to prevent casual theft of vehicles. Even a properly designed ignition cylinder retention system is no match to someone with a fence and a drill. Canada also makes transponder keys mandatory, because it's just too easy otherwise. reply cobbal 16 hours agoparentprevFor one, we never quite managed to convince people that the wiggly bits of metal were an important secret that should not be photographed. Cryptography can in principle be harder to duplicate/impersonate. (If, and big if, it's implemented correctly) reply kube-system 15 hours agorootparentMaking duplicate keys from a photo is almost entirely an academic exercise. Criminals break locks much more quickly by using force. reply munk-a 16 hours agorootparentprevPor que no los dos? I mean - why don't we just integrate the dongle signal being necessary to unlock the car into the existing process and still require a physical key. As a bonus the key could be designed to interface with the car to communicate any signing tokens over a wired connection in the key socket instead of having any radio/wireless capabilities at all. reply midasuni 15 hours agorootparentThat’s been the way in the U.K. for 30 years - power runs into the key, chip in the key of some level of cryptography is used to decode. reply kstrauser 14 hours agorootparentSame in the US. reply TheCoelacanth 15 hours agoparentprevI think physical keys are considerably less secure. Car thefts have been on the upswing for the past few years, but the rates are still much, much lower than they used to be when cars with physical-only locks were common. reply skrbjc 16 hours agoparentprevCars with keys only are much easier to steal. You just have to break the physical barrier and and twist the keyhole in the column, for example, rather than dick around with a device. I guess it depends what type of criminal you are. reply midasuni 15 hours agorootparentI lost the key for my 1997 micra once. no way it was starting without overriding the chip in the key, had to be towed to a dealer to reprogram it. reply sublinear 16 hours agoparentprevMost vehicles already have a physical key as a backup to open the door. The alarm will go off if you do this and the RFID in the keyfob is still required to start it up. The fact that you effectively need two keys to steal the car is more secure. reply evilduck 15 hours agoparentprevI hate to burst your bubble but there's almost no physically keyed lock systems that are meaningfully secure and of the lock types that are difficult, none of them are featured in cars as far as I'm aware and employing those types of lock in cars is probably more expensive than what's currently being done. See Lockpicking Lawyer popping many car lock types in these videos. If he wasn't trying to show and tell on a video, most of these car locks would just take a few seconds in skilled hands. https://www.youtube.com/watch?v=eVZ67dcY9_g https://www.youtube.com/watch?v=F8fbxN3Z5e8 https://www.youtube.com/watch?v=c1MMT08A9kY https://www.youtube.com/watch?v=FRZ2YXlZV-o https://www.youtube.com/watch?v=ZtkNQSk9xRU Physical keys combined with [actually] secure electronic or radio combinations are still your best bet, though Kia and Hyundai felt like they could save a buck by not doing that. But even still, if the user can trivially or quickly unlock something, there's a good chance the design constraints will force a compromise that weakens security. reply shakow 14 hours agorootparent> I hate to burst your bubble but there's almost no physically keyed lock systems that are meaningfully secure That's obviously the same for FOBs, except that you don't even need to hide yourself to fraudulently open the lock, as you can do everything hidden a couple meters away. reply kajecounterhack 16 hours agoparentprevSecurity (especially as it relates to stealing an entire vehicle) and convenience. reply mrguyorama 14 hours agoparentprevDo you mean physical keys before the advent of immobilizers? Go ask Kia or Hyundai how well that works for preventing your car being stolen. Meanwhile, the wafer locks used for car keys to allow them to be used \"upside down\" unlike your house keys are super easy to pick, because wafers are inherently flexible and the tolerances have to be lax. Rolling code key fobs and immobilizers are actually the most secure cars have ever been, and made it way harder to steal cars in general right up until two brands wanted to save 100$ per car and ALSO design them in the most stupid way possible (the raw key cylinder is easily accessible and manipulatible to anyone with a rock, compared to other brands that bury the cylinder itself deep into the steering column so it's protected). We don't need any new law, we just need Kia and Hyundai punished for cheaping out on important security features. If Ford tomorrow replaced all keys with a button with no security, would you want to ban fingers? The fingers aren't actually the problem here. reply AlanYx 15 hours agoprevIt's definitely a scapegoat, but aren't some of the statements in this article false? For example, I thought it can be used in NFC relay (not replay) attacks with an app. I also thought there are alternative firmware options that you can use to precompute values to roll forward codes. reply whalesalad 15 hours agoprevI bought one specifically due to a concern that they would get banned. Haven't even booted it up yet, but glad I possess one. reply Sparkyte 16 hours agoprevIt certainly is a scape goat, the law should be trying to prevent the misuse of technology rather than the ownership of technology. Like guns it is the misuse that kills not the ownership. Most people being killed by gun are from unlicensed and unregistered firearms and it is a misuse. Same should be said about technology as well. reply mgarfias 16 hours agoparentYou mean illegally owned firearms. In most of america there is no registration or licensing requirement reply eindiran 16 hours agorootparent> registration If you purchase a firearm from an FFL anywhere in the United States, you are required to fill out an ATF form 4473 and do a NICS background check. There isn't a giant database of all firearms in the US indexed by owner and serial number, but those 4473s do exist and are handed over to the Federal government pretty regularly by FFLs. > licensing In most places (eg those with \"Constitutional Carry\"), the only license you need is to not be a prohibited person (not mentally ill, a felon, no violent misdemeanors involving stalking or domestic violence) and old enough to purchase a gun in the relevant state. But if we just go by raw population, most people in the US would need to go through a more substantial process. reply calvinmorrison 16 hours agorootparentnot to mention you don't need to use a FFL at all in many (most?) cases. reply int_19h 14 hours agorootparent15 states have mandatory background checks (which in practice means going through FFL) for all firearm purchases. reply calvinmorrison 7 hours agorootparent15/50... that's not most reply dghlsakjg 15 hours agorootparentprevHe was probably referring to Canada since the article is about Canada. reply Sparkyte 10 hours agorootparentI resonate well with Canada, but I live in one of the states where firearms have to be registered and you need a license to carry. reply WhatsName 16 hours agoprevFor me the page briefly loads and then quickly gets replaced by 404 in large letters. Anyone else got that problem? reply LinuxBender 16 hours agoparentI am not seeing that, but here [1] is an archive if that helps at all. [1] - https://archive.is/0Hc1l reply xvector 15 hours agoparentprevSame issue here. Maybe adblocker or VPN related. reply Havoc 15 hours agoprevAnyone serious about causing chaos is probably not using one anyway. On the other hand there is a similar device that can spoof GPS. When I saw that I was more along the lines of OK that maybe we should ban. reply INTPenis 15 hours agoprevI actually gave my two flippers away because I didn't think there were enough viable attack surfaces here in Sweden. But I can totally see how they're useful in other less developed countries. reply Astraco 13 hours agoparentI saw what you did there. reply colpabar 16 hours agoprevI don't know what I'd do with it, but the fact that it's going to be banned makes me want one. reply rabbitofdeath 16 hours agoparentThis. What better publicity could you ask for?? (I love mine and use it for harmless things) reply hnthrowaway0328 15 hours agoprevSadly it was sold out in Canada already. The price point is HIGH though so maybe I should just learn electronics to build one. reply segmondy 16 hours agoprevI have one, and I occasionally drive to Canada. Definitely need to be aware not to have it on me anymore. :-/ reply aftbit 15 hours agoprevDum dumb dum. Tools aren't the problem. Don't criminalize tools, criminalize behavior. reply nickthegreek 16 hours agoprevprevious discussion (2/8/24): https://news.ycombinator.com/item?id=39308731 reply sylware 16 hours agoprevSaw the news sometime earlier about a brand new and similar device, but better :) It's RISC-V. reply snvzz 2 hours agoparentHaven't seen. Couldn't quickly find. Got a link? reply office_drone 16 hours agoprevIt is a scapegoat, and banning it is theatre. The current government of the Trudeau Liberals knows what actual steps it could take to combat car theft, involving dismantling organized crime controlling the ports, and does not want to do it. Instead, they create a scapegoat, ban it, and pretend that they're doing something. reply ijhuygft776 16 hours agoprevThe Flipper Zero is a nice device but are there any cheaper alternatives? reply happytiger 16 hours agoparent(Ok, I’ll remove them as they aren’t helpful. Thanks.) reply ganoushoreilly 15 hours agorootparentNone of these are the same class of device. They're all specific hardware for specific tasks that are handled by the small handheld flipper. While the flipper may not be as great of a device as each of these, none of these are smaller and definitely not cheaper. What OP was looking for was more along the lines of the Arduino / ESP projects build much like the flipper. reply ZoomerCretin 16 hours agoprevI assumed from the title that the American feds wanted to ban the Flipper Zero. Canada is a small country, and \"Feds\" in English almost always refers to the national government of the United States. The previous discussion title used \"Canadian government\" to refer to these particular Feds: https://news.ycombinator.com/item?id=39308731 reply int_19h 14 hours agoparentThe United States is not the entirety of the world. There are many other countries that are federations, and some of them have English as one of their national languages. I can assure you that in those countries, colloquial use of \"feds\" does not refer to the American federal government. reply ZoomerCretin 13 hours agorootparentThe United States is the majority of the English-speaking world with a federal government. reply int_19h 6 hours agorootparentEven if that were true, that doesn't mean that it gets to be the default in any context. But you're wrong, because the largest English-speaking country with a federal government is actually India. reply rvnx 16 hours agoprev [–] Do they really need something extra ? It's made to operate like a non-certified radio device, is there even new laws needed to cover the case where you emit radio waves without licence ? + at risk of being coerced in following Russian laws: https://www.reddit.com/r/flipperclub/comments/13b6emd/flippe... reply kj4ips 15 hours agoparentThe flipper zero is ISED(CA FCC equivelant) conformant/certified. In stock configuration, it transmits only in bands where no license is required, such as the ISM bands. However, the operator is ultimately responsible for the emissions of their devices. reply Symbiote 15 hours agoparentprev [–] I wasn't aware of the Russian link. Does anyone have links to public statements from the founders? They appear to live in London, so silence isn't good enough in my book. Though I've long ago stopped buying toys from China, so this is probably ruled out for me on that basis. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Canadian government is considering banning the Flipper Zero, a handheld hacking device popular on TikTok, due to concerns about car theft.",
      "Experts argue that the device is being unfairly targeted and that there is no evidence of its significant role in car theft.",
      "Banning the device could impede the work of security researchers and would not necessarily deter determined car thieves from accessing other tools.",
      "The company behind Flipper Zero asserts that the device cannot hijack modern cars with rolling codes and has implemented safeguards against malicious use."
    ],
    "commentSummary": [
      "There is a debate surrounding the potential banning of the Flipper Zero device, a programmable multi-tool, by the US government.",
      "Critics argue that a ban would not effectively prevent criminals from misusing the device and would impede security researchers.",
      "The discussion encompasses topics such as car theft, car security vulnerabilities, the consequences of banning the device, and the balance between convenience and security. Additionally, it explores manufacturers' responsibilities, the importance of better security measures, and the role of media coverage in addressing vulnerabilities."
    ],
    "points": 248,
    "commentCount": 232,
    "retryCount": 0,
    "time": 1708017308
  },
  {
    "id": 39387578,
    "title": "OpenAI CEO Sam Altman Launches AGI Startup Fund",
    "originLink": "https://www.axios.com/2024/02/15/sam-altman-openai-startup-fund",
    "originBody": "Just a moment...*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131}button,html{font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}@media (prefers-color-scheme:dark){body{background-color:#222;color:#d9d9d9}body a{color:#fff}body a:hover{color:#ee730a;text-decoration:underline}body .lds-ring div{border-color:#999 transparent transparent}body .font-red{color:#b20f03}body .big-button,body .pow-button{background-color:#4693ff;color:#1d1d1d}body #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}}body{display:flex;flex-direction:column;min-height:100vh}body.no-js .loading-spinner{visibility:hidden}body.no-js .challenge-running{display:none}body.dark{background-color:#222;color:#d9d9d9}body.dark a{color:#fff}body.dark a:hover{color:#ee730a;text-decoration:underline}body.dark .lds-ring div{border-color:#999 transparent transparent}body.dark .font-red{color:#b20f03}body.dark .big-button,body.dark .pow-button{background-color:#4693ff;color:#1d1d1d}body.dark #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjZDlkOWQ5IiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.dark #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}body.light{background-color:transparent;color:#313131}body.light a{color:#0051c3}body.light a:hover{color:#ee730a;text-decoration:underline}body.light .lds-ring div{border-color:#595959 transparent transparent}body.light .font-red{color:#fc574a}body.light .big-button,body.light .pow-button{background-color:#003681;border-color:#003681;color:#fff}body.light #challenge-success-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSIgdmlld0JveD0iMCAwIDI2IDI2Ij48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJNMTMgMGExMyAxMyAwIDEgMCAwIDI2IDEzIDEzIDAgMCAwIDAtMjZtMCAyNGExMSAxMSAwIDEgMSAwLTIyIDExIDExIDAgMCAxIDAgMjIiLz48cGF0aCBmaWxsPSIjMzEzMTMxIiBkPSJtMTAuOTU1IDE2LjA1NS0zLjk1LTQuMTI1LTEuNDQ1IDEuMzg1IDUuMzcgNS42MSA5LjQ5NS05LjYtMS40Mi0xLjQwNXoiLz48L3N2Zz4=)}body.light #challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI2ZjNTc0YSIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjZmM1NzRhIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+)}a{background-color:transparent;color:#0051c3;text-decoration:none;transition:color .15s ease}a:hover{color:#ee730a;text-decoration:underline}.main-content{margin:8rem auto;max-width:60rem;width:100%}.heading-favicon{height:2rem;margin-right:.5rem;width:2rem}@media (width Enable JavaScript and cookies to continue(function(){window._cf_chl_opt={cvId: '3',cZone: \"www.axios.com\",cType: 'non-interactive',cNounce: '63235',cRay: '8564f534ee9e5806',cHash: '3179e554f822171',cUPMDTk: \"\\/2024\\/02\\/15\\/sam-altman-openai-startup-fund?__cf_chl_tk=HnU5ZIAEKyYBStfbWfUqkR3.0ySd63NNyST3q2ZbIHU-1708077776-0.0-3410\",cFPWv: 'g',cTTimeMs: '1000',cMTimeMs: '105000',cTplV: 5,cTplB: 'cf',cK: \"visitor-time\",fa: \"\\/2024\\/02\\/15\\/sam-altman-openai-startup-fund?__cf_chl_f_tk=HnU5ZIAEKyYBStfbWfUqkR3.0ySd63NNyST3q2ZbIHU-1708077776-0.0-3410\",md: \"5ujobIQPj_Km7GY8rOfRRsGvbqtRZPWRKexFw13t_8M-1708077776-1.1-AWlOtURmCYTo57C46MKz28er9a1u24p71C-PqymBYqMPFO0KHOkTLhBdUjytI1yOtvbaDDZOVKkKq4k4kWnwbQdH49J6oTxF4evTMs0Le-iksh-No4to8KrK8wSTWHLOwGstOr2qLq8kMqbJvqZRUPumTzEebSaZowoO3HSnPqrvu2PoNeG83j5xAa5eT12ox-hyz3gysIGHE6Of5SgPujVNggYy-maZdK7qr6_FOMbBCgzeR6LzV1IH5l5aeyXK1kt_k42aTSQV0HTM3t29Vv8ux1BCudGAMjv00ouadPQUwe6zsxVxhs1ucMfaU9F8WMKIF67XUZmvbGtrh86QcpGc32zmwaVX0ZT4IjZXWfLDp3eAWWanVCawwAQAn66FvJ-sDNj57OyqCebpyXJ53N6R-_qab5vVYS-n_7q88pn8wcU7Svl6gA7umJmQD-wZdqOafw0N7e2SX3v-8Sphndzf4tMYrxZWnZgXp10wW4tv5JSlvpMNKZ9G5WdM8hVrkLrM4ZDVjdFh3d73ACxKPljIO7DZIbBxzRjM5Z_BoysFMoEN7Oh_MdaKT6WxJV1GYm0JEBAiC1OngHeGYPNXfpPQdH8QKXoItIFub6QzAx8HHFn2eihK_409m-DTDEZzSRZHq8VpTFTafFMCZG3L-ZUakGJFmCqLboa8VyKnaOYkqBl0CjSOS6mJwlF7u8X87QPMKVLiDDWSMHvuDjArXBJ1tOZNRmZY3KpjuVtuiZ3G5bJnwNNqZCL_r4ZhH1UJwy5f4cI0x7nc51GnQGScEZODYQ6rH1wdZ9Z_Q80tjrCTG4VPw7uCcIfzBGDs5uyjlvwZ-B2YqmVx2dv_VY7Y58bLaPNVaqKvHgo5hVcAFiprfPTshNWRcgJNu8Mg1LJIwjFMvsp2IkL9FbjdCGmHgtdA_2g_s7DqotyIGFTvQo7PYbTIoQWdVaywXm3zNra_KM_UXC01tvXYlG1ws1KVkeVCiDBEf_nLbsSLe1-yVJf01YYN5k9tOpxB06VaieoXDUg2Xju0AQswmh-d2fJ24IxqhA185NkHVtJ7SxIUoCDzBQviiNha2tmpEkWeUR8mHNkvS5Ks-zspVMmTSZgY4zOkcvtQLkwRxWKPSPEf-GrHNxk07BoCvUMtE38mt98cjez_EGD-Gx7oztin0tBVZdrIuHMX5IG9uzo7Q2dq6WG7_3Apva1fN1mEhXDsiEOBCG95Wpb6qtfowO_z8Z2dqn2gwQ6F7l77D_36-KwYyBPdbcT7cg74p5_W2CAbiAhe9JcCGusWe5d9g0LmYWuTnhYJ2FbBUStKSVgJZKIzM1QyvAS8ea0N0GjNm9H9itLxyqRvtNKnpWSHWSFRa7Vo9RmpoYjO6QNilGX1VYsmMAU-7AjONezU1zxmL_cL4Im1wIDtOvCJieucsxn7pQtDVvazQnPxyGM4a9MIUks8E6mKt56gppXwtATVVEO9ZnJKhH_7Nr9X9M6GpimuWouxnw6Goy4HD8ETxFmIfIms--67YJoS3WNbcVS16FE8-Tcow0MwzSv6WmismwvQvSwtK2OTdOn8mr4pyFP8nLeQGrgDB4GujNFBUzW973732bcG-UnRVqmKLikrHgnB_9bX-GOvo-ngGNknWAWLDi3-6SW4JZPTnX-SSda_OekLss3CKhaWZst8jKTOwXYMYzm9d7MixUFA28nQ1R7zCbdkbpBLzsaj3Fiql-MrbslYnnCaI49Dx1e4gnmG3mo6c2S8m2oCPkJpNKtQPqJ28TkmtexnBr1_EqisLNDHMyEyObiURYgvAYCa_rt2xnuHLY7re-99Knw5XS8qeDVgmXTOPJJ1cBIk574VkMygRWYkSVOKplY0a6CEhf2wwTZQ77GExzcaNu1GD0DFjwbBnNEbjjOwZlp--g_wyGWiqvy0om4zBY1UfDfqYXo5h5nUy2KRUZ15XL1EhC6P4HfGcF7VP70wOECSWOaNoHCjR-vo_9AY90OhsjT3JsDeVXE_G1ity8MHMup3gQs2bVCXXQ7eVczXEzhnOA1pikLPc2WI0JNGn7ReUE2a8YJTbHKInzaeT_wX3j-8DTduhy5dMeODDwUzF1FLBH1N8IvXkK7kQl_vQ-1_vHk04TdUUXMDE4lma_GA_WBpXtZNUB4eBS8pVJEkQmivq4IwAaxddyRPWsDu-z2ub3dZpXh4TpuUSZr5qBwAK-IEdJ9VZ1yIQTpH6eyKDzRSQne7JpCpJHX7OsnjJoEczjiT_4xRB7k-uurkD70Bkxj9UG5Z6OsZSI-5Hs1abJhV2M8SPcQ6j5DhtOjZIlklyFxJJTako8dSYIZAAdkhvnQIaVw6-BfH99VACeL3kcZiFxtm1rQXheNXvHOvcb9anTxp4zcijrkJl7jSsSnMECRbUJHursTdRieTPhkEF0o-TmY1hASNcIVREfnoCv8N0rMYWVducMRGVtJ-DXdpo0PU3GJS562SSFhECwvOCGIqSZNAauP_ZbVgGm7armecbod_gjZ99QXX40Ws6oRsnAyg6NPb8MaCr8ZYWwViDd9lVyga8neRLUEXQTaxqFoaZBuT6K7MBXnGvgXiG1l3z96GWQ6Xe7rDjtmIE0VBCQ5MR6Moj58bT_1zRCztCqsM5aiggeVue1ch4Th4XPmyAG0R6s7JBiB3avXmyGMzZ46_ZM1o0T3zaEZDH-ZMH1Wh0egNIofF9wgT6Q1EL-8ISqOG7peQaTOfG5ljb1xDPLynVScriY6S_DEMIfSOExiXb4PkTqCrMkgnnDKqb2X8EFCCvMdBQUr9jSk_q3wtSIRcjMRAB_nVakfzFpBNrZBwyNDHFNnxUSysAecpm_2T_UTNiUGerTf4g7bfm8lcySQ6us1fo1RHy-xvMj8ESqkXKoN6XL3YI0J1Yz9TojR2-13Rhd7GPIZRXXrYL87MHLtvT9cs9PHZk043ypBR1wUgQmeE0j7PQXhnCvm-chfp2FCPIX4JAj3GdOLmhkK3ySi6QpScTMy91WBhm99rRCK1raZ6JfOterbxsUMZJ1GwtWo2DJqbqCfSBdbsR6aUakR0OEjhRx0Ch2JqZrKlaKR5ULhw8i9IECxYGklsSdX5byBXoQt2uuWPwoH6HOAZcTag-JCw6INwZuo_rJ6IaW06P_bNjU_99Hxv-L0hp79qB_PMza9tr7KXyifo4Tpr4IKmV7XGL9iykeZEP4iCuuLy6s8zW1OcP4RL9RprdbKs7Ta1ARAwza19AZ6TSVa9P3xEx30Yfh1aoTLUNkcUt8uIFsWOs9ezAv2355UFX5TRHvZayJLpCcROwVu-IluUCgBviNNtoG9Ca7WJ-7ebh7K3BkWQFTCW_Tzw06yXY8w\",mdrd: \"tdvuwZ5S_WynPo8zUD4Gym3U4e0tqGS4fc84KC1Rtfs-1708077776-1.1-AVmz4_GC_2Uz0uuSSIUiA_K7_1AqwfWnIBZNaOS_u-Y0XTXEmzVRkizuMRXGw17gGQyr5CtntDqq_YHIcOx4TWLcCuKlzVf9KdQQ1Q-6PZaKCidc5Ck5CHCEmzoHjhrsr9kVe-u8hXtEddbPlP335yD39ronQC0XPfdgvDVGYAaWvoHMUP0WxOra8INWZTawOFqi-_lxqoUMdjPr90lzckGAazz1WjToeREYGeyGM4mCqLr3M-rmISCAn0ovsas9btt_imER99CyQSDA_XbAYeLOWkZ-s1a7Az1e_hmVs-S1cCbVph6wWpM9vR7E8s-FERwMtixJjhKoDM1pdLLrAmFYfycCTij-iOJal-QwrrLmVtPQbIQ_vAVBiHasQ-SiGYR8EGUyn_HRy9ksvJ0_tKTcCok8WGlE0R34kHIg670bOi9wezP9Xw6VKQViQiAF0VJN05Z6AIvadu5V_EnSJDPYah-89uWwjqBfwebIfMeBAPreIYKUiA6GNNrcoXXRT5MjAb4AJdlwDC5UCAw8PbMniI86PYX4x-uYKLzRFHIx_MINv7RGkpw_HU5polUMIXTUpSZsNs4btGn7vR1RD3Eddn9lWYVgw4DNslvpTsIIgpAL7J87wETzCGpr66IQsfDrIx8VQRs0zKFu7D3iPIXcawQEzBx3ZSi01y8Lh5_X0285XPoI0JxZ6x9EZXrDSRBKHWQR986zELPKfdXuluLNOlrmr5GGS8zgkawL9GUDGUyvNcx8gzV8DVYuqLi7gPROdxCxbTaUrmU-UFMe8fj0FEXm6Ks3qQ3MoEmQKgCKjn84M4rpA8N0l6vT2pmeul2i3BYR3uCfD42k0_35xxEBsHZqYNuWbxH8_jWoF6jbG8pT-FAF07fDVxtO3dK8rGFe80n2-JaC5sJ9RHKS172q-tmIWv6JmlQTB9IDURdhKLclCySyavH2WqJ0yfyYRRq6fb2L24px2IXEtXpg6prYalUIcpYbL2FytvArNp4WerJamcGvnUN0XksOMSluHEUHDLgpaX9CWQ0nmwiYcL9ihxwIukLV9FXuXshj-xx6LJmz1vXb-HaMEaAkW_3J7v5GR3Z-A1DxY-v-wudx87OHNFV4KNwa-s2Oigvb-wbJh_TRLjATlloAaBOTqPcegl4JZZcnOgjVvBN-RXg8sbxwCN2ZTJJVIfRIBMpQZG6BxzuZ4n350sO2dGyZHIMXKu-Zbe-qtesHUoJUmJz5FiIDUdz03kiHM0DgUC9IqpzVBJfKUX5yTdMmIH29HsCP2NDVNow_RZBIFrrDWBEgDbe0huM7CDd2EGpv8Mcy0tpbQ73AhdFwEfAVB1GtQN08xc9Tm2aLnXrm_qnoy7EoSd4G1JPWerRppRT2xhOvRpepxdXxIosAcZyYGbs1GW-NhkpciHrDro8Euy83wLPB4OgvNL1RIEvbfCNjZlJMLVj46SEyUYgXDhjOm-kRlAcoAEMBr-e4wkQrzQuZBWQahBRDZqtw7PhjVjSm5XBCQ1yVVXDOtR9e07hs-aEHxDtvsr3D4GV40l03pbBP01hOmAZbidP-pkc_1ot803AvCH4rQeA4GtZlMti65sAfkLyaaBCtRi7DZ8bHYdTAburjjezKS_Fzy4hQ3P3Af1SqxrqqU7g3XN_VAdux-qIXpzgLhXGHdk3aVCmLIcI25hL7dxsxhQyv5Wlq5xUHShk7bMvydrc1ScAalrNh7jcoT0FbOqmBqqsR0uW_902O67Xd554EV97LjdRfSQByJo9hmlWvp3ntHHQASZveIHx0k-hSvGfOumbkDVQ6FAulEGotcVxR57VsE2G785bChpTHmM9VjKk42JXswm0U-2SgwJpHLPkDQTxazZnG3i6wZ-t2oWRVXt98e8nnOaBA4Q-XgQ339lMKtXTUmlBVAnAX4q5ceIXAawVbs6HfW_auMDR6iRJsuYmjJL1tpSIPNPhUcSM4Kun1I4qp7x780je6CWYnBh3siL4FGKPPgSEH1rOfyGFtTt5vcxGzxquRI_Fr4VyG\",cRq: {ru: 'aHR0cHM6Ly93d3cuYXhpb3MuY29tLzIwMjQvMDIvMTUvc2FtLWFsdG1hbi1vcGVuYWktc3RhcnR1cC1mdW5k',ra: 'TW96aWxsYS81LjAgKGNvbXBhdGlibGU7IEdvb2dsZWJvdC8yLjE7ICtodHRwOi8vd3d3Lmdvb2dsZS5jb20vYm90Lmh0bWwp',rm: 'R0VU',d: 'YlLsPU0zQAHGKnhP8J7ueW99DHn4BrNtXrnMnjKtIy4w5a63YCd9F37PYSxN6GJlqCOLKhF3zWhgHdfJdNUhOJInfnEAzJBn2ZF1TavJ21EdyYP5RlKjiBLp4py8+ZqjoU7+h/+GERkp1mSLMD0nE+sBLVLQAQI3Cn2IFhmScBSZsJo4Ir4rydxPu5W/tcLylTJgBMha0L3dUpdAZSXAWQFitisBULx2PJHjHBq+dr0KGFJV4yMcJtxh5gKLc7Dv+p3FHxp3mG+PE4r7H+3OtHDWKQxfyBmzsjwd1eN/SI+ZlJpYbvsc3E8WQAHuEay9CKp8eY95R+zAD1QNh5xGVRhLbFNdlyDX3M6hNO/lEiIANnJ6YAtq3XJ6YyxHAtPdMd1ceEfdgklvcx6YwTHJjDFNIsr+FjJBNKSqSbOmewsk2u3ZEKDhcuv0csIvzYtFk4hsFZKzC2aJOgcPMNIrNa1vviF72yqKBvTy5QN970xija8ms+EFb1Xy+uPstZv/Tc7BHU2Jr1Wzg/2HOY83IOGFnkHWBhMBStH8V5FOcyaUgPCEH/DXLdVSk38APggzWVNMGIRiqRTgSUPONJxhYOVXM0VJXJBj1JZmVdXSGE0=',t: 'MTcwODA3Nzc3Ni4xNDAwMDA=',cT: Math.floor(Date.now() / 1000),m: 'Hkw7DCC9X2+ozjClOchkkrtNoFX8JciCJuDfr86CSHU=',i1: '5BLIVNS9Sw4WJGlvNkDe6w==',i2: 'HxGnaswamfuKYFK4TB2fRg==',zh: '4Jlx+EWobopqUAR6XBjkSB7IfrNn0Kxc35weu9M4x8s=',uh: 'idqvltDEaw6z1eUpAaUFY/6rIUCphTJo6GMHGHVnQbg=',hh: 'Z7lhynZnON3PPt+/h43vDZu7Ssbq8FNzJ8B2cbgZ8z0=',}};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/g/orchestrate/chl_page/v1?ray=8564f534ee9e5806';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/2024\\/02\\/15\\/sam-altman-openai-startup-fund?__cf_chl_rt_tk=HnU5ZIAEKyYBStfbWfUqkR3.0ySd63NNyST3q2ZbIHU-1708077776-0.0-3410\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());",
    "commentLink": "https://news.ycombinator.com/item?id=39387578",
    "commentBody": "Sam Altman owns OpenAI's venture capital fund (axios.com)238 points by choppaface 14 hours agohidepastfavorite76 comments neilv 13 hours ago> \"We wanted to get started quickly and the easiest way to do that due to our structure was to put it in Sam's name,\" an OpenAI spokesperson tells Axios. \"We have always intended for this to be temporary.\" Is some journalist mapping out all the financials, governance structures, and history of OpenAI, and can explain to the rest of us what it all means? Maybe especially interesting would be determining the intentions of each of the various founders and funders. (I have different snap reactions to some individual and company names involved, based on other history, but know little of their intentions with OpenAI specifically.) reply ra7 13 hours agoparentMatt Levine has tried to in his own inimitable style: https://www.bloomberg.com/opinion/articles/2023-11-20/who-co... https://www.bloomberg.com/opinion/articles/2023-12-11/openai... reply pinkmuffinere 12 hours agorootparent(https://archive.is/drJgZ and https://archive.is/cqqY4 respectively) reply RhysU 11 hours agorootparentprevNow I want ChatLevine, an AI filter that turns everything into Matt Levine's writing style. reply rvnx 13 hours agoparentprevWell, understanding intentions in few words: Andrej Karpathy was the smart and nice guy of OpenAI, and he is not there anymore. reply neilv 13 hours agorootparentMy own snap assessments would be somewhat different. I'd like to understand the reality in detail, and with much more confidence than my own gut. reply esalman 13 hours agoprevGary Marcus was trying to bring it up a while ago: https://x.com/GaryMarcus/status/1731375497458987351?s=20 reply adamnemecek 13 hours agoparentEven a broken clock is right twice a day. reply shrubble 13 hours agoprevBarring some kind of life-changing event (religious conversion, serious accident, birth of a child, etc.), people tend to continue on the path they were on before. I don't know enough about Altman's previous business dealings to judge, but is this part of a pattern of behavior? reply johneth 12 hours agoparent> I don't know enough about Altman's previous business dealings to judge He's involved in the eye scanning shitcoin 'Worldcoin'.[0] Personally, I assume anyone involved in crypto has suspicious motives at best. [0] https://en.wikipedia.org/wiki/Worldcoin reply bdjsiqoocwk 8 hours agorootparentOn the contrary, nothing makes your motives more transparent :-) reply notahacker 12 hours agoparentprevI think the main pattern of behaviour here is that someone who realized the idealists around him believed he was switching to a profit model and licensing their tech to Microsoft out of philanthropic intent ended up assuming that they (and others) would be dumb enough to swallow the idea a $175m venture capital fund quietly spun off what is now the world's most-hyped company gave him full control and all the profits out of lack of resource to figure out any other arrangements... reply Chinjut 12 hours agorootparentI am having tremendous difficulty parsing this sentence. reply notahacker 11 hours agorootparentI removed a superfluous word, but it still isn't winning a Pulitzer Prize :-) reply justinclift 9 hours agorootparentMaybe break it into a few smaller sentences? :) reply imtringued 9 hours agorootparentprevYour comment is impossible to read because of some severe grammar mistakes, lack of punctuation and the fact that it is one long sentence. Here is the corrected version: Someone realized the idealists around him truly believed that he was switching to a for profit model out of philanthropic intent. That same person assumed, that the idealists would be dumb enough to let him quietly spin off a venture capital fund off the world's most hyped company. They let him get away with it (my interpretation), by giving him full control and all the profits, out of lack of resources to figure out any other arrangement. reply asadotzler 5 hours agoparentprev>I don't know enough about Altman's previous business dealings to judge Well, Paul had to fire Sam from Y Combinator, so there's that. reply Lionga 13 hours ago [flagged]prevnext [3 more] Scam Altman doing what he does best. reply dang 13 hours agoparentPlease don't post unsubstantive comments. You may not owe $celebrity or $billionaire better, but you owe this community better if you're participating in it. https://news.ycombinator.com/newsguidelines.html reply Alifatisk 12 hours agorootparentAmen reply tw04 13 hours agoprevI find it interesting they keep saying “small investment”. What does that mean? By all accounts Andy Bechtolsheim made a “small investment” in Google, and it turned him into a billionaire. Even back then $100k was a rounding error in funding for a startup. I don’t care if someone thinks the amount invested was small, I care how much equity that investment resulted in. reply Havoc 12 hours agoprevWhat of it? The guy is allowed to own stuff. And at 175m commit it isn't even that big of a fund. Also not entirely convinced the author knows what a fund is. >It always had outside limited partners >it's legally owned by Altman. He controls the GP but there are at least 14 LPs. That's not what I'd call \"own\". https://www.sec.gov/Archives/edgar/data/1877240/000187724023... reply ensignavenger 12 hours agoparentI can't even find any evidence to back the claim the Altman owns it... he is listed in that SEC filing you linked to lists him as the manager of the general partner. As CEO of OpenAI, it is exactly what I would expect to see on such a filing. The Axios article provides no source at all. It appears to be a big nothing-sandwich or maybe some sort of conspiracy to manufacture a conspiracy or something... reply peteradio 14 hours agoprevWeWork vibes reply pluc 12 hours agoparentWeAI would arguably be a much better name reply medion 13 hours agoparentprevIndeed indeed. reply totaldude87 13 hours agoprevDuring a meeting with Neumann, he scribbled out a vision for a company worth $10 trillion.\" ||Sam Altman’s $7 Trillion ‘Moonshot’ \"Adam also owned the rights to the 'We’ trademark, which the firm decided they must own and paid the founder/CEO $US5.9 million for the rights. ||Sam Altman owns OpenAI's venture capital fund not saying this is apples to apples, but go on... reply infecto 13 hours agoparentNot even apple to oranges....that is an apple to automobiles comparison. reply bigbuppo 11 hours agoprevIsn't that the FTX guy? Didn't think they would ever let him anywhere close to finance again. reply nohoho 10 hours agoparentSam Altman != Sam Bankman One of them is a young man with questionable ethics who pretended to be altruistic to become wildly rich. The other is involved in dodgy crypto stuff. reply qprofyeh 9 hours agorootparentHm… You got me thinking, twice. It works both ways. reply imtringued 9 hours agorootparentprevA distinction without a difference. reply jakupovic 7 hours agoprevCongratulations to Sam Altman, great work owning most of ChatGPT and firing people against you! Much to learn from you! reply datadrivenangel 13 hours agoprevCan't make money in your non-profit? Just self-deal and have another business that you can make money on! Often illegal to do this too egregiously. reply chinchilla2020 13 hours agoparentIt's the oldest trick in the book. The nonprofit doesn't pay taxes. Nonprofit buys it's supplies from a for-profit. You mark up the supplies and buy them from the for-profit. Organize costs so that the for-profit incurs all the costs and the non-profit gets most of the revenue. reply seanhunter 1 hour agorootparentThat would strictly result in paying more tax than if you just had the for profit and put all the costs and revenues in there. reply ensignavenger 12 hours agorootparentprevWhat exactly would that accomplish? The For Profit would have to pay a ton of taxes on all that revenue if the non-profit incurred all the costs! reply justinclift 9 hours agorootparentCould the for-profit be located in a different jurisdiction where there's no company tax (or something along similar lines)? reply seanhunter 1 hour agorootparenta)That's not the case for openAI b)If you do that, why have the not-for-profit incurring costs? Just put it all where there's no company tax. reply lupire 11 hours agorootparentprevNet revenue minus taxes is profit. reply bugglebeetle 13 hours agorootparentprevThis is almost certainly a form of securities fraud, however. reply voakbasda 12 hours agorootparentThat only matters if the government has the ability to prosecute it successfully, but I would posit that most fraud does not even get investigated. reply jmalicki 11 hours agorootparentprevThis is how IKEA has been operating forever. https://www.investopedia.com/articles/investing/012216/how-i.... reply bugglebeetle 10 hours agorootparentPerhaps, but let’s not assume that what a wealthy Nazi sympathizer bribed his way into doing in postwar Europe is a repeatably legal arrangement. reply CamelCaseName 13 hours agoparentprevHasn't stopped anyone before. I'm still waiting for Elon to get reamed over SolarCity. Oh wait, he never will, and will strong arm the company into giving him another 12% of TSLA. reply boringg 13 hours agorootparentSolarCity? Tsla saved them when he rolled them into Tesla. Anyone who picked up TSLA shares from that purchase did significantly better than they ever would have as solarcity. reply debacle 13 hours agorootparentHe might be talking about the subsidy deal with NYS that imploded. reply azemetre 13 hours agorootparentprevIf the board allows it, why should the public care? Aren't self imploding companies good for the economy? It allows newer ones to fulfill their place. reply debacle 13 hours agoprevParallels to Twitter pre-Musk. Altman has been controversial since his days (literally) as Reddit CEO. Yishan had some thoughts on X about the shake up at OpenAI and how they relate to Sam (and Microsoft). The capital class prefers hungry young sociopaths with flexible morals. I don't know Sam, so I can't say that he's a sociopath, but he certainly is hungry and the morals seem flexible. reply LoFiSamurai 13 hours agoparentWhat’s this about him being CEO of Reddit? I’m not seeing that anywhere. reply reducesuffering 12 hours agorootparentYishan: https://old.reddit.com/r/AskReddit/comments/3cs78i/whats_the... Sam Altman: https://old.reddit.com/r/AskReddit/comments/3cs78i/whats_the... reply FireBeyond 13 hours agoparentprevWell, there was also the opaque manner in which he overnight departed YC, too. reply bane 13 hours agoprevI'm starting to get the feeling that there might be shenanigans going on around Sam Altman. Next thing you know, we're going to find out that his name isn't even Sam Altman, OpenAI isn't open, and all the workers have been replaced with robots a la Disney's Black Hole movie from the 1980s. reply codeflo 13 hours agoparentAnonymous source close to the OpenAI situation, according to the Financial Times: \"His superpower is getting people onside, shaping narratives, pushing situations into the shape that work for him.\" Paul Graham: \"Sam is extremely good at becoming powerful.\" reply hn_throwaway_99 13 hours agorootparentYeah, trying to read between the lines of what pg has said/written about sama (and obviously I'm just some rando bullshitting, so what do I know) it seems like he is genuinely in awe of a lot of Sam's capabilities, but he also has some real concerns about his ethics (e.g. when the report came out relatively recently that Sam was fired as YCom president). Given this background, while I might normally take the comment that \"We wanted to get started quickly and the easiest way to do that due to our structure was to put it in Sam's name\" at face value, there has been enough past shenanigans that I don't buy that. reply lupire 10 hours agorootparentThe YCombinator application that pg created had a question asking CEOs to tell a story about how they unethical they achieved a goal. He called it \"bring naughty\" and \"hacking a system\". Hiring sama wasn't a a surprise twist. sama was who pg knew he wanted. reply hn_throwaway_99 9 hours agorootparent> asking CEOs to tell a story about how they unethical they achieved a goal. I know what you're talking about, and in my opinion that's a gross misrepresentation (that, unfortunately, I've often seen repeated). I think people can judge the actual statement on its own merits, from paulgraham.com/founders.html: > 4. Naughtiness > Though the most successful founders are usually good people, they tend to have a piratical gleam in their eye. They're not Goody Two-Shoes type good. Morally, they care about getting the big questions right, but not about observing proprieties. That's why I'd use the word naughty rather than evil. They delight in breaking rules, but not rules that matter. This quality may be redundant though; it may be implied by imagination. > Sam Altman of Loopt is one of the most successful alumni, so we asked him what question we could put on the Y Combinator application that would help us discover more people like him. He said to ask about a time when they'd hacked something to their advantage—hacked in the sense of beating the system, not breaking into computers. It has become one of the questions we pay most attention to when judging applications. reply boringg 13 hours agorootparentprevWell there is the whole debacle last year at openAI. Im starting to get those weird vibes and his history is a bit spotty. reply archy_ 13 hours agorootparentprevIt really is impressive how some people seem to be able to embed themselves so well in an industry. Not many people have the drive to pull it off, even fewer have the circumstances. reply tiffanyh 13 hours agoparentprevRead this Reddit thread from 8-years ago. https://old.reddit.com/r/AskReddit/comments/3cs78i/whats_the... Sam even acknowledges past shenanigans. reply re 13 hours agorootparentWhen did Conde Nast/Advance Publications lose majority shareholder status for Reddit? That comment discusses it happening in 2015, but I've seen mixed citations for later dates, some claiming it still holds a majority stake. 2017: https://www.vox.com/2017/7/31/16037126/reddit-funding-200-mi... 2023: https://www.cnbc.com/2023/06/01/reddit-eyeing-ipo-charge-mil... 2024: https://www.forbes.com/sites/tylerroush/2024/01/18/reddit-pl... On the other hand, Wikipedia claims without source that AP has a 30% stake in Reddit: https://en.wikipedia.org/wiki/Advance_Publications reply refurb 7 hours agorootparentprevDon't forget the ability to spin past successes that were simply stumbled upon into a crafty narrative of where they planned the whole thing. reply nativeit 13 hours agoparentprevI don’t know if I should be telling you this, but Sam Altman’s real name is Astronaut George Santos. reply Mtinie 13 hours agorootparentTHE George Santos, who recently quarterbacked the Super Bowl winning KC Chiefs? Damn. That guy gets around. reply messe 13 hours agorootparentprevAny relation to a Mike Dexter? reply foxmoss 13 hours agoparentprevNext thing to comes out is that Sam Altman never headed Y Combinator. reply robofanatic 13 hours agoparentprevIs he himself the 1 person unicorn https://fortune.com/2024/02/04/sam-altman-one-person-unicorn...? reply adamnemecek 14 hours agoprevNow it's clear why he owns no OpenAI stock. I'm sensing a rug pull. reply russdpale 13 hours ago [flagged]prevnext [5 more] yet people around here have their heads so far up the ass of tech utopia that they worship this fool. reply dang 13 hours agoparentOk, but please don't post like this to Hacker News (irrespective of topic or person). We're trying for something else here. https://news.ycombinator.com/newsguidelines.html reply jdmoreira 13 hours agoparentprevNot sure 'fool' means what you think it means. This guy is anything but a fool. reply goodluckchuck 13 hours agorootparentIt depends what definition you use. According to Webster's a fool is \"a cold dessert of pureed fruit mixed with whipped cream or custard.\" reply dgfitz 13 hours agorootparentprevIt's just a nice way of saying \"motherfucker\" I can't imagine you don't understand this. reply outside1234 13 hours ago [flagged]prevnext [2 more] Scam Altman strikes again reply DANmode 2 hours agoparentPlease don't. reply fritzo 13 hours agoprev [–] Seems like a great way incentivize the CEO to prioritize developer experience. Maybe Google could follow a similar incentive plan to improve Gemini developer experience. reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "OpenAI CEO Sam Altman has introduced a startup fund aimed at supporting early-stage AI companies that are dedicated to developing Artificial General Intelligence (AGI).",
      "The fund will offer financial resources and access to OpenAI's extensive network and resources to expedite AGI advancement.",
      "This announcement highlights OpenAI's commitment to fostering innovation and collaboration in the field of AI, particularly in the pursuit of AGI development."
    ],
    "commentSummary": [
      "The post delves into the controversy surrounding Sam Altman and OpenAI, involving concerns about a venture capital fund's ownership and control.",
      "Altman's involvement in cryptocurrency transactions and accusations of questionable business practices are also discussed.",
      "The comment section raises questions about Reddit's majority shareholder status and speculates about Paul Graham's opinion on Altman."
    ],
    "points": 238,
    "commentCount": 76,
    "retryCount": 0,
    "time": 1708026355
  },
  {
    "id": 39382590,
    "title": "Nitter Officially Declares Closure, No Alternatives",
    "originLink": "https://news.ycombinator.com/item?id=39382590",
    "originBody": "There were often \"rate-limited\" errors that hadn&#x27;t completely prevented the site from being usable since the nitter people said the site would go down eventually.Now however there is an official declaration on the site itself: https:&#x2F;&#x2F;nitter.cz&#x2F;Due to the reasons stated by Nitter itself on their repo, it seems unlikely there will alternatives.Are there any currently?",
    "commentLink": "https://news.ycombinator.com/item?id=39382590",
    "commentBody": "Nitter officially declared \"over\" today – alternatives?237 points by bookaway 20 hours agohidepastfavorite279 comments There were often \"rate-limited\" errors that hadn't completely prevented the site from being usable since the nitter people said the site would go down eventually. Now however there is an official declaration on the site itself: https://nitter.cz/ Due to the reasons stated by Nitter itself on their repo, it seems unlikely there will alternatives. Are there any currently? thom 12 hours agoI mostly have the same attitude to this as I do to sites with ridiculously aggressive cookie popups… I don’t need to see the content, I can just go for a walk in the sun instead. reply flyinghamster 12 hours agoparentBasically, I don't want to bother if it's lurker-hostile. Twixxer joins Facebook in the \"closed silos\" category. reply jamesear 10 hours agorootparent+1. I wasn't happy to have to use Nitter to access Twitter, but I accepted it. I'm not jumping through any more hoops for Twitter. Random Twitter links become random FB/Medium/LinkedIn: a closed world I'm not interested in. I only ~followed two people's content: * Dan Luu, available on https://mastodon.social/@danluu * Paul Graham, available on https://mas.to/@paulg but he doesn't post anymore. I'll live without this. reply justaj 9 hours agorootparentIf lurking Twitter / X works only with JS enabled, and if the same applies to Mastodon as well, then (strictly speaking in reading / lurking ability) what would be the difference between those two other than perhaps the size of total JS served? reply lavela 8 hours agorootparent1. If I understand correctly they talk about whether you need an account to lurk or not (I'd agree) and 2. the same does not apply to Mastodon. There even are CLI clients and I'd be interested to hear where you got the impression that js is required for Mastodon. reply autoexec 8 hours agorootparentWhen I clicked on https://mastodon.social/@danluu I got: \"To use the Mastodon web application, please enable JavaScript. Alternatively, try one of the native apps for Mastodon for your platform.\" That's probably going to leave people with the impression that JS is required. Sure, there are desktop clients (all third party) and I could probably try those, but generally the kinds of people who'd run random code on their systems and give it network access will probably just have JS enabled by default in the first place. At least some are open source I guess. Looking at some of the the open source projects I was amused to find a client for MS-DOS (https://github.com/SuperIlu/DOStodon) and then amused again to see all the .js files it needs to work. It looks like it might take a little work to find a desktop client that doesn't just run a bunch of javascript anyway reply justaj 8 hours agorootparentNot only is JS required, but for some reason those Mastodon pages can't be (easily?) archived in https://web.archive.org/, whereas Twitter pages can. reply autoexec 8 hours agorootparentWhat I've been doing when people here post Mastodon links to is add .rss after the @whatever bit which lets me grab their RSS feed and then I can scroll through that to try to find the post being mentioned. I'm not sure the entire post always shows up, and I think you don't get replies or comments or whatever Mastodon is supposed to have with posts, but you can at least get some kind of information out of Mastodon that way. reply ehPReth 7 hours agorootparentTry adding /embed after - sadly you don't get the replies etc (same as RSS) but it's a lot less hassle than scrolling though RSS reply DANmode 4 hours agorootparent> sadly you don't get the replies etc So, parity to unauthenticated Twitter browsing. reply hmcq6 4 hours agorootparentprevArchiving is an interesting issue to bring up. Due to the federated nature of Mastodon every other instance is ostensibly an archive as there is currently no way to guarantee that a tweet/comment/account is removed from remote instances when you delete it from your local instance. reply ehPReth 7 hours agorootparentprevIt used to work, then they broke it in v4 with whatever 'upgrades' they made and haven't brought back the lost functionality yet :/. You can add /embed on the end to see the singular post without replies, but it's not really a good substitute. GH issues: https://github.com/mastodon/mastodon/issues/19953 https://github.com/mastodon/mastodon/issues/23153 reply hardcopy 8 hours agorootparentprevhttps://mastodon.social/@danluu.rss reply jamesear 8 hours agorootparentprevYes, that's it. I don't want an account. reply justaj 8 hours agorootparentI can see the posts just fine (albeit with JS enabled), but not the replies and subsequent conversations. Assuming you were referring to the latter, then yes I'd agree with you. reply jamesear 2 hours agorootparentSometimes when I load Twitter, even to view a single, it requires sign in. I don't know why it sometimes does and sometimes doesn't. reply unnervingduck 47 minutes agorootparentI've noticed the same and it's really frustrating, it just straight up redirects to the login page sometimes. I guess I'll have to accept the fact that it's closing down, visitors are not welcome. Can't view a single post or picture in the future but so be it. reply moneywoes 6 hours agorootparentprevweird i can’t lurk twitter without login reply ineedaj0b 9 hours agorootparentprevMake an account. Only follow those guys. You don’t even need to include your real name man. This is like saying you wanna use windows without a user account. You want to use twitter no account in the age of AI. It don’t work like that anymore reply Liquix 9 hours agorootparentIf you choose to roll over and give $PRISMpartner unfettered access to your data in exchange for a modicrum of convenience, go for it. But there are millions of people who stopped using Windows, Chrome, Android, Facebook, etc because they care. Many people will stop interacting with Twitter after this change. Don't bash them for being principled where you have surrendered. reply orangecat 9 hours agorootparentprevThis is like saying you wanna use windows without a user account. It's like saying I want to use Windows without a Microsoft account, which I do. reply serf 8 hours agorootparentprev>You want to use twitter no account in the age of AI. It don’t work like that anymore how does having an account to view twitter meaningfully change anything during this mystick time of AI? If it's to prevent AIs from reading twitter threads, well, good luck. >It don’t work like that anymore well if a company doesn't follow customer demand they fail; I don't intend to continue using a service that requires me to have an account to lurk -- i'm not the only one. The rules for customer service don't somehow just get cast away because of magic software. reply anileated 6 hours agorootparent> how does having an account to view twitter meaningfully change anything during this mystick time of AI? > If it's to prevent AIs from reading twitter threads, well, good luck. If you require an account, it’s harder to scrape you and train an AI for free using platform you've build with your own investment and effort. Until court rule in favor of copyright holders, welcome to the future where nothing is shared in the open anymore. reply soraminazuki 4 hours agorootparentI'm curious who you consider that rights holder to be. reply jamesear 8 hours agorootparentprev> Make an account. Only follow those guys. You don’t even need to include your real name man. I understand this is easy, and others won't mind doing this. That's fine. I object to the idea of needing an account solely to read heavily linked, otherwise free, content. Besides, my browser doesn't store logins/cookies, so it'd be another login I have to do on each session. > You want to use twitter no account in the age of AI. It don’t work like that anymore So be it, I guess? The content isn't that valuable to me anyway. reply elsjaako 2 hours agorootparentprevI had an account to follow two or three guys, and maybe 4-5 accounts that only post every few months. The timeline gets filled with all kinds of things. Besides the horrible clickbait ads, it puts in random posts from unsubscribed parties. You really have to look between the crap for the stuff you're subscribed to. If this is Twitter in the age of AI, Twitter isn't worth the effort to me in the age of AI. Especially since I can use Mastodon, and that is actually very nice. I get that not all interests are as well represented, but I like it. reply swells34 8 hours agorootparentprev> This is like saying you want to use Windows without a user account If only I was able to do what you describe, I would use Windows. But sadly, Microsoft wants to invade users' lives like a malignant cancer, so Linux it is. reply autoexec 7 hours agorootparentI thought you could skip creating a MS account if you ran the setup entirely offline. Does that trick not work anymore? To be honest, even if it did work you can't trust MS to stay out of your business. Windows is constantly collecting data on the what you do on your system including the name of the file you open and what software you have installed. Jumping through hoops to try and work around a user hostile OS is a losing battle. You'll always be one forced update away from defeat. Linux is the way to go. I'm forced to use windows at work, but at home the last windows OS I had was 7 professional and it looks like it'll be the last I ever use. reply jasonfarnon 6 hours agorootparentIs this level of tracking (files you open) something you can't opt out of? If so I hadn't realized that. Do you have a link so I can read more? reply charcircuit 7 hours agorootparentprevLinux requires a user account too. There is no anonymous mode. You will always be running something as a user who has a user id. getuid and geteuid are always successful and correspond to a valid user. In theory there could be a way to run things without a user, but Linux was designed to not allow that. reply xk_id 5 hours agorootparentprevExactly, I literally can’t remember accessing any content on Facebook in the past year; nor did I really think about it. reply hiccuphippo 10 hours agoparentprevI do wish some people mirrored their content to their own blogs because there's some interesting stuff there once in a while. reply forgotmypw17 5 hours agoparentprevI'm the same way, with few exceptions. The best part about it is that I've noticed a strong correlation between content quality and ease of access. reply mmgfxcv 5 hours agorootparent>I've noticed a strong correlation between content quality and ease of access. it being inversely proportional? reply rchaud 18 hours agoprevIt's over. It isn't just Twitter, it's every single website that's turned themselves into a login-walled \"application\". Twitter's relative openness lasted a long time. It was open by default because it is a product built in 2006, when the idea of coralling people into walled gardens to show them ads didn't exist. Apps built later take the concept of \"walled garden\" as a default feature. Slack , Discord, Snapchat, Tiktok, Telegram .... all largely closed off platforms. You can't see anything unless you're logged in. reply renegade-otter 15 hours agoparentBut Twitter is an ad-driven platform. Most of those other ones are not. It's ALL about the exposure to eyeballs. But now that Elon chewed on some wires and killed whole colocations, they are not able to serve all that traffic that is supposed to view the ads - for all the talk about how \"Twitter is still running like it used to\" after being gutted like a fish. It is definitely not. reply godelski 8 hours agorootparentWell it probably doesn't help that they're now riddled with bots. About 6 months after the Musk takeover I've started to receive 2-3 likes a day from bots and a follow every week. I only have an academic account so my bot interaction vastly outweighs my non-bot interaction. I stopped reporting them because they still exist. The big change I saw was that they no longer suggest to me 30 other bots with the same profile picture when I click on the bot's page but instead suggest I follow other researchers. I guess a slight improvement, but only visually. It's weird to see him talk about how bots are so harmful to the platform, see that the platform is identifying bots, but then not see any action. These are accounts that can be identified via a naive bayes filter too, so pretty low hanging fruit. But then again, same thing is happening to my gmail. reply wkat4242 11 hours agorootparentprevIt's not really that ad driven anymore since most of the advertisers have gone to fuck themselves as musk told them to :) But seriously, if they want to increase revenue it probably is more effective to not insult their advertisers than it is to make a login mandatory. reply MisterBastahrd 11 hours agorootparentprevOnce upon a time, you could go to Twitter as a non-registered user by clicking on an embed in another application, view the post, and then click on the user's post and see all their interactions without ever registering or logging in. Today, you get to see the one post, and if you're lucky, it will give you a few of their most highly interacted posts. If the point of twitter is to make money, then it doesn't matter whether someone is logged in or not: ads in front of eyeballs is what's important. Musk's entire schtick since buying the platform is that he'll bully people into doing what he wants. But users on the internet have near zero patience with such demands from platforms, especially when the platform in question is losing relevance and isn't unique. What genius! Not only did he make the ads less valuable, but his behavior has created less competition for the ad slots that people actually see. I've watched while shaking my head as a former employer has taken a similar approach and absolutely cratered their online business. I warned them that it was going to end in disaster. I provided the evidence that we'd used to make decisions against exactly what they were attempting to do. I can't unstupid them. reply jdminhbg 10 hours agorootparent> If the point of twitter is to make money, then it doesn't matter whether someone is logged in or not: ads in front of eyeballs is what's important. To serve you ads that have any hope of making money, they need to know which eyeballs they're going in front of. reply burkaman 10 hours agorootparentNo they don't. People sold ads profitably for hundreds of years without any sort of surveillance, and many people continue to do so today. If it were impossible to make money just selling ads (I wish it were) then billboards and bus stop posters wouldn't exist. You can even make money on the internet this way: www.ethicalads.io. Twitter also has an enormous advantage: even if they don't know anything about you, they know a whole bunch about whoever posted the tweets you're reading. They could do a lot of targeting by just looking at the content you're viewing. reply jdminhbg 9 hours agorootparent> People sold ads profitably for hundreds of years without any sort of surveillance, and many people continue to do so today. If it were impossible to make money just selling ads (I wish it were) then billboards and bus stop posters Billboards and bus stop posters are cheaper to run than Twitter.com is, so making much less money is ok. The whole reason Twitter has always been unprofitable but Facebook/Meta is a trillion-dollar public company is that FB figured out how profitably identify users and serve them ads and Twitter didn't. reply burkaman 9 hours agorootparentI agree with you, it is unquestionably more profitable to spy on people and then sell them ads. My point is that you can still make money without the spying part, and there is no reason for us to accept that the two always have to be bundled. If you can't make a profit without spying on people then your business model sucks. The fact that you might be able to make more money by being less ethical is not very interesting, that's true of almost anyone. reply rchaud 8 hours agorootparentprevIt absolutely matters if someone is logged in. 3rd party cookie blocking on Safari, Chrome and Firefox has crushed the ability for advertisers to do remarketing with any level of precision. That was where you didn't need the user to be logged in, you just needed to match their cookie ID on Twitter.com with the cookie ID passed on by Site X, which the user had visited previously. Nowadays, Advertisers upload customer lists with email, phone numbers and other identifiers into Twitter Ads for ad targeting. Twitter shows those advertisers' ads to logged-in users that have the same email/phone # or other identifier. https://business.twitter.com/en/help/campaign-setup/campaign... Anything else is effectively untargeted and useless. reply autoexec 7 hours agorootparentThey already have the only information they really need, which is what you've requested to look at. If I'm following someone who tweets about X you can safely guess that I'm interested in X and target me with ads related to that without ever knowing my identity. reply jdminhbg 6 hours agorootparentThere may be a reason there's no social media network that does this. reply foobarchu 5 hours agorootparentIt may be that it wasn't feasible on large scale to match content to ads. I feel like recent advanced in machine learning and ai could change the game there. What were describing is essentially how television ads worked for decades, isn't it? You know the content, so you can identify the demographics and advertise properly. Podcast and YouTube sponsor deals often work that way too (not always, but that's on the advertiser). reply autoexec 6 hours agorootparentprevTo some extent they very often do use the type of content you consume for various things, but they don't use that data exclusively because they can make far more money by collecting, leveraging, and/or selling every scrap of personal data they can get their hands on and money is really all they care about. reply jasonfarnon 6 hours agorootparentprevInteresting that something initially seen as a privacy victory has ended up harming the experience of anonymous internet browsing. reply MisterBastahrd 9 hours agorootparentprevCookies do this for them. reply autoexec 7 hours agorootparentprev> Musk's entire schtick since buying the platform is that he'll bully people into doing what he wants. But users on the internet have near zero patience with such demands from platforms The continuing decline of reddit makes me suspect people are much more tolerant of being bullied than you think. when old.reddit.com is finally killed off (it already seems to be getting less functional) I'll stop going there entirely too. reply macNchz 6 hours agorootparentIt’s somewhat intriguing how long they’ve kept old reddit alive. I had figured it’d get the axe fairly soon after they made the redesign the default, even if they claimed otherwise. I suspect there must be a contingent of users who are big contributors or otherwise important, who they believe will leave if they shut it down. reply literalAardvark 2 minutes agorootparentI suspect they have loads of data showing that contributors use old Reddit and cat video watchers use new Reddit. And they haven't chosen to cater only to the watchers, yet. MisterBastahrd 5 hours agorootparentprevPeople ceaselessly cry about reddit and its moderation while anyone is perfectly free to start a community of their own and moderate it to their own heart's content. I've seen no real decline in reddit. It's generally the same mindless shithole it was 10 years ago, while the communities which have had steady moderation haven't changed at all. reply autoexec 19 minutes agorootparentThe quality of individual subreddits has a very wide range, but it's the admin side of things that just get worse and worse. Anyone can create a community but you can't escape the way they run the site. Over time more and more subreddits get shutdown for questionable reasons, censorship creeps in more often, long standing problems with moderation go entirely unaddressed (both in terms of problematic moderators/moderation and in terms of the lack of tools/resources available to moderators), transparency, communication, and integrity get worse all the time, nice features get removed, obnoxious new ones get added, etc. Even old.reddit.com is starting to become broken. If you're lucky you can still find some great little subreddits, and maybe they'll even be allowed to stick around, too many good users won't get chased off, and they don't degrade in quality much as the site itself gets worse around them. There's still no good reddit alternatives but I'm still hoping we'll get one soon. reply rplnt 11 hours agoparentprevSlack, Discord, Snapchat, Telegram are not open forums as their main selling point. They are 1 to 1 or group/community chat applications first. So relatively scoped or even private. It's like a blog vs icq/irc. reply brucethemoose2 11 hours agorootparentAnd yet Discord has become a de-facto forum replacement for niche topics/communities. ...Which is awful. As is often said here, Discord is where information goes to die. reply EVa5I7bHFq9mnYK 2 hours agoparentprevAdd Reddit to the list. Lately, I get \"Whoa pardner\" treatment whenever I try to read it without logging in. But at least you can still create an account without a phone and without even an email. AI is evil and already makes us all suffer. reply mjevans 12 hours agoparentprevForget them all. If it isn't on the open web it's a private club. reply ineedaj0b 9 hours agoparentprevIt’s because of AI scraping. Wait until you realize ‘verified’ paid accounts will be a necessity in the future to prove personhood unless we toss it all in the wind and create a national id system which guess what, you’ll be tracked by. Which way brave one? You will lose an arm or a leg. You get to choose reply Retr0id 7 hours agorootparentWhy should Twitter care about AI scraping, beyond the load it causes to their servers? Scraping isn't new, and I don't think the overall rate of scraping has changed much since the advent of AI - it only needs to be scraped once, then it's in a dataset (I don't have any stats to back this up, though) reply a_bonobo 7 hours agorootparentIf you have a company building AI on top of Twitter's data, it could've been a company Twitter itself could've built. It's the feeling of lost money for them. reply rchaud 5 hours agorootparentThe API has been wide open until 2023, so if there was anything of value, I think we would have seen something by now. Musk would also have been focused on that instead of trying to become WeChat US. reply singleshot_ 8 hours agorootparentprev> Which way brave one? Probably the same way my grandparents did. reply hmcq6 3 hours agorootparentprevI think you're overestimating the value of raw text. A large unsorted dataset is not \"free\" for AI companies. Without API access there's very little useful information that can be scraped from a tweet. In my opinion, Twitter just wanted to convert lurkers to make it look like the platform isn't dying. reply thriftwy 10 hours agoparentprevYou can see plain text Telegram (and Twitter?) posts by a direct link without login. You cannot do that anymore to FB or Instagram posts. reply Dalewyn 9 hours agoparentprevYou must be new and young, most internet communities have always been login-walled or otherwise inaccessible to the wider public. Why? Nowadays it's to combat freeloading \"AI\" data scraping, but more predominantly it's been to fight spam and scraping of data in general. So no, nothing is over. If anything, we're getting back to the status quo of 20 years ago when most forums required you to make an account to enter. reply rchaud 8 hours agorootparentHere's a list of open-access communities I grew up on: Hacker News, Myspace, LiveJournal, XDA-Developers, RateyourMusic/AbsolutePunk forums, and about a thousand phpBB/vBuletin boards from 20 years ago. Every single one of these is close to 20 years old. It is in fact the \"new and young\" that think they need to \"download the app\" and \"join the community\" for every single thing that could just be a Discourse message board. reply autoexec 7 hours agorootparentHell, there were BBSs that let you browse around under a guest account with zero requirement to register an account reply jimmySixDOF 13 minutes agoprevTwitter under the X revamp has exactly two available legit API plans. $100/month and then $4000/month. Nothing in between. And you can't just layer $100 packages for more API calls when you run out. So the idea of being a 3rd party friendly API 2.0+ is just a joke because access is either too limited to be useful or to expensive to find out. Meanwhile their rate of internal innovation seems to have reached zero or slightly negative. What a joke the content is becoming more valuable than ever but what you can do with it is practically in decline. reply wl 19 hours agoprevThere's two distinct Nitter use cases I need to replace. 1. Someone drops a link to Twitter. Twitter hides threads and throws items in some weird non-chronological order—assuming I don't get a login wall. I need an unfucked UI. 2. There are some content I can't get anywhere else that I follow through RSS. I wish these people would move elsewhere, but if they haven't by now, they probably won't ever. I may just run a local instance with an account created for the purpose if that remains viable, but associating all that with a single login/IP address is something I'd like to avoid. reply prmoustache 12 hours agoparent1) Ask people to send screenshots of the tweets instead of links. I think this has naturally been happening a lot more over the years anyway and people will just get used to do that. 2) I guess those people will slowly realize they have lost most of their audience anyway. reply promiseofbeans 6 hours agorootparentKinda sad that we have to send screenshots since it hurts accessibility, but I guess that's less of an issue with local OCR on most devices these days. reply apercu 12 hours agorootparentprevRight? (#2), I can't be so far in the minority to just not be willing to bother with Twitter. There is really very little content that will compel me to have a bad time consuming it. Is it 1 out of 10? 2 out of 10? More? Even if it's just 10% that's still significant. Just my $0.02 of course. reply prvc 13 hours agoparentprevIn addition to a chronological feed, Nitter provided pagination and link de-obfuscation. Would be nice to get that back somehow. reply andy99 19 hours agoparentprevRight, all the \"just don't use it\" comments miss the point. I used Nitter specifically because I don't use twitter, so I could see the contents of a link that was being posted or discussed. I suppose a solution could be \"ignore a large swath of posts and links and discussions\" which is basically what I do, but sometimes it's nice to have the option to look at them. Same as if you don't use MS Word, someone might still occasionally send you a word document and it's nice to have a way to open it without having to install Word. reply toomuchtodo 19 hours agorootparent+1. Need something like archive.today/.is for Twitter so you can rip and archive the content that might not live elsewhere. Grab it, stick it in Wayback Machine, return a Wayback url. reply madamelic 18 hours agorootparent+1 on Reddit as well. Reddit doesn't have login walls yet but it has way too much information stored within their walls to not have a backup / non-social-media way of extracting it. It's infeasible to have Reddit blocked because it's UI is intended to be addictive like all social media but also be able to extract information from it. reply ben_w 18 hours agorootparentFor the moment, old.reddit.com is sill useful. For the moment. reply pimlottc 12 hours agorootparentIt’s dying a slow death through neglect. Image posts don’t work correctly, image comments don’t show up, and the dirent comment links generated from www don’t work on old reply hnick 9 hours agorootparentThere's also a thing lately where link targets posted on New Reddit (I assume, since mine aren't doing this) are all lower cased, while the link text is correct as you typed. This breaks the links for some sites. In addition to the issues with underscores getting extra slash-escapes. reply apercu 12 hours agorootparentprevStill better than logging in, using the new web app or downloading the app. It's not like 95% of the content is any good anyway. You have to dig deep into a niche to really get any value, and the last few years, less and less. Of course, I haven't logged in for 3-4 years so maybe I'm missing something. Doubt it. reply whstl 12 hours agorootparentprevThere are 18+ age walls that just force you to login, often in unnecessary places. Plus mobile sometimes refuses to show some things. old.reddit still works though. reply MSFT_Edging 11 hours agorootparentSome subreddits will impose the 18+ wall because reddit hasn't specifically vetted/approved of the subreddit. So it will be something totally not adult, just a small sub with important information you're looking for and you can't view it anonymously from a browser. reply WaxProlix 10 hours agorootparentThese can be avoided by using old.reddit.com instead of www. I think. reply godelski 8 hours agorootparentprevI think this is only true if you're using mobile. If you're on a desktop you can get through just fine. Usually. reply godelski 8 hours agorootparentprevReddit also now blocks all Mullvad connections that I'm aware of. It's kinda ironic seeing all the scamy YouTube ads promoting using VPNs to watch Netflix in another country when that's never worked and other companies tend to be hostile towards VPN users. reply rglullis 11 hours agorootparentprevhttps://academictorrents.com/details/7c0645c94321311bb05bd87... reply thaumasiotes 12 hours agorootparentprev> Reddit doesn't have login walls yet There isn't one on the root directory, but Reddit has plenty of login walls. reply dpassens 12 hours agorootparentOn New Reddit. I haven't seen any on Old Reddit yet. reply thaumasiotes 5 hours agorootparentThere's not a difference. If a subreddit requires you to be logged in, then it requires you to be logged in. reply pogue 18 hours agorootparentprevThe EFF just recently wrote an article with instructions on how to persevere & archive your own tweets on the Wayback Machine, but it involves exporting your own backup and uploading it to them. Since the API is completely cut off from Twitter, there is no official way to backup other people's accounts. But archive.today uses scraping and all sorts of tricky methods to bypass paywalls. I honestly don't understand why Nitter can't just stay logged out and rotate IPs. Although I'm sure that gets pricey when other people are accessing it constantly. https://www.eff.org/deeplinks/2024/01/save-your-twitter-acco... reply toomuchtodo 18 hours agorootparentIf the scraping model is impaired due to aggressive countermeasures, end game are browser extensions that scrape as users view the site and ship scraped data back to a processor, similar to recap the law (uses an extension to scrape the PACER legal database and ship digital artifacts to the Internet Archive). Care will need to be taken around potentially sensitive data that could be shipped if users are logged in. https://free.law/recap reply pogue 14 hours agorootparentOh, that's a very cool project! How successful has it been? If it wasn't for Sci-hub that would be a great idea for the scientific publishing world as well. reply toomuchtodo 13 hours agorootparentVery successful. Millions of court filings extracted and indexed, and a crucial component in driving down PACER costs. https://news.ycombinator.com/item?id=24086570 > I'm the director of Free Law Project. For the case mentioned in the article we actually did a full expert testimony figuring out roughly how much per page it'd cost to run PACER using AWS GovCloud and a handful of other assumptions. It was...half a ten thousandth of a penny per page https://www.courtlistener.com/docket/4214664/52/15/national-... https://news.ycombinator.com/item?id=24085158 > Government’s PACER Fees Are Too High, Federal Circuit Says https://news.bloomberglaw.com/white-collar-and-criminal-law/... reply phone8675309 13 hours agorootparentprevThis model also works well for deep web content archiving. There was a gaming message board where someone wrote a browser extension that would back up all topics someone visited in the background while they were reading them. It became important for archiving as much content from those forums as possible as the forum was in the process of shutting down. reply PaulHoule 19 hours agorootparentprevnext [7 more] [flagged] wl 18 hours agorootparentIf the content we wanted was on Mastodon, we would not be having this conversation. Your comment is deeply unhelpful. reply PaulHoule 18 hours agorootparentnext [5 more] [flagged] ben_w 18 hours agorootparentYou're looking at a vase and seeing two faces side-on. \"Twitter won't let me read content people post on it\" \"Try posting it on Mastodon\" \"If it was on Mastodon we wouldn't be having this conversation\" \"Whatever, you don't share anything from Twitter anyway\" Can you see the vase yet? reply PaulHoule 17 hours agorootparentIt's like asking a Christian if he can see the devil. reply wl 18 hours agorootparentprevThe issue isn't me posting Twitter links here or elsewhere. It's what to do when others do. reply PaulHoule 14 hours agorootparentnext [2 more] [flagged] kps 12 hours agorootparentMuch as I dislike login walls, Mastodon still doesn't respect `:prefers-color-scheme`, so they're not my friends either. reply ben_w 18 hours agorootparentprevWhat problem is that suggestion supposed to help with? reply carlosjobim 17 hours agorootparentprevWhy don't you make a twitter account and install a duplicate web browser that you only use to open twitter links (and other crap that you don't want polluting your normal browser)? reply xigoi 15 hours agorootparentI don’t want the company to have any information about me. reply UncleOxidant 10 hours agorootparentI also don't want to give them any traffic. reply carlosjobim 15 hours agorootparentprevThat's why I suggested you use a burner browser. reply MilaM 13 hours agorootparentYou also need a burner phone number. Otherwise it will be difficult to get an account. reply carlosjobim 11 hours agorootparentI didn't know you needed a phone number for twitter. Yeah, then it's difficult. reply smaudet 11 hours agorootparentprevThese systems are completely losing propositions. My data is worth $$$$, my time is worth $$$, and I have to spend $$-$$$ in order to safely interop with them? Twitter/FB don't understand just what a terrible value proposition and complete waste of time they represent. I'm happy Ediot Mashbrains has been bleeding money for the damage he's caused. reply amenhotep 9 hours agorootparentprevSpite, personally. reply amenhotep 9 hours agorootparentprevSpite, personally. reply 8note 9 hours agoparentprevFor 2, you might want to send them an email asking them to post said content elsewhere. Given that it's Twitter, there's not a ton of text or anything in what you're missing. If it's a blog post, you could see about them enabling RSS on it? If it's video content or something, they could put it on patreon with you paying them for it? reply speps 10 hours agoparentprevFor 1: replace twitter.com with vxtwitter.com. reply godelski 8 hours agoparentprev> I need an unfucked UI. Preach. I need a UI where I don't have to click \"Read more\" to only find out there is one word missing. Then required to swipe back and repeat the process because someone used all 240 characters in several tweets. This is literally what happens when your devs don't dog food. What an insane thing to do and with such an easy fix. It is just baffling. There's so many little things like this but I can't understand how this isn't just a few lines of code somewhere. reply fnordpiglet 18 hours agoparentprevI’d also vote for 3) the user interface is fast, responsive, and not total garbage inflicted with man boy ego whim randomly mutating a decade of questionable product management decisions reply aftbit 11 hours agoprevYea I just don't read twitter content anymore. Same thing I did to facebook. There's some really good stuff on there that I miss, but it simply isn't worth it to me. Easy enough. reply spike021 6 hours agoparentI don't understand. There are some handy mechanisms you can use on Twitter to filter and curate what you get to see. You can mute any word or hashtag you want. You can create lists containing specific people or orgs you'd like to keep up with. Occasionally something slips through the cracks but nothing is perfect. With those mechanisms in mind though, Twitter is pretty hackable. You can get it into a state where you can still consume things you're interested in. And if you don't want to give ad impressions you can access it with a browser that can block ads. reply refulgentis 6 hours agorootparentThey're saying: I don't read Twitter anymore [because I don't want to get a log in and now it requires a login] reply spike021 6 hours agorootparentYou're right. I'd just figure at that point it's not that complicated to get a random spam email box just to create an account with. reply jasonfarnon 6 hours agorootparentThey don't ask for a phone #? I would consider making an account or two in that case. If only because many services that start out requiring only an email end up requiring a phone # (like google did) and those old anonymous accounts become useful. reply piperswe 5 hours agorootparentIn my experience, they do indeed ask for a phone number. reply Tommy430 9 hours agoparentprev> There's some really good stuff on there that I miss Tbh, same. I do miss getting some information about Windows betas pretty much, but other than that, I won't miss Twitter at all. People need to publish more on more open and community driven solutions. Heck, even publishing information for a site that still works on older PCs is better than publishing information on Twitter. reply nonrandomstring 11 hours agoparentprevWhat I find weird, is of all the things I totally ignore because of its corporate shitfuckery, Twitter is the one that should be the easiest to read. How in 2024 is it possible that I, using a text only browser without JavaScript, cannot read what are short text-only messages on what's really a jumped up version of NNTP? With each passing day we regress technically . reply ineedaj0b 9 hours agorootparentThey want to at least try to reduce data scraping. At least attempt. Do you have a better idea because we’d love to hear it reply CaptainFever 6 hours agorootparentIgnore it. What's the reason to restrict it? Scraping is important to interoperability. reply nonrandomstring 5 hours agorootparentprev> data scraping. What we old people call \"reading\"? But if that's what you crazy kids call it these days. > Do you have a better idea because we’d love to hear it Oh well, now you mention it, it'd be rather nice if Elon Musk went and stuck his head up the back of a cow. Anyway gotta go scrape some more HN posts... reply MikusR 1 hour agorootparentHave cows not suffered enough? reply rurp 6 hours agorootparentprevI mean, yes? There are many techniques for blocking or throttling high volume scraping. You don't even need to understand the techniques, plenty of companies sell this as a service. That's beside the point though. There's no actual need to force logins, it's just something Elon wants. Given what a dumpster fire Twitter has turned into the rational move for most people is probably to just forget about the site at this point. reply somenameforme 5 hours agorootparentWhile this is tangential, you've stoked my curiosity. What could prevent scraping? In this case, they're combating against scraping from other major businesses, so another company doing something like setting up thousands of distinct IPs to scrape from at rates which are specifically intended to mimic organic usage would not be difficult. Only thing I can think of is starting to get into gaming-site type territory where you end up trying to do things like analyze mouse position, click patterns (every 30 seconds at exactly the 0,0 pixel or whatever), and so on. But this sort of stuff is a cat and mouse game, where I think the cat is generally going to be at a pretty big disadvantage. reply chris_wot 11 hours agoparentprevIt's the Great Tune Out. More people are joining this movement every day. reply dspillett 18 hours agoprevFor the same reason given for Nitter stopping, it is unlikely that you'll find a public service like that. There are nitter-like options, including forks of nitter itself, that you can self-host to give a better UX, but with those you have to have a twitter⁰ account for it to login with. Another option (that also requires an account) is to use twitter⁰ itself with a browser extension that tweaks the UI. My solution is the one I've been using for a _long_ time: simply don't go there. It has never been more than a novelty-gone-wrong, unless you count “a cesspool of humanity” as more, and as far as I know I've not missed out on anything significant. If you want me not to know what you have to say, say it on twitter⁰! Though I acknowledge that this is not an acceptable solution for all. -- [0] The site desperately trying to be known as Χ reply pogue 18 hours agoparentIn terms of a browser extension for Twitter, I highly recommend Control Panel for Twitter. It works as a browser extension as well as on some mobile browsers. It is highly customizable to filter out who/what you don't want to see and is fully open source if you feel the need to tweak. It's updated regularly and the creator is highly active on Twitter to provide updates and answer questions - @ControlPanelFT If you decide to use it, drop the guy a donation, they work hard on it! https://github.com/insin/control-panel-for-twitter reply mst 17 hours agorootparentControl Panel ftw. I'm also eyeing https://chromewebstore.google.com/detail/trab-tweet-reporter... for rapid block+report of the crud that accumulates on various posts, and pondering how much hassle it would be to port to firefox. reply pogue 14 hours agorootparentThat looks interesting in theory, but unfortunately it was last updated in Feb 2022 so I would doubt highly it still works. There were a great deal of 3rd party tools to reduce abuse, bots and known bad actors on Twitter, but Elon took that all away when he restricted access to the API to only those paying $42k/month. I haven't actively been on Twitter since July, but after he essentially removed the majority of moderation staff after he bought the place, reporting people is basically a non-working feature anyway. I remember getting a notice on someone I reported 3 months after the fact. reply vehemenz 12 hours agoprevPublic-facing tweets are a huge part of Twitter's value proposition. Between this, removal of verification, and publish.twitter.com being broken, I wonder how many of the biggest outlets and organizations will continue to abide Twitter's decline. reply bloopernova 18 hours agoprevTwitter became the defacto public square, so it's understandable that there's inertia for society to keep visiting. This particular public square has been bought and fenced off. Ostensibly this is to drive more traffic to it. Passively standing outside the fence trying to peek in is a lost cause. Find a new public square and convince as many people as you can to move. To do that, engage with those who moved, and create compelling reasons to go to the new public square. reply klabb3 10 hours agoparent> Find a new public square and convince as many people as you can to move. In particular, complain loudly to your local governments etc that (still) use Twitter for “quickly reaching the public” or whatever their remaining excuse may be, especially if that information isn’t accessible elsewhere. The public square rhetoric was always a red herring. A distraction to fool people, including yours truly, although it’s been years since the illusion came falling down. There is still a need for public spaces. I just don’t have any hopes about ad-tech corporations any more. reply godelski 8 hours agoparentprev> Twitter became the defacto public square I think people often miss this about social media. Private spaces can become public spaces. The same way you can lose a trademark if your product becomes associated with the general thing (which is why OpenAI failed to get a trademark). In a way too much success is limiting to the company's power, but that's probably a feature and not a bug in terms of protecting the public. It's not like it is easy to navigate away from Twitter or any other major platform. Unlike traditional products you can't simply choose Pepsi if you are upset with Coke, or vise versa, because the product's utility (and product) is it's network. It also makes it very difficult to compete against as you can make an infinitely better UI/UX but if no one is on it you are missing the key product. So you only move to a ghost town in hopes that others will follow but if that doesn't happen quickly then it'll remain a ghost town. reply rldjbpin 34 minutes agoprevsay what you may but i never used twitter because you needed to login to lurk properly all this time anyways. moreover requiring mobile number, at first for specific regions but then for everyone, was a deal-breaker which kept me off, and for good reasons in the long run (https://news.ycombinator.com/item?id=31510865). i would like to think that i am not the only one not using the platform all this time to get my news. to be fair i do get shared some links to tweets but at least until this debacle you could read them without too much trouble. reply KomoD 18 hours agoprev> Now however there is an official declaration on the site itself: https://nitter.cz/ FYI: That's not official, nitter.net was, and there are other instances of Nitter that still work. https://status.d420.de/ reply not_your_vase 16 hours agoparentThey work only for a few more days, till their account expires (30 days after creation). After that no more guest account creation is possible: each instance will go red one by one. reply KomoD 15 hours agorootparentNot all instances use guest accounts, some use a lot of real accounts reply Astraco 11 hours agorootparentThey are rate limited faster than guess accounts and banned. It's over reply strunz 9 hours agorootparentNot if you setup your own instance and use your own account sparingly reply Astraco 8 hours agorootparentI'm talking about public instances. Using nitter with your own account is not for what nitter was intended to. reply joeframbach 19 hours agoprevI have Tampermonkey scripts that delete Twitter entries from HN and anywhere else on the web. Seems to work well for me. reply redrove 19 hours agoparentWould you mind sharing? reply joeframbach 10 hours agorootparentuBlock Origin rules: news.ycombinator.com##tr.athing:has(a[href^=\"https://twitter.com\"]) + tr + tr.spacer news.ycombinator.com##tr.athing:has(a[href^=\"https://twitter.com\"]) + tr news.ycombinator.com##tr.athing:has(a[href^=\"https://twitter.com\"]) *##a[href^=\"https://twitter.com\"]:style(text-decoration: line-through !important) reply joeframbach 10 hours agorootparentprevI tried responding here but my comment isn't showing up -- was it autoremoved? I'm commenting with this meta-comment to check. reply philipkglass 10 hours agorootparentI see 3 very similar comments from you sharing block rules. Is one of your browser extensions hiding your own comments from you? Try viewing this thread in a no-extension browser. reply joeframbach 10 hours agorootparent...yes. The rule deletes this comment as well. reply rglullis 11 hours agoprevThe developer from bird.makeup is asking for donations of account tokens: https://www.patreon.com/posts/call-for-special-98167212 I'm also thinking about adding twscrape support to my https://github.com/mushroomlabs/fediverser and extend its mirrors to Mastodon servers, but to be honest I can not afford (money- and time-wise) to get into yet-another project without some minimal financial support. reply sva_ 20 hours agoprevI usually check this list: https://status.d420.de/ reply not_your_vase 19 hours agoprevWhat are you looking for? If you want to be anonymous, your are SOL unfortunately. If you are looking for a less crappy browsing experience than Twitter, and Nitter filled that void, you can find forks which fetch content with your Twitter account. Setting up for local self hosting doesn't take a lot of minutes. reply mozman 19 hours agoparentI used to use Nitter to view content without logging in, as I do not have a twitter account nor do I want one. reply pogue 18 hours agoparentprevThe question is whether or not they'll continue to develop Nitter just for people who want to run it locally. Twitter's page layout & functions get updated and changed CONSTANTLY. If someone isn't updating Nitter regularly it will become depreciated very quickly. reply Astraco 11 hours agoparentprevNitter has been abandoned by the developer and I don't have time to deal with Elon Musk's whims reply alchemist1e9 11 hours agoparentprev> you can find forks which fetch content with your Twitter account What is the recommended/preferred fork for self hosted using your own account? reply Tommy430 11 hours agoprevAh, can't wait for more login walls, oversized UIs, and more \"Please Subscribe\" crap. Thanks Twitter. reply ActorNightly 13 hours agoprevThere is enough decent resources on Twitter to warrant signing up IMO. I just avoid installing the app so I don't end up browsing it. reply INTPenis 13 hours agoprevlibreddit is suffering the same problem. Some instances are still working but they're probably switching outgoing IPs often to evade the ban hammer. As others have noted, I think this is part of a larger trend. All websites have realized that data is power, data is money, and they don't want to share anymore. I used to host both nitter and libreddit, now I host neither of them. I've simply given up on reading that data. reply based_gigachad2 11 hours agoparentThere's a fork of LibReddit called RedLib which should work better: https://github.com/redlib-org/redlib?tab=readme-ov-file#libr... reply INTPenis 11 hours agorootparentWhy would it work better when reddit are blocking IPs? It's an arms race you can't win in the long run. reply sodality2 7 hours agorootparentIt is working better because previously Reddit was blocking IPs from accessing the JSON endpoints, but Redlib doesn’t use those anymore, we emulate an official client, which currently doesn’t have any kind of IP blocking (they don’t want to ban any mobile VPN users probably). reply smashah 6 hours agoprevaround the same time, twitter social cards started working. maybe there's a way in there. The promises of Web 2.0 are dead and megacorps are killing them. Adversarial interop is a digital human right and Elon is taking that away from us. Shame on him. If he can't run a business without stepping all over our API rights then he shouldn't be in business. reply throwaway5959 10 hours agoprevAlternative: Stop consuming any content from that shitty platform? reply bhaney 7 hours agoprev> alternatives? Stop consuming Twitter posts reply syoc 13 hours agoprevHost it your self. I'm doing that with libreddit. Gives me much better performance than the highly used public instances. reply BLKNSLVR 12 hours agoparentI was self hosting Reddit, which now seems entirely dead, and need to switch over to libreddit. Hopefully that lasts longer... reply nanolith 9 hours agoprevTwitter is doing its best to paywall and authwall content. Fighting this is a losing battle. I think that the best alternative to Nitter is probably learning to live without Twitter. For the folks you used to follow, try reaching out to them to see if they are willing to also send updates on other platforms. If they are, great. If not, well, it may be time to let them go. For public accounts that are still using Twitter, definitely write appropriate representatives to request that they use more open means of disseminating important information. Twitter used to be the \"public square\", but its actively hostile behavior toward lurkers and non-paying members means that it no longer serves this purpose. In turn, public accounts that use Twitter aren't reaching as many people as they used to, and in time, will reach fewer and fewer people. reply etc-hosts 18 hours agoprevyou could run your own instance of rsshub https://docs.rsshub.app/ reply SkyMarshal 9 hours agoprevMaybe this one? https://nitter.unixfox.eu/ reply satvikpendem 11 hours agoprevI just made a Twitter account. I don't care to post anything in it, I just use it to read tweets that websites post or embed, such as on HN. reply btzs 11 hours agoprevMaybe someone wants to earn some karma by pasting the content of the tweets here? Similar how it happens with the archive.ph/today links. reply ttiurani 19 hours agoprevFor the past few weeks I've been using https://twiiit.com/ to find independent nitter servers that can show tweets of the few academics I still want to follow. Now Twitter might soon break also these small third party servers but for the moment, they still work. reply 2024throwaway 19 hours agoprevMastodon reply matheusmoreira 8 hours agoprevThe alternative is the fediverse. Just drop twitter. Anything of value in there will eventually make its way outside anyway. reply rc_mob 10 hours agoprevindividual users can ifttt to another site https://ifttt.com/connect/sendie/twitter reply bluish29 19 hours agoprevI thought that the official instance (nitter.net) works and that it works but visited it now, and it seems it doesn't have a valid certificate since Jan24th. reply kotaKat 18 hours agoparentIf you're in Chrome it likes to give you a full screen \"oh no you can't go to this website!\" with no visible override, but if you type in \"thisisunsafe\" it'll fly by it. I wish Chrome would just let me have the damn button. I'm not a five year old. reply tryauuum 12 hours agorootparentthis is why it forces you to type those things, the button would have been bypassed by a five year old reply wkat4242 11 hours agoprevWhat about threadreader? I used that a lot when I still used Twitter. reply andersa 13 hours agoprevWhy do you need one? It takes a few minutes to make a Twitter account and keep browsing. You probably spent more time writing this post. I'm glad I won't have to deal with people posting these off-brand Twitter links anymore. reply Havoc 12 hours agoparentTheir UX is a trashfire even when logged in. reply kibwen 10 hours agoparentprevWhy would I want an account? Blocking me from viewing Twitter has done wonders for my mental health. reply logicalmonster 19 hours agoprevIf your concern is quasi-anonymity, get a burner phone to create your social media accounts. reply friend_and_foe 15 hours agoparentMy personal concern is, if I have to sign up for an account to see what you have to say, I don't care what you have to say. If you want reach pick a platform that let's people easily read your thoughts. This is no different than \"download the app to continue reading.\" People on twitter are irrelevant as far as I'm concerned, and they just don't know it yet. They will. reply 1vuio0pswjnm7 12 hours agoprevWhen nitter.poast.org announces it is going offline, I will believe \"Nitter is over\". (Unless I find another instance that works.) Meanwhile I'm still using Nitter. reply Springtime 5 hours agoparentThe issue as I understand it is guest accounts no longer being supported by Twitter, so it now requires real accounts which are said to not be feasible for most public instances. Not sure if Poast.org has a smaller number of users or how they're handling it. Side note but it was the original maintainer (zedeus) a few weeks back who declared 'Nitter is dead' in a Github issue. reply qprofyeh 19 hours agoprevI wonder if archive.ph could work for at least the original tweet(s) reply theodric 10 hours agoprevI simply have a Twitter account (linked to a purpose-specific @goatse.email account, if you must know) and I log into the app on my phone and the website on my computers. This allows me to see all the content I like. I appreciate the position of the folks who want to use a third-party client (Christ's sake, I'm the author of Twittirix, the unpopular, entirely unknown, and now-dead Twitter client for SGI IRIX) but engaging with reality-as-it-is rather than lamenting the inaccessibility of reality-as-I-wish-it-were is a supremely useful way of interfacing with the world. reply vcg3rd 17 hours agoprevStarted using Twitter in 2006. [Long story] Quit around 2017. Privacy Badger extension blocks embeds. Used to allow occasionally until I noticed it was never worth it and finally stopped reading \"news\" sites that were sentence|tweet|s|t etc. Used Nitter for a while for the reason many do: to see that 1 tweet or thread that sounds interesting. Realized it either wasn't or was a little FOMO. When I was a kid if you missed a good movie in theaters you had to wait years to see it on TV. I've started returning to that mentality. If it's genuinely good enough and interesting enough it will turn up somewhere eventually or I'll just miss out. I can't number the people who have told me I must subscribe to AppleTV to watch some Ted show no one talks about any more. I always said: \"No. It will turn up on some platform I use or come out on Blu-ray or I'll just never see it.\" For all I know it's on Blu-ray already. I forgot about it until just now it's been so long since I must watch. reply troad 10 hours agoparent> If it's genuinely good enough and interesting enough it will turn up somewhere eventually or I'll just miss out. Waiting a few years for the marketing to die down, the hype to move on, and the dust to settle has served me well. Time is an amazing filter of quality. Twitter is a FOMO based product. What if you miss the latest announcement about some important breaking research development? What then?! You'll be behind! You'll have missed the bus! It's not like you can just wait five hours for the announcement to be reported on- oh wait. And how often does that actually happen? Virtually nothing on Twitter has a shelf-life of more than one news cycle, which is reason enough not to waste time on it. The signal-to-noise ratio on Twitter is abysmal, and has gotten much, much worse in the last five years. reply AlienRobot 19 hours agoprevI think you have 3 alternatives: 1. Create a Twitter account. 2. Stop using Twitter. 3. Use Facebook, Tumblr, or Mastodon for microblogging. Twitter started requiring a login screen to view posts, but it's not the first website to do so. Pinterest and Instagram have done this for ages. We all hate it, but it's business. I wonder why Tumblr isn't more successful than it is. It used to be a pretty well-known platform, and it's almost identical to Twitter, but while every celebrity seems to have a Twitter account, nobody seems to have a Tumblr account. Perhaps they do, they just don't tell anybody about it? I wish Mastodon wasn't a thing. I believe federation is a terrible idea for normal computer users due to its non-obvious dangers, specially as more people will begin using Mastodon as if it were Facebook. I saw on Reddit that someone is building an open source, non-federated Reddit clone. That's what I think would have been better: an open-source, non-federated Twitter clone. Does anybody know of something like that, by the way? reply dspillett 18 hours agoparent> I wonder why Tumblr isn't more successful than it is. It used to be a pretty well-known platform, and it's almost identical to Twitter, Twitter won over that and a number of other options on novelty, inertia, and notoriety, essentially. A mix of right-place-right-time, further luck, and network effects. Tumblr did better than many alternatives, but eventually shot itself in the foot (well, was shot in the foot by its parent) when it alienated a chunk of the audience it did have by deleting a lot of content in order to appease potential advertisers. reply NikkiA 15 hours agorootparent> in order to appease potential advertisers. It wasn't advertisers, it was apple, they'd been delisted from the app store, and getting rid of the NSFW material was part of the deal that apple would allow them back with. reply jsheard 19 hours agoparentprevTumblr used to be a lot more popular, but its collapse is usually attributed to them banning NSFW content. Not everyone was posting or viewing NSFW of course, but there was enough overlap in audiences to cause a cascade which ended with nearly everyone, NSFW or not, moving to Twitter. It's a classic Yahoo acquisition fumble, they bought it for $1.1 billion and ended up selling it on to Automattic for just $3 million post-exodus. reply paulddraper 12 hours agorootparentNone of those other platforms allowed NSFW, and even when it did allow it, Tumblr had a fraction of the popularity. reply yifanl 12 hours agorootparentTwitter might not allow NSFW content, but it has a lot of NSFW content nonetheless. reply PaulHoule 18 hours agoparentprevYou could just run a Mastodon instance that doesn't federate. reply AlienRobot 18 hours agorootparentI see. Does anybody do that, though? reply ajot 12 hours agorootparentI've recently read TFA from this discussion, and felt tempted to do the same. https://news.ycombinator.com/item?id=38825520 reply PaulHoule 18 hours agorootparentprevhttps://en.wikipedia.org/wiki/Gab_(social_network) reply prmoustache 12 hours agorootparentprevIsn't it what Donald Trump did with its mastodon instance? Or is it federated? reply hanniabu 19 hours agoprevFarcaster reply colpabar 19 hours agoprevIf you don't like twitter, why not just not use it? I guess it sucks that you can't click twitter links, but honestly, you're not missing anything. Whenever I jump through some hoop to view a tweet linked here, it's not worth it. reply ceejayoz 19 hours agoparentThere are sometimes newsworthy things on Twitter. I have the domain blocked at the Pihole to break the \"check Twitter\" loop I get into; having to do the Nitter thing helped enormously in breaking the bad habit. reply dspillett 18 hours agorootparent> There are sometimes newsworthy things on Twitter. If something is particularly newsworthy, it'll appear elsewhere in pretty short order IME, often it originated elsewhere in fact. reply ceejayoz 13 hours agorootparentSometimes the tweets themselves are newsworthy, or the news articles cite a tweet. Some local governments use Twitter for announcements you can't easily get elsewhere, especially during a disaster like a big snowstorm. reply dspillett 8 hours agorootparent> Some local governments use Twitter for announcements you can't easily get elsewhere, especially during a disaster like a big snowstorm. A bit like my national government seems to be run via WhatsApp… In an emergency situation, if twitter was the only rapid source, I'd have to go look there. This is partly why I said elsewhere in this thread that avoiding twitter isn't practical for everyone. The chances of such an emergency where I am is pretty remote. If any of my local politicians are listening: if there is something that important and you can't reliably provide information somewhere instead of (or as well as) twitter, rest assured that even if I voted for you last time I won't the next! reply prmoustache 11 hours agorootparentprevMost local gov have their own websites too. The thing is people used to check on them on twitter by default. reply dspillett 7 hours agorootparentThat, and some government run sites are under-resourced to survive the deluge of traffic that an emergency might generate. As much as I dislike twitter, I understand that it is a useful fallback. reply wl 11 hours agorootparentprevDuring the last natural disaster I found myself in, the authorities were updating Twitter and Facebook but not their official websites. At least the important/urgent stuff was going out through the emergency alert system. reply prmoustache 11 hours agorootparentFrom what I understand, the official measures in a situation of emergency and disaster in my country and local gov is: - messages on the fm radios - sms broadcasting reply wl 19 hours agoparentprevThere are people doing things of interest to me where I can either read it on Twitter (currently using Nitter's RSS feeds) or see the misleading blogspam or fluff-filled YouTube video about it a few days later. I'd rather get the information from the source. reply paulnpace 19 hours agoprevUse a completely different platform. Find users providing content you like. Follow them and interact. Either Twitter opens back up or segments trickle off the platform. I used nitter only because it loaded faster and displyed raw cronological order. Life existed before Twitter was created. You can do it. reply fnordpiglet 18 hours agoparentI think this misses the point that a lot of nitter users aren’t looking for a social media platform to interact with people on, but to access information only available on twitter. “Use a completely different platform” is useful to people consuming the social media product, but not useful for people who are uninterested in “content you like” but in very specific content they’re interested in. I’m not saying there’s a solution that’s good either or there needs to be a good solution. It’s a private business and there are all sorts of shitburger private businesses building golden walls around important content only available on their crappy platform and there’s no alternatives other than submit to their exploitation or remain ignorant in the world of subjects that are important to you. But it would be nice if there were alternatives between brutal exploitation and unrequited ignorance. But heading over to mastodon or whatever doesn’t help you read “important thread about X discovery” or whatever since the content is singular and only exists on twitter. Personally HN is the only social media like platform I use, and I have no interest in maintaining the energy levels to participate in the others. I’m just a passive observer of specific pieces of content in those platforms. reply dspillett 18 hours agorootparent> but to access information only available on twitter I see this being said a lot, even by some of my own contacts who insist on occasionally sending me links to things on twitter¹, but I'm not convinced there is really much of worth on there that isn't available elsewhere. What is uniquely on there that I might possibly care about isn't, IMO, worth being associated with or exposed to the rest. -- [1] I used to use nitter to view such things, but stopped that many moons ago and ask if they have any other source, or if it is a joke maybe download/screenshot and forward that way. reply fnordpiglet 18 hours agorootparentYou may feel the subject is inane, but an example that sticks out in my mind was the Varda replication thread of LK99. It was really only on twitter, I found it entertaining to read occasionally, but I wasn’t really going to invest energy in asking for screenshots etc. But I agree with you regarding being associated with it exposed to the rest. That’s the value nitter brought ! It’s a sad day that it’s gone. End of the world? No. But the world has become slightly less good. reply roywiggins 17 hours agorootparentprevTwitter at least used to be the best place to find official statements from local government, local cops, etc. They would put stuff out on their official accounts, other people would post video of news conferences, and so on. I am not sure there is a replacement. reply prmoustache 11 hours agorootparentyes, they can all have their private blog/microblog or use something else on the fediverse. You might have a tiny bit of friction in discoverability but it isn't hard to spread the word when it is about local agencies/administrations. reply ehPReth 7 hours agorootparentI would love this. Absolutely love this. Unfortunately, this is not happening now. The vast majority of 'official'/'governmental' institutions/people seem post on Twitter and, sadly, only on Twitter. Maybe Facebook if you're lucky. I've had to resort to using the premium tier of IFTTT to get things like road closure notices for my area.. it's maddening. I'd love if they would set up some ActivityPub something under their own domain that I could subscribe to :/ reply fnordpiglet 3 hours agorootparentprevCan is arbitrarily complex. Reality is they don’t. I actually wish the UN had acquired twitter as a global public good than baby man boy. reply vdaea 19 hours agoprevnitter.cz is one of many mirrors. The official site was nitter.net (which is down as well). reply rideontime 19 hours agoprevThe alternative is to finally abandon twitter for good. reply timeon 16 hours agoparentHow? There are currently 2 HN submissions which are twitter links. reply prmoustache 11 hours agorootparentAnd you are threatened at gun point to click on those links? reply rideontime 12 hours agorootparentprevI'm not sure I understand the question. reply ksherlock 16 hours agorootparentprevYou don't need to click every link you see on hacker news. reply Astraco 11 hours agorootparentAnd you don't have to comment reply AwaAwa 18 hours agoparentprevToo few people who care, too many that are happy to be fed what the twitter algo decides they should see. Dopamine takes care of the rest. reply s1artibartfast 18 hours agorootparentToo few people care for what to happen? Maybe I am misreading your post, but why does it matter if people behave in a certain way en masse, when the majority of the personal impact is based on personal behavior. reply pierat 18 hours agoparentprevThis is the actual answer... but social networks are super sticky, and trap people in with the threat of cutting other people off who also cant/wont leave. reply BiteCode_dev 18 hours agoparentprevDespite the outrage, I think only a minority of users think this. Most twitter users like it, and didn't even attempt to move to another platform. I personally tried substack notes, mastodon and bluesky, and none of them bring 0.1% of the activity and interesting things that used to happen on twitter. Now twitter is less interesting than before, but it still the only candidate that is worth my time. Even reddit is slowly becoming meh. I'm certain that the new generation, however, is creating their own wonderland in a place I'm not active in. That's how we got twitter started, it's usually the young that stir those things. reply lupusreal 19 hours agoprevnext [2 more] [flagged] renegade-otter 15 hours agoparentThe only winning move is NOT to play. Social media is a massive time sink. reply zoeysmithe 19 hours agoprevnext [15 more] [flagged] BiteCode_dev 18 hours agoparentThere is no such thing as \"one twitter\", it's way too big. I assume your activity mean you must be filtered in a bucket that shows you those things, because I never encounter such tweets in my timeline. reply sneak 19 hours agoparentprevSo does Google, Facebook, Tumblr, Cloudflare, GoDaddy, and Dreamhost. Should we stop linking to all information on all of these platforms because some of the information is undesirable to some people? Do you allow others to poison your well like that? If so, that strikes me as easily exploitable. Also, the idea that this sort of content is inherently dangerous doesn’t hold water. I’m not going to become a white supremacist because Twitter showed me a racist tweet. Information and ideology is not inherently dangerous. reply bsder 17 hours agorootparent> So does Google, Facebook, Tumblr, Cloudflare, GoDaddy, and Dreamhost. That is intentionally and maliciously obfuscating the issue by equating social media (Google, Facebook, Tumblr) with infrastructure hosting (Cloudflare, GoDaddy, and Dreamhost). Those two types of companies are very different and should be regulated very differently. > Should we stop linking to all information on all of these platforms because some of the information is undesirable to some people? Um, yes? Links to social media vaporize regularly. If it isn't worth the effort to pull and host onto a less ephemeral medium, was it really worth sharing at all? reply chimprich 18 hours agorootparentprev> So does Google, Facebook, Tumblr, Cloudflare, GoDaddy, and Dreamhost. Those are all very different things. Only Facebook is somewhat similar in that it has an algorithm that surfaces emotionally engaging content. > I’m not going to become a white supremacist because Twitter showed me a racist tweet. How about if it showed you 50 racist tweets? If repetition and exposure didn't have any effect on our behaviour then there would be no advertising market and no one would bother to spend vast sums on political campaigning. > Information and ideology is not inherently dangerous. How about misinformation? As an example, I'd say the rise in anti-vaccination activity is an example of inherently dangerous information that has been spread primarily through social media. reply sneak 18 hours agorootparentNeither is misinformation inherently dangerous. There are 400,000 churches in the US and every year fewer people identify as religious. reply mschuster91 19 hours agorootparentprev> Also, the idea that this sort of content is inherently dangerous doesn’t hold water. I’m not going to become a white supremacist because Twitter showed me a racist tweet. Information and ideology is not inherently dangerous. There's been enough work that suggests a close link between exposure to propaganda and getting funneled in to increasingly more radical material, e.g. [1]. Particularly regarding Twitter, it's noticeable that it's not just one racist tweet that gets shown to you when you deliberately click on one - the space below will be filled with similar kind of content, and you can see a marked increase of far-right crap on your algorithmic timeline as well, with every little interaction you have with far-right content. It was bad before Musk, but since his takeover it's gotten really really bad. [1] https://www.technologyreview.com/2020/01/29/276000/a-study-o... reply madamelic 18 hours agorootparent> you can see a marked increase of far-right crap on your algorithmic timeline as well, with every little interaction you have with far-right content. And? I trust people to be intelligent enough to make their own decisions. If seeing an incredibly (or even mildly) racist tweet suddenly makes them proverbially goose-step around their home, they already were going to. One, ten, or hundred posts won't make them racist unless they were already predisposed to those ideas. In a healthy mind, viewing alternative views may broaden their view which might include disagreeing with their previous opinions. If viewing a gay marriage doesn't make you gay, neither does seeing someone complain about other races or LGBT people. I am on 'your' side politically but the opinion that all conservative opinion should be extinguished or somehow that it is inherently harmful because you disagree with is just as bad as conservatives saying the same about your opinion. There is no harm in reading and understanding other's opinions. All sides need to understand that. It only crosses into the need for 'deplatforming' when they are making implicit or explicit threats against a person or a group of people. \"I thinkrace is less likely to be successful due to \" is not a bad opinion. It may be wrong, but it isn't hurtful beyond maybe to someone who is too sensitive. \"I thinkrace should be exterminated\" is beyond the line and shouldn't be allowed to be posted publicly. reply logicalmonster 16 hours agorootparent> If viewing a gay marriage doesn't make you gay, neither does seeing someone complain about other races or LGBT people. This is a great line that probably pisses off almost everybody. Love it. reply sneak 18 hours agorootparentprevYour link mentions YouTube. Under your logic, should we also stop using YouTube because its recommendations will radicalize us? This line of thinking doesn’t make sense to me. Furthermore, bad ideology and its ideologues won’t go away simply because we individually stop looking at them. I quit Twitter after 12 years when they started censoring the site search. I was trying to research QAnon wackos and it turns out that the search box had been neutered. It’s one thing to tell people what they can post, it’s another to tell me what I’m not allowed to read (that is allowed to be posted). Fuck censorship. reply tjpnz 19 hours agoparentprevWhat one individual might view as transphobia another would view as radical feminism. The world's not as black and white as you make it out to be. reply madeofpalk 18 hours ago [flagged]rootparentnext [4 more] yikes oops i accidentally terfed myself reply ben_w 18 hours agorootparentThe initialism \"TERF\" means \"trans-exclusionary radical feminism\"; I'm sure those who hold these views see themselves as being \"just\" radical feminists — the way the discussions go, it seems to me people with these views are unable to comprehend that the model they have of what gender is, is one of several, or that there is any value in the models they do not themselves have. reply merfing 16 hours agorootparentThere's only room for one model when it comes to deciding who gets to use which space though. For example, should a male convict who identifies as a woman be incarcerated in the female prison estate or the male one? There's not really room for several models of sex and gender in answering that question, as there's a single choice to be made with two mutually exclusive options. reply ben_w 16 hours agorootparent> There's only room for one model when it comes to deciding who gets to use which space though. One model per space. For example, the answer to \"given how much testosterone is now in their body, which gender sports team should this F2M person be on?\" is different to \"which do we need to screen them for, testicular cancer or cervical cancer?\" > For example, should a male convict who identifies as a woman be incarcerated in the female prison estate or the male one? There's not really room for several models of sex and gender in answering that question, as there's a single choice to be made with two mutually exclusive options. Four[0] options, if you think outside the box. Ideally, I would have my prisons set up with enough guards that this doesn't matter. As I don't live in the ideal world, I would also have a[0] trans estate for those who have begun but not yet completed transitioning, and those who have completed a transition would be in whatever the new gender is. [0] or +1, if M2F != F2M while transitioning reply 28 more comments... GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The website Nitter, known for frequently encountering rate-limited errors, has announced its eventual shutdown.",
      "The availability of alternative options for Nitter remains uncertain.",
      "It is recommended to find alternative platforms for the functionalities provided by Nitter."
    ],
    "commentSummary": [
      "The discussion tackles platform alternatives, data privacy, advertising effectiveness, content moderation, and challenges in accessing and scraping content from platforms like Twitter and Reddit.",
      "Users are frustrated with the limitations and restrictions of major platforms, propose alternatives, and express concerns about privacy and data access.",
      "The conversation also highlights declining quality, functionality, and the difficulty in navigating away from major platforms. Users explore methods and tools to access and preserve content while avoiding restrictions, emphasizing the need for open, accessible, and user-friendly platforms that prioritize privacy and control over personal information."
    ],
    "points": 237,
    "commentCount": 279,
    "retryCount": 0,
    "time": 1708004702
  },
  {
    "id": 39381435,
    "title": "Indian government bans ProtonMail over bomb threat",
    "originLink": "https://www.androidcentral.com/apps-software/indian-government-moves-to-ban-protonmail-after-bomb-threat",
    "originBody": "Apps & Software Indian government moves to ban ProtonMail after bomb threat News By Harish Jonnalagadda published 15 February 2024 A ProtonMail account was used to send bomb threats to schools in the region, so the government wants to ban the service outright. Comments (0) (Image credit: Harish Jonnalagadda / Android Central) What you need to know The Indian government's Information Technology ministry issued an order to block ProtonMail in the region. The move comes after a bomb threat was sent to schools in Chennai via a ProtonMail account. ProtonMail is still active in the country as of writing, but it remains to be seen if that will continue to be the case. ProtonMail is the best choice if you want an end-to-end encrypted email platform, and the nature of the service means it is inevitably used by bad actors. On February 8, a bomb threat was sent to 13 schools in Chennai, a city in the state of Tamil Nadu in southern India. The threat turned out to be a hoax, and the Tamil Nadu police found that the email was sent via a ProtonMail account. Unable to trace the IP address of the sender and failing to get assistance from Interpol, the Tamil Nadu police put in a request to India's Ministry of Electronics and Information Technology to block access to ProtonMail within the country, according to Hindustan Times. That request was granted today, with the government authority issuing an order to block the service in the region. The enforcement will be carried out by the Department of Telecommunications, which will likely entail delisting ProtonMail from the App Store and Play Store. That said, the website is still working as of writing, and the app is listed on both storefronts. This isn't the first instance where the Indian government went after the Swiss-based Proton AG. Proton VPN pulled its servers out of the country following a controversial 2022 ruling by the Indian government mandating providers to maintain usage logs. As for the ProtonMail ban, Proton AG sent a statement to Hindustan Times that it was working with the government over the issue. \"We are currently working to resolve this situation and are investigating how we can best work together with the Indian authorities to do so. We understand the urgency of the situation and are completely clear that our services are not to be used for illegal purposes. We routinely remove users who are found to be doing so and are willing to cooperate wherever possible within international cooperation agreements.\" The issue is that Proton AG didn't hand over the IP address to Indian authorities. As the email provider told Hindustan Times, it cannot do that under Swiss law: \"Proton cannot answer directly to foreign law enforcement authorities, but Swiss authorities may assist foreign authorities with requests, provided they are valid under international assistance procedures and determined to be in compliance with Swiss law” The government's move is in line with a recent policy that has targeted services with end-to-end encryption. A host of encrypted apps were blocked at the start of last year — including the likes of Threema, Element, Wickrme, and Safeswiss — and the government is going after WhatsApp to disable end-to-end encryption, although it isn't clear how that would even work. Proton AG clearly agrees with that sentiment, as it said this to HT: \"We condemn a potential block as a misguided measure that only serves to harm ordinary people. Blocking access to Proton is an ineffective and inappropriate response to the reported threats. It will not prevent cybercriminals from sending threats with another email service and will not be effective if the perpetrators are located outside of India.\" I'll share an update once there are more details, but if you use ProtonMail in India, there's a good chance that the service may be inaccessible. Be an expert in 5 minutes Get the latest news from Android Central, your trusted companion in the world of Android Contact me with news and offers from other Future brands Receive email from us on behalf of our trusted partners or sponsors By submitting your information you agree to the Terms & Conditions and Privacy Policy and are aged 16 or over. Harish Jonnalagadda Senior Editor - Asia Harish Jonnalagadda is a Senior Editor overseeing Asia at Android Central. He leads the site's coverage of Chinese phone brands, contributing to reviews, features, and buying guides. He also writes about storage servers, audio products, and the semiconductor industry. Contact him on Twitter at @chunkynerd. MORE ABOUT APPS SOFTWARE YouTube looks to 'Remix' Shorts for creators inspired by music videos Google announces Gemini 1.5 as it seeks the 'next generation' of AI LATEST Galaxy Z Fold 6 camera leak doesn't suggest anything exciting SEE MORE LATEST ► TOPICS PROTONMAIL SEE ALL COMMENTS (0) No comments yet Comment from the forums MOST POPULAR Custom Multiviews in YouTube TV let you pick four basketball games to watch at once By Brady SnyderFebruary 15, 2024 The Samsung Galaxy Fit 3 poses for the camera in this hands-on video By Jay BonggoltoFebruary 15, 2024 Indian government moves to ban ProtonMail after bomb threat By Harish JonnalagaddaFebruary 15, 2024 The Galaxy Z Flip 5 and Fold 5 are picking up the February 2024 security update By Jay BonggoltoFebruary 15, 2024 Android's photo picker now supports Google Photos and other cloud media apps By Vishnu SarangapurkarFebruary 15, 2024 Chrome web pages should load faster thanks to a Safe Browsing update By Brady SnyderFebruary 15, 2024 Wunderlist creators launch a new to-do app to handle all your lists By Johnny FloresFebruary 15, 2024 Google One is playing hide-and-seek with its 200GB plan By Jay BonggoltoFebruary 15, 2024 OpenAI tests 'memory' for ChatGPT so you won't have to repeat yourself By Nickolas DiazFebruary 15, 2024 Google's pre-Pixel Fold 'Jumbojack' prototype just popped up for sale By Michael L HicksFebruary 15, 2024 Samsung and Huawei reportedly prep for a new rollable and foldable push By Nickolas DiazFebruary 14, 2024 TOPICS PROTONMAIL MOST READ 1 Galaxy Z Fold 6 camera leak doesn't suggest anything exciting 2 YouTube looks to 'Remix' Shorts for creators inspired by music videos 3 Nothing Phone 2a price leak doubles down on its budget market 'shake up' 4 Seriously?! The 2023 Amazon Fire HD 10 tablet is 42% off right now 5 Google announces Gemini 1.5 as it seeks the 'next generation' of AI",
    "commentLink": "https://news.ycombinator.com/item?id=39381435",
    "commentBody": "Indian government moves to ban ProtonMail after bomb threat (androidcentral.com)232 points by thunderbong 22 hours agohidepastfavorite142 comments i67vw3 21 hours agoWtf!! I am user of Protonmail and its other services (from India). The protonmail ID is actually my main Email-Id and is used everywhere, even on government sites. Hope https://internetfreedom.in/ steps in or some other organization. reply miroljub 20 hours agoparentWhen registering your next mail, make sure to register a domain first, and use it as your online identity. reply brink 17 hours agorootparent> \"Just in - Indian government moves to ban i67vw3.com -\" reply solardev 17 hours agorootparentDamn it, now all my friends have to switch to i67vw4.com! reply qart 21 hours agoparentprevYep. Same here. I'll get locked out of my bank account too. reply behringer 17 hours agoparentprevI wouldn't trust someone else to host my email ID. Get yourself your own domain at porkbun.com, make sure it's a .com or at least a very reliable TLD that won't be going anywhere, and then setup proton to point to it. You are no longer locked into any one provider :) You can always transfer your domain and you can always transfer your email host. reply dutchCourage 15 hours agorootparentDo your due diligence when choosing a registrar. I recall a blog post where an attacker got access to the blogger's domain through a social engineering attack on the registrar, and subsequently got access to their emails. I'm curious if anyone knows the article I'm mentioning and how to prevent such an attack. I couldn't find the article back. reply abdullahkhalids 15 hours agorootparentIf the social engineering can get past 2FA, then the only options you have are 1. The registrar has offices in your country, so you can take legal action against them. Of course, this also means that your despotic government can force the registrar to ban you, etc. 2. The registrar is not in your country, so you depend on their benevolence to reverse the social engineering. reply canistel 19 hours agoprevWhat do you expect? They banned VLC for months, for some silly reason. https://www.indiatoday.in/technology/news/story/vlc-player-h... reply rldjbpin 23 minutes agoprevyou have to wonder just how much such rulings help anyone. - practically nobody uses the service in the country (especially when dealing with hundreds of millions connected on the internet), and for some this might have a streissand effect. - those using such services for nefarious reasons would have little to no reason to abide by it. IT law enforcement is already very ineffective as it is, and would only be used as a lever when dealing with cases the administration has special interest in. - this is not really a matter of encryption but about data sharing arrangements with other countries (as correctly pointed out in the comments). funnily enough it is against the law to refuse decryption (https://en.wikipedia.org/wiki/Information_Technology_Act%2C_...). reply rockyj 22 hours agoprevBan everything you cannot control / understand! That is the classic Indian bureaucracy reaction. For example, They also banned tinted windows in cars after an assualt happened in a car. Then, there was a time where they banned something or the other on a daily basis. Even right now there is Section 144 imposed in multiple cities - which means a \"ban\" on \"unlawful assembly\" of 5 or more people. 5 or more people in multiple cities which have a population of millions! Now, how do they enforce / check these \"assemblies of people\" depends on the people you ask. I have already spoken too much. reply jatins 21 hours agoparent> Ban everything you cannot control / understand! That is the classic Indian bureaucracy reaction Reminds me of how India's leading research institute removed ceiling fans to prevent student suicides https://www.indiatoday.in/education-today/news/story/iisc-ba... reply alephnerd 21 hours agoparentprevThe issue is India doesn't have a judicial agreement with Switzerland over data sharing (which includes User IP Addresses) for criminal investigations [0] while the US does [1], and Protonmail only honors Swiss litigation [2] This should change with the new India-Switzerland FTA though. [0] - https://carnegieendowment.org/files/ParsheeraJha_DataAccess.... [1] - https://www.dataprivacyframework.gov/framework-article/1%E2%... [2] - https://proton.me/legal/law-enforcement reply jwalton 20 hours agorootparentI think the actual issue is that a government holds the insane belief that by blocking one out of many ways that someone could make an anonymous threat, it somehow contributes to the safety of their citizens. reply alephnerd 20 hours agorootparent> blocking one out of many ways that someone could make an anonymous threat, it somehow contributes to the safety of their citizens If you make an anonymous bomb threat using Gmail in India, Google will hand off all information to the Indian government as they have operations in India and will be held liable, just like they would in the US. This is the reason why Proton AG honors American law enforcement requests - the US and Switzerland have an agreement that data platforms in both countries need to honor each other's law enforcement requests. If Proton AG won't give User metadata without litigation in Switzerland, it will get blocked in those jurisdictions it doesn't play ball with. This is why most piracy platforms and data platforms will honor metadata requests from US Law Enforcement - you will become a toxic financial liability if you choose to flout US litigation. reply shaan7 19 hours agorootparentYour statements are correct but they aren't relevant to parent's point. Blocking an email provider has absolutely no positive effect on the safety of the citizens. While it has the potential of a lot of negative effects, like the inability of other innocent citizens to use their email account. It is the same thing when the GoI went ahead and blocked pastebin.com because of a bunch of pastes. reply kumarvvr 18 hours agorootparent> Blocking an email provider has absolutely no positive effect on the safety of the citizens. If all the available platforms allow for data sharing and tracking on judicial orders, then a perpetrator does not have a safe way to give threats, without the risk of being identified. In my opinion, this is a deterrent in itself, the fear of getting caught. reply shaan7 14 hours agorootparentAh my bad, I should have explicitly mentioned that merely a threat does not constitute a safety issue enough to justify a broad ban. If such a ban could prevent a real attack, then sure. Yes, personally even I would feel disturbed and anxious when somebody threatens me, but it would be too broad to classify mental disturbance as a safety issue. I am saying this having survived an episode where my father was threatened for life. reply alephnerd 19 hours agorootparentprev> Blocking an email provider has absolutely no positive effect on the safety of the citizens I agree that it's a half assed patched, but if a platform isn't responding to litigation or law enforcement requests, there is always the chance of bad actors weaponizing that loophole. And it's not like Proton AG hasn't been linked to terror attacks. The perpetrator of the Bataclan Massacre used Protonmail to communicate with handlers, leading to the French government to require email platforms like Proton AG to honor French law enforcement requests [1]. [0] - https://www.wired.com/2015/11/isis-opsec-encryption-manuals-... [1] - https://www.ejn-crimjust.europa.eu/ejnupload/DynamicPages/Fr... reply protonmail 18 hours agorootparentThat is false information, there was no connection between Proton and the Bataclan attack. reply alephnerd 16 hours agorootparentUpvote this. Can't edit my previous comment which misread the wired article linked or can @Dang just delete the offending comment for incorrect/misleading info? reply heikrana 19 hours agorootparentprev> blocked pastebin.com because of a bunch of pastes Say what now?! reply alephnerd 19 hours agorootparentIt was a temporary block due to an overly broad denylist the Indian government put out in 2013. Pastebin ended up getting unblocked in India in the same time period as well. reply mdp2021 18 hours agorootparentprev> using Gmail in India, Google will hand off all information Why should you use am E-Mail provider to send an electronic postcard. Since when would you need a third party to send E-Mails? reply capybara_2020 19 hours agorootparentprevIt feels like the Indian gov is reactionary and has tunnel vision. They fix one problem but never consider if that fix will cause problems elsewhere or if even if that fix is worth it. reply manuelabeledo 18 hours agorootparentprevThe issue is that India has a body of hand picked bureaucrats, who have the authority to both target and ban platforms they cannot control or spy on. The article clearly states that all was a hoax and there weren't any bombs. The Indian government is setting up a nice slippery slope here for total political control of the Internet. Perhaps ProtonMail would be better off if they just pulled out of the country. reply alephnerd 15 hours agorootparent> issue is that India has a body of hand picked bureaucrats, who have the authority to both target and ban platforms they cannot control or spy on Agreed. Indian jurisprudence has not kept up and is still stuck in an authoritarian mindset found in the Colonial British legal system (same problem in Pakistan, Malaysia, Kenya, and Singapore as well btw) > setting up a nice slippery slope here for total political control of the Internet The Indian government has always had the authority to control electronic communication due to the Indian Telegraph Act, 1885 [0] and it's equally authoritarian successor the Telecommunications Act, 2023 [1]. India always has been, and sadly, always will be an Illiberal Democracy, and for the exact same reasons that Malaysia, Kenya, and Pakistan will be as well. It's the original sin of the British Colonial legal system. [0] - https://en.m.wikipedia.org/wiki/Indian_Telegraph_Act,_1885 [1] - https://en.m.wikipedia.org/wiki/Telecommunications_Act,_2023 reply jszymborski 18 hours agorootparentprevRight, but the US didn't block Yandex Mail when it was HQ'd in Russia. It's not for Switzerland's data sharing with the US that folks in the US have access to ProtonMail. reply jwr 21 hours agoparentprevIt's not specifically Indian. Canada just banned Flipper Zero devices because the little radios can replay car key fob signals and older cars are susceptible to replay attacks. Stupidity is everywhere. reply cedws 21 hours agorootparentUK government has tried to ban encryption time and time again. This is what happens when you have old/incompetent career politicians in power instead of deep thinkers like scientists and engineers. reply ChrisMarshallNY 21 hours agorootparent> deep thinkers like scientists and engineers That doesn't work, either, because they tend to be rather dismissive of human concerns, and, at its heart, government is all about humans. I don't have a solution, but I don't think that declaring that only one-or-another \"class\" of humans is fit to govern, is it. reply midasuni 20 hours agorootparentThe U.K. has a system where experts in various fields like medicine and engineering are put in the lawmaking process, in addition to experts in becoming elected (ie raising money and selling non tangible ideas to people) It’s not perfect of course, but in my opinion it’s better than a fully democratic system. reply pmontra 20 hours agorootparentDo those unelected experts advise on new legislation, even write it (why not? We don't expect elected politicians to be experts in much more than ordinary people) or do they also vote to approve or reject those laws like elected politicians do? reply eigenket 18 hours agorootparentTheoretically they do both. I think the system that the above commenter is alluding to is the House of Lords, where a bunch of unelected \"lords\" can vote on legislation. The idea is for the lords to be people with particular expertise who we want to be voting on stuff. For example if you have some very highly thought of scientist or engineer you reward them with a peerage and they can sit in the house of lords and vote on stuff. Of course the reality is not so great. https://en.wikipedia.org/wiki/Life_peer reply jvanderbot 21 hours agorootparentprevThat's a stereotype and probably not true. Many deep thinkers are humanists. It's probably more likely around the hyper rational types, but my boss is the most empathetic engineer I've ever worked for. This is anecdotal but your comment seems fairly clearly overbroad reply ChrisMarshallNY 20 hours agorootparent> Many deep thinkers are humanists. That's the deal, though. Engineers and scientists don't have a monopoly on \"deep thinker™\". My sister is a \"deep thinker.\" She has an economics degree from Princeton, and has been working at very high levels, for decades. Very decent human being. Not sure if she'd be interested in being a \"leader,\" though. That's part of the problem; it's almost as if wanting the job, automatically disqualifies you. But you are right. It's an overbroad statement. reply lynx23 20 hours agorootparentprevI've seen the stereotype confirmed on HN several times already. Whenever I, a blind pedestrian, voice my concerns about driverless car technology, I am being downvoted and outright critizised. The undertone is \"How can this single person try to block an emerging technology\". That pretty much confirms the statement that tech people sometimes have a hard time with human concerns. reply 0xBDB 14 hours agorootparentI am empathetic to your concerns but I may or may not agree with your proposed solutions. I do think it's always important to keep in mind that empathy and compassion aren't the same thing, or always aligned. Compassion is more utilitarian. Driverless cars will save a lot of lives when the technology is good enough, and the compassionate thing is implementing the technology when it saves more lives than it endangers. If that's the non-empathy you are getting from the HN community then the community is right, but again, I genuinely empathize even so. reply yungporko 20 hours agorootparentprevi think it just confirms that in any given group of people, a majority percentage of them will be self absorbed dickheads. reply suoduandao3 20 hours agorootparentI don't think it's always necessarily a majority - it's just always going to be more than we estimate. reply YurgenJurgensen 21 hours agorootparentprevIt's worse than you think. Read the Criminal Justice Act (Offensive Weapons) Order 1988 (S.I 1988/2019) and marvel at some of the nonsense some politician thought it important to ban. My personal favourite is \"Death Stars\", since it creates the mental image of some constable trying to confiscate a superlaser-equipped battlestation. reply pritambaral 6 hours agorootparentHere's the relevant text of the legislation: > the weapon sometimes known as a “shuriken”, “shaken” or “death star”, being a hard non-flexible plate having three or more sharp radiating points and designed to be thrown; reply jvanderbot 21 hours agorootparentprevIts possible for young people to make these mistakes. My wife is not an old man and her default position is not to defend e2e encryption. So all it takes is a spurious argument against it (think of the children!) and without skin in the game she is happy to go along. The argument is about proportional gain vs proportional loss and she is not aware of the devastating loss of privacy that would come from banning strong safe encryption. reply supriyo-biswas 21 hours agorootparentYou could prevent this by teaching rational thinking and cognitive biases at the school level, but I assume the reason that hasn’t happened yet because said students would start calling out the hyperbole that politicians and business people often like to employ. reply gryn 20 hours agorootparentIt Would not be enough. Good unbiased Thinking requires effort. To optimize this there are caching mechanisms at multiple levels, from inside your brain to the societal level to save the energy required to do the thinking. If you deem that cache and all future ones to be invalid(untrustworthy) you'll have to do a lot of thinking from scratch. If you want to practically brick such agent you'll just need to do a denial of service by bringing a huge deluge of claims that they have to spend more than their lifetime thinking through all of them critically. reply jvanderbot 15 hours agorootparentprevI am not going to jump to the bait of defending my own wife as a rational person. Instead I'll just point out that difference in information is not difference in ability. She just wasn't aware encryption was used basically everywhere, and so could be forgiven for not having at hand the information to refute the assertion that some back doors in one algorithm or system is harmless. Only an education in these subjects will help, or a widespread awareness campaign by educated folks. Or even a law protecting it as a fundamental right. Just as I criticize her field all the time, and am quickly embarrassed by my presumption of hyper rational super powers. Or at least I was for years.. I'm getting better. reply marcosdumay 21 hours agorootparentprevAt least electromagnetic transmitters are something one expect to be regulated. It is bad regulation, but it's just overzealous. Email ban is borderline censorship. reply jwr 21 hours agorootparentFlipper Zero complies with all regulations, it's a certified consumer device. That it can record and replay a radio signal is not something that should be regulated. We have laws for stealing cars, we don't need to ban specific tools that, among a multitude of other uses, might be used to steal a car. reply mantas 21 hours agorootparentSometimes overreaching laws is the only way. E.g. knife carrying laws. reply gryn 20 hours agorootparentwe should ban people from buying kitchen knives ! better not cach you in your trip from the mall to your house. /s reply mantas 16 hours agorootparentI was thinking about knives carrying laws. reply Chris2048 17 hours agorootparentprevWhat if the only use for FZ was stealing cars, would that change things? reply bobsmith432 19 hours agorootparentprevThe 1986 Assault Weapons Ban in the US restricted the sale and ownership of several non-existant gun attachments and modifications. It also for some reason banned specific guns like the KS-23 (quite ridiculous gun you should read on if you're a fan of them) that was only manufactured in the Soviet Union and other bloc states and literally couldn't be imported to the US normally regardless because it used the barrel off a 23mm aircraft cannon. Remember to always put someone with no knowledge of guns in charge with making gun laws. reply bheadmaster 21 hours agoparentprev> Now, how do they enforce / check these \"assemblies of people\" depends on the people you ask. I assume police officers enforce / check them when they need to fill their ticket quota, want to get money through a bribe, or just want to punish someone who personally annoyed them? That's how it usually works with half-enforced laws. In every law, there should be a requirement that it either gets enforced equally, or it loses power. reply Intermernet 20 hours agorootparentBut who enforces the equality of the enforcement? The only feasible system for this is 100% transparency of all legal proceedings and massive penalties for obscuring any legal proceedings. Governments and law enforcement bodies have only ever paid lip service to these ideals. They always resort to excuses involving \"national security\", \"Realpolitik\" or other convenient constructs that just happen to bias the legal system towards the incumbent powers. reply konschubert 21 hours agorootparentprevSelective enforcement transfers all power to the enforcer. reply candiodari 20 hours agorootparent... which is the point. reply OJFord 21 hours agorootparentprevIt doesn't even have to be that deliberate - these kinds of things end up being the reason you can use when you can't find/prove another. Which has 'good' uses too I suppose, as in where everyone agrees it was correct even if technical process a bit silly. (Not just cop on the street arresting 'obvious' drug dealers or whatever for unlawfully assembling, but charging mafia with tax evasion, or sexual assaulter CEOs with securities fraud.) But.. I'm guessing the majority of unlawful 5 or more assembly cases are not 'good'. reply AwaAwa 20 hours agorootparentprevThis is true of every nation on earth. The bar is lower in countries where volumes work better. reply WarOnPrivacy 20 hours agorootparentprev> In every law, there should be a requirement that it either gets enforced equally, or it loses power. The evil twin of this is maximized enforcement where enforcement and punishment have become a strong focus and shaping societal behavior is maybe a justification. It is the point at which we have lost our way. reply bheadmaster 1 hour agorootparentWhich in turn is caused by inflexibility of law change. If a law in place is found to be overly strict or general, then it should be changed or removed, and doing so should be simple and swift. reply goda90 20 hours agoparentprev> For example, They also banned tinted windows in cars after an assualt happened I think every jurisdiction should put limits on how tinted the windshield and front windows can be. Being able to see where a driver is looking is important in many situations in order to avoid collisions. It's especially important for pedestrians and cyclists that have to cross the path of cars. reply EasyMark 19 hours agorootparentI think this sort of government hand holding is unnecessary and promotes the surveillance state. I'm all for going back to the levels we had in the 70s. People should be given the means to be safe but it shouldn't forced on them, same with surveillance. I think putting bumper guards on everything in life leads to a society that is afraid of everything and values safety over liberty, like the society of today. reply bmicraft 6 hours agorootparentAs a cyclist I have to be very aware of people opening their car doors into my lane. This is a direct safety concerns for me and not some hurr durr soorvwaylanze concern about slippery slope fallacies. You wouldn't say this about OSHA either (I hope). This is not about protecting the person tinting their window, but everyone around them. As such, it doesn't even qualify as government hand holding. Your not protecting someone from themselves. reply baq 21 hours agoparentprev> Ban everything you cannot control / understand! That is the classic Indian bureaucracy reaction. This is the classic reaction of any government. I assure you Indian one is not in any way unique. That's why you need a strong constitution and an independent constitutional court - hardly possible, but at least it's a goal. reply kumarvvr 18 hours agoparentprevYou don't seem to understand governments. They are controlling it because they absolutely understand, and can give a narrative of how anonymity can be used for nefarious purposes. I support banning of tinted glasses, because, for the population and education level here, these measures are necessary. Because one rape is too many, and what is to be done ought to be done. For those unaware, this ban on tinted glasses in a car or a vehicle came about when there were a spate of rapes and assaults on women done in a moving car with tinted windows. Unlawful assembly laws are there in many countries. https://en.wikipedia.org/wiki/Unlawful_assembly In India, it is used often, but generally when there is a communal angle involved. India sees many rallies and protests (there is one massive one going on right now). reply manuelabeledo 18 hours agorootparent> For those unaware, this ban on tinted glasses in a car or a vehicle came about when there were a spate of rapes and assaults on women done in a moving car with tinted windows. A moving car? Gee, wonder why they didn't ban moving cars as well. reply zilti 17 hours agoparentprevIt is that way everywhere. Bonus points if you claim it is because terrorism or pedophiles. reply _giorgio_ 20 hours agoparentprevThey're searching for you right now. reply szundi 21 hours agoparentprevYou are now probably banned also HN. reply SmokeyHamster 19 hours agoparentprev\"India has banned rockyj from posting on Hacker News.\" reply _heimdall 21 hours agoprevThere's a pretty egregious misunderstanding of how email works in both the article and the proposed ban. Protonmail can only end-to-end encrypt email when the receiver is also using Protonmail. The email spec has no support for a universal encryption method, one of the reasons we'd be better off not using email at all today. They also don't explain how the inability to track the sender's IP is specific to Protonmail. Unless I missed a key feature, Protonmail doesn't do anything to hide or obscure the sender's IP. reply alephnerd 21 hours agoparent> inability to track the sender's IP is specific to Protonmail The issue is India doesn't have a judicial agreement with Switzerland over data sharing (which includes User IP Addresses) for criminal investigations [0] while the US does [1], and Protonmail only honors Swiss litigation [2] This should change with the new India-Switzerland FTA though. [0] - https://carnegieendowment.org/files/ParsheeraJha_DataAccess.... [1] - https://www.dataprivacyframework.gov/framework-article/1%E2%... [2] - https://proton.me/legal/law-enforcement reply _heimdall 19 hours agorootparentIndia is target Protonmail rather than all companies in countries that India doesn't have an agreement with though, right? My point was just that singling out Protonmail doesn't make sense and misses the point on how email works. reply alephnerd 19 hours agorootparentThink of laws like Blacklists/Deny Lists. A platform is default allowed until it denies to comply with Law Enforcement Requests. When that happens, a platform can by denied/blacklisted. This is why Protonmail is blocked in India and not Gmail or Yahoo. If Proton AG decided to ignore US Law Enforcement requests, it would get shut down the same way. This exact thing happened to Lavabit in 2013. reply _heimdall 14 hours agorootparentI may be getting out over my skis here, hopefully someone will correct me if so. But I believe this is the main distinction with a Common Law system, where everything is default legal unless regulated by legislation. Effectively, laws are only blocklists under legal systems based on Common Law. I don't know for sure if India is Common Law, though given its history with the British Empire I would guess that it isn't. reply alephnerd 13 hours agorootparentIndia is Common Law as well. Former British Dependencies like India, Malaysia, Singapore, Canada, South Africa, New Zealand, Ireland, and Australia are ruled under Common Law with additional colonial authoritarian flourishes, as these dependencies could be overruled by Westminster until the mid-late 1900s. England, Wales, and North Ireland are themselves Common Law, and it's somewhat common for Indian lawyers to cross apply to join the English Inns of Court as well. That said, modern India is starting to transition towards an American style common law system over the British one, as America has way more of an impact in India today. Civil/Roman/Latin Law is a continental thing. You'll see influences of it in former Spanish, French, and Russian colonies. reply behringer 17 hours agoparentprevThat is completely untrue. Email supports end to end encryption between any two servers. You set each server up with a list of supported protocols and denied protocols. If either side can't agree on the encryption algorithm, then the email does not go through. If both sides do agree, which is almost always the case if both sides are using industry standard encryption methods, then the email is end to end encrypted. On top of that, we have PGP encryption which allows the user to encrypt the email from everybody including the email provider. Only the recipient email address and possibly the subject line would be readable to the email providers. As for the IP, if protonmail removes the sender's origin IP then it's removed and that's it. Email is one of our best methods of international communication available today. reply _heimdall 5 hours agorootparentThere aren't many services that support e2e encryption though. I've been a Protonmail user for years and only remember being able to send encrypted emails to other PM users, maybe Fastmail also supports the same protocols? Regardless, if I'm not mistaken encryption protocols are layered on and not part of the official email spec. I'm not 100% on that so may it was added to the spec as an optional feature, but by no means is it common (especially with the market share Gmail owns). reply behringer 3 hours agorootparentPGP supports all email carriers. But there's also server side encryption that is end to end. If both the sender and recipient uses a trusted mail server that uses encryption then nobody between the two can see the email. reply thih9 22 hours agoprevI guess they will receive their next threat from a gmail account? reply nottorp 22 hours agoparentYou're not thinking big enough. Next email should come from the Indian government's email. Considering how tech aware they are, I'm sure there are hundreds of thousands of indian gov email acounts with passwords like 1234... reply tempodox 20 hours agorootparentThis would make things interesting, since they'd have to ban governmental use of email then. reply davchana 18 hours agorootparentprevWhat if it comes by postal mail i.e. India Post? reply alex_smart 3 hours agorootparentWhat if it comes by a pigeon? Oh no! reply vinni2 22 hours agoparentprevwhich is easier to trace presumably? reply thih9 22 hours agorootparentI suppose not by much if you create a new one or use somebody else’s data. I’m sure the proton one wasn’t also someone’s main email account. reply helsinkiandrew 22 hours agorootparentBut Google will usually provide logs/IP addresses (not content) to police without a warrant, which can be used to start tracking down the culprit. It isn't clear from the report if the Police got a warrant or even made a request to ProtonMail. reply chollida1 21 hours agorootparent> But Google will usually provide logs/IP addresses (not content) to police without a warrant, which can be used to start tracking down the culprit. Not in Canada. Google has been very clear they don't give anything to law enforcement without a warrant. Where are you getting your information from? Because its very scary if true. reply spacecadet 21 hours agorootparentprevMost do not just sign in to a compromised account and send and email from their laptop... It usually involves some level of obscurity. Im sure if they want to find out bad enough they will- but I would be surprised if this was sent by someone just sitting there. reply ijhuygft776 19 hours agorootparentprevyou used to be able to create a protonmail account using Tor.... so I guess it might be easier reply recroad 21 hours agoprevIndia for all intents and purposes is now an ethno-national state with no press freedom, severe persecution of minorities, and human rights violations aplenty. I grew up in India when it was a relatively secular state. For example, when the Babri Masjid (mosque) was destroyed by Hindus in the early 90s, the national magazine, India Today and major newspapers led with the headline, \"India's Shame\" and acknowledge how bad that was for Indian secularism. Less than a month ago the same mosque was now converted into a Hindu temple and the press and government led the cheerleading. https://www.aljazeera.com/news/2024/1/22/why-is-indias-ram-t... reply 1sembiyan 21 hours agoparent1. No press freedom: what explains the presence and popularity of the wire, scroll, news minute, the quint, etc? Traditional print media that’s critical of the current party in power includes The Hindu, Telegraph etc. That there’s no press freedom is false. 2. Ethno-nationalist state: what ethnicity are we talking about here? BJP loses often in elections locally, and majority of their opponents are Hindus. What India has always been is illiberal. You are weakening your point by exaggerating the current conditions. Moreover this prosed ban is because we have an overzealous bureaucracy that doesn’t understand technology and does not care to. It’s got nothing to do with what India has become. reply supriyo-biswas 21 hours agorootparentAs a data point, the previous government that grandparent speaks of also has been involved in actual suspension of democracy, abolition of press rights, and jailing of opposition leaders[1]. Indian administrations have always have had an authoritarian bent regardless of who has been in power. [1] https://en.m.wikipedia.org/wiki/The_Emergency_(India) reply derpitron 18 hours agorootparentprev1. The government has been, or is trying to take down media pieces critical of them, including but not limited to investigations on Indian Army Torture in Kashmir[1] and documentaries about the current Prime Minister's role in locally fomented pogroms in 2002[2]. They have also been using the income tax enforcement apparatus to punish dissident independent news organisations such as The Quint[3] and Newslaundry[4]. That these news organisations are allowed to exist (as of 2024) is merely a compromise because outright banning and suppressing the organisation for no clear wrong doing would be bad for optics. It is in no way a litmus test for the measure of effective press freedom there actually exists. 2. The previously mentioned 2002 Gujarat pogrom[5], come to mind, supported by complacent ministers such as the now Prime Minister Modi, who was banned from the USA and several other nations due to his role in the incident (until recently)[6]. The Prime Minister and his party have been silent on ensuing regional ethnic conflict that has killed more than 200 people thus far.[7] The term 'Bulldozer Justice' was coined from the practice of BJP ruled states demolishing Muslim people's homes using bulldozer machines with public support, under the pretext of \"illegal constructions\" [8] The BJP party is the political wing of the Hindutva outfit RSS (whose claim to fame is one of their members having assassinated Mahatma Gandhi. [9]) Throughout the decade of their governance, they, their regional sub-parties and their corporate partners have systematically enacted policies of aforementioned media suppression, public communications suppression in the face of mass protest/mobilization[10][11], arbitrary arrest of protesters under British colonial era sedition laws without bail[12][13] mass internet traffic surveillance via Deep Packet Inspection[14]. They have suspended around 150 opposition MPs as of a few months ago[15]. All the above which I've listed are bad enough but there are many more skeletons in the proverbial closet which I don't have the energy to recall and cite at the moment. None of the above points to India as being a free and secular nation. To engage in semantic handwaving is a frankly pathetic attempt of apologism. I wish I had more time to elaborate but I'm horrified that I even need to. [1] https://www.thehindu.com/news/national/govt-orders-magazine-... [2] https://www.washingtonpost.com/world/2023/01/25/india-bbc-na... [3] https://www.thehindu.com/news/national/it-raids-at-premises-... [4] https://www.newslaundry.com/2023/05/05/at-least-44-times-ove... [5] https://en.wikipedia.org/wiki/2002_Gujarat_riots [6] https://www.theguardian.com/world/2012/oct/22/uk-ends-boycot... [7] https://economictimes.indiatimes.com/news/politics-and-natio... [8] https://time.com/6303571/how-bulldozers-became-a-symbol-of-a... [9] https://www.thehindu.com/news/national/pm-modi-continues-to-... [10] https://www.deccanherald.com/india/haryana/farmers-protest-m... [11] https://www.theguardian.com/world/2023/sep/25/a-tool-of-poli... [12] https://www.livelaw.in/articles/father-stan-swamy-uapa-marty... [13] https://main.sci.gov.in/supremecourt/2023/29067/29067_2023_1... [14] https://cis-india.org/internet-governance/blog/reliance-jio-... [15] https://economictimes.indiatimes.com/news/politics-and-natio... reply web108 15 hours agorootparentThis comment is filled with so many half-truths and misinformation, it should not belong here. Please respect hacker news guidelines https://news.ycombinator.com/newsguidelines.html * Please don't use Hacker News for political or ideological battle. That tramples curiosity.* reply oarla 20 hours agoparentprevTangential to the article being discussed, as this is not about secularism. Not all the facts provided, just a one sided view that is parroted repeatedly in online forums with the intention of claiming a moral high ground when the facts are far more complex and intricate. reply heikrana 18 hours agorootparent> the facts are far more complex and intricate Exactly. reply dartharva 20 hours agoparentprevThe mosque was converted by a judgement from India's Supreme Court. But yes, the administration's stunt of overtly participating in religious conflict by having the PM and country leaders inaugurate the temple sure leaves a bad taste. Thankfully, religion as a whole is becoming increasingly irrelevant among new generations as Western individualism takes over. This incident will hopefully be remembered just as an appeasement tactic for old to middle-aged people and not an escalation. reply bluish29 19 hours agorootparent>The mosque was converted by a judgement from India's Supreme Court Many would say that doesn't change anything because they think that Indian supreme court is just another tool in the hand of Modi's government [1] [2] [3]. [1] https://www.lemonde.fr/en/international/article/2023/12/27/i... [2] https://www.theatlantic.com/international/archive/2024/02/wh... [3] https://www.lawfaremedia.org/article/india-s-justice-system-... reply dartharva 17 hours agorootparentMany would say that regarding this decision, yes. But they'd be overlooking the kind of exceptional dilemma the court faced in this case - it was not just about determining what club gets a legal right over public property, but about defusing a several generations-long historical and religious conflict of vastly higher scale. In the end they had to pass a judgement that antagonized the least number of people and prevented large-scale disruption and violence. We can debate how right or wrong it was all day, but that won't take away the fact that there was no other way of resolving this without messing up social harmony. Whether or not Modi's government has undue influence over the judiciary is still up for debate, but in this particular case, I fail to see how it could have made a difference either way. reply 2Gkashmiri 6 hours agorootparentIsnt it just convenient. To hell with due process and law and justice and equality. Give a judgenent that offends least number of people, be it right or wrong. You know how that sounds like? A corrupt judiciary that's at the whims of satisfying the ego of masses. Btw >The incident, which resulted in heavy casualties, had shaken the entire nation and the collective conscience of the society will only be satisfied if the capital punishment is awarded to the offender. This quote from an actual judgment made by supreme court of India literally says so. To satisfy collective consciousness of masses, a man must die reply recroad 19 hours agorootparentprevYes, many would say that and they'd be correct in saying that. reply unmole 20 hours agoparentprev> ethno-national state Arguably the most diverse country in the world is an ethno-national state? reply huytersd 18 hours agorootparentWell, it’s a very diverse “ethno” reply dotnet00 18 hours agoparentprevIndia is illiberal and authoritarian, but boiling down the extremely complex issue of the Babri Masjid to \"Hindus tore it down and replaced it with a temple\" is very disingenuous. The case remained unaddressed - even through the rule of more secular parties - for decades for good reasons. Plus, India has a long record of kneejerk censorship. There was the incident with GitHub back in 2014, and even before then there have been many cases of the national or state governments censoring material that could be construed as criticizing them or material they could construe as supporting a terrorist movement. reply sremani 18 hours agorootparentYes, India is not liberal and Yes, India has leaders who concentrated power in their hands overrode the States. On the other side of the spectrum if you have lived experience of the 80s, you would understand chaos and anarchy of multiple ethno-insugrencies. As a man who grew up in South India, I am proponent of State's rights etc. But it's not magic, India's geography and demogrphics compel, this cycle of powerful center that is near authoritarian to weak center that is a monumental chaos. In between there are periods of some balance. That was the nature of India since the Mahajanapadha period. reply ridiculous_leke 13 hours agoparentprevSuch claims have absolutely no relevance to the story. The block request came from Tamil Nadu police where major politics is on the opposite end of the spectrum. I wish I could go back to the time where people actually read the article and stay on point. reply eklavya 20 hours agoparentprevYeah not like they won a case in supreme court or something. Do you honestly believe they couldn't have done that with violence in all these years? I don't understand, some people here just really have a beef with India/Hindus. reply testhn2ac 19 hours agoparentprevnext [2 more] [flagged] heikrana 18 hours agorootparent> Aljazeera funded by the 'human rights friendly' government of Qatar says so. Must be the truth :)) Lol reply upofadown 21 hours agoprevThis all seems a bit confused. This has nothing to do with encryption. ProtonMail cooperates with law enforcement to track down users, but they do need a proper legal process. They won't just release user information on a simple request. They do have the ability to capture IP addresses. ProtonMail is accessible over Tor, but they don't allow registration/verification over Tor. reply heikrana 18 hours agoparent> ProtonMail is accessible over Tor, but they don't allow registration/verification over Tor. They do now. reply seatac76 18 hours agoprevBureaucracy does its thing. Interesting how governments just do not understand technology. reply testhn2ac 19 hours agoprev> Unable to trace the IP address of the sender and failing to get assistance from Interpol, the Tamil Nadu police put in a request to India's Ministry of Electronics and Information Technology to block access to ProtonMail within the country, according to Hindustan Times. That request was granted today, with the government authority issuing an order to block the service in the region. This is at the request of a state police of Tamilnadu. This particular state in India is ruled by a Party that's against Modi and his party. Question here, why can't Protonmail cooperate with the police investigating bombing threat against schools ? reply lukan 19 hours agoparentBecause swiss and india have no jucidial agreement on sharing data, but working on it. reply dommer 20 hours agoprevWhat an ad for ProtonMail - Governments cannot track you. reply Gys 19 hours agoprevJust ban terrorism. Problem solved. reply shinryuu 19 hours agoprevIf you’re making a bomb threat through normal mail. Are they going to ban the post as well? reply mrtksn 21 hours agoprevSo they want to block the service? Why not simply block incoming mail from ProtonMail? reply SmokeyHamster 19 hours agoprevWould the ban work the other way too? As a PM user, would I stop receiving a ton of spam from Indian addresses? reply testhn2ac 19 hours agoparentMove to Google if the PM spam filter is so bad reply acatton 21 hours agoprev> ProtonMail is the best choice if you want an end-to-end encrypted email platform Is this native advertisement? There are many other choices, some of them being as good if not better. A few of them are small mom-and-pop businesses which didn't take on investment, and won't enshittify ( https://en.wiktionary.org/wiki/enshittification ) * https://www.privacytools.io/privacy-email * https://github.com/pluja/awesome-privacy?tab=readme-ov-file#... reply szundi 21 hours agoprevBest ad reply alephnerd 21 hours agoprev\"On February 8, a bomb threat was sent to 13 schools in Chennai, a city in the state of Tamil Nadu in southern India. The threat turned out to be a hoax, and the Tamil Nadu police found that the email was sent via a ProtonMail account. Unable to trace the IP address of the sender and failing to get assistance from Interpol, the Tamil Nadu police put in a request to India's Ministry of Electronics and Information Technology to block access to ProtonMail within the country\" reply BLKNSLVR 21 hours agoparentWait until they hear about the inability for US authorities to trace swatting phone calls and robocalls and scam texts. Ban the phone system! reply alephnerd 21 hours agorootparentIn the US, local PDs can and have litigated telcos over swatting [0]. Every state has a Anti-Swatting Litigation Task Force within their AG now to take Telcos to court over swatting incidents. On the other hand, India doesn't have a judicial agreement with Switzerland over data sharing for criminal investigations [1] (while the US does [2]), and Protonmail only honors Swiss litigation [3] This should change with the new India-Switzerland FTA though. [0] - https://portal.ct.gov/AG/Press-Releases/2022-Press-Releases/... [1] - https://carnegieendowment.org/files/ParsheeraJha_DataAccess.... [2] - https://www.dataprivacyframework.gov/framework-article/1%E2%... [3] - https://proton.me/legal/law-enforcement reply sampli 21 hours agoprevHopefully they use gmail next reply honeybadger1 20 hours agoprev\"The Indian government uses a bomb threat as an excuse to take away more of your freedom\" reply verisimi 21 hours agoprevBureaucrats will write rules. No need to follow them. Why can a jumped up idiot determine what's right or wrong? reply ijhuygft776 19 hours agoprevWhy don't they ban phones too? reply nimish 19 hours agoparentThey severely restricted the buying of SIM cards after the Mumbai terror attacks on the flimsy basis that the terrorists used cell phones to coordinate them . In practice it means that it's a massive pain to get a local number when visiting family. VOIP intra-country is also illegal, but it's not clear if that's regulatory capture or for similar \"national security\" grounds. reply ijhuygft776 10 hours agorootparent> it's not clear if that's regulatory capture or for similar \"national security\" grounds The reason given doesn't matter that much... they give whatever reason they think most people will approve. reply miohtama 19 hours agoparentprevChina is already there, leading the pack. If you are Uighur ethnicity you need to use a special government issued “phone” or force installed app. They really use it as a tracking device. https://www.hrw.org/news/2019/05/01/interview-chinas-big-bro... reply supertrope 16 hours agoparentprevSatellite phones are banned. reply 2Gkashmiri 21 hours agoprev [–] https://www.onmanorama.com/content/mm/en/kerala/top-news/202... so apparently a child was abducted and one thing led to another and the child was recovered so the child revealed how he was shown tom and jerry cartoon. the police then went on a fishing trip and literally cross referenced which user in a particular area watched tom and jerry on youtube at a particular time/date to find the cuprits. if this wont get your antenna up, i dont think anything else will proton thing is normal compared to this reply mfrw 20 hours agoparentIf this is the current condition, what alternatives are there that you may suggest apart from; `Don't use it!` reply 2Gkashmiri 18 hours agorootparentDont use what? reply mfrw 18 hours agorootparentYouTube/Gmail/etc etc and everything that the government is tracking. FWIW, they are tracking our internet with all sorts of fancy technology. I think probably what I meant to ask is: What do you use to by-pass censorship ? reply rockyj 21 hours agoparentprevFunnily enough, it reminds me of this - https://www.youtube.com/watch?v=jnk8Bwk3r_M (from the 17:00 mark) reply astura 21 hours agoparentprev [–] This seems like normal police work? reply EasyMark 18 hours agorootparentI think that they're point at the police state monitoring everything you watch on tv or accessing it. reply 2Gkashmiri 18 hours agorootparentprev [–] Normal police work meaning you can willy nilly go and canvass internet browsing history of thousands of citizens ? What stops them from taking political vendetta ? reply GuidelinesFAQListsAPISecurityLegalApply to YCContact Search:",
    "originSummary": [
      "The Indian government has ordered a block on ProtonMail in the country following a bomb threat sent via a ProtonMail account to schools in Chennai.",
      "ProtonMail, an encrypted email platform, is currently active, but its future accessibility remains uncertain.",
      "The government's action is in line with its policy targeting services with end-to-end encryption, while Proton AG is working with the Indian government to find a resolution and stressing that its services should not be used for illegal activities."
    ],
    "commentSummary": [
      "The Indian government is considering a ban on ProtonMail following a bomb threat, sparking concerns and consequences among users.",
      "The discussion covers various instances of bans and restrictions in India, debating their effectiveness and expressing concerns about government control over the internet.",
      "Topics also include encryption methods in email communication, press freedom in India, and controversies surrounding religious and political issues. Additionally, limitations of tracing phone calls and government tracking of internet activity are discussed."
    ],
    "points": 232,
    "commentCount": 143,
    "retryCount": 0,
    "time": 1707996296
  }
]
